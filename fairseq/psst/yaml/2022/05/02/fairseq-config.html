<article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Recreating PSST challenge parameters in YAML</h1><p class="page-description">I don't even know why I did this</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-05-02T00:00:00-05:00" itemprop="datePublished">
        May 2, 2022
      </time>
       â€¢ <span class="read-time" title="Estimated read time">
    
    
      1 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/notes/categories/#fairseq">fairseq</a>
        &nbsp;
      
        <a class="category-tags-link" href="/notes/categories/#psst">psst</a>
        &nbsp;
      
        <a class="category-tags-link" href="/notes/categories/#yaml">yaml</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/jimregan/notes/tree/master/_notebooks/2022-05-02-fairseq-config.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/notes/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/jimregan/notes/master?filepath=_notebooks%2F2022-05-02-fairseq-config.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/notes/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/jimregan/notes/blob/master/_notebooks/2022-05-02-fairseq-config.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/notes/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2022-05-02-fairseq-config.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The following cell is an attempt to recreate the parameters for the PSST challenge in YAML.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<div class="highlight"><pre><span></span><span class="nt">common</span><span class="p">:</span>
  <span class="nt">fp16</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
  <span class="nt">log_format</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">json</span>
  <span class="nt">log_interval</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">50</span>

<span class="nt">checkpoint</span><span class="p">:</span>
  <span class="nt">no_epoch_checkpoints</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
  <span class="nt">best_checkpoint_metric</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">uer</span>

<span class="nt">task</span><span class="p">:</span>
  <span class="nt">_name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">audio_finetuning</span>
  <span class="nt">data</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">???</span>
  <span class="nt">max_sample_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1120000</span>
  <span class="nt">normalize</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">false</span>
  <span class="nt">labels</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ltr</span>

<span class="nt">dataset</span><span class="p">:</span>
  <span class="nt">num_workers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
  <span class="nt">max_tokens</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1120000</span>
  <span class="nt">skip_invalid_size_inputs_valid_test</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
  <span class="nt">validate_after_updates</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1000</span>
  <span class="nt">validate_interval</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
  <span class="nt">valid_subset</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">valid</span>

<span class="nt">distributed_training</span><span class="p">:</span>
  <span class="nt">ddp_backend</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">no_c10d</span>
  <span class="nt">distributed_world_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>

<span class="nt">criterion</span><span class="p">:</span>
  <span class="nt">_name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ctc</span>
  <span class="nt">zero_infinity</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>

<span class="nt">optimization</span><span class="p">:</span>
  <span class="nt">max_update</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">12000</span>
  <span class="nt">lr</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="nv">0.00005</span><span class="p p-Indicator">]</span>
  <span class="nt">sentence_avg</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
  <span class="nt">weight_decay</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.0</span>
  <span class="nt">update_freq</span><span class="p">:</span> <span class="p p-Indicator">[]</span>

<span class="nt">optimizer</span><span class="p">:</span>
  <span class="nt">_name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">adam</span>
  <span class="nt">adam_betas</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">(0.9,0.98)</span>
  <span class="nt">adam_eps</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1e-08</span>

<span class="nt">lr_scheduler</span><span class="p">:</span>
  <span class="nt">_name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">tri_stage</span>
  <span class="nt">phase_ratio</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="nv">0.33</span><span class="p p-Indicator">,</span> <span class="nv">0.33</span><span class="p p-Indicator">,</span> <span class="nv">0.33</span><span class="p p-Indicator">]</span>
  <span class="nt">final_lr_scale</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.05</span>

<span class="nt">model</span><span class="p">:</span>
  <span class="nt">_name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">wav2vec_ctc</span>
  <span class="nt">w2v_path</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">???</span>
  <span class="nt">apply_mask</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
  <span class="nt">mask_prob</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.65</span>
  <span class="nt">mask_channel_prob</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.25</span>
  <span class="nt">mask_channel_length</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">64</span>
  <span class="nt">layerdrop</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.1</span>
  <span class="nt">activation_dropout</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.1</span>
  <span class="nt">feature_grad_mult</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.0</span>
  <span class="nt">freeze_finetune_updates</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
  <span class="nt">final_dropout</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.1</span>
  <span class="nt">attention_dropout</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.1</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This cell is a modification of <a href="https://raw.githubusercontent.com/pytorch/fairseq/6d2cf0ddf64040543c346b3866eb636d14522dde/examples/wav2vec/config/finetuning/base_10m.yaml">base_10m.yaml</a> from the fairseq source</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<div class="highlight"><pre><span></span><span class="c1"># @package _group_</span>

<span class="nt">common</span><span class="p">:</span>
  <span class="nt">fp16</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
  <span class="nt">log_format</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">json</span>
  <span class="nt">log_interval</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">50</span>

<span class="nt">checkpoint</span><span class="p">:</span>
  <span class="nt">save_interval</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1000</span>
  <span class="nt">save_interval_updates</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">50</span>
  <span class="nt">keep_interval_updates</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
  <span class="nt">no_epoch_checkpoints</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
  <span class="nt">best_checkpoint_metric</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">uer</span>

<span class="nt">task</span><span class="p">:</span>
  <span class="nt">_name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">audio_pretraining</span>
  <span class="nt">data</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">???</span>
  <span class="nt">max_sample_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1120000</span>
  <span class="nt">normalize</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">false</span>
  <span class="nt">labels</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ltr</span>

<span class="nt">dataset</span><span class="p">:</span>
  <span class="nt">num_workers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
  <span class="nt">max_tokens</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1120000</span>
  <span class="nt">skip_invalid_size_inputs_valid_test</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
  <span class="nt">validate_after_updates</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1000</span>
  <span class="nt">validate_interval</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
  <span class="nt">valid_subset</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">valid</span>

<span class="nt">distributed_training</span><span class="p">:</span>
  <span class="nt">ddp_backend</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">no_c10d</span>
  <span class="nt">distributed_world_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>

<span class="nt">criterion</span><span class="p">:</span>
  <span class="nt">_name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">ctc</span>
  <span class="nt">zero_infinity</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>

<span class="nt">optimization</span><span class="p">:</span>
  <span class="nt">max_update</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">12000</span>
  <span class="nt">lr</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="nv">0.00005</span><span class="p p-Indicator">]</span>
  <span class="nt">sentence_avg</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
  <span class="nt">update_freq</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="nv">4</span><span class="p p-Indicator">]</span>

<span class="nt">optimizer</span><span class="p">:</span>
  <span class="nt">_name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">adam</span>
  <span class="nt">adam_betas</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">(0.9,0.98)</span>
  <span class="nt">adam_eps</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1e-08</span>

<span class="nt">lr_scheduler</span><span class="p">:</span>
  <span class="nt">_name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">tri_stage</span>
  <span class="nt">phase_ratio</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="nv">0.1</span><span class="p p-Indicator">,</span> <span class="nv">0.4</span><span class="p p-Indicator">,</span> <span class="nv">0.5</span><span class="p p-Indicator">]</span>
  <span class="nt">final_lr_scale</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.05</span>

<span class="nt">model</span><span class="p">:</span>
  <span class="nt">_name</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">wav2vec_ctc</span>
  <span class="nt">w2v_path</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">???</span>
  <span class="nt">apply_mask</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
  <span class="nt">mask_prob</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.65</span>
  <span class="nt">mask_channel_prob</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.25</span>
  <span class="nt">mask_channel_length</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">64</span>
  <span class="nt">layerdrop</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.1</span>
  <span class="nt">activation_dropout</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.1</span>
  <span class="nt">feature_grad_mult</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.0</span>
  <span class="nt">final_dropout</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.1</span>
  <span class="nt">attention_dropout</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.1</span>
  <span class="nt">freeze_finetune_updates</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0</span>
</pre></div>

</div>
</div>
</div>
</div>



  </div><a class="u-url" href="/notes/fairseq/psst/yaml/2022/05/02/fairseq-config.html" hidden></a>
</article>