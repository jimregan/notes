{
  
    
        "post0": {
            "title": "Task list, 28/9/2021",
            "content": "Today . separation script: spleeter: see run_spleeter.py . | Extend abair xml to return list of timestamps; segment long recordings: notebook . | Rebase w2v notebook on this or this . | Add LM and timings: see here, repo, file, this issue, parlance/ctcdecode, wav2vec2_kenlm.py . | Fingerprint for known audio: dejavu . | Pass over input data, with this or something similar . | MFA, based on this . | . Look into: . Add official ASR CTC example to examples/pytorch/speech-recognition | Rewrite padding logic from pure python to numpy | Non-Adversarial Unsupervised Word Translation | Phonetic-and-Semantic Embedding of Spoken Words with Applications in Spoken Content Retrieval | grtzsohalf/Audio-Phonetic-and-Semantic-Embedding | SpeechToolsWorkers | . Personal . Run this See this: | . --match-filter &quot;license=&#39;Creative Commons Attribution license (reuse allowed)&#39;&quot; . Living audio . Longer term . TG4 Foghlaim scraper Lessons . | Scrape more Ros na R√∫n . | Compare this with stuff from last year . | Segmentation: run_cleanup_segmentation.sh, tedlium, AMI . | VOSK LM . | CUNY-CL . | . Look at: . 2dot71mily/youtube_captions_corrections | microsoft/Recognizers-Text | hiromis/notes | Alexander-H-Liu/NPC | andi611/Mockingjay-Speech-Representation | jina-ai/jina | Continue this ‚Äî p. 18 | scrapinghub/portia | wav2vec2-large-voxrex, Kungbib/swedish-bert-models | .",
            "url": "https://jimregan.github.io/notes/tasklist/2021/09/27/tasklist.html",
            "relUrl": "/tasklist/2021/09/27/tasklist.html",
            "date": " ‚Ä¢ Sep 27, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Interesting links, 27/9/2021",
            "content": "KTH Academic year 2021-22 . Irish pronunciation: practice and theory . A grammar of the Irish language . perfall/Edyson . Low Resource ASR: The Surprising Effectiveness of High Resource Transliteration pdf . @inproceedings{khare21_interspeech, author={Shreya Khare and Ashish Mittal and Anuj Diwan and Sunita Sarawagi and Preethi Jyothi and Samarth Bharadwaj}, title=, year=2021, booktitle={Proc. Interspeech 2021}, pages={1529--1533}, doi={10.21437/Interspeech.2021-2062} } . Exploring wav2vec 2.0 on Speaker Verification and Language Identification pdf . @inproceedings{fan21_interspeech, author={Zhiyun Fan and Meng Li and Shiyu Zhou and Bo Xu}, title=, year=2021, booktitle={Proc. Interspeech 2021}, pages={1509--1513}, doi={10.21437/Interspeech.2021-1280} } . Improving Accent Identification and Accented Speech Recognition Under a Framework of Self-Supervised Learning pdf . @inproceedings{deng21b_interspeech, author={Keqi Deng and Songjun Cao and Long Ma}, title=, year=2021, booktitle={Proc. Interspeech 2021}, pages={1504--1508}, doi={10.21437/Interspeech.2021-1186} } .",
            "url": "https://jimregan.github.io/notes/links/2021/09/27/misc-links.html",
            "relUrl": "/links/2021/09/27/misc-links.html",
            "date": " ‚Ä¢ Sep 27, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Cognitive and Structural Correlates of Conversational Speech Timing in Mild Cognitive Impairment and Mild-to-Moderate Alzheimer‚Äôs Disease - Relevance for Early Detection Approaches",
            "content": "Cognitive and Structural Correlates of Conversational Speech Timing in Mild Cognitive Impairment and Mild-to-Moderate Alzheimer‚Äôs Disease: Relevance for Early Detection Approaches . Background | . The present study examines whether the temporal characteristics of speech in a collaborative referencing task are associated with cognitive function and the volumes of brain regions involved in speech production and known to be reduced in MCI and AD pathology. . Method | Results | Conclusion | . Introduction . Speech and language impairments are indeed salient characteristics of MCI and early AD link . However, the cognitive and structural underpinnings of these speech-based measures in classification approaches have not been systematically investigated and are not fully established. link . Deficits in the lexical, semantic, executive, discourse and pragmatic domains of language are commonly observed in MCI and early AD link . AD speech is characterized by slower speech rate (global speed of speech including pauses), a higher number of silent pauses, longer pauses and shorter interpausal units (or chunks of speech bounded by silent pauses link . Expectations . | Participants . | Neuropsychological Tests . | Speech Annotation and Measure Extraction . | . The pause threshold used in the automatic procedure was set at 100 ms to ensure its distinction with silent plosives link . The significance level was set at Œ± = 0.006 link . Classification used cgplibrary . our exploratory analyses showed moderate accuracy rates for the speech-based classifiers in the pairwise contrasts link . Limitations . Abbreviations ‚Äî might have been more useful earlier .",
            "url": "https://jimregan.github.io/notes/journal%20club/2021/09/27/journal-club.html",
            "relUrl": "/journal%20club/2021/09/27/journal-club.html",
            "date": " ‚Ä¢ Sep 27, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Interesting links, 26/9/2021",
            "content": "A Framework for Any-to-Any Voice Conversion with Self-Supervised Pretrained Representations . howard1337/S2VC . yistLin/universal-vocoder; paper: Towards achieving robust universal neural vocoding . cywang97/unispeech; paper: UniSpeech: Unified Speech Representation Learning with Labeled and Unlabeled Data . microsoft/unilm ‚Äî UniLM AI - Large-scale Self-supervised Pre-training across Tasks, Languages, and Modalities . Continual-wav2vec2: an Application of Continual Learning for Self-Supervised Automatic Speech Recognition . Interactive demo: LayoutLMv2 . Improving Pretrained Cross-Lingual Language Models via Self-Labeled Word Alignment; CZWin32768/XLM-Align . waydroid/waydroid . huseinzol05/malaya-speech . Fine-tuning XLSR-Wav2Vec2 for WOLOF ASR with ü§ó . model = Wav2Vec2ForCTC.from_pretrained( &quot;facebook/wav2vec2-large-xlsr-53&quot;, attention_dropout=0.1, hidden_dropout=0.1, feat_proj_dropout=0.0, mask_time_prob=0.05, layerdrop=0.1, gradient_checkpointing=True, ctc_loss_reduction=&quot;mean&quot;, pad_token_id=processor.tokenizer.pad_token_id, vocab_size=len(processor.tokenizer) ) training_args = TrainingArguments( output_dir=&quot;./wav2vec2-large-xlsr-WOLOF&quot;, group_by_length=True, per_device_train_batch_size=16, gradient_accumulation_steps=2, evaluation_strategy=&quot;steps&quot;, num_train_epochs=40, fp16=True, save_steps=500, eval_steps=500, logging_steps=500, learning_rate=3e-4, warmup_steps=1000, save_total_limit=2, ) . run_spleeter.py . Few-shot Intent Classification and Slot Filling with Retrieved Examples . Comparing CTC and LFMMI for out-of-domain adaptation of wav2vec 2.0 acoustic model . Unsupervised Cross-Modal Alignment of Speech and Text Embedding Spaces .",
            "url": "https://jimregan.github.io/notes/links/2021/09/26/misc-links.html",
            "relUrl": "/links/2021/09/26/misc-links.html",
            "date": " ‚Ä¢ Sep 26, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Interesting links, 25/9/2021",
            "content": "Add an official audio classification example #13722 . To use your own dataset, convert your data into a csv or json format with the fields file and label like so: . worldveil/dejavu ‚Äî Audio fingerprinting and recognition in Python Blog . Perlence/PyGuitarPro ‚Äî Read, write and manipulate GP3, GP4 and GP5 files . alphaTab . microsoft/muzic ‚Äî Muzic: Music Understanding and Generation with Artificial Intelligence . ESPNet Colab . open-mmlab/mmaction2 ‚Äî OpenMMLab‚Äôs Next Generation Video Understanding Toolbox and Benchmark . Assisting the Human Fact-Checkers: Detecting All Previously Fact-Checked Claims in a Document . tree-sitter/tree-sitter . lima-vm/lima ‚Äî Linux virtual machines, on macOS (aka ‚ÄúLinux-on-Mac‚Äù, ‚ÄúmacOS subsystem for Linux‚Äù, ‚Äúcontainerd for Mac‚Äù, unofficially) . openai/triton ‚Äî a language and compiler for writing highly efficient custom Deep-Learning primitives . JohnSnowLabs/spark-nlp . Haskell Liftoff . mingrammer/diagrams ‚Äî Diagram as Code for prototyping cloud system architectures . babysor/MockingBird ‚Äî Clone a voice in 5 seconds to generate arbitrary speech in real-time . PaddlePaddle/PaddleOCR . jina-ai/jina . iperov/DeepFaceLive ‚Äî Real-time face swap for PC streaming or video calls . paulgavrikov/visualkeras/ . HarisIqbal88/PlotNeuralNet ‚Äî Latex code for making neural networks diagrams . keplr-io/quiver ‚Äî Interactive convnet features visualization for Keras . asappresearch/sew ‚Äî SEW (Squeezed and Efficient Wav2vec) Performance-Efficiency Trade-offs in Unsupervised Pre-training for Speech Recognition . Efficient Nearest Neighbor Language Models . google/fnet-base ‚Äî FNet is a transformers model with attention replaced with fourier transforms . Block Pruning For Faster Transformers . aterenin/phdthesis . pzelasko/kaldialign . bytedance/music_source_separation . mlflow/mlflow . willmcgugan/rich ‚Äî Rich is a Python library for rich text and beautiful formatting in the terminal. . smacke/ffsubsync ‚Äî Automagically synchronize subtitles with video. . chriskiehl/Gooey ‚Äî Turn (almost) any Python command line program into a full GUI application with one line . deanmalmgren/textract . scrapinghub/portia . bohanli/BERT-flow ‚Äî TensorFlow implementation of On the Sentence Embeddings from Pre-trained Language Models (EMNLP 2020) . 5 Podcasts To Listen To If You‚Äôre Learning Swedish . brapodcast.se . Podcast om Wikipedia . DeepFovea: Neural Reconstruction for Foveated Rendering and Video Compression using Learned Statistics of Natural Videos . PySimpleGUI/PySimpleGUI . tyiannak/pyAudioAnalysis .",
            "url": "https://jimregan.github.io/notes/links/2021/09/25/misc-links.html",
            "relUrl": "/links/2021/09/25/misc-links.html",
            "date": " ‚Ä¢ Sep 25, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "Utterance XML to json",
            "content": "import xml.etree.ElementTree as ET . class Utterance: def __init__(self, input, sentences): self.input = input self.sentences = sentences . class Sentence: def __init__(self, input, tokens): self.input = input self.tokens = tokens . class Token: def __init__(self, input, words): self.input = input self.words = words . class Word: def __init__(self, input, source, syllables, pos=&quot;&quot;): self.input = input self.source = source self.pos = pos self.syllables = syllables if self.syllables is None: self.syllables = [] def get_phonemes(self): return &quot; &quot;.join([a.get_phonemes() for a in self.syllables]) def get_clean_word(self): word = self.input if word[0:1] in &quot;nt&quot; and word[1:2] in &quot;A√ÅE√âI√çO√ìU√ö&quot;: return word[0:1] + &quot;-&quot; + word[1:].lower() else: return word.lower() . class Syllable: def __init__(self, stress: int = 0, phonemes = None): self.stress = stress self.phonemes = phonemes if self.phonemes is None: self.phonemes = [] def get_phonemes(self): return &quot; &quot;.join([a.symbol for a in self.phonemes]) . class Phoneme: def __init__(self, symbol: str = &quot;&quot;, end: float = 0.0): self.symbol = symbol self.end = end . def from_xml(source): tree = ET.parse(source) root = tree.getroot() if &#39;input_string&#39; in root.attrib: input = root.attrib[&#39;input_string&#39;] else: input = &#39;&#39; sentences = [] for sentence in root.findall(&#39;./sentence&#39;): if &#39;input_string&#39; in sentence.attrib: input = sentence.attrib[&#39;input_string&#39;] else: input = &#39;&#39; tokens = [] for token in sentence.findall(&#39;./token&#39;): if &#39;input_string&#39; in token.attrib: input = token.attrib[&#39;input_string&#39;] else: input = &#39;&#39; words = [] for word in token.findall(&#39;./word&#39;): if &#39;input_string&#39; in word.attrib: input = word.attrib[&#39;input_string&#39;] else: input = &quot;&quot; if &#39;trans_source&#39; in word.attrib: source = word.attrib[&#39;trans_source&#39;] else: source = &quot;&quot; if &#39;pos&#39; in word.attrib: pos = word.attrib[&#39;pos&#39;] else: pos = &quot;&quot; syllables = [] for syllable in word.findall(&#39;./syllable&#39;): phonemes = [] if &#39;stress&#39; in syllable.attrib: if syllable.attrib[&#39;stress&#39;] == &#39;None&#39;: stress = 0 else: stress = int(syllable.attrib[&#39;stress&#39;]) else: stress = 0 for phoneme in syllable.findall(&#39;./phoneme&#39;): if &#39;symbol&#39; in phoneme.attrib: symbol = phoneme.attrib[&#39;symbol&#39;] else: symbol = &#39;&#39; if &#39;end&#39; in phoneme.attrib: end = float(phoneme.attrib[&#39;end&#39;]) else: symbol = 0.0 phonemes.append(Phoneme(symbol, end)) syllables.append(Syllable(stress, phonemes)) words.append(Word(input, source, syllables, pos)) tokens.append(Token(input, words)) sentences.append(Sentence(input, tokens)) return Utterance(input, sentences) . def get_dictionary(utt): prons = {} for sent in utt.sentences: for tok in sent.tokens: for word in tok.words: if not word.get_clean_word() in prons.keys(): prons[word.get_clean_word()] = set() prons[word.get_clean_word()].add(word.get_phonemes()) return prons . utt = from_xml(&quot;/home/jim/tmp/pmg_ga_co/RCPiarsachALL/xml/MI0001RCPiarsachBairbre_0021.xml&quot;) . import json json.dumps(utt, default=lambda o: o.__dict__) . get_dictionary(utt) . co_pron_replacements = { &quot;thosaigh&quot;: &quot;h o s @&quot;, &quot;f√©in&quot;: &quot;h ee nj&quot;, &quot;haghaidh&quot;: &quot;h ai&quot; } . co_text_word_fixes = { &quot;RCPiarsachBairbre_0021.xml&quot;: [(&quot;ar&quot;, &quot;ar ar&quot;), (&quot;s√∫l&quot;, &quot;s√∫ile&quot;), (&quot;m√°thair&quot;, &quot;mothair&quot;)], } . import IPython.display as ipd ipd.Audio(&#39;/home/jim/tmp/pmg_ga_co/RCPiarsachALL/wav44_trimmed/MI0001RCPiarsachBairbre_0021.wav&#39;) .",
            "url": "https://jimregan.github.io/notes/irish/abair/mfa/2021/09/23/utterance-xml-to-mfa.html",
            "relUrl": "/irish/abair/mfa/2021/09/23/utterance-xml-to-mfa.html",
            "date": " ‚Ä¢ Sep 23, 2021"
        }
        
    
  
    
        ,"post6": {
            "title": "Swedish youtube scrape 1",
            "content": "Original on Kaggle . !pip install youtube-dl . !youtube-dl -o &#39;%(id)s.%(ext)s&#39; --match-filter &quot;license=&#39;Creative Commons Attribution license (reuse allowed)&#39;&quot; https://www.youtube.com/channel/UCagnPy0JPimGTqTzv1YQBpQ . [youtube:tab] UCagnPy0JPimGTqTzv1YQBpQ: Downloading webpage [download] Downloading playlist: Riksantikvarie√§mbetet - Home [youtube:tab] playlist Riksantikvarie√§mbetet - Home: Downloading 2 videos [download] Downloading video 1 of 2 [youtube:tab] heritageboard: Downloading webpage [download] Downloading playlist: Riksantikvarie√§mbetet - Videos [youtube:tab] Downloading page 1 [youtube:tab] Downloading page 2 [youtube:tab] Downloading page 3 [youtube:tab] Downloading page 4 [youtube:tab] Downloading page 5 [youtube:tab] Downloading page 6 [youtube:tab] Downloading page 7 [youtube:tab] Downloading page 8 [youtube:tab] Downloading page 9 [youtube:tab] Downloading page 10 [youtube:tab] Downloading page 11 [youtube:tab] Downloading page 12 [youtube:tab] Downloading page 13 [youtube:tab] Downloading page 14 [youtube:tab] Downloading page 15 [youtube:tab] Downloading page 16 [youtube:tab] playlist Riksantikvarie√§mbetet - Videos: Downloading 481 videos [download] Downloading video 1 of 481 [youtube] uU4M5-ajGt4: Downloading webpage [youtube] uU4M5-ajGt4: Downloading MPD manifest [download] Omv√§rld och insikt - Museipanelen does not pass filter license=&#39;Creative Commons Attribution license (reuse allowed)&#39;, skipping .. [download] Downloading video 2 of 481 [youtube] Kvz2xeTHN50: Downloading webpage [download] Destination: Kvz2xeTHN50.f137.mp4 [download] 100% of 412.77MiB in 00:30 [download] Destination: Kvz2xeTHN50.f140.m4a [download] 100% of 20.05MiB in 00:01 [ffmpeg] Merging formats into &#34;Kvz2xeTHN50.mp4&#34; Deleting original file Kvz2xeTHN50.f137.mp4 (pass -k to keep) Deleting original file Kvz2xeTHN50.f140.m4a (pass -k to keep) [download] Downloading video 3 of 481 [youtube] RafIRgJ-qPw: Downloading webpage [youtube] RafIRgJ-qPw: Downloading MPD manifest [download] Omv√§rld och insikt - Museipanelen does not pass filter license=&#39;Creative Commons Attribution license (reuse allowed)&#39;, skipping .. [download] Downloading video 4 of 481 [youtube] lnw92d5msqQ: Downloading webpage [youtube] lnw92d5msqQ: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 342 [download] Destination: lnw92d5msqQ.f247.webm [download] 100% of 178.10MiB in 02:07 [download] Destination: lnw92d5msqQ.f140.m4a [download] 100% of 28.11MiB in 00:01 [ffmpeg] Merging formats into &#34;lnw92d5msqQ.mkv&#34; Deleting original file lnw92d5msqQ.f247.webm (pass -k to keep) Deleting original file lnw92d5msqQ.f140.m4a (pass -k to keep) [download] Downloading video 5 of 481 [youtube] iJol2hdgYdw: Downloading webpage [youtube] iJol2hdgYdw: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 140 [download] Destination: iJol2hdgYdw.f248.webm [download] 100% of 82.07MiB in 00:50 [download] Destination: iJol2hdgYdw.f140.m4a [download] 100% of 10.96MiB in 00:00 [ffmpeg] Merging formats into &#34;iJol2hdgYdw.mkv&#34; Deleting original file iJol2hdgYdw.f248.webm (pass -k to keep) Deleting original file iJol2hdgYdw.f140.m4a (pass -k to keep) [download] Downloading video 6 of 481 [youtube] BoJ1-urZ5b4: Downloading webpage [youtube] BoJ1-urZ5b4: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 267 [download] Destination: BoJ1-urZ5b4.f248.webm [download] 100% of 130.54MiB in 01:36 [download] Destination: BoJ1-urZ5b4.f140.m4a [download] 100% of 20.99MiB in 00:01 [ffmpeg] Merging formats into &#34;BoJ1-urZ5b4.mkv&#34; Deleting original file BoJ1-urZ5b4.f248.webm (pass -k to keep) Deleting original file BoJ1-urZ5b4.f140.m4a (pass -k to keep) [download] Downloading video 7 of 481 [youtube] qDVkZW7BTQs: Downloading webpage [youtube] qDVkZW7BTQs: Downloading MPD manifest [download] Dag 3 - 03: Nonesthic ‚Äì en plattform f√∂r virtuella bes√∂k i kulturarvsbyggnader &amp; ‚ÄùPop In &amp; Play‚Äù does not pass filter license=&#39;Creative Commons Attribution license (reuse allowed)&#39;, skipping .. [download] Downloading video 8 of 481 [youtube] kfz1WOs30LE: Downloading webpage [youtube] kfz1WOs30LE: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 217 [download] Destination: kfz1WOs30LE.f248.webm [download] 100% of 36.33MiB in 01:17 [download] Destination: kfz1WOs30LE.f140.m4a [download] 100% of 17.08MiB in 00:01 [ffmpeg] Merging formats into &#34;kfz1WOs30LE.mkv&#34; Deleting original file kfz1WOs30LE.f248.webm (pass -k to keep) Deleting original file kfz1WOs30LE.f140.m4a (pass -k to keep) [download] Downloading video 9 of 481 [youtube] MPHHH_bN7ic: Downloading webpage [youtube] MPHHH_bN7ic: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 288 [download] Destination: MPHHH_bN7ic.f248.webm [download] 100% of 177.75MiB in 01:38 [download] Destination: MPHHH_bN7ic.f140.m4a [download] 100% of 22.62MiB in 00:03 [ffmpeg] Merging formats into &#34;MPHHH_bN7ic.mkv&#34; Deleting original file MPHHH_bN7ic.f248.webm (pass -k to keep) Deleting original file MPHHH_bN7ic.f140.m4a (pass -k to keep) [download] Downloading video 10 of 481 [youtube] 1Wbzean_07g: Downloading webpage [youtube] 1Wbzean_07g: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 240 [download] Destination: 1Wbzean_07g.f248.webm [download] 100% of 201.56MiB in 01:32 [download] Destination: 1Wbzean_07g.f140.m4a [download] 100% of 18.83MiB in 00:01 [ffmpeg] Merging formats into &#34;1Wbzean_07g.mkv&#34; Deleting original file 1Wbzean_07g.f248.webm (pass -k to keep) Deleting original file 1Wbzean_07g.f140.m4a (pass -k to keep) [download] Downloading video 11 of 481 [youtube] CnfKrwDxGag: Downloading webpage [youtube] CnfKrwDxGag: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 211 [download] Destination: CnfKrwDxGag.f248.webm [download] 100% of 128.89MiB in 01:14 [download] Destination: CnfKrwDxGag.f140.m4a [download] 100% of 17.25MiB in 00:01 [ffmpeg] Merging formats into &#34;CnfKrwDxGag.mkv&#34; Deleting original file CnfKrwDxGag.f248.webm (pass -k to keep) Deleting original file CnfKrwDxGag.f140.m4a (pass -k to keep) [download] Downloading video 12 of 481 [youtube] j8_pzb0Zj0c: Downloading webpage [youtube] j8_pzb0Zj0c: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 217 [download] Destination: j8_pzb0Zj0c.f248.webm [download] 100% of 69.01MiB in 01:19 [download] Destination: j8_pzb0Zj0c.f140.m4a [download] 100% of 17.75MiB in 00:01 [ffmpeg] Merging formats into &#34;j8_pzb0Zj0c.mkv&#34; Deleting original file j8_pzb0Zj0c.f248.webm (pass -k to keep) Deleting original file j8_pzb0Zj0c.f140.m4a (pass -k to keep) [download] Downloading video 13 of 481 [youtube] 5pJdR7pXEKA: Downloading webpage [youtube] 5pJdR7pXEKA: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 227 [download] Destination: 5pJdR7pXEKA.f248.webm [download] 100% of 129.12MiB in 01:25 [download] Destination: 5pJdR7pXEKA.f140.m4a [download] 100% of 18.58MiB in 06:54 [ffmpeg] Merging formats into &#34;5pJdR7pXEKA.mkv&#34; Deleting original file 5pJdR7pXEKA.f248.webm (pass -k to keep) Deleting original file 5pJdR7pXEKA.f140.m4a (pass -k to keep) [download] Downloading video 14 of 481 [youtube] k4dQAQ4grow: Downloading webpage [youtube] k4dQAQ4grow: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 212 [download] Destination: k4dQAQ4grow.f248.webm [download] 100% of 54.52MiB in 01:14 [download] Destination: k4dQAQ4grow.f140.m4a [download] 100% of 17.36MiB in 00:02 [ffmpeg] Merging formats into &#34;k4dQAQ4grow.mkv&#34; Deleting original file k4dQAQ4grow.f248.webm (pass -k to keep) Deleting original file k4dQAQ4grow.f140.m4a (pass -k to keep) [download] Downloading video 15 of 481 [youtube] kHX0PvydWQQ: Downloading webpage [youtube] kHX0PvydWQQ: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 207 [download] Destination: kHX0PvydWQQ.f248.webm [download] 100% of 120.15MiB in 01:15 [download] Destination: kHX0PvydWQQ.f140.m4a [download] 100% of 16.96MiB in 00:01 [ffmpeg] Merging formats into &#34;kHX0PvydWQQ.mkv&#34; Deleting original file kHX0PvydWQQ.f248.webm (pass -k to keep) Deleting original file kHX0PvydWQQ.f140.m4a (pass -k to keep) [download] Downloading video 16 of 481 [youtube] 2dmtx_ytJBc: Downloading webpage [youtube] 2dmtx_ytJBc: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 235 [download] Destination: 2dmtx_ytJBc.f248.webm [download] 100% of 169.85MiB in 01:28 [download] Destination: 2dmtx_ytJBc.f140.m4a [download] 100% of 19.24MiB in 05:52 [ffmpeg] Merging formats into &#34;2dmtx_ytJBc.mkv&#34; Deleting original file 2dmtx_ytJBc.f248.webm (pass -k to keep) Deleting original file 2dmtx_ytJBc.f140.m4a (pass -k to keep) [download] Downloading video 17 of 481 [youtube] mdsyDk4oG2I: Downloading webpage [youtube] mdsyDk4oG2I: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 183 [download] Destination: mdsyDk4oG2I.f248.webm [download] 100% of 68.80MiB in 01:04 [download] Destination: mdsyDk4oG2I.f140.m4a [download] 100% of 14.34MiB in 00:01 [ffmpeg] Merging formats into &#34;mdsyDk4oG2I.mkv&#34; Deleting original file mdsyDk4oG2I.f248.webm (pass -k to keep) Deleting original file mdsyDk4oG2I.f140.m4a (pass -k to keep) [download] Downloading video 18 of 481 [youtube] 3ydSZ9Uk-3A: Downloading webpage [youtube] 3ydSZ9Uk-3A: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 280 [download] Destination: 3ydSZ9Uk-3A.f248.webm [download] 100% of 41.92MiB in 01:37 [download] Destination: 3ydSZ9Uk-3A.f140.m4a [download] 100% of 22.00MiB in 00:02 [ffmpeg] Merging formats into &#34;3ydSZ9Uk-3A.mkv&#34; Deleting original file 3ydSZ9Uk-3A.f248.webm (pass -k to keep) Deleting original file 3ydSZ9Uk-3A.f140.m4a (pass -k to keep) [download] Downloading video 19 of 481 [youtube] tiM2l9rYrVw: Downloading webpage [youtube] tiM2l9rYrVw: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 252 [download] Destination: tiM2l9rYrVw.f248.webm [download] 100% of 95.93MiB in 01:34 [download] Destination: tiM2l9rYrVw.f140.m4a [download] 100% of 19.82MiB in 00:01 [ffmpeg] Merging formats into &#34;tiM2l9rYrVw.mkv&#34; Deleting original file tiM2l9rYrVw.f248.webm (pass -k to keep) Deleting original file tiM2l9rYrVw.f140.m4a (pass -k to keep) [download] Downloading video 20 of 481 [youtube] FPdgF5zRPcc: Downloading webpage [youtube] FPdgF5zRPcc: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 248 [download] Destination: FPdgF5zRPcc.f248.webm [download] 100% of 30.54MiB in 01:25 [download] Destination: FPdgF5zRPcc.f140.m4a [download] 100% of 19.52MiB in 00:03 [ffmpeg] Merging formats into &#34;FPdgF5zRPcc.mkv&#34; Deleting original file FPdgF5zRPcc.f248.webm (pass -k to keep) Deleting original file FPdgF5zRPcc.f140.m4a (pass -k to keep) [download] Downloading video 21 of 481 [youtube] XhoTQzu4VAE: Downloading webpage [youtube] XhoTQzu4VAE: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 157 [download] Destination: XhoTQzu4VAE.f248.webm [download] 100% of 100.06MiB in 00:58 [download] Destination: XhoTQzu4VAE.f140.m4a [download] 100% of 12.28MiB in 00:01 [ffmpeg] Merging formats into &#34;XhoTQzu4VAE.mkv&#34; Deleting original file XhoTQzu4VAE.f248.webm (pass -k to keep) Deleting original file XhoTQzu4VAE.f140.m4a (pass -k to keep) [download] Downloading video 22 of 481 [youtube] -5DwojwgLe0: Downloading webpage [youtube] -5DwojwgLe0: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 310 [download] Destination: -5DwojwgLe0.f248.webm [download] 100% of 52.16MiB in 01:47 [download] Destination: -5DwojwgLe0.f140.m4a [download] 100% of 24.42MiB in 00:01 [ffmpeg] Merging formats into &#34;-5DwojwgLe0.mkv&#34; Deleting original file -5DwojwgLe0.f248.webm (pass -k to keep) Deleting original file -5DwojwgLe0.f140.m4a (pass -k to keep) [download] Downloading video 23 of 481 [youtube] Lfz3yDI2rdY: Downloading webpage [youtube] Lfz3yDI2rdY: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 15 [download] Destination: Lfz3yDI2rdY.f248.webm [download] 100% of 10.16MiB in 00:05 [download] Destination: Lfz3yDI2rdY.f140.m4a [download] 100% of 1.12MiB in 00:01 [ffmpeg] Merging formats into &#34;Lfz3yDI2rdY.mkv&#34; Deleting original file Lfz3yDI2rdY.f248.webm (pass -k to keep) Deleting original file Lfz3yDI2rdY.f140.m4a (pass -k to keep) [download] Downloading video 24 of 481 [youtube] vOu-MuP4mLA: Downloading webpage [youtube] vOu-MuP4mLA: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 39 [download] Destination: vOu-MuP4mLA.f303.webm [download] 100% of 36.90MiB in 00:15 [download] Destination: vOu-MuP4mLA.f140.m4a [download] 100% of 2.99MiB in 00:00 [ffmpeg] Merging formats into &#34;vOu-MuP4mLA.mkv&#34; Deleting original file vOu-MuP4mLA.f303.webm (pass -k to keep) Deleting original file vOu-MuP4mLA.f140.m4a (pass -k to keep) [download] Downloading video 25 of 481 [youtube] QtFRPmTRyWw: Downloading webpage [youtube] QtFRPmTRyWw: Downloading MPD manifest [download] Destination: QtFRPmTRyWw.f137.mp4 [download] 100% of 148.39MiB in 00:05 [download] Destination: QtFRPmTRyWw.f140.m4a [download] 100% of 7.13MiB in 00:00 [ffmpeg] Merging formats into &#34;QtFRPmTRyWw.mp4&#34; Deleting original file QtFRPmTRyWw.f137.mp4 (pass -k to keep) Deleting original file QtFRPmTRyWw.f140.m4a (pass -k to keep) [download] Downloading video 26 of 481 [youtube] Gci-BbB0i5g: Downloading webpage [youtube] Gci-BbB0i5g: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 206 [download] Destination: Gci-BbB0i5g.f248.webm [download] 100% of 34.73MiB in 01:12 [download] Destination: Gci-BbB0i5g.f140.m4a [download] 100% of 16.87MiB in 00:01 [ffmpeg] Merging formats into &#34;Gci-BbB0i5g.mkv&#34; Deleting original file Gci-BbB0i5g.f248.webm (pass -k to keep) Deleting original file Gci-BbB0i5g.f140.m4a (pass -k to keep) [download] Downloading video 27 of 481 [youtube] 8jSE5bzQVbk: Downloading webpage [youtube] 8jSE5bzQVbk: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 504 [download] Destination: 8jSE5bzQVbk.f248.webm [download] 100% of 388.26MiB in 03:09 [download] Destination: 8jSE5bzQVbk.f140.m4a [download] 100% of 41.41MiB in 00:03 [ffmpeg] Merging formats into &#34;8jSE5bzQVbk.mkv&#34; Deleting original file 8jSE5bzQVbk.f248.webm (pass -k to keep) Deleting original file 8jSE5bzQVbk.f140.m4a (pass -k to keep) [download] Downloading video 28 of 481 [youtube] hm7RZHfFKeA: Downloading webpage [youtube] hm7RZHfFKeA: Downloading MPD manifest [download] Omv√§rld och insikt - Museipanelen does not pass filter license=&#39;Creative Commons Attribution license (reuse allowed)&#39;, skipping .. [download] Downloading video 29 of 481 [youtube] xMZu6MR5BrM: Downloading webpage [youtube] xMZu6MR5BrM: Downloading MPD manifest [dashsegments] Total fragments: 206 [download] Destination: xMZu6MR5BrM.f137.mp4 [download] 100% of 136.54MiB in 01:18 [download] Destination: xMZu6MR5BrM.f140.m4a [download] 100% of 16.81MiB in 00:01 [ffmpeg] Merging formats into &#34;xMZu6MR5BrM.mp4&#34; Deleting original file xMZu6MR5BrM.f137.mp4 (pass -k to keep) Deleting original file xMZu6MR5BrM.f140.m4a (pass -k to keep) [download] Downloading video 30 of 481 [youtube] YeNcvCrF_V4: Downloading webpage [youtube] YeNcvCrF_V4: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 295 [download] Destination: YeNcvCrF_V4.f244.webm [download] 100% of 12.36MiB in 01:38 [download] Destination: YeNcvCrF_V4.f140.m4a [download] 100% of 23.24MiB in 00:04 [ffmpeg] Merging formats into &#34;YeNcvCrF_V4.mkv&#34; Deleting original file YeNcvCrF_V4.f244.webm (pass -k to keep) Deleting original file YeNcvCrF_V4.f140.m4a (pass -k to keep) [download] Downloading video 31 of 481 [youtube] HQiNjDVARxI: Downloading webpage [youtube] HQiNjDVARxI: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 273 [download] Destination: HQiNjDVARxI.f248.webm [download] 100% of 65.31MiB in 01:36 [download] Destination: HQiNjDVARxI.f140.m4a [download] 100% of 22.34MiB in 00:02 [ffmpeg] Merging formats into &#34;HQiNjDVARxI.mkv&#34; Deleting original file HQiNjDVARxI.f248.webm (pass -k to keep) Deleting original file HQiNjDVARxI.f140.m4a (pass -k to keep) [download] Downloading video 32 of 481 [youtube] A_pmPIyDfXw: Downloading webpage [youtube] A_pmPIyDfXw: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 403 [download] Destination: A_pmPIyDfXw.f248.webm [download] 100% of 262.74MiB in 02:36 [download] Destination: A_pmPIyDfXw.f140.m4a [download] 100% of 33.03MiB in 00:01 [ffmpeg] Merging formats into &#34;A_pmPIyDfXw.mkv&#34; Deleting original file A_pmPIyDfXw.f248.webm (pass -k to keep) Deleting original file A_pmPIyDfXw.f140.m4a (pass -k to keep) [download] Downloading video 33 of 481 [youtube] sQyC8woJwR8: Downloading webpage [youtube] sQyC8woJwR8: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 158 [download] Destination: sQyC8woJwR8.f248.webm [download] 100% of 38.34MiB in 00:55 [download] Destination: sQyC8woJwR8.f140.m4a [download] 100% of 12.88MiB in 04:21 [ffmpeg] Merging formats into &#34;sQyC8woJwR8.mkv&#34; Deleting original file sQyC8woJwR8.f248.webm (pass -k to keep) Deleting original file sQyC8woJwR8.f140.m4a (pass -k to keep) [download] Downloading video 34 of 481 [youtube] mwNFSiKza00: Downloading webpage [youtube] mwNFSiKza00: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 30 [download] Destination: mwNFSiKza00.f248.webm [download] 100% of 15.28MiB in 00:11 [download] Destination: mwNFSiKza00.f140.m4a [download] 100% of 2.38MiB in 00:00 [ffmpeg] Merging formats into &#34;mwNFSiKza00.mkv&#34; Deleting original file mwNFSiKza00.f248.webm (pass -k to keep) Deleting original file mwNFSiKza00.f140.m4a (pass -k to keep) [download] Downloading video 35 of 481 [youtube] GKpnihA9Am0: Downloading webpage [youtube] GKpnihA9Am0: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 283 [download] Destination: GKpnihA9Am0.f248.webm [download] 100% of 70.30MiB in 01:39 [download] Destination: GKpnihA9Am0.f140.m4a [download] 100% of 23.21MiB in 00:02 [ffmpeg] Merging formats into &#34;GKpnihA9Am0.mkv&#34; Deleting original file GKpnihA9Am0.f248.webm (pass -k to keep) Deleting original file GKpnihA9Am0.f140.m4a (pass -k to keep) [download] Downloading video 36 of 481 [youtube] ELz_eDr2Jxg: Downloading webpage [youtube] ELz_eDr2Jxg: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 180 [download] Destination: ELz_eDr2Jxg.f248.webm [download] 100% of 34.08MiB in 01:03 [download] Destination: ELz_eDr2Jxg.f140.m4a [download] 100% of 14.72MiB in 00:02 [ffmpeg] Merging formats into &#34;ELz_eDr2Jxg.mkv&#34; Deleting original file ELz_eDr2Jxg.f248.webm (pass -k to keep) Deleting original file ELz_eDr2Jxg.f140.m4a (pass -k to keep) [download] Downloading video 37 of 481 [youtube] eS3vz6en90Q: Downloading webpage [youtube] eS3vz6en90Q: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 252 [download] Destination: eS3vz6en90Q.f248.webm [download] 100% of 41.49MiB in 01:29 [download] Destination: eS3vz6en90Q.f140.m4a [download] 100% of 20.60MiB in 00:02 [ffmpeg] Merging formats into &#34;eS3vz6en90Q.mkv&#34; Deleting original file eS3vz6en90Q.f248.webm (pass -k to keep) Deleting original file eS3vz6en90Q.f140.m4a (pass -k to keep) [download] Downloading video 38 of 481 [youtube] Gpr7RETcS6A: Downloading webpage [youtube] Gpr7RETcS6A: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 229 [download] Destination: Gpr7RETcS6A.f248.webm [download] 100% of 50.44MiB in 01:21 [download] Destination: Gpr7RETcS6A.f140.m4a [download] 100% of 18.73MiB in 00:02 [ffmpeg] Merging formats into &#34;Gpr7RETcS6A.mkv&#34; Deleting original file Gpr7RETcS6A.f248.webm (pass -k to keep) Deleting original file Gpr7RETcS6A.f140.m4a (pass -k to keep) [download] Downloading video 39 of 481 [youtube] P0GRef2Nn0g: Downloading webpage [youtube] P0GRef2Nn0g: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 55 [download] Destination: P0GRef2Nn0g.f136.mp4 [download] 100% of 80.24MiB in 00:21 [download] Destination: P0GRef2Nn0g.f251.webm [download] 100% of 4.52MiB in 00:00 [ffmpeg] Merging formats into &#34;P0GRef2Nn0g.mkv&#34; Deleting original file P0GRef2Nn0g.f136.mp4 (pass -k to keep) Deleting original file P0GRef2Nn0g.f251.webm (pass -k to keep) [download] Downloading video 40 of 481 [youtube] BJpmB6tpKKY: Downloading webpage [youtube] BJpmB6tpKKY: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 445 [download] Destination: BJpmB6tpKKY.f137.mp4 [download] 100% of 1.48GiB in 03:52 [download] Destination: BJpmB6tpKKY.f251.webm [download] 100% of 39.22MiB in 00:03 [ffmpeg] Merging formats into &#34;BJpmB6tpKKY.mkv&#34; Deleting original file BJpmB6tpKKY.f137.mp4 (pass -k to keep) Deleting original file BJpmB6tpKKY.f251.webm (pass -k to keep) [download] Downloading video 41 of 481 [youtube] wIwi4JxORsQ: Downloading webpage [youtube] wIwi4JxORsQ: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 560 [download] Destination: wIwi4JxORsQ.f247.webm [download] 100% of 103.88MiB in 03:58 [download] Destination: wIwi4JxORsQ.f140.m4a [download] 100% of 46.02MiB in 00:07 [ffmpeg] Merging formats into &#34;wIwi4JxORsQ.mkv&#34; Deleting original file wIwi4JxORsQ.f247.webm (pass -k to keep) Deleting original file wIwi4JxORsQ.f140.m4a (pass -k to keep) [download] Downloading video 42 of 481 [youtube] 1M9i1bhqG4k: Downloading webpage [youtube] 1M9i1bhqG4k: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 425 [download] Destination: 1M9i1bhqG4k.f248.webm [download] 100% of 322.71MiB in 02:43 [download] Destination: 1M9i1bhqG4k.f140.m4a [download] 100% of 34.91MiB in 00:03 [ffmpeg] Merging formats into &#34;1M9i1bhqG4k.mkv&#34; Deleting original file 1M9i1bhqG4k.f248.webm (pass -k to keep) Deleting original file 1M9i1bhqG4k.f140.m4a (pass -k to keep) [download] Downloading video 43 of 481 [youtube] 4lSp2mN9c0c: Downloading webpage [youtube] 4lSp2mN9c0c: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 290 [download] Destination: 4lSp2mN9c0c.f247.webm [download] 100% of 183.10MiB in 02:24 [download] Destination: 4lSp2mN9c0c.f140.m4a [download] 100% of 23.76MiB in 00:02 [ffmpeg] Merging formats into &#34;4lSp2mN9c0c.mkv&#34; Deleting original file 4lSp2mN9c0c.f247.webm (pass -k to keep) Deleting original file 4lSp2mN9c0c.f140.m4a (pass -k to keep) [download] Downloading video 44 of 481 [youtube] S8JHEfd6UYo: Downloading webpage [youtube] S8JHEfd6UYo: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 260 [download] Destination: S8JHEfd6UYo.f248.webm [download] 100% of 32.58MiB in 01:30 [download] Destination: S8JHEfd6UYo.f140.m4a [download] 100% of 21.28MiB in 00:03 [ffmpeg] Merging formats into &#34;S8JHEfd6UYo.mkv&#34; Deleting original file S8JHEfd6UYo.f248.webm (pass -k to keep) Deleting original file S8JHEfd6UYo.f140.m4a (pass -k to keep) [download] Downloading video 45 of 481 [youtube] wJjAaArYzJs: Downloading webpage [youtube] wJjAaArYzJs: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 217 [download] Destination: wJjAaArYzJs.f248.webm [download] 100% of 93.03MiB in 01:18 [download] Destination: wJjAaArYzJs.f140.m4a [download] 100% of 17.75MiB in 00:02 [ffmpeg] Merging formats into &#34;wJjAaArYzJs.mkv&#34; Deleting original file wJjAaArYzJs.f248.webm (pass -k to keep) Deleting original file wJjAaArYzJs.f140.m4a (pass -k to keep) [download] Downloading video 46 of 481 [youtube] HjUJKVFLfGc: Downloading webpage [youtube] HjUJKVFLfGc: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 335 [download] Destination: HjUJKVFLfGc.f248.webm [download] 100% of 62.32MiB in 01:56 [download] Destination: HjUJKVFLfGc.f140.m4a [download] 100% of 27.44MiB in 00:01 [ffmpeg] Merging formats into &#34;HjUJKVFLfGc.mkv&#34; Deleting original file HjUJKVFLfGc.f248.webm (pass -k to keep) Deleting original file HjUJKVFLfGc.f140.m4a (pass -k to keep) [download] Downloading video 47 of 481 [youtube] 5-WvzW6Goq0: Downloading webpage [youtube] 5-WvzW6Goq0: Downloading MPD manifest [download] Museipanelen does not pass filter license=&#39;Creative Commons Attribution license (reuse allowed)&#39;, skipping .. [download] Downloading video 48 of 481 [youtube] -O8QKVL4IWY: Downloading webpage [youtube] -O8QKVL4IWY: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 223 [download] Destination: -O8QKVL4IWY.f248.webm [download] 100% of 41.78MiB in 01:21 [download] Destination: -O8QKVL4IWY.f140.m4a [download] 100% of 18.24MiB in 00:02 [ffmpeg] Merging formats into &#34;-O8QKVL4IWY.mkv&#34; Deleting original file -O8QKVL4IWY.f248.webm (pass -k to keep) Deleting original file -O8QKVL4IWY.f140.m4a (pass -k to keep) [download] Downloading video 49 of 481 [youtube] _aPZ9kc7pSE: Downloading webpage [youtube] _aPZ9kc7pSE: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 313 [download] Destination: _aPZ9kc7pSE.f247.webm [download] 58.1% of ~170.35MiB at 28.65MiB/s ETA 01:30[download] Got server HTTP error: HTTP Error 404: Not Found. Retrying fragment 183 (attempt 1 of 10)... [download] 83.4% of ~170.80MiB at 24.78MiB/s ETA 00:36[download] Got server HTTP error: HTTP Error 404: Not Found. Retrying fragment 262 (attempt 1 of 10)... [download] Got server HTTP error: HTTP Error 404: Not Found. Retrying fragment 262 (attempt 2 of 10)... [download] 100% of 169.40MiB in 03:39 [download] Destination: _aPZ9kc7pSE.f140.m4a [download] 100% of 24.60MiB in 00:01 [ffmpeg] Merging formats into &#34;_aPZ9kc7pSE.mkv&#34; Deleting original file _aPZ9kc7pSE.f247.webm (pass -k to keep) Deleting original file _aPZ9kc7pSE.f140.m4a (pass -k to keep) [download] Downloading video 50 of 481 [youtube] c_wqdJMJbhc: Downloading webpage [youtube] c_wqdJMJbhc: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 203 [download] Destination: c_wqdJMJbhc.f248.webm [download] 100% of 34.47MiB in 01:23 [download] Destination: c_wqdJMJbhc.f140.m4a [download] 100% of 16.64MiB in 00:03 [ffmpeg] Merging formats into &#34;c_wqdJMJbhc.mkv&#34; Deleting original file c_wqdJMJbhc.f248.webm (pass -k to keep) Deleting original file c_wqdJMJbhc.f140.m4a (pass -k to keep) [download] Downloading video 51 of 481 [youtube] pigyLnE0DmA: Downloading webpage [youtube] pigyLnE0DmA: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 425 [download] Destination: pigyLnE0DmA.f248.webm [download] 100% of 107.17MiB in 02:34 [download] Destination: pigyLnE0DmA.f140.m4a [download] 100% of 34.87MiB in 08:25 [ffmpeg] Merging formats into &#34;pigyLnE0DmA.mkv&#34; Deleting original file pigyLnE0DmA.f248.webm (pass -k to keep) Deleting original file pigyLnE0DmA.f140.m4a (pass -k to keep) [download] Downloading video 52 of 481 [youtube] ngxK_PvUSIo: Downloading webpage [youtube] ngxK_PvUSIo: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 357 [download] Destination: ngxK_PvUSIo.f248.webm [download] 100% of 70.31MiB in 02:05 [download] Destination: ngxK_PvUSIo.f140.m4a [download] 100% of 29.26MiB in 00:01 [ffmpeg] Merging formats into &#34;ngxK_PvUSIo.mkv&#34; Deleting original file ngxK_PvUSIo.f248.webm (pass -k to keep) Deleting original file ngxK_PvUSIo.f140.m4a (pass -k to keep) [download] Downloading video 53 of 481 [youtube] c_0BcUmqM50: Downloading webpage [youtube] c_0BcUmqM50: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 11 [download] Destination: c_0BcUmqM50.f248.webm [download] 100% of 5.73MiB in 00:04 ERROR: unable to download video data: HTTP Error 403: Forbidden .",
            "url": "https://jimregan.github.io/notes/kaggle/swedish/2021/09/21/scrape-swedish-youtube-take1.html",
            "relUrl": "/kaggle/swedish/2021/09/21/scrape-swedish-youtube-take1.html",
            "date": " ‚Ä¢ Sep 21, 2021"
        }
        
    
  
    
        ,"post7": {
            "title": "Check Riksantikvarie√§mbetet youtube for licence",
            "content": "Original on Kaggle . %%capture !pip install youtube-dl . !youtube-dl -j --flat-playlist &quot;https://www.youtube.com/c/heritageboard/playlists?view=1&amp;sort=dd&amp;shelf_id=0&quot; &gt; rplist.json . !cat rplist.json | awk -F&#39;&quot;url&quot;: &quot;&#39; &#39;{print $2}&#39;|awk -F&#39;&quot;&#39; &#39;{print $1}&#39; | while read i;do youtube-dl -j --flat-playlist $i &gt;&gt; pl_videos.json || echo $i &gt;&gt; retry;done . !youtube-dl -j --flat-playlist &quot;https://www.youtube.com/c/heritageboard/videos?view=0&amp;sort=dd&amp;shelf_id=0&quot; &gt; uploads.json . import json import requests cc_by = [] other = [] retry = [] seen = [] . lic = &#39;&quot;Creative Commons Attribution licence (reuse allowed)&quot;&#39; def inner(cur_id): if cur_id in seen: return req = requests.get(f&quot;https://www.youtube.com/watch?v={cur_id}&quot;) if req.status_code != 200: retry.append(cur_id) if lic in req.text: cc_by.append(cur_id) else: other.append(cur_id) seen.append(cur_id) . with open(&quot;pl_videos.json&quot;) as pl_videos: for line in pl_videos.readlines(): line_data = json.loads(line.strip()) inner(line_data[&#39;id&#39;]) with open(&quot;uploads.json&quot;) as pl_videos: for line in pl_videos.readlines(): line_data = json.loads(line.strip()) inner(line_data[&#39;id&#39;]) . with open(&#39;proc.json&#39;, &#39;w&#39;) as outfile: json.dump({&#39;cc-by&#39;: cc_by, &#39;other&#39;: other, &#39;retry&#39;: retry}, outfile) . print(len(cc_by)) . 469 . other . [&#39;qDVkZW7BTQs&#39;, &#39;LvsH1IURj5E&#39;, &#39;uU4M5-ajGt4&#39;, &#39;RafIRgJ-qPw&#39;, &#39;hm7RZHfFKeA&#39;, &#39;5-WvzW6Goq0&#39;, &#39;6PsuJIIDAEA&#39;, &#39;rB0uJG3fUwg&#39;, &#39;BK0fsTtfF9s&#39;, &#39;_tVo6Iwbx8E&#39;, &#39;qLXM4OgGO5c&#39;, &#39;tVK_NaGnxio&#39;, &#39;cgc0Z1QAzS8&#39;, &#39;oSWLwD79Xps&#39;, &#39;h8IIilrFdHk&#39;, &#39;fdrI7O9v0f4&#39;, &#39;KbacshS5qN0&#39;, &#39;URaZRJM5wQE&#39;, &#39;ZpBgogulsvk&#39;, &#39;Vbbb97vlPfw&#39;, &#39;4OvMqfWayk4&#39;, &#39;2er5uIiXF18&#39;, &#39;2STecAi0gRQ&#39;, &#39;bIC9bJntqrI&#39;, &#39;NKD_P7d82NE&#39;, &#39;Rkqi0TTN_94&#39;, &#39;p85fNZ7vi2A&#39;, &#39;s7_bkrhfwoE&#39;, &#39;oN8srXalBmU&#39;, &#39;FIat0r_xg5U&#39;, &#39;D25NgXwNTtM&#39;, &#39;l86yzp3kqc0&#39;, &#39;9EhOyBTjcFg&#39;, &#39;7TueN2uz-pc&#39;, &#39;BTIl1PDy4LQ&#39;, &#39;zEXwU9pO-aA&#39;, &#39;ctl3W8dAbNA&#39;, &#39;t1uFA5nMVc0&#39;, &#39;M5VkaMFLMKI&#39;, &#39;IVZE-B0C80k&#39;, &#39;H8Fj3W7ZtGM&#39;, &#39;v1rpeMJ6fac&#39;, &#39;i7rTsXMu6KY&#39;, &#39;Zxpgq1jc4no&#39;] . retry . [] . cc_by . [&#39;XhoTQzu4VAE&#39;, &#39;3ydSZ9Uk-3A&#39;, &#39;tiM2l9rYrVw&#39;, &#39;FPdgF5zRPcc&#39;, &#39;mdsyDk4oG2I&#39;, &#39;-5DwojwgLe0&#39;, &#39;2dmtx_ytJBc&#39;, &#39;kHX0PvydWQQ&#39;, &#39;k4dQAQ4grow&#39;, &#39;5pJdR7pXEKA&#39;, &#39;j8_pzb0Zj0c&#39;, &#39;CnfKrwDxGag&#39;, &#39;1Wbzean_07g&#39;, &#39;MPHHH_bN7ic&#39;, &#39;kfz1WOs30LE&#39;, &#39;BoJ1-urZ5b4&#39;, &#39;iJol2hdgYdw&#39;, &#39;vOu-MuP4mLA&#39;, &#39;kCPJh_v70bA&#39;, &#39;Lfz3yDI2rdY&#39;, &#39;zAAgEFoJvkw&#39;, &#39;A_pmPIyDfXw&#39;, &#39;8jSE5bzQVbk&#39;, &#39;1UaXcix1HIE&#39;, &#39;S8JHEfd6UYo&#39;, &#39;1M9i1bhqG4k&#39;, &#39;4lSp2mN9c0c&#39;, &#39;BJpmB6tpKKY&#39;, &#39;wIwi4JxORsQ&#39;, &#39;P0GRef2Nn0g&#39;, &#39;Gpr7RETcS6A&#39;, &#39;eS3vz6en90Q&#39;, &#39;ELz_eDr2Jxg&#39;, &#39;GKpnihA9Am0&#39;, &#39;sQyC8woJwR8&#39;, &#39;ZujFZjPpC5s&#39;, &#39;ngxK_PvUSIo&#39;, &#39;pigyLnE0DmA&#39;, &#39;c_wqdJMJbhc&#39;, &#39;-O8QKVL4IWY&#39;, &#39;HjUJKVFLfGc&#39;, &#39;HQiNjDVARxI&#39;, &#39;xMZu6MR5BrM&#39;, &#39;Gci-BbB0i5g&#39;, &#39;RAnaS3ctS5g&#39;, &#39;jp-rNPkHsE0&#39;, &#39;48pg0lHtciQ&#39;, &#39;BKIiBYFyK4M&#39;, &#39;iRh1bwx4c6w&#39;, &#39;lnw92d5msqQ&#39;, &#39;UhkrLH-8zOc&#39;, &#39;GHDHpIxnXUs&#39;, &#39;e8I8vtKbVf0&#39;, &#39;DmkOurgeDaU&#39;, &#39;ykJFS30nh0w&#39;, &#39;hp4Xocu5YFM&#39;, &#39;zuUX9FjCXrM&#39;, &#39;zM9c-zidvkk&#39;, &#39;g6YtbuvGmDA&#39;, &#39;Hh7axQNXXBE&#39;, &#39;opnUyJaoC5g&#39;, &#39;YH9oPx8j1HU&#39;, &#39;QtFRPmTRyWw&#39;, &#39;smcfjOlINro&#39;, &#39;oBopkQbtIXo&#39;, &#39;BsZzjOX1Ff4&#39;, &#39;HtV9ZJDc_R8&#39;, &#39;W5HTPh23Yo8&#39;, &#39;SY8SLSuqVtI&#39;, &#39;khfupiNLUSA&#39;, &#39;bHgLR73tKp0&#39;, &#39;kJjUVydQkKg&#39;, &#39;1uFO8S_phd0&#39;, &#39;6G3jRE_AnrA&#39;, &#39;5En68jOlr6I&#39;, &#39;-rLL_8FSiYo&#39;, &#39;8pN6I79RNZc&#39;, &#39;s3UMHClphyM&#39;, &#39;43jtyTxwQzE&#39;, &#39;SinXSm4TM8Y&#39;, &#39;hmOy5lJo9a0&#39;, &#39;fUEiIYNVuoQ&#39;, &#39;_AajW3ALi94&#39;, &#39;0jJMNx592LE&#39;, &#39;x_g2FElUUus&#39;, &#39;ReFwmH29_b4&#39;, &#39;OdvnZJhhgK8&#39;, &#39;TpyQwsMLni0&#39;, &#39;to7Oq-MYHX4&#39;, &#39;b2gEr_FnfUU&#39;, &#39;x0FGBxJuNXM&#39;, &#39;nj9Fbwf6UnY&#39;, &#39;LWh0F4C8Ffo&#39;, &#39;qSajIPCuZkA&#39;, &#39;6r7JtdRpRzo&#39;, &#39;JF1c97PkudY&#39;, &#39;vHw6VQT9WiE&#39;, &#39;KXHH6b-XrUE&#39;, &#39;mE_VViu1bUA&#39;, &#39;rFjxjWwUcsk&#39;, &#39;zwxruQCvNO4&#39;, &#39;UakyimUn-Xg&#39;, &#39;oPib9P3f4b0&#39;, &#39;r_X8eEEj_jI&#39;, &#39;158AslrkcOo&#39;, &#39;grrMwlqd9ps&#39;, &#39;d3fhWTkpm5s&#39;, &#39;2kj5A0UN8lQ&#39;, &#39;6-a5b9QZtsM&#39;, &#39;aMXI-nMxUs0&#39;, &#39;h65A1Xss5Yg&#39;, &#39;m9YTLHXLp_s&#39;, &#39;F07D-jSspa4&#39;, &#39;l1i9y0zji_g&#39;, &#39;7LOfIq8bfw0&#39;, &#39;vccSlA0gsIo&#39;, &#39;t1_XNFop7gc&#39;, &#39;iHpHdIJynhE&#39;, &#39;El57R6AACkY&#39;, &#39;y54Rj-gZzM8&#39;, &#39;63D1-PSkTxw&#39;, &#39;sMDkQ7cY3P4&#39;, &#39;jNunAK9p1gc&#39;, &#39;aIGJFNmRRZw&#39;, &#39;4KYv6x2ugw0&#39;, &#39;mwNqA9KDxpc&#39;, &#39;67BOTkByWa4&#39;, &#39;KyXA5H5wTMg&#39;, &#39;ZTzBMhgZDqg&#39;, &#39;HFHacP5fvZw&#39;, &#39;eEn1mYkf95k&#39;, &#39;6TchEw5P-lw&#39;, &#39;pF7qnON0BtA&#39;, &#39;r0zWEoK5JUQ&#39;, &#39;7u2uUQ2VK5c&#39;, &#39;Tj6pV1IQ4vE&#39;, &#39;rEpZmf_G4vM&#39;, &#39;qEIKDTxHuZc&#39;, &#39;HcsNWPVtbcQ&#39;, &#39;QBlQYUxMMy0&#39;, &#39;5NW_mtCLPGk&#39;, &#39;dw4aVpZVUY0&#39;, &#39;6BMvzW_7cwg&#39;, &#39;jdi04wuTdyM&#39;, &#39;JYOmFRDobdQ&#39;, &#39;YqwWq7pTFTc&#39;, &#39;MWfy_Wa_Pw4&#39;, &#39;TuAdSfBqcZM&#39;, &#39;Xq74U7vyY9U&#39;, &#39;usXdw1VXJv4&#39;, &#39;M05UCd7MyjU&#39;, &#39;AeAPY9EpWl8&#39;, &#39;33U5sD_y4CM&#39;, &#39;Y9FwoL_Ec8U&#39;, &#39;cbW_MECwJaA&#39;, &#39;6Vmxy_xjG_0&#39;, &#39;UBcCWGzrk84&#39;, &#39;oiQlv5gWQ3M&#39;, &#39;oFbybConp3o&#39;, &#39;1lfs92cqQCU&#39;, &#39;ZQI6gp8NRwQ&#39;, &#39;eOdYZGU7gZE&#39;, &#39;l-G4p9OmM88&#39;, &#39;Vi2qf44WWOw&#39;, &#39;aeaYTs7BpIs&#39;, &#39;tqa7qJo_IOw&#39;, &#39;zkIICffvEb0&#39;, &#39;vaS30NelmOQ&#39;, &#39;FrqKYOCJB2o&#39;, &#39;F_yZh5ylilk&#39;, &#39;d_9oqMyOQYU&#39;, &#39;2vBOid_XI7c&#39;, &#39;EwlAOWMGHhk&#39;, &#39;I0F2FEvf7NQ&#39;, &#39;Co2FtbHfJyI&#39;, &#39;Jt4lMNO0awU&#39;, &#39;dVXr2HMvGDs&#39;, &#39;pODBAY8wLtI&#39;, &#39;qUBeTlFLRTs&#39;, &#39;O1yPrfdly_8&#39;, &#39;icBkFBzSL2Y&#39;, &#39;Fc61_W5mRv8&#39;, &#39;whw9yeqJRM8&#39;, &#39;BvxsYEPIqUs&#39;, &#39;KVC8MeIMOho&#39;, &#39;MadIzepvF54&#39;, &#39;069S4_2bpcQ&#39;, &#39;uz-eYa9nYxU&#39;, &#39;qchF4bE4c2I&#39;, &#39;Eo7X2zYYQfY&#39;, &#39;u8qMKrY_xR4&#39;, &#39;eRi_eLkOuqg&#39;, &#39;K9SK5Jbgghc&#39;, &#39;jrc98ml9raE&#39;, &#39;8V4HkgIL1hU&#39;, &#39;eR_s2QdvdVI&#39;, &#39;vucA517bBX4&#39;, &#39;wuXfhGA5HsE&#39;, &#39;Ok62QIuFEEE&#39;, &#39;gSb9EIpLt4k&#39;, &#39;BgT-OpKb42I&#39;, &#39;XVElEVZKgE8&#39;, &#39;9rvxGbvFnZ0&#39;, &#39;qFQWBMB5NaM&#39;, &#39;IeHxOb4ENaw&#39;, &#39;m8qS-SNPGBQ&#39;, &#39;sGUDVqLJJJY&#39;, &#39;taGUqz0wPVU&#39;, &#39;sHhfZgJ2IDg&#39;, &#39;OTm4x6A-Ly4&#39;, &#39;j-jZCcfT2Gs&#39;, &#39;NAeuV3quheI&#39;, &#39;RgR_1ivBlVY&#39;, &#39;wNLx1rTJWAQ&#39;, &#39;qM80mCa0Ep8&#39;, &#39;NnHrXgVhXPw&#39;, &#39;euNgPNTsUzc&#39;, &#39;hddEeI7y06A&#39;, &#39;wGHaLcVtgI8&#39;, &#39;-_1ZzfePCC4&#39;, &#39;hhowOXG47hc&#39;, &#39;JHnQK1Dhww0&#39;, &#39;iof4P5Noy7Q&#39;, &#39;AIUSbUOeU-I&#39;, &#39;2qCBtMVYo80&#39;, &#39;j1gPqlQaUiA&#39;, &#39;Z7BptF_8Iek&#39;, &#39;5T7BpU4_dGM&#39;, &#39;D3FTkHyxwNc&#39;, &#39;as8T2fD3gPE&#39;, &#39;aIAX1UXZaBA&#39;, &#39;nzSjUYmyuFA&#39;, &#39;hrN9EQyrkIk&#39;, &#39;BPue1t0Sb7o&#39;, &#39;v12uhdIbb9U&#39;, &#39;RrElbPusHjQ&#39;, &#39;3thjaV8yOnI&#39;, &#39;eydgXuWCMF4&#39;, &#39;_z9R9uSWeqI&#39;, &#39;Gq5fIJ1YuuU&#39;, &#39;fmrlF-4dPkk&#39;, &#39;CeJYqC72GCw&#39;, &#39;ItAZPb6lkpw&#39;, &#39;dz1Lc98C4Bo&#39;, &#39;72p2rqgJMyw&#39;, &#39;IuaMZgS_nFU&#39;, &#39;lkGSo0dEdrc&#39;, &#39;HzUFXjph-Cw&#39;, &#39;2WyfLH6XYAI&#39;, &#39;wrN8l2kAVfg&#39;, &#39;06sj0Fz5fxQ&#39;, &#39;lNy92TM5vMw&#39;, &#39;Rl2N-NDMieM&#39;, &#39;oMGmmX5LbW4&#39;, &#39;DyNjhA9Y7Ng&#39;, &#39;Zcpjo6V7Mc8&#39;, &#39;UMRYbVf52oQ&#39;, &#39;SFSREVDMWMI&#39;, &#39;YwgguuuBlWM&#39;, &#39;zFiFxoHAgTk&#39;, &#39;eQXGqtVYpwY&#39;, &#39;r45giI3pj8c&#39;, &#39;xiyOjgalwUY&#39;, &#39;aBwCh_PGeE4&#39;, &#39;Dxj9yfK76do&#39;, &#39;1qGsQWzBVPE&#39;, &#39;wyCG_-uSwiI&#39;, &#39;uRQ-a56YECE&#39;, &#39;fH67lpDRTFE&#39;, &#39;YYnklEAQcHM&#39;, &#39;UM40uEN2RWw&#39;, &#39;sLTY3EE5wJA&#39;, &#39;MS2Q_mAMrRI&#39;, &#39;kw7Qi7tYC0A&#39;, &#39;D5EWY8X1NSc&#39;, &#39;HTvvoL2WkpM&#39;, &#39;8t-h7b_XUTY&#39;, &#39;Zg5NxJzG9zY&#39;, &#39;pFRq0rM-pGU&#39;, &#39;BnFtHgDiHdk&#39;, &#39;5cnsfhxYRzY&#39;, &#39;zJh9ulEGpts&#39;, &#39;TY8aPYC0S0o&#39;, &#39;XMDz2g2-Hv8&#39;, &#39;utfUezAXRfk&#39;, &#39;VE3ci2LtunI&#39;, &#39;u4V7EAqWqhA&#39;, &#39;U6bXL6_wX74&#39;, &#39;TQefMvN0psc&#39;, &#39;uw7FBD0Z_BM&#39;, &#39;IlZaQ_7Wva4&#39;, &#39;kL1KMZWueLw&#39;, &#39;4aajXWM7Uu4&#39;, &#39;dX3yLyQrph4&#39;, &#39;A5qknrf0MF8&#39;, &#39;zU2uRGyDOgs&#39;, &#39;PR6PT2hi5Vc&#39;, &#39;UlGaIqVG9rM&#39;, &#39;u2VDtVTEdQo&#39;, &#39;MdK4fZRZHEE&#39;, &#39;mbIZj41CT8o&#39;, &#39;uaX3j3IjSo4&#39;, &#39;tZXFWFHzSLc&#39;, &#39;zgE6KIUskq8&#39;, &#39;K7Wbfqcx1Zo&#39;, &#39;uBTTEHt1m90&#39;, &#39;xMwGF_JBg_o&#39;, &#39;7X0M5ywpIX0&#39;, &#39;HHm-QeE20_E&#39;, &#39;U8f4EE2j5ak&#39;, &#39;XA6MQXGCkUE&#39;, &#39;7pe5SGXRaEc&#39;, &#39;9AptlKhcB8k&#39;, &#39;W8shUT2TQC8&#39;, &#39;Yw7AeyxnC_k&#39;, &#39;9wXrw4Ow8tc&#39;, &#39;BXiJXcoxfEc&#39;, &#39;AHjQC6a21s8&#39;, &#39;tmFIQVlTeDU&#39;, &#39;aFLw67Ru1hw&#39;, &#39;URAwZpxpDAw&#39;, &#39;d3cquS60HW0&#39;, &#39;TtJSv_iKJJw&#39;, &#39;7jZuodD_2D4&#39;, &#39;KFQLaBZoEIw&#39;, &#39;kFiagliVoIs&#39;, &#39;vNGPIrHmHPc&#39;, &#39;8MvyICliEZ4&#39;, &#39;TxISo-NKT4I&#39;, &#39;uh08FNimajY&#39;, &#39;Suli-ebCCy8&#39;, &#39;mKWLEDjkfiA&#39;, &#39;ueqlXyT5HVw&#39;, &#39;a5yvt9ngUrU&#39;, &#39;thHNUpj1gYQ&#39;, &#39;-ffLpRNIqK0&#39;, &#39;3A2-UB-T8iA&#39;, &#39;I53BODAEKg0&#39;, &#39;BtIf5F1fjlQ&#39;, &#39;fdMHvUkeQyQ&#39;, &#39;rOHDEHByG-k&#39;, &#39;a6Cfmf9Gp7M&#39;, &#39;dOJklyLVQDQ&#39;, &#39;KFJs8WEdvfo&#39;, &#39;0I0hPqBPScU&#39;, &#39;ChkulqIRcpw&#39;, &#39;xUzkkywFIuU&#39;, &#39;tLQW-Vvjmmo&#39;, &#39;2zbk_nFzFl0&#39;, &#39;l59TLJTi_PQ&#39;, &#39;0ZG55J1vg8s&#39;, &#39;gMB-iS6--uA&#39;, &#39;yHm9y9bwjf4&#39;, &#39;-xXWvGsDkhs&#39;, &#39;HjNQXXpvLa0&#39;, &#39;4M8le6nzfP4&#39;, &#39;nePqawiDQ5o&#39;, &#39;ijPx0opan-k&#39;, &#39;PZGZRnuoAxk&#39;, &#39;wnKXkArwDww&#39;, &#39;kM_CEz40m54&#39;, &#39;G4q22Vnisy0&#39;, &#39;MIPfMUR_U8Q&#39;, &#39;WMA0Vt15QQg&#39;, &#39;G5UseKKUW2A&#39;, &#39;MHNi-R83jac&#39;, &#39;2a5JZj5rlgY&#39;, &#39;aAi-fPpYmeA&#39;, &#39;QDaKSC45SCA&#39;, &#39;QLQGJ15jfpU&#39;, &#39;0I8NTCpVcMw&#39;, &#39;o-RSL_BJoHI&#39;, &#39;TDzgL8XFeJs&#39;, &#39;L8x0VNnLZpo&#39;, &#39;5sT4uVqL-Yo&#39;, &#39;C9YgJeNt5zs&#39;, &#39;ED5PpOJC6Ws&#39;, &#39;AzMIPBUzLvg&#39;, &#39;FpAmmPsIzMQ&#39;, &#39;m5HIvRJo_Xg&#39;, &#39;R3R6kyDDyh4&#39;, &#39;p5m56GVUyBg&#39;, &#39;MiXxNaW9wHs&#39;, &#39;HySnGLJgG6g&#39;, &#39;LIIg7PpAgI0&#39;, &#39;W9a6NASUulA&#39;, &#39;JRcVCZgA4F4&#39;, &#39;sx_LbHRPv1Q&#39;, &#39;kwfIBN0pu8o&#39;, &#39;olcTSGQvDNk&#39;, &#39;rezkrkV8Uv8&#39;, &#39;lsM2VYv2d_A&#39;, &#39;u28CPnlUsgA&#39;, &#39;Kvz2xeTHN50&#39;, &#39;YeNcvCrF_V4&#39;, &#39;mwNFSiKza00&#39;, &#39;wJjAaArYzJs&#39;, &#39;_aPZ9kc7pSE&#39;, &#39;c_0BcUmqM50&#39;, &#39;-7ZSBmL3YfM&#39;, &#39;EZ3586U0_ao&#39;, &#39;FFt3mV7S8oc&#39;, &#39;ycVs_ITfbdY&#39;, &#39;NLtij5qUcHA&#39;, &#39;pmsisULzYes&#39;, &#39;zgTk_4yuNco&#39;, &#39;79CzFXfFiF4&#39;, &#39;_x2WDQ0uc-w&#39;, &#39;R5fvJTl7nzE&#39;, &#39;SBuBGxzYXt8&#39;, &#39;CR2Jo4GFVOw&#39;, &#39;yhs3lMFgeLA&#39;, &#39;kZNFwX0yA1M&#39;, &#39;JmLRRc-Xz9Q&#39;, &#39;oph6i3_9MRw&#39;, &#39;5df3okXC3Gs&#39;, &#39;XhD4xqfrO0Y&#39;, &#39;Di4uTAoccaQ&#39;, &#39;fni2R8xDwdo&#39;, &#39;u-qF_G3Ntss&#39;, &#39;AzCcbhSCb0Y&#39;, &#39;H5GRVIRHeAY&#39;, &#39;_UYzHQek-T4&#39;, &#39;hHk6l4Rrsuk&#39;, &#39;Xv-2wxofozk&#39;, &#39;jUBIzYNYF9E&#39;, &#39;LtMCCLB_AB0&#39;, &#39;y1Y_BhuV5zc&#39;, &#39;Epk4xeJ3AIE&#39;, &#39;6Ru__nrF0Fk&#39;, &#39;m350f5BOslM&#39;, &#39;iH96d73pLMI&#39;, &#39;ZAlnj1i3SCs&#39;, &#39;jOYzvvNreX4&#39;, &#39;GRfUq1pZ6H8&#39;, &#39;sDRvasGmgEU&#39;, &#39;zp_Uentx3dY&#39;, &#39;3BwN5qd5p-U&#39;, &#39;6b12eiSMjHc&#39;, &#39;_XMeIpN5BRQ&#39;, &#39;5HE_6vP8XkM&#39;, &#39;E3estyoUfNs&#39;, &#39;GeO1ijPv2nE&#39;, &#39;pOLTb7BfnkE&#39;, &#39;1tWAES5ecH8&#39;, &#39;hhsBrmLP_hw&#39;, &#39;AwvU3Y5b6vQ&#39;, &#39;XB8JSDYi-Ic&#39;, &#39;P2OY7YSXE50&#39;, &#39;RBVu7y1e0mA&#39;, &#39;3grbAJM5i60&#39;, &#39;Cr_g4rszmn0&#39;, &#39;G2qU9tIQRcw&#39;, &#39;Z0QShQd4nKk&#39;, &#39;EjT6kZfFNgo&#39;, &#39;vvaMF3rmFEk&#39;, &#39;zsmG3oY2T08&#39;, &#39;5u5AyT6FHtY&#39;, &#39;RHoUrcdxKeA&#39;, &#39;cRDKjacWPck&#39;, &#39;139PY_5VCaY&#39;, &#39;pfleyFhCGtQ&#39;, &#39;eBrV-CPCJSs&#39;, &#39;zRtZknBuioU&#39;, &#39;eL5qJsAHg2c&#39;, &#39;l0gCaOituDU&#39;, &#39;0_AiNU7bh84&#39;, &#39;uruUQ38Sfaw&#39;, &#39;jOJDXu44KMc&#39;] .",
            "url": "https://jimregan.github.io/notes/kaggle/swedish/2021/09/21/check-riksantikvarieambetet-youtube-for-licence.html",
            "relUrl": "/kaggle/swedish/2021/09/21/check-riksantikvarieambetet-youtube-for-licence.html",
            "date": " ‚Ä¢ Sep 21, 2021"
        }
        
    
  
    
        ,"post8": {
            "title": "The New Statistics Why and How",
            "content": "The New Statistics: Why and How . @article{cumming2014newstatistics, author = {Geoff Cumming}, title ={The New Statistics: Why and How}, journal = {Psychological Science}, volume = {25}, number = {1}, pages = {7-29}, year = {2014}, doi = {10.1177/0956797613504966}, note ={PMID: 24220629} } . The problem: . Research Integrity . Published research is a biased selection of all research; | data analysis and reporting are often selective and biased; and | in many research fields, studies are rarely replicated, so false conclusions persist. | . a decision to report research [‚Ä¶] must be independent of the results. . Agree, but‚Ä¶ . The best way to ensure this is to make a commitment to report research in advance of conducting it . Not sure I agree. . No matter how intriguing, however, the results of such pilot work rarely deserve even a brief mention in a report. . Strongly disagree. . PHONEME TRANSPOSITION AND TEMPORAL ENCODING IN HUMAN SPEECH RECOGNITION - example pre-registration that seems relevant to the lab. .",
            "url": "https://jimregan.github.io/notes/journal%20club/2021/09/20/journal-club.html",
            "relUrl": "/journal%20club/2021/09/20/journal-club.html",
            "date": " ‚Ä¢ Sep 20, 2021"
        }
        
    
  
    
        ,"post9": {
            "title": "Interesting links, 19/9/2021",
            "content": "German ASR: Fine-Tuning Wav2Vec2 . torchaudio.resample is faster than librosa.resample | disable group_by_length if there‚Äôs a long delay before training starts Made no difference to the outcome | . | . . ASR Systems as Models of Phonetic Category Perception in Adults . PHONEME TRANSPOSITION AND TEMPORAL ENCODING IN HUMAN SPEECH RECOGNITION . . 19th-Century Cockney and RP .",
            "url": "https://jimregan.github.io/notes/links/2021/09/19/misc-links.html",
            "relUrl": "/links/2021/09/19/misc-links.html",
            "date": " ‚Ä¢ Sep 19, 2021"
        }
        
    
  
    
        ,"post10": {
            "title": "Interesting links, 16/9/2021",
            "content": "A comparative acoustic analysis of purring in four cats . @inproceedings{Schotz539090, author = {Sch{ &quot;o}tz, Susanne and Eklund, Robert}, booktitle = {Proceedings from Fonetik 2011, Quarterly Progress and Status Report TMH-QPSR, Volume 51, 2011}, pages = {5--8}, publisher = {Universitetsservice}, title = {A comparative acoustic analysis of purring in four cats}, series = {Quarterly Progress and Status Report TMH-QPSR}, number = {51}, URL = {http://www.speech.kth.se/fonetik2011/}, year = {2011} } . spotify/pedalboard - library for adding effects to audio, supports VST3 and Audio Unit plugins. . Jam3/math-as-code - ‚Äúa cheat-sheet for mathematical notation in code form‚Äù . VOSK language model adaptation . Svito-zar/gesticulator: ‚ÄúGesticulator: A framework for semantically-aware speech-driven gesture generation‚Äù . Remember the context! ASR slot error correction through memorization . Setup - ngrok . optuna/optuna: A hyperparameter optimization framework . dataqa/dataqa: Labelling platform for text using distant supervision . That XOR Trick . abhishekkrthakur/colabcode: Run VSCode (codeserver) on Google Colab or Kaggle Notebooks . tarun-bisht/wav2vec2-asr: wav2vec2 asr with transformers .",
            "url": "https://jimregan.github.io/notes/links/2021/09/16/misc-links.html",
            "relUrl": "/links/2021/09/16/misc-links.html",
            "date": " ‚Ä¢ Sep 16, 2021"
        }
        
    
  
    
        ,"post11": {
            "title": "XOR number guessing",
            "content": "def make_1ton_missing_number(n, to_remove): return [a for a in range(1, n + 1) if a != to_remove] . n = 12 l = make_1ton_missing_number(n, 8) . l . [1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12] . def get_missing_number(l1ton, n): res = 0 for val in range(1, n + 1): res ^= val for val in l1ton: res ^= val return res . get_missing_number(l, n) . 8 . 8 ^ 8 . 0 . 0 ^ 8 . 8 .",
            "url": "https://jimregan.github.io/notes/xor/misc/2021/09/15/xor-number-guessing.html",
            "relUrl": "/xor/misc/2021/09/15/xor-number-guessing.html",
            "date": " ‚Ä¢ Sep 15, 2021"
        }
        
    
  
    
        ,"post12": {
            "title": "Utterance XML to json",
            "content": "sample = &quot;&quot;&quot; &lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt; &lt;utterance input_string=&quot;&quot;&gt; &lt;sentence input_string=&quot;&quot;&gt; &lt;token input_string=&quot;SILENCE_TOKEN&quot;&gt; &lt;word input_string=&quot;SILENCE_TOKEN&quot; trans_source=&quot;src&quot; trans_output_format=&quot;final&quot;&gt; &lt;syllable &gt; &lt;phoneme symbol=&quot;sil&quot; end=&quot;1.19&quot;/&gt; &lt;/syllable&gt; &lt;/word&gt; &lt;/token&gt; &lt;/sentence&gt; &lt;/utterance&gt; &quot;&quot;&quot; . import xml.etree.ElementTree as ET . class Utterance: def __init__(self, input, sentences): self.input = input self.sentences = sentences . class Sentence: def __init__(self, input, tokens): self.input = input self.tokens = tokens . class Token: def __init__(self, input, words): self.input = input self.words = words . class Word: def __init__(self, input, source, syllables): self.input = input self.source = source self.syllables = syllables if self.syllables is None: self.syllables = [] def get_phonemes(self): return &quot; &quot;.join([a.get_phonemes() for a in self.syllables]) def get_clean_word(self): word = self.input if word[0:1] in &quot;nt&quot; and word[1:2] in &quot;A√ÅE√âI√çO√ìU√ö&quot;: return word[0:1] + &quot;-&quot; + word[1:].lower() else: return word.lower() . class Syllable: def __init__(self, stress: int = 0, phonemes = None): self.stress = stress self.phonemes = phonemes if self.phonemes is None: self.phonemes = [] def get_phonemes(self): return &quot; &quot;.join([a.symbol for a in self.phonemes]) . class Phoneme: def __init__(self, symbol: str = &quot;&quot;, end: float = 0.0): self.symbol = symbol self.end = end . import io sio = io.StringIO(sample.strip()) . def from_xml(source): tree = ET.parse(source) root = tree.getroot() if &#39;input_string&#39; in root.attrib: input = root.attrib[&#39;input_string&#39;] else: input = &#39;&#39; sentences = [] for sentence in root.findall(&#39;./sentence&#39;): if &#39;input_string&#39; in sentence.attrib: input = sentence.attrib[&#39;input_string&#39;] else: input = &#39;&#39; tokens = [] for token in sentence.findall(&#39;./token&#39;): if &#39;input_string&#39; in token.attrib: input = token.attrib[&#39;input_string&#39;] else: input = &#39;&#39; words = [] for word in token.findall(&#39;./word&#39;): if &#39;input_string&#39; in word.attrib: input = word.attrib[&#39;input_string&#39;] else: input = &quot;&quot; if &#39;trans_source&#39; in word.attrib: source = word.attrib[&#39;trans_source&#39;] else: source = &quot;&quot; syllables = [] for syllable in word.findall(&#39;./syllable&#39;): phonemes = [] if &#39;stress&#39; in syllable.attrib: if syllable.attrib[&#39;stress&#39;] == &#39;None&#39;: stress = 0 else: stress = int(syllable.attrib[&#39;stress&#39;]) else: stress = 0 for phoneme in syllable.findall(&#39;./phoneme&#39;): if &#39;symbol&#39; in phoneme.attrib: symbol = phoneme.attrib[&#39;symbol&#39;] else: symbol = &#39;&#39; if &#39;end&#39; in phoneme.attrib: end = float(phoneme.attrib[&#39;end&#39;]) else: symbol = 0.0 phonemes.append(Phoneme(symbol, end)) syllables.append(Syllable(stress, phonemes)) words.append(Word(input, source, syllables)) tokens.append(Token(input, words)) sentences.append(Sentence(input, tokens)) return Utterance(input, sentences) . utt = from_xml(sio) . import json json.dumps(utt, default=lambda o: o.__dict__) . &#39;{&#34;input&#34;: &#34;SILENCE_TOKEN&#34;, &#34;sentences&#34;: [{&#34;input&#34;: &#34;SILENCE_TOKEN&#34;, &#34;tokens&#34;: [{&#34;input&#34;: &#34;SILENCE_TOKEN&#34;, &#34;words&#34;: [{&#34;input&#34;: &#34;SILENCE_TOKEN&#34;, &#34;source&#34;: &#34;src&#34;, &#34;syllables&#34;: [{&#34;stress&#34;: 0, &#34;phonemes&#34;: [{&#34;symbol&#34;: &#34;sil&#34;, &#34;end&#34;: 1.19}]}]}]}]}]}&#39; . for sent in utt.sentences: for tok in sent.tokens: for word in tok.words: print(f&#39;{word.get_clean_word()} {word.get_phonemes()}&#39;) . silence_token sil .",
            "url": "https://jimregan.github.io/notes/irish/abair/mfa/2021/09/15/utterance-xml-to-mfa.html",
            "relUrl": "/irish/abair/mfa/2021/09/15/utterance-xml-to-mfa.html",
            "date": " ‚Ä¢ Sep 15, 2021"
        }
        
    
  
    
        ,"post13": {
            "title": "Interesting links, roughly 15/9/2021",
            "content": "H5P ‚Äì used for learning materials on TG4 and Tuairisc . Commits on transformers: Add SpeechEncoderDecoder &amp; Speech2Text2, Add the AudioClassificationPipeline, Add Wav2Vec2 &amp; Hubert ForSequenceClassification (based on converting s3rpl checkpoints) . monologg/JointBERT ‚Äì (Unofficial) Pytorch implementation of JointBERT: BERT for Joint Intent Classification and Slot Filling . deezer/spleeter ‚Äì Deezer source separation library including pretrained models. . VoxLingua107: a Dataset for Spoken Language Recognition ‚Äì no Irish . Appen/UHV-OTS-Speech ‚Äì A data annotation pipeline to generate high-quality, large-scale speech datasets with machine pre-labeling and fully manual auditing. Paper . The Effects of Automatic Speech Recognition Quality on Human Transcription Latency . @inproceedings{gaur16latency, author = {Yashesh Gaur and Walter S. Lasecki and Florian Metze and Jeffrey P. Bigham}, editor = {Gregory R. Gay and Tiago Jo{ ~{a}}o Guerreiro}, title = , booktitle = {Proceedings of the 13th Web for All Conference, {W4A} &#39;16, Montreal, Canada, April 11-13, 2016}, pages = {23:1--23:8}, publisher = , year = {2016}, doi = {10.1145/2899475.2899478}, } . BirgerMoell/tmh . as-ideas/DeepPhonemizer See: Transformer based Grapheme-to-Phoneme Conversion . Unifying Speech and Gesture Synthesis . Locals create CD-ROM celebrating Gaeltacht area of Dun Chaochain . Facebook‚Äôs latest: Textless NLP: Generating expressive speech from raw audio Demo Code, Generative Spoken Language Modeling from Raw Audio, Speech Resynthesis from Discrete Disentangled Self-Supervised Representations, Text-Free Prosody-Aware Generative Spoken Language Modeling . AIdeaLab/wav2vec2_docker ‚Äì pretraining wav2vec docker for sagemaker . as-ideas/DeepForcedAligner . citizensinformation.ie mojibake . kingabzpro/fine-tuning-xlsr-wav2vec2-for-wolof-asr-with . ceyda/wav2vec2-base-760 ‚Äì Turkish wav2vec2 base model . Excessive GPU-GPU communication with GPT2 making multi-GPU training slow? . Vosk LM . Svito-zar/gesticulator . run_cleanup_segmentation.sh from malach, based on AMI, in turn based on Tedlium . Numbers . Classroom materials .",
            "url": "https://jimregan.github.io/notes/links/2021/09/15/misc-links.html",
            "relUrl": "/links/2021/09/15/misc-links.html",
            "date": " ‚Ä¢ Sep 15, 2021"
        }
        
    
  
    
        ,"post14": {
            "title": "T5G2P -- Using Text-to-Text Transfer Transformer for Grapheme-to-Phoneme Conversion",
            "content": "T5G2P: Using Text-to-Text Transfer Transformer for Grapheme-to-Phoneme Conversion . @inproceedings{rezackova21_interspeech, author={Mark√©ta ≈òez√°ƒçkov√° and Jan ≈†vec and Daniel Tihelka}, title=, year=2021, booktitle={Proc. Interspeech 2021}, pages={6--10}, doi={10.21437/Interspeech.2021-546} } . Phonological Corpus of Czech ‚Äì seems similar enough to the described corpus for Czech. .",
            "url": "https://jimregan.github.io/notes/journal%20club/2021/09/13/journal-club.html",
            "relUrl": "/journal%20club/2021/09/13/journal-club.html",
            "date": " ‚Ä¢ Sep 13, 2021"
        }
        
    
  
    
        ,"post15": {
            "title": "CoNLL 2017 Irish data",
            "content": "CoNLL 2017 Shared Task - Automatically Annotated Raw Texts and Word Embeddings . There was a web page with raw text; the Irish data has some stuff that looks weird. There are items that look like they were poorly split, but there are items from Logos Poetry like this: . 41] N√° tr√©ig neamh ar n√≠ nach lat; . where the line numbering and brace were intentional. Not that there aren‚Äôt odd splits because of poor sentence splitting. The sentence at line 4467 of ga-common_crawl-000.conllu.xz is: . do giallaibh) .i. tech l√°n do ghiallaibh aigi. . which comes from here: . N√≥ Eochaid Dompl√©n .i. domus (.i. tech) plena (.i. do giallaibh) .i. tech l√°n do ghiallaibh aigi. Is de rohainmniged Eochaid Dompl√©n de. . (i.e., it‚Äôs not even modern Irish). .",
            "url": "https://jimregan.github.io/notes/irish/2021/09/13/conll-2017.html",
            "relUrl": "/irish/2021/09/13/conll-2017.html",
            "date": " ‚Ä¢ Sep 13, 2021"
        }
        
    
  
    
        ,"post16": {
            "title": "Read a .wav file with Vosk API",
            "content": "import vosk import wave . from vosk import Model, KaldiRecognizer, SetLogLevel model = Model(&quot;model&quot;) rec = KaldiRecognizer(model, 16000) rec.SetWords(True) . wave_file = WAV_FILE . wf = wave.open(wave_file) . while True: data = wf.readframes(4000) if len(data) == 0: break if rec.AcceptWaveform(data): print(rec.Result()) else: print(rec.PartialResult()) rec.Result() .",
            "url": "https://jimregan.github.io/notes/vosk/2021/09/10/vosk-wav.html",
            "relUrl": "/vosk/2021/09/10/vosk-wav.html",
            "date": " ‚Ä¢ Sep 10, 2021"
        }
        
    
  
    
        ,"post17": {
            "title": "TG4 Foghlaim scraper pieces",
            "content": "import requests from bs4 import BeautifulSoup . landing = &quot;https://www.tg4.ie/ga/brandai-eile/foghlaim/ceachtanna/&quot; . landing_page = requests.get(landing) assert landing_page.status_code == 200 . soup = BeautifulSoup(landing_page.text, &quot;lxml&quot;) . lessons = [] for lesson_item in soup.find_all(&quot;a&quot;, {&quot;class&quot;: &quot;prog-panel&quot;}): lessons.append(lesson_item.get(&quot;href&quot;)) . def _reamhobair_text(url): out = [] page = requests.get(url) assert page.status_code == 200 soup = BeautifulSoup(page.text, &quot;lxml&quot;) for part in soup.find(&quot;div&quot;, {&quot;class&quot;: &quot;arconix-toggle-content&quot;}): #out.append(part.text) print(part) return out . _reamhobair_text(&quot;https://www.tg4.ie/ga/brandai-eile/foghlaim/ceachtanna/an-scoil/reamhobair/&quot;) . def _reamhobair_questions(url): import json out = [] page = requests.get(url) assert page.status_code == 200 soup = BeautifulSoup(page.text, &quot;lxml&quot;) for script_tag in soup.find_all(&quot;script&quot;): if script_tag.text.startswith(&quot;H5PIntegration=&quot;): if script_tag.text.endswith(&quot;;&quot;): json_inner = json.loads(script_tag.text[15:-1]) else: json_inner = json.loads(script_tag.text[15:]) if &quot;contents&quot; in json_inner: for k in json_inner[&quot;contents&quot;].keys(): if &quot;library&quot; in json_inner[&quot;contents&quot;][k].keys(): if &quot;jsonContent&quot; in json_inner[&quot;contents&quot;][k].keys(): jsc = json_inner[&quot;contents&quot;][k][&quot;jsonContent&quot;] if type(jsc) == str and &quot;questions&quot; in jsc: jsc_l = json.loads(jsc) out.append((k, json_inner[&quot;contents&quot;][k][&quot;library&quot;], jsc_l[&quot;questions&quot;])) else: continue return out _reamhobair_questions(&quot;https://www.tg4.ie/ga/brandai-eile/foghlaim/ceachtanna/an-scoil/reamhobair/&quot;) . _reamhobair_questions(&quot;https://www.tg4.ie/ga/brandai-eile/foghlaim/ceachtanna/ras-na-bpointi/mir-a-haon/&quot;) .",
            "url": "https://jimregan.github.io/notes/irish/scraper/tg4/incomplete/2021/09/07/tg4-foghlaim-scraper.html",
            "relUrl": "/irish/scraper/tg4/incomplete/2021/09/07/tg4-foghlaim-scraper.html",
            "date": " ‚Ä¢ Sep 7, 2021"
        }
        
    
  
    
        ,"post18": {
            "title": "Interesting links, 6/9/2021",
            "content": "Kungbib/swedish-bert-models. Paper: Playing with Words at the National Library of Sweden ‚Äì Making a Swedish BERT Huggingface: KBLab . NST Swedish Dictation (22 kHz) . SCRIBE - Spoken Corpus of British English . The available audio recordings and annotations were released on eleven CD-ROMs (labelled SCRIBE_0 to SCRIBE_11) in April . These were originally distributed by the Speech Group at the National Physical Laboratory, but after this was closed down the disks were passed to the MOD Speech Research Unit at Malvern which passed the disks on to a private contractor (who kept them in his garage). | google/cld3 . google-research/text-to-text-transfer-transformer . superb benchmark models . . Scraping notes: . Gaelchult√∫r eolaire . Cogg: √Åiseanna Taca√≠ochta don Oideachas Speisialta, Bain S√∫p As, Leabhair Dhigiteacha . TG4: an-scoil/reamhobair, cursai-idirnaisiunta/reamhobair/, fadhbanna/reamhobair/, cursai-timpeallachta, cursai-airgid/mir-a-do, ponc/ponc-reamhobair . F√≠s agus Foghlaim . Comhar . Coisc√©im . Club Leabhar: PODCHRAOLTA√ç L√âIRMHEAST√ìIREACHTA AR LEABHAIR NA M√çOSA, AGALLAIMH AT√Å D√âANTA AGAINN LE H√öDAIR AGUS LE CRITICEOIR√ç LITEARTHA, Tintin mar charachtar an sc√©il .",
            "url": "https://jimregan.github.io/notes/links/scraping/2021/09/06/misc-links.html",
            "relUrl": "/links/scraping/2021/09/06/misc-links.html",
            "date": " ‚Ä¢ Sep 6, 2021"
        }
        
    
  
    
        ,"post19": {
            "title": "The processing of rhythmic structures in music and prosody by children with developmental dyslexia and developmental language disorder",
            "content": "The processing of rhythmic structures in music and prosody by children with developmental dyslexia and developmental language disorder . @article{caccia2021process, author = {Caccia, Martina and Lorusso, Maria Luisa}, title = {The processing of rhythmic structures in music and prosody by children with developmental dyslexia and developmental language disorder}, journal = {Developmental Science}, volume = {24}, number = {1}, pages = {e12981}, doi = {https://doi.org/10.1111/desc.12981}, year = {2021} } .",
            "url": "https://jimregan.github.io/notes/journal%20club/2021/09/06/journal-club.html",
            "relUrl": "/journal%20club/2021/09/06/journal-club.html",
            "date": " ‚Ä¢ Sep 6, 2021"
        }
        
    
  
    
        ,"post20": {
            "title": "Playing .wav files",
            "content": "from pathlib import Path import wave ncb_path = Path(&quot;/media/storage/phonetics/corpas_ncb/corpas_full_split_210415/&quot;) . files = [] for wf in ncb_path.glob(&quot;*.wav&quot;): cur = {} cur[&quot;id&quot;] = wf.stem wav = wave.open(str(wf)) fr = wav.getframerate() cur[&quot;framerate&quot;] = fr cur[&quot;duration&quot;] = wav.getnframes() / fr files.append(cur) . import json with open(&quot;out.json&quot;, &quot;w&quot;) as outf: json.dump(files, outf) .",
            "url": "https://jimregan.github.io/notes/test/2021/09/05/wav-playing.html",
            "relUrl": "/test/2021/09/05/wav-playing.html",
            "date": " ‚Ä¢ Sep 5, 2021"
        }
        
    
  
    
        ,"post21": {
            "title": "Playing with pyannote.audio 2",
            "content": "%%capture !pip install condacolab . Requirement already satisfied: condacolab in /usr/local/lib/python3.7/dist-packages (0.1.3) . import condacolab condacolab.install() . ‚è¨ Downloading https://github.com/jaimergp/miniforge/releases/latest/download/Mambaforge-colab-Linux-x86_64.sh... üì¶ Installing... üìå Adjusting configuration... ü©π Patching environment... ‚è≤ Done in 0:00:39 üîÅ Restarting kernel... . !conda create -n pyannote python=3.8.5 !conda activate pyannote !conda install numpy cffi !conda install libsndfile=1.0.28 -c conda-forge !pip install https://github.com/pyannote/pyannote-audio/archive/develop.zip . %%capture !wget https://podcast.rasset.ie/podcasts/audio/2021/0626/20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.mp3 . %%capture !ffmpeg -i /content/20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.mp3 -acodec pcm_s16le -ac 1 -ar 16000 /content/20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.wav . from pyannote.audio.pipelines import VoiceActivityDetection pipeline = VoiceActivityDetection(segmentation=&quot;pyannote/segmentation&quot;) HYPER_PARAMETERS = { # onset/offset activation thresholds &quot;onset&quot;: 0.5, &quot;offset&quot;: 0.5, # remove speech regions shorter than that many seconds. &quot;min_duration_on&quot;: 0.0, # fill non-speech regions shorter than that many seconds. &quot;min_duration_off&quot;: 0.0 } pipeline.instantiate(HYPER_PARAMETERS) vad = pipeline(&quot;/content/20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.wav&quot;) . ImportError Traceback (most recent call last) &lt;ipython-input-5-e82545d3d9d2&gt; in &lt;module&gt;() -&gt; 1 from pyannote.audio.pipelines import VoiceActivityDetection 2 pipeline = VoiceActivityDetection(segmentation=&#34;pyannote/segmentation&#34;) 3 HYPER_PARAMETERS = { 4 # onset/offset activation thresholds 5 &#34;onset&#34;: 0.5, &#34;offset&#34;: 0.5, /usr/local/lib/python3.7/site-packages/pyannote/audio/__init__.py in &lt;module&gt;() 27 28 &gt; 29 from .core.inference import Inference 30 from .core.io import Audio 31 from .core.model import Model /usr/local/lib/python3.7/site-packages/pyannote/audio/core/inference.py in &lt;module&gt;() 28 import torch 29 from einops import rearrange &gt; 30 from pytorch_lightning.utilities.memory import is_oom_error 31 32 from pyannote.audio.core.io import AudioFile /usr/local/lib/python3.7/site-packages/pytorch_lightning/__init__.py in &lt;module&gt;() 18 _PROJECT_ROOT = os.path.dirname(_PACKAGE_ROOT) 19 &gt; 20 from pytorch_lightning import metrics # noqa: E402 21 from pytorch_lightning.callbacks import Callback # noqa: E402 22 from pytorch_lightning.core import LightningDataModule, LightningModule # noqa: E402 /usr/local/lib/python3.7/site-packages/pytorch_lightning/metrics/__init__.py in &lt;module&gt;() 13 # limitations under the License. 14 &gt; 15 from pytorch_lightning.metrics.classification import ( # noqa: F401 16 Accuracy, 17 AUC, /usr/local/lib/python3.7/site-packages/pytorch_lightning/metrics/classification/__init__.py in &lt;module&gt;() 12 # See the License for the specific language governing permissions and 13 # limitations under the License. &gt; 14 from pytorch_lightning.metrics.classification.accuracy import Accuracy # noqa: F401 15 from pytorch_lightning.metrics.classification.auc import AUC # noqa: F401 16 from pytorch_lightning.metrics.classification.auroc import AUROC # noqa: F401 /usr/local/lib/python3.7/site-packages/pytorch_lightning/metrics/classification/accuracy.py in &lt;module&gt;() 16 from torchmetrics import Accuracy as _Accuracy 17 &gt; 18 from pytorch_lightning.metrics.utils import deprecated_metrics, void 19 20 /usr/local/lib/python3.7/site-packages/pytorch_lightning/metrics/utils.py in &lt;module&gt;() 27 from torchmetrics.utilities.distributed import reduce as _reduce 28 &gt; 29 from pytorch_lightning.utilities import rank_zero_deprecation 30 from pytorch_lightning.utilities.imports import _TORCHMETRICS_GREATER_EQUAL_0_3, _TORCHMETRICS_LOWER_THAN_0_3 31 /usr/local/lib/python3.7/site-packages/pytorch_lightning/utilities/__init__.py in &lt;module&gt;() 16 import numpy 17 &gt; 18 from pytorch_lightning.utilities.apply_func import move_data_to_device # noqa: F401 19 from pytorch_lightning.utilities.distributed import AllGatherGrad, rank_zero_info, rank_zero_only # noqa: F401 20 from pytorch_lightning.utilities.enums import ( # noqa: F401 /usr/local/lib/python3.7/site-packages/pytorch_lightning/utilities/apply_func.py in &lt;module&gt;() 28 29 if _TORCHTEXT_AVAILABLE: &gt; 30 if _compare_version(&#34;torchtext&#34;, operator.ge, &#34;0.9.0&#34;): 31 from torchtext.legacy.data import Batch 32 else: /usr/local/lib/python3.7/site-packages/pytorch_lightning/utilities/imports.py in _compare_version(package, op, version) 52 &#34;&#34;&#34; 53 try: &gt; 54 pkg = importlib.import_module(package) 55 except (ModuleNotFoundError, DistributionNotFound): 56 return False /usr/lib/python3.7/importlib/__init__.py in import_module(name, package) 125 break 126 level += 1 --&gt; 127 return _bootstrap._gcd_import(name[level:], package, level) 128 129 /usr/local/lib/python3.7/dist-packages/torchtext/__init__.py in &lt;module&gt;() 3 from . import datasets 4 from . import utils -&gt; 5 from . import vocab 6 from . import legacy 7 /usr/local/lib/python3.7/dist-packages/torchtext/vocab.py in &lt;module&gt;() 11 from typing import Dict, List, Optional, Iterable 12 from collections import Counter, OrderedDict &gt; 13 from torchtext._torchtext import ( 14 Vocab as VocabPybind, 15 ) ImportError: /usr/local/lib/python3.7/dist-packages/torchtext/_torchtext.so: undefined symbol: _ZN2at6detail10noopDeleteEPv NOTE: If your import is failing due to a missing package, you can manually install dependencies using either !pip or !apt. To view examples of installing some common dependencies, click the &#34;Open Examples&#34; button below. .",
            "url": "https://jimregan.github.io/notes/diarisation/pyannote/2021/09/05/playing-with-pyannote-audio2.html",
            "relUrl": "/diarisation/pyannote/2021/09/05/playing-with-pyannote-audio2.html",
            "date": " ‚Ä¢ Sep 5, 2021"
        }
        
    
  
    
        ,"post22": {
            "title": "Playing with inaSpeechSegmenter",
            "content": "%%capture !pip install inaSpeechSegmenter . from inaSpeechSegmenter import Segmenter . %%capture !wget https://podcast.rasset.ie/podcasts/audio/2021/0626/20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.mp3 . seg = Segmenter() . segmentation = seg(&#39;20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.mp3&#39;) . /usr/local/lib/python3.7/dist-packages/pyannote/algorithms/utils/viterbi.py:88: FutureWarning: arrays to stack must be passed as a &#34;sequence&#34; type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future. for e, c in six.moves.zip(emission.T, consecutive) /usr/local/lib/python3.7/dist-packages/pyannote/algorithms/utils/viterbi.py:97: FutureWarning: arrays to stack must be passed as a &#34;sequence&#34; type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future. for e, c in six.moves.zip(constraint.T, consecutive) . segmentation[0:6] . [(&#39;noEnergy&#39;, 0.0, 0.88), (&#39;music&#39;, 0.88, 4.72), (&#39;female&#39;, 4.72, 6.82), (&#39;male&#39;, 6.82, 11.34), (&#39;music&#39;, 11.34, 15.38), (&#39;male&#39;, 15.38, 26.68)] . !pip install pydub . Collecting pydub Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB) Installing collected packages: pydub Successfully installed pydub-0.25.1 . from pydub import AudioSegment audio = AudioSegment.from_mp3(&#39;20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.mp3&#39;) . clip1 = audio[int(0.88 * 1000):int(4.72 * 1000)] . clip1.export(&quot;clip1.ogg&quot;, format=&quot;ogg&quot;) . &lt;_io.BufferedRandom name=&#39;clip1.ogg&#39;&gt; . import IPython IPython.display.Audio(&quot;clip1.ogg&quot;) . clip2 = audio[int(4.72 * 1000):int(11.34 * 1000)] clip2.export(&quot;clip2.ogg&quot;, format=&quot;ogg&quot;) IPython.display.Audio(&quot;clip2.ogg&quot;) . clip3 = audio[int(981.08 * 1000):int(992.74 * 1000)] clip3.export(&quot;clip3.ogg&quot;, format=&quot;ogg&quot;) IPython.display.Audio(&quot;clip3.ogg&quot;) .",
            "url": "https://jimregan.github.io/notes/inaspeechsegmenter/segmentation/2021/09/05/playing-with-inaspeechsegmenter.html",
            "relUrl": "/inaspeechsegmenter/segmentation/2021/09/05/playing-with-inaspeechsegmenter.html",
            "date": " ‚Ä¢ Sep 5, 2021"
        }
        
    
  
    
        ,"post23": {
            "title": "Playing with Asteroid",
            "content": "%%capture !pip install -U asteroid . %%capture !wget https://podcast.rasset.ie/podcasts/audio/2021/0626/20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.mp3 . %%capture !ffmpeg -i /content/20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.mp3 -acodec pcm_s16le -ac 1 -ar 16000 /content/20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.wav . !asteroid-infer &quot;mpariente/ConvTasNet_WHAM!_sepclean&quot; --files /content/20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.wav --resample --ola-window 8000 --ola-hop 4000 . 100% 19.3M/19.3M [00:03&lt;00:00, 5.35MB/s] .",
            "url": "https://jimregan.github.io/notes/asteroid/separation/2021/09/05/playing-with-asteroid.html",
            "relUrl": "/asteroid/separation/2021/09/05/playing-with-asteroid.html",
            "date": " ‚Ä¢ Sep 5, 2021"
        }
        
    
  
    
        ,"post24": {
            "title": "N√≥s scraper pieces",
            "content": "sample = &#39;http://nos.ie/cultur/scannain/fisean-out-of-innocence-agallamh-le-heoin-o-dubhghaill/&#39; . import requests from bs4 import BeautifulSoup . page = requests.get(sample) . soup = BeautifulSoup(page.text, &#39;lxml&#39;) . vid = soup.find(&#39;div&#39;, {&#39;id&#39;, &#39;video-wrapper&#39;}) . _get_video(soup) . &#39;https://www.youtube.com/embed/lXr1QZPY7aY&#39; . def _get_video(soup): vid = soup.find(&#39;div&#39;, {&#39;id&#39;: &#39;video-wrapper&#39;}) if vid: iframe = vid.find(&#39;iframe&#39;) if iframe: return iframe.get(&#39;src&#39;, &#39;&#39;) return &#39;&#39; . def _get_details(soup): details = {} pubdet = soup.find(&quot;div&quot;, {&quot;id&quot;: &quot;single-publish-details&quot;}) ptags = [p for p in pubdet.find_all(&#39;p&#39;)] if ptags[0].b: details[&#39;author&#39;] = ptags[0].b.get_text(strip=True) if ptags[1]: details[&#39;date&#39;] = ptags[1].get_text(strip=True) broll = pubdet.find(&quot;div&quot;, {&quot;class&quot;: &quot;blogroll-tag-category&quot;}) cats = set() for cat in broll.find_all(&quot;a&quot;, {&quot;class&quot;: &quot;featured-category&quot;}): if cat.get_text(strip=True) != &quot;&quot;: cats.add(cat.get_text(strip=True)) if len(cats) &gt; 0: details[&#39;categories&#39;] = list(cats) tags = set() for tag in broll.find_all(&quot;a&quot;, {&quot;class&quot;: &quot;featured-tag&quot;}): if tag.get_text(strip=True) != &quot;&quot;: tags.add(tag.get_text(strip=True)) if len(tags) &gt; 0: details[&#39;tags&#39;] = list(tags) return details . _get_subhead(soup) . &#39;&#39; . def _get_subhead(soup): out = [] content = soup.find(&quot;div&quot;, {&quot;id&quot;: &quot;single-area-center&quot;}) if content.h1 and content.h1.span: return content.h1.span.get_text(strip=True) else: return &#39;&#39; . def _mksoup(url): page = requests.get(url) soup = BeautifulSoup(page.text, &#39;lxml&#39;) return soup . def _read_menu(): page = requests.get(&quot;http://nos.ie/&quot;) soup = BeautifulSoup(page.text, &#39;lxml&#39;) menu = soup.find(&quot;ul&quot;, {&quot;id&quot;: &quot;menu-main-menu&quot;}) cat_pages = set() for li in menu.find_all(&quot;li&quot;): if li.a: cat_pages.add(li.a[&#39;href&#39;]) return cat_pages . links = _read_menu() . a = _get_article_list(links) . len(a) . 296 . def _get_article_list(urls): rest = set() articles = set() for url in urls: page = requests.get(url) soup = BeautifulSoup(page.text, &#39;lxml&#39;) new = _get_remainder(soup) rest = rest.union(new) art = _collect_articles(soup) articles = articles.union(art) for url in rest: page = requests.get(url) soup = BeautifulSoup(page.text, &#39;lxml&#39;) art = _collect_articles(soup) articles = articles.union(art) return list(articles) . def _get_remainder(soup): import re pagination = soup.find(&quot;div&quot;, {&quot;class&quot;: &quot;pagination&quot;}) if not pagination: return [] current = pagination.find(&quot;span&quot;, {&quot;class&quot;: &quot;current&quot;}) if not (current and current.get_text(strip=True) == &quot;1&quot;): return [] cats = [a for a in pagination.find_all(&#39;a&#39;)] last_cat = cats[-1] last_url = last_cat.get(&#39;href&#39;, &#39;&#39;) if not last_url: return [] print(last_url) m = re.match(&quot;(.*/)([0-9]+)/$&quot;, last_url) if not m: return [] base = m.group(1) num = int(m.group(2)) + 1 return [f&#39;{base}{i}/&#39; for i in range(2, num)] . def _collect_articles(soup): out = set() for art in soup.find_all(&quot;article&quot;, {&quot;class&quot;: &quot;blogroll-post&quot;}): a = art.find(&#39;a&#39;) out.add(a.get(&#39;href&#39;)) return list(out) . top = _read_menu() . page = requests.get(&quot;http://nos.ie/category/cultur/ceol/&quot;) soup = BeautifulSoup(page.text, &#39;lxml&#39;) _collect_articles(soup) . arts = _get_article_list(top) .",
            "url": "https://jimregan.github.io/notes/irish/scraper/nos/2021/09/04/nos-scraper-pieces.html",
            "relUrl": "/irish/scraper/nos/2021/09/04/nos-scraper-pieces.html",
            "date": " ‚Ä¢ Sep 4, 2021"
        }
        
    
  
    
        ,"post25": {
            "title": "Interesting links, 3/9/2021",
            "content": "2dot71mily/youtube_captions_corrections: dataset here . facebookresearch/detr: End-to-End Object Detection with Transformers . timmahrt/praatIO: A python library for working with praat, textgrids, time aligned audio transcripts, and audio files. It is primarily used for extracting features from and making manipulations on audio files given hierarchical time-aligned transcriptions (utterance &gt; word &gt; syllable &gt; phone, etc). . nypl-openaudio/transcript-editor: Web-based tool for correcting speech-to-text generated transcripts. Runs Together We Listen . WGBH-MLA/transcript-editor: Web-based tool for correcting speech-to-text generated transcripts. . CNN Explainer . https://github.com/m3hrdadfi/soxan: Wav2Vec for speech recognition, classification, and audio classification . Irish relative clause . Indirect vs Direct Relative Clause ‚Äì Irish for English Speakers/Gaeilge do Bh√©arl√≥ir√≠ . Notes on Nolan (the Relative Clause) . Irish Gaelic dialects .",
            "url": "https://jimregan.github.io/notes/links/2021/09/03/misc-links.html",
            "relUrl": "/links/2021/09/03/misc-links.html",
            "date": " ‚Ä¢ Sep 3, 2021"
        }
        
    
  
    
        ,"post26": {
            "title": "Scraper pieces for beo.ie",
            "content": "sample_url = &#39;http://beo.ie/alt-an-eaglais-fein-a-bheas-thios-leis-ma-chuirtear-ba.aspx&#39; . import requests from bs4 import BeautifulSoup . page = requests.get(sample_url) . soup = BeautifulSoup(page.text, &#39;html.parser&#39;) . def _get_translations(soup): out = [] for gloss in soup.find_all(&#39;span&#39;, {&#39;class&#39;: &#39;gloss&#39;}): if gloss.get(&#39;title&#39;) != None and gloss.text: out.append({&#39;en&#39;: gloss.get(&#39;title&#39;), &#39;ga&#39;: gloss.text}) return out . def _get_captioned_images(soup): out = [] for pic in soup.find_all(&#39;div&#39;, {&#39;class&#39;: &#39;pic&#39;}): title = pic.find(&#39;div&#39;, {&#39;class&#39;: &#39;title&#39;}) if title: imgtag = pic.find(&#39;img&#39;) out.append({&#39;image&#39;: f&quot;http://beo.ie/{imgtag.get(&#39;src&#39;)}&quot;, &#39;caption&#39;: title.text}) return out . def _get_title(soup): title = soup.find(&#39;title&#39;).text if title and title.startswith(&#39;Beo! - &#39;): return(title[7:]) else: return None . def _get_blurb(soup): return soup.find(&#39;div&#39;, {&#39;class&#39;, &#39;blurb&#39;}).text.strip() . def _get_author(soup): dauth = soup.find(&#39;div&#39;, {&#39;class&#39;: &#39;author&#39;}) return dauth.find(&#39;span&#39;, {&#39;class&#39;: &#39;smallscreenInline&#39;}).text.strip() . def _get_paragraphs(soup): out = [] content = soup.find(&#39;div&#39;, {&#39;class&#39;: &#39;content&#39;}) for p in content.find_all(&#39;p&#39;): text = p.text.strip() if text: out.append(text) return out . edition_sample = &#39;http://beo.ie/eagran-2014-09.aspx&#39; . def _get_article_links(url): out = set() page = requests.get(url) soup = BeautifulSoup(page.text, &#39;html.parser&#39;) for article in soup.find_all(&#39;div&#39;, {&#39;class&#39;: &#39;articleListing&#39;}): for a in article.find_all(&#39;a&#39;): link = a.get(&#39;href&#39;) if link: out.add(f&quot;http://beo.ie/{link}&quot;) return list(out) . def _get_edition_links(): out = set() for i in range(1, 15): url = f&quot;http://beo.ie/Editions.aspx?Year=20{i:02}&quot; page = requests.get(url) soup = BeautifulSoup(page.text, &#39;html.parser&#39;) eds = soup.find(&#39;ul&#39;, {&#39;class&#39;: &#39;editions&#39;}) for ed in eds.find_all(&#39;a&#39;): if ed.get(&#39;href&#39;): out.add(f&quot;http://beo.ie/{ed.get(&#39;href&#39;)}&quot;) return list(out) .",
            "url": "https://jimregan.github.io/notes/irish/text/2021/09/01/beo-scraper-pieces.html",
            "relUrl": "/irish/text/2021/09/01/beo-scraper-pieces.html",
            "date": " ‚Ä¢ Sep 1, 2021"
        }
        
    
  
    
        ,"post27": {
            "title": "Convert .lab to textgrid",
            "content": "!pip install praatio . Collecting praatio Downloading praatio-5.0.0-py3-none-any.whl (76 kB) |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 76 kB 2.9 MB/s Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from praatio) (3.7.4.3) Installing collected packages: praatio Successfully installed praatio-5.0.0 . def _read_lab(filename: str, skip_empty_labels: bool = True): ret = [] with open(filename) as file: for line in file.readlines(): if line.strip() == &#39;&#39;: continue if line.startswith(&#39;#&#39;): continue l = line.rstrip().split(&#39; &#39;) if skip_empty_labels and len(l) != 3: continue tmp = {} tmp[&#39;start&#39;] = l[0] tmp[&#39;end&#39;] = l[1] if len(l) == 3: tmp[&#39;phone&#39;] = l[2] else: tmp[&#39;phone&#39;] = &#39;&#39; ret.append(tmp) return ret . %%writefile sample.lab 0 9700000 sil 9700000 10900000 i 10900000 12400000 mj 12400000 13100000 lj 13100000 15200000 au 15200000 16300000 r 16300000 18100000 sil 18100000 19100000 sil 19100000 23700000 . Writing sample.lab . ll = _read_lab(&#39;sample.lab&#39;, False) . from praatio import textgrid . from praatio.utilities.constants import Interval . out = [] for l in ll: out.append(Interval(int(l[&#39;start&#39;])/10000000.0, int(l[&#39;end&#39;])/10000000.0, l[&#39;phone&#39;])) . tier_start = out[0][0] tier_end = out[-1][1] . out . [Interval(start=0.0, end=0.97, label=&#39;sil&#39;), Interval(start=0.97, end=1.09, label=&#39;i&#39;), Interval(start=1.09, end=1.24, label=&#39;mj&#39;), Interval(start=1.24, end=1.31, label=&#39;lj&#39;), Interval(start=1.31, end=1.52, label=&#39;au&#39;), Interval(start=1.52, end=1.63, label=&#39;r&#39;), Interval(start=1.63, end=1.81, label=&#39;sil&#39;), Interval(start=1.81, end=1.91, label=&#39;sil&#39;), Interval(start=1.91, end=2.37, label=&#39;&#39;)] . tg = textgrid.Textgrid() phone_tier = textgrid.IntervalTier(&#39;phones&#39;, out, tier_start, tier_end) tg.addTier(phone_tier) tg.save(&#39;out.TextGrid&#39;, format=&quot;long_textgrid&quot;, includeBlankSpaces=False) . !cat out.TextGrid . File type = &#34;ooTextFile&#34; Object class = &#34;TextGrid&#34; xmin = 0 xmax = 2.37 tiers? &lt;exists&gt; size = 1 item []: item [1]: class = &#34;IntervalTier&#34; name = &#34;phones&#34; xmin = 0 xmax = 2.37 intervals: size = 9 intervals [1]: xmin = 0 xmax = 0.97 text = &#34;sil&#34; intervals [2]: xmin = 0.97 xmax = 1.09 text = &#34;i&#34; intervals [3]: xmin = 1.09 xmax = 1.24 text = &#34;mj&#34; intervals [4]: xmin = 1.24 xmax = 1.31 text = &#34;lj&#34; intervals [5]: xmin = 1.31 xmax = 1.52 text = &#34;au&#34; intervals [6]: xmin = 1.52 xmax = 1.63 text = &#34;r&#34; intervals [7]: xmin = 1.63 xmax = 1.81 text = &#34;sil&#34; intervals [8]: xmin = 1.81 xmax = 1.91 text = &#34;sil&#34; intervals [9]: xmin = 1.91 xmax = 2.37 text = &#34;&#34; .",
            "url": "https://jimregan.github.io/notes/lab/speech/textgrid/2021/08/31/lab_to_textgrid.html",
            "relUrl": "/lab/speech/textgrid/2021/08/31/lab_to_textgrid.html",
            "date": " ‚Ä¢ Aug 31, 2021"
        }
        
    
  
    
        ,"post28": {
            "title": "Read .lab files",
            "content": "%%writefile test.lab # 0 230 f 230 350 o 350 470 n . Writing test.lab . def _read_lab(filename: str): ret = [] with open(filename) as file: for line in file.readlines(): if line.strip() == &#39;&#39;: continue if line.startswith(&#39;#&#39;): continue l = line.rstrip().split(&#39; &#39;) if len(l) != 3: continue tmp = {} tmp[&#39;start&#39;] = l[0] tmp[&#39;end&#39;] = l[1] tmp[&#39;phone&#39;] = l[2] ret.append(tmp) return ret . _read_lab(&#39;test.lab&#39;) . [{&#39;end&#39;: &#39;230&#39;, &#39;phone&#39;: &#39;f&#39;, &#39;start&#39;: &#39;0&#39;}, {&#39;end&#39;: &#39;350&#39;, &#39;phone&#39;: &#39;o&#39;, &#39;start&#39;: &#39;230&#39;}, {&#39;end&#39;: &#39;470&#39;, &#39;phone&#39;: &#39;n&#39;, &#39;start&#39;: &#39;350&#39;}] .",
            "url": "https://jimregan.github.io/notes/lab/speech/2021/08/30/read_lab_file.html",
            "relUrl": "/lab/speech/2021/08/30/read_lab_file.html",
            "date": " ‚Ä¢ Aug 30, 2021"
        }
        
    
  
    
        ,"post29": {
            "title": "Parse Swedish gigaword XML",
            "content": "example = &quot;&quot;&quot; &lt;corpus id=&quot;1960-0000&quot;&gt; &lt;text date=&quot;1965-02-14&quot; datefrom=&quot;19650214&quot; dateto=&quot;19650214&quot; genre=&quot;news&quot; publisher=&quot;Stockholms Tidningen &quot; timefrom=&quot;000000&quot; timeto=&quot;235959&quot; topic=&quot;Politik och samh√§llsfr√•gor&quot; year=&quot;1965&quot;&gt; &lt;sentence id=&quot;aa9c2ac8-ae5dd1a1&quot;&gt; &lt;w dephead=&quot;4&quot; deprel=&quot;RA&quot; lemma=&quot;|i|&quot; lex=&quot;|i..pp.1|&quot; msd=&quot;PP&quot; pos=&quot;PP&quot; prefix=&quot;|&quot; ref=&quot;1&quot; saldo=&quot;|i..2|&quot; suffix=&quot;|&quot;&gt;I&lt;/w&gt; &lt;w dephead=&quot;3&quot; deprel=&quot;DT&quot; lemma=&quot;|&quot; lex=&quot;|&quot; msd=&quot;HD.UTR.SIN.IND&quot; pos=&quot;HD&quot; prefix=&quot;|&quot; ref=&quot;2&quot; saldo=&quot;|&quot; suffix=&quot;|&quot;&gt;vilken&lt;/w&gt; &lt;/sentence&gt; &lt;/text&gt; &lt;/corpus&gt; &quot;&quot;&quot; . import xml.etree.ElementTree as ET def _attrib(node, attrib: str) -&gt; str: if attrib in node.attrib: return node.attrib[attrib].strip() else: return &quot;&quot; def _iattrib(node, attrib: str) -&gt; str: if attrib in node.attrib: try: return int(node.attrib[attrib].strip()) except ValueError: return 0 else: return 0 class Corpus: def __init__(self, source): tree = ET.parse(source) root = tree.getroot() self.id = _attrib(root, &#39;id&#39;) self.texts = [] for text_node in root.findall(&#39;./text&#39;): self.texts.append(Text(text_node)) class Text: def __init__(self, node): self.date = _attrib(node, &#39;date&#39;) self.datefrom = _iattrib(node, &#39;datefrom&#39;) self.dateto = _iattrib(node, &#39;dateto&#39;) self.genre = _attrib(node, &#39;genre&#39;) self.publisher = _attrib(node, &#39;publisher&#39;) self.timefrom = _iattrib(node, &#39;timefrom&#39;) self.timeto = _iattrib(node, &#39;timeto&#39;) self.topic = _attrib(node, &#39;topic&#39;) self.year = _iattrib(node, &#39;year&#39;) self.sentences = [] for sent_node in node.findall(&#39;./sentence&#39;): self.sentences.append(Sentence(sent_node)) class Sentence: def __init__(self, node): self.id = _attrib(node, &#39;id&#39;) self.words = [] for w_node in node.findall(&#39;./w&#39;): self.words.append(Word(w_node)) class Word: def __init__(self, node): self.dephead = _attrib(node, &#39;dephead&#39;) self.deprel = _attrib(node, &#39;deprel&#39;) self.lemma = _attrib(node, &#39;lemma&#39;) self.lex = _attrib(node, &#39;lex&#39;) self.msd = _attrib(node, &#39;msd&#39;) self.pos = _attrib(node, &#39;pos&#39;) self.prefix = _attrib(node, &#39;prefix&#39;) self.ref = _attrib(node, &#39;ref&#39;) self.saldo = _attrib(node, &#39;saldo&#39;) self.suffix = _attrib(node, &#39;suffix&#39;) self.word = node.text.strip() . import io sio = io.StringIO(example) corp = Corpus(sio) . import json json.dumps(corp, default=lambda o: o.__dict__) . &#39;{&#34;id&#34;: &#34;1960-0000&#34;, &#34;texts&#34;: [{&#34;date&#34;: &#34;1965-02-14&#34;, &#34;datefrom&#34;: 19650214, &#34;dateto&#34;: 19650214, &#34;genre&#34;: &#34;news&#34;, &#34;publisher&#34;: &#34;Stockholms Tidningen&#34;, &#34;timefrom&#34;: 0, &#34;timeto&#34;: 235959, &#34;topic&#34;: &#34;Politik och samh u00e4llsfr u00e5gor&#34;, &#34;year&#34;: 1965, &#34;sentences&#34;: [{&#34;id&#34;: &#34;aa9c2ac8-ae5dd1a1&#34;, &#34;words&#34;: [{&#34;dephead&#34;: &#34;4&#34;, &#34;deprel&#34;: &#34;RA&#34;, &#34;lemma&#34;: &#34;|i|&#34;, &#34;lex&#34;: &#34;|i..pp.1|&#34;, &#34;msd&#34;: &#34;PP&#34;, &#34;pos&#34;: &#34;PP&#34;, &#34;prefix&#34;: &#34;|&#34;, &#34;ref&#34;: &#34;1&#34;, &#34;saldo&#34;: &#34;|i..2|&#34;, &#34;suffix&#34;: &#34;|&#34;, &#34;word&#34;: &#34;I&#34;}, {&#34;dephead&#34;: &#34;3&#34;, &#34;deprel&#34;: &#34;DT&#34;, &#34;lemma&#34;: &#34;|&#34;, &#34;lex&#34;: &#34;|&#34;, &#34;msd&#34;: &#34;HD.UTR.SIN.IND&#34;, &#34;pos&#34;: &#34;HD&#34;, &#34;prefix&#34;: &#34;|&#34;, &#34;ref&#34;: &#34;2&#34;, &#34;saldo&#34;: &#34;|&#34;, &#34;suffix&#34;: &#34;|&#34;, &#34;word&#34;: &#34;vilken&#34;}]}]}]}&#39; .",
            "url": "https://jimregan.github.io/notes/swedish/gigaword/xml/2021/08/30/parse_swedish_gigaword.html",
            "relUrl": "/swedish/gigaword/xml/2021/08/30/parse_swedish_gigaword.html",
            "date": " ‚Ä¢ Aug 30, 2021"
        }
        
    
  
    
        ,"post30": {
            "title": "Playing with pyannote.audio",
            "content": "Only the dia pipeline seems to work. . %%capture !pip install -q pyannote.audio==1.1 . %%capture !wget https://podcast.rasset.ie/podcasts/audio/2021/0626/20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.mp3 . %%capture !ffmpeg -i /content/20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.mp3 -acodec pcm_s16le -ac 1 -ar 16000 /content/20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.wav . import torch pipeline = torch.hub.load(&#39;pyannote/pyannote-audio&#39;, &#39;dia&#39;) diarization = pipeline({&#39;audio&#39;: &#39;/content/20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.wav&#39;}) . diarization . with open(&#39;/content/20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.rttm&#39;, &#39;w&#39;) as f: diarization.write_rttm(f) . %%capture !pip install youtube-dl . %%capture !youtube-dl f3wKxcP7hYE . %%capture !ffmpeg -i &#39;Sraith 2 Eip 1-f3wKxcP7hYE.mp4&#39; -acodec pcm_s16le -ac 1 -ar 16000 f3wKxcP7hYE.wav . diarization2 = pipeline({&#39;audio&#39;: &#39;/content/f3wKxcP7hYE.wav&#39;}) . diarization2 . No good; first 8 seconds are silence (ok), next 30 are theme music (not ok). . with open(&#39;/content/f3wKxcP7hYE.rttm&#39;, &#39;w&#39;) as f2: diarization2.write_rttm(f2) .",
            "url": "https://jimregan.github.io/notes/diarisation/pyannote/2021/08/27/playing-with-pyannote-audio.html",
            "relUrl": "/diarisation/pyannote/2021/08/27/playing-with-pyannote-audio.html",
            "date": " ‚Ä¢ Aug 27, 2021"
        }
        
    
  
    
        ,"post31": {
            "title": "Utterance XML to json",
            "content": "sample = &quot;&quot;&quot; &lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt; &lt;utterance input_string=&quot;&quot;&gt; &lt;sentence input_string=&quot;&quot;&gt; &lt;token input_string=&quot;SILENCE_TOKEN&quot;&gt; &lt;word input_string=&quot;SILENCE_TOKEN&quot; trans_source=&quot;src&quot; trans_output_format=&quot;final&quot;&gt; &lt;syllable &gt; &lt;phoneme symbol=&quot;sil&quot; end=&quot;1.19&quot;/&gt; &lt;/syllable&gt; &lt;/word&gt; &lt;/token&gt; &lt;/sentence&gt; &lt;/utterance&gt; &quot;&quot;&quot; . import xml.etree.ElementTree as ET . class Utterance: def __init__(self, input, sentences): self.input = input self.sentences = sentences . class Sentence: def __init__(self, input, tokens): self.input = input self.tokens = tokens . class Token: def __init__(self, input, words): self.input = input self.words = words . class Word: def __init__(self, input, source, syllables): self.input = input self.source = source self.syllables = syllables if self.syllables is None: self.syllables = [] . class Syllable: def __init__(self, stress: int = 0, phonemes = None): self.stress = stress self.phonemes = phonemes if self.phonemes is None: self.phonemes = [] . class Phoneme: def __init__(self, symbol: str = &quot;&quot;, end: float = 0.0): self.symbol = symbol self.end = end . import io sio = io.StringIO(sample.strip()) . def from_xml(source): tree = ET.parse(source) root = tree.getroot() if &#39;input_string&#39; in root.attrib: input = root.attrib[&#39;input_string&#39;] else: input = &#39;&#39; sentences = [] for sentence in root.findall(&#39;./sentence&#39;): if &#39;input_string&#39; in sentence.attrib: input = sentence.attrib[&#39;input_string&#39;] else: input = &#39;&#39; tokens = [] for token in sentence.findall(&#39;./token&#39;): if &#39;input_string&#39; in token.attrib: input = token.attrib[&#39;input_string&#39;] else: input = &#39;&#39; words = [] for word in token.findall(&#39;./word&#39;): if &#39;input_string&#39; in word.attrib: input = word.attrib[&#39;input_string&#39;] else: input = &quot;&quot; if &#39;trans_source&#39; in word.attrib: source = word.attrib[&#39;trans_source&#39;] else: source = &quot;&quot; syllables = [] for syllable in word.findall(&#39;./syllable&#39;): phonemes = [] if &#39;stress&#39; in syllable.attrib: stress = int(syllable.attrib[&#39;stress&#39;]) else: stress = 0 for phoneme in syllable.findall(&#39;./phoneme&#39;): if &#39;symbol&#39; in phoneme.attrib: symbol = phoneme.attrib[&#39;symbol&#39;] else: symbol = &#39;&#39; if &#39;end&#39; in phoneme.attrib: end = float(phoneme.attrib[&#39;end&#39;]) else: symbol = 0.0 phonemes.append(Phoneme(symbol, end)) syllables.append(Syllable(stress, phonemes)) words.append(Word(input, source, syllables)) tokens.append(Token(input, words)) sentences.append(Sentence(input, tokens)) return Utterance(input, sentences) . utt = from_xml(sio) . import json json.dumps(utt, default=lambda o: o.__dict__) . &#39;{&#34;input&#34;: &#34;SILENCE_TOKEN&#34;, &#34;sentences&#34;: [{&#34;input&#34;: &#34;SILENCE_TOKEN&#34;, &#34;tokens&#34;: [{&#34;input&#34;: &#34;SILENCE_TOKEN&#34;, &#34;words&#34;: [{&#34;input&#34;: &#34;SILENCE_TOKEN&#34;, &#34;source&#34;: &#34;src&#34;, &#34;syllables&#34;: [{&#34;stress&#34;: 0, &#34;phonemes&#34;: [{&#34;symbol&#34;: &#34;sil&#34;, &#34;end&#34;: 1.19}]}]}]}]}]}&#39; .",
            "url": "https://jimregan.github.io/notes/irish/abair/2021/08/22/utterance_xml_to_json.html",
            "relUrl": "/irish/abair/2021/08/22/utterance_xml_to_json.html",
            "date": " ‚Ä¢ Aug 22, 2021"
        }
        
    
  
    
        ,"post32": {
            "title": "Soundcloud - Raidi√≥ na Gaeltachta/Raidi√≥ F√°ilte",
            "content": "!pip install youtube-dl !youtube-dl -o &#39;%(id)s.%(ext)s&#39; https://soundcloud.com/rte-rnag/ !youtube-dl -o &#39;%(id)s.%(ext)s&#39; https://soundcloud.com/raidio-f .",
            "url": "https://jimregan.github.io/notes/kaggle/irish/soundcloud/dataset/unlabelled/rnag/raidiofailte/2021/08/21/soundcloud-raidio-na-gaeltachta.html",
            "relUrl": "/kaggle/irish/soundcloud/dataset/unlabelled/rnag/raidiofailte/2021/08/21/soundcloud-raidio-na-gaeltachta.html",
            "date": " ‚Ä¢ Aug 21, 2021"
        }
        
    
  
    
        ,"post33": {
            "title": "Download C√∫la4 ar Scoil video",
            "content": "urls = &quot;&quot;&quot; https://www.youtube.com/playlist?list=PLbcLsUBW9b3DvFSKW94bXDkVT0rIIbDTk https://www.youtube.com/playlist?list=PLbcLsUBW9b3ArxQoB-GhdSzGtYhhU-KGT https://www.youtube.com/playlist?list=PLbcLsUBW9b3CZJpM59kQ76Wxdfm3buABK https://www.youtube.com/playlist?list=PLbcLsUBW9b3ATOk7Kdzxb5KGM1wOFmwby https://www.youtube.com/playlist?list=PLbcLsUBW9b3DknBLzIWl0tRC_jYpmYdc5 https://www.youtube.com/playlist?list=PLbcLsUBW9b3B0D2MrdXYyxT9kgADvHfIJ https://www.youtube.com/playlist?list=PLbcLsUBW9b3AgMxkiet3mnzspREWj6o54 https://www.youtube.com/playlist?list=PLbcLsUBW9b3BWCOmTz3PNNsH2B71h2EeR https://www.youtube.com/playlist?list=PLbcLsUBW9b3A-N-5701r8dhxstLqBQFKm https://www.youtube.com/playlist?list=PLbcLsUBW9b3CZAzppIH9EidEIIvNdZFsL https://www.youtube.com/playlist?list=PLbcLsUBW9b3B5DD8uXW0rJySgsqAeed1C https://www.youtube.com/playlist?list=PLbcLsUBW9b3DVprPwU4hHT73VdmmY45bc https://www.youtube.com/playlist?list=PLbcLsUBW9b3AcCrGgD04ryY6bnN8h7GSr https://www.youtube.com/playlist?list=PLbcLsUBW9b3COzIi5Rnl0F9yRZVR3tf_1 https://www.youtube.com/playlist?list=PLbcLsUBW9b3BHkhYBvNIlQknE-wpBT5vp https://www.youtube.com/playlist?list=PLbcLsUBW9b3AJVck8CCw35QGPYHxPXi-F &quot;&quot;&quot; . for url in urls.strip().split(&#39; n&#39;): !youtube-dl -i -o &#39;%(id)s.%(ext)s&#39; {url} .",
            "url": "https://jimregan.github.io/notes/irish/dataset/cula4/2021/08/21/download-cula4-ar-scoil-video.html",
            "relUrl": "/irish/dataset/cula4/2021/08/21/download-cula4-ar-scoil-video.html",
            "date": " ‚Ä¢ Aug 21, 2021"
        }
        
    
  
    
        ,"post34": {
            "title": "Download BBC Gaeilge clips",
            "content": "for i in range(1, 27): !youtube-dl -o &#39;%(id)s.%(ext)s&#39; &#39;https://www.bbc.co.uk/programmes/b007cpvp/clips?page={i}&#39; .",
            "url": "https://jimregan.github.io/notes/irish/dataset/bbc/2021/08/21/download-bbc-gaeilge-clips.html",
            "relUrl": "/irish/dataset/bbc/2021/08/21/download-bbc-gaeilge-clips.html",
            "date": " ‚Ä¢ Aug 21, 2021"
        }
        
    
  
    
        ,"post35": {
            "title": "Soundcloud - Raidio na Life",
            "content": "Original on Kaggle (private) . !pip install youtube-dl !youtube-dl https://soundcloud.com/rnl .",
            "url": "https://jimregan.github.io/notes/kaggle/irish/soundcloud/dataset/unlabelled/raidionalife/2021/08/01/soundcloud-raidio-na-life.html",
            "relUrl": "/kaggle/irish/soundcloud/dataset/unlabelled/raidionalife/2021/08/01/soundcloud-raidio-na-life.html",
            "date": " ‚Ä¢ Aug 1, 2021"
        }
        
    
  
    
        ,"post36": {
            "title": "Soundcloud - N√ìS",
            "content": "Original on Kaggle (private) . !pip install youtube-dl !youtube-dl https://soundcloud.com/nosmag .",
            "url": "https://jimregan.github.io/notes/kaggle/irish/soundcloud/dataset/unlabelled/nos/2021/08/01/soundcloud-nos-pod.html",
            "relUrl": "/kaggle/irish/soundcloud/dataset/unlabelled/nos/2021/08/01/soundcloud-nos-pod.html",
            "date": " ‚Ä¢ Aug 1, 2021"
        }
        
    
  
    
        ,"post37": {
            "title": "Soundcloud - Cois Life",
            "content": "Original on Kaggle (private) . !pip install youtube-dl !youtube-dl https://soundcloud.com/cois-life-teoranta .",
            "url": "https://jimregan.github.io/notes/kaggle/irish/soundcloud/dataset/unlabelled/coislife/2021/08/01/soundcloud-cois-life.html",
            "relUrl": "/kaggle/irish/soundcloud/dataset/unlabelled/coislife/2021/08/01/soundcloud-cois-life.html",
            "date": " ‚Ä¢ Aug 1, 2021"
        }
        
    
  
    
        ,"post38": {
            "title": "Soundcloud - Club Leabhar",
            "content": "Original on Kaggle . !pip install youtube-dl !youtube-dl https://soundcloud.com/clubleabhar .",
            "url": "https://jimregan.github.io/notes/kaggle/irish/clubleabhar/dataset/unlabelled/2021/08/01/soundcloud-club-leabhar.html",
            "relUrl": "/kaggle/irish/clubleabhar/dataset/unlabelled/2021/08/01/soundcloud-club-leabhar.html",
            "date": " ‚Ä¢ Aug 1, 2021"
        }
        
    
  
    
        ,"post39": {
            "title": "Download Ros na R√∫n season 2",
            "content": "Original on Kaggle . %%capture !pip install youtube-dl . !youtube-dl -f bestaudio PLtVSQEQG0xVHeyao6vZyaY3kXGfbFFiAk .",
            "url": "https://jimregan.github.io/notes/kaggle/irish/rosnarun/dataset/unlabelled/2021/08/01/ros-na-run-s2.html",
            "relUrl": "/kaggle/irish/rosnarun/dataset/unlabelled/2021/08/01/ros-na-run-s2.html",
            "date": " ‚Ä¢ Aug 1, 2021"
        }
        
    
  
    
        ,"post40": {
            "title": "RnaG Podchraolta√≠",
            "content": "!curl https://www.rte.ie/radio/rnag/articles/eolas/2021/0712/1234521-podchraoltai/|grep &#39;il/Download&lt;/a&gt;&#39;|awk -F&#39;href=&quot;&#39; &#39;{print $2}&#39;|awk -F&#39;&quot;&#39; &#39;{print $1}&#39;|sed -e &#39;s/http:/https:/&#39; &gt; urls !cat urls |while read i;do wget $(curl $i|grep &#39;&lt;enclosure&#39;|awk -F&#39;url=&quot;&#39; &#39;{print $2}&#39;|awk -F&#39;&quot;&#39; &#39;{print $1}&#39;);done . https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-adhmhaidin-adhmhaidin_c21985558_21985605_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-adhmhaidin-nuachtnisi_c21985559_21985606_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-adhmhaidin-nuachtande_c21985560_21985607_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-adhmhaidin-nuachtantu_c21985561_21985608_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-adhmhaidin-nuachtania_c21985562_21985609_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-adhmhaidin-promhscalt_c21985563_21985610_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-adhmhaidin-promhscalt_c21985564_21985611_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-adhmhaidin-drcolmhenr_c21985565_21985612_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-adhmhaidin-tomssochin_c21985566_21985613_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-adhmhaidin-gearidnnic_c21985567_21985614_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-adhmhaidin-murtcualin_c21985568_21985615_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-adhmhaidin-sendebuitl_c21985569_21985616_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-adhmhaidin-anthonymol_c21985570_21985617_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-adhmhaidin-eoincathai_c21985571_21985618_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-adhmhaidin-adhmhaidin_c21985442_21985543_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-adhmhaidin-nuachtnisi_c21985443_21985544_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-adhmhaidin-nuachtande_c21985445_21985546_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-adhmhaidin-promhscalt_c21985447_21985548_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-adhmhaidin-antuairisc_c21985448_21985549_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-adhmhaidin-gearidnnic_c21985449_21985550_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-adhmhaidin-jimkeoghat_c21985450_21985551_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-adhmhaidin-gearidtuat_c21985451_21985552_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-adhmhaidin-eoincathai_c21985452_21985553_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-adhmhaidin-catherinec_c21985453_21985554_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-adhmhaidin-sencadhain_c21985454_21985555_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-adhmhaidin-crnanighal_c21985455_21985556_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-adhmhaidin-samuscosam_c21985456_21985557_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-adhmhaidin-adhmhaidin_c21984630_21984658_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-adhmhaidin-nuachtnisi_c21984631_21984659_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-adhmhaidin-nuachtantu_c21984632_21984660_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-adhmhaidin-nuachtania_c21984633_21984661_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-adhmhaidin-nuachtande_c21984634_21984662_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-adhmhaidin-promhscalt_c21984635_21984663_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-adhmhaidin-antuairisc_c21984636_21984664_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-adhmhaidin-gearidnnic_c21984637_21984665_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-adhmhaidin-eoincathin_c21984638_21984666_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-adhmhaidin-dithdemrdh_c21984639_21984667_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-adhmhaidin-drciarnfea_c21984640_21984668_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-adhmhaidin-aengussnod_c21984641_21984669_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-adhmhaidin-johnshamui_c21984642_21984670_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-adhmhaidin-johnconnol_c21984643_21984671_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-adhmhaidin-adhmhaidin_c21984065_21984079_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-adhmhaidin-nuachtnisi_c21984066_21984080_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-adhmhaidin-nuachtande_c21984067_21984081_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-adhmhaidin-nuachtantu_c21984068_21984082_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-adhmhaidin-nuachtania_c21984069_21984083_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-adhmhaidin-promhscalt_c21984070_21984084_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-adhmhaidin-antuairisc_c21984071_21984085_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-adhmhaidin-eoincathin_c21984072_21984086_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-adhmhaidin-pilnnchiar_c21984073_21984087_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-adhmhaidin-breandnmac_c21984074_21984088_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-adhmhaidin-rnndomhnai_c21984075_21984089_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-adhmhaidin-thomasotoo_c21984076_21984090_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-adhmhaidin-francesnic_c21984077_21984091_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-adhmhaidin-mirnuchidi_c21984078_21984092_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-adhmhaidin-adhmhaidin_c21983518_21983580_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-adhmhaidin-nuachtnisi_c21983519_21983581_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-adhmhaidin-nuachtania_c21983520_21983582_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-adhmhaidin-nuachtande_c21983521_21983583_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-adhmhaidin-nuachtantu_c21983522_21983584_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-adhmhaidin-promhscalt_c21983523_21983585_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-adhmhaidin-antuairisc_c21983524_21983586_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-adhmhaidin-eoghancorr_c21983525_21983587_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-adhmhaidin-anthonydoo_c21983526_21983588_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-adhmhaidin-jasonmongi_c21983527_21983589_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-adhmhaidin-cathalseoi_c21983528_21983590_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-adhmhaidin-johndownin_c21983529_21983591_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-adhmhaidin-slinenchat_c21983530_21983592_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-adhmhaidin-seosaimhcu_c21983531_21983593_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-adhmhaidin-adhmhaidin_c21982311_21982326_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-adhmhaidin-nuachtnisi_c21982312_21982327_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-adhmhaidin-nuachtantu_c21982313_21982328_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-adhmhaidin-nuachtania_c21982314_21982329_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-adhmhaidin-nuachtande_c21982315_21982330_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-adhmhaidin-promhscalt_c21982316_21982331_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-adhmhaidin-antuairisc_c21982317_21982332_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-adhmhaidin-drniallcle_c21982318_21982333_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-adhmhaidin-eoincathin_c21982319_21982334_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-adhmhaidin-pidbrowneo_c21982320_21982335_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-adhmhaidin-niallmurch_c21982321_21982336_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-adhmhaidin-pilnnchiar_c21982322_21982337_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-adhmhaidin-kevinohara_c21982323_21982338_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-adhmhaidin-aindriasmu_c21982324_21982339_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-adhmhaidin-niallmuill_c21982325_21982340_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-adhmhaidin-adhmhaidin_c21981849_21981901_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-adhmhaidin-nuachtnisi_c21981850_21981902_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-adhmhaidin-nuachtande_c21981851_21981903_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-adhmhaidin-nuachtantu_c21981852_21981904_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-adhmhaidin-nuachtania_c21981853_21981905_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-adhmhaidin-promhscalt_c21981854_21981906_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-ansaolodheas-ansaoldhea_c21988383_21988390_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-ansaolodheas-malachamac_c21988384_21988391_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-ansaolodheas-cathalfian_c21988385_21988392_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-ansaolodheas-jacquidesi_c21988386_21988393_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-ansaolodheas-gearidnnic_c21988387_21988394_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-ansaolodheas-michelmacg_c21988388_21988395_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-ansaolodheas-aoifenchob_c21988389_21988396_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-ansaolodheas-ansaoldhea_c21987459_21987473_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-ansaolodheas-michelglia_c21987460_21987474_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-ansaolodheas-edelnloibh_c21987461_21987475_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-ansaolodheas-padalypdra_c21987462_21987476_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-ansaolodheas-dnalliathi_c21987463_21987477_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-ansaolodheas-caitlnbrea_c21987464_21987478_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-ansaolodheas-crthachfao_c21987465_21987479_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-ansaolodheas-ansaoldhea_c21987011_21987017_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-ansaolodheas-gearidnnic_c21987012_21987018_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-ansaolodheas-peadarriad_c21987013_21987019_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-ansaolodheas-niallluasa_c21987014_21987020_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-ansaolodheas-aoifenghra_c21987015_21987021_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-ansaolodheas-gearidnnic_c21987016_21987022_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0726/20210726_rteraidion-ansaolodheas-ansaoldhea_c21986466_21986472_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0726/20210726_rteraidion-ansaolodheas-michelmuir_c21986467_21986473_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0726/20210726_rteraidion-ansaolodheas-michelcrod_c21986468_21986474_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0726/20210726_rteraidion-ansaolodheas-diarmaiddu_c21986469_21986475_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0726/20210726_rteraidion-ansaolodheas-mikeosheac_c21986470_21986476_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0726/20210726_rteraidion-ansaolodheas-valeriench_c21986471_21986477_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-ansaolodheas-ansaoldhea_c21985661_21985682_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-ansaolodheas-pdraigcear_c21985662_21985683_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-ansaolodheas-niamhndhri_c21985663_21985684_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-ansaolodheas-ritanbheag_c21985664_21985685_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-ansaolodheas-breandncob_c21985665_21985686_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-ansaolodheas-michelcrod_c21985666_21985687_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-ansaolodheas-aoifenchob_c21985667_21985688_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-ansaolodheas-ansaoldhea_c21985439_21985441_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-ansaolodheas-ansaoldhea_c21984759_21984765_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-ansaolodheas-johndownin_c21984760_21984766_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-ansaolodheas-nramarianm_c21984761_21984767_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-ansaolodheas-mirtnmacio_c21984762_21984768_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-ansaolodheas-samusciobh_c21984763_21984769_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-ansaolodheas-diarmuiddo_c21984764_21984770_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-ansaolodheas-ansaoldhea_c21984294_21984300_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-ansaolodheas-liamrchinl_c21984295_21984301_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-ansaolodheas-macdaramac_c21984296_21984302_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-ansaolodheas-donnchafia_c21984297_21984303_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-ansaolodheas-johngoduib_c21984298_21984304_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-ansaolodheas-pdraigcdri_c21984299_21984305_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-ansaolodheas-ansaoldhea_c21983702_21983707_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-ansaolodheas-michelmuir_c21983703_21983708_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-ansaolodheas-senceallai_c21983704_21983709_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-ansaolodheas-seghansuil_c21983705_21983710_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-ansaolodheas-miresebrea_c21983706_21983711_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0716/20210716_rteraidion-ansaolodheas-ansaoldhea_c21983345_21983346_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-ansaolodheas-ansaoldhea_c21982591_21982593_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-ansaolodheas-ansaoldhea_c21982052_21982073_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-ansaolodheas-senlionird_c21982053_21982074_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-ansaolodheas-slenchonai_c21982054_21982075_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-ansaolodheas-fredanicgi_c21982055_21982076_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-ansaolodheas-ruthnriada_c21982056_21982077_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-ansaolodheas-deirdrenic_c21982057_21982078_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-ansaolodheas-liambeagla_c21982058_21982079_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0713/20210713_rteraidion-ansaolodheas-ansaoldhea_c21981432_21981438_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0713/20210713_rteraidion-ansaolodheas-breandnmac_c21981433_21981439_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0713/20210713_rteraidion-ansaolodheas-samusdrisc_c21981434_21981440_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0713/20210713_rteraidion-ansaolodheas-mireniccra_c21981435_21981441_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0713/20210713_rteraidion-ansaolodheas-breandnbea_c21981436_21981442_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0713/20210713_rteraidion-ansaolodheas-michelceal_c21981437_21981443_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-ansaolodheas-ansaoldhea_c21980962_21980968_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-ansaolodheas-dithdemord_c21980963_21980969_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-ansaolodheas-padalytdbe_c21980964_21980970_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-ansaolodheas-andreapala_c21980965_21980971_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-ansaolodheas-mabhuainif_c21980966_21980972_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-ansaolodheas-michelcinn_c21980967_21980973_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-ansaolodheas-ansaolodhe_c21980827_21980839_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-ansaolodheas-deaglnragi_c21980828_21980840_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-ansaolodheas-aoifenchro_c21980829_21980841_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-ansaolodheas-ineuchuill_c21980830_21980842_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-ansaolodheas-amonnbraon_c21980831_21980843_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-ansaolodheas-oifenchobh_c21980832_21980844_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0708/20210708_rteraidion-ansaolodheas-ansaoldhea_c21979524_21979531_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0708/20210708_rteraidion-ansaolodheas-dnalgruagi_c21979525_21979532_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0708/20210708_rteraidion-ansaolodheas-angelaughr_c21979526_21979533_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0708/20210708_rteraidion-ansaolodheas-johnkenned_c21979527_21979534_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0708/20210708_rteraidion-ansaolodheas-sensilleab_c21979528_21979535_232_drm_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0708/20210708_rteraidion-ansaolodheas-ruthnriada_c21979529_21979536_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0708/20210708_rteraidion-ansaolodheas-drbreandnc_c21979530_21979537_232_drm_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0707/20210707_rteraidion-ansaolodheas-ansaoldhea_c21979272_21979273_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0706/20210706_rteraidion-ansaolodheas-ansaoldhea_c21978234_21978239_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0706/20210706_rteraidion-ansaolodheas-antathairc_c21978235_21978240_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0706/20210706_rteraidion-ansaolodheas-macdaramac_c21978236_21978241_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0706/20210706_rteraidion-ansaolodheas-sensuillea_c21978237_21978242_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-barrscealta-barrscalta_c21988305_21988432_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-barrscealta-inenbhreis_c21988306_21988433_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-barrscealta-nicolanbha_c21988307_21988434_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-barrscealta-marybnmhic_c21988308_21988435_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-barrscealta-ciarnrabha_c21988309_21988436_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-barrscealta-lorcnmirtn_c21988310_21988437_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-barrscealta-eimearngha_c21988311_21988438_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-barrscealta-maryaggiea_c21988312_21988439_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-barrscealta-barrscalta_c21987865_21987872_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-barrscealta-pilnnicgei_c21987866_21987873_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-barrscealta-andrteaghl_c21987867_21987874_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-barrscealta-michealdui_c21987868_21987875_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-barrscealta-conalldomh_c21987869_21987876_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-barrscealta-fearnaromh_c21987870_21987877_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-barrscealta-geneeoghai_c21987871_21987878_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-barrscealta-barrscalta_c21987378_21987385_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-barrscealta-inenbhreis_c21987379_21987386_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-barrscealta-michelhean_c21987380_21987387_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-barrscealta-aoifenicse_c21987381_21987388_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-barrscealta-taynanicga_c21987382_21987389_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-barrscealta-anradomhna_c21987383_21987390_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-barrscealta-antathaire_c21987384_21987391_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-barrscealta-barrscalta_c21986924_21986930_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-barrscealta-inenbhreis_c21986925_21986931_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-barrscealta-ancomhairl_c21986926_21986932_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-barrscealta-edwardmaol_c21986927_21986933_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-barrscealta-ansirsintj_c21986928_21986934_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-barrscealta-sylvesterm_c21986929_21986935_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-barrscealta-barrscalta_c21985619_21985696_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-barrscealta-francesnic_c21985620_21985697_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-barrscealta-caitlnnbhr_c21985621_21985698_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-barrscealta-deirdrenbh_c21985622_21985699_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-barrscealta-eoghanmacg_c21985623_21985700_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-barrscealta-gearidnnic_c21985624_21985701_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-barrscealta-slenfhearr_c21985625_21985702_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-barrscealta-maryaggiea_c21985626_21985703_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-barrscealta-barrscalta_c21985027_21985033_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-barrscealta-maighradua_c21985028_21985034_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-barrscealta-andrteaghl_c21985029_21985035_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-barrscealta-anteachtad_c21985030_21985036_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-barrscealta-cathalmacs_c21985031_21985037_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-barrscealta-fearnaromh_c21985032_21985038_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-barrscealta-barrscalta_c21984708_21984715_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-barrscealta-francesnic_c21984709_21984716_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-barrscealta-antathairb_c21984710_21984717_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-barrscealta-marjorienc_c21984711_21984718_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-barrscealta-siobhnocon_c21984712_21984719_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-barrscealta-annienmhio_c21984713_21984720_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-barrscealta-dianenchan_c21984714_21984721_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-barrscealta-pilnnicgid_c21984183_21984190_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-barrscealta-paddybrown_c21984184_21984191_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-barrscealta-ansirsintj_c21984185_21984192_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-barrscealta-willieghri_c21984186_21984193_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-barrscealta-rnndochart_c21984187_21984194_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-barrscealta-dnallceall_c21984188_21984195_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-barrscealta-barrscalta_c21983753_21983759_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-barrscealta-nascaltanu_c21983754_21983760_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-barrscealta-msdoogiedu_c21983755_21983761_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-barrscealta-turasireac_c21983756_21983762_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-barrscealta-sriantasli_c21983757_21983763_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-barrscealta-crsaspirtl_c21983758_21983764_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0716/20210716_rteraidion-barrscealta-barrscalta_c21982973_21982979_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0716/20210716_rteraidion-barrscealta-maighradua_c21982974_21982980_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0716/20210716_rteraidion-barrscealta-eilsndhoch_c21982975_21982981_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0716/20210716_rteraidion-barrscealta-antdarsenc_c21982976_21982982_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0716/20210716_rteraidion-barrscealta-maryaggiea_c21982977_21982983_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0716/20210716_rteraidion-barrscealta-charliever_c21982978_21982984_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-barrscealta-barrscalta_c21982443_21982450_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-barrscealta-pilnnicgid_c21982444_21982451_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-barrscealta-andrteaghl_c21982445_21982452_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-barrscealta-anteachtad_c21982446_21982453_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-barrscealta-caoimhnbao_c21982447_21982454_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-barrscealta-ancomhairl_c21982448_21982455_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-barrscealta-ciaranstii_c21982449_21982456_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-barrscealta-scaltanuac_c21980995_21981010_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-barrscealta-mrturasire_c21980996_21981011_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-barrscealta-kayleighnm_c21980997_21981012_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-barrscealta-antathairm_c21980998_21981013_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-barrscealta-nacluichga_c21980999_21981014_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-barrscealta-barrscalta_c21980223_21980230_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-barrscealta-pilnnicgid_c21980224_21980231_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-barrscealta-dnallcnimh_c21980225_21980232_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-barrscealta-conorgallc_c21980226_21980233_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-barrscealta-patriciada_c21980227_21980234_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-barrscealta-dannydomhn_c21980228_21980235_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-barrscealta-maryaggiea_c21980229_21980236_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0708/20210708_rteraidion-barrscealta-barrscalta_c21979436_21979442_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0708/20210708_rteraidion-barrscealta-francesnic_c21979437_21979443_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0708/20210708_rteraidion-barrscealta-annabeanug_c21979438_21979444_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0708/20210708_rteraidion-barrscealta-andrteaghl_c21979439_21979445_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0604/20210604_rteraidion-bladhairernag-igecilleac_c21963252_21963259_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0604/20210604_rteraidion-bladhairernag-jessiesmit_c21963253_21963260_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0604/20210604_rteraidion-bladhairernag-ancraoltir_c21963256_21963263_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0604/20210604_rteraidion-bladhairernag-johnfearra_c21963257_21963264_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0604/20210604_rteraidion-bladhairernag-michaelcur_c21963316_21963324_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0603/20210603_rteraidion-bladhairernag-filenageal_c21962703_21963068_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0603/20210603_rteraidion-bladhairernag-jamiesugru_c21962705_21963070_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0603/20210603_rteraidion-bladhairernag-eimearmcgo_c21962706_21963071_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0603/20210603_rteraidion-bladhairernag-marcusmacc_c21962707_21963072_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0528/20210528_rteraidion-bladhairernag-nadescalta_c21959922_21959928_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0528/20210528_rteraidion-bladhairernag-leahndhoch_c21959924_21959930_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0528/20210528_rteraidion-bladhairernag-conorbrumm_c21959925_21959931_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0528/20210528_rteraidion-bladhairernag-conormaccr_c21959926_21959932_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0527/20210527_rteraidion-bladhairernag-susancolem_c21959338_21959344_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0527/20210527_rteraidion-bladhairernag-ilsndhuibh_c21959339_21959345_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0527/20210527_rteraidion-bladhairernag-deirdrench_c21959340_21959346_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0527/20210527_rteraidion-bladhairernag-namonaghan_c21959341_21959347_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0527/20210527_rteraidion-bladhairernag-diarmuidma_c21959342_21959348_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0521/20210521_rteraidion-bladhairernag-nadescalta_c21956962_21957052_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0521/20210521_rteraidion-bladhairernag-clarenchea_c21956964_21957054_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0521/20210521_rteraidion-bladhairernag-pamelapren_c21956965_21957055_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0521/20210521_rteraidion-bladhairernag-gaeltharsi_c21956966_21957056_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0520/20210520_rteraidion-bladhairernag-lisanicanb_c21956281_21956288_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0520/20210520_rteraidion-bladhairernag-comrtasnag_c21956282_21956289_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0520/20210520_rteraidion-bladhairernag-taiscevint_c21956283_21956290_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0520/20210520_rteraidion-bladhairernag-richieconr_c21956284_21956291_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0520/20210520_rteraidion-bladhairernag-tessaflemi_c21956285_21956292_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0520/20210520_rteraidion-bladhairernag-rosienghai_c21956286_21956293_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0514/20210514_rteraidion-bladhairernag-bladhairec_c21954020_21954027_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0514/20210514_rteraidion-bladhairernag-nadescalta_c21954021_21954028_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0514/20210514_rteraidion-bladhairernag-ceolbeobil_c21954022_21954029_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0514/20210514_rteraidion-bladhairernag-edelnbhrao_c21954023_21954030_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0514/20210514_rteraidion-bladhairernag-pdraigcong_c21954024_21954031_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0514/20210514_rteraidion-bladhairernag-mrteilifse_c21954025_21954032_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0514/20210514_rteraidion-bladhairernag-claresands_c21954026_21954033_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0513/20210513_rteraidion-bladhairernag-bladhairec_c21953402_21953408_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0513/20210513_rteraidion-bladhairernag-filenascco_c21953403_21953409_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0513/20210513_rteraidion-bladhairernag-aoisachath_c21953404_21953410_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0513/20210513_rteraidion-bladhairernag-claramurra_c21953405_21953411_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0513/20210513_rteraidion-bladhairernag-franktorma_c21953406_21953412_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0513/20210513_rteraidion-bladhairernag-gearidcobh_c21953407_21953413_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0507/20210507_rteraidion-bladhairernag-bladhairec_c21950931_21951100_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0507/20210507_rteraidion-bladhairernag-nadescalta_c21950932_21951101_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0507/20210507_rteraidion-bladhairernag-aoisachath_c21950933_21951102_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0507/20210507_rteraidion-bladhairernag-mrceoilemm_c21950934_21951103_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0507/20210507_rteraidion-bladhairernag-cultrlannm_c21950935_21951104_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0507/20210507_rteraidion-bladhairernag-comhdhilna_c21950936_21951105_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0506/20210506_rteraidion-bladhairernag-bladhairec_c21950342_21950351_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0506/20210506_rteraidion-bladhairernag-deirdrendh_c21950343_21950352_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0506/20210506_rteraidion-bladhairernag-comrtasnab_c21950344_21950353_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0506/20210506_rteraidion-bladhairernag-branmacglo_c21950345_21950354_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0506/20210506_rteraidion-bladhairernag-ceolbeomar_c21950346_21950355_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0506/20210506_rteraidion-bladhairernag-buachailln_c21950347_21950356_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0506/20210506_rteraidion-bladhairernag-ceolbeomar_c21950348_21950357_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0506/20210506_rteraidion-bladhairernag-pdraigjack_c21950349_21950358_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0506/20210506_rteraidion-bladhairernag-ceolbeocat_c21950350_21950359_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0430/20210430_rteraidion-bladhairernag-bladhairec_c21948145_21948153_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0430/20210430_rteraidion-bladhairernag-nadescalta_c21948146_21948154_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0430/20210430_rteraidion-bladhairernag-jonnydillo_c21948147_21948155_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0430/20210430_rteraidion-bladhairernag-diarmuidma_c21948148_21948156_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0430/20210430_rteraidion-bladhairernag-geariddris_c21948149_21948157_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0430/20210430_rteraidion-bladhairernag-paddyglack_c21948150_21948158_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0430/20210430_rteraidion-bladhairernag-cianmaonla_c21948151_21948159_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0430/20210430_rteraidion-bladhairernag-aonachmhac_c21948152_21948160_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0429/20210429_rteraidion-bladhairernag-bladhairec_c21947633_21947911_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0429/20210429_rteraidion-bladhairernag-seoirsnnmh_c21947634_21947912_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0429/20210429_rteraidion-bladhairernag-aoisachath_c21947635_21947913_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0429/20210429_rteraidion-bladhairernag-darraghcao_c21947636_21947914_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0429/20210429_rteraidion-bladhairernag-brdnfoxant_c21947637_21947915_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0429/20210429_rteraidion-bladhairernag-muireannni_c21947638_21947916_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0429/20210429_rteraidion-bladhairernag-nascoilnas_c21947639_21947917_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0423/20210423_rteraidion-bladhairernag-bladhairec_c21943846_21943852_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0423/20210423_rteraidion-bladhairernag-hughmacgio_c21943847_21943853_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0423/20210423_rteraidion-bladhairernag-helendiamo_c21943848_21943854_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0423/20210423_rteraidion-bladhairernag-eoinmuirch_c21943849_21943855_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0423/20210423_rteraidion-bladhairernag-ruthnicaoi_c21943850_21943856_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0423/20210423_rteraidion-bladhairernag-risnagusei_c21943851_21943857_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0422/20210422_rteraidion-bladhairernag-bladhairec_c21943159_21943166_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0422/20210422_rteraidion-bladhairernag-mollyheste_c21943160_21943167_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0422/20210422_rteraidion-bladhairernag-garrymacdo_c21943161_21943168_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0422/20210422_rteraidion-bladhairernag-culchaintl_c21943162_21943169_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0422/20210422_rteraidion-bladhairernag-ciaraoconn_c21943163_21943170_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0422/20210422_rteraidion-bladhairernag-gaeltharsi_c21943164_21943171_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0422/20210422_rteraidion-bladhairernag-andrcillia_c21943165_21943172_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0416/20210416_rteraidion-bladhairernag-bladhairec_c21940555_21940562_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0416/20210416_rteraidion-bladhairernag-juliejayna_c21940556_21940563_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0416/20210416_rteraidion-bladhairernag-aoisachath_c21940557_21940564_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0416/20210416_rteraidion-bladhairernag-bhalnamban_c21940558_21940565_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0416/20210416_rteraidion-bladhairernag-paulinesca_c21940559_21940566_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0416/20210416_rteraidion-bladhairernag-gaeltharsi_c21940560_21940567_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0725/20210725_rteraidion-cartlannbhothar-citpheatsa_c21986304_21986305_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0718/20210718_rteraidion-cartlannbhothar-katepheats_c21984168_21984169_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0711/20210711_rteraidion-cartlannbhothar-mirencheoc_c21981051_21981052_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0627/20210627_rteraidion-cartlannbhothar-cartlannbh_c21974782_21974852_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0620/20210620_rteraidion-cartlannbhothar-cartlannbh_c21971339_21972928_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0620/20210620_rteraidion-cartlannbhothar-samuspound_c21971340_21972929_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0620/20210620_rteraidion-cartlannbhothar-muirisgogc_c21971341_21972930_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0620/20210620_rteraidion-cartlannbhothar-seanchasan_c21971342_21972931_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0613/20210613_rteraidion-cartlannbhothar-cartlannbh_c21967487_21967522_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0606/20210606_rteraidion-cartlannbhothar-leabharanp_c21965134_21965135_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0530/20210530_rteraidion-cartlannbhothar-clriomln30_c21961256_21961259_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0530/20210530_rteraidion-cartlannbhothar-nracitinna_c21961257_21961260_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0530/20210530_rteraidion-cartlannbhothar-nrauchoiti_c21961258_21961261_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0523/20210523_rteraidion-cartlannbhothar-cartlannbh_c21957611_21957615_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0523/20210523_rteraidion-cartlannbhothar-tadhgdrisc_c21957612_21957616_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0523/20210523_rteraidion-cartlannbhothar-michelmaol_c21957613_21957617_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0523/20210523_rteraidion-cartlannbhothar-annradeblc_c21957614_21957618_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0516/20210516_rteraidion-cartlannbhothar-cartlannbh_c21954551_21954552_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0509/20210509_rteraidion-cartlannbhothar-cartlannbh_c21951494_21951647_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0425/20210425_rteraidion-cartlannbhothar-cartlannbh_c21945215_21945216_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0418/20210418_rteraidion-cartlannbhothar-clriomln18_c21941195_21941196_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0404/20210404_rteraidion-cartlannbhothar-cartlannbh_c21934559_21934560_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0321/20210321_rteraidion-cartlannbhothar-cartlannbh_c21927145_21927146_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0314/20210314_rteraidion-cartlannbhothar-cartlannbh_c21924362_21924363_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0221/20210221_rteraidion-cartlannbhothar-cartlannbh_c21913398_21913399_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0207/20210207_rteraidion-cartlannbhothar-cartlannbh_c21907422_21907423_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0117/20210117_rteraidion-cartlannbhothar-cuasabhoda_c21894664_21894665_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/1230/20201230_rteraidion-cartlannbhothar-cartlannbh_c21888929_21888933_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/1230/20201230_rteraidion-cartlannbhothar-tommhicgro_c21888930_21888934_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/1230/20201230_rteraidion-cartlannbhothar-siobhngrom_c21888931_21888935_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/1230/20201230_rteraidion-cartlannbhothar-peigsayers_c21888932_21888936_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/1220/20201220_rteraidion-cartlannbhothar-cartlannbh_c21886239_21886240_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/1025/20201025_rteraidion-cartlannbhothar-clriomln25_c21856360_21856365_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/1025/20201025_rteraidion-cartlannbhothar-dnallliath_c21856361_21856366_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/1025/20201025_rteraidion-cartlannbhothar-plarluacha_c21856362_21856367_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/1025/20201025_rteraidion-cartlannbhothar-simcionnfh_c21856363_21856368_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/1025/20201025_rteraidion-cartlannbhothar-sendehra_c21856364_21856369_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/1018/20201018_rteraidion-cartlannbhothar-cartlannbh_c21854576_21854577_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/1011/20201011_rteraidion-cartlannbhothar-cartlannbh_c21849866_21849867_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/0927/20200927_rteraidion-cartlannbhothar-cartlannbh_c21842121_21842122_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/0920/20200920_rteraidion-cartlannbhothar-cartlannbh_c21837633_21837637_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/0920/20200920_rteraidion-cartlannbhothar-cearnaigha_c21837634_21837638_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/0920/20200920_rteraidion-cartlannbhothar-mirenshcai_c21837635_21837639_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/0920/20200920_rteraidion-cartlannbhothar-donnchasha_c21837636_21837640_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-irisaniar-irisaniard_c21988256_21988263_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-irisaniar-andrneasan_c21988260_21988264_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-irisaniar-michaelfra_c21988261_21988265_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-irisaniar-senbnbreat_c21988262_21988266_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-irisaniar-irisaniard_c21987809_21987816_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-irisaniar-caomhnmacc_c21987811_21987817_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-irisaniar-deborahugh_c21987812_21987818_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-irisaniar-barrafthar_c21987813_21987819_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-irisaniar-pidtombnbr_c21987814_21987820_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-irisaniar-senbnbreat_c21987815_21987821_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-irisaniar-irisaniard_c21987335_21987342_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-irisaniar-mirnurinne_c21987336_21987343_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-irisaniar-angardabib_c21987337_21987344_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-irisaniar-bernienche_c21987338_21987345_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-irisaniar-senbnbreat_c21987339_21987346_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-irisaniar-aifrickeog_c21987341_21987347_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-irisaniar-tomsmaccon_c21986984_21986993_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-irisaniar-senbnbreat_c21986985_21986994_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0726/20210726_rteraidion-irisaniar-jimkeoghat_c21986327_21986332_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0726/20210726_rteraidion-irisaniar-breanndnbe_c21986328_21986333_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0726/20210726_rteraidion-irisaniar-chloenmhil_c21986329_21986334_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0726/20210726_rteraidion-irisaniar-senbnbreat_c21986330_21986335_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-irisaniar-irisaniard_c21984136_21984146_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-irisaniar-michelsmac_c21984137_21984147_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-irisaniar-desmondfen_c21984141_21984148_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-irisaniar-maryseoigh_c21984145_21984149_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-irisaniar-antollamhc_c21982413_21982417_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-irisaniar-michelsmac_c21982414_21982418_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-irisaniar-siobhnngha_c21982415_21982419_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-irisaniar-angardamic_c21982416_21982420_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-irisaniar-antiriseoi_c21981925_21981928_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-irisaniar-tomsruairc_c21981926_21981929_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-irisaniar-jenniferni_c21981927_21981930_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0713/20210713_rteraidion-irisaniar-endacongha_c21981362_21981365_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0713/20210713_rteraidion-irisaniar-bredanmhui_c21981363_21981366_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0713/20210713_rteraidion-irisaniar-bairbrenic_c21981364_21981367_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-irisaniar-geariddevn_c21980815_21980818_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-irisaniar-ritagibbon_c21980816_21980819_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-irisaniar-donnchamac_c21980817_21980820_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0702/20210702_rteraidion-irisaniar-irisaniard_c21976845_21976851_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0702/20210702_rteraidion-irisaniar-mairadfarr_c21976846_21976852_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0702/20210702_rteraidion-irisaniar-franorourk_c21976847_21976853_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0702/20210702_rteraidion-irisaniar-deirdrendh_c21976850_21976854_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0701/20210701_rteraidion-irisaniar-irisaniard_c21976185_21976215_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0701/20210701_rteraidion-irisaniar-deirdrensh_c21976211_21976216_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0701/20210701_rteraidion-irisaniar-pdraigmacd_c21976212_21976217_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0701/20210701_rteraidion-irisaniar-darachtuai_c21976213_21976218_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0701/20210701_rteraidion-irisaniar-muireannnd_c21976214_21976219_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0630/20210630_rteraidion-irisaniar-irisaniard_c21975584_21975593_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0630/20210630_rteraidion-irisaniar-breandnseo_c21975587_21975594_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0630/20210630_rteraidion-irisaniar-angardasti_c21975591_21975595_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0630/20210630_rteraidion-irisaniar-bridgebark_c21975592_21975596_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0625/20210625_rteraidion-irisaniar-antathairp_c21974114_21974115_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0623/20210623_rteraidion-irisaniar-pdraigloid_c21973019_21973024_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0623/20210623_rteraidion-irisaniar-colmanragh_c21973020_21973025_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0623/20210623_rteraidion-irisaniar-mairadmacc_c21973021_21973026_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0623/20210623_rteraidion-irisaniar-louisendhi_c21973022_21973027_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0623/20210623_rteraidion-irisaniar-annemarieu_c21973023_21973028_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0622/20210622_rteraidion-irisaniar-cilnneacht_c21972408_21972413_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0622/20210622_rteraidion-irisaniar-johnconnol_c21972409_21972414_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0622/20210622_rteraidion-irisaniar-ruairnillb_c21972410_21972415_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0622/20210622_rteraidion-irisaniar-inenfhgart_c21972411_21972416_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0622/20210622_rteraidion-irisaniar-samusrchin_c21972412_21972417_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0618/20210618_rteraidion-irisaniar-colmcuaiga_c21969857_21969862_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0618/20210618_rteraidion-irisaniar-brianstaun_c21969858_21969863_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0618/20210618_rteraidion-irisaniar-mirtncathi_c21969859_21969864_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0618/20210618_rteraidion-irisaniar-frankfahyc_c21969860_21969865_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0617/20210617_rteraidion-irisaniar-johnbhabaj_c21969299_21969318_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0617/20210617_rteraidion-irisaniar-fergusmacs_c21969300_21969319_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0617/20210617_rteraidion-irisaniar-donnchahal_c21969301_21969320_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0617/20210617_rteraidion-irisaniar-aislingnic_c21969302_21969321_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0616/20210616_rteraidion-irisaniar-mireumhaol_c21968788_21968792_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0616/20210616_rteraidion-irisaniar-orladebrca_c21968789_21968793_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0616/20210616_rteraidion-irisaniar-angardasal_c21968790_21968794_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0615/20210615_rteraidion-irisaniar-daramaoild_c21968302_21968307_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0615/20210615_rteraidion-irisaniar-emernrogin_c21968303_21968308_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0615/20210615_rteraidion-irisaniar-mirenneach_c21968304_21968309_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0615/20210615_rteraidion-irisaniar-edelnchurr_c21968305_21968310_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0614/20210614_rteraidion-irisaniar-samusbreat_c21967529_21967533_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0614/20210614_rteraidion-irisaniar-daramcgees_c21967530_21967534_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0611/20210611_rteraidion-irisaniar-aoifepower_c21966698_21966703_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0611/20210611_rteraidion-irisaniar-barryfthar_c21966699_21966704_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0611/20210611_rteraidion-irisaniar-lasairfhon_c21966700_21966705_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0611/20210611_rteraidion-irisaniar-andrsiobhn_c21966701_21966706_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0611/20210611_rteraidion-irisaniar-martndonnc_c21966702_21966707_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0610/20210610_rteraidion-irisaniar-inenchiari_c21966108_21966111_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0610/20210610_rteraidion-irisaniar-senhanaigh_c21966109_21966112_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0610/20210610_rteraidion-irisaniar-gearidcrib_c21966110_21966113_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0608/20210608_rteraidion-irisaniar-mireineuai_c21964956_21964960_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0608/20210608_rteraidion-irisaniar-cilliandon_c21964957_21964961_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-tusaite-tsite29721_c21988022_21988036_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-tusaite-tsitetuara_c21988023_21988037_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-tusaite-tsitepolai_c21988024_21988038_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-tusaite-tsiterbuai_c21988025_21988039_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-tusaite-tsitecscir_c21988026_21988040_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-tusaite-tsitemrnal_c21988027_21988041_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-tusaite-tsitemrnan_c21988028_21988042_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-tusaite-tsite28721_c21987525_21987533_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-tusaite-tsitenasco_c21987526_21987534_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-tusaite-tsitepolai_c21987527_21987535_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-tusaite-tsiteceapa_c21987528_21987536_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-tusaite-tsitegarch_c21987529_21987537_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-tusaite-tsitejoeca_c21987530_21987538_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-tusaite-tsiteansca_c21987531_21987539_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-tusaite-tsitemrnam_c21987532_21987540_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-tusaite-tsite27721_c21987049_21987054_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-tusaite-tsitepolai_c21987050_21987055_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-tusaite-tsitevacsa_c21987051_21987056_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-tusaite-tsitecosdo_c21987052_21987057_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-tusaite-tsiteanpai_c21987053_21987058_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0726/20210726_rteraidion-tusaite-tsite26721_c21986532_21986536_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0726/20210726_rteraidion-tusaite-tsiteathos_c21986533_21986537_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0726/20210726_rteraidion-tusaite-tsitevacsa_c21986534_21986538_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0726/20210726_rteraidion-tusaite-tsitebagai_c21986535_21986539_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-tusaite-tsite23721_c21985898_21985905_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-tusaite-tsitepolai_c21985899_21985906_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-tusaite-tsitetreoi_c21985900_21985907_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-tusaite-tsitefiosr_c21985901_21985908_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-tusaite-tsitesilsi_c21985902_21985909_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-tusaite-tsitescalt_c21985903_21985910_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-tusaite-tsitecrsas_c21985904_21985911_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-tusaite-tsite22721_c21985214_21985221_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-tusaite-tsitepolai_c21985215_21985222_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-tusaite-tsitedeacr_c21985216_21985223_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-tusaite-tsitenuach_c21985217_21985224_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-tusaite-tsitecluic_c21985218_21985225_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-tusaite-tsiteleasu_c21985219_21985226_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-tusaite-tsitemrnan_c21985220_21985227_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-tusaite-tsite21721_c21984807_21984814_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-tusaite-tsitepolai_c21984808_21984815_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-tusaite-tsitebsdes_c21984809_21984816_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-tusaite-tsiteathos_c21984810_21984817_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-tusaite-tsiteleasu_c21984811_21984818_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-tusaite-tsitemrnam_c21984812_21984819_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-tusaite-tsitemrnal_c21984813_21984820_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-tusaite-tsite20721_c21984357_21984363_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-tusaite-tsitedeaai_c21984358_21984364_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-tusaite-tsitepolai_c21984359_21984365_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-tusaite-tsitereach_c21984360_21984366_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-tusaite-tsiteancoi_c21984361_21984367_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-tusaite-tsiteanpai_c21984362_21984368_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-tusaite-tsite19721_c21983790_21983795_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-tusaite-tsitemaols_c21983791_21983796_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-tusaite-tsitedeire_c21983792_21983797_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-tusaite-tsiteeasao_c21983793_21983798_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-tusaite-tsitebsdea_c21983794_21983799_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0716/20210716_rteraidion-tusaite-tsite16721_c21983160_21983166_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0716/20210716_rteraidion-tusaite-tsitepolai_c21983161_21983167_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0716/20210716_rteraidion-tusaite-tsiteceart_c21983162_21983168_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0716/20210716_rteraidion-tusaite-tsitesilsi_c21983163_21983169_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0716/20210716_rteraidion-tusaite-tsitescalt_c21983164_21983170_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0716/20210716_rteraidion-tusaite-tsitecrsas_c21983165_21983171_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-tusaite-tsite15721_c21982632_21982639_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-tusaite-tsitepolai_c21982633_21982640_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-tusaite-tsitelonna_c21982634_21982641_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-tusaite-tsitedroch_c21982635_21982642_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-tusaite-tsitemrnal_c21982636_21982643_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-tusaite-tsitemrnan_c21982637_21982644_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-tusaite-tsitedeaai_c21982638_21982645_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-tusaite-tsite14721_c21982121_21982127_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-tusaite-tsitepolai_c21982122_21982128_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-tusaite-tsiteconco_c21982123_21982129_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-tusaite-tsitereach_c21982124_21982130_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-tusaite-tsitetarma_c21982125_21982131_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-tusaite-tsitemrnam_c21982126_21982132_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0713/20210713_rteraidion-tusaite-tsite13721_c21981552_21981558_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0713/20210713_rteraidion-tusaite-tsitepolai_c21981553_21981559_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0713/20210713_rteraidion-tusaite-tsiteathos_c21981554_21981560_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0713/20210713_rteraidion-tusaite-tsitebreat_c21981555_21981561_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0713/20210713_rteraidion-tusaite-tsitesaigh_c21981556_21981562_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0713/20210713_rteraidion-tusaite-tsiteanpai_c21981557_21981563_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-tusaite-tsite12721_c21981073_21981093_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-tusaite-tsiteathos_c21981074_21981094_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-tusaite-tsitestdas_c21981075_21981095_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-tusaite-tsiteandar_c21981076_21981096_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-tusaite-tsitenaeur_c21981077_21981097_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-tusaite-tsite9721_c21980451_21980457_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-tusaite-tsitefotho_c21980452_21980458_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-tusaite-tsitepolai_c21980453_21980459_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-tusaite-tsitesilsi_c21980454_21980460_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0706/20210706_rteraidion-ancheadghluineile-clr3tinnch_c21978343_21978617_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0629/20210629_rteraidion-ancheadghluineile-clr2aedrae_c21977827_21977828_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0622/20210622_rteraidion-ancheadghluineile-clr1evelyn_c21973179_21975128_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-aistionaer-antidsceas_c21985799_21985809_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-aistionaer-oilithreac_c21985800_21985810_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-aistionaer-seandaoine_c21985801_21985811_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-aistionaer-mchmagusla_c21985802_21985812_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-aistionaer-seanlitrea_c21985803_21985813_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0724/20210724_rteraidion-bailiuchanbhairbre-bailichnbh_c21986295_21986296_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0717/20210717_rteraidion-bailiuchanbhairbre-clr6cuairt_c21984170_21984171_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0710/20210710_rteraidion-bailiuchanbhairbre-clr5btharg_c21981049_21981050_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0703/20210703_rteraidion-bailiuchanbhairbre-clr4anscoi_c21977529_21977530_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0626/20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0619/20210619_rteraidion-bailiuchanbhairbre-bailichnbh_c21971319_21975130_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0612/20210612_rteraidion-bailiuchanbhairbre-bailichnbh_c21967481_21975129_232_.mp3 .",
            "url": "https://jimregan.github.io/notes/irish/kaggle/dataset/2021/08/01/rnag-podchraoltai.html",
            "relUrl": "/irish/kaggle/dataset/2021/08/01/rnag-podchraoltai.html",
            "date": " ‚Ä¢ Aug 1, 2021"
        }
        
    
  
    
        ,"post41": {
            "title": "Unpack Swedish Gigaword",
            "content": "Original on Kaggle . !for i in ../input/download-swedish-gigaword/*.tar;do tar xvf $i;done .",
            "url": "https://jimregan.github.io/notes/kaggle/swedish/incomplete/2021/07/31/unpack-swedish-gigaword.html",
            "relUrl": "/kaggle/swedish/incomplete/2021/07/31/unpack-swedish-gigaword.html",
            "date": " ‚Ä¢ Jul 31, 2021"
        }
        
    
  
    
        ,"post42": {
            "title": "Soundcloud - Foras na Gaeilge",
            "content": "Original on Kaggle (private) . !pip install youtube-dl !youtube-dl https://soundcloud.com/forasnagaeilge .",
            "url": "https://jimregan.github.io/notes/kaggle/irish/soundcloud/dataset/unlabelled/forasnagaeilge/2021/07/31/soundcloud-foras-na-gaeilge.html",
            "relUrl": "/kaggle/irish/soundcloud/dataset/unlabelled/forasnagaeilge/2021/07/31/soundcloud-foras-na-gaeilge.html",
            "date": " ‚Ä¢ Jul 31, 2021"
        }
        
    
  
    
        ,"post43": {
            "title": "Download Swedish Gigaword",
            "content": "Original on Kaggle . !wget http://spraakbanken.gu.se/lb/resurser/meningsmangder/gigaword-1950-59.tar !wget http://spraakbanken.gu.se/lb/resurser/meningsmangder/gigaword-1960-69.tar !wget http://spraakbanken.gu.se/lb/resurser/meningsmangder/gigaword-1970-79.tar !wget http://spraakbanken.gu.se/lb/resurser/meningsmangder/gigaword-1980-89.tar !wget http://spraakbanken.gu.se/lb/resurser/meningsmangder/gigaword-1990-99.tar !wget http://spraakbanken.gu.se/lb/resurser/meningsmangder/gigaword-2000-09.tar !wget http://spraakbanken.gu.se/lb/resurser/meningsmangder/gigaword-2010-15.tar .",
            "url": "https://jimregan.github.io/notes/swedish/kaggle/2021/07/31/download-swedish-gigaword.html",
            "relUrl": "/swedish/kaggle/2021/07/31/download-swedish-gigaword.html",
            "date": " ‚Ä¢ Jul 31, 2021"
        }
        
    
  
    
        ,"post44": {
            "title": "Github asset release from Colab",
            "content": "!pip install -q condacolab import condacolab condacolab.install() . ‚è¨ Downloading https://github.com/jaimergp/miniforge/releases/latest/download/Mambaforge-colab-Linux-x86_64.sh... üì¶ Installing... üìå Adjusting configuration... ü©π Patching environment... ‚è≤ Done in 0:00:44 üîÅ Restarting kernel... . !conda install gh --channel conda-forge . !pip install youtube-dl . !youtube-dl -i --write-sub --sub-lang ga -o &#39;%(id)s.%(ext)s&#39; PLbcLsUBW9b3BvuTbtMKBXmuyJq6Ygg3Rg . !ls ./*.vtt|zip subtitles.zip -@ . from google.colab import files files.download(&#39;subtitles.zip&#39;) . !ls ./*.mp4 ./*.mkv |zip videos.zip -@ . !echo $KEY |gh auth login --with-token . !git clone $REPO . %cd $REPO . !gh release upload v0.1 ../videos.zip . Successfully uploaded 1 asset to v0.1 .",
            "url": "https://jimregan.github.io/notes/github/colab/2021/07/30/github-release-from-colab.html",
            "relUrl": "/github/colab/2021/07/30/github-release-from-colab.html",
            "date": " ‚Ä¢ Jul 30, 2021"
        }
        
    
  
    
        ,"post45": {
            "title": "ICU RBNF format in Python",
            "content": "%%capture !pip install pyicu . import icu formatter = icu.RuleBasedNumberFormat(icu.URBNFRuleSetTag.SPELLOUT, icu.Locale(&#39;ga&#39;)) formatter.format(23) . &#39;fiche a tr√≠&#39; .",
            "url": "https://jimregan.github.io/notes/irish/icu/rbnf/2021/07/22/icu-rbnf-format.html",
            "relUrl": "/irish/icu/rbnf/2021/07/22/icu-rbnf-format.html",
            "date": " ‚Ä¢ Jul 22, 2021"
        }
        
    
  
    
        ,"post46": {
            "title": "Getting lmt to work",
            "content": "tl;dr -- lmt needs there to be either: . markdown after the last file piece | two newline characters | . !git clone https://github.com/driusan/lmt . fatal: destination path &#39;lmt&#39; already exists and is not an empty directory. . %cd lmt . /content/lmt . %%capture !apt install golang . !go build . import os os.environ[&#39;PATH&#39;] = f&#39;{os.environ[&quot;PATH&quot;]}:/content/lmt&#39; . %cd /content . /content . %%writefile test.go.md # Thing go test.go package main import ( fmt ) . Overwriting test.go.md . !lmt test.go.md . !cat test.go . cat: test.go: No such file or directory . %%writefile test2.go.md # Thing go test2.go package main import ( fmt ) . Overwriting test2.go.md . !lmt test2.go.md . !cat test2.go . cat: test2.go: No such file or directory . %%writefile test3.go.md # Thing go test3.go package main import ( fmt ) # Blah . Writing test3.go.md . !lmt test3.go.md !cat test3.go . //line test3.go.md:4 package main import ( fmt ) . %%writefile test4.go.md # Thing go test4.go package main import ( fmt ) . Writing test4.go.md . !lmt test4.go.md !cat test4.go . //line test4.go.md:4 package main import ( fmt ) .",
            "url": "https://jimregan.github.io/notes/lmt/2021/07/22/getting-lmt-to-work.html",
            "relUrl": "/lmt/2021/07/22/getting-lmt-to-work.html",
            "date": " ‚Ä¢ Jul 22, 2021"
        }
        
    
  
    
        ,"post47": {
            "title": "Render offline map with ipyleaflet and ipywebrtc",
            "content": "%%capture !pip install ipyleaflet ipywebrtc . from ipyleaflet import * thurles_point = (52.6801064,-7.804442099999999) thurles = Map(center=(52.8001064,-7.804442099999999), zoom=8, basemap=basemaps.Esri.DeLorme) marker = Marker(location=thurles_point, draggable=False) thurles.add_layer(marker) . The map needs to be rendered for ipywebrtc to work . thurles . from ipywebrtc import WidgetStream, ImageRecorder thurles_stream = WidgetStream(widget=thurles, max_fps=1) . thurles_img = ImageRecorder(stream=thurles_stream) thurles_img.recording = True thurles_img.autosave = False thurles_img.download() . import PIL.Image import PIL.ImageFilter import io thurles_pil = PIL.Image.open(io.BytesIO(thurles_img.image.value)) . thurles_pil .",
            "url": "https://jimregan.github.io/notes/ipyleaflet/ipywebrtc/map/2021/07/15/ipyleaflet-and-ipywebrtc.html",
            "relUrl": "/ipyleaflet/ipywebrtc/map/2021/07/15/ipyleaflet-and-ipywebrtc.html",
            "date": " ‚Ä¢ Jul 15, 2021"
        }
        
    
  
    
        ,"post48": {
            "title": "Swedish data from nb.no",
            "content": "Original on Kaggle (private) . !wget https://www.nb.no/sbfil/talegjenkjenning/22kHz/sv.22khz.txt.tar.gz . !tar zxvf sv.22khz.txt.tar.gz . !cat ./txt/dsm_txt/sw_mod_010.txt . !wget https://www.nb.no/sbfil/talegjenkjenning/16kHz_2020/se_2020/lydfiler_16_1.tar.gz . !tar zxvf lydfiler_16_1.tar.gz . !wget https://www.nb.no/sbfil/talegjenkjenning/16kHz_2020/se_2020/ADB_SWE_0467.tar.gz . !tar zxvf ADB_SWE_0467.tar.gz . !wget http://www.nb.no/sbfil/talegjenkjenning/16kHz/sve.16khz.0467-1.tar.gz . !tar zxvf sve.16khz.0467-1.tar.gz . !wget https://www.nb.no/sbfil/talesyntese/sve.ibm.talesyntese.tar.gz . !tar zxvf sve.ibm.talesyntese.tar.gz . !cat se10x016-08071999-1334_r4670016.json . ls -al se/se16x735-04111999-1559/se16x735-04111999-1559_u0107303-1.wav .",
            "url": "https://jimregan.github.io/notes/kaggle/swedish/incomplete/2021/07/09/nbno-swedish-data-links.html",
            "relUrl": "/kaggle/swedish/incomplete/2021/07/09/nbno-swedish-data-links.html",
            "date": " ‚Ä¢ Jul 9, 2021"
        }
        
    
  
    
        ,"post49": {
            "title": "Syllabify Phonetisaurus output",
            "content": "def is_schwa(phone, is_timit=True): if is_timit: return phone in [&quot;ax&quot;, &quot;axr&quot;, &quot;ix&quot;] else: return phone == &quot;AH0&quot; # CMUdict doesn&#39;t have syllabic consonants def is_syllabic_consonant(phone, is_timit=True): SYLLC = [&quot;el&quot;, &quot;em&quot;, &quot;en&quot;, &quot;er&quot;, &quot;er1&quot;, &quot;er2&quot;] if is_timit and phone in SYLLC: return True else: return False def is_vowel(phone): VOWELS = [&quot;aa&quot;, &quot;ae&quot;, &quot;ah&quot;, &quot;ao&quot;, &quot;aw&quot;, &quot;ax&quot;, &quot;axr&quot;, &quot;ay&quot;, &quot;eh&quot;, &quot;ey&quot;, &quot;ih&quot;, &quot;ix&quot;, &quot;iy&quot;, &quot;ow&quot;, &quot;oy&quot;, &quot;uh&quot;, &quot;uw&quot;] if phone[-1] in &quot;012&quot;: return phone[:-1].lower() in VOWELS else: return phone.lower() in VOWELS def is_vocalic(phone): return is_vowel(phone) or is_syllabic_consonant(phone) # http://web.archive.org/web/20100614180508/http://semarch.linguistics.fas.nyu.edu/barker/Syllables/syllabify.pl def sonority(phone): STOPS = [&quot;p&quot;, &quot;b&quot;, &quot;t&quot;, &quot;d&quot;, &quot;k&quot;, &quot;g&quot;] AFFRICATES = [&quot;ch&quot;, &quot;jh&quot;] FRICATIVES = [&quot;th&quot;, &quot;dh&quot;, &quot;f&quot;, &quot;v&quot;, &quot;s&quot;, &quot;z&quot;, &quot;sh&quot;, &quot;zh&quot;] NASALS = [&quot;m&quot;, &quot;n&quot;, &quot;ng&quot;] LIQUIDS = [&quot;l&quot;, &quot;r&quot;] GLIDES = [&quot;w&quot;, &quot;y&quot;] # &#39;s&#39; is special if phone == &quot;s&quot;: return 1 elif phone in STOPS: return 1 elif phone in AFFRICATES: return 2 elif phone in FRICATIVES: return 3 elif phone in NASALS: return 4 elif phone in LIQUIDS: return 5 elif phone == &quot;hh&quot;: return 6 elif phone in GLIDES: return 6 else: return 7 . def last_phoneme(graphone): grapheme, phoneme = graphone.split(&#39;}&#39;) return phoneme.split(&#39;|&#39;)[-1] def first_phoneme(graphone): grapheme, phoneme = graphone.split(&#39;}&#39;) return phoneme.split(&#39;|&#39;)[0] . assert last_phoneme(&#39;x}e|k|s&#39;) == &#39;s&#39; assert first_phoneme(&#39;x}e|k|s&#39;) == &#39;e&#39; . def voicing_mismatch(phone1, phone2): VOICED = [&quot;b&quot;, &quot;d&quot;, &quot;g&quot;, &quot;jh&quot;, &quot;dh&quot;, &quot;v&quot;, &quot;z&quot;, &quot;zh&quot;] DEVOICED = [&quot;p&quot;, &quot;t&quot;, &quot;k&quot;, &quot;ch&quot;, &quot;th&quot;, &quot;f&quot;, &quot;s&quot;, &quot;sh&quot;] if phone1 in VOICED and phone2 in DEVOICED: return True elif phone2 in VOICED and phone1 in DEVOICED: return True else: return False . def merge_graphones(graphones): graphemes = [] phonemes = [] for graphone in graphones: graphemes_string, phonemes_string = graphone.split(&#39;}&#39;) cur_graphemes = graphemes_string.split(&#39;|&#39;) cur_phonemes = phonemes_string.split(&#39;|&#39;) graphemes += cur_graphemes phonemes += cur_phonemes if len(graphemes) &gt; 1: pruned_graphemes = [a for a in graphemes if a != &#39;_&#39;] if len(pruned_graphemes) == 0: pruned_graphemes = [&#39;_&#39;] else: pruned_graphemes = graphemes if len(phonemes) &gt; 1: pruned_phonemes = [a for a in phonemes if a != &#39;_&#39;] if len(pruned_phonemes) == 0: pruned_phonemes = [&#39;_&#39;] else: pruned_phonemes = phonemes return &#39;}&#39;.join((&#39;|&#39;.join(pruned_graphemes), &#39;|&#39;.join(pruned_phonemes))) . assert merge_graphones(&quot;a}a t|h}th x}k|s&quot;.split(&#39; &#39;)) == &#39;a|t|h|x}a|th|k|s&#39; assert merge_graphones(&quot;a}a t|h}th x}k|s e}_&quot;.split(&#39; &#39;)) == &#39;a|t|h|x|e}a|th|k|s&#39; assert merge_graphones(&quot;a}_ t|h}_ x}_ e}_&quot;.split(&#39; &#39;)) == &#39;a|t|h|x|e}_&#39; assert merge_graphones(&quot;_}a _}th _}k|s&quot;.split(&#39; &#39;)) == &#39;_}a|th|k|s&#39; . def syllabify(graphones): sonority_up = True last_sonority_up = True last_sonority = 0 isvowel = False last_isvowel = False saw_vowel = False stack = [] output = [] last_phoneme = &quot;&quot; labials = [&quot;p&quot;, &quot;b&quot;, &quot;m&quot;, &quot;f&quot;, &quot;v&quot;] s_sh = [&quot;s&quot;, &quot;sh&quot;] for graphone in graphones[::-1]: phoneme = first_phoneme(graphone) phone_sonority = sonority(phoneme) isvowel = is_vocalic(phoneme) sonority_up = last_sonority &lt; phone_sonority # For timit if graphone == &#39;_&#39;: stack.append(graphone) continue if last_sonority == 3 and phone_sonority == 1: sonority_up = True if last_phoneme == &#39;w&#39; and phoneme in labials: last_sonority_up = False sonority_up = True if last_phoneme == &quot;m&quot; and not sonority_up and not phoneme in s_sh: last_sonority_up = False sonority_up = True if phoneme == &quot;m&quot; and not sonority_up and last_sonority &lt; 7: last_sonority_up = False sonority_up = True if phoneme == &quot;n&quot; and not sonority_up and last_sonority &lt; 6: last_sonority_up = False sonority_up = True if last_phoneme == &quot;m&quot; and not sonority_up and not phoneme in s_sh: last_sonority_up = False sonority_up = True if not sonority_up and phoneme == &quot;ng&quot;: last_sonority_up = False sonority_up = True if last_sonority == 7 and phone_sonority == 7: last_sonority_up = True sonority_up = True if sonority_up and last_sonority == 1 and sonority == 1 and phoneme != &quot;s&quot;: sonority_up = True # avoid bs/ps onsets if last_phoneme in [&quot;s&quot;, &quot;sh&quot;, &quot;z&quot;, &quot;zh&quot;] and phoneme in &quot;bp&quot;: last_sonority_up = False sonority_up = True if last_phoneme == &#39;l&#39; and phoneme in [&#39;d&#39;, &#39;t&#39;, &#39;dh&#39;, &#39;th&#39;]: last_sonority_up = False sonority_up = True def splitsyll(): if not saw_vowel: return False if isvowel and saw_vowel: return True if last_isvowel and isvowel: return True if voicing_mismatch(phoneme, last_phoneme): return True if not last_sonority_up and sonority_up: return True return False if splitsyll(): output.append(merge_graphones(stack[::-1])) stack = [] saw_vowel = False stack.append(graphone) last_sonority_up = sonority_up last_phoneme = phoneme last_sonority = phone_sonority last_isvowel = isvowel saw_vowel = saw_vowel or isvowel output.append(merge_graphones(stack[::-1])) return output[::-1] . assert syllabify(&#39;a}ax b}b o|u}aw1 t}t&#39;.split(&#39; &#39;)) == [&#39;a}ax&#39;, &#39;b|o|u|t}b|aw1|t&#39;] . with open(&#39;TIMIT.clean.corpus&#39;, &#39;r&#39;) as f, open(&#39;TIMIT.syllable.corpus&#39;, &#39;w&#39;) as of: for line in f.readlines(): graphones = line.split(&#39; &#39;) syll = syllabify(graphones) print(&#39; &#39;.join(syll), file=of) .",
            "url": "https://jimregan.github.io/notes/colab/timit/phonetisaurus/syllabification/2021/07/03/syllabify-phonetisaurus-output.html",
            "relUrl": "/colab/timit/phonetisaurus/syllabification/2021/07/03/syllabify-phonetisaurus-output.html",
            "date": " ‚Ä¢ Jul 3, 2021"
        }
        
    
  
    
        ,"post50": {
            "title": "Run phonetisaurus on TIMIT",
            "content": "The first few cells set up phonetisaurus; they are adapted from the instructions in the git README. . %%capture !apt-get -y install git g++ autoconf-archive make libtool # Python bindings !apt-get -y install python-setuptools python-dev # mitlm (to build a quick play model) !apt-get -y install gfortran . %%capture !wget http://www.openfst.org/twiki/pub/FST/FstDownload/openfst-1.6.2.tar.gz !tar -xvzf openfst-1.6.2.tar.gz %cd openfst-1.6.2 # Minimal configure, compatible with current defaults for Kaldi !./configure --enable-static --enable-shared --enable-far --enable-ngram-fsts !make -j 4 # Now wait a while... !make install . import os ldlibpath = os.environ[&#39;LD_LIBRARY_PATH&#39;] #_STORED_LD = &quot;/usr/local/nvidia/lib:/usr/local/nvidia/lib64&quot; newld = f&#39;{ldlibpath}:/usr/local/lib:/usr/local/lib/fst&#39; os.environ[&#39;LD_LIBRARY_PATH&#39;]=newld %env LD_LIBRARY_PATH . &#39;/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/lib:/usr/local/lib/fst&#39; . %%capture %cd /content !git clone https://github.com/AdolfVonKleist/Phonetisaurus.git %cd Phonetisaurus !./configure !make !make install . %cd /content/ . /content . We also need MITLM . %%capture !git clone https://github.com/mitlm/mitlm %cd mitlm !autoreconf -i !./configure !make !make install . %cd /content . /content . The TIMIT dictionary is relatively clean, so there are only a few small changes that are needed for phonetisaurus. . !cat TIMITDIC.txt|grep -v &#39;^;&#39;|tr -d &#39;/&#39;|sed -e &#39;s/ */ /g;s/~adj//;s/~v_past//;s/~v_pres//;s/~v//;s/~n//;&#39; &gt; TIMIT.cleaned !cat TIMIT.cleaned | perl -pe &#39;s/ s+/ /g; s/^ s+//; s/ s+$//; @_ = split (/ s+/); $w = shift (@_); $_ = $w.&quot; t&quot;.join (&quot; &quot;, @_).&quot; n&quot;;&#39; &gt; TIMIT.clean . !phonetisaurus-align --input=TIMIT.clean --ofile=TIMIT.clean.corpus --seq1_del=false . GitRevision: 0.9.1 Loading input file: TIMIT.clean Alignment failed: x Starting EM... Finished first iter... Iteration: 1 Change: 2.70318 Iteration: 2 Change: 0.0603504 Iteration: 3 Change: 0.0425539 Iteration: 4 Change: 0.0206814 Iteration: 5 Change: 0.0114756 Iteration: 6 Change: 0.00711536 Iteration: 7 Change: 0.0042429 Iteration: 8 Change: 0.00297546 Iteration: 9 Change: 0.00223923 Iteration: 10 Change: 0.00151825 Iteration: 11 Change: 0.00115204 Last iteration: 0.001 Loading corpus TIMIT.clean.corpus... 0.037 Smoothing[1] = ModKN 0.037 Smoothing[2] = ModKN 0.037 Smoothing[3] = ModKN 0.037 Smoothing[4] = ModKN 0.037 Smoothing[5] = ModKN 0.037 Smoothing[6] = ModKN 0.037 Smoothing[7] = ModKN 0.037 Smoothing[8] = ModKN 0.037 Set smoothing algorithms... 0.037 Y 6.063492e-01 0.037 Y 6.304450e-01 0.037 Y 7.305669e-01 0.037 Y 7.950124e-01 0.037 Y 8.524463e-01 0.038 Y 9.033717e-01 0.038 Y 9.355036e-01 0.038 Y 9.092702e-01 0.038 Estimating full n-gram model... 0.040 Saving LM to timit.arpa... GitRevision: 0.9.1 Initializing... Converting... . That thing I just said about the TIMIT dictionary being relatively clean? Nah. There are some errors, particularly with &#39;c&#39; being transcribed as &#39;ao&#39; (which is a vowel sound). Also, the default output of phonetisaurus-align only does 1:1, 1:0, 0:1, 2:1, and 1:2 mappings of graphemes and phonemes, which means some of the alignments look quite strange. . %%writefile clean_ngrams.pl #!/usr/bin/perl # Fix some of the alignments from phonetisaurus-align to be more recognisable to humans # Also fixes some transcription errors in the TIMIT dictionary (mostly c -&gt; ao) use warnings; use strict; use utf8; my $raw_replacements = &lt;&lt;_HERE_; e}_ l}el e|l}el e}_ d}ed e|d}ed e}_ d}d e|d}d e}iy1 e}_ e|e}iy1 i}ix o|n}n i|o}ix n}n r}_ t|-}r t}t r}r t|-|t}t -|k}n n|a}ae1 -}_ k|n}n a}ae1 a|c}ax c}k a}ax c|c}k c}k h}_ c|h}k c}k q|u}w c|q}k u}w n}n|t c}s n}n c}t|s i|c}ih1 k|-}k i}ih1 c|k}k -}_ a|k}ey1 e|-}k a}ey1 k}k e|-}_ -|k}n n|a}ae2 -}_ k|n}n a}ae2 a|t}ax e}_ -|e}t y}ay1 a}ax t}t e}_ -}_ e|y}ay1 t|u}ch r}axr t}ch u|r}axr e}_ d}d e|d}d a}ae1 e}_ a|e}ae1 a}ih e}_ a|e}ih -|c}ao -}_ c}k x}eh1|k -}s x}eh1|k|s -}_ e}_ l|l}el e|l|l}el w|h}hh y}w|ay1 w|h}hh|w y}ay1 a|d}ax j|o}jh u|r}er1 a}ax d|j}jh o|u|r}er1 a|d}ae2 u}jh|uw a}ae2 d}jh u}uw u}y|uh a|b}b u|a}y|uh b}b x}k -}s x}k|s -}_ u|r}er1 r}_ u|r|r}er1 o|r}axr r}_ o|r|r}axr u|r}axr r}_ u|r|r}axr e|r}axr r}_ e|r|r}axr a|r}axr r}_ h|o}iy1 e}_ a|r|r|h}axr o|e}iy1 e|r}er r}_ e|r|r}er i|r}er1 r}_ i|r|r}er1 u}_ a}aa1 u|a}aa1 w|h}hh i}w|er1 r}_ w|h}hh|w i|r}er1 b|o}b r}r b}b o|r}r e}_ a|r}er1 e|a|r}er1 q|u}k a}w|ey2 q}k u}w a}ey2 q|u}k a}w|ao1 q}k u}w a}ao1 w|h}hh a}w|ax w|h}hh|w a}ax t|u}ch r}axr t}ch u|r}axr d|u}jh a}uw|ax d}jh u}uw a}ax c|i}sh a}iy|ey2 c}sh i}iy a}ey2 i}ix a|t}t i|a}ix t}t w|h}hh e}w|iy1 a|t}t w|h}hh|w e|a}iy1 t}t q|u}k a}w|aa1 q}k u}w a}aa1 q|u}k a}w|ao2 q}k u}w a}ao2 q|u}k a}w|ae1 q}k u}w a}ae1 w|h}hh a}w|aa1 w|h}hh|w a}aa1 w|h}hh a}w|aa2 w|h}hh|w a}aa2 w|h}hh e}w|ae1 w|h}hh|w a}ae1 w|h}hh e}w|ae2 w|h}hh|w a}ae2 w|h}hh i}w|ay1 w|h}hh|w a}ay1 w|h}hh o}w|aa1 w|h}hh|w o}aa1 y|a}y c|h}aa1 t}t y}y a}aa1 c|h}_ t}t i}iy1 e}_ i|e}iy1 m|a}m &#39;}_ a}ae1 m}m a|&#39;|a}ae1 g|u}g e}_ g}g u|e}_ r}r h}_ r|h}r s}z s|a}ix s|s}z a}ix _HERE_ my %replacements = (); for my $rl (split(&#39; n&#39;, $raw_replacements)) { next if($rl !~ / t/); my @tmp = split(/ t/, $rl); $replacements{$tmp[0]} = $tmp[1]; } my $regex_inner = join(&#39;|&#39;, map { quotemeta $_ } keys %replacements); while(&lt;&gt;) { chomp; while(/(?:^| )($regex_inner)(?:$| )/g) { my $m = $1; my $qm = quotemeta($m); s/$qm/$replacements{$m}/; } my @phns = split/ /; my @out = (); for my $phn (@phns) { if($phn =~ /^([-&#39;]) |/) { my $ch = $1; push @out, &quot;$ch}_&quot;; push @out, substr($phn,2); } elsif($phn =~ /^([^ |]) |([-&#39;]) }(.*)$/) { my $ch1 = $1; my $ch2 = $2; my $ch3 = $3; push @out, &quot;$ch1}$ch3&quot;; push @out, &quot;$ch2}_&quot;; } elsif($phn eq &#39;c}ao&#39;) { if($phns[0] eq &#39;n}n&#39;) { push @out, &#39;c}s&#39;; } else { push @out, &#39;c}k&#39;; } } else { push @out, $phn; } } print join(&#39; &#39;, @out) . &quot; n&quot;; } . Writing clean_ngrams.pl . !cat TIMIT.clean.corpus | perl clean_ngrams.pl &gt; TIMIT.cleaner.corpus . !estimate-ngram -o 8 -t TIMIT.cleaner.corpus -wl timit.arpa # Convert to OpenFst format (10s-20s): !phonetisaurus-arpa2wfst --lm=timit.arpa --ofile=timit.fst . 0.001 Loading corpus TIMIT.cleaner.corpus... 0.026 Smoothing[1] = ModKN 0.026 Smoothing[2] = ModKN 0.026 Smoothing[3] = ModKN 0.026 Smoothing[4] = ModKN 0.026 Smoothing[5] = ModKN 0.026 Smoothing[6] = ModKN 0.026 Smoothing[7] = ModKN 0.026 Smoothing[8] = ModKN 0.026 Set smoothing algorithms... 0.026 Y 6.390977e-01 0.026 Y 6.202592e-01 0.026 Y 7.251729e-01 0.026 Y 7.967686e-01 0.027 Y 8.548704e-01 0.027 Y 9.046288e-01 0.027 Y 9.354281e-01 0.027 Y 9.105453e-01 0.027 Estimating full n-gram model... 0.029 Saving LM to timit.arpa... GitRevision: 0.9.1 Initializing... Converting... . .",
            "url": "https://jimregan.github.io/notes/colab/timit/phonetisaurus/2021/07/03/run-phonetisaurus-on-timit.html",
            "relUrl": "/colab/timit/phonetisaurus/2021/07/03/run-phonetisaurus-on-timit.html",
            "date": " ‚Ä¢ Jul 3, 2021"
        }
        
    
  
    
        ,"post51": {
            "title": "Run phonetisaurus on TIMIT via Kaggle",
            "content": "Original on Kaggle . The first few cells set up phonetisaurus; they are adapted from the instructions in the git README. . %%capture !apt-get -y install git g++ autoconf-archive make libtool # Python bindings !apt-get -y install python-setuptools python-dev !apt-get -y install gfortran . %%capture %cd /tmp !wget http://www.openfst.org/twiki/pub/FST/FstDownload/openfst-1.6.2.tar.gz !tar -xvzf openfst-1.6.2.tar.gz %cd openfst-1.6.2 !./configure --enable-static --enable-shared --enable-far --enable-ngram-fsts !make -j 4 # Now wait a while... !make install . import os ldlibpath = os.environ[&#39;LD_LIBRARY_PATH&#39;] newld = f&#39;{ldlibpath}:/usr/local/lib:/usr/local/lib/fst&#39; os.environ[&#39;LD_LIBRARY_PATH&#39;]=newld %env LD_LIBRARY_PATH . &#39;/opt/conda/lib:/usr/local/lib:/usr/local/lib/fst&#39; . %%capture %cd /tmp !git clone https://github.com/AdolfVonKleist/Phonetisaurus.git %cd Phonetisaurus !./configure !make !make install . %cd /tmp/ . /tmp . We also need MITLM . %%capture !git clone https://github.com/mitlm/mitlm %cd mitlm !autoreconf -i !./configure !make !make install . %cd /kaggle/working . /kaggle/working . The TIMIT dictionary is relatively clean, so there are only a few small changes that are needed for phonetisaurus. . !cat ../input/darpa-timit-acousticphonetic-continuous-speech/TIMITDIC.TXT|grep -v &#39;^;&#39;|tr -d &#39;/&#39;|sed -e &#39;s/ */ /g;s/~adj//;s/~v_past//;s/~v_pres//;s/~v//;s/~n//;&#39; &gt; /tmp/TIMIT.cleaned !cat /tmp/TIMIT.cleaned | perl -pe &#39;s/ s+/ /g; s/^ s+//; s/ s+$//; @_ = split (/ s+/); $w = shift (@_); $_ = $w.&quot; t&quot;.join (&quot; &quot;, @_).&quot; n&quot;;&#39; &gt; /tmp/TIMIT.clean . !phonetisaurus-align --input=/tmp/TIMIT.clean --ofile=TIMIT.clean.corpus --seq1_del=false . GitRevision: 0.9.1 Loading input file: /tmp/TIMIT.clean Alignment failed: x Starting EM... Finished first iter... Iteration: 1 Change: 2.70318 Iteration: 2 Change: 0.0603504 Iteration: 3 Change: 0.0425539 Iteration: 4 Change: 0.0206814 Iteration: 5 Change: 0.0114756 Iteration: 6 Change: 0.00711536 Iteration: 7 Change: 0.0042429 Iteration: 8 Change: 0.00297546 Iteration: 9 Change: 0.00223923 Iteration: 10 Change: 0.00151825 Iteration: 11 Change: 0.00115204 Last iteration: . That thing I just said about the TIMIT dictionary being relatively clean? Nah. There are some errors, particularly with &#39;c&#39; being transcribed as &#39;ao&#39; (which is a vowel sound). Also, the default output of phonetisaurus-align only does 1:1, 1:0, 0:1, 2:1, and 1:2 mappings of graphemes and phonemes, which means some of the alignments look quite strange. . %%writefile clean_ngrams.pl #!/usr/bin/perl # Fix some of the alignments from phonetisaurus-align to be more recognisable to humans # Also fixes some transcription errors in the TIMIT dictionary (mostly c -&gt; ao) use warnings; use strict; use utf8; my $raw_replacements = &lt;&lt;_HERE_; e}_ l}el e|l}el e}_ d}ed e|d}ed e}_ d}d e|d}d e}iy1 e}_ e|e}iy1 i}ix o|n}n i|o}ix n}n r}_ t|-}r t}t r}r t|-|t}t -|k}n n|a}ae1 -}_ k|n}n a}ae1 a|c}ax c}k a}ax c|c}k c}k h}_ c|h}k c}k q|u}w c|q}k u}w n}n|t c}s n}n c}t|s i|c}ih1 k|-}k i}ih1 c|k}k -}_ a|k}ey1 e|-}k a}ey1 k}k e|-}_ -|k}n n|a}ae2 -}_ k|n}n a}ae2 a|t}ax e}_ -|e}t y}ay1 a}ax t}t e}_ -}_ e|y}ay1 t|u}ch r}axr t}ch u|r}axr e}_ d}d e|d}d a}ae1 e}_ a|e}ae1 a}ih e}_ a|e}ih -|c}ao -}_ c}k x}eh1|k -}s x}eh1|k|s -}_ e}_ l|l}el e|l|l}el w|h}hh y}w|ay1 w|h}hh|w y}ay1 a|d}ax j|o}jh u|r}er1 a}ax d|j}jh o|u|r}er1 a|d}ae2 u}jh|uw a}ae2 d}jh u}uw u}y|uh a|b}b u|a}y|uh b}b x}k -}s x}k|s -}_ u|r}er1 r}_ u|r|r}er1 o|r}axr r}_ o|r|r}axr u|r}axr r}_ u|r|r}axr e|r}axr r}_ e|r|r}axr a|r}axr r}_ h|o}iy1 e}_ a|r|r|h}axr o|e}iy1 e|r}er r}_ e|r|r}er i|r}er1 r}_ i|r|r}er1 u}_ a}aa1 u|a}aa1 w|h}hh i}w|er1 r}_ w|h}hh|w i|r}er1 b|o}b r}r b}b o|r}r e}_ a|r}er1 e|a|r}er1 q|u}k a}w|ey2 q}k u}w a}ey2 q|u}k a}w|ao1 q}k u}w a}ao1 w|h}hh a}w|ax w|h}hh|w a}ax t|u}ch r}axr t}ch u|r}axr d|u}jh a}uw|ax d}jh u}uw a}ax c|i}sh a}iy|ey2 c}sh i}iy a}ey2 i}ix a|t}t i|a}ix t}t w|h}hh e}w|iy1 a|t}t w|h}hh|w e|a}iy1 t}t q|u}k a}w|aa1 q}k u}w a}aa1 q|u}k a}w|ao2 q}k u}w a}ao2 q|u}k a}w|ae1 q}k u}w a}ae1 w|h}hh a}w|aa1 w|h}hh|w a}aa1 w|h}hh a}w|aa2 w|h}hh|w a}aa2 w|h}hh e}w|ae1 w|h}hh|w a}ae1 w|h}hh e}w|ae2 w|h}hh|w a}ae2 w|h}hh i}w|ay1 w|h}hh|w a}ay1 w|h}hh o}w|aa1 w|h}hh|w o}aa1 y|a}y c|h}aa1 t}t y}y a}aa1 c|h}_ t}t i}iy1 e}_ i|e}iy1 m|a}m &#39;}_ a}ae1 m}m a|&#39;|a}ae1 g|u}g e}_ g}g u|e}_ r}r h}_ r|h}r s}z s|a}ix s|s}z a}ix _HERE_ my %replacements = (); for my $rl (split(&#39; n&#39;, $raw_replacements)) { next if($rl !~ / t/); my @tmp = split(/ t/, $rl); $replacements{$tmp[0]} = $tmp[1]; } my $regex_inner = join(&#39;|&#39;, map { quotemeta $_ } keys %replacements); while(&lt;&gt;) { chomp; while(/(?:^| )($regex_inner)(?:$| )/g) { my $m = $1; my $qm = quotemeta($m); s/$qm/$replacements{$m}/; } my @phns = split/ /; my @out = (); for my $phn (@phns) { if($phn =~ /^([-&#39;]) |/) { my $ch = $1; push @out, &quot;$ch}_&quot;; push @out, substr($phn,2); } elsif($phn =~ /^([^ |]) |([-&#39;]) }(.*)$/) { my $ch1 = $1; my $ch2 = $2; my $ch3 = $3; push @out, &quot;$ch1}$ch3&quot;; push @out, &quot;$ch2}_&quot;; } elsif($phn eq &#39;c}ao&#39;) { if($phns[0] eq &#39;n}n&#39;) { push @out, &#39;c}s&#39;; } else { push @out, &#39;c}k&#39;; } } else { push @out, $phn; } } print join(&#39; &#39;, @out) . &quot; n&quot;; } . Writing clean_ngrams.pl . !cat TIMIT.clean.corpus | perl clean_ngrams.pl &gt; TIMIT.cleaner.corpus . !estimate-ngram -o 8 -t TIMIT.cleaner.corpus -wl timit.arpa # Convert to OpenFst format (10s-20s): !phonetisaurus-arpa2wfst --lm=timit.arpa --ofile=timit.fst . 0.001 Loading corpus TIMIT.cleaner.corpus... 0.026 Smoothing[1] = ModKN 0.026 Smoothing[2] = ModKN 0.026 Smoothing[3] = ModKN 0.026 Smoothing[4] = ModKN 0.026 Smoothing[5] = ModKN 0.026 Smoothing[6] = ModKN 0.026 Smoothing[7] = ModKN 0.026 Smoothing[8] = ModKN 0.026 Set smoothing algorithms... 0.026 Y 6.390977e-01 0.026 Y 6.202592e-01 0.026 Y 7.251729e-01 0.026 Y 7.967686e-01 0.027 Y 8.548704e-01 0.027 Y 9.046288e-01 0.027 Y 9.354281e-01 0.027 Y 9.105453e-01 0.027 Estimating full n-gram model... 0.029 Saving LM to timit.arpa... GitRevision: 0.9.1 Initializing... Converting... . .",
            "url": "https://jimregan.github.io/notes/kaggle/timit/phonetisaurus/2021/07/03/run-phonetisaurus-on-timit-kaggle.html",
            "relUrl": "/kaggle/timit/phonetisaurus/2021/07/03/run-phonetisaurus-on-timit-kaggle.html",
            "date": " ‚Ä¢ Jul 3, 2021"
        }
        
    
  
    
        ,"post52": {
            "title": "Install phonetisaurus on Colab",
            "content": "%%capture !apt-get -y install git g++ autoconf-archive make libtool # Python bindings !apt-get -y install python-setuptools python-dev # mitlm (to build a quick play model) !apt-get -y install gfortran . %%capture !wget http://www.openfst.org/twiki/pub/FST/FstDownload/openfst-1.6.2.tar.gz !tar -xvzf openfst-1.6.2.tar.gz %cd openfst-1.6.2 # Minimal configure, compatible with current defaults for Kaldi !./configure --enable-static --enable-shared --enable-far --enable-ngram-fsts !make -j 4 # Now wait a while... !make install . import os ldlibpath = os.environ[&#39;LD_LIBRARY_PATH&#39;] #_STORED_LD = &quot;/usr/local/nvidia/lib:/usr/local/nvidia/lib64&quot; newld = f&#39;{ldlibpath}:/usr/local/lib:/usr/local/lib/fst&#39; os.environ[&#39;LD_LIBRARY_PATH&#39;]=newld %env LD_LIBRARY_PATH . &#39;/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/lib:/usr/local/lib/fst&#39; . %%capture %cd /content !git clone https://github.com/AdolfVonKleist/Phonetisaurus.git %cd Phonetisaurus !./configure !make !make install . %cd /content/ . /content .",
            "url": "https://jimregan.github.io/notes/phonetisaurus/colab/2021/07/03/install-phonetisaurus.html",
            "relUrl": "/phonetisaurus/colab/2021/07/03/install-phonetisaurus.html",
            "date": " ‚Ä¢ Jul 3, 2021"
        }
        
    
  
    
        ,"post53": {
            "title": "English hyphenation from Wiktionary",
            "content": "Original on Kaggle . %%capture !wget https://dumps.wikimedia.org/enwiktionary/20210620/enwiktionary-20210620-pages-articles-multistream.xml.bz2 . !bzcat enwiktionary-20210620-pages-articles-multistream.xml.bz2|grep &#39;hyphenation|en&#39; &gt; /tmp/rawhyph . !grep &#39;{{a|U.S.&#39; /tmp/rawhyph|sed -e &#39;s/{a|U.S.}//;s/{}//&#39; . * {{hyphenation|en|caption=|tub|er|vil}} . !cat /tmp/rawhyph|sed -e &#39;s/{a|U.S.}//;s/{}//;&#39;|sed -e &quot;s/&#39;&#39;&#39;:&#39;&#39;&#39;/|/g&quot;|awk -F&#39;{{hyphenation |en |&#39; &#39;{print $2}&#39;|awk -F&#39;}}&#39; &#39;{print $1}&#39;|perl -ane &#39;chomp;@l=split/ |/;if($l[0] =~ /=/){shift @l};if($l[$#l] =~ /=/){pop @l};print join(&quot;&quot;, @l) . &quot; t&quot; . join(&quot; &quot;, @l). &quot; n&quot;&#39;|sort|uniq &gt; hyphenation.tsv .",
            "url": "https://jimregan.github.io/notes/english/wiktionary/hyphenation/2021/06/24/english-hyphenation-from-wiktionary.html",
            "relUrl": "/english/wiktionary/hyphenation/2021/06/24/english-hyphenation-from-wiktionary.html",
            "date": " ‚Ä¢ Jun 24, 2021"
        }
        
    
  
    
        ,"post54": {
            "title": "Sine curve unit circle on Colab",
            "content": "%%capture # https://docs.manim.community/en/stable/installation/colab.html !sudo apt update !sudo apt install libcairo2-dev ffmpeg texlive texlive-latex-extra texlive-fonts-extra texlive-latex-recommended texlive-science tipa libpango1.0-dev !pip install manim !pip install IPython --upgrade . from manim import * . Manim Community v0.7.0 . %%manim -v WARNING --disable_caching -qm SineCurveUnitCircle # https://docs.manim.community/en/stable/examples.html#sinecurveunitcircle class SineCurveUnitCircle(Scene): # contributed by heejin_park, https://infograph.tistory.com/230 def construct(self): self.show_axis() self.show_circle() self.move_dot_and_draw_curve() self.wait() def show_axis(self): x_start = np.array([-6,0,0]) x_end = np.array([6,0,0]) y_start = np.array([-4,-2,0]) y_end = np.array([-4,2,0]) x_axis = Line(x_start, x_end) y_axis = Line(y_start, y_end) self.add(x_axis, y_axis) self.add_x_labels() self.origin_point = np.array([-4,0,0]) self.curve_start = np.array([-3,0,0]) def add_x_labels(self): x_labels = [ MathTex(&quot; pi&quot;), MathTex(&quot;2 pi&quot;), MathTex(&quot;3 pi&quot;), MathTex(&quot;4 pi&quot;), ] for i in range(len(x_labels)): x_labels[i].next_to(np.array([-1 + 2*i, 0, 0]), DOWN) self.add(x_labels[i]) def show_circle(self): circle = Circle(radius=1) circle.move_to(self.origin_point) self.add(circle) self.circle = circle def move_dot_and_draw_curve(self): orbit = self.circle origin_point = self.origin_point dot = Dot(radius=0.08, color=YELLOW) dot.move_to(orbit.point_from_proportion(0)) self.t_offset = 0 rate = 0.25 def go_around_circle(mob, dt): self.t_offset += (dt * rate) # print(self.t_offset) mob.move_to(orbit.point_from_proportion(self.t_offset % 1)) def get_line_to_circle(): return Line(origin_point, dot.get_center(), color=BLUE) def get_line_to_curve(): x = self.curve_start[0] + self.t_offset * 4 y = dot.get_center()[1] return Line(dot.get_center(), np.array([x,y,0]), color=YELLOW_A, stroke_width=2 ) self.curve = VGroup() self.curve.add(Line(self.curve_start,self.curve_start)) def get_curve(): last_line = self.curve[-1] x = self.curve_start[0] + self.t_offset * 4 y = dot.get_center()[1] new_line = Line(last_line.get_end(),np.array([x,y,0]), color=YELLOW_D) self.curve.add(new_line) return self.curve dot.add_updater(go_around_circle) origin_to_circle_line = always_redraw(get_line_to_circle) dot_to_curve_line = always_redraw(get_line_to_curve) sine_curve_line = always_redraw(get_curve) self.add(dot) self.add(orbit, origin_to_circle_line, dot_to_curve_line, sine_curve_line) self.wait(8.5) dot.remove_updater(go_around_circle) . . Your browser does not support the video tag.",
            "url": "https://jimregan.github.io/notes/manim/colab/2021/06/23/manim_sine_curve_colab.html",
            "relUrl": "/manim/colab/2021/06/23/manim_sine_curve_colab.html",
            "date": " ‚Ä¢ Jun 23, 2021"
        }
        
    
  
    
        ,"post55": {
            "title": "Scoring librispeech with Kaldi on Kaggle",
            "content": "Original here. This basically recreates this blog post, but with different test sets, and on Kaggle, where setting up Kaldi is a little more involved than usual. . Results: . test-clean test-other . tgsmall LM | 7.13 | 17.92 | . rnnlm rescored: | 5.85 | 15.98 | . Unpack Kaldi . %cd /opt . /opt . %%capture !tar xvf /kaggle/input/extract-prebuilt-kaldi-from-docker/kaldi.tar . import os os.environ[&#39;LD_LIBRARY_PATH&#39;] = &#39;/opt/conda/lib:/opt/kaldi/tools/openfst-1.6.7/lib:/opt/kaldi/src/lib:&#39; EXISTING_PATH = os.environ[&#39;PATH&#39;] . %cd / . / . %%capture !tar xvf /kaggle/input/extract-cuda-from-kaldi-docker/cuda.tar . import os os.environ[&#39;LD_LIBRARY_PATH&#39;] = f&#39;{os.environ[&quot;LD_LIBRARY_PATH&quot;]}:/usr/local/cuda-10.0/targets/x86_64-linux/lib/&#39; . %cd /opt/kaldi/egs . /opt/kaldi/egs . Install flac . %%capture !apt install -y flac . Create a work directory . !mkdir -p usels/s5 %cd usels/s5 . /opt/kaldi/egs/usels/s5 . !mkdir /kaggle/working/data !mkdir /kaggle/working/exp !ln -s /kaggle/working/data !ln -s /kaggle/working/exp . !ln -s ../../wsj/s5/steps !ln -s ../../wsj/s5/utils !ln -s ../../librispeech/s5/local . !mkdir conf . %%writefile conf/mfcc_hires.conf # config for high-resolution MFCC features, intended for neural network training # Note: we keep all cepstra, so it has the same info as filterbank features, # but MFCC is more easily compressible (because less correlated) which is why # we prefer this method. --use-energy=false # use average of log energy, not energy. --num-mel-bins=40 # similar to Google&#39;s setup. --num-ceps=40 # there is no dimensionality reduction. --low-freq=20 # low cutoff frequency for mel bins... this is high-bandwidth data, so # there might be some information at the low end. --high-freq=-400 # high cutoff frequently, relative to Nyquist of 8000 (=7600) . Writing conf/mfcc_hires.conf . Setting up paths . (In the scripts, you just source path.sh) . %env KALDI_ROOT=/opt/kaldi . env: KALDI_ROOT=/opt/kaldi . !cat ../../wsj/s5/path.sh . export KALDI_ROOT=`pwd`/../../.. [ -f $KALDI_ROOT/tools/env.sh ] &amp;&amp; . $KALDI_ROOT/tools/env.sh export PATH=$PWD/utils/:$KALDI_ROOT/tools/openfst/bin:$PWD:$PATH [ ! -f $KALDI_ROOT/tools/config/common_path.sh ] &amp;&amp; echo &gt;&amp;2 &#34;The standard file $KALDI_ROOT/tools/config/common_path.sh is not present -&gt; Exit!&#34; &amp;&amp; exit 1 . $KALDI_ROOT/tools/config/common_path.sh export LC_ALL=C . %env LC_ALL=C #PWD = !pwd PWD = &#39;/opt/kaldi/egs/usels/s5&#39; KALDI_ROOT = &#39;/opt/kaldi&#39; WSJ_PATH = f&#39;{PWD}/utils/:{KALDI_ROOT}/tools/openfst/bin:{PWD}:{EXISTING_PATH}&#39; . env: LC_ALL=C . !cat $KALDI_ROOT/tools/config/common_path.sh . # we assume KALDI_ROOT is already defined [ -z &#34;$KALDI_ROOT&#34; ] &amp;&amp; echo &gt;&amp;2 &#34;The variable KALDI_ROOT must be already defined&#34; &amp;&amp; exit 1 # The formatting of the path export command is intentionally weird, because # this allows for easy diff&#39;ing export PATH= ${KALDI_ROOT}/src/bin: ${KALDI_ROOT}/src/chainbin: ${KALDI_ROOT}/src/featbin: ${KALDI_ROOT}/src/fgmmbin: ${KALDI_ROOT}/src/fstbin: ${KALDI_ROOT}/src/gmmbin: ${KALDI_ROOT}/src/ivectorbin: ${KALDI_ROOT}/src/kwsbin: ${KALDI_ROOT}/src/latbin: ${KALDI_ROOT}/src/lmbin: ${KALDI_ROOT}/src/nnet2bin: ${KALDI_ROOT}/src/nnet3bin: ${KALDI_ROOT}/src/nnetbin: ${KALDI_ROOT}/src/online2bin: ${KALDI_ROOT}/src/onlinebin: ${KALDI_ROOT}/src/rnnlmbin: ${KALDI_ROOT}/src/sgmm2bin: ${KALDI_ROOT}/src/sgmmbin: ${KALDI_ROOT}/src/tfrnnlmbin: ${KALDI_ROOT}/src/cudadecoderbin: $PATH . raw_kaldi_paths=!cat $KALDI_ROOT/tools/config/common_path.sh|grep &#39;/src/&#39;|awk -F&#39;:&#39; &#39;{print $1}&#39;|awk -F&#39;/&#39; &#39;{print &quot;/opt/kaldi/src/&quot;$NF}&#39; . KALDI_PATHS=raw_kaldi_paths.nlstr.replace(&#39; n&#39;,&#39;:&#39;) . !cat $KALDI_ROOT/tools/env.sh . export PATH=/opt/kaldi/tools/python:${PATH} export PHONETISAURUS=&#34;/tmp/output/opt/kaldi/tools/phonetisaurus-g2p&#34; export PATH=&#34;$PATH:${PHONETISAURUS}:${PHONETISAURUS}/src/scripts&#34; . PHONETISAURUS = &quot;/tmp/output/opt/kaldi/tools/phonetisaurus-g2p&quot; TOOLS_PATH = f&#39;/opt/kaldi/tools/python:{PHONETISAURUS}:{PHONETISAURUS}/src/scripts&#39; . %env PATH = f&quot;{WSJ_PATH}:{KALDI_PATHS}:{TOOLS_PATH}&quot; . env: PATH=f&#34;/opt/kaldi/egs/usels/s5/utils/:/opt/kaldi/tools/openfst/bin:/opt/kaldi/egs/usels/s5:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/kaldi/src/bin:/opt/kaldi/src/chainbin:/opt/kaldi/src/featbin:/opt/kaldi/src/fgmmbin:/opt/kaldi/src/fstbin:/opt/kaldi/src/gmmbin:/opt/kaldi/src/ivectorbin:/opt/kaldi/src/kwsbin:/opt/kaldi/src/latbin:/opt/kaldi/src/lmbin:/opt/kaldi/src/nnet2bin:/opt/kaldi/src/nnet3bin:/opt/kaldi/src/nnetbin:/opt/kaldi/src/online2bin:/opt/kaldi/src/onlinebin:/opt/kaldi/src/rnnlmbin:/opt/kaldi/src/sgmm2bin:/opt/kaldi/src/sgmmbin:/opt/kaldi/src/tfrnnlmbin:/opt/kaldi/src/cudadecoderbin:/opt/kaldi/tools/python:/tmp/output/opt/kaldi/tools/phonetisaurus-g2p:/tmp/output/opt/kaldi/tools/phonetisaurus-g2p/src/scripts&#34; . !cat ../../wsj/s5/cmd.sh . # you can change cmd.sh depending on what type of queue you are using. # If you have no queueing system and want to run on a local machine, you # can change all instances &#39;queue.pl&#39; to run.pl (but be careful and run # commands one by one: most recipes will exhaust the memory on your # machine). queue.pl works with GridEngine (qsub). slurm.pl works # with slurm. Different queues are configured differently, with different # queue names and different ways of specifying things like memory; # to account for these differences you can create and edit the file # conf/queue.conf to match your queue&#39;s configuration. Search for # conf/queue.conf in http://kaldi-asr.org/doc/queue.html for more information, # or search for the string &#39;default_config&#39; in utils/queue.pl or utils/slurm.pl. export train_cmd=queue.pl export decode_cmd=&#34;queue.pl --mem 2G&#34; # the use of cuda_cmd is deprecated, used only in &#39;nnet1&#39;, export cuda_cmd=&#34;queue.pl --gpu 1&#34; if [ &#34;$(hostname -d)&#34; == &#34;fit.vutbr.cz&#34; ]; then queue_conf=$HOME/queue_conf/default.conf # see example /homes/kazi/iveselyk/queue_conf/default.conf, export train_cmd=&#34;queue.pl --config $queue_conf --mem 2G --matylda 0.2&#34; export decode_cmd=&#34;queue.pl --config $queue_conf --mem 3G --matylda 0.1&#34; export cuda_cmd=&#34;queue.pl --config $queue_conf --gpu 1 --mem 10G --tmp 40G&#34; fi . %env train_cmd=run.pl %env decode_cmd=run.pl . env: train_cmd=run.pl env: decode_cmd=run.pl . !ln -s ../../wsj/s5/cmd.sh !ln -s ../../wsj/s5/path.sh !ln -s utils/queue.pl !ln -s utils/run.pl . !rm *.pl . Data prep . !local/data_prep.sh /kaggle/input/librispeech-test-clean-and-other/LibriSpeech/test-other data/test-other !local/data_prep.sh /kaggle/input/librispeech-test-clean-and-other/LibriSpeech/test-clean data/test-clean . utils/validate_data_dir.sh: Successfully validated data-directory data/test-other local/data_prep.sh: successfully prepared data in data/test-other utils/validate_data_dir.sh: Successfully validated data-directory data/test-clean local/data_prep.sh: successfully prepared data in data/test-clean . !utils/copy_data_dir.sh data/test-clean data/test-clean_hires !utils/copy_data_dir.sh data/test-other data/test-other_hires . utils/copy_data_dir.sh: copied data from data/test-clean to data/test-clean_hires utils/validate_data_dir.sh: Successfully validated data-directory data/test-clean_hires utils/copy_data_dir.sh: copied data from data/test-other to data/test-other_hires utils/validate_data_dir.sh: Successfully validated data-directory data/test-other_hires . !ln -s utils/parse_options.sh . !steps/make_mfcc.sh --nj 20 --mfcc-config conf/mfcc_hires.conf --cmd &quot;$train_cmd&quot; data/test-clean_hires !steps/compute_cmvn_stats.sh data/test-clean_hires !utils/fix_data_dir.sh data/test-clean_hires !steps/make_mfcc.sh --nj 20 --mfcc-config conf/mfcc_hires.conf --cmd &quot;$train_cmd&quot; data/test-other_hires !steps/compute_cmvn_stats.sh data/test-other_hires !utils/fix_data_dir.sh data/test-other_hires . steps/make_mfcc.sh --nj 20 --mfcc-config conf/mfcc_hires.conf --cmd run.pl data/test-clean_hires utils/validate_data_dir.sh: Successfully validated data-directory data/test-clean_hires steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance. steps/make_mfcc.sh: Succeeded creating MFCC features for test-clean_hires steps/compute_cmvn_stats.sh data/test-clean_hires Succeeded creating CMVN stats for test-clean_hires fix_data_dir.sh: kept all 2620 utterances. fix_data_dir.sh: old files are kept in data/test-clean_hires/.backup steps/make_mfcc.sh --nj 20 --mfcc-config conf/mfcc_hires.conf --cmd run.pl data/test-other_hires utils/validate_data_dir.sh: Successfully validated data-directory data/test-other_hires steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance. steps/make_mfcc.sh: Succeeded creating MFCC features for test-other_hires steps/compute_cmvn_stats.sh data/test-other_hires Succeeded creating CMVN stats for test-other_hires fix_data_dir.sh: kept all 2939 utterances. fix_data_dir.sh: old files are kept in data/test-other_hires/.backup . Extract i-vectors . !ln -s /kaggle/input/kaldi-librispeech-model/exp/nnet3_cleaned/ exp/nnet3_cleaned !ln -s /kaggle/input/kaldi-librispeech-model/exp/chain_cleaned/ exp/chain_cleaned . %env nspk=$(wc -l &lt;data/test-clean_hires/spk2utt) !steps/online/nnet2/extract_ivectors_online.sh --cmd &quot;$train_cmd&quot; --nj &quot;${nspk}&quot; data/test-clean_hires exp/nnet3_cleaned/extractor exp/nnet3_cleaned_out/ivectors_test-clean_hires %env nspk=$(wc -l &lt;data/test-other_hires/spk2utt) !steps/online/nnet2/extract_ivectors_online.sh --cmd &quot;$train_cmd&quot; --nj &quot;${nspk}&quot; data/test-other_hires exp/nnet3_cleaned/extractor exp/nnet3_cleaned_out/ivectors_test-other_hires . env: nspk=$(wc -l &lt;data/test-clean_hires/spk2utt) steps/online/nnet2/extract_ivectors_online.sh --cmd run.pl --nj $(wc -l &lt;data/test-clean_hires/spk2utt) data/test-clean_hires exp/nnet3_cleaned/extractor exp/nnet3_cleaned_out/ivectors_test-clean_hires steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to exp/nnet3_cleaned_out/ivectors_test-clean_hires using the extractor in exp/nnet3_cleaned/extractor. env: nspk=$(wc -l &lt;data/test-other_hires/spk2utt) steps/online/nnet2/extract_ivectors_online.sh --cmd run.pl --nj $(wc -l &lt;data/test-other_hires/spk2utt) data/test-other_hires exp/nnet3_cleaned/extractor exp/nnet3_cleaned_out/ivectors_test-other_hires steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to exp/nnet3_cleaned_out/ivectors_test-other_hires using the extractor in exp/nnet3_cleaned/extractor. . Build decoding graph . Just linking this directory won&#39;t work, as it expects to be able to write to it (Kaldi scripts, smh) . !cp -r /kaggle/input/kaldi-librispeech-model/data/lang_test_tgsmall data . %env tdnndir=exp/chain_cleaned/tdnn_1d_sp %env graph_dir=exp/chain_cleaned_out/graph_tgsmall !utils/mkgraph.sh --self-loop-scale 1.0 --remove-oov data/lang_test_tgsmall $tdnndir $graph_dir . env: tdnndir=exp/chain_cleaned/tdnn_1d_sp env: graph_dir=exp/chain_cleaned_out/graph_tgsmall tree-info exp/chain_cleaned/tdnn_1d_sp/tree tree-info exp/chain_cleaned/tdnn_1d_sp/tree fstpushspecial fstdeterminizestar --use-log=true fstminimizeencoded fsttablecompose data/lang_test_tgsmall/L_disambig.fst data/lang_test_tgsmall/G.fst fstisstochastic data/lang_test_tgsmall/tmp/LG.fst -0.0459745 -0.0466771 [info]: LG not stochastic. fstcomposecontext --context-size=2 --central-position=1 --read-disambig-syms=data/lang_test_tgsmall/phones/disambig.int --write-disambig-syms=data/lang_test_tgsmall/tmp/disambig_ilabels_2_1.int data/lang_test_tgsmall/tmp/ilabels_2_1.113735 data/lang_test_tgsmall/tmp/LG.fst fstisstochastic data/lang_test_tgsmall/tmp/CLG_2_1.fst -0.0459745 -0.0466771 [info]: CLG not stochastic. make-h-transducer --disambig-syms-out=exp/chain_cleaned_out/graph_tgsmall/disambig_tid.int --transition-scale=1.0 data/lang_test_tgsmall/tmp/ilabels_2_1 exp/chain_cleaned/tdnn_1d_sp/tree exp/chain_cleaned/tdnn_1d_sp/final.mdl fstdeterminizestar --use-log=true fsttablecompose exp/chain_cleaned_out/graph_tgsmall/Ha.fst &#39;fstrmsymbols --remove-arcs=true --apply-to-output=true data/lang_test_tgsmall/oov.int data/lang_test_tgsmall/tmp/CLG_2_1.fst|&#39; fstminimizeencoded fstrmsymbols exp/chain_cleaned_out/graph_tgsmall/disambig_tid.int fstrmepslocal fstrmsymbols --remove-arcs=true --apply-to-output=true data/lang_test_tgsmall/oov.int data/lang_test_tgsmall/tmp/CLG_2_1.fst fstisstochastic exp/chain_cleaned_out/graph_tgsmall/HCLGa.fst 3.39453 -0.209239 HCLGa is not stochastic add-self-loops --self-loop-scale=1.0 --reorder=true exp/chain_cleaned/tdnn_1d_sp/final.mdl exp/chain_cleaned_out/graph_tgsmall/HCLGa.fst fstisstochastic exp/chain_cleaned_out/graph_tgsmall/HCLG.fst 3.05078 -0.127788 [info]: final HCLG is not stochastic. . Decode . !mkdir exp/tdnn_1d_sp %pushd exp/tdnn_1d_sp !for i in /kaggle/input/kaldi-librispeech-model/exp/chain_cleaned/tdnn_1d_sp/*;do ln -s $i;done %popd . /kaggle/working/exp/tdnn_1d_sp /opt/kaldi/egs/usels/s5 popd -&gt; /opt/kaldi/egs/usels/s5 . %env tdnndir=exp/tdnn_1d_sp !steps/nnet3/decode.sh --acwt 1.0 --post-decode-acwt 10.0 --nj 8 --cmd &quot;$decode_cmd&quot; --online-ivector-dir exp/nnet3_cleaned_out/ivectors_test-clean_hires $graph_dir data/test-clean_hires $tdnndir/decode_test-clean_tgsmall !steps/nnet3/decode.sh --acwt 1.0 --post-decode-acwt 10.0 --nj 8 --cmd &quot;$decode_cmd&quot; --online-ivector-dir exp/nnet3_cleaned_out/ivectors_test-other_hires $graph_dir data/test-other_hires $tdnndir/decode_test-other_tgsmall . env: tdnndir=exp/tdnn_1d_sp steps/nnet3/decode.sh --acwt 1.0 --post-decode-acwt 10.0 --nj 8 --cmd run.pl --online-ivector-dir exp/nnet3_cleaned_out/ivectors_test-clean_hires exp/chain_cleaned_out/graph_tgsmall data/test-clean_hires exp/tdnn_1d_sp/decode_test-clean_tgsmall steps/nnet3/decode.sh: feature type is raw steps/diagnostic/analyze_lats.sh --cmd run.pl --iter final exp/chain_cleaned_out/graph_tgsmall exp/tdnn_1d_sp/decode_test-clean_tgsmall steps/diagnostic/analyze_lats.sh: see stats in exp/tdnn_1d_sp/decode_test-clean_tgsmall/log/analyze_alignments.log Overall, lattice depth (10,50,90-percentile)=(1,2,5) and mean=2.8 steps/diagnostic/analyze_lats.sh: see stats in exp/tdnn_1d_sp/decode_test-clean_tgsmall/log/analyze_lattice_depth_stats.log score best paths score confidence and timing with sclite Decoding done. steps/nnet3/decode.sh --acwt 1.0 --post-decode-acwt 10.0 --nj 8 --cmd run.pl --online-ivector-dir exp/nnet3_cleaned_out/ivectors_test-other_hires exp/chain_cleaned_out/graph_tgsmall data/test-other_hires exp/tdnn_1d_sp/decode_test-other_tgsmall steps/nnet3/decode.sh: feature type is raw steps/diagnostic/analyze_lats.sh --cmd run.pl --iter final exp/chain_cleaned_out/graph_tgsmall exp/tdnn_1d_sp/decode_test-other_tgsmall steps/diagnostic/analyze_lats.sh: see stats in exp/tdnn_1d_sp/decode_test-other_tgsmall/log/analyze_alignments.log Overall, lattice depth (10,50,90-percentile)=(1,3,13) and mean=6.3 steps/diagnostic/analyze_lats.sh: see stats in exp/tdnn_1d_sp/decode_test-other_tgsmall/log/analyze_lattice_depth_stats.log score best paths score confidence and timing with sclite Decoding done. . Score . !steps/score_kaldi.sh --cmd &quot;run.pl&quot; data/test-clean_hires $graph_dir $tdnndir/decode_test-clean_tgsmall !steps/score_kaldi.sh --cmd &quot;run.pl&quot; data/test-other_hires $graph_dir $tdnndir/decode_test-other_tgsmall . steps/score_kaldi.sh --cmd run.pl data/test-clean_hires exp/chain_cleaned_out/graph_tgsmall exp/tdnn_1d_sp/decode_test-clean_tgsmall steps/score_kaldi.sh: scoring with word insertion penalty=0.0,0.5,1.0 steps/score_kaldi.sh --cmd run.pl data/test-other_hires exp/chain_cleaned_out/graph_tgsmall exp/tdnn_1d_sp/decode_test-other_tgsmall steps/score_kaldi.sh: scoring with word insertion penalty=0.0,0.5,1.0 . !cat exp/tdnn_1d_sp/decode_test-clean_tgsmall/scoring_kaldi/best_wer !cat exp/tdnn_1d_sp/decode_test-other_tgsmall/scoring_kaldi/best_wer . %WER 7.13 [ 3747 / 52576, 648 ins, 242 del, 2857 sub ] exp/tdnn_1d_sp/decode_test-clean_tgsmall/wer_17_0.5 %WER 17.92 [ 9378 / 52343, 1384 ins, 723 del, 7271 sub ] exp/tdnn_1d_sp/decode_test-other_tgsmall/wer_17_1.0 . Rescoring . !cp -r /kaggle/input/kaldi-librispeech-model/exp/rnnlm_lstm_1a/ exp . !ln -s /opt/kaldi/scripts/rnnlm . %env decode_dir=exp/tdnn_1d_sp/decode_test-clean_tgsmall !rnnlm/lmrescore_pruned.sh --cmd &quot;$decode_cmd&quot; --weight 0.45 --max-ngram-order 4 data/lang_test_tgsmall exp/rnnlm_lstm_1a data/test-clean_hires ${decode_dir} $tdnndir/decode_test-clean_rescore %env decode_dir=exp/tdnn_1d_sp/decode_test-other_tgsmall !rnnlm/lmrescore_pruned.sh --cmd &quot;$decode_cmd&quot; --weight 0.45 --max-ngram-order 4 data/lang_test_tgsmall exp/rnnlm_lstm_1a data/test-other_hires ${decode_dir} $tdnndir/decode_test-other_rescore . env: decode_dir=exp/tdnn_1d_sp/decode_test-clean_tgsmall rnnlm/lmrescore_pruned.sh --cmd run.pl --weight 0.45 --max-ngram-order 4 data/lang_test_tgsmall exp/rnnlm_lstm_1a data/test-clean_hires exp/tdnn_1d_sp/decode_test-clean_tgsmall exp/tdnn_1d_sp/decode_test-clean_rescore local/score.sh --cmd run.pl data/test-clean_hires data/lang_test_tgsmall exp/tdnn_1d_sp/decode_test-clean_rescore env: decode_dir=exp/tdnn_1d_sp/decode_test-other_tgsmall rnnlm/lmrescore_pruned.sh --cmd run.pl --weight 0.45 --max-ngram-order 4 data/lang_test_tgsmall exp/rnnlm_lstm_1a data/test-other_hires exp/tdnn_1d_sp/decode_test-other_tgsmall exp/tdnn_1d_sp/decode_test-other_rescore local/score.sh --cmd run.pl data/test-other_hires data/lang_test_tgsmall exp/tdnn_1d_sp/decode_test-other_rescore . !steps/score_kaldi.sh --cmd &quot;run.pl&quot; data/test-clean_hires $graph_dir $tdnndir/decode_test-clean_rescore !steps/score_kaldi.sh --cmd &quot;run.pl&quot; data/test-other_hires $graph_dir $tdnndir/decode_test-other_rescore . steps/score_kaldi.sh --cmd run.pl data/test-clean_hires exp/chain_cleaned_out/graph_tgsmall exp/tdnn_1d_sp/decode_test-clean_rescore steps/score_kaldi.sh: scoring with word insertion penalty=0.0,0.5,1.0 steps/score_kaldi.sh --cmd run.pl data/test-other_hires exp/chain_cleaned_out/graph_tgsmall exp/tdnn_1d_sp/decode_test-other_rescore steps/score_kaldi.sh: scoring with word insertion penalty=0.0,0.5,1.0 . !cat $tdnndir/decode_test-clean_rescore/scoring_kaldi/best_wer !cat $tdnndir/decode_test-other_rescore/scoring_kaldi/best_wer . %WER 5.85 [ 3078 / 52576, 617 ins, 198 del, 2263 sub ] exp/tdnn_1d_sp/decode_test-clean_rescore/wer_17_0.5 %WER 15.98 [ 8362 / 52343, 1381 ins, 588 del, 6393 sub ] exp/tdnn_1d_sp/decode_test-other_rescore/wer_17_1.0 . .",
            "url": "https://jimregan.github.io/notes/asr/kaldi/kaggle/2021/06/22/run-kaldi-on-librispeech-test.html",
            "relUrl": "/asr/kaldi/kaggle/2021/06/22/run-kaldi-on-librispeech-test.html",
            "date": " ‚Ä¢ Jun 22, 2021"
        }
        
    
  
    
        ,"post56": {
            "title": "Kaldi LibriSpeech model on Kaggle",
            "content": "Setting up the LibriSpeech Kaldi model on Kaggle: see here . %%capture !wget http://kaldi-asr.org/models/13/0013_librispeech_v1_chain.tar.gz !wget http://kaldi-asr.org/models/13/0013_librispeech_v1_extractor.tar.gz !wget http://kaldi-asr.org/models/13/0013_librispeech_v1_lm.tar.gz . %%capture !for i in *.tar.gz;do tar zxvf $i;done . !find . -type l !find . -type l -exec ls -al {} ; . ./exp/chain_cleaned/tdnn_1d_sp/configs/lda.mat ./exp/nnet3_cleaned/extractor/final.ie lrwxrwxrwx 1 61208 fax 10 Feb 2 2020 ./exp/chain_cleaned/tdnn_1d_sp/configs/lda.mat -&gt; ../lda.mat lrwxrwxrwx 1 61208 fax 5 Feb 2 2020 ./exp/nnet3_cleaned/extractor/final.ie -&gt; 10.ie . !rm exp/chain_cleaned/tdnn_1d_sp/configs/lda.mat !rm exp/nnet3_cleaned/extractor/final.ie !cp exp/chain_cleaned/tdnn_1d_sp/lda.mat exp/chain_cleaned/tdnn_1d_sp/configs/lda.mat !cp exp/nnet3_cleaned/extractor/10.ie exp/nnet3_cleaned/extractor/final.ie .",
            "url": "https://jimregan.github.io/notes/kaggle/kaldi/librispeech/2021/06/21/kaldi-librispeech-model.html",
            "relUrl": "/kaggle/kaldi/librispeech/2021/06/21/kaldi-librispeech-model.html",
            "date": " ‚Ä¢ Jun 21, 2021"
        }
        
    
  
    
        ,"post57": {
            "title": "wav2vec-u CV-sv - w2vu_generate",
            "content": "This is based on this. The main difference is the script that&#39;s being run, and setting up flashlight&#39;s python bindings . I already had the GAN model in gdrive; those files are available here. . Preparation . !pip install condacolab . Collecting condacolab Using cached condacolab-0.1.2-py3-none-any.whl (6.0 kB) Installing collected packages: condacolab Successfully installed condacolab-0.1.2 . import condacolab condacolab.install() . ‚ú®üç∞‚ú® Everything looks OK! . %%capture !conda install -c pykaldi pykaldi -y . !git clone https://github.com/pytorch/fairseq/ . fatal: destination path &#39;fairseq&#39; already exists and is not an empty directory. . !git clone https://github.com/kpu/kenlm . fatal: destination path &#39;kenlm&#39; already exists and is not an empty directory. . %%capture !apt-get -y install libeigen3-dev liblzma-dev zlib1g-dev libbz2-dev . The python build doesn&#39;t build utils, so this is (probably) necessary . %cd /content/kenlm !mkdir build %cd build !cmake .. !make -j 4 . %%capture %cd /content/kenlm !python setup.py install %cd /tmp . import os os.environ[&#39;PATH&#39;] = f&quot;{os.environ[&#39;PATH&#39;]}:/content/kenlm/build/bin/&quot; os.environ[&#39;FAIRSEQ_ROOT&#39;] = &#39;/content/fairseq&#39; . %cd /content/fairseq/ . /content/fairseq . For next cell, see here . %%capture !pip install --editable ./ !python setup.py build develop . os.environ[&#39;HYDRA_FULL_ERROR&#39;] = &#39;1&#39; . %%capture !pip install editdistance . https://colab.research.google.com/github/corrieann/kaggle/blob/master/kaggle_api_in_colab.ipynb . %%capture !pip install kaggle . from google.colab import files uploaded = files.upload() for fn in uploaded.keys(): print(&#39;User uploaded file &quot;{name}&quot; with length {length} bytes&#39;.format( name=fn, length=len(uploaded[fn]))) # Then move kaggle.json into the folder where the API expects to find it. !mkdir -p ~/.kaggle/ &amp;&amp; mv kaggle.json ~/.kaggle/ &amp;&amp; chmod 600 ~/.kaggle/kaggle.json . Upload widget is only available when the cell has been executed in the current browser session. Please rerun this cell to enable. Saving kaggle.json to kaggle.json User uploaded file &#34;kaggle.json&#34; with length 64 bytes . %cd /content . /content . !kaggle datasets download &quot;jimregan/w2vu-cvsv-audio-processed&quot; . Downloading w2vu-cvsv-audio-processed.zip to /content 100% 4.31G/4.31G [01:24&lt;00:00, 102MB/s] 100% 4.31G/4.31G [01:24&lt;00:00, 54.7MB/s] . %%capture !unzip /content/w2vu-cvsv-audio-processed.zip . !kaggle datasets download -d jimregan/w2vu-cvsv-prepared-text . Downloading w2vu-cvsv-prepared-text.zip to /content 80% 14.0M/17.4M [00:00&lt;00:00, 33.7MB/s] 100% 17.4M/17.4M [00:00&lt;00:00, 44.2MB/s] . %%capture !unzip w2vu-cvsv-prepared-text.zip . !rm *.zip . !cp /content/preppedtext/phones/dict* /content/precompute_pca512_cls128_mean . %cd /content . /content . !git clone https://github.com/flashlight/flashlight . Cloning into &#39;flashlight&#39;... remote: Enumerating objects: 17649, done. remote: Counting objects: 100% (1523/1523), done. remote: Compressing objects: 100% (718/718), done. remote: Total 17649 (delta 827), reused 1336 (delta 761), pack-reused 16126 Receiving objects: 100% (17649/17649), 14.23 MiB | 24.82 MiB/s, done. Resolving deltas: 100% (12298/12298), done. . %%capture !apt install -q libfftw3-dev . Reading package lists... Building dependency tree... Reading state information... libfftw3-dev is already the newest version (3.3.7-1). cmake is already the newest version (3.10.2-1ubuntu2.18.04.1). 0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded. . %cd flashlight/bindings/python . /content/flashlight/bindings/python . %%capture !pip install packaging . !USE_MKL=0 KENLM_ROOT=/content/kenlm python setup.py install . w2vu-generate . import torch torch.version.cuda . &#39;10.2&#39; . torch.backends.cudnn.version() . 7605 . %cd /content/fairseq . /content/fairseq . from google.colab import drive drive.mount(&#39;/content/drive&#39;) . Mounted at /content/drive . %cd /content/fairseq/examples/wav2vec/unsupervised . /content/fairseq/examples/wav2vec/unsupervised . %%writefile rungan.sh python w2vu_generate.py --config-dir config/generate --config-name viterbi fairseq.common.user_dir=/content/fairseq/examples/wav2vec/unsupervised fairseq.task.data=/content/precompute_pca512_cls128_mean fairseq.common_eval.path=/content/drive/MyDrive/w2vu/checkpoint_best.pt fairseq.dataset.gen_subset=valid results_path=/content/drive/MyDrive/w2vures . Overwriting rungan.sh . !bash rungan.sh . [2021-06-19 19:24:18,601][__main__][INFO] - {&#39;_name&#39;: None, &#39;fairseq&#39;: {&#39;_name&#39;: None, &#39;common&#39;: {&#39;_name&#39;: None, &#39;no_progress_bar&#39;: False, &#39;log_interval&#39;: 100, &#39;log_format&#39;: None, &#39;log_file&#39;: None, &#39;tensorboard_logdir&#39;: None, &#39;wandb_project&#39;: None, &#39;azureml_logging&#39;: False, &#39;seed&#39;: 1, &#39;cpu&#39;: False, &#39;tpu&#39;: False, &#39;bf16&#39;: False, &#39;memory_efficient_bf16&#39;: False, &#39;fp16&#39;: False, &#39;memory_efficient_fp16&#39;: False, &#39;fp16_no_flatten_grads&#39;: False, &#39;fp16_init_scale&#39;: 128, &#39;fp16_scale_window&#39;: None, &#39;fp16_scale_tolerance&#39;: 0.0, &#39;on_cpu_convert_precision&#39;: False, &#39;min_loss_scale&#39;: 0.0001, &#39;threshold_loss_scale&#39;: None, &#39;amp&#39;: False, &#39;amp_batch_retries&#39;: 2, &#39;amp_init_scale&#39;: 128, &#39;amp_scale_window&#39;: None, &#39;user_dir&#39;: &#39;/content/fairseq/examples/wav2vec/unsupervised&#39;, &#39;empty_cache_freq&#39;: 0, &#39;all_gather_list_size&#39;: 16384, &#39;model_parallel_size&#39;: 1, &#39;quantization_config_path&#39;: None, &#39;profile&#39;: False, &#39;reset_logging&#39;: False, &#39;suppress_crashes&#39;: False, &#39;use_plasma_view&#39;: False, &#39;plasma_path&#39;: &#39;/tmp/plasma&#39;}, &#39;common_eval&#39;: {&#39;_name&#39;: None, &#39;path&#39;: &#39;/content/drive/MyDrive/w2vu/checkpoint_best.pt&#39;, &#39;post_process&#39;: None, &#39;quiet&#39;: True, &#39;model_overrides&#39;: &#39;{}&#39;, &#39;results_path&#39;: None}, &#39;distributed_training&#39;: {&#39;_name&#39;: None, &#39;distributed_world_size&#39;: 1, &#39;distributed_num_procs&#39;: 1, &#39;distributed_rank&#39;: 0, &#39;distributed_backend&#39;: &#39;nccl&#39;, &#39;distributed_init_method&#39;: None, &#39;distributed_port&#39;: -1, &#39;device_id&#39;: 0, &#39;distributed_no_spawn&#39;: False, &#39;ddp_backend&#39;: pytorch_ddp, &#39;ddp_comm_hook&#39;: none, &#39;bucket_cap_mb&#39;: 25, &#39;fix_batches_to_gpus&#39;: False, &#39;find_unused_parameters&#39;: False, &#39;fast_stat_sync&#39;: False, &#39;heartbeat_timeout&#39;: -1, &#39;broadcast_buffers&#39;: False, &#39;slowmo_momentum&#39;: None, &#39;slowmo_algorithm&#39;: &#39;LocalSGD&#39;, &#39;localsgd_frequency&#39;: 3, &#39;nprocs_per_node&#39;: 1, &#39;pipeline_model_parallel&#39;: False, &#39;pipeline_balance&#39;: None, &#39;pipeline_devices&#39;: None, &#39;pipeline_chunks&#39;: 0, &#39;pipeline_encoder_balance&#39;: None, &#39;pipeline_encoder_devices&#39;: None, &#39;pipeline_decoder_balance&#39;: None, &#39;pipeline_decoder_devices&#39;: None, &#39;pipeline_checkpoint&#39;: never, &#39;zero_sharding&#39;: none, &#39;fp16&#39;: &#39;${common.fp16}&#39;, &#39;memory_efficient_fp16&#39;: &#39;${common.memory_efficient_fp16}&#39;, &#39;tpu&#39;: &#39;${common.tpu}&#39;, &#39;no_reshard_after_forward&#39;: False, &#39;fp32_reduce_scatter&#39;: False, &#39;cpu_offload&#39;: False, &#39;use_sharded_state&#39;: False}, &#39;dataset&#39;: {&#39;_name&#39;: None, &#39;num_workers&#39;: 1, &#39;skip_invalid_size_inputs_valid_test&#39;: False, &#39;max_tokens&#39;: None, &#39;batch_size&#39;: 1, &#39;required_batch_size_multiple&#39;: 8, &#39;required_seq_len_multiple&#39;: 1, &#39;dataset_impl&#39;: None, &#39;data_buffer_size&#39;: 10, &#39;train_subset&#39;: &#39;train&#39;, &#39;valid_subset&#39;: &#39;valid&#39;, &#39;combine_valid_subsets&#39;: None, &#39;ignore_unused_valid_subsets&#39;: False, &#39;validate_interval&#39;: 1, &#39;validate_interval_updates&#39;: 0, &#39;validate_after_updates&#39;: 0, &#39;fixed_validation_seed&#39;: None, &#39;disable_validation&#39;: False, &#39;max_tokens_valid&#39;: &#39;${dataset.max_tokens}&#39;, &#39;batch_size_valid&#39;: &#39;${dataset.batch_size}&#39;, &#39;max_valid_steps&#39;: None, &#39;curriculum&#39;: 0, &#39;gen_subset&#39;: &#39;valid&#39;, &#39;num_shards&#39;: 1, &#39;shard_id&#39;: 0}, &#39;optimization&#39;: {&#39;_name&#39;: None, &#39;max_epoch&#39;: 0, &#39;max_update&#39;: 0, &#39;stop_time_hours&#39;: 0.0, &#39;clip_norm&#39;: 0.0, &#39;sentence_avg&#39;: False, &#39;update_freq&#39;: [1], &#39;lr&#39;: [0.25], &#39;stop_min_lr&#39;: -1.0, &#39;use_bmuf&#39;: False}, &#39;checkpoint&#39;: {&#39;_name&#39;: None, &#39;save_dir&#39;: &#39;checkpoints&#39;, &#39;restore_file&#39;: &#39;checkpoint_last.pt&#39;, &#39;finetune_from_model&#39;: None, &#39;reset_dataloader&#39;: False, &#39;reset_lr_scheduler&#39;: False, &#39;reset_meters&#39;: False, &#39;reset_optimizer&#39;: False, &#39;optimizer_overrides&#39;: &#39;{}&#39;, &#39;save_interval&#39;: 1, &#39;save_interval_updates&#39;: 0, &#39;keep_interval_updates&#39;: -1, &#39;keep_interval_updates_pattern&#39;: -1, &#39;keep_last_epochs&#39;: -1, &#39;keep_best_checkpoints&#39;: -1, &#39;no_save&#39;: False, &#39;no_epoch_checkpoints&#39;: False, &#39;no_last_checkpoints&#39;: False, &#39;no_save_optimizer_state&#39;: False, &#39;best_checkpoint_metric&#39;: &#39;loss&#39;, &#39;maximize_best_checkpoint_metric&#39;: False, &#39;patience&#39;: -1, &#39;checkpoint_suffix&#39;: &#39;&#39;, &#39;checkpoint_shard_count&#39;: 1, &#39;load_checkpoint_on_all_dp_ranks&#39;: False, &#39;write_checkpoints_asynchronously&#39;: False, &#39;model_parallel_size&#39;: &#39;${common.model_parallel_size}&#39;}, &#39;bmuf&#39;: {&#39;_name&#39;: None, &#39;block_lr&#39;: 1.0, &#39;block_momentum&#39;: 0.875, &#39;global_sync_iter&#39;: 50, &#39;warmup_iterations&#39;: 500, &#39;use_nbm&#39;: False, &#39;average_sync&#39;: False, &#39;distributed_world_size&#39;: &#39;${distributed_training.distributed_world_size}&#39;}, &#39;generation&#39;: {&#39;_name&#39;: None, &#39;beam&#39;: 5, &#39;nbest&#39;: 1, &#39;max_len_a&#39;: 0.0, &#39;max_len_b&#39;: 200, &#39;min_len&#39;: 1, &#39;match_source_len&#39;: False, &#39;unnormalized&#39;: False, &#39;no_early_stop&#39;: False, &#39;no_beamable_mm&#39;: False, &#39;lenpen&#39;: 1.0, &#39;unkpen&#39;: 0.0, &#39;replace_unk&#39;: None, &#39;sacrebleu&#39;: False, &#39;score_reference&#39;: False, &#39;prefix_size&#39;: 0, &#39;no_repeat_ngram_size&#39;: 0, &#39;sampling&#39;: False, &#39;sampling_topk&#39;: -1, &#39;sampling_topp&#39;: -1.0, &#39;constraints&#39;: None, &#39;temperature&#39;: 1.0, &#39;diverse_beam_groups&#39;: -1, &#39;diverse_beam_strength&#39;: 0.5, &#39;diversity_rate&#39;: -1.0, &#39;print_alignment&#39;: None, &#39;print_step&#39;: False, &#39;lm_path&#39;: None, &#39;lm_weight&#39;: 0.0, &#39;iter_decode_eos_penalty&#39;: 0.0, &#39;iter_decode_max_iter&#39;: 10, &#39;iter_decode_force_max_iter&#39;: False, &#39;iter_decode_with_beam&#39;: 1, &#39;iter_decode_with_external_reranker&#39;: False, &#39;retain_iter_history&#39;: False, &#39;retain_dropout&#39;: False, &#39;retain_dropout_modules&#39;: None, &#39;decoding_format&#39;: None, &#39;no_seed_provided&#39;: False}, &#39;eval_lm&#39;: {&#39;_name&#39;: None, &#39;output_word_probs&#39;: False, &#39;output_word_stats&#39;: False, &#39;context_window&#39;: 0, &#39;softmax_batch&#39;: 9223372036854775807}, &#39;interactive&#39;: {&#39;_name&#39;: None, &#39;buffer_size&#39;: 0, &#39;input&#39;: &#39;-&#39;}, &#39;model&#39;: &#39;???&#39;, &#39;task&#39;: {&#39;_name&#39;: &#39;unpaired_audio_text&#39;, &#39;labels&#39;: &#39;phn&#39;, &#39;data&#39;: &#39;/content/precompute_pca512_cls128_mean&#39;, &#39;sort_by_length&#39;: False, &#39;shuffle&#39;: False, &#39;text_data&#39;: &#39;&#39;}, &#39;criterion&#39;: None, &#39;optimizer&#39;: None, &#39;lr_scheduler&#39;: None, &#39;scoring&#39;: None, &#39;bpe&#39;: None, &#39;tokenizer&#39;: None}, &#39;lm_weight&#39;: 2.0, &#39;w2l_decoder&#39;: &lt;DecoderType.VITERBI: 1&gt;, &#39;kaldi_decoder_config&#39;: None, &#39;lexicon&#39;: None, &#39;lm_model&#39;: None, &#39;unit_lm&#39;: False, &#39;beam_threshold&#39;: 50.0, &#39;beam_size_token&#39;: 100.0, &#39;beam&#39;: 5, &#39;nbest&#39;: 1, &#39;word_score&#39;: 1.0, &#39;unk_weight&#39;: -inf, &#39;sil_weight&#39;: 0.0, &#39;targets&#39;: None, &#39;results_path&#39;: &#39;/content/drive/MyDrive/w2vures&#39;, &#39;post_process&#39;: &#39;silence&#39;, &#39;vocab_usage_power&#39;: 2.0, &#39;viterbi_transcript&#39;: None, &#39;min_lm_ppl&#39;: 0.0, &#39;min_vt_uer&#39;: 0.0, &#39;blank_weight&#39;: 0.0, &#39;blank_mode&#39;: &#39;set&#39;, &#39;sil_is_blank&#39;: False, &#39;unsupervised_tuning&#39;: False, &#39;is_ax&#39;: False, &#39;job_logging_cfg&#39;: {&#39;version&#39;: 1, &#39;formatters&#39;: {&#39;simple&#39;: {&#39;format&#39;: &#39;[%(asctime)s][%(name)s][%(levelname)s] - %(message)s&#39;}}, &#39;handlers&#39;: {&#39;console&#39;: {&#39;class&#39;: &#39;logging.StreamHandler&#39;, &#39;formatter&#39;: &#39;simple&#39;, &#39;stream&#39;: &#39;ext://sys.stdout&#39;}, &#39;file&#39;: {&#39;class&#39;: &#39;logging.FileHandler&#39;, &#39;formatter&#39;: &#39;simple&#39;, &#39;filename&#39;: &#39;w2vu_generate.log&#39;}}, &#39;root&#39;: {&#39;level&#39;: &#39;INFO&#39;, &#39;handlers&#39;: [&#39;console&#39;, &#39;file&#39;]}, &#39;disable_existing_loggers&#39;: False}} [2021-06-19 19:24:18,629][__main__][INFO] - | loading model(s) from /content/drive/MyDrive/w2vu/checkpoint_best.pt [2021-06-19 19:24:22,829][unsupervised.data.extracted_features_dataset][INFO] - loaded 2019, skipped 0 samples [2021-06-19 19:24:22,829][unsupervised.tasks.unpaired_audio_text][INFO] - split valid has unpaired text? False [2021-06-19 19:24:22,833][__main__][INFO] - | /content/precompute_pca512_cls128_mean valid 2019 examples [2021-06-19 19:24:41,807][__main__][INFO] - WER: 158.79173813943652 [2021-06-19 19:24:41,808][__main__][INFO] - | Processed 2019 sentences (80270 tokens) in 18.9s (106.61 sentences/s, 4238.35 tokens/s) [2021-06-19 19:24:41,809][__main__][INFO] - | Generate valid with beam=5, lm_weight=2.0, word_score=1.0, sil_weight=0.0, blank_weight=0.0, WER: 158.79173813943652, LM_PPL: inf, num feats: 130753, length: 80270, UER to viterbi: 0, score: inf .",
            "url": "https://jimregan.github.io/notes/colab/wav2vec-u/2021/06/19/wav2vec-u-cv-swedish-w2vu-generate.html",
            "relUrl": "/colab/wav2vec-u/2021/06/19/wav2vec-u-cv-swedish-w2vu-generate.html",
            "date": " ‚Ä¢ Jun 19, 2021"
        }
        
    
  
    
        ,"post58": {
            "title": "Download Swedish Literature Bank",
            "content": "[Original](https://www.kaggle.com/jimregan/download-swedish-literature-bank) . !wget http://spraakbanken.gu.se/lb/resurser/meningsmangder/lb.xml.bz2 . !wget https://svn.spraakdata.gu.se/sb-arkiv/pub/frekvens/stats_LB.txt .",
            "url": "https://jimregan.github.io/notes/kaggle/swedish/2021/06/18/download-swedish-literature-bank.html",
            "relUrl": "/kaggle/swedish/2021/06/18/download-swedish-literature-bank.html",
            "date": " ‚Ä¢ Jun 18, 2021"
        }
        
    
  
    
        ,"post59": {
            "title": "Diarisation with pyannote.audio",
            "content": "!pip install pyannote.audio==1.1 . !wget http://www.bealoideasbeo.ie/bealoideas/httpdocs/fuaim/iomlan/teip/010T0013.mp3 . !ffmpeg -i 010T0013.mp3 -acodec pcm_s16le -ac 1 -ar 16000 010T0013.wav . import pyannote.core . import torch import pyannote.core pipeline = torch.hub.load(&#39;pyannote/pyannote-audio&#39;, &#39;dia&#39;) diarization = pipeline({&#39;audio&#39;: &#39;010T0013.wav&#39;}) . json = pyannote.core.json.dumps(diarization) . with open(&#39;010T0013.json&#39;, &#39;w&#39;) as f: f.write(json) .",
            "url": "https://jimregan.github.io/notes/diarisation/pyannote/2021/06/17/diarisation-with-pyannote.html",
            "relUrl": "/diarisation/pyannote/2021/06/17/diarisation-with-pyannote.html",
            "date": " ‚Ä¢ Jun 17, 2021"
        }
        
    
  
    
        ,"post60": {
            "title": "Poleval 2021 through wav2vec2",
            "content": "%%capture !pip install gdown . !gdown https://drive.google.com/uc?id=1b6MyyqgA9D1U7DX3Vtgda7f9ppkxjCXJ . Downloading... From: https://drive.google.com/uc?id=1b6MyyqgA9D1U7DX3Vtgda7f9ppkxjCXJ To: /content/poleval_wav.train.tar.gz 2.14GB [00:38, 55.7MB/s] . %%capture !tar zxvf poleval_wav.train.tar.gz &amp;&amp; rm poleval_wav.train.tar.gz . %%capture !pip install librosa webrtcvad . # VAD wrapper is taken from PyTorch Speaker Verification: # https://github.com/HarryVolek/PyTorch_Speaker_Verification # Copyright (c) 2019, HarryVolek # License: BSD-3-Clause # based on https://github.com/wiseman/py-webrtcvad/blob/master/example.py # Copyright (c) 2016 John Wiseman # License: MIT import collections import contextlib import numpy as np import sys import librosa import wave import webrtcvad #from hparam import hparam as hp sr = 16000 def read_wave(path, sr): &quot;&quot;&quot;Reads a .wav file. Takes the path, and returns (PCM audio data, sample rate). Assumes sample width == 2 &quot;&quot;&quot; with contextlib.closing(wave.open(path, &#39;rb&#39;)) as wf: num_channels = wf.getnchannels() assert num_channels == 1 sample_width = wf.getsampwidth() assert sample_width == 2 sample_rate = wf.getframerate() assert sample_rate in (8000, 16000, 32000, 48000) pcm_data = wf.readframes(wf.getnframes()) data, _ = librosa.load(path, sr) assert len(data.shape) == 1 assert sr in (8000, 16000, 32000, 48000) return data, pcm_data class Frame(object): &quot;&quot;&quot;Represents a &quot;frame&quot; of audio data.&quot;&quot;&quot; def __init__(self, bytes, timestamp, duration): self.bytes = bytes self.timestamp = timestamp self.duration = duration def frame_generator(frame_duration_ms, audio, sample_rate): &quot;&quot;&quot;Generates audio frames from PCM audio data. Takes the desired frame duration in milliseconds, the PCM data, and the sample rate. Yields Frames of the requested duration. &quot;&quot;&quot; n = int(sample_rate * (frame_duration_ms / 1000.0) * 2) offset = 0 timestamp = 0.0 duration = (float(n) / sample_rate) / 2.0 while offset + n &lt; len(audio): yield Frame(audio[offset:offset + n], timestamp, duration) timestamp += duration offset += n def vad_collector(sample_rate, frame_duration_ms, padding_duration_ms, vad, frames): &quot;&quot;&quot;Filters out non-voiced audio frames. Given a webrtcvad.Vad and a source of audio frames, yields only the voiced audio. Uses a padded, sliding window algorithm over the audio frames. When more than 90% of the frames in the window are voiced (as reported by the VAD), the collector triggers and begins yielding audio frames. Then the collector waits until 90% of the frames in the window are unvoiced to detrigger. The window is padded at the front and back to provide a small amount of silence or the beginnings/endings of speech around the voiced frames. Arguments: sample_rate - The audio sample rate, in Hz. frame_duration_ms - The frame duration in milliseconds. padding_duration_ms - The amount to pad the window, in milliseconds. vad - An instance of webrtcvad.Vad. frames - a source of audio frames (sequence or generator). Returns: A generator that yields PCM audio data. &quot;&quot;&quot; num_padding_frames = int(padding_duration_ms / frame_duration_ms) # We use a deque for our sliding window/ring buffer. ring_buffer = collections.deque(maxlen=num_padding_frames) # We have two states: TRIGGERED and NOTTRIGGERED. We start in the # NOTTRIGGERED state. triggered = False voiced_frames = [] for frame in frames: is_speech = vad.is_speech(frame.bytes, sample_rate) if not triggered: ring_buffer.append((frame, is_speech)) num_voiced = len([f for f, speech in ring_buffer if speech]) # If we&#39;re NOTTRIGGERED and more than 90% of the frames in # the ring buffer are voiced frames, then enter the # TRIGGERED state. if num_voiced &gt; 0.9 * ring_buffer.maxlen: triggered = True start = ring_buffer[0][0].timestamp # We want to yield all the audio we see from now until # we are NOTTRIGGERED, but we have to start with the # audio that&#39;s already in the ring buffer. for f, s in ring_buffer: voiced_frames.append(f) ring_buffer.clear() else: # We&#39;re in the TRIGGERED state, so collect the audio data # and add it to the ring buffer. voiced_frames.append(frame) ring_buffer.append((frame, is_speech)) num_unvoiced = len([f for f, speech in ring_buffer if not speech]) # If more than 90% of the frames in the ring buffer are # unvoiced, then enter NOTTRIGGERED and yield whatever # audio we&#39;ve collected. if num_unvoiced &gt; 0.9 * ring_buffer.maxlen: triggered = False yield (start, frame.timestamp + frame.duration) ring_buffer.clear() voiced_frames = [] # If we have any leftover voiced audio when we run out of input, # yield it. if voiced_frames: yield (start, frame.timestamp + frame.duration) def VAD_chunk(aggressiveness, path): audio, byte_audio = read_wave(path, sr) vad = webrtcvad.Vad(int(aggressiveness)) frames = frame_generator(20, byte_audio, sr) frames = list(frames) times = vad_collector(sr, 20, 200, vad, frames) speech_times = [] speech_segs = [] for i, time in enumerate(times): start = np.round(time[0],decimals=2) end = np.round(time[1],decimals=2) j = start while j + .4 &lt; end: end_j = np.round(j+.4,decimals=2) speech_times.append((j, end_j)) speech_segs.append(audio[int(j*sr):int(end_j*sr)]) j = end_j else: speech_times.append((j, end)) speech_segs.append(audio[int(j*sr):int(end*sr)]) return speech_times, speech_segs . . # Based on code from PyTorch Speaker Verification: # https://github.com/HarryVolek/PyTorch_Speaker_Verification # Copyright (c) 2019, HarryVolek # Additions Copyright (c) 2021, Jim O&#39;Regan # License: MIT import numpy as np # wav2vec2&#39;s max duration is 40 seconds, using 39 by default # to be a little safer def vad_concat(times, segs, max_duration=39.0): &quot;&quot;&quot; Concatenate continuous times and their segments, where the end time of a segment is the same as the start time of the next Parameters: times: list of tuple (start, end) segs: list of segments (audio frames) max_duration: maximum duration of the resulting concatenated segments; the kernel size of wav2vec2 is 40 seconds, so the default max_duration is 39, to ensure the resulting list of segments will fit Returns: concat_times: list of tuple (start, end) concat_segs: list of segments (audio frames) &quot;&quot;&quot; absolute_maximum=40.0 if max_duration &gt; absolute_maximum: raise Exception(&#39;`max_duration` {:.2f} larger than kernel size (40 seconds)&#39;.format(max_duration)) # we take 0.0 to mean &quot;don&#39;t concatenate&quot; do_concat = (max_duration != 0.0) concat_seg = [] concat_times = [] seg_concat = segs[0] time_concat = times[0] for i in range(0, len(times)-1): can_concat = (times[i+1][1] - time_concat[0]) &lt; max_duration if time_concat[1] == times[i+1][0] and do_concat and can_concat: seg_concat = np.concatenate((seg_concat, segs[i+1])) time_concat = (time_concat[0], times[i+1][1]) else: concat_seg.append(seg_concat) seg_concat = segs[i+1] concat_times.append(time_concat) time_concat = times[i+1] else: concat_seg.append(seg_concat) concat_times.append(time_concat) return concat_times, concat_seg . . def make_dataset(concat_times, concat_segs): starts = [s[0] for s in concat_times] ends = [s[1] for s in concat_times] return {&#39;start&#39;: starts, &#39;end&#39;: ends, &#39;speech&#39;: concat_segs} . %%capture !pip install datasets . from datasets import Dataset def vad_to_dataset(path, max_duration): t,s = VAD_chunk(3, path) if max_duration &gt; 0.0: ct, cs = vad_concat(t, s, max_duration) dset = make_dataset(ct, cs) else: dset = make_dataset(t, s) return Dataset.from_dict(dset) . %%capture !pip install -q transformers . %%capture from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC # load model and tokenizer processor = Wav2Vec2Processor.from_pretrained(&quot;mbien/wav2vec2-large-xlsr-polish&quot;) model = Wav2Vec2ForCTC.from_pretrained(&quot;mbien/wav2vec2-large-xlsr-polish&quot;) model.to(&quot;cuda&quot;) . def speech_file_to_array_fn(batch): import torchaudio speech_array, sampling_rate = torchaudio.load(batch[&quot;path&quot;]) batch[&quot;speech&quot;] = speech_array[0].numpy() batch[&quot;sampling_rate&quot;] = sampling_rate batch[&quot;target_text&quot;] = batch[&quot;sentence&quot;] return batch def evaluate(batch): import torch inputs = processor(batch[&quot;speech&quot;], sampling_rate=16_000, return_tensors=&quot;pt&quot;, padding=True) with torch.no_grad(): logits = model(inputs.input_values.to(&quot;cuda&quot;), attention_mask=inputs.attention_mask.to(&quot;cuda&quot;)).logits pred_ids = torch.argmax(logits, dim=-1) batch[&quot;pred_strings&quot;] = processor.batch_decode(pred_ids) return batch . import json def process_wave(filename, duration): import json dataset = vad_to_dataset(filename, duration) result = dataset.map(evaluate, batched=True, batch_size=16) speechless = result.remove_columns([&#39;speech&#39;]) d=speechless.to_dict() tlog = list() for i in range(0, len(d[&#39;end&#39;]) - 1): out = dict() out[&#39;start&#39;] = d[&#39;start&#39;][i] out[&#39;end&#39;] = d[&#39;end&#39;][i] out[&#39;transcript&#39;] = d[&#39;pred_strings&#39;][i] tlog.append(out) with open(&#39;{}.tlog&#39;.format(filename), &#39;w&#39;) as outfile: json.dump(tlog, outfile) . import glob for f in glob.glob(&#39;/content/poleval_final_dataset_wav/train/*.wav&#39;): print(f) process_wave(f, 10.0) . !find . -name &#39;*tlog&#39;|zip poleval-train.zip -@ .",
            "url": "https://jimregan.github.io/notes/wav2vec2/poleval/colab/2021/06/16/poleval-through-wav2vec2.html",
            "relUrl": "/wav2vec2/poleval/colab/2021/06/16/poleval-through-wav2vec2.html",
            "date": " ‚Ä¢ Jun 16, 2021"
        }
        
    
  
    
        ,"post61": {
            "title": "Poleval 2021 punctuation restoration data",
            "content": "Original here . !pip install gdown . !gdown https://drive.google.com/uc?id=1PYfEhg-zGwnJ07HIaimlD3EgILPOBojq !gdown https://drive.google.com/uc?id=1b6MyyqgA9D1U7DX3Vtgda7f9ppkxjCXJ !gdown https://drive.google.com/uc?id=1gwQRvrUtFqz3xGnmEN8znAzkBwC12Czu !gdown https://drive.google.com/uc?id=16MaKgexMtMhQL6sftMsS3H1pPjJqY_zx . Downloading... From: https://drive.google.com/uc?id=1PYfEhg-zGwnJ07HIaimlD3EgILPOBojq To: /kaggle/working/poleval_fa.train.tar.gz 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.45M/1.45M [00:00&lt;00:00, 95.9MB/s] Downloading... From: https://drive.google.com/uc?id=1b6MyyqgA9D1U7DX3Vtgda7f9ppkxjCXJ To: /kaggle/working/poleval_wav.train.tar.gz 2.14GB [00:24, 86.7MB/s] Downloading... From: https://drive.google.com/uc?id=1gwQRvrUtFqz3xGnmEN8znAzkBwC12Czu To: /kaggle/working/poleval_wav.validation.tar.gz 537MB [00:08, 64.6MB/s] Downloading... From: https://drive.google.com/uc?id=16MaKgexMtMhQL6sftMsS3H1pPjJqY_zx To: /kaggle/working/poleval_text.rest.tar.gz 48.8MB [00:01, 29.6MB/s] .",
            "url": "https://jimregan.github.io/notes/asr/polish/kaggle/2021/06/16/poleval-2021-punctuation-restoration-data.html",
            "relUrl": "/asr/polish/kaggle/2021/06/16/poleval-2021-punctuation-restoration-data.html",
            "date": " ‚Ä¢ Jun 16, 2021"
        }
        
    
  
    
        ,"post62": {
            "title": "Poleval 2021 wav durations",
            "content": "%cd /tmp . /tmp . %%capture !tar zxvf /kaggle/input/poleval-2021-punctuation-restoration-data/poleval_wav.train.tar.gz . !for i in poleval_final_dataset_wav/train/*.wav;do ffmpeg -i $i 2&gt;&amp;1 | grep &quot;Duration&quot;;done . Duration: 00:01:50.34, bitrate: 256 kb/s Duration: 00:01:24.78, bitrate: 256 kb/s Duration: 00:01:17.90, bitrate: 256 kb/s Duration: 00:01:53.58, bitrate: 256 kb/s Duration: 00:01:09.72, bitrate: 256 kb/s Duration: 00:02:34.74, bitrate: 256 kb/s Duration: 00:01:22.14, bitrate: 256 kb/s Duration: 00:01:58.56, bitrate: 256 kb/s Duration: 00:01:45.78, bitrate: 256 kb/s Duration: 00:02:14.04, bitrate: 256 kb/s Duration: 00:01:34.72, bitrate: 256 kb/s Duration: 00:01:11.61, bitrate: 256 kb/s Duration: 00:01:07.25, bitrate: 256 kb/s Duration: 00:01:26.52, bitrate: 256 kb/s Duration: 00:01:40.56, bitrate: 256 kb/s Duration: 00:02:03.72, bitrate: 256 kb/s Duration: 00:02:13.02, bitrate: 256 kb/s Duration: 00:01:42.19, bitrate: 256 kb/s Duration: 00:01:26.94, bitrate: 256 kb/s Duration: 00:01:17.22, bitrate: 256 kb/s Duration: 00:01:55.62, bitrate: 256 kb/s Duration: 00:01:14.52, bitrate: 256 kb/s Duration: 00:01:22.14, bitrate: 256 kb/s Duration: 00:01:38.28, bitrate: 256 kb/s Duration: 00:01:44.52, bitrate: 256 kb/s Duration: 00:01:27.66, bitrate: 256 kb/s Duration: 00:01:55.97, bitrate: 256 kb/s Duration: 00:01:31.44, bitrate: 256 kb/s Duration: 00:01:54.71, bitrate: 256 kb/s Duration: 00:01:52.38, bitrate: 256 kb/s Duration: 00:01:56.28, bitrate: 256 kb/s Duration: 00:01:39.15, bitrate: 256 kb/s Duration: 00:02:26.28, bitrate: 256 kb/s Duration: 00:01:33.30, bitrate: 256 kb/s Duration: 00:01:57.72, bitrate: 256 kb/s Duration: 00:01:21.96, bitrate: 256 kb/s Duration: 00:01:39.36, bitrate: 256 kb/s Duration: 00:01:22.32, bitrate: 256 kb/s Duration: 00:01:34.36, bitrate: 256 kb/s Duration: 00:02:29.35, bitrate: 256 kb/s Duration: 00:01:22.13, bitrate: 256 kb/s Duration: 00:01:37.74, bitrate: 256 kb/s Duration: 00:01:47.04, bitrate: 256 kb/s Duration: 00:02:51.36, bitrate: 256 kb/s Duration: 00:01:05.40, bitrate: 256 kb/s Duration: 00:01:23.10, bitrate: 256 kb/s Duration: 00:01:33.22, bitrate: 256 kb/s Duration: 00:01:21.00, bitrate: 256 kb/s Duration: 00:01:21.15, bitrate: 256 kb/s Duration: 00:01:24.22, bitrate: 256 kb/s Duration: 00:01:31.62, bitrate: 256 kb/s Duration: 00:01:28.98, bitrate: 256 kb/s Duration: 00:01:15.30, bitrate: 256 kb/s Duration: 00:01:32.40, bitrate: 256 kb/s Duration: 00:01:08.44, bitrate: 256 kb/s Duration: 00:01:17.88, bitrate: 256 kb/s Duration: 00:01:15.66, bitrate: 256 kb/s Duration: 00:01:54.19, bitrate: 256 kb/s Duration: 00:01:41.34, bitrate: 256 kb/s Duration: 00:01:26.24, bitrate: 256 kb/s Duration: 00:02:12.45, bitrate: 256 kb/s Duration: 00:01:12.23, bitrate: 256 kb/s Duration: 00:01:13.10, bitrate: 256 kb/s Duration: 00:01:12.90, bitrate: 256 kb/s Duration: 00:01:14.70, bitrate: 256 kb/s Duration: 00:01:33.24, bitrate: 256 kb/s Duration: 00:01:20.70, bitrate: 256 kb/s Duration: 00:02:06.66, bitrate: 256 kb/s Duration: 00:01:34.74, bitrate: 256 kb/s Duration: 00:01:38.64, bitrate: 256 kb/s Duration: 00:02:02.07, bitrate: 256 kb/s Duration: 00:01:25.25, bitrate: 256 kb/s Duration: 00:01:06.68, bitrate: 256 kb/s Duration: 00:01:35.94, bitrate: 256 kb/s Duration: 00:02:09.75, bitrate: 256 kb/s Duration: 00:02:04.29, bitrate: 256 kb/s Duration: 00:01:44.12, bitrate: 256 kb/s Duration: 00:01:22.44, bitrate: 256 kb/s Duration: 00:01:00.60, bitrate: 256 kb/s Duration: 00:01:25.44, bitrate: 256 kb/s Duration: 00:02:00.00, bitrate: 256 kb/s Duration: 00:02:30.72, bitrate: 256 kb/s Duration: 00:01:51.30, bitrate: 256 kb/s Duration: 00:02:00.41, bitrate: 256 kb/s Duration: 00:01:46.62, bitrate: 256 kb/s Duration: 00:01:22.50, bitrate: 256 kb/s Duration: 00:01:33.20, bitrate: 256 kb/s Duration: 00:01:29.58, bitrate: 256 kb/s Duration: 00:01:47.70, bitrate: 256 kb/s Duration: 00:02:40.32, bitrate: 256 kb/s Duration: 00:01:26.70, bitrate: 256 kb/s Duration: 00:02:05.34, bitrate: 256 kb/s Duration: 00:01:23.64, bitrate: 256 kb/s Duration: 00:01:20.16, bitrate: 256 kb/s Duration: 00:02:21.60, bitrate: 256 kb/s Duration: 00:01:19.26, bitrate: 256 kb/s Duration: 00:01:54.04, bitrate: 256 kb/s Duration: 00:01:34.02, bitrate: 256 kb/s Duration: 00:01:21.96, bitrate: 256 kb/s Duration: 00:01:42.66, bitrate: 256 kb/s Duration: 00:01:44.45, bitrate: 256 kb/s Duration: 00:01:58.26, bitrate: 256 kb/s Duration: 00:00:59.18, bitrate: 256 kb/s Duration: 00:02:40.20, bitrate: 256 kb/s Duration: 00:01:49.02, bitrate: 256 kb/s Duration: 00:01:17.52, bitrate: 256 kb/s Duration: 00:01:13.98, bitrate: 256 kb/s Duration: 00:01:11.77, bitrate: 256 kb/s Duration: 00:01:13.38, bitrate: 256 kb/s Duration: 00:01:34.98, bitrate: 256 kb/s Duration: 00:02:47.88, bitrate: 256 kb/s Duration: 00:01:03.36, bitrate: 256 kb/s Duration: 00:00:56.88, bitrate: 256 kb/s Duration: 00:01:29.54, bitrate: 256 kb/s Duration: 00:01:28.84, bitrate: 256 kb/s Duration: 00:02:08.34, bitrate: 256 kb/s Duration: 00:00:55.47, bitrate: 256 kb/s Duration: 00:02:00.84, bitrate: 256 kb/s Duration: 00:01:43.44, bitrate: 256 kb/s Duration: 00:02:03.39, bitrate: 256 kb/s Duration: 00:01:12.30, bitrate: 256 kb/s Duration: 00:00:59.40, bitrate: 256 kb/s Duration: 00:01:21.18, bitrate: 256 kb/s Duration: 00:01:11.52, bitrate: 256 kb/s Duration: 00:02:04.74, bitrate: 256 kb/s Duration: 00:01:31.44, bitrate: 256 kb/s Duration: 00:01:07.68, bitrate: 256 kb/s Duration: 00:01:23.10, bitrate: 256 kb/s Duration: 00:02:44.94, bitrate: 256 kb/s Duration: 00:01:52.43, bitrate: 256 kb/s Duration: 00:01:16.86, bitrate: 256 kb/s Duration: 00:01:34.56, bitrate: 256 kb/s Duration: 00:01:57.12, bitrate: 256 kb/s Duration: 00:02:18.18, bitrate: 256 kb/s Duration: 00:01:28.26, bitrate: 256 kb/s Duration: 00:01:31.38, bitrate: 256 kb/s Duration: 00:02:25.02, bitrate: 256 kb/s Duration: 00:01:19.92, bitrate: 256 kb/s Duration: 00:01:14.04, bitrate: 256 kb/s Duration: 00:01:14.16, bitrate: 256 kb/s Duration: 00:01:15.00, bitrate: 256 kb/s Duration: 00:01:44.92, bitrate: 256 kb/s Duration: 00:01:30.66, bitrate: 256 kb/s Duration: 00:01:57.90, bitrate: 256 kb/s Duration: 00:01:59.76, bitrate: 256 kb/s Duration: 00:01:32.58, bitrate: 256 kb/s Duration: 00:01:16.56, bitrate: 256 kb/s Duration: 00:01:34.38, bitrate: 256 kb/s Duration: 00:01:37.96, bitrate: 256 kb/s Duration: 00:01:49.74, bitrate: 256 kb/s Duration: 00:01:15.54, bitrate: 256 kb/s Duration: 00:01:23.04, bitrate: 256 kb/s Duration: 00:02:08.38, bitrate: 256 kb/s Duration: 00:01:41.76, bitrate: 256 kb/s Duration: 00:01:12.54, bitrate: 256 kb/s Duration: 00:01:24.96, bitrate: 256 kb/s Duration: 00:01:52.43, bitrate: 256 kb/s Duration: 00:00:58.51, bitrate: 256 kb/s Duration: 00:01:48.06, bitrate: 256 kb/s Duration: 00:01:10.27, bitrate: 256 kb/s Duration: 00:02:35.73, bitrate: 256 kb/s Duration: 00:02:28.26, bitrate: 256 kb/s Duration: 00:02:08.96, bitrate: 256 kb/s Duration: 00:01:19.91, bitrate: 256 kb/s Duration: 00:01:20.21, bitrate: 256 kb/s Duration: 00:01:11.68, bitrate: 256 kb/s Duration: 00:01:38.46, bitrate: 256 kb/s Duration: 00:01:58.80, bitrate: 256 kb/s Duration: 00:01:16.68, bitrate: 256 kb/s Duration: 00:01:18.36, bitrate: 256 kb/s Duration: 00:01:18.07, bitrate: 256 kb/s Duration: 00:01:29.64, bitrate: 256 kb/s Duration: 00:02:06.12, bitrate: 256 kb/s Duration: 00:01:05.64, bitrate: 256 kb/s Duration: 00:01:25.80, bitrate: 256 kb/s Duration: 00:02:22.32, bitrate: 256 kb/s Duration: 00:02:00.00, bitrate: 256 kb/s Duration: 00:01:13.98, bitrate: 256 kb/s Duration: 00:01:14.42, bitrate: 256 kb/s Duration: 00:01:22.50, bitrate: 256 kb/s Duration: 00:02:00.79, bitrate: 256 kb/s Duration: 00:02:13.68, bitrate: 256 kb/s Duration: 00:02:18.24, bitrate: 256 kb/s Duration: 00:01:21.49, bitrate: 256 kb/s Duration: 00:01:34.21, bitrate: 256 kb/s Duration: 00:01:34.80, bitrate: 256 kb/s Duration: 00:02:17.52, bitrate: 256 kb/s Duration: 00:01:20.28, bitrate: 256 kb/s Duration: 00:01:27.78, bitrate: 256 kb/s Duration: 00:01:56.28, bitrate: 256 kb/s Duration: 00:01:14.46, bitrate: 256 kb/s Duration: 00:01:11.94, bitrate: 256 kb/s Duration: 00:01:32.82, bitrate: 256 kb/s Duration: 00:02:18.66, bitrate: 256 kb/s Duration: 00:01:45.96, bitrate: 256 kb/s Duration: 00:01:29.30, bitrate: 256 kb/s Duration: 00:01:52.20, bitrate: 256 kb/s Duration: 00:01:15.72, bitrate: 256 kb/s Duration: 00:01:20.40, bitrate: 256 kb/s Duration: 00:01:33.54, bitrate: 256 kb/s Duration: 00:01:43.32, bitrate: 256 kb/s Duration: 00:01:53.76, bitrate: 256 kb/s Duration: 00:01:12.06, bitrate: 256 kb/s Duration: 00:01:26.27, bitrate: 256 kb/s Duration: 00:01:19.68, bitrate: 256 kb/s Duration: 00:01:24.82, bitrate: 256 kb/s Duration: 00:01:33.53, bitrate: 256 kb/s Duration: 00:01:28.74, bitrate: 256 kb/s Duration: 00:01:53.16, bitrate: 256 kb/s Duration: 00:01:29.64, bitrate: 256 kb/s Duration: 00:01:28.56, bitrate: 256 kb/s Duration: 00:01:44.38, bitrate: 256 kb/s Duration: 00:02:02.46, bitrate: 256 kb/s Duration: 00:01:09.29, bitrate: 256 kb/s Duration: 00:01:35.80, bitrate: 256 kb/s Duration: 00:00:59.95, bitrate: 256 kb/s Duration: 00:01:46.32, bitrate: 256 kb/s Duration: 00:01:32.40, bitrate: 256 kb/s Duration: 00:01:23.82, bitrate: 256 kb/s Duration: 00:01:45.02, bitrate: 256 kb/s Duration: 00:01:57.90, bitrate: 256 kb/s Duration: 00:01:37.32, bitrate: 256 kb/s Duration: 00:01:58.44, bitrate: 256 kb/s Duration: 00:01:28.66, bitrate: 256 kb/s Duration: 00:01:33.78, bitrate: 256 kb/s Duration: 00:01:49.23, bitrate: 256 kb/s Duration: 00:01:35.34, bitrate: 256 kb/s Duration: 00:01:44.63, bitrate: 256 kb/s Duration: 00:01:46.50, bitrate: 256 kb/s Duration: 00:01:56.04, bitrate: 256 kb/s Duration: 00:01:13.72, bitrate: 256 kb/s Duration: 00:01:14.76, bitrate: 256 kb/s Duration: 00:01:29.16, bitrate: 256 kb/s Duration: 00:01:13.38, bitrate: 256 kb/s Duration: 00:01:27.08, bitrate: 256 kb/s Duration: 00:01:50.10, bitrate: 256 kb/s Duration: 00:02:05.27, bitrate: 256 kb/s Duration: 00:01:59.07, bitrate: 256 kb/s Duration: 00:01:25.03, bitrate: 256 kb/s Duration: 00:01:25.89, bitrate: 256 kb/s Duration: 00:01:37.68, bitrate: 256 kb/s Duration: 00:01:12.53, bitrate: 256 kb/s Duration: 00:01:40.26, bitrate: 256 kb/s Duration: 00:01:25.80, bitrate: 256 kb/s Duration: 00:01:31.44, bitrate: 256 kb/s Duration: 00:01:02.29, bitrate: 256 kb/s Duration: 00:01:42.06, bitrate: 256 kb/s Duration: 00:01:47.82, bitrate: 256 kb/s Duration: 00:01:13.86, bitrate: 256 kb/s Duration: 00:01:27.44, bitrate: 256 kb/s Duration: 00:01:18.84, bitrate: 256 kb/s Duration: 00:01:28.38, bitrate: 256 kb/s Duration: 00:02:04.50, bitrate: 256 kb/s Duration: 00:01:27.49, bitrate: 256 kb/s Duration: 00:01:41.28, bitrate: 256 kb/s Duration: 00:01:30.06, bitrate: 256 kb/s Duration: 00:02:03.42, bitrate: 256 kb/s Duration: 00:01:39.54, bitrate: 256 kb/s Duration: 00:01:05.76, bitrate: 256 kb/s Duration: 00:02:08.76, bitrate: 256 kb/s Duration: 00:02:29.34, bitrate: 256 kb/s Duration: 00:01:15.00, bitrate: 256 kb/s Duration: 00:01:07.26, bitrate: 256 kb/s Duration: 00:02:16.06, bitrate: 256 kb/s Duration: 00:01:35.58, bitrate: 256 kb/s Duration: 00:01:37.62, bitrate: 256 kb/s Duration: 00:02:07.32, bitrate: 256 kb/s Duration: 00:01:33.66, bitrate: 256 kb/s Duration: 00:01:42.30, bitrate: 256 kb/s Duration: 00:01:52.02, bitrate: 256 kb/s Duration: 00:01:36.24, bitrate: 256 kb/s Duration: 00:01:20.70, bitrate: 256 kb/s Duration: 00:01:09.47, bitrate: 256 kb/s Duration: 00:01:34.27, bitrate: 256 kb/s Duration: 00:01:33.12, bitrate: 256 kb/s Duration: 00:01:21.32, bitrate: 256 kb/s Duration: 00:01:43.56, bitrate: 256 kb/s Duration: 00:01:13.26, bitrate: 256 kb/s Duration: 00:01:20.10, bitrate: 256 kb/s Duration: 00:01:18.96, bitrate: 256 kb/s Duration: 00:01:50.76, bitrate: 256 kb/s Duration: 00:01:53.16, bitrate: 256 kb/s Duration: 00:01:16.25, bitrate: 256 kb/s Duration: 00:02:17.51, bitrate: 256 kb/s Duration: 00:01:26.58, bitrate: 256 kb/s Duration: 00:01:03.96, bitrate: 256 kb/s Duration: 00:01:14.45, bitrate: 256 kb/s Duration: 00:01:39.06, bitrate: 256 kb/s Duration: 00:01:17.10, bitrate: 256 kb/s Duration: 00:01:23.46, bitrate: 256 kb/s Duration: 00:01:20.46, bitrate: 256 kb/s Duration: 00:01:40.62, bitrate: 256 kb/s Duration: 00:01:10.45, bitrate: 256 kb/s Duration: 00:01:59.04, bitrate: 256 kb/s Duration: 00:02:12.95, bitrate: 256 kb/s Duration: 00:01:11.28, bitrate: 256 kb/s Duration: 00:01:47.52, bitrate: 256 kb/s Duration: 00:01:38.05, bitrate: 256 kb/s Duration: 00:01:53.45, bitrate: 256 kb/s Duration: 00:01:49.08, bitrate: 256 kb/s Duration: 00:01:20.13, bitrate: 256 kb/s Duration: 00:01:31.20, bitrate: 256 kb/s Duration: 00:01:54.96, bitrate: 256 kb/s Duration: 00:02:13.74, bitrate: 256 kb/s Duration: 00:01:52.56, bitrate: 256 kb/s Duration: 00:02:05.04, bitrate: 256 kb/s Duration: 00:01:47.28, bitrate: 256 kb/s Duration: 00:01:30.70, bitrate: 256 kb/s Duration: 00:01:48.54, bitrate: 256 kb/s Duration: 00:01:19.80, bitrate: 256 kb/s Duration: 00:02:17.28, bitrate: 256 kb/s Duration: 00:01:53.04, bitrate: 256 kb/s Duration: 00:01:14.34, bitrate: 256 kb/s Duration: 00:01:24.78, bitrate: 256 kb/s Duration: 00:01:40.56, bitrate: 256 kb/s Duration: 00:01:26.22, bitrate: 256 kb/s Duration: 00:01:21.66, bitrate: 256 kb/s Duration: 00:01:49.48, bitrate: 256 kb/s Duration: 00:01:41.46, bitrate: 256 kb/s Duration: 00:01:13.74, bitrate: 256 kb/s Duration: 00:01:52.38, bitrate: 256 kb/s Duration: 00:01:26.94, bitrate: 256 kb/s Duration: 00:01:45.30, bitrate: 256 kb/s Duration: 00:01:26.58, bitrate: 256 kb/s Duration: 00:02:02.10, bitrate: 256 kb/s Duration: 00:01:22.73, bitrate: 256 kb/s Duration: 00:01:42.84, bitrate: 256 kb/s Duration: 00:02:14.52, bitrate: 256 kb/s Duration: 00:02:09.66, bitrate: 256 kb/s Duration: 00:01:30.98, bitrate: 256 kb/s Duration: 00:02:09.54, bitrate: 256 kb/s Duration: 00:01:18.60, bitrate: 256 kb/s Duration: 00:01:33.24, bitrate: 256 kb/s Duration: 00:01:33.78, bitrate: 256 kb/s Duration: 00:02:07.74, bitrate: 256 kb/s Duration: 00:01:22.02, bitrate: 256 kb/s Duration: 00:01:50.98, bitrate: 256 kb/s Duration: 00:01:32.10, bitrate: 256 kb/s Duration: 00:01:59.40, bitrate: 256 kb/s Duration: 00:01:25.20, bitrate: 256 kb/s Duration: 00:01:40.26, bitrate: 256 kb/s Duration: 00:01:07.08, bitrate: 256 kb/s Duration: 00:01:48.38, bitrate: 256 kb/s Duration: 00:01:26.28, bitrate: 256 kb/s Duration: 00:02:14.94, bitrate: 256 kb/s Duration: 00:02:10.54, bitrate: 256 kb/s Duration: 00:01:37.50, bitrate: 256 kb/s Duration: 00:02:26.70, bitrate: 256 kb/s Duration: 00:01:57.72, bitrate: 256 kb/s Duration: 00:01:20.94, bitrate: 256 kb/s Duration: 00:01:36.06, bitrate: 256 kb/s Duration: 00:01:48.78, bitrate: 256 kb/s Duration: 00:01:32.76, bitrate: 256 kb/s Duration: 00:01:45.64, bitrate: 256 kb/s Duration: 00:02:19.26, bitrate: 256 kb/s Duration: 00:01:13.75, bitrate: 256 kb/s Duration: 00:01:54.90, bitrate: 256 kb/s Duration: 00:01:16.12, bitrate: 256 kb/s Duration: 00:01:42.84, bitrate: 256 kb/s Duration: 00:01:22.68, bitrate: 256 kb/s Duration: 00:01:25.62, bitrate: 256 kb/s Duration: 00:01:33.18, bitrate: 256 kb/s Duration: 00:01:34.74, bitrate: 256 kb/s Duration: 00:01:45.42, bitrate: 256 kb/s Duration: 00:01:41.04, bitrate: 256 kb/s Duration: 00:01:58.14, bitrate: 256 kb/s Duration: 00:02:11.52, bitrate: 256 kb/s Duration: 00:02:01.04, bitrate: 256 kb/s Duration: 00:01:39.36, bitrate: 256 kb/s Duration: 00:01:26.70, bitrate: 256 kb/s Duration: 00:01:59.28, bitrate: 256 kb/s Duration: 00:02:12.72, bitrate: 256 kb/s Duration: 00:01:33.96, bitrate: 256 kb/s Duration: 00:01:44.03, bitrate: 256 kb/s Duration: 00:01:44.10, bitrate: 256 kb/s Duration: 00:01:06.12, bitrate: 256 kb/s Duration: 00:02:28.46, bitrate: 256 kb/s Duration: 00:02:06.78, bitrate: 256 kb/s Duration: 00:01:57.18, bitrate: 256 kb/s Duration: 00:01:20.52, bitrate: 256 kb/s Duration: 00:01:42.84, bitrate: 256 kb/s Duration: 00:01:33.54, bitrate: 256 kb/s Duration: 00:01:41.10, bitrate: 256 kb/s Duration: 00:02:47.74, bitrate: 256 kb/s Duration: 00:02:25.32, bitrate: 256 kb/s Duration: 00:01:50.58, bitrate: 256 kb/s Duration: 00:01:39.18, bitrate: 256 kb/s Duration: 00:01:52.80, bitrate: 256 kb/s Duration: 00:01:23.58, bitrate: 256 kb/s Duration: 00:01:10.36, bitrate: 256 kb/s Duration: 00:01:36.30, bitrate: 256 kb/s Duration: 00:01:36.06, bitrate: 256 kb/s Duration: 00:01:34.32, bitrate: 256 kb/s Duration: 00:02:53.40, bitrate: 256 kb/s Duration: 00:02:19.55, bitrate: 256 kb/s Duration: 00:01:07.02, bitrate: 256 kb/s Duration: 00:01:24.84, bitrate: 256 kb/s Duration: 00:01:26.36, bitrate: 256 kb/s Duration: 00:01:36.30, bitrate: 256 kb/s Duration: 00:01:28.65, bitrate: 256 kb/s Duration: 00:01:59.64, bitrate: 256 kb/s Duration: 00:01:59.82, bitrate: 256 kb/s Duration: 00:02:19.69, bitrate: 256 kb/s Duration: 00:01:48.42, bitrate: 256 kb/s Duration: 00:01:27.89, bitrate: 256 kb/s Duration: 00:02:45.30, bitrate: 256 kb/s Duration: 00:01:53.34, bitrate: 256 kb/s Duration: 00:01:52.80, bitrate: 256 kb/s Duration: 00:01:37.80, bitrate: 256 kb/s Duration: 00:02:03.54, bitrate: 256 kb/s Duration: 00:01:35.70, bitrate: 256 kb/s Duration: 00:02:00.42, bitrate: 256 kb/s Duration: 00:02:21.60, bitrate: 256 kb/s Duration: 00:01:24.95, bitrate: 256 kb/s Duration: 00:02:11.34, bitrate: 256 kb/s Duration: 00:01:07.16, bitrate: 256 kb/s Duration: 00:01:29.94, bitrate: 256 kb/s Duration: 00:02:53.46, bitrate: 256 kb/s Duration: 00:02:24.96, bitrate: 256 kb/s Duration: 00:01:21.24, bitrate: 256 kb/s Duration: 00:03:23.48, bitrate: 256 kb/s Duration: 00:02:08.40, bitrate: 256 kb/s Duration: 00:01:32.40, bitrate: 256 kb/s Duration: 00:01:55.92, bitrate: 256 kb/s Duration: 00:01:58.79, bitrate: 256 kb/s Duration: 00:01:18.36, bitrate: 256 kb/s Duration: 00:02:33.36, bitrate: 256 kb/s Duration: 00:01:05.83, bitrate: 256 kb/s Duration: 00:01:47.94, bitrate: 256 kb/s Duration: 00:01:45.60, bitrate: 256 kb/s Duration: 00:01:19.14, bitrate: 256 kb/s Duration: 00:01:27.18, bitrate: 256 kb/s Duration: 00:02:19.32, bitrate: 256 kb/s Duration: 00:01:36.90, bitrate: 256 kb/s Duration: 00:02:06.90, bitrate: 256 kb/s Duration: 00:01:49.46, bitrate: 256 kb/s Duration: 00:02:03.24, bitrate: 256 kb/s Duration: 00:01:34.80, bitrate: 256 kb/s Duration: 00:01:57.24, bitrate: 256 kb/s Duration: 00:01:25.26, bitrate: 256 kb/s Duration: 00:01:13.69, bitrate: 256 kb/s Duration: 00:01:16.56, bitrate: 256 kb/s Duration: 00:01:36.72, bitrate: 256 kb/s Duration: 00:01:27.18, bitrate: 256 kb/s Duration: 00:01:25.86, bitrate: 256 kb/s Duration: 00:01:17.35, bitrate: 256 kb/s Duration: 00:01:01.50, bitrate: 256 kb/s Duration: 00:01:09.85, bitrate: 256 kb/s Duration: 00:02:00.78, bitrate: 256 kb/s Duration: 00:01:33.40, bitrate: 256 kb/s Duration: 00:01:23.94, bitrate: 256 kb/s Duration: 00:02:27.96, bitrate: 256 kb/s Duration: 00:01:23.64, bitrate: 256 kb/s Duration: 00:01:37.66, bitrate: 256 kb/s Duration: 00:01:24.82, bitrate: 256 kb/s Duration: 00:01:22.38, bitrate: 256 kb/s Duration: 00:01:35.88, bitrate: 256 kb/s Duration: 00:01:13.75, bitrate: 256 kb/s Duration: 00:01:37.38, bitrate: 256 kb/s Duration: 00:01:11.58, bitrate: 256 kb/s Duration: 00:01:32.88, bitrate: 256 kb/s Duration: 00:01:51.42, bitrate: 256 kb/s Duration: 00:01:52.52, bitrate: 256 kb/s Duration: 00:01:17.40, bitrate: 256 kb/s Duration: 00:01:34.50, bitrate: 256 kb/s Duration: 00:01:55.11, bitrate: 256 kb/s Duration: 00:01:57.60, bitrate: 256 kb/s Duration: 00:01:33.01, bitrate: 256 kb/s Duration: 00:01:51.90, bitrate: 256 kb/s Duration: 00:02:30.22, bitrate: 256 kb/s Duration: 00:01:36.48, bitrate: 256 kb/s Duration: 00:02:14.91, bitrate: 256 kb/s Duration: 00:01:59.64, bitrate: 256 kb/s Duration: 00:04:04.50, bitrate: 256 kb/s Duration: 00:01:50.70, bitrate: 256 kb/s Duration: 00:02:13.20, bitrate: 256 kb/s Duration: 00:02:20.94, bitrate: 256 kb/s Duration: 00:01:26.52, bitrate: 256 kb/s Duration: 00:02:15.18, bitrate: 256 kb/s Duration: 00:01:14.82, bitrate: 256 kb/s Duration: 00:01:23.16, bitrate: 256 kb/s Duration: 00:01:15.60, bitrate: 256 kb/s Duration: 00:01:38.18, bitrate: 256 kb/s Duration: 00:01:20.40, bitrate: 256 kb/s Duration: 00:01:25.14, bitrate: 256 kb/s Duration: 00:01:35.28, bitrate: 256 kb/s Duration: 00:02:10.26, bitrate: 256 kb/s Duration: 00:01:23.93, bitrate: 256 kb/s Duration: 00:01:17.46, bitrate: 256 kb/s Duration: 00:01:01.61, bitrate: 256 kb/s Duration: 00:01:43.42, bitrate: 256 kb/s Duration: 00:01:13.81, bitrate: 256 kb/s Duration: 00:02:34.32, bitrate: 256 kb/s Duration: 00:01:16.14, bitrate: 256 kb/s Duration: 00:01:25.92, bitrate: 256 kb/s Duration: 00:01:10.22, bitrate: 256 kb/s Duration: 00:01:16.48, bitrate: 256 kb/s Duration: 00:01:09.60, bitrate: 256 kb/s Duration: 00:02:37.31, bitrate: 256 kb/s Duration: 00:01:19.32, bitrate: 256 kb/s Duration: 00:02:04.02, bitrate: 256 kb/s Duration: 00:01:27.90, bitrate: 256 kb/s Duration: 00:01:34.92, bitrate: 256 kb/s Duration: 00:02:00.42, bitrate: 256 kb/s Duration: 00:01:25.94, bitrate: 256 kb/s Duration: 00:01:26.40, bitrate: 256 kb/s Duration: 00:01:56.28, bitrate: 256 kb/s Duration: 00:02:10.80, bitrate: 256 kb/s Duration: 00:02:05.10, bitrate: 256 kb/s Duration: 00:01:25.93, bitrate: 256 kb/s Duration: 00:01:18.02, bitrate: 256 kb/s Duration: 00:01:15.66, bitrate: 256 kb/s Duration: 00:02:11.24, bitrate: 256 kb/s Duration: 00:01:11.04, bitrate: 256 kb/s Duration: 00:01:27.68, bitrate: 256 kb/s Duration: 00:01:21.46, bitrate: 256 kb/s Duration: 00:01:24.18, bitrate: 256 kb/s Duration: 00:01:10.14, bitrate: 256 kb/s Duration: 00:01:29.52, bitrate: 256 kb/s Duration: 00:01:38.94, bitrate: 256 kb/s Duration: 00:01:33.12, bitrate: 256 kb/s Duration: 00:01:39.18, bitrate: 256 kb/s Duration: 00:01:33.82, bitrate: 256 kb/s Duration: 00:01:13.68, bitrate: 256 kb/s Duration: 00:01:36.42, bitrate: 256 kb/s Duration: 00:01:37.08, bitrate: 256 kb/s Duration: 00:01:02.38, bitrate: 256 kb/s Duration: 00:01:24.54, bitrate: 256 kb/s Duration: 00:02:15.18, bitrate: 256 kb/s Duration: 00:02:34.62, bitrate: 256 kb/s Duration: 00:01:31.68, bitrate: 256 kb/s Duration: 00:03:07.56, bitrate: 256 kb/s Duration: 00:01:20.16, bitrate: 256 kb/s Duration: 00:01:59.40, bitrate: 256 kb/s Duration: 00:01:33.95, bitrate: 256 kb/s Duration: 00:01:51.87, bitrate: 256 kb/s Duration: 00:01:23.40, bitrate: 256 kb/s Duration: 00:01:03.60, bitrate: 256 kb/s Duration: 00:01:20.34, bitrate: 256 kb/s Duration: 00:01:47.70, bitrate: 256 kb/s Duration: 00:02:43.50, bitrate: 256 kb/s Duration: 00:01:24.47, bitrate: 256 kb/s Duration: 00:01:37.56, bitrate: 256 kb/s Duration: 00:01:54.42, bitrate: 256 kb/s Duration: 00:01:15.66, bitrate: 256 kb/s Duration: 00:01:33.31, bitrate: 256 kb/s Duration: 00:02:07.32, bitrate: 256 kb/s Duration: 00:01:39.18, bitrate: 256 kb/s Duration: 00:01:46.16, bitrate: 256 kb/s Duration: 00:01:50.40, bitrate: 256 kb/s Duration: 00:02:35.70, bitrate: 256 kb/s Duration: 00:01:51.54, bitrate: 256 kb/s Duration: 00:01:41.46, bitrate: 256 kb/s Duration: 00:01:29.52, bitrate: 256 kb/s Duration: 00:02:40.62, bitrate: 256 kb/s Duration: 00:02:14.76, bitrate: 256 kb/s Duration: 00:01:25.32, bitrate: 256 kb/s Duration: 00:01:04.68, bitrate: 256 kb/s Duration: 00:01:30.54, bitrate: 256 kb/s Duration: 00:01:18.90, bitrate: 256 kb/s Duration: 00:01:05.45, bitrate: 256 kb/s Duration: 00:01:21.24, bitrate: 256 kb/s Duration: 00:02:01.09, bitrate: 256 kb/s Duration: 00:02:14.21, bitrate: 256 kb/s Duration: 00:01:17.22, bitrate: 256 kb/s Duration: 00:01:46.44, bitrate: 256 kb/s Duration: 00:02:39.54, bitrate: 256 kb/s Duration: 00:02:03.31, bitrate: 256 kb/s Duration: 00:01:38.52, bitrate: 256 kb/s Duration: 00:02:04.98, bitrate: 256 kb/s Duration: 00:01:51.54, bitrate: 256 kb/s Duration: 00:02:44.94, bitrate: 256 kb/s Duration: 00:01:40.32, bitrate: 256 kb/s Duration: 00:01:25.62, bitrate: 256 kb/s Duration: 00:01:28.33, bitrate: 256 kb/s Duration: 00:01:13.20, bitrate: 256 kb/s Duration: 00:01:18.30, bitrate: 256 kb/s Duration: 00:01:47.40, bitrate: 256 kb/s Duration: 00:02:05.10, bitrate: 256 kb/s Duration: 00:02:42.72, bitrate: 256 kb/s Duration: 00:01:22.80, bitrate: 256 kb/s Duration: 00:01:37.02, bitrate: 256 kb/s Duration: 00:01:27.73, bitrate: 256 kb/s Duration: 00:01:42.96, bitrate: 256 kb/s Duration: 00:01:24.12, bitrate: 256 kb/s Duration: 00:01:25.67, bitrate: 256 kb/s Duration: 00:01:30.23, bitrate: 256 kb/s Duration: 00:01:19.14, bitrate: 256 kb/s Duration: 00:01:24.06, bitrate: 256 kb/s Duration: 00:01:26.64, bitrate: 256 kb/s Duration: 00:01:33.39, bitrate: 256 kb/s Duration: 00:01:40.68, bitrate: 256 kb/s Duration: 00:01:41.38, bitrate: 256 kb/s Duration: 00:02:34.62, bitrate: 256 kb/s Duration: 00:01:27.36, bitrate: 256 kb/s Duration: 00:01:58.68, bitrate: 256 kb/s Duration: 00:01:36.78, bitrate: 256 kb/s Duration: 00:01:58.26, bitrate: 256 kb/s Duration: 00:01:09.21, bitrate: 256 kb/s Duration: 00:01:24.78, bitrate: 256 kb/s Duration: 00:01:17.65, bitrate: 256 kb/s Duration: 00:01:34.80, bitrate: 256 kb/s Duration: 00:01:20.58, bitrate: 256 kb/s Duration: 00:01:22.38, bitrate: 256 kb/s Duration: 00:01:59.06, bitrate: 256 kb/s Duration: 00:01:22.26, bitrate: 256 kb/s Duration: 00:01:09.12, bitrate: 256 kb/s Duration: 00:01:41.94, bitrate: 256 kb/s Duration: 00:01:34.32, bitrate: 256 kb/s Duration: 00:01:07.88, bitrate: 256 kb/s Duration: 00:01:41.28, bitrate: 256 kb/s Duration: 00:01:43.08, bitrate: 256 kb/s Duration: 00:01:45.51, bitrate: 256 kb/s Duration: 00:01:24.96, bitrate: 256 kb/s Duration: 00:01:42.42, bitrate: 256 kb/s Duration: 00:02:27.78, bitrate: 256 kb/s Duration: 00:01:59.34, bitrate: 256 kb/s Duration: 00:01:37.52, bitrate: 256 kb/s Duration: 00:01:51.12, bitrate: 256 kb/s Duration: 00:02:26.16, bitrate: 256 kb/s Duration: 00:02:15.36, bitrate: 256 kb/s Duration: 00:02:04.08, bitrate: 256 kb/s Duration: 00:01:30.06, bitrate: 256 kb/s Duration: 00:02:04.98, bitrate: 256 kb/s Duration: 00:02:35.94, bitrate: 256 kb/s Duration: 00:02:03.72, bitrate: 256 kb/s Duration: 00:01:45.78, bitrate: 256 kb/s Duration: 00:01:34.56, bitrate: 256 kb/s Duration: 00:01:30.78, bitrate: 256 kb/s Duration: 00:01:34.98, bitrate: 256 kb/s Duration: 00:02:13.56, bitrate: 256 kb/s Duration: 00:02:09.02, bitrate: 256 kb/s Duration: 00:01:11.76, bitrate: 256 kb/s Duration: 00:02:07.80, bitrate: 256 kb/s Duration: 00:01:23.94, bitrate: 256 kb/s Duration: 00:01:17.64, bitrate: 256 kb/s Duration: 00:01:12.24, bitrate: 256 kb/s Duration: 00:01:43.32, bitrate: 256 kb/s Duration: 00:01:50.88, bitrate: 256 kb/s Duration: 00:01:01.98, bitrate: 256 kb/s Duration: 00:01:48.24, bitrate: 256 kb/s Duration: 00:02:04.69, bitrate: 256 kb/s Duration: 00:01:18.72, bitrate: 256 kb/s Duration: 00:03:08.58, bitrate: 256 kb/s Duration: 00:01:38.58, bitrate: 256 kb/s Duration: 00:01:12.72, bitrate: 256 kb/s Duration: 00:01:58.56, bitrate: 256 kb/s Duration: 00:01:33.90, bitrate: 256 kb/s Duration: 00:00:49.74, bitrate: 256 kb/s Duration: 00:01:13.38, bitrate: 256 kb/s Duration: 00:00:49.83, bitrate: 256 kb/s Duration: 00:01:44.04, bitrate: 256 kb/s Duration: 00:02:37.92, bitrate: 256 kb/s Duration: 00:02:17.52, bitrate: 256 kb/s Duration: 00:01:10.38, bitrate: 256 kb/s Duration: 00:01:37.44, bitrate: 256 kb/s Duration: 00:01:23.40, bitrate: 256 kb/s Duration: 00:01:52.86, bitrate: 256 kb/s Duration: 00:01:54.84, bitrate: 256 kb/s Duration: 00:01:29.04, bitrate: 256 kb/s Duration: 00:01:28.62, bitrate: 256 kb/s Duration: 00:01:14.82, bitrate: 256 kb/s Duration: 00:01:31.02, bitrate: 256 kb/s Duration: 00:01:04.92, bitrate: 256 kb/s Duration: 00:01:40.78, bitrate: 256 kb/s Duration: 00:01:27.60, bitrate: 256 kb/s Duration: 00:01:37.38, bitrate: 256 kb/s Duration: 00:01:17.00, bitrate: 256 kb/s Duration: 00:01:20.34, bitrate: 256 kb/s Duration: 00:01:03.12, bitrate: 256 kb/s Duration: 00:01:24.18, bitrate: 256 kb/s Duration: 00:02:44.70, bitrate: 256 kb/s Duration: 00:01:48.06, bitrate: 256 kb/s Duration: 00:01:49.08, bitrate: 256 kb/s Duration: 00:01:26.28, bitrate: 256 kb/s Duration: 00:01:56.34, bitrate: 256 kb/s Duration: 00:01:20.52, bitrate: 256 kb/s Duration: 00:01:23.10, bitrate: 256 kb/s Duration: 00:01:13.42, bitrate: 256 kb/s Duration: 00:01:57.42, bitrate: 256 kb/s Duration: 00:01:42.30, bitrate: 256 kb/s Duration: 00:02:21.42, bitrate: 256 kb/s Duration: 00:01:29.34, bitrate: 256 kb/s Duration: 00:02:02.64, bitrate: 256 kb/s Duration: 00:01:37.96, bitrate: 256 kb/s Duration: 00:01:40.62, bitrate: 256 kb/s Duration: 00:01:51.60, bitrate: 256 kb/s Duration: 00:02:05.76, bitrate: 256 kb/s Duration: 00:01:08.64, bitrate: 256 kb/s Duration: 00:01:51.54, bitrate: 256 kb/s Duration: 00:01:19.08, bitrate: 256 kb/s Duration: 00:02:02.58, bitrate: 256 kb/s Duration: 00:01:42.84, bitrate: 256 kb/s Duration: 00:01:52.02, bitrate: 256 kb/s Duration: 00:01:15.42, bitrate: 256 kb/s Duration: 00:01:53.58, bitrate: 256 kb/s Duration: 00:01:15.68, bitrate: 256 kb/s Duration: 00:02:07.92, bitrate: 256 kb/s Duration: 00:01:56.10, bitrate: 256 kb/s Duration: 00:01:48.67, bitrate: 256 kb/s Duration: 00:01:24.42, bitrate: 256 kb/s Duration: 00:01:33.60, bitrate: 256 kb/s Duration: 00:02:18.02, bitrate: 256 kb/s Duration: 00:01:11.86, bitrate: 256 kb/s Duration: 00:01:18.66, bitrate: 256 kb/s Duration: 00:01:51.30, bitrate: 256 kb/s Duration: 00:01:32.40, bitrate: 256 kb/s Duration: 00:01:52.32, bitrate: 256 kb/s Duration: 00:00:58.62, bitrate: 256 kb/s Duration: 00:02:19.68, bitrate: 256 kb/s Duration: 00:01:20.52, bitrate: 256 kb/s Duration: 00:02:10.20, bitrate: 256 kb/s Duration: 00:02:06.78, bitrate: 256 kb/s Duration: 00:02:08.10, bitrate: 256 kb/s Duration: 00:02:51.96, bitrate: 256 kb/s Duration: 00:01:01.65, bitrate: 256 kb/s Duration: 00:01:09.72, bitrate: 256 kb/s Duration: 00:01:53.40, bitrate: 256 kb/s Duration: 00:01:26.34, bitrate: 256 kb/s Duration: 00:01:44.88, bitrate: 256 kb/s Duration: 00:02:13.56, bitrate: 256 kb/s Duration: 00:01:58.80, bitrate: 256 kb/s Duration: 00:01:48.62, bitrate: 256 kb/s Duration: 00:02:03.54, bitrate: 256 kb/s Duration: 00:01:46.02, bitrate: 256 kb/s Duration: 00:01:03.60, bitrate: 256 kb/s Duration: 00:01:36.38, bitrate: 256 kb/s Duration: 00:01:19.98, bitrate: 256 kb/s Duration: 00:01:15.00, bitrate: 256 kb/s Duration: 00:01:47.04, bitrate: 256 kb/s Duration: 00:00:59.64, bitrate: 256 kb/s Duration: 00:01:34.02, bitrate: 256 kb/s Duration: 00:01:39.06, bitrate: 256 kb/s Duration: 00:02:23.64, bitrate: 256 kb/s Duration: 00:01:49.74, bitrate: 256 kb/s Duration: 00:01:50.68, bitrate: 256 kb/s Duration: 00:02:03.84, bitrate: 256 kb/s Duration: 00:01:40.62, bitrate: 256 kb/s Duration: 00:01:47.58, bitrate: 256 kb/s Duration: 00:00:54.18, bitrate: 256 kb/s Duration: 00:01:37.68, bitrate: 256 kb/s Duration: 00:01:22.24, bitrate: 256 kb/s Duration: 00:00:54.54, bitrate: 256 kb/s Duration: 00:01:37.74, bitrate: 256 kb/s Duration: 00:02:02.22, bitrate: 256 kb/s Duration: 00:01:38.64, bitrate: 256 kb/s Duration: 00:01:32.88, bitrate: 256 kb/s Duration: 00:02:04.14, bitrate: 256 kb/s Duration: 00:01:05.56, bitrate: 256 kb/s Duration: 00:01:53.58, bitrate: 256 kb/s Duration: 00:01:59.76, bitrate: 256 kb/s Duration: 00:01:21.54, bitrate: 256 kb/s Duration: 00:01:54.10, bitrate: 256 kb/s Duration: 00:01:59.88, bitrate: 256 kb/s Duration: 00:00:29.94, bitrate: 256 kb/s Duration: 00:01:24.86, bitrate: 256 kb/s Duration: 00:01:20.82, bitrate: 256 kb/s Duration: 00:01:58.20, bitrate: 256 kb/s Duration: 00:01:15.96, bitrate: 256 kb/s Duration: 00:01:53.28, bitrate: 256 kb/s Duration: 00:01:05.94, bitrate: 256 kb/s Duration: 00:01:20.34, bitrate: 256 kb/s Duration: 00:01:53.88, bitrate: 256 kb/s Duration: 00:02:10.80, bitrate: 256 kb/s Duration: 00:00:56.76, bitrate: 256 kb/s Duration: 00:01:32.88, bitrate: 256 kb/s Duration: 00:01:01.92, bitrate: 256 kb/s Duration: 00:01:49.38, bitrate: 256 kb/s Duration: 00:01:19.14, bitrate: 256 kb/s Duration: 00:00:54.48, bitrate: 256 kb/s Duration: 00:01:31.26, bitrate: 256 kb/s Duration: 00:01:35.22, bitrate: 256 kb/s Duration: 00:01:08.40, bitrate: 256 kb/s Duration: 00:02:02.40, bitrate: 256 kb/s Duration: 00:01:19.14, bitrate: 256 kb/s Duration: 00:02:09.30, bitrate: 256 kb/s Duration: 00:01:27.62, bitrate: 256 kb/s Duration: 00:01:59.46, bitrate: 256 kb/s Duration: 00:02:50.64, bitrate: 256 kb/s Duration: 00:00:47.76, bitrate: 256 kb/s Duration: 00:01:31.92, bitrate: 256 kb/s Duration: 00:01:13.44, bitrate: 256 kb/s Duration: 00:01:23.22, bitrate: 256 kb/s Duration: 00:01:31.74, bitrate: 256 kb/s Duration: 00:01:43.16, bitrate: 256 kb/s Duration: 00:01:29.64, bitrate: 256 kb/s Duration: 00:02:13.62, bitrate: 256 kb/s Duration: 00:02:01.80, bitrate: 256 kb/s Duration: 00:02:21.18, bitrate: 256 kb/s Duration: 00:01:55.92, bitrate: 256 kb/s Duration: 00:01:03.00, bitrate: 256 kb/s Duration: 00:01:29.82, bitrate: 256 kb/s Duration: 00:01:42.00, bitrate: 256 kb/s Duration: 00:02:18.78, bitrate: 256 kb/s Duration: 00:01:40.80, bitrate: 256 kb/s Duration: 00:02:55.74, bitrate: 256 kb/s Duration: 00:01:28.08, bitrate: 256 kb/s Duration: 00:01:57.78, bitrate: 256 kb/s Duration: 00:01:58.38, bitrate: 256 kb/s Duration: 00:01:12.00, bitrate: 256 kb/s .",
            "url": "https://jimregan.github.io/notes/asr/polish/kaggle/2021/06/16/poleval-2021-durations.html",
            "relUrl": "/asr/polish/kaggle/2021/06/16/poleval-2021-durations.html",
            "date": " ‚Ä¢ Jun 16, 2021"
        }
        
    
  
    
        ,"post63": {
            "title": "Irish Texts from South West Donegal, Abair comparison.",
            "content": "The table below compares the transcription of Texts 1 &amp; 2: (‚ÄúPoit√≠n‚Äù and ‚ÄúAn mh√≥in‚Äù) from O‚ÄôNeill‚Äôs1 ‚ÄúIrish Texts from South West Donegal‚Äù, comparing it with Abair‚Äôs transcription. . Texts 1‚Äî4 were contributed by Seamus √ì Beirn (Jim Phat James), aged c. 70 years, cobbler, from the townland of M√≠n na Gaoithe, Teelin. . A special feature of his speech is the clearness and strength of the affricates t‚Ä≤ É and d‚Ä≤ í due to the deliberate manner in which each word is enunciated. . The phonetic rules were mostly to help with automatic comparison, though the places where verb froms were pronounced differently before a pronoun was interesting enough to note. . Original Transcript Abair G2P Abair source Adjusted word (standardised) Adjusted Abair Rule . a | ¬† | …ô | l | ¬† | ¬† | …ô ‚Üí ‚àÖ / v # _ | . a | √® | …ô | l | ¬† | ¬† | ¬† | . a | …ô | …ô | l | ¬† | ¬† | ¬† | . a | ·µä | …ô | l | ¬† | ¬† | ¬† | . ach | …ëx | Ààah | l | ¬† | ¬† | ¬† | . ac√∫ | …îku | ÀàakÀ†uÀê | ¬† | acu | akÀ†u | ¬† | . adharc | Ààne:rk | ÀàeÀê…æÀ†kÀ† | l | ¬† | ¬† | ¬† | . ag | …ô | Ààe…ü | l | ¬† | ¬† | …ü ‚Üí ‚àÖ / _ # [+stop] | . ag | …™g‚Ä≤ | Ààe…ü | l | ¬† | ¬† | ¬† | . againn | ÀàŒµiŒΩ‚Ä≤ | Àà…ôgÀ†…ô…¥ ≤ | l | ¬† | ¬† | ¬† | . agamsa | √®ims…ô | Àà…ôgÀ†…ômÀ†sÀ†…ô | l | ¬† | ¬† | ¬† | . agat | √®it | Àà…ôgÀ†…ôtÀ† | l | ¬† | ¬† | ¬† | . agat | …õit | Àà…ôgÀ†…ôtÀ† | l | ¬† | ¬† | ¬† | . agat | …õj…ôd | Àà…ôgÀ†…ôtÀ† | l | ¬† | ¬† | ¬† | . agus | og…ôs | ÀàagÀ†…ôsÀ† | l | ¬† | ¬† | ¬† | . agus | …îgas | ÀàagÀ†…ôsÀ† | l | ¬† | ¬† | ¬† | . agus | …îges | ÀàagÀ†…ôsÀ† | l | ¬† | ¬† | ¬† | . agus | …îg…ôs | ÀàagÀ†…ôsÀ† | l | ¬† | ¬† | ¬† | . aige | …õg‚Ä≤…ô | Ààe…ü…ô | l | ¬† | ¬† | ¬† | . air | er‚Ä≤ î | Ààe…æ ≤ | l | ¬† | ¬† | ¬† | . air | √®r‚Ä≤ | Ààe…æ ≤ | l | ¬† | ¬† | ¬† | . air | …õr‚Ä≤ | Ààe…æ ≤ | l | ¬† | ¬† | ¬† | . am | Ààn…ëm | ÀàamÀ† | l | ¬† | ¬† | ¬† | . amach | …ôÀàmax | …ôÀàmÀ†ah | l | ¬† | ¬† | ¬† | . amach | …ôÀàm…ëh | …ôÀàmÀ†ah | l | ¬† | ¬† | ¬† | . amach | …ôÀàm…ëx | …ôÀàmÀ†ah | l | ¬† | ¬† | ¬† | . an | n | Àà…ô…¥À† | l | ¬† | ¬† | …ô ‚Üí ‚àÖ / v # _ | . an | nÃ• | Àà…ô…¥À† | l | ¬† | ¬† | …ô ‚Üí ‚àÖ / v # _ | . an | …ô | Àà…ô…¥À† | l | ¬† | ¬† | ¬† | . ann | oÃ§n | Ààa…¥À† | l | ¬† | ¬† | ¬† | . annsin | nÃ•Àà É…™n‚Ä≤ | ÀàaÀà…¥ ≤ Éin ≤ | ¬† | ansin | …ô…¥À†Àà Éin ≤ | …ô ‚Üí ‚àÖ / v # _ | . annsin | Àà É…™n‚Ä≤ | ÀàaÀà…¥ ≤ Éin ≤ | ¬† | ¬† | ¬† | ¬† | . anois | (…ô)Ààn…™ É | …ôÀà…¥À†i É | l | ¬† | ¬† | ¬† | . aon | e:Ààn | ÀàeÀê…¥À† | l | ¬† | ¬† | ¬† | . ar | …ô | Ààe…æ ≤ | l | ¬† | ¬† | ¬† | . ar | …ôr | Ààe…æ ≤ | l | ¬† | ¬† | ¬† | . ar | …õr | Ààe…æ ≤ | l | ¬† | ¬† | ¬† | . arais | …ôÀàra É | Ààa…æÀ†…ô É | ¬† | ar ais | Ààe…æ ≤ Ààa É | ¬† | . araist | …ôÀàra Éd‚Ä≤ | Ààa…æÀ†…ô Ét ≤ | ¬† | ar ais | Ààe…æ ≤ Ààa É | ¬† | . arma√≠ | Àà…ërm ∑i | Ààa…æÀ†…ômÀ†iÀê | ¬† | ¬† | ¬† | ¬† | . as | iÃàs | ÀàasÀ† | l | ¬† | ¬† | ¬† | . astoigh | …ôÀàsdih î | ÀàasÀ†tÀ†…ô | ¬† | istigh | isÀ†ÀàtÀ†ij | ¬† | . astoigh | …ôÀà Édih î | ÀàasÀ†tÀ†…ô | ¬† | istigh | isÀ†ÀàtÀ†ij | ¬† | . at√° | …ô | …ôÀàtÀ†aÀê | l | ¬† | ¬† | ¬† | . at√° | …ôt…ë: | …ôÀàtÀ†aÀê | l | ¬† | ¬† | ¬† | . at√° | Ààt…ë: | …ôÀàtÀ†aÀê | l | ¬† | ¬† | ¬† | . ba | boÃ§ | ÀàbÀ†…ô | l | ¬† | ¬† | ¬† | . ba √© | byje: | ÀàbÀ†…ô ÀàeÀê | l | ¬† | ¬† | ¬† | . bachtadh | Ààb…ëxdu | ÀàbÀ†a…æÀ†tÀ†uÀê | ¬† | bachta | ÀàbÀ†a…æÀ†tÀ†…ô | ¬† | . barraille | Ààb…ër…ôl‚Ä≤…ô | ÀàbÀ†aÀêÀà…æÀ†a ü ≤…ô | ¬† | bairille | ÀàbÀ†a…æ ≤ ü ≤…ô | ¬† | . barraill√≠ | Ààb…ër…ôl‚Ä≤i | ÀàbÀ†aÀêÀà…æÀ†a ü ≤iÀê | ¬† | bairill√≠ | ÀàbÀ†a…æ ≤…ô ü ≤iÀê | ¬† | . basc√≥id | Ààb…ësg…îd‚Ä≤·∂æ | ÀàbÀ†asÀ†kÀ†…îd ≤ | ¬† | bascaed | ÀàbÀ†asÀ†kÀ†edÀ† | ¬† | . beach√≥g | Ààb‚Ä≤ah…îg | Ààb ≤ah…îgÀ† | ¬† | ¬† | ¬† | ¬† | . beag | Ààb‚Ä≤√∏g | Ààb ≤ogÀ† | l | ¬† | ¬† | ¬† | . bealtaine | Ààb‚Ä≤a:lt…™n‚Ä≤…ô | Ààb ≤o üÀ†tÀ†…ôn ≤…ô | l | ¬† | ¬† | ¬† | . bhachta | Ààw…ëxd…ô | Ààwa…æÀ†tÀ†…ô | l+m | ¬† | ¬† | ¬† | . bhachtadh | Ààw…ëxdu | Ààwa…æÀ†tÀ†uÀê | ¬† | bhachta | ¬† | ¬† | . bhaint | w√Ø‚Ä≤nt | Ààwan ≤t ≤ | l | ¬† | ¬† | ¬† | . bharraille | Ààw…ër…ôl‚Ä≤…ô | ÀàwaÀêÀà…æÀ†a ü ≤…ô | ¬† | bhairille | Ààwa…æ ≤ ü ≤…ô | ¬† | . bheireadh | v…õr‚Ä≤…ôd‚Ä≤ | Ààv ≤e…æ ≤uÀê | l | ¬† | ¬† | &lt;eadh&gt; ‚Üí …ôd ≤ / _ # pronoun | . bhfaghaidh | Ààw…ë: | ÀàweÀêiÀê | ¬† | bhfaighidh | ÀàwiÀê | ¬† | . bhfeiceadh | Ààv…õk‚Ä≤u | Ààv ≤ecuÀê | ¬† | ¬† | ¬† | ¬† | . bhfosclaidh | Ààw…îsgli | ÀàwoÀàsÀ†kÀ† üÀ†eÀê | ¬† | bhfoscla√≠ | ÀàwoÀàsÀ†kÀ† üÀ†iÀê | ¬† | . bhfuil | Ààwil‚Ä≤ | Ààwil ≤ | l | ¬† | ¬† | ¬† | . bhinn | ÀàŒΩ√ØŒΩ‚Ä≤ | Ààv ≤i…¥ ≤ | l | ¬† | ¬† | ¬† | . bhraich | Ààvreih î | Ààw…æÀ†a√ß | l+m | ¬† | ¬† | ¬† | . bhun | ÀàwoÃ§n | Ààwu…¥À† | l | ¬† | ¬† | ¬† | . bh√©adh | v…õuw | Ààv ≤eÀê…£ | ¬† | ¬† | ¬† | ¬† | . bh√©arfaidh | verh…ô | Ààv ≤eÀê…æÀ†hiÀê | l | ¬† | ¬† | ¬† | . bh√©arfaidh | v√®rh…ô | Ààv ≤eÀê…æÀ†hiÀê | l | ¬† | ¬† | ¬† | . bh√©arfaidh | v…õ:rh…ô | Ààv ≤eÀê…æÀ†hiÀê | l | ¬† | ¬† | ¬† | . bh√©arfaidh | v…õrh…ô | Ààv ≤eÀê…æÀ†hiÀê | l | ¬† | ¬† | ¬† | . bh√≠ | vi: | Ààv ≤iÀê | l | ¬† | ¬† | ¬† | . bh√≠odh | vi:d‚Ä≤ | Ààv ≤iÀêuÀê | l | ¬† | ¬† | &lt;odh&gt; ‚Üí (…ô)d ≤ / _ # pronoun | . bh√≠odh | viuw | Ààv ≤iÀêuÀê | l | ¬† | ¬† | ¬† | . binn | Ààb‚Ä≤√Øn‚Ä≤ | Ààb ≤i…¥ ≤ | l | ¬† | ¬† | ¬† | . bith | Ààb‚Ä≤i | Ààb ≤iÀê | l | ¬† | ¬† | ¬† | . bladhaire | Ààbl·¥áir‚Ä≤…ô | ÀàbÀ† üÀ†eÀê…æ ≤…ô | l | ¬† | ¬† | ¬† | . bocsa | ÀàboÃ§ks | ÀàbÀ†okÀ†sÀ†…ô | ¬† | bosca | ÀàbÀ†okÀ†sÀ†…ô | ¬† | . bracha | Ààbr…ëx…ô | ÀàbÀ†…æÀ†ah…ô | ¬† | braiche | ÀàbÀ†…æÀ†a√ß…ô | ¬† | . briste | Ààb‚Ä≤r‚Ä≤√Ø Éd‚Ä≤…ô | Ààb ≤…æ ≤i Ét ≤…ô | l | ¬† | ¬† | ¬† | . bruach | Ààbri:x | ÀàbÀ†…æÀ†uah | l | ¬† | ¬† | ¬† | . bruach | Ààbry…ôx | ÀàbÀ†…æÀ†uah | l | ¬† | ¬† | ¬† | . br√≥inte | Ààbr…î:n‚Ä≤t‚Ä≤…ô | ÀàbÀ†…æÀ†oÀên ≤t ≤…ô | ¬† | br√≥nna | bÀ†…æÀ†oÀê…¥À†…ô | ¬† | . b√°rr | Ààb…ë:r | ÀàbÀ†aÀê…æÀ† | ¬† | barr | ÀàbÀ†aÀê…æÀ† | ¬† | . caid√© | g…ôÀàd‚Ä≤·∂æe: | kÀ†…ôÀàd ≤eÀê | l | ¬† | ¬† | ¬† | . cailleadh | Ààkal‚Ä≤l‚Ä≤u | ÀàkÀ†a ü ≤uÀê | l | ¬† | ¬† | ¬† | . caithfidh | Ààkaih…™ | ÀàkÀ†ahjiÀê | l | ¬† | ¬† | ¬† | . caithfidh | Ààk…ëihi | ÀàkÀ†ahjiÀê | l | ¬† | ¬† | ¬† | . caithfidh | Ààk…ëih…™ | ÀàkÀ†ahjiÀê | l | ¬† | ¬† | ¬† | . caithte | ÀàkoÃ§t‚Ä≤·∂¥…ô | ÀàkÀ†aht ≤…ô | ¬† | caite | ÀàkÀ†at ≤…ô | ¬† | . ceig | Ààk‚Ä≤√®g‚Ä≤ | Ààce…ü | ¬† | ¬† | ¬† | ¬† | . ce√≥l | Ààk‚Ä≤ ≤…î:l | ÀàcoÀê üÀ† | ¬† | ceol | ÀàcoÀê üÀ† | ¬† | . chaith | Ààx…ëih | Ààxahj | l | ¬† | ¬† | ¬† | . chaitheamh | Ààx…ëhu | ÀàxahjuÀê | l | ¬† | ¬† | ¬† | . cheann | Ààx‚Ä≤oÃ§n | Àà√ßi…¥À† | l | ¬† | ¬† | ¬† | . cheig | Ààx‚Ä≤…õg‚Ä≤ | Àà√ße…ü | ¬† | ¬† | ¬† | ¬† | . cheithre | Ààx‚Ä≤…õr‚Ä≤…ô | Ààxe…æ ≤…ô | l | ¬† | ¬† | ¬† | . chiadhna | Ààx‚Ä≤i…ôn…ô | Àà√ßi…ô…£…¥À†…ô | ¬† | ch√©anna | Àà√ßeÀê…æÀ†…¥À†…ô | ¬† | . chiall | Ààx‚Ä≤i:…ôl | Àà√ßia üÀ† | l | ¬† | ¬† | ¬† | . chionn | x‚Ä≤oÃ§n | Àà√ßi…¥À† | l+m | ¬† | ¬† | ¬† | . chor | Ààx…îr | Ààxa…æÀ† | l | ¬† | ¬† | ¬† | . chuireadh | xoÃ§r‚Ä≤…ôd‚Ä≤ | Ààxu…æ ≤uÀê | l | ¬† | ¬† | &lt;eadh&gt; ‚Üí …ôd ≤ / _ # pronoun | . chuireas | ÀàxoÃ§r‚Ä≤…ôs | Ààxu…æ ≤…ôsÀ† | l | ¬† | ¬† | ¬† | . chur | ÀàxoÃ§r | Ààxu…æÀ† | l | ¬† | ¬† | ¬† | . ch√©ad | Ààx‚Ä≤e(:)d | Àà√ßeÀêdÀ† | l | ¬† | ¬† | ¬† | . clampa√≠ | Ààkl…ëmbi | ÀàkÀ† üÀ†amÀ†pÀ†iÀê | ¬† | ¬† | ¬† | ¬† | . crapanna√≠ | Ààkr…ëp…ôni | ÀàkÀ†…æÀ†apÀ†…ô…¥À†iÀê | ¬† | ¬† | ¬† | ¬† | . croiceann | Ààkr…õk‚Ä≤…ôn | ÀàkÀ†…æÀ†oc…ô…¥À† | ¬† | craiceann | ÀàkÀ†…æÀ†ac…ô…¥À† | ¬† | . cruacha | Ààkru…ôx | ÀàkÀ†…æÀ†u…ôÀàxa | ¬† | ¬† | ¬† | ¬† | . cruachta | Ààkru…ôxd…ô | ÀàkÀ†…æÀ†u…ôÀà…æÀ†tÀ†a | ¬† | ¬† | ¬† | ¬† | . cr√≥ige√°in | Ààkr…î:·µäg‚Ä≤…ôn‚Ä≤ | ÀàkÀ†…æÀ†oÀê…üaÀên ≤ | ¬† | gr√≥ige√°in | ÀàgÀ†…æÀ†oÀê…üaÀên ≤ | ¬† | . cr√≥igfidh | Ààkr…î:·µäk‚Ä≤…ô | ÀàkÀ†…æÀ†oÀê…üiÀê | ¬† | gr√≥igfidh | ÀàgÀ†…æÀ†oÀê…üiÀê | ¬† | . cubhar | Ààku:r | ÀàkÀ†uw…ô…æÀ† | ¬† | c√∫r | ÀàkÀ†uÀê…æÀ† | ¬† | . cumhdach | Ààku:d…ëx | ÀàkÀ†uÀêdÀ†ah | l | ¬† | ¬† | ¬† | . cur | ÀàkoÃ§r | ÀàkÀ†u…æÀ† | l | ¬† | ¬† | ¬† | . c√°ithte | Ààka:t‚Ä≤ É…ô | ÀàkÀ†aÀêht ≤…ô | ¬† | c√°ite | kÀ†aÀêt ≤…ô | ¬† | . d‚Äôfh√°sfadh | d…ë:sh…ôd‚Ä≤ | ÀàdÀ†aÀêsÀ†uÀê | ¬† | ¬† | ¬† | &lt;adh&gt; ‚Üí …ôd ≤ / _ # pronoun | . dabhach | Ààd…îu ∑…ëx | ÀàdÀ†auh | l | ¬† | ¬† | ¬† | . daoithe | di: ∞…ô | ÀàdÀ†iÀêh…ô | ¬† | di | ÀàdÀ†i | ¬† | . daoithe | dih…ô | ÀàdÀ†iÀêh…ô | ¬† | di | ÀàdÀ†i | ¬† | . dara | Ààd…ër…ô | ÀàdÀ†a…æÀ†…ô | l | ¬† | ¬† | ¬† | . de‚Äôn | …în | ÀàdÀ†enÀ† | l | ¬† | ¬† | d ‚Üí ‚àÖ / t # _ | . deasach | Ààd‚Ä≤·∂æas…ëx | Ààd ≤asÀ†ah | l | ¬† | ¬† | ¬† | . den | d…î | ÀàdÀ†enÀ† | l | ¬† | ¬† | ¬† | . den | d…în | ÀàdÀ†enÀ† | l | ¬† | ¬† | ¬† | . dh‚Äôfh√°s | Àà…£…ë:s | Àà…£aÀêsÀ† | ¬† | d‚Äôfh√°s | ÀàdÀ†aÀêsÀ† | ¬† | . dh√° | Àà…£…ë: | Àà…£aÀê | l | ¬† | ¬† | ¬† | . dh√©anamh | Ààja:nu | ÀàjeÀê…¥À†uÀê | l | ¬† | ¬† | ¬† | . dh√©anfaidh | ja:nh…ô | Àà…£eÀê…¥À†hiÀê | l | ¬† | ¬† | ¬† | . dh√©in | Ààje:n‚Ä≤ | ÀàjeÀên ≤ | l+m | ¬† | ¬† | ¬† | . do | d…î | ÀàdÀ†…ô | l | ¬† | ¬† | ¬† | . domh | du | ÀàdÀ†uÀê | l | ¬† | ¬† | ¬† | . dorga | Ààd…îr…ôg…ô | ÀàdÀ†oÀà…æÀ†gÀ†a | ¬† | dor√∫ | ÀàdÀ†o…æÀ†uÀê | ¬† | . dtaobh | du: | Ààd ≤iÀêw | l | ¬† | ¬† | ¬† | . dtig | Ààd‚Ä≤…™g‚Ä≤ | Ààd ≤i…ü | l | ¬† | ¬† | ¬† | . dtig | Ààd‚Ä≤·∂æ…™g‚Ä≤ | Ààd ≤i…ü | l | ¬† | ¬† | ¬† | . dtiocfadh | d‚Ä≤·∂æoÃ§ku | Ààd ≤okÀ†uÀê | l | ¬† | ¬† | ¬† | . dtiocfadh | d‚Ä≤·∂æoÃ§ku | Ààd ≤okÀ†uÀê | l | ¬† | ¬† | ¬† | . dtugadh | doÃ§g…ôd‚Ä≤ | ÀàdÀ†ugÀ†uÀê | l+m | ¬† | ¬† | &lt;adh&gt; ‚Üí …ôd ≤ / _ # pronoun | . dt√©ighidh | Ààd‚Ä≤·∂æe:·µä | Ààd ≤eÀêjiÀê | ¬† | dt√© | Ààd ≤eÀê | ¬† | . dt√≠ | Ààd í‚Ä≤i: | Ààd ≤iÀê | l | ¬† | ¬† | ¬† | . dt√≠ | Ààd‚Ä≤ íi: | Ààd ≤iÀê | l | ¬† | ¬† | ¬† | . dt√≥lamh | Ààd…î:luw | ÀàdÀ†oÀê üÀ†uÀê | l+m | ¬† | ¬† | ¬† | . dt√≥lamh | Ààd…î:l…ôf‚Ä≤ | ÀàdÀ†oÀê üÀ†uÀê | l+m | ¬† | ¬† | ¬† | . duine | Ààd…™n‚Ä≤ | ÀàdÀ†in ≤…ô | l | ¬† | ¬† | …ô ‚Üí ‚àÖ / _ # v | . d√≥igh | d…î:i | ÀàdÀ†oÀêj | l | ¬† | ¬† | ¬† | . d√≥igh | Ààd…î:i | ÀàdÀ†oÀêj | l | ¬† | ¬† | ¬† | . d√≥rtadh | Ààd…î:rtu | ÀàdÀ†oÀêÀà…æÀ†tÀ†eÀê | ¬† | doirteadh | ÀàdÀ†o…æÀ†t ≤uÀê | ¬† | . eagla | √∏gl…ô | ÀàogÀ† üÀ†…ô | l | ¬† | ¬† | ¬† | . eile | Àà…õl‚Ä≤i: | Ààel ≤…ô | l | ¬† | ¬† | ¬† | . eile | Œµl‚Ä≤…ô | Ààel ≤…ô | l | ¬† | ¬† | ¬† | . e√≥rna | Ààn‚Ä≤…î:rn | ÀàoÀê…æÀ†…¥À†…ô | ¬† | eorna | ÀàoÀê…æÀ†…¥À†…ô | …ô ‚Üí ‚àÖ / _ # v | . e√≥rna | Ààn‚Ä≤…î:rn…ô | ÀàoÀê…æÀ†…¥À†…ô | ¬† | ¬† | ¬† | ¬† | . e√≥rna | Ààn‚Ä≤…î:rn…ô | ÀàoÀê…æÀ†…¥À†…ô | ¬† | eorna | ÀàoÀê…æÀ†…¥À†…ô | ¬† | . fad | f…ëd | ÀàfÀ†adÀ† | l | ¬† | ¬† | ¬† | . faoi | f ∑i | ÀàfÀ†iÀê | l | ¬† | ¬† | ¬† | . faoin | f ∑i:n | ÀàfÀ†in ≤ | l | ¬† | ¬† | ¬† | . fhad | ad | ÀàadÀ† | l | ¬† | ¬† | ¬† | . fhad | Àà…ëd | ÀàadÀ† | l | ¬† | ¬† | ¬† | . fhios | iÃàs | ÀàisÀ† | l | ¬† | ¬† | ¬† | . fh√©il | l‚Ä≤ | ÀàeÀêl ≤ | l | ¬† | ¬† | ¬† | . fh√≥d | o:d | ÀàoÀêdÀ† | l+m | ¬† | ¬† | ¬† | . fichead | Ààf‚Ä≤ih…ôd | Ààf ≤ihj…ôdÀ† | l | ¬† | ¬† | ¬† | . fiog | Ààf‚Ä≤√∏g | Ààf ≤igÀ† | ¬† | ¬† | ¬† | ¬† | . fuar | Ààfy…ôr | ÀàfÀ†ia…æÀ† | l | ¬† | ¬† | ¬† | . f√° | f…ë | ÀàfÀ†aÀê | l | ¬† | ¬† | ¬† | . f√°gfaidh | Ààf…ë:kh…ô | ÀàfÀ†aÀêgÀ†h…ô | l | ¬† | ¬† | ¬† | . f√°gfaidh | Ààf…ë:k…ô | ÀàfÀ†aÀêgÀ†h…ô | l | ¬† | ¬† | ¬† | . f√°g√°il | Ààf…ë:g…ël‚Ä≤ | ÀàfÀ†aÀêgÀ†al ≤ | l | ¬† | ¬† | ¬† | . f√≥d | Ààfo:d | ÀàfÀ†oÀêdÀ† | l | ¬† | ¬† | ¬† | . gabh√°il | g…îl‚Ä≤ | ÀàgÀ†ol ≤ | l | ¬† | ¬† | ¬† | . gcionn | g‚Ä≤oÃ§n | Àà…üo…¥À† | l | ¬† | ¬† | ¬† | . gclocha | gloÃ§h…ô | ÀàgÀ† üÀ†ah…ô | l+m | ¬† | ¬† | ¬† | . gconnadae | ÀàgoÃ§ndei | ÀàgÀ†o…¥À†…ôdÀ†eÀê | ¬† | gcontae | ÀàgÀ†…ô…¥À†ÀàtÀ†e | ¬† | . gcruachaidh | Ààgru…ôx…ô | ÀàgÀ†…æÀ†u…ôÀàxeÀê | ¬† | gcruacha | ÀàgÀ†…æÀ†u…ôÀàxa | ¬† | . ge√°rradh | Ààg‚Ä≤…ë:ru | Àà…üaÀê…æÀ†uÀê | ¬† | gearradh | Àà…üa…æÀ†uÀê | ¬† | . ge√°rraidh | Ààg‚Ä≤…ë:ri | Àà…üaÀê…æÀ†iÀê | ¬† | gearra | Àà…üa…æÀ†…ô | ¬† | . ge√°rrfaidh | Ààg‚Ä≤…ë:rh…ô | Àà…üaÀê…æÀ†iÀê | ¬† | gearrfaidh | Àà…üa…æÀ†iÀê | ¬† | . ge√°rrtha | Ààg‚Ä≤…ë:rh…ô | Àà…üaÀê…æÀ†h…ô | ¬† | gearrtha | Àà…üaÀê…æÀ†Ààha | ¬† | . ghabh√°il | Àà…£…î(:)l‚Ä≤ | Àà…£ol ≤ | l | ¬† | ¬† | ¬† | . gheimhridh | Ààj…õvr‚Ä≤i | Ààjiv ≤…æ ≤i | l | ¬† | ¬† | ¬† | . ghe√°rradh | Ààj…ë:ru | ÀàjaÀê…æÀ†uÀê | ¬† | ghearradh | Ààja…æÀ†uÀê | ¬† | . ghlas | Àà…£l…ës | Àà…£ üÀ†asÀ† | l | ¬† | ¬† | ¬† | . ghoirid | Àà…£oÃ§r‚Ä≤id‚Ä≤·∂æ | Àà…£o…æ ≤…ôd ≤ | ¬† | ¬† | ¬† | ¬† | . ghrian | Ààj·µär‚Ä≤i…ôn | Àà…£…æ ≤ia…¥À† | l | ¬† | ¬† | ¬† | . gloine | Ààgl√∂n‚Ä≤…ô | ÀàgÀ† üÀ†in ≤…ô | l | ¬† | ¬† | ¬† | . go | go | ÀàgÀ†…ô | l | ¬† | ¬† | ¬† | . go | g…î | ÀàgÀ†…ô | l | ¬† | ¬† | ¬† | . go | g…ô | ÀàgÀ†…ô | l | ¬† | ¬† | ¬† | . goid√© | g…ôÀàd‚Ä≤·∂æe: | ÀàgÀ†…ôd ≤eÀê | l | ¬† | ¬† | ¬† | . grian | Ààg‚Ä≤r‚Ä≤i…ôn | Àà…ü…æ ≤ia…¥À† | l | ¬† | ¬† | ¬† | . g√©ar | Ààg‚Ä≤…õ:·µär | Àà…üeÀê…æÀ† | l | ¬† | ¬† | ¬† | . g√©arrfaidh | Ààg‚Ä≤…ë:rh…ô | Àà…üeÀêÀà…æÀ†eÀê | ¬† | gearrfaidh | Àà…üa…æÀ†iÀê | ¬† | . h-√°irid | Ààha:rid‚Ä≤·∂æ | ÀàhaÀê…æ ≤…ôd ≤ | ¬† | h√°irithe | ÀàhaÀê…æ ≤ihj…ô | ¬† | . h-√°iteacha | Ààha:n‚Ä≤t‚Ä≤ah…ô | ÀàhaÀêt ≤…ôh…ô | h-√°iteacha | ¬† | ¬† | ¬† | . h-√© | h√® | ÀàheÀê | l+m | ¬† | ¬† | ¬† | . huaire | Ààhu…ôr‚Ä≤…ô | Ààhua…æ ≤…ô | l | ¬† | ¬† | ¬† | . i | ¬† | Àài | l | ¬† | ¬† | ¬† | . i | …ô | Àài | l | ¬† | ¬† | ¬† | . iad | i…ôd | ÀàiadÀ† | l | ¬† | ¬† | ¬† | . iad | …ôd | ÀàiadÀ† | l | ¬† | ¬† | ¬† | . ina | n…ô | Àài…¥À†…ô | l | ¬† | ¬† | ¬† | . ina | …ôŒΩ…ô | Àài…¥À†…ô | l | ¬† | ¬† | ¬† | . innse | iÃàŒΩ‚Ä≤ É…ô | ÀàiÀà…¥ ≤ Ée | ¬† | insint | Àåin ≤Àà Éin ≤t ≤ | ¬† | . innt√≠ | Àà…™n‚Ä≤t‚Ä≤i | ÀàiÀà…¥ ≤t ≤iÀê | ¬† | inti | i…¥ ≤t ≤i | ¬† | . ins | nÃ•s | Ààin ≤ É | ¬† | ¬† | ¬† | ¬† | . ins | nÃ•s | Ààin ≤ É | ¬† | ¬† | ¬† | …ô ‚Üí ‚àÖ / v # _ | . ins | nÃ•s | Ààin ≤ É | ¬† | sa | ÀàsÀ†…ô | ¬† | . ins an | nÃ•s…ô | Ààin ≤ É Àà…ô…¥À† | ¬† | ¬† | ¬† | ¬† | . insa | nÃ•s…ô | Ààin ≤ÀàsÀ†…ô | ¬† | ¬† | ¬† | ¬† | . insa | nÃ•s…ô | Ààin ≤ÀàsÀ†…ô | ¬† | sa | ÀàsÀ†…ô | ¬† | . isteach | …ôÀà Éd‚Ä≤ah | i ÉÀàt ≤ah | l | ¬† | ¬† | ¬† | . isteach | …ôÀà Éd‚Ä≤ax | i ÉÀàt ≤ah | l | ¬† | ¬† | ¬† | . le | l‚Ä≤…õ | Ààl ≤e | l | ¬† | ¬† | ¬† | . leagfaidh | Ààl‚Ä≤oÃ§kh…ô | Àà ü ≤agÀ†iÀê | ¬† | ¬† | ¬† | ¬† | . leat | l‚Ä≤at | Ààl ≤atÀ† | l | ¬† | ¬† | ¬† | . leis | l‚Ä≤e É | Ààl ≤i É | l | ¬† | ¬† | ¬† | . leis | l‚Ä≤…õ | Ààl ≤i É | l | ¬† | ¬† |  É ‚Üí ‚àÖ / _ #  É | . leithead | Ààl‚Ä≤…õh…ôd | Àà ü ≤aihj…ôdÀ† | l | ¬† | ¬† | ¬† | . lena | l‚Ä≤…õn…ô | Ààl ≤e…¥À†…ô | l | ¬† | ¬† | ¬† | . le√≥fa | l‚Ä≤…î:f…ô | Àà ü ≤oÀêfÀ†…ô | ¬† | leo | Ààl ≤o | ¬† | . lomadh | ÀàloÃ§mu | Àà üÀ†omÀ†uÀê | l | ¬† | ¬† | ¬† | . lomta | ÀàloÃ§mt | Àà üÀ†omÀ†tÀ†…ô | ¬† | ¬† | ¬† | ¬† | . l√° | Ààl…ë: | Àà üÀ†aÀê | l | ¬† | ¬† | ¬† | . l√°imhe | Ààl…ë:v…ô | Àà üÀ†aÀêv ≤…ô | l | ¬† | ¬† | ¬† | . l√°mh | Ààl…ë:w | Àà üÀ†aÀêw | l | ¬† | ¬† | ¬† | . l√°mha | Ààl…ë:w…ô | Àà üÀ†aÀêw…ô | l | ¬† | ¬† | ¬† | . l√°n | l…ë:n | Àà üÀ†aÀê…¥À† | l | ¬† | ¬† | ¬† | . l√©ithe | l‚Ä≤…õ:h…ô | Ààl ≤eÀêhj…ô | l | ¬† | ¬† | ¬† | . l√≠onadh | Ààl‚Ä≤i:n…ôd‚Ä≤ | Àà ü ≤iÀê…¥À†uÀê | l | ¬† | ¬† | ¬† | . maith | Ààm…ëi | ÀàmÀ†ahj | l | ¬† | ¬† | ¬† | . mar | moÃ§r | ÀàmÀ†a…æÀ† | l | ¬† | ¬† | ¬† | . mar‚Äôs | moÃ§≈ô≈° | Ààm_ea_er_ez_e | l | ¬† | ¬† | ¬† | . mar‚Äôs | m…ôs | ÀàmÀ†a…æÀ†sÀ† | l | ¬† | ¬† | ¬† | . marbh | Ààmaru | ÀàmÀ†a…æÀ†…ôw | l | ¬† | ¬† | ¬† | . mheileadh | v…ôl‚Ä≤h…ôd‚Ä≤ | Ààv ≤el ≤uÀê | ¬† | ¬† | ¬† | &lt;eadh&gt; ‚Üí …ôd ≤ / _ # pronoun | . mh√°rta | Ààw…ë:rt…ô | ÀàwaÀê…æÀ†tÀ†…ô | l+m | ¬† | ¬† | ¬† | . mh√≥in | Ààwo:n‚Ä≤ | ÀàwoÀên ≤ | l+m | ¬† | ¬† | ¬† | . mh√≥in | Ààwo:·µän‚Ä≤ | ÀàwoÀên ≤ | l+m | ¬† | ¬† | ¬† | . midhe | Ààm‚Ä≤i:…ô | Ààm ≤iÀê…ô | ¬† | m√≠ | Ààm ≤iÀê | ¬† | . m√° | m…ë | ÀàmÀ†a | l | ¬† | ¬† | ¬† | . m√°la | Ààm…ë:l…ô | ÀàmÀ†aÀê üÀ†…ô | l | ¬† | ¬† | ¬† | . m√≠ | Ààm‚Ä≤i: | Ààm ≤iÀê | l | ¬† | ¬† | ¬† | . m√≥in | mo:n‚Ä≤ | ÀàmÀ†oÀên ≤ | l | ¬† | ¬† | ¬† | . m√≥nadh | mo:nu | ÀàmÀ†oÀê…¥À†uÀê | l | ¬† | ¬† | ¬† | . m√≥r | Ààmo:r | ÀàmÀ†oÀê…æÀ† | l | ¬† | ¬† | ¬† | . n | n | nÀ† | l | ¬† | ¬† | ¬† | . n | nÃ• | nÀ† | l | ¬† | ¬† | ¬† | . na | n…ô | Àà…¥À†…ô | l | ¬† | ¬† | ¬† | . naoi | Ààni: | Àà…¥À†iÀê | l | ¬† | ¬† | ¬† | . ndam | Ààn…ëm ∑ | Àà…¥À†amÀ† | ¬† | ndamba | Àà…¥À†amÀ†bÀ†…ô | ¬† | . nd√©antar | Ààn‚Ä≤a:nt…ôr | Ààn ≤eÀê…¥À†tÀ†…ô…æÀ† | l | ¬† | ¬† | ¬† | . nuair | nu…ôr‚Ä≤ | Àà…¥À†uÀê…æ ≤ | l | ¬† | ¬† | ¬† | . n√° | n…ë: | Àà…¥À†aÀê | l | ¬† | ¬† | ¬† | . n√≠ | n‚Ä≤i: | Àà…¥ ≤iÀê | l | ¬† | ¬† | ¬† | . n√≠l | Ààn‚Ä≤i:l‚Ä≤ | Àà…¥ ≤iÀêl ≤ | l | ¬† | ¬† | ¬† | . n√≠odh | Ààn‚Ä≤i:w…ôd‚Ä≤ | Ààn ≤iÀêuÀê | l | ¬† | ¬† | &lt;odh&gt; ‚Üí …ôd ≤ / _ # pronoun | . n√≥ | n…ë: | Àà…¥À†oÀê | l | ¬† | ¬† | ¬† | . ocht | …îxd | ÀàaxtÀ† | l | ¬† | ¬† | ¬† | . ortha√≠ | …îrhi | ÀàoÀê…æÀ†hiÀê | ¬† | uirthi | Ààa…æÀ†hjiÀê | ¬† | . phoit√≠n | Ààfot‚Ä≤in‚Ä≤ | ÀàfÀ†ot ≤in ≤ | l+m | ¬† | ¬† | ¬† | . phoit√≠n | Ààf…ît‚Ä≤in‚Ä≤ | ÀàfÀ†ot ≤in ≤ | l+m | ¬† | ¬† | ¬† | . phortaigh | Ààf…îrti | ÀàfÀ†a…æÀ†tÀ†iÀê | l | ¬† | ¬† | ¬† | . poit√≠n | Ààp…ît‚Ä≤in‚Ä≤ | ÀàpÀ†ot ≤in ≤ | l | ¬† | ¬† | ¬† | . p√°draig | Ààp…ë:drik‚Ä≤ | ÀàpÀ†aÀêdÀ†…æÀ†…ô…ü | l | ¬† | ¬† | ¬† | . rabh | ro | Àà…æÀ†au | ¬† | raibh | Àà…æÀ†oÀêw | ¬† | . rachadh | r…ëhu | Àà…æÀ†ahuÀê | l | ¬† | ¬† | ¬† | . rachadh | r…ëh…ôd‚Ä≤ | Àà…æÀ†ahuÀê | l | ¬† | ¬† | &lt;adh&gt; ‚Üí …ôd ≤ / _ # pronoun | . rachaidh | Ààr…ëh…ô | Àà…æÀ†aÀêhij | l | ¬† | ¬† | ¬† | . raithte | Ààrat‚Ä≤ É | Àà…æÀ†aht ≤…ô | ¬† | r√°ite | Àà…æÀ†aÀêt ≤…ô | …ô ‚Üí ‚àÖ / _ # v | . rannadh | Ààr…ënhu | Àà…æÀ†a…¥À†uÀê | ¬† | roinnt | Àà…æÀ†o…¥ ≤t ≤ | ¬† | . rathaidh | nÃ•Ààrahi | Àà…æÀ†ahiÀê | ¬† | ¬† | ¬† | ¬† | . rathaidh | Ààr…ëhi | Àà…æÀ†ahiÀê | ¬† | ratha | Àà…æÀ†ah…ô | ¬† | . ricl√≠n√≠ | Ààr√Øk‚Ä≤l‚Ä≤i:n‚Ä≤i | Àà…æÀ†icl ≤iÀên ≤iÀê | ¬† | ¬† | ¬† | ¬† | . rotha | Ààr…îh | Àà…æÀ†oh…ô | ¬† | ¬† | ¬† | ¬† | . rud | roÃ§d | Àà…æÀ†udÀ† | l | ¬† | ¬† | ¬† | . rud | ÀàroÃ§d | Àà…æÀ†udÀ† | l | ¬† | ¬† | ¬† | . r√©idh | Ààre:i | Àà…æÀ†eÀêj | l | ¬† | ¬† | ¬† | . r√©ir | Ààre: | Àà…æÀ†eÀê…æ ≤ | l | ¬† | ¬† | ¬† | . r√©ir | Ààr‚Ä≤e: | Àà…æÀ†eÀê…æ ≤ | l | ¬† | ¬† | ¬† | . sa | s…ô | ÀàsÀ†…ô | l | ¬† | ¬† | ¬† | . seachtmhaine | Àà Éaxd…™n‚Ä≤…ô | Àà Éa…æÀ†tÀ†w…ôn ≤…ô | ¬† | seachtaine | Àà Éa…æÀ†tÀ†…ôn ≤…ô | ¬† | . seo |  É…î | Àà Éo | l | ¬† | ¬† | ¬† | . shoin | x…™n‚Ä≤ | ÀàhoÀàin ≤ | ¬† | shin | Ààhin ≤ | ¬† | . sh√≠olthuigheadh | Ààhi…ôlhiuw | ÀàhiÀê üÀ†h…ôjuÀê | ¬† | sh√≠othla√≠odh | ÀàhiÀêh üÀ†i…ô…£ | ¬† | . siad |  É…ôd | Àà ÉiÀêdÀ† | l | ¬† | ¬† | ¬† | . sin |  É…™n‚Ä≤ | Àà Éin ≤ | l | ¬† | ¬† | ¬† | . sin‚Äôs |  É…™n‚Ä≤s | Àà Éin ≤ É | ¬† | ¬† | ¬† | ¬† | . sioc | Àà ÉoÃ§k | Àà ÉikÀ† | l | ¬† | ¬† | ¬† | . slat | Ààsl…ët | ÀàsÀ† üÀ†atÀ† | l | ¬† | ¬† | ¬† | . sleagh√°n | Àà Él‚Ä≤a:n | Àà Él ≤a…£aÀê…¥À† | ¬† | sle√°n | Àà Él ≤aÀê…¥À† | ¬† | . spr√©idhfidh | Ààsb‚Ä≤r‚Ä≤e:f‚Ä≤…ô | ÀàsÀ†p ≤…æ ≤eÀêjiÀê | ¬† | spr√©ifidh | ÀàsÀ†p ≤…æ ≤eÀêiÀê | ¬† | . sp√°d | Ààsb…ë:d | ÀàsÀ†pÀ†aÀêdÀ† | l | ¬† | ¬† | ¬† | . sp√°d | Ààsb ∑…ë:d | ÀàsÀ†pÀ†aÀêdÀ† | l | ¬† | ¬† | ¬† | . still | Ààsd√Øl | Àà Ét ≤i ü ≤ | ¬† | ¬† | ¬† | ¬† | . st√°luighidh | Ààsd…ë:li | ÀàsÀ†tÀ†aÀê üÀ†…ôjiÀê | ¬† | st√°la√≠ | ÀàsÀ†tÀ†aÀê üÀ†iÀê | ¬† | . suas |  Éu…ôs | ÀàsÀ†uasÀ† | l | ¬† | ¬† | ¬† | . s√°bh√°ilte | Ààs…ë:w…ël‚Ä≤t‚Ä≤ | ÀàsÀ†aÀêwa ü ≤t ≤…ô | l | ¬† | ¬† | ¬† | . s√°bh√°ilte | Ààs…ë:w…ël‚Ä≤t‚Ä≤·∂¥…ô | ÀàsÀ†aÀêwa ü ≤t ≤…ô | l | ¬† | ¬† | ¬† | . s√© |  É…õ | Àà ÉeÀê | l | ¬† | ¬† | ¬† | . s√≠ | t…ë: Éi: | Àà ÉiÀê | l | ¬† | ¬† | ¬† | . s√≠ |  Éi(:) | Àà ÉiÀê | l | ¬† | ¬† | ¬† | . s√≠os | Àà Éi:s | Àà ÉiÀêsÀ† | l | ¬† | ¬† | ¬† | . s√≠os | Àà Éi·µäs | Àà ÉiÀêsÀ† | l | ¬† | ¬† | ¬† | . t-am | Ààt…ë(:)m | ÀàtÀ†aÀêmÀ† | l | ¬† | ¬† | ¬† | . t-ioml√°n | Ààt‚Ä≤·∂¥oÃ§mlan | Ààt ≤uÀêmÀ† üÀ†a…¥À† | ¬† | ¬† | ¬† | ¬† | . t-uachtar | Ààtu…ôxd…ôr | ÀàtÀ†uaxtÀ†…ô…æÀ† | l+m | ¬† | ¬† | ¬† | . t-uisce | t…™ Ég‚Ä≤…ô | ÀàtÀ†i Éc…ô | l | ¬† | ¬† | ¬† | . talamh | Ààt…ëlu | ÀàtÀ†o üÀ†uÀê | l | ¬† | ¬† | ¬† | . tamallt | t…ëm…ôlt | ÀàtÀ†amÀ†…ô üÀ†tÀ† | ¬† | tamall | ÀàtÀ†amÀ†…ô üÀ† | ¬† | . taobh | ti:w | ÀàtÀ†iÀêw | l | ¬† | ¬† | ¬† | . tarraingt | t…ër…ôn‚Ä≤t‚Ä≤ | ÀàtÀ†a…æÀ†in ≤t ≤ | l | ¬† | ¬† | ¬† | . teinidh | Ààt‚Ä≤ É…™n‚Ä≤i | Ààt ≤en ≤iÀê | ¬† | tine | ¬† | ¬† | . thart | h…ërt | Ààha…æÀ†tÀ† | l | ¬† | ¬† | ¬† | . theacht | haxd | ÀàhjaxtÀ† | l | ¬† | ¬† | ¬† | . thig | h…™g‚Ä≤ | Ààhji…ü | l | ¬† | ¬† | ¬† | . thiocfadh | hoÃ§ku | ÀàhjokÀ†uÀê | l | ¬† | ¬† | ¬† | . thoirt | ÀàhoÃ§rt‚Ä≤ | Ààha…æÀ†t ≤ | l+m | ¬† | ¬† | ¬† | . thriomuigheadh | Ààx‚Ä≤r‚Ä≤iÃàm ∑ied‚Ä≤ | ÀàrÃ™ ≤imÀ†…ôjuÀê | ¬† | thrioma√≠odh | ÀàrÃ™ ≤imÀ†i…ô…£ | ¬† | . thriomuigheann | Ààx‚Ä≤r‚Ä≤oÃ§m ∑i…ôn | ÀàrÃ™ ≤imÀ†…ôj…ô…¥À† | ¬† | thrioma√≠onn | ÀàrÃ™ ≤imÀ†i…ô…¥À† | ¬† | . th√©igheadh | Ààhe:w…ôd‚Ä≤ | ÀàheÀêjuÀê | ¬† | th√©adh | ÀàhjeÀêh | ¬† | . th√©igheann | Ààhe:·µän | ÀàheÀêj…ô…¥À† | ¬† | th√©ann | ÀàheÀê…¥À† | ¬† | . tionntochaidh | Ààt‚Ä≤·∂¥oÃ§ntah…ô | Ààt ≤i…¥À†tÀ†…ôhiÀê | ¬† | tiont√≥idh | Ààt ≤i…¥À†tÀ†…îj | ¬† | . toithe | tih…ô | ÀàtÀ†oh…ô | ¬† | tithe | Ààt ≤ihjiÀê | ¬† | . toithe | Ààtih…ô | ÀàtÀ†oh…ô | ¬† | tithe | Ààt ≤ihjiÀê | ¬† | . tosochaidh | Ààt…îsah…ô | ÀàtÀ†osÀ†…ôhiÀê | ¬† | tos√≥idh | ÀàtÀ†osÀ†…îj | ¬† | . triomochaidh | Ààt‚Ä≤·∂¥r‚Ä≤√Øm…ëh…ô | Ààt ≤…æ ≤imÀ†…ôhiÀê | ¬† | triom√≥idh | Ààt ≤…æ ≤imÀ†…îj | ¬† | . tr√≠ | t‚Ä≤ Ér‚Ä≤i: | Ààt ≤…æ ≤iÀê | l | ¬† | ¬† | ¬† | . tsleagh√°in | ‚Ä≤t‚Ä≤ Él‚Ä≤a:n‚Ä≤ | Ààt ≤l ≤a…£aÀên ≤ | ¬† | tsle√°in | Ààt ≤l ≤aÀên ≤ | ¬† | . tuairim | tu…ôr‚Ä≤…™m‚Ä≤ | ÀàtÀ†ua…æ ≤im ≤ | l | ¬† | ¬† | ¬† | . tusa | Ààt√∂s…ô | ÀàtÀ†usÀ†…ô | l | ¬† | ¬† | ¬† | . t√° | Ààt…ë(:) | ÀàtÀ†aÀê | l | ¬† | ¬† | ¬† | . t√≠r | Ààt‚Ä≤·∂¥i:r‚Ä≤ | Ààt ≤iÀê…æ ≤ | l | ¬† | ¬† | ¬† | . t√∫ | tu(·µä) | ÀàtÀ†uÀê | l | ¬† | ¬† | ¬† | . uair | nu…ôr‚Ä≤ | Ààua…æ ≤ | l | ¬† | ¬† | ¬† | . uair | Àànu…ôr‚Ä≤ | Ààua…æ ≤ | l | ¬† | ¬† | ¬† | . uile | Ààn…™l‚Ä≤…ô | Ààil ≤…ô | l | ¬† | ¬† | ¬† | . uisce | …™ Ég‚Ä≤…ô | Àài Éc…ô | l | ¬† | ¬† | ¬† | . well | w…õl‚Ä≤ | Ààwe ü ≤ | ¬† | ¬† | ¬† | ¬† | . worm | Ààw√Ør‚Ä≤…ôm | ÀàwoÀê…æÀ†…ômÀ† | ¬† | ¬† | ¬† | ¬† | . √° | a | aÀê | l | ¬† | ¬† | ¬† | . √°iteacha | Ààa:n‚Ä≤t‚Ä≤ax…ô | ÀàaÀêt ≤…ôh…ô | ¬† | √°iteanna | ÀàaÀêt ≤…ô…¥À†…ô | ¬† | . √©adan | Ààe:·µäd…ën | ÀàeÀêdÀ†…ô…¥À† | l | ¬† | ¬† | ¬† | . √©adan | Àà…õ:d…ën | ÀàeÀêdÀ†…ô…¥À† | l | ¬† | ¬† | ¬† | . √©adan | Àà…õ:·µäd…ën | ÀàeÀêdÀ†…ô…¥À† | l | ¬† | ¬† | ¬† | . √≠ | ¬† | ÀàiÀê | l | ¬† | ¬† | ¬† | . √≠ | i: | ÀàiÀê | l | ¬† | ¬† | ¬† | . √≥ | …ë | ÀàoÀê | l | ¬† | ¬† | ¬† | . √≥ | …î | ÀàoÀê | l | ¬† | ¬† | ¬† | . O‚ÄôNeill, John E. ‚ÄúIrish Texts from South West Donegal.‚Äù Zeitschrift F√ºr Celtische Philologie, vol. 33, 1974, doi:10.1515/zcph.1974.33.1.285.¬†&#8617; . |",
            "url": "https://jimregan.github.io/notes/irish/donegal/2021/06/14/irish-texts-from-south-west-donegal-texts-1-2.html",
            "relUrl": "/irish/donegal/2021/06/14/irish-texts-from-south-west-donegal-texts-1-2.html",
            "date": " ‚Ä¢ Jun 14, 2021"
        }
        
    
  
    
        ,"post64": {
            "title": "Tuairisc scraper pieces",
            "content": "_SITEMAP=&#39;https://tuairisc.ie/sitemap.xml&#39; . import requests from bs4 import BeautifulSoup . def _read_main_sitemap(): output = [] sm = requests.get(_SITEMAP) if sm.status_code != 200: raise Exception(&quot;Failed to read sitemap&quot;) base_soup = BeautifulSoup(sm.text, &#39;lxml&#39;) for submap in base_soup.findAll(&#39;sitemap&#39;): location = submap.find(&#39;loc&#39;).text if &#39;sitemap-pt&#39; in location: output.append(_read_sub_sitemap(location)) return output . def _read_sub_sitemap(url): output = [] sm = requests.get(url) if sm.status_code != 200: raise Exception(&quot;Failed to read sitemap&quot;) base_soup = BeautifulSoup(sm.text, &quot;lxml&quot;) for submap in base_soup.findAll(&quot;url&quot;): output.append(submap.find(&quot;loc&quot;).text) return output . def _fetch_article(url): page = requests.get(url) if page.status_code != 200: raise Exception(&quot;Failed to read page: &quot; + url) return page.text . def _get_article_text(content): base_soup = BeautifulSoup(content, &quot;lxml&quot;) main = base_soup.find(&quot;div&quot;, {&quot;class&quot;: &quot;article--full__content&quot;}) paras = [p.text.strip() for p in main.findAll(&quot;p&quot;) if p.text.strip() != &#39;&#39;] return(paras) . def _get_pub_date(content): base_soup = BeautifulSoup(content, &quot;lxml&quot;) date = base_soup.find(&quot;time&quot;, {&quot;itemprop&quot;: &quot;datePublished&quot;}) return date[&quot;datetime&quot;] . _get_article_text(_fetch_article(&#39;https://tuairisc.ie/nuair-a-thainig-john-hume-go-hollscoil-na-banriona-thuig-me-gur-i-lathair-ceannaire-agus-faidh-a-bhi-me/&#39;)) . _get_pub_date(_fetch_article(&#39;https://tuairisc.ie/nuair-a-thainig-john-hume-go-hollscoil-na-banriona-thuig-me-gur-i-lathair-ceannaire-agus-faidh-a-bhi-me/&#39;)) . &#39;2020-08-04 05:44&#39; .",
            "url": "https://jimregan.github.io/notes/irish/scraper/tuairisc/2021/06/13/tuairisc-scraper.html",
            "relUrl": "/irish/scraper/tuairisc/2021/06/13/tuairisc-scraper.html",
            "date": " ‚Ä¢ Jun 13, 2021"
        }
        
    
  
    
        ,"post65": {
            "title": "Download w2v-u Swedish model trained on Colab",
            "content": "Original . %%capture !pip install gdown . !gdown https://drive.google.com/uc?id=1-3fYwuDq-l7UpowGtzq3X4Dg-jTrb5jQ !gdown https://drive.google.com/uc?id=1E3LB7rlmk00zhsgYEYFq8y-2Ck6QU-wx . Downloading... From: https://drive.google.com/uc?id=1-3fYwuDq-l7UpowGtzq3X4Dg-jTrb5jQ To: /kaggle/working/checkpoint_last.pt 13.0MB [00:00, 57.6MB/s] Downloading... From: https://drive.google.com/uc?id=1E3LB7rlmk00zhsgYEYFq8y-2Ck6QU-wx To: /kaggle/working/checkpoint_best.pt 13.0MB [00:00, 65.7MB/s] .",
            "url": "https://jimregan.github.io/notes/kaggle/w2vu/2021/06/09/download-w2vu-sv-model-trained-on-colab.html",
            "relUrl": "/kaggle/w2vu/2021/06/09/download-w2vu-sv-model-trained-on-colab.html",
            "date": " ‚Ä¢ Jun 9, 2021"
        }
        
    
  
    
        ,"post66": {
            "title": "wav2vec-u notes",
            "content": "The skippable blah . wav2vec unsupervised has caught a bit of attention. . There has been a mixed bag of expectations: there was a blog post, they even had a video: . Facebook AI‚Äôs new open source speech recognition model, wav2vec Unsupervised, uses no transcribed data at all. We‚Äôve tested it on many languages, such as Swahili, that have proven challenging for other systems. Learn more in our blog post here: https://t.co/b6ic50AsM6 pic.twitter.com/x3Tx9nxq5i . &mdash; Facebook AI (@facebookai) June 1, 2021 So, a few people have had the expectation that it would be quite a bit easier than it turned out to. . I‚Äôve been beating my head against multiple walls for over a decade, with various pieces of research software for various purposes, so my expectations were a little different. Just looking at the directory, the third subdirectory is kaldi_self_train, which is the first red flag: this will not be easy. Scrolling down, among the first instructions are zsh scripts. zsh is a great shell, and using it as a shell was a sign of sophistication in the late 90s, but it isn‚Äôt the most universal shell, so if your scripts are zsh scripts, that‚Äôs a pretty good sign you‚Äôve never tried to run them on a second computer. That said, trying to use any kind of software on Linux in the late 90s involved some sort of beating of heads against walls, so that contributes too. . I like Kaggle. A lot. I like the workflow, and being able to use the output of one notebook as the input to another. I like being able to run something, and not have to babysit it in case it disconnects, like with Colab. So I‚Äôve tried to do as much of this as possible on Kaggle. . But the GPU images on Kaggle are seriously broken. It could be by design: the handful of things I‚Äôve tried that are run purely as a notebook seem to work well. Maybe conda is deliberately cobbled, maybe it‚Äôs unintentional, but it fails more often than not. So anything that involves using a GPU: switch to Colab. . Caveat . These are my notes for my own use, because once I‚Äôve done a full trial run, I have some data I want to try out. I‚Äôm deliberately not adding additional text, mostly because I want the trial run to go as quickly as possible; that‚Äôs failing for other reasons, but such is life. . What I‚Äôve done was based on my understanding, or best guess. I can guarantee that I was not smoking any illegal substances, but considering where I live, I can‚Äôt guarantee that there was no second-hand smoke. . There is an issue on fairseq‚Äôs github where Alexei Baevski has said that better instructions are coming in a week or so, so maybe bide your time; he also offered to answer questions on that thread, so if you have questions, your best bet is to ask there. . Step 0: Data . In an ideal world, Kaggle‚Äôs dataset uploader would Do The Right Thing when given a link to a zip file, or, rather, one of two Right Things: just download it, or download and unzip. Instead, it creates a directory for every file in the zip. . ü§¶ . Cool, I‚Äôll just do that in a notebook. . wav2vec-u (and just about everything else in the world of ASR, ever) needs audio sampled at 16 kHz, and uses soundfile, so MP3s are not welcome, so I‚Äôll do that in another notebook. . Step 0.1: ltr/wrd/phn files . Preparing these files is mentioned in passing, as though they‚Äôre self-explanatory. Which they are, if you happen to have played with phoneme-based ASR as well as wav2letter. So, not really. . What I ended up doing is this; I should have changed the tab separation in the dict.* files to a space, because that‚Äôs what‚Äôs usually given to Kaldi, but IIRC, it handles tab. So change: . paste /tmp/$i.wl /tmp/$i.wl.phn &gt; dict.$i . to: . paste /tmp/$i.wl /tmp/$i.wl.phn | tr &#39; t&#39; &#39; &#39; &gt; dict.$i . or equivalent. . Caveat: I can‚Äôt say for sure if these are actually correct outputs, and I‚Äôm not even sure they‚Äôre actually used by default, aside from the prepare_audio.sh script dying if they‚Äôre missing. . There are some notes in that notebook where I tracked down and corrected for espeak‚Äôs language switching; feel free to ignore that if you‚Äôre not borderline OCD. . Step 0.2: Preparing TSVs . Another thing that‚Äôs glossed over a bit is the TSV files, which are more pseudo-TSV. . ‚ÄúSimilar to wav2vec 2.0‚Äù is more-or-less true, in that you can figure it out if you look at this script; basically, the format is: . /path/to/my/audio/ file1.wav [number of frames] file2.wav [number of frames] ... (etc.) . I used this notebook to convert Common Voice TSV to these pseudo-TSVs, but the number of frames aren‚Äôt read by anything, so you can get away with a file list, as long as the first line is the path. . Step 1: VAD/Silence trimming . There‚Äôs a passing mention of rVAD, like it‚Äôs a common piece of software that you should just be able to install. It‚Äôs not: it‚Äôs here. Or, you know, save yourself the trouble and copy the relevant steps from the notebook . This went fairly smoothly; I wrestled with Kaggle a bit, but I think any problems here were of my own creation. . Step 2: prepare_audio.sh . My notebook for prepare_audio.sh is quite short; basically, you need the dict.*, *.wrd, *.ltr, and *.phn files from Step 0.1, and: . pip install npy-append-array faiss-gpu . (also, possibly, apt install zsh) . Also: wow! This used GPU on Kaggle, and actually worked. . Step 3: prepare_text.sh . This needs Kaldi to compile FSTs. On Kaggle, I used this notebook to extract a pre-built version from the official docker images. DNN parts won‚Äôt run, because they‚Äôre compiled for an earlier version of CUDA, but they‚Äôre not necessary for this step. . If you‚Äôre using Colab, this question on Stack Overflow is for you: . !pip install kora -q import kora.install.kaldi . The version of Kaldi there is also from the official docker image (that‚Äôs where I got the idea), but it also downloads and unpacks it for you. Which is nice. . My notebook for running prepare_text.sh has more notes than usual: check it out . Step 4: GAN training . This doesn‚Äôt work on Kaggle, because GPU. It does, however, run on CPU‚Äîalbeit 8-9 times slower‚Äîso I‚Äôve been chaining together calls, starting with this, leading up to (at the time of writing) this. . The good news is, it runs fine on Colab: notebook here. . (By ‚Äúfine‚Äù, I mean ‚Äúwith this patch added, running from this branch where everything has been moved around.‚Äù Close enough.) . Fin . I‚Äôm still waiting for GAN training to finish, so I can‚Äôt comment on anything else. .",
            "url": "https://jimregan.github.io/notes/wav2vec-u/2021/06/05/wav2vec-u-notes.html",
            "relUrl": "/wav2vec-u/2021/06/05/wav2vec-u-notes.html",
            "date": " ‚Ä¢ Jun 5, 2021"
        }
        
    
  
    
        ,"post67": {
            "title": "wav2vec-u Common Voice Swedish - GAN training, CPU8",
            "content": "Original here . Preparation . !cp ../input/w2vu-cvsv-checkpoints-cpu7/checkpoint_best.pt . !cp ../input/w2vu-cvsv-checkpoints-cpu7/checkpoint_last.pt . . %%capture !conda install -c pykaldi pykaldi -y . %cd /tmp . !git clone https://github.com/jimregan/fairseq/ --branch issue3581 . !git clone https://github.com/kpu/kenlm . %%capture !apt-get -y install libeigen3-dev liblzma-dev zlib1g-dev libbz2-dev . %%capture %cd /tmp/kenlm !python setup.py install %cd /tmp . import os os.environ[&#39;PATH&#39;] = f&quot;{os.environ[&#39;PATH&#39;]}:/tmp/kenlm/build/bin/&quot; os.environ[&#39;FAIRSEQ_ROOT&#39;] = &#39;/tmp/fairseq&#39; . %cd /tmp/fairseq/ . %%capture !python setup.py install . %cd /tmp/fairseq/ . os.environ[&#39;HYDRA_FULL_ERROR&#39;] = &#39;1&#39; . %%capture !pip install editdistance . GAN . %%writefile rungan.sh PREFIX=w2v_unsup_gan_xp TASK_DATA=/kaggle/input/wav2vec-u-cv-swedish-audio/precompute_pca512_cls128_mean_pooled/ TEXT_DATA=/kaggle/input/wav2vec-u-cv-swedish-text-prep/preppedtext/phones/ KENLM_PATH=/kaggle/input/wav2vec-u-cv-swedish-text-prep/preppedtext/phones/lm.phones.filtered.04.bin PREFIX=$PREFIX fairseq-hydra-train -m --config-dir fairseq/config/model/wav2vecu/gan --config-name w2vu task.data=${TASK_DATA} task.text_data=${TEXT_DATA} task.kenlm_path=${KENLM_PATH} checkpoint.no_epoch_checkpoints=false checkpoint.keep_last_epochs=5 checkpoint.save_dir=/kaggle/working &#39;common.seed=range(0,5)&#39; . !bash rungan.sh .",
            "url": "https://jimregan.github.io/notes/kaggle/wav2vec-u/2021/06/05/wav2vec-u-cv-swedish-gan-cpu8.html",
            "relUrl": "/kaggle/wav2vec-u/2021/06/05/wav2vec-u-cv-swedish-gan-cpu8.html",
            "date": " ‚Ä¢ Jun 5, 2021"
        }
        
    
  
    
        ,"post68": {
            "title": "CC-Aligned Irish contains porn",
            "content": "I re-ran this notebook and forgot to take the opportunity to see why M2M100 thinks everything is porn. . Now I know. . !wget http://www.statmt.org/cc-aligned/en_XX-ga_IE.tsv.xz . --2021-06-05 18:10:06-- http://www.statmt.org/cc-aligned/en_XX-ga_IE.tsv.xz Resolving www.statmt.org (www.statmt.org)... 129.215.197.184 Connecting to www.statmt.org (www.statmt.org)|129.215.197.184|:80... connected. HTTP request sent, awaiting response... 200 OK Length: 150347648 (143M) [application/x-xz] Saving to: ‚Äòen_XX-ga_IE.tsv.xz‚Äô en_XX-ga_IE.tsv.xz 100%[===================&gt;] 143.38M 128KB/s in 18m 23s 2021-06-05 18:28:30 (133 KB/s) - ‚Äòen_XX-ga_IE.tsv.xz‚Äô saved [150347648/150347648] . !unxz en_XX-ga_IE.tsv.xz . unxz: en_XX-ga_IE.tsv: File exists . !cat en_XX-ga_IE.tsv|grep -a -i brazzers|wc -l . 461 . !cat en_XX-ga_IE.tsv|grep -a -i brazzers|cut -c -120 . brazzers-n.com http://brazzers-n.com/en/tgb/6350-%E0%A6%86%E0%A6%B0%E0%A6%AC%2C+%E0%A6%AC%E0%A7%87%E0%A6%B6%E0%A7%8D%E0% brazzers-n.com http://brazzers-n.com/en/tgb/3981-%E0%A4%AD%E0%A4%B5%E0%A5%8D%E0%A4%AF+%E0%A4%95%E0%A4%BF%E0%A4%B6%E0%A5% brazzers-n.com http://brazzers-n.com/en/tgb/13264-%E0%B0%AA%E0%B0%BE%E0%B0%A0%E0%B0%B6%E0%B0%BE%E0%B0%B2+%E0%B0%AB%E0%B0 brazzers-n.com http://brazzers-n.com/en/tgb/16024-%D0%93%D2%AF%D0%BD+Creampie/ Deep Creampie - BRAZZERS porn Studio. Por brazzers-n.com http://brazzers-n.com/en/tgb/7978-%D0%94%D0%B0%D0%BB%D0%B4+%D0%93%D0%B0%D0%BB%D0%B7%D1%83%D1%83%D0%B3%D0% brazzers-n.com http://brazzers-n.com/en/tgb/6324-CFNM+%D0%A1%D0%B5%D0%BA%D1%81/ CFNM Sex - BRAZZERS porn Studio. Porn cl porndig-n.com http://porndig-n.com/en/bikini Bikini porn video porndig|Menu|Main (current)|Random video|All categories|E hotpornadult.com http://hotpornadult.com/ HotPornAdult - porn in HD|Free porn videos online|Sliding menu|HotPornAdult|Ma brazzers-n.com http://brazzers-n.com/en/tgb/17530-%E0%A6%AA%E0%A7%87%E0%A6%9B%E0%A6%A8+%E0%A6%A5%E0%A7%87%E0%A6%95%E0%A7 ecml.at http://edl.ecml.at/LanguageFun/LanguageQuiz/tabid/1873/language/en-GB/Default.aspx European Day of Languages &gt; L brazzers-n.com http://brazzers-n.com/en/tgb/14265-%D0%A5%D1%83%D1%83%D1%87%D0%B8%D0%BD+Dicks/ Old Dicks - BRAZZERS porn brazzers-n.com http://brazzers-n.com/en/tgb/12184-%D0%95%D0%B2%D1%80%D0%BE+%D0%93%D1%80%D1%83%D0%BF%D0%BF/ Euro Group - brazzers-n.com http://brazzers-n.com/en/tgb/6922-%E0%A6%9C%E0%A6%BE%E0%A6%AA%E0%A6%BE%E0%A6%A8%E0%A6%BF+%E0%A6%A6%E0%A7% foto-semya.ru https://foto-semya.ru/ bohsia doggie telugubrothersistersexvides asa akira hot|bohsia doggie|bohsia doggie lenkino.mobi http://lenkino.mobi/en/mv/1916008-danielle-dynamite-masturbates.html Danielle Dynamite Masturbates|Apostate brazzers-n.com http://brazzers-n.com/en/tgb/16058-%E0%A6%AA%E0%A6%B0%E0%A6%BF%E0%A6%9A%E0%A6%BE%E0%A6%B0%E0%A6%BF%E0%A6% 24video-xxx.com http://24video-xxx.com/en/hairy-pussy Hairy pussy this category contains selected videos in HD quality. brazzers-n.com http://brazzers-n.com/en/tgb/733-Chubby/ Chubby - BRAZZERS porn Studio. Porn clips brazzers Studio and no brazzers-n.com http://brazzers-n.com/en/tgb/9953-%E0%A6%95%E0%A7%81%E0%A6%96%E0%A7%8D%E0%A6%AF%E0%A6%BE%E0%A6%A4/ Infamo brazzers-n.com http://brazzers-n.com/en/mb/3319014-eva.html Eva|Menu|Main (current)|Random video|Chat|All categories|Eng brazzers-n.com http://brazzers-n.com/en/tgb/952-%E0%A6%B2%E0%A6%BE%E0%A6%B2+%E0%A6%B8%E0%A6%AC%E0%A7%81%E0%A6%9C/ Red Gr brazzers-n.com http://brazzers-n.com/en/tgb/10228-Girl+Loves+Anal/ Girl Loves Anal - BRAZZERS porn Studio. Porn clips br hdbox.ws https://hdbox.ws/en/sat-tv-novosti/5092-transpondernye-novosti-sputnikovogo-televideniya-20-fevralya-2018.html hotpornadult.com http://hotpornadult.com/en/tag/ Free porn videos online|Sliding menu|HotPornAdult|Main (current)|Random brazzers-n.com http://brazzers-n.com/en/tgb/12851-%E0%A6%B8%E0%A7%8D%E0%A6%AC%E0%A6%B0%E0%A7%8D%E0%A6%A3%E0%A6%95%E0%A7% pornoload-n.com http://pornoload-n.com/en/tag/431-%C4%90%E1%BB%93/page/7/ Hard Sex - Pornload best website with adult vi brazzers-n.com http://brazzers-n.com/en/vibrator/ Vibrator brazzers|Menu|Main (current)|Random video|Chat|All categories pornoload-n.com http://pornoload-n.com/en/tag/11490-Famous/ Famous - Pornload best website with adult videos and porn cl ruporn-tv.com http://ruporn-tv.com/en/blonde Blonde|Menu|Main (current)|Random|Category|English|–†—É—Å—Å–∫–∏–π|English|A pornk.mobi http://pornk.mobi/en/bikini Bikini porn pornk|Menu|Main (current)|Topics porn|Random video|Chat|English|–†—ÉÔøΩ eporner-n.com http://eporner-n.com/en/facialized Cum on face _ EPORNER|Menu|Main (current)|All categories|Random|English brazzers-n.com http://brazzers-n.com/en/tgb/16337-%E0%A8%A6%E0%A8%BF%E0%A8%A8/ Daytime - BRAZZERS porn Studio. Porn clip brazzers-n.com http://brazzers-n.com/en/tgb/12184-%E0%A8%AF%E0%A9%82%E0%A8%B0%E0%A9%8B+%E0%A8%97%E0%A8%B0%E0%A9%81%E0%A9 gonzofap.com http://gonzofap.com/en/ Gonzo Fap|English|Afrikaans|ÿßŸÑÿπÿ±ÿ®Ÿäÿ©|Az…ôrbaycanca|–ë–µ–ª–∞—Ä—É—Å–∫–∞—è|–ë—äÔøΩ pornoload-n.com http://pornoload-n.com/en/hardcore Hardcore|Menu|PornoLoad|Main (current)|Random video|All categories|En oisquipedia.org https://oisquipedia.org/encheu_a_boca_dela_de_porra_0532 Encheu A Boca Dela De Porra - English Porn Vide ruporn-tv.com http://ruporn-tv.com/en/p/6/ Russian porn online watch free video on Ruporn.tv - page 6|Menu|Main (current ecml.at http://edl.ecml.at/LanguageFun/FAQsonsignlanguage/tabid/2741/language/en-GB/Default.aspx European Day of Languag cucek.net http://cucek.net/en/porn-orgasms Porn orgasms|Sliding menu|Cucek.NET|Main (current)|Random video|All categorie ecml.at http://edl.ecml.at/LanguageFun/LanguageFacts/tabid/1859/language/en-GB/Default.aspx European Day of Languages &gt; trahtubetv.com http://trahtubetv.com/en/tag/351-Pounded/ Pounded - Fuck tube. Check out hot pussies. Porn videos for fre brazzers-n.com http://brazzers-n.com/en/tgb/12398-%E0%B9%80%E0%B8%82%E0%B9%88%E0%B8%B2%E0%B8%AA%E0%B8%B9%E0%B8%87%E0%B8% brazzers-n.com http://brazzers-n.com/en/tgb/344-%E0%A6%AB%E0%A6%BF%E0%A6%B8%E0%A6%A8%E0%A7%87%E0%A6%9F/ Fishnet - BRAZZE pornoload-n.com http://pornoload-n.com/en/tag/9763-%D0%97%D0%B2%D1%83%D1%87%D0%B0%D0%BD%D0%B8%D0%B5/ Sounding - Pornload brazzers-n.com http://brazzers-n.com/en/tgb/5075-%E0%A6%95%E0%A7%83%E0%A6%B7%E0%A6%95%E0%A6%A6%E0%A7%87%E0%A6%B0/ Farmer estudiogrum.com https://estudiogrum.com/en/home English Porn Video - Free Porn Videos Xvideos, Pornhub, xnxx - Ladyboy P brazzers-n.com http://brazzers-n.com/en/azeri/ Azeri brazzers|Menu|Main (current)|Random video|Chat|All categories|Engli pornoload-n.com http://pornoload-n.com/en/page/8/ Pornload best website with adult videos and porn clips adult free - pa brazzers-n.com http://brazzers-n.com/en/tgb/23432-%E0%A6%9B%E0%A7%8B%E0%A6%9F+%E0%A6%B2%E0%A6%BE%E0%A6%B2+%E0%A6%9A%E0%A brazzers-n.com http://brazzers-n.com/en/tgb/12940-%E0%A6%AC%E0%A6%A1%E0%A6%BC%E0%A7%8B+%E0%A6%AA%E0%A7%8B%E0%A6%81%E0%A6 hotpornohub.com http://hotpornohub.com/en/next/3/ Cool porn video from hotpornohub.com! - page 3|Sliding menu|HotPornoHu brazzers-n.com http://brazzers-n.com/en/tgb/7808-%E0%A6%97%E0%A6%B0%E0%A6%AE%2C+%E0%A6%AA%E0%A7%80%E0%A6%A8%E0%A6%B8%E0% brazzers-n.com http://brazzers-n.com/en/tgb/12939-%E0%A6%AE%E0%A6%BE%E0%A6%87+%E0%A6%8F%E0%A6%B0/ Huge Titties - BRAZZER brazzers-n.com http://brazzers-n.com/en/tgb/11635-%E0%A6%AA%E0%A6%B0%E0%A6%BF%E0%A6%A3%E0%A6%A4%2C+%E0%A6%AA%E0%A7%8B%E0 erkiss-tv.com http://erkiss-tv.com/en/bikini/ Bikini porn on the phone|Menu|Main (current)|Random|Chat|Category|English| brazzers-n.com http://brazzers-n.com/en/tgb/21088-%D0%9D%D1%83%D0%BB%D0%B8%D0%BC%D0%B6+%D0%A8%D2%AF%D1%82%D1%8D%D1%8D%D0 brazzers-n.com http://brazzers-n.com/en/tgb/12030-%E0%A6%AE%E0%A6%BE%E0%A6%87+%E0%A6%8F%E0%A6%B0+%E0%A6%AE%E0%A6%BE%E0%A brazzers-n.com http://brazzers-n.com/en/tgb/11741-%E0%A6%A8%E0%A6%BF%E0%A6%96%E0%A7%81%E0%A6%81%E0%A6%A4+%E0%A6%B8%E0%A7 xyutv-a.com http://xyutv-a.com/en/tag/2528-%E0%A6%95%E0%A7%81%E0%A6%A4%E0%A7%8D%E0%A6%A4%E0%A6%BE/ Motherfucker - fuck T hotpornadult.com http://hotpornadult.com/en/ HotPornAdult - porn in HD|Free porn videos online|Sliding menu|HotPornAdult trahtubetv.com http://trahtubetv.com/en/mi/9353721-vol.258-typorno.com.html vol.258 typorno.com|Menu|Tractor|Main (curre brazzers-n.com http://brazzers-n.com/en/tgb/8595-%E0%A6%97%E0%A6%B0%E0%A6%AE+%E0%A6%A7%E0%A6%BE%E0%A6%AA/ Hot Step - BRA xnxx-hd.pro http://xnxx-hd.pro/en/tag/4659-%E0%A6%AE%E0%A6%BE/ Busty Mother - Porno HD online in high quality|100% free 24video-net.com http://24video-net.com/en/footwork Footwork|Menu|24video|Main (current)|Random video|All categories|Engl ruporn-tv.com http://ruporn-tv.com/en/tag/1023-%E0%A4%8F%E0%A4%AE%E0%A4%86%E0%A4%88%E0%A4%8F%E0%A4%B2%E0%A4%8F+%E0%A4%AE pornoload-n.com http://pornoload-n.com/en/page/9/ Pornload best website with adult videos and porn clips adult free - pa porndig-n.com http://porndig-n.com/ PornDig: Porn tube video HD online Sex Free porn|Menu|Main (current)|Random video|Al brazzers-n.com http://brazzers-n.com/en/tgb/9-%E0%A6%AC%E0%A6%BE%E0%A6%B8%E0%A7%8D%E0%A6%A4%E0%A6%AC/ Real - BRAZZERS po pornoload-n.com http://pornoload-n.com/en/page/5/ Pornload best website with adult videos and porn clips adult free - pa brazzers-n.com http://brazzers-n.com/en/tgb/17424-%E0%A6%AB%E0%A7%8D%E0%A6%B2%E0%A6%BE%E0%A6%B6+%E0%A6%97%E0%A6%BE%E0%A6 reachporn.com https://www.reachporn.com/ Reach Porn ¬ª List Of The Best Porn Sites On The Net|Reach the best porn sites sozrelxxx.com http://sozrelxxx.com/en/c/ The list of all categories|ripe for porn|View all|English|–†—É—Å—Å–∫–∏–π|Englis cucek.net http://cucek.net/en/hardcore Hardcore|Sliding menu|Cucek.NET|Main (current)|Random video|All categories|Englis brazzers-n.com http://brazzers-n.com/en/tgb/5025-%D0%A1%D1%83%D0%B2%D0%B4%D0%B0%D0%BD+%D0%97%D2%AF%D2%AF%D0%BB%D1%82/ Pe brazzers-n.com http://brazzers-n.com/en/tgb/9523-%D0%9D%D1%8E+%D0%94%D0%BE%D0%BC%D0%B0/ Nude House - BRAZZERS porn Studi trahtubetv.com http://trahtubetv.com/en/tag/55-%E0%A6%B8%E0%A7%81%E0%A6%A8%E0%A7%8D%E0%A6%A6%E0%A6%B0%E0%A6%BF+%E0%A6%B8 brazzers-n.com http://brazzers-n.com/en/tgb/19143-%D0%90%D1%80%D0%BC%D0%B5%D0%BD%D0%B8%D0%B9+%D0%9E%D1%85%D0%B8%D0%BD/ A biqle-ru.com http://biqle-ru.com/en/mk/50810-zombie-joi.html Zombie JOI|Menu|Main (current)|Random|Category|English|–†—É hdbox.ws https://hdbox.ws/en/sat-tv-novosti/5065-transpondernye-novosti-sputnikovogo-televideniya-30-yanvarya-2018.html ecml.at http://edl.ecml.at/Home/WhyaEuropeanDayofLanguages/tabid/1763/language/en-GB/Default.aspx Why a European Day of brazzers-n.com http://brazzers-n.com/en/tgb/7754-%E0%A6%9F%E0%A6%BE%E0%A6%87%E0%A6%9F+%E0%A6%AF%E0%A7%8B%E0%A6%A8%E0%A6% brazzers-n.com http://brazzers-n.com/en/tgb/12173-%E0%A6%AA%E0%A7%8B%E0%A6%81%E0%A6%A6%2C+%E0%A6%AA%E0%A6%AA/ Ass Pop - brazzers-n.com http://brazzers-n.com/en/tgb/18830-Gaping+%D0%9D%D0%BE%D0%B9%D1%82%D0%BE%D0%BD+Pussy/ Gaping Wet Pussy - brazzers-n.com http://brazzers-n.com/en/tgb/17511-%E0%A6%9A%E0%A6%B0%E0%A6%AE+%E0%A6%B9%E0%A6%BF%E0%A6%B2/ Extreme Heels brazzers-n.com http://brazzers-n.com/en/tgb/15787-%E0%A4%8F%E0%A4%AE%E0%A5%87%E0%A4%9A%E0%A5%8D%E0%A4%AF%E0%A5%8B%E0%A4% xnxx-hd.pro http://xnxx-hd.pro/en/tag/16818-%E0%A4%AC%E0%A4%A1%E0%A4%BC%E0%A5%87+%E0%A4%B8%E0%A5%8D%E0%A4%A4%E0%A4%A8+%E brazzers-n.com http://brazzers-n.com/en/tgb/3373-%D0%A8%D0%B0%D1%80+%D0%91%D0%B8%D0%BA%D0%B8%D0%BD%D0%B8/ Yellow Bikini ruporn-tv.com http://ruporn-tv.com/en/tag/582-Fellatio/ Fellatio - Russian porn online watch free video on Ruporn.tv|Men pornoload-n.com http://pornoload-n.com/en/ch/ Chat|Menu|PornoLoad|Main (current)|Random video|All categories|English|–†ÔøΩ biqle-ru.com http://biqle-ru.com/en/mk/27008-,-brazzers--franceska-james , Brazzers - Franceska James&#39;s anal adventure|M gannuaire.com https://gannuaire.com/en/home Just Porn Xvideos, Free Porn Videos, Free Porn Download, Bb Ladies|DE|EN|CS| brazzers-n.com http://brazzers-n.com/en/tgb/9550-Craziest/ Craziest - BRAZZERS porn Studio. Porn clips brazzers Studio a brazzers-n.com http://brazzers-n.com/en/tgb/3714-POV+Fuck/ POV Fuck - BRAZZERS porn Studio. Porn clips brazzers Studio a affinicasts.com https://affinicasts.com/lexi-luna-bikini-0-1-223 Lexi Luna Bikini - English Porn Video - Free Porn Video ecml.at http://edl.ecml.at/LanguageFun/Celebritiesspeakinglanguages/tabid/3113/language/en-GB/Default.aspx European Day pornoload-n.com http://pornoload-n.com/ Pornload best website with adult videos and porn clips adult free|Menu|PornoLoad brazzers-n.com http://brazzers-n.com/en/hardcore/ Hardcore brazzers|Menu|Main (current)|Random video|Chat|All categories brazzers-n.com http://brazzers-n.com/en/tgb/21948-Big+C%C3%ADocha+M%C3%BAinteoir/ Big Boobs Teacher - BRAZZERS porn Stud brazzers-n.com http://brazzers-n.com/en/tgb/3096-%E0%A6%AD%E0%A6%BE%E0%A6%B2%2C+%E0%A6%AC%E0%A7%8D%E0%A6%B2%E0%A6%9C%E0% brazzers-n.com http://brazzers-n.com/en/celebrity/ Celebrity brazzers|Menu|Main (current)|Random video|Chat|All categori brazzers-n.com http://brazzers-n.com/en/tgb/13598-%E0%A6%AC%E0%A7%8D%E0%A6%B2%E0%A6%9C%E0%A6%AC+%E0%A6%AE%E0%A6%BE%E0%A6 brazzers-n.com http://brazzers-n.com/en/tgb/22448-%E0%A6%AE%E0%A7%81%E0%A6%96+%E0%A6%9A%E0%A6%A1%E0%A6%BC/ Face Slap - B brazzers-n.com http://brazzers-n.com/en/tgb/654-Bachelorette/ Bachelorette - BRAZZERS porn Studio. Porn clips brazzers S brazzers-n.com http://brazzers-n.com/en/tgb/14011-%D0%91%D0%B0%D0%B9%D0%B3%D0%B0%D0%BB%D0%B8%D0%B9%D0%BD+%D3%A8%D1%81%D0 brazzers-n.com http://brazzers-n.com/en/tgb/4224-%E0%A6%B8%E0%A7%87%E0%A6%95%E0%A7%8D%E0%A6%B8+%E0%A6%95%E0%A7%8D%E0%A6% brazzers-n.com http://brazzers-n.com/en/tgb/23569-%E0%A6%9A%E0%A7%81%E0%A6%B2%2C+%E0%A6%AA%E0%A7%8B%E0%A6%81%E0%A6%A6%2C brazzers-n.com http://brazzers-n.com/en/tgb/8670-%D0%AD%D0%BC%D1%87+%D0%A1%D1%83%D0%B2%D0%B8%D0%BB%D0%B0%D0%B3%D1%87/ Do brazzers-n.com http://brazzers-n.com/en/tgb/7986-%D0%91%D0%B0%D1%8F%D1%80%D1%82%D0%B0%D0%B9/ Excited - BRAZZERS porn Stu brazzers-n.com http://brazzers-n.com/en/tgb/6338-%E0%A6%B0%E0%A6%BE%E0%A6%B8%E0%A7%8D%E0%A6%A4%E0%A6%BE%E0%A6%B0+%E0%A6% brazzers-n.com http://brazzers-n.com/en/tgb/17449-%E0%A6%95%E0%A7%8D%E0%A6%AF%E0%A6%BE%E0%A6%AE%E0%A7%87%E0%A6%B0%E0%A6% redtube-n.com http://redtube-n.com/en/tag/ Menu|Main (current)|All categories|Random|English|–†—É—Å—Å–∫–∏–π|English|Az…ô dojki-n.com http://dojki-n.com/en/nudists/pp/2/ Nudist videos online in hd quality - page 2|Menu|Main (current)|Random v ecml.at http://edl.ecml.at/LanguageFun/Hello/tabid/1876/language/en-GB/Default.aspx European Day of Languages &gt; Language brazzers-n.com http://brazzers-n.com/en/tgb/21973-%E0%A6%8F%E0%A6%95%E0%A6%BE%E0%A6%A7%E0%A6%BF%E0%A6%95+Squirting/ Mult youporn-n.com http://youporn-n.com/en/tis/11242-Brazzers%2C/ Brazzers Ass - Excellent Porn videos, sex movies, XXX Porn, sozrelxxx.com http://sozrelxxx.com/en/blowjob Super Blowjob video in excellent quality online|ripe for porn|Arab|Beach|B brazzers-n.com http://brazzers-n.com/en/tgb/19032-%E0%A6%A1%E0%A7%81%E0%A6%AC/ Dipping - BRAZZERS porn Studio. Porn clip brazzers-n.com http://brazzers-n.com/en/tgb/4846-%E0%A6%AE%E0%A6%BE%E0%A6%A4%E0%A7%8D%E0%A6%B0%E0%A6%BE%E0%A6%A4%E0%A6%B brazzers-n.com http://brazzers-n.com/en/tgb/15098-%2C+%E0%A6%97%E0%A6%AD%E0%A7%80%E0%A6%B0%2C+%E0%A6%AA%E0%A7%8B%E0%A6%8 brazzers-n.com http://brazzers-n.com/en/tgb/9090-%E0%A6%A4%E0%A6%B0%E0%A7%81%E0%A6%A3%2C+%E0%A6%AE%E0%A7%87%E0%A6%AF%E0% brazzers-n.com http://brazzers-n.com/en/tgb/8788-%E0%B0%AA%E0%B1%86%E0%B0%A6%E0%B1%8D%E0%B0%A7+%E0%B0%B0%E0%B1%8A%E0%B0% brazzers-n.com http://brazzers-n.com/en/tgb/32-Glamour/ Glamour - BRAZZERS porn Studio. Porn clips brazzers Studio and n ecml.at http://edl.ecml.at/Participate/Promoteyourevent/tabid/1768/language/en-GB/Default.aspx European Day of Languages brazzers-n.com http://brazzers-n.com/en/tgb/22267-%E0%A6%B9%E0%A7%8B%E0%A6%9F%E0%A7%87%E0%A6%B2+%E0%A6%AB%E0%A7%8D%E0%A6 brazzers-n.com http://brazzers-n.com/en/tgb/17023-%E0%A6%AD%E0%A6%BE%E0%A6%97%E0%A7%8D%E0%A6%AF%E0%A6%AC%E0%A6%BE%E0%A6% vporn-com.com http://vporn-com.com/en/ms/3397020-striptease.html Striptease|Menu|Main (current)|Random video|All categor ecml.at http://edl.ecml.at/Home/Movingintothepolyglotage/tabid/2970/language/en-GB/Default.aspx European Day of Language brazzers-n.com http://brazzers-n.com/en/threesome Threesome brazzers|Menu|Main (current)|Random video|Chat|All categorie brazzers-n.com http://brazzers-n.com/en/tgb/12851-%E0%B0%AD%E0%B0%BE%E0%B0%B0%E0%B1%8D%E0%B0%AF+%E0%B0%87%E0%B0%B0%E0%B1 brazzers-n.com http://brazzers-n.com/en/columbia/ Columbia brazzers|Menu|Main (current)|Random video|Chat|All categories xyutv-a.com http://xyutv-a.com/en/tag/6404-Sexy+Poibl%C3%AD/ Sexy Public - fuck TV PORN VIDEOS ONLINE - WATCH FREE best vporn-com.com http://vporn-com.com/en/tag/3821-%D0%97%D0%B0%D0%BB%D1%83%D1%83+%D0%AD%D0%BC%D1%8D%D0%B3%D1%82%D1%8D%D0%B9 brazzers-n.com http://brazzers-n.com/en/tgb/13598-%2C/ Suck Tits - BRAZZERS porn Studio. Porn clips brazzers Studio and brazzers-n.com http://brazzers-n.com/en/tgb/10582-%E0%A6%B8%E0%A7%87%E0%A6%95%E0%A7%8D%E0%A6%B8%E0%A6%BF%2C+%E0%A6%B8%E0 lenkino.mobi http://lenkino.mobi/en/mv/10405951-spandexporn-michaela.html SpandexPorn Michaela|720 HD video|Adult toys|A online-casino-10.pro http://online-casino-10.pro/ online-casino-10.pro - Free Czech Porn Videos And Amateur Sex Videos|M brazzers-n.com http://brazzers-n.com/en/tgb/21449-%E0%A6%A4%E0%A6%BF%E0%A6%A8%E0%A7%87+%E0%A6%AE%E0%A6%BF%E0%A6%B2%E0%A7 vporn-com.com http://vporn-com.com/en/tag/8471-Fraincis+Cum/ French Cum - porn - Best porn videos and Sex XXX movies, HD brazzers-n.com http://brazzers-n.com/en/tgb/16058-%D9%81%D9%8A+%D8%B3%D9%86+%D8%A7%D9%84%D9%85%D8%B1%D8%A7%D9%87%D9%82%D brazzers-n.com http://brazzers-n.com/en/tgb/13566-%E0%A6%AE%E0%A7%8D%E0%A6%AF%E0%A6%BE%E0%A6%B8%E0%A7%87%E0%A6%9C+%E0%A6 lenkino.mobi http://lenkino.mobi/en/otslaivanie/ Otslaivanie in lenkino|Adult toys|Apostate|Bisexual|Blonde|Bukkake|Cart brazzers-n.com http://brazzers-n.com/en/tgb/14756-%D0%97%D0%B0%D0%BB%D1%83%D1%83+%D0%A1%D0%BE%D0%BD%D0%B8%D1%80%D1%85%D0 pornyfree.com https://pornyfree.com/ Free Porn HD 4k,1080p,720p , Latest Porno Are Here|Skip to content|Follow me on:|We cucek.net http://cucek.net/en/rimjob/ Rimjob|Sliding menu|Cucek.NET|Main (current)|Random video|All categories|English|ÔøΩ brazzers-n.com http://brazzers-n.com/en/tgb/10899-%E0%A6%AC%E0%A6%A1%E0%A6%BC%E0%A7%8B+%E0%A6%AE%E0%A6%BE%E0%A6%87/ Voye ruporn-tv.com http://ruporn-tv.com/en/tag/17899-%2C%2C+%E0%A6%86%E0%A6%AF%E0%A6%BC%E0%A6%A8%E0%A6%BE%2C/ Teen Mirror - R ruporn-tv.com http://ruporn-tv.com/en/erotic/ Erotic|Menu|Main (current)|Random|Category|English|–†—É—Å—Å–∫–∏–π|English| hdbox.ws https://hdbox.ws/en/sat-tv-novosti/4737-transpondernye-novosti-za-08-08-2017.html Ôªø Transponder news for 08.0 24video-xxx.com http://24video-xxx.com/en/tag/11458-R%C3%B8yking+120s/ Smoking 120s - 24video.xxx com porn watch online, brazzers-n.com http://brazzers-n.com/en/tgb/10485-%E0%A6%A6%E0%A7%87%E0%A6%96%E0%A6%BE/ Meet up - BRAZZERS porn Studio. tube8-n.com http://tube8-n.com/en/vibrator Vibrator porn videos|Menu|Main (current)|View all|At random|English|–†—É—Å—ÅÔøΩ hotpornohub.com http://hotpornohub.com/en/tag/ Sliding menu|HotPornoHub|Main (current)|Random video|All categories|Engli biqle-ru.com http://biqle-ru.com/en/arab-porn/ Arab porn porn videos|Menu|Main (current)|Random|Category|English|–†—É—ÅÔøΩ brazzers-n.com http://brazzers-n.com/en/tgb/19015-%E0%A6%A1%E0%A6%BE%E0%A6%95%E0%A7%8D%E0%A6%A4%E0%A6%BE%E0%A6%B0/ Old D brazzers-n.com http://brazzers-n.com/en/tgb/19771-%E0%A8%B5%E0%A8%BF%E0%A8%86%E0%A8%B9+%E0%A8%A8%E0%A9%82%E0%A9%B0+%E0%A youjizzhd.net https://youjizzhd.net/en/porn-orgasms/ Porn orgasms on youjizz|Menu|Main (current)|Random video|All catego brazzers-n.com http://brazzers-n.com/en/tgb/17716-%E0%A6%AA%E0%A7%8B%E0%A6%81%E0%A6%A6+%E0%A6%97%E0%A7%81%E0%A6%A6+%E0%A ecml.at http://edl.ecml.at/LanguageFun/Selfevaluateyourlanguageskills/tabid/2194/language/en-GB/Default.aspx European Da brazzers-n.com http://brazzers-n.com/en/tgb/20192-%E0%A4%B8%E0%A4%B9+%E0%A4%95%E0%A4%B5%E0%A4%B0+Slut/ Cum Covered Slut brazzers-n.com http://brazzers-n.com/en/tgb/17-%D0%A2%D0%BE%D0%BC+%D0%A5%D1%83%D0%BB%D0%B0%D0%BD/ Big Ass - BRAZZERS por brazzers-n.com http://brazzers-n.com/en/tgb/1256-%D0%9E%D0%BD%D0%BB%D0%B0%D0%B9%D0%BD/ Online - BRAZZERS porn Studio. Po brazzers-n.com http://brazzers-n.com/en/tgb/21088-%E0%A6%A4%E0%A6%BF%E0%A6%A8%E0%A7%87+%E0%A6%AE%E0%A6%BF%E0%A6%B2%E0%A7 brazzers-n.com http://brazzers-n.com/en/tgb/10213-%E0%A6%86%E0%A6%AE%E0%A6%BE%E0%A6%B0+%E0%A6%B8%E0%A7%87%E0%A6%95%E0%A7 brazzers-n.com http://brazzers-n.com/en/tgb/18868-%D0%AD%D1%80%D0%BE%D1%82%D0%B8%D0%BA%D0%B0%D0%BB%D1%8B%D2%9B+%D0%91%D0 brazzers-n.com http://brazzers-n.com/en/tgb/5025-%E0%B9%80%E0%B8%9E%E0%B8%B4%E0%B8%A3%E0%B9%8C%E0%B8%A5%E0%B8%AD%E0%B8%A brazzers-n.com http://brazzers-n.com/en/tgb/5827-%E0%A6%B8%E0%A6%B0%E0%A6%95%E0%A6%BE%E0%A6%B0%E0%A7%80+%E0%A6%AB%E0%A7% vporn-com.com http://vporn-com.com/en/tag/4951-%D0%A5%D0%B0%D1%80+%D2%AE%D1%81%D1%82%D1%8D%D0%B9+%D0%A8%D1%83%D0%BB%D1%8 brazzers-n.com http://brazzers-n.com/en/tgb/12700-%E0%A6%B8%E0%A6%BE%E0%A6%A6%E0%A6%BE+%E0%A6%A6%E0%A7%88%E0%A6%A4%E0%A7 brazzers-n.com http://brazzers-n.com/en/tgb/12414-%E0%A6%B8%E0%A7%81%E0%A6%A8%E0%A7%8D%E0%A6%A6%E0%A6%B0%E0%A6%BF+%E0%A6 trahtubetv.com http://trahtubetv.com/en/mi/9686996-crazy-squealing-orgasm-dachix.com.html Crazy Squealing Orgasm dachix. brazzers-n.com http://brazzers-n.com/en/piercing/ Piercing brazzers|Menu|Main (current)|Random video|Chat|All categories ruporn-tv.com http://ruporn-tv.com/en/tag/2047-%E0%A4%97%E0%A5%81%E0%A4%B2%E0%A4%BE%E0%A4%AE+%E0%A4%AA%E0%A5%8D%E0%A4%B0 lenkino.mobi http://lenkino.mobi/en/tg/6394-%E0%A4%B8%E0%A5%80%E0%A4%96%E0%A4%A8%E0%A5%87/ Learning - Porn videos in HD 24video-xxx.com http://24video-xxx.com/en/c/full/ The list of all categories|To switch the language|–†—É—Å—Å–∫–∏–π|Engli brazzers-n.com http://brazzers-n.com/en/tgb/5954-%D0%A2%D0%BE%D0%BC+%D0%98%D0%BB%D0%B6%D0%B8%D0%B3+Latina/ Big Ass Latin dojki-n.com http://dojki-n.com/en/tag/23086-%D0%98%D1%85+%D0%91%D1%80%D0%B8%D1%82%D0%B0%D0%BD%D0%B8%D0%B9%D0%BD+Sluts/ B brazzers-n.com http://brazzers-n.com/en/tgb/18928-%E0%A4%B6%E0%A4%BF%E0%A4%95%E0%A5%8D%E0%A4%B7%E0%A4%95+%E0%A4%89%E0%A4 trahtubetv.com http://trahtubetv.com/en/bikini Bikini|Menu|Tractor|Main (current)|Random video|All categories|English|–† trahtubetv.com http://trahtubetv.com/en/tag/758-Sciorta/ Skirt - Fuck tube. Check out hot pussies. Porn videos for free| tube8-n.com http://tube8-n.com/en/naked-porn-star Naked porn star porn videos|Menu|Main (current)|View all|At random|Eng cucek.net http://cucek.net/en/mcuc/11219659-scarlett-johansson%2C-john-g%2C-barea-follando-en-el-semad-sexed.su.html Sca brazzers-n.com http://brazzers-n.com/en/tgb/559-%E0%A6%95%E0%A6%BE%E0%A6%B2%E0%A7%8B+%E0%A6%AC%E0%A6%B9%E0%A7%81+%E0%A6% trahtubetv.com http://trahtubetv.com/en/massage Massage|Menu|Tractor|Main (current)|Random video|All categories|English| pornoload-n.com http://pornoload-n.com/en/tag/2615-%E0%A4%B5%E0%A4%BF%E0%A4%B6%E0%A4%BE%E0%A4%B2+%E0%A4%B8%E0%A5%8D%E0%A brazzers-n.com http://brazzers-n.com/en/tgb/12884-%E0%A6%95%E0%A7%8D%E0%A6%B0%E0%A7%80%E0%A6%A4%E0%A6%A6%E0%A6%BE%E0%A6% dojki-n.com http://dojki-n.com/en/tag/16482-%E0%A4%AE%E0%A5%87%E0%A4%B0%E0%A5%87+%E0%A4%B8%E0%A4%AC%E0%A4%B8%E0%A5%87+%E cucek.net http://cucek.net/en/rimjob Rimjob|Sliding menu|Cucek.NET|Main (current)|Random video|All categories|English|–† brazzers-n.com http://brazzers-n.com/en/tgb/20752-%E0%A4%85%E0%A4%9A%E0%A5%8D%E0%A4%9B%E0%A4%BE+%E0%A4%97%E0%A5%8D%E0%A4 trahtubetv.com http://trahtubetv.com/en/tag/12353-Busty+%E0%A4%B8%E0%A4%9A%E0%A4%BF%E0%A4%B5/ Busty Secretary - Fuck tub brazzers-n.com http://brazzers-n.com/en/tgb/5954-Asal+M%C3%B3r+Latina/ Big Ass Latina - BRAZZERS porn Studio. Porn clips pornk.mobi http://pornk.mobi/en/yoga/ Yoga porn pornk|Menu|Main (current)|Topics porn|Random video|Chat|English|–†—É—Å—Å brazzers-n.com http://brazzers-n.com/en/tgb/4593-%E0%A6%B2%E0%A6%82+%E0%A6%AA%E0%A6%A6/ Long Legged - BRAZZERS porn Stud bizneswkatalogu.pl http://bizneswkatalogu.pl/en/ Lustful.TV|English|Afrikaans|ÿßŸÑÿπÿ±ÿ®Ÿäÿ©|Az…ôrbaycanca|–ë–µ–ª–∞—Ä—ÉÔøΩ trahtubetv.com http://trahtubetv.com/en/tag/41-%E0%A6%97%E0%A7%81%E0%A6%A6/pi/11/ Pussy - Fuck tube. Check out hot pussi brazzers-n.com http://brazzers-n.com/en/tgb/11039-%E0%A6%A7%E0%A6%B0%E0%A7%8D%E0%A6%B7%E0%A6%A3%2C+%E0%A6%B8%E0%A7%8D%E0 brazzers-n.com http://brazzers-n.com/en/tgb/19357-%E0%A6%85%E0%A6%AA%E0%A7%87%E0%A6%B6%E0%A6%BE%E0%A6%A6%E0%A6%BE%E0%A6% erkiss-tv.com http://erkiss-tv.com/en/canadians/ Canadians porn on phone|Menu|Main (current)|Random|Chat|Category|Englis brazzers-n.com http://brazzers-n.com/en/tgb/8788-%D2%AE%D0%BB%D0%BA%D0%B5%D0%BD+%D0%A1%D0%B8%D1%81%D1%8C%D0%BA%D0%B8+%D0 brazzers-n.com http://brazzers-n.com/en/footwork/pgb/3/ Footwork brazzers - page 3|Menu|Main (current)|Random video|Chat brazzers-n.com http://brazzers-n.com/en/tgb/4872-Public+Fuck/ Public Fuck - BRAZZERS porn Studio. Porn clips brazzers St brazzers-n.com http://brazzers-n.com/en/pgb/3/ BRAZZERS porn Studio. Porn clips brazzers Studio and not only. - page 3|M hdbox.ws https://hdbox.ws/en/wetek-play/414-spisok-kanalov-36e-dlya-resivera-wetek-play-ot-05-11-2015.html Channel list pornk.mobi http://pornk.mobi/en/canadians/ Canadians porn pornk|Menu|Main (current)|Topics porn|Random video|Chat|Englis ruporn-tv.com http://ruporn-tv.com/en/tag/17050-%E0%A4%AC%E0%A4%82%E0%A4%A7%E0%A4%95+%E0%A4%AA%E0%A4%B0%E0%A4%AA%E0%A5%8 brazzers-n.com http://brazzers-n.com/en/tgb/36-%E0%A6%AC%E0%A6%A1%E0%A6%BC%E0%A7%8B+%E0%A6%AE%E0%A6%BE%E0%A6%87/ Big Tit brazzers-n.com http://brazzers-n.com/en/tgb/530-%D0%9D%D2%AF%D2%AF%D1%80+%D0%A5%D1%83%D1%83%D0%B4%D0%B0%D1%81+%D0%A5%D0% brazzers-n.com http://brazzers-n.com/en/tgb/13141-Caliente/ Caliente - BRAZZERS porn Studio. Porn clips brazzers Studio brazzers-n.com http://brazzers-n.com/en/tgb/2896-%E0%A6%B8%E0%A7%8D%E0%A6%A4%E0%A7%8D%E0%A6%B0%E0%A7%80/ Granny Fucks - brazzers-n.com http://brazzers-n.com/en/tgb/2045-Feminization/ Feminization - BRAZZERS porn Studio. Porn clips brazzers cucek.net http://cucek.net/en/mcuc/9325057-cunilingus-fantasti.cc.html Cunilingus fantasti.cc|Sliding menu|Cucek.NET|Mai brazzers-n.com http://brazzers-n.com/en/tgb/7168-%E0%A8%AE%E0%A8%BF%E0%A8%B2%E0%A9%8D%E0%A8%AB%E0%A8%BC+%E0%A8%9A%E0%A8% biqle-ru.com http://biqle-ru.com/en/mk/3350324-vor-der-cam-mastubiert.html Vor der Cam Mastubiert|Menu|Main (current)|Ra brazzers-n.com http://brazzers-n.com/en/tgb/4631-%E0%A6%B6%E0%A7%8D%E0%A6%B0%E0%A7%8B%E0%A6%A3%E0%A7%80%E0%A6%9A%E0%A6%9 x-artvideo.net https://x-artvideo.net/ x-artvideo - X-art Video is a free daily porn tube that offers free porn movies o pornoload-n.com http://pornoload-n.com/en/rimjob Rimjob|Menu|PornoLoad|Main (current)|Random video|All categories|Englis brazzers-n.com http://brazzers-n.com/en/tgb/10241-%E0%A6%AC%E0%A6%A1%E0%A6%BC%E0%A7%8B+%E0%A6%AE%E0%A6%BE%E0%A6%87+%E0%A brazzers-n.com http://brazzers-n.com/en/tgb/12764-%E0%A6%AD%E0%A6%BF%E0%A6%9C%E0%A6%BE%2C+%E0%A6%97%E0%A7%8B%E0%A6%B2%E0 hotpornohub.com http://hotpornohub.com/en/fatties/ Bbw porn videos in excellent quality|Sliding menu|HotPornoHub|Main (c pornk.mobi http://pornk.mobi/en/cheerleaders/ Cheerleaders porn pornk|Menu|Main (current)|Topics porn|Random video|Chat| ruporn-tv.com http://ruporn-tv.com/en/tag/328-%E0%A8%95%E0%A8%AE+++%E0%A8%A4%E0%A9%87+%E0%A8%AA%E0%A8%BF%E0%A8%9B%E0%A9% pornoload-n.com http://pornoload-n.com/en/tag/457-Oifig/page/10/ Office - Pornload best website with adult videos and po brazzers-n.com http://brazzers-n.com/en/tgb/18261-%E0%A6%85%E0%A6%A8%E0%A7%8D%E0%A6%A7%E0%A6%95%E0%A6%BE%E0%A6%B0+%E0%A6 brazzers-n.com http://brazzers-n.com/en/tgb/18869-%E0%A6%89%E0%A6%A4%E0%A7%8D%E0%A6%AF%E0%A6%95%E0%A7%8D%E0%A6%A4+%E0%A6 brazzers-n.com http://brazzers-n.com/en/tgb/3375-%E0%A6%AE%E0%A6%BE%E0%A6%96%E0%A6%A8%E0%A7%87%E0%A6%B0+%E0%A6%AE%E0%A6% brazzers-n.com http://brazzers-n.com/en/tgb/15712-%E0%A4%95%E0%A4%BF%E0%A4%B6%E0%A5%8B%E0%A4%B0+%E0%A4%AC%E0%A4%A1%E0%A4 brazzers-n.com http://brazzers-n.com/en/tgb/4427-%E0%A6%AF%E0%A7%8C%E0%A6%A8/ Sexually - BRAZZERS porn Studio. Porn clip brazzers-n.com http://brazzers-n.com/en/tgb/12398-%E0%A6%B9%E0%A6%BE%E0%A6%81%E0%A6%9F%E0%A7%81+%E0%A6%89%E0%A6%9A%E0%A7 brazzers-n.com http://brazzers-n.com/en/tgb/16614-%E0%A6%B9%E0%A6%BE%E0%A6%B0%E0%A7%8D%E0%A6%A1%2C/ Hard Strapon - BRAZZ brazzers-n.com http://brazzers-n.com/en/bdsm BDSM brazzers|Menu|Main (current)|Random video|Chat|All categories|English| brazzers-n.com http://brazzers-n.com/en/tgb/12601-%E0%A6%AE%E0%A7%81%E0%A6%96%E0%A6%97%E0%A6%A4+%E0%A6%AA%E0%A7%82%E0%A6 brazzers-n.com http://brazzers-n.com/en/tgb/14420-%D0%A1%D0%BE%D0%BB%D0%BE+%D0%94%D1%83%D1%80/ Solo Orgasm - BRAZZERS po brazzers-n.com http://brazzers-n.com/en/tgb/5183-%E0%A6%AA%E0%A7%8D%E0%A6%B0%E0%A6%9A%E0%A6%A3%E0%A7%8D%E0%A6%A1+%E0%A6% brazzers-n.com http://brazzers-n.com/en/tgb/21424-%E0%A6%86%E0%A6%81%E0%A6%9F+%E0%A6%AC%E0%A6%A1%E0%A6%BC%E0%A7%8B+%E0%A lenkino.mobi http://lenkino.mobi/en/anal Anal on lenkino|Anonymous chat !|18 years|Amateurs|Arab porn|Bathroom|Beach|Cum biqle-ru.com http://biqle-ru.com/en/t/1680-%E0%A8%86%E0%A8%AE/ Roughly - Porno HD online in high quality on biqle, witho brazzers-n.com http://brazzers-n.com/en/tgb/20975-%D0%92%D1%82%D0%B5%D1%87%D0%B0/ Escape - BRAZZERS porn Studio. Porn cl brazzers-n.com http://brazzers-n.com/en/tgb/23507-%E0%A6%B2%E0%A7%87%E0%A6%B8%E0%A6%AC%E0%A6%BF%E0%A6%AF%E0%A6%BC%E0%A6% trahtubetv.com http://trahtubetv.com/en/anal/pi/6/ Anal - page 6|Menu|Tractor|Main (current)|Random video|All categories brazzers-n.com http://brazzers-n.com/en/tgb/13264-%E0%A6%B8%E0%A7%8D%E0%A6%95%E0%A7%81%E0%A6%B2%2C/ School Fuck - BRAZZE vporn-com.com http://vporn-com.com/en/latex/ Latex only on anysex|Menu|Main (current)|Random video|All categories|Englis brazzers-n.com http://brazzers-n.com/en/tgb/19829-%E0%A4%97%E0%A5%81%E0%A4%82%E0%A4%A1%E0%A4%BE%2C/ Punk Lesbian - BRAZZ xvideos-a.com http://xvideos-a.com/en/moa/3597716-verronica-tempting-handjob.html Verronica Tempting Handjob|Navigation| brazzers-n.com http://brazzers-n.com/en/tgb/10899-%E0%B0%A4%E0%B0%B0%E0%B1%81%E0%B0%B2%E0%B1%81+%E0%B0%B8%E0%B1%86%E0%B0 ruporn-tv.com http://ruporn-tv.com/en/tag/3298-%E0%A4%B8%E0%A4%B9%E0%A4%AA%E0%A4%BE%E0%A4%A0%E0%A5%80/ Classmate - Russi brazzers-n.com http://brazzers-n.com/en/tgb/12967-%E0%A6%AA%E0%A6%B0%E0%A6%BF%E0%A6%A3%E0%A6%A4+%E0%A6%AE%E0%A7%87%E0%A6 ecml.at http://edl.ecml.at/LanguageFun/Talktome/tabid/1878/language/en-GB/Default.aspx European Day of Languages &gt; Langu brazzers-n.com http://brazzers-n.com/en/tgb/8788-%E0%A6%AC%E0%A6%A1%E0%A6%BC%E0%A7%8B+%E0%A6%AE%E0%A6%BE%E0%A6%87+%E0%A6 brazzers-n.com http://brazzers-n.com/en/tgb/10099-%E0%A6%B8%E0%A7%81%E0%A6%A8%E0%A7%8D%E0%A6%A6%E0%A6%B0%E0%A7%80+%E0%A6 brazzers-n.com http://brazzers-n.com/en/tgb/19789-%E0%A6%95%E0%A6%BE%E0%A6%B2%E0%A7%8B+%E0%A6%95%E0%A6%AE%E0%A7%8D%E0%A6 hdbox.ws https://hdbox.ws/en/sat-tv-novosti/5311-transpondernye-novosti-sputnikovogo-televideniya-11-maya-2018.html Ôªø hotpornohub.com http://hotpornohub.com/en/mov/11135847-closeup-creampie.html closeup Creampie|Sliding menu|HotPornoHub|M ecml.at http://edl.ecml.at/Participate/Materials/tabid/1769/language/en-GB/Default.aspx European Day of Languages &gt; Part hotpornohub.com http://hotpornohub.com/en/fatties Bbw porn videos in excellent quality|Sliding menu|HotPornoHub|Main (cu brazzers-n.com http://brazzers-n.com/en/tgb/15845-%E0%A6%B8%E0%A6%95+%E0%A6%AA%E0%A7%82%E0%A6%9C%E0%A6%BE/ Sock Worship pornoload-n.com http://pornoload-n.com/en/tag/11115-%D0%92+%D0%A8%D0%BA%D0%BE%D0%BB%D0%B5/ At School - Pornload best web pikeals.org https://pikeals.org/en/home English Porn Video - Free Porn Videos Xvideos, Pornhub, xnxx - Snapchat Cosplay| brazzers-n.com http://brazzers-n.com/en/tgb/14315-%E0%A6%B8%E0%A7%8D%E0%A6%A4%E0%A7%8D%E0%A6%B0%E0%A7%80+%E0%A6%9D%E0%A6 brazzers-n.com http://brazzers-n.com/en/tgb/112-%E0%A8%97%E0%A9%B0%E0%A8%A6%E0%A9%87+%E0%A8%A6%E0%A9%80+%E0%A8%9A%E0%A9% erkiss-tv.com http://erkiss-tv.com/en/tag_phone/1586-%E0%A6%AE%E0%A6%BE%E0%A6%B0%E0%A7%8D%E0%A6%9C%E0%A6%A8/ Rubbing - P ecml.at http://edl.ecml.at/Participate/Howtoparticipate/tabid/1766/language/en-GB/Default.aspx European Day of Languages ruporn-tv.com http://ruporn-tv.com/en/tag/381-%E0%A4%AC%E0%A4%BF%E0%A4%B2%E0%A5%8D%E0%A4%B2%E0%A5%80+%E0%A4%95%E0%A4%AE% brazzers-n.com http://brazzers-n.com/en/tgb/18853-%E0%A6%AA%E0%A6%A4%E0%A6%BF%E0%A6%A4+%E0%A6%9C%E0%A6%AE%E0%A6%BF/ Wast brazzers-n.com http://brazzers-n.com/en/tgb/21233-%E0%A6%85%E0%A6%AA%E0%A7%87%E0%A6%B6%E0%A6%BE%E0%A6%A6%E0%A6%BE%E0%A6% ruporn-tv.com http://ruporn-tv.com/en/tag/1494-%E0%A4%96%E0%A5%82%E0%A4%AC%E0%A4%B8%E0%A5%82%E0%A4%B0%E0%A4%A4+%E0%A4%B5 hdbox.ws https://hdbox.ws/en/sat-tv-novosti/3008-transpondernye-novosti-za-07-10-2016.html ¬ª Transponder news for 07.10 brazzers-n.com http://brazzers-n.com/en/tgb/10899-%E0%A4%A6%E0%A5%83%E0%A4%B6%E0%A5%8D%E0%A4%AF%E0%A4%B0%E0%A4%A4%E0%A4% brazzers-n.com http://brazzers-n.com/en/tgb/19829-%E0%A6%AC%E0%A6%BE%E0%A6%9C%E0%A7%87+%E0%A6%95%E0%A6%A5%E0%A6%BE%2C/ P brazzers-n.com http://brazzers-n.com/en/tgb/15812-%E0%A6%AC%E0%A7%8D%E0%A6%B0%E0%A6%BF%E0%A6%9F%E0%A6%BF%E0%A6%B6+%E0%A6 fuckedtonight.com http://www.fuckedtonight.com/en/ Free porn @ Fucked Tonight|FuckedTonight|English|ŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨|Gal brazzers-n.com http://brazzers-n.com/en/tgb/4173-%E0%A6%B8%E0%A7%8D%E0%A6%AC%E0%A6%B0%E0%A7%8D%E0%A6%A3%E0%A6%95%E0%A7%8 brazzers-n.com http://brazzers-n.com/en/tgb/21533-%E0%A4%B9%E0%A5%82%E0%A4%95%E0%A4%B0%2C/ Hooker Creampie - BRAZZERS po vporn-com.com http://vporn-com.com/en/tag/458-%D0%94%D0%BE%D1%82%D1%83%D1%83%D1%80+%D1%85%D1%83%D0%B2%D1%86%D0%B0%D1%81/ sozrelxxx.com http://sozrelxxx.com/en/tag/23492-%D3%98%D1%83%D0%B5%D1%81%D2%9B%D0%BE%D0%B9%D0%BB%D1%8B%D2%9B+%D0%96%D0%B brazzers-n.com http://brazzers-n.com/en/tgb/12632-%E0%A6%AC%E0%A6%BE%E0%A6%B9+%E0%A6%AC%E0%A7%83%E0%A6%A6%E0%A7%8D%E0%A6 pornoload-n.com http://pornoload-n.com/en/tag/8784-%E0%A6%86%E0%A6%AC%E0%A6%B9%E0%A6%BE%E0%A6%93%E0%A6%AF%E0%A6%BC%E0%A6 eporner-n.com http://eporner-n.com/en/negros Negros _ EPORNER|Menu|Main (current)|All categories|Random|English|–†—É—Å—Å ecml.at http://edl.ecml.at/Participate/Whocanparticipate/tabid/1765/language/en-GB/Default.aspx European Day of Language biqle-ru.com http://biqle-ru.com/en/t/35-%D0%97%D0%B0%D0%BB%D1%83%D1%83/ Young - Porno HD online in high quality on biql ecml.at http://edl.ecml.at/Participate/tabid/1764/language/en-GB/Default.aspx Participate|Home (Basque)|What is it?|Why erkiss-tv.com http://erkiss-tv.com/en/gangbang-gangbang Gangbang gangbang porn on phone|Menu|Main (current)|Random|Chat| pornoload-n.com http://pornoload-n.com/en/tag/255-Big+Dick Big Dick - Pornload best website with adult videos and porn c brazzers-n.com http://brazzers-n.com/en/tgb/16181-%E0%A6%A8%E0%A6%97%E0%A7%8D%E0%A6%A8+%E0%A6%AA%E0%A6%B0%E0%A7%8D%E0%A6 brazzers-n.com http://brazzers-n.com/en/feedback/ Feedback|Menu|Main (current)|Random video|Chat|All categories|English| xyutv-a.com http://xyutv-a.com/en/tag/1773-I+an+linn+Sn%C3%A1mha/ In the Pool - fuck TV PORN VIDEOS ONLINE - WATCH FREE lenkino.mobi http://lenkino.mobi/en/pg/4/ Porn videos in HD quality. This Lenkino porn online! Watch porn for free! - pa nakedgirls.org https://nakedgirls.org/ Naked Girls - Hot Nude Women &amp; Naked Teen Girls Videos|Skip to content|Home|Categ brazzers-n.com http://brazzers-n.com/en/tgb/1600-%E0%A6%8F%E0%A6%B6%E0%A6%BF%E0%A6%AF%E0%A6%BC%E0%A6%BE%E0%A6%A8/ Asian tube8-n.com http://tube8-n.com/en/otslaivanie Otslaivanie porn videos|Menu|Main (current)|View all|At random|English|–†ÔøΩ brazzers-n.com http://brazzers-n.com/en/tgb/7858-%E0%A6%AA%E0%A7%81%E0%A6%B0%E0%A7%81%2C+%E0%A6%86%E0%A6%AC%E0%A6%B2%E0% brazzers-n.com http://brazzers-n.com/en/tgb/16899-%E0%A6%AC%E0%A6%BE%E0%A6%B8%E0%A7%8D%E0%A6%A4%E0%A6%AC+%E0%A6%AA%E0%A7 ecml.at http://edl.ecml.at/Events/PictureGallery2012/tabid/3090/language/en-GB/Default.aspx Picture Gallery 2012|Home (B pornozal-net.com http://pornozal-net.com/en/tag/ Menu|Pornosu Porn|Main (current)|Random|Our categories|English|–†—É—Å—Å online-casino-10.pro http://online-casino-10.pro/en/reference/online_services/ online-casino-10.pro - Free Czech Porn Vi dojki-n.com http://dojki-n.com/en/latina Latina videos online in hd quality|Menu|Main (current)|Random video|All categor ruporn-tv.com http://ruporn-tv.com/en/moms Moms|Menu|Main (current)|Random|Category|English|–†—É—Å—Å–∫–∏–π|English|Az…ôr brazzers-n.com http://brazzers-n.com/en/footwork/ Footwork brazzers|Menu|Main (current)|Random video|Chat|All categories ruporn-tv.com http://ruporn-tv.com/en/m/10201287-nackt-im-wald.html Nackt im Wald|Menu|Main (current)|Random|Category|En ruporn-tv.com http://ruporn-tv.com/en/tag/17143-%E0%A4%A1%E0%A5%88%E0%A4%B0%E0%A4%BF%E0%A4%B2/ Darryl - Russian porn onl ruporn-tv.com http://ruporn-tv.com/en/tag/12421-%2C+%E0%A4%95%E0%A4%BE%E0%A4%AE/ MILF Work - Russian porn online watch f fucked-movies.com http://fucked-movies.com/en/ Fucked Movies|English|Afrikaans|ÿßŸÑÿπÿ±ÿ®Ÿäÿ©|Az…ôrbaycanca|–ë–µ–ª–∞—Ä—É xnxx-hd.pro http://xnxx-hd.pro/en/tag/16818-%E0%A6%AC%E0%A6%A1%E0%A6%BC%E0%A7%8B+%E0%A6%AE%E0%A6%BE%E0%A6%87+%E0%A6%A8%E brazzers-n.com http://brazzers-n.com/en/tgb/18992-%D0%9E%D1%85%D0%B8%D0%BD+%D0%A5%D0%B0%D1%88%D0%B3%D0%B8%D1%80%D1%87/ G biqle-ru.com http://biqle-ru.com/en/closeup Closeup porn videos|Menu|Main (current)|Random|Category|English|–†—É—Å—Å–∫–∏ brazzers-n.com http://brazzers-n.com/en/tgb/19541-%E0%A6%AC%E0%A6%BE%E0%A6%81%E0%A6%A1%E0%A6%BC%E0%A6%BE%E0%A6%B0+%E0%A6 pornoload-n.com http://pornoload-n.com/en/tag/19078-Melena/ Melena - Pornload best website with adult videos and porn cl brazzers-n.com http://brazzers-n.com/en/tgb/5183-%E0%B0%A8%E0%B0%B2%E0%B1%81%E0%B0%97%E0%B1%81%E0%B0%B0%E0%B1%81+%E0%B0% brazzers-n.com http://brazzers-n.com/en/tgb/7168-%E0%A6%B8%E0%A7%81%E0%A6%A8%E0%A7%8D%E0%A6%A6%E0%A6%B0%E0%A6%BF+%E0%A6% brazzers-n.com http://brazzers-n.com/en/tgb/11752-%E0%A6%9F%E0%A7%8D%E0%A6%AF%E0%A6%BE%E0%A6%95%E0%A7%8D%E0%A6%B8%E0%A6% brazzers-n.com http://brazzers-n.com/en/tgb/6306-%E0%A6%96%E0%A7%81%E0%A6%AC%2C+%E0%A6%B8%E0%A7%87%E0%A6%95%E0%A7%8D%E0% brazzers-n.com http://brazzers-n.com/en/tgb/590-%E0%A6%86%E0%A6%99%E0%A7%81%E0%A6%B2+%E0%A6%97%E0%A7%81%E0%A6%A6/ Finger pornk.mobi http://pornk.mobi/en/strapon/ Strapon porn pornk|Menu|Main (current)|Topics porn|Random video|Chat|English|–† brazzers-n.com http://brazzers-n.com/en/tgb/11643-%E0%A6%B8%E0%A7%8D%E0%A6%A4%E0%A7%8D%E0%A6%B0%E0%A7%80%2C+Cheats+%E0%A vporn-com.com http://vporn-com.com/en/tag/7184-%E0%A6%A1%E0%A6%AC%E0%A6%B2%2C+%E0%A6%B8%E0%A7%8D%E0%A6%9F%E0%A6%BE%E0%A6 lenkino.mobi http://lenkino.mobi/en/pg/6/ Porn videos in HD quality. This Lenkino porn online! Watch porn for free! - pa ecml.at http://edl.ecml.at/Contact/tabid/1519/language/en-GB/Default.aspx European Day of Languages &gt; Contact|Home (Basq brazzers-n.com http://brazzers-n.com/en/tgb/8238-%E0%A6%B0%E0%A6%BE%E0%A6%A4/ Nights - BRAZZERS porn Studio. Porn clips brazzers-n.com http://brazzers-n.com/en/tgb/6150-Hard+Ass+Fuck/ Hard Ass Fuck - BRAZZERS porn Studio. Porn clips brazzer pornoload-n.com http://pornoload-n.com/en/tag/7401-%E0%A8%B5%E0%A9%87%E0%A8%B8%E0%A8%BC%E0%A8%B5%E0%A8%BE+%E0%A8%A6%E0%A brazzers-n.com http://brazzers-n.com/en/tgb/9967-%E0%A6%85%E0%A6%AA%E0%A7%87%E0%A6%B6%E0%A6%BE%E0%A6%A6%E0%A6%BE%E0%A6%B brazzers-n.com http://brazzers-n.com/en/tgb/1545-%E0%A6%AC%E0%A6%BF%E0%A6%A6%E0%A6%BE%E0%A6%B0%E0%A6%A3/ Cleavage - BRAZ lenkino.mobi http://lenkino.mobi/en/tg/19868-%E0%A4%AC%E0%A4%A6%E0%A4%B8%E0%A5%82%E0%A4%B0%E0%A4%A4+%E0%A4%B5%E0%A5%89%E brazzers-n.com http://brazzers-n.com/en/tgb/9369-%E0%A6%AC%E0%A6%BE%E0%A6%81%E0%A6%A1%E0%A6%BC%E0%A6%BE%E0%A6%B0+%E0%A6% brazzers-n.com http://brazzers-n.com/en/tgb/5399-%E0%A6%97%E0%A6%B0%E0%A6%AE%2C+%E0%A6%AA%E0%A6%BE%E0%A6%AF%E0%A6%BC%E0% brazzers-n.com http://brazzers-n.com/en/tgb/13919-%E0%A6%AC%E0%A7%8D%E0%A6%B2%E0%A6%9C%E0%A6%AC+%E0%A6%AA%E0%A6%BE%E0%A6 brazzers-n.com http://brazzers-n.com/en/tgb/18500-%E0%A6%AF%E0%A7%8C%E0%A6%A8%E0%A6%A4%E0%A6%BE+%E0%A6%86%E0%A6%AE%E0%A6 brazzers-n.com http://brazzers-n.com/en/tgb/10664-%E0%A6%97%E0%A7%8B%E0%A6%B2%E0%A6%BE%E0%A6%AA%E0%A7%80+%E0%A6%AA%E0%A7 brazzers-n.com http://brazzers-n.com/en/tgb/4628-%E0%A6%9D%E0%A6%B0%E0%A6%A8%E0%A6%BE+%E0%A6%AE%E0%A6%9C%E0%A6%BE/ Showe 24video-xxx.com http://24video-xxx.com/en/tag/8784-Wetter+M%C3%A4dchen/ Weather Girl - 24video.xxx com porn watch online brazzers-n.com http://brazzers-n.com/en/tgb/18853-%E0%A8%B5%E0%A8%BF%E0%A8%B0%E0%A8%BE%E0%A8%A8/ Wasteland - BRAZZERS po brazzers-n.com http://brazzers-n.com/en/tgb/9408-%E0%A6%95%E0%A6%A6%E0%A6%B0%E0%A7%8D%E0%A6%AF+%E0%A6%AE%E0%A7%81%E0%A6% lenkino.mobi http://lenkino.mobi/en/rimjob/ Rimjob on lenkino|Anonymous chat !|18 years|720 HD video|BDSM|Big Tits|Casti hdbox.ws https://hdbox.ws/en/sat-tv-novosti/3714-transpondernye-novosti-za-23-11-2016.html ¬ª Transponder news for 23.11 lenkino.mobi http://lenkino.mobi/en/720-hd-video/ 720 HD video on lenkino|Arab porn|BDSM|Bikini|Bondage|Celebrity|Chines ruporn-tv.com http://ruporn-tv.com/en/moms/ Moms|Menu|Main (current)|Random|Category|English|–†—É—Å—Å–∫–∏–π|English|Az…ô brazzers-n.com http://brazzers-n.com/en/tgb/21948-%D2%AE%D0%BB%D0%BA%D0%B5%D0%BD+%D0%A1%D0%B8%D1%81%D1%8C%D0%BA%D0%B8+%D brazzers-n.com http://brazzers-n.com/en/mb/5552913-milf,-molto-troia.html Milf, molto Troia|Menu|Main (current)|Random v brazzers-n.com http://brazzers-n.com/en/tgb/3663-%E0%A6%AC%E0%A6%A1%E0%A6%BC+%E0%A6%B8%E0%A7%81%E0%A6%A8%E0%A7%8D%E0%A6% brazzers-n.com http://brazzers-n.com/en/ BRAZZERS porn Studio. Porn clips brazzers Studio and not only.|Menu|Main (curre ruporn-tv.com http://ruporn-tv.com/en/tag/3862-Par+Elske/ Couple Make Love - Russian porn online watch free video on Rup brazzers-n.com http://brazzers-n.com/en/tgb/20235-%D0%A2%D0%BE%D0%BC+%D0%98%D0%BB%D0%B6%D0%B8%D0%B3+Slut/ Big Ass Slut - brazzers-n.com http://brazzers-n.com/en/tgb/583-%E0%A6%87%E0%A6%A4%E0%A6%B0/ Hooker - BRAZZERS porn Studio. Porn clips b brazzers-n.com http://brazzers-n.com/en/tgb/44-%D0%93%D1%83%D1%80%D0%B2%D0%B0%D0%BB%D1%81%D0%B0%D0%BD+%D0%B3%D1%80%D1%83 trahtubetv.com http://trahtubetv.com/en/tag/3351-Te+Altra/ Hot Nurse - Fuck tube. Check out hot pussies. Porn videos for brazzers-n.com http://brazzers-n.com/en/tgb/353-%E0%A6%97%E0%A6%B0%E0%A6%AE+%E0%A6%B8%E0%A7%81%E0%A6%A8%E0%A7%8D%E0%A6%A erkiss-tv.com http://erkiss-tv.com/en/tag_phone/1977-%E0%A6%AC%E0%A6%A1%E0%A6%BC+%E0%A6%AE%E0%A7%8B%E0%A6%B0%E0%A6%97+%E brazzers-n.com http://brazzers-n.com/en/tgb/7870-%E0%A6%B8%E0%A7%81%E0%A6%A8%E0%A7%8D%E0%A6%A6%E0%A6%B0%E0%A6%BF+%E0%A6% vporn-com.com http://vporn-com.com/en/tag/16192-%E0%A6%95%E0%A6%BE%E0%A6%B2%E0%A7%8B+%E0%A6%AA%E0%A7%8D%E0%A6%AF%E0%A6%B ecml.at http://edl.ecml.at/Home/Whatisit/tabid/1760/language/en-GB/Default.aspx What is it?|Home (Basque)|What is it?|Wh 24video-xxx.com http://24video-xxx.com/en/tag/562-%D0%A5%D0%B0%D1%80%2C/ Black and - 24video.xxx com porn watch online, brazzers-n.com http://brazzers-n.com/en/tgb/11849-%E0%A6%A8%E0%A6%BF%E0%A6%9F%E0%A7%8B%E0%A6%B2+%E0%A6%AC%E0%A6%A1%E0%A6 brazzers-n.com http://brazzers-n.com/en/venezuelan/ Venezuelan brazzers|Menu|Main (current)|Random video|Chat|All catego pornoload-n.com http://pornoload-n.com/en/tag/36-%E0%A6%AC%E0%A6%A1%E0%A6%BC%E0%A7%8B+%E0%A6%AE%E0%A6%BE%E0%A6%87/page/4 vuku-cc.com http://vuku-cc.com/en/tag/ Menu|Main (current)|Random video|All categories|English|–†—É—Å—Å–∫–∏–π|English|Az brazzers-n.com http://brazzers-n.com/en/tgb/720-%E0%A6%9F%E0%A6%BE%E0%A6%87%E0%A6%9F+%E0%A6%AD%E0%A6%97+%E0%A6%B0%E0%A6% brazzers-n.com http://brazzers-n.com/en/tgb/11930-%E0%A6%AE%E0%A7%8D%E0%A6%AF%E0%A6%BE%E0%A6%A1%E0%A6%BF%E0%A6%B8%E0%A6% hdbox.ws https://hdbox.ws/en/soft/2288-skachat-plagin-emulyator-oscam-11272-arm-wetek-pod-libreelec-i-openelec.html ¬ª D brazzers-n.com http://brazzers-n.com/en/tgb/8193-%E0%A6%AC%E0%A7%83%E0%A6%A6%E0%A7%8D%E0%A6%A7%E0%A6%BE%2C+%E0%A6%AA%E0% brazzers-n.com http://brazzers-n.com/en/tgb/18928-%E0%A6%B6%E0%A6%BF%E0%A6%95%E0%A7%8D%E0%A6%B7%E0%A6%95+%E0%A6%A4%E0%A6 ruporn-tv.com http://ruporn-tv.com/en/tag/12421-MILF+Arbeid/ MILF Work - Russian porn online watch free video on Ruporn. brazzers-n.com http://brazzers-n.com/en/tgb/13249-%E0%A6%95%E0%A6%BF%E0%A6%AD%E0%A6%BE%E0%A6%AC%E0%A7%87+%E0%A6%AC%E0%A7 hdbox.ws https://hdbox.ws/en/sat-tv-novosti/5089-transpondernye-novosti-sputnikovogo-televideniya-17-fevralya-2018.html xvideos-a.com http://xvideos-a.com/en/vibrator/ View Vibrator|Navigation|On the main (current)|Random video|Sections|Eng brazzers-n.com http://brazzers-n.com/en/tgb/18868-%E0%A6%AA%E0%A7%8D%E0%A6%B0%E0%A7%87%E0%A6%AE%E0%A6%AE%E0%A7%82%E0%A6% brazzers-n.com http://brazzers-n.com/en/tgb/20478-%E0%A8%95%E0%A8%BE%E0%A8%B2%E0%A9%87+%E0%A8%85%E0%A8%A7%E0%A8%BF%E0%A8 brazzers-n.com http://brazzers-n.com/en/tgb/424-Tits+N%C3%A1d%C3%BArtha/ Natural Tits - BRAZZERS porn Studio. Porn clips brazzers-n.com http://brazzers-n.com/en/tgb/10968-%E0%A6%B8%E0%A7%87%E0%A6%95%E0%A7%8D%E0%A6%B8%2C+%E0%A6%95%E0%A7%8D%E0 brazzers-n.com http://brazzers-n.com/en/tgb/15712-%E0%A6%AA%E0%A7%8B%E0%A6%81%E0%A6%A6%2C+Big+Dick%2C/ Teen with Big Dic brazzers-n.com http://brazzers-n.com/en/bdsm/ BDSM brazzers|Menu|Main (current)|Random video|Chat|All categories|English brazzers-n.com http://brazzers-n.com/en/tgb/4871-%E0%A6%AA%E0%A7%8D%E0%A6%B0%E0%A7%87%E0%A6%AE+%E0%A6%9F%E0%A6%BE%E0%A6% eporner-n.com http://eporner-n.com/en/fisting Fisting _ EPORNER|Menu|Main (current)|All categories|Random|English|–†—É—Å pornoload-n.com http://pornoload-n.com/en/movie/9725122-hairy-monica-2.html Hairy Monica 2|Menu|PornoLoad|Main (current) brazzers-n.com http://brazzers-n.com/en/tgb/19745-%E0%A6%97%E0%A6%B0%E0%A6%AE%2C+%E0%A6%87%E0%A6%A4%E0%A6%BE%E0%A6%B2%E0 brazzers-n.com http://brazzers-n.com/en/tgb/21973-%E0%A8%95%E0%A8%88+Squirting/ Multiple Squirting - BRAZZERS porn Studi lenkino.mobi http://lenkino.mobi/en/tg/2050-%E0%A4%97%E0%A5%81%E0%A4%A6%E0%A4%BE+%E0%A4%AA%E0%A5%8D%E0%A4%AF%E0%A4%BE%E0 brazzers-n.com http://brazzers-n.com/en/tgb/16056-%E0%A6%B9%E0%A6%BF%E0%A6%A8%E0%A7%8D%E0%A6%A6%E0%A6%BF+%E0%A6%97%E0%A6 pornk.mobi http://pornk.mobi/en/negros Negros porn pornk|Menu|Main (current)|Topics porn|Random video|Chat|English|–†—ÉÔøΩ yaxochu.ru http://yaxochu.ru/en/tag/ Sliding menu|I want...|Main (current)|Category|Random video|English|–†—É—Å—Å–∫–∏–π| pornoload-n.com http://pornoload-n.com/en/massage/ Massage|Menu|PornoLoad|Main (current)|Random video|All categories|Eng brazzers-n.com http://brazzers-n.com/en/tgb/21924-%E0%A6%9C%E0%A6%BE%E0%A6%AA%E0%A6%BE%E0%A6%A8%E0%A6%BF+%E0%A6%B8%E0%A7 brazzers-n.com http://brazzers-n.com/en/mb/11116607-kigurumi.html kigurumi|Menu|Main (current)|Random video|Chat|All cat brazzers-n.com http://brazzers-n.com/en/otslaivanie/ Otslaivanie brazzers|Menu|Main (current)|Random video|Chat|All cate ruporn-tv.com http://ruporn-tv.com/en/tag/1505-Rubia+Folla/ Blonde Fucks - Russian porn online watch free video on Rupor brazzers-n.com http://brazzers-n.com/en/tgb/15787-%D0%A1%D0%BE%D0%BD%D0%B8%D1%80%D1%85%D0%BE%D0%B3%D1%87%D0%B4%D1%8B%D0% brazzers-n.com http://brazzers-n.com/en/tgb/41-%E0%A6%97%E0%A7%81%E0%A6%A6/ Pussy - BRAZZERS porn Studio. Porn clips bra pornk.mobi http://pornk.mobi/en/bikini/ Bikini porn pornk|Menu|Main (current)|Topics porn|Random video|Chat|English|–†—É brazzers-n.com http://brazzers-n.com/en/cb/ The list of all categories|Menu|Main (current)|Random video|Chat|All categor brazzers-n.com http://brazzers-n.com/en/tgb/18721-%E0%A6%B9%E0%A6%BE%E0%A6%81%E0%A6%9F%E0%A7%81+%E0%A6%89%E0%A6%9A%E0%A7 xnxx-hd.pro http://xnxx-hd.pro/en/cts/ The list of all categories|100% free porn videos sex content|Search|Main (current brazzers-n.com http://brazzers-n.com/en/tgb/1972-%E0%A6%AC%E0%A6%BF%E0%A6%B0%E0%A6%95%E0%A7%8D%E0%A6%A4+%E0%A6%95%E0%A6% lenkino.mobi http://lenkino.mobi/en/rimjob Rimjob on lenkino|Anonymous chat !|Amateurs|Big Tits|Bisexual|Cartoon adult|C 24video-xxx.com http://24video-xxx.com/en/m/3377548-moms.html Moms|To switch the language|–†—É—Å—Å–∫–∏–π|English|Az…ôrba brazzers-n.com http://brazzers-n.com/en/fisting/ Fisting brazzers|Menu|Main (current)|Random video|Chat|All categories|E dojki-n.com http://dojki-n.com/en/threesome Threesome sex videos online in hd quality|Menu|Main (current)|Random video|A brazzers-n.com http://brazzers-n.com/en/tgb/8579-%E0%A6%86%E0%A6%B6%E0%A7%8D%E0%A6%9A%E0%A6%B0%E0%A7%8D%E0%A6%AF%E0%A6%9 brazzers-n.com http://brazzers-n.com/en/tgb/4203-%E0%A6%AD%E0%A6%BE%E0%A6%97%E0%A7%8D%E0%A6%AF%E0%A6%AC%E0%A6%BE%E0%A6%A ruporn-tv.com http://ruporn-tv.com/en/tag/8058-%E0%A8%B5%E0%A8%BF%E0%A8%86%E0%A8%B9/ Wedding - Russian porn online watch brazzers-n.com http://brazzers-n.com/en/tgb/2703-%E0%A6%95%E0%A6%B0%E0%A7%8D%E0%A6%AE%E0%A6%9A%E0%A6%BE%E0%A6%B0%E0%A7%8 xnxx-hd.pro http://xnxx-hd.pro/en/striptease/ Striptease high quality videos for You.|100% free porn videos sex content| pornoload-n.com http://pornoload-n.com/en/tag/429-Coileach+M%C3%B3r/ Big Cock - Pornload best website with adult videos trahtubetv.com http://trahtubetv.com/en/yoga/ Yoga|Menu|Tractor|Main (current)|Random video|All categories|English|–†—ÉÔøΩ brazzers-n.com http://brazzers-n.com/en/tgb/9098-%E0%A6%8F%E0%A6%95+%E0%A6%AE%E0%A6%B9%E0%A6%BF%E0%A6%B2%E0%A6%BE+%E0%A6 ruporn-tv.com http://ruporn-tv.com/en/vibrator/p/6/ Vibrator - page 6|Menu|Main (current)|Random|Category|English|–†—É—Å brazzers-n.com http://brazzers-n.com/en/tgb/22349-%E0%A6%B8%E0%A7%8D%E0%A6%AC%E0%A6%BE%E0%A6%AE%E0%A7%80/ Teagan - BRAZZ brazzers-n.com http://brazzers-n.com/en/tgb/15966-%E0%A6%AC%E0%A6%BE%E0%A6%B8%E0%A7%8D%E0%A6%A4%E0%A6%AC+%E0%A6%AE%E0%A7 brazzers-n.com http://brazzers-n.com/en/tgb/15712-%D9%81%D9%8A+%D8%B3%D9%86+%D8%A7%D9%84%D9%85%D8%B1%D8%A7%D9%87%D9%82%D brazzers-n.com http://brazzers-n.com/en/tgb/16875-%E0%A6%B0%E0%A6%BE%E0%A6%A4%E0%A7%87%E0%A6%B0+%E0%A6%B8%E0%A6%AE%E0%A6 ecml.at http://edl.ecml.at/LanguageFun/LanguageTreasures/tabid/1533/language/en-GB/Default.aspx Language Treasures|Home brazzers-n.com http://brazzers-n.com/en/tgb/13598-%D0%94%D0%B0%D1%80%D0%BE%D0%B2+%D0%90%D0%BB%D0%BB%D0%B0/ Suck Tits - B vporn-com.com http://vporn-com.com/en/tag/7184-Duplo+Recheado/ Double Stuffed - porn - Best porn videos and Sex XXX movi hotpornohub.com http://hotpornohub.com/en/dildo Dildo porn videos in excellent quality|Sliding menu|HotPornoHub|Main (cu pornoload-n.com http://pornoload-n.com/en/movie/9135781-piss.html piss|Menu|PornoLoad|Main (current)|Random video|All ca ecml.at http://edl.ecml.at/Participate/Materials/Logo/tabid/1526/language/en-GB/Default.aspx Logo|Home|What is it?|Why a dojki-n.com http://dojki-n.com/en/amateurs Amateurs videos online in hd quality|Menu|Main (current)|Random video|All cat ruporn-tv.com http://ruporn-tv.com/en/tag/3499-%D0%97%D1%83%D0%B7%D0%B0%D0%B0%D0%BD+Chubby/ Thick Chubby - Russian porn cucek.net http://cucek.net/en/pg/5/ No Boobs. While there, enjoy selective porn. - page 5|Sliding menu|Cucek.NET|Main (c brazzers-n.com http://brazzers-n.com/en/tgb/20099-%E0%A6%AA%E0%A6%A6%E0%A6%AC%E0%A7%8D%E0%A6%B0%E0%A6%9C%E0%A7%87+%E0%A6 pornoload-n.com http://pornoload-n.com/en/movie/524228-redheaded-moms-crave-orgasm.html Redheaded moms crave orgasm|Menu hdbox.ws https://hdbox.ws/en/sat-tv-novosti/4060-transpondernye-novosti-za-05-01-2017.html ¬ª Transponder news for 05.01 online-casino-10.pro http://online-casino-10.pro/en/ FakeTaxi - English Escort Girl Amber Jayne - online-casino-10.pro|M xnxx-hd.pro http://xnxx-hd.pro/en/mvi/54585-hairy-pussy-whores-ufa.html Hairy pussy whores Ufa|100% free porn videos sex lustful.tv http://www.lustful.tv/en/ Free porn @ Lustful TV|LustfulTV|English|ŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨|Galego|◊ô◊ô÷¥◊ì◊ô◊©|‡∏†ÔøΩ hotpornadult.com http://hotpornadult.com/en/tag/733-Pullea/ Chubby - HotPornAdult - porn in HD|Free porn videos online|S brazzers-n.com http://brazzers-n.com/en/tgb/4273-%E0%A6%B8%E0%A6%A4%E0%A7%8D%E0%A6%AF+%E0%A6%AC%E0%A6%BE+Dare/ Truth or 24video-net.com http://24video-net.com/en/tag/124-Fucked Fucked - 24video xxx porn watch online, porn videos for free 24 biqle-ru.com http://biqle-ru.com/en/cs/ The list of all categories|Menu|Main (current)|Random|Category|English|–†—É—Å—ÅÔøΩ pornk.mobi http://pornk.mobi/en/pcts/full/ The list of all categories|Menu|Main (current)|Topics porn|Random video|Chat| pornoload-n.com http://pornoload-n.com/en/movie/3754286-voyeur-pissing-13.html Voyeur pissing 13|Menu|PornoLoad|Main (cu sozrelxxx.com http://sozrelxxx.com/en/feedback/ Feedback|ripe for porn|Bondage|British|Cartoon adult|Changed|Dildo|Dirty dojki-n.com http://dojki-n.com/en/hairy-pussy Hairy pussy videos online in hd quality|Menu|Main (current)|Random video|A brazzers-n.com http://brazzers-n.com/en/tgb/22723-%E0%A6%95%E0%A6%BE%E0%A6%B2%E0%A7%8B%2C+%E0%A6%B8%E0%A7%81%E0%A6%A8%E0 pornoload-n.com http://pornoload-n.com/en/movie/11258860-turkije.html turkije|Menu|PornoLoad|Main (current)|Random video brazzers-n.com http://brazzers-n.com/en/tgb/2526-%E0%A6%AA%E0%A6%B0%E0%A6%BF%E0%A6%A3%E0%A6%A4%2C+%E0%A6%B8%E0%A7%8D%E0% drtuber-n.com http://drtuber-n.com/en/striptease/ Striptease porn videos DrTuber|Sliding menu|Main (current)|Random vide brazzers-n.com http://brazzers-n.com/en/tgb/17799-%E0%A6%B8%E0%A7%81%E0%A6%A8%E0%A7%8D%E0%A6%A6%E0%A6%B0%E0%A6%BF+%E0%A6 brazzers-n.com http://brazzers-n.com/en/tgb/9965-%E0%A6%B8%E0%A7%81%E0%A6%A8%E0%A7%8D%E0%A6%A6%E0%A6%B0%E0%A6%BF+%E0%A6% hotpornohub.com http://hotpornohub.com/en/next/6/ Cool porn video from hotpornohub.com! - page 6|Sliding menu|HotPornoHu brazzers-n.com http://brazzers-n.com/en/tgb/9050-18%2C+%E0%A6%AA%E0%A7%8B%E0%A6%81%E0%A6%A6%2C/ 18 Anal - BRAZZERS porn brazzers-n.com http://brazzers-n.com/en/tgb/10246-%E0%A6%85%E0%A6%AA%E0%A7%87%E0%A6%B6%E0%A6%BE%E0%A6%A6%E0%A6%BE%E0%A6% trahtubetv.com http://trahtubetv.com/en/blonde Blonde|Menu|Tractor|Main (current)|Random video|All categories|English|–† pornoload-n.com http://pornoload-n.com/en/celebrity/ Celebrity|Menu|PornoLoad|Main (current)|Random video|All categories xnxx-hd.pro http://xnxx-hd.pro/en/tag/16818-%E0%A8%B5%E0%A9%B1%E0%A8%A1%E0%A9%87+%E0%A8%9A%E0%A9%82%E0%A8%9A%E0%A8%95+%E brazzers-n.com http://brazzers-n.com/en/tgb/1212-%E0%A6%AE%E0%A7%87%E0%A6%AF%E0%A6%BC%E0%A7%87%E0%A6%A6%E0%A7%87%E0%A6%B ruporn-tv.com http://ruporn-tv.com/en/tag/7326-T%C3%AB+Par%C3%AB+Gjat%C3%AB+Gjith%C3%AB/ See Thru - Russian porn online 24video-xxx.com http://24video-xxx.com/en/porn-orgasms Porn orgasms this category contains selected videos in HD quality pornk.mobi http://pornk.mobi/en/big-breasts/ Big breast porn pornk|Menu|Main (current)|Topics porn|Random video|Chat|Eng brazzers-n.com http://brazzers-n.com/en/tgb/84-%D0%A2%D0%BE%D0%BC+%D0%9E%D1%85%D0%B8%D0%BD+%D0%A5%D1%83%D0%BB%D0%B0%D0%B ecml.at http://edl.ecml.at/Events/PictureGallery2013/tabid/3122/language/en-GB/Default.aspx European Day of Languages &gt; brazzers-n.com http://brazzers-n.com/en/tgb/4962-%E0%A6%AC%E0%A6%A1%E0%A6%BF%E0%A6%AC%E0%A6%BF%E0%A6%B2%E0%A7%8D%E0%A6%A brazzers-n.com http://brazzers-n.com/en/tgb/3101-%E0%A6%A6%E0%A7%81%E0%A6%B7%E0%A7%8D%E0%A6%9F%E0%A7%81+%E0%A6%85%E0%A6% brazzers-n.com http://brazzers-n.com/en/tgb/20478-%E0%A6%95%E0%A6%BE%E0%A6%B2%E0%A7%8B+%E0%A6%B6%E0%A6%BF%E0%A6%95%E0%A7 xhamster-n.com http://xhamster-n.com/en/otslaivanie/ Otslaivanie free|Sliding menu|Main (current)|Random video|All categ brazzers-n.com http://brazzers-n.com/en/tgb/12973-%E0%A6%AB%E0%A6%BE%E0%A6%B2%E0%A6%BE%2C+%E0%A6%AE%E0%A7%87%E0%A6%B0%E0 brazzers-n.com http://brazzers-n.com/en/tgb/19634-%E0%A6%AE%E0%A6%BE/ Seduced by a Cougar - BRAZZERS porn Studio. Porn c brazzers-n.com http://brazzers-n.com/en/tgb/21794-%E0%A6%AA%E0%A7%8B%E0%A6%81%E0%A6%A6+%E0%A6%96%E0%A7%87%E0%A6%B2%E0%A6 24video-xxx.com http://24video-xxx.com/en/footwork/ The footwork in this category, collected the best video in HD qualit brazzers-n.com http://brazzers-n.com/en/tgb/19378-%E0%A6%B9%E0%A7%8D%E0%A6%AF%E0%A6%BE%E0%A6%B0%E0%A6%BF%E0%A6%B8/ Harri cucek.net http://cucek.net/en/mcuc/10978279-busty-flexibe-babe-fucking-ruporn.tv.html Busty flexibe babe fucking ruporn. brazzers-n.com http://brazzers-n.com/en/tgb/9820-Bavarian/ Bavarian - BRAZZERS porn Studio. Porn clips brazzers Studio a brazzers-n.com http://brazzers-n.com/en/tgb/12297-%E0%A6%AA%E0%A7%8D%E0%A6%B0%E0%A6%BE%E0%A6%95%E0%A7%83%E0%A6%A4%E0%A6% ruporn-tv.com http://ruporn-tv.com/en/tag/255-%E0%A4%AC%E0%A4%BF%E0%A4%97+%E0%A4%A1%E0%A4%BF%E0%A4%95/ Big Dick - Russia vporn-com.com http://vporn-com.com/en/gangbang Gangbang only on anysex|Menu|Main (current)|Random video|All categories|E .",
            "url": "https://jimregan.github.io/notes/badmt/irish/2021/06/05/cc-aligned-irish-porn.html",
            "relUrl": "/badmt/irish/2021/06/05/cc-aligned-irish-porn.html",
            "date": " ‚Ä¢ Jun 5, 2021"
        }
        
    
  
    
        ,"post69": {
            "title": "Extract CUDA from Kaldi docker image",
            "content": "%cd /tmp . !git clone https://github.com/jjlin/docker-image-extract/ . !docker-image-extract/docker-image-extract kaldiasr/kaldi:gpu-latest . %cd output/ . !find . -name &#39;*cudnn*&#39; -or -name &#39;*cuda*&#39; . !tar cvf /kaggle/working/cuda.tar ./usr/local/cuda-10.0/ ./usr/include/cudnn.h ./usr/include/x86_64-linux-gnu/cudnn_v7.h ./usr/include/linux/cuda.h ./usr/lib/x86_64-linux-gnu/libcudnn* .",
            "url": "https://jimregan.github.io/notes/asr/kaggle/2021/06/04/extract-cuda-from-kaldi-docker.html",
            "relUrl": "/asr/kaggle/2021/06/04/extract-cuda-from-kaldi-docker.html",
            "date": " ‚Ä¢ Jun 4, 2021"
        }
        
    
  
    
        ,"post70": {
            "title": "Multidict scraper",
            "content": "import requests from bs4 import BeautifulSoup def scrapepage(pageid): page = requests.get(f&#39;https://multidict.net/clilstore/page.php?id={pageid}&#39;) soup = BeautifulSoup(page.text, &#39;html.parser&#39;) body = soup.find(&#39;body&#39;) bodytext = body.find(&#39;div&#39;, {&#39;class&#39;: &#39;body-indent&#39;}) text = [tmp.text for tmp in bodytext.findAll(&#39;p&#39;)] iframe = bodytext.findAll(&#39;iframe&#39;) return iframe[0][&#39;src&#39;], text . print(scrapepage(&#39;8839&#39;)) . headers = { &quot;accept&quot;: &quot;text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9&quot;, &quot;accept-language&quot;: &quot;en-US,en;q=0.9,pl;q=0.8,ga;q=0.7,en-GB;q=0.6&quot;, &quot;cache-control&quot;: &quot;max-age=0&quot;, &quot;content-type&quot;: &quot;application/x-www-form-urlencoded&quot;, &quot;sec-ch-ua&quot;: &quot; &quot; Not A;Brand &quot;;v= &quot;99 &quot;, &quot;Chromium &quot;;v= &quot;90 &quot;, &quot;Google Chrome &quot;;v= &quot;90 &quot;&quot;, &quot;sec-ch-ua-mobile&quot;: &quot;?0&quot;, &quot;sec-fetch-dest&quot;: &quot;document&quot;, &quot;sec-fetch-mode&quot;: &quot;navigate&quot;, &quot;sec-fetch-site&quot;: &quot;same-origin&quot;, &quot;sec-fetch-user&quot;: &quot;?1&quot;, &quot;upgrade-insecure-requests&quot;: &quot;1&quot; } . s = requests.Session() s.headers.update(headers) s.get(&quot;https://multidict.net/clilstore/&quot;) s.headers.update({&#39;referer&#39;: &quot;https://multidict.net/clilstore/&quot;}) x = s.post(&quot;https://multidict.net/clilstore/&quot;, data=&quot;sl=ga&amp;filterForm=1&amp;title=&amp;text=&amp;showAll=showAll&quot;) . listsoup = BeautifulSoup(x.text, &#39;html.parser&#39;) . table = listsoup.find(&#39;table&#39;, {&#39;id&#39;: &#39;main&#39;}) . links = table.findAll(&#39;a&#39;) . def attrstartswith(tag, attr, needle): return tag.attrs and attr in tag.attrs and tag.attrs[attr].startswith(needle) . def collectlinks(links): out = [] for link in links: if attrstartswith(link, &#39;href&#39;, &#39;/cs/&#39;): out.append(link.attrs[&#39;href&#39;][4:]) return out .",
            "url": "https://jimregan.github.io/notes/asr/irish/todo/2021/06/02/multidict-scraper.html",
            "relUrl": "/asr/irish/todo/2021/06/02/multidict-scraper.html",
            "date": " ‚Ä¢ Jun 2, 2021"
        }
        
    
  
    
        ,"post71": {
            "title": "wav2vec-u Common Voice Swedish - GAN training, CPU1",
            "content": "Original here . Preparation . %%capture !conda install -c pykaldi pykaldi -y . %cd /tmp . /tmp . !git clone https://github.com/jimregan/fairseq/ --branch issue3581 . !git clone https://github.com/kpu/kenlm . %%capture !apt-get -y install libeigen3-dev liblzma-dev zlib1g-dev libbz2-dev . %%capture %cd /tmp/kenlm !python setup.py install %cd /tmp . import os os.environ[&#39;PATH&#39;] = f&quot;{os.environ[&#39;PATH&#39;]}:/tmp/kenlm/build/bin/&quot; os.environ[&#39;FAIRSEQ_ROOT&#39;] = &#39;/tmp/fairseq&#39; . %cd /tmp/fairseq/ . /tmp/fairseq . %%capture !python setup.py install . %cd /tmp/fairseq/ . /tmp/fairseq . os.environ[&#39;HYDRA_FULL_ERROR&#39;] = &#39;1&#39; . %%capture !pip install editdistance . GAN . %%writefile rungan.sh PREFIX=w2v_unsup_gan_xp TASK_DATA=/kaggle/input/wav2vec-u-cv-swedish-audio/precompute_pca512_cls128_mean_pooled/ TEXT_DATA=/kaggle/input/wav2vec-u-cv-swedish-text-prep/preppedtext/phones/ KENLM_PATH=/kaggle/input/wav2vec-u-cv-swedish-text-prep/preppedtext/phones/lm.phones.filtered.04.bin PREFIX=$PREFIX fairseq-hydra-train -m --config-dir fairseq/config/model/wav2vecu/gan --config-name w2vu task.data=${TASK_DATA} task.text_data=${TEXT_DATA} task.kenlm_path=${KENLM_PATH} checkpoint.no_epoch_checkpoints=false checkpoint.keep_last_epochs=20 checkpoint.save_dir=/kaggle/working &#39;common.seed=range(0,5)&#39; . Writing rungan.sh . !bash rungan.sh .",
            "url": "https://jimregan.github.io/notes/kaggle/wav2vec-u/2021/06/01/wav2vec-u-cv-swedish-gan-cpu1.html",
            "relUrl": "/kaggle/wav2vec-u/2021/06/01/wav2vec-u-cv-swedish-gan-cpu1.html",
            "date": " ‚Ä¢ Jun 1, 2021"
        }
        
    
  
    
        ,"post72": {
            "title": "wav2vec-u CV-sv - GAN",
            "content": "The original attempt on Kaggle won&#39;t run because of an issue with CuDNN, but this notebook runs fine on Colab. . Preparation . !pip install condacolab . Collecting condacolab Downloading https://files.pythonhosted.org/packages/ee/47/6f9fe13087c31aba889c4b09f9beaa558bf216bf9108c9ccef44e6c9dcfe/condacolab-0.1.2-py3-none-any.whl Installing collected packages: condacolab Successfully installed condacolab-0.1.2 . import condacolab condacolab.install() . ‚è¨ Downloading https://github.com/jaimergp/miniforge/releases/latest/download/Mambaforge-colab-Linux-x86_64.sh... üì¶ Installing... üìå Adjusting configuration... ü©π Patching environment... ‚è≤ Done in 0:00:36 üîÅ Restarting kernel... . %%capture !conda install -c pykaldi pykaldi -y . !git clone https://github.com/jimregan/fairseq/ --branch issue3581 . Cloning into &#39;fairseq&#39;... remote: Enumerating objects: 28296, done. remote: Total 28296 (delta 0), reused 0 (delta 0), pack-reused 28296 Receiving objects: 100% (28296/28296), 11.77 MiB | 24.69 MiB/s, done. Resolving deltas: 100% (21286/21286), done. . !git clone https://github.com/kpu/kenlm . Cloning into &#39;kenlm&#39;... remote: Enumerating objects: 13824, done. remote: Counting objects: 100% (137/137), done. remote: Compressing objects: 100% (79/79), done. remote: Total 13824 (delta 76), reused 92 (delta 45), pack-reused 13687 Receiving objects: 100% (13824/13824), 5.49 MiB | 20.76 MiB/s, done. Resolving deltas: 100% (7956/7956), done. . %%capture !apt-get -y install libeigen3-dev liblzma-dev zlib1g-dev libbz2-dev . %%capture %cd /content/kenlm !python setup.py install %cd /tmp . import os os.environ[&#39;PATH&#39;] = f&quot;{os.environ[&#39;PATH&#39;]}:/content/kenlm/build/bin/&quot; os.environ[&#39;FAIRSEQ_ROOT&#39;] = &#39;/content/fairseq&#39; . %cd /content/fairseq/ . /content/fairseq . %%capture !python setup.py install . os.environ[&#39;HYDRA_FULL_ERROR&#39;] = &#39;1&#39; . %%capture !pip install editdistance . https://colab.research.google.com/github/corrieann/kaggle/blob/master/kaggle_api_in_colab.ipynb . %%capture !pip install kaggle . from google.colab import files uploaded = files.upload() for fn in uploaded.keys(): print(&#39;User uploaded file &quot;{name}&quot; with length {length} bytes&#39;.format( name=fn, length=len(uploaded[fn]))) # Then move kaggle.json into the folder where the API expects to find it. !mkdir -p ~/.kaggle/ &amp;&amp; mv kaggle.json ~/.kaggle/ &amp;&amp; chmod 600 ~/.kaggle/kaggle.json . Upload widget is only available when the cell has been executed in the current browser session. Please rerun this cell to enable. Saving kaggle.json to kaggle.json User uploaded file &#34;kaggle.json&#34; with length 64 bytes . %cd /content . /content . !kaggle datasets download &quot;jimregan/w2vu-cvsv-prepared-text&quot; . Downloading w2vu-cvsv-prepared-text.zip to /content 75% 13.0M/17.4M [00:00&lt;00:00, 55.1MB/s] 100% 17.4M/17.4M [00:00&lt;00:00, 64.5MB/s] . %%capture !unzip /content/w2vu-cvsv-prepared-text.zip . !kaggle datasets download -d jimregan/w2vu-cvsv-precompute-pca512-cls128-mean-pooled . Downloading w2vu-cvsv-precompute-pca512-cls128-mean-pooled.zip to /content 98% 386M/394M [00:04&lt;00:00, 90.1MB/s] 100% 394M/394M [00:04&lt;00:00, 102MB/s] . %%capture !unzip w2vu-cvsv-precompute-pca512-cls128-mean-pooled.zip . !rm *.zip . GAN . import torch torch.version.cuda . &#39;10.1&#39; . torch.backends.cudnn.version() . 7603 . %cd /content/fairseq . /content/fairseq . from google.colab import drive drive.mount(&#39;/content/drive&#39;) . %%writefile rungan.sh PREFIX=w2v_unsup_gan_xp TASK_DATA=/content/precompute_pca512_cls128_mean_pooled TEXT_DATA=/content/preppedtext/phones/ KENLM_PATH=/content/preppedtext/phones/lm.phones.filtered.04.bin PREFIX=$PREFIX CUDA_LAUNCH_BLOCKING=1 fairseq-hydra-train -m --config-dir fairseq/config/model/wav2vecu/gan --config-name w2vu task.data=${TASK_DATA} task.text_data=${TEXT_DATA} task.kenlm_path=${KENLM_PATH} checkpoint.no_epoch_checkpoints=true checkpoint.save_dir=/content/drive/MyDrive/w2vu &#39;common.seed=range(0,5)&#39; . Writing rungan.sh . !bash rungan.sh . [2021-06-04 00:06:14,189][fairseq.tasks.unpaired_audio_text][INFO] - REF: …õ n f ≈ì  Ç …ô n a d …µ  Ç …ô k t f √∏Àê r d eÀê t s …î m h …õ n d …ô p oÀê …ï ≈ì r k …î n s …õ t …ô n [2021-06-04 00:06:14,192][fairseq.tasks.unpaired_audio_text][INFO] - HYP: oÀê b iÀê  É ≈ì m …ï m ≈ì …ï …™ …µ …ï …µ m …µ s …µ uÀê …µ s …µ …õ  Ç a tÀê sx [2021-06-04 00:06:14,198][fairseq.tasks.unpaired_audio_text][INFO] - LM [REF]: -53.44462585449219, 0.05339602260269112 [2021-06-04 00:06:14,198][fairseq.tasks.unpaired_audio_text][INFO] - LM [HYP]: -61.104984283447266, 0.006571721232914821 [2021-06-04 00:06:14,844][valid][INFO] - {&#34;epoch&#34;: 8, &#34;valid_loss&#34;: &#34;0.93&#34;, &#34;valid_ntokens&#34;: &#34;3039.79&#34;, &#34;valid_nsentences&#34;: &#34;144.214&#34;, &#34;valid_lm_score_sum&#34;: &#34;-71760.8&#34;, &#34;valid_num_pred_chars&#34;: &#34;28972&#34;, &#34;valid_vocab_seen_pct&#34;: &#34;0.949477&#34;, &#34;valid_uer&#34;: &#34;92.9812&#34;, &#34;valid_weighted_lm_ppl&#34;: &#34;229.386&#34;, &#34;valid_lm_ppl&#34;: &#34;206.793&#34;, &#34;valid_wps&#34;: &#34;15426&#34;, &#34;valid_wpb&#34;: &#34;3039.8&#34;, &#34;valid_bsz&#34;: &#34;144.2&#34;, &#34;valid_num_updates&#34;: &#34;128&#34;, &#34;valid_best_weighted_lm_ppl&#34;: &#34;189.002&#34;} [2021-06-04 00:06:14,846][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 8 @ 128 updates [2021-06-04 00:06:14,847][fairseq.trainer][INFO] - Saving checkpoint to /content/drive/MyDrive/w2vu/checkpoint8.pt [2021-06-04 00:06:14,911][fairseq.trainer][INFO] - Finished saving checkpoint to /content/drive/MyDrive/w2vu/checkpoint8.pt [2021-06-04 00:06:14,974][fairseq.checkpoint_utils][INFO] - Saved checkpoint /content/drive/MyDrive/w2vu/checkpoint8.pt (epoch 8 @ 128 updates, score 229.38563413598007) (writing took 0.12713056299980963 seconds) .",
            "url": "https://jimregan.github.io/notes/kaggle/colab/wav2vec-u/2021/05/30/wav2vec-u-cv-swedish-gan.html",
            "relUrl": "/kaggle/colab/wav2vec-u/2021/05/30/wav2vec-u-cv-swedish-gan.html",
            "date": " ‚Ä¢ May 30, 2021"
        }
        
    
  
    
        ,"post73": {
            "title": "Find datives in Unimorph",
            "content": "Unimorph&#39;s Irish extraction from Wiktionary is basically useless: nouns don&#39;t include gender, they extract contexts instead of forms, and only extract the first of multiple contexts; their tagset is bizarre and incomplete regarding Irish. About the only thing it&#39;s even potentially good for is finding the dative forms of nouns (without doing a full wiktionary extraction). . with open(&#39;../input/unimorph-gle/gle&#39;, &#39;r&#39;) as crap: for line in crap.readlines(): if line.strip() == &#39;&#39;: continue parts = line.split(&#39; t&#39;) if len(parts) &lt; 3: print(f&#39;Junk: &lt;{parts[0]}&gt; &lt;{parts[1]}&gt;&#39;) if parts[2] == &#39;N;DAT;SG&#39; and parts[0] != parts[1]: print(f&#39;{parts[0]} t{parts[1]}&#39;) elif parts[2] == &#39;N;DAT;SG;DEF&#39;: form = parts[2].replace(&#39;leis an &#39;, &#39;&#39;) if len(form) &gt; 3 and form[0:2] == &#39;bhf&#39; or form[0:1] == &#39;n-&#39;: if parts[0] != form[2:]: print(f&#39;{parts[0]} t{form[2:]}&#39;) elif len(form) &gt; 2 and form[0:1] in [&#39;mb&#39;, &#39;gc&#39;, &#39;nd&#39;, &#39;ng&#39;, &#39;bp&#39;, &#39;dt&#39;]: if parts[0] != form[1:]: print(f&#39;{parts[0]} t{form[1:]}&#39;) else: continue .",
            "url": "https://jimregan.github.io/notes/irish/unimorph/2021/05/29/find-datives-in-unimorph-gle.html",
            "relUrl": "/irish/unimorph/2021/05/29/find-datives-in-unimorph-gle.html",
            "date": " ‚Ä¢ May 29, 2021"
        }
        
    
  
    
        ,"post74": {
            "title": "Compiling Kaldi on Kaggle",
            "content": "Original . Kaldi is a bit of a beast to install. I tried to get around it by extracting files from the official docker image: tl;dr, it works fine for the tools that run on CPU, but the GPU-based tools depend on CUDA 10.0, while Kaggle&#39;s GPU images use CUDA 11.0. . I&#39;m building this in /opt to match the docker extraction notebook. . %cd /opt . !git clone https://github.com/kaldi-asr/kaldi . I&#39;m installing cudatoolkit to make sure it&#39;s there, and the same version as the one in the gpu docker image, because issues with that are why I&#39;m compiling this in the first place. You can quite possibly get away with not running this step, but I&#39;m not taking a chance on it. If you are going to re-run this, make sure to check the gpu docker image to match the version for cudatoolkit. . #!conda install cudatoolkit=11.0 -y . !conda install cudatoolkit-dev=11.0 . %%capture !apt-get -y install liblapack-dev sox . First step is to follow the instructions in kaldi/tools . %cd /opt/kaldi/tools . The INSTALL file says to run extras/check_dependencies.sh, fix anything that&#39;s missing, and then run make. It&#39;s unlikely that new dependencies will be added (Kaldi more in maintenance mode than active development), but just in case, uncomment the line in the next cell and run it. . #!./extras/check_dependencies.sh . This is what I was missing from the check_dependencies check: . %%capture !apt-get -y install automake autoconf gfortran subversion . %%capture !make . Next,we need a maths library: . %%capture !extras/install_openblas.sh . Now is the time to build any of the optional dependencies you might want. I want phonetisaurus. . %%capture !bash extras/install_phonetisaurus.sh . I had problems with phonetisaurus-apply from the branch installed by install_phonetisaurus.sh, so I&#39;m replacing it with an updated version from the phonetisaurus repo: . %%writefile /opt/kaldi/tools/phonetisaurus-g2p/src/scripts/phonetisaurus-apply #!/usr/bin/env python # -*- mode: python; coding: utf-8 -*- from __future__ import print_function from __future__ import unicode_literals import os, logging, subprocess, time, re from datetime import datetime from collections import defaultdict import tempfile class G2PModelTester () : &quot;&quot;&quot;G2P Model training wrapper class. Phonetisaurus G2P modeling training wrapper class. This wraps the alignment, joint n-gram training, and ARPA to WFST conversion steps into one command. &quot;&quot;&quot; def __init__ (self, model, **kwargs) : self.model = model self.lexicon_file = kwargs.get (&quot;lexicon&quot;, None) self.nbest = kwargs.get (&quot;nbest&quot;, 1) self.thresh = kwargs.get (&quot;thresh&quot;, 99) self.beam = kwargs.get (&quot;beam&quot;, 10000) self.greedy = kwargs.get (&quot;greedy&quot;, False) self.accumulate = kwargs.get (&quot;accumulate&quot;, False) self.pmass = kwargs.get (&quot;pmass&quot;, 0.0) self.probs = kwargs.get (&quot;probs&quot;, False) self.verbose = kwargs.get (&quot;verbose&quot;, False) self.logger = self.setupLogger () def setupLogger (self) : &quot;&quot;&quot;Setup the logger and logging level. Setup the logger and logging level. We only support verbose and non-verbose mode. Args: verbose (bool): Verbose mode, or not. Returns: Logger: A configured logger instance. &quot;&quot;&quot; level = logging.DEBUG if self.verbose else logging.INFO logging.basicConfig ( level=level, format=&quot; 033[94m%(levelname)s:%(name)s:&quot; &quot;%(asctime)s 033[0m: %(message)s&quot;, datefmt=&quot;%Y-%m-%d %H:%M:%S&quot; ) return logging.getLogger (&quot;phonetisaurus-apply&quot;) def _loadLexicon (self) : &quot;&quot;&quot;Load the lexicon from a file. Load the reference lexicon from a file, and store it in a defaultdict (list). &quot;&quot;&quot; _lexicon = defaultdict (list) if not self.lexicon_file : return _lexicon self.logger.debug (&quot;Loading lexicon from file...&quot;) with open (self.lexicon_file, &quot;r&quot;) as ifp : for line in ifp : # py2py3 compatbility, if sys.version_info[0] &lt; 3: line = line.decode(&quot;utf8&quot;).strip () else: line = line.strip () word, pron = re.split (r&quot; t&quot;, line, 1) _lexicon [word].append (pron) return _lexicon def checkPhonetisaurusConfig (self) : &quot;&quot;&quot;Run some basic checks before training. Run some basic checks regarding the $PATH, environment, and provided data before starting training. Raises: EnvironmentError: raised if binaries are not found. &quot;&quot;&quot; self.logger.debug (&quot;Checking command configuration...&quot;) for program in [&quot;phonetisaurus-g2pfst&quot;] : if not self.which (program) : raise EnvironmentError(&quot;Phonetisaurus command, &#39;{0}&#39;, &quot; &quot;not found in path.&quot;.format (program)) if self.lexicon_file and not os.path.exists (self.lexicon_file) : self.logger.error (&quot;Could not find provided lexicon file.&quot;) sys.exit (1) for key,val in sorted (vars (self).items ()) : self.logger.debug (u&quot;{0}: {1}&quot;.format (key, val)) self.lexicon = self._loadLexicon () return def which (self, program) : &quot;&quot;&quot;Basic &#39;which&#39; implementation for python. Basic &#39;which&#39; implementation for python from stackoverflow: * https://stackoverflow.com/a/377028/6739158 Args: program (str): The program name to search the $PATH for. Returns: path/None: The path to the executable, or None. &quot;&quot;&quot; def is_exe (fpath) : return os.path.isfile (fpath) and os.access (fpath, os.X_OK) fpath, fname = os.path.split (program) if fpath: if is_exe (program): return program else: for path in os.environ[&quot;PATH&quot;].split (os.pathsep) : path = path.strip (&#39;&quot;&#39;) exe_file = os.path.join (path, program) if is_exe (exe_file): return exe_file return None def makeG2PCommand (self, word_list) : &quot;&quot;&quot;Build the G2P command. Build the G2P command from the provided arguments. Returns: list: The command in subprocess list format. &quot;&quot;&quot; command = [ u&quot;phonetisaurus-g2pfst&quot;, u&quot;--model={0}&quot;.format (self.model), u&quot;--nbest={0}&quot;.format (self.nbest), u&quot;--beam={0}&quot;.format (self.beam), u&quot;--thresh={0}&quot;.format (self.thresh), u&quot;--accumulate={0}&quot;.format (str (self.accumulate).lower ()), u&quot;--pmass={0}&quot;.format (self.pmass), u&quot;--nlog_probs={0}&quot;.format (str(not self.probs).lower ()), u&quot;--wordlist={0}&quot;.format (word_list) ] self.logger.debug (u&quot; &quot;.join (command)) return command def runG2PCommand (self, word_list_file) : &quot;&quot;&quot;Generate and run the actual G2P command. Generate and run the actual G2P command. Each synthesized entry will be yielded back on-the-fly via the subprocess stdout readline method. Args: word_list_file (str): The input word list. &quot;&quot;&quot; g2p_command = self.makeG2PCommand (word_list_file) self.logger.debug (&quot;Applying G2P model...&quot;) with open (os.devnull, &quot;w&quot;) as devnull : proc = subprocess.Popen ( g2p_command, stdout=subprocess.PIPE, stderr=devnull if not self.verbose else None ) for line in proc.stdout : parts = re.split (r&quot; t&quot;, line.decode (&quot;utf8&quot;).strip ()) if not len (parts) == 3 : self.logger.warning ( u&quot;No pronunciation for word: &#39;{0}&#39;&quot;.format (parts [0]) ) continue yield parts return def applyG2POnly (self, word_list_file) : &quot;&quot;&quot;Apply the G2P model to a word list. Apply the G2P model to a word list. No filtering or application of a reference lexicon is used here. Args: word_list_file (str): The input word list. &quot;&quot;&quot; for word, score, pron in self.runG2PCommand (word_list_file) : line = u&quot;&quot; if self.verbose : line = u&quot;{0} t{1:.2f} t{2}&quot;.format ( word, float (score), pron ) else : line = u&quot;{0} t{1}&quot;.format (word, pron) # py2py3 compatbility, if sys.version_info[0] &lt; 3: print (line.encode (&quot;utf8&quot;)) else : print (line) return def applyG2PWithLexicon (self, word_list_file) : &quot;&quot;&quot;Apply the G2P model to a word list, combined with lexicon. Apply the G2P model to a word list, but combine this with a reference lexicon. Words for which a reference entry exists will not be sent to the G2P, unless the additional &#39;--greedy&#39; flag is set to True. Args: word_list_file (str): The input word list. &quot;&quot;&quot; target_lexicon = defaultdict (list) tmpwordlist = tempfile.NamedTemporaryFile(mode=&#39;w&#39;, delete=False) #First, find any words in the target list for which we already # have a canonical pronunciation in the reference lexicon. with open (word_list_file, &quot;r&quot;) as ifp : for word in ifp : # py2py3 compatbility, if sys.version_info[0] &lt; 3: word = word.decode (&quot;utf8&quot;).strip () else: word = word.strip () # already in &#39;utf8&#39;. if word in self.lexicon : target_lexicon [word] = [(0.0,pron) for pron in self.lexicon [word]] #In greedy mode we still send words to the G2P, even # if we have canonical entries in the reference lexicon. if self.greedy : print (word.encode (&quot;utf8&quot;), file=tmpwordlist) else : # py2py3 compatbility, if sys.version_info[0] &lt; 3: print (word.encode (&quot;utf8&quot;), file=tmpwordlist) else: print (word, file=tmpwordlist) tmpwordlist.close () #Second, iterate through the G2P output, and filter against # any possible duplicates previously found in the reference lexicon. for word, score, pron in self.runG2PCommand (tmpwordlist.name) : prons = set ([p for s,p in target_lexicon [word]]) if pron in prons : continue target_lexicon [word].append ((score, pron)) #Finally, sort everything that is left and print it. for word in sorted (target_lexicon.keys ()) : for score, pron in target_lexicon [word] : line = u&quot;&quot; if self.verbose : line = u&quot;{0} t{1:.2f} t{2}&quot;.format ( word, float (score), pron ) else : line = u&quot;{0} t{1}&quot;.format (word, pron) # py2py3 compatbility, if sys.version_info[0] &lt; 3: print (line.encode (&quot;utf8&quot;)) else : print (line) os.unlink (tmpwordlist.name) return def ApplyG2PModel (self, word_list_file) : &quot;&quot;&quot;Apply the G2P model to a word list. Apply the G2P model to a word list. Args: word_list_file (str): The input word list. &quot;&quot;&quot; self.checkPhonetisaurusConfig () if not os.path.exists (word_list_file) or not os.path.isfile (word_list_file) : raise IOError(&quot;Word list file not found.&quot;) if len (self.lexicon) == 0 : self.applyG2POnly (word_list_file) else : self.applyG2PWithLexicon (word_list_file) return if __name__ == &quot;__main__&quot; : import sys, argparse example = &quot;{0} --model train/model.fst --word test&quot;.format (sys.argv [0]) parser = argparse.ArgumentParser (description=example) parser.add_argument (&quot;--model&quot;, &quot;-m&quot;, help=&quot;Phonetisaurus G2P fst model.&quot;, required=True) parser.add_argument (&quot;--lexicon&quot;, &quot;-l&quot;, help=&quot;Optional reference lexicon.&quot;, required=False) parser.add_argument (&quot;--nbest&quot;, &quot;-n&quot;, help=&quot;Maximum number of hypotheses &quot; &quot;to produce. Overridden if --pmass is set.&quot;, default=1, type=int) parser.add_argument (&quot;--beam&quot;, &quot;-b&quot;, help=&quot;Search &#39;beam&#39;.&quot;, default=10000, type=int) parser.add_argument (&quot;--thresh&quot;, &quot;-t&quot;, help=&quot;Pruning threshold for n-best.&quot;, default=99.0, type=float) parser.add_argument (&quot;--greedy&quot;, &quot;-g&quot;, help=&quot;Use the G2P even if a &quot; &quot;reference lexicon has been provided.&quot;, default=False, action=&quot;store_true&quot;) parser.add_argument (&quot;--accumulate&quot;, &quot;-a&quot;, help=&quot;Accumulate probabilities &quot; &quot;across unique pronunciations.&quot;, default=False, action=&quot;store_true&quot;) parser.add_argument (&quot;--pmass&quot;, &quot;-p&quot;, help=&quot;Select the maximum number of &quot; &quot;hypotheses summing to P total mass for a word.&quot;, default=0.0, type=float) parser.add_argument (&quot;--probs&quot;, &quot;-pr&quot;, help=&quot;Print exp(-val) &quot; &quot;instead of default -log values.&quot;, default=False, action=&quot;store_true&quot;) parser.add_argument (&quot;--word_list&quot;, &quot;-wl&quot;, help=&quot;Input word or word list to apply &quot; &quot;G2P model to.&quot;, type=str) parser.add_argument (&quot;--verbose&quot;, &quot;-v&quot;, help=&quot;Verbose mode.&quot;, default=False, action=&quot;store_true&quot;) args = parser.parse_args () tester = G2PModelTester ( args.model, **{key:val for key,val in args.__dict__.items () if not key in [&quot;model&quot;,&quot;word_list&quot;]} ) tester.ApplyG2PModel (args.word_list) . %cd /opt/kaldi/src/ . Be sure to uncomment and run the next cell, to make sure nothing&#39;s changed; it&#39;s unlikely that anything will have changed, though. The following cell does configure, make depend, and make, which is all that the current INSTALL says. . . !./configure --shared --use-cuda --mathlib=OPENBLAS !make depend -j 8 !make -j 8 . %cd /opt . Second last step, clean up the object files: . !find /opt/kaldi -type f ( -name &quot;*.o&quot; -o -name &quot;*.la&quot; -o -name &quot;*.a&quot; ) -exec rm {} ; . !tar cvf /kaggle/working/kaldi.tar kaldi/ .",
            "url": "https://jimregan.github.io/notes/kaggle/kaldi/2021/05/28/compile-kaldi.html",
            "relUrl": "/kaggle/kaldi/2021/05/28/compile-kaldi.html",
            "date": " ‚Ä¢ May 28, 2021"
        }
        
    
  
    
        ,"post75": {
            "title": "Common Voice Swedish - prepare audio",
            "content": "Original here . %cd /tmp . /tmp . %%capture !pip install git+https://github.com/pytorch/fairseq/ . %%capture !git clone https://github.com/pytorch/fairseq/ . %cd fairseq/examples/wav2vec/unsupervised/scripts . /tmp/fairseq/examples/wav2vec/unsupervised/scripts . !mkdir tsv !for i in train test valid; do echo /kaggle/input/wav2vec-u-cv-swedish-vads/wav/$i/common-voice-swedish-16bit-wav/ &gt; tsv/$i.tsv; cat /kaggle/input/fork-of-wav2vec-u-cv-swedish-tsv/$i.tsv|sed &#39;1d&#39; &gt;&gt; tsv/$i.tsv;done !cp /kaggle/input/wav2vec-u-cv-swedish-prep-ltr-phn-wrd/dic* tsv/ !cp /kaggle/input/wav2vec-u-cv-swedish-prep-ltr-phn-wrd/*.wrd tsv/ !cp /kaggle/input/wav2vec-u-cv-swedish-prep-ltr-phn-wrd/*.ltr tsv/ !cp /kaggle/input/wav2vec-u-cv-swedish-prep-ltr-phn-wrd/*.phn tsv/ . %%capture !pip install npy-append-array . !pip install faiss-gpu . %%capture !apt-get -y install zsh . !zsh prepare_audio.sh tsv /kaggle/working /kaggle/input/download-xlsr-53-wav2vec2-model/xlsr_53_56k.pt . using 512 dim for PCA 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2331/2331 [01:21&lt;00:00, 28.76it/s] 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2019/2019 [01:07&lt;00:00, 29.98it/s] 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2027/2027 [01:08&lt;00:00, 29.41it/s] Faiss Specs: [faiss_spec(pca=0, norm=False, n_clus=128, sphere=False, spec_str=&#39;CLUS128&#39;)] 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2331/2331 [01:10&lt;00:00, 33.09it/s] (223140, 1024) Processing spec faiss_spec(pca=0, norm=False, n_clus=128, sphere=False, spec_str=&#39;CLUS128&#39;) Computing kmeans Clustering 223140 points in 1024D to 128 clusters, redo 3 times, 50 iterations Preprocessing in 0.17 s Outer iteration 0 / 3 Objective improved: keep new clusters Outer iteration 1 / 3 Objective improved: keep new clusters Outer iteration 2 / 3 Objective improved: keep new clusters Faiss Spec: faiss_spec(pca=0, norm=False, n_clus=128, sphere=False, spec_str=&#39;CLUS128&#39;) Loaded centroids (128, 1024) 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2331/2331 [00:58&lt;00:00, 40.05it/s] Faiss Spec: faiss_spec(pca=0, norm=False, n_clus=128, sphere=False, spec_str=&#39;CLUS128&#39;) Loaded centroids (128, 1024) 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2019/2019 [00:57&lt;00:00, 35.24it/s] Faiss Spec: faiss_spec(pca=0, norm=False, n_clus=128, sphere=False, spec_str=&#39;CLUS128&#39;) Loaded centroids (128, 1024) 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2027/2027 [00:51&lt;00:00, 39.40it/s] Reading features Computing PCA data path: /kaggle/working/train 0%| | 0/1 [00:00&lt;?, ?it/s]apply_pca.py:66: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1603729047590/work/torch/csrc/utils/tensor_numpy.cpp:141.) x = torch.from_numpy(features[start:end]).cuda() 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01&lt;00:00, 1.53s/it] data path: /kaggle/working/precompute_pca512/train 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2331/2331 [00:05&lt;00:00, 402.56it/s] data path: /kaggle/working/precompute_pca512_cls128_mean/train 0%| | 0/2331 [00:00&lt;?, ?it/s]mean_pool.py:69: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1603729047590/work/torch/csrc/utils/tensor_numpy.cpp:141.) x = torch.from_numpy(feats).cuda() 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2331/2331 [00:03&lt;00:00, 692.56it/s] data path: /kaggle/working/valid 0%| | 0/1 [00:00&lt;?, ?it/s]apply_pca.py:66: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1603729047590/work/torch/csrc/utils/tensor_numpy.cpp:141.) x = torch.from_numpy(features[start:end]).cuda() 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01&lt;00:00, 1.60s/it] data path: /kaggle/working/precompute_pca512/valid 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2019/2019 [00:04&lt;00:00, 447.45it/s] data path: /kaggle/working/precompute_pca512_cls128_mean/valid 0%| | 0/2019 [00:00&lt;?, ?it/s]mean_pool.py:69: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1603729047590/work/torch/csrc/utils/tensor_numpy.cpp:141.) x = torch.from_numpy(feats).cuda() 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2019/2019 [00:03&lt;00:00, 592.35it/s] data path: /kaggle/working/test 0%| | 0/1 [00:00&lt;?, ?it/s]apply_pca.py:66: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1603729047590/work/torch/csrc/utils/tensor_numpy.cpp:141.) x = torch.from_numpy(features[start:end]).cuda() 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01&lt;00:00, 1.22s/it] data path: /kaggle/working/precompute_pca512/test 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2027/2027 [00:05&lt;00:00, 379.47it/s] data path: /kaggle/working/precompute_pca512_cls128_mean/test 0%| | 0/2027 [00:00&lt;?, ?it/s]mean_pool.py:69: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1603729047590/work/torch/csrc/utils/tensor_numpy.cpp:141.) x = torch.from_numpy(feats).cuda() 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2027/2027 [00:03&lt;00:00, 569.65it/s] .",
            "url": "https://jimregan.github.io/notes/kaggle/wav2vec-u/2021/05/27/wav2vec-u-cv-swedish-audio.html",
            "relUrl": "/kaggle/wav2vec-u/2021/05/27/wav2vec-u-cv-swedish-audio.html",
            "date": " ‚Ä¢ May 27, 2021"
        }
        
    
  
    
        ,"post76": {
            "title": "wav2vec-u CV-sv - prepare text",
            "content": "Original here . %cd /opt . /opt . %%capture !tar xvf /kaggle/input/extract-prebuilt-kaldi-from-docker/kaldi.tar . %cd /tmp . /tmp . !git clone https://github.com/pytorch/fairseq/ . %%capture !pip install phonemizer . %%capture !pip install git+https://github.com/pytorch/fairseq/ . %%capture !apt-get -y install espeak . !git clone https://github.com/kpu/kenlm . %%capture !apt-get -y install libeigen3-dev liblzma-dev zlib1g-dev libbz2-dev . %%capture %cd kenlm !mkdir build %cd build !cmake .. !make -j 4 %cd /tmp . import os os.environ[&#39;PATH&#39;] = f&quot;{os.environ[&#39;PATH&#39;]}:/tmp/kenlm/build/bin/&quot; os.environ[&#39;FAIRSEQ_ROOT&#39;] = &#39;/tmp/fairseq&#39; . !cat /kaggle/input/wav2vec-u-cv-swedish-audio/*.wrd | grep -v &#39;^$&#39; | sort| uniq &gt; /kaggle/working/sentences.txt . %cd fairseq/examples/wav2vec/unsupervised . /tmp/fairseq/examples/wav2vec/unsupervised . %%capture !apt-get -y install zsh . !mkdir /kaggle/working/preppedtext . %cd scripts . /tmp/fairseq/examples/wav2vec/unsupervised/scripts . The next part requires a FastText language id model; I don&#39;t know where the 187 language model comes from, but there is a model for 176 languages here . !wget https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin . !cat normalize_and_filter_text.py|sed -e &#39;s/187/176/&#39; &gt; tmp !mv tmp normalize_and_filter_text.py . os.environ[&#39;HYDRA_FULL_ERROR&#39;] = &#39;1&#39; . import os os.environ[&#39;LD_LIBRARY_PATH&#39;] = &#39;/opt/conda/lib:/opt/kaldi/tools/openfst-1.6.7/lib:/opt/kaldi/src/lib&#39; . There are two lines with missing variables in prepare_text.sh - pull request - so replace the file. . While I&#39;m replacing the file: most of the first part of the script is unneeded, as I already have a phonetic dictionary, so I&#39;m using that instead. . With the calls of the preprocess.py script, make sure to check the threshold: there&#39;s a divide by zero if the threshold is set too high. . Config options for kaldi_initializer.py . in_labels: a naming component, for the Kaldi lexicons/fsts (required) | wav2letter_lexicon: path to wav2letter lexicon | out_labels: a naming component, for the Kaldi lexicons/fsts: set to in_label if missing | kaldi_root: path to Kaldi: /opt/kaldi for my kaggle image | fst_dir: path where generated fsts will be saved | data_dir: path to phones data | lm_arpa: path to the lm in ARPA format | blank_symbol: CTC blank symbol (&lt;s&gt; here) | silence_symbol: Kaldi symbol for silence (&lt;SIL&gt; is set for two of the scripts) | . A config file needs to exist for this, even though the options set in it seem to be ignored. . !mkdir /tmp/fairseq/examples/speech_recognition/kaldi/config/ . %%writefile /tmp/fairseq/examples/speech_recognition/kaldi/config/config.yaml kaldi_root: &quot;/opt/kaldi&quot; . Writing /tmp/fairseq/examples/speech_recognition/kaldi/config/config.yaml . %%writefile prepare_text.sh #!/usr/bin/env zsh # Copyright (c) Facebook, Inc. and its affiliates. # # This source code is licensed under the MIT license found in the # LICENSE file in the root directory of this source tree. lg=$1 text_path=$2 target_dir=$3 #ph_lg=${lg:l} #if test &quot;$lg&quot; = &#39;fr&#39;; then # ph_lg=&#39;fr-fr&#39; #elif test &quot;$lg&quot; = &#39;en&#39;; then # ph_lg=&#39;en-us&#39; #elif test &quot;$lg&quot; = &#39;pt&#39;; then # ph_lg=&#39;pt-br&#39; #fi ph_lg=&quot;sv&quot; echo $lg echo $ph_lg echo $text_path echo $target_dir mkdir -p $target_dir #python normalize_and_filter_text.py --lang $lg &lt; $text_path | grep -v &#39; - - -&#39; &gt;! $target_dir/lm.upper.lid.txt #python $FAIRSEQ_ROOT/fairseq_cli/preprocess.py --dataset-impl mmap --trainpref $target_dir/lm.upper.lid.txt --only-source --destdir $target_dir --thresholdsrc 2 --padding-factor 1 --dict-only #cut -f1 -d&#39; &#39; $target_dir/dict.txt | grep -v -x &#39;[[:punct:]]*&#39; | grep -Pv &#39; d d d d d+&#39; &gt;! $target_dir/words.txt cp /kaggle/input/wav2vec-u-cv-swedish-audio/train.wrd $target_dir/lm.upper.lid.txt cut -f1 -d&#39; &#39; /kaggle/input/wav2vec-u-cv-swedish-audio/dict.train &gt;! $target_dir/words.txt #one=$(echo &quot;1&quot; | PHONEMIZER_ESPEAK_PATH=$(which espeak) phonemize -p &#39; &#39; -w &#39;&#39; -l $ph_lg --language-switch remove-flags) #sed &#39;s/$/ 1/&#39; $target_dir/words.txt | PHONEMIZER_ESPEAK_PATH=$(which espeak) phonemize -o $target_dir/phones.txt -p &#39; &#39; -w &#39;&#39; -l $ph_lg -j 70 --language-switch remove-flags cut -f2- -d&#39; &#39; /kaggle/input/wav2vec-u-cv-swedish-audio/dict.train &gt;! $target_dir/phones.txt #echo &quot;one is ${one}&quot; #sed -i &quot;s/${one}$//&quot; $target_dir/phones.txt #paste $target_dir/words.txt $target_dir/phones.txt &gt;! $target_dir/lexicon.lst cp /kaggle/input/wav2vec-u-cv-swedish-audio/dict.train $target_dir/lexicon.lst #python $FAIRSEQ_ROOT/fairseq_cli/preprocess.py --dataset-impl mmap --trainpref $target_dir/phones.txt --only-source --destdir $target_dir/phones --thresholdsrc 1000 --padding-factor 1 --dict-only python $FAIRSEQ_ROOT/fairseq_cli/preprocess.py --dataset-impl mmap --trainpref $target_dir/phones.txt --only-source --destdir $target_dir/phones --thresholdsrc 2 --padding-factor 1 --dict-only python filter_lexicon.py -d $target_dir/phones/dict.txt &lt; $target_dir/lexicon.lst &gt;! $target_dir/lexicon_filtered.lst python phonemize_with_sil.py -s 0.25 --surround --lexicon $target_dir/lexicon_filtered.lst &lt; $target_dir/lm.upper.lid.txt &gt;! $target_dir/phones/lm.phones.filtered.txt cp $target_dir/phones/dict.txt $target_dir/phones/dict.phn.txt echo &quot;&lt;SIL&gt; 0&quot; &gt;&gt; $target_dir/phones/dict.phn.txt python $FAIRSEQ_ROOT/fairseq_cli/preprocess.py --dataset-impl mmap --trainpref $target_dir/phones/lm.phones.filtered.txt --workers 70 --only-source --destdir $target_dir/phones --srcdict $target_dir/phones/dict.phn.txt lmplz -o 4 &lt; $target_dir/lm.upper.lid.txt --discount_fallback --prune 0 0 0 3 &gt;! $target_dir/kenlm.wrd.o40003.arpa build_binary $target_dir/kenlm.wrd.o40003.arpa $target_dir/kenlm.wrd.o40003.bin lg=$lg python $FAIRSEQ_ROOT/examples/speech_recognition/kaldi/kaldi_initializer.py fst_dir=$target_dir/fst/phn_to_words_sil lm_arpa=$target_dir/kenlm.wrd.o40003.arpa wav2letter_lexicon=$target_dir/lexicon_filtered.lst data_dir=$target_dir/phones &quot;blank_symbol=&#39;&lt;SIL&gt;&#39;&quot; &quot;in_labels=&#39;phn&#39;&quot; &quot;kaldi_root=&#39;/opt/kaldi&#39;&quot; lg=$lg python $FAIRSEQ_ROOT/examples/speech_recognition/kaldi/kaldi_initializer.py fst_dir=$target_dir/fst/phn_to_words lm_arpa=$target_dir/kenlm.wrd.o40003.arpa wav2letter_lexicon=$target_dir/lexicon_filtered.lst data_dir=$target_dir/phones &quot;in_labels=&#39;phn&#39;&quot; &quot;kaldi_root=&#39;/opt/kaldi&#39;&quot; lmplz -o 4 &lt; $target_dir/phones/lm.phones.filtered.txt --discount_fallback &gt;! $target_dir/phones/lm.phones.filtered.04.arpa build_binary -s $target_dir/phones/lm.phones.filtered.04.arpa $target_dir/phones/lm.phones.filtered.04.bin lmplz -o 6 &lt; $target_dir/phones/lm.phones.filtered.txt --discount_fallback &gt;! $target_dir/phones/lm.phones.filtered.06.arpa build_binary -s $target_dir/phones/lm.phones.filtered.06.arpa $target_dir/phones/lm.phones.filtered.06.bin lg=$lg python $FAIRSEQ_ROOT/examples/speech_recognition/kaldi/kaldi_initializer.py fst_dir=$target_dir/fst/phn_to_phn_sil lm_arpa=$target_dir/phones/lm.phones.filtered.06.arpa data_dir=$target_dir/phones &quot;blank_symbol=&#39;&lt;SIL&gt;&#39;&quot; &quot;in_labels=&#39;phn&#39;&quot; &quot;kaldi_root=&#39;/opt/kaldi&#39;&quot; . Overwriting prepare_text.sh . add-self-loop-simple.cc attempts to use std::endl with KALDI_LOG, which doesn&#39;t work, so rewrite that (I&#39;m not sure if this actually prevents anything from working, but it is really distracting). . %%writefile /tmp/fairseq/examples/speech_recognition/kaldi/add-self-loop-simple.cc /* * Copyright (c) Facebook, Inc. and its affiliates. * * This source code is licensed under the MIT license found in the * LICENSE file in the root directory of this source tree. */ #include &lt;iostream&gt; #include &quot;fstext/fstext-lib.h&quot; // @manual #include &quot;util/common-utils.h&quot; // @manual /* * This program is to modify a FST without self-loop by: * for each incoming arc with non-eps input symbol, add a self-loop arc * with that non-eps symbol as input and eps as output. * * This is to make sure the resultant FST can do deduplication for repeated * symbols, which is very common in acoustic model * */ namespace { int32 AddSelfLoopsSimple(fst::StdVectorFst* fst) { typedef fst::MutableArcIterator&lt;fst::StdVectorFst&gt; IterType; int32 num_states_before = fst-&gt;NumStates(); fst::MakePrecedingInputSymbolsSame(false, fst); int32 num_states_after = fst-&gt;NumStates(); KALDI_LOG &lt;&lt; &quot;There are &quot; &lt;&lt; num_states_before &lt;&lt; &quot; states in the original FST; &quot; &lt;&lt; &quot; after MakePrecedingInputSymbolsSame, there are &quot; &lt;&lt; num_states_after &lt;&lt; &quot; states &quot;; auto weight_one = fst::StdArc::Weight::One(); int32 num_arc_added = 0; fst::StdArc self_loop_arc; self_loop_arc.weight = weight_one; int32 num_states = fst-&gt;NumStates(); std::vector&lt;std::set&lt;int32&gt;&gt; incoming_non_eps_label_per_state(num_states); for (int32 state = 0; state &lt; num_states; state++) { for (IterType aiter(fst, state); !aiter.Done(); aiter.Next()) { fst::StdArc arc(aiter.Value()); if (arc.ilabel != 0) { incoming_non_eps_label_per_state[arc.nextstate].insert(arc.ilabel); } } } for (int32 state = 0; state &lt; num_states; state++) { if (!incoming_non_eps_label_per_state[state].empty()) { auto&amp; ilabel_set = incoming_non_eps_label_per_state[state]; for (auto it = ilabel_set.begin(); it != ilabel_set.end(); it++) { self_loop_arc.ilabel = *it; self_loop_arc.olabel = 0; self_loop_arc.nextstate = state; fst-&gt;AddArc(state, self_loop_arc); num_arc_added++; } } } return num_arc_added; } void print_usage() { std::cout &lt;&lt; &quot;add-self-loop-simple usage: n&quot; &quot; tadd-self-loop-simple &lt;in-fst&gt; &lt;out-fst&gt; n&quot;; } } // namespace int main(int argc, char** argv) { if (argc != 3) { print_usage(); exit(1); } auto input = argv[1]; auto output = argv[2]; auto fst = fst::ReadFstKaldi(input); auto num_states = fst-&gt;NumStates(); KALDI_LOG &lt;&lt; &quot;Loading FST from &quot; &lt;&lt; input &lt;&lt; &quot; with &quot; &lt;&lt; num_states &lt;&lt; &quot; states.&quot;; int32 num_arc_added = AddSelfLoopsSimple(fst); KALDI_LOG &lt;&lt; &quot;Adding &quot; &lt;&lt; num_arc_added &lt;&lt; &quot; self-loop arcs &quot;; fst::WriteFstKaldi(*fst, std::string(output)); KALDI_LOG &lt;&lt; &quot;Writing FST to &quot; &lt;&lt; output; delete fst; } . Overwriting /tmp/fairseq/examples/speech_recognition/kaldi/add-self-loop-simple.cc . !zsh prepare_text.sh sv /kaggle/working/sentences.txt /kaggle/working/preppedtext . sv sv /kaggle/working/sentences.txt /kaggle/working/preppedtext === 1/5 Counting and sorting n-grams === Reading /kaggle/working/preppedtext/lm.upper.lid.txt -5101520253035404550556065707580859095--100 **************************************************************************************************** Unigram tokens 14359 types 3160 === 2/5 Calculating and sorting adjusted counts === Chain sizes: 1:37920 2:2571431424 3:4821433856 4:7714294272 Statistics: 1 3160 D1=0.722623 D2=1.14413 D3+=1.45956 2 10285 D1=0.848104 D2=1.2466 D3+=1.46191 3 12632 D1=0.943362 D2=1.24166 D3+=1.32723 4 19/11699 D1=0.970399 D2=1.4843 D3+=2.12351 Memory estimate for binary LM: type kB probing 617 assuming -p 1.5 probing 764 assuming -r models -p 1.5 trie 309 without quantization trie 182 assuming -q 8 -b 8 quantization trie 293 assuming -a 22 array pointer compression trie 166 assuming -a 22 -q 8 -b 8 array pointer compression and quantization === 3/5 Calculating and sorting initial probabilities === Chain sizes: 1:37920 2:164560 3:252640 4:456 -5101520253035404550556065707580859095--100 #################################################################################################### === 4/5 Calculating and writing order-interpolated probabilities === Chain sizes: 1:37920 2:164560 3:252640 4:456 -5101520253035404550556065707580859095--100 #################################################################################################### === 5/5 Writing ARPA model === -5101520253035404550556065707580859095--100 **************************************************************************************************** Name:lmplz VmPeak:14925024 kB VmRSS:6488 kB RSSMax:2975268 kB user:0.194576 sys:0.839708 CPU:1.03431 real:1.03864 Reading /kaggle/working/preppedtext/kenlm.wrd.o40003.arpa -5101520253035404550556065707580859095--100 **************************************************************************************************** SUCCESS [2021-05-30 15:50:13,771][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words_sil/kaldi_dict.phn.txt [2021-05-30 15:50:13,771][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words_sil/G_kenlm.wrd.o40003.fst /opt/kaldi/src/lmbin/arpa2fst --disambig-symbol=#0 --write-symbol-table=/kaggle/working/preppedtext/fst/phn_to_words_sil/kaldi_dict.kenlm.wrd.o40003.txt /kaggle/working/preppedtext/kenlm.wrd.o40003.arpa /kaggle/working/preppedtext/fst/phn_to_words_sil/G_kenlm.wrd.o40003.fst LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:94) Reading data section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 1-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 2-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 3-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 4-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:RemoveRedundantStates():arpa-lm-compiler.cc:359) Reduced num-states from 22665 to 12144 [2021-05-30 15:50:13,918][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words_sil/kaldi_lexicon.phn.kenlm.wrd.o40003.txt (in units file: /kaggle/working/preppedtext/fst/phn_to_words_sil/kaldi_dict.phn.txt) [2021-05-30 15:50:14,005][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words_sil/H.phn.fst [2021-05-30 15:50:14,045][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words_sil/L.phn.kenlm.wrd.o40003.fst (in units: /kaggle/working/preppedtext/fst/phn_to_words_sil/kaldi_dict.phn_disambig.txt) [2021-05-30 15:50:14,244][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words_sil/LG.phn.kenlm.wrd.o40003.fst [2021-05-30 15:50:15,269][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words_sil/HLGa.phn.kenlm.wrd.o40003.fst [2021-05-30 15:50:17,600][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words_sil/HLG.phn.kenlm.wrd.o40003.fst [2021-05-30 15:50:26,782][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words/kaldi_dict.phn.txt [2021-05-30 15:50:26,783][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words/G_kenlm.wrd.o40003.fst /opt/kaldi/src/lmbin/arpa2fst --disambig-symbol=#0 --write-symbol-table=/kaggle/working/preppedtext/fst/phn_to_words/kaldi_dict.kenlm.wrd.o40003.txt /kaggle/working/preppedtext/kenlm.wrd.o40003.arpa /kaggle/working/preppedtext/fst/phn_to_words/G_kenlm.wrd.o40003.fst LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:94) Reading data section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 1-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 2-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 3-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 4-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:RemoveRedundantStates():arpa-lm-compiler.cc:359) Reduced num-states from 22665 to 12144 [2021-05-30 15:50:26,992][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words/kaldi_lexicon.phn.kenlm.wrd.o40003.txt (in units file: /kaggle/working/preppedtext/fst/phn_to_words/kaldi_dict.phn.txt) [2021-05-30 15:50:27,047][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words/H.phn.fst [2021-05-30 15:50:27,088][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words/L.phn.kenlm.wrd.o40003.fst (in units: /kaggle/working/preppedtext/fst/phn_to_words/kaldi_dict.phn_disambig.txt) [2021-05-30 15:50:27,281][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words/LG.phn.kenlm.wrd.o40003.fst [2021-05-30 15:50:28,293][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words/HLGa.phn.kenlm.wrd.o40003.fst [2021-05-30 15:50:31,245][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words/HLG.phn.kenlm.wrd.o40003.fst === 1/5 Counting and sorting n-grams === Reading /kaggle/working/preppedtext/phones/lm.phones.filtered.txt -5101520253035404550556065707580859095--100 **************************************************************************************************** Unigram tokens 63676 types 44 === 2/5 Calculating and sorting adjusted counts === Chain sizes: 1:528 2:2571437824 3:4821446144 4:7714313728 Substituting fallback discounts for order 0: D1=0.5 D2=1 D3+=1.5 Statistics: 1 44 D1=0.5 D2=1 D3+=1.5 2 1053 D1=0.421189 D2=1.06361 D3+=1.49793 3 8534 D1=0.558099 D2=1.17765 D3+=1.45173 4 23058 D1=0.643934 D2=1.15876 D3+=1.53884 Memory estimate for binary LM: type kB probing 631 assuming -p 1.5 probing 687 assuming -r models -p 1.5 trie 203 without quantization trie 88 assuming -q 8 -b 8 quantization trie 196 assuming -a 22 array pointer compression trie 81 assuming -a 22 -q 8 -b 8 array pointer compression and quantization === 3/5 Calculating and sorting initial probabilities === Chain sizes: 1:528 2:16848 3:170680 4:553392 -5101520253035404550556065707580859095--100 #################################################################################################### === 4/5 Calculating and writing order-interpolated probabilities === Chain sizes: 1:528 2:16848 3:170680 4:553392 -5101520253035404550556065707580859095--100 #################################################################################################### === 5/5 Writing ARPA model === -5101520253035404550556065707580859095--100 **************************************************************************************************** Name:lmplz VmPeak:14916784 kB VmRSS:7056 kB RSSMax:2973864 kB user:0.209899 sys:0.716931 CPU:0.926881 real:0.936705 Reading /kaggle/working/preppedtext/phones/lm.phones.filtered.04.arpa -5101520253035404550556065707580859095--100 **************************************************************************************************** SUCCESS === 1/5 Counting and sorting n-grams === Reading /kaggle/working/preppedtext/phones/lm.phones.filtered.txt -5101520253035404550556065707580859095--100 **************************************************************************************************** Unigram tokens 63676 types 44 === 2/5 Calculating and sorting adjusted counts === Chain sizes: 1:528 2:929673728 3:1743138176 4:2789021184 5:4067322624 6:5578042368 Substituting fallback discounts for order 0: D1=0.5 D2=1 D3+=1.5 Statistics: 1 44 D1=0.5 D2=1 D3+=1.5 2 1053 D1=0.421189 D2=1.06361 D3+=1.49793 3 8534 D1=0.558099 D2=1.17765 D3+=1.45173 4 23058 D1=0.704256 D2=1.25425 D3+=1.63465 5 35879 D1=0.821218 D2=1.34714 D3+=1.61281 6 43593 D1=0.834579 D2=1.24241 D3+=1.56972 Memory estimate for binary LM: type kB probing 2373 assuming -p 1.5 probing 2775 assuming -r models -p 1.5 trie 907 without quantization trie 401 assuming -q 8 -b 8 quantization trie 838 assuming -a 22 array pointer compression trie 331 assuming -a 22 -q 8 -b 8 array pointer compression and quantization === 3/5 Calculating and sorting initial probabilities === Chain sizes: 1:528 2:16848 3:170680 4:553392 5:1004612 6:1394976 -5101520253035404550556065707580859095--100 #################################################################################################### === 4/5 Calculating and writing order-interpolated probabilities === Chain sizes: 1:528 2:16848 3:170680 4:553392 5:1004612 6:1394976 -5101520253035404550556065707580859095--100 #################################################################################################### === 5/5 Writing ARPA model === -5101520253035404550556065707580859095--100 **************************************************************************************************** Name:lmplz VmPeak:14949572 kB VmRSS:6500 kB RSSMax:2354520 kB user:0.256512 sys:0.588288 CPU:0.84484 real:0.81585 Reading /kaggle/working/preppedtext/phones/lm.phones.filtered.06.arpa -5101520253035404550556065707580859095--100 **************************************************************************************************** SUCCESS [2021-05-30 15:50:35,812][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_phn_sil/kaldi_dict.phn.txt [2021-05-30 15:50:35,812][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_phn_sil/G_lm.phones.filtered.06.fst /opt/kaldi/src/lmbin/arpa2fst --disambig-symbol=#0 --write-symbol-table=/kaggle/working/preppedtext/fst/phn_to_phn_sil/kaldi_dict.lm.phones.filtered.06.txt /kaggle/working/preppedtext/phones/lm.phones.filtered.06.arpa /kaggle/working/preppedtext/fst/phn_to_phn_sil/G_lm.phones.filtered.06.fst LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:94) Reading data section. LOG (arpa2fst[5.5.0~1-2b62]:HeaderAvailable():arpa-lm-compiler.cc:300) Reverting to slower state tracking because model is large: 6-gram with symbols up to 47 LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 1-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 2-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 3-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 4-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 5-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 6-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:RemoveRedundantStates():arpa-lm-compiler.cc:359) Reduced num-states from 67529 to 67528 [2021-05-30 15:50:36,696][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_phn_sil/kaldi_lexicon.phn.lm.phones.filtered.06.txt (in units file: /kaggle/working/preppedtext/fst/phn_to_phn_sil/kaldi_dict.phn.txt) [2021-05-30 15:50:36,713][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_phn_sil/H.phn.fst [2021-05-30 15:50:36,754][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_phn_sil/L.phn.lm.phones.filtered.06.fst (in units: /kaggle/working/preppedtext/fst/phn_to_phn_sil/kaldi_dict.phn_disambig.txt) [2021-05-30 15:50:36,802][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_phn_sil/LG.phn.lm.phones.filtered.06.fst [2021-05-30 15:50:37,700][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_phn_sil/HLGa.phn.lm.phones.filtered.06.fst [2021-05-30 15:50:40,759][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_phn_sil/HLG.phn.lm.phones.filtered.06.fst .",
            "url": "https://jimregan.github.io/notes/kaggle/wav2vec-u/2021/05/26/wav2vec-u-cv-swedish-text-prep.html",
            "relUrl": "/kaggle/wav2vec-u/2021/05/26/wav2vec-u-cv-swedish-text-prep.html",
            "date": " ‚Ä¢ May 26, 2021"
        }
        
    
  
    
        ,"post77": {
            "title": "wav2vec-u Common Voice Swedish - prepare ltr/phn/wrd",
            "content": "Original here . In the section Preparation of speech and text data of the readme, it says: . Similar to wav2vec 2.0, data folders contain {train,valid,test}.{tsv,wrd,phn} files, where audio paths are stored in tsv files, and word, letter or phoneme transcriptions are stored in .{wrd,ltr,phn}. The .wrd and .ltr files are outputs of libri_labels.py . %%capture !pip install phonemizer . %%capture !apt-get -y install espeak . %%capture !apt-get -y install zsh . This is just my best guess at what the .wrd files contain - it seems to match up with what libri_labels.py does: given input like . 1272-128104-0000 MISTER QUILTER IS THE APOSTLE OF THE MIDDLE CLASSES AND WE ARE GLAD TO WELCOME HIS GOSPEL . it does &quot; &quot;.join(items[1:]), which is basically the same . !cat /kaggle/input/download-common-voice-swedish/cv-corpus-6.1-2020-12-11/sv-SE/test.tsv | awk -F&#39; t&#39; &#39;{print $3}&#39;|grep -v &#39;^sentence$&#39; | perl -C7 -ane &#39;chomp;$_=lc($_);s/[^ p{L} p{N} p{M}&#39;&quot; &#39;&quot;&#39; -]/ /g;s/ +/ /g;s/ $//;s/^ //;print &quot;$_ n&quot;;&#39; &gt; test.wrd !cat /kaggle/input/download-common-voice-swedish/cv-corpus-6.1-2020-12-11/sv-SE/dev.tsv | awk -F&#39; t&#39; &#39;{print $3}&#39;|grep -v &#39;^sentence$&#39; | perl -C7 -ane &#39;chomp;$_=lc($_);s/[^ p{L} p{N} p{M}&#39;&quot; &#39;&quot;&#39; -]/ /g;s/ +/ /g;s/ $//;s/^ //;print &quot;$_ n&quot;;&#39; &gt; valid.wrd !cat /kaggle/input/download-common-voice-swedish/cv-corpus-6.1-2020-12-11/sv-SE/train.tsv | awk -F&#39; t&#39; &#39;{print $3}&#39;|grep -v &#39;^sentence$&#39; | perl -C7 -ane &#39;chomp;$_=lc($_);s/[^ p{L} p{N} p{M}&#39;&quot; &#39;&quot;&#39; -]/ /g;s/ +/ /g;s/ $//;s/^ //;print &quot;$_ n&quot;;&#39; &gt; train.wrd . for i in [&#39;train&#39;, &#39;test&#39;, &#39;valid&#39;]: with open(f&#39;/kaggle/working/{i}.wrd&#39;, &#39;r&#39;) as inf, open(f&#39;/kaggle/working/{i}.ltr&#39;, &#39;w&#39;) as out: for line in inf.readlines(): print(&quot; &quot;.join(list(line.strip().replace(&quot; &quot;, &quot;|&quot;))) + &quot; |&quot;, file=out) . !head train.ltr . v a d | √§ r | d e t | i | e u r o | d u | s k a | v e t a | a t t | d e t | √§ r | d u | s o m | h a r | f e l | g √• | n e r | p √• | k n √§ | f √∂ r s t | m √• s t e | j a g | s l √• | s √∂ n d e r | d e n | d √§ r | s t o r a | s k r o t h √∂ g e n | d e t | b l i r | s v √• r t | v a d | f √∂ r | j √§ v l a | f r √• g a | √§ r | d e t | j a g | √• t e r v √§ n d e r | i n t e | t i l l | s k i t h √• l e t | t i t t a | p √• | s √∂ m m a r n a | f e s | d u | p r e c i s | a k t r i s e r | h a r | e t t | b √§ s t | f √∂ r e d a t u m | . There are some warnings about switching, so echo the filename first to known where the errors are . !for i in train test valid; do echo $i.wrd; cat $i.wrd | PHONEMIZER_ESPEAK_PATH=$(which espeak) phonemize -o $i.phn -p &#39; &#39; -w &#39;&#39; -l sv -j 70 --language-switch remove-flags ;done . train.wrd [WARNING] 2 utterances containing language switches on lines 254, 1457 [WARNING] extra phones may appear in the &#34;sv&#34; phoneset [WARNING] language switch flags have been removed (applying &#34;remove-flags&#34; policy) test.wrd [WARNING] 1 utterances containing language switches on lines 81 [WARNING] extra phones may appear in the &#34;sv&#34; phoneset [WARNING] language switch flags have been removed (applying &#34;remove-flags&#34; policy) valid.wrd [WARNING] 1 utterances containing language switches on lines 1831 [WARNING] extra phones may appear in the &#34;sv&#34; phoneset [WARNING] language switch flags have been removed (applying &#34;remove-flags&#34; policy) . !cat test.wrd|awk &#39;BEGIN{ln=1}{if(ln==81){print $0};ln++}&#39; !cat train.wrd|awk &#39;BEGIN{ln=1}{if(ln==254||ln==1457){print $0};ln++}&#39; !cat valid.wrd|awk &#39;BEGIN{ln=1}{if(ln==1831){print $0};ln++}&#39; . det √§r taskigt och s√• unik design internet slutade fungera det finns inget internet . !cat test.phn|awk &#39;BEGIN{ln=1}{if(ln==81){print $0};ln++}&#39; !cat train.phn|awk &#39;BEGIN{ln=1}{if(ln==254||ln==1457){print $0};ln++}&#39; !cat valid.phn|awk &#39;BEGIN{ln=1}{if(ln==1831){print $0};ln++}&#39; . d eÀê t …õÀê r t a s k …™ …° t …î k s oÀê …µ n iÀê k d …™ z a…™ n …™ n t …ô n …õ t s l  â t a d …ô f …µ n …° eÀê r a d eÀê t f …™ n s …™ ≈ã …ô t …™ n t …ô n …õ t . &quot;design&quot; and &quot;internet&quot; are clearly the English words that are causing the switch in their respective sentences, but I&#39;m not sure what the problem in test.wrd is: &quot;taskigt&quot;? . design /d…õÀàsajn/ | internet /Àà…™nt…õrn…õt/, /…™nt…õrÀàn…õt/ | . !echo taskigt|espeak -v sv --ipa 2&gt; /dev/null . (en)tÀàask…™…°t(sv) . !cat test.phn|sed -e &#39;s/^ //;s/t a s k …™ …° t/t a s k …™ t/&#39; &gt; tmp !mv tmp test.phn !cat train.phn|sed -e &#39;s/^ //;s/d …™ z a…™ n/d …õ s a j n/;s/…™ n t …ô n …õ t/…™ n t …õ r n …õ t/&#39; &gt; tmp !mv tmp train.phn !cat valid.phn|sed -e &#39;s/^ //;s/…™ n t …ô n …õ t/…™ n t …õ r n …õ t/&#39; &gt; tmp !mv tmp valid.phn . !for i in train test valid; do cat $i.wrd|tr &#39; &#39; &#39; n&#39;|sort|uniq |grep -v &#39;^internet$&#39;|grep -v &#39;^design$&#39;|grep -v &#39;^taskigt$&#39; &gt; /tmp/$i.wl; cat /tmp/$i.wl | PHONEMIZER_ESPEAK_PATH=$(which espeak) phonemize -o /tmp/$i.wl.phn -p &#39; &#39; -w &#39;&#39; -l sv -j 70 --language-switch remove-flags;paste /tmp/$i.wl /tmp/$i.wl.phn &gt; dict.$i; done !printf &quot;taskigt tt a s k …™ t n&quot; &gt;&gt; dict.test !printf &quot;design td …õ s a j n n&quot; &gt;&gt; dict.train !printf &quot;internet t…™ n t …õ r n …õ t n&quot; &gt;&gt; dict.train !printf &quot;internet t…™ n t …õ r n …õ t n&quot; &gt;&gt; dict.valid . !for i in dic*;do cat $i |sort &gt; tmp;mv tmp $i;done . cat: valid: No such file or directory .",
            "url": "https://jimregan.github.io/notes/kaggle/wav2vec-u/2021/05/26/wav2vec-u-cv-swedish-prep-ltr-phn-wrd.html",
            "relUrl": "/kaggle/wav2vec-u/2021/05/26/wav2vec-u-cv-swedish-prep-ltr-phn-wrd.html",
            "date": " ‚Ä¢ May 26, 2021"
        }
        
    
  
    
        ,"post78": {
            "title": "Attempt to install Merlin on Kaggle",
            "content": "!git clone https://github.com/CSTR-Edinburgh/merlin . Merlin needs bandmat, but there&#39;s an issue with Python 3.7 and Cython, so build it separately: . %%capture !pip install git+https://github.com/MattShannon/bandmat . %cd merlin . /kaggle/working/merlin . %%capture !pip install -r requirements.txt . %cd tools . /kaggle/working/merlin/tools . %%capture !apt-get -y install csh automake autoconf . !./compile_tools.sh . %cd /kaggle/working/merlin . /kaggle/working/merlin . %cd egs/slt_arctic . /kaggle/working/merlin/egs/slt_arctic . !cat README . About the SLT Arctic corpus The CMU_ARCTIC databases were constructed at the Language Technologies Institute at Carnegie Mellon University as phonetically balanced, US English single speaker databases designed for unit selection speech synthesis research. The databases consist of around 1150 utterances carefully selected from out-of-copyright texts from Project Gutenberg. The databses include US English male (bdl) and female (slt) speakers (both experienced voice talent) as well as other accented speakers. Each subdirectory of this directory contains the scripts for a sequence of experiments. s1: To run slt_arctic_demo with WORLD vocoder. s2: To run slt_arctic_demo with MagPhase vocoder (includes acoustic feature extraction). . %cd s1 . /kaggle/working/merlin/egs/slt_arctic/s1 . !ls . 01_setup.sh RESULTS.md scripts 02_prepare_conf_files.sh conf slt_arctic_full_data 03_train_duration_model.sh experiments slt_arctic_full_data.zip 04_train_acoustic_model.sh merlin_synthesis.sh testrefs 05_run_merlin.sh run_demo.sh README.md run_full_voice.sh . !./01_setup.sh . ################################ Usage: Chose any of the below datasets To run on short data: ./01_setup.sh slt_arctic_demo ./01_setup.sh awb_arctic_demo (or) To run on full data: ./01_setup.sh slt_arctic_full ./01_setup.sh awb_arctic_full ./01_setup.sh bdl_arctic_full ################################ . !./01_setup.sh slt_arctic_full . Step 1: downloading data..... % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 247M 100 247M 0 0 23.1M 0 0:00:10 0:00:10 --:--:-- 26.5M unzipping files...... data is ready! Merlin default voice settings configured in conf/global_settings.cfg setup done...! . !./02_prepare_conf_files.sh . ################################ Usage: ./02_prepare_conf_files.sh &lt;path_to_global_conf_file&gt; default path to global conf file: conf/global_settings.cfg Config files will be prepared based on settings in global conf file ################################ . !cat conf/global_settings.cfg . MerlinDir=/kaggle/working/merlin WorkDir=/kaggle/working/merlin/egs/slt_arctic/s1 Voice=slt_arctic_full Labels=state_align QuestionFile=questions-radio_dnn_416.hed Vocoder=WORLD SamplingFreq=16000 FileIDList=file_id_list_full.scp Train=1000 Valid=66 Test=66 . !./02_prepare_conf_files.sh conf/global_settings.cfg . Step 2: preparing config files for acoustic, duration models... Duration configuration settings stored in conf/duration_slt_arctic_full.conf Acoustic configuration settings stored in conf/acoustic_slt_arctic_full.conf preparing config files for synthesis... Duration configuration settings stored in conf/test_dur_synth_slt_arctic_full.conf Acoustic configuration settings stored in conf/test_synth_slt_arctic_full.conf . !./03_train_duration_model.sh . ################################ Usage: ./03_train_duration_model.sh &lt;path_to_duration_conf_file&gt; Default path to duration conf file: conf/duration_slt_arctic_full.conf ################################ . !./03_train_duration_model.sh conf/duration_slt_arctic_full.conf . Step 3: training duration model... Architecture: x86_64 Distribution: Ubuntu 18.04.5 LTS HOSTNAME=37a070d6fe91 USER= PATH: /opt/conda/bin /usr/local/sbin /usr/local/bin /usr/sbin /usr/bin /sbin /bin LD_LIBRARY_PATH: /opt/conda/lib PYTHONPATH: /kaggle/lib/kagglegym /kaggle/lib PYTHONBIN: python MERLIN_THEANO_FLAGS: cuda.root=/usr/local/8.0 floatX=float32 on_unused_input=ignore No GPU is available! Running on CPU... /opt/conda/lib/python3.7/site-packages/theano/configparser.py:255: UserWarning: Theano does not recognise this flag: cuda.root warnings.warn(f&#34;Theano does not recognise this flag: {key}&#34;) Traceback (most recent call last): File &#34;/kaggle/working/merlin/src/run_merlin.py&#34;, line 74, in &lt;module&gt; from models.deep_rnn import DeepRecurrentNetwork File &#34;/kaggle/working/merlin/src/models/deep_rnn.py&#34;, line 9, in &lt;module&gt; from theano.tensor.shared_randomstreams import RandomStreams ModuleNotFoundError: No module named &#39;theano.tensor.shared_randomstreams&#39; .",
            "url": "https://jimregan.github.io/notes/kaggle/merlin/2021/05/26/merlin-attempt.html",
            "relUrl": "/kaggle/merlin/2021/05/26/merlin-attempt.html",
            "date": " ‚Ä¢ May 26, 2021"
        }
        
    
  
    
        ,"post79": {
            "title": "wav2vec-u Common Voice Swedish - vad",
            "content": "Original here . %cd /tmp . /tmp . !git clone https://github.com/pytorch/fairseq/ . %cd fairseq/examples/wav2vec/unsupervised . /tmp/fairseq/examples/wav2vec/unsupervised . !git clone https://github.com/zhenghuatan/rVADfast . !cat scripts/vads.py|sed -e &#39;s!/path/to/rVADfast_py_2.0!/tmp/fairseq/examples/wav2vec/unsupervised/rVADfast!&#39; &gt; tmp !mv tmp scripts/vads.py . !for i in train valid test;do cat /kaggle/input/fork-of-wav2vec-u-cv-swedish-tsv/$i.tsv|python scripts/vads.py &gt; /kaggle/working/$i.vads;done . 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2331/2331 [1:01:46&lt;00:00, 1.59s/it] 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2019/2019 [53:39&lt;00:00, 1.59s/it] 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2027/2027 [57:26&lt;00:00, 1.70s/it] . !mkdir /kaggle/working/wav !mkdir /kaggle/working/wav/train !mkdir /kaggle/working/wav/test !mkdir /kaggle/working/wav/valid . !for i in train test valid; do python scripts/remove_silence.py --tsv /kaggle/input/fork-of-wav2vec-u-cv-swedish-tsv/$i.tsv --vads /kaggle/working/$i.vads --out /kaggle/working/wav/$i;done .",
            "url": "https://jimregan.github.io/notes/kaggle/wav2vec-u/2021/05/25/wav2vec-u-cv-swedish-vads.html",
            "relUrl": "/kaggle/wav2vec-u/2021/05/25/wav2vec-u-cv-swedish-vads.html",
            "date": " ‚Ä¢ May 25, 2021"
        }
        
    
  
    
        ,"post80": {
            "title": "wav2vec-u Common Voice Swedish - prepare tsv",
            "content": "Original here . import soundfile input = { &#39;train&#39;: &#39;/kaggle/input/download-common-voice-swedish/cv-corpus-6.1-2020-12-11/sv-SE/train.tsv&#39;, &#39;test&#39;: &#39;/kaggle/input/download-common-voice-swedish/cv-corpus-6.1-2020-12-11/sv-SE/test.tsv&#39;, &#39;valid&#39;: &#39;/kaggle/input/download-common-voice-swedish/cv-corpus-6.1-2020-12-11/sv-SE/dev.tsv&#39; } for split in input.keys(): with open(input[split], &#39;r&#39;) as tsv: with open(f&#39;/kaggle/working/{split}.tsv&#39;, &#39;w&#39;) as out: print(&#39;/kaggle/input/common-voice-swedish-16bit-wav/&#39;, file=out) for line in tsv.readlines(): data = line.split(&#39; t&#39;) if data[1] == &#39;path&#39;: continue file = data[1] file = file.replace(&#39;.mp3&#39;, &#39;.wav&#39;) path = f&#39;/kaggle/input/common-voice-swedish-16bit-wav/{file}&#39; frames = soundfile.info(path).frames print(&quot;{} t{}&quot;.format(file, frames), file=out) .",
            "url": "https://jimregan.github.io/notes/kaggle/wav2vec-u/2021/05/25/wav2vec-u-cv-swedish-tsv.html",
            "relUrl": "/kaggle/wav2vec-u/2021/05/25/wav2vec-u-cv-swedish-tsv.html",
            "date": " ‚Ä¢ May 25, 2021"
        }
        
    
  
    
        ,"post81": {
            "title": "Download Common Voice Swedish",
            "content": "Original notebook here . This link won&#39;t work any more, so you&#39;ll need a fresh link from Common Voice Datasets . !wget &#39;https://mozilla-common-voice-datasets.s3.dualstack.us-west-2.amazonaws.com/cv-corpus-6.1-2020-12-11/sv-SE.tar.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=ASIAQ3GQRTO3KA6TWRBY%2F20210525%2Fus-west-2%2Fs3%2Faws4_request&amp;X-Amz-Date=20210525T103604Z&amp;X-Amz-Expires=43200&amp;X-Amz-Security-Token=FwoGZXIvYXdzEHwaDAOxZbXj8dSCv%2B%2B1%2FyKSBFuQ4WGxxfHEd51rf4QvMe6fipqbY4nXKUe7Hi%2FCoUFR%2BgXEgXjMjzgKih3fiiBllsdJ1w%2BO4dQ6mKmIYdYWwfXWezdctGJ13gGNYRX2RO8EpTEHOcG48Jvc8pF97Wrv4vZ3Kmlo0jf3Y6rKLZ3HHiKbkQBQgCT40vylI0wPZg5pFXZm6o%2B8zXun1NncwAzRtbmsDSuYT0tJ4zLXpzTZhJ0Ln%2F5gZVxPnZv5WleN0sFcYBMsqTnt9hNyaCQFbnQuCv1BfE6m6KBCG8cSc23YN%2FALgcd4EzxvPaIRM%2F0vFjPTHQFuipe3du7u6TW5gJemh0xaJnLczIx7FbmkrWuZ6HXQH77U7S4YQEX3BSLrBhkcIS7QeTv9oZ5D7yfCbRAXc2V2qzVANcAoipgYxP2By0iA0C90t3ggu5YvTwSAnrHxtSDMalsXU6%2BVcEo87VDb2DkOZ9OtpApZdpstX7QXHmC5QdR7Gg7M4aiW9jbZMyAH%2FQAowc2pZHqh%2BrJqySYOLYMWEApqDZ94VaCkuguuXODS25l%2F07IqAaCzT5LO%2FjPyuFBs7nXlDZXZo64295Iu6VDprtvutUvHbxQy6qkiMYT%2Fkt297E%2FsorK9YjNhj17PjtGPx6EW4WZIHLikvpkQ3aEiVN5%2ByLu9sbj8lwdzWnf9mSGp3T5oedv27ARY1SvmWn9uQH1FB6Tet%2ByaM5u1KIBKKJGbs4UGMipKgz7uHdY53WDR2h1mkBlucbyh484Wj%2BldCrqic%2FgIKjqhay57WHKZe2w%3D&amp;X-Amz-Signature=549006bf559d20bba1fbc6523f7b7b02ef8b2b7a68f229b1875bd02336e3c3b6&amp;X-Amz-SignedHeaders=host&#39; -O sv-SE.tar.gz . !tar zxvf sv-SE.tar.gz !rm sv-SE.tar.gz .",
            "url": "https://jimregan.github.io/notes/kaggle/wav2vec-u/2021/05/25/download-common-voice-swedish.html",
            "relUrl": "/kaggle/wav2vec-u/2021/05/25/download-common-voice-swedish.html",
            "date": " ‚Ä¢ May 25, 2021"
        }
        
    
  
    
        ,"post82": {
            "title": "Convert Common Voice Swedish to 16bit wav",
            "content": "Original here . !for i in ../input/download-common-voice-swedish/cv-corpus-6.1-2020-12-11/sv-SE/clips/*.mp3;do o=$(basename $i &#39;.mp3&#39;); ffmpeg -i &quot;$i&quot; -acodec pcm_s16le -ac 1 -ar 16000 $o.wav;done .",
            "url": "https://jimregan.github.io/notes/kaggle/wav2vec-u/2021/05/25/common-voice-swedish-16bit-wav.html",
            "relUrl": "/kaggle/wav2vec-u/2021/05/25/common-voice-swedish-16bit-wav.html",
            "date": " ‚Ä¢ May 25, 2021"
        }
        
    
  
    
        ,"post83": {
            "title": "Tuairisc question page scraper",
            "content": "import requests from bs4 import BeautifulSoup . url1 = &#39;https://tuairisc.ie/leamhthuiscint-faoiseamh-agus-saoirse-sa-snamh/&#39; . def _get_url(url): r = requests.get(url) if r.status_code != 200: raise Exception(&quot;Failed to open landing page&quot;) return r.content . def _stop_reading(elem): from bs4.element import NavigableString if isinstance(elem, NavigableString): return False elems = [c for c in elem.children] return len(elems) == 1 and elems[0].name == &#39;h2&#39; and &#39; &#39;.join(elems[0][&#39;class&#39;]) == &#39;heading-banner education__banner&#39; . t1 = _get_url(url1) . soup = BeautifulSoup(t1, &#39;html.parser&#39;) . desc = soup.find(&#39;meta&#39;, {&#39;property&#39;: &#39;og:description&#39;})[&#39;content&#39;] title = soup.find(&#39;meta&#39;, {&#39;property&#39;: &#39;og:title&#39;})[&#39;content&#39;] . article_outer = soup.find(&#39;article&#39;) . article = article_outer.find(&#39;div&#39;, {&#39;itemprop&#39;: &#39;articleBody&#39;}) . def _extract_text(article): from bs4.element import NavigableString paragraphs = [] for i in article.children: if isinstance(i, NavigableString): continue if _stop_reading(i): return paragraphs paragraphs.append(i.text.replace(&#39; xa0&#39;, &#39; &#39;)) . def _extract_questions(article): out = [] for p in article.find(&#39;ol&#39;).findAll(&#39;li&#39;): out.append(p.text) return out . qs = _extract_questions(article) . qs . x.findAll(&#39;li&#39;) .",
            "url": "https://jimregan.github.io/notes/irish/tuairisc/incomplete/2021/05/24/tuairisc-question-page-scraper.html",
            "relUrl": "/irish/tuairisc/incomplete/2021/05/24/tuairisc-question-page-scraper.html",
            "date": " ‚Ä¢ May 24, 2021"
        }
        
    
  
    
        ,"post84": {
            "title": "Training Kaldi on Kaggle - Data Prep",
            "content": "%cd /opt . /opt . %%capture !tar xvf /kaggle/input/extract-prebuilt-kaldi-from-docker/kaldi.tar . %cd kaldi/egs . /opt/kaldi/egs . !git clone https://github.com/danijel3/ClarinStudioKaldi . Cloning into &#39;ClarinStudioKaldi&#39;... remote: Enumerating objects: 778, done. remote: Counting objects: 100% (3/3), done. remote: Compressing objects: 100% (3/3), done. remote: Total 778 (delta 0), reused 0 (delta 0), pack-reused 775 Receiving objects: 100% (778/778), 35.26 MiB | 19.96 MiB/s, done. Resolving deltas: 100% (262/262), done. . %cd ClarinStudioKaldi . /opt/kaldi/egs/ClarinStudioKaldi . %%capture !conda install -c bioconda perl-perlio-gzip -y . import os os.environ[&#39;LD_LIBRARY_PATH&#39;] = &#39;/opt/conda/lib:/opt/kaldi/tools/openfst-1.6.7/lib:/opt/kaldi/src/lib&#39; . !cat path.sh|sed -e &#39;s/~ /apps/ /opt/&#39; &gt; tmp !mv tmp path.sh . !echo &gt; local_clarin/clarin_pl_clean.sh . !mkdir /kaggle/working/data !ln -s /kaggle/working/data . %%writefile /opt/kaldi/tools/phonetisaurus-g2p/src/scripts/phonetisaurus-apply #!/usr/bin/env python # -*- mode: python; coding: utf-8 -*- from __future__ import print_function from __future__ import unicode_literals import os, logging, subprocess, time, re from datetime import datetime from collections import defaultdict import tempfile class G2PModelTester () : &quot;&quot;&quot;G2P Model training wrapper class. Phonetisaurus G2P modeling training wrapper class. This wraps the alignment, joint n-gram training, and ARPA to WFST conversion steps into one command. &quot;&quot;&quot; def __init__ (self, model, **kwargs) : self.model = model self.lexicon_file = kwargs.get (&quot;lexicon&quot;, None) self.nbest = kwargs.get (&quot;nbest&quot;, 1) self.thresh = kwargs.get (&quot;thresh&quot;, 99) self.beam = kwargs.get (&quot;beam&quot;, 10000) self.greedy = kwargs.get (&quot;greedy&quot;, False) self.accumulate = kwargs.get (&quot;accumulate&quot;, False) self.pmass = kwargs.get (&quot;pmass&quot;, 0.0) self.probs = kwargs.get (&quot;probs&quot;, False) self.verbose = kwargs.get (&quot;verbose&quot;, False) self.logger = self.setupLogger () def setupLogger (self) : &quot;&quot;&quot;Setup the logger and logging level. Setup the logger and logging level. We only support verbose and non-verbose mode. Args: verbose (bool): Verbose mode, or not. Returns: Logger: A configured logger instance. &quot;&quot;&quot; level = logging.DEBUG if self.verbose else logging.INFO logging.basicConfig ( level=level, format=&quot; 033[94m%(levelname)s:%(name)s:&quot; &quot;%(asctime)s 033[0m: %(message)s&quot;, datefmt=&quot;%Y-%m-%d %H:%M:%S&quot; ) return logging.getLogger (&quot;phonetisaurus-apply&quot;) def _loadLexicon (self) : &quot;&quot;&quot;Load the lexicon from a file. Load the reference lexicon from a file, and store it in a defaultdict (list). &quot;&quot;&quot; _lexicon = defaultdict (list) if not self.lexicon_file : return _lexicon self.logger.debug (&quot;Loading lexicon from file...&quot;) with open (self.lexicon_file, &quot;r&quot;) as ifp : for line in ifp : # py2py3 compatbility, if sys.version_info[0] &lt; 3: line = line.decode(&quot;utf8&quot;).strip () else: line = line.strip () word, pron = re.split (r&quot; t&quot;, line, 1) _lexicon [word].append (pron) return _lexicon def checkPhonetisaurusConfig (self) : &quot;&quot;&quot;Run some basic checks before training. Run some basic checks regarding the $PATH, environment, and provided data before starting training. Raises: EnvironmentError: raised if binaries are not found. &quot;&quot;&quot; self.logger.debug (&quot;Checking command configuration...&quot;) for program in [&quot;phonetisaurus-g2pfst&quot;] : if not self.which (program) : raise EnvironmentError(&quot;Phonetisaurus command, &#39;{0}&#39;, &quot; &quot;not found in path.&quot;.format (program)) if self.lexicon_file and not os.path.exists (self.lexicon_file) : self.logger.error (&quot;Could not find provided lexicon file.&quot;) sys.exit (1) for key,val in sorted (vars (self).items ()) : self.logger.debug (u&quot;{0}: {1}&quot;.format (key, val)) self.lexicon = self._loadLexicon () return def which (self, program) : &quot;&quot;&quot;Basic &#39;which&#39; implementation for python. Basic &#39;which&#39; implementation for python from stackoverflow: * https://stackoverflow.com/a/377028/6739158 Args: program (str): The program name to search the $PATH for. Returns: path/None: The path to the executable, or None. &quot;&quot;&quot; def is_exe (fpath) : return os.path.isfile (fpath) and os.access (fpath, os.X_OK) fpath, fname = os.path.split (program) if fpath: if is_exe (program): return program else: for path in os.environ[&quot;PATH&quot;].split (os.pathsep) : path = path.strip (&#39;&quot;&#39;) exe_file = os.path.join (path, program) if is_exe (exe_file): return exe_file return None def makeG2PCommand (self, word_list) : &quot;&quot;&quot;Build the G2P command. Build the G2P command from the provided arguments. Returns: list: The command in subprocess list format. &quot;&quot;&quot; command = [ u&quot;phonetisaurus-g2pfst&quot;, u&quot;--model={0}&quot;.format (self.model), u&quot;--nbest={0}&quot;.format (self.nbest), u&quot;--beam={0}&quot;.format (self.beam), u&quot;--thresh={0}&quot;.format (self.thresh), u&quot;--accumulate={0}&quot;.format (str (self.accumulate).lower ()), u&quot;--pmass={0}&quot;.format (self.pmass), u&quot;--nlog_probs={0}&quot;.format (str(not self.probs).lower ()), u&quot;--wordlist={0}&quot;.format (word_list) ] self.logger.debug (u&quot; &quot;.join (command)) return command def runG2PCommand (self, word_list_file) : &quot;&quot;&quot;Generate and run the actual G2P command. Generate and run the actual G2P command. Each synthesized entry will be yielded back on-the-fly via the subprocess stdout readline method. Args: word_list_file (str): The input word list. &quot;&quot;&quot; g2p_command = self.makeG2PCommand (word_list_file) self.logger.debug (&quot;Applying G2P model...&quot;) with open (os.devnull, &quot;w&quot;) as devnull : proc = subprocess.Popen ( g2p_command, stdout=subprocess.PIPE, stderr=devnull if not self.verbose else None ) for line in proc.stdout : parts = re.split (r&quot; t&quot;, line.decode (&quot;utf8&quot;).strip ()) if not len (parts) == 3 : self.logger.warning ( u&quot;No pronunciation for word: &#39;{0}&#39;&quot;.format (parts [0]) ) continue yield parts return def applyG2POnly (self, word_list_file) : &quot;&quot;&quot;Apply the G2P model to a word list. Apply the G2P model to a word list. No filtering or application of a reference lexicon is used here. Args: word_list_file (str): The input word list. &quot;&quot;&quot; for word, score, pron in self.runG2PCommand (word_list_file) : line = u&quot;&quot; if self.verbose : line = u&quot;{0} t{1:.2f} t{2}&quot;.format ( word, float (score), pron ) else : line = u&quot;{0} t{1}&quot;.format (word, pron) # py2py3 compatbility, if sys.version_info[0] &lt; 3: print (line.encode (&quot;utf8&quot;)) else : print (line) return def applyG2PWithLexicon (self, word_list_file) : &quot;&quot;&quot;Apply the G2P model to a word list, combined with lexicon. Apply the G2P model to a word list, but combine this with a reference lexicon. Words for which a reference entry exists will not be sent to the G2P, unless the additional &#39;--greedy&#39; flag is set to True. Args: word_list_file (str): The input word list. &quot;&quot;&quot; target_lexicon = defaultdict (list) tmpwordlist = tempfile.NamedTemporaryFile(mode=&#39;w&#39;, delete=False) #First, find any words in the target list for which we already # have a canonical pronunciation in the reference lexicon. with open (word_list_file, &quot;r&quot;) as ifp : for word in ifp : # py2py3 compatbility, if sys.version_info[0] &lt; 3: word = word.decode (&quot;utf8&quot;).strip () else: word = word.strip () # already in &#39;utf8&#39;. if word in self.lexicon : target_lexicon [word] = [(0.0,pron) for pron in self.lexicon [word]] #In greedy mode we still send words to the G2P, even # if we have canonical entries in the reference lexicon. if self.greedy : print (word.encode (&quot;utf8&quot;), file=tmpwordlist) else : # py2py3 compatbility, if sys.version_info[0] &lt; 3: print (word.encode (&quot;utf8&quot;), file=tmpwordlist) else: print (word, file=tmpwordlist) tmpwordlist.close () #Second, iterate through the G2P output, and filter against # any possible duplicates previously found in the reference lexicon. for word, score, pron in self.runG2PCommand (tmpwordlist.name) : prons = set ([p for s,p in target_lexicon [word]]) if pron in prons : continue target_lexicon [word].append ((score, pron)) #Finally, sort everything that is left and print it. for word in sorted (target_lexicon.keys ()) : for score, pron in target_lexicon [word] : line = u&quot;&quot; if self.verbose : line = u&quot;{0} t{1:.2f} t{2}&quot;.format ( word, float (score), pron ) else : line = u&quot;{0} t{1}&quot;.format (word, pron) # py2py3 compatbility, if sys.version_info[0] &lt; 3: print (line.encode (&quot;utf8&quot;)) else : print (line) os.unlink (tmpwordlist.name) return def ApplyG2PModel (self, word_list_file) : &quot;&quot;&quot;Apply the G2P model to a word list. Apply the G2P model to a word list. Args: word_list_file (str): The input word list. &quot;&quot;&quot; self.checkPhonetisaurusConfig () if not os.path.exists (word_list_file) or not os.path.isfile (word_list_file) : raise IOError(&quot;Word list file not found.&quot;) if len (self.lexicon) == 0 : self.applyG2POnly (word_list_file) else : self.applyG2PWithLexicon (word_list_file) return if __name__ == &quot;__main__&quot; : import sys, argparse example = &quot;{0} --model train/model.fst --word test&quot;.format (sys.argv [0]) parser = argparse.ArgumentParser (description=example) parser.add_argument (&quot;--model&quot;, &quot;-m&quot;, help=&quot;Phonetisaurus G2P fst model.&quot;, required=True) parser.add_argument (&quot;--lexicon&quot;, &quot;-l&quot;, help=&quot;Optional reference lexicon.&quot;, required=False) parser.add_argument (&quot;--nbest&quot;, &quot;-n&quot;, help=&quot;Maximum number of hypotheses &quot; &quot;to produce. Overridden if --pmass is set.&quot;, default=1, type=int) parser.add_argument (&quot;--beam&quot;, &quot;-b&quot;, help=&quot;Search &#39;beam&#39;.&quot;, default=10000, type=int) parser.add_argument (&quot;--thresh&quot;, &quot;-t&quot;, help=&quot;Pruning threshold for n-best.&quot;, default=99.0, type=float) parser.add_argument (&quot;--greedy&quot;, &quot;-g&quot;, help=&quot;Use the G2P even if a &quot; &quot;reference lexicon has been provided.&quot;, default=False, action=&quot;store_true&quot;) parser.add_argument (&quot;--accumulate&quot;, &quot;-a&quot;, help=&quot;Accumulate probabilities &quot; &quot;across unique pronunciations.&quot;, default=False, action=&quot;store_true&quot;) parser.add_argument (&quot;--pmass&quot;, &quot;-p&quot;, help=&quot;Select the maximum number of &quot; &quot;hypotheses summing to P total mass for a word.&quot;, default=0.0, type=float) parser.add_argument (&quot;--probs&quot;, &quot;-pr&quot;, help=&quot;Print exp(-val) &quot; &quot;instead of default -log values.&quot;, default=False, action=&quot;store_true&quot;) parser.add_argument (&quot;--word_list&quot;, &quot;-wl&quot;, help=&quot;Input word or word list to apply &quot; &quot;G2P model to.&quot;, type=str) parser.add_argument (&quot;--verbose&quot;, &quot;-v&quot;, help=&quot;Verbose mode.&quot;, default=False, action=&quot;store_true&quot;) args = parser.parse_args () tester = G2PModelTester ( args.model, **{key:val for key,val in args.__dict__.items () if not key in [&quot;model&quot;,&quot;word_list&quot;]} ) tester.ApplyG2PModel (args.word_list) . Overwriting /opt/kaldi/tools/phonetisaurus-g2p/src/scripts/phonetisaurus-apply . !chmod a+x /opt/kaldi/tools/phonetisaurus-g2p/src/scripts/phonetisaurus-apply . %%writefile local_clarin/clarin_prepare_dict.sh #!/bin/bash # Copyright 2010-2012 Microsoft Corporation # 2012-2014 Johns Hopkins University (Author: Daniel Povey) # 2015 Guoguo Chen # Modified 2017 Danijel Korzinek # Licensed under the Apache License, Version 2.0 (the &quot;License&quot;); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # THIS CODE IS PROVIDED *AS IS* BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY # KIND, EITHER EXPRESS OR IMPLIED, INCLUDING WITHOUT LIMITATION ANY IMPLIED # WARRANTIES OR CONDITIONS OF TITLE, FITNESS FOR A PARTICULAR PURPOSE, # MERCHANTABLITY OR NON-INFRINGEMENT. # See the Apache 2 License for the specific language governing permissions and # limitations under the License. # Call this script from one level above, e.g. from the s3/ directory. It puts # its output in data/local/. # The parts of the output of this that will be needed are # [in data/local/dict/ ] # lexicon.txt # extra_questions.txt # nonsilence_phones.txt # optional_silence.txt # silence_phones.txt # run this from ../ echo &quot;$0 $@&quot; # Print the command line for logging . utils/parse_options.sh || exit 1; . ./path.sh if [ $# -ne 2 ]; then echo &quot;Usage: ./local/prepare_lang.sh &lt;word_list&gt; &lt;dict_dir&gt;&quot; echo &quot;Creates a folder &lt;dict_dir&gt; with lexicon derived from&quot; echo &quot; word list &lt;word_list&gt;.&quot; exit 1 fi word_list=$1 dir=$2 mkdir -p $dir # Make phones symbol-table (adding in silence and verbal and non-verbal noises at this point). # We are adding suffixes _B, _E, _S for beginning, ending, and singleton phones. # silence phones, one per line. (echo sil) &gt; $dir/silence_phones.txt echo sil &gt; $dir/optional_silence.txt # nonsilence phones; on each line is a list of phones that correspond # really to the same base phone. printf &quot;I nS nZ na nb nd ndZ ndz ndzi ne nen nf ng ni nj nk nl nm nn nni no non np nr ns nsi nt ntS nts ntsi nu nv nw nx nz nzi n&quot; &gt; $dir/nonsilence_phones.txt # A few extra questions that will be added to those obtained by automatically clustering # the &quot;real&quot; phones. These ask about stress; there&#39;s also one for silence. cat $dir/silence_phones.txt| awk &#39;{printf(&quot;%s &quot;, $1);} END{printf &quot; n&quot;;}&#39; &gt; $dir/extra_questions.txt || exit 1; cat $dir/nonsilence_phones.txt | perl -e &#39;while(&lt;&gt;){ foreach $p (split(&quot; &quot;, $_)) { $p =~ m:^([^ d]+)( d*)$: || die &quot;Bad phone $_&quot;; $q{$2} .= &quot;$p &quot;; } } foreach $l (values %q) {print &quot;$l n&quot;;}&#39; &gt;&gt; $dir/extra_questions.txt || exit 1; #Transcribe the wordlist export LD_LIBRARY_PATH=$KALDI_ROOT/tools/openfst/lib export PATH=$PATH:/opt/kaldi/tools/phonetisaurus-g2p/ /opt/kaldi/tools/phonetisaurus-g2p/src/scripts/phonetisaurus-apply --model local_clarin/model.fst --lexicon local_clarin/lexicon.txt --word_list $word_list -p 0.8 &gt; $dir/lexicon_raw_nosil.txt || exit 1 sort -u $dir/lexicon_raw_nosil.txt -o $dir/lexicon_raw_nosil.txt # Add the silences, noises etc. # the sort | uniq is to remove a duplicated pron. # lexicon.txt is without the _B, _E, _S, _I markers. (echo -e &#39;&lt;unk&gt; tsil&#39; ) | cat - $dir/lexicon_raw_nosil.txt | sort -u &gt; $dir/lexicon.txt || exit 1; # Cleanup rm -f $dir/lexiconp.txt rm -f $dir/lexicon_raw_nosil.txt echo &quot;Dictionary preparation succeeded&quot; . Overwriting local_clarin/clarin_prepare_dict.sh . %%writefile local_clarin/clarin_pl_data_prep.sh #!/bin/bash . ./path.sh #you can change this here, if you want it on a different partition, for example AUDIO_DL_PATH=audio if [ ! -d $AUDIO_DL_PATH ] ; then mkdir -p $AUDIO_DL_PATH ; fi pushd $AUDIO_DL_PATH if [ ! -f audio.tar.gz ] ; then echo &quot;Downloading audio from the Clarin-pl website (~4.6GB)...&quot; curl -O http://mowa.clarin-pl.eu/korpusy/audio.tar.gz else echo &quot;File already downloaded! Checking if download is consistent...&quot; curl -O http://mowa.clarin-pl.eu/korpusy/audio.md5sum if ! md5sum -c audio.md5sum ; then echo &quot;Download doesn&#39;t match the one on the server! &quot; echo &quot;Erase the audio.tar.gz file (and audio folder) and run this script again!&quot; exit -1 fi fi if [ ! -d audio ] ; then echo &quot;Extracting files...&quot; tar xf audio.tar.gz else echo &quot;Files already extracted?&quot; echo &quot;Remove the audio dir to extract them again...&quot; fi popd if [ ! -d data ] ; then mkdir data ; fi echo Generating file lists using proper paths... python3 local_clarin/generate_lists.py $AUDIO_DL_PATH/audio data local_clarin echo Generating spk2utt... utils/utt2spk_to_spk2utt.pl data/train/utt2spk &gt; data/train/spk2utt utils/utt2spk_to_spk2utt.pl data/test/utt2spk &gt; data/test/spk2utt utils/utt2spk_to_spk2utt.pl data/dev/utt2spk &gt; data/dev/spk2utt echo Preparing dictionary... if [ ! -d data/local ] ; then mkdir data/local ; fi cut -f2- -d&#39; &#39; &lt; data/train/text | tr &#39; &#39; &#39; n&#39; | sort -u &gt; data/local/train.wlist if [ x&quot;$(which ngram)&quot; != x&quot;&quot; ] then ngram -lm local_clarin/arpa.lm.gz -unk -write-vocab data/local/lm.wlist else perl local_clarin/extract_vocab.pl local_clarin/arpa.lm.gz &gt; data/local/lm.wlist fi tail -n +5 data/local/lm.wlist | cat data/local/train.wlist - | sort -u &gt; data/local/all.wlist if [ ! -f local_clarin/model.fst ] ; then gunzip -c local_clarin/model.fst.gz &gt; local_clarin/model.fst ; fi local_clarin/clarin_prepare_dict.sh data/local/all.wlist data/local/dict_nosp || exit 1 . Overwriting local_clarin/clarin_pl_data_prep.sh . %%writefile runmfcc.sh #!/bin/bash . ./path.sh ## set the paths in this file correctly! # link to scripts from the standard Kaldi distribution # we try to use these as much as possible if [ ! -f $KALDI_ROOT/egs/wsj/s5/conf ] ; then ln -s $KALDI_ROOT/egs/wsj/s5/conf ; fi if [ ! -f $KALDI_ROOT/egs/wsj/s5/local ] ; then ln -s $KALDI_ROOT/egs/wsj/s5/local ; fi if [ ! -f $KALDI_ROOT/egs/wsj/s5/utils ] ; then ln -s $KALDI_ROOT/egs/wsj/s5/utils ; fi if [ ! -f $KALDI_ROOT/egs/wsj/s5/steps ] ; then ln -s $KALDI_ROOT/egs/wsj/s5/steps ; fi # exits script if error occurs anywhere # you might not want to do this for interactive shells. set -e export nj=40 ##number of concurrent processes export nj_test=30 ## number of concurrent processes for test has to be &lt;=30 # This is a shell script, but it&#39;s recommended that you run the commands one by # one by copying and pasting into the shell. #run some initial data preparation (look at the file for more details): local_clarin/clarin_pl_data_prep.sh #prepare the lang directory utils/prepare_lang.sh data/local/dict_nosp &quot;&lt;unk&gt;&quot; data/local/tmp_nosp data/lang_nosp #make G.fst utils/format_lm.sh data/lang_nosp local_clarin/arpa.lm.gz data/local/dict_nosp/lexicon.txt data/lang_nosp_test # Make normalized MFCC features. steps/make_mfcc.sh --nj $nj data/train steps/compute_cmvn_stats.sh data/train steps/make_mfcc.sh --nj $nj data/test steps/compute_cmvn_stats.sh data/test . Writing runmfcc.sh . !bash runmfcc.sh .",
            "url": "https://jimregan.github.io/notes/kaggle/kaldi/2021/05/24/kaldi-clarinstudio-polish-data-prep.html",
            "relUrl": "/kaggle/kaldi/2021/05/24/kaldi-clarinstudio-polish-data-prep.html",
            "date": " ‚Ä¢ May 24, 2021"
        }
        
    
  
    
        ,"post85": {
            "title": "Kaldi on Kaggle, ClarinStudio PL Mono iters 30-40",
            "content": "%cd /opt . /opt . %%capture !tar xvf /kaggle/input/extract-prebuilt-kaldi-from-docker/kaldi.tar . %cd kaldi/egs . /opt/kaldi/egs . !git clone https://github.com/danijel3/ClarinStudioKaldi . Cloning into &#39;ClarinStudioKaldi&#39;... remote: Enumerating objects: 778, done. remote: Counting objects: 100% (3/3), done. remote: Compressing objects: 100% (3/3), done. remote: Total 778 (delta 0), reused 0 (delta 0), pack-reused 775 Receiving objects: 100% (778/778), 35.26 MiB | 22.14 MiB/s, done. Resolving deltas: 100% (262/262), done. . %cd ClarinStudioKaldi . /opt/kaldi/egs/ClarinStudioKaldi . %%capture !conda install -c bioconda perl-perlio-gzip -y . import os os.environ[&#39;LD_LIBRARY_PATH&#39;] = &#39;/opt/conda/lib:/opt/kaldi/tools/openfst-1.6.7/lib:/opt/kaldi/src/lib&#39; . !cat path.sh|sed -e &#39;s/~ /apps/ /opt/&#39; &gt; tmp !mv tmp path.sh . !echo &gt; local_clarin/clarin_pl_clean.sh . !ln -s ../wsj/s5/steps !ln -s ../wsj/s5/conf !ln -s ../wsj/s5/local !ln -s ../wsj/s5/utils . !cp -r /kaggle/input/kaldi-clarinstudio-polish-train-mono-1-30/data /kaggle/working/ !cp -r /kaggle/input/kaldi-clarinstudio-polish-train-mono-1-30/exp /kaggle/working/ . !ln -s /kaggle/working/exp !ln -s /kaggle/working/data . !find /kaggle/working/exp -name &#39;*.log&#39; -delete . !/opt/kaldi/src/gmmbin/gmm-info --print-args=false exp/mono0/30.mdl | grep gaussians | awk &#39;{print $NF}&#39; . 925 . %%writefile train_mono.sh #!/usr/bin/env bash # Copyright 2012 Johns Hopkins University (Author: Daniel Povey) # 2019 Xiaohui Zhang # Apache 2.0 # Trimmed down from WSJ train_mono.sh, to continue from 30 # Begin configuration section. nj=4 cmd=run.pl scale_opts=&quot;--transition-scale=1.0 --acoustic-scale=0.1 --self-loop-scale=0.1&quot; num_iters=40 # Number of iterations of training max_iter_inc=30 # Last iter to increase #Gauss on. regular_beam=10 # beam used after the first iteration retry_beam=40 totgauss=1000 # Target #Gaussians. careful=false boost_silence=1.0 # Factor by which to boost silence likelihoods in alignment realign_iters=&quot;1 2 3 4 5 6 7 8 9 10 12 14 16 18 20 23 26 29 32 35 38&quot;; config= # name of config file. stage=-4 power=0.25 # End configuration section. echo &quot;$0 $@&quot; # Print the command line for logging if [ -f path.sh ]; then . ./path.sh; fi . parse_options.sh || exit 1; if [ $# != 3 ]; then echo &quot;Usage: steps/train_mono.sh [options] &lt;data-dir&gt; &lt;lang-dir&gt; &lt;exp-dir&gt;&quot; echo &quot; e.g.: steps/train_mono.sh data/train.1k data/lang exp/mono&quot; echo &quot;main options (for others, see top of script file)&quot; echo &quot; --config &lt;config-file&gt; # config containing options&quot; echo &quot; --nj &lt;nj&gt; # number of parallel jobs&quot; echo &quot; --cmd (utils/run.pl|utils/queue.pl &lt;queue opts&gt;) # how to run jobs.&quot; exit 1; fi data=$1 lang=$2 dir=$3 oov_sym=`cat $lang/oov.int` || exit 1; mkdir -p $dir/log echo $nj &gt; $dir/num_jobs sdata=$data/split$nj; [[ -d $sdata &amp;&amp; $data/feats.scp -ot $sdata ]] || split_data.sh $data $nj || exit 1; feats=&quot;ark,s,cs:apply-cmvn $cmvn_opts --utt2spk=ark:$sdata/JOB/utt2spk scp:$sdata/JOB/cmvn.scp scp:$sdata/JOB/feats.scp ark:- | add-deltas $delta_opts ark:- ark:- |&quot; cp $lang/phones.txt $dir || exit 1; numgauss=`gmm-info --print-args=false $dir/0.mdl | grep gaussians | awk &#39;{print $NF}&#39;` incgauss=$[($totgauss-$numgauss)/$max_iter_inc] # per-iter increment for #Gauss # update from last run #numgauss=`gmm-info --print-args=false $dir/30.mdl | grep gaussians | awk &#39;{print $NF}&#39;` #numgauss=925 igauss=1 while [ $igauss -lt 30 ];do numgauss=$[$numgauss+$incgauss]; igauss=$[$igauss+1] done # beam is only set to $initial_beam for first run beam=$regular_beam x=30 while [ $x -lt $num_iters ]; do echo &quot;$0: Pass $x&quot; if [ $stage -le $x ]; then if echo $realign_iters | grep -w $x &gt;/dev/null; then echo &quot;$0: Aligning data&quot; mdl=&quot;gmm-boost-silence --boost=$boost_silence `cat $lang/phones/optional_silence.csl` $dir/$x.mdl - |&quot; $cmd JOB=1:$nj $dir/log/align.$x.JOB.log gmm-align-compiled $scale_opts --beam=$beam --retry-beam=$retry_beam --careful=$careful &quot;$mdl&quot; &quot;ark:gunzip -c $dir/fsts.JOB.gz|&quot; &quot;$feats&quot; &quot;ark,t:|gzip -c &gt;$dir/ali.JOB.gz&quot; || exit 1; fi $cmd JOB=1:$nj $dir/log/acc.$x.JOB.log gmm-acc-stats-ali $dir/$x.mdl &quot;$feats&quot; &quot;ark:gunzip -c $dir/ali.JOB.gz|&quot; $dir/$x.JOB.acc || exit 1; $cmd $dir/log/update.$x.log gmm-est --write-occs=$dir/$[$x+1].occs --mix-up=$numgauss --power=$power $dir/$x.mdl &quot;gmm-sum-accs - $dir/$x.*.acc|&quot; $dir/$[$x+1].mdl || exit 1; rm $dir/$x.mdl $dir/$x.*.acc $dir/$x.occs 2&gt;/dev/null fi if [ $x -le $max_iter_inc ]; then numgauss=$[$numgauss+$incgauss]; fi beam=$regular_beam x=$[$x+1] done ( cd $dir; rm final.{mdl,occs} 2&gt;/dev/null; ln -s $x.mdl final.mdl; ln -s $x.occs final.occs ) steps/diagnostic/analyze_alignments.sh --cmd &quot;$cmd&quot; $lang $dir utils/summarize_warnings.pl $dir/log steps/info/gmm_dir_info.pl $dir echo &quot;$0: Done training monophone system in $dir&quot; exit 0 . Writing train_mono.sh . !bash train_mono.sh --nj 40 data/train data/lang_nosp exp/mono0 .",
            "url": "https://jimregan.github.io/notes/kaldi/kaggle/clarinstudio/2021/05/23/kaldi-clarinstudio-polish-train-mono-30-40.html",
            "relUrl": "/kaldi/kaggle/clarinstudio/2021/05/23/kaldi-clarinstudio-polish-train-mono-30-40.html",
            "date": " ‚Ä¢ May 23, 2021"
        }
        
    
  
    
        ,"post86": {
            "title": "Run ffmpeg silence detection on Wolne Lektury audio",
            "content": "Original on Kaggle . !for i in ../input/wolne-lektury-audio-zip/*.zip; do unzip $i -d /tmp; for j in /tmp/*.mp3; do base=$(basename &quot;$j&quot; &quot;.mp3&quot;); ffmpeg -i $j -af silencedetect=noise=-30dB:d=0.5 -f null - 2&gt; $base.txt; done; rm /tmp/*.mp3; done .",
            "url": "https://jimregan.github.io/notes/asr/polish/kaggle/2021/05/23/ffmpeg-silence-detection-wolne-lektury.html",
            "relUrl": "/asr/polish/kaggle/2021/05/23/ffmpeg-silence-detection-wolne-lektury.html",
            "date": " ‚Ä¢ May 23, 2021"
        }
        
    
  
    
        ,"post87": {
            "title": "CoreNLP English model on Kaggle",
            "content": "Original on Kaggle (complete with downloaded model). . !pip install stanza . import stanza stanza.install_corenlp(dir=&quot;corenlp&quot;) . Downloading http://nlp.stanford.edu/software/stanford-corenlp-latest.zip: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 504M/504M [02:28&lt;00:00, 3.39MB/s] . stanza.download_corenlp_models(model=&#39;english&#39;, version=&#39;4.1.0&#39;, dir=&quot;corenlp&quot;) . Downloading http://nlp.stanford.edu/software/stanford-corenlp-4.1.0-models-english.jar: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 671M/671M [03:37&lt;00:00, 3.08MB/s] .",
            "url": "https://jimregan.github.io/notes/kaggle/corenlp/english/2021/05/22/stanza-corenlp-english-model.html",
            "relUrl": "/kaggle/corenlp/english/2021/05/22/stanza-corenlp-english-model.html",
            "date": " ‚Ä¢ May 22, 2021"
        }
        
    
  
    
        ,"post88": {
            "title": "Quiggin to IPA",
            "content": "import icu def transliterator_from_rules(name, rules): fromrules = icu.Transliterator.createFromRules(name, rules) icu.Transliterator.registerInstance(fromrules) return icu.Transliterator.createInstance(name) . quiggin_to_wikipedia = &quot;&quot;&quot; b‚Ä≤ ‚Üí b ≤; b ‚Üí bÀ†; k‚Ä≤ ‚Üí c; k ‚Üí k; √ß ‚Üí √ß; d‚Ä≤ ‚Üí d ≤; d ‚Üí dÃ™À†; e : ‚Üí eÀê; …õ ‚Üí …õ; e ‚Üí …õ; …ô ‚Üí …ô; Œ±i ‚Üí …ôi; Œ±u ‚Üí …ôu; Œ± : ‚Üí aÀê; Œ±ÃÉ : ‚Üí aÀê; √¶ ‚Üí a; Œ± ‚Üí a; f‚Ä≤ ‚Üí f ≤; f ‚Üí fÀ†; …°‚Ä≤ ‚Üí …ü; g‚Ä≤ ‚Üí …ü; …° ‚Üí …°; g ‚Üí …°; ‚Ñä ‚Üí …£; h ‚Üí h; i : ‚Üí iÀê; i…ô ‚Üí i…ô; √Ø ‚Üí …™; ƒ© ‚Üí …™; i ‚Üí …™; y ‚Üí …™; j ‚Üí j; L‚Ä≤ ‚Üí lÃ† ≤; l‚Ä≤ ‚Üí l ≤; L ‚Üí lÃ™À†; l ‚Üí lÀ†; m‚Ä≤ ‚Üí m ≤; m ‚Üí mÀ†; n‚Ä≤ ‚Üí n ≤; n ‚Üí nÀ†; N‚Ä≤ ‚Üí nÃ† ≤; N ‚Üí nÃ™À†; …≤ ‚Üí …≤; ≈ã ‚Üí ≈ã; o : ‚Üí oÀê; …î : ‚Üí oÀê; …î ‚Üí …î; oÃ§ ‚Üí …î; p‚Ä≤ ‚Üí p ≤; p ‚Üí pÀ†; r‚Ä≤ ‚Üí …æ ≤; r ‚Üí …æÀ†; R ‚Üí …æÀ†; s ‚Üí sÀ†;  É ‚Üí  É; t‚Ä≤ ‚Üí t ≤; t ‚Üí tÃ™À†; u : ‚Üí uÀê; u…ô ‚Üí u…ô; ≈® ‚Üí  ä; U ‚Üí  ä; v ‚Üí v ≤; wÃ•&#39;`&#39; ‚Üí w; wÃ• ‚Üí w; w ‚Üí w; œá ‚Üí x; &quot;&quot;&quot; . quiggin = transliterator_from_rules(&#39;quiggin&#39;, quiggin_to_wikipedia) . quiggin.transliterate(&quot;…ô t‚Ä≤Œ±sp…ôl&quot;) . &#39;…ô t ≤asÀ†pÀ†…ôlÀ†&#39; . sample = &quot;&quot;&quot;  ÉŒ±n…îkl…ô. 1.‚ÄÉl‚Ä≤e É …ô N√Øl‚Ä≤…ô wŒ±duw Œ± œárŒ±ÃÉ:v. 2.‚ÄÉb‚Ä≤i: …ô √ßi…ôL hein‚Ä≤ …õg‚Ä≤ …ô N√Øl‚Ä≤…ô ‚Ñäyn‚Ä≤…ô Œ±g…ôs k‚Ä≤i…ôL …ôr L‚Ä≤e√ß …õg‚Ä≤ …ô N‚Ä≤Œ±r vir‚Ä≤…ô. 3.‚ÄÉN‚Ä≤i: wi:r‚Ä≤ …ô mŒ±duw ru…ô t‚Ä≤Œ±œát‚Ä≤ir‚Ä≤…ô N‚Ä≤i: b‚Ä≤Œ±:r NŒ± …õ hein‚Ä≤. 4.‚ÄÉmŒ±r…ôguw N…ô bŒ±: Ét‚Ä≤i:, L‚Ä≤ig‚Ä≤ d≈®wÃ•`, L‚Ä≤ik‚Ä≤…ô m‚Ä≤…ô did‚Ä≤. 5.‚ÄÉ…ôs NŒ±ÃÉ:wid‚Ä≤ …ô √ß√Ørd‚Ä≤ g…ôn …ô f‚Ä≤j…î:l‚Ä≤…ôm‚Ä≤. 6.‚ÄÉ Éi:l‚Ä≤i: N‚Ä≤ t‚Ä≤…õ…ôN dUwÃ• g…ôr b‚Ä≤e: …õ…ôn hein‚Ä≤ …ô t‚Ä≤…õ…ôn …ôs bŒ±:n‚Ä≤…ô er‚Ä≤ b‚Ä≤i√ß. 7.‚ÄÉ Ék‚Ä≤…õ…ôl …ô iN‚Ä≤ É…ô d…ô œáŒ±p…ôL s…ô kŒ±p…ôL …ôr to:n‚Ä≤ …ô NŒ±:rd‚Ä≤…ô. 8.‚ÄÉN‚Ä≤i:r‚Ä≤ vƒ© Ét‚Ä≤…ô d…ô f‚Ä≤Œ±d…ôr p…î:l. 9.‚ÄÉtu:s k‚Ä≤Œ±h…ô k‚Ä≤…î:. &quot;&quot;&quot; . print(quiggin.transliterate(sample)) .  ÉanÀ†…îklÀ†…ô. 1.‚ÄÉl ≤…õ É …ô nÃ™À†…™l ≤…ô wadÃ™À†uw a x…æÀ†aÀêv ≤. 2.‚ÄÉb ≤iÀê …ô √ßi…ôlÃ™À† h…õ…™n ≤ …õ…ü …ô nÃ™À†…™l ≤…ô …£…™n ≤…ô a…°…ôsÀ† ci…ôlÃ™À† …ô…æÀ† lÃ† ≤…õ√ß …õ…ü …ô nÃ† ≤a…æÀ† v ≤…™…æ ≤…ô. 3.‚ÄÉnÃ† ≤iÀê wiÀê…æ ≤ …ô mÀ†adÃ™À†uw …æÀ†u…ô t ≤axt ≤…™…æ ≤…ô nÃ† ≤iÀê b ≤aÀê…æÀ† nÃ™À†a …õ h…õ…™n ≤. 4.‚ÄÉmÀ†a…æÀ†…ô…°uw nÃ™À†…ô bÀ†aÀê Ét ≤iÀê, lÃ† ≤…™…ü dÃ™À† äw, lÃ† ≤…™c…ô m ≤…ô dÃ™À†…™d ≤. 5.‚ÄÉ…ôsÀ† nÃ™À†aÀêw…™d ≤ …ô √ß…™…æÀ†d ≤ …°…ônÀ† …ô f ≤joÀêl ≤…ôm ≤. 6.‚ÄÉ ÉiÀêl ≤iÀê nÃ† ≤ t ≤…õ…ônÃ™À† dÃ™À† äw …°…ô…æÀ† b ≤eÀê …õ…ônÀ† h…õ…™n ≤ …ô t ≤…õ…ônÀ† …ôsÀ† bÀ†aÀên ≤…ô …õ…æ ≤ b ≤…™√ß. 7.‚ÄÉ Éc…õ…ôlÀ† …ô …™nÃ† ≤ É…ô dÃ™À†…ô xapÀ†…ôlÃ™À† sÀ†…ô kapÀ†…ôlÃ™À† …ô…æÀ† tÃ™À†oÀên ≤ …ô nÃ™À†aÀê…æÀ†d ≤…ô. 8.‚ÄÉnÃ† ≤iÀê…æ ≤ v ≤…™ Ét ≤…ô dÃ™À†…ô f ≤adÃ™À†…ô…æÀ† pÀ†oÀêlÀ†. 9.‚ÄÉtÃ™À†uÀêsÀ† cah…ô coÀê. .",
            "url": "https://jimregan.github.io/notes/irish/quiggin/icu/ipa/phonetic/2021/05/21/quiggin-to-ipa.html",
            "relUrl": "/irish/quiggin/icu/ipa/phonetic/2021/05/21/quiggin-to-ipa.html",
            "date": " ‚Ä¢ May 21, 2021"
        }
        
    
  
    
        ,"post89": {
            "title": "Running rbg2p on Colab",
            "content": "!pip install -q condacolab import condacolab condacolab.install() . ‚è¨ Downloading https://github.com/jaimergp/miniforge/releases/latest/download/Mambaforge-colab-Linux-x86_64.sh... üì¶ Installing... üìå Adjusting configuration... ü©π Patching environment... ‚è≤ Done in 0:00:30 üîÅ Restarting kernel... . %%capture !conda install -c conda-forge go go-cgo -y . %%capture !pip install --upgrade setuptools wheel . !go get github.com/sergi/go-diff !go get github.com/stts-se/rbg2p . go: downloading github.com/sergi/go-diff v1.2.0 . !git clone https://github.com/stts-se/rbg2p . Cloning into &#39;rbg2p&#39;... remote: Enumerating objects: 3918, done. remote: Counting objects: 100% (123/123), done. remote: Compressing objects: 100% (85/85), done. remote: Total 3918 (delta 59), reused 77 (delta 29), pack-reused 3795 Receiving objects: 100% (3918/3918), 678.17 KiB | 2.32 MiB/s, done. Resolving deltas: 100% (1233/1233), done. . import os os.environ[&quot;PATH&quot;]=f&#39;{os.environ[&quot;PATH&quot;]}:/root/go/bin&#39; . %cd rbg2p . /content/rbg2p . %%writefile maori.g2p CHARACTER_SET &quot;aeghikmnoprtuwƒÅƒìƒ´≈ç≈´&quot; DEFAULT_PHONEME &quot;_&quot; PHONEME_DELIMITER &quot; &quot; wh -&gt; f h -&gt; h k -&gt; k m -&gt; m ng -&gt; ≈ã n -&gt; n p -&gt; p r -&gt; …æ t -&gt; t w -&gt; w au -&gt; au ƒÅ -&gt; aÀê a -&gt; a ƒì -&gt; …õÀê e -&gt; …õ ƒ´ -&gt; iÀê i -&gt; i ≈ç -&gt; …îÀê o -&gt; …î ≈´ -&gt;  âÀê u -&gt;  â g -&gt; ‚àÖ . Writing maori.g2p . !echo kaumƒÅtua | go run cmd/g2p/g2p.go ../maori.g2p . 0 ERROR(S) FOR ../maori.g2p 0 WARNING(S) FOR ../maori.g2p ALL 0 TESTS PASSED FOR ../maori.g2p Reading input from stdin... kaumƒÅtua k au m aÀê t  â a TOTAL INPUT : 1 ERRORS : 0 TRANSCRIBED : 1 .",
            "url": "https://jimregan.github.io/notes/rbg2p/colab/2021/05/20/running-rbg2p.html",
            "relUrl": "/rbg2p/colab/2021/05/20/running-rbg2p.html",
            "date": " ‚Ä¢ May 20, 2021"
        }
        
    
  
    
        ,"post90": {
            "title": "Kilkenny vs. Waterford",
            "content": "Comparing Kilkenny Irish with Waterford Irish. . The Kilkenny Irish comes from these tweets: (Google Books says √âigse, vol. 26, p. 35 1) . C√∫pla sampla sp√©isi√∫il breise: pic.twitter.com/tYckKMrPM7 . &mdash; Cormac de Briot√∫n (@erisceres) May 17, 2021 I‚Äôve marked the clear differences in bold face; differences in transcription (s‚Ä≤/ É, …ëÀê/aÀê) are not marked, nor are expected differences (‚ü®ao‚ü© ‚Üí [ai] in Waterford Irish; /r‚Ä≤/ ‚Üí [ í] in Kilkenny Irish). . The Waterford side of the comparison is from Breatnach 2; references as in the index. I chose the first (that matched), except with some common words, where I used the first place I came across them. . ansoin and ansan are clearly different, but Breatnach (t. 20) gives √≥ shoin (/oÀê xin‚Ä≤/). . raibh /re/ is a bit of a stretch; Breatnach says this is only before pronouns, and considers it a back-formation from the unstressed form /r…ô/ (/rev‚Ä≤/ stressed). . /duÀêr‚Ä≤t‚Ä≤/ for d√∫irt in Waterford is a little unexpected: the usual rule is r‚Ä≤ ‚Üí [r] / _ [+dental]. . K. Word K. Phonetic W. Phonetic TIoRCW ref. W. Word . a | …ô | …ô | t. 349 | ¬† | . acu | …ôku | …ôÀàku | 163 | aca | . ag | eg‚Ä≤ | eg‚Ä≤ | p. 146 n. 4 | ¬† | . ag | …ô | …ô | 317 | ¬† | . ag | g‚Ä≤ | g‚Ä≤ | 42 | ¬† | . agus | …ëg…ôs | ag…ô(s) | 303 | ¬† | . √°it | …ëÀêt‚Ä≤ | aÀêt‚Ä≤ | 53 | ¬† | . an | …ôn | …ôn | 250 | ¬† | . an | …ô | …ô | t. 339 | ¬† | . an | (…ô)n | n | 496 | ¬† | . ag an | g‚Ä≤en | g‚Ä≤en | t. 78 | aige ‚Äôn | . anall | …ôn…ôul | (…ô)Àànaul | 111 | ¬† | . anchuid | an…ôÀàxid‚Ä≤ | an…ô + xid‚Ä≤ | 171 + t. 253 | ana- + chuid | . ann | uÀên | aun | 110 | ¬† | . anonn | …ônuÀên | (…ô)Àànaun | 111 | ¬† | . ansoin | …ônsin‚Ä≤ | …ônson | 320 | annsan | . ar | e í | er‚Ä≤ | 42 | ¬† | . bean | b‚Ä≤an | b‚Ä≤an | 44 | ¬† | . bhean | v‚Ä≤an | v‚Ä≤an | 483 | ¬† | . bhfuil | bil‚Ä≤ | bil‚Ä≤ | 399 | ¬† | . bh√≠ | v‚Ä≤iÀê | v‚Ä≤iÀê | 21 | ¬† | . broim | br…ôim‚Ä≤ | br…ôim‚Ä≤ | 545 | ¬† | . cad√© | d‚Ä≤eÀê | d‚Ä≤eÀê | 302 | d√© | . chuir | xi í | xir‚Ä≤ | 28 | ¬† | . chun | xuÀên | xuÀên | 308 | ch√∫n | . c√© | k‚Ä≤eÀê | k‚Ä≤eÀê | t. 56 | cia | . conas | kun…ôs | kun…ôs | 66 | cionnus | . cuir | kir | kir‚Ä≤ | 260 | ¬† | . d√©in | t‚Ä≤eÀên‚Ä≤ | d‚Ä≤eÀên‚Ä≤ | 34 | ¬† | . deir | d‚Ä≤er | d‚Ä≤er‚Ä≤ | 303 | ¬† | . duine | din‚Ä≤…ô | din‚Ä≤…ô | 77 | ¬† | . d√∫irt | duÀêrt‚Ä≤ | duÀêr‚Ä≤t‚Ä≤ | 72 | adubhairt | . √©inne | eÀê≈ã‚Ä≤…ô | ai≈ã‚Ä≤…ô | 106 | aonduine | . fad√≥ | f…ôdoÀê | f…ôÀàdoÀê | 62 | fad‚Äô √≥ | . fear | f‚Ä≤ar | f‚Ä≤ar | 44 | ¬† | . feicim | hek‚Ä≤…ôm‚Ä≤ | f‚Ä≤ek‚Ä≤…ôm‚Ä≤ | 553 | faicim | . fhios | (…ô)s | …ô ≈ãan…ôs | 231 | i ngan-fhios | . lig | l‚Ä≤ig‚Ä≤ | l‚Ä≤ig‚Ä≤ | 426 | l√©ig | . l√°mh | l…ëÀê | laÀê l‚Ä≤…ô, laÀêv‚Ä≤ | p. 134 n. 2 | l√°imh l√©, l√°imh | . leis | l‚Ä≤es‚Ä≤ | l‚Ä≤e É | 39 | ¬† | . mn√° | mn…ëÀê | m…ôÀànaÀê | 227 | ¬† | . n√≠ | n‚Ä≤iÀê | n‚Ä≤iÀê | p. 67 n. 2 | ¬† | . orthu | orh…ô | orh…ô | 57 | ortha | . raibh | re | re | p. 119 n. 6 | ¬† | . r√©idh | reÀê | reÀêg‚Ä≤ | 36 | ¬† | . siar | s‚Ä≤i…ôr |  Éi…ôr | 180 | ¬† | . su√≠ | siÀê | siÀê | 24 | suidhe | . s√© | s‚Ä≤e |  Ée | t. 305 | ¬† | . scian | s‚Ä≤g‚Ä≤i…ôn |  Ég‚Ä≤i…ôn | 87 | ¬† | . t-ainm | tan‚Ä≤…ôm‚Ä≤ | an‚Ä≤…ôm‚Ä≤ | 44 | ainm | . thine | hin‚Ä≤…ô | t‚Ä≤in‚Ä≤…ô | 26 + 210 | teine | . th√° | h…ëÀê | haÀê | t. 323 | at√° | . tr√≠ | t‚Ä≤ íiÀê | t‚Ä≤siÀê | 219 | ¬† | . t√∫ | tu | tuÀê, t…ô | 134, 80 | ¬† | . T√° droch-chaoi ar mo ch√≥ip f√©in den alt iontach so le R.A. Breathnach.Breatnach (R. A.): Iarsma√≠ de Ghaeilig Chontae Chill Choinnigh. In √âigse 26 (1992) pp. 21 42. pic.twitter.com/wkIu4EUBpl . &mdash; Sƒ±onnaƒã (@SeaghanSionnach) May 19, 2021 Breatnach, R. A., (1992). ‚ÄòIarsma√≠ de Ghaeilig Chontae Chill Choinnigh‚Äô. In √âigse, 26, pp. 21‚Äî42.¬†&#8617; . | Breatnach, R. B., (1947). The Irish of Ring, Co. Waterford: A Phonetic Study. Dublin Institute for Advanced Studies.¬†&#8617; . |",
            "url": "https://jimregan.github.io/notes/irish/kilkenny/waterford/2021/05/19/kilkenny-vs-waterford.html",
            "relUrl": "/irish/kilkenny/waterford/2021/05/19/kilkenny-vs-waterford.html",
            "date": " ‚Ä¢ May 19, 2021"
        }
        
    
  
    
        ,"post91": {
            "title": "Converting √ì Raghallaigh (2010)",
            "content": "This notebook contains a re-implementation of the &quot;global&quot; phonetiser from Brian √ì Raghallaigh&#39;s Ph.D. thesis using rbg2p, along with the &quot;local&quot; phonetiser for Kerry. . The global phonetiser here is essentially the same as the earlier one, except the output phonemes are lowercase, and there are no spaces between output phonemes, to work around some slight limitations of rbg2p. . Brian √ì Raghallaigh (2010). Multi-dialect phonetisation for Irish text-to-speech synthesis: a modular approach. (Doctoral thesis, Trinity College, Dublin), Appendix B.1 . %%writefile oraghallaigh.g2p CHARACTER_SET &quot;a√°bcde√©fghi√≠jklmno√≥pqrstu√∫vwxyz&#39;-‚Äô&quot; DEFAULT_PHONEME &quot;_&quot; PHONEME_DELIMITER &quot;&quot; VAR CONS [bcdfghjklmnpqrstvwxyz] VAR CONSS [bcdfghjklmnpqrstvwxyz]* VAR CONSP [bcdfghjklmnpqrstvwxyz]+ VAR NONSYLLABIC [√°bcdfghjklmn√≥pqrst√∫vwxyz] // broad future/conditional endings VAR BFCE (√°|adh|aidh|aid√≠s|aimid|aimis|ainn|as) // slender future/conditional endings VAR SFCE (e√°|eadh|idh|id√≠s|imid|imis|inn) VAR FMP [fmp] VAR LNRP [lnr]+ VAR DNLST [dnlst] VAR RDNLR (rd|rn|rl|rr) VAR VOWEL [a√°e√©i√≠o√≥u√∫] VAR VOWELS [a√°e√©i√≠o√≥u√∫]* VAR VOWELP [a√°e√©i√≠o√≥u√∫]+ // left context short broad vowel VAR LCSBV (ea|io|iu|a|o|u) // left context short slender vowel VAR LCSSV (ai|eai|ei|e|iui|i|oi|ui) // left context broad vowel VAR LCBV (adh|ae|ao|a√°|ea|e√°|eo|√©a|io|iu|i√∫|√≠o|o√≥|u√≠o|ua|u|√∫) // left context slender vowel VAR LCSV (aei|aidh|ai|a√≠|aoi|√°i|eai|e√°i|ei|eoi|e|√©i|√©|iai|iui|i√∫i|i|√≠|oi|√≥i|uai|ui|u√≠|√∫i) VAR LCSVS (aei|aidh|ai|a√≠|aoi|√°i|eai|e√°i|ei|eoi|e|√©i|√©|iai|iui|i√∫i|i|√≠|oi|√≥i|uai|ui|u√≠|√∫i)* // right context slender vowel VAR RCSV (eai|ea|e√°i|e√°|ei|eoi|eo|e|√©a|√©i|√©|iai|ia|io|iui|iu|i√∫i|i√∫|i|√≠o|√≠) // left context long vowel VAR LCLV (aei|ae|aoi|ao|√°i|√°|e√°i|e√°|eoi|e√≥|eo|√©i|√©|i√∫i|i√∫|√≠o|√≠|√≥i|√≥|u√≠o|u√≠|√∫i|√∫) // left context slender long vowel VAR LCSLV (aei|aidh|aoi|√°i|e√°i|eoi|√©i|√©|i√∫i|√≠|√≥i|uai|u√≠|√∫i) √°dh -&gt; aa √°i -&gt; aa √° -&gt; aa abh -&gt; abh adh -&gt; adh / _ # adh -&gt; ai agh -&gt; ai aei -&gt; ee ae -&gt; ee a√≠odh -&gt; √≠odh / _ # a√≠o -&gt; a√≠o a√≠ -&gt; ii aidh -&gt; idh / _ # aidh -&gt; ai aigh -&gt; igh / _ # aigh -&gt; ai aithe -&gt; ithe / _ # ai -&gt; ‚àÖ / # CONSS VOWELS (abh|adh|agh|amh|√≥dh|ogh|omh|umh) _ CONSP ai -&gt; ‚àÖ / # CONSS (obh|odh) _ CONSP ai -&gt; aa / # CONSS _ RDNLR ai -&gt; a / # CONSS _ ai -&gt; @@ / VOWELP CONSP _ ai -&gt; a amh -&gt; amh / _ # amh -&gt; au aoi -&gt; ao ao -&gt; ao a -&gt; ‚àÖ / # CONSS VOWELS (abh|adh|agh|amh|√≥dh|ogh|omh|umh) _ CONSP a -&gt; ‚àÖ / # CONSS (obh|odh) _ CONSP # addition a -&gt; ‚àÖ / # CONSS VOWELS ogh _ # omh -&gt; OO / (gc|ch|c) _ (ai|a) r a -&gt; aa / # CONSS _ RDNLR a -&gt; a / # CONSS _ a -&gt; @@ / VOWELP CONSP _ a -&gt; a √©a -&gt; ee √©i -&gt; ee √© -&gt; ee e√°i -&gt; aa e√° -&gt; aa eabh -&gt; abh eadh -&gt; adh / _ # eadh -&gt; au eagh -&gt; ai eai -&gt; a eamh -&gt; amh / _ # eamh -&gt; au / # CONSS _ # VOWEL, or VOWELS ?? ea -&gt; ‚àÖ / # CONSS VOWEL igh _ CONSP ea -&gt; aa / # CONSS _ RDNLR ea -&gt; a / # CONSS _ ea -&gt; @@ / VOWELP CONSP _ ea -&gt; a eidh -&gt; eidh eigh -&gt; eigh ei -&gt; ee / # CONSS _ RDNLR # ei -&gt; ee / # CONSS _ RDNLR NONSYLLABIC ei -&gt; e / # CONSS _ ei -&gt; e e√≥dh -&gt; oo eoi -&gt; oo e√≥ -&gt; oo eo -&gt; oo e -&gt; e / # CONSS _ e -&gt; @@ / VOWELP CONSP _ e -&gt; e √≠odh -&gt; √≠odh / _ # √≠o -&gt; ii √≠ -&gt; ii iadh -&gt; i@ iath -&gt; i@ iai -&gt; i@ ia -&gt; i@ idh -&gt; idh igh -&gt; igh io -&gt; io ithe -&gt; ithe / _ # i√∫i -&gt; uu i√∫ -&gt; uu iubh -&gt; ubh iumh -&gt; uu iui -&gt; uu iu -&gt; u i -&gt; ‚àÖ / # CONSS VOWEL idh _ CONSP # i -&gt; ‚àÖ / # CONSS VOWEL igh _ CONSP i -&gt; @@ / VOWELP CONSP _ i -&gt; I √≥dh -&gt; √≥dh / _ # √≥i -&gt; oo √≥ -&gt; oo obh -&gt; obh odh -&gt; odh ogh -&gt; ogh o√≠ -&gt; ii oidh -&gt; oidh oigh -&gt; oigh oi -&gt; oo / # CONSS _ RDNLR oi -&gt; @@ / # VOWELP CONSP _ oi -&gt; oi omh -&gt; omh o -&gt; oo / # CONSS _ RDNLR # o -&gt; oo / # CONSS _ RDNLR NONSYLLABIC o -&gt; o / # VOWELP CONSP _ o -&gt; o √∫i -&gt; uu √∫ -&gt; uu uath -&gt; u@ uai -&gt; u@ ua -&gt; u@ ubh -&gt; ubh ue -&gt; e ui -&gt; uu / # CONSS _ RDNLR # ui -&gt; uu / # CONSS _ RDNLR NONSYLLABIC ui -&gt; i / # CONSS _ ui -&gt; @@ / VOWELP CONSP _ ui -&gt; ui u√≠o -&gt; ii u√≠ -&gt; ii umh -&gt; uu u -&gt; uu / # CONSS _ RDNLR u -&gt; u / # CONSS _ u -&gt; @@ / VOWELP CONSP _ u -&gt; u bf -&gt; p / _ BFCE # bf -&gt; pj / _ SFCE # bhf -&gt; vj / # _ CONSS RCSV # bhf -&gt; vj / # _ CONSS RCSV NONSYLLABIC bhf -&gt; v / # _ bhf -&gt; f / _ BFCE # bhf -&gt; fj / _ SFCE # bh -&gt; @@ v / # LCSBV LNRP _ bh -&gt; @@ v / NONSYLLABIC LCSBV LNRP _ bh -&gt; @@ vj / # LCSSV LNRP _ bh -&gt; @@ vj / NONSYLLABIC LCSSV LNRP _ bh -&gt; vj / # _ CONSS RCSV # bh -&gt; vj / # _ CONSS RCSV NONSYLLABIC bh -&gt; v / # _ bh -&gt; vj / _ CONSS RCSV # bh -&gt; vj / _ CONSS RCSV NONSYLLABIC bh -&gt; vj / # LCSV CONSP _ bh -&gt; vj / NONSYLLABIC LCSV CONSP _ bh -&gt; vj / # LCSV _ bh -&gt; vj / NONSYLLABIC LCSV _ bh -&gt; v bp -&gt; bj / # _ CONSS RCSV # bp -&gt; bj / # _ CONSS RCSV NONSYLLABIC bp -&gt; b / # _ bth -&gt; p / LCBV CONSS _ bth -&gt; pj / LCSV CONSS _ b -&gt; @@ b / # LCSBV LNRP _ b -&gt; @@ b / NONSYLLABIC LCSBV LNRP _ b -&gt; @@ bj / # LCSSV LNRP _ b -&gt; @@ bj / NONSYLLABIC LCSSV LNRP _ b -&gt; bj / _ CONSS RCSV # b -&gt; bj / _ CONSS RCSV NONSYLLABIC b -&gt; bj / # LCSV CONSP _ b -&gt; bj / NONSYLLABIC LCSV CONSP _ b -&gt; bj / # LCSV _ b -&gt; bj / NONSYLLABIC LCSV _ b -&gt; b cf -&gt; k / _ BFCE # cf -&gt; kj / _ SFCE # chf -&gt; x / _ BFCE # chf -&gt; xj / _ SFCE # ch -&gt; @@ x / # LCSBV LNRP _ ch -&gt; @@ x / NONSYLLABIC LCSBV LNRP _ ch -&gt; @@ xj / # LCSSV LNRP _ ch -&gt; @@ xj / NONSYLLABIC LCSSV LNRP _ ch -&gt; xj / # _ CONSS RCSV # ch -&gt; xj / # _ CONSS RCSV NONSYLLABIC ch -&gt; x / # _ ch -&gt; xj / _ CONSS RCSV # ch -&gt; xj / _ CONSS RCSV NONSYLLABIC ch -&gt; xj / # LCSV CONSP _ ch -&gt; xj / NONSYLLABIC LCSV CONSP _ ch -&gt; xj / # LCSV _ ch -&gt; xj / NONSYLLABIC LCSV _ ch -&gt; x cth -&gt; k / LCBV CONSS _ cth -&gt; kj / LCSV CONSS _ c -&gt; kj / _ CONSS RCSV # c -&gt; kj / _ CONSS RCSV NONSYLLABIC c -&gt; kj / # LCSV CONSP _ c -&gt; kj / NONSYLLABIC LCSV CONSP _ c -&gt; kj / # LCSV _ c -&gt; kj / NONSYLLABIC LCSV _ c -&gt; k df -&gt; t / _ BFCE # df -&gt; tj / _ SFCE # dha -&gt; ‚àÖ / # LCLV _ dha -&gt; ‚àÖ / NONSYLLABIC LCLV _ dh -&gt; gfj / # LCSLV _ dh -&gt; gfj / NONSYLLABIC LCSLV _ dh -&gt; gfj / # CONSS LCSVS _ # dh -&gt; ‚àÖ / # LCLV _ dh -&gt; ‚àÖ / NONSYLLABIC LCLV _ dh -&gt; gfj / # _ CONSS RCSV # dh -&gt; gfj / # _ CONSS RCSV NONSYLLABIC dh -&gt; gf / # _ dh -&gt; gfj / _ CONSS RCSV # dh -&gt; gfj / _ CONSS RCSV NONSYLLABIC dh -&gt; gfj / # LCSV CONSP _ dh -&gt; gfj / NONSYLLABIC LCSV CONSP _ dh -&gt; gfj / # LCSV _ dh -&gt; gfj / NONSYLLABIC LCSV _ dh -&gt; gf dt -&gt; dj / # _ CONSS RCSV # dt -&gt; dj / # _ CONSS RCSV NONSYLLABIC dt -&gt; d / # _ dt -&gt; t / LCBV CONSS _ dt -&gt; tj / LCSV CONSS _ d -&gt; dj / _ CONSS RCSV # d -&gt; dj / _ CONSS RCSV NONSYLLABIC d -&gt; dj / # LCSV CONSP _ d -&gt; dj / NONSYLLABIC LCSV CONSP _ d -&gt; dj / # LCSV _ d -&gt; dj / NONSYLLABIC LCSV _ d -&gt; d fh -&gt; ‚àÖ f -&gt; h / VOWEL _ BFCE # f -&gt; hj / VOWEL _ SFCE # f -&gt; @@ f / # LCSBV LNRP _ f -&gt; @@ f / NONSYLLABIC LCSBV LNRP _ f -&gt; @@ fj / # LCSSV LNRP _ f -&gt; @@ fj / NONSYLLABIC LCSSV LNRP _ f -&gt; fj / _ CONSS RCSV # f -&gt; fj / _ CONSS RCSV NONSYLLABIC f -&gt; fj / # LCSV CONSP _ f -&gt; fj / NONSYLLABIC LCSV CONSP _ f -&gt; fj / # LCSV _ f -&gt; fj / NONSYLLABIC LCSV _ f -&gt; f gc -&gt; gj / # _ CONSS RCSV # gc -&gt; gj / # _ CONSS RCSV NONSYLLABIC gc -&gt; g / # _ gf -&gt; k / _ BFCE # gf -&gt; kj / _ SFCE # gh -&gt; gfj / # _ CONSS RCSV # gh -&gt; gfj / # _ CONSS RCSV NONSYLLABIC gh -&gt; gf / # _ gh -&gt; gfj / # LCSLV _ gh -&gt; gfj / NONSYLLABIC LCSLV _ gh -&gt; gfj / # CONSS LCSVS _ # gh -&gt; ‚àÖ / # LCLV _ gh -&gt; ‚àÖ / NONSYLLABIC LCLV _ gh -&gt; gfj / _ CONSS RCSV # gh -&gt; gfj / _ CONSS RCSV NONSYLLABIC gh -&gt; gfj / # LCSV CONSP _ gh -&gt; gfj / NONSYLLABIC LCSV CONSP _ gh -&gt; gfj / # LCSV _ gh -&gt; gfj / NONSYLLABIC LCSV _ gh -&gt; gf gth -&gt; k / LCBV CONSS _ gth -&gt; kj / LCSV CONSS _ g -&gt; @@ g / # LCSBV LNRP _ g -&gt; @@ g / NONSYLLABIC LCSBV LNRP _ g -&gt; @@ gj / # LCSSV LNRP _ g -&gt; @@ gj / NONSYLLABIC LCSSV LNRP _ g -&gt; gj / _ CONSS RCSV # g -&gt; gj / _ CONSS RCSV NONSYLLABIC g -&gt; gj / # LCSV CONSP _ g -&gt; gj / NONSYLLABIC LCSV CONSP _ g -&gt; gj / # LCSV _ g -&gt; gj / NONSYLLABIC LCSV _ g -&gt; g h -&gt; hj / _ CONSS RCSV # h -&gt; hj / _ CONSS RCSV NONSYLLABIC h -&gt; hj / # LCSV CONSP _ h -&gt; hj / NONSYLLABIC LCSV CONSP _ h -&gt; hj / # LCSV _ h -&gt; hj / NONSYLLABIC LCSV _ h -&gt; h j -&gt; djzj k -&gt; kj / _ CONSS RCSV # k -&gt; kj / _ CONSS RCSV NONSYLLABIC k -&gt; kj / # LCSV CONSP _ k -&gt; kj / NONSYLLABIC LCSV CONSP _ k -&gt; kj / # LCSV _ k -&gt; kj / NONSYLLABIC LCSV _ k -&gt; k llf -&gt; ll_d / _ BFCE # llf -&gt; llj_d / _ SFCE # llth -&gt; ll_d / LCBV CONSS _ llth -&gt; llj_d / LCSV CONSS _ ll -&gt; llj / _ CONSS RCSV # ll -&gt; llj / _ CONSS RCSV NONSYLLABIC ll -&gt; llj / # LCSV CONSP _ ll -&gt; llj / NONSYLLABIC LCSV CONSP _ ll -&gt; llj / # LCSV _ ll -&gt; llj / NONSYLLABIC LCSV _ ll -&gt; ll lf -&gt; ll_d / _ BFCE # lf -&gt; lj_d / _ SFCE # lth -&gt; ll_d / LCBV CONSS _ lth -&gt; lj_d / LCSV CONSS _ l -&gt; lj / _ CONSS RCSV # l -&gt; lj / _ CONSS RCSV NONSYLLABIC l -&gt; lj / # LCSV CONSP _ l -&gt; lj / NONSYLLABIC LCSV CONSP _ l -&gt; lj / # LCSV _ l -&gt; lj / NONSYLLABIC LCSV _ l -&gt; ll mb -&gt; mj / # _ CONSS RCSV # mb -&gt; mj / # _ CONSS RCSV NONSYLLABIC mb -&gt; m / # _ mf -&gt; m_d / _ BFCE # mf -&gt; mj_d / _ SFCE # mhf -&gt; f / _ BFCE # mhf -&gt; fj / _ SFCE # mh -&gt; vj / # _ CONSS RCSV # mh -&gt; vj / # _ CONSS RCSV NONSYLLABIC mh -&gt; v / # _ mh -&gt; @@ v / # LCSBV LNRP _ mh -&gt; @@ v / NONSYLLABIC LCSBV LNRP _ mh -&gt; @@ vj / # LCSSV LNRP _ mh -&gt; @@ vj / NONSYLLABIC LCSSV LNRP _ mh -&gt; vj / _ CONSS RCSV # mh -&gt; vj / _ CONSS RCSV NONSYLLABIC mh -&gt; vj / # LCSV CONSP _ mh -&gt; vj / NONSYLLABIC LCSV CONSP _ mh -&gt; vj / # LCSV _ mh -&gt; vj / NONSYLLABIC LCSV _ mh -&gt; v mth -&gt; m_d / LCBV CONSS _ mth -&gt; mj_d / LCSV CONSS _ m -&gt; @@ m / # LCSBV LNRP _ m -&gt; @@ m / NONSYLLABIC LCSBV LNRP _ m -&gt; @@ mj / # LCSSV LNRP _ m -&gt; @@ mj / NONSYLLABIC LCSSV LNRP _ m -&gt; mj / _ CONSS RCSV # m -&gt; mj / _ CONSS RCSV NONSYLLABIC m -&gt; mj / # LCSV CONSP _ m -&gt; mj / NONSYLLABIC LCSV CONSP _ m -&gt; mj / # LCSV _ m -&gt; mj / NONSYLLABIC LCSV _ m -&gt; m nnf -&gt; nn_d / _ BFCE # nnf -&gt; nnj_d / _ SFCE # nnth -&gt; nn_d / LCBV CONSS _ nnth -&gt; nnj_d / LCSV CONSS _ nn -&gt; nnj / _ CONSS RCSV # nn -&gt; nnj / _ CONSS RCSV NONSYLLABIC nn -&gt; nnj / # LCSV CONSP _ nn -&gt; nnj / NONSYLLABIC LCSV CONSP _ nn -&gt; nnj / # LCSV _ nn -&gt; nnj / NONSYLLABIC LCSV _ nn -&gt; nn n- -&gt; nj / # _ RCSV # n- -&gt; nj / # _ RCSV NONSYLLABIC n- -&gt; nn / # _ nd -&gt; nnj / # _ CONSS RCSV # nd -&gt; nnj / # _ CONSS RCSV NONSYLLABIC nd -&gt; nn / # _ nf -&gt; nn_d / _ BFCE # nf -&gt; nj_d / _ SFCE # ngf -&gt; ng_d / _ BFCE # ngf -&gt; ngj_d / _ SFCE # ngth -&gt; ng_d / LCBV CONSS _ ngth -&gt; ngj_d / LCSV CONSS _ ng -&gt; ngj / # _ CONSS RCSV # ng -&gt; ngj / # _ CONSS RCSV NONSYLLABIC ng -&gt; ng / # _ ng -&gt; nj / # LCSV _ t # ng -&gt; nj / NONSYLLABIC LCSV _ t # ng -&gt; ngj / _ CONSS RCSV # ng -&gt; ngj / _ CONSS RCSV NONSYLLABIC ng -&gt; ngj / # LCSV CONSP _ ng -&gt; ngj / NONSYLLABIC LCSV CONSP _ ng -&gt; ngj / # LCSV _ ng -&gt; ngj / NONSYLLABIC LCSV _ ng -&gt; ng nth -&gt; nn_d / LCBV CONSS _ nth -&gt; nj_d / LCSV CONSS _ n -&gt; ngj / # LCSV _ c n -&gt; ngj / NONSYLLABIC LCSV _ c n -&gt; ng / _ c n -&gt; nj / _ CONSS RCSV # n -&gt; nj / _ CONSS RCSV NONSYLLABIC n -&gt; nj / # LCSV CONSP _ n -&gt; nj / NONSYLLABIC LCSV CONSP _ n -&gt; nj / # LCSV _ n -&gt; nj / NONSYLLABIC LCSV _ n -&gt; nn pf -&gt; p / _ BFCE # pf -&gt; pj / _ SFCE # ph -&gt; fj / # _ CONSS RCSV # ph -&gt; fj / # _ CONSS RCSV NONSYLLABIC ph -&gt; f / # _ ph -&gt; fj / _ CONSS RCSV # ph -&gt; fj / _ CONSS RCSV NONSYLLABIC ph -&gt; fj / # LCSV CONSP _ ph -&gt; fj / NONSYLLABIC LCSV CONSP _ ph -&gt; fj / # LCSV _ ph -&gt; fj / NONSYLLABIC LCSV _ ph -&gt; f pth -&gt; p / LCBV CONSS _ pth -&gt; pj / LCSV CONSS _ p -&gt; pj / _ CONSS RCSV # p -&gt; pj / _ CONSS RCSV NONSYLLABIC p -&gt; pj / # LCSV CONSP _ p -&gt; pj / NONSYLLABIC LCSV CONSP _ p -&gt; pj / # LCSV _ p -&gt; pj / NONSYLLABIC LCSV _ p -&gt; p # really? there&#39;s a &#39;W&#39; in the phoneset q -&gt; k v rrf -&gt; rr_d / _ BFCE # rrf -&gt; rrj_d / _ SFCE # rrth -&gt; rr_d / LCBV CONSS _ rrth -&gt; rrj_d / LCSV CONSS _ rr -&gt; rrj / _ CONSS RCSV # rr -&gt; rrj / _ CONSS RCSV NONSYLLABIC rr -&gt; rrj / # LCSV CONSP _ rr -&gt; rrj / NONSYLLABIC LCSV CONSP _ rr -&gt; rrj / # LCSV _ rr -&gt; rrj / NONSYLLABIC LCSV _ rr -&gt; rr rf -&gt; r_d / _ BFCE # rf -&gt; rj_d / _ SFCE # rth -&gt; r_d / LCBV CONSS _ rth -&gt; rj_d / LCSV CONSS _ r -&gt; r / # s _ r -&gt; r / # _ r -&gt; r / _ DNLST r -&gt; rj / _ CONSS RCSV # r -&gt; rj / _ CONSS RCSV NONSYLLABIC r -&gt; rj / # LCSV CONSP _ r -&gt; rj / NONSYLLABIC LCSV CONSP _ r -&gt; rj / # LCSV _ r -&gt; rj / NONSYLLABIC LCSV _ r -&gt; r sf -&gt; s / _ BFCE # sf -&gt; sj / _ SFCE # shl -&gt; lj_d / _ CONSS RCSV # shl -&gt; lj_d / _ CONSS RCSV NONSYLLABIC shl -&gt; ll_d shm -&gt; mj_d / _ CONSS RCSV # shm -&gt; mj_d / _ CONSS RCSV NONSYLLABIC shm -&gt; m_d shn -&gt; nj_d / _ CONSS RCSV # shn -&gt; nj_d / _ CONSS RCSV NONSYLLABIC shn -&gt; nn_d shr -&gt; rj_d / _ CONSS RCSV # shr -&gt; rj_d / _ CONSS RCSV NONSYLLABIC shr -&gt; r_d sh -&gt; xj / # _ CONSS RCSV # sh -&gt; xj / # _ CONSS RCSV NONSYLLABIC sh -&gt; h / # _ sh -&gt; xj / _ CONSS RCSV # sh -&gt; xj / _ CONSS RCSV NONSYLLABIC sh -&gt; xj / # LCSV CONSP _ sh -&gt; xj / NONSYLLABIC LCSV CONSP _ sh -&gt; xj / # LCSV _ sh -&gt; xj / NONSYLLABIC LCSV _ sh -&gt; h s -&gt; s / # _ r s -&gt; s / # _ FMP CONSS RCSV # s -&gt; s / # _ FMP CONSS RCSV NONSYLLABIC s -&gt; sj / _ CONSS RCSV # s -&gt; sj / _ CONSS RCSV NONSYLLABIC s -&gt; sj / # LCSV CONSP _ s -&gt; sj / NONSYLLABIC LCSV CONSP _ s -&gt; sj / # LCSV _ s -&gt; sj / NONSYLLABIC LCSV _ s -&gt; s t- -&gt; tj / # _ RCSV # t- -&gt; tj / # _ RCSV NONSYLLABIC t- -&gt; t / # _ tf -&gt; t / _ BFCE # tf -&gt; tj / _ SFCE # // &quot;hack for compound boundaries&quot; th -&gt; ‚àÖ / _ CONS h thb -&gt; pj / _ CONSS RCSV # thb -&gt; pj / _ CONSS RCSV NONSYLLABIC thb -&gt; p thc -&gt; kj / _ CONSS RCSV # thc -&gt; kj / _ CONSS RCSV NONSYLLABIC thc -&gt; k thd -&gt; tj / _ CONSS RCSV # thd -&gt; tj / _ CONSS RCSV NONSYLLABIC thd -&gt; t thf -&gt; h / _ BFCE # thf -&gt; xj / _ SFCE # thl -&gt; lj_d / _ CONSS RCSV # thl -&gt; lj_d / _ CONSS RCSV NONSYLLABIC thl -&gt; ll_d thm -&gt; mj_d / _ CONSS RCSV # thm -&gt; mj_d / _ CONSS RCSV NONSYLLABIC thm -&gt; m_d thn -&gt; nj_d / _ CONSS RCSV # thn -&gt; nj_d / _ CONSS RCSV NONSYLLABIC thn -&gt; nn_d thp -&gt; pj / _ CONSS RCSV # thp -&gt; pj / _ CONSS RCSV NONSYLLABIC thp -&gt; p thr -&gt; rj_d / _ CONSS RCSV # thr -&gt; rj_d / _ CONSS RCSV NONSYLLABIC thr -&gt; r_d ths -&gt; sj / _ CONSS RCSV # ths -&gt; sj / _ CONSS RCSV NONSYLLABIC ths -&gt; s tht -&gt; tj / _ CONSS RCSV # tht -&gt; tj / _ CONSS RCSV NONSYLLABIC tht -&gt; t th -&gt; hj / # _ CONSS RCSV # th -&gt; hj / # _ CONSS RCSV NONSYLLABIC th -&gt; h / # _ th -&gt; hj / _ CONSS RCSV # th -&gt; hj / _ CONSS RCSV NONSYLLABIC th -&gt; hj / # LCSV CONSP _ th -&gt; hj / NONSYLLABIC LCSV CONSP _ th -&gt; hj / # LCSV _ th -&gt; hj / NONSYLLABIC LCSV _ th -&gt; h ts -&gt; tj / # _ CONSS RCSV # ts -&gt; tj / # _ CONSS RCSV NONSYLLABIC ts -&gt; t / # _ t -&gt; tj / _ CONSS RCSV # t -&gt; tj / _ CONSS RCSV NONSYLLABIC t -&gt; tj / # LCSV CONSP _ t -&gt; tj / NONSYLLABIC LCSV CONSP _ t -&gt; tj / # LCSV _ t -&gt; tj / NONSYLLABIC LCSV _ t -&gt; t v -&gt; vj / _ CONSS RCSV # v -&gt; vj / _ CONSS RCSV NONSYLLABIC v -&gt; vj / # LCSV CONSP _ v -&gt; vj / NONSYLLABIC LCSV CONSP _ v -&gt; vj / # LCSV _ v -&gt; vj / NONSYLLABIC LCSV _ v -&gt; v w -&gt; v x- -&gt; e kj s x -&gt; zj y -&gt; gfj z -&gt; zj / _ CONSS RCSV # z -&gt; zj / _ CONSS RCSV NONSYLLABIC z -&gt; zj / # LCSV CONSP _ z -&gt; zj / NONSYLLABIC LCSV CONSP _ z -&gt; zj / # LCSV _ z -&gt; zj / NONSYLLABIC LCSV _ z -&gt; z &#39; -&gt; ‚àÖ ‚Äô -&gt; ‚àÖ - -&gt; ‚àÖ TEST √°dh -&gt; aa TEST √°iseanna -&gt; aa sj @@ nn @@ TEST √°thas -&gt; aa h @@ s TEST abhainn -&gt; abh nnj TEST bualadh -&gt; b u@ ll adh TEST sadhbh -&gt; s ai v TEST saghas -&gt; s ai s TEST gaeilge -&gt; g ee lj gj @@ TEST saola√≠odh -&gt; s ao ll √≠odh TEST garda√≠ -&gt; g aa r d ii TEST d√∫nfaidh -&gt; d uu nn_d idh TEST aidhm -&gt; ai mj TEST cheadaigh -&gt; xj a d igh TEST aighneas -&gt; ai nj @@ s TEST di√∫ltaithe -&gt; dj uu ll t ithe TEST seabhaic -&gt; sj abh kj TEST feadhain -&gt; fj au nj TEST teaghais -&gt; tj ai sj TEST eamhain -&gt; au nj TEST lobhair -&gt; ll obh rj TEST le√≥dhais -&gt; lj oo sj TEST bodhair -&gt; b odh rj TEST eoghain -&gt; oo nj TEST broghais -&gt; b r ogh sj TEST comhair -&gt; k oo rj TEST ciumhais -&gt; kj uu sj TEST airde -&gt; aa r dj @@ TEST cait -&gt; k a tj TEST sodair -&gt; s o d @@ rj TEST ait -&gt; a tj TEST d√©anamh -&gt; dj ee nn amh TEST amharc -&gt; au r k TEST gaoil -&gt; g ao lj TEST gaol -&gt; g ao ll TEST seabhac -&gt; sj abh k TEST ceadharlach -&gt; kj au r ll @@ x TEST teaghas√°n -&gt; tj ai s aa nn TEST lobhar -&gt; ll obh r TEST le√≥dhas -&gt; lj oo s TEST bodhar -&gt; b odh r TEST eoghan -&gt; oo nn TEST bogha -&gt; b ogh TEST comhar -&gt; k oo r TEST dumhach -&gt; d uu x TEST ard -&gt; aa r d TEST cat -&gt; k a t TEST sodar -&gt; s o d @@ r TEST at -&gt; a t TEST √©an -&gt; ee nn TEST √©in√≠n√≠ -&gt; ee nj ii nj ii TEST √© -&gt; ee TEST she√°in -&gt; xj aa nj TEST se√°n -&gt; sj aa nn TEST seabhac -&gt; sj abh k TEST seinneadh -&gt; sj e nnj adh TEST ceadharlach -&gt; kj au r ll @@ x TEST teaghlach -&gt; tj ai ll @@ x TEST beairic -&gt; bj a rj @@ kj TEST √°ireamh -&gt; aa rj amh TEST sleamhn√°n -&gt; sj lj au nn aa nn TEST oighear -&gt; oigh r TEST ceard -&gt; kj aa r d TEST cead -&gt; kj a d TEST √°ireamh√°n -&gt; aa rj @@ v aa nn TEST eas -&gt; a s TEST feidhm -&gt; fj eidh mj TEST leigheas -&gt; lj eigh s TEST ceird -&gt; kj ee r dj TEST deis -&gt; dj e sj TEST eitpheil -&gt; e tj fj e lj TEST ceoil -&gt; kj oo lj TEST bainse√≥ -&gt; b a nj sj oo TEST ceol -&gt; kj oo ll TEST uile -&gt; i lj @@ TEST ceanna√≠odh -&gt; kj a nn √≠odh TEST s√≠os -&gt; sj ii s TEST s√≠ -&gt; sj ii TEST siadhail -&gt; sj i@ lj TEST sciath -&gt; sj kj i@ TEST riail -&gt; r i@ lj TEST siad -&gt; sj i@ d TEST seinnfidh -&gt; sj e nnj_d idh TEST cheannaigh -&gt; xj a nn igh TEST fios -&gt; fj io s TEST imithe -&gt; i mj ithe TEST si√∫il -&gt; sj uu lj TEST si√∫l -&gt; sj uu ll TEST tiubh -&gt; tj ubh TEST ciumhais -&gt; kj uu sj TEST giuirl√©id -&gt; gj uu r lj ee dj TEST fiuch -&gt; fj u x TEST leighis -&gt; lj eigh sj TEST foighid -&gt; f oigh dj TEST aithris -&gt; a rj_d @@ sj TEST sin -&gt; sj i nj TEST cheann√≥dh -&gt; xj a nn √≥dh TEST √≥il -&gt; oo lj TEST √≥l -&gt; oo ll TEST lobhadh -&gt; ll obh adh TEST todhcha√≠ -&gt; t odh x ii TEST toghadh -&gt; t ogh adh TEST o√≠che -&gt; ii xj @@ TEST oidhe -&gt; oidh @@ TEST oighear -&gt; oigh r TEST boird -&gt; b oo r dj TEST soir -&gt; s oi rj TEST comhar -&gt; k oo r TEST bord -&gt; b oo r d TEST bos -&gt; b o s TEST s√∫il -&gt; s uu lj TEST s√∫l -&gt; s uu ll TEST uath√∫il -&gt; u@ uu lj TEST uaine -&gt; u@ nj @@ TEST uan -&gt; u@ nn TEST subh -&gt; s ubh TEST bhuel -&gt; v e ll TEST guird -&gt; g uu r dj TEST cuid -&gt; k i dj TEST uile -&gt; i lj @@ TEST bru√≠on -&gt; b r ii nn TEST bru√≠ne -&gt; b r ii nj @@ TEST cumhacht -&gt; k uu x t TEST burd√∫n -&gt; b uu r d uu nn TEST cur -&gt; k u r TEST bus -&gt; b u s TEST scuabfaidh -&gt; s k u@ p idh TEST clibfidh -&gt; kj lj i pj idh TEST scuabfadh -&gt; s k u@ p adh TEST clibfeadh -&gt; kj lj i pj adh TEST bhf√°inne -&gt; v aa nnj @@ TEST bhfianaise -&gt; vj i@ nn @@ sj @@ TEST scr√≠obhfaidh -&gt; sj kj rj ii f idh TEST d√≠bhfidh -&gt; dj ii fj idh TEST scr√≠obhfadh -&gt; sj kj rj ii f adh TEST d√≠bhfeadh -&gt; dj ii fj adh TEST searbh -&gt; sj a r @@ v TEST seirbh√≠s -&gt; sj e rj @@ vj ii sj TEST bhrostaigh -&gt; v r o s t igh TEST bhris -&gt; vj rj i sj TEST coibh√≠n -&gt; k oi vj ii nj TEST bp√°ist√≠ -&gt; b aa sj tj ii TEST bp√©isteanna -&gt; bj ee sj tj @@ nn @@ TEST scuabtha -&gt; s k u@ p @@ TEST clibthe -&gt; kj lj i pj @@ TEST borb -&gt; b o r @@ b TEST seirbiach -&gt; sj e rj @@ bj i@ x TEST br√≥na -&gt; b r oo nn @@ TEST brian -&gt; bj rj i@ nn TEST le√≥dhas -&gt; lj oo s TEST t-uisce -&gt; t ui sj kj @@ TEST t-√©abhl√≥id√≠ -&gt; tj ee v ll oo dj ii TEST atfaidh -&gt; a t idh TEST titfidh -&gt; tj i tj idh TEST athdh√©anamh -&gt; a gfj ee nn amh TEST meathfadh -&gt; mj a h adh TEST rithfeadh -&gt; r i xj adh TEST bl√°thra -&gt; b ll aa r_d @@ TEST tharla -&gt; h aa r ll @@ TEST thit -&gt; hj i tj TEST tseachtain -&gt; tj a x t @@ nj TEST tsagairt -&gt; t a g @@ r tj TEST teann -&gt; tj a nn TEST tit -&gt; tj i tj TEST togra -&gt; t o g r @@ TEST sadhbh -&gt; s ai v TEST bh√©al -&gt; vj ee ll TEST bh√©il -&gt; vj ee lj . %%writefile oraghallaigh-cd.g2p CHARACTER_SET &quot;abcdefghi√≠jklmno√≥prstuvwxz@.012-_&quot; DEFAULT_PHONEME &quot;_&quot; PHONEME_DELIMITER &quot; &quot; VAR BC (p|b|f|v|m_d|m|t_|t|d_|d|ll_d|ll|l_d|l|nn_d|nn|n_d|n|rr_d|r_d|rr|r|s|z|k|g|x|gf|ng_d|ng|h) VAR LLJ (llj|nnj|rrj|mj) VAR LL (ll|nn|rr|m) aa -&gt; aa abh -&gt; au adh -&gt; @ x agh -&gt; ai a√≠o -&gt; i@ amh -&gt; @ v ai -&gt; ai ao -&gt; ee au -&gt; au a -&gt; ai / _ LLJ a -&gt; au / _ LL a -&gt; a ee -&gt; i@ / _ BC ee -&gt; ee eidh -&gt; e gj / _ # eidh -&gt; ai eigh -&gt; ai e -&gt; e idh -&gt; @ gj igh -&gt; @ gj √≠odh -&gt; i@ x ithe -&gt; @ . 0 h @ i@ -&gt; i@ ii -&gt; ii io -&gt; i i -&gt; ii / _ LLJ # i -&gt; i obh -&gt; au √≥dh -&gt; oo x odh -&gt; au ogh -&gt; au oidh -&gt; ai oigh -&gt; ai oi -&gt; ii / _ LLJ # oi -&gt; i omh -&gt; au oo -&gt; oo o -&gt; au / _ LL # o -&gt; o ubh -&gt; u v / _ # ubh -&gt; @ v u@ -&gt; u@ ui -&gt; ii / _ LLJ ui -&gt; i uu -&gt; uu u -&gt; u @@ -&gt; @ pj -&gt; pj p -&gt; p bj -&gt; bj b -&gt; b fj -&gt; fj f -&gt; f vj -&gt; vj v -&gt; v w -&gt; w mj_d -&gt; mj_d m_d -&gt; m_d mj -&gt; mj m -&gt; m tjsj -&gt; tjsj djzj -&gt; djzj t_- -&gt; t_- tj -&gt; tj t -&gt; t d_- -&gt; d_- dj -&gt; dj d -&gt; d llj_d -&gt; lj_d ll_d -&gt; l_d llj -&gt; lj ll -&gt; l lj_d -&gt; lj_d l_d -&gt; l_d lj -&gt; lj l -&gt; l nnj_d -&gt; nj_d nn_d -&gt; n_d nnj -&gt; nj nn -&gt; n nj_d -&gt; nj_d n_d -&gt; n_d rrj_d -&gt; rj_d rj_d -&gt; rj_d rr_d -&gt; r_d r_d -&gt; r_d rrj -&gt; rj rj -&gt; rj rr -&gt; r r -&gt; r sj -&gt; sj s -&gt; s zj -&gt; zj z -&gt; z kj -&gt; kj k -&gt; k gj -&gt; gj g -&gt; g xj -&gt; xj x -&gt; x gfj -&gt; ‚àÖ / _ # gfj -&gt; gfj ngj_d -&gt; ngj h ng_d -&gt; ng h ngj -&gt; nj / _ # ngj -&gt; ngj ng -&gt; ng nj -&gt; nj n -&gt; n hj -&gt; h h -&gt; h 0 -&gt; 0 1 -&gt; 1 2 -&gt; 2 . -&gt; . - -&gt; ‚àÖ @ -&gt; ‚àÖ c -&gt; ‚àÖ j -&gt; ‚àÖ √≠ -&gt; ‚àÖ √≥ -&gt; ‚àÖ _ -&gt; ‚àÖ TEST faas -&gt; f aa s TEST abhnnj -&gt; au nj TEST saghd -&gt; s ai d TEST sa√≠oxt -&gt; s i@ x t TEST djeennamh -&gt; dj ee n @ v TEST taig -&gt; t ai g TEST saoll -&gt; s ee l TEST saulj -&gt; s au lj TEST kallj -&gt; k ai lj TEST krann -&gt; k r au n TEST kad -&gt; k a d TEST eenn -&gt; i@ n TEST sjee -&gt; sj ee TEST beidh -&gt; b e gj TEST fjeidhmj -&gt; fj ai mj TEST ljeighs -&gt; lj ai s TEST djesj -&gt; dj e sj TEST bjrjisjidh -&gt; bj rj i sj @ gj TEST xjannigh -&gt; xj a n @ gj TEST kjann√≠odh -&gt; kj a n i@ x TEST kjannithe -&gt; kj a n @ h @ TEST i@rr -&gt; i@ r TEST sjiinj -&gt; sj ii nj TEST fjios -&gt; fj i s TEST imj -&gt; ii mj TEST sjinj -&gt; sj i nj TEST llobhr -&gt; l au r TEST kjann√≥dh -&gt; kj a n oo x TEST bodhr -&gt; b au r TEST toghxaann -&gt; t au x aa n TEST oidhrjaxt -&gt; ai rj a x t TEST oighr -&gt; ai r TEST koillj -&gt; k ii lj TEST koillj@@ -&gt; k i lj @ TEST domhnn -&gt; d au n TEST moor -&gt; m oo r TEST poll -&gt; p au l TEST polladh -&gt; p o l @ x TEST ubh@@gaann -&gt; @ v @ g aa n TEST bu@ -&gt; b u@ TEST suimj -&gt; s ii mj TEST kuidj -&gt; k i dj TEST kuur -&gt; k uu r TEST kur -&gt; k u r TEST farjsj@@ngj -&gt; f a rj sj @ nj .",
            "url": "https://jimregan.github.io/notes/irish/g2p/kerry/2021/05/17/o-raghallaigh-thesis-attempt-2-cd.html",
            "relUrl": "/irish/g2p/kerry/2021/05/17/o-raghallaigh-thesis-attempt-2-cd.html",
            "date": " ‚Ä¢ May 17, 2021"
        }
        
    
  
    
        ,"post92": {
            "title": "Kilkenny Irish example",
            "content": "Sc√©al beag√°n i nGaeilig Osra√≠ (Contae Chill Choinnigh). pic.twitter.com/KhG3fd7fkE . &mdash; Cormac de Briot√∫n (@erisceres) May 17, 2021 The picture is nice; transcriptions are better: . v‚Ä≤iÀê toÀêr…ô uÀên f…ôdoÀê …ëg…ôs v‚Ä≤i an…ôÀàxid‚Ä≤ mn…ëÀê eg‚Ä≤…ôn toÀêr…ô, …ëg…ôs v‚Ä≤iÀê s‚Ä≤i…ôd …ô siÀê e í …ô loxd…ô, …ôn …ëÀêt‚Ä≤ …ô re n toÀêr…ô. wel‚Ä≤, l‚Ä≤ig‚Ä≤ din‚Ä≤…ô br…ôim‚Ä≤ …ëg…ôs n‚Ä≤iÀê res eg‚Ä≤ eÀê≈ã‚Ä≤…ô k‚Ä≤eÀê l‚Ä≤ig‚Ä≤ …ôn br…ôim‚Ä≤ duÀêrt‚Ä≤ f‚Ä≤ar …ô v‚Ä≤iÀê g‚Ä≤en toÀêr…ô ‚Äòwel‚Ä≤‚Äô, …ô d‚Ä≤er s‚Ä≤e, ‚Äò…ôn b‚Ä≤an …ô l‚Ä≤ig‚Ä≤ …ô br…ôim‚Ä≤ h…ëÀê k…ôip‚Ä≤ t‚Ä≤ íiÀê hin‚Ä≤…ô‚Äô …ônsin‚Ä≤ xi í …ôn v‚Ä≤an «ù l…ëÀê s‚Ä≤i…ôr xuÀên …ô k…ôip‚Ä≤, …ëg«ùs v‚Ä≤iÀês …ôku el‚Ä≤…ô (…ô)nsin‚Ä≤ …ôn b‚Ä≤an …ô l‚Ä≤ig‚Ä≤ …ôn br…ôim‚Ä≤. . Bh√≠ t√≥rramh ann fad√≥ agus bh√≠ anchuid mn√° ag an t√≥rramh, agus bh√≠ siad ag su√≠ ar an lochta, an √°it a raibh an t√≥rramh. Well, lig duine broim agus n√≠ raibh a fhios ag √©inne c√© lig an broim. D√∫irt fear a bh√≠ ag an t√≥rramh ‚ÄòWell‚Äô, a deir s√©, ‚Äòan bean (sic) a lig an broim, th√° a caidhp tr√≠ thine.‚Äô Ansoin chuir an bhean a l√°mh siar chun a caidhp, agus bh√≠ a fhios acu uile ansoin an bean a lig an broim. .",
            "url": "https://jimregan.github.io/notes/irish/twitter/kilkenny/2021/05/17/kilkenny-irish.html",
            "relUrl": "/irish/twitter/kilkenny/2021/05/17/kilkenny-irish.html",
            "date": " ‚Ä¢ May 17, 2021"
        }
        
    
  
    
        ,"post93": {
            "title": "√ì Raghallaigh in ICU",
            "content": "$wb=[^[:L:][:M:]]; $alpha = [abcdefghijklmnopqrstuvwxyz]; $cons = [bcdfghjklmnpqrstvwxyz]; $nonsyllabic = [√°bcdfghjklmn√≥pqrst√∫vwxyz#] # broad future/conditional endings $bfce = [√°{adh}{aidh}{aid√≠s}{aimid}{aimis}{ainn}{as}]; # slender future/conditional endings $sfce = [{e√°}{eadh}{idh}{id√≠s}{imid}{imis}{inn}]; $l = [{ll}l]; $mn = [mn]; $fmp = [fmp]; $lnr = [lnr]; $lrst = [lrst]; $dnlst = [dnlst]; $dnst = [dnst]; $rdnlr = [{rd}{rn}{rl}{rr}]; $vowel = [a√°e√©i√≠o√≥u√∫]; # left context short broad vowel $lcsbv = [{ea}{io}{iu}aou]; # left context short slender vowel $lcssv = [{ai}{eai}{ei}e{iui}i{oi}{ui}]; # left context broad vowel $lcbv = [{adh}{ae}{ao}a√°{ea}{e√°}{eo}{√©a}{io}{iu}{i√∫}{√≠o}o√≥{u√≠o}u√∫]; # right context broad vowel $rcbv = [{aei}{ae}{ai}{aoi}{ao}{a}{√°i}√°{oi}o{√≥i}√≥{ui}{u√≠o}{u√≠}u{√∫i}√∫]; # left context slender vowel $lcsv = [{aei}{aidh}{ai}{a√≠}{aoi}{√°i}{eai}{e√°i}{ei}{eoi}e{√©i}√©{iai}{iui}{i√∫i}i√≠{oi}{√≥i}{uai}{ui}{u√≠}{√∫i}]; # right context slender vowel $rcsv = [{aei}{ea}{e√°i}{e√°}{ei}{eoi}e{√©a}{√©i}√©{iai}{ia}{io}{iui}{iu}{i√∫i}{i√∫}i{√≠o}√≠]; # left context long vowel $lclv = [{aei}{ae}{aoi}{ao}{√°i}{√°}{e√°i}{e√°}{eoi}{e√≥}{eo}{√©i}√©{i√∫i}{i√∫}{√≠o}√≠{√≥i}√≥{u√≠o}{u√≠}{√∫i}√∫]; # left context slender long vowel $lcslv = [{aei}{aidh}{aoi}{√°i}{e√°i}{eoi}{√©i}√©{i√∫i}√≠{√≥i}{uai}{u√≠}{√∫i}]; √°dh ‚Üí AA _; √°i ‚Üí AA _; √° ‚Üí AA _; abh ‚Üí ABH _; adh } $wb ‚Üí ADH _; adh ‚Üí AI _; agh ‚Üí AI _; aei ‚Üí EE _; ae ‚Üí EE _; a√≠odh } $wb ‚Üí √çODH; a√≠o ‚Üí A√çO _; a√≠ ‚Üí II _; aidh } $wb ‚Üí IDH; aidh ‚Üí AI _; aigh } $wb ‚Üí IGH; aigh ‚Üí AI _; aithe } $wb ‚Üí ITHE; $wb $cons* $vowel* abh { ai } $cons+ ‚Üí &#39;&#39;; $wb $cons* $vowel* adh { ai } $cons+ ‚Üí &#39;&#39;; $wb $cons* $vowel* agh { ai } $cons+ ‚Üí &#39;&#39;; $wb $cons* $vowel* amh { ai } $cons+ ‚Üí &#39;&#39;; $wb $cons* obh { ai } $cons+ ‚Üí &#39;&#39;; $wb $cons* $vowel* √≥dh { ai } $cons+ ‚Üí &#39;&#39;; $wb $cons* odh { ai } $cons+ ‚Üí &#39;&#39;; $wb $cons* $vowel* ogh { ai } $cons+ ‚Üí &#39;&#39;; $wb $cons* $vowel* omh { ai } $cons+ ‚Üí &#39;&#39;; $wb $cons* $vowel* umh { ai } $cons+ ‚Üí &#39;&#39;; $wb $cons* { ai } $rdnlr ‚Üí AA _; $wb $cons* { ai ‚Üí A _; $vowel+ $cons+ { ai ‚Üí @@; ai ‚Üí A; amh { $wb ‚Üí AMH; amh ‚Üí AU _; aoi ‚Üí AO; ao ‚Üí AO; $wb $cons* $vowel* abh { a } $cons+ ‚Üí &#39;&#39;; $wb $cons* $vowel* adh { a } $cons+ ‚Üí &#39;&#39;; $wb $cons* $vowel* agh { a } $cons+ ‚Üí &#39;&#39;; $wb $cons* $vowel* amh { a } $cons+ ‚Üí &#39;&#39;; $wb $cons* obh { a } $cons+ ‚Üí &#39;&#39;; $wb $cons* $vowel* √≥dh { a } $cons+ ‚Üí &#39;&#39;; $wb $cons* odh { a } $cons+ ‚Üí &#39;&#39;; $wb $cons* $vowel* ogh { a } $cons+ ‚Üí &#39;&#39;; $wb $cons* $vowel* omh { a } $cons+ ‚Üí &#39;&#39;; $wb $cons* $vowel* umh { a } $cons+ ‚Üí &#39;&#39;; $wb $cons* { a } $rdnlr ‚Üí AA _; $wb $cons* { a ‚Üí A _; $vowel+ $cons+ { a ‚Üí @ _; a ‚Üí A _; √©a ‚Üí EE _; √©i ‚Üí EE _; √© ‚Üí EE _; e√°i ‚Üí AA _; e√° ‚Üí AA _; eabh ‚Üí ABH _; eadh } $wb ‚Üí ADH; eadh ‚Üí AU _; eagh ‚Üí AI _; eai ‚Üí A _; eamh } $wb ‚Üí AMH; $wb $cons* eamh ‚Üí AU _; $wb $cons* $vowel igh { ea } $cons+ ‚Üí &#39;&#39;; . abhainn ABH NNJ bualadh B U@ LL ADH sadhbh S AI V saghas S AI S gaeilge G EE LJ GJ @@ saola√≠odh S AO LL √çODH garda√≠ G AA R D II d√∫nfaidh D UU NN_D IDH aidhm AI MJ cheadaigh XJ A D IGH aighneas AI NJ @@ S di√∫ltaithe DJ UU LL T ITHE seabhaic SJ ABH KJ feadhain FJ AU NJ teaghais TJ AI SJ eamhain AU NJ lobhair LL OBH RJ le√≥dhais LJ OO SJ bodhair B ODH RJ eoghain OO NJ broghais B R OGH SJ comhair K OO RJ ciumhais KJ UU SJ airde AA RJ DJ @@ cait K A TJ sodair S O D @@ RJ ait A TJ d√©anamh DJ EE NN AMH amharc AU R K gaoil G AO LJ gaol G AO L seabhac SJ ABH K ceadharlach KJ AU R LL @@ X teaghas√°n TJ AI S AA NN lobhar LL OBH R le√≥dhas LL OO S bodhar B ODH R eoghan OO NN bogha B OGH comhar K OO R dumhach D UU X ard AA R D cat K A T sodar S O D @@ R at A T √©an EE NN √©in√≠n√≠ EE NJ II NJ II √© EE .",
            "url": "https://jimregan.github.io/notes/irish/g2p/incomplete/2021/05/16/oraghallaigh-icu.html",
            "relUrl": "/irish/g2p/incomplete/2021/05/16/oraghallaigh-icu.html",
            "date": " ‚Ä¢ May 16, 2021"
        }
        
    
  
    
        ,"post94": {
            "title": "Converting √ì Raghallaigh (2010)",
            "content": "This notebook contains a re-implementation of the &quot;global&quot; phonetiser from Brian √ì Raghallaigh&#39;s Ph.D. thesis using rbg2p. . Brian √ì Raghallaigh (2010). Multi-dialect phonetisation for Irish text-to-speech synthesis: a modular approach. (Doctoral thesis, Trinity College, Dublin), Appendix B.1 . @phdthesis{oraghallaigh2010multidialect, author = {Brian √ì~Raghallaigh}, title = {Multi-dialect phonetisation for {I}rish text-to-speech synthesis: a modular approach}, school = {Trinity College, Dublin}, year = 2010, address = {Dublin, Ireland}, month = 9, } . The initial run (after small conversion errors were corrected) gave the following set of errors: . FAILED TEST: for &#39;comhair&#39;, expected /K OO RJ/, got /K OMH RJ/ FAILED TEST: for &#39;airde&#39;, expected /AA RJ DJ @@/, got /AA R DJ @@/ FAILED TEST: for &#39;bogha&#39;, expected /B OGH/, got /B OGH @@/ FAILED TEST: for &#39;comhar&#39;, expected /K OO R/, got /K OMH R/ FAILED TEST: for &#39;ceird&#39;, expected /KJ EE RJ DJ/, got /KJ EE R DJ/ FAILED TEST: for &#39;riail&#39;, expected /RJ I@ LJ/, got /R I@ LJ/ FAILED TEST: for &#39;giuirl√©id&#39;, expected /GJ UU RJ LJ EE DJ/, got /GJ UU R LJ EE DJ/ FAILED TEST: for &#39;boird&#39;, expected /B OO RJ DJ/, got /B OO R DJ/ FAILED TEST: for &#39;bantaboic&#39;, expected /B A NN T @@ B @@ KJ/, got /B A NN T @@ B OI KJ/ FAILED TEST: for &#39;comhar&#39;, expected /K OO R/, got /K OMH R/ FAILED TEST: for &#39;bantaboc&#39;, expected /B A NN T @@ B @@ K/, got /B A NN T @@ B O K/ FAILED TEST: for &#39;guird&#39;, expected /G UU RJ DJ/, got /G UU R DJ/ FAILED TEST: for &#39;bhfianaise&#39;, expected /VJ I@ NN @@ SJ @@/, got /V I@ NN @@ SJ @@/ FAILED TEST: for &#39;leathbhosca&#39;, expected /LJ A V @@ S K @@/, got /LJ A V O S K @@/ FAILED TEST: for &#39;rithfeadh&#39;, expected /RJ I XJ ADH/, got /R I XJ ADH/ FAILED TEST: for &#39;tsagairt&#39;, expected /T A G @@ RJ TJ/, got /T A G @@ R TJ/ 16 OF 168 TESTS FAILED FOR briain.g2p exit status 1 . The most consistent source of errors is slender &#39;r&#39; in environments (word initially, before &#39;d&#39;, etc.) where the rule is that they should be left broad; I corrected the tests (which were intended only as tests of the vowels). . Of the remainder, bogha represents a missing rule, while comhar/comhair does not fit with the given rule, so I added a somewhat lexicalised rule to handle it (and its mutated forms) specifically. . This leaves these words: . FAILED TEST: for &#39;bantaboic&#39;, expected /B A NN T @@ B @@ KJ/, got /B A NN T @@ B OI KJ/ FAILED TEST: for &#39;bantaboc&#39;, expected /B A NN T @@ B @@ K/, got /B A NN T @@ B O K/ FAILED TEST: for &#39;leathbhosca&#39;, expected /LJ A V @@ S K @@/, got /LJ A V O S K @@/ . leathbhosca is a compound, and keeping bhosca as V O S K @@ is correct; otherwise, the rule which for other short vowels converts to schwa is specifically converted to O, so I disabled these rules. . %%writefile oraghallaigh.g2p CHARACTER_SET &quot;a√°bcde√©fghi√≠jklmno√≥pqrstu√∫vwxyz&#39;-‚Äô&quot; DEFAULT_PHONEME &quot;_&quot; PHONEME_DELIMITER &quot; &quot; #VAR ALPHA [abcdefghijklmnopqrstuvwxyz] VAR CONS [bcdfghjklmnpqrstvwxyz] VAR CONSS [bcdfghjklmnpqrstvwxyz]* VAR CONSP [bcdfghjklmnpqrstvwxyz]+ # including &#39;#&#39; doesn&#39;t work, so those rules were duplicated #VAR NONSYLLABIC (√°|b|c|d|f|g|h|j|k|l|m|n|√≥|p|q|r|s|t|√∫|v|w|x|y|z|#) VAR NONSYLLABIC [√°bcdfghjklmn√≥pqrst√∫vwxyz] // broad future/conditional endings VAR BFCE (√°|adh|aidh|aid√≠s|aimid|aimis|ainn|as) // slender future/conditional endings VAR SFCE (e√°|eadh|idh|id√≠s|imid|imis|inn) #VAR L (ll|l) #VAR MN [mn] VAR FMP [fmp] #VAR LNR [lnr] VAR LNRP [lnr]+ #VAR LRST [lrst] VAR DNLST [dnlst] #VAR DNST [dnst] VAR RDNLR (rd|rn|rl|rr) VAR VOWEL [a√°e√©i√≠o√≥u√∫] VAR VOWELS [a√°e√©i√≠o√≥u√∫]* VAR VOWELP [a√°e√©i√≠o√≥u√∫]+ // left context short broad vowel VAR LCSBV (ea|io|iu|a|o|u) // left context short slender vowel VAR LCSSV (ai|eai|ei|e|iui|i|oi|ui) // left context broad vowel VAR LCBV (adh|ae|ao|a√°|ea|e√°|eo|√©a|io|iu|i√∫|√≠o|o√≥|u√≠o|ua|u|√∫) // right context broad vowel #VAR RCBV (aei|ae|ai|aoi|ao|a|√°i|√°|oi|o|√≥i|√≥|ui|u√≠o|u√≠|u|√∫i|√∫) // left context slender vowel VAR LCSV (aei|aidh|ai|a√≠|aoi|√°i|eai|e√°i|ei|eoi|e|√©i|√©|iai|iui|i√∫i|i|√≠|oi|√≥i|uai|ui|u√≠|√∫i) VAR LCSVS (aei|aidh|ai|a√≠|aoi|√°i|eai|e√°i|ei|eoi|e|√©i|√©|iai|iui|i√∫i|i|√≠|oi|√≥i|uai|ui|u√≠|√∫i)* // right context slender vowel VAR RCSV (eai|ea|e√°i|e√°|ei|eoi|eo|e|√©a|√©i|√©|iai|ia|io|iui|iu|i√∫i|i√∫|i|√≠o|√≠) // left context long vowel VAR LCLV (aei|ae|aoi|ao|√°i|√°|e√°i|e√°|eoi|e√≥|eo|√©i|√©|i√∫i|i√∫|√≠o|√≠|√≥i|√≥|u√≠o|u√≠|√∫i|√∫) // left context slender long vowel VAR LCSLV (aei|aidh|aoi|√°i|e√°i|eoi|√©i|√©|i√∫i|√≠|√≥i|uai|u√≠|√∫i) √°dh -&gt; AA √°i -&gt; AA √° -&gt; AA abh -&gt; ABH adh -&gt; ADH / _ # adh -&gt; AI agh -&gt; AI aei -&gt; EE ae -&gt; EE a√≠odh -&gt; √çODH / _ # a√≠o -&gt; A√çO a√≠ -&gt; II aidh -&gt; IDH / _ # aidh -&gt; AI aigh -&gt; IGH / _ # aigh -&gt; AI aithe -&gt; ITHE / _ # ai -&gt; ‚àÖ / # CONSS VOWELS abh _ CONSP ai -&gt; ‚àÖ / # CONSS VOWELS adh _ CONSP ai -&gt; ‚àÖ / # CONSS VOWELS agh _ CONSP ai -&gt; ‚àÖ / # CONSS VOWELS amh _ CONSP ai -&gt; ‚àÖ / # CONSS obh _ CONSP ai -&gt; ‚àÖ / # CONSS VOWELS √≥dh _ CONSP ai -&gt; ‚àÖ / # CONSS odh _ CONSP ai -&gt; ‚àÖ / # CONSS VOWELS ogh _ CONSP ai -&gt; ‚àÖ / # CONSS VOWELS omh _ CONSP ai -&gt; ‚àÖ / # CONSS VOWELS umh _ CONSP ai -&gt; AA / # CONSS _ RDNLR ai -&gt; A / # CONSS _ ai -&gt; @@ / VOWELP CONSP _ ai -&gt; A amh -&gt; AMH / _ # amh -&gt; AU aoi -&gt; AO ao -&gt; AO a -&gt; ‚àÖ / # CONSS VOWELS abh _ CONSP a -&gt; ‚àÖ / # CONSS VOWELS adh _ CONSP a -&gt; ‚àÖ / # CONSS VOWELS agh _ CONSP a -&gt; ‚àÖ / # CONSS VOWELS amh _ CONSP a -&gt; ‚àÖ / # CONSS obh _ CONSP a -&gt; ‚àÖ / # CONSS VOWELS √≥dh _ CONSP a -&gt; ‚àÖ / # CONSS odh _ CONSP a -&gt; ‚àÖ / # CONSS VOWELS ogh _ CONSP a -&gt; ‚àÖ / # CONSS VOWELS omh _ CONSP a -&gt; ‚àÖ / # CONSS VOWELS umh _ CONSP # addition a -&gt; ‚àÖ / # CONSS VOWELS ogh _ # omh -&gt; OO / (gc|ch|c) _ (ai|a) r a -&gt; AA / # CONSS _ RDNLR a -&gt; A / # CONSS _ a -&gt; @@ / VOWELP CONSP _ a -&gt; A √©a -&gt; EE √©i -&gt; EE √© -&gt; EE e√°i -&gt; AA e√° -&gt; AA eabh -&gt; ABH eadh -&gt; ADH / _ # eadh -&gt; AU eagh -&gt; AI eai -&gt; A eamh -&gt; AMH / _ # eamh -&gt; AU / # CONSS _ # VOWEL, or VOWELS ?? ea -&gt; ‚àÖ / # CONSS VOWEL igh _ CONSP ea -&gt; AA / # CONSS _ RDNLR ea -&gt; A / # CONSS _ ea -&gt; @@ / VOWELP CONSP _ ea -&gt; A eidh -&gt; EIDH eigh -&gt; EIGH ei -&gt; EE / # CONSS _ RDNLR # ei -&gt; EE / # CONSS _ RDNLR NONSYLLABIC ei -&gt; E / # CONSS _ ei -&gt; E e√≥dh -&gt; OO eoi -&gt; OO e√≥ -&gt; OO eo -&gt; OO e -&gt; E / # CONSS _ e -&gt; @@ / VOWELP CONSP _ e -&gt; E √≠odh -&gt; √çODH / _ # √≠o -&gt; II √≠ -&gt; II iadh -&gt; I@ iath -&gt; I@ iai -&gt; I@ ia -&gt; I@ idh -&gt; IDH igh -&gt; IGH io -&gt; IO ithe -&gt; ITHE / _ # i√∫i -&gt; UU i√∫ -&gt; UU iubh -&gt; UBH iumh -&gt; UU iui -&gt; UU iu -&gt; U i -&gt; ‚àÖ / # CONSS VOWEL idh _ CONSP # i -&gt; ‚àÖ / # CONSS VOWEL igh _ CONSP i -&gt; @@ / VOWELP CONSP _ i -&gt; I √≥dh -&gt; √ìDH / _ # √≥i -&gt; OO √≥ -&gt; OO obh -&gt; OBH odh -&gt; ODH ogh -&gt; OGH o√≠ -&gt; II oidh -&gt; OIDH oigh -&gt; OIGH oi -&gt; OO / # CONSS _ RDNLR oi -&gt; @@ / # VOWELP CONSP _ oi -&gt; OI omh -&gt; OMH o -&gt; OO / # CONSS _ RDNLR # o -&gt; OO / # CONSS _ RDNLR NONSYLLABIC o -&gt; O / # VOWELP CONSP _ o -&gt; O √∫i -&gt; UU √∫ -&gt; UU uath -&gt; U@ uai -&gt; U@ ua -&gt; U@ ubh -&gt; UBH ue -&gt; E ui -&gt; UU / # CONSS _ RDNLR # ui -&gt; UU / # CONSS _ RDNLR NONSYLLABIC ui -&gt; I / # CONSS _ ui -&gt; @@ / VOWELP CONSP _ ui -&gt; UI u√≠o -&gt; II u√≠ -&gt; II umh -&gt; UU u -&gt; UU / # CONSS _ RDNLR u -&gt; U / # CONSS _ u -&gt; @@ / VOWELP CONSP _ u -&gt; U bf -&gt; P / _ BFCE # bf -&gt; PJ / _ SFCE # bhf -&gt; VJ / # _ CONSS RCSV # bhf -&gt; VJ / # _ CONSS RCSV NONSYLLABIC bhf -&gt; V / # _ bhf -&gt; F / _ BFCE # bhf -&gt; FJ / _ SFCE # bh -&gt; @@ V / # LCSBV LNRP _ bh -&gt; @@ V / NONSYLLABIC LCSBV LNRP _ bh -&gt; @@ VJ / # LCSSV LNRP _ bh -&gt; @@ VJ / NONSYLLABIC LCSSV LNRP _ bh -&gt; VJ / # _ CONSS RCSV # bh -&gt; VJ / # _ CONSS RCSV NONSYLLABIC bh -&gt; V / # _ bh -&gt; VJ / _ CONSS RCSV # bh -&gt; VJ / _ CONSS RCSV NONSYLLABIC bh -&gt; VJ / # LCSV CONSP _ bh -&gt; VJ / NONSYLLABIC LCSV CONSP _ bh -&gt; VJ / # LCSV _ bh -&gt; VJ / NONSYLLABIC LCSV _ bh -&gt; V bp -&gt; BJ / # _ CONSS RCSV # bp -&gt; BJ / # _ CONSS RCSV NONSYLLABIC bp -&gt; B / # _ bth -&gt; P / LCBV CONSS _ bth -&gt; PJ / LCSV CONSS _ b -&gt; @@ B / # LCSBV LNRP _ b -&gt; @@ B / NONSYLLABIC LCSBV LNRP _ b -&gt; @@ BJ / # LCSSV LNRP _ b -&gt; @@ BJ / NONSYLLABIC LCSSV LNRP _ b -&gt; BJ / _ CONSS RCSV # b -&gt; BJ / _ CONSS RCSV NONSYLLABIC b -&gt; BJ / # LCSV CONSP _ b -&gt; BJ / NONSYLLABIC LCSV CONSP _ b -&gt; BJ / # LCSV _ b -&gt; BJ / NONSYLLABIC LCSV _ b -&gt; B cf -&gt; K / _ BFCE # cf -&gt; KJ / _ SFCE # chf -&gt; X / _ BFCE # chf -&gt; XJ / _ SFCE # ch -&gt; @@ X / # LCSBV LNRP _ ch -&gt; @@ X / NONSYLLABIC LCSBV LNRP _ ch -&gt; @@ XJ / # LCSSV LNRP _ ch -&gt; @@ XJ / NONSYLLABIC LCSSV LNRP _ ch -&gt; XJ / # _ CONSS RCSV # ch -&gt; XJ / # _ CONSS RCSV NONSYLLABIC ch -&gt; X / # _ ch -&gt; XJ / _ CONSS RCSV # ch -&gt; XJ / _ CONSS RCSV NONSYLLABIC ch -&gt; XJ / # LCSV CONSP _ ch -&gt; XJ / NONSYLLABIC LCSV CONSP _ ch -&gt; XJ / # LCSV _ ch -&gt; XJ / NONSYLLABIC LCSV _ ch -&gt; X cth -&gt; K / LCBV CONSS _ cth -&gt; KJ / LCSV CONSS _ c -&gt; KJ / _ CONSS RCSV # c -&gt; KJ / _ CONSS RCSV NONSYLLABIC c -&gt; KJ / # LCSV CONSP _ c -&gt; KJ / NONSYLLABIC LCSV CONSP _ c -&gt; KJ / # LCSV _ c -&gt; KJ / NONSYLLABIC LCSV _ c -&gt; K df -&gt; T / _ BFCE # df -&gt; TJ / _ SFCE # dha -&gt; ‚àÖ / # LCLV _ dha -&gt; ‚àÖ / NONSYLLABIC LCLV _ dh -&gt; GFJ / # LCSLV _ dh -&gt; GFJ / NONSYLLABIC LCSLV _ dh -&gt; GFJ / # CONSS LCSVS _ # dh -&gt; ‚àÖ / # LCLV _ dh -&gt; ‚àÖ / NONSYLLABIC LCLV _ dh -&gt; GFJ / # _ CONSS RCSV # dh -&gt; GFJ / # _ CONSS RCSV NONSYLLABIC dh -&gt; GF / # _ dh -&gt; GFJ / _ CONSS RCSV # dh -&gt; GFJ / _ CONSS RCSV NONSYLLABIC dh -&gt; GFJ / # LCSV CONSP _ dh -&gt; GFJ / NONSYLLABIC LCSV CONSP _ dh -&gt; GFJ / # LCSV _ dh -&gt; GFJ / NONSYLLABIC LCSV _ dh -&gt; GF dt -&gt; DJ / # _ CONSS RCSV # dt -&gt; DJ / # _ CONSS RCSV NONSYLLABIC dt -&gt; D / # _ dt -&gt; T / LCBV CONSS _ dt -&gt; TJ / LCSV CONSS _ d -&gt; DJ / _ CONSS RCSV # d -&gt; DJ / _ CONSS RCSV NONSYLLABIC d -&gt; DJ / # LCSV CONSP _ d -&gt; DJ / NONSYLLABIC LCSV CONSP _ d -&gt; DJ / # LCSV _ d -&gt; DJ / NONSYLLABIC LCSV _ d -&gt; D fh -&gt; ‚àÖ f -&gt; H / VOWEL _ BFCE # f -&gt; HJ / VOWEL _ SFCE # f -&gt; @@ F / # LCSBV LNRP _ f -&gt; @@ F / NONSYLLABIC LCSBV LNRP _ f -&gt; @@ FJ / # LCSSV LNRP _ f -&gt; @@ FJ / NONSYLLABIC LCSSV LNRP _ f -&gt; FJ / _ CONSS RCSV # f -&gt; FJ / _ CONSS RCSV NONSYLLABIC f -&gt; FJ / # LCSV CONSP _ f -&gt; FJ / NONSYLLABIC LCSV CONSP _ f -&gt; FJ / # LCSV _ f -&gt; FJ / NONSYLLABIC LCSV _ f -&gt; F gc -&gt; GJ / # _ CONSS RCSV # gc -&gt; GJ / # _ CONSS RCSV NONSYLLABIC gc -&gt; G / # _ gf -&gt; K / _ BFCE # gf -&gt; KJ / _ SFCE # gh -&gt; GFJ / # _ CONSS RCSV # gh -&gt; GFJ / # _ CONSS RCSV NONSYLLABIC gh -&gt; GF / # _ gh -&gt; GFJ / # LCSLV _ gh -&gt; GFJ / NONSYLLABIC LCSLV _ gh -&gt; GFJ / # CONSS LCSVS _ # gh -&gt; ‚àÖ / # LCLV _ gh -&gt; ‚àÖ / NONSYLLABIC LCLV _ gh -&gt; GFJ / _ CONSS RCSV # gh -&gt; GFJ / _ CONSS RCSV NONSYLLABIC gh -&gt; GFJ / # LCSV CONSP _ gh -&gt; GFJ / NONSYLLABIC LCSV CONSP _ gh -&gt; GFJ / # LCSV _ gh -&gt; GFJ / NONSYLLABIC LCSV _ gh -&gt; GF gth -&gt; K / LCBV CONSS _ gth -&gt; KJ / LCSV CONSS _ g -&gt; @@ G / # LCSBV LNRP _ g -&gt; @@ G / NONSYLLABIC LCSBV LNRP _ g -&gt; @@ GJ / # LCSSV LNRP _ g -&gt; @@ GJ / NONSYLLABIC LCSSV LNRP _ g -&gt; GJ / _ CONSS RCSV # g -&gt; GJ / _ CONSS RCSV NONSYLLABIC g -&gt; GJ / # LCSV CONSP _ g -&gt; GJ / NONSYLLABIC LCSV CONSP _ g -&gt; GJ / # LCSV _ g -&gt; GJ / NONSYLLABIC LCSV _ g -&gt; G h -&gt; HJ / _ CONSS RCSV # h -&gt; HJ / _ CONSS RCSV NONSYLLABIC h -&gt; HJ / # LCSV CONSP _ h -&gt; HJ / NONSYLLABIC LCSV CONSP _ h -&gt; HJ / # LCSV _ h -&gt; HJ / NONSYLLABIC LCSV _ h -&gt; H j -&gt; DJZJ k -&gt; KJ / _ CONSS RCSV # k -&gt; KJ / _ CONSS RCSV NONSYLLABIC k -&gt; KJ / # LCSV CONSP _ k -&gt; KJ / NONSYLLABIC LCSV CONSP _ k -&gt; KJ / # LCSV _ k -&gt; KJ / NONSYLLABIC LCSV _ k -&gt; K llf -&gt; LL_D / _ BFCE # llf -&gt; LLJ_D / _ SFCE # llth -&gt; LL_D / LCBV CONSS _ llth -&gt; LLJ_D / LCSV CONSS _ ll -&gt; LLJ / _ CONSS RCSV # ll -&gt; LLJ / _ CONSS RCSV NONSYLLABIC ll -&gt; LLJ / # LCSV CONSP _ ll -&gt; LLJ / NONSYLLABIC LCSV CONSP _ ll -&gt; LLJ / # LCSV _ ll -&gt; LLJ / NONSYLLABIC LCSV _ ll -&gt; LL lf -&gt; LL_D / _ BFCE # lf -&gt; LJ_D / _ SFCE # lth -&gt; LL_D / LCBV CONSS _ lth -&gt; LJ_D / LCSV CONSS _ l -&gt; LJ / _ CONSS RCSV # l -&gt; LJ / _ CONSS RCSV NONSYLLABIC l -&gt; LJ / # LCSV CONSP _ l -&gt; LJ / NONSYLLABIC LCSV CONSP _ l -&gt; LJ / # LCSV _ l -&gt; LJ / NONSYLLABIC LCSV _ l -&gt; LL mb -&gt; MJ / # _ CONSS RCSV # mb -&gt; MJ / # _ CONSS RCSV NONSYLLABIC mb -&gt; M / # _ mf -&gt; M_D / _ BFCE # mf -&gt; MJ_D / _ SFCE # mhf -&gt; F / _ BFCE # mhf -&gt; FJ / _ SFCE # mh -&gt; VJ / # _ CONSS RCSV # mh -&gt; VJ / # _ CONSS RCSV NONSYLLABIC mh -&gt; V / # _ mh -&gt; @@ V / # LCSBV LNRP _ mh -&gt; @@ V / NONSYLLABIC LCSBV LNRP _ mh -&gt; @@ VJ / # LCSSV LNRP _ mh -&gt; @@ VJ / NONSYLLABIC LCSSV LNRP _ mh -&gt; VJ / _ CONSS RCSV # mh -&gt; VJ / _ CONSS RCSV NONSYLLABIC mh -&gt; VJ / # LCSV CONSP _ mh -&gt; VJ / NONSYLLABIC LCSV CONSP _ mh -&gt; VJ / # LCSV _ mh -&gt; VJ / NONSYLLABIC LCSV _ mh -&gt; V mth -&gt; M_D / LCBV CONSS _ mth -&gt; MJ_D / LCSV CONSS _ m -&gt; @@ M / # LCSBV LNRP _ m -&gt; @@ M / NONSYLLABIC LCSBV LNRP _ m -&gt; @@ MJ / # LCSSV LNRP _ m -&gt; @@ MJ / NONSYLLABIC LCSSV LNRP _ m -&gt; MJ / _ CONSS RCSV # m -&gt; MJ / _ CONSS RCSV NONSYLLABIC m -&gt; MJ / # LCSV CONSP _ m -&gt; MJ / NONSYLLABIC LCSV CONSP _ m -&gt; MJ / # LCSV _ m -&gt; MJ / NONSYLLABIC LCSV _ m -&gt; M nnf -&gt; NN_D / _ BFCE # nnf -&gt; NNJ_D / _ SFCE # nnth -&gt; NN_D / LCBV CONSS _ nnth -&gt; NNJ_D / LCSV CONSS _ nn -&gt; NNJ / _ CONSS RCSV # nn -&gt; NNJ / _ CONSS RCSV NONSYLLABIC nn -&gt; NNJ / # LCSV CONSP _ nn -&gt; NNJ / NONSYLLABIC LCSV CONSP _ nn -&gt; NNJ / # LCSV _ nn -&gt; NNJ / NONSYLLABIC LCSV _ nn -&gt; NN n- -&gt; NJ / # _ RCSV # n- -&gt; NJ / # _ RCSV NONSYLLABIC n- -&gt; NN / # _ nd -&gt; NNJ / # _ CONSS RCSV # nd -&gt; NNJ / # _ CONSS RCSV NONSYLLABIC nd -&gt; NN / # _ nf -&gt; NN_D / _ BFCE # nf -&gt; NJ_D / _ SFCE # ngf -&gt; NG_D / _ BFCE # ngf -&gt; NGJ_D / _ SFCE # ngth -&gt; NG_D / LCBV CONSS _ ngth -&gt; NGJ_D / LCSV CONSS _ ng -&gt; NGJ / # _ CONSS RCSV # ng -&gt; NGJ / # _ CONSS RCSV NONSYLLABIC ng -&gt; NG / # _ ng -&gt; NJ / # LCSV _ t # ng -&gt; NJ / NONSYLLABIC LCSV _ t # ng -&gt; NGJ / _ CONSS RCSV # ng -&gt; NGJ / _ CONSS RCSV NONSYLLABIC ng -&gt; NGJ / # LCSV CONSP _ ng -&gt; NGJ / NONSYLLABIC LCSV CONSP _ ng -&gt; NGJ / # LCSV _ ng -&gt; NGJ / NONSYLLABIC LCSV _ ng -&gt; NG nth -&gt; NN_D / LCBV CONSS _ nth -&gt; NJ_D / LCSV CONSS _ n -&gt; NGJ / # LCSV _ c n -&gt; NGJ / NONSYLLABIC LCSV _ c n -&gt; NG / _ c n -&gt; NJ / _ CONSS RCSV # n -&gt; NJ / _ CONSS RCSV NONSYLLABIC n -&gt; NJ / # LCSV CONSP _ n -&gt; NJ / NONSYLLABIC LCSV CONSP _ n -&gt; NJ / # LCSV _ n -&gt; NJ / NONSYLLABIC LCSV _ n -&gt; NN pf -&gt; P / _ BFCE # pf -&gt; PJ / _ SFCE # ph -&gt; FJ / # _ CONSS RCSV # ph -&gt; FJ / # _ CONSS RCSV NONSYLLABIC ph -&gt; F / # _ ph -&gt; FJ / _ CONSS RCSV # ph -&gt; FJ / _ CONSS RCSV NONSYLLABIC ph -&gt; FJ / # LCSV CONSP _ ph -&gt; FJ / NONSYLLABIC LCSV CONSP _ ph -&gt; FJ / # LCSV _ ph -&gt; FJ / NONSYLLABIC LCSV _ ph -&gt; F pth -&gt; P / LCBV CONSS _ pth -&gt; PJ / LCSV CONSS _ p -&gt; PJ / _ CONSS RCSV # p -&gt; PJ / _ CONSS RCSV NONSYLLABIC p -&gt; PJ / # LCSV CONSP _ p -&gt; PJ / NONSYLLABIC LCSV CONSP _ p -&gt; PJ / # LCSV _ p -&gt; PJ / NONSYLLABIC LCSV _ p -&gt; P # really? there&#39;s a &#39;W&#39; in the phoneset q -&gt; K V rrf -&gt; RR_D / _ BFCE # rrf -&gt; RRJ_D / _ SFCE # rrth -&gt; RR_D / LCBV CONSS _ rrth -&gt; RRJ_D / LCSV CONSS _ rr -&gt; RRJ / _ CONSS RCSV # rr -&gt; RRJ / _ CONSS RCSV NONSYLLABIC rr -&gt; RRJ / # LCSV CONSP _ rr -&gt; RRJ / NONSYLLABIC LCSV CONSP _ rr -&gt; RRJ / # LCSV _ rr -&gt; RRJ / NONSYLLABIC LCSV _ rr -&gt; RR rf -&gt; R_D / _ BFCE # rf -&gt; RJ_D / _ SFCE # rth -&gt; R_D / LCBV CONSS _ rth -&gt; RJ_D / LCSV CONSS _ r -&gt; R / # s _ r -&gt; R / # _ // This rule blocks tests for airde and ceird r -&gt; R / _ DNLST r -&gt; RJ / _ CONSS RCSV # r -&gt; RJ / _ CONSS RCSV NONSYLLABIC r -&gt; RJ / # LCSV CONSP _ r -&gt; RJ / NONSYLLABIC LCSV CONSP _ r -&gt; RJ / # LCSV _ r -&gt; RJ / NONSYLLABIC LCSV _ r -&gt; R sf -&gt; S / _ BFCE # sf -&gt; SJ / _ SFCE # shl -&gt; LJ_D / _ CONSS RCSV # shl -&gt; LJ_D / _ CONSS RCSV NONSYLLABIC shl -&gt; LL_D shm -&gt; MJ_D / _ CONSS RCSV # shm -&gt; MJ_D / _ CONSS RCSV NONSYLLABIC shm -&gt; M_D shn -&gt; NJ_D / _ CONSS RCSV # shn -&gt; NJ_D / _ CONSS RCSV NONSYLLABIC shn -&gt; NN_D shr -&gt; RJ_D / _ CONSS RCSV # shr -&gt; RJ_D / _ CONSS RCSV NONSYLLABIC shr -&gt; R_D sh -&gt; XJ / # _ CONSS RCSV # sh -&gt; XJ / # _ CONSS RCSV NONSYLLABIC sh -&gt; H / # _ sh -&gt; XJ / _ CONSS RCSV # sh -&gt; XJ / _ CONSS RCSV NONSYLLABIC sh -&gt; XJ / # LCSV CONSP _ sh -&gt; XJ / NONSYLLABIC LCSV CONSP _ sh -&gt; XJ / # LCSV _ sh -&gt; XJ / NONSYLLABIC LCSV _ sh -&gt; H s -&gt; S / # _ r s -&gt; S / # _ FMP CONSS RCSV # s -&gt; S / # _ FMP CONSS RCSV NONSYLLABIC s -&gt; SJ / _ CONSS RCSV # s -&gt; SJ / _ CONSS RCSV NONSYLLABIC s -&gt; SJ / # LCSV CONSP _ s -&gt; SJ / NONSYLLABIC LCSV CONSP _ s -&gt; SJ / # LCSV _ s -&gt; SJ / NONSYLLABIC LCSV _ s -&gt; S t- -&gt; TJ / # _ RCSV # t- -&gt; TJ / # _ RCSV NONSYLLABIC t- -&gt; T / # _ tf -&gt; T / _ BFCE # tf -&gt; TJ / _ SFCE # // &quot;hack for compound boundaries&quot; th -&gt; ‚àÖ / _ CONS h thb -&gt; PJ / _ CONSS RCSV # thb -&gt; PJ / _ CONSS RCSV NONSYLLABIC thb -&gt; P thc -&gt; KJ / _ CONSS RCSV # thc -&gt; KJ / _ CONSS RCSV NONSYLLABIC thc -&gt; K thd -&gt; TJ / _ CONSS RCSV # thd -&gt; TJ / _ CONSS RCSV NONSYLLABIC thd -&gt; T thf -&gt; H / _ BFCE # thf -&gt; XJ / _ SFCE # thl -&gt; LJ_D / _ CONSS RCSV # thl -&gt; LJ_D / _ CONSS RCSV NONSYLLABIC thl -&gt; LL_D thm -&gt; MJ_D / _ CONSS RCSV # thm -&gt; MJ_D / _ CONSS RCSV NONSYLLABIC thm -&gt; M_D thn -&gt; NJ_D / _ CONSS RCSV # thn -&gt; NJ_D / _ CONSS RCSV NONSYLLABIC thn -&gt; NN_D thp -&gt; PJ / _ CONSS RCSV # thp -&gt; PJ / _ CONSS RCSV NONSYLLABIC thp -&gt; P thr -&gt; RJ_D / _ CONSS RCSV # thr -&gt; RJ_D / _ CONSS RCSV NONSYLLABIC thr -&gt; R_D ths -&gt; SJ / _ CONSS RCSV # ths -&gt; SJ / _ CONSS RCSV NONSYLLABIC ths -&gt; S tht -&gt; TJ / _ CONSS RCSV # tht -&gt; TJ / _ CONSS RCSV NONSYLLABIC tht -&gt; T th -&gt; HJ / # _ CONSS RCSV # th -&gt; HJ / # _ CONSS RCSV NONSYLLABIC th -&gt; H / # _ th -&gt; HJ / _ CONSS RCSV # th -&gt; HJ / _ CONSS RCSV NONSYLLABIC th -&gt; HJ / # LCSV CONSP _ th -&gt; HJ / NONSYLLABIC LCSV CONSP _ th -&gt; HJ / # LCSV _ th -&gt; HJ / NONSYLLABIC LCSV _ th -&gt; H ts -&gt; TJ / # _ CONSS RCSV # ts -&gt; TJ / # _ CONSS RCSV NONSYLLABIC ts -&gt; T / # _ t -&gt; TJ / _ CONSS RCSV # t -&gt; TJ / _ CONSS RCSV NONSYLLABIC t -&gt; TJ / # LCSV CONSP _ t -&gt; TJ / NONSYLLABIC LCSV CONSP _ t -&gt; TJ / # LCSV _ t -&gt; TJ / NONSYLLABIC LCSV _ t -&gt; T v -&gt; VJ / _ CONSS RCSV # v -&gt; VJ / _ CONSS RCSV NONSYLLABIC v -&gt; VJ / # LCSV CONSP _ v -&gt; VJ / NONSYLLABIC LCSV CONSP _ v -&gt; VJ / # LCSV _ v -&gt; VJ / NONSYLLABIC LCSV _ v -&gt; V w -&gt; V x- -&gt; E KJ S x -&gt; ZJ y -&gt; GFJ z -&gt; ZJ / _ CONSS RCSV # z -&gt; ZJ / _ CONSS RCSV NONSYLLABIC z -&gt; ZJ / # LCSV CONSP _ z -&gt; ZJ / NONSYLLABIC LCSV CONSP _ z -&gt; ZJ / # LCSV _ z -&gt; ZJ / NONSYLLABIC LCSV _ z -&gt; Z &#39; -&gt; ‚àÖ ‚Äô -&gt; ‚àÖ - -&gt; ‚àÖ TEST √°dh -&gt; AA TEST √°iseanna -&gt; AA SJ @@ NN @@ TEST √°thas -&gt; AA H @@ S TEST abhainn -&gt; ABH NNJ TEST bualadh -&gt; B U@ LL ADH TEST sadhbh -&gt; S AI V TEST saghas -&gt; S AI S TEST gaeilge -&gt; G EE LJ GJ @@ TEST saola√≠odh -&gt; S AO LL √çODH TEST garda√≠ -&gt; G AA R D II TEST d√∫nfaidh -&gt; D UU NN_D IDH TEST aidhm -&gt; AI MJ TEST cheadaigh -&gt; XJ A D IGH TEST aighneas -&gt; AI NJ @@ S TEST di√∫ltaithe -&gt; DJ UU LL T ITHE TEST seabhaic -&gt; SJ ABH KJ TEST feadhain -&gt; FJ AU NJ TEST teaghais -&gt; TJ AI SJ TEST eamhain -&gt; AU NJ TEST lobhair -&gt; LL OBH RJ TEST le√≥dhais -&gt; LJ OO SJ TEST bodhair -&gt; B ODH RJ TEST eoghain -&gt; OO NJ TEST broghais -&gt; B R OGH SJ TEST comhair -&gt; K OO RJ TEST ciumhais -&gt; KJ UU SJ # wiktionary has: Àà…ëÀê…æÀ†d ≤…ô ÀàiÀê…æÀ†d ≤…ô Àà…ëÀê…æÀ†d ≤…ô Ààai…æ ≤d ≤…ô Àà√¶Àê…æÀ†d ≤…ô Àà å…æÀ†d ≤…ô, so rule seems right #TEST airde -&gt; AA RJ DJ @@ TEST airde -&gt; AA R DJ @@ TEST cait -&gt; K A TJ TEST sodair -&gt; S O D @@ RJ TEST ait -&gt; A TJ TEST d√©anamh -&gt; DJ EE NN AMH TEST amharc -&gt; AU R K TEST gaoil -&gt; G AO LJ TEST gaol -&gt; G AO LL TEST seabhac -&gt; SJ ABH K TEST ceadharlach -&gt; KJ AU R LL @@ X TEST teaghas√°n -&gt; TJ AI S AA NN TEST lobhar -&gt; LL OBH R TEST le√≥dhas -&gt; LJ OO S TEST bodhar -&gt; B ODH R TEST eoghan -&gt; OO NN TEST bogha -&gt; B OGH TEST comhar -&gt; K OO R TEST dumhach -&gt; D UU X TEST ard -&gt; AA R D TEST cat -&gt; K A T TEST sodar -&gt; S O D @@ R TEST at -&gt; A T TEST √©an -&gt; EE NN TEST √©in√≠n√≠ -&gt; EE NJ II NJ II TEST √© -&gt; EE TEST she√°in -&gt; XJ AA NJ TEST se√°n -&gt; SJ AA NN TEST seabhac -&gt; SJ ABH K TEST seinneadh -&gt; SJ E NNJ ADH TEST ceadharlach -&gt; KJ AU R LL @@ X TEST teaghlach -&gt; TJ AI LL @@ X TEST beairic -&gt; BJ A RJ @@ KJ TEST √°ireamh -&gt; AA RJ AMH TEST sleamhn√°n -&gt; SJ LJ AU NN AA NN TEST oighear -&gt; OIGH R TEST ceard -&gt; KJ AA R D TEST cead -&gt; KJ A D TEST √°ireamh√°n -&gt; AA RJ @@ V AA NN TEST eas -&gt; A S TEST feidhm -&gt; FJ EIDH MJ TEST leigheas -&gt; LJ EIGH S # wiktionary gives c…ôi…æÀ†d ≤ and c…™…æÀ†d ≤; the rule seems right #TEST ceird -&gt; KJ EE RJ DJ TEST ceird -&gt; KJ EE R DJ TEST deis -&gt; DJ E SJ TEST eitpheil -&gt; E TJ FJ E LJ TEST ceoil -&gt; KJ OO LJ TEST bainse√≥ -&gt; B A NJ SJ OO TEST ceol -&gt; KJ OO LL TEST uile -&gt; I LJ @@ TEST ceanna√≠odh -&gt; KJ A NN √çODH TEST s√≠os -&gt; SJ II S TEST s√≠ -&gt; SJ II TEST siadhail -&gt; SJ I@ LJ TEST sciath -&gt; SJ KJ I@ #TEST riail -&gt; RJ I@ LJ TEST riail -&gt; R I@ LJ TEST siad -&gt; SJ I@ D TEST seinnfidh -&gt; SJ E NNJ_D IDH TEST cheannaigh -&gt; XJ A NN IGH TEST fios -&gt; FJ IO S TEST imithe -&gt; I MJ ITHE TEST si√∫il -&gt; SJ UU LJ TEST si√∫l -&gt; SJ UU LL TEST tiubh -&gt; TJ UBH TEST ciumhais -&gt; KJ UU SJ #TEST giuirl√©id -&gt; GJ UU RJ LJ EE DJ TEST giuirl√©id -&gt; GJ UU R LJ EE DJ TEST fiuch -&gt; FJ U X TEST leighis -&gt; LJ EIGH SJ TEST foighid -&gt; F OIGH DJ TEST aithris -&gt; A RJ_D @@ SJ TEST sin -&gt; SJ I NJ TEST cheann√≥dh -&gt; XJ A NN √ìDH TEST √≥il -&gt; OO LJ TEST √≥l -&gt; OO LL TEST lobhadh -&gt; LL OBH ADH TEST todhcha√≠ -&gt; T ODH X II TEST toghadh -&gt; T OGH ADH TEST o√≠che -&gt; II XJ @@ TEST oidhe -&gt; OIDH @@ TEST oighear -&gt; OIGH R #TEST boird -&gt; B OO RJ DJ TEST boird -&gt; B OO R DJ TEST soir -&gt; S OI RJ TEST comhar -&gt; K OO R TEST bord -&gt; B OO R D TEST bos -&gt; B O S TEST s√∫il -&gt; S UU LJ TEST s√∫l -&gt; S UU LL TEST uath√∫il -&gt; U@ UU LJ TEST uaine -&gt; U@ NJ @@ TEST uan -&gt; U@ NN TEST subh -&gt; S UBH // not LJ ? TEST bhuel -&gt; V E LL #TEST guird -&gt; G UU RJ DJ TEST guird -&gt; G UU R DJ TEST cuid -&gt; K I DJ TEST uile -&gt; I LJ @@ TEST bru√≠on -&gt; B R II NN TEST bru√≠ne -&gt; B R II NJ @@ TEST cumhacht -&gt; K UU X T TEST burd√∫n -&gt; B UU R D UU NN TEST cur -&gt; K U R TEST bus -&gt; B U S TEST scuabfaidh -&gt; S K U@ P IDH TEST clibfidh -&gt; KJ LJ I PJ IDH TEST scuabfadh -&gt; S K U@ P ADH TEST clibfeadh -&gt; KJ LJ I PJ ADH TEST bhf√°inne -&gt; V AA NNJ @@ TEST bhfianaise -&gt; VJ I@ NN @@ SJ @@ TEST scr√≠obhfaidh -&gt; SJ KJ RJ II F IDH TEST d√≠bhfidh -&gt; DJ II FJ IDH TEST scr√≠obhfadh -&gt; SJ KJ RJ II F ADH TEST d√≠bhfeadh -&gt; DJ II FJ ADH TEST searbh -&gt; SJ A R @@ V TEST seirbh√≠s -&gt; SJ E RJ @@ VJ II SJ TEST bhrostaigh -&gt; V R O S T IGH TEST bhris -&gt; VJ RJ I SJ TEST coibh√≠n -&gt; K OI VJ II NJ TEST bp√°ist√≠ -&gt; B AA SJ TJ II TEST bp√©isteanna -&gt; BJ EE SJ TJ @@ NN @@ TEST scuabtha -&gt; S K U@ P @@ TEST clibthe -&gt; KJ LJ I PJ @@ TEST borb -&gt; B O R @@ B TEST seirbiach -&gt; SJ E RJ @@ BJ I@ X TEST br√≥na -&gt; B R OO NN @@ TEST brian -&gt; BJ RJ I@ NN TEST le√≥dhas -&gt; LJ OO S TEST t-uisce -&gt; T UI SJ KJ @@ TEST t-√©abhl√≥id√≠ -&gt; TJ EE V LL OO DJ II TEST atfaidh -&gt; A T IDH TEST titfidh -&gt; TJ I TJ IDH TEST athdh√©anamh -&gt; A GFJ EE NN AMH TEST meathfadh -&gt; MJ A H ADH #TEST rithfeadh -&gt; RJ I XJ ADH TEST rithfeadh -&gt; R I XJ ADH TEST bl√°thra -&gt; B LL AA R_D @@ TEST tharla -&gt; H AA R LL @@ TEST thit -&gt; HJ I TJ TEST tseachtain -&gt; TJ A X T @@ NJ #TEST tsagairt -&gt; T A G @@ RJ TJ # wiktionary (sagairt): ÀàsÀ†a…°…ô…æÀ†t ≤ ÀàsÀ†√¶…°…ô…æÀ†t ≤ TEST tsagairt -&gt; T A G @@ R TJ TEST teann -&gt; TJ A NN TEST tit -&gt; TJ I TJ TEST togra -&gt; T O G R @@ TEST sadhbh -&gt; S AI V # disabled; the rule for &#39;o&#39; in an unaccented syllable # does not produce schwa; also, &#39;leathbhosca&#39; is a compound; # the &#39;o&#39; should not be reduced #TEST leathbhosca -&gt; LJ A V @@ S K @@ #TEST bantaboic -&gt; B A NN T @@ B @@ KJ #TEST bantaboc -&gt; B A NN T @@ B @@ K TEST bh√©al -&gt; VJ EE LL TEST bh√©il -&gt; VJ EE LJ .",
            "url": "https://jimregan.github.io/notes/irish/g2p/2021/05/16/o-raghallaigh-thesis-attempt-1.html",
            "relUrl": "/irish/g2p/2021/05/16/o-raghallaigh-thesis-attempt-1.html",
            "date": " ‚Ä¢ May 16, 2021"
        }
        
    
  
    
        ,"post95": {
            "title": "Extract pre-built Kaldi on Kaggle",
            "content": "Original here . %cd /tmp . /tmp . !git clone https://github.com/jjlin/docker-image-extract/ . !docker-image-extract/docker-image-extract kaldiasr/kaldi:gpu-latest . Getting API token... Getting image manifest for kaldiasr/kaldi:gpu-latest... Fetching and extracting layer 976a760c94fcdd7d105269ae621e8269e7bb25a58c52ae667b4029a6bc7e33cb... Fetching and extracting layer c58992f3c37bb64aeba18910408cda9a7a63e212fe27e95065a8d54130ca5926... Fetching and extracting layer 0ca0e5e7f12e6eb512246aea5579fcb771fe7203bc60944384d5cd7962f87ddb... Fetching and extracting layer f2a274cc00ca5f671b1740c43672dbc96504760cee585e7604029a3fe56854a8... Fetching and extracting layer 708a53113e13a385afdeddfe409f4b7b71e65b1e5cff48ba33906c8803e19808... Fetching and extracting layer 465b2edc87fbc8c5fb06541c382eefd1edbfcac71521273855dbe0841a5aaf4a... Fetching and extracting layer 4189f57a58ef61e7e283534fb6d0dd4b2b818a037d82c0e1a2994cea35b01883... Fetching and extracting layer 35de2d1091bb82248c486931c94f18336d55dfee05d32d549305626c2e54ca82... Fetching and extracting layer 719d77537fdce03bba6ed02fcbc2e4b84d58906af53a95102326d7aa290549bf... Fetching and extracting layer 3745e7bcc1b3b7ef8b9afe38e20019cdd052d2ed5fa6b32f063e693620179f90... Fetching and extracting layer d990bd9da1ddb55d091b2fcc12a80dc7d3b04e1ba14c2e79f6e0ec9f487773fe... Fetching and extracting layer 15f2cb6c17ae91014b292d6db2438f202e2fb2f9527cb6730f5a38f639526641... Fetching and extracting layer d3305c2a9a9794962ae8183ae36e93f656f290fcec1216407bf4f417e09e512b... Image contents extracted into ./output. . %cd output/opt/ . /tmp/output/opt . import os os.environ[&#39;LD_LIBRARY_PATH&#39;] = &#39;/opt/conda/lib:/opt/kaldi/tools/openfst-1.6.7/lib:/opt/kaldi/src/lib&#39; . %pushd kaldi/tools !bash extras/install_phonetisaurus.sh %popd . !tar cvf /kaggle/working/kaldi.tar kaldi/ .",
            "url": "https://jimregan.github.io/notes/kaggle/kaldi/wav2vec-u/2021/05/15/extract-prebuilt-kaldi-from-docker.html",
            "relUrl": "/kaggle/kaldi/wav2vec-u/2021/05/15/extract-prebuilt-kaldi-from-docker.html",
            "date": " ‚Ä¢ May 15, 2021"
        }
        
    
  
    
        ,"post96": {
            "title": "G2P with MFA",
            "content": "%%capture import os os.chdir(&#39;/tmp&#39;) !wget https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/releases/download/v1.0.1/montreal-forced-aligner_linux.tar.gz !tar zxvf montreal-forced-aligner_linux.tar.gz !ln -s /tmp/montreal-forced-aligner/lib/libpython3.6m.so.1.0 /tmp/montreal-forced-aligner/lib/libpython3.6m.so . os.chdir(&#39;/kaggle/working&#39;) os.environ[&#39;LD_LIBRARY_PATH&#39;] = f&#39;{os.environ[&quot;LD_LIBRARY_PATH&quot;]}:/tmp/montreal-forced-aligner/lib/&#39; os.environ[&#39;PATH&#39;] = f&#39;{os.environ[&quot;PATH&quot;]}:/tmp/montreal-forced-aligner/bin/&#39; . %%capture !apt-get -y install libgfortran3 . !mkdir /tmp/example . The example below is from section 488 (p. 239) of Gaeilge Chorca Dhuibhne by Diarmuid √ì S√©. . The provided transcription is: …ôs kiÀên‚Ä≤ l‚Ä≤…ôm n…ô ÀàheÀên‚Ä≤…™ v‚Ä≤eh …ô b…™n‚Ä≤t‚Ä≤ vuÀên er‚Ä≤ . %%writefile /tmp/example/test1.lab is cuimhin liom na haoinne a bheith ag baint mh√≥na air . Writing /tmp/example/test1.lab . Ibid, Section 488, p. 238 . xuÀê…ôrÀàdiÀês Ààgax …ëÀêt‚Ä≤ . %%writefile /tmp/example/test2.lab chuarda√≠os gach √°it . Writing /tmp/example/test2.lab . MFA insists on having .wav files, which it reads, even though it makes no use of them for G2P . %%capture !apt-get -y install sox . !sox -n -r 16000 -b 16 -c 1 -L /tmp/example/test1.wav trim 0.0 6.000 !sox -n -r 16000 -b 16 -c 1 -L /tmp/example/test2.wav trim 0.0 6.000 . !mfa_generate_dictionary ../input/train-irish-mfa-model-fuaimeanna/g2p-munster.zip /tmp/example/ output . Setting up corpus information... . !cat output . cuimhin k …™ vÀ† n ≤ √°it …ëÀê t ≤ a …ô mh√≥na vÀ† oÀê nÃ™À† …ô bheith v ≤ …õ baint bÀ† …™ n ≤ t ≤ air a …æ ≤ is …™  É na nÃ™À† …ô gach …° …ô x chuarda√≠os x u…ô …æÀ† dÃ™À† iÀê  å sÀ† ag a …° liom l ≤  å mÀ† haoinne …™ n ≤ …õ . Word Pronunciation Alt. Transcript Generated Correct? In context? Rule/Reason . is | …ôs | …ôsÀ† (~ …™ É) | …™  É | ‚úîÔ∏è | ‚ùå | Exception: ios but correct before a slender consonant | . cuimhin | kiÀên‚Ä≤ | kiÀên ≤ | k …™ vÀ† n ≤ | ‚ùå | ‚ùå | Missing grapheme: uimhi | . liom | l‚Ä≤…ôm | l ≤…ômÀ† (~ l ≤ åmÀ†) | l ≤  å mÀ† | ‚úîÔ∏è | ‚úîÔ∏è | (See, e.g., section 291: l‚Ä≤um) | . na | n…ô | nÃ™À†…ô | nÃ™À† …ô | ‚úîÔ∏è | ‚úîÔ∏è | | . haoinne | ÀàheÀên‚Ä≤…™ | heÀên ≤…™ | …™ n ≤ …õ | ‚ùå | ‚ùå | | . a | …ô | | …ô | ‚úîÔ∏è | ‚úîÔ∏è | | . bheith | v‚Ä≤eh | v ≤…õ(h) | v ≤ …õ | ‚úîÔ∏è | ‚ùå | Section 9: h ‚Üí ‚àÖ / _ # -V | . ag | …ô | …ô (~ …™…ü) | a …° | ‚ùå | ‚ùå | …™g‚Ä≤, section 60 | . baint | b…™n‚Ä≤t‚Ä≤ | bÀ†…™n ≤t ≤ | bÀ† …™ n ≤ t ≤ | ‚úîÔ∏è | ‚úîÔ∏è | | . mh√≥na | vuÀên | vÀ†uÀênÃ™À†(…ô) | vÀ† oÀê nÃ™À† …ô | ‚úîÔ∏è | ‚ùå | √≥ ‚Üí oÀê ~ uÀê / _ [+nasal], …ô ‚Üí ‚àÖ / _ # | . air | er‚Ä≤ | e…æ ≤ | a …æ ≤ | ‚ùå | ‚ùå | Exception: eir | . chuarda√≠os | xuÀê…ôrÀàdiÀês | xu…ô…æÀ†dÃ™À†iÀêsÀ† | x u…ô …æÀ† dÃ™À† iÀê  å sÀ† | ‚ùå | ‚ùå | Missing grapheme a√≠o | . gach | Ààgax | …°ax (~ …°…ôx) | …° …ô x | ‚úîÔ∏è | ‚úîÔ∏è | See section 810 | . √°it | …ëÀêt‚Ä≤ | …ëÀêt ≤ | …ëÀê t ≤ | ‚úîÔ∏è | ‚úîÔ∏è | | .",
            "url": "https://jimregan.github.io/notes/kaggle/g2p/mfa/2021/05/14/g2p-with-mfa.html",
            "relUrl": "/kaggle/g2p/mfa/2021/05/14/g2p-with-mfa.html",
            "date": " ‚Ä¢ May 14, 2021"
        }
        
    
  
    
        ,"post97": {
            "title": "Training MFA on fuaimeanna.ie",
            "content": "Original . Part, the first . Setting up MFA . %%capture import os os.chdir(&#39;/tmp&#39;) !wget https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/releases/download/v1.0.1/montreal-forced-aligner_linux.tar.gz !tar zxvf montreal-forced-aligner_linux.tar.gz !ln -s /tmp/montreal-forced-aligner/lib/libpython3.6m.so.1.0 /tmp/montreal-forced-aligner/lib/libpython3.6m.so . os.chdir(&#39;/kaggle/working&#39;) os.environ[&#39;LD_LIBRARY_PATH&#39;] = f&#39;{os.environ[&quot;LD_LIBRARY_PATH&quot;]}:/tmp/montreal-forced-aligner/lib/&#39; os.environ[&#39;PATH&#39;] = f&#39;{os.environ[&quot;PATH&quot;]}:/tmp/montreal-forced-aligner/bin/&#39; . %%capture !apt-get -y install libgfortran3 . To create the same data, fork and run this notebook . !mkdir /tmp/m !mkdir /tmp/c !mkdir /tmp/u !cp ../input/scrape-fuaimeanna-private/wav/*s1.wav /tmp/u !cp ../input/scrape-fuaimeanna-private/wav/*s2.wav /tmp/m !cp ../input/scrape-fuaimeanna-private/wav/*s3.wav /tmp/c . %%writefile fuaimeanna-write.pl #!/usr/bin/perl use warnings; use strict; use utf8; binmode(STDIN, &quot;:utf8&quot;); binmode(STDOUT, &quot;:utf8&quot;); binmode(STDERR, &quot;:utf8&quot;); my %cr_files = ( &#39;mo shmidi√∫&#39; =&gt; &#39;mo chuid smidi√∫&#39;, &#39;mo shmior&#39; =&gt; &#39;mo chuid smior&#39;, &#39;mo shm√≥lach&#39; =&gt; &#39;mo sm√≥lach&#39;, &#39;shmachtaigh&#39; =&gt; &#39;smachtaigh&#39;, &#39;shmaoinigh&#39; =&gt; &#39;smaoinigh&#39;, &#39;shmear&#39; =&gt; &#39;smear&#39;, &#39;deamhain&#39; =&gt; &#39;diabhail&#39;, &#39;folach&#39; =&gt; &#39;i bhfolach&#39;, &#39;captaen&#39; =&gt; &#39;caipt√≠n&#39;, &#39;oirthe&#39; =&gt; &#39;feilte&#39;, ); my %empty = ( &#39;/sounds/gob_i3_s3.mp3&#39; =&gt; 1, &#39;/sounds/iioctha_i3_s3.mp3&#39; =&gt; 1, &#39;/sounds/mo_shuiiochaan_i3_s3.mp3&#39; =&gt; 1, &#39;/sounds/riail_i3_s3.mp3&#39; =&gt; 1 ); open(LEXM, &#39;&gt;&gt;&#39;, &#39;/tmp/lexicon-munster.raw&#39;); binmode LEXM, &#39;:utf8&#39;; open(LEXU, &#39;&gt;&gt;&#39;, &#39;/tmp/lexicon-ulster.raw&#39;); binmode LEXU, &#39;:utf8&#39;; open(LEXC, &#39;&gt;&gt;&#39;, &#39;/tmp/lexicon-connaught.raw&#39;); binmode LEXC, &#39;:utf8&#39;; sub write_text { my $file = shift; my $text = shift; open(OUTF, &#39;&gt;&gt;&#39;, $file); binmode OUTF, &#39;:utf8&#39;; print OUTF $text; close OUTF; } sub write_pron { my $file = shift; my $text = shift; my $pron = shift; if ($text eq &#39;ar t√≠&#39;) { $pron =~ s/ . Àà / # /g; } $pron =~ s/ [ÀàÀå] / /g; $pron =~ s/^[ÀàÀå] //g; $pron =~ s/ . / /g; my @words = split/ /, $text; my @prons = split/ # /, $pron; if($#words != $#prons) { print STDERR &quot;ERROR: $file $text $pron n&quot;; } if($#words == 0) { print $file &quot;$text $pron n&quot;; } else { for(my $i = 0; $i &lt;= $#words; $i++) { print $file &quot;$words[$i] $prons[$i] n&quot;; } } } while(&lt;STDIN&gt;) { chomp; my @line = split/ t/; next if($line[0] eq &#39;Orthographic&#39;); my $text = lc($line[0]); next if($line[0] eq &quot;d&#39;fh√°g&quot;); my $uout = $line[1]; $uout =~ s!/sounds/!!; $uout =~ s/ .mp3$/.txt/; my $cout = $line[3]; $cout =~ s!/sounds/!!; $cout =~ s/ .mp3$/.txt/; my $mout = $line[5]; $mout =~ s!/sounds/!!; $mout =~ s/ .mp3$/.txt/; $uout = &#39;/tmp/u/&#39; . $uout; $cout = &#39;/tmp/c/&#39; . $cout; $mout = &#39;/tmp/m/&#39; . $mout; my $pronu = $line[2]; my $pronc = $line[4]; my $pronm = $line[6]; if($text eq &#39;Gaeilge&#39;) { write_text($uout, &quot;gaeilic&quot;); write_text($cout, &quot;gaeilge&quot;); write_text($mout, &quot;gaelainn&quot;); write_pron( *LEXU, &quot;gaeilic&quot;, $pronu); write_pron( *LEXC, &quot;gaeilge&quot;, $pronc); write_pron( *LEXM, &quot;gaelainn&quot;, $pronm); next; } if($line[0] eq &#39;bocht&#39; || $line[0] eq &#39;teacht&#39; || $line[0] eq &#39;teocht&#39;) { $pronu =~ s/x tÃ™À†/…æÀ† tÃ™À†/; } write_text($uout, $text); write_pron( *LEXU, $text, $pronu); write_text($mout, $text); write_pron( *LEXM, $text, $pronm); if(!exists $empty{$line[3]}) { my $cfix = exists $cr_files{$text} ? $cr_files{$text} : $text; write_text($cout, $cfix); write_pron( *LEXC, $cfix, $pronc); } } . Writing fuaimeanna-write.pl . !cat ../input/scrape-fuaimeanna-private/all-fuaimeanna-data.tsv | perl fuaimeanna-write.pl . !cat /tmp/lexicon-connaught.raw | sort | uniq &gt; /tmp/lexicon-connaught.txt !cat /tmp/lexicon-ulster.raw | sort | uniq &gt; /tmp/lexicon-ulster.txt !cat /tmp/lexicon-munster.raw | sort | uniq &gt; /tmp/lexicon-munster.txt !cat /tmp/lexicon-connaught.raw /tmp/lexicon-ulster.raw /tmp/lexicon-munster.raw | sort | uniq &gt; /tmp/lexicon-all.txt . !mkdir /tmp/all !cp /tmp/c/* /tmp/all !cp /tmp/m/* /tmp/all !cp /tmp/u/* /tmp/all !mkdir /tmp/mfa-temp . Run MFA . !mfa_train_and_align -t /tmp/mfa-temp -o ./munster-model /tmp/m /tmp/lexicon-munster.txt /tmp/textgrid-munster !mfa_train_and_align -t /tmp/mfa-temp -o ./ulster-model /tmp/u /tmp/lexicon-ulster.txt /tmp/textgrid-ulster !mfa_train_and_align -t /tmp/mfa-temp -o ./connaught-model /tmp/c /tmp/lexicon-connaught.txt /tmp/textgrid-connaught !mfa_train_and_align -t /tmp/mfa-temp -o ./all-model /tmp/all /tmp/lexicon-all.txt /tmp/textgrid-all . !mfa_train_g2p -t /tmp/mfa-temp /tmp/lexicon-ulster.txt ./g2p-ulster !mfa_train_g2p -t /tmp/mfa-temp /tmp/lexicon-munster.txt ./g2p-munster !mfa_train_g2p -t /tmp/mfa-temp /tmp/lexicon-connaught.txt ./g2p-connaught !mfa_train_g2p -t /tmp/mfa-temp /tmp/lexicon-all.txt ./g2p-all .",
            "url": "https://jimregan.github.io/notes/kaggle/mfa/fuaimeanna/2021/05/13/train-irish-mfa-model-fuaimeanna.html",
            "relUrl": "/kaggle/mfa/fuaimeanna/2021/05/13/train-irish-mfa-model-fuaimeanna.html",
            "date": " ‚Ä¢ May 13, 2021"
        }
        
    
  
    
        ,"post98": {
            "title": "Scrape fuaimeanna.ie",
            "content": "Not-quite original version . %%writefile fuaimeanna.pl #!/usr/bin/perl # License: Apache 2.0 # Scrapes sounds from fuaimeanna.ie # Creates a set of labels in &#39;label/&#39; (which must exist) # along with three files: # run-wget.sh, which downloads the sounds to mp3/ (it creates it) # run-ffmpeg.sh, which converts the sounds in mp3/ to wav files in wav/ # all-fuaimeanna-data.tsv, which contains all of the data use warnings; use strict; use utf8; use URI; use Web::Scraper; use Data::Dumper; binmode(STDOUT, &quot;:utf8&quot;); binmode(STDERR, &quot;:utf8&quot;); open(WGET, &quot;&gt;&quot;, &quot;run-wget.sh&quot;); binmode(WGET, &quot;:utf8&quot;); open(FFMPEG, &quot;&gt;&quot;, &quot;run-ffmpeg.sh&quot;); binmode(FFMPEG, &quot;:utf8&quot;); open(ALL, &quot;&gt;&quot;, &quot;all-fuaimeanna-data.tsv&quot;); binmode(ALL, &quot;:utf8&quot;); my $phones = scraper { process &#39;div[class=&quot;friotal&quot;]&#39;, &#39;sounds[]&#39; =&gt; scraper { process &#39;span[class=&quot;ortho&quot;]&#39;, &#39;orth&#39; =&gt; &#39;TEXT&#39;; process &#39;span[class=&quot;taifead&quot;] span[class=&quot;player&quot;] a audio source&#39;, &#39;sounds[]&#39; =&gt; &#39;@src&#39;; process &#39;span[class=&quot;phonological&quot;]&#39;, &#39;dialects[]&#39; =&gt; scraper { process &#39;a[class=&quot;phoneme&quot;]&#39;, &#39;phonemes[]&#39; =&gt; &#39;TEXT&#39;; }; }; }; if(! -d &quot;label&quot;) { die &quot;Directory &#39;label&#39; does not exist n&quot;; } # write shell headers to output files print WGET &quot;#!/bin/sh n&quot;; print WGET &quot;mkdir mp3 n&quot;; print FFMPEG &quot;#!/bin/sh n&quot;; print FFMPEG &quot;mkdir wav n&quot;; # write .tsv header print ALL &quot;Orthographic t&quot;; print ALL &quot;Audio (Gaoth Dobhair) tIPA (Gaoth Dobhair) t&quot;; print ALL &quot;Audio (Ceathr√∫ Rua) tIPA (Ceathr√∫ Rua) t&quot;; print ALL &quot;Audio (Corca Dhuibhne) tIPA (Corca Dhuibhne) n&quot;; for my $i (1..77) { my $res = $phones-&gt;scrape(URI-&gt;new(&quot;http://www.fuaimeanna.ie/en/Recordings.aspx?Page=$i&quot;)); for my $sound (@{$res-&gt;{&#39;sounds&#39;}}) { my $word = $sound-&gt;{&#39;orth&#39;}; $word =~ s/^&lt;//; $word =~ s/&gt;$//; if($#{$sound-&gt;{&#39;sounds&#39;}} != 2 &amp;&amp; $#{$sound-&gt;{&#39;dialects&#39;}} != 2) { print STDERR &quot;Error reading &lt;$word&gt; on page $i&quot;; } print ALL &quot;$word t&quot;; for my $j (0..2) { my $sound_raw = ${$sound-&gt;{&#39;sounds&#39;}}[$j]; my $phones_raw = join(&#39; &#39;, @{${$sound-&gt;{&#39;dialects&#39;}}[$j]-&gt;{&#39;phonemes&#39;}}); # put everything in a tsv file first, because it doesn&#39;t make sense to hammer their server again print ALL $sound_raw . &quot; t&quot; . $phones_raw; print ALL &quot; t&quot; unless ($j == 2); my $sound_base = $sound_raw; $sound_base =~ s!/sounds/!!; $sound_base =~ s/ .mp3//; my $phones_out = $phones_raw; # discard word boundary $phones_out =~ s/ # / /g; $phones_out =~ s/ .//g; $phones_out =~ s/Àà//g; $phones_out =~ s/ s+/ /g; $phones_out =~ s/^ //; $phones_out =~ s/ $//; # write the script line print WGET &quot;wget http://www.fuaimeanna.ie$sound_raw -O mp3/$sound_base.mp3 n&quot;; print FFMPEG &quot;ffmpeg -i &quot;mp3/$sound_base.mp3 &quot; -acodec pcm_s16le -ac 1 -ar 16000 wav/$sound_base.wav n&quot;; # write the phones to the label file my $label_file = &quot;label/$sound_base.phones&quot;; open(OUT, &quot;&gt;&quot;, $label_file); binmode(OUT, &quot;:utf8&quot;); print OUT &quot;$phones_out&quot;; close(OUT); } # add a newline to the tsv file print ALL &quot; n&quot;; } } . !mkdir label . %%capture !apt-get -y install libweb-scraper-perl liburi-perl . !chmod a+x fuaimeanna.pl . !./fuaimeanna.pl . %%capture !sh run-wget.sh !sh run-ffmpeg.sh .",
            "url": "https://jimregan.github.io/notes/kaggle/fuaimeanna/scraper/2021/05/13/scrape-fuaimeanna-ie.html",
            "relUrl": "/kaggle/fuaimeanna/scraper/2021/05/13/scrape-fuaimeanna-ie.html",
            "date": " ‚Ä¢ May 13, 2021"
        }
        
    
  
    
        ,"post99": {
            "title": "CMU Wilderness no longer works",
            "content": "tl;dr - grabbing the audio doesn&#39;t work . !git clone https://github.com/festvox/datasets-CMU_Wilderness . Cloning into &#39;datasets-CMU_Wilderness&#39;... remote: Enumerating objects: 791, done. remote: Total 791 (delta 0), reused 0 (delta 0), pack-reused 791 Receiving objects: 100% (791/791), 91.48 MiB | 11.83 MiB/s, done. Resolving deltas: 100% (32/32), done. . %cd datasets-CMU_Wilderness . /kaggle/working/datasets-CMU_Wilderness . %%capture !yes|apt install sptk html2text sox libncurses-dev . %%capture !bin/do_found make_dependencies . !bin/do_found fast_make_align indices/ABIWBT.tar.gz . /bin/bash: bin/do_found: No such file or directory .",
            "url": "https://jimregan.github.io/notes/kaggle/cmuwilderness/bibleis/2021/05/09/cmu-wilderness-does-not-work.html",
            "relUrl": "/kaggle/cmuwilderness/bibleis/2021/05/09/cmu-wilderness-does-not-work.html",
            "date": " ‚Ä¢ May 9, 2021"
        }
        
    
  
    
        ,"post100": {
            "title": "Run deepspeech on Wolne Lektury audio (20-000-mil-podmorskiej-zeglugi pt. 1)",
            "content": "Original on Kaggle . !cp ../input/wolne-lektury-deepspeech/*.json . . !pip install deepspeech . deepspeech --model ../input/polish-deepspeech-models/output_graph_pl.pbmm --scorer ../input/polish-deepspeech-models/kenlm_pl.scorer --json --audio ../input/wolne-lektury-deepspeech/20-000-mil-podmorskiej-zeglugi_026_nowa-propozycja-kapitana-nemo.wav &gt; 20-000-mil-podmorskiej-zeglugi_026_nowa-propozycja-kapitana-nemo.json; rm $out $j; done;done . !for i in $(ls ../input/wolne-lektury-deepspeech/*.mp3|grep -v zeglugi_026_nowa-propozycja-kapitana); do base=$(basename &quot;$i&quot; &quot;.mp3&quot;); out=&quot;$base.wav&quot;; ffmpeg -i $i -acodec pcm_s16le -ac 1 -ar 16000 $out; deepspeech --model ../input/polish-deepspeech-models/output_graph_pl.pbmm --scorer ../input/polish-deepspeech-models/kenlm_pl.scorer --json --audio $out &gt; $base.json; rm $out $j; done .",
            "url": "https://jimregan.github.io/notes/asr/polish/kaggle/2021/05/07/deepspeech-wolne-lektury-20-000-mil-podmorskiej-zeglugi-pt-1.html",
            "relUrl": "/asr/polish/kaggle/2021/05/07/deepspeech-wolne-lektury-20-000-mil-podmorskiej-zeglugi-pt-1.html",
            "date": " ‚Ä¢ May 7, 2021"
        }
        
    
  
    
        ,"post101": {
            "title": "Azure ASR's JSONL output to JSON",
            "content": "import glob import json for i in glob.glob(&#39;../input/mo-sgeal-fein-wikisource-azure-asr-output/*.jsonl&#39;): outf = i.replace(&#39;jsonl&#39;, &#39;json&#39;).split(&#39;/&#39;)[-1] with open(i) as f: curfile = [] for line in f.readlines(): cur = {} json_data = json.loads(line) cur[&#39;start&#39;] = json_data[&#39;Offset&#39;] cur[&#39;duration&#39;] = json_data[&#39;Duration&#39;] cur[&#39;text&#39;] = json_data[&#39;NBest&#39;][0][&#39;Lexical&#39;] curfile.append(cur) with open(outf, &#39;w&#39;) as of: json.dump(curfile, of) .",
            "url": "https://jimregan.github.io/notes/azure/irish/asr/2021/05/04/msf-azure-jsonl-to-json.html",
            "relUrl": "/azure/irish/asr/2021/05/04/msf-azure-jsonl-to-json.html",
            "date": " ‚Ä¢ May 4, 2021"
        }
        
    
  
    
        ,"post102": {
            "title": "Azure speech recognition for Irish",
            "content": "%%capture !pip install azure-cognitiveservices-speech . %%capture !pip install youtube-dl . %%capture !youtube-dl https://www.youtube.com/watch?v=cfjdfaqWY3Y . %%capture !ffmpeg -i C√∫la4 Ar Scoil _ √Åbhar - Mata _ T√©ama - Bia-cfjdfaqWY3Y.mkv -acodec pcm_s16le -ac 1 -ar 16000 cfjdfaqWY3Y.wav . import IPython IPython.display.Audio(&#39;/content/cfjdfaqWY3Y.wav&#39;) . import azure.cognitiveservices.speech as speechsdk . Use either Key1 or Key2 (on Azure Portal, in &quot;Keys and Endpoints&quot; from the menu on the left hand side of the screen). . _SUBS=&#39;&#39; . _LOC=&#39;westeurope&#39; . speech_config = speechsdk.SpeechConfig(region=_LOC, subscription=_SUBS) . audio_input=speechsdk.audio.AudioConfig(filename=&#39;cfjdfaqWY3Y.wav&#39;) . speech_config.speech_recognition_language = &#39;ga-IE&#39; speech_config.request_word_level_timestamps() speech_config.output_format = speechsdk.OutputFormat(1) speech_config.endpoint_id=&#39;https://westeurope.api.cognitive.microsoft.com/sts/v1.0/issuetoken&#39; . speech_config.set_property(speechsdk.PropertyId.Speech_LogFilename, &quot;azure.log&quot;) . # Copyright (c) Microsoft. All rights reserved. # Licensed under the MIT license. See LICENSE.md file in the project root for full license information. import time def speech_recognize_continuous_from_file(speech_config, audio_config): &quot;&quot;&quot;performs continuous speech recognition with input from an audio file&quot;&quot;&quot; speech_config = speech_config audio_config = audio_config speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, language=&#39;ga-IE&#39;, audio_config=audio_config) done = False def stop_cb(evt): &quot;&quot;&quot;callback that signals to stop continuous recognition upon receiving an event `evt`&quot;&quot;&quot; print(&#39;CLOSING on {}&#39;.format(evt)) nonlocal done done = True def cancelled(evt): result = evt.result cancellation_details = result.cancellation_details print(&quot;Speech Recognition canceled: {}&quot;.format(cancellation_details.reason)) if cancellation_details.reason == speechsdk.CancellationReason.Error: print(&quot;Error details: {}&quot;.format(cancellation_details.error_details)) # Connect callbacks to the events fired by the speech recognizer speech_recognizer.recognizing.connect(lambda evt: print(&#39;RECOGNIZING: {}&#39;.format(evt))) speech_recognizer.recognized.connect(lambda evt: print(&#39;RECOGNIZED: {}&#39;.format(evt))) speech_recognizer.session_started.connect(lambda evt: print(&#39;SESSION STARTED: {}&#39;.format(evt))) speech_recognizer.session_stopped.connect(lambda evt: print(&#39;SESSION STOPPED {}&#39;.format(evt))) speech_recognizer.canceled.connect(cancelled) # stop continuous recognition on either session stopped or canceled events speech_recognizer.session_stopped.connect(stop_cb) speech_recognizer.canceled.connect(stop_cb) # Start continuous speech recognition speech_recognizer.start_continuous_recognition() while not done: time.sleep(.5) speech_recognizer.stop_continuous_recognition() . speech_recognize_continuous_from_file(speech_config, audio_input) . Debugging with curl . !curl -v -X POST &quot;https://{_LOC}.api.cognitive.microsoft.com/sts/v1.0/issueToken&quot; -H &quot;Ocp-Apim-Subscription-Key: {_SUBS}&quot; -H &quot;Content-type: application/x-www-form-urlencoded&quot; -H &quot;Content-Length: 0&quot; . _TOK=&#39;&#39; . !curl -v -X POST &quot;https://{_LOC}.stt.speech.microsoft.com/speech/recognition/interactive/cognitiveservices/v1?language=ga-IE&quot; -H &quot;Authorization: Bearer {_TOK}&quot; -H &quot;Transfer-Encoding: chunked&quot; -H &quot;Content-type: audio/wav; codec=audio/pcm; samplerate=16000&quot; --data-binary @cfjdfaqWY3Y.wav . Next step, get at the innards (TODO) . transcript_display_list = [] transcript_ITN_list = [] confidence_list = [] words = [] def parse_azure_result(evt): import json response = json.loads(evt.result.json) transcript_display_list.append(response[&#39;DisplayText&#39;]) confidence_list_temp = [item.get(&#39;Confidence&#39;) for item in response[&#39;NBest&#39;]] max_confidence_index = confidence_list_temp.index(max(confidence_list_temp)) confidence_list.append(response[&#39;NBest&#39;][max_confidence_index][&#39;Confidence&#39;]) transcript_ITN_list.append(response[&#39;NBest&#39;][max_confidence_index][&#39;ITN&#39;]) words.extend(response[&#39;NBest&#39;][max_confidence_index][&#39;Words&#39;]) logger.debug(evt) .",
            "url": "https://jimregan.github.io/notes/azure/irish/asr/2021/05/04/azure-asr-with-irish.html",
            "relUrl": "/azure/irish/asr/2021/05/04/azure-asr-with-irish.html",
            "date": " ‚Ä¢ May 4, 2021"
        }
        
    
  
    
        ,"post103": {
            "title": "Azure speech recognition for Irish, part 2",
            "content": "%%capture !pip install azure-cognitiveservices-speech !pip install youtube-dl . %%capture !youtube-dl https://www.youtube.com/watch?v=cfjdfaqWY3Y . import azure.cognitiveservices.speech as speechsdk . Use either Key1 or Key2 (on Azure Portal, in &quot;Keys and Endpoints&quot; from the menu on the left hand side of the screen). . _SUBS=input(&#39;put your subscription key here: &#39;) . _LOC=&#39;westeurope&#39; . speech_config = speechsdk.SpeechConfig(region=_LOC, subscription=_SUBS) . !wget https://upload.wikimedia.org/wikipedia/commons/6/60/MSF_chapter_3.ogg https://upload.wikimedia.org/wikipedia/commons/e/ee/MSF_chapter_4.ogg https://upload.wikimedia.org/wikipedia/commons/b/b3/MSF_chapter_5.ogg https://upload.wikimedia.org/wikipedia/commons/2/21/MSF_chapter_6.ogg https://upload.wikimedia.org/wikipedia/commons/7/71/MSF_chapter_7.ogg https://upload.wikimedia.org/wikipedia/commons/d/d5/MSF_chapter_8.ogg . !ffmpeg -i MSF_chapter_5.ogg -acodec pcm_s16le -ac 1 -ar 16000 MSF_chapter_5.wav . speech_config.speech_recognition_language = &#39;ga-IE&#39; speech_config.request_word_level_timestamps() speech_config.output_format = speechsdk.OutputFormat(1) speech_config.endpoint_id=f&#39;https://{_LOC}.api.cognitive.microsoft.com/sts/v1.0/issuetoken&#39; . # Copyright (c) Microsoft. All rights reserved. # Licensed under the MIT license. See LICENSE.md file in the project root for full license information. import time import json def speech_recognize_continuous_from_file(speech_config, filename): &quot;&quot;&quot;performs continuous speech recognition with input from an audio file&quot;&quot;&quot; speech_config = speech_config audio_config = speechsdk.audio.AudioConfig(filename=filename) outfilename = filename.replace(&#39;.wav&#39;, &#39;.json&#39;) outfile = open(outfilename, &#39;a&#39;) speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, language=&#39;ga-IE&#39;, audio_config=audio_config) done = False def stop_cb(evt): &quot;&quot;&quot;callback that signals to stop continuous recognition upon receiving an event `evt`&quot;&quot;&quot; print(&#39;CLOSING on {}&#39;.format(evt)) nonlocal done done = True def cancelled(evt): result = evt.result cancellation_details = result.cancellation_details print(&quot;Speech Recognition canceled: {}&quot;.format(cancellation_details.reason)) if cancellation_details.reason == speechsdk.CancellationReason.Error: print(&quot;Error details: {}&quot;.format(cancellation_details.error_details)) def recognised(evt): response = json.loads(evt.result.json) outfile.write(&#39;{} n&#39;.format(evt.result.json)) # Connect callbacks to the events fired by the speech recognizer speech_recognizer.recognizing.connect(lambda evt: print(&#39;RECOGNIZING: {}&#39;.format(evt))) speech_recognizer.recognized.connect(recognised) speech_recognizer.session_started.connect(lambda evt: print(&#39;SESSION STARTED: {}&#39;.format(evt))) speech_recognizer.session_stopped.connect(lambda evt: print(&#39;SESSION STOPPED {}&#39;.format(evt))) speech_recognizer.canceled.connect(cancelled) # stop continuous recognition on either session stopped or canceled events speech_recognizer.session_stopped.connect(stop_cb) speech_recognizer.canceled.connect(stop_cb) # Start continuous speech recognition speech_recognizer.start_continuous_recognition() while not done: time.sleep(.5) speech_recognizer.stop_continuous_recognition() outfile.close() . for i in &quot;345678&quot;: speech_recognize_continuous_from_file(speech_config, f&#39;MSF_chapter_{i}.wav&#39;) .",
            "url": "https://jimregan.github.io/notes/azure/irish/asr/2021/05/04/azure-asr-with-irish-part2.html",
            "relUrl": "/azure/irish/asr/2021/05/04/azure-asr-with-irish-part2.html",
            "date": " ‚Ä¢ May 4, 2021"
        }
        
    
  
    
        ,"post104": {
            "title": "Playing with auditok",
            "content": "%%capture !pip install auditok . %%capture !yes|apt install python3-pyaudio . %%capture !pip install youtube-dl . !youtube-dl https://www.youtube.com/watch?v=D44-x6PTd_Q . [youtube] D44-x6PTd_Q: Downloading webpage [youtube] D44-x6PTd_Q: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 22 [download] Destination: Sraith Picti√∫r - An Ghaeilge Seoid luachmhar-D44-x6PTd_Q.f247.webm [download] 22.7% of ~12.60MiB at 5.49MiB/s ETA 00:13[download] Got server HTTP error: HTTP Error 404: Not Found. Retrying fragment 6 (attempt 1 of 10)... [download] 100% of 15.12MiB in 00:18 [download] Destination: Sraith Picti√∫r - An Ghaeilge Seoid luachmhar-D44-x6PTd_Q.f140.m4a [download] 100% of 1.73MiB in 00:00 [ffmpeg] Merging formats into &#34;Sraith Picti√∫r - An Ghaeilge Seoid luachmhar-D44-x6PTd_Q.mkv&#34; Deleting original file Sraith Picti√∫r - An Ghaeilge Seoid luachmhar-D44-x6PTd_Q.f247.webm (pass -k to keep) Deleting original file Sraith Picti√∫r - An Ghaeilge Seoid luachmhar-D44-x6PTd_Q.f140.m4a (pass -k to keep) . import auditok input = &#39;Sraith Picti√∫r - An Ghaeilge Seoid luachmhar-D44-x6PTd_Q.mkv&#39; audio_regions = auditok.split( input, min_dur=1, max_dur=10, max_silence=0.9, energy_threshold=20 ) for i, r in enumerate(audio_regions): print(&quot;Region {i}: {r.meta.start:.3f}s -- {r.meta.end:.3f}s&quot;.format(i=i, r=r)) . Region 0: 0.300s -- 6.550s Region 1: 7.450s -- 12.950s Region 2: 13.150s -- 15.700s Region 3: 15.900s -- 19.200s Region 4: 19.350s -- 29.350s Region 5: 29.700s -- 34.200s Region 6: 34.300s -- 38.600s Region 7: 39.000s -- 43.650s Region 8: 43.700s -- 46.550s Region 9: 46.750s -- 49.500s Region 10: 49.550s -- 52.950s Region 11: 53.000s -- 56.050s Region 12: 56.250s -- 59.500s Region 13: 59.700s -- 62.550s Region 14: 63.150s -- 69.600s Region 15: 69.650s -- 73.100s Region 16: 73.400s -- 77.450s Region 17: 77.800s -- 81.150s Region 18: 81.350s -- 89.100s Region 19: 89.500s -- 92.750s Region 20: 92.950s -- 96.250s Region 21: 96.500s -- 99.600s Region 22: 99.850s -- 104.350s Region 23: 104.500s -- 108.050s . regs = auditok.load(input) regs.split_and_plot( min_dur=1, max_dur=10, max_silence=0.9, energy_threshold=20, dpi=600 ) . [AudioRegion(duration=6.250, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=5.500, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=2.550, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.300, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=10.000, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=4.500, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=4.300, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=4.650, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=2.850, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=2.750, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.400, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.050, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.250, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=2.850, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=6.450, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.450, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=4.050, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.350, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=7.750, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.250, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.300, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.100, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=4.500, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.550, sampling_rate=44100, sample_width=2, channels=2)] .",
            "url": "https://jimregan.github.io/notes/auditok/2021/05/03/playing-with-auditok.html",
            "relUrl": "/auditok/2021/05/03/playing-with-auditok.html",
            "date": " ‚Ä¢ May 3, 2021"
        }
        
    
  
    
        ,"post105": {
            "title": "rclone and Sharepoint",
            "content": "%%capture !curl https://rclone.org/install.sh |bash . curl_out=!curl --cookie -i -L &#39;https://uniwersytetlodzki-my.sharepoint.com/:f:/g/personal/pelcra_uni_lodz_pl/EpPehikqGqZJltrAKlVp3k0BOeyzEgBBO_ZwmFC9WaLbWw&#39;|grep &#39;var _spPageContextInfo=&#39; . import json for s in curl_out: if &#39;var _spPageContextInfo=&#39; in s: start = s[s.index(&#39;access_token=&#39;)+len(&#39;access_token=&#39;):] access_token = start[:start.index(&#39;&quot;&#39;)] . _URL=&#39;https://uniwersytetlodzki-my.sharepoint.com/personal/pelcra_uni_lodz_pl/Documents&#39; . _COOKIE=&#39;FedAuth=77u/PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0idXRmLTgiPz48U1A+VjksMGguZnxtZW1iZXJzaGlwfHVybiUzYXNwbyUzYWFub24jNTZiNDAwY2Y5OWYxMjQwYTkyYjRhNWU3ZTkwYjJlNWVlY2Q3MzYyMGJlNmNiMjI4OTllNjhiMWU4Zjc2Nzk4ZCwwIy5mfG1lbWJlcnNoaXB8dXJuJTNhc3BvJTNhYW5vbiM1NmI0MDBjZjk5ZjEyNDBhOTJiNGE1ZTdlOTBiMmU1ZWVjZDczNjIwYmU2Y2IyMjg5OWU2OGIxZThmNzY3OThkLDEzMjY0NDY0NTU3MDAwMDAwMCwwLDEzMjY0NTUwNjU4MDQxOTgzNCwwLjAuMC4wLDI1OCxkZGIyZmM4NS0xYzE4LTRjMmItOTkyYS1lODQxMWJmZmMwZTcsLCw0ODEyYzQ5Zi02MGY0LTIwMDAtZTE0Mi02YzYwM2MyZGE3YzQsNDgxMmM0OWYtNjBmNC0yMDAwLWUxNDItNmM2MDNjMmRhN2M0LDVrVml3YU9rSGtxaWZjbzVzKytYSlEsMCwwLDAsLCwsMjY1MDQ2Nzc0Mzk5OTk5OTk5OSwwLCwsLCwsc0JtSkR4RTZJd3I5VmsraGJHclFSUDhSNzJIUXh2UWlqNDZ6WnFPdXArUVZnVWhkNkVmQWljNUZ1YUYwMEdGUjRFRnhMRUJsRlNTZ3lnNElkTUdSSnpwbGZUT0JGSkw0Tyt4cjRHS01WdjZ1YnhJWTFzMkFWYWpySVgzbXRGWm9zOHkrYjk0SnhPZElibVVxaUJWZzVaZHVTcWxSMnlFdzc0Y3BueERjVHdQU3FVYTk3VG5qOTRWM0s4YkdkUnA1QVVGSGtacjg2Q0YvZVY5R2Y1OGlTd1ZKUWx2VEc5OVByaU9JWE94Umc4N2FZc2ZFTWZzcG9JL05tYlU0cm9sQ1ZnVzVVNUl3NXJlY29PNzkxUXZZbDBlUlZNcXBVSHI0UEdBOVhLaEJVb3I5YTJpMFpQZEhZRE9SQnlVcWtHRDQvb0NXY21JamdGQVhNM2RtTFgwWGJBPT08L1NQPg==; path=/; SameSite=None; secure; HttpOnly&#39; . !rclone config create pelcra webdav url {_URL} webdav-vendor other access_token {access_token} #cookie &quot;{_COOKIE}&quot; . Remote config -- [pelcra] type = webdav url = https://uniwersytetlodzki-my.sharepoint.com/personal/pelcra_uni_lodz_pl/Documents webdav-vendor = other access_token = eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJhdWQiOiIwMDAwMDAwMy0wMDAwLTBmZjEtY2UwMC0wMDAwMDAwMDAwMDAvdW5pd2Vyc3l0ZXRsb2R6a2ktbXkuc2hhcmVwb2ludC5jb21ANjM0NDFhZWYtZGEwZS00Mzk3LWJiN2UtZjlkNDcwNWU5NjNiIiwiaXNzIjoiMDAwMDAwMDMtMDAwMC0wZmYxLWNlMDAtMDAwMDAwMDAwMDAwIiwibmJmIjoxNjIwMjU0MjMwLCJleHAiOjE2MjAyNzU4MzAsImlzbG9vcGJhY2siOiJUcnVlIiwibmFtZWlkIjoiMCMuZnxtZW1iZXJzaGlwfHVybiUzYXNwbyUzYWFub24jNTZiNDAwY2Y5OWYxMjQwYTkyYjRhNWU3ZTkwYjJlNWVlY2Q3MzYyMGJlNmNiMjI4OTllNjhiMWU4Zjc2Nzk4ZCIsIm5paSI6Im1pY3Jvc29mdC5zaGFyZXBvaW50IiwiaXN1c2VyIjoidHJ1ZSIsImNhY2hla2V5IjoiMGguZnxtZW1iZXJzaGlwfHVybiUzYXNwbyUzYWFub24jNTZiNDAwY2Y5OWYxMjQwYTkyYjRhNWU3ZTkwYjJlNWVlY2Q3MzYyMGJlNmNiMjI4OTllNjhiMWU4Zjc2Nzk4ZCIsInR0IjoiMCIsInVzZVBlcnNpc3RlbnRDb29raWUiOiIyIn0.A50UZ17CCLwueDg9UAJx4NY4FM-3p_vRN59OrxDxFz4u0026prooftoken=eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsIng1dCI6IkcydDJKYzlkMVZ6RkdjdzZUZy02YUhZVXk2VSJ9.eyJhdWQiOiIwMDAwMDAwMy0wMDAwLTBmZjEtY2UwMC0wMDAwMDAwMDAwMDBAKiIsImlzcyI6IjAwMDAwMDAzLTAwMDAtMGZmMS1jZTAwLTAwMDAwMDAwMDAwMEAqIiwibmJmIjoiMTYyMDI0NjgzMCIsImV4cCI6IjE2MjA4NTE2MzAiLCJwcmYiOiJLMUs2Z21oMFNpZDBaL2E0SjJReXpDSVJLMXBTWGlyOXAzcitoM1UwTjZRNWo2UEc2REZPaG5OU2dPU3FwZDRXK1ZpenppSTlCcWc2d2kvSE83Zk9scGhmaE9pU3NLN1p6clFGMUxlOFk3dnJJejdNb1RLQ3Njbjh5cUhvSklVbjFmVFlIcGltb1E0NnJQdVlJV0pJK3UwOXVHTVBpSS9ZcWlCYzhHd0VBTit0bnoyZ2tIcXM3OGhXbGo2Y3dBNzNTckJwTHBTdG53QzZaRXRoUVV1N3l6eGhuRVlXdkNhNUFPdVlWaXRiMndTZWpib0g5QlBCc0puemVEL1ZMUDFqZXh2Qk9DRVpYN25XRjU4SC9Sck1tdWdZb2ZxMGQzZnhlTG56d0RJbDFEYjdqcFc3L20vaURJV1FQRUZScmFmUW1pbFJmYjRSTFUxVFFGWWptVHJmU1E9PSIsImlzdXNlciI6InRydWUifQ.o1x0-K2UNkorQjKyT5o0HXJiOJxHP3vlYscEzjKN2KQHzp95ja3ml5yzqPtSXdCwYxjCdJjWgtAvS5YlQzLBX2Eac8odydBxDa8EHyuVxIa6T-n7dD4R1WHVebyXt62shIP61s_TeiJkwiD0Sl_nPIzqY9zkrKEg_cSe0isEi0mCv6ynYXCWetYpaMdv4ifaGAl5aK7v6zxNKzwVoxBUfEIcJLV8MjdeV1i1Puuinpj69GUispryx7ruDs0g5CLVjOeAk0wwaoTeRzL4y04EKTKdt4UsdeAAXzE1Rby4na3xqDkeewPUCYxZHQL89tGOUcmiwjJKeB7Fos39XIhrRg -- . !rclone ls --use-cookies -vv &#39;pelcra:SHARE/CLARIN/SPOKES/PELCRA_EMO&#39; --dump bodies . 2021/05/05 22:54:48 DEBUG : Using config file from &#34;/root/.config/rclone/rclone.conf&#34; 2021/05/05 22:54:48 DEBUG : rclone: Version &#34;v1.55.1&#34; starting with parameters [&#34;rclone&#34; &#34;ls&#34; &#34;--use-cookies&#34; &#34;-vv&#34; &#34;pelcra:SHARE/CLARIN/SPOKES/PELCRA_EMO&#34; &#34;--dump&#34; &#34;bodies&#34;] 2021/05/05 22:54:48 DEBUG : Creating backend with remote &#34;pelcra:SHARE/CLARIN/SPOKES/PELCRA_EMO&#34; 2021/05/05 22:54:48 DEBUG : You have specified to dump information. Please be noted that the Accept-Encoding as shown may not be correct in the request and the response may not show Content-Encoding if the go standard libraries auto gzip encoding was in effect. In this case the body of the request will be gunzipped before showing it. 2021/05/05 22:54:48 DEBUG : &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 2021/05/05 22:54:48 DEBUG : HTTP REQUEST (req 0xc000596a00) 2021/05/05 22:54:48 DEBUG : PROPFIND /personal/pelcra_uni_lodz_pl/Documents/SHARE/CLARIN/SPOKES/PELCRA_EMO HTTP/1.1 Host: uniwersytetlodzki-my.sharepoint.com User-Agent: rclone/v1.55.1 Depth: 1 Referer: https://uniwersytetlodzki-my.sharepoint.com/personal/pelcra_uni_lodz_pl/Documents/ Accept-Encoding: gzip 2021/05/05 22:54:48 DEBUG : &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 2021/05/05 22:54:49 DEBUG : &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; 2021/05/05 22:54:49 DEBUG : HTTP RESPONSE (req 0xc000596a00) 2021/05/05 22:54:49 DEBUG : HTTP/2.0 403 Forbidden Content-Length: 13 Content-Type: text/plain; charset=utf-8 Date: Wed, 05 May 2021 22:54:48 GMT Microsoftsharepointteamservices: 16.0.0.21221 Ms-Cv: n8UOqHwAACDhQmsT9SmG6Q.0 P3p: CP=&#34;ALL IND DSP COR ADM CONo CUR CUSo IVAo IVDo PSA PSD TAI TELo OUR SAMo CNT COM INT NAV ONL PHY PRE PUR UNI&#34; Request-Id: a80ec59f-007c-2000-e142-6b13f52986e9 Sprequestguid: a80ec59f-007c-2000-e142-6b13f52986e9 X-Content-Type-Options: nosniff X-Forms_based_auth_required: https://uniwersytetlodzki-my.sharepoint.com/_forms/default.aspx?ReturnUrl=/_layouts/15/error.aspx&amp;Source=%2fpersonal%2fpelcra_uni_lodz_pl%2fDocuments%2fSHARE%2fCLARIN%2fSPOKES%2fPELCRA_EMO X-Forms_based_auth_return_url: https://uniwersytetlodzki-my.sharepoint.com/_layouts/15/error.aspx X-Idcrl_auth_params_v1: IDCRL Type=&#34;BPOSIDCRL&#34;, EndPoint=&#34;/personal/pelcra_uni_lodz_pl/_vti_bin/idcrl.svc/&#34;, RootDomain=&#34;sharepoint.com&#34;, Policy=&#34;MBI&#34; X-Ms-Invokeapp: 1; RequireReadOnly X-Msdavext_error: 917656; Access+denied.+Before+opening+files+in+this+location%2c+you+must+first+browse+to+the+web+site+and+select+the+option+to+login+automatically. X-Msedge-Ref: Ref A: 8A3CC80AA56A42C4A2112F4377B61AA6 Ref B: HK2EDGE0921 Ref C: 2021-05-05T22:54:49Z X-Powered-By: ASP.NET X-Sharepointhealthscore: 3 403 FORBIDDEN 2021/05/05 22:54:49 DEBUG : &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; 2021/05/05 22:54:49 Failed to create file system for &#34;pelcra:SHARE/CLARIN/SPOKES/PELCRA_EMO&#34;: read metadata failed: 403 FORBIDDEN: 403 Forbidden . !rclone ls :http: --http-url &#39;https://uniwersytetlodzki-my.sharepoint.com/:f:/g/personal/pelcra_uni_lodz_pl/EpPehikqGqZJltrAKlVp3k0BOeyzEgBBO_ZwmFC9WaLbWw&#39; --use-cookies -vv . !rclone config dump .",
            "url": "https://jimregan.github.io/notes/rclone/sharepoint/2021/05/02/rclone-and-sharepoint.html",
            "relUrl": "/rclone/sharepoint/2021/05/02/rclone-and-sharepoint.html",
            "date": " ‚Ä¢ May 2, 2021"
        }
        
    
  
    
        ,"post106": {
            "title": "Ruby kernel on Colab",
            "content": "!apt-get install ruby-dev !sudo apt install libtool libffi-dev ruby ruby-dev make !sudo apt install libzmq3-dev libczmq-dev !gem install ffi-rzmq !gem install specific_install !gem specific_install https://github.com/SciRuby/iruby !iruby register . !jupyter kernelspec list . Available kernels: ruby /root/.local/share/jupyter/kernels/ruby ir /usr/local/share/jupyter/kernels/ir python2 /usr/local/share/jupyter/kernels/python2 python3 /usr/local/share/jupyter/kernels/python3 .",
            "url": "https://jimregan.github.io/notes/colab/misc/2021/05/01/colab-ruby-kernel.html",
            "relUrl": "/colab/misc/2021/05/01/colab-ruby-kernel.html",
            "date": " ‚Ä¢ May 1, 2021"
        }
        
    
  
    
        ,"post107": {
            "title": "Two speechbrain speech enhancement models",
            "content": "The Colab notebook (with outputs) is here; the models are on the Huggingface hub: mtl-mimic-voicebank and speechbrain/metricgan-plus-voicebank . The first twenty seconds of mtl-mimic-voicebank aren&#39;t great (but they are quieter in the recording); the rest is fantastic. The output from metricgan-plus-voicebank is bad from start to finish. . %%capture !pip install torchaudio speechbrain . !wget http://assets.doegen.ie/sound/MP3_versions/aud_Ul1-LA_1202d1u1.mp3 . import IPython IPython.display.Audio(&#39;aud_Ul1-LA_1202d1u1.mp3&#39;) . import torchaudio from speechbrain.pretrained import SpectralMaskEnhancement enhance_model = SpectralMaskEnhancement.from_hparams( source=&quot;speechbrain/mtl-mimic-voicebank&quot;, savedir=&quot;pretrained_models/mtl-mimic-voicebank&quot;, ) enhanced = enhance_model.enhance_file(&quot;aud_Ul1-LA_1202d1u1.mp3&quot;) # Saving enhanced signal on disk torchaudio.save(&#39;enhanced.wav&#39;, enhanced.unsqueeze(0), 16000) . IPython.display.Audio(&#39;enhanced.wav&#39;) . import torch enhance_model = SpectralMaskEnhancement.from_hparams( source=&quot;speechbrain/metricgan-plus-voicebank&quot;, savedir=&quot;pretrained_models/metricgan-plus-voicebank&quot;, ) noisy = enhance_model.load_audio(&quot;aud_Ul1-LA_1202d1u1.mp3&quot;).unsqueeze(0) # Add relative length tensor enhanced = enhance_model.enhance_batch(noisy, lengths=torch.tensor([1.])) # Saving enhanced signal on disk torchaudio.save(&#39;enhanced2.wav&#39;, enhanced, 16000) . IPython.display.Audio(&#39;enhanced2.wav&#39;) .",
            "url": "https://jimregan.github.io/notes/speechbrain/speech%20enhancement/2021/04/30/speechbrain_speech_enhancements.html",
            "relUrl": "/speechbrain/speech%20enhancement/2021/04/30/speechbrain_speech_enhancements.html",
            "date": " ‚Ä¢ Apr 30, 2021"
        }
        
    
  
    
        ,"post108": {
            "title": "Polish phonetic comparison",
            "content": "from difflib import SequenceMatcher import icu . plipa = icu.Transliterator.createInstance(&#39;pl-pl_FONIPA&#39;) . The errors in E2E models are quite often phonetic confusions, so we do the opposite of traditional ASR and generate the phonetic representation from the output as a basis for comparison. . def phonetic_check(word1, word2, ignore_spaces=False): &quot;&quot;&quot;Uses ICU&#39;s IPA transliteration to check if words are the same&quot;&quot;&quot; tl1 = plipa.transliterate(word1) if not ignore_spaces else plipa.transliterate(word1.replace(&#39; &#39;, &#39;&#39;)) tl2 = plipa.transliterate(word2) if not ignore_spaces else plipa.transliterate(word2.replace(&#39; &#39;, &#39;&#39;)) return tl1 == tl2 . phonetic_check(&quot;j√≥rz&quot;, &quot;jusz&quot;, False) . True . The Polish y is phonetically a raised schwa; like the schwa in English, it&#39;s often deleted in fast speech. This function returns true if the only differences between the first word and the second is are deletions of y, except at the end of the word (which is typically the plural ending). . def no_igrek(word1, word2): &quot;&quot;&quot;Checks if a word-internal y has been deleted&quot;&quot;&quot; sm = SequenceMatcher(None, word1, word2) for oc in sm.get_opcodes(): if oc[0] == &#39;equal&#39;: continue elif oc[0] == &#39;delete&#39; and word1[oc[1]:oc[2]] != &#39;y&#39;: return False elif oc[0] == &#39;delete&#39; and word1[oc[1]:oc[2]] == &#39;y&#39; and oc[2] == len(word1): return False elif oc[0] == &#39;insert&#39; or oc[0] == &#39;replace&#39;: return False return True . no_igrek(&#39;uniwersytet&#39;, &#39;uniwerstet&#39;) . True . no_igrek(&#39;uniwerstety&#39;, &#39;uniwerstet&#39;) . False . phonetic_alternatives = [ [&#39;u&#39;, &#39;√≥&#39;], [&#39;rz&#39;, &#39;≈º&#39;] ] def reverse_alts(phonlist): return [ [i[1], i[0]] for i in phonlist ] . sm = SequenceMatcher(None, &quot;ju≈º&quot;, &quot;jurz&quot;) for oc in sm.get_opcodes(): print(oc) . (&#39;equal&#39;, 0, 2, 0, 2) (&#39;replace&#39;, 2, 3, 2, 4) . Reads a CTM-like file, returning a list of lists containing the filename, start time, end time, and word. . def read_ctmish(filename): output = [] with open(filename, &#39;r&#39;) as f: for line in f.readlines(): pieces = line.strip().split(&#39; &#39;) if len(pieces) &lt;= 4: continue for piece in pieces[4:]: output.append([pieces[0], pieces[2], pieces[3], piece]) return output . Returns the contents of a plain text file as a list of lists containing the line number and the word, for use in locating mismatches . def read_text(filename): output = [] counter = 0 with open(filename, &#39;r&#39;) as f: for line in f.readlines(): counter += 1 for word in line.strip().split(&#39; &#39;) output.append([counter, word]) return output . ctmish = read_ctmish(&quot;/mnt/c/Users/Jim O &#39;Regan/git/notes/PlgU9JyTLPE.ctm&quot;) . rec_words = [i[3] for i in ctmish] .",
            "url": "https://jimregan.github.io/notes/asr/polish/phonetic/todo/2021/04/29/phonetic-comparison.html",
            "relUrl": "/asr/polish/phonetic/todo/2021/04/29/phonetic-comparison.html",
            "date": " ‚Ä¢ Apr 29, 2021"
        }
        
    
  
    
        ,"post109": {
            "title": "Doegen recordings scraper",
            "content": "import requests from bs4 import BeautifulSoup import json . _BASE = &#39;https://doegen.ie/counties&#39; def do_get(url): r = requests.get(url, headers = {&#39;User-agent&#39;: &#39;Mozilla/5.0&#39;}) if r.status_code != 200: raise Exception(&quot;Failed to open landing page&quot;) return r.content . soup = BeautifulSoup(do_get(_BASE), &#39;html.parser&#39;) . counties = soup.find(&#39;ul&#39;, {&#39;class&#39;: &#39;vocabindex&#39;}).find_all(&#39;li&#39;) . pages = [] for county in counties: item = {} anchor = county.find(&#39;a&#39;) href = anchor[&#39;href&#39;] item[&#39;link&#39;] = f&#39;https://doegen.ie{href}&#39; if anchor.find(&#39;span&#39;).text.strip() != &#39;(0)&#39;: item[&#39;county&#39;] = anchor.text.split()[1] pages.append(item) . def proc_page(url): result = {} html = do_get(url) soup = BeautifulSoup(html, &#39;html.parser&#39;) main = soup.find(&#39;div&#39;, {&#39;id&#39;: &#39;main&#39;}) content = main.find(&#39;div&#39;, {&#39;class&#39;: &#39;content&#39;}) source = content.find(&#39;source&#39;) if source == None: return {} result[&#39;mp3&#39;] = source[&#39;src&#39;] result[&#39;transcript&#39;] = content.find(&#39;div&#39;, id=&#39;transcript&#39;).text if content.find(&#39;div&#39;, id=&#39;translation&#39;) != None: result[&#39;translation&#39;] = content.find(&#39;div&#39;, id=&#39;translation&#39;).text if content.find(&#39;div&#39;, id=&#39;footnote&#39;) != None: result[&#39;footnote&#39;] = content.find(&#39;div&#39;, id=&#39;footnote&#39;).text result[&#39;recording_metadata&#39;] = content.find(&#39;div&#39;, id=&#39;recording_metadata&#39;).text return result . def proc_county(item): content = do_get(item[&#39;link&#39;]) soup = BeautifulSoup(content, &#39;html.parser&#39;) main = soup.find(&#39;div&#39;, id=&#39;main&#39;) nodes = main.find_all(&#39;div&#39;, {&#39;class&#39;: &#39;node&#39;}) stories = [] for node in nodes: story = {} anchor = node.find(&#39;a&#39;) story[&#39;link&#39;] = f&quot;https://doegen.ie{anchor[&#39;href&#39;]}&quot; story[&#39;content&#39;] = proc_page(story[&#39;link&#39;]) if story[&#39;content&#39;] == {}: continue tags = node.find(&#39;div&#39;, {&#39;class&#39;: &#39;terms&#39;}).find_all(&#39;a&#39;, rel=&#39;tag&#39;) text = anchor.text if &#39; - &#39; in text: tmp = text.split(&#39; - &#39;) if len(tmp) == 2: story[&#39;title&#39;] = tmp[0] story[&#39;speaker_name&#39;] = tmp[1] name_parts = tmp[1].split(&#39; &#39;) first = name_parts[0] for tag in tags: if first in tag.text: story[&#39;speaker_url&#39;] = f&quot;https://doegen.ie{tag[&#39;href&#39;]}&quot; else: story[&#39;raw&#39;] = text else: story[&#39;raw&#39;] = text stories.append(story) item[&#39;stories&#39;] = stories . for page in pages: proc_county(page) . with open(&#39;doegen.json&#39;, &#39;w&#39;) as f: json.dump(pages, f) .",
            "url": "https://jimregan.github.io/notes/irish/scraper/2021/04/29/doegen-scraper.html",
            "relUrl": "/irish/scraper/2021/04/29/doegen-scraper.html",
            "date": " ‚Ä¢ Apr 29, 2021"
        }
        
    
  
    
        ,"post110": {
            "title": "Praat via parselmouth",
            "content": "import numpy as np import matplotlib.pyplot as plt import seaborn as sns import requests import parselmouth import tempfile . sns.set() # Use seaborn&#39;s default style to make attractive graphs plt.rcParams[&#39;figure.dpi&#39;] = 300 # Show nicely large images in this notebook . def load_from_teanglann(word, dialect): valid_dialects = [&#39;C&#39;, &#39;M&#39;, &#39;U&#39;] if dialect not in valid_dialects and dialect.upper()[0] not in valid_dialects: raise Exception(f&#39;Dialect must be one of &quot;C&quot;, &quot;M&quot; or &quot;U&quot;; got &quot;{dialect}&quot;&#39;) url = f&#39;https://www.teanglann.ie/Can{dialect}/{word}.mp3&#39; r = requests.get(url) if r.status_code != 200: raise Exception(f&#39;Failed to fetch {url}&#39;) file = tempfile.NamedTemporaryFile(mode=&#39;w+b&#39;) file.write(r.content) return file . def draw_spectrogram(spectrogram, dynamic_range=70): X, Y = spectrogram.x_grid(), spectrogram.y_grid() sg_db = 10 * np.log10(spectrogram.values) plt.pcolormesh(X, Y, sg_db, vmin=sg_db.max() - dynamic_range, cmap=&#39;afmhot&#39;) plt.ylim([spectrogram.ymin, spectrogram.ymax]) plt.xlabel(&quot;time [s]&quot;) plt.ylabel(&quot;frequency [Hz]&quot;) def draw_intensity(intensity): plt.plot(intensity.xs(), intensity.values.T, linewidth=3, color=&#39;w&#39;) plt.plot(intensity.xs(), intensity.values.T, linewidth=1) plt.grid(False) plt.ylim(0) plt.ylabel(&quot;intensity [dB]&quot;) . file=load_from_teanglann(&#39;athdhreas&#39;, &#39;U&#39;) snd = parselmouth.Sound(file_path=file.name) intensity = snd.to_intensity() spectrogram = snd.to_spectrogram() plt.figure() draw_spectrogram(spectrogram) plt.twinx() #draw_intensity(intensity) plt.xlim([snd.xmin, snd.xmax]) plt.show() . def draw_pitch(pitch): # Extract selected pitch contour, and # replace unvoiced samples by NaN to not plot pitch_values = pitch.selected_array[&#39;frequency&#39;] pitch_values[pitch_values==0] = np.nan plt.plot(pitch.xs(), pitch_values, &#39;o&#39;, markersize=5, color=&#39;w&#39;) plt.plot(pitch.xs(), pitch_values, &#39;o&#39;, markersize=2) plt.grid(False) plt.ylim(0, pitch.ceiling) plt.ylabel(&quot;fundamental frequency [Hz]&quot;) pitch = snd.to_pitch() # If desired, pre-emphasize the sound fragment before calculating the spectrogram pre_emphasized_snd = snd.copy() pre_emphasized_snd.pre_emphasize() spectrogram = pre_emphasized_snd.to_spectrogram(window_length=0.03, maximum_frequency=8000) plt.figure() draw_spectrogram(spectrogram) plt.twinx() #draw_pitch(pitch) plt.xlim([snd.xmin, snd.xmax]) plt.show() .",
            "url": "https://jimregan.github.io/notes/praat/parselmouth/2021/04/24/parselmouth.html",
            "relUrl": "/praat/parselmouth/2021/04/24/parselmouth.html",
            "date": " ‚Ä¢ Apr 24, 2021"
        }
        
    
  
    
        ,"post111": {
            "title": "BuNaMo to json",
            "content": "from lxml import etree . class BuNaMoWrongDocument(Exception): &quot;&quot;&quot;Exception raised for wrong document type&quot;&quot;&quot; def __init__(self, expected, got): self.expected = expected self.got = got self.message = f&quot;Expected root element &lt;{self.expected}&gt; but got &lt;{self.got}&gt;&quot; super().__init__(self.message) . Various functions to read one of the types of XML file. The open parts of speech (noun, adjective, verb) can have multiple forms, so those functions return attributes (a dictionary) and forms (a list of dictionaries) separately. . Close parts of speech (possessives and prepositions) are simpler, and most of the attributes are needless, so they return a simple dictionary containing the forms. . def read_adjective(file): tree = etree.parse(file) root = tree.getroot() valid_tags = [&#39;sgNom&#39;, &#39;sgGenMasc&#39;, &#39;sgGenFem&#39;, &#39;plNom&#39;, &#39;graded&#39;, &#39;abstractNoun&#39;, &#39;sgVocMasc&#39;, &#39;sgVocFem&#39;] attribs = {} forms = [] if root.tag != &#39;adjective&#39;: raise BuNaMoWrongDocument(&#39;adjective&#39;, root.tag) attribs[&#39;default&#39;] = root.get(&#39;default&#39;) attribs[&#39;declension&#39;] = root.get(&#39;declension&#39;) attribs[&#39;disambig&#39;] = root.get(&#39;disambig&#39;) attribs[&#39;isPre&#39;] = root.get(&#39;isPre&#39;) for child in root: if child.tag not in valid_tags: raise Exception(&#39;Unexpected tag &#39; + child.tag) tmp = {} tmp[&#39;props&#39;] = child.tag tmp[&#39;form&#39;] = child.get(&#39;default&#39;) forms.append(tmp) return attribs, forms def read_noun(file): tree = etree.parse(file) root = tree.getroot() valid_tags = [&#39;sgNom&#39;, &#39;sgGen&#39;, &#39;plNom&#39;, &#39;plGen&#39;, &#39;count&#39;, &#39;sgDat&#39;] attribs = {} forms = [] if root.tag != &#39;noun&#39;: raise BuNaMoWrongDocument(&#39;noun&#39;, root.tag) attribs[&#39;default&#39;] = root.get(&#39;default&#39;) attribs[&#39;declension&#39;] = root.get(&#39;declension&#39;) attribs[&#39;disambig&#39;] = root.get(&#39;disambig&#39;) attribs[&#39;isProper&#39;] = root.get(&#39;isProper&#39;) attribs[&#39;isDefinite&#39;] = root.get(&#39;isDefinite&#39;) attribs[&#39;allowArticledGenitive&#39;] = root.get(&#39;allowArticledGenitive&#39;) for child in root: if child.tag not in valid_tags: raise Exception(&#39;Unexpected tag &#39; + child.tag) tmp = {} tmp[&#39;props&#39;] = child.tag tmp[&#39;form&#39;] = child.get(&#39;default&#39;) tmp[&#39;gender&#39;] = child.get(&#39;gender&#39;) tmp[&#39;strength&#39;] = child.get(&#39;strength&#39;) forms.append(tmp) return attribs, forms def read_verb(file): tree = etree.parse(file) root = tree.getroot() valid_tags = [&#39;verbalNoun&#39;, &#39;verbalAdjective&#39;, &#39;tenseForm&#39;, &#39;moodForm&#39;] attribs = {} forms = [] if root.tag != &#39;verb&#39;: raise BuNaMoWrongDocument(&#39;verb&#39;, root.tag) attribs[&#39;default&#39;] = root.get(&#39;default&#39;) attribs[&#39;disambig&#39;] = root.get(&#39;disambig&#39;) for child in root: if child.tag not in valid_tags: raise Exception(&#39;Unexpected tag &#39; + child.tag) tmp = {} tmp[&#39;props&#39;] = child.tag tmp[&#39;form&#39;] = child.get(&#39;default&#39;) tmp[&#39;tense&#39;] = child.get(&#39;tense&#39;) tmp[&#39;mood&#39;] = child.get(&#39;mood&#39;) tmp[&#39;dependency&#39;] = child.get(&#39;dependency&#39;) tmp[&#39;person&#39;] = child.get(&#39;person&#39;) forms.append(tmp) return attribs, forms def read_nounphrase(file): tree = etree.parse(file) root = tree.getroot() valid_tags = [&#39;sgNom&#39;, &#39;sgGen&#39;, &#39;plNom&#39;, &#39;plGen&#39;, &#39;sgNomArt&#39;, &#39;sgGenArt&#39;, &#39;plNomArt&#39;, &#39;plGenArt&#39;] attribs = {} forms = [] if root.tag != &#39;nounPhrase&#39;: raise BuNaMoWrongDocument(&#39;nounPhrase&#39;, root.tag) attribs[&#39;default&#39;] = root.get(&#39;default&#39;) attribs[&#39;declension&#39;] = root.get(&#39;declension&#39;) attribs[&#39;disambig&#39;] = root.get(&#39;disambig&#39;) attribs[&#39;isProper&#39;] = root.get(&#39;isProper&#39;) attribs[&#39;isDefinite&#39;] = root.get(&#39;isDefinite&#39;) attribs[&#39;allowArticledGenitive&#39;] = root.get(&#39;allowArticledGenitive&#39;) attribs[&#39;forceNominative&#39;] = root.get(&#39;forceNominative&#39;) for child in root: if child.tag not in valid_tags: raise Exception(&#39;Unexpected tag &#39; + child.tag) tmp = {} tmp[&#39;props&#39;] = child.tag tmp[&#39;form&#39;] = child.get(&#39;default&#39;) tmp[&#39;gender&#39;] = child.get(&#39;gender&#39;) tmp[&#39;strength&#39;] = child.get(&#39;strength&#39;) forms.append(tmp) return attribs, forms def read_possessive(file): tree = etree.parse(file) root = tree.getroot() valid_tags = [&#39;full&#39;, &#39;apos&#39;] attribs = {} forms = [] if root.tag != &#39;possessive&#39;: raise BuNaMoWrongDocument(&#39;possessive&#39;, root.tag) attribs[&#39;default&#39;] = root.get(&#39;default&#39;) attribs[&#39;disambig&#39;] = root.get(&#39;disambig&#39;) attribs[&#39;mutation&#39;] = root.get(&#39;mutation&#39;) for child in root: if child.tag not in valid_tags: raise Exception(&#39;Unexpected tag &#39; + child.tag) if child.tag == &#39;apos&#39;: attribs[&#39;apos&#39;] = child.get(&#39;default&#39;) return attribs def read_preposition(file): tree = etree.parse(file) root = tree.getroot() valid_tags = [&#39;sg1&#39;, &#39;sg2&#39;, &#39;sg3Masc&#39;, &#39;sg3Fem&#39;, &#39;pl1&#39;, &#39;pl2&#39;, &#39;pl3&#39;] attribs = {} forms = [] if root.tag != &#39;preposition&#39;: raise BuNaMoWrongDocument(&#39;preposition&#39;, root.tag) attribs[&#39;default&#39;] = root.get(&#39;default&#39;) for child in root: if child.tag not in valid_tags: raise Exception(&#39;Unexpected tag &#39; + child.tag) attribs[child.tag] = child.get(&#39;default&#39;) return attribs . import glob import json adjectives = {} for x in glob.glob(&#39;../input/bunamo-bunachar-naisiunta-moirfeolaiochta/adjective/*.xml&#39;): fname = x.split(&#39;/&#39;)[-1].replace(&#39;.xml&#39;, &#39;&#39;) attribs, forms = read_adjective(x) tmp = {} tmp[&#39;attributes&#39;] = attribs tmp[&#39;forms&#39;] = forms adjectives[fname] = tmp word = attribs[&#39;default&#39;] with open(&#39;adjectives.json&#39;, &#39;w&#39;) as outfile: json.dump(adjectives, outfile) . nouns = {} for x in glob.glob(&#39;../input/bunamo-bunachar-naisiunta-moirfeolaiochta/noun/*.xml&#39;): fname = x.split(&#39;/&#39;)[-1].replace(&#39;.xml&#39;, &#39;&#39;) attribs, forms = read_noun(x) tmp = {} tmp[&#39;attributes&#39;] = attribs tmp[&#39;forms&#39;] = forms nouns[fname] = tmp word = attribs[&#39;default&#39;] with open(&#39;nouns.json&#39;, &#39;w&#39;) as outfile: json.dump(nouns, outfile) . nounphrases = {} for x in glob.glob(&#39;../input/bunamo-bunachar-naisiunta-moirfeolaiochta/nounPhrase/*.xml&#39;): fname = x.split(&#39;/&#39;)[-1].replace(&#39;.xml&#39;, &#39;&#39;) attribs, forms = read_nounphrase(x) tmp = {} tmp[&#39;attributes&#39;] = attribs tmp[&#39;forms&#39;] = forms nounphrases[fname] = tmp word = attribs[&#39;default&#39;] with open(&#39;nounphrases.json&#39;, &#39;w&#39;) as outfile: json.dump(nounphrases, outfile) . verbs = {} for x in glob.glob(&#39;../input/bunamo-bunachar-naisiunta-moirfeolaiochta/verb/*.xml&#39;): fname = x.split(&#39;/&#39;)[-1].replace(&#39;.xml&#39;, &#39;&#39;) attribs, forms = read_verb(x) tmp = {} tmp[&#39;attributes&#39;] = attribs tmp[&#39;forms&#39;] = forms verbs[fname] = tmp word = attribs[&#39;default&#39;] with open(&#39;verbs.json&#39;, &#39;w&#39;) as outfile: json.dump(verbs, outfile) . preposition = {} for x in glob.glob(&#39;../input/bunamo-bunachar-naisiunta-moirfeolaiochta/preposition/*.xml&#39;): fname = x.split(&#39;/&#39;)[-1].replace(&#39;.xml&#39;, &#39;&#39;) attribs = read_preposition(x) tmp = {} tmp[&#39;attributes&#39;] = attribs preposition[fname] = tmp with open(&#39;prepositions.json&#39;, &#39;w&#39;) as outfile: json.dump(preposition, outfile) . possessive = {} for x in glob.glob(&#39;../input/bunamo-bunachar-naisiunta-moirfeolaiochta/possessive/*.xml&#39;): fname = x.split(&#39;/&#39;)[-1].replace(&#39;.xml&#39;, &#39;&#39;) attribs = read_possessive(x) tmp = {} tmp[&#39;attributes&#39;] = attribs possessive[fname] = tmp with open(&#39;possessives.json&#39;, &#39;w&#39;) as outfile: json.dump(possessive, outfile) . possessive . {&#39;√°r_poss&#39;: {&#39;attributes&#39;: {&#39;default&#39;: &#39;√°r&#39;, &#39;disambig&#39;: &#39;&#39;, &#39;mutation&#39;: &#39;ecl1&#39;}}, &#39;a_poss_masc&#39;: {&#39;attributes&#39;: {&#39;default&#39;: &#39;a&#39;, &#39;disambig&#39;: &#39;masc&#39;, &#39;mutation&#39;: &#39;len1&#39;}}, &#39;a_poss_fem&#39;: {&#39;attributes&#39;: {&#39;default&#39;: &#39;a&#39;, &#39;disambig&#39;: &#39;fem&#39;, &#39;mutation&#39;: &#39;prefH&#39;}}, &#39;do_poss&#39;: {&#39;attributes&#39;: {&#39;default&#39;: &#39;do&#39;, &#39;disambig&#39;: &#39;&#39;, &#39;mutation&#39;: &#39;len1&#39;, &#39;apos&#39;: &#34;d&#39;&#34;}}, &#39;a_poss_pl&#39;: {&#39;attributes&#39;: {&#39;default&#39;: &#39;a&#39;, &#39;disambig&#39;: &#39;pl&#39;, &#39;mutation&#39;: &#39;ecl1&#39;}}, &#39;mo_poss&#39;: {&#39;attributes&#39;: {&#39;default&#39;: &#39;mo&#39;, &#39;disambig&#39;: &#39;&#39;, &#39;mutation&#39;: &#39;len1&#39;, &#39;apos&#39;: &#34;m&#39;&#34;}}, &#39;bhur_poss&#39;: {&#39;attributes&#39;: {&#39;default&#39;: &#39;bhur&#39;, &#39;disambig&#39;: &#39;&#39;, &#39;mutation&#39;: &#39;ecl1&#39;}}} .",
            "url": "https://jimregan.github.io/notes/irish/bunamo/kaggle/2021/04/24/bunamo-raw-json.html",
            "relUrl": "/irish/bunamo/kaggle/2021/04/24/bunamo-raw-json.html",
            "date": " ‚Ä¢ Apr 24, 2021"
        }
        
    
  
    
        ,"post112": {
            "title": "Kashubian PDF corpus 1",
            "content": "!wget $(lynx -dump http://skarbnicakaszubska.pl/najo-uczba/|grep pdf|awk &#39;{print $NF}&#39;) . For the most part, the text extracted from the pdfs is fine as is; one of the files has multiple articles, several with translations, making it potentially useful as a parallel corpus. . The text (seems to) come out fine with pdftotext, so I haven&#39;t bothered doing anything else. . !pdftotext -nopgbrk -f 9 -l 10 ZKP_biuletynRJK_2015_internet.pdf - | grep -v &#39;BIU¬≠L E¬≠T IN RADZ√ãZN√ã KASZ√ãBSCZ√âG√í J√ÉZ√ãKA 2015&#39;|grep -v &#39;^10&#39;|grep -v &#39;^$&#39; &gt; ZKP_biuletynRJK_2015_internet_1.csb.txt . !pdftotext -nopgbrk -f 11 -l 12 ZKP_biuletynRJK_2015_internet.pdf - | grep -v &#39;BIU¬≠L E¬≠T YN RADY JƒòZYKA KASZUBSKIEGO 2015&#39;|grep -v &#39;^12&#39;|grep -v &#39;^$&#39; &gt; ZKP_biuletynRJK_2015_internet_1.pl.txt . !pdftotext -nopgbrk -f 14 -l 20 ZKP_biuletynRJK_2015_internet.pdf - | grep -v &#39;BIU¬≠L E¬≠T IN RADZ√ãZN√ã KASZ√ãBSCZ√âG√í J√ÉZ√ãKA 2015&#39;|grep -v &#39;^P√≤stanowienia Radz√´zn√´ Kasz√´bscz√©g√≤ J√£z√´ka&#39;|grep -v &#39;^$&#39;|grep -v &#39;^1[5-9]$&#39;|grep -v &#39;^20$&#39; &gt; ZKP_biuletynRJK_2015_internet_wl1.txt . !pdftotext -nopgbrk -f 21 -l 23 ZKP_biuletynRJK_2015_internet.pdf - | grep -v &#39;BIU¬≠L E¬≠T IN RADZ√ãZN√ã KASZ√ãBSCZ√âG√í J√ÉZ√ãKA 2015&#39;|grep -v &#39;^P√≤stanowienia Radz√´zn√´ Kasz√´bscz√©g√≤ J√£z√´ka&#39;|grep -v &#39;^$&#39;|grep -v &#39;^2[1-9]$&#39; &gt; ZKP_biuletynRJK_2015_internet_wl2.txt . !pdftotext -nopgbrk -f 24 -l 29 ZKP_biuletynRJK_2015_internet.pdf - | grep -v &#39;BIU¬≠L E¬≠T IN RADZ√ãZN√ã KASZ√ãBSCZ√âG√í J√ÉZ√ãKA 2015&#39;|grep -v &#39;^P√≤stanowienia Radz√´zn√´ Kasz√´bscz√©g√≤ J√£z√´ka&#39;|grep -v &#39;^$&#39;|grep -v &#39;^2[1-9]$&#39; &gt; ZKP_biuletynRJK_2015_internet_wl3.txt . !pdftotext -nopgbrk -f 30 -l 48 ZKP_biuletynRJK_2015_internet.pdf - | grep -v &#39;BIU¬≠L E¬≠T IN RADZ√ãZN√ã KASZ√ãBSCZ√âG√í J√ÉZ√ãKA 2015&#39;|grep -v &#39;^P√≤stanowienia Radz√´zn√´ Kasz√´bscz√©g√≤ J√£z√´ka&#39;|grep -v &#39;^$&#39;|grep -v &#39;^[34][0-9]$&#39; &gt; ZKP_biuletynRJK_2015_internet_wl4.txt . !pdftotext -nopgbrk -f 49 -l 49 ZKP_biuletynRJK_2015_internet.pdf - | grep -v &#39;BIU¬≠L E¬≠T IN RADZ√ãZN√ã KASZ√ãBSCZ√âG√í J√ÉZ√ãKA 2015&#39;|grep -v &#39;^P√≤stanowienia Radz√´zn√´ Kasz√´bscz√©g√≤ J√£z√´ka&#39;|grep -v &#39;^$&#39;|grep -v &#39;^[34][0-9]$&#39; &gt; ZKP_biuletynRJK_2015_internet_wl5.txt . !pdftotext -nopgbrk -f 50 -l 65 ZKP_biuletynRJK_2015_internet.pdf - | grep -v &#39;BIU¬≠L E¬≠T IN RADZ√ãZN√ã KASZ√ãBSCZ√âG√í J√ÉZ√ãKA 2015&#39;|grep -v &#39;^P√≤stanowienia Radz√´zn√´ Kasz√´bscz√©g√≤ J√£z√´ka&#39;|grep -v &#39;^$&#39;|grep -v &#39;^[56][0-9]$&#39; &gt; ZKP_biuletynRJK_2015_internet_wl6.txt . def runner(file, start, end, suffix): base = file.replace(&#39;.pdf&#39;, &#39;&#39;) outfile = f&quot;{base}_{suffix}.txt&quot; !pdftotext -nopgbrk -f {start} -l {end} {file} - | grep -v &#39;BIU¬≠L E¬≠T IN RADZ√ãZN√ã KASZ√ãBSCZ√âG√í J√ÉZ√ãKA 2015&#39;|grep -v &#39;BIU¬≠L E¬≠T YN RADY JƒòZYKA KASZUBSKIEGO 2015&#39;|grep -v &#39;^P√≤stanowienia Radz√´zn√´ Kasz√´bscz√©g√≤ J√£z√´ka&#39;|grep -v &#39;^$&#39;|grep -v &#39;^[0-9][0-9]$&#39;|grep -v &#39;^[1-4][0-9][0-9]$&#39; &gt; {outfile} . runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 68, 74, &#39;wl7&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 75, 77, &#39;wl8&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 78, 83, &#39;wl9&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 84, 102, &#39;wl10&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 103, 103, &#39;wl11&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 104, 119, &#39;wl12&#39;) . runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 122, 128, &#39;csb2&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 129, 132, &#39;csb3&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 133, 144, &#39;csb4&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 145, 151, &#39;csb5&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 153, 161, &#39;csb6&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 162, 166, &#39;csb7&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 168, 178, &#39;csb8&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 179, 185, &#39;csb9&#39;) # it took me this long to remember that there&#39;s a table of contents! runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 186, 197, &#39;csb10&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 198, 204, &#39;csb11&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 205, 211, &#39;csb12&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 212, 220, &#39;csb13&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 222, 228, &#39;pl2&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 229, 237, &#39;plx1&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 238, 241, &#39;pl3&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 242, 248, &#39;plx2&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 249, 254, &#39;plx3&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 255, 266, &#39;pl4&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 267, 274, &#39;pl5&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 275, 283, &#39;pl6&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 284, 289, &#39;pl7&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 290, 300, &#39;plx4&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 301, 313, &#39;pl8&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 314, 320, &#39;pl9&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 5, 8, &#39;toc&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 321, 333, &#39;pl10&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 334, 359, &#39;plx5&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 360, 367, &#39;pl11&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 368, 374, &#39;pl12&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 375, 390, &#39;plx6&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 391, 396, &#39;plx7&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 397, 404, &#39;pl13&#39;) . Now, the rest . !for i in [0-9N]*.pdf;do pdftotext $i;done . uname=!uname -a if not &#39;LAPTOP-6PFTN7M9&#39; in uname: !rm *.pdf .",
            "url": "https://jimregan.github.io/notes/kashubian/lazyscrape/2021/04/23/najo-uczba-pdfs.html",
            "relUrl": "/kashubian/lazyscrape/2021/04/23/najo-uczba-pdfs.html",
            "date": " ‚Ä¢ Apr 23, 2021"
        }
        
    
  
    
        ,"post113": {
            "title": "Checking a Kashubian adjective-like declension",
            "content": "def _list_to_check(pos): num = [&#39;sg&#39;, &#39;pl&#39;] gen = [&#39;mp&#39;, &#39;ma&#39;, &#39;mi&#39;, &#39;f&#39;, &#39;nt&#39;] cas = [&#39;nom&#39;, &#39;gen&#39;, &#39;dat&#39;, &#39;acc&#39;, &#39;ins&#39;, &#39;loc&#39;, &#39;voc&#39;] out = [] for n in num: for g in gen: for c in cas: out.append(f&quot;{pos}.{g}.{n}.{c}&quot;) return out . len(_list_to_check(&#39;num.ord&#39;)) . 70 . dredzi = &quot;&quot;&quot; dr√´d≈ºi dr√´d≈ºi num.ord.mp|ma|mi.sg.nom|voc dr√´g√¥ dr√´d≈ºi num.ord.f.sg.nom|voc dr√´d≈º√© dr√´d≈ºi num.ord.nt.sg.nom|acc|voc dr√´gƒÖ dr√´d≈ºi num.ord.f.sg.acc|ins dr√´d≈ºi dr√´d≈ºi num.ord.f.sg.gen|dat|loc dr√´d≈ºim dr√´d≈ºi num.ord.mp|ma|mi|nt.sg.loc|ins dr√´d≈º√© dr√´d≈ºi num.ord.nt|f|mi|ma.pl.nom|acc|voc dr√´d≈ºich dr√´d≈ºi num.ord.nt|f|mi|ma|mp.pl.gen|loc dr√´d≈ºima dr√´d≈ºi num.ord.nt|f|mi|ma.pl.ins dr√´d≈º√©g√≤ dr√´d≈ºi num.ord.nt|mi|ma|mp.sg.gen dr√´d≈º√©g√≤ dr√´d≈ºi num.ord.ma|mp.sg.acc dr√´d≈º√©m√π dr√´d≈ºi num.ord.nt|mi|ma|mp.sg.dat dr√´d≈ºi dr√´d≈ºi num.ord.mp.pl.nom|voc dr√´d≈ºich dr√´d≈ºi num.ord.mp.pl.acc dr√´d≈ºim dr√´d≈ºi num.ord.nt|f|mi|ma|mp.pl.dat &quot;&quot;&quot; . def _do_expand(stack, todo): onward = [] if not &#39;.&#39; in todo: return [f&#39;{a}.{b}&#39; for a in stack for b in todo.split(&#39;|&#39;)] cur, rest = todo.split(&#39;.&#39;, 1) if stack == []: onward = cur.split(&#39;|&#39;) return _do_expand(onward, rest) else: onward = [f&#39;{a}.{b}&#39; for a in stack for b in cur.split(&#39;|&#39;)] return _do_expand(onward, rest) def expand_compressed(lines): output = [] for i in lines: form, lemma, postag = i.split(&#39; t&#39;) newtags = _do_expand([], postag) output.extend([f&quot;{form} t{lemma} t{itag}&quot; for itag in newtags]) return output . expand_compressed([l for l in dredzi.split(&#39; n&#39;) if l != &#39;&#39;]) . vals = expand_compressed([l for l in dredzi.split(&#39; n&#39;) if l != &#39;&#39;]) . tags = [a.split(&#39; t&#39;)[-1] for a in vals] . for tc in _list_to_check(&#39;num.ord&#39;): if not tc in tags: print(tc) . num.ord.mi.sg.acc num.ord.mp.pl.ins . dredzi = &quot;&quot;&quot; dr√´d≈ºi dr√´d≈ºi num.ord.mp|ma|mi.sg.nom|voc dr√´d≈ºi dr√´d≈ºi num.ord.mi.sg.acc dr√´g√¥ dr√´d≈ºi num.ord.f.sg.nom|voc dr√´d≈º√© dr√´d≈ºi num.ord.nt.sg.nom|acc|voc dr√´gƒÖ dr√´d≈ºi num.ord.f.sg.acc|ins dr√´d≈ºi dr√´d≈ºi num.ord.f.sg.gen|dat|loc dr√´d≈ºim dr√´d≈ºi num.ord.mp|ma|mi|nt.sg.loc|ins dr√´d≈º√© dr√´d≈ºi num.ord.nt|f|mi|ma.pl.nom|acc|voc dr√´d≈ºich dr√´d≈ºi num.ord.nt|f|mi|ma|mp.pl.gen|loc dr√´d≈ºima dr√´d≈ºi num.ord.nt|f|mi|ma|mp.pl.ins dr√´d≈º√©g√≤ dr√´d≈ºi num.ord.nt|mi|ma|mp.sg.gen dr√´d≈º√©g√≤ dr√´d≈ºi num.ord.ma|mp.sg.acc dr√´d≈º√©m√π dr√´d≈ºi num.ord.nt|mi|ma|mp.sg.dat dr√´d≈ºi dr√´d≈ºi num.ord.mp.pl.nom|voc dr√´d≈ºich dr√´d≈ºi num.ord.mp.pl.acc dr√´d≈ºim dr√´d≈ºi num.ord.nt|f|mi|ma|mp.pl.dat &quot;&quot;&quot; .",
            "url": "https://jimregan.github.io/notes/kashubian/declension/2021/04/23/check-kashubian-adjlike.html",
            "relUrl": "/kashubian/declension/2021/04/23/check-kashubian-adjlike.html",
            "date": " ‚Ä¢ Apr 23, 2021"
        }
        
    
  
    
        ,"post114": {
            "title": "Title",
            "content": "&gt; &quot;Train a model for MFA on Irish data on Kaggle&quot; - toc: false - branch: master - hidden: true - categories: [kaggle, irish, mfa] . Original on [Kaggle](https://www.kaggle.com/jimregan/train-irish-mfa-model) . %%capture import os os.chdir(&#39;/tmp&#39;) !wget https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/releases/download/v1.0.1/montreal-forced-aligner_linux.tar.gz !tar zxvf montreal-forced-aligner_linux.tar.gz !ln -s /tmp/montreal-forced-aligner/lib/libpython3.6m.so.1.0 /tmp/montreal-forced-aligner/lib/libpython3.6m.so . os.chdir(&#39;/kaggle/working&#39;) os.environ[&#39;LD_LIBRARY_PATH&#39;] = f&#39;{os.environ[&quot;LD_LIBRARY_PATH&quot;]}:/tmp/montreal-forced-aligner/lib/&#39; os.environ[&#39;PATH&#39;] = f&#39;{os.environ[&quot;PATH&quot;]}:/tmp/montreal-forced-aligner/bin/&#39; . %%capture !yes|apt install libgfortran3 . !mkdir /tmp/mfa-temp . import json datapath = &#39;../input/living-audio-irish-speech-corpus/living-audio.json&#39; with open(datapath) as jsonf: data = json.load(jsonf) . !mkdir /tmp/living-audio . lexicon_words = set() with open(&#39;../input/living-audio-irish-speech-corpus/lexicon.txt&#39;) as lexicon_file: for line in lexicon_file.readlines(): words = line.split(&#39; &#39;) lexicon_words.add(words[0]) . import shutil missing_words = set() for utt in data: shutil.copyfile(utt[&#39;path&#39;], f&quot;/tmp/living-audio/{utt[&#39;id&#39;]}.wav&quot;) with open(f&quot;/tmp/living-audio/{utt[&#39;id&#39;]}.txt&quot;, &#39;w&#39;) as text: sentence = utt[&#39;sentence&#39;] sentence = sentence.replace(&#39;(&#39;, &#39;&#39;).replace(&#39;)&#39;, &#39;&#39;) words = [] for word in sentence.split(&#39; &#39;): if not word in lexicon_words: missing_words.add(word) if &#39;-&#39; in word: if word.startswith(&#39;n-&#39;) or word.startswith(&#39;t-&#39;): workword = word[2:] workword.replace(&#39;-&#39;, &#39; &#39;) word = word[0:2] + workword else: word = word.replace(&#39;-&#39;, &#39; &#39;) words.append(word) text.write(&#39; &#39;.join(words)) . !mfa_train_and_align -t /tmp/mfa-temp -o ./irish-model /tmp/living-audio ../input/living-audio-irish-speech-corpus/lexicon.txt ./textgrid . Setting up corpus information... Creating dictionary information... Setting up training data... Calculating MFCCs... Calculating CMVN... Number of speakers in corpus: 1, average number of utterances per speaker: 1121.0 b&#39;number of phones 215 nnumber of pdfs 165 nnumber of transition-ids 1470 nnumber of transition-states 675 nfeature dimension 39 nnumber of gaussians 165 n&#39; None b&#39;number of phones 215 nnumber of pdfs 165 nnumber of transition-ids 1470 nnumber of transition-states 675 nfeature dimension 39 nnumber of gaussians 165 n&#39; None Beginning monophone training... 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [25:35&lt;00:00, 21.13s/it] Initializing triphone training... Beginning triphone training... 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 34/34 [19:09&lt;00:00, 16.35s/it] Initializing speaker-adapted triphone training... Beginning speaker-adapted triphone training... 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 34/34 [08:55&lt;00:00, 8.33s/it] Saved model to ./irish-model .",
            "url": "https://jimregan.github.io/notes/2021/04/22/train-irish-mfa-model.html",
            "relUrl": "/2021/04/22/train-irish-mfa-model.html",
            "date": " ‚Ä¢ Apr 22, 2021"
        }
        
    
  
    
        ,"post115": {
            "title": "Kashubian - extract text from tlog",
            "content": "import json with open(&quot;/tmp/csb/kashubian-data.json&quot;, &quot;r&quot;) as read_file: data = json.load(read_file) . for datum in data: file = datum[&#39;audio&#39;].split(&#39;/&#39;)[-1].replace(&#39;.ogg&#39;, &#39;.txt&#39;) with open(f&#39;/tmp/csb/{file}&#39;, &#39;w&#39;) as f: text = &#39; n&#39;.join([a.strip() for a in datum[&#39;text&#39;].split(&#39; n&#39;) if a.strip() != &#39;&#39;]) f.write(text) . import glob for file in glob.glob(&#39;/tmp/csb/*.ogg.wav.tlog&#39;): outfile = file.replace(&#39;.ogg.wav.tlog&#39;, &#39;.rec.txt&#39;) with open(file, &quot;r&quot;) as tlog: data = json.load(tlog) with open(outfile, &quot;w&quot;) as rectxt: for datum in data: rectxt.write(f&quot;{datum[&#39;transcript&#39;]} n&quot;) .",
            "url": "https://jimregan.github.io/notes/asr/kashubian/2021/04/22/kashubian-extract-text-from-tlog.html",
            "relUrl": "/asr/kashubian/2021/04/22/kashubian-extract-text-from-tlog.html",
            "date": " ‚Ä¢ Apr 22, 2021"
        }
        
    
  
    
        ,"post116": {
            "title": "Training MFA G2P on fuaimeanna.ie",
            "content": "Original on Kaggle . %%capture import os os.chdir(&#39;/tmp&#39;) !wget https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/releases/download/v1.0.1/montreal-forced-aligner_linux.tar.gz !tar zxvf montreal-forced-aligner_linux.tar.gz !ln -s /tmp/montreal-forced-aligner/lib/libpython3.6m.so.1.0 /tmp/montreal-forced-aligner/lib/libpython3.6m.so . os.chdir(&#39;/kaggle/working&#39;) os.environ[&#39;LD_LIBRARY_PATH&#39;] = f&#39;{os.environ[&quot;LD_LIBRARY_PATH&quot;]}:/tmp/montreal-forced-aligner/lib/&#39; . os.environ[&#39;PATH&#39;] = f&#39;{os.environ[&quot;PATH&quot;]}:/tmp/montreal-forced-aligner/bin/&#39; . !mkdir /tmp/mfa-temp . !mfa_train_g2p -t /tmp/mfa-temp ../input/living-audio-irish-speech-corpus/lexicon.txt ./g2p-model . GitRevision: kaldi-6-g64719c Loading input file: /tmp/mfa-temp/g2p-model/input.txt Starting EM... Finished first iter... Iteration: 1 Change: 3.18428 Iteration: 2 Change: 0.068243 Iteration: 3 Change: 0.0359888 Iteration: 4 Change: 0.00983238 Iteration: 5 Change: 0.00348759 Iteration: 6 Change: 0.00150681 Iteration: 7 Change: 0.00084877 Iteration: 8 Change: 0.000713348 Iteration: 9 Change: 0.000318527 Iteration: 10 Change: 0.000238419 Iteration: 11 Change: 0.000259399 Last iteration: GitRevision: kaldi-6-g64719c Initializing... Converting... Saved model to ./g2p-model .",
            "url": "https://jimregan.github.io/notes/kaggle/mfa/fuaimeanna/2021/04/21/train-irish-g2p-model-with-mfa.html",
            "relUrl": "/kaggle/mfa/fuaimeanna/2021/04/21/train-irish-g2p-model-with-mfa.html",
            "date": " ‚Ä¢ Apr 21, 2021"
        }
        
    
  
    
        ,"post117": {
            "title": "Installing montreal-forced-aligner on kaggle",
            "content": "%%capture !wget https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/releases/download/v1.0.1/montreal-forced-aligner_linux.tar.gz . %%capture !tar zxvf montreal-forced-aligner_linux.tar.gz !rm montreal-forced-aligner_linux.tar.gz . !mv montreal-forced-aligner/bin montreal-forced-aligner/bb . !ln -s montreal-forced-aligner/lib/libpython3.6m.so.1.0 montreal-forced-aligner/lib/libpython3.6m.so .",
            "url": "https://jimregan.github.io/notes/kaggle/itworks/2021/04/20/mfa-on-kaggle.html",
            "relUrl": "/kaggle/itworks/2021/04/20/mfa-on-kaggle.html",
            "date": " ‚Ä¢ Apr 20, 2021"
        }
        
    
  
    
        ,"post118": {
            "title": "Title",
            "content": "&gt; &quot;[Incomplete]&quot; - toc: false - branch: master - hidden: true - categories: [irish, g2p, icu, incomplete] . import icu . def transliterator_from_rules(name, rules): fromrules = icu.Transliterator.createFromRules(name, rules) icu.Transliterator.registerInstance(fromrules) return icu.Transliterator.createInstance(name) . irishlc_rules = &quot;&quot;&quot; :: NFD; $uvowel=[AEIOU]; $wb=[^[:L:][:M:]]; $wb { ([nt]) } $uvowel ‚Üí $1 &#39;-&#39;; :: lower; :: NFC; &quot;&quot;&quot; . irishlc = transliterator_from_rules(&#39;irishlc&#39;, irishlc_rules) . ulster_stress_rules = &quot;&quot;&quot; $wb=[^[:L:][:M:]]; $cons = [bcdfghjklmnpqrstvwxyz]; $vowel = [aeiou√°√©√≠√≥√∫]; $bvowel = [aou√°√≥√∫{ae}]; $svowel = [ei√©√≠]; :: irishlc; $wb { anois } $wb ‚Üí an&#39;Àà&#39;ois; $wb { ar√≠s } $wb ‚Üí air&#39;Àà&#39;√≠s; $wb { isteach } $wb ‚Üí ist&#39;Àà&#39;each; $wb { istigh } $wb ‚Üí ist&#39;Àà&#39;igh; $wb { amach } $wb ‚Üí am&#39;Àà&#39;ach; $wb $cons* { ($vowel) ‚Üí &#39;Àà&#39;$1; &quot;&quot;&quot; . stress = transliterator_from_rules(&#39;ulster_stress&#39;, ulster_stress_rules) . stress.transliterate(&quot;amach&quot;) . &#39;amÀàach&#39; . ulster_g2p_rules = &quot;&quot;&quot; $wb=[^[:L:][:M:]]; $cons = [bcdfghjklmnpqrstvwxyz]; # when we transliterate past the first consonant, # we need to use the transliteration as context $scons = [{b ≤}c√ß{d ≤}{f ≤}…ü{m ≤}{…¥ ≤} É{t ≤}{v ≤}{GJ}{DJ}{BJ}{MJ}]; $bcons = [{bÀ†}{kÀ†}x{dÀ†}{fÀ†}{gÀ†}{mÀ†}{…¥À†}{sÀ†}{tÀ†}w{GH}{DH}{BH}{MH}]; $vowel = [aeiou√°√©√≠√≥√∫]; $bvowel = [aou√°√≥√∫{ae}]; $svowel = [ei√©√≠]; $apos = [‚Äô &#39;]; $bfce = [{√°}{adh}{aidh}{aid√≠s}{aimid}{aimis}{ainn}{as}]; $sfce = [{e√°}{eadh}{idh}{id√≠s}{imid}{imis}{inn}]; $ps = &#39;Àà&#39;; :: irishlc; :: ulster_stress; $wb { mb $apos? } $cons* Àà? $bvowel ‚Üí mÀ†; $wb { mb $apos? } $cons* Àà? $svowel ‚Üí m ≤; #$bvowel $bcons* { bh ‚Üí w; #bh } $cons* Àà? $bvowel ‚Üí w; #$svowel $scons* { bh ‚Üí v ≤; #bh } $cons* Àà? $svowel ‚Üí v ≤; $bvowel $bcons* { bh ‚Üí BH; bh } $cons* Àà? $bvowel ‚Üí BH; $svowel $scons* { bh ‚Üí BJ; bh } $cons* Àà? $svowel ‚Üí BJ; bf } $bfce $wb ‚Üí pÀ†; bf } $sfce $wb ‚Üí p ≤; $bvowel $bcons* { b ‚Üí bÀ†; b } $cons* Àà? $bvowel ‚Üí bÀ†; $svowel $scons* { b ‚Üí b ≤; b } $cons* Àà? $svowel ‚Üí b ≤; # gKim/Khim are things that happen too $wb { gc } $cons* Àà? $bvowel ‚Üí gÀ†; $wb { gc } $cons* Àà? $svowel ‚Üí …ü; $bvowel $bcons* { ch ‚Üí x; ch } $cons* Àà? $bvowel ‚Üí x; $svowel $scons* { ch ‚Üí √ß; ch } $cons* Àà? $svowel ‚Üí √ß; $bvowel $bcons* { [ck] ‚Üí kÀ†; [ck] } $cons* Àà? $bvowel ‚Üí kÀ†; $svowel $scons* { [ck] ‚Üí c; [ck] } $cons* Àà? $svowel ‚Üí c; $wb { nd } $cons* Àà? $bvowel ‚Üí …¥À†; $wb { nd } $cons* Àà? $svowel ‚Üí …¥ ≤; $wb { dh $apos? } $cons* Àà? $bvowel ‚Üí …£; $wb { dh $apos? } $cons* Àà? $svowel ‚Üí j; # can&#39;t do this here, because the next pass does diphthongs #$bvowel $bcons* { dh ‚Üí …£; #dh } $cons* Àà? $bvowel ‚Üí …£; #$svowel $scons* { dh ‚Üí j; #dh } $cons* Àà? $svowel ‚Üí j; $bvowel $bcons* { dh ‚Üí DH; dh } $cons* Àà? $bvowel ‚Üí DH; $svowel $scons* { dh ‚Üí DJ; dh } $cons* Àà? $svowel ‚Üí DJ; $wb { d $apos? } $cons* Àà? $bvowel ‚Üí dÀ†; $wb { d $apos? } $cons* Àà? $svowel ‚Üí d ≤; $bvowel $bcons* { d ‚Üí dÀ†; d } $cons* Àà? $bvowel ‚Üí dÀ†; $svowel $scons* { d ‚Üí d ≤; d } $cons* Àà? $svowel ‚Üí d ≤; j ‚Üí d ≤ ; $wb { bhf } $cons* Àà? $bvowel ‚Üí w; $wb { bhf } $cons* Àà? $svowel ‚Üí v ≤; fh ‚Üí ; $bvowel $bcons* { f ‚Üí fÀ†; f } $cons* Àà? $bvowel ‚Üí fÀ†; $svowel $scons* { f ‚Üí f ≤; f } $cons* Àà? $svowel ‚Üí f ≤; # can&#39;t do this here, because the next pass does diphthongs #$bvowel $bcons* { gh ‚Üí …£; #gh } $cons* Àà? $bvowel ‚Üí …£; #$svowel $scons* { gh ‚Üí j; #gh } $cons* Àà? $svowel ‚Üí j; $bvowel $bcons* { gh ‚Üí GH; gh } $cons* Àà? $bvowel ‚Üí GH; $svowel $scons* { gh ‚Üí GJ; gh } $cons* Àà? $svowel ‚Üí GJ; $bvowel $bcons* { g ‚Üí gÀ†; g } $cons* Àà? $bvowel ‚Üí gÀ†; $svowel $scons* { g ‚Üí …ü; g } $cons* Àà? $svowel ‚Üí …ü; $wb { l } Àà? $svowel ‚Üí  ü ≤; $bvowel $bcons* { ll ‚Üí  üÀ†; ll } $cons* Àà? $bvowel ‚Üí  üÀ†; $svowel $scons* { ll ‚Üí  ü ≤; ll } $cons* Àà? $svowel ‚Üí  ü ≤; $bvowel $bcons* { l ‚Üí  üÀ†; l } $cons* Àà? $bvowel ‚Üí  üÀ†; $svowel $scons* { l ‚Üí l ≤; l } $cons* Àà? $svowel ‚Üí l ≤; #$bvowel $bcons* { mh ‚Üí w; #mh } $cons* Àà? $bvowel ‚Üí w; #$svowel $scons* { mh ‚Üí v ≤; #mh } $cons* Àà? $svowel ‚Üí v ≤; $bvowel $bcons* { mh ‚Üí MH; mh } $cons* Àà? $bvowel ‚Üí MH; $svowel $scons* { mh ‚Üí MJ; mh } $cons* Àà? $svowel ‚Üí MJ; $wb { m $apos? } $cons* Àà? $bvowel ‚Üí mÀ†; $wb { m $apos? } $cons* Àà? $svowel ‚Üí m ≤; $bvowel $bcons* { m ‚Üí mÀ†; m } $cons* Àà? $bvowel ‚Üí mÀ†; $svowel $scons* { m ‚Üí m ≤; m } $cons* Àà? $svowel ‚Üí m ≤; $wb { bp } $cons* Àà? $bvowel ‚Üí bÀ†; $wb { bp } $cons* Àà? $svowel ‚Üí b ≤; $bvowel $bcons* { ph ‚Üí fÀ†; ph } $cons* Àà? $bvowel ‚Üí fÀ†; $svowel $scons* { ph ‚Üí f ≤; ph } $cons* Àà? $svowel ‚Üí f ≤; $bvowel $bcons* { p ‚Üí pÀ†; p } $cons* Àà? $bvowel ‚Üí pÀ†; $svowel $scons* { p ‚Üí p ≤; p } $cons* Àà? $svowel ‚Üí p ≤; $wb { r ‚Üí …æÀ†; [st]hr } Àà? $bvowel ‚Üí rÃ™À† ; [st]hr } Àà? $svowel ‚Üí rÃ™ ≤ ; $bvowel $cons* { [st]hr ‚Üí rÃ™À†; [st]hr } Àà? $bvowel ‚Üí rÃ™À† ; $svowel $cons* { [st]hr ‚Üí rÃ™ ≤; [st]hr } Àà? $svowel ‚Üí rÃ™ ≤ ; $wb { sh } Àà? [{e√°}{e√°i}{eoi}{eo}{i√∫i}{i√∫}] ‚Üí √ß ; [st]h ‚Üí h ; h ‚Üí h ; $bvowel $cons* { s ‚Üí sÀ†; s } $cons* Àà? $bvowel ‚Üí sÀ†; $svowel $cons* { s ‚Üí  É; s } $cons* Àà? $svowel ‚Üí  É; $bvowel $bcons* { t ‚Üí tÀ†; t } $cons* Àà? $bvowel ‚Üí tÀ†; $svowel $scons* { t ‚Üí t ≤; t } $cons* Àà? $svowel ‚Üí t ≤; # &#39;oi&#39; can represent either: # * &#39;o&#39; before a slender consonant # * &#39;i&#39; after a broad consonant # &#39;goitse&#39; can be either, I think, but abair says /i/ ([…™]) (I&#39;ve only ever heard /o/ ([ å])) $wb g $ps { oi } tse $wb ‚Üí i ; $wb an $ps { oi } s $wb ‚Üí i ; :: null; e?a DH ai? ‚Üí eÀê; $ps { e?a DH ‚Üí eÀê; e?a DH ‚Üí uÀê; $ps { oi [DG]J ‚Üí ai; $ps { [ae]i DJ ‚Üí eÀê; $ps { a?i GJ ‚Üí ai; oi [DG]J ‚Üí …ô; ai [DG]J ‚Üí iÀê; ei DJ ‚Üí …ô; i DJ ‚Üí iÀê; i GJ ‚Üí …ô; o MH } $wb ‚Üí uÀê; o MH ‚Üí oÀê; $ps { o BH ai? ‚Üí au; $ps { o [DG]H a? ‚Üí au; o GH a? ‚Üí …ô; o BH a i? ‚Üí …ô; o DH a ‚Üí …ô; o DH ‚Üí uÀê; $ps { ea [MB]H ai ‚Üí au ; $ps { ea [MB]H a ‚Üí au ; $ps { ea [MB]H ‚Üí au ; $ps { a [MB]H ai ‚Üí au ; $ps { a [MB]H a ‚Üí au ; $ps { a [MB]H ‚Üí au ; ea [MB]H ai ‚Üí …ô ; ea [MB]H a ‚Üí …ô ; ea [MB]H ‚Üí uÀê ; a [MB]H ai ‚Üí …ô ; a [MB]H a ‚Üí …ô ; a [MB]H ‚Üí …ô ; $ps { ei GH ea ‚Üí eÀê; # it seems like abair ought to have this rule, but doesn&#39;t #a GH ai ‚Üí eÀê; # instead this happens (agha + i separately) a GH ai ‚Üí eÀê…ô; a GH a ‚Üí eÀê; $ps { a GH ‚Üí eÀê; ei GH ea ‚Üí …ô; a GH ‚Üí …ô; $ps { e√°i ‚Üí aÀê; $ps { e√° ‚Üí aÀê; $ps { √°i ‚Üí aÀê; $ps { √° ‚Üí aÀê; $ps { aei ‚Üí eÀê; $ps { ae ‚Üí eÀê; $ps { √©i ‚Üí eÀê; $ps { √© ‚Üí eÀê; $ps { u√≠o ‚Üí iÀê; $ps { a√≠o ‚Üí iÀê; $ps { a√≠ ‚Üí iÀê; $ps { u√≠ ‚Üí iÀê; $ps { o√≠ ‚Üí iÀê; $ps { √≠o ‚Üí iÀê; $ps { aoi ‚Üí iÀê; $ps { ao ‚Üí iÀê; $ps { √≠ ‚Üí iÀê; $ps { eoi ‚Üí oÀê; $ps { e√≥ ‚Üí oÀê; $ps { eo ‚Üí oÀê; $ps { i√≥ ‚Üí oÀê; $ps { √≥i ‚Üí oÀê; $ps { √≥ ‚Üí oÀê; e√°i ‚Üí a; e√° ‚Üí a; √°i ‚Üí a; √° ‚Üí a; aei ‚Üí e; ae ‚Üí e; √©i ‚Üí e; √© ‚Üí e; u√≠o ‚Üí i…ô; a√≠o ‚Üí i…ô; a√≠ ‚Üí i; u√≠ ‚Üí i; o√≠ ‚Üí i; √≠o ‚Üí i…ô; aoi ‚Üí i; ao ‚Üí i; √≠ ‚Üí i; eoi ‚Üí …î; e√≥ ‚Üí …î; eo ‚Üí …î; i√≥ ‚Üí …î; √≥i ‚Üí …î; √≥ ‚Üí …î; $ps { i√∫i ‚Üí uÀê; $ps { √∫ai ‚Üí uÀê; $ps { i√∫ ‚Üí uÀê; i√∫ } $wb ‚Üí uÀê; $ps { √∫i ‚Üí uÀê; $ps { √∫ ‚Üí uÀê; √∫ } $wb ‚Üí uÀê; i√∫i ‚Üí u; √∫ai ‚Üí u; i√∫ ‚Üí u; √∫i ‚Üí u; √∫ ‚Üí u; $ps { eai ‚Üí a ; $ps { ea ‚Üí a ; $ps { ai ‚Üí a ; $ps { a ‚Üí a ; $ps { ei ‚Üí e ; $ps { ue ‚Üí e ; $ps { e ‚Üí e ; eai ‚Üí …ô ; ea ‚Üí …ô ; ai ‚Üí …ô ; a ‚Üí …ô ; ei ‚Üí …ô ; ue ‚Üí …ô ; e ‚Üí …ô ; $ps { oi ‚Üí o ; $ps { ui ‚Üí i ; $ps { iu ‚Üí u ; $ps { u ‚Üí u ; $ps { io ‚Üí i ; $ps { i ‚Üí i ; $wb $ps? { o } [r{…æÀ†}] ‚Üí oÀê ; $ps { o ‚Üí o ; oi ‚Üí …ô ; ui ‚Üí …ô ; iu ‚Üí …ô ; io ‚Üí …ô ; u ‚Üí …ô ; i ‚Üí …ô ; o ‚Üí …ô ; DH ‚Üí …£; DJ ‚Üí j; GH ‚Üí …£; GJ ‚Üí j; BH ‚Üí w; BJ ‚Üí v; MH ‚Üí w; MJ ‚Üí v; $ps ‚Üí $ps; &quot;&quot;&quot; . ulster_g2p = transliterator_from_rules(&#39;ulster_g2p&#39;, ulster_g2p_rules) . ulster_g2p.transliterate(&quot;scuaibfe√°&quot;) . &#39;sÀ†kÀ†Ààu…ôp ≤a&#39; .",
            "url": "https://jimregan.github.io/notes/2021/04/19/ulster_g2p.html",
            "relUrl": "/2021/04/19/ulster_g2p.html",
            "date": " ‚Ä¢ Apr 19, 2021"
        }
        
    
  
    
        ,"post119": {
            "title": "Irish lowercase with ICU",
            "content": "import icu . def transliterator_from_rules(name, rules): fromrules = icu.Transliterator.createFromRules(name, rules) icu.Transliterator.registerInstance(fromrules) return icu.Transliterator.createInstance(name) . irishlc_rules = &quot;&quot;&quot; :: NFD; $uvowel=[AEIOU]; $wb=[^[:L:][:M:]]; $wb { ([nt]) } $uvowel ‚Üí $1 &#39;-&#39;; :: lower; :: NFC; &quot;&quot;&quot; . irishlc = transliterator_from_rules(&#39;irishlc&#39;, irishlc_rules) . irishlc.transliterate(&quot;t√° an tUachtar√°n tar √©is a l√°mh a chur leis&quot;) . &#39;t√° an t-uachtar√°n tar √©is a l√°mh a chur leis&#39; .",
            "url": "https://jimregan.github.io/notes/icu/2021/04/18/irish-lower-with-icu.html",
            "relUrl": "/icu/2021/04/18/irish-lower-with-icu.html",
            "date": " ‚Ä¢ Apr 18, 2021"
        }
        
    
  
    
        ,"post120": {
            "title": "Clarin-Studio dataset",
            "content": "The datasets are on the hub: jimregan/clarinpl_studio and jimregan/clarinpl_sejmsenat . !wget http://mowa.clarin-pl.eu/korpusy/audio.tar.gz . !tar zxvf audio.tar.gz . !cat /content/audio/SES0001/spk.txt . SPK0001 . !cat /content/audio/SES0001/sent030.txt . gdy maluch ju≈º siƒô wypluska wytrzyjcie go dok≈Çadnie rƒôcznikiem posmarujcie jeszcze raz kremem przeciws≈Çonecznym i ubierzcie w suche u branie . !head /content/SejmSenat/test/wav.scp.orig . !head /content/SejmSenat/test/spk2utt . !head /content/SejmSenat/train/text . !huggingface-cli login . !huggingface-cli repo create clarinpl_studio --type dataset . !rm -rf clarinpl_studio !git clone https://huggingface.co/datasets/jimregan/clarinpl_studio . Cloning into &#39;clarinpl_studio&#39;... remote: Enumerating objects: 6, done. remote: Counting objects: 100% (6/6), done. remote: Compressing objects: 100% (5/5), done. remote: Total 6 (delta 0), reused 0 (delta 0) Unpacking objects: 100% (6/6), done. . !datasets-cli test clarinpl_studio --save_infos --all_configs . Testing builder &#39;clean&#39; (1/1) Downloading and preparing dataset clarin_pl_studio/clean (download: 4.59 GiB, generated: 4.50 MiB, post-processed: Unknown size, total: 4.60 GiB) to /root/.cache/huggingface/datasets/clarin_pl_studio/clean/2.1.0/733df40ff099ad45628c8c755782c0abb5554817218890a3d232ed359122252c... 0 examples [00:00, ? examples/s]2021-04-15 10:43:00.739700: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0 Dataset clarin_pl_studio downloaded and prepared to /root/.cache/huggingface/datasets/clarin_pl_studio/clean/2.1.0/733df40ff099ad45628c8c755782c0abb5554817218890a3d232ed359122252c. Subsequent calls will reuse this data. 100% 3/3 [00:00&lt;00:00, 176.78it/s] Dataset Infos file saved at clarinpl_studio/dataset_infos.json Test successful. . # coding=utf-8 # Copyright 2021 The TensorFlow Datasets Authors and the HuggingFace Datasets Authors. # Copyright 2021 Jim O&#39;Regan # # Licensed under the Apache License, Version 2.0 (the &quot;License&quot;); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an &quot;AS IS&quot; BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # Lint as: python3 &quot;&quot;&quot;ClarinPL Studio automatic speech recognition dataset.&quot;&quot;&quot; import os import datasets _CITATION = &quot;&quot;&quot; @article{korvzinek2017polish, title={Polish read speech corpus for speech tools and services}, author={Kor{ v{z}}inek, Danijel and Marasek, Krzysztof and Brocki, { L}ukasz and Wo{ l}k, Krzysztof}, journal={arXiv preprint arXiv:1706.00245}, year={2017} } &quot;&quot;&quot; _DESCRIPTION = &quot;&quot;&quot; The corpus consists of 317 speakers recorded in 554 sessions, where each session consists of 20 read sentences and 10 phonetically rich words. The size of the audio portion of the corpus amounts to around 56 hours, with transcriptions containing 356674 words from a vocabulary of size 46361. Note that in order to limit the required storage for preparing this dataset, the audio is stored in the .wav format and is not converted to a float32 array. To convert the audio file to a float32 array, please make use of the `.map()` function as follows: python import soundfile as sf def map_to_array(batch): speech_array, _ = sf.read(batch[&quot;file&quot;]) batch[&quot;speech&quot;] = speech_array return batch dataset = dataset.map(map_to_array, remove_columns=[&quot;file&quot;]) &quot;&quot;&quot; _URL = &quot;https://mowa.clarin-pl.eu/&quot; _DS_URL = &quot;http://mowa.clarin-pl.eu/korpusy/audio.tar.gz&quot; _TRAIN_URL = &quot;https://raw.githubusercontent.com/danijel3/ClarinStudioKaldi/master/local_clarin/train.sessions&quot; _TEST_URL = &quot;https://raw.githubusercontent.com/danijel3/ClarinStudioKaldi/master/local_clarin/test.sessions&quot; _VALID_URL = &quot;https://raw.githubusercontent.com/danijel3/ClarinStudioKaldi/master/local_clarin/dev.sessions&quot; class ClarinPLStudioASRConfig(datasets.BuilderConfig): &quot;&quot;&quot;BuilderConfig for ClarinPLStudioASR.&quot;&quot;&quot; def __init__(self, **kwargs): &quot;&quot;&quot; Args: data_dir: `string`, the path to the folder containing the files in the downloaded .tar citation: `string`, citation for the data set url: `string`, url for information about the data set **kwargs: keyword arguments forwarded to super. &quot;&quot;&quot; super(ClarinPLStudioASRConfig, self).__init__(version=datasets.Version(&quot;2.1.0&quot;, &quot;&quot;), **kwargs) class ClarinPLStudio(datasets.GeneratorBasedBuilder): &quot;&quot;&quot;ClarinPL Studio dataset.&quot;&quot;&quot; BUILDER_CONFIGS = [ ClarinPLStudioASRConfig(name=&quot;clean&quot;, description=&quot;&#39;Clean&#39; speech.&quot;), ] def _info(self): return datasets.DatasetInfo( description=_DESCRIPTION, features=datasets.Features( { &quot;file&quot;: datasets.Value(&quot;string&quot;), &quot;text&quot;: datasets.Value(&quot;string&quot;), &quot;speaker_id&quot;: datasets.Value(&quot;string&quot;), &quot;id&quot;: datasets.Value(&quot;string&quot;), } ), supervised_keys=(&quot;file&quot;, &quot;text&quot;), homepage=_URL, citation=_CITATION, ) def _split_generators(self, dl_manager): def get_sessions(path): sessions = [] with open(path, &#39;r&#39;) as f: for line in f: sessions.append(line.strip()) return sessions archive_path = dl_manager.download_and_extract(_DS_URL) train_sessions_path = dl_manager.download(_TRAIN_URL) test_sessions_path = dl_manager.download(_TEST_URL) valid_sessions_path = dl_manager.download(_VALID_URL) train_sessions = get_sessions(train_sessions_path) test_sessions = get_sessions(test_sessions_path) valid_sessions = get_sessions(valid_sessions_path) archive_path = os.path.join(archive_path, &quot;audio&quot;) return [ datasets.SplitGenerator(name=&quot;train&quot;, gen_kwargs={ &quot;archive_path&quot;: archive_path, &quot;sessions&quot;: train_sessions }), datasets.SplitGenerator(name=&quot;test&quot;, gen_kwargs={ &quot;archive_path&quot;: archive_path, &quot;sessions&quot;: test_sessions }), datasets.SplitGenerator(name=&quot;valid&quot;, gen_kwargs={ &quot;archive_path&quot;: archive_path, &quot;sessions&quot;: valid_sessions }), ] def _generate_examples(self, archive_path, sessions): &quot;&quot;&quot;Generate examples from a ClarinPL Studio archive_path.&quot;&quot;&quot; def get_single_line(path): lines = [] with open(path, &#39;r&#39;, encoding=&quot;utf-8&quot;) as f: for line in f: line = line.strip() lines.append(line) assert(len(lines) == 1) return lines[0] for session in sessions: session_path = os.path.join(archive_path, session) speaker = get_single_line(os.path.join(session_path, &quot;spk.txt&quot;)) text_glob = os.path.join(session_path, &quot;*.txt&quot;) for text_file in sorted(glob.glob(text_glob)): if text_file.endswith(&quot;spk.txt&quot;): continue basename = os.path.basename(text_file) basename = basename.replace(&#39;.txt&#39;, &#39;&#39;) key = f&#39;{session}_{basename}&#39; text = get_single_line(text_file) audio = text_file.replace(&#39;.txt&#39;, &#39;.wav&#39;) example = { &quot;id&quot;: key, &quot;speaker_id&quot;: speaker, &quot;file&quot;: audio, &quot;text&quot;: text, } yield key, example . !pip install datasets . from datasets import load_dataset dataset = load_dataset(&#39;clarinpl_studio.py&#39;) . Downloading and preparing dataset clarin_pl_studio/clean (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/clarin_pl_studio/clean/2.1.0/733df40ff099ad45628c8c755782c0abb5554817218890a3d232ed359122252c... Dataset clarin_pl_studio downloaded and prepared to /root/.cache/huggingface/datasets/clarin_pl_studio/clean/2.1.0/733df40ff099ad45628c8c755782c0abb5554817218890a3d232ed359122252c. Subsequent calls will reuse this data. . dataset . DatasetDict({ train: Dataset({ features: [&#39;file&#39;, &#39;text&#39;, &#39;speaker_id&#39;, &#39;id&#39;], num_rows: 11222 }) test: Dataset({ features: [&#39;file&#39;, &#39;text&#39;, &#39;speaker_id&#39;, &#39;id&#39;], num_rows: 1362 }) valid: Dataset({ features: [&#39;file&#39;, &#39;text&#39;, &#39;speaker_id&#39;, &#39;id&#39;], num_rows: 1229 }) }) . import IPython IPython.display.Audio(dataset[&#39;train&#39;][&#39;file&#39;][2184]) . dataset . DatasetDict({ train: Dataset({ features: [&#39;file&#39;, &#39;text&#39;, &#39;speaker_id&#39;, &#39;id&#39;], num_rows: 6622 }) test: Dataset({ features: [&#39;file&#39;, &#39;text&#39;, &#39;speaker_id&#39;, &#39;id&#39;], num_rows: 130 }) }) . dataset[&#39;train&#39;][0] . {&#39;file&#39;: &#39;/root/.cache/huggingface/datasets/downloads/extracted/333ddc746f2df1e1d19b44986992d4cbe28710fde81d533a220e755ee6c5c519/audio/SES0001/rich001.wav&#39;, &#39;id&#39;: &#39;SES0001_rich001&#39;, &#39;speaker_id&#39;: &#39;SPK0001&#39;, &#39;text&#39;: &#39;dro≈ºd≈ºe d≈ºip gwo≈ºd≈ºenie ozimina wƒôdzarz rdze≈Ñ wƒôdzonka ingerowaƒá k≈Çadzenie jutrzenka&#39;} . !wc -l /root/.cache/huggingface/datasets/downloads/extracted/4143b1d75559b10028c1c7e8800c9ccc05934ca5a8ea15f8f9a92770576a1ee3/SejmSenat/*/text . 130 /root/.cache/huggingface/datasets/downloads/extracted/4143b1d75559b10028c1c7e8800c9ccc05934ca5a8ea15f8f9a92770576a1ee3/SejmSenat/test/text 6622 /root/.cache/huggingface/datasets/downloads/extracted/4143b1d75559b10028c1c7e8800c9ccc05934ca5a8ea15f8f9a92770576a1ee3/SejmSenat/train/text 6752 total . !find /root/.cache/huggingface/datasets/downloads/extracted/4143b1d75559b10028c1c7e8800c9ccc05934ca5a8ea15f8f9a92770576a1ee3/SejmSenat/audio/ -type f|wc . 6752 6752 1159384 . !rm -rf SejmSenat/ .",
            "url": "https://jimregan.github.io/notes/clarinpl/huggingface/2021/04/14/clarin-studio-dataset.html",
            "relUrl": "/clarinpl/huggingface/2021/04/14/clarin-studio-dataset.html",
            "date": " ‚Ä¢ Apr 14, 2021"
        }
        
    
  
    
        ,"post121": {
            "title": "CC-Aligned Irish contains rubbish",
            "content": "See here. This is probably why M2M100 sucks at Irish. . !wget http://www.statmt.org/cc-aligned/en_XX-ga_IE.tsv.xz . --2021-06-05 17:38:16-- http://www.statmt.org/cc-aligned/en_XX-ga_IE.tsv.xz Resolving www.statmt.org (www.statmt.org)... 129.215.197.184 Connecting to www.statmt.org (www.statmt.org)|129.215.197.184|:80... connected. HTTP request sent, awaiting response... 200 OK Length: 150347648 (143M) [application/x-xz] Saving to: ‚Äòen_XX-ga_IE.tsv.xz‚Äô en_XX-ga_IE.tsv.xz 100%[===================&gt;] 143.38M 139KB/s in 20m 26s 2021-06-05 17:58:43 (120 KB/s) - ‚Äòen_XX-ga_IE.tsv.xz‚Äô saved [150347648/150347648] . !unxz en_XX-ga_IE.tsv.xz . !grep &#39; .ca&#39; en_XX-ga_IE.tsv| cut -c -120 . boutiquestepup.ca https://boutiquestepup.ca/collections/figure-skating-tights Figure skating tights ‚Äì Boutique Step Up boutiquestepup.ca https://boutiquestepup.ca/collections/crystalized-dress-and-catsuit Figure Skating Dress with Crystals boutiquestepup.ca https://boutiquestepup.ca/collections/mens-skatewear BOYS &amp; MENS FIGURE SKATING WEAR ‚Äì Boutique Step boutiquestepup.ca https://boutiquestepup.ca/collections/black-figure-skating-dresses Black Figure Skating Dresses, Catsu boutiquestepup.ca https://boutiquestepup.ca/products/new-jerrys-figure-skating-dress-catsuit-unitard-black-lace-made-on- boutiquestepup.ca https://boutiquestepup.ca/ Boutique Step Up|All Departments|GIFT CARDS|AQUATICS &amp; SWIMMING|WOMENS /GIR boutiquestepup.ca https://boutiquestepup.ca/products/new-skating-dress-catsuit-unitard-290-high-neck-made-on-order-youth boutiquestepup.ca https://boutiquestepup.ca/collections/training-racing-swimsuit Training &amp; Racing Swimsuit ‚Äì Boutique boutiquestepup.ca https://boutiquestepup.ca/collections/skating-catsuit-unitard SKATING CATSUIT- UNITARD ‚Äì Boutique St boutiquestepup.ca https://boutiquestepup.ca/collections/figure-skates-skating-boots-and-skating-blades Figure Skates, Sk boutiquestepup.ca https://boutiquestepup.ca/collections/dance-shoes Dance Shoes ‚Äì Boutique Step Up|‚ùÖ|‚ùÜ|‚ùÖ|‚ùÜ|‚ùÖ boutiquestepup.ca https://boutiquestepup.ca/collections/dance-costumes Dance Costumes ‚Äì Boutique Step Up|All Departmen mp3gain-pro.com http://mp3gain-pro.com/mp3/keywords Keywords ¬´ Mp3 Gain PRO official site Mp3 Normalizer|Home|Tags|Keyw boutiquestepup.ca https://boutiquestepup.ca/collections/skating-shorts Skating Shorts ‚Äì Boutique Step Up|All Departmen boutiquestepup.ca https://boutiquestepup.ca/products/new-jerrys-competition-skating-dress-142-mirror-red-made-on-order N boutiquestepup.ca https://boutiquestepup.ca/collections/jammers Men&#39;s &amp; Boys Swimwear ‚Äì Boutique Step Up|All Departmen boutiquestepup.ca https://boutiquestepup.ca/products/new-rockerz-figure-skating-guards-skate-guards-mix-match-colors Fig boutiquestepup.ca https://boutiquestepup.ca/collections/practice-gymnastics-leotard-competition-gymnastics-leotard-team- boutiquestepup.ca https://boutiquestepup.ca/collections/figure-skating-skirt FIGURE SKATING SKIRT ‚Äì Boutique Step Up|A boutiquestepup.ca https://boutiquestepup.ca/collections/aqua-fitness-chlorine-resistant-swimsuit Aqua Fitness Swimsuits boutiquestepup.ca https://boutiquestepup.ca/collections/dance-accessories-tights DANCE ACCESSORIES &amp; TIGHTS ‚Äì Boutique cantonfair.net https://www.cantonfair.net/category/49-health-industry Trade Shows from Health Industry China|Search|Sear lrmsafety.com https://en.lrmsafety.com/products/3m-11525 3M ‡∏£‡∏∏‡πà‡∏ô 11525 ‚Äì ‡∏ö‡∏£‡∏¥‡∏©‡∏±‡∏ó ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á Binary file en_XX-ga_IE.tsv matches .",
            "url": "https://jimregan.github.io/notes/badmt/irish/2021/04/14/cc-aligned-irish.html",
            "relUrl": "/badmt/irish/2021/04/14/cc-aligned-irish.html",
            "date": " ‚Ä¢ Apr 14, 2021"
        }
        
    
  
    
        ,"post122": {
            "title": "M2M100 sucks at Irish",
            "content": "Huggingface Transformers added the M2M 100 model, I tried it out and tweeted screenshots of the appalling output, so I thought I&#39;d recreate the translations to show they were very real. . !pip install sentencepiece transformers . from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer model = M2M100ForConditionalGeneration.from_pretrained(&quot;facebook/m2m100_418M&quot;) tokenizer = M2M100Tokenizer.from_pretrained(&quot;facebook/m2m100_418M&quot;) . def translate(text, src_lang=&quot;pl&quot;, trg_lang=&quot;ga&quot;): tokenizer.src_lang = src_lang encoded = tokenizer(text, return_tensors=&quot;pt&quot;) generated_tokens = model.generate(**encoded, forced_bos_token_id=tokenizer.get_lang_id(trg_lang)) print(tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)) . So, do massively multilingual MT models trained on massively crawled datasets lead to great output?No pic.twitter.com/SckNGTq09B . &mdash; Jim O&#39;Regan (@jimregan) April 12, 2021 . ‚ÄúOne must love one&#39;s wife‚Äù . translate(&quot;Trzeba kochaƒá swojƒÖ ≈ºonƒô&quot;) . [&#39;Brazzers f√≠se√°n catag√≥ir Inexperienced, D√©ag√≥ir Inexperienced&#39;] . pic.twitter.com/4b6DgbbhtE . &mdash; Jim O&#39;Regan (@jimregan) April 12, 2021 . ‚ÄúWhat are you on about?‚Äù or ‚ÄúWhat are you getting at?‚Äù . translate(&quot;O co Ci chodzi?&quot;) . [&#39;Brazzers f√≠se√°n catag√≥ir Inexperienced, D√©ag√≥ir Inexperienced&#39;] . It&#39;s almost poetic pic.twitter.com/IbJi1zvlrX . &mdash; Jim O&#39;Regan (@jimregan) April 12, 2021 . Let&#39;s try English: . translate(&quot;Hello, how are you?&quot;, src_lang=&#39;en&#39;) . [&#39;Brazzers f√≠se√°n catag√≥ir Inexperienced, D√©ag√≥ir Inexperienced, D√©ag√≥ir Inexperienced&#39;] . pic.twitter.com/GH4KtctnTI . &mdash; Jim O&#39;Regan (@jimregan) April 12, 2021 . How poetic. How about some actual poetry? (Pan Tadeusz) . translate(&quot;Litwo, Ojczyzno moja! ty jeste≈õ jak zdrowie; Ile ciƒô trzeba ceniƒá, ten tylko siƒô dowie, Kto ciƒô straci≈Ç.&quot;) . [&#39;Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers&#39;] . Switching to English output, it at least gives a decent-looking sentence. (It only looks decent, it&#39;s wrong) pic.twitter.com/4HyBQvTAux . &mdash; Jim O&#39;Regan (@jimregan) April 12, 2021 . ‚ÄúIt seems to me that you are not sober‚Äù . translate(&quot;Mi siƒô wydaje, ≈ºe nie jeste≈õ trze≈∫wy&quot;, trg_lang=&#39;en&#39;) . [&#39;I don‚Äôt think you‚Äôre trembling.&#39;] .",
            "url": "https://jimregan.github.io/notes/m2m100/badmt/2021/04/13/m2m100-sucks-at-irish.html",
            "relUrl": "/m2m100/badmt/2021/04/13/m2m100-sucks-at-irish.html",
            "date": " ‚Ä¢ Apr 13, 2021"
        }
        
    
  
    
        ,"post123": {
            "title": "Living Audio Irish",
            "content": "%%capture !wget https://ia800700.us.archive.org/6/items/ga.ie.cll.48000.tar/ga.ie.cll.48000.tar.gz . %%capture !wget https://raw.githubusercontent.com/Idlak/Living-Audio-Dataset/master/ga/text.xml . %%capture !tar zxvf ga.ie.cll.48000.tar.gz !rm ga.ie.cll.48000.tar.gz . %%capture !pip install bs4 . from bs4 import BeautifulSoup import unicodedata soup = BeautifulSoup(open(&#39;text.xml&#39;).read(), &#39;lxml&#39;) dataset = list() for entry in soup.find_all(&#39;fileid&#39;): current = dict() current[&#39;id&#39;] = entry[&#39;id&#39;] current[&#39;text&#39;] = unicodedata.normalize(&#39;NFC&#39;, entry.text.strip()) dataset.append(current) . !rm text.xml . def is_upper_vowel(letter): if letter in [&#39;A&#39;, &#39;E&#39;, &#39;I&#39;, &#39;O&#39;, &#39;U&#39;, &#39;√Å&#39;, &#39;√â&#39;, &#39;√ç&#39;, &#39;√ì&#39;, &#39;√ö&#39;]: return True else: return False def irish_lower(word): if len(word) &gt; 1 and word[0] in [&#39;n&#39;, &#39;t&#39;] and is_upper_vowel(word[1]): return word[0] + &#39;-&#39; + word[1:].lower() else: return word.lower() def irish_lower_sentence(sentence): return &quot; &quot;.join([irish_lower(w) for w in sentence.split(&quot; &quot;)]) . import re hyphens = &#39;cll_z0001_713 cll_z0001_804 cll_z0002_069 cll_z0002_296 cll_z0002_448 cll_z0002_481 cll_z0002_484 cll_z0002_495&#39;.split(&#39; &#39;) for entry in dataset: tmp = entry[&#39;text&#39;] tmp = re.sub(&#39; - &#39;, &#39; &#39;, tmp) tmp = re.sub(&#39; ‚Äì &#39;, &#39; &#39;, tmp) tmp = re.sub(&#39;[‚Äò‚Äú‚Äù &quot; . ?!,‚Äì‚Äî;:]&#39;, &#39;&#39;, tmp) if entry[&#39;id&#39;] in hyphens: tmp = re.sub(&#39; &#39;&#39;, &#39;&#39;, tmp) entry[&#39;sentence&#39;] = irish_lower_sentence(tmp) . for entry in dataset: entry[&#39;speaker&#39;] = &#39;cll&#39; entry[&#39;accent&#39;] = &#39;dublin&#39; entry[&#39;gender&#39;] = &#39;male&#39; entry[&#39;path&#39;] = &#39;../input/living-audio-irish-speech-corpus/48000_orig/{}.wav&#39;.format(entry[&#39;id&#39;]) . import json datasetjson = json.dumps(dataset) jsonf = open(&quot;living-audio.json&quot;, &quot;w&quot;) jsonf.write(datasetjson) jsonf.close() . !wget https://raw.githubusercontent.com/Idlak/idlak/master/idlak-data/ga/ie/lexicon-default.xml . --2021-04-20 21:54:40-- https://raw.githubusercontent.com/Idlak/idlak/master/idlak-data/ga/ie/lexicon-default.xml Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ... Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 405337 (396K) [text/plain] Saving to: ‚Äòlexicon-default.xml‚Äô lexicon-default.xml 100%[===================&gt;] 395.84K --.-KB/s in 0.03s 2021-04-20 21:54:40 (14.8 MB/s) - ‚Äòlexicon-default.xml‚Äô saved [405337/405337] . from bs4 import BeautifulSoup import unicodedata soup = BeautifulSoup(open(&#39;lexicon-default.xml&#39;).read(), &#39;lxml&#39;) lexicon = [] for entry in soup.find_all(&#39;lex&#39;): current = {} current[&#39;pron&#39;] = entry[&#39;pron&#39;] current[&#39;text&#39;] = unicodedata.normalize(&#39;NFC&#39;, entry.text.strip()) lexicon.append(current) . lexiconjson = json.dumps(lexicon) jsonf = open(&quot;ga-lexicon.json&quot;, &quot;w&quot;) jsonf.write(lexiconjson) jsonf.close() . !rm lexicon-default.xml . with open(&#39;lexicon.txt&#39;, &#39;w&#39;) as lextxt: for lex in lexicon: text = lex[&#39;text&#39;] cleaned = lex[&#39;pron&#39;].replace(&#39;0&#39;, &#39;&#39;).replace(&#39;1&#39;, &#39;&#39;).replace(&#39;2&#39;, &#39;&#39;) lextxt.write(f&#39;{text} {cleaned} n&#39;) .",
            "url": "https://jimregan.github.io/notes/speech/dataset/2021/04/06/living-audio-irish.html",
            "relUrl": "/speech/dataset/2021/04/06/living-audio-irish.html",
            "date": " ‚Ä¢ Apr 6, 2021"
        }
        
    
  
    
        ,"post124": {
            "title": "Install pynini on Colab",
            "content": "!pip install -q condacolab import condacolab condacolab.install() . ‚ú®üç∞‚ú® Everything looks OK! . !conda install -c conda-forge pynini . import pynini .",
            "url": "https://jimregan.github.io/notes/colab/pynini/2021/04/06/install-pynini-on-colab.html",
            "relUrl": "/colab/pynini/2021/04/06/install-pynini-on-colab.html",
            "date": " ‚Ä¢ Apr 6, 2021"
        }
        
    
  
    
        ,"post125": {
            "title": "Running wav2vec2 for Polish on Kashubian",
            "content": "%%capture import requests from bs4 import BeautifulSoup . URL=&#39;http://www.miesiecznikpomerania.pl/audio&#39; . req = requests.get(URL) soup = BeautifulSoup(req.content, &#39;html.parser&#39;) . contents = list() for part in soup.find_all(&#39;div&#39;, class_=&#39;sp-accordion-inner&#39;): out = {} audtag = part.find(&#39;audio&#39;) source = audtag.find(&#39;source&#39;) out[&#39;audio&#39;] = &#39;http://www.miesiecznikpomerania.pl{}&#39;.format(source[&#39;src&#39;]) audtag.decompose() out[&#39;text&#39;] = part.text.strip() contents.append(out) . for c in contents: !echo {c[&#39;audio&#39;]} &gt;&gt; input . %%capture !cat input|sort|uniq &gt; input.sorted !wget -i input.sorted . !cat input.sorted|grep -v uczba_5_Miedzy_niebem_a_ziemia_-_Najo_uczba|awk &#39;{print &quot;http://web.archive.org/web/&quot; $0}&#39; &gt; input.wayback . %%capture !wget -i input.wayback . import json with open(&#39;data.json&#39;, &#39;w&#39;) as outfile: json.dump(contents, outfile) . %%capture !for i in *.ogg;do ffmpeg -y -i &quot;$i&quot; -acodec pcm_s16le -ac 1 -ar 16000 &quot;$i.wav&quot;;done . %%capture !pip install librosa webrtcvad . # VAD wrapper is taken from PyTorch Speaker Verification: # https://github.com/HarryVolek/PyTorch_Speaker_Verification # Copyright (c) 2019, HarryVolek # License: BSD-3-Clause # based on https://github.com/wiseman/py-webrtcvad/blob/master/example.py # Copyright (c) 2016 John Wiseman # License: MIT import collections import contextlib import numpy as np import sys import librosa import wave import webrtcvad #from hparam import hparam as hp sr = 16000 def read_wave(path, sr): &quot;&quot;&quot;Reads a .wav file. Takes the path, and returns (PCM audio data, sample rate). Assumes sample width == 2 &quot;&quot;&quot; with contextlib.closing(wave.open(path, &#39;rb&#39;)) as wf: num_channels = wf.getnchannels() assert num_channels == 1 sample_width = wf.getsampwidth() assert sample_width == 2 sample_rate = wf.getframerate() assert sample_rate in (8000, 16000, 32000, 48000) pcm_data = wf.readframes(wf.getnframes()) data, _ = librosa.load(path, sr) assert len(data.shape) == 1 assert sr in (8000, 16000, 32000, 48000) return data, pcm_data class Frame(object): &quot;&quot;&quot;Represents a &quot;frame&quot; of audio data.&quot;&quot;&quot; def __init__(self, bytes, timestamp, duration): self.bytes = bytes self.timestamp = timestamp self.duration = duration def frame_generator(frame_duration_ms, audio, sample_rate): &quot;&quot;&quot;Generates audio frames from PCM audio data. Takes the desired frame duration in milliseconds, the PCM data, and the sample rate. Yields Frames of the requested duration. &quot;&quot;&quot; n = int(sample_rate * (frame_duration_ms / 1000.0) * 2) offset = 0 timestamp = 0.0 duration = (float(n) / sample_rate) / 2.0 while offset + n &lt; len(audio): yield Frame(audio[offset:offset + n], timestamp, duration) timestamp += duration offset += n def vad_collector(sample_rate, frame_duration_ms, padding_duration_ms, vad, frames): &quot;&quot;&quot;Filters out non-voiced audio frames. Given a webrtcvad.Vad and a source of audio frames, yields only the voiced audio. Uses a padded, sliding window algorithm over the audio frames. When more than 90% of the frames in the window are voiced (as reported by the VAD), the collector triggers and begins yielding audio frames. Then the collector waits until 90% of the frames in the window are unvoiced to detrigger. The window is padded at the front and back to provide a small amount of silence or the beginnings/endings of speech around the voiced frames. Arguments: sample_rate - The audio sample rate, in Hz. frame_duration_ms - The frame duration in milliseconds. padding_duration_ms - The amount to pad the window, in milliseconds. vad - An instance of webrtcvad.Vad. frames - a source of audio frames (sequence or generator). Returns: A generator that yields PCM audio data. &quot;&quot;&quot; num_padding_frames = int(padding_duration_ms / frame_duration_ms) # We use a deque for our sliding window/ring buffer. ring_buffer = collections.deque(maxlen=num_padding_frames) # We have two states: TRIGGERED and NOTTRIGGERED. We start in the # NOTTRIGGERED state. triggered = False voiced_frames = [] for frame in frames: is_speech = vad.is_speech(frame.bytes, sample_rate) if not triggered: ring_buffer.append((frame, is_speech)) num_voiced = len([f for f, speech in ring_buffer if speech]) # If we&#39;re NOTTRIGGERED and more than 90% of the frames in # the ring buffer are voiced frames, then enter the # TRIGGERED state. if num_voiced &gt; 0.9 * ring_buffer.maxlen: triggered = True start = ring_buffer[0][0].timestamp # We want to yield all the audio we see from now until # we are NOTTRIGGERED, but we have to start with the # audio that&#39;s already in the ring buffer. for f, s in ring_buffer: voiced_frames.append(f) ring_buffer.clear() else: # We&#39;re in the TRIGGERED state, so collect the audio data # and add it to the ring buffer. voiced_frames.append(frame) ring_buffer.append((frame, is_speech)) num_unvoiced = len([f for f, speech in ring_buffer if not speech]) # If more than 90% of the frames in the ring buffer are # unvoiced, then enter NOTTRIGGERED and yield whatever # audio we&#39;ve collected. if num_unvoiced &gt; 0.9 * ring_buffer.maxlen: triggered = False yield (start, frame.timestamp + frame.duration) ring_buffer.clear() voiced_frames = [] # If we have any leftover voiced audio when we run out of input, # yield it. if voiced_frames: yield (start, frame.timestamp + frame.duration) def VAD_chunk(aggressiveness, path): audio, byte_audio = read_wave(path, sr) vad = webrtcvad.Vad(int(aggressiveness)) frames = frame_generator(20, byte_audio, sr) frames = list(frames) times = vad_collector(sr, 20, 200, vad, frames) speech_times = [] speech_segs = [] for i, time in enumerate(times): start = np.round(time[0],decimals=2) end = np.round(time[1],decimals=2) j = start while j + .4 &lt; end: end_j = np.round(j+.4,decimals=2) speech_times.append((j, end_j)) speech_segs.append(audio[int(j*sr):int(end_j*sr)]) j = end_j else: speech_times.append((j, end)) speech_segs.append(audio[int(j*sr):int(end*sr)]) return speech_times, speech_segs . . # Based on code from PyTorch Speaker Verification: # https://github.com/HarryVolek/PyTorch_Speaker_Verification # Copyright (c) 2019, HarryVolek # Additions Copyright (c) 2021, Jim O&#39;Regan # License: MIT import numpy as np # wav2vec2&#39;s max duration is 40 seconds, using 39 by default # to be a little safer def vad_concat(times, segs, max_duration=39.0): &quot;&quot;&quot; Concatenate continuous times and their segments, where the end time of a segment is the same as the start time of the next Parameters: times: list of tuple (start, end) segs: list of segments (audio frames) max_duration: maximum duration of the resulting concatenated segments; the kernel size of wav2vec2 is 40 seconds, so the default max_duration is 39, to ensure the resulting list of segments will fit Returns: concat_times: list of tuple (start, end) concat_segs: list of segments (audio frames) &quot;&quot;&quot; absolute_maximum=40.0 if max_duration &gt; absolute_maximum: raise Exception(&#39;`max_duration` {:.2f} larger than kernel size (40 seconds)&#39;.format(max_duration)) # we take 0.0 to mean &quot;don&#39;t concatenate&quot; do_concat = (max_duration != 0.0) concat_seg = [] concat_times = [] seg_concat = segs[0] time_concat = times[0] for i in range(0, len(times)-1): can_concat = (times[i+1][1] - time_concat[0]) &lt; max_duration if time_concat[1] == times[i+1][0] and do_concat and can_concat: seg_concat = np.concatenate((seg_concat, segs[i+1])) time_concat = (time_concat[0], times[i+1][1]) else: concat_seg.append(seg_concat) seg_concat = segs[i+1] concat_times.append(time_concat) time_concat = times[i+1] else: concat_seg.append(seg_concat) concat_times.append(time_concat) return concat_times, concat_seg . . def make_dataset(concat_times, concat_segs): starts = [s[0] for s in concat_times] ends = [s[1] for s in concat_times] return {&#39;start&#39;: starts, &#39;end&#39;: ends, &#39;speech&#39;: concat_segs} . %%capture !pip install datasets . from datasets import Dataset def vad_to_dataset(path, max_duration): t,s = VAD_chunk(3, path) if max_duration &gt; 0.0: ct, cs = vad_concat(t, s, max_duration) dset = make_dataset(ct, cs) else: dset = make_dataset(t, s) return Dataset.from_dict(dset) . %%capture !pip install -q transformers . %%capture from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC # load model and tokenizer processor = Wav2Vec2Processor.from_pretrained(&quot;mbien/wav2vec2-large-xlsr-polish&quot;) model = Wav2Vec2ForCTC.from_pretrained(&quot;mbien/wav2vec2-large-xlsr-polish&quot;) model.to(&quot;cuda&quot;) . def speech_file_to_array_fn(batch): import torchaudio speech_array, sampling_rate = torchaudio.load(batch[&quot;path&quot;]) batch[&quot;speech&quot;] = speech_array[0].numpy() batch[&quot;sampling_rate&quot;] = sampling_rate batch[&quot;target_text&quot;] = batch[&quot;sentence&quot;] return batch def evaluate(batch): import torch inputs = processor(batch[&quot;speech&quot;], sampling_rate=16_000, return_tensors=&quot;pt&quot;, padding=True) with torch.no_grad(): logits = model(inputs.input_values.to(&quot;cuda&quot;), attention_mask=inputs.attention_mask.to(&quot;cuda&quot;)).logits pred_ids = torch.argmax(logits, dim=-1) batch[&quot;pred_strings&quot;] = processor.batch_decode(pred_ids) return batch . import json def process_wave(filename, duration): import json dataset = vad_to_dataset(filename, duration) result = dataset.map(evaluate, batched=True, batch_size=16) speechless = result.remove_columns([&#39;speech&#39;]) d=speechless.to_dict() tlog = list() for i in range(0, len(d[&#39;end&#39;]) - 1): out = dict() out[&#39;start&#39;] = d[&#39;start&#39;][i] out[&#39;end&#39;] = d[&#39;end&#39;][i] out[&#39;transcript&#39;] = d[&#39;pred_strings&#39;][i] tlog.append(out) with open(&#39;{}.tlog&#39;.format(filename), &#39;w&#39;) as outfile: json.dump(tlog, outfile) . import glob for f in glob.glob(&#39;./*.wav&#39;): print(f) process_wave(f, 10.0) . !ls *tlog|zip tlogs-csb.zip -@ .",
            "url": "https://jimregan.github.io/notes/wav2vec2/kashubian/2021/03/28/wav2vec2-polish-with-kashubian.html",
            "relUrl": "/wav2vec2/kashubian/2021/03/28/wav2vec2-polish-with-kashubian.html",
            "date": " ‚Ä¢ Mar 28, 2021"
        }
        
    
  
    
        ,"post126": {
            "title": "Using a wav2vec2 model with DSAlign",
            "content": "%%capture !pip install librosa webrtcvad . . The VAD wrapper is taken from PyTorch Speaker Verification, which is in turn is based on py-webrtcvad. . # VAD wrapper is taken from PyTorch Speaker Verification: # https://github.com/HarryVolek/PyTorch_Speaker_Verification # Copyright (c) 2019, HarryVolek # License: BSD-3-Clause # based on https://github.com/wiseman/py-webrtcvad/blob/master/example.py # Copyright (c) 2016 John Wiseman # License: MIT import collections import contextlib import numpy as np import sys import librosa import wave import webrtcvad #from hparam import hparam as hp sr = 16000 def read_wave(path, sr): &quot;&quot;&quot;Reads a .wav file. Takes the path, and returns (PCM audio data, sample rate). Assumes sample width == 2 &quot;&quot;&quot; with contextlib.closing(wave.open(path, &#39;rb&#39;)) as wf: num_channels = wf.getnchannels() assert num_channels == 1 sample_width = wf.getsampwidth() assert sample_width == 2 sample_rate = wf.getframerate() assert sample_rate in (8000, 16000, 32000, 48000) pcm_data = wf.readframes(wf.getnframes()) data, _ = librosa.load(path, sr) assert len(data.shape) == 1 assert sr in (8000, 16000, 32000, 48000) return data, pcm_data class Frame(object): &quot;&quot;&quot;Represents a &quot;frame&quot; of audio data.&quot;&quot;&quot; def __init__(self, bytes, timestamp, duration): self.bytes = bytes self.timestamp = timestamp self.duration = duration def frame_generator(frame_duration_ms, audio, sample_rate): &quot;&quot;&quot;Generates audio frames from PCM audio data. Takes the desired frame duration in milliseconds, the PCM data, and the sample rate. Yields Frames of the requested duration. &quot;&quot;&quot; n = int(sample_rate * (frame_duration_ms / 1000.0) * 2) offset = 0 timestamp = 0.0 duration = (float(n) / sample_rate) / 2.0 while offset + n &lt; len(audio): yield Frame(audio[offset:offset + n], timestamp, duration) timestamp += duration offset += n def vad_collector(sample_rate, frame_duration_ms, padding_duration_ms, vad, frames): &quot;&quot;&quot;Filters out non-voiced audio frames. Given a webrtcvad.Vad and a source of audio frames, yields only the voiced audio. Uses a padded, sliding window algorithm over the audio frames. When more than 90% of the frames in the window are voiced (as reported by the VAD), the collector triggers and begins yielding audio frames. Then the collector waits until 90% of the frames in the window are unvoiced to detrigger. The window is padded at the front and back to provide a small amount of silence or the beginnings/endings of speech around the voiced frames. Arguments: sample_rate - The audio sample rate, in Hz. frame_duration_ms - The frame duration in milliseconds. padding_duration_ms - The amount to pad the window, in milliseconds. vad - An instance of webrtcvad.Vad. frames - a source of audio frames (sequence or generator). Returns: A generator that yields PCM audio data. &quot;&quot;&quot; num_padding_frames = int(padding_duration_ms / frame_duration_ms) # We use a deque for our sliding window/ring buffer. ring_buffer = collections.deque(maxlen=num_padding_frames) # We have two states: TRIGGERED and NOTTRIGGERED. We start in the # NOTTRIGGERED state. triggered = False voiced_frames = [] for frame in frames: is_speech = vad.is_speech(frame.bytes, sample_rate) if not triggered: ring_buffer.append((frame, is_speech)) num_voiced = len([f for f, speech in ring_buffer if speech]) # If we&#39;re NOTTRIGGERED and more than 90% of the frames in # the ring buffer are voiced frames, then enter the # TRIGGERED state. if num_voiced &gt; 0.9 * ring_buffer.maxlen: triggered = True start = ring_buffer[0][0].timestamp # We want to yield all the audio we see from now until # we are NOTTRIGGERED, but we have to start with the # audio that&#39;s already in the ring buffer. for f, s in ring_buffer: voiced_frames.append(f) ring_buffer.clear() else: # We&#39;re in the TRIGGERED state, so collect the audio data # and add it to the ring buffer. voiced_frames.append(frame) ring_buffer.append((frame, is_speech)) num_unvoiced = len([f for f, speech in ring_buffer if not speech]) # If more than 90% of the frames in the ring buffer are # unvoiced, then enter NOTTRIGGERED and yield whatever # audio we&#39;ve collected. if num_unvoiced &gt; 0.9 * ring_buffer.maxlen: triggered = False yield (start, frame.timestamp + frame.duration) ring_buffer.clear() voiced_frames = [] # If we have any leftover voiced audio when we run out of input, # yield it. if voiced_frames: yield (start, frame.timestamp + frame.duration) def VAD_chunk(aggressiveness, path): audio, byte_audio = read_wave(path, sr) vad = webrtcvad.Vad(int(aggressiveness)) frames = frame_generator(20, byte_audio, sr) frames = list(frames) times = vad_collector(sr, 20, 200, vad, frames) speech_times = [] speech_segs = [] for i, time in enumerate(times): start = np.round(time[0],decimals=2) end = np.round(time[1],decimals=2) j = start while j + .4 &lt; end: end_j = np.round(j+.4,decimals=2) speech_times.append((j, end_j)) speech_segs.append(audio[int(j*sr):int(end_j*sr)]) j = end_j else: speech_times.append((j, end)) speech_segs.append(audio[int(j*sr):int(end*sr)]) return speech_times, speech_segs . . Running . I&#39;m going to use a video from YouTube as my input, so first I need to install youtube-dl . %%capture !pip install youtube-dl . I&#39;ve selected this video because it&#39;s a speech by the President of Ireland (and so copyright-free as a matter of public record), it has subtitles (in Irish, though listed as English), and the subtitles are quite faithful to what was spoken. . %%capture !youtube-dl --all-subs -o &#39;%(id)s&#39; VRg-a0qSGa8 . The audio needs to be a 16k wav, so I&#39;m converting it with ffmpeg. . %%capture !ffmpeg -i VRg-a0qSGa8.mkv -acodec pcm_s16le -ac 1 -ar 16000 VRg-a0qSGa8.wav . Next, I&#39;m using the VAD_chunk() function to get the start and end times, and audio segements of each part of the video with speech. . times, segs = VAD_chunk(3, &#39;VRg-a0qSGa8.wav&#39;) . The wav2vec2 models generally perform badly on short input, so vad_concat() concatenates the segments, as well as the times (for DSAlign). . # Based on code from PyTorch Speaker Verification: # https://github.com/HarryVolek/PyTorch_Speaker_Verification # Copyright (c) 2019, HarryVolek # Additions Copyright (c) 2021, Jim O&#39;Regan # License: MIT import numpy as np # wav2vec2&#39;s max duration is 40 seconds, using 39 by default # to be a little safer def vad_concat(times, segs, max_duration=39.0): &quot;&quot;&quot; Concatenate continuous times and their segments, where the end time of a segment is the same as the start time of the next Parameters: times: list of tuple (start, end) segs: list of segments (audio frames) max_duration: maximum duration of the resulting concatenated segments; the kernel size of wav2vec2 is 40 seconds, so the default max_duration is 39, to ensure the resulting list of segments will fit Returns: concat_times: list of tuple (start, end) concat_segs: list of segments (audio frames) &quot;&quot;&quot; absolute_maximum=40.0 if max_duration &gt; absolute_maximum: raise Exception(&#39;`max_duration` {:.2f} larger than kernel size (40 seconds)&#39;.format(max_duration)) # we take 0.0 to mean &quot;don&#39;t concatenate&quot; do_concat = (max_duration != 0.0) concat_seg = [] concat_times = [] seg_concat = segs[0] time_concat = times[0] for i in range(0, len(times)-1): can_concat = (times[i+1][1] - time_concat[0]) &lt; max_duration if time_concat[1] == times[i+1][0] and do_concat and can_concat: seg_concat = np.concatenate((seg_concat, segs[i+1])) time_concat = (time_concat[0], times[i+1][1]) else: concat_seg.append(seg_concat) seg_concat = segs[i+1] concat_times.append(time_concat) time_concat = times[i+1] else: concat_seg.append(seg_concat) concat_times.append(time_concat) return concat_times, concat_seg . . ntimes, nsegs = vad_concat(times, segs) . Next, I&#39;m putting the data into a dict that Huggingface datasets can read: . starts = [s[0] for s in ntimes] ends = [s[1] for s in ntimes] . dset = {&#39;start&#39;: starts, &#39;end&#39;: ends, &#39;speech&#39;: nsegs} . %%capture !pip install datasets . from datasets import Dataset dataset = Dataset.from_dict(dset) . dataset . Dataset({ features: [&#39;start&#39;, &#39;end&#39;, &#39;speech&#39;], num_rows: 137 }) . Now, the data is ready to plug into my wav2vec2 model. . %%capture !pip install -q transformers . %%capture from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC # load model and tokenizer processor = Wav2Vec2Processor.from_pretrained(&quot;jimregan/wav2vec2-large-xlsr-irish-basic&quot;) model = Wav2Vec2ForCTC.from_pretrained(&quot;jimregan/wav2vec2-large-xlsr-irish-basic&quot;) model.to(&quot;cuda&quot;) . Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained. . def speech_file_to_array_fn(batch): import torchaudio speech_array, sampling_rate = torchaudio.load(batch[&quot;path&quot;]) batch[&quot;speech&quot;] = speech_array[0].numpy() batch[&quot;sampling_rate&quot;] = sampling_rate batch[&quot;target_text&quot;] = batch[&quot;sentence&quot;] return batch def evaluate(batch): import torch inputs = processor(batch[&quot;speech&quot;], sampling_rate=16_000, return_tensors=&quot;pt&quot;, padding=True) with torch.no_grad(): logits = model(inputs.input_values.to(&quot;cuda&quot;), attention_mask=inputs.attention_mask.to(&quot;cuda&quot;)).logits pred_ids = torch.argmax(logits, dim=-1) batch[&quot;pred_strings&quot;] = processor.batch_decode(pred_ids) return batch . . result = dataset.map(evaluate, batched=True, batch_size=8) . . speechless = result.remove_columns([&#39;speech&#39;]) . d=speechless.to_dict() . tlog = list() for i in range(0, len(d[&#39;end&#39;]) - 1): out = dict() out[&#39;start&#39;] = d[&#39;start&#39;][i] out[&#39;end&#39;] = d[&#39;end&#39;][i] out[&#39;transcript&#39;] = d[&#39;pred_strings&#39;][i] tlog.append(out) . import json with open(&#39;/content/VRg-a0qSGa8.tlog&#39;, &#39;w&#39;) as outfile: json.dump(tlog, outfile) . Next, I&#39;m extracting the text content from the vtt file . !pip install webvtt-py . Requirement already satisfied: webvtt-py in /usr/local/lib/python3.7/dist-packages (0.4.6) Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from webvtt-py) (0.6.2) . def get_vtt_text(filename): import webvtt out = list() for sub in webvtt.read(filename): out.append(sub.text) return &#39; &#39;.join(out) . text = get_vtt_text(&#39;/content/VRg-a0qSGa8.en.vtt&#39;) . I can do some normalisation now: . text = text.replace(&#39;1901&#39;, &#39;naoi d√©ag is a haon&#39;) text = text.replace(&#39;2021&#39;, &#39;fiche is fiche is a haon&#39;) text = text.replace(&#39;Covid-19&#39;, &#39;covid a naoi d√©ag&#39;) text = text.replace(&#39;fiche fiche haon&#39;, &#39;fiche is fiche is a haon&#39;) . I want sentences, so I&#39;m going to use mosestokenizer to split the text (there aren&#39;t any specific abbreviations in this video, so the English splitter works fine. YMMV.) . %%capture !pip install mosestokenizer . The actual moses tokeniser has sentence splitting support for Irish, but the Python version was forked before that; we don&#39;t actually need any specific support for Irish here, so we can just use English. . from mosestokenizer import MosesSentenceSplitter with MosesSentenceSplitter(&#39;en&#39;) as splitsents: sents = splitsents([text]) . with open(&#39;/content/VRg-a0qSGa8.txt&#39;, &#39;w&#39;) as outfile: outfile.writelines([&#39; n&#39;.join(sents)]) . DSAlign requires an alphabet (1 character per line), so create that first . alpha=&quot;a√°bcde√©fghi√≠jklmno√≥pqrstu√∫vwxyz&#39;-&quot; alpha_chars = [char for char in alpha] . with open(&#39;/content/ga.alphabet&#39;, &#39;w&#39;) as outfile: outfile.writelines([&#39; n&#39;.join(alpha_chars)]) . Now, to install DSAlign and its dependencies: . %%capture !git clone https://github.com/mozilla/DSAlign . %%capture !apt-get install sox . %%capture import os os.chdir(&#39;DSAlign&#39;) !pip install -r requirements.txt . Now, I&#39;m ready to align: . !bin/align.sh --force --tlog /content/VRg-a0qSGa8.tlog --script /content/VRg-a0qSGa8.txt --aligned /content/VRg-a0qSGa8.aligned --text-meaningful-newlines --alphabet /content/ga.alphabet . bin/align.sh: line 3: /content/DSAlign/venv/bin/activate: No such file or directory INFO:root:Aligning 1 of 1 : 100.00% (elapsed: 00:00:04, speed: 0.25 it/s, ETA: 00:00:00) INFO:root:Aligned 24 fragments INFO:root:Dropped 112 fragments 466.67%: . 24 out of 136 fragments isn&#39;t great, but it&#39;s quite good considering the WER of the model (43.7%); the next step would be to add the aligned data to the training set, retrain, and repeat. .",
            "url": "https://jimregan.github.io/notes/wav2vec2/dsalign/2021/03/27/using-a-wav2vec2-model-with-dsalign.html",
            "relUrl": "/wav2vec2/dsalign/2021/03/27/using-a-wav2vec2-model-with-dsalign.html",
            "date": " ‚Ä¢ Mar 27, 2021"
        }
        
    
  
    
        ,"post127": {
            "title": "Seanchas Rann na Feirste scraper pieces",
            "content": "import requests from bs4 import BeautifulSoup BASE=&#39;http://www.rannnafeirste.com&#39; . class Page: def __init__(self, id, title): self.id = id self.title = title self.url = &#39;{}/{}&#39;.format(BASE, id) # TODO: stop trying to make fetch happen def _fetch_text(self): req = requests.get(self.url) if req.status_code != 200: raise Exception(&#39;Error fetching page &#39; + self.url) self.content = req.content def _soupynorman(self): self.soup = BeautifulSoup(self.content, &#39;html.parser&#39;) def _fetch_audio(self): audio_div = self.soup.find(&quot;div&quot;, class_=&#39;sqs-audio-embed&#39;) self.audio = audio_div[&quot;data-url&quot;] def _fetch_fragments(self): for i in self.soup.find_all(&quot;div&quot;, class_=&#39;sqs-block-content&#39;): children = list(i.children) if children[0].name == &quot;h1&quot;: self.fragments = children ## don&#39;t actually need this, because the title comes from the landing page def _fetch_title(self): if self.fragments[0].name == &quot;h1&quot;: self.title = fragments[0].text else: raise Exception(&#39;Error reading title: &#39; + self.url) def _fetch_author(self): if len(self.fragments) &gt; 2 and self.fragments[1].name == &quot;h2&quot;: self.author = self.fragments[1].text else: raise Exception(&#39;Error reading author: &#39; + self.url) def _fetch_paragraphs(self): raw_paras = [n for n in self.fragments if n.name == &quot;p&quot;] for frag in raw_paras: for br in frag.find_all(&quot;br&quot;): br.insert(0, &#39; n&#39;) br.unwrap() first = list(raw_paras[0].children) if len(first) == 1 and first[0].name == &#39;em&#39;: self.em_para = raw_paras[0].text.strip() del raw_paras[0] extent = len(raw_paras) counter = 0 for i in raw_paras: if i.text.strip().startswith(&#39;N√≥ta&#39;) or i.text.strip().startswith(&#39;N√ìTA&#39;) and extent &gt; counter: extent = counter counter += 1 filt = raw_paras[0:extent] self.paragraphs = [p.text for p in filt] def get_initials(self): fada = { &#39;√Å&#39;: &#39;A&#39;, &#39;√â&#39;: &#39;E&#39;, &#39;√ç&#39;: &#39;I&#39;, &#39;√ì&#39;: &#39;O&#39;, &#39;√ö&#39;: &#39;U&#39; } def initial(s): if s == None or len(s) &lt; 1: return &#39;&#39; else: return fada.get(s.upper()[0]) or s.upper()[0] try: return &quot;&quot;.join([initial(i) for i in self.author.split(&#39; &#39;)]) except: print(&#39;Author missing: did you run scrape()?&#39;) def _specifics(self): title = [&#39;mo-bhaile-dchais&#39;, &#39;taiscidh-ghleann-domhain&#39;, &#39;banron-an-uaignis&#39;, &#39;non-an-r-agus-an-frog&#39;, &#39;seanchaithe-agus-fil-rann-na-feirste&#39;, &#39;an-ghaeltacht-bheo&#39;] titlele = [&#39;liontar-duinn-an-cruiscin&#39;, &#39;oireachtas-na-ndise&#39;, &#39;fidilir-ghleann-fhinne&#39;] if self.id in title: self.paragraphs.insert(0, self.title) if self.id in titlele: second = self.em_para.replace(&#39; a chum&#39;, &#39;&#39;) self.paragraphs.insert(0, &#39;{} le {}&#39;.format(self.title, second)) def scrape(self): self._fetch_text() self._soupynorman() self._fetch_audio() self._fetch_fragments() self._fetch_author() self._fetch_paragraphs() self._specifics() . foo = Page(&#39;deorai-an-oileain&#39;, &#39;Mo Bhaile&#39;) foo.scrape() foo.paragraphs . para = foo.fragments[4] . #one = para.contents[0] for br in para.find_all(&quot;br&quot;): br.insert(0, &#39; n&#39;) br.unwrap() para.contents . raw_paras = [n for n in foo.fragments if n.name == &quot;p&quot;] #raw_paras first = list(raw_paras[0].children) if len(first) == 1 and first[0].name == &#39;em&#39;: del raw_paras[0] extent = len(raw_paras) counter = 0 for i in raw_paras: print(i.text) if i.text.strip().startswith(&#39;N√≥ta&#39;) or i.text.strip().startswith(&#39;N√ìTA&#39;) and extent &gt; counter: extent = counter counter += 1 raw_paras[0:extent] #counter .",
            "url": "https://jimregan.github.io/notes/irish/asr/text/2021/03/25/rann_na_feirste_scraper.html",
            "relUrl": "/irish/asr/text/2021/03/25/rann_na_feirste_scraper.html",
            "date": " ‚Ä¢ Mar 25, 2021"
        }
        
    
  
    
        ,"post128": {
            "title": "Irish Texts from South West Donegal. An mh√≥in.",
            "content": "The table below compares the transcription of Text 2: ‚ÄúAn mh√≥in‚Äù from O‚ÄôNeill‚Äôs1 ‚ÄúIrish Texts from South West Donegal‚Äù, comparing it with Abair‚Äôs transcription. . Texts 1‚Äî4 were contributed by Seamus √ì Beirn (Jim Phat James), aged c. 70 years, cobbler, from the townland of M√≠n na Gaoithe, Teelin. . A special feature of his speech is the clearness and strength of the affricates t‚Ä≤ É and d‚Ä≤ í due to the deliberate manner in which each word is enunciated. . The phonetic rules were mostly to help with automatic comparison, though the places where verb froms were pronounced differently before a pronoun was interesting enough to note. . Original Transcript Abair G2P Abair source Adjusted word (standardised) Adjusted Abair Rule . An | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . dtiocfadh | d‚Ä≤{ í}oÃ§ku | Ààd ≤okÀ†uÀê | L | ¬† | ¬† | ¬† | . leat | L‚Ä≤at | Ààl ≤atÀ† | L | ¬† | ¬† | ¬† | . innse | iÃàŒù‚Ä≤ É…ô | ÀàiÀà…¥ ≤ Ée | ¬† | insint | Àåin ≤Àà Éin ≤t ≤ | ¬† | . domh | du | ÀàdÀ†uÀê | L | ¬† | ¬† | ¬† | . caid√© | g…ôÀàd‚Ä≤{ í}e: | kÀ†…ôÀàd ≤eÀê | L | ¬† | ¬† | ¬† | . n | n | nÀ† | L | ¬† | ¬† | ¬† | . d√≥igh | Ààd…î:i | ÀàdÀ†oÀêj | L | ¬† | ¬† | ¬† | . a | …ô | …ô | L | ¬† | ¬† | ¬† | . nd√©antar | N‚Ä≤a:Nt…ër | Ààn ≤eÀê…¥À†tÀ†…ô…æÀ† | L | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . mh√≥in | Ààwo:·µän‚Ä≤ | ÀàwoÀên ≤ | L+M | ¬† | ¬† | ¬† | . Nuair | Nu…ôr‚Ä≤ | Àà…¥À†uÀê…æ ≤ | L | ¬† | ¬† | ¬† | . a | …ô | …ô | L | ¬† | ¬† | ¬† | . thig | h…™g‚Ä≤ | Ààhji…ü | L | ¬† | ¬† | ¬† | . m√≠ | Ààm‚Ä≤i: | Ààm ≤iÀê | L | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . Mh√°rta | Ààw…ë:rt…ô | ÀàwaÀê…æÀ†tÀ†…ô | L+M | ¬† | ¬† | ¬† | . agus | …îg…ôs | ÀàagÀ†…ôsÀ† | L | ¬† | ¬† | ¬† | . go | g…î | ÀàgÀ†…ô | L | ¬† | ¬† | ¬† | . h-√°irid | Ààha:rid‚Ä≤·∂æ | ÀàhaÀê…æ ≤…ôd ≤ | ¬† | h√°irithe | ÀàhaÀê…æ ≤ihj…ô | ¬† | . nuair | Nu…ôr‚Ä≤ | Àà…¥À†uÀê…æ ≤ | L | ¬† | ¬† | ¬† | . a | …ô | …ô | L | ¬† | ¬† | ¬† | . th√©igheann | Ààhe:·µäN | ÀàheÀêj…ô…¥À† | ¬† | th√©ann | ÀàheÀê…¥À† | ¬† | . L√° | L…ë: | Àà üÀ†aÀê | L | ¬† | ¬† | ¬† | . Fh√©il | l‚Ä≤ | ÀàeÀêl ≤ | L | ¬† | ¬† | ¬† | . P√°draig | Ààp…ë:drik‚Ä≤ | ÀàpÀ†aÀêdÀ†…æÀ†…ô…ü | L | ¬† | ¬† | ¬† | . thart | h…ërt | Ààha…æÀ†tÀ† | L | ¬† | ¬† | ¬† | . t√° | t…ë: | ÀàtÀ†aÀê | L | ¬† | ¬† | ¬† | . an | n | Àà…ô…¥À† | L | ¬† | ¬† | …ô ‚Üí ‚àÖ / V # _ | . t-am | Ààt…ë:m | ÀàtÀ†aÀêmÀ† | L | ¬† | ¬† | ¬† | . ann | oÃ§N | Ààa…¥À† | L | ¬† | ¬† | ¬† | . f√° | f…ë | ÀàfÀ†aÀê | L | ¬† | ¬† | ¬† | . dh√©in | Ààje:n‚Ä≤ | ÀàjeÀên ≤ | L+M | ¬† | ¬† | ¬† | . a | …ô | …ô | L | ¬† | ¬† | ¬† | . ghabh√°il | Àà…£…îl‚Ä≤ | Àà…£ol ≤ | L | ¬† | ¬† | ¬† | . na | n…ô | Àà…¥À†…ô | L | ¬† | ¬† | ¬† | . phortaigh. | Ààf…îrti | ÀàfÀ†a…æÀ†tÀ†iÀê | L | ¬† | ¬† | ¬† | . Bh√©arfaidh | verh…ô | Ààv ≤eÀê…æÀ†hiÀê | L | ¬† | ¬† | ¬† | . t√∫ | tu | ÀàtÀ†uÀê | L | ¬† | ¬† | ¬† | . leat | L‚Ä≤at | Ààl ≤atÀ† | L | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . sp√°d | Ààsb ∑…ë:d | ÀàsÀ†pÀ†aÀêdÀ† | L | ¬† | ¬† | ¬† | . s√≠ |  Éi: | Àà ÉiÀê | L | ¬† | ¬† | ¬† | . an | nÃ• | Àà…ô…¥À† | L | ¬† | ¬† | …ô ‚Üí ‚àÖ / V # _ | . ch√©ad | Ààx‚Ä≤e:d | Àà√ßeÀêdÀ† | L | ¬† | ¬† | ¬† | . arma√≠ | Àà…ërm ∑i | Ààa…æÀ†…ômÀ†iÀê | ¬† | ¬† | ¬† | ¬† | . a | √® | …ô | L | ¬† | ¬† | ¬† | . bh√©arfaidh | v…õrh…ô | Ààv ≤eÀê…æÀ†hiÀê | L | ¬† | ¬† | ¬† | . t√∫ | tu | ÀàtÀ†uÀê | L | ¬† | ¬† | ¬† | . leat | ÀàL‚Ä≤at | Ààl ≤atÀ† | L | ¬† | ¬† | ¬† | . na | n…ô | Àà…¥À†…ô | L | ¬† | ¬† | ¬† | . phortaigh | Ààf…îrti | ÀàfÀ†a…æÀ†tÀ†iÀê | L | ¬† | ¬† | ¬† | . Agus | …îg…ôs | ÀàagÀ†…ôsÀ† | L | ¬† | ¬† | ¬† | . rachaidh | Ààr…ëh…ô | Àà…æÀ†aÀêhij | L | ¬† | ¬† | ¬† | . t√∫ | tu | ÀàtÀ†uÀê | L | ¬† | ¬† | ¬† | . fhad | ad | ÀàadÀ† | L | ¬† | ¬† | ¬† | . leis | L‚Ä≤e É | Ààl ≤i É | L | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . bhachta | Ààw…ëxd…ô | Ààwa…æÀ†tÀ†…ô | L+M | ¬† | ¬† | ¬† | . agus | …îg…ôs | ÀàagÀ†…ôsÀ† | L | ¬† | ¬† | ¬† | . caithfidh | Ààkaih…™ | ÀàkÀ†ahjiÀê | L | ¬† | ¬† | ¬† | . t√∫ | tu | ÀàtÀ†uÀê | L | ¬† | ¬† | ¬† | . an | nÃ• | Àà…ô…¥À† | L | ¬† | ¬† | …ô ‚Üí ‚àÖ / V # _ | . bachtadh | Ààb…ëxdu | ÀàbÀ†a…æÀ†tÀ†uÀê | ¬† | bachta | ¬† | ¬† | . a | …ô | …ô | L | ¬† | ¬† | ¬† | . lomadh | ÀàLoÃ§mu | Àà üÀ†omÀ†uÀê | L | ¬† | ¬† | ¬† | . leis | L‚Ä≤e É | Ààl ≤i É | L | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . sp√°d | Ààsb…ë:d | ÀàsÀ†pÀ†aÀêdÀ† | L | ¬† | ¬† | ¬† | . Agus | …îg…ôs | ÀàagÀ†…ôsÀ† | L | ¬† | ¬† | ¬† | . s√© |  ÉŒµ | Àà ÉeÀê | L | ¬† | ¬† | ¬† | . an | nÃ• | Àà…ô…¥À† | L | ¬† | ¬† | …ô ‚Üí ‚àÖ / V # _ | . chiall | Ààx‚Ä≤i:…ôL | Àà√ßia üÀ† | L | ¬† | ¬† | ¬† | . at√° | …ôt…ë: | …ôÀàtÀ†aÀê | L | ¬† | ¬† | ¬† | . leis | l‚Ä≤…õ | Ààl ≤i É | L | ¬† | ¬† |  É ‚Üí ‚àÖ /  É # _ | . sin | Àà É…™n‚Ä≤ | Àà Éin ≤ | L | ¬† | ¬† | ¬† | . an | nÃ• | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . croiceann | Ààkr…õk‚Ä≤…ôN | ÀàkÀ†…æÀ†oc…ô…¥À† | ¬† | craiceann | ÀàkÀ†…æÀ†ac…ô…¥À† | ¬† | . a | …ô | …ô | L | ¬† | ¬† | ¬† | . bhaint | w√Ø‚Ä≤Nt | Ààwan ≤t ≤ | L | ¬† | ¬† | ¬† | . de‚Äôn | …în | ÀàdÀ†enÀ† | L | ¬† | ¬† | d ‚Üí ‚àÖ / t # _ | . talamh | Ààt…ëlu | ÀàtÀ†o üÀ†uÀê | L | ¬† | ¬† | ¬† | . go | go | ÀàgÀ†…ô | L | ¬† | ¬† | ¬† | . dt√©ighidh | Ààd‚Ä≤·∂æe:·µä | Ààd ≤eÀêjiÀê | ¬† | dt√© | Ààd ≤eÀê | ¬† | . t√∫ | tu | ÀàtÀ†uÀê | L | ¬† | ¬† | ¬† | . s√≠os | Àà Éi:s | Àà ÉiÀêsÀ† | L | ¬† | ¬† | ¬† | . fhad | …ëd | ÀàadÀ† | L | ¬† | ¬† | ¬† | . leis | L‚Ä≤e É | Ààl ≤i É | L | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . mh√≥in. | Ààwo:n‚Ä≤ | ÀàwoÀên ≤ | L+M | ¬† | ¬† | ¬† | . T√° | t…ë: | ÀàtÀ†aÀê | L | ¬† | ¬† | ¬† | . an | nÃ• | Àà…ô…¥À† | L | ¬† | ¬† | …ô ‚Üí ‚àÖ / V # _ | . t-uachtar | Ààtu…ôxd…ôr | ÀàtÀ†uaxtÀ†…ô…æÀ† | L+M | ¬† | ¬† | ¬† | . marbh | Ààmaru | ÀàmÀ†a…æÀ†…ôw | L | ¬† | ¬† | ¬† | . ag | …™g‚Ä≤ | Ààe…ü | L | ¬† | ¬† | ¬† | . sioc | Àà ÉoÃ§k | Àà ÉikÀ† | L | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . Gheimhridh | Ààj…õvr‚Ä≤i | Ààjiv ≤…æ ≤i | L | ¬† | ¬† | ¬† | . agus | …îg…ôs | ÀàagÀ†…ôsÀ† | L | ¬† | ¬† | ¬† | . caithfidh | Ààk…ëih…™ | ÀàkÀ†ahjiÀê | L | ¬† | ¬† | ¬† | . t√∫ | tu | ÀàtÀ†uÀê | L | ¬† | ¬† | ¬† | . ghabh√°il | …£…îl‚Ä≤ | Àà…£ol ≤ | L | ¬† | ¬† | ¬† | . s√≠os | Àà Éi·µäs | Àà ÉiÀêsÀ† | L | ¬† | ¬† | ¬† | . go | g…î | ÀàgÀ†…ô | L | ¬† | ¬† | ¬† | . dt√≠ | Ààd‚Ä≤ íi: | Ààd ≤iÀê | L | ¬† | ¬† | ¬† | . go | g…î | ÀàgÀ†…ô | L | ¬† | ¬† | ¬† | . bhfaghaidh | Ààw…ë: | ÀàweÀêiÀê | ¬† | bhfaighidh | ÀàwiÀê | ¬† | . t√∫ | tu | ÀàtÀ†uÀê | L | ¬† | ¬† | ¬† | . an | nÃ• | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . mh√≥in | Ààwo:·µän‚Ä≤ | ÀàwoÀên ≤ | L+M | ¬† | ¬† | ¬† | . Leagfaidh | ÀàL‚Ä≤oÃ§kh…ô | Àà ü ≤agÀ†iÀê | ¬† | ¬† | ¬† | ¬† | . t√∫ | tu | ÀàtÀ†uÀê | L | ¬† | ¬† | ¬† | . an | nÃ• | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . dorga | Ààd…îr…ôg…ô | ÀàdÀ†oÀà…æÀ†gÀ†a | ¬† | dor√∫ | ÀàdÀ†o…æÀ†uÀê | ¬† | . ar | …õr | Ààe…æ ≤ | L | ¬† | ¬† | ¬† | . √©adan | Ààe:·µäd…ën | ÀàeÀêdÀ†…ô…¥À† | L | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . bhachta | Ààw…ëxd…ô | Ààwa…æÀ†tÀ†…ô | L+M | ¬† | ¬† | ¬† | . agus | …îg…ôs | ÀàagÀ†…ôsÀ† | L | ¬† | ¬† | ¬† | . bh√©arfaidh | v√®rh…ô | Ààv ≤eÀê…æÀ†hiÀê | L | ¬† | ¬† | ¬† | . t√∫ | tu | ÀàtÀ†uÀê | L | ¬† | ¬† | ¬† | . slat | Ààsl…ët | ÀàsÀ† üÀ†atÀ† | L | ¬† | ¬† | ¬† | . ar | …õr | Ààe…æ ≤ | L | ¬† | ¬† | ¬† | . leithead | ÀàL‚Ä≤…õh…ôd | Àà ü ≤aihj…ôdÀ† | L | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . bhachtadh | Ààw…ëxdu | Ààwa…æÀ†tÀ†uÀê | ¬† | ¬† | ¬† | ¬† | . √≥ | …ë | ÀàoÀê | L | ¬† | ¬† | ¬† | . bhun | ÀàwoÃ§n | Ààwu…¥À† | L | ¬† | ¬† | ¬† | . go | g…î | ÀàgÀ†…ô | L | ¬† | ¬† | ¬† | . b√°rr | Ààb…ë:R | ÀàbÀ†aÀê…æÀ† | ¬† | barr | ÀàbÀ†aÀê…æÀ† | ¬† | . Nuair | Nu…ôr‚Ä≤ | Àà…¥À†uÀê…æ ≤ | L | ¬† | ¬† | ¬† | . at√° | …ôt…ë: | …ôÀàtÀ†aÀê | L | ¬† | ¬† | ¬† | . an | nÃ• | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . bachtadh | Ààb…ëxdu | ÀàbÀ†a…æÀ†tÀ†uÀê | ¬† | ¬† | ¬† | ¬† | . lomta | ÀàLoÃ§mt | Àà üÀ†omÀ†tÀ†…ô | ¬† | ¬† | ¬† | ¬† | . agat | √®it | Àà…ôgÀ†…ôtÀ† | L | ¬† | ¬† | ¬† | . annsin | nÃ•Àà É…™n‚Ä≤ | ÀàaÀà…¥ ≤ Éin ≤ | ¬† | ansin | …ô…¥À† Éin ≤ | ¬† | . bh√©arfaidh | v…õ:rh…ô | Ààv ≤eÀê…æÀ†hiÀê | L | ¬† | ¬† | ¬† | . t√∫ | tu | ÀàtÀ†uÀê | L | ¬† | ¬† | ¬† | . leat | L‚Ä≤at | Ààl ≤atÀ† | L | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . sp√°d | Ààsb ∑…ë:d | ÀàsÀ†pÀ†aÀêdÀ† | L | ¬† | ¬† | ¬† | . araist | …ôÀàra Éd‚Ä≤ | Ààa…æÀ†…ô Ét ≤ | ¬† | ar ais | ¬† | ¬† | . agus | og…ôs | ÀàagÀ†…ôsÀ† | L | ¬† | ¬† | ¬† | . g√©arrfaidh | Ààg‚Ä≤…ë:Rh…ô | Àà…üeÀêÀà…æÀ†eÀê | ¬† | gearrfaidh | Àà…üa…æÀ†iÀê | ¬† | . t√∫ | tu | ÀàtÀ†uÀê | L | ¬† | ¬† | ¬† | . le | l‚Ä≤…õ | Ààl ≤e | L | ¬† | ¬† | ¬† | . √©adan | Àà…õ:d…ën | ÀàeÀêdÀ†…ô…¥À† | L | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . bhachtadh | Ààw…ëxdu | Ààwa…æÀ†tÀ†uÀê | ¬† | ¬† | ¬† | ¬† | . ar | …õr | Ààe…æ ≤ | L | ¬† | ¬† | ¬† | . fhad | Àà…ëd | ÀàadÀ† | L | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . bhachtadh | Ààw…ëxdu | Ààwa…æÀ†tÀ†uÀê | ¬† | ¬† | ¬† | ¬† | . leis | L‚Ä≤e É | Ààl ≤i É | L | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . sp√°d | Ààsb…ë:d | ÀàsÀ†pÀ†aÀêdÀ† | L | ¬† | ¬† | ¬† | . T√° | t…ë: | ÀàtÀ†aÀê | L | ¬† | ¬† | ¬† | . t√∫ | tu | ÀàtÀ†uÀê | L | ¬† | ¬† | ¬† | . ag | …ô | Ààe…ü | L | ¬† | ¬† | ¬† | . gabh√°il | g…îl‚Ä≤ | ÀàgÀ†ol ≤ | L | ¬† | ¬† | ¬† | . a | …ô | …ô | L | ¬† | ¬† | ¬† | . ghe√°rradh | Ààj…ë:Ru | ÀàjaÀê…æÀ†uÀê | ¬† | ghearradh | ¬† | ¬† | . le | l‚Ä≤…õ | Ààl ≤e | L | ¬† | ¬† | ¬† | . sleagh√°n | Àà ÉL‚Ä≤a:n | Àà Él ≤a…£aÀê…¥À† | ¬† | sle√°n | Àà Él ≤aÀê…¥À† | ¬† | . m√° | m…ë | ÀàmÀ†a | L | ¬† | ¬† | ¬† | . t√° | t…ë: | ÀàtÀ†aÀê | L | ¬† | ¬† | ¬† | . t√∫ | tu | ÀàtÀ†uÀê | L | ¬† | ¬† | ¬† | . deasach | Ààd‚Ä≤·∂æas…ëx | Ààd ≤asÀ†ah | L | ¬† | ¬† | ¬† | . agus | …îg…ôs | ÀàagÀ†…ôsÀ† | L | ¬† | ¬† | ¬† | . ag | …ô | Ààe…ü | L | ¬† | ¬† | ¬† | . gabh√°il | Ààg…îl‚Ä≤ | ÀàgÀ†ol ≤ | L | ¬† | ¬† | ¬† | . a | …ô | …ô | L | ¬† | ¬† | ¬† | . chur | xoÃ§r | Ààxu…æÀ† | L | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . mh√≥in | Ààwo:n‚Ä≤ | ÀàwoÀên ≤ | L+M | ¬† | ¬† | ¬† | . ar | …õr | Ààe…æ ≤ | L | ¬† | ¬† | ¬† | . bruach | Ààbry…ôx | ÀàbÀ†…æÀ†uah | L | ¬† | ¬† | ¬† | . Caithfidh | Ààk…ëihi | ÀàkÀ†ahjiÀê | L | ¬† | ¬† | ¬† | . t√∫ | tu | ÀàtÀ†uÀê | L | ¬† | ¬† | ¬† | . ge√°rradh | Ààg‚Ä≤…ë:Ru | Àà…üaÀê…æÀ†uÀê | ¬† | gearradh | Àà…üa…æÀ†uÀê | ¬† | . leis | L‚Ä≤e É | Ààl ≤i É | L | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . sp√°d | Ààsb…ë:d | ÀàsÀ†pÀ†aÀêdÀ† | L | ¬† | ¬† | ¬† | . le | l‚Ä≤Œµ | Ààl ≤e | L | ¬† | ¬† | ¬† | . √©adan | Ààe:·µäd…ën | ÀàeÀêdÀ†…ô…¥À† | L | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . bhachtadh | Ààw…ëxdu | Ààwa…æÀ†tÀ†uÀê | ¬† | ¬† | ¬† | ¬† | . mar | moÃ§r | ÀàmÀ†a…æÀ† | L | ¬† | ¬† | ¬† | . go | g…î | ÀàgÀ†…ô | L | ¬† | ¬† | ¬† | . bhfuil | w…™l‚Ä≤ | Ààwil ≤ | L | ¬† | ¬† | ¬† | . binn | Ààb‚Ä≤√ØN‚Ä≤ | Ààb ≤i…¥ ≤ | L | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . tsleagh√°in | ‚Ä≤t‚Ä≤ ÉL‚Ä≤a:n‚Ä≤ | Ààt ≤l ≤a…£aÀên ≤ | ¬† | tsle√°in | Ààt ≤l ≤aÀên ≤ | ¬† | . i | ¬† | Àài | L | ¬† | ¬† | ¬† | . dt√≥lamh | Ààd…î:luw | ÀàdÀ†oÀê üÀ†uÀê | L+M | ¬† | ¬† | ¬† | . ag | …ô | Ààe…ü | L | ¬† | ¬† | ¬† | . f√°g√°il | Ààf…ë:g…ël‚Ä≤ | ÀàfÀ†aÀêgÀ†al ≤ | L | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . bhachtadh | Ààw…ëxdu | Ààwa…æÀ†tÀ†uÀê | ¬† | ¬† | ¬† | ¬† | . nuair | Nu…ôr‚Ä≤ | Àà…¥À†uÀê…æ ≤ | L | ¬† | ¬† | ¬† | . at√° | …ôt…ë: | …ôÀàtÀ†aÀê | L | ¬† | ¬† | ¬† | . tusa | Ààt√∂s…ô | ÀàtÀ†usÀ†…ô | L | ¬† | ¬† | ¬† | . ag | …ô | Ààe…ü | L | ¬† | ¬† | ¬† | . cur | koÃ§r | ÀàkÀ†u…æÀ† | L | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . mh√≥in | Ààwo:n‚Ä≤ | ÀàwoÀên ≤ | L+M | ¬† | ¬† | ¬† | . ar | Œµr | Ààe…æ ≤ | L | ¬† | ¬† | ¬† | . bruach | Ààbri:x | ÀàbÀ†…æÀ†uah | L | ¬† | ¬† | ¬† | . Ach | …ëx | Ààah | L | ¬† | ¬† | ¬† | . t√° | t…ë: | ÀàtÀ†aÀê | L | ¬† | ¬† | ¬† | . √°iteacha | Ààa:N‚Ä≤t‚Ä≤ax…ô | ÀàaÀêt ≤…ôh…ô | ¬† | √°iteanna | ÀàaÀêt ≤…ô…¥À†…ô | ¬† | . agus | …îg…ôs | ÀàagÀ†…ôsÀ† | L | ¬† | ¬† | ¬† | . n√≠ | N‚Ä≤i: | Àà…¥ ≤iÀê | L | ¬† | ¬† | ¬† | . h-√© | h√® | ÀàheÀê | L+M | ¬† | ¬† | ¬† | . sin | Àà É…™n‚Ä≤ | Àà Éin ≤ | L | ¬† | ¬† | ¬† | . mar‚Äôs | moÃ§≈ô≈° | Ààm_ea_er_ez_e | L | ¬† | ¬† | ¬† | . ge√°rraidh | Ààg‚Ä≤…ë:Ri | Àà…üaÀê…æÀ†iÀê | ¬† | gearra | Àà…üa…æÀ†…ô | ¬† | . siad |  É…ôd | Àà ÉiÀêdÀ† | L | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . mh√≥in | Ààwo:n‚Ä≤ | ÀàwoÀên ≤ | L+M | ¬† | ¬† | ¬† | . ar | …ô | Ààe…æ ≤ | L | ¬† | ¬† | ¬† | . chor | x…îr | Ààxa…æÀ† | L | ¬† | ¬† | ¬† | . ar | …ô | Ààe…æ ≤ | L | ¬† | ¬† | ¬† | . bith | Ààb‚Ä≤i | Ààb ≤iÀê | L | ¬† | ¬† | ¬† | . s√≠os |  Éi:s | Àà ÉiÀêsÀ† | L | ¬† | ¬† | ¬† | . i | ¬† | Àài | L | ¬† | ¬† | ¬† | . gConnadae | ÀàgoÃ§Ndei | ÀàgÀ†o…¥À†…ôdÀ†eÀê | ¬† | gContae | ÀàgÀ†…ô…¥À†ÀàtÀ†e | ¬† | . na | N…ô | Àà…¥À†…ô | L | ¬† | ¬† | ¬† | . Midhe | Ààm‚Ä≤i:…ô | Ààm ≤iÀê…ô | ¬† | M√≠ | Ààm ≤iÀê | ¬† | . agus | …îg…ôs | ÀàagÀ†…ôsÀ† | L | ¬† | ¬† | ¬† | . na | N…ô | Àà…¥À†…ô | L | ¬† | ¬† | ¬† | . h-√°iteacha | Ààha:N‚Ä≤t‚Ä≤ah…ô | ÀàhaÀêt ≤…ôh…ô | h-√°iteacha | ¬† | ¬† | ¬† | . sin | Àà É…™n‚Ä≤ | Àà Éin ≤ | L | ¬† | ¬† | ¬† | . Ach | …ëx | Ààah | L | ¬† | ¬† | ¬† | . seo |  É…î | Àà Éo | L | ¬† | ¬† | ¬† | . mar‚Äôs | moÃ§≈ô≈° | Ààm_ea_er_ez_e | L | ¬† | ¬† | ¬† | . ge√°rraidh | Ààg‚Ä≤…ë:Ri | Àà…üaÀê…æÀ†iÀê | ¬† | gearra | Àà…üa…æÀ†…ô | ¬† | . siad |  É…ôd | Àà ÉiÀêdÀ† | L | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . mh√≥in | Ààwo:n‚Ä≤ | ÀàwoÀên ≤ | L+M | ¬† | ¬† | ¬† | . insa | nÃ•s…ô | Ààin ≤ÀàsÀ†…ô | ¬† | sa | ÀàsÀ†…ô | ¬† | . t√≠r | Ààt‚Ä≤·∂¥i:r‚Ä≤ | Ààt ≤iÀê…æ ≤ | L | ¬† | ¬† | ¬† | . seo |  É…î | Àà Éo | L | ¬† | ¬† | ¬† | . Tosochaidh | Ààt…îsah…ô | ÀàtÀ†osÀ†…ôhiÀê | ¬† | Tos√≥idh | ÀàtÀ†osÀ†…îj | ¬† | . t√∫ | tu | ÀàtÀ†uÀê | L | ¬† | ¬† | ¬† | . a | ¬† | …ô | L | ¬† | ¬† | ¬† | . ghe√°rradh | Ààj…ë:Ru | ÀàjaÀê…æÀ†uÀê | ¬† | ghearradh | Ààja…æÀ†uÀê | ¬† | . agus | …îg…ôs | ÀàagÀ†…ôsÀ† | L | ¬† | ¬† | ¬† | . n√≠l | ÀàN‚Ä≤i:l‚Ä≤ | Àà…¥ ≤iÀêl ≤ | L | ¬† | ¬† | ¬† | . t√∫ | tu | ÀàtÀ†uÀê | L | ¬† | ¬† | ¬† | . ag | …ô | Ààe…ü | L | ¬† | ¬† | ¬† | . cailleadh | ÀàkaL‚Ä≤L‚Ä≤u | ÀàkÀ†a ü ≤uÀê | L | ¬† | ¬† | ¬† | . aon | e:ÀàN | ÀàeÀê…¥À† | L | ¬† | ¬† | ¬† | . fh√≥d | o:d | ÀàoÀêdÀ† | L+M | ¬† | ¬† | ¬† | . t√° | t…ë: | ÀàtÀ†aÀê | L | ¬† | ¬† | ¬† | . t√∫ | tu | ÀàtÀ†uÀê | L | ¬† | ¬† | ¬† | . ag | …ô | Ààe…ü | L | ¬† | ¬† | ¬† | . cur | koÃ§r | ÀàkÀ†u…æÀ† | L | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . uile | ÀàN…™l‚Ä≤…ô | Ààil ≤…ô | L | ¬† | ¬† | ¬† | . cheann | Ààx‚Ä≤oÃ§N | Àà√ßi…¥À† | L | ¬† | ¬† | ¬† | . isteach | …ô‚Ä≤ Éd‚Ä≤ax | i ÉÀàt ≤ah | L | ¬† | ¬† | ¬† | . ar | …õr | Ààe…æ ≤ | L | ¬† | ¬† | ¬† | . bruach | Ààbri:x | ÀàbÀ†…æÀ†uah | L | ¬† | ¬† | ¬† | . Agus | …îg…ôs | ÀàagÀ†…ôsÀ† | L | ¬† | ¬† | ¬† | . nuair | Nu…ôr‚Ä≤ | Àà…¥À†uÀê…æ ≤ | L | ¬† | ¬† | ¬† | . at√° | …ôt…ë: | …ôÀàtÀ†aÀê | L | ¬† | ¬† | ¬† | . an | n | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . f√≥d | Ààfo:d | ÀàfÀ†oÀêdÀ† | L | ¬† | ¬† | ¬† | . sin |  É…™n‚Ä≤ | Àà Éin ≤ | L | ¬† | ¬† | ¬† | . ge√°rrtha | Ààg‚Ä≤…ë:Rh | Àà…üaÀê…æÀ†h…ô | ¬† | gearrtha | Àà…üaÀê…æÀ†Ààha | ¬† | . agat | …õit | Àà…ôgÀ†…ôtÀ† | L | ¬† | ¬† | ¬† | . ge√°rrfaidh | Ààg‚Ä≤…ë:Rh…ô | Àà…üaÀê…æÀ†iÀê | ¬† | gearrfaidh | Àà…üa…æÀ†iÀê | ¬† | . t√∫ | tu | ÀàtÀ†uÀê | L | ¬† | ¬† | ¬† | . an | nÃ• | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . dara | Ààd…ër…ô | ÀàdÀ†a…æÀ†…ô | L | ¬† | ¬† | ¬† | . f√≥d | Ààfo:d | ÀàfÀ†oÀêdÀ† | L | ¬† | ¬† | ¬† | . ar | …õr | Ààe…æ ≤ | L | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . d√≥igh | d…î:i | ÀàdÀ†oÀêj | L | ¬† | ¬† | ¬† | . chiadhna | Ààx‚Ä≤i…ôN…ô | Àà√ßi…ô…£…¥À†…ô | ¬† | ch√©anna | Àà√ßeÀê…æÀ†…¥À†…ô | ¬† | . Well | w…õL‚Ä≤ | Ààwe ü ≤ | ¬† | ¬† | ¬† | ¬† | . m√° | m…ë | ÀàmÀ†a | L | ¬† | ¬† | ¬† | . t√° | t…ë: | ÀàtÀ†aÀê | L | ¬† | ¬† | ¬† | . bachtadh | Ààb…ëxdu | ÀàbÀ†a…æÀ†tÀ†uÀê | ¬† | bachta | ÀàbÀ†a…æÀ†tÀ†…ô | ¬† | . m√≥r | Ààmo:r | ÀàmÀ†oÀê…æÀ† | L | ¬† | ¬† | ¬† | . agat | √®it | Àà…ôgÀ†…ôtÀ† | L | ¬† | ¬† | ¬† | . f√° | f…ë | ÀàfÀ†aÀê | L | ¬† | ¬† | ¬† | . dh√©in | Ààje:n‚Ä≤ | ÀàjeÀên ≤ | L+M | ¬† | ¬† | ¬† | . a | ¬† | …ô | L | ¬† | ¬† | ¬† | . dtig | Ààd‚Ä≤·∂æ…™g‚Ä≤ | Ààd ≤i…ü | L | ¬† | ¬† | ¬† | . leat | ÀàL‚Ä≤at | Ààl ≤atÀ† | L | ¬† | ¬† | ¬† | . m√≥in | mo:n‚Ä≤ | ÀàmÀ†oÀên ≤ | L | ¬† | ¬† | ¬† | . a | …ô | …ô | L | ¬† | ¬† | ¬† | . rannadh | Ààr…ëNhu | Àà…æÀ†a…¥À†uÀê | ¬† | roinnt | Àà…æÀ†o…¥ ≤t ≤ | ¬† | . air | √®r‚Ä≤ | Ààe…æ ≤ | L | ¬† | ¬† | ¬† | . Anois | N…™ É | …ôÀà…¥À†i É | L | ¬† | ¬† | ¬† | . tionntochaidh | Ààt‚Ä≤·∂¥oÃ§Ntah…ô | Ààt ≤i…¥À†tÀ†…ôhiÀê | ¬† | tiont√≥idh | Ààt ≤i…¥À†tÀ†…îj | ¬† | . t√∫ | tu | ÀàtÀ†uÀê | L | ¬† | ¬† | ¬† | . ar | …õr | Ààe…æ ≤ | L | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . bhachtadh | Ààw…ëxdu | Ààwa…æÀ†tÀ†uÀê | ¬† | bhachta | ¬† | ¬† | . agus | …îg…ôs | ÀàagÀ†…ôsÀ† | L | ¬† | ¬† | ¬† | . bh√©arfaidh | v…õrh…ô | Ààv ≤eÀê…æÀ†hiÀê | L | ¬† | ¬† | ¬† | . t√∫ | tu | ÀàtÀ†uÀê | L | ¬† | ¬† | ¬† | . an | nÃ• | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . bhinn | ÀàŒΩ√ØŒù‚Ä≤ | Ààv ≤i…¥ ≤ | L | ¬† | ¬† | ¬† | . le | l‚Ä≤Œµ | Ààl ≤e | L | ¬† | ¬† | ¬† | . √©adan | Àà…õ:·µäd…ën | ÀàeÀêdÀ†…ô…¥À† | L | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . bhachtadh | Ààw…ëxdu | Ààwa…æÀ†tÀ†uÀê | ¬† | bhachta | ¬† | ¬† | . Agus | …îg…ôs | ÀàagÀ†…ôsÀ† | L | ¬† | ¬† | ¬† | . rachaidh | r…ëh…ô | Àà…æÀ†aÀêhij | L | ¬† | ¬† | ¬† | . t√∫ | tu | ÀàtÀ†uÀê | L | ¬† | ¬† | ¬† | . a | …ô | …ô | L | ¬† | ¬† | ¬† | . chaitheamh | Ààx…ëhu | ÀàxahjuÀê | L | ¬† | ¬† | ¬† | . amach | …ôÀàm…ëh | …ôÀàmÀ†ah | L | ¬† | ¬† | ¬† | . as | √Øs | ÀàasÀ† | L | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . bhachtadh | Ààw…ëxdu | Ààwa…æÀ†tÀ†uÀê | ¬† | bhachta | ¬† | ¬† | . n√° | n…ë: | Àà…¥À†aÀê | L | ¬† | ¬† | ¬† | . go | g…î | ÀàgÀ†…ô | L | ¬† | ¬† | ¬† | . rabh | ro | Àà…æÀ†au | ¬† | raibh | Àà…æÀ†oÀêw | ¬† | . an | nÃ• | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . bachtadh | Ààb…ëxdu | ÀàbÀ†a…æÀ†tÀ†uÀê | ¬† | bachta | ÀàbÀ†a…æÀ†tÀ†…ô | ¬† | . ge√°rrtha | Ààg‚Ä≤…ë:Rh…ô | Àà…üaÀê…æÀ†h…ô | ¬† | gearrtha | Àà…üaÀê…æÀ†Ààha | ¬† | . Nuair | Nu…ôr‚Ä≤ | Àà…¥À†uÀê…æ ≤ | L | ¬† | ¬† | ¬† | . at√° | …ôt…ë: | …ôÀàtÀ†aÀê | L | ¬† | ¬† | ¬† | . an | nÃ• | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . bachtadh | Ààb…ëxdu | ÀàbÀ†a…æÀ†tÀ†uÀê | ¬† | bachta | ÀàbÀ†a…æÀ†tÀ†…ô | ¬† | . ge√°rrtha | Ààg‚Ä≤…ë:Rh…ô | Àà…üaÀê…æÀ†h…ô | ¬† | gearrtha | Àà…üaÀê…æÀ†Ààha | ¬† | . annsin | nÃ•Àà É…™n‚Ä≤ | ÀàaÀà…¥ ≤ Éin ≤ | ¬† | ansin | ¬† | ¬† | . agat | √®it | Àà…ôgÀ†…ôtÀ† | L | ¬† | ¬† | ¬† | . bh√©arfaidh | v…õrh…ô | Ààv ≤eÀê…æÀ†hiÀê | L | ¬† | ¬† | ¬† | . t√∫ | tu | ÀàtÀ†uÀê | L | ¬† | ¬† | ¬† | . leat | L‚Ä≤at | Ààl ≤atÀ† | L | ¬† | ¬† | ¬† | . basc√≥id | Ààb…ësg…îd‚Ä≤·∂æ | ÀàbÀ†asÀ†kÀ†…îd ≤ | ¬† | bascaed | ÀàbÀ†asÀ†kÀ†edÀ† | ¬† | . n√° | n…ë: | Àà…¥À†aÀê | L | ¬† | ¬† | ¬† | . t√° | t…ë: | ÀàtÀ†aÀê | L | ¬† | ¬† | ¬† | . rud | roÃ§D | Àà…æÀ†udÀ† | L | ¬† | ¬† | ¬† | . againn | ÀàŒµiŒù‚Ä≤ | Àà…ôgÀ†…ô…¥ ≤ | L | ¬† | ¬† | ¬† | . sa | s…ô | ÀàsÀ†…ô | L | ¬† | ¬† | ¬† | . t√≠r | Ààt‚Ä≤·∂¥i:r‚Ä≤ | Ààt ≤iÀê…æ ≤ | L | ¬† | ¬† | ¬† | . seo |  É…î | Àà Éo | L | ¬† | ¬† | ¬† | . a | …ô | …ô | L | ¬† | ¬† | ¬† | . bhfuil | w…™l‚Ä≤ | Ààwil ≤ | L | ¬† | ¬† | ¬† | . rotha | Ààr…îh | Àà…æÀ†oh…ô | ¬† | ¬† | ¬† | ¬† | . air | er‚Ä≤ î | Ààe…æ ≤ | L | ¬† | ¬† | ¬† | . agus | …îg…ôs | ÀàagÀ†…ôsÀ† | L | ¬† | ¬† | ¬† | . dh√° | Àà…£…ë: | Àà…£aÀê | L | ¬† | ¬† | ¬† | . l√°mh | ÀàL…ë:w | Àà üÀ†aÀêw | L | ¬† | ¬† | ¬† | . amach | …ôÀàm…ëh | …ôÀàmÀ†ah | L | ¬† | ¬† | ¬† | . as | √Øs | ÀàasÀ† | L | ¬† | ¬† | ¬† | . agus | …îg…ôs | ÀàagÀ†…ôsÀ† | L | ¬† | ¬† | ¬† | . bocsa | ÀàboÃ§ks | ÀàbÀ†okÀ†sÀ†…ô | ¬† | bosca | ÀàbÀ†okÀ†sÀ†…ô | ¬† | . air | …õr‚Ä≤ | Ààe…æ ≤ | L | ¬† | ¬† | ¬† | . a | …ô | …ô | L | ¬† | ¬† | ¬† | . chuireas | ÀàxoÃ§r‚Ä≤…ôs | Ààxu…æ ≤…ôsÀ† | L | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . mh√≥in | Ààwo:n‚Ä≤ | ÀàwoÀên ≤ | L+M | ¬† | ¬† | ¬† | . amach | …ôÀàm…ëx | …ôÀàmÀ†ah | L | ¬† | ¬† | ¬† | . Sin |  É…™n‚Ä≤ | Àà Éin ≤ | L | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . d√≥igh | Ààd…î:i | ÀàdÀ†oÀêj | L | ¬† | ¬† | ¬† | . a | ·µä | …ô | L | ¬† | ¬† | ¬† | . nd√©antar | ÀàN‚Ä≤a:Nt…ôr | Ààn ≤eÀê…¥À†tÀ†…ô…æÀ† | L | ¬† | ¬† | ¬† | . T√° | t…ë | ÀàtÀ†aÀê | L | ¬† | ¬† | ¬† | . an | nÃ• | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . bruach | Ààbri:x | ÀàbÀ†…æÀ†uah | L | ¬† | ¬† | ¬† | . m√≥nadh | mo:nu | ÀàmÀ†oÀê…¥À†uÀê | L | ¬† | ¬† | ¬† | . sin | Àà É…™n‚Ä≤ | Àà Éin ≤ | L | ¬† | ¬† | ¬† | . agat | …õit | Àà…ôgÀ†…ôtÀ† | L | ¬† | ¬† | ¬† | . le | l‚Ä≤Œµ | Ààl ≤e | L | ¬† | ¬† | ¬† | . cur | ÀàkoÃ§r | ÀàkÀ†u…æÀ† | L | ¬† | ¬† | ¬† | . amach | …ôÀàmax | …ôÀàmÀ†ah | L | ¬† | ¬† | ¬† | . agus | …îg…ôs | ÀàagÀ†…ôsÀ† | L | ¬† | ¬† | ¬† | . anois | …ôÀàn…™ É | …ôÀà…¥À†i É | L | ¬† | ¬† | ¬† | . f√°gfaidh | Ààf…ë:kh…ô | ÀàfÀ†aÀêgÀ†h…ô | L | ¬† | ¬† | ¬† | . t√∫ | tu | ÀàtÀ†uÀê | L | ¬† | ¬† | ¬† | . annsin | nÃ•Àà Éin‚Ä≤ | ÀàaÀà…¥ ≤ Éin ≤ | ¬† | ansin | …ô…¥À†Àà Éin ≤ | ¬† | . √≠ | i: | ÀàiÀê | L | ¬† | ¬† | ¬† | . mar | moÃ§r | ÀàmÀ†a…æÀ† | L | ¬† | ¬† | ¬† | . at√° | Ààt…ë: | …ôÀàtÀ†aÀê | L | ¬† | ¬† | ¬† | . s√≠ |  Éi: | Àà ÉiÀê | L | ¬† | ¬† | ¬† | . n√≥ | n…ë: | Àà…¥À†oÀê | L | ¬† | ¬† | ¬† | . go | g…î | ÀàgÀ†…ô | L | ¬† | ¬† | ¬† | . dt√≠ | Ààd í‚Ä≤i: | Ààd ≤iÀê | L | ¬† | ¬† | ¬† | . go | g…î | ÀàgÀ†…ô | L | ¬† | ¬† | ¬† | . dtig | Ààd‚Ä≤…™g‚Ä≤ | Ààd ≤i…ü | L | ¬† | ¬† | ¬† | . grian | Ààg‚Ä≤r‚Ä≤i…ôn | Àà…ü…æ ≤ia…¥À† | L | ¬† | ¬† | ¬† | . ortha√≠ | …îrhi | ÀàoÀê…æÀ†hiÀê | ¬† | uirthi | Ààa…æÀ†hjiÀê | ¬† | . i | …ô | Àài | L | ¬† | ¬† | ¬† | . m√≠ | m‚Ä≤i: | Ààm ≤iÀê | L | ¬† | ¬† | ¬† | . na | N…ô | Àà…¥À†…ô | L | ¬† | ¬† | ¬† | . Bealtaine | Ààb‚Ä≤a:Lt…™n‚Ä≤…ô | Ààb ≤o üÀ†tÀ†…ôn ≤…ô | L | ¬† | ¬† | ¬† | . Agus | …îg…ôs | ÀàagÀ†…ôsÀ† | L | ¬† | ¬† | ¬† | . t√° | t…ë: | ÀàtÀ†aÀê | L | ¬† | ¬† | ¬† | . s√≠ |  Éi | Àà ÉiÀê | L | ¬† | ¬† | ¬† | . caithte | ÀàkoÃ§t‚Ä≤·∂¥…ô | ÀàkÀ†aht ≤…ô | ¬† | caite | ÀàkÀ†at ≤…ô | ¬† | . ina | N…ô | Àài…¥À†…ô | L | ¬† | ¬† | ¬† | . crapanna√≠ | Ààkr…ëp…ôNi | ÀàkÀ†…æÀ†apÀ†…ô…¥À†iÀê | ¬† | ¬† | ¬† | ¬† | . agat | …õit | Àà…ôgÀ†…ôtÀ† | L | ¬† | ¬† | ¬† | . go | g…î | ÀàgÀ†…ô | L | ¬† | ¬† | ¬† | . dt√≠ | Ààd‚Ä≤ íi: | Ààd ≤iÀê | L | ¬† | ¬† | ¬† | . go | go | ÀàgÀ†…ô | L | ¬† | ¬† | ¬† | . bhfosclaidh | Ààw…îsgli | ÀàwoÀàsÀ†kÀ† üÀ†eÀê | ¬† | bhfoscla√≠ | ÀàwoÀàsÀ†kÀ† üÀ†iÀê | ¬† | . an | nÃ• | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . ghrian | Ààj·µär‚Ä≤i…ôn | Àà…£…æ ≤ia…¥À† | L | ¬† | ¬† | ¬† | . rud | roÃ§D | Àà…æÀ†udÀ† | L | ¬† | ¬† | ¬† | . beag | Ààb‚Ä≤√∏G | Ààb ≤ogÀ† | L | ¬† | ¬† | ¬† | . agus | …îg…ôs | ÀàagÀ†…ôsÀ† | L | ¬† | ¬† | ¬† | . spr√©idhfidh | Ààsb‚Ä≤r‚Ä≤e:f‚Ä≤…ô | ÀàsÀ†p ≤…æ ≤eÀêjiÀê | ¬† | spr√©ifidh | ÀàsÀ†p ≤…æ ≤eÀêiÀê | ¬† | . t√∫ | tu | ÀàtÀ†uÀê | L | ¬† | ¬† | ¬† | . le | l‚Ä≤Œµ | Ààl ≤e | L | ¬† | ¬† | ¬† | . do | d…î | ÀàdÀ†…ô | L | ¬† | ¬† | ¬† | . l√°mha | ÀàL…ë:w…ô | Àà üÀ†aÀêw…ô | L | ¬† | ¬† | ¬† | . annsin | nÃ•Àà É…™n‚Ä≤ | ÀàaÀà…¥ ≤ Éin ≤ | ¬† | ansin | …ô…¥À†Àà Éin ≤ | ¬† | . √≠ | i: | ÀàiÀê | L | ¬† | ¬† | ¬† | . F√°gfaidh | Ààf…ë:k…ô | ÀàfÀ†aÀêgÀ†h…ô | L | ¬† | ¬† | ¬† | . t√∫ | tu·µä | ÀàtÀ†uÀê | L | ¬† | ¬† | ¬† | . anois | Ààn…™ É | …ôÀà…¥À†i É | L | ¬† | ¬† | ¬† | . tamallt | t…ëm…ôLt | ÀàtÀ†amÀ†…ô üÀ†tÀ† | ¬† | tamall | ÀàtÀ†amÀ†…ô üÀ† | ¬† | . eile | Àà…õl‚Ä≤i: | Ààel ≤…ô | L | ¬† | ¬† | ¬† | . √≠ | ¬† | ÀàiÀê | L | ¬† | ¬† | ¬† | . agus | …îgas | ÀàagÀ†…ôsÀ† | L | ¬† | ¬† | ¬† | . nuair | Nu…ôr‚Ä≤ | Àà…¥À†uÀê…æ ≤ | L | ¬† | ¬† | ¬† | . a | …ô | …ô | L | ¬† | ¬† | ¬† | . thriomuigheann | Ààx‚Ä≤r‚Ä≤oÃ§m ∑i…ôN | ÀàrÃ™ ≤imÀ†…ôj…ô…¥À† | ¬† | thrioma√≠onn | ÀàrÃ™ ≤imÀ†i…ô…¥À† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . uair | ÀàNu…ôr‚Ä≤ | Ààua…æ ≤ | L | ¬† | ¬† | ¬† | . suas |  Éu…ôs | ÀàsÀ†uasÀ† | L | ¬† | ¬† | ¬† | . faoi | f ∑i | ÀàfÀ†iÀê | L | ¬† | ¬† | ¬† | . chionn | x‚Ä≤oÃ§N | Àà√ßi…¥À† | L+M | ¬† | ¬† | ¬† | . seachtmhaine | Àà Éaxd…™n‚Ä≤…ô | Àà Éa…æÀ†tÀ†w…ôn ≤…ô | ¬† | seachtaine | Àà Éa…æÀ†tÀ†…ôn ≤…ô | ¬† | . n√° | n…ë: | Àà…¥À†aÀê | L | ¬† | ¬† | ¬† | . mar | moÃ§r | ÀàmÀ†a…æÀ† | L | ¬† | ¬† | ¬† | . sin | Àà É…™n‚Ä≤ | Àà Éin ≤ | L | ¬† | ¬† | ¬† | . rachaidh | r…ëh…ô | Àà…æÀ†aÀêhij | L | ¬† | ¬† | ¬† | . t√∫ | tu | ÀàtÀ†uÀê | L | ¬† | ¬† | ¬† | . fhad | …ëd | ÀàadÀ† | L | ¬† | ¬† | ¬† | . l√©ithe | L‚Ä≤…õ:h…ô | Ààl ≤eÀêhj…ô | L | ¬† | ¬† | ¬† | . arais | …ôÀàra É | Ààa…æÀ†…ô É | ¬† | ar ais | Ààe…æ ≤ Ààa É | ¬† | . agus | …îg…ôs | ÀàagÀ†…ôsÀ† | L | ¬† | ¬† | ¬† | . cr√≥igfidh | Ààkr…î:·µäk‚Ä≤…ô | ÀàkÀ†…æÀ†oÀê…üiÀê | ¬† | gr√≥igfidh | ÀàgÀ†…æÀ†oÀê…üiÀê | ¬† | . t√∫ | tu | ÀàtÀ†uÀê | L | ¬† | ¬† | ¬† | . √≠ | i: | ÀàiÀê | L | ¬† | ¬† | ¬† | . F√°gfaidh | Ààf…ë:k…ô | ÀàfÀ†aÀêgÀ†h…ô | L | ¬† | ¬† | ¬† | . t√∫ | tu | ÀàtÀ†uÀê | L | ¬† | ¬† | ¬† | . ins | nÃ•s | Ààin ≤ É | ¬† | sa | ÀàsÀ†…ô | ¬† | . na | N…ô | Àà…¥À†…ô | L | ¬† | ¬† | ¬† | . cr√≥ige√°in | Ààkr…î:·µäg‚Ä≤…ôn‚Ä≤ | ÀàkÀ†…æÀ†oÀê…üaÀên ≤ | ¬† | gr√≥ige√°in | ÀàgÀ†…æÀ†oÀê…üaÀên ≤ | ¬† | . anois | …ôÀàn…™ É | …ôÀà…¥À†i É | L | ¬† | ¬† | ¬† | . √≠ | i: | ÀàiÀê | L | ¬† | ¬† | ¬† | . tamallt | t…ëm…ôLt | ÀàtÀ†amÀ†…ô üÀ†tÀ† | ¬† | tamall | ÀàtÀ†amÀ†…ô üÀ† | ¬† | . eile | Œµl‚Ä≤…ô | Ààel ≤…ô | L | ¬† | ¬† | ¬† | . agus | …îg…ôs | ÀàagÀ†…ôsÀ† | L | ¬† | ¬† | ¬† | . dh√©anfaidh | ja:nh…ô | Àà…£eÀê…¥À†hiÀê | L | ¬† | ¬† | ¬† | . t√∫ | tu | ÀàtÀ†uÀê | L | ¬† | ¬† | ¬† | . anois | …ôÀàn…™ É | …ôÀà…¥À†i É | L | ¬† | ¬† | ¬† | . clampa√≠ | Ààkl…ëmbi | ÀàkÀ† üÀ†amÀ†pÀ†iÀê | ¬† | ¬† | ¬† | ¬† | . daoithe | dih…ô | ÀàdÀ†iÀêh…ô | ¬† | di | ÀàdÀ†i | ¬† | . Nuair | Nu…ôr‚Ä≤ | Àà…¥À†uÀê…æ ≤ | L | ¬† | ¬† | ¬† | . at√° | …ô | …ôÀàtÀ†aÀê | L | ¬† | ¬† | ¬† | . s√≠ | t…ë: Éi: | Àà ÉiÀê | L | ¬† | ¬† | ¬† | . ins | nÃ•s | Ààin ≤ É | ¬† | sa | ÀàsÀ†…ô | ¬† | . na | N…ô | Àà…¥À†…ô | L | ¬† | ¬† | ¬† | . clampa√≠ | Ààkl…ëmbi | ÀàkÀ† üÀ†amÀ†pÀ†iÀê | ¬† | ¬† | ¬† | ¬† | . tamallt | t…ëm…ôLt | ÀàtÀ†amÀ†…ô üÀ†tÀ† | ¬† | tamall | ÀàtÀ†amÀ†…ô üÀ† | ¬† | . agat | √®it | Àà…ôgÀ†…ôtÀ† | L | ¬† | ¬† | ¬† | . √° | a | aÀê | L | ¬† | ¬† | ¬† | . r√©ir | Ààr‚Ä≤e: | Àà…æÀ†eÀê…æ ≤ | L | ¬† | ¬† | ¬† | . sin |  É…™n‚Ä≤ | Àà Éin ≤ | L | ¬† | ¬† | ¬† | . mar‚Äôs | m…ôs | ÀàmÀ†a…æÀ†sÀ† | L | ¬† | ¬† | ¬† | . t√° | t…ë: | ÀàtÀ†aÀê | L | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . uair | ÀàNu…ôr‚Ä≤ | Ààua…æ ≤ | L | ¬† | ¬† | ¬† | . briste | Ààb‚Ä≤r‚Ä≤√Ø Éd‚Ä≤…ô | Ààb ≤…æ ≤i Ét ≤…ô | L | ¬† | ¬† | ¬† | . caithfidh | kaih…™ | ÀàkÀ†ahjiÀê | L | ¬† | ¬† | ¬† | . t√∫ | tu | ÀàtÀ†uÀê | L | ¬† | ¬† | ¬† | . ricl√≠n√≠ | Ààr√Øk‚Ä≤l‚Ä≤i:n‚Ä≤i | Àà…æÀ†icl ≤iÀên ≤iÀê | ¬† | ¬† | ¬† | ¬† | . a | …ô | …ô | L | ¬† | ¬† | ¬† | . dh√©anamh | Ààja:nu | ÀàjeÀê…¥À†uÀê | L | ¬† | ¬† | ¬† | . daoithe | di: ∞…ô | ÀàdÀ†iÀêh…ô | ¬† | di | ÀàdÀ†i | ¬† | . Ach | …ëx | Ààah | L | ¬† | ¬† | ¬† | . m√° | m…ë | ÀàmÀ†a | L | ¬† | ¬† | ¬† | . t√° | t…ë: | ÀàtÀ†aÀê | L | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . uair | Nu…ôr‚Ä≤ | Ààua…æ ≤ | L | ¬† | ¬† | ¬† | . maith | Ààm…ëi | ÀàmÀ†ahj | L | ¬† | ¬† | ¬† | . triomochaidh | Ààt‚Ä≤·∂¥r‚Ä≤√Øm…ëh…ô | Ààt ≤…æ ≤imÀ†…ôhiÀê | ¬† | triom√≥idh | Ààt ≤…æ ≤imÀ†…îj | ¬† | . s√≠ |  Éi: | Àà ÉiÀê | L | ¬† | ¬† | ¬† | . ins | nÃ•s | Ààin ≤ É | ¬† | sa | ÀàsÀ†…ô | ¬† | . na | N…ô | Àà…¥À†…ô | L | ¬† | ¬† | ¬† | . clampa√≠ | Ààkl…ëmbi | ÀàkÀ† üÀ†amÀ†pÀ†iÀê | ¬† | ¬† | ¬† | ¬† | . go | g…ô | ÀàgÀ†…ô | L | ¬† | ¬† | ¬† | . gcruachaidh | Ààgru…ôx…ô | ÀàgÀ†…æÀ†u…ôÀàxeÀê | ¬† | gcruacha | ÀàgÀ†…æÀ†u…ôÀàxa | ¬† | . t√∫ | tu | ÀàtÀ†uÀê | L | ¬† | ¬† | ¬† | . √≠ | i: | ÀàiÀê | L | ¬† | ¬† | ¬† | . Nuair | Nu…ôr‚Ä≤ | Àà…¥À†uÀê…æ ≤ | L | ¬† | ¬† | ¬† | . at√° | …ôt…ë: | …ôÀàtÀ†aÀê | L | ¬† | ¬† | ¬† | . s√≠ |  Éi: | Àà ÉiÀê | L | ¬† | ¬† | ¬† | . cruachta | Ààkru…ôxd…ô | ÀàkÀ†…æÀ†u…ôÀà…æÀ†tÀ†a | ¬† | ¬† | ¬† | ¬† | . annsin | nÃ•Àà É…™n‚Ä≤ | ÀàaÀà…¥ ≤ Éin ≤ | ¬† | ¬† | ¬† | ¬† | . agat | …õj…ôd | Àà…ôgÀ†…ôtÀ† | L | ¬† | ¬† | ¬† | . f√°gfaidh | Ààf…ë:k…ô | ÀàfÀ†aÀêgÀ†h…ô | L | ¬† | ¬† | ¬† | . t√∫ | tu | ÀàtÀ†uÀê | L | ¬† | ¬† | ¬† | . ins | nÃ•s | Ààin ≤ É | ¬† | ¬† | ¬† | ¬† | . na | N…ô | Àà…¥À†…ô | L | ¬† | ¬† | ¬† | . cruacha | Ààkru…ôx | ÀàkÀ†…æÀ†u…ôÀàxa | ¬† | ¬† | ¬† | ¬† | . √≠ | i: | ÀàiÀê | L | ¬† | ¬† | ¬† | . go | g…î | ÀàgÀ†…ô | L | ¬† | ¬† | ¬† | . st√°luighidh | Ààsd…ë:li | ÀàsÀ†tÀ†aÀê üÀ†…ôjiÀê | ¬† | st√°la√≠ | ÀàsÀ†tÀ†aÀê üÀ†iÀê | ¬† | . s√≠ |  Éi: | Àà ÉiÀê | L | ¬† | ¬† | ¬† | . Agus | …îg…ôs | ÀàagÀ†…ôsÀ† | L | ¬† | ¬† | ¬† | . t√° | Ààt…ë: | ÀàtÀ†aÀê | L | ¬† | ¬† | ¬† | . s√≠ |  Éi: | Àà ÉiÀê | L | ¬† | ¬† | ¬† | . agat | √®it | Àà…ôgÀ†…ôtÀ† | L | ¬† | ¬† | ¬† | . s√°bh√°ilte | Ààs…ë:w…ëL‚Ä≤t‚Ä≤·∂¥…ô | ÀàsÀ†aÀêwa ü ≤t ≤…ô | L | ¬† | ¬† | ¬† | . annsin | nÃ•Àà É…™n‚Ä≤ | ÀàaÀà…¥ ≤ Éin ≤ | ¬† | ¬† | ¬† | ¬† | . O‚ÄôNeill, John E. ‚ÄúIrish Texts from South West Donegal.‚Äù Zeitschrift F√ºr Celtische Philologie, vol. 33, 1974, doi:10.1515/zcph.1974.33.1.285.¬†&#8617; . |",
            "url": "https://jimregan.github.io/notes/irish/donegal/2021/01/25/irish-texts-from-south-west-donegal-text-2-an-mhoin.html",
            "relUrl": "/irish/donegal/2021/01/25/irish-texts-from-south-west-donegal-text-2-an-mhoin.html",
            "date": " ‚Ä¢ Jan 25, 2021"
        }
        
    
  
    
        ,"post129": {
            "title": "Irish Texts from South West Donegal. Poit√≠n.",
            "content": "The table below compares the transcription of Text 1: ‚ÄúPoit√≠n‚Äù from O‚ÄôNeill‚Äôs1 ‚ÄúIrish Texts from South West Donegal‚Äù, comparing it with Abair‚Äôs transcription. . Texts 1‚Äî4 were contributed by Seamus √ì Beirn (Jim Phat James), aged c. 70 years, cobbler, from the townland of M√≠n na Gaoithe, Teelin. . A special feature of his speech is the clearness and strength of the affricates t‚Ä≤ É and d‚Ä≤ í due to the deliberate manner in which each word is enunciated. . The phonetic rules were mostly to help with automatic comparison, though the places where verb froms were pronounced differently before a pronoun was interesting enough to note. . Original Transcript Abair G2P Abair source Adjusted word (standardised) Adjusted Abair Rule . An | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . dtiocfadh | d‚Ä≤·∂æoÃ§ku | Ààd ≤okÀ†uÀê | L | ¬† | ¬† | ¬† | . leat | L‚Ä≤at | Ààl ≤atÀ† | L | ¬† | ¬† | ¬† | . innse | iÃàŒù‚Ä≤ É…ô | ÀàiÀà…¥ ≤ Ée | ¬† | insint | Àåin ≤Àà Éin ≤t ≤ | ¬† | . domh | du | ÀàdÀ†uÀê | L | ¬† | ¬† | ¬† | . goid√© | g…ôÀàd‚Ä≤·∂æe: | ÀàgÀ†…ôd ≤eÀê | L | ¬† | ¬† | ¬† | . n | nÃ• | nÀ† | L | ¬† | ¬† | ¬† | . d√≥igh | d…î:i | ÀàdÀ†oÀêj | L | ¬† | ¬† | ¬† | . a | …ô | …ô | L | ¬† | ¬† | ¬† | . nd√©antar | N‚Ä≤a:Nt…ër | Ààn ≤eÀê…¥À†tÀ†…ô…æÀ† | L | ¬† | ¬† | ¬† | . poit√≠n | Ààp…ît‚Ä≤in‚Ä≤ | ÀàpÀ†ot ≤in ≤ | L | ¬† | ¬† | ¬† | . Well | w…õL‚Ä≤ | Ààwe ü ≤ | ¬† | ¬† | ¬† | ¬† | . s√© |  ÉŒµ | Àà ÉeÀê | L | ¬† | ¬† | ¬† | . a | ¬† | …ô | L | ¬† | ¬† | …ô ‚Üí ‚àÖ / V # _ | . bhfuil | Ààwil‚Ä≤ | Ààwil ≤ | L | ¬† | ¬† | ¬† | . fhios | iÃàs | ÀàisÀ† | L | ¬† | ¬† | ¬† | . agamsa | √®ims…ô | Àà…ôgÀ†…ômÀ†sÀ†…ô | L | ¬† | ¬† | ¬† | . f√° | f…ë | ÀàfÀ†aÀê | L | ¬† | ¬† | ¬† | . dtaobh | du: | Ààd ≤iÀêw | L | ¬† | ¬† | ¬† | . den | d…în | ÀàdÀ†enÀ† | L | ¬† | ¬† | ¬† | . phoit√≠n | Ààfot‚Ä≤in‚Ä≤ | ÀàfÀ†ot ≤in ≤ | L+M | ¬† | ¬† | ¬† | . fad | f…ëd | ÀàfÀ†adÀ† | L | ¬† | ¬† | ¬† | . √≥ | …î | ÀàoÀê | L | ¬† | ¬† | ¬† | . shoin | x…™n‚Ä≤ | ÀàhoÀàin ≤ | ¬† | shin | Ààhin ≤ | ¬† | . nuair | Nu…ôr‚Ä≤ | Àà…¥À†uÀê…æ ≤ | L | ¬† | ¬† | ¬† | . a | …ô | …ô | L | ¬† | ¬† | ¬† | . n√≠odh | ÀàN‚Ä≤i:w…ôd‚Ä≤ | Ààn ≤iÀêuÀê | L | ¬† | ¬† | &lt;odh&gt; ‚Üí …ôd ≤ / _ # PRONOUN | . siad |  É…ôd | Àà ÉiÀêdÀ† | L | ¬† | ¬† | ¬† | . as | iÃàs | ÀàasÀ† | L | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . e√≥rna | ÀàN‚Ä≤…î:rN | ÀàoÀê…æÀ†…¥À†…ô | ¬† | eorna | ÀàoÀê…æÀ†…¥À†…ô | …ô ‚Üí ‚àÖ / _ # V | . √≠ | i: | ÀàiÀê | L | ¬† | ¬† | ¬† | . Nuair | Nu…ôr‚Ä≤ | Àà…¥À†uÀê…æ ≤ | L | ¬† | ¬† | ¬† | . a | …ô | …ô | L | ¬† | ¬† | ¬† | . bh√©adh | v…õuw | Ààv ≤eÀê…£ | ¬† | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . e√≥rna | ÀàN‚Ä≤…î:rN…ô | ÀàoÀê…æÀ†…¥À†…ô | ¬† | ¬† | ¬† | ¬† | . s√°bh√°ilte | Ààs…ë:w…ëL‚Ä≤t‚Ä≤ | ÀàsÀ†aÀêwa ü ≤t ≤…ô | L | ¬† | ¬† | ¬† | . ac√∫ | …îku | ÀàakÀ†uÀê | ¬† | ¬† | ¬† | ¬† | . c√°ithte | Ààka:t‚Ä≤ É…ô | ÀàkÀ†aÀêht ≤…ô | ¬† | c√°ite | kÀ†aÀêt ≤…ô | ¬† | . astoigh | …ôÀàsdih î | ÀàasÀ†tÀ†…ô | ¬† | istigh | isÀ†ÀàtÀ†ij | ¬† | . ina | …ôŒù…ô | Àài…¥À†…ô | L | ¬† | ¬† | ¬† | . m√°la | Ààm…ë:l…ô | ÀàmÀ†aÀê üÀ†…ô | L | ¬† | ¬† | ¬† | . bheireadh | v…õr‚Ä≤…ôd‚Ä≤ | Ààv ≤e…æ ≤uÀê | L | ¬† | ¬† | &lt;eadh&gt; ‚Üí …ôd ≤ / _ # PRONOUN | . siad |  É…ôd | Àà ÉiÀêdÀ† | L | ¬† | ¬† | ¬† | . le√≥fa | L‚Ä≤…î:f…ô | Àà ü ≤oÀêfÀ†…ô | ¬† | leo | Ààl ≤o | ¬† | . tuairim | tu…ôr‚Ä≤…™m‚Ä≤ | ÀàtÀ†ua…æ ≤im ≤ | L | ¬† | ¬† | ¬† | . ar | …ôr | Ààe…æ ≤ | L | ¬† | ¬† | ¬† | . ocht | …îxd | ÀàaxtÀ† | L | ¬† | ¬† | ¬† | . gclocha | gloÃ§h…ô | ÀàgÀ† üÀ†ah…ô | L+M | ¬† | ¬† | ¬† | . den | d…î | ÀàdÀ†enÀ† | L | ¬† | ¬† | ¬† | . e√≥rna | ÀàN‚Ä≤…î:rN…ô | ÀàoÀê…æÀ†…¥À†…ô | ¬† | eorna | ÀàoÀê…æÀ†…¥À†…ô | ¬† | . sin |  É…™n‚Ä≤ | Àà Éin ≤ | L | ¬† | ¬† | ¬† | . agus | …îg…ôs | ÀàagÀ†…ôsÀ† | L | ¬† | ¬† | ¬† | . chuireadh | xoÃ§r‚Ä≤…ôd‚Ä≤ | Ààxu…æ ≤uÀê | L | ¬† | ¬† | &lt;eadh&gt; ‚Üí …ôd ≤ / _ # PRONOUN | . siad |  É…ôd | Àà ÉiÀêdÀ† | L | ¬† | ¬† | ¬† | . isteach | …ôÀà Éd‚Ä≤ax | i ÉÀàt ≤ah | L | ¬† | ¬† | ¬† | . ina | …ôŒù…ô | Àài…¥À†…ô | L | ¬† | ¬† | ¬† | . ndam | ÀàN…ëM ∑ | Àà…¥À†amÀ† | ¬† | ndamba | Àà…¥À†amÀ†bÀ†…ô | ¬† | . √≠ | i: | ÀàiÀê | L | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . rud | roÃ§D | Àà…æÀ†udÀ† | L | ¬† | ¬† | ¬† | . a | …ô | …ô | L | ¬† | ¬† | ¬† | . dtugadh | doÃ§g…ôd‚Ä≤ | ÀàdÀ†ugÀ†uÀê | L+M | ¬† | ¬† | &lt;adh&gt; ‚Üí …ôd ≤ / _ # PRONOUN | . siad |  É…ôd | Àà ÉiÀêdÀ† | L | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . bachtadh | Ààb…ëxdu | ÀàbÀ†a…æÀ†tÀ†uÀê | ¬† | bachta | ÀàbÀ†a…æÀ†tÀ†…ô | ¬† | . air | …õr‚Ä≤ | Ààe…æ ≤ | L | ¬† | ¬† | ¬† | . Nuair | Nu…ôr‚Ä≤ | Àà…¥À†uÀê…æ ≤ | L | ¬† | ¬† | ¬† | . a | …ô | …ô | L | ¬† | ¬† | ¬† | . bh√≠odh | vi:d‚Ä≤ | Ààv ≤iÀêuÀê | L | ¬† | ¬† | &lt;odh&gt; ‚Üí …ôd ≤ / _ # PRONOUN | . s√≠ |  Éi: | Àà ÉiÀê | L | ¬† | ¬† | ¬† | . naoi | ÀàNi: | Àà…¥À†iÀê | L | ¬† | ¬† | ¬† | . l√° | ÀàL…ë: | Àà üÀ†aÀê | L | ¬† | ¬† | ¬† | . annsin | nÃ•Àà É…™n‚Ä≤ | ÀàaÀà…¥ ≤ Éin ≤ | ¬† | ¬† | ¬† | ¬† | . d‚Äôfh√°sfadh | d…ë:sh…ôd‚Ä≤ | ÀàdÀ†aÀêsÀ†uÀê | ¬† | ¬† | ¬† | &lt;adh&gt; ‚Üí …ôd ≤ / _ # PRONOUN | . s√≠ |  Éi: | Àà ÉiÀê | L | ¬† | ¬† | ¬† | . g√©ar | Ààg‚Ä≤…õ:·µär | Àà…üeÀê…æÀ† | L | ¬† | ¬† | ¬† | . agus | …îg…ôs | ÀàagÀ†…ôsÀ† | L | ¬† | ¬† | ¬† | . rachadh | r…ëh…ôd‚Ä≤ | Àà…æÀ†ahuÀê | L | ¬† | ¬† | &lt;adh&gt; ‚Üí …ôd ≤ / _ # PRONOUN | . s√≠ |  Éi: | Àà ÉiÀê | L | ¬† | ¬† | ¬† | . a | ¬† | …ô | L | ¬† | ¬† | …ô ‚Üí ‚àÖ / V # _ | . dh‚Äôfh√°s | Àà…£…ë:s | Àà…£aÀêsÀ† | ¬† | d‚Äôfh√°s | ÀàdÀ†aÀêsÀ† | ¬† | . agus | …îg…ôs | ÀàagÀ†…ôsÀ† | L | ¬† | ¬† | ¬† | . ba √© | byje: | ÀàbÀ†…ô ÀàeÀê | ¬† | ¬† | ¬† | ¬† | . sin |  É…™n‚Ä≤ | Àà Éin ≤ | L | ¬† | ¬† | ¬† | . an | …ôÀà | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . t-am | t…ëM | ÀàtÀ†aÀêmÀ† | L | ¬† | ¬† | ¬† | . ac√∫ | …îku | ÀàakÀ†uÀê | ¬† | ¬† | ¬† | ¬† | . lena | l‚Ä≤…õn…ô | Ààl ≤e…¥À†…ô | L | ¬† | ¬† | ¬† | . tarraingt | t…ëR…ôN‚Ä≤t‚Ä≤ | ÀàtÀ†a…æÀ†in ≤t ≤ | L | ¬† | ¬† | ¬† | . amach | …ôÀàm…ëx | …ôÀàmÀ†ah | L | ¬† | ¬† | ¬† | . Agus | …îg…ôs | ÀàagÀ†…ôsÀ† | L | ¬† | ¬† | ¬† | . ins an | nÃ•s…ô | Ààin ≤ É Àà…ô…¥À† | ¬† | ¬† | ¬† | ¬† | . am | ÀàN…ëM | ÀàamÀ† | L | ¬† | ¬† | ¬† | . sin |  É…™n‚Ä≤ | Àà Éin ≤ | L | ¬† | ¬† | ¬† | . bh√≠ | vi: | Ààv ≤iÀê | L | ¬† | ¬† | ¬† | . na | N…ô | Àà…¥À†…ô | L | ¬† | ¬† | ¬† | . toithe | tih…ô | ÀàtÀ†oh…ô | ¬† | tithe | Ààt ≤ihjiÀê | ¬† | . bracha | Ààbr…ëx…ô | ÀàbÀ†…æÀ†ah…ô | ¬† | braiche | ÀàbÀ†…æÀ†a√ß…ô | ¬† | . faoin | f ∑i:n | ÀàfÀ†in ≤ | L | ¬† | ¬† | ¬† | . talamh | Ààt…ëlu | ÀàtÀ†o üÀ†uÀê | L | ¬† | ¬† | ¬† | . ar | …õr | Ààe…æ ≤ | L | ¬† | ¬† | ¬† | . eagla | √∏Gl…ô | ÀàogÀ† üÀ†…ô | L | ¬† | ¬† | ¬† | . go | g…î | ÀàgÀ†…ô | L | ¬† | ¬† | ¬† | . bhfeiceadh | Ààv…õk‚Ä≤u | Ààv ≤ecuÀê | ¬† | ¬† | ¬† | ¬† | . duine | Ààd…™n‚Ä≤ | ÀàdÀ†in ≤…ô | L | ¬† | ¬† | …ô ‚Üí ‚àÖ / _ # V | . ar | …õr | Ààe…æ ≤ | L | ¬† | ¬† | ¬† | . bith | b‚Ä≤i | Ààb ≤iÀê | L | ¬† | ¬† | ¬† | . iad | i…ôd | ÀàiadÀ† | L | ¬† | ¬† | ¬† | . Agus | …îg…ôs | ÀàagÀ†…ôsÀ† | L | ¬† | ¬† | ¬† | . ins | nÃ•s | Ààin ≤ É | ¬† | ¬† | ¬† | ¬† | . na | N…ô | Àà…¥À†…ô | L | ¬† | ¬† | ¬† | . toithe | Ààtih…ô | ÀàtÀ†oh…ô | ¬† | tithe | Ààt ≤ihjiÀê | ¬† | . bracha | Ààbr…ëx…ô | ÀàbÀ†…æÀ†ah…ô | ¬† | braiche | ÀàbÀ†…æÀ†a√ß…ô | ¬† | . thriomuigheadh | Ààx‚Ä≤r‚Ä≤iÃàm ∑ied‚Ä≤ | ÀàrÃ™ ≤imÀ†…ôjuÀê | ¬† | thrioma√≠odh | ÀàrÃ™ ≤imÀ†i…ô…£ | ¬† | . siad |  É…ôd | Àà ÉiÀêdÀ† | L | ¬† | ¬† | ¬† | . araist | …ôÀàra Éd‚Ä≤ | Ààa…æÀ†…ô Ét ≤ | ¬† | ¬† | ¬† | ¬† | . √≠ | i: | ÀàiÀê | L | ¬† | ¬† | ¬† | . Annsin | nÃ•Àà É…™n‚Ä≤ | ÀàaÀà…¥ ≤ Éin ≤ | ¬† | ¬† | ¬† | …ô ‚Üí ‚àÖ / V # _ | . mheileadh | v…ôl‚Ä≤h…ôd‚Ä≤ | Ààv ≤el ≤uÀê | ¬† | ¬† | ¬† | &lt;eadh&gt; ‚Üí …ôd ≤ / _ # PRONOUN | . siad |  É…ôd | Àà ÉiÀêdÀ† | L | ¬† | ¬† | ¬† | . √≠ | i: | ÀàiÀê | L | ¬† | ¬† | ¬† | . le | l‚Ä≤…õ | Ààl ≤e | L | ¬† | ¬† | ¬† | . br√≥inte | Ààbr…î:N‚Ä≤t‚Ä≤…ô | ÀàbÀ†…æÀ†oÀên ≤t ≤…ô | ¬† | br√≥nna | bÀ†…æÀ†oÀê…¥À†…ô | ¬† | . l√°imhe | ÀàL…ë:v…ô | Àà üÀ†aÀêv ≤…ô | L | ¬† | ¬† | ¬† | . Bh√≠ | vi: | Ààv ≤iÀê | L | ¬† | ¬† | ¬† | . na | N…ô | Àà…¥À†…ô | L | ¬† | ¬† | ¬† | . barraill√≠ | Ààb…ëR…ôL‚Ä≤i | ÀàbÀ†aÀêÀà…æÀ†a ü ≤iÀê | ¬† | bairill√≠ | ÀàbÀ†a…æ ≤…ô ü ≤iÀê | ¬† | . ac√∫ | …îku | ÀàakÀ†uÀê | ¬† | acu | akÀ†u | ¬† | . annsin | nÃ•Àà É…™n‚Ä≤ | ÀàaÀà…¥ ≤ Éin ≤ | ¬† | ansin | …ô…¥À† Éin ≤ | …ô ‚Üí ‚àÖ / V # _ | . agus | …îges | ÀàagÀ†…ôsÀ† | L | ¬† | ¬† | ¬† | . l√≠onadh | ÀàL‚Ä≤i:n…ôd‚Ä≤ | Àà ü ≤iÀê…¥À†uÀê | L | ¬† | ¬† | ¬† | . siad |  É…ôd | Àà ÉiÀêdÀ† | L | ¬† | ¬† | ¬† | . l√°n | L…ë:n | Àà üÀ†aÀê…¥À† | L | ¬† | ¬† | ¬† | . uisce | …™ Ég‚Ä≤…ô | Àài Éc…ô | L | ¬† | ¬† | ¬† | . an | nÃ• | Àà…ô…¥À† | L | ¬† | ¬† | …ô ‚Üí ‚àÖ / V # _ | . barraille | Ààb…ëR…ôL‚Ä≤…ô | ÀàbÀ†aÀêÀà…æÀ†a ü ≤…ô | ¬† | bairille | ÀàbÀ†a…æ ≤ ü ≤…ô | ¬† | . Chuireadh | xoÃ§r‚Ä≤…ôd‚Ä≤ | Ààxu…æ ≤uÀê | L | ¬† | ¬† | &lt;eadh&gt; ‚Üí …ôd ≤ / _ # PRONOUN | . siad |  É…ôd | Àà ÉiÀêdÀ† | L | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . bhraich | Ààvreih î | Ààw…æÀ†a√ß | L+M | ¬† | ¬† | ¬† | . isteach | …ôÀà Éd‚Ä≤ax | i ÉÀàt ≤ah | L | ¬† | ¬† | ¬† | . insa | nÃ•s…ô | Ààin ≤ÀàsÀ†…ô | ¬† | sa | ÀàsÀ†…ô | ¬† | . bharraille | Ààw…ëR…ôL‚Ä≤…ô | ÀàwaÀêÀà…æÀ†a ü ≤…ô | ¬† | bhairille | Ààwa…æ ≤ ü ≤…ô | ¬† | . agus | …îg…ôs | ÀàagÀ†…ôsÀ† | L | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . ghabh√°il | Àà…£…î:l‚Ä≤ | Àà…£ol ≤ | L | ¬† | ¬† | ¬† | . annsin | nÃ•Àà É…™n‚Ä≤ | Ààa…¥ ≤ Éin ≤ | ¬† | ansin | …ô…¥À† Éin ≤ | ¬† | . Chuireadh | xoÃ§r‚Ä≤…ôd‚Ä≤ | Ààxu…æ ≤uÀê | L | ¬† | ¬† | &lt;eadh&gt; ‚Üí …ôd ≤ / _ # PRONOUN | . siad |  É…ôd | Àà ÉiÀêdÀ† | L | ¬† | ¬† | ¬† | . cumhdach | Ààku:d…ëx | ÀàkÀ†uÀêdÀ†ah | L | ¬† | ¬† | ¬† | . ar | …õr | Ààe…æ ≤ | L | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . bharraille | Ààw…ëR…ôL‚Ä≤…ô | ÀàwaÀêÀà…æÀ†a ü ≤…ô | ¬† | bhairille | Ààwa…æ ≤ ü ≤…ô | ¬† | . agus | …îg…ôs | ÀàagÀ†…ôsÀ† | L | ¬† | ¬† | ¬† | . ba | boÃ§ | ÀàbÀ†…ô | L | ¬† | ¬† | ¬† | . ghoirid | Àà…£oÃ§r‚Ä≤id‚Ä≤·∂æ | Àà…£o…æ ≤…ôd ≤ | ¬† | ¬† | ¬† | ¬† | . i | …ô | Àài | L | ¬† | ¬† | ¬† | . gcionn | g‚Ä≤oÃ§N | Àà…üo…¥À† | L | ¬† | ¬† | ¬† | . cheithre | Ààx‚Ä≤…õr‚Ä≤…ô | Ààxe…æ ≤…ô | L | ¬† | ¬† | ¬† | . huaire | Ààhu…ôr‚Ä≤…ô | Ààhua…æ ≤…ô | L | ¬† | ¬† | ¬† | . fichead | Ààf‚Ä≤ih…ôd | Ààf ≤ihj…ôdÀ† | L | ¬† | ¬† | ¬† | . thiocfadh | hoÃ§ku | ÀàhjokÀ†uÀê | L | ¬† | ¬† | ¬† | . an | nÃ• | Àà…ô…¥À† | L | ¬† | ¬† | …ô ‚Üí ‚àÖ / V # _ | . cubhar | Ààku:r | ÀàkÀ†uw…ô…æÀ† | ¬† | c√∫r | ÀàkÀ†uÀê…æÀ† | ¬† | . a | …ô | …ô | L | ¬† | ¬† | ¬† | . theacht | haxd | ÀàhjaxtÀ† | L | ¬† | ¬† | ¬† | . ar | …õr | Ààe…æ ≤ | L | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . bharraille | Ààw…ëR…ôL‚Ä≤…ô | ÀàwaÀêÀà…æÀ†a ü ≤…ô | ¬† | bhairille | Ààwa…æ ≤ ü ≤…ô | ¬† | . agus | …îg…ôs | ÀàagÀ†…ôsÀ† | L | ¬† | ¬† | ¬† | . bh√≠ | vi: | Ààv ≤iÀê | L | ¬† | ¬† | ¬† | . an | n | Àà…ô…¥À† | L | ¬† | ¬† | …ô ‚Üí ‚àÖ / V # _ | . ceol | Ààk‚Ä≤ ≤…î:l | ÀàcoÀê üÀ† | L | ¬† | ¬† | ¬† | . aige | …õg‚Ä≤…ô | Ààe…ü…ô | L | ¬† | ¬† | ¬† | . mar | moÃ§r | ÀàmÀ†a…æÀ† | L | ¬† | ¬† | ¬† | . ce√≥l | Ààk‚Ä≤ ≤…î:l | ÀàcoÀê üÀ† | ¬† | ceol | ÀàcoÀê üÀ† | ¬† | . beach√≥g | Ààb‚Ä≤ah…îg | Ààb ≤ah…îgÀ† | ¬† | ¬† | ¬† | ¬† | . Nuair | Nu…ôr‚Ä≤ | Àà…¥À†uÀê…æ ≤ | L | ¬† | ¬† | ¬† | . a | …ô | …ô | L | ¬† | ¬† | ¬† | . bh√≠odh | vi:d‚Ä≤ | Ààv ≤iÀêuÀê | L | ¬† | ¬† | &lt;odh&gt; ‚Üí …ôd ≤ / _ # PRONOUN | . s√© |  É…õ | Àà ÉeÀê | L | ¬† | ¬† | ¬† | . naoi | ÀàNi: | Àà…¥À†iÀê | L | ¬† | ¬† | ¬† | . l√° | ÀàL…ë: | Àà üÀ†aÀê | L | ¬† | ¬† | ¬† | . sh√≠olthuigheadh | Ààhi…ôlhiuw | ÀàhiÀê üÀ†h…ôjuÀê | ¬† | sh√≠othla√≠odh | ÀàhiÀêh üÀ†i…ô…£ | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . t-ioml√°n | Ààt‚Ä≤·∂¥oÃ§mlan | Ààt ≤uÀêmÀ† üÀ†a…¥À† | ¬† | ¬† | ¬† | ¬† | . s√≠os |  Éi:s | Àà ÉiÀêsÀ† | L | ¬† | ¬† | ¬† | . ins | nÃ•s | Ààin ≤ É | ¬† | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . bharraille | Ààw…ëR…ôL‚Ä≤…ô | ÀàwaÀêÀà…æÀ†a ü ≤…ô | ¬† | ¬† | ¬† | ¬† | . araist | …ôÀàra Éd‚Ä≤ | Ààa…æÀ†…ô Ét ≤ | ¬† | ¬† | ¬† | ¬† | . agus | …îg…ôs | ÀàagÀ†…ôsÀ† | L | ¬† | ¬† | ¬† | . ba √© | byje: | ÀàbÀ†…ô ÀàeÀê | L | ¬† | ¬† | ¬† | . sin |  É…™n‚Ä≤ | Àà Éin ≤ | L | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . t-am | Ààt…ëM | ÀàtÀ†aÀêmÀ† | L | ¬† | ¬† | ¬† | . ac√∫ | …îku | ÀàakÀ†uÀê | ¬† | ¬† | ¬† | ¬† | . lena | l‚Ä≤…õn…ô | Ààl ≤e…¥À†…ô | L | ¬† | ¬† | ¬† | . chur | ÀàxoÃ§r | Ààxu…æÀ† | L | ¬† | ¬† | ¬† | . sa | s…ô | ÀàsÀ†…ô | L | ¬† | ¬† | ¬† | . still | Ààsd√Øl | Àà Ét ≤i ü ≤ | ¬† | ¬† | ¬† | ¬† | . Bh√≠ | vi: | Ààv ≤iÀê | L | ¬† | ¬† | ¬† | . s√≠ |  Éi: | Àà ÉiÀê | L | ¬† | ¬† | ¬† | . r√©idh | Ààre:i | Àà…æÀ†eÀêj | L | ¬† | ¬† | ¬† | . f√° | f…ë | ÀàfÀ†aÀê | L | ¬† | ¬† | ¬† | . dh√©in | Ààje:n‚Ä≤ | ÀàjeÀên ≤ | L+M | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . still | Ààsd√Øl | Àà Ét ≤i ü ≤ | ¬† | ¬† | ¬† | ¬† | . Chuireadh | xoÃ§r‚Ä≤…ôd‚Ä≤ | Ààxu…æ ≤uÀê | L | ¬† | ¬† | &lt;eadh&gt; ‚Üí …ôd ≤ / _ # PRONOUN | . siad |  É…ôd | Àà ÉiÀêdÀ† | L | ¬† | ¬† | ¬† | . isteach | …ôÀà Éd‚Ä≤ah | i ÉÀàt ≤ah | L | ¬† | ¬† | ¬† | . insa | nÃ•s…ô | Ààin ≤ÀàsÀ†…ô | ¬† | ¬† | ¬† | ¬† | . still | Ààsd√Øl | Àà Ét ≤i ü ≤ | ¬† | ¬† | ¬† | ¬† | . √≠ | i: | ÀàiÀê | L | ¬† | ¬† | ¬† | . agus | …îg…ôs | ÀàagÀ†…ôsÀ† | L | ¬† | ¬† | ¬† | . bh√≠ | vi: | Ààv ≤iÀê | L | ¬† | ¬† | ¬† | . dabhach | Ààd…îu ∑…ëx | ÀàdÀ†auh | L | ¬† | ¬† | ¬† | . ac√∫ | …îku | ÀàakÀ†uÀê | ¬† | ¬† | ¬† | ¬† | . agus | …îg…ôs | ÀàagÀ†…ôsÀ† | L | ¬† | ¬† | ¬† | . rud | ÀàroÃ§D | Àà…æÀ†udÀ† | L | ¬† | ¬† | ¬† | . a | …ô | …ô | L | ¬† | ¬† | ¬† | . dtugadh | doÃ§g…ôd‚Ä≤ | ÀàdÀ†ugÀ†uÀê | L+M | ¬† | ¬† | &lt;adh&gt; ‚Üí …ôd ≤ / _ # PRONOUN | . siad |  É…ôd | Àà ÉiÀêdÀ† | L | ¬† | ¬† | ¬† | . worm | Ààw√Ør‚Ä≤…ôm | ÀàwoÀê…æÀ†…ômÀ† | ¬† | ¬† | ¬† | ¬† | . air | …õr‚Ä≤ | Ààe…æ ≤ | L | ¬† | ¬† | ¬† | . a | …ô | …ô | L | ¬† | ¬† | ¬† | . rabh | roÀà | Àà…æÀ†au | ¬† | raibh | Àà…æÀ†oÀêw | ¬† | . tr√≠ | t‚Ä≤ Ér‚Ä≤i: | Ààt ≤…æ ≤iÀê | L | ¬† | ¬† | ¬† | . chor | Ààx…îr | Ààxa…æÀ† | L | ¬† | ¬† | ¬† | . innt√≠ | Àà…™N‚Ä≤t‚Ä≤i | ÀàiÀà…¥ ≤t ≤iÀê | ¬† | inti | i…¥ ≤t ≤i | ¬† | . Agus | …îg…ôs | ÀàagÀ†…ôsÀ† | L | ¬† | ¬† | ¬† | . bh√≠ | vi: | Ààv ≤iÀê | L | ¬† | ¬† | ¬† | . an | nÃ• | Àà…ô…¥À† | L | ¬† | ¬† | …ô ‚Üí ‚àÖ / V # _ | . worm | Ààw√Ør‚Ä≤…ôm | ÀàwoÀê…æÀ†…ômÀ† | ¬† | ¬† | ¬† | ¬† | . astoigh | …ôÀà Édih î | ÀàasÀ†tÀ†…ô | ¬† | istigh | isÀ†ÀàtÀ†ij | ¬† | . sa | s…ô | ÀàsÀ†…ô | L | ¬† | ¬† | ¬† | . dabhach | Ààd…îu ∑…ëx | ÀàdÀ†auh | L | ¬† | ¬† | ¬† | . agus | …îg…ôs | ÀàagÀ†…ôsÀ† | L | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . t-uisce | t…™ Ég‚Ä≤…ô | ÀàtÀ†i Éc…ô | L | ¬† | ¬† | ¬† | . fuar | Ààfy…ôr | ÀàfÀ†ia…æÀ† | L | ¬† | ¬† | ¬† | . ag | …ô | Ààe…ü | L | ¬† | ¬† | …ü ‚Üí ‚àÖ / _ # [+stop] | . d√≥rtadh | Ààd…î:rtu | ÀàdÀ†oÀêÀà…æÀ†tÀ†eÀê | ¬† | doirteadh | ÀàdÀ†o…æÀ†t ≤uÀê | ¬† | . ortha√≠ | …îrhi | ÀàoÀê…æÀ†hiÀê | ¬† | uirthi | Ààa…æÀ†hjiÀê | ¬† | . Agus | …îg…ôs | ÀàagÀ†…ôsÀ† | L | ¬† | ¬† | ¬† | . ar | …õr | Ààe…æ ≤ | L | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . taobh | ti:w | ÀàtÀ†iÀêw | L | ¬† | ¬† | ¬† | . eile | Œµl‚Ä≤…ô | Ààel ≤…ô | L | ¬† | ¬† | ¬† | . den | d…în | ÀàdÀ†enÀ† | L | ¬† | ¬† | ¬† | . worm | Ààw√Ør‚Ä≤…ôm | ÀàwoÀê…æÀ†…ômÀ† | ¬† | ¬† | ¬† | ¬† | . bh√≠ | vi: | Ààv ≤iÀê | L | ¬† | ¬† | ¬† | . an | nÃ• | Àà…ô…¥À† | L | ¬† | ¬† | …ô ‚Üí ‚àÖ / V # _ | . ceig | Ààk‚Ä≤√®G‚Ä≤ | Ààce…ü | ¬† | ¬† | ¬† | ¬† | . agus | …îg…ôs | ÀàagÀ†…ôsÀ† | L | ¬† | ¬† | ¬† | . ar | …ôr | Ààe…æ ≤ | L | ¬† | ¬† | ¬† | . tuairim | tu…ôr‚Ä≤…™m‚Ä≤ | ÀàtÀ†ua…æ ≤im ≤ | L | ¬† | ¬† | ¬† | . ar | …õr | Ààe…æ ≤ | L | ¬† | ¬† | ¬† | . thoirt | ÀàhoÃ§Rt‚Ä≤ | Ààha…æÀ†t ≤ | L+M | ¬† | ¬† | ¬† | . fiog | Ààf‚Ä≤√∏G | Ààf ≤igÀ† | ¬† | ¬† | ¬† | ¬† | . ghlas | Àà…£l…ës | Àà…£ üÀ†asÀ† | L | ¬† | ¬† | ¬† | . rachadh | r…ëhu | Àà…æÀ†ahuÀê | L | ¬† | ¬† | ¬† | . an | nÃ• | Àà…ô…¥À† | L | ¬† | ¬† | …ô ‚Üí ‚àÖ / V # _ | . poit√≠n | Ààp…ît‚Ä≤in‚Ä≤ | ÀàpÀ†ot ≤in ≤ | L | ¬† | ¬† | ¬† | . isteach | …ôÀà Éd‚Ä≤ah | i ÉÀàt ≤ah | L | ¬† | ¬† | ¬† | . insa | nÃ•s…ô | Ààin ≤ÀàsÀ†…ô | ¬† | ¬† | ¬† | ¬† | . cheig | Ààx‚Ä≤…õG‚Ä≤ | Àà√ße…ü | ¬† | ¬† | ¬† | ¬† | . amach | …ôÀàm…ëh | …ôÀàmÀ†ah | L | ¬† | ¬† | ¬† | . as | √Øs | ÀàasÀ† | L | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . worm | Ààw√Ør‚Ä≤…ôm | ÀàwoÀê…æÀ†…ômÀ† | ¬† | ¬† | ¬† | ¬† | . Annsin | nÃ•Àà É…™n‚Ä≤ | ÀàaÀà…¥ ≤ Éin ≤ | ¬† | ¬† | ¬† | ¬† | . nuair | Nu…ôr‚Ä≤ | Àà…¥À†uÀê…æ ≤ | L | ¬† | ¬† | ¬† | . a | …ô | …ô | L | ¬† | ¬† | ¬† | . bh√≠odh | viuw | Ààv ≤iÀêuÀê | L | ¬† | ¬† | ¬† | . an | nÃ• | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . ch√©ad | Ààx‚Ä≤ed | Àà√ßeÀêdÀ† | L | ¬† | ¬† | ¬† | . rathaidh | Ààr…ëhi | Àà…æÀ†ahiÀê | ¬† | ratha | Àà…æÀ†ah…ô | ¬† | . raithte | Ààrat‚Ä≤ É | Àà…æÀ†aht ≤…ô | ¬† | r√°ite | Àà…æÀ†aÀêt ≤…ô | …ô ‚Üí ‚àÖ / _ # V | . ac√∫ | …îku | ÀàakÀ†uÀê | ¬† | ¬† | ¬† | ¬† | . chuireadh | xoÃ§r‚Ä≤…ôd‚Ä≤ | Ààxu…æ ≤uÀê | L | ¬† | ¬† | &lt;eadh&gt; ‚Üí …ôd ≤ / _ # PRONOUN | . siad |  É…ôd | Àà ÉiÀêdÀ† | L | ¬† | ¬† | ¬† | . isteach | …ôÀà Éd‚Ä≤ah | i ÉÀàt ≤ah | L | ¬† | ¬† | ¬† | . araist | …ôÀàra Éd‚Ä≤ | Ààa…æÀ†…ô Ét ≤ | ¬† | ¬† | ¬† | ¬† | . √≠ | i: | ÀàiÀê | L | ¬† | ¬† | ¬† | . ins | nÃ•s | Ààin ≤ É | ¬† | ¬† | ¬† | …ô ‚Üí ‚àÖ / V # _ | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . still | Ààsd√Øl | Àà Ét ≤i ü ≤ | ¬† | ¬† | ¬† | ¬† | . agus | …îg…ôs | ÀàagÀ†…ôsÀ† | L | ¬† | ¬† | ¬† | . n√≠odh | ÀàN‚Ä≤i:w…ôd‚Ä≤ | Ààn ≤iÀêuÀê | L | ¬† | ¬† | &lt;odh&gt; ‚Üí …ôd ≤ / _ # PRONOUN | . siad |  É…ôd | Àà ÉiÀêdÀ† | L | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . dara | Ààd…ër…ô | ÀàdÀ†a…æÀ†…ô | L | ¬† | ¬† | ¬† | . rathaidh | nÃ•Ààrahi | Àà…æÀ†ahiÀê | ¬† | ¬† | ¬† | ¬† | . annsin | Àà É…™n‚Ä≤ | ÀàaÀà…¥ ≤ Éin ≤ | ¬† | ¬† | ¬† | ¬† | . Bh√≠odh | viuw | Ààv ≤iÀêuÀê | L | ¬† | ¬† | ¬† | . gloine | Ààgl√∂n‚Ä≤…ô | ÀàgÀ† üÀ†in ≤…ô | L | ¬† | ¬† | ¬† | . ac√∫ | …îku | ÀàakÀ†uÀê | ¬† | ¬† | ¬† | ¬† | . a | …ô | …ô | L | ¬† | ¬† | ¬† | . dtugadh | doÃ§g…ôd‚Ä≤ | ÀàdÀ†ugÀ†uÀê | L+M | ¬† | ¬† | &lt;adh&gt; ‚Üí …ôd ≤ / _ # PRONOUN | . siad |  É…ôd | Àà ÉiÀêdÀ† | L | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . adharc | ÀàNe:rk | ÀàeÀê…æÀ†kÀ† | L | ¬† | ¬† | ¬† | . air | …õr‚Ä≤ | Ààe…æ ≤ | L | ¬† | ¬† | ¬† | . agus | …îg…ôs | ÀàagÀ†…ôsÀ† | L | ¬† | ¬† | ¬† | . √° | a | aÀê | L | ¬† | ¬† | ¬† | . r√©ir | Ààre: | Àà…æÀ†eÀê…æ ≤ | L | ¬† | ¬† | ¬† | . sin‚Äôs |  É…™n‚Ä≤s | Àà Éin ≤ É | ¬† | ¬† | ¬† | ¬† | . bh√≠odh | vi:d‚Ä≤ | Ààv ≤iÀêuÀê | L | ¬† | ¬† | ¬† | . siad |  É…ôd | Àà ÉiÀêdÀ† | L | ¬† | ¬† | ¬† | . ag | …ô | Ààe…ü | L | ¬† | ¬† | ¬† | . rathaidh | Ààr…ëhi | Àà…æÀ†ahiÀê | ¬† | ¬† | ¬† | ¬† | . an | nÃ• | Àà…ô…¥À† | L | ¬† | ¬† | …ô ‚Üí ‚àÖ / V # _ | . phoit√≠n | Ààf…ît‚Ä≤in‚Ä≤ | ÀàfÀ†ot ≤in ≤ | L+M | ¬† | ¬† | ¬† | . chuireadh | xoÃ§r‚Ä≤…ôd‚Ä≤ | Ààxu…æ ≤uÀê | L | ¬† | ¬† | &lt;eadh&gt; ‚Üí …ôd ≤ / _ # PRONOUN | . siad |  É…ôd | Àà ÉiÀêdÀ† | L | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . adharc | ÀàNe:rk | ÀàeÀê…æÀ†kÀ† | L | ¬† | ¬† | ¬† | . isteach | …ôÀà Éd‚Ä≤ax | i ÉÀàt ≤ah | L | ¬† | ¬† | ¬† | . faoin | f ∑i:n | ÀàfÀ†in ≤ | L | ¬† | ¬† | ¬† | . phoit√≠n | Ààf…ît‚Ä≤in‚Ä≤ | ÀàfÀ†ot ≤in ≤ | L+M | ¬† | ¬† | ¬† | . agus | …îg…ôs | ÀàagÀ†…ôsÀ† | L | ¬† | ¬† | ¬† | . chaith | Ààx…ëih | Ààxahj | L | ¬† | ¬† | ¬† | . iad | …ôd | ÀàiadÀ† | L | ¬† | ¬† | ¬† | . insa | nÃ•s…ô | Ààin ≤ÀàsÀ†…ô | ¬† | ¬† | ¬† | ¬† | . teinidh | Ààt‚Ä≤ É…™n‚Ä≤i | Ààt ≤en ≤iÀê | ¬† | ¬† | ¬† | ¬† | . √≠ | i: | ÀàiÀê | L | ¬† | ¬† | ¬† | . Agus | …îg…ôs | ÀàagÀ†…ôsÀ† | L | ¬† | ¬† | ¬† | . nuair | Nu…ôr‚Ä≤ | Àà…¥À†uÀê…æ ≤ | L | ¬† | ¬† | ¬† | . a | …ô | …ô | L | ¬† | ¬† | ¬† | . thiocfadh | hoÃ§ku | ÀàhjokÀ†uÀê | L | ¬† | ¬† | ¬† | . an | nÃ• | Àà…ô…¥À† | L | ¬† | ¬† | …ô ‚Üí ‚àÖ / V # _ | . bladhaire | Ààbl·¥áir‚Ä≤…ô | ÀàbÀ† üÀ†eÀê…æ ≤…ô | L | ¬† | ¬† | ¬† | . bh√≠ | vi: | Ààv ≤iÀê | L | ¬† | ¬† | ¬† | . s√© |  É…õ | Àà ÉeÀê | L | ¬† | ¬† | ¬† | . i | ¬† | Àài | L | ¬† | ¬† | ¬† | . dt√≥lamh | Ààd…î:l…ôf‚Ä≤ | ÀàdÀ†oÀê üÀ†uÀê | L+M | ¬† | ¬† | ¬† | . ar | …õr | Ààe…æ ≤ | L | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . phoit√≠n | Ààf…ît‚Ä≤in‚Ä≤ | ÀàfÀ†ot ≤in ≤ | L+M | ¬† | ¬† | ¬† | . Agus | …îg…ôs | ÀàagÀ†…ôsÀ† | L | ¬† | ¬† | ¬† | . nuair | Nu…ôr‚Ä≤ | Àà…¥À†uÀê…æ ≤ | L | ¬† | ¬† | ¬† | . a | …ô | …ô | L | ¬† | ¬† | ¬† | . th√©igheadh | Ààhe:w…ôd‚Ä≤ | ÀàheÀêjuÀê | ¬† | th√©adh | ÀàhjeÀêh | ¬† | . s√≠ |  Éi: | Àà ÉiÀê | L | ¬† | ¬† | ¬† | . a | ¬† | …ô | L | ¬† | ¬† | …ô ‚Üí ‚àÖ / V # _ | . chur | xoÃ§r | Ààxu…æÀ† | L | ¬† | ¬† | ¬† | . an | …ô | Àà…ô…¥À† | L | ¬† | ¬† | ¬† | . teinidh | Ààt‚Ä≤ É…™n‚Ä≤i | Ààt ≤en ≤iÀê | ¬† | tine | ¬† | ¬† | . as | √Øs | ÀàasÀ† | L | ¬† | ¬† | ¬† | . bh√≠ | vi: | Ààv ≤iÀê | L | ¬† | ¬† | ¬† | . an | nÃ• | Àà…ô…¥À† | L | ¬† | ¬† | …ô ‚Üí ‚àÖ / V # _ | . poit√≠n | Ààp…ît‚Ä≤in‚Ä≤ | ÀàpÀ†ot ≤in ≤ | L | ¬† | ¬† | ¬† | . ac√∫ | …îku | ÀàakÀ†uÀê | ¬† | ¬† | ¬† | ¬† | . O‚ÄôNeill, John E. ‚ÄúIrish Texts from South West Donegal.‚Äù Zeitschrift F√ºr Celtische Philologie, vol. 33, 1974, doi:10.1515/zcph.1974.33.1.285.¬†&#8617; . |",
            "url": "https://jimregan.github.io/notes/irish/donegal/2021/01/24/irish-texts-from-south-west-donegal-text-1-poitin.html",
            "relUrl": "/irish/donegal/2021/01/24/irish-texts-from-south-west-donegal-text-1-poitin.html",
            "date": " ‚Ä¢ Jan 24, 2021"
        }
        
    
  
    
        ,"post130": {
            "title": "In√≠on an cheanna√≠",
            "content": "T√° tamall fad anois a bh√≠ fear ina ch√≥na√≠ i mbaile m√≥r Chorca√≠. Fear saibhir agus ceanna√≠ farraige ab ea √©. Do bh√≠odh loingeas ag teacht thar l√°r ch√∫ige. Do bh√≠ aon in√≠on amh√°in aige gurb √© an ainm a bh√≠ uirthi M√°ire Bh√°n. Do sh√≠l s√≠ an ainm sin mar n√≠ raibh s√≠ sa bhaile mh√≥r aon chail√≠n comh deas comh maorga l√©i. N√≠ raibh √©inne clainne aige ina muintir ach √≠ agus do mh√©adaigh sin urraim agus gr√° na ndaoine don in√≠on √≥g so. . Ba ghn√°thach l√©i captaen √≥g loinge teacht ar cuairt go tigh an cheanna√≠ go minic agus bh√≠odh s√© an-chean√∫il ar Mh√°ire bh√°n. Bh√≠ M√°ire ag titim i ngr√° leis i gan fhios di f√©in. Nuair a im√≠odh s√© √≥n gcuan bh√≠odh uaigneas agus d√≠om√° an domhain uirthi ach n√≠ bh√≠odh fhios aici cad √© an f√°th. N√≠ raibh aon fhear √≥g uasal timpeall n√° go raibh √© tn√∫th le M√°ire Bh√°n i dh√°il le p√≥sadh ach n√≠ raibh aon mhaith dena bheith √° lorg. N√≠ ph√≥sadh s√≠ aon fhear ach a captaen √≥g. N√≠or mhaith lena muintir √≠ (a) thabhairt le p√≥sadh d√≥san. Do b‚Äôfhearr leo √≠ a bheith ina gc√≥ngar f√©in. D‚Äôfhan M√°ire blianta gan p√≥sadh. Deireadh s√≠ ina haigne f√©in ‚Äúd√° bheadh m‚Äôathair b√°s bheadh s√© ar mo chumas mo reogha fear a ph√≥sadh.‚Äù .",
            "url": "https://jimregan.github.io/notes/irish/2021/01/16/in%C3%ADon-an-cheanna%C3%AD.html",
            "relUrl": "/irish/2021/01/16/in%C3%ADon-an-cheanna%C3%AD.html",
            "date": " ‚Ä¢ Jan 16, 2021"
        }
        
    
  
    
        ,"post131": {
            "title": "Dinneen, p. 34",
            "content": "ainmheas, -a and -ta, m., disrespect. . ainmheasartha, indec. a., unmeasured, immoderate, intemperate. . ainmheasarthacht, -a, f., immoderateness, excess, intemperance. . ainmheisneach, -nigh and -nighe, m. and f., rashness, hesitancy, weakness, state of discouragement (m. in M.). . ainmheon, a., busy (Clare). . ainmhian, -mh√©ine, pl. -a, and -ta, dpl. ainmhianaibh (Kea.), f., lust, concupiscence, passion; ainmhianta na colna, the concupiscence of the flesh. . ainmhianach, -aighe, a., passionate, lustful, sensual. . ainmhidhe, g. id., pl. ainmhinte and ainmhidhthe, m., a brute, an animal. . ainmhidheach, -dhighe, a., brutish, beastly. . ainmhidheacht, -a, f., brutality. . ainmh√≠n, -e, a., rough, passionate. . ainmh√≠ne, g. id., f., roughness, coarseness, passionateness. . ainmneach, -nighe, a., famous, illustrious. . ainmneamhail, -mhla, a., famous. . ainmnighim, -iughadh, v. tr., I name, assign. . ainmnighthe, p. a., named, specified; go ha., namely. . ainmniughadh, -ighthe, m., act of naming, denomination, dedication. . ainnir (ainnear), -nire, pl. id., f., a maiden; is √≠ &#39;na hainnir bhig, while she was a young maiden. . ainreacht (ainriocht), -a, pl. id., m., evil plight. . ainriachtanach, -aighe, a., necessitous, poor, miserable. . ainriachtanas, -ais, m., extreme danger, great misery or necessity. . ainriochtach, -aighe, a., pitiable. See riocht. . ainscian, -cine, pl. -ceanna, f., a large knife; fury, extravagance; a furious or wild person. . ainscianach, -aighe, a., furious, extravagant. . ainscianta, indecl. a., furious, extravagant. . ainshearc, g. -eirce and -earca, f., hatred. . ainshearc, m. and f., excessive love. . ainshearcach, -aighe, a., unloving, merciless, cruel. . ainsheascair, -e, a., troublous, uneasy, uncomfortable. . ainspioraid, -e, -idhe, f., an evil spirit; the devil. . ainshrianta, a., unbridled, debauched. . ainshriantacht, -a., f., libertinism, debauchery, unbridled passion. . ainteann, -einne, a., very violent, oppressive, severe; braced up, very stiff, very stout. . ainteas, -a, m., great heat, inflammation, wrath. . ainteasach, -aighe, a., hot, feverish. . ainteasaidhe, indec. a., sultry, warm (of weather). . ainteastach, -aigh, pl. id., m., a false witness; ‚Äúainteastach br√©ag,‚Äù a base asserter of lies (Kea.); ‚Äúinnisin sc√©al ainteastach do bh√≠ fuathmhar d√≥‚Äù (id.). . ainteastach, -aighe, a., falsely testified. . aintighearna, g. id., pl., -idhe, m., a tyrant, an oppressor. . aintighearnacht, -a, f., tyranny, oppression. . aipche, g. id., f., maturity (from abaidh, ripe). . aipidh, see abaid. . air, prep., on, upon, etc.; more generally written ar, which see. . air, prep, pr., m., upon him or it. See ar, prep. . airc, -e, f., greed, voracity; g√©ar-airc (O&#39;Ra.) want, hardship (Don.). . airc, in phr. gheall s√© na huirc is na hairc dam, he promised me the world and all. . airc, -e, -eacha, f., a chest, a coffer; an ark. . airc, in various meanings, as a lizard, etc. See earc and arc. .",
            "url": "https://jimregan.github.io/notes/irish/dinneen/2021/01/09/dinneen-p-34.html",
            "relUrl": "/irish/dinneen/2021/01/09/dinneen-p-34.html",
            "date": " ‚Ä¢ Jan 9, 2021"
        }
        
    
  
    
        ,"post132": {
            "title": "Evernote web clips, 16/10/2020",
            "content": "High or low? Comparing high and low-variability phonetic training in adult and child second language learners . Introducing LexTALE: A quick and valid Lexical Test for Advanced Learners of English . A Tutorial on Extracting Formants in Praat . A Dive Into GhostNet with PyTorch and TensorFlow .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/praat/2020/10/16/evernote-links.html",
            "relUrl": "/evernote/web%20clip/praat/2020/10/16/evernote-links.html",
            "date": " ‚Ä¢ Oct 16, 2020"
        }
        
    
  
    
        ,"post133": {
            "title": "Evernote web clips, 5/10/2020",
            "content": "How to use multiple keywords in Pocketsphinx continuous mode . Richer Sentence Embeddings using Sentence-BERT ‚Äî Part I . Examples of synthesizing sounds with Praat VocalTract area functions . Recommendations for Real-Time Speech MRI .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2020/10/05/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2020/10/05/evernote-links.html",
            "date": " ‚Ä¢ Oct 5, 2020"
        }
        
    
  
    
        ,"post134": {
            "title": "Evernote web clips, 29/9/2020",
            "content": "Poor Man‚Äôs BERT - Exploring layer pruning . Computing MFCCs voice recognition features on ARM systems . Beginner‚Äôs guide to Speech Analysis . Yes you should understand backprop . Long Form Question Answering with ELI5 and Wikipedia . A Framework For Contrastive Self-Supervised Learning And Designing A New Approach . DeepSpeech-Polyglot-PL - Google Drive . Speech Recognition ‚Äî ASR Model Training .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2020/09/29/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2020/09/29/evernote-links.html",
            "date": " ‚Ä¢ Sep 29, 2020"
        }
        
    
  
    
        ,"post135": {
            "title": "Training spaCy on IDT",
            "content": "!git clone https://github.com/UniversalDependencies/UD_Irish-IDT . Cloning into &#39;UD_Irish-IDT&#39;... remote: Enumerating objects: 32, done. remote: Counting objects: 100% (32/32), done. remote: Compressing objects: 100% (23/23), done. remote: Total 328 (delta 14), reused 25 (delta 9), pack-reused 296 Receiving objects: 100% (328/328), 3.63 MiB | 12.73 MiB/s, done. Resolving deltas: 100% (182/182), done. . !mkdir idt-json . !python -m spacy convert /content/UD_Irish-IDT/ga_idt-ud-train.conllu /content/idt-json . ‚úî Generated output file (2019 documents): /content/idt-json/ga_idt-ud-train.json . !python -m spacy convert /content/UD_Irish-IDT/ga_idt-ud-dev.conllu /content/idt-json . ‚úî Generated output file (451 documents): /content/idt-json/ga_idt-ud-dev.json . !wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ga.300.vec.gz !python -m spacy init-model ga /content/ga_vectors_cc --vectors-loc cc.ga.300.vec.gz . --2020-09-14 17:16:11-- https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ga.300.vec.gz Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.75.142, 104.22.74.142, ... Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 184422000 (176M) [binary/octet-stream] Saving to: ‚Äòcc.ga.300.vec.gz‚Äô cc.ga.300.vec.gz 100%[===================&gt;] 175.88M 44.2MB/s in 4.0s 2020-09-14 17:16:16 (43.8 MB/s) - ‚Äòcc.ga.300.vec.gz‚Äô saved [184422000/184422000] ‚úî Successfully created model 316836it [00:27, 11398.56it/s] ‚úî Loaded vectors from cc.ga.300.vec.gz ‚úî Sucessfully compiled vocab 317041 entries, 316836 vectors . WikiANN is currently only available through Google Drive . from google.colab import drive drive.mount(&#39;/gdrive&#39;) . Mounted at /gdrive . !cp /gdrive/My Drive/ga.tar.gz . . !tar zxvf ga.tar.gz . README.txt wikiann-ga.bio . !wget http://downloads.dbpedia.org/links/resources/wikidatadump/2017-07-07/enwiki/20170701/enwiki-20170701-interlanguage-links_wikidataorg.ttl . --2020-09-14 17:15:11-- http://downloads.dbpedia.org/links/resources/wikidatadump/2017-07-07/enwiki/20170701/enwiki-20170701-interlanguage-links_wikidataorg.ttl Resolving downloads.dbpedia.org (downloads.dbpedia.org)... 139.18.16.66 Connecting to downloads.dbpedia.org (downloads.dbpedia.org)|139.18.16.66|:80... connected. HTTP request sent, awaiting response... 200 OK Length: 1020894244 (974M) [text/turtle] Saving to: ‚Äòenwiki-20170701-interlanguage-links_wikidataorg.ttl‚Äô enwiki-20170701-int 100%[===================&gt;] 973.60M 18.7MB/s in 54s 2020-09-14 17:16:05 (18.1 MB/s) - ‚Äòenwiki-20170701-interlanguage-links_wikidataorg.ttl‚Äô saved [1020894244/1020894244] . !cat wikiann-ga.bio | awk &#39;(NF == 7){print $6}&#39;|sort|uniq|while read i;do grep &quot;/$i&gt;&quot; enwiki-20170701-interlanguage-links_wikidataorg.ttl &gt;&gt; filtered;done . !pip install danlp . Collecting danlp Downloading https://files.pythonhosted.org/packages/3c/79/96d0d3f3634ce75787d408383fa81cdd854552e27e4e279a985b511a6d88/danlp-0.0.9-py3-none-any.whl Collecting pyconll Downloading https://files.pythonhosted.org/packages/2c/6e/c325d0db05ac1b8d45645de903e4ba691d419e861c915c3d4ebfcaf8ac25/pyconll-2.2.1-py3-none-any.whl Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from danlp) (4.41.1) Requirement already satisfied: tweepy in /usr/local/lib/python3.6/dist-packages (from danlp) (3.6.0) Requirement already satisfied: requests&gt;=2.21 in /usr/local/lib/python3.6/dist-packages (from pyconll-&gt;danlp) (2.23.0) Requirement already satisfied: six&gt;=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy-&gt;danlp) (1.15.0) Requirement already satisfied: PySocks&gt;=1.5.7 in /usr/local/lib/python3.6/dist-packages (from tweepy-&gt;danlp) (1.7.1) Requirement already satisfied: requests-oauthlib&gt;=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy-&gt;danlp) (1.3.0) Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests&gt;=2.21-&gt;pyconll-&gt;danlp) (2020.6.20) Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.6/dist-packages (from requests&gt;=2.21-&gt;pyconll-&gt;danlp) (2.10) Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests&gt;=2.21-&gt;pyconll-&gt;danlp) (1.24.3) Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests&gt;=2.21-&gt;pyconll-&gt;danlp) (3.0.4) Requirement already satisfied: oauthlib&gt;=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib&gt;=0.7.0-&gt;tweepy-&gt;danlp) (3.1.0) Installing collected packages: pyconll, danlp Successfully installed danlp-0.0.9 pyconll-2.2.1 . import danlp.datasets.wiki_ann wa = danlp.datasets.wiki_ann._convert_wikiann_to_iob(&#39;wikiann-ga.bio&#39;, &#39;wikiann-ga.ner&#39;) . !head out . Colm _ _ B-PER √ì _ _ I-PER Ruairc _ _ I-PER Seosamh _ _ B-PER √ì _ _ I-PER Cain√≠n _ _ I-PER D√≥nal _ _ B-PER √ì _ _ I-PER . !python -m spacy convert -n 10 wikiann-ga.ner /content/idt-json/ . ‚Ñπ Auto-detected token-per-line NER format ‚Ñπ Grouping every 10 sentences into a document. ‚úî Generated output file (757 documents): /content/idt-json/wikiann-ga.json . !rm -rf models !mkdir models !python -m spacy train -v /content/ga_vectors_cc -p &#39;tagger,parser,ner&#39; ga models idt-json/ga_idt-ud-train.json idt-json/ga_idt-ud-dev.json . Training pipeline: [&#39;tagger&#39;, &#39;parser&#39;] Starting with blank model &#39;ga&#39; Loading vector from model &#39;/content/ga_vectors_cc&#39; Counting training words (limit=0) /usr/lib/python3.6/runpy.py:193: UserWarning: [W022] Training a new part-of-speech tagger using a model with no lemmatization rules or data. This means that the trained model may not be able to lemmatize correctly. If this is intentional or the language you&#39;re using doesn&#39;t have lemmatization data, you can ignore this warning by setting SPACY_WARNING_IGNORE=W022. If this is surprising, make sure you have the spacy-lookups-data package installed. &#34;__main__&#34;, mod_spec) Itn Tag Loss Tag % Dep Loss UAS LAS Token % CPU WPS -- - - 1 14058.829 90.650 43482.222 74.804 56.787 100.000 11293 2 6188.294 92.810 34097.493 79.836 66.009 100.000 11461 3 4475.949 93.400 30061.441 81.314 69.572 100.000 11930 4 3549.242 93.530 27752.841 82.784 71.759 100.000 11719 5 2916.639 93.570 25861.771 83.066 72.401 100.000 11616 6 2438.355 93.550 24533.545 83.133 72.726 100.000 12227 7 2084.913 93.500 22901.218 83.281 73.043 100.000 11842 8 1845.607 93.610 21836.129 83.516 73.346 100.000 12094 9 1698.212 93.630 20626.109 83.555 73.507 100.000 11907 10 1406.626 93.570 19251.761 83.712 73.978 100.000 11926 11 1366.677 93.620 18882.570 83.896 74.128 100.000 12023 12 1209.500 93.610 17836.598 83.968 74.177 100.000 11924 13 1140.886 93.640 17341.624 84.098 74.375 100.000 11522 14 1043.542 93.670 16748.375 83.992 74.292 100.000 11766 15 926.876 93.700 15727.938 84.183 74.572 100.000 11931 16 848.805 93.680 15002.112 84.059 74.427 100.000 11750 17 857.415 93.760 14686.168 84.075 74.465 100.000 11724 18 775.277 93.750 14028.872 84.091 74.603 100.000 11890 19 651.078 93.680 13698.526 84.215 74.794 100.000 11932 20 672.552 93.670 13036.999 84.356 74.879 100.000 11724 21 590.244 93.670 12162.862 84.468 75.048 100.000 11851 22 593.722 93.680 12494.905 84.441 75.122 100.000 11910 23 582.541 93.660 12110.757 84.351 75.032 100.000 11544 24 514.448 93.690 11635.750 84.232 74.879 100.000 11984 25 491.457 93.640 10942.966 84.226 74.816 100.000 12106 26 521.324 93.660 10958.952 84.232 74.779 100.000 12112 27 507.717 93.650 10907.860 84.255 74.790 100.000 11754 28 485.186 93.660 10149.477 84.143 74.666 100.000 11411 29 507.038 93.720 10331.116 84.165 74.644 100.000 11740 30 477.966 93.700 9649.121 84.300 74.891 100.000 11300 ‚úî Saved model to output directory models/model-final ‚úî Created best model models/model-best . !mkdir modelout !python -m spacy package --meta meta.json /content/models/model-best modelout . ‚úî Loaded meta.json from file meta.json ‚úî Successfully created package &#39;ga_idt_lg-1.0.0&#39; modelout/ga_idt_lg-1.0.0 To build the package, run `python setup.py sdist` in this directory. . import os os.chdir(&#39;/content/modelout/ga_idt_lg-1.0.0&#39;) !python setup.py sdist . running sdist running egg_info creating ga_idt_lg.egg-info writing ga_idt_lg.egg-info/PKG-INFO writing dependency_links to ga_idt_lg.egg-info/dependency_links.txt writing requirements to ga_idt_lg.egg-info/requires.txt writing top-level names to ga_idt_lg.egg-info/top_level.txt writing manifest file &#39;ga_idt_lg.egg-info/SOURCES.txt&#39; reading manifest file &#39;ga_idt_lg.egg-info/SOURCES.txt&#39; reading manifest template &#39;MANIFEST.in&#39; writing manifest file &#39;ga_idt_lg.egg-info/SOURCES.txt&#39; warning: sdist: standard file not found: should have one of README, README.rst, README.txt, README.md running check creating ga_idt_lg-1.0.0 creating ga_idt_lg-1.0.0/ga_idt_lg creating ga_idt_lg-1.0.0/ga_idt_lg.egg-info creating ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0 creating ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/parser creating ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/tagger creating ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/vocab copying files to ga_idt_lg-1.0.0... copying MANIFEST.in -&gt; ga_idt_lg-1.0.0 copying meta.json -&gt; ga_idt_lg-1.0.0 copying setup.py -&gt; ga_idt_lg-1.0.0 copying ga_idt_lg/__init__.py -&gt; ga_idt_lg-1.0.0/ga_idt_lg copying ga_idt_lg/meta.json -&gt; ga_idt_lg-1.0.0/ga_idt_lg copying ga_idt_lg.egg-info/PKG-INFO -&gt; ga_idt_lg-1.0.0/ga_idt_lg.egg-info copying ga_idt_lg.egg-info/SOURCES.txt -&gt; ga_idt_lg-1.0.0/ga_idt_lg.egg-info copying ga_idt_lg.egg-info/dependency_links.txt -&gt; ga_idt_lg-1.0.0/ga_idt_lg.egg-info copying ga_idt_lg.egg-info/not-zip-safe -&gt; ga_idt_lg-1.0.0/ga_idt_lg.egg-info copying ga_idt_lg.egg-info/requires.txt -&gt; ga_idt_lg-1.0.0/ga_idt_lg.egg-info copying ga_idt_lg.egg-info/top_level.txt -&gt; ga_idt_lg-1.0.0/ga_idt_lg.egg-info copying ga_idt_lg/ga_idt_lg-1.0.0/meta.json -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0 copying ga_idt_lg/ga_idt_lg-1.0.0/tokenizer -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0 copying ga_idt_lg/ga_idt_lg-1.0.0/parser/cfg -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/parser copying ga_idt_lg/ga_idt_lg-1.0.0/parser/model -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/parser copying ga_idt_lg/ga_idt_lg-1.0.0/parser/moves -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/parser copying ga_idt_lg/ga_idt_lg-1.0.0/tagger/cfg -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/tagger copying ga_idt_lg/ga_idt_lg-1.0.0/tagger/model -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/tagger copying ga_idt_lg/ga_idt_lg-1.0.0/tagger/tag_map -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/tagger copying ga_idt_lg/ga_idt_lg-1.0.0/vocab/key2row -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/vocab copying ga_idt_lg/ga_idt_lg-1.0.0/vocab/lexemes.bin -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/vocab copying ga_idt_lg/ga_idt_lg-1.0.0/vocab/strings.json -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/vocab copying ga_idt_lg/ga_idt_lg-1.0.0/vocab/vectors -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/vocab Writing ga_idt_lg-1.0.0/setup.cfg creating dist Creating tar archive removing &#39;ga_idt_lg-1.0.0&#39; (and everything under it) . !cat /content/models/model-best/meta.json . { &#34;lang&#34;:&#34;ga&#34;, &#34;name&#34;:&#34;model&#34;, &#34;version&#34;:&#34;0.0.0&#34;, &#34;spacy_version&#34;:&#34;&gt;=2.2.4&#34;, &#34;description&#34;:&#34;&#34;, &#34;author&#34;:&#34;&#34;, &#34;email&#34;:&#34;&#34;, &#34;url&#34;:&#34;&#34;, &#34;license&#34;:&#34;&#34;, &#34;vectors&#34;:{ &#34;width&#34;:300, &#34;vectors&#34;:316836, &#34;keys&#34;:316836, &#34;name&#34;:&#34;ga_model.vectors&#34; }, &#34;pipeline&#34;:[ &#34;tagger&#34;, &#34;parser&#34; ], &#34;factories&#34;:{ &#34;tagger&#34;:&#34;tagger&#34;, &#34;parser&#34;:&#34;parser&#34; }, &#34;labels&#34;:{ &#34;tagger&#34;:[ &#34;!&#34;, &#34;.&#34;, &#34;...&#34;, &#34;?&#34;, &#34;Abr&#34;, &#34;Ad&#34;, &#34;Adj&#34;, &#34;Art&#34;, &#34;CM&#34;, &#34;CU&#34;, &#34;Cmp&#34;, &#34;Cmpd&#34;, &#34;CmpdNoGen&#34;, &#34;Comp&#34;, &#34;Cond&#34;, &#34;Coord&#34;, &#34;Cop&#34;, &#34;Cp&#34;, &#34;Deg&#34;, &#34;Dem&#34;, &#34;Det&#34;, &#34;Dir&#34;, &#34;Foreign&#34;, &#34;FutInd&#34;, &#34;Gn&#34;, &#34;Idf&#34;, &#34;Imper&#34;, &#34;Inf&#34;, &#34;Item&#34;, &#34;Itj&#34;, &#34;Its&#34;, &#34;Loc&#34;, &#34;Nm&#34;, &#34;Noun&#34;, &#34;Num&#34;, &#34;PastImp&#34;, &#34;PastInd&#34;, &#34;Pat&#34;, &#34;Pers&#34;, &#34;Poss&#34;, &#34;Prep&#34;, &#34;PresImp&#34;, &#34;PresInd&#34;, &#34;PresSubj&#34;, &#34;Pron&#34;, &#34;Punct&#34;, &#34;Q&#34;, &#34;Ref&#34;, &#34;Rel&#34;, &#34;Simp&#34;, &#34;Subord&#34;, &#34;Subst&#34;, &#34;Sup&#34;, &#34;Temp&#34;, &#34;Unknown&#34;, &#34;VD&#34;, &#34;VI&#34;, &#34;VT&#34;, &#34;VTI&#34;, &#34;Vb&#34;, &#34;Voc&#34;, &#34;Web&#34;, &#34;_SP&#34;, &#34;cionn&#34; ], &#34;parser&#34;:[ &#34;ROOT&#34;, &#34;acl:relcl&#34;, &#34;advcl&#34;, &#34;advmod&#34;, &#34;amod&#34;, &#34;appos&#34;, &#34;case&#34;, &#34;cc&#34;, &#34;ccomp&#34;, &#34;compound&#34;, &#34;conj&#34;, &#34;cop&#34;, &#34;csubj:cleft&#34;, &#34;csubj:cop&#34;, &#34;dep&#34;, &#34;det&#34;, &#34;fixed&#34;, &#34;flat&#34;, &#34;flat:name&#34;, &#34;mark&#34;, &#34;mark:prt&#34;, &#34;nmod&#34;, &#34;nmod:poss&#34;, &#34;nsubj&#34;, &#34;nummod&#34;, &#34;obj&#34;, &#34;obl&#34;, &#34;obl:prep&#34;, &#34;obl:tmod&#34;, &#34;parataxis&#34;, &#34;punct&#34;, &#34;xcomp&#34;, &#34;xcomp:pred&#34; ] }, &#34;accuracy&#34;:{ &#34;tags_acc&#34;:92.23, &#34;token_acc&#34;:100.0, &#34;las&#34;:68.3640850205, &#34;uas&#34;:80.5899837362, &#34;las_per_type&#34;:{ &#34;nummod&#34;:{ &#34;p&#34;:70.0, &#34;r&#34;:61.5384615385, &#34;f&#34;:65.4970760234 }, &#34;root&#34;:{ &#34;p&#34;:88.0266075388, &#34;r&#34;:88.0266075388, &#34;f&#34;:88.0266075388 }, &#34;case&#34;:{ &#34;p&#34;:88.8535031847, &#34;r&#34;:91.7763157895, &#34;f&#34;:90.2912621359 }, &#34;obl&#34;:{ &#34;p&#34;:47.0031545741, &#34;r&#34;:54.9815498155, &#34;f&#34;:50.6802721088 }, &#34;mark:prt&#34;:{ &#34;p&#34;:71.1538461538, &#34;r&#34;:81.9620253165, &#34;f&#34;:76.1764705882 }, &#34;ccomp&#34;:{ &#34;p&#34;:40.2777777778, &#34;r&#34;:47.5409836066, &#34;f&#34;:43.6090225564 }, &#34;nsubj&#34;:{ &#34;p&#34;:75.1824817518, &#34;r&#34;:79.7213622291, &#34;f&#34;:77.3854244929 }, &#34;obj&#34;:{ &#34;p&#34;:55.5555555556, &#34;r&#34;:49.2957746479, &#34;f&#34;:52.2388059701 }, &#34;nmod&#34;:{ &#34;p&#34;:52.912142152, &#34;r&#34;:54.8618219038, &#34;f&#34;:53.8693467337 }, &#34;mark&#34;:{ &#34;p&#34;:82.7715355805, &#34;r&#34;:72.6973684211, &#34;f&#34;:77.408056042 }, &#34;xcomp&#34;:{ &#34;p&#34;:60.4743083004, &#34;r&#34;:65.3846153846, &#34;f&#34;:62.8336755647 }, &#34;acl:relcl&#34;:{ &#34;p&#34;:47.2602739726, &#34;r&#34;:53.488372093, &#34;f&#34;:50.1818181818 }, &#34;xcomp:pred&#34;:{ &#34;p&#34;:44.0476190476, &#34;r&#34;:59.6774193548, &#34;f&#34;:50.6849315068 }, &#34;amod&#34;:{ &#34;p&#34;:57.5438596491, &#34;r&#34;:54.3046357616, &#34;f&#34;:55.8773424191 }, &#34;det&#34;:{ &#34;p&#34;:92.8480204342, &#34;r&#34;:94.0491591203, &#34;f&#34;:93.4447300771 }, &#34;csubj:cleft&#34;:{ &#34;p&#34;:47.2222222222, &#34;r&#34;:27.4193548387, &#34;f&#34;:34.693877551 }, &#34;obl:prep&#34;:{ &#34;p&#34;:77.6041666667, &#34;r&#34;:65.6387665198, &#34;f&#34;:71.1217183771 }, &#34;advcl&#34;:{ &#34;p&#34;:54.4, &#34;r&#34;:49.2753623188, &#34;f&#34;:51.711026616 }, &#34;parataxis&#34;:{ &#34;p&#34;:42.4242424242, &#34;r&#34;:27.4509803922, &#34;f&#34;:33.3333333333 }, &#34;nmod:poss&#34;:{ &#34;p&#34;:73.4939759036, &#34;r&#34;:75.3086419753, &#34;f&#34;:74.3902439024 }, &#34;cc&#34;:{ &#34;p&#34;:78.9473684211, &#34;r&#34;:79.5454545455, &#34;f&#34;:79.2452830189 }, &#34;conj&#34;:{ &#34;p&#34;:42.7609427609, &#34;r&#34;:42.0529801325, &#34;f&#34;:42.4040066778 }, &#34;dep&#34;:{ &#34;p&#34;:0.0, &#34;r&#34;:0.0, &#34;f&#34;:0.0 }, &#34;compound&#34;:{ &#34;p&#34;:75.0, &#34;r&#34;:26.0869565217, &#34;f&#34;:38.7096774194 }, &#34;flat&#34;:{ &#34;p&#34;:64.1025641026, &#34;r&#34;:64.9350649351, &#34;f&#34;:64.5161290323 }, &#34;cop&#34;:{ &#34;p&#34;:69.3251533742, &#34;r&#34;:70.625, &#34;f&#34;:69.9690402477 }, &#34;flat:name&#34;:{ &#34;p&#34;:63.4782608696, &#34;r&#34;:51.4084507042, &#34;f&#34;:56.8093385214 }, &#34;obl:tmod&#34;:{ &#34;p&#34;:66.6666666667, &#34;r&#34;:2.7397260274, &#34;f&#34;:5.2631578947 }, &#34;advmod&#34;:{ &#34;p&#34;:66.2745098039, &#34;r&#34;:65.0, &#34;f&#34;:65.6310679612 }, &#34;appos&#34;:{ &#34;p&#34;:21.9512195122, &#34;r&#34;:20.9302325581, &#34;f&#34;:21.4285714286 }, &#34;flat:foreign&#34;:{ &#34;p&#34;:0.0, &#34;r&#34;:0.0, &#34;f&#34;:0.0 }, &#34;fixed&#34;:{ &#34;p&#34;:74.7663551402, &#34;r&#34;:61.0687022901, &#34;f&#34;:67.2268907563 }, &#34;csubj:cop&#34;:{ &#34;p&#34;:62.5, &#34;r&#34;:55.5555555556, &#34;f&#34;:58.8235294118 }, &#34;discourse&#34;:{ &#34;p&#34;:0.0, &#34;r&#34;:0.0, &#34;f&#34;:0.0 }, &#34;case:voc&#34;:{ &#34;p&#34;:0.0, &#34;r&#34;:0.0, &#34;f&#34;:0.0 }, &#34;vocative&#34;:{ &#34;p&#34;:0.0, &#34;r&#34;:0.0, &#34;f&#34;:0.0 } } }, &#34;speed&#34;:{ &#34;cpu&#34;:13038.7132631094, &#34;gpu&#34;:null, &#34;nwords&#34;:10000 } } . import os os.chdir(&#39;/content&#39;) !rm -rf modelout !mkdir modelout !rm meta.json . !cat meta.json . { &#34;name&#34;: &#34;ga_idt_sm&#34;, &#34;lang&#34;: &#34;ga&#34;, &#34;version&#34;: &#34;1.0.0&#34;, &#34;spacy_version&#34;: &#34;&gt;=2.0.0,&lt;3.0.0&#34;, &#34;description&#34;: &#34;Irish model for spaCy trained on IDT&#34;, &#34;author&#34;: &#34;Jim O&#39;Regan&#34;, &#34;email&#34;: &#34;jaoregan@tcd.ie&#34;, &#34;license&#34;: &#34;CC BY-SA 3.0&#34;, &#34;pipeline&#34;: [&#34;tagger&#34;, &#34;parser&#34;, &#34;ner&#34;] } .",
            "url": "https://jimregan.github.io/notes/spacy/idt/2020/09/14/train-spacy-idt.html",
            "relUrl": "/spacy/idt/2020/09/14/train-spacy-idt.html",
            "date": " ‚Ä¢ Sep 14, 2020"
        }
        
    
  
    
        ,"post136": {
            "title": "Evernote web clips, 30/8/2020",
            "content": "Language-Agnostic BERT Sentence Embedding . End-to-End Automatic Pronunciation Error Detection Based on Improved Hybrid CTC/Attention Architecture . Festival Speech Synthesis System - 13 Lexicons . awslabs/mlm-scoring .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2020/08/30/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2020/08/30/evernote-links.html",
            "date": " ‚Ä¢ Aug 30, 2020"
        }
        
    
  
    
        ,"post137": {
            "title": "Javascript hoops",
            "content": "!git clone https://github.com/jimregan/coco-ssd-ga . Cloning into &#39;coco-ssd-ga&#39;... remote: Enumerating objects: 55, done. remote: Counting objects: 100% (55/55), done. remote: Compressing objects: 100% (38/38), done. remote: Total 55 (delta 17), reused 48 (delta 14), pack-reused 0 Unpacking objects: 100% (55/55), done. . import os os.chdir(&#39;coco-ssd-ga&#39;) . !npm install -g yarn rimraf browserify typescript ts-node @tensorflow/tfjs-core @tensorflow/tfjs-converter . &gt; yarn@1.22.10 preinstall /tools/node/lib/node_modules/yarn &gt; :; (node ./preinstall.js &gt; /dev/null 2&gt;&amp;1 || true) /tools/node/bin/browserify -&gt; /tools/node/lib/node_modules/browserify/bin/cmd.js /tools/node/bin/rimraf -&gt; /tools/node/lib/node_modules/rimraf/bin.js /tools/node/bin/ts-node -&gt; /tools/node/lib/node_modules/ts-node/dist/bin.js /tools/node/bin/ts-script -&gt; /tools/node/lib/node_modules/ts-node/dist/bin-script-deprecated.js /tools/node/bin/ts-node-script -&gt; /tools/node/lib/node_modules/ts-node/dist/bin-script.js /tools/node/bin/ts-node-transpile-only -&gt; /tools/node/lib/node_modules/ts-node/dist/bin-transpile.js /tools/node/bin/tsc -&gt; /tools/node/lib/node_modules/typescript/bin/tsc /tools/node/bin/tsserver -&gt; /tools/node/lib/node_modules/typescript/bin/tsserver /tools/node/bin/yarn -&gt; /tools/node/lib/node_modules/yarn/bin/yarn.js /tools/node/bin/yarnpkg -&gt; /tools/node/lib/node_modules/yarn/bin/yarn.js + rimraf@3.0.2 + yarn@1.22.10 + browserify@17.0.0 + ts-node@9.1.1 + @tensorflow/tfjs-converter@3.5.0 + @tensorflow/tfjs-core@3.5.0 + typescript@4.2.4 added 203 packages from 137 contributors in 12.754s . !npm install . npm WARN deprecated fsevents@2.1.3: &#34;Please update to latest v2.3 or v2.2&#34; npm WARN deprecated core-js@2.6.12: core-js@&lt;3 is no longer maintained and not recommended for usage due to the number of issues. Please, upgrade your dependencies to the actual version of core-js@3. &gt; core-js@2.6.12 postinstall /content/coco-ssd-ga/node_modules/core-js &gt; node -e &#34;try{require(&#39;./postinstall&#39;)}catch(e){}&#34; Thank you for using core-js ( https://github.com/zloirock/core-js ) for polyfilling JavaScript standard library! The project needs your help! Please consider supporting of core-js on Open Collective or Patreon: &gt; https://opencollective.com/core-js &gt; https://www.patreon.com/zloirock Also, the author of core-js ( https://github.com/zloirock ) is looking for a good job -) npm notice created a lockfile as package-lock.json. You should commit this file. npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@~2.1.2 (node_modules/rollup/node_modules/fsevents): npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@2.1.3: wanted {&#34;os&#34;:&#34;darwin&#34;,&#34;arch&#34;:&#34;any&#34;} (current: {&#34;os&#34;:&#34;linux&#34;,&#34;arch&#34;:&#34;x64&#34;}) npm WARN @rollup/plugin-typescript@3.1.1 requires a peer of rollup@^1.20.0 but none is installed. You must install peer dependencies yourself. added 196 packages from 157 contributors and audited 197 packages in 10.534s 10 packages are looking for funding run `npm fund` for details found 0 vulnerabilities ‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ ‚îÇ ‚îÇ ‚îÇ New major version of npm available! 6.14.8 ‚Üí 7.11.1 ‚îÇ ‚îÇ Changelog: https://github.com/npm/cli/releases/tag/v7.11.1 ‚îÇ ‚îÇ Run npm install -g npm to update! ‚îÇ ‚îÇ ‚îÇ ‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ . !yarn build . yarn run v1.22.10 $ rimraf dist &amp;&amp; tsc Done in 6.76s. . !npm install yalc . npm WARN @rollup/plugin-typescript@3.1.1 requires a peer of rollup@^1.20.0 but none is installed. You must install peer dependencies yourself. npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@2.1.3 (node_modules/fsevents): npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@2.1.3: wanted {&#34;os&#34;:&#34;darwin&#34;,&#34;arch&#34;:&#34;any&#34;} (current: {&#34;os&#34;:&#34;linux&#34;,&#34;arch&#34;:&#34;x64&#34;}) + yalc@1.0.0-pre.51 updated 1 package and audited 197 packages in 2.25s 8 packages are looking for funding run `npm fund` for details found 0 vulnerabilities . !npm install -g cross-env . /tools/node/bin/cross-env -&gt; /tools/node/lib/node_modules/cross-env/src/bin/cross-env.js /tools/node/bin/cross-env-shell -&gt; /tools/node/lib/node_modules/cross-env/src/bin/cross-env-shell.js + cross-env@7.0.3 added 7 packages from 5 contributors in 0.789s . !npm install -g @tensorflow/tfjs-core @tensorflow/tfjs-converter rollup yalc !npm install --save install !yarn run publish-local . . /tools/node/bin/rollup -&gt; /tools/node/lib/node_modules/rollup/dist/bin/rollup /tools/node/bin/yalc -&gt; /tools/node/lib/node_modules/yalc/src/yalc.js npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@~2.3.1 (node_modules/rollup/node_modules/fsevents): npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@2.3.2: wanted {&#34;os&#34;:&#34;darwin&#34;,&#34;arch&#34;:&#34;any&#34;} (current: {&#34;os&#34;:&#34;linux&#34;,&#34;arch&#34;:&#34;x64&#34;}) + rollup@2.45.2 + yalc@1.0.0-pre.51 + @tensorflow/tfjs-core@3.5.0 + @tensorflow/tfjs-converter@3.5.0 updated 4 packages in 3.883s npm WARN @rollup/plugin-typescript@3.1.1 requires a peer of rollup@^1.20.0 but none is installed. You must install peer dependencies yourself. npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@2.1.3 (node_modules/fsevents): npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@2.1.3: wanted {&#34;os&#34;:&#34;darwin&#34;,&#34;arch&#34;:&#34;any&#34;} (current: {&#34;os&#34;:&#34;linux&#34;,&#34;arch&#34;:&#34;x64&#34;}) + install@0.13.0 added 1 package from 1 contributor and audited 198 packages in 1.647s 10 packages are looking for funding run `npm fund` for details found 0 vulnerabilities yarn run v1.22.10 $ yarn build &amp;&amp; rollup -c &amp;&amp; yalc push . $ rimraf dist &amp;&amp; tsc src/index.ts ‚Üí dist/coco-ssd.node.js... created dist/coco-ssd.node.js in 8.9s coco-ssd-ga@2.1.0 published in store. Done in 16.51s. . !npm install -g browserify . /tools/node/bin/browserify -&gt; /tools/node/lib/node_modules/browserify/bin/cmd.js + browserify@17.0.0 updated 1 package in 4.871s . !npm i minify -g . /tools/node/bin/minify -&gt; /tools/node/lib/node_modules/minify/bin/minify.js + minify@7.0.1 added 26 packages from 52 contributors in 1.951s . !browserify /content/coco-ssd-ga/dist/coco-ssd.node.js --s cocoGa -o /content/coco-ssd-ga/dist/coco-ssd.browser.js . !minify /content/coco-ssd-ga/dist/coco-ssd.browser.js &gt; /content/coco-ssd-ga/dist/coco-ssd.min.js .",
            "url": "https://jimregan.github.io/notes/web/coco-ssd/2020/08/12/coco-ssd-ga.html",
            "relUrl": "/web/coco-ssd/2020/08/12/coco-ssd-ga.html",
            "date": " ‚Ä¢ Aug 12, 2020"
        }
        
    
  
    
        ,"post138": {
            "title": "Evernote web clips, 9/8/2020",
            "content": "LM Rescoring . any example on lattice rescoring for large language model . Lattice re-scoring during manual editing for automatic error correction of ASR transcripts . Neural Network Language Modeling with Letter-Based Features and Importance Sampling . Tutorial - RiveScript.com . An Overview of Multi-Task Learning in Speech Recognition . aalto-speech/subword-kaldi Properly handle position-dependent phones in a subword lexicon FST . wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2020/08/09/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2020/08/09/evernote-links.html",
            "date": " ‚Ä¢ Aug 9, 2020"
        }
        
    
  
    
        ,"post139": {
            "title": "Evernote web clips, 8/7/2020",
            "content": "Muskerry pronunciation . Dive into Deep Learning . One LEGO at a Time - Explaining the Math of how Neural Networks Learn with Implementation from Scratch . MULTI-LINGUAL AUTOMATIC PHONEME CLUSTERING . Closleabhair: 13 Irish language audiobooks you can listen to for free online . Measuring Unsupervised Acoustic Clustering through Phoneme Pair Merge-and-Split Tests . The General Ideas of Word Embeddings .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2020/07/08/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2020/07/08/evernote-links.html",
            "date": " ‚Ä¢ Jul 8, 2020"
        }
        
    
  
    
        ,"post140": {
            "title": "Boat parts",
            "content": "en pron. pl . mast | ¬† | maszt | . jib | ¬† | fok | . mainsail | ¬† | grot | . forestay | ¬† | forsztag | . foremast | ¬† | fokmaszt | . shroud | ¬† | wanta | . tack | ¬† | hals | . clew | ¬† | r√≥g szotowy | . stern | ¬† | rufa | . bow | ¬† | dzi√≥b | . hull | ¬† | kad≈Çub | . tiller | ¬† | rumpel | . boom | ¬† | bom | . gunwale | (/Àà…° ån…ôl/ - ganl) | reling | . board | ¬† | pok≈Çad | . rudder | ¬† | ster | . halyard | ¬† | fa≈Ç (halliard) | . head | ¬† | lik g√≥rny | . leech | ¬† | lik wolny | . luff | ¬† | lik przedni | . foot | ¬† | lik dolny | . boatswain | /Ààb…ô äsnÃ©/ (bosn) | bosman | . coxswain | ¬† | sternik | .",
            "url": "https://jimregan.github.io/notes/english%20teaching/pruszk%C3%B3w/2020/06/10/boat-parts.html",
            "relUrl": "/english%20teaching/pruszk%C3%B3w/2020/06/10/boat-parts.html",
            "date": " ‚Ä¢ Jun 10, 2020"
        }
        
    
  
    
        ,"post141": {
            "title": "Interesting links, 16/3/2020",
            "content": "Pocketsphinx.js - Speech Recognition in JavaScript and WebAssembly . RiveScript - Artificial Intelligence Scripting Language . andi611/Mockingjay-Speech-Representation Official Implementation of Mockingjay in Pytorch . grtzsohalf/Audio-Phonetic-and-Semantic-Embedding . Phonetic-and-Semantic Embedding of Spoken Words with Applications in Spoken Content Retrieval . Tesseract.js ‚Äì pure Javascript port of the popular Tesseract OCR engine. . microsoft/Recognizers-Text Microsoft.Recognizers.Text provides recognition and resolution of numbers, units, and date/time expressed in multiple languages .",
            "url": "https://jimregan.github.io/notes/links/2020/03/16/misc-links.html",
            "relUrl": "/links/2020/03/16/misc-links.html",
            "date": " ‚Ä¢ Mar 16, 2020"
        }
        
    
  
    
        ,"post142": {
            "title": "Evernote web clips, 15/3/2020",
            "content": "Open Challenge for Correcting Errors of Speech Recognition Systems . Understanding RNNs . Unsupervised Pre-training for Speech Recognition wav2vec . Podchraolta√≠ Gaeilge . Universal Phone Recognition with a Multilingual Allophone System . Re-Scoring Word Lattices from Automatic Speech Recognition System Based on Manual Error Corrections . ASR Context-Sensitive Error Correction Based on Microsoft N-Gram Dataset . Results of the IMPACT project .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2020/03/15/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2020/03/15/evernote-links.html",
            "date": " ‚Ä¢ Mar 15, 2020"
        }
        
    
  
    
        ,"post143": {
            "title": "ClarinPL SpeechTools links",
            "content": "ForcedAlign/run.sh . ./steps/make_mfcc.sh --nj 1 data ./steps/compute_cmvn_stats.sh data ./local_utils/prepare_dict.sh data dict ./utils/prepare_lang.sh dict &quot;&lt;unk&gt;&quot; tmp lang ./steps/align_fmllr.sh --nj 1 --beam ${beam} --retry-beam ${retry_beam} data lang tri3b_mmi ali ./steps/get_train_ctm.sh data lang ali ./local_utils/get_phoneme_ctm.sh data lang ali awk &#39;$0=&quot;@&quot;$0&#39; ali/phonectm | cat ali/ctm - | sort -r -k3n &gt; $out . ForcedAlign/run_eaf.sh . if $phones ; then ./local_utils/get_phoneme_ctm.sh --use-segments false data lang ali python3 local_utils/ctm2eaf.py --phones-ctm ali/phonectm ali/ctm data/seg2tier ${eaf_in} ${eaf_out} else python3 local_utils/ctm2eaf.py ali/ctm data/seg2tier ${eaf_in} ${eaf_out} fi . ForcedAlign/run_segments.sh . SegmentAlign/run.sh . misc/transcribe_word_list.sh . misc/train_g2p.sh . SpeechActivityDetection/run.sh .",
            "url": "https://jimregan.github.io/notes/kaldi/2020/03/07/kaldi-pl-scripts.html",
            "relUrl": "/kaldi/2020/03/07/kaldi-pl-scripts.html",
            "date": " ‚Ä¢ Mar 7, 2020"
        }
        
    
  
    
        ,"post144": {
            "title": "S√©adna, Caibidil a hAon",
            "content": "S√âADNA. . CAIBIDIL A hAON. . Cois na tine. Peig, N√≥ra, Gobnait, S√≠le bheag, agus C√°it N√≠ Bhuachalla. . N√≥ra.‚ÄîA Pheig, inis sc√©al d√∫inn. . Peig.‚ÄîB‚Äôait liom san! Inis f√©in sc√©al. . Gobnait.‚ÄîN√≠l aon mhaith inti, a Pheig. B‚Äôfhearr linn do sc√©alsa. . S√≠le.‚ÄîDein, a Pheig, agus beimid an-shocair. . Peig.‚ÄîNach maith n√°r fhanais socair ar√©ir, nuair a bh√≠ ‚ÄúMadra na nOcht gCos‚Äù agam d√° insint! . S√≠le.‚ÄîMar sin n√≠ stadfadh C√°it N√≠ Bhuachalla ach am priocadh. . C√°it.‚ÄîThugais d‚Äô√©itheach! N√≠ rabhas-sa ad phriocadh, a chaillich√≠n! . Gobnait.‚ÄîN√° bac √≠ f√©in, a Ch√°it. N√≠ raibh √©inne √° priocadh ach √≠ √° ligeant uirthi. . S√≠le.‚ÄîDo bh√≠, is d√≥in; agus mura mbeadh go raibh, n√≠ li√∫fainn. . N√≥ra.‚ÄîAbair le Peig n√° li√∫fair anois, a Sh√≠le, agus ‚Äòneosaidh s√≠ sc√©al d√∫inn. . S√≠le.‚ÄîN√≠ li√∫fad, a Pheig, p√© rud a imeoidh orm. . Peig.‚ÄîM√°s ea, suigh anso i m‚Äôaice, i dtreo n√° f√©adfaidh √©inne th√∫ phriocadh a gan fhios dom. . C√°it.‚ÄîB√≠odh geall go bpriocfaidh an cat √≠. A thoice bhig, bheadh sc√©al bre√° againn mura mbeadh t√∫ f√©in agus do chuid li√∫ir√≠. . Gobnait.‚Äî√âist, a Ch√°it, n√≥ cuirfir ag gol √≠, agus beimid gan sc√©al. M√° curtar fearg ar Pheig n√≠ ‚Äòneosaidh s√≠ aon sc√©al anocht. Sea anois, a Pheig, t√° gach √©inne ci√∫in ag brath ar sc√©al uait. . Peig.‚ÄîBh√≠ fear ann fad√≥ agus is √© ainm a bh√≠ air n√° S√©adna. Gr√©asa√≠ ab ea √©. Bh√≠ tigh beag deas cluthar aige ag bun cnoic, ar thaobh na fothana. Bh√≠ cathaoir sh√∫g√°in aige do dhein s√© f√©in d√≥ f√©in, agus ba ghn√°th leis su√≠ inti um thr√°thn√≥na, nuair a bh√≠odh obair an lae cr√≠ochnaithe, agus nuair a shu√≠odh s√© inti bh√≠odh s√© ar a sh√°stacht. Bh√≠ mealbh√≥g mine aige ar crochadh in aice na tine, agus anois agus ar√≠s chuireadh s√© a l√°mh inti agus th√≥gadh s√© l√°n a dhoirn den mhin, agus bh√≠odh s√© √° cogaint ar a shuaimhneas. Bh√≠ crann √∫ll ag f√°s ar an dtaobh amuigh de dhoras aige, agus nuair a bh√≠odh tart air √≥ bheith ag cogaint na mine, chuireadh s√© l√°mh sa chrann san agus th√≥gadh s√© ceann desna h√∫llaibh, agus d‚Äôitheadh s√© √©. . S√≠le.‚Äî√ì, a thiarcais, a Pheig, n√°r dheas √©! . Peig.‚ÄîC√© acu an chathaoir n√≥ an mhin n√≥ an t‚Äë√∫ll ba dheas? . S√≠le.‚ÄîAn t‚Äë√∫ll, gan amhras! . C√°it.‚ÄîB‚Äôfhearr liomsa an mhin. N√≠ bhainfeadh an t‚Äë√∫ll an t‚Äëocras de dhuine. . Gobnait.‚ÄîB‚Äôfhearr liomsa an chathaoir, agus chuirfinn Peig ina su√≠ inti, ag insint na sc√©al. . Peig.‚ÄîIs maith chun pl√°m√°is th√∫, a Ghobnait. . Gobnait.‚ÄîIs fearr chun na sc√©al tusa, a Pheig. Conas d‚Äôimigh le S√©adna? . Peig.‚ÄîL√° d√° raibh s√© ag d√©anamh br√≥g, thug s√© f√© ndeara n√° raibh a thuilleadh leathair aige, n√° a thuilleadh sn√°ithe, n√° a thuilleadh c√©arach. Bh√≠ an taoibh√≠n d√©anach suas agus an greim d√©anach curtha, agus n√≠orbh fhol√°ir d√≥ dul agus √°bhar do shol√°thar sula bhf√©adfadh s√© a thuilleadh br√≥g a dh√©anamh. Do ghluais s√© ar maidin, agus bh√≠ tr√≠ scillinge ina ph√≥ca, agus n√≠ raibh s√© ach m√≠le √≥n dtigh nuair a bhuail duine bocht uime, a d‚Äôiaraidh d√©irce. . ‚ÄúTabhair dhom d√©irc ar son an tSl√°naitheora agus le h‚Äëanaman na marbh, agus tar cheann do shl√°inte,‚Äù arsan duine bocht. . Thug S√©adna scilling d√≥, agus ansan n√≠ raibh aige ach dh√° scilling. D√∫irt s√© leis f√©in go mb‚Äôfh√©idir go nd√©anfadh an d√° scilling a ghn√≥. N√≠ raibh s√© ach m√≠le eile √≥ bhaile nuair a bhuail bean bhocht uime agus √≠ cos-nochtaithe. . ‚ÄúTabhair dhom c√∫namh √©igin,‚Äù ar sise, ‚Äúar son an tSl√°naitheora, agus le hanaman do mharbh, agus tar cheann do shl√°inte.‚Äù . Do ghlac trua dh√≠ √©, agus thug s√© scilling di, agus d‚Äôimigh s√≠. Do bh√≠ aon scilling amh√°in ansan aige, ach do chom√°in s√© leis, ag brath air go mbuailfeadh seans √©igin uime a chuirfeadh ar a chumas a ghn√≥ a dh√©anamh. N√≠orbh fhada gur casadh air leanbh agus √© ag gol le fuacht agus le hocras. ‚ÄúAr son an tSl√°naitheora,‚Äù arsan leanbh, ‚Äútabhair dhom rud √©igin le n‚Äëithe.‚Äù . Bh√≠ tigh √≥sta i ngar d√≥ibh, agus do chuaigh S√©adna isteach ann, agus cheannaigh s√© br√≠c ar√°in agus thug s√© chun an linbh √©. Nuair a fuair an leanbh an t‚Äëar√°n d‚Äôathraigh a dhealbh. D‚Äôfh√°s s√© suas in‚Äëairde, agus do las solas iontach ina sh√∫ilibh agus ina cheannachaibh, i dtreo go dt√°inig scanradh ar Sh√©anna. . S√≠le.‚ÄîDia linn! a Pheig, is d√≥cha gur thit S√©adna bocht i laige. . Peig.‚ÄîN√≠or thit; ach m√°s ea, ba dh√≠cheall d√≥. Chomh luath agus d‚Äôfh√©ad s√© labhairt, d√∫irt s√©:‚Äì . ‚ÄúCad √© an saghas duine thusa?‚Äù Agus is √© freagra a fuair s√©:‚Äî . ‚ÄúA Sh√©anna, t√° Dia bu√≠och d√≠ot. Aingeal is ea mise. Is m√© an tr√≠√∫ h‚Äëaingeal gur thugais d√©irc d√≥ inniu ar son an tSl√°naitheora. Agus anois t√° tr√≠ ghu√≠ agat le f√°il √≥ Dhia na gl√≥ire. Iar ar Dhia aon tr√≠ ghu√≠ is toil leat, agus gheobhair iad. Ach t√° aon chomhairle amh√°in agamsa le tabhairt duit.‚ÄîN√° dear√∫d an Tr√≥caire.‚Äù . ‚ÄúAgus an ndeirir liom go bhfaighead mo ghu√≠?‚Äù arsa S√©adna. . ‚ÄúDeirim, gan amhras,‚Äù arsan t‚Äëaingeal. . ‚ÄúT√° go maith,‚Äù arsa S√©adna. ‚ÄúT√° cathaoir bheag dheas s√∫g√°in agam sa bhaile, agus an uile dhailt√≠n a thagann isteach, n√≠ fol√°ir leis su√≠ inti. An ch√©ad duine eile a shu√≠fidh inti, ach m√© f√©in, go gceangla√≠ s√© inti!‚Äù . ‚ÄúFaire, faire, a Sh√©anna,‚Äù arsan t‚Äëaingeal; ‚Äúsin gu√≠ bre√° imithe gan tairbhe. T√° dh√° cheann eile agat, agus n√° dear√∫d an Tr√≥caire.‚Äù . ‚ÄúT√°,‚Äù arsa S√©adna, ‚Äúmealbh√≥ig√≠n mine agam sa bhaile, agus an uile dhailt√≠n a thagann isteach, n√≠ fol√°ir leis a dhorn a sh√° inti. An ch√©ad duine eile a chuirfidh l√°mh sa mhealbh√≥ig sin, ach m√© f√©in, go gceangla√≠ s√© inti, f√©ach!‚Äù . ‚Äú√ì, a Sh√©anna, a Sh√©anna, n√≠l fasc agat,‚Äù arsan t‚Äëaingeal. ‚ÄúN√≠l agat anois ach aon ghu√≠ amh√°in eile. Iar Tr√≥caire D√© do d‚Äôanam.‚Äù . ‚Äú√ì, is f√≠or dhuit,‚Äù arsa S√©adna, ‚Äúba dh√≥bair dom √© dhear√∫d. T√° crann beag √∫ll agam i leataoibh mo dhorais, agus an uile dhailt√≠n a thagann an treo, n√≠ fol√°ir leis a l√°mh do chur in airde agus √∫ll do stathadh agus do bhreith leis. An ch√©ad duine eile, ach m√© f√©in, a chuirfidh l√°mh sa chrann san, go gceangla√≠ s√© ann!‚Äî√ì! a dhaoine!‚Äù ar seisean, ag scairteadh ar gh√°ir√≠, ‚Äúnach agam a bheidh an sp√≥rt orthu!‚Äù . Nuair a th√°inig s√© as na trith√≠bh, d‚Äôfh√©ach s√© suas agus bh√≠ an t‚Äëaingeal imithe. Dhein s√© a mhachnamh air f√©in ar feadh tamaill mhaith. F√© dheireadh thiar thall, d√∫irt s√© leis f√©in: ‚ÄúF√©ach anois, n√≠l aon amad√°n in √âirinn is m√≥ n√° m√©! D√° mbeadh tri√∫r ceangailte agam um an dtaca so, duine sa chathaoir, duine sa mhealbh√≥ig, agus duine sa chrann, cad √© an mhaith a dh√©anfadh san domsa agus m√© i bhfad √≥ bhaile, gan bia, gan deoch, gan airgead?‚Äù . N√≠ t√∫isce a bh√≠ an m√©id sin cainte r√°ite aige n√° a thug s√© f√© ndeara os a chomhair amach, sa n‚Äë√°it ina raibh an t‚Äëaingeal, fear fada caol dubh, agus √© ag glinni√∫int air, agus tine chreasa ag teacht as a dh√° sh√∫il ina spr√©achaibh nimhe. Bh√≠ dh√° adhairc air mar bheadh ar phoc√°n gabhair; agus meigeall fada liathghorm garbh air, eireaball mar a bheadh ar mhadra rua, agus cr√∫b ar chois leis mar chr√∫b thairbh. Do leath a bh√©al agus a dh√° sh√∫il ar Sh√©anna, agus do stad a chaint. I gceann tamaill do labhair an Fear Dubh. . ‚ÄúA Sh√©anna,‚Äù ar seisean, ‚Äún√≠ g√° dhuit aon eagla do bheith ort romhamsa. N√≠lim ar t√≠ do dh√≠obh√°la. Ba mhian liom tairbhe √©igin a dh√©anamh duit, d√° nglacf√° mo chomhairle. Do chloiseas th√∫, anois beag, √° r√° go rabhais gan bia, gan deoch, gan airgead. Thabharfainnse airgead do dh√≥thain duit ar aon choinn√≠oll bheag amh√°in.‚Äù . ‚ÄúAgus greadadh tr√© l√°r do scairt!‚Äù arsa S√©adna, agus th√°inig a chaint d√≥; ‚Äún√° f√©adf√° an m√©id sin do r√° gan duine do mhilleadh led‚Äô chuid glinni√∫na, p√© h√© th√∫ f√©in?‚Äù . ‚ÄúIs cuma dhuit c√© h√© m√©, ach bh√©arfad an oiread airgid duit anois agus cheann√≥idh an oiread leathair agus choime√°dfaidh ag obair th√∫ go ceann tr√≠ mbliain nd√©ag, ar an gcoinn√≠oll seo‚Äîgo dtiocfair liom an uair sin.‚Äù . ‚ÄúAgus m√° r√©idhtighim leat, c√° raghmao√≠d an uair sin?‚Äù . ‚ÄúC√° beag duit an cheist sin do chur nuair a bheidh an leathar √≠dithe agus bheimid ag gluaiseacht?‚Äù . ‚ÄúT√°ir g√©arch√∫iseach. B√≠odh agat. Feiceam an t‚Äëairgead.‚Äù . ‚ÄúT√°irse g√©arch√∫iseach. F√©ach!‚Äù‚Äîdo chuir an Fear Dubh a l√°mh ina ph√≥ca agus tharraing s√© amach spar√°n m√≥r, agus as an spar√°n do lig s√© amach ar a bhais carn beag d‚Äô√≥r bhre√° bhu√≠. . ‚ÄúF√©ach!‚Äù ar seisean, agus sh√≠n s√© a l√°mh agus chuir s√© an carn de ph√≠osa√≠bh gleoite gl√©ineacha suas f√© sh√∫ilibh Sh√©anna bhoicht. Do sh√≠n S√©adna a dh√° l√°imh, agus do leathadar a dh√° ladhar chun an √≥ir. . ‚ÄúGo r√©idh!‚Äù arsan Fear Dubh, ag tarrang an √≥ir chuige isteach. ‚ÄúN√≠l an margadh d√©anta f√≥s.‚Äù . ‚ÄúB√≠odh ina mhargadh,‚Äù arsa S√©adna. . ‚ÄúGan teip?‚Äù arsan Fear Dubh. . ‚ÄúGan teip,‚Äù arsa S√©adna. . ‚ÄúDar bhr√≠ na mionn?‚Äù arsan Fear Dubh. . ‚ÄúDar bhr√≠ na mionn,‚Äù arsa S√©adna. .",
            "url": "https://jimregan.github.io/notes/irish/seadna/2020/02/15/seadna-caibidil-a-haon.html",
            "relUrl": "/irish/seadna/2020/02/15/seadna-caibidil-a-haon.html",
            "date": " ‚Ä¢ Feb 15, 2020"
        }
        
    
  
    
        ,"post145": {
            "title": "Evernote web clips, 10/1/2020",
            "content": "PDF - www.ilrweb.ie . Kaldi Tutorial . How to get timestamps of an audio file using pre-trained model with Kaldi . kaldi/create_segments_from_ctm.pl . kaldi/run_unk_model.sh . Create shared versions of get_ctm_conf.sh, add get_ctm_conf‚Ä¶ . Added a new lexicon learning (adaptation) recipe for tedlium . Output-Gate Projected Gated Recurrent Unit for Speech Recognition . Improvements to multi_en tdnn-opgru/lstm recipes #2824 . Fix a typo in steps/dict/learn_lexicon_bayesian.sh #3288 . simple-g2p/run_simpleG2P.sh . Backstitch: Counteracting Finite-Sample Bias via Negative Steps . Acoustic data-driven lexicon learning based on a greedy pronunciation selection framework . Evaluating Natural Language Understanding Services for Conversational Question Answering Systems . [ASR Independent Hybrid Recurrent Neural Network Based Error Correction for Dialog System Applications | Request PDF](https://www.researchgate.net/publication/302498352_ASR_Independent_Hybrid_Recurrent_Neural_Network_Based_Error_Correction_for_Dialog_System_Applications) | . Improving Performance of End-to-End ASR on Numeric Sequences . REFORMER: THE EFFICIENT TRANSFORMER . Reformer: The Efficient Transformer - Pastebin.com . Fix issue in copy_lat_dir.sh affecting combine_lat_dirs.sh . kaldi/compute-gop.cc at b0f6bcb76824fc7ce0dbf8ecaba3467273bba1c7 . Make compute-gop work with missing alignments . Add layer for attention with bypass by danpovey . Incremental determinization . Handwriting recognition and language modeling with MXNet Gluon .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2020/01/10/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2020/01/10/evernote-links.html",
            "date": " ‚Ä¢ Jan 10, 2020"
        }
        
    
  
    
        ,"post146": {
            "title": "Evernote web clips, 9/1/2020",
            "content": "Luik 1 - Gospel of Luke in Ulster-Scots . Acoustic data-driven lexicon learning based on a greedy pronunciation selection framework . The Illustrated BERT, ELMo, and co. . A Visual Guide to Using BERT for the First Time . Zwroty angielskie przydatne u fryzjera .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2020/01/09/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2020/01/09/evernote-links.html",
            "date": " ‚Ä¢ Jan 9, 2020"
        }
        
    
  
    
        ,"post147": {
            "title": "Evernote web clips, 30/12/2019",
            "content": "Lesson 1: Deep Learning 2019 - Image classification . Arrayfire Getting Started . flashlight/examples . gulp21/languagetool-neural-network . Neural Network Rules - Development - LanguageTool Forum . Java Regex - Java Regular Expressions . PDF - www.speech.cs.cmu.edu . gf5353/deploytools . Books ¬∑ L√©amh ‚Äì Learn Early Modern Irish . Deep Lip Reading . Add Chime 6 baseline system #3755 . Minority language resources: a guide - How to get fluent, with Dr Popkins . facebookresearch/detectron2 . PyTorch 1.3 adds mobile, privacy, quantization, and named tensors . Learning from Past Mistakes: Improving Automatic Speech Recognition Output via Noisy-Clean Phrase Context Modeling . Statistical Error Correction Methods for Domain-Specific ASR Systems . A simple module consistently outperforms self-attention and Transformer model on main NMT datasets with SoTA performance . Google‚Äôs Explainable AI service sheds light on how machine learning models make decisions . EdgeSpeechNets: Highly Efficient Deep Neural Networks for Speech Recognition on the Edge . Google AI technique reduces speech recognition errors by 29% . ASR Context-Sensitive Error Correction Based on Microsoft N-Gram Dataset . Automatic Speech Recognition Errors Detection and Correction: A Review . Creating and using ground truth OCR sample data for Finnish historical newspapers and journals . NBoost: Boost Elasticsearch Search Relevance by 80% with BERT : MachineLearning . CMU Sphinx Use Needleman-Wunsch algorithm to get results. . openslr.org Crowdsourced high-quality Basque speech data set . Added tri3b and chain training for Aurora4 #3638 . A Visual Guide to Using BERT for the First Time . Mathematics for Machine Learning . The Illustrated Word2vec . The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning) . Is m√∫inteoir Gaeilge m√©‚Ä¶ . Gramadach - Blag Gaeilge SMPPS . Goodness of Pronunciation (GOP) #3703 . Talking Head Anime from a Single Image : MachineLearning . GELU better than RELU? : MachineLearning . [How to write vectorized code | ArrayFire](http://arrayfire.com/how-to-write-vectorized-code/) | . Post-Editing Error Correction Algorithm For Speech Recognition using Bing Spelling Suggestion . A spelling correction model for end-to-end speech recognition . Novelist Cormac McCarthy‚Äôs tips on how to write a great science paper . How to do Unsupervised Clustering with Keras . Contrastive Predictive Coding Based Feature for Automatic Speaker Verification . Representation Learning with Contrastive Predictive Coding . Maven ‚Äì Maven on Windows .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2019/12/30/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2019/12/30/evernote-links.html",
            "date": " ‚Ä¢ Dec 30, 2019"
        }
        
    
  
    
        ,"post148": {
            "title": "Evernote web clips, 22/12/2019",
            "content": "KPWr . Marian :: MTM2017 Tutorial - Part 2 . Training and Adapting Multilingual NMT for Less-resourced and Morphologically Rich Languages . An Exploration of Neural Sequence-to-Sequence Architectures for Automatic Post-Editing .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2019/12/22/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2019/12/22/evernote-links.html",
            "date": " ‚Ä¢ Dec 22, 2019"
        }
        
    
  
    
        ,"post149": {
            "title": "Evernote web clips, 15/12/2019",
            "content": "Controlling Text Generation with Plug and Play Language Models . How To Code Modern Neural Networks Using Python and NumPy . Distilling knowledge from Neural Networks to build smaller and faster models .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2019/12/15/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2019/12/15/evernote-links.html",
            "date": " ‚Ä¢ Dec 15, 2019"
        }
        
    
  
    
        ,"post150": {
            "title": "Trick or Treat",
            "content": "Trick or treat is an American custom, but it has its origins in earlier customs: ‚Äúguising‚Äù, which was practiced in Scotland and Ireland; and ‚Äúsouling‚Äù, which was practiced in Britain and Ireland, but is more usually associated with England. . In ‚Äúguising‚Äù, children wore costumes (or ‚Äúguises‚Äù), and went from door to door, much like with trick or treat. The main difference was that children who went guising had to perform something - a joke, a song, or a poem - to receive a treat. . ‚ÄúSouling‚Äù involved people going in groups, offering to pray for the souls of family members of the people they visited: for this, they would receive a ‚Äúsoul cake‚Äù. . ‚ÄúTrick or treat‚Äù is usually just something that people say - these days, people don‚Äôt usually expect to have to play a trick - but in the 1990s, egging (throwing raw eggs) and TP-ing (throwing an opened roll of toilet paper, to ‚Äúdecorate‚Äù the house) were common ‚Äútricks‚Äù. .",
            "url": "https://jimregan.github.io/notes/english%20teaching/pruszk%C3%B3w/2019/10/31/trick-or-treat.html",
            "relUrl": "/english%20teaching/pruszk%C3%B3w/2019/10/31/trick-or-treat.html",
            "date": " ‚Ä¢ Oct 31, 2019"
        }
        
    
  
    
        ,"post151": {
            "title": "Harry Potter quiz",
            "content": "1. What is Harry‚Äôs full address? . (The Cupboard under the stairs, 2 Privet Drive) . 2. What did Harry get for Christmas? . (The invisibility cloak) . 3. What did Harry get at the end of the movie? . (A photo album) . 4. What was the number of Harry‚Äôs vault at Gringott‚Äôs . 687 . 5. What was spelled on Harry‚Äôs birthday cake? . Happee birthdae Harry . 6. Who taught Defence Against the Dark Arts? . Quirrell . 7. How many times did McGonagall appear as a cat? . Twice . 8. What is the name of the wizard‚Äôs bank? . Gringott‚Äôs . 9. What was the number of the vault Hagrid went to at Gringott‚Äôs? . 713 . 10. What did Neville receive in the mail? . A rememberall . 11. What is the name of Harry‚Äôs aunt? . Petunia . 12. What is the name of the ball that wins a game of quidditch? . The Golden Snitch . 13. What is the name of Hagrid‚Äôs dog . Fang/Kie≈Ç . 14. What is the name of the dog guarding the trap door? . Fluffy . 15. What was the name of Hagrid‚Äôs dragon? . Norbert . 16. How many points did Neville receive at the end of the movie? . 10 . 17. What was the name of the centaur? . Firenze . 18. Where was the snake at the start of the movie from? . Burma . 19. Where is Ron‚Äôs brother studying dragons? . Romania . 20. What kind of dragon did Hagrid have? . A Norwegian Ridgeback . 21. How old was Harry when he found out he is a wizard? . 11 . 22. What flavour of Every Flavour Beans did Dumbledore eat in the hospital? . Ear wax . 23. Who was the wizard on the Chocolate Frog card that Harry opened on the train? . Dumbledore . 24. What is at the core of Harry‚Äôs wand? . Phoenix feather .",
            "url": "https://jimregan.github.io/notes/english%20teaching/siemczyno/2019/07/28/hp-quiz.html",
            "relUrl": "/english%20teaching/siemczyno/2019/07/28/hp-quiz.html",
            "date": " ‚Ä¢ Jul 28, 2019"
        }
        
    
  
    
        ,"post152": {
            "title": "Treasure Island, Chapter 1 vocab",
            "content": "year of grace: year in the Christian era; year A.D. . Cove: an inlet, usually with high cliffs that can protect ships from the wind . Capstan: machine for putting force on ropes, usually on a ship . Grog: rum and water . ‚Äúsittyated‚Äù - situated . ‚Äúmought‚Äù - might . berth - bunk for sleeping (usually on a ship); also, room for movement: to give someone a wide berth means to avoid them . keep a weather eye open - be alert (a weather eye was a tool for predicting the weather) . assizes - court hearing . be quit of - be rid of in modern English . rheumatics - rheumatism .",
            "url": "https://jimregan.github.io/notes/english%20teaching/pruszk%C3%B3w/2019/06/03/treasure-island-chapter-1.html",
            "relUrl": "/english%20teaching/pruszk%C3%B3w/2019/06/03/treasure-island-chapter-1.html",
            "date": " ‚Ä¢ Jun 3, 2019"
        }
        
    
  
    
        ,"post153": {
            "title": "Snatch vocabulary",
            "content": "Bust a cap in his ass: African-American slang. ‚ÄúBust a cap‚Äù means to shoot (a cap can be a small explosive used to set off a larger explosive, especially in mining, so in slang, it‚Äôs a bullet); one‚Äôs ass can be used as an emphatic replacement for a pronoun: ‚Äúmy ass is tired‚Äù, ‚Äúhe has to drag his ass to work‚Äù. Possibly from work one‚Äôs ass off (to work to the point of fatigue). . Yardie: a Jamaican (‚Äúyard‚Äù in Jamaican Creole means ‚Äúhome‚Äù); more specifically, a member of a Jamaican gang . Goody gumdrops (or goody goody gumdrops): childish expression of happiness, usually sarcastic when used by adults. . Pisshead: person who regularly gets drunk. ‚ÄúPiss‚Äù can be used to mean alcohol (‚ÄúWe‚Äôre going on the piss‚Äù = ‚Äúwe‚Äôre going drinking‚Äù); -head can be used to form a noun (usually derogatory) for a person who‚Äôs dedicated to something: a pothead likes to smoke marijuana (‚Äúpot‚Äù), a metalhead listens to heavy metal; it can also be added to other insults to imply stupidity (blockhead, shithead). . Look like curry to a pisshead: curry is an extremely popular post-pub food in Britain, so this is irresistible food. . Porky pies: rhyming slang for lies. Usually shortened to porkies. .",
            "url": "https://jimregan.github.io/notes/english%20teaching/pruszk%C3%B3w/2019/06/03/snatch-vocab.html",
            "relUrl": "/english%20teaching/pruszk%C3%B3w/2019/06/03/snatch-vocab.html",
            "date": " ‚Ä¢ Jun 3, 2019"
        }
        
    
  
    
        ,"post154": {
            "title": "Evernote web clips, 29/3/2019",
            "content": "Multilingual Speech Recognition With A Single End-To-End Model . Memory, attention, sequences . natsuhh / SWC . Building Kaldi on Windows: Part 1 . Yes you should understand backprop . The M-AILABS Speech Dataset ‚Äì caito .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2019/03/29/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2019/03/29/evernote-links.html",
            "date": " ‚Ä¢ Mar 29, 2019"
        }
        
    
  
    
        ,"post155": {
            "title": "Interesting links, 29/1/2019",
            "content": "FstContrib . OpenGrm Libraries . OpenGrm Thrax Grammar Compiler . OpenGrm Thrax tools . mjansche/tts-tutorial . google/sparrowhawk . google/language-resources . Free Linguistic Environment ‚Äì a grammar engineering platform for LFG. git . dcavar/treebankparsersa ‚Äì This is a tool that reads treebank files and generates a probabilistic grammar for use in FLE. . Practical Instructions for Working with LFG . Grammar Development with LFG and XLE . S --&gt; NP: (^ SUBJ)=! (! CASE)=NOM; VP: ^=!. &quot;indicate comments&quot; VP --&gt; V: ^=!; &quot;head&quot; (NP: (^ OBJ)=! &quot;() = optionality&quot; (! CASE)=ACC) PP*: ! $ (^ ADJUNCT). &quot;$ = set, * = Kleene star&quot; . astorfi/TensorFlow-World ‚Äì Simple and ready-to-use tutorials for TensorFlow .",
            "url": "https://jimregan.github.io/notes/links/2019/01/29/misc-links.html",
            "relUrl": "/links/2019/01/29/misc-links.html",
            "date": " ‚Ä¢ Jan 29, 2019"
        }
        
    
  
    
        ,"post156": {
            "title": "Last Christmas notes",
            "content": "For Christmas, the school insisted that we get the students to sing a song, and record it for their parents. So, with older students, we generally let them pick the song themselves. . I had two all-girl groups, and both chose ‚ÄúLast Christmas‚Äù - fine by me, one set of notes. It also ended up being the song chosen by a group of mainly boys, because their other teacher foolishly mentioned that, having spent a Christmas working in retail in England, she really hated that song. Which I mentioned to them. Next lesson, she walked in to a serenade of ‚ÄúLast Christmas‚Äù, and immediately came across to the office to ask if I might know why that had happened. . . Very . We most often see ‚Äúvery‚Äù as an adverb which intensifies an adjective: very dark, very wet, etc., but it can also be used as an adjective meaning ‚Äúthe same‚Äù or ‚Äúidentical‚Äù: he left that very night. . Once bitten, twice shy . This is a proverb that means that if you‚Äôve been hurt by something once, you‚Äôll be more careful the next time. . It‚Äôs an example of elliptical causation: if once bitten, then twice shy: that is, the causation (if‚Ä¶ then‚Ä¶) is omitted: this kind of omission is known as an ellipsis, which is also the name given to the triple dots (‚Ä¶) used to show a piece of a quotation has been omitted. . Other examples of elliptical causation include ‚Äúno pain, no gain‚Äù, ‚Äúwaste not, want not‚Äù, ‚Äúnothing ventured, nothing gained‚Äù. . Gave: not that, unlike the standard pronunciation (gejw), George Michael pronounces it as gew throughout. This is typical of a number of accents in England. (He pronounces ‚Äúsave‚Äù in a similar manner.) . To catch s.b.‚Äôs eye: to capture someone‚Äôs attention. . A shoulder to cry on: a person who is prepared to listen to someone else‚Äôs problems . Undercover: in secret; spying. . With a fire in one‚Äôs heart: to be very passionate about something .",
            "url": "https://jimregan.github.io/notes/english%20teaching/pruszk%C3%B3w/2018/11/27/last-christmas.html",
            "relUrl": "/english%20teaching/pruszk%C3%B3w/2018/11/27/last-christmas.html",
            "date": " ‚Ä¢ Nov 27, 2018"
        }
        
    
  
    
        ,"post157": {
            "title": "Evernote web clips, 11/4/2018",
            "content": "The Annotated Transformer . General Information . explosion/sense2vec .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2018/04/11/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2018/04/11/evernote-links.html",
            "date": " ‚Ä¢ Apr 11, 2018"
        }
        
    
  
    
        ,"post158": {
            "title": "Evernote web clips, 23/3/2018",
            "content": "Gangster‚Äôs paradise: how organised crime took over Russia . WIP: Segmenting long erroneous recordings by vimalmanohar . vimalmanohar/kaldi . vimalmanohar/kaldi . vimalmanohar/kaldi . vimalmanohar/kaldi . vimalmanohar/kaldi . vimalmanohar/kaldi . vimalmanohar/kaldi . vimalmanohar/kaldi . Modeling Relational Data with Graph Convolutional Networks . RodenLuo/Smith-Waterman-in-Perl . Untitled note . Plucene-Plugin-Analyzer-MetaphoneAnalyzer-1.02 - Metaphone analyzer - metacpan.org . Find What You Want with Plucene . Machine Learning 10-701/15-781: Lectures . Top Machine Learning MOOCs and Online Lectures: A Comprehensive Survey . tcsai/data-mining . Add the diphone alignment system by akreal . Add diphones acoustic model and dictionary by akreal . akreal/diphones . Add modernized vystadial_cz recipe . Pretrained models . GSByeon/multi-speaker-tacotron-tensorflow . How to build a three-layer neural network from scratch . Prerequisites and Prework . voicy-ai/DialogStateTracking . RasaHQ/rasa_nlu . Question answering with TensorFlow . English gold standard recipe ‚Äî Ossian 1.3 documentation . Implementation of Gradient Descent in TensorFlow using tf.gradients . tensorflow/tensor2tensor . AI::FANN - search.cpan.org . [Machine learning in Perl | Sergey Kolychev [blogs.perl.org]](http://blogs.perl.org/users/sergey_kolychev/2017/02/machine-learning-in-perl.html) | . AN TRIAIL le M√°ir√©ad N√≠ Ghr√°da . Anna Heussaff ag l√©amh as S√ÅR√ö . deepmipt/DeepPavlov . CMU-Perceptual-Computing-Lab/openpose . dlib C++ Library - train_shape_predictor_ex.cpp . Real-Time Face Pose Estimation . astorfi/lip-reading-deeplearning . facebookresearch/TensorComprehensions . facebookresearch/StarSpace . facebookresearch/MUSE . facebookresearch/InferSent . facebookresearch/tdfbanks . facebookresearch/loop . fastai/numerical-linear-algebra . zackchase/mxnet-slides . zackchase/mxnet-the-straight-dope . zackchase/mxnet-the-straight-dope . aalto-speech/finnish-parliament-scripts . tudarmstadt-lt/kaldi-tuda-de . cltk/lapos . Speech::Recognizer::SPX - search.cpan.org . opencv/opencv_contrib . Dynamic word embeddings for evolving semantic discovery . Machine Learning Top 10 Open Source Projects (v.Mar 2018) . Bliain an √Åir (Year of Slaughter) ‚Äì Irish Famine of 1740-1741 . Phn2vec Embeddings . syhw/speech_embeddings . Pointer Networks . ikostrikov/TensorFlow-Pointer-Networks . atom/flight-manual.atom.io . tsee/p5-ML-TensorFlow . How To Write Your Own Tensorflow in C++ . MycroftAI/padatious . Pocketsphinx.js - Speech Recognition in JavaScript and WebAssembly . MycroftAI/padatious . Conv Nets: A Modular Perspective . Attention and Augmented Recurrent Neural Networks . Understanding LSTM Networks . UFLDL Recommended Readings . tiny-dnn/tiny-dnn . zotroneneis/machine_learning_basics . mozilla/TTS . uclmr/inferbeddings . Rayhane-mamah/Tacotron-2 . sdkcarlos/artyom.js . kan-bayashi/PytorchWaveNetVocoder . Rayhane-mamah/Tacotron-2 . Kyubyong/cross_vc . k2kobayashi/sprocket . timothycrosley/jiphy . pyjs/pyjs . uwgraphics/Leap . A-Jacobson/tacotron2 . The Books and the Pilgrimage of the Polish Nation . Adversarial Sets for Regularising Neural Link Predictors . Compiling Deep Learning Models to WebGL with TVM . NNVM Compiler: Open Compiler for AI Frameworks . Tool for segmenting long audio files with erroneous transcripts ¬∑ Issue #869 ¬∑ kaldi-asr/kaldi . resonance-audio/resonance-audio . Implementation - Rust By Example . Starting to Corrode . KeyMe Releases Two Machine Learning Models - KeyMe Blog . PDF - arxiv.org . Community Interaction and Conflict on the Web . Transfer Your Font Style with GANs . PolEval 2017 :: Tasks . Introduction to Gaussian Processes . Bad Speech Synthesis Made Simple . Are the hyper-realistic results of Tacotron-2 and Wavenet not reproducible? ‚Ä¢ r/MachineLearning . KPWr . PDF - static.googleusercontent.com . a-nagrani/VGGVox . Visual Geometry Group: VoxCeleb dataset . Transfer learning wsj-rm by pegahgh ¬∑ Pull Request #1633 ¬∑ kaldi-asr/kaldi . Semi-supervised training on Fisher English by vimalmanohar ¬∑ Pull Request #2140 ¬∑ kaldi-asr/kaldi . DNN-based speaker embedding - Google Groups . End-to-end speech recognition - Google Groups . [Machine learning in Perl | Sergey Kolychev [blogs.perl.org]](http://blogs.perl.org/users/sergey_kolychev/2017/02/machine-learning-in-perl.html) | . salesforce/nonauto-nmt . salesforce/awd-lstm-lm . An Analysis of Neural Language Modeling at Multiple Scales . facebookresearch/tdfbanks . tensorflow/tensorflow . fomorians/highway-cnn . Highway Networks with TensorFlow ‚Äì Jim Fleming ‚Äì Medium . deltamachine/naive-automatic-postediting . Added lexnet_nc model. ¬∑ tensorflow/models@1f37153 . [Understanding Deep Learning through Neuron Deletion | DeepMind](https://deepmind.com/blog/understanding-deep-learning-through-neuron-deletion/) | . kaldi-asr/kaldi . facebookresearch/tdfbanks . PDF - arxiv.org . Corpus building for data-driven TTS systems . apohllo/pjn . Time alignments off by a factor of 3 when using nnet3-align-compiled - Google Groups . One best hypothesis Lattice to CTM - Google Groups . zackchase/ddc . ethanfetaya/NRI . C++ gradients: Fractional*Pool, Soft{Plus,Sign} by kbsriram ¬∑ Pull Request #17331 ¬∑ tensorflow/tensorflow .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2018/03/23/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2018/03/23/evernote-links.html",
            "date": " ‚Ä¢ Mar 23, 2018"
        }
        
    
  
    
        ,"post159": {
            "title": "Evernote web clips, 22/3/2018",
            "content": "Language Transfer of Audio Word2Vec: Learning Audio Segment Representations without Target Language Data . Peering into Neural Networks‚ÄîHow Sequence Models View State of the Union Speeches from Three U.S. Presidents . Annotation Artifacts in Natural Language Inference Data . CMU Sphinx Frequently Asked Questions . How to use an Existing DNN Recognizer for Decoding in Kaldi . Exploring the Boost Graph Library . How to build a deep learning model in 15 minutes . Requests for Research . Gradient Descent in a Nutshell .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2018/03/22/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2018/03/22/evernote-links.html",
            "date": " ‚Ä¢ Mar 22, 2018"
        }
        
    
  
    
        ,"post160": {
            "title": "Evernote web clips, 14/2/2018",
            "content": "Create a working compiler with the LLVM framework, Part 1 . Create a working compiler with the LLVM framework, Part 2 .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/llvm/2018/02/14/evernote-links.html",
            "relUrl": "/evernote/web%20clip/llvm/2018/02/14/evernote-links.html",
            "date": " ‚Ä¢ Feb 14, 2018"
        }
        
    
  
    
        ,"post161": {
            "title": "Evernote web clips, 16/1/2018",
            "content": "Fast Inference for Neural Vocoders . The 10 Deep Learning Methods AI Practitioners Need to Apply . Adapting the default acoustic model . What most people don‚Äôt understand about AI and the the state of machine learning . Recent Advances in Recurrent Neural Networks . Deep Learning: A Critical Appraisal . mozilla/DeepSpeech document-init-from-frozen-model . Building Speech Applications Using CMU Sphinx and Related Resources .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2018/01/16/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2018/01/16/evernote-links.html",
            "date": " ‚Ä¢ Jan 16, 2018"
        }
        
    
  
    
        ,"post162": {
            "title": "Evernote web clips, 5/12/2016",
            "content": "[Readings | √öFAL](https://ufal.mff.cuni.cz/milan-straka/readings) | .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2016/12/05/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2016/12/05/evernote-links.html",
            "date": " ‚Ä¢ Dec 5, 2016"
        }
        
    
  
    
        ,"post163": {
            "title": "Evernote web clips, 11/7/2016",
            "content": "User:Krvoje/Foma script for testing finite-state disambiguation - Apertium . Facebook will soon introduce a new Multilingual composer that automatically translates posts .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2016/07/11/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2016/07/11/evernote-links.html",
            "date": " ‚Ä¢ Jul 11, 2016"
        }
        
    
  
    
        ,"post164": {
            "title": "Evernote web clips, 4/4/2016",
            "content": "Formant-controlled HMM-based Speech Synthesis .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/tts/2016/04/04/evernote-links.html",
            "relUrl": "/evernote/web%20clip/tts/2016/04/04/evernote-links.html",
            "date": " ‚Ä¢ Apr 4, 2016"
        }
        
    
  
    
        ,"post165": {
            "title": "Evernote web clips, 25/3/2016",
            "content": "SpeCT - The Speech Corpus Toolkit for Praat .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/praat/2016/03/25/evernote-links.html",
            "relUrl": "/evernote/web%20clip/praat/2016/03/25/evernote-links.html",
            "date": " ‚Ä¢ Mar 25, 2016"
        }
        
    
  
    
        ,"post166": {
            "title": "Evernote web clips, 19/3/2016",
            "content": "Train your own image classifier with Inception in TensorFlow .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2016/03/19/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2016/03/19/evernote-links.html",
            "date": " ‚Ä¢ Mar 19, 2016"
        }
        
    
  
    
        ,"post167": {
            "title": "Evernote web clips, 17/3/2016",
            "content": "Train your own image classifier with Inception in TensorFlow . TensorFlow for Poets .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2016/03/17/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2016/03/17/evernote-links.html",
            "date": " ‚Ä¢ Mar 17, 2016"
        }
        
    
  
    
        ,"post168": {
            "title": "signal processing definitions",
            "content": "periodic - traces same path . aperiodic - doesn‚Äôt . cycle - shape that repeats . period - time cycle takes to repeat . Hertz - cycles per second .",
            "url": "https://jimregan.github.io/notes/evernote/2016/01/31/signal-processing-defn.html",
            "relUrl": "/evernote/2016/01/31/signal-processing-defn.html",
            "date": " ‚Ä¢ Jan 31, 2016"
        }
        
    
  
    
        ,"post169": {
            "title": "node",
            "content": "Node . class Node { ¬†¬†¬†¬† char ch = START; ¬†¬†¬†¬† List&lt;Node&gt; = List.newArrayList(); ¬†¬†¬†¬† void add (String str) { ¬†¬†¬†¬†¬†¬†¬†¬†¬† if (str.length() == 0) ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† return; ¬†¬†¬†¬†¬†¬†¬†¬†¬† char chNew = str.charAt(0); ¬†¬†¬†¬†¬†¬†¬†¬†¬† for (Node n : nodes) { ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† if (n.ch == chNew) { ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† n.add (str.substring(1)); ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† return; ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† } ¬†¬†¬†¬†¬†¬†¬†¬†¬† Node newNode = new Node(); ¬†¬†¬†¬†¬†¬†¬†¬†¬† newNode.ch = chNew; ¬†¬†¬†¬†¬†¬†¬†¬†¬† new Node.add(str.substring(1)); ¬†¬†¬†¬†¬†¬†¬†¬†¬† nodes.add(newNode); ¬†¬†¬†¬† } ¬†¬†¬†¬† String toRegexp() { ¬†¬†¬†¬†¬†¬†¬†¬†¬† StringBuilder .",
            "url": "https://jimregan.github.io/notes/evernote/incomplete/2016/01/31/node.html",
            "relUrl": "/evernote/incomplete/2016/01/31/node.html",
            "date": " ‚Ä¢ Jan 31, 2016"
        }
        
    
  
    
        ,"post170": {
            "title": "neuron",
            "content": "double activation = 0.0; for (int i = 0; i &lt; n; i++) { ¬† ¬† ¬†activation += x[i] + n[i]; } . e = 2.7183 (approx) . a = activation . p = shape of curve . sigmoid . output = $1/1 + e^{-a/p}$ . class Neuron { ¬† ¬† ¬†int num_inputs; ¬† ¬† ¬†vector&lt;double&gt; weights; ¬† ¬† ¬†Neuron (int num); } Neuron::Neuron (int num) : num.inputs(num + 1) { ¬† ¬† ¬†for (int i = 0; i &lt;= num; i++) { ¬† ¬† ¬† ¬† ¬† weights.push_back(random()); ¬† ¬† ¬†} } .",
            "url": "https://jimregan.github.io/notes/evernote/2016/01/31/neuron.html",
            "relUrl": "/evernote/2016/01/31/neuron.html",
            "date": " ‚Ä¢ Jan 31, 2016"
        }
        
    
  
    
        ,"post171": {
            "title": "Influence",
            "content": "Influence . Festinger - cognitive dissonance | experiment - 20 dollars vs 1 to lie | &gt; $1 changed beliefs | Americans in Korea, captured by China | rice for propaganda, most became Communist | . ‚ÄòWe have to take our country back‚Äô . No details Listener fills in details | . | don‚Äôt sell past the close | . Points: . Loss response &gt; gain response . | When you laugh, you look at the person you‚Äôre most comfortable with | Feet pointing towards you -&gt; at ease | People remember first &amp; last moments most clearly | Concert or amusement park for first dates - excitement | Silence encourages the other to talk more | A mirror behind customer service - people like to check themselves/others in line | Sitting next to someone discourages badmouthing | Sincere excitement when seeing someone elicits the same reaction from them next time | Ask for small favours - encourages people to like you | Confidence boost in meeting - pretend interviewer is your best friend | Mirror body language to build trust | Cold hands - wear gloves -&gt; warm handshake | Laughter causes happiness | Teaching is the best way to learn | Use names in conversation | .",
            "url": "https://jimregan.github.io/notes/evernote/2016/01/31/influence.html",
            "relUrl": "/evernote/2016/01/31/influence.html",
            "date": " ‚Ä¢ Jan 31, 2016"
        }
        
    
  
    
        ,"post172": {
            "title": "FST",
            "content": "FST (openfst? morfologik?) . for (StateIterator&lt; FST&lt;A&gt;&gt; siter(fst); ¬† ¬† ¬†!siter.Done(); ¬†¬†¬†¬†¬†siter.Next() { ¬† ¬† ¬†StateId s = siter.Value(); ¬† ¬† ¬†if (fst.Final(s) != Weight::Zero()) { ¬† ¬† ¬† ¬† ¬† //do stuff ¬† ¬† ¬†} } . Weight::Zero() applies with unweighted FSTs .",
            "url": "https://jimregan.github.io/notes/evernote/2016/01/31/fst.html",
            "relUrl": "/evernote/2016/01/31/fst.html",
            "date": " ‚Ä¢ Jan 31, 2016"
        }
        
    
  
    
        ,"post173": {
            "title": "LuaJ / Scribunto",
            "content": "LuaJ / Scribunto . LuaJ Field Access / function calls . LuaValue globals = JsePlatform.standardGlobals(); LuaValue sqrt = globals.get(&quot;math&quot;).get(&quot;sqrt&quot;); LuaValue print = globals.get(&quot;print&quot;); LuaValue d = sqrt.call(a); print.call(LuaValue.valueOf(&quot;sqrt(5):&quot;), a); . varargs / multiple returns . use invoke(Varargs) or invokemethod(LuaValue, Varargs) . LuaValue modf = globals.get(&quot;math&quot;).get(&quot;modf&quot;); Varargs r = modf.invoke(d); print.call(r.arg(1), r.arg(2)); . To load / run script: LoadState . LoadState.load(new FileInputStream(&quot;main.lua&quot;), &quot;main.lua&quot;, globals).call(); . or require . globals.get(&quot;require&quot;).call(LuaValue.valueOf(&quot;main&quot;)) . preinit tables: . listOf(LuaValue[]) - for unnamed elements | tableOf (LuaValue[]) - for named | tableOf(LuaValue[], LuaValue[], Varargs) - mixture | . LuaJ - date not implemented . if (format[0] == &#39;!&#39;) { ¬†¬†¬†¬† calendar = Calendar.getInstance(TimeZone.getTimeZone(&quot;GMT&quot;); } else { ¬†¬†¬†¬† calendar = Cak,getInst(TimeZone.getDefault()); } . also adjust format . DST: TimeZone tz = TimeZone.getDefault(); ¬†¬†¬†¬† bool.isdst = tz.useDaylightTime(); function setTTL ($ttl) { ¬†¬†¬†¬† $args = func_get_args(); ¬†¬†¬†¬† $this-&gt;checkNumber(&#39;setTTL&#39;, $args, 0); ¬†¬†¬†¬† $frame = $this-&gt;getFrameById(&#39;current&#39;); ¬†¬†¬†¬† if (is_callable(array($frame, &#39;setTTL&#39;))) { ¬†¬†¬†¬†¬†¬†¬†¬†¬† $frame-&gt;setTTL($ttl); // ?? ¬†¬†¬†¬† } } . Scribunto . Module: Bananas . local p = {} function p.hello(frame) ¬†¬†¬†¬† return &quot;Hello world&quot; end return p . other page: . {{#invoke:Bananas|hello}} .",
            "url": "https://jimregan.github.io/notes/evernote/2016/01/30/luaj-scribunto.html",
            "relUrl": "/evernote/2016/01/30/luaj-scribunto.html",
            "date": " ‚Ä¢ Jan 30, 2016"
        }
        
    
  
    
        ,"post174": {
            "title": "lisa-groundhog layers",
            "content": "lisa-groundhog layers . Layer | MultiLayer | SoftmaxLayer | HierarchicalSoftmaxLayer | LSTMLayer | RecurrentLayer | RecursiveConvolutionLayer | UnaryOp | Shift | LastState | DropOp | Concatenate | .",
            "url": "https://jimregan.github.io/notes/evernote/2016/01/30/lisa-groundhog-layers.html",
            "relUrl": "/evernote/2016/01/30/lisa-groundhog-layers.html",
            "date": " ‚Ä¢ Jan 30, 2016"
        }
        
    
  
    
        ,"post175": {
            "title": "Evernote web clips, 27/1/2016",
            "content": "A cross-language vowel normalisation procedure . An Aspectual Classification of Polish Verbs .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2016/01/27/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2016/01/27/evernote-links.html",
            "date": " ‚Ä¢ Jan 27, 2016"
        }
        
    
  
    
        ,"post176": {
            "title": "Evernote web clips, 16/1/2016",
            "content": "generate-bidix-templates.py . Hiberno-English Vowel System: Drogheda English . Tonal Alignment in Three Varieties of Hiberno-English . Hiberno-English Question Intonation: the Case of Drogheda English .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2016/01/16/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2016/01/16/evernote-links.html",
            "date": " ‚Ä¢ Jan 16, 2016"
        }
        
    
  
    
        ,"post177": {
            "title": "Evernote web clips, 1/12/2015",
            "content": "Unsupervised estimation of the human vocal tract length over sentence level utterances .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/12/01/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/12/01/evernote-links.html",
            "date": " ‚Ä¢ Dec 1, 2015"
        }
        
    
  
    
        ,"post178": {
            "title": "Evernote web clips, 29/11/2015",
            "content": "The invisible minority: revisiting the debate on foreign-accented speakers and upward mobility in the workplace. . Accents in the workplace: their effects during a job interview. . PLURILINGUALISM ‚Äì PRIORITY IN PROMOTING EQUALITY OF CHANCES. . Challenges of multilingualism in the EU. . Piecing together the workplace multilingualism jigsaw puzzle .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/11/29/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/11/29/evernote-links.html",
            "date": " ‚Ä¢ Nov 29, 2015"
        }
        
    
  
    
        ,"post179": {
            "title": "Evernote web clips, 17/11/2015",
            "content": "[Swesaurus | Spr√•kbanken](http://spraakbanken.gu.se/eng/resource/swesaurus) | . [SALDO‚Äôs morphology | Spr√•kbanken](http://spraakbanken.gu.se/eng/resource/saldom) | . [LWT | Spr√•kbanken](http://spraakbanken.gu.se/eng/resource/lwt) | . [LWT-PWN | Spr√•kbanken](http://spraakbanken.gu.se/eng/resource/lwt-pwn) | . An Engineer‚Äôs Guide to GEMM .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/11/17/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/11/17/evernote-links.html",
            "date": " ‚Ä¢ Nov 17, 2015"
        }
        
    
  
    
        ,"post180": {
            "title": "Evernote web clips, 28/10/2015",
            "content": "Guidelines for developing NIF-based NLP services . The Stanford NLP (Natural Language Processing) Group . Guidelines for Linked Data corpus creation using NIF . [Torch | The power of Spatial Transformer Networks](http://torch.ch/blog/2015/09/07/spatial_transformers.html) | .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/10/28/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/10/28/evernote-links.html",
            "date": " ‚Ä¢ Oct 28, 2015"
        }
        
    
  
    
        ,"post181": {
            "title": "Dependency analysis",
            "content": "Irish stuff . ¬† ¬† ¬† . d‚Äô | do | do+Part+Vb+@&gt;V | . √≥l | √≥l | √≥l+Verb+VTI+Vow+PastInd+Len+@FMV | . m√© | m√© | m√©+Pron+Pers+1P+Sg+@SUBJ | .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/10/26/irish-dependency.html",
            "relUrl": "/evernote/web%20clip/2015/10/26/irish-dependency.html",
            "date": " ‚Ä¢ Oct 26, 2015"
        }
        
    
  
    
        ,"post182": {
            "title": "Evernote web clips, 6/9/2015",
            "content": "Phoneme Recognition . btrask/stronglink .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/09/06/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/09/06/evernote-links.html",
            "date": " ‚Ä¢ Sep 6, 2015"
        }
        
    
  
    
        ,"post183": {
            "title": "Evernote web clips, 3/9/2015",
            "content": "Wikidata/Wikidata-Toolkit . NASARI . [Transition-Based Dependency Parsing with Stack Long Short-Term Memory | GitXiv](http://gitxiv.com/posts/qEQvDP8eidkAsGcPQ/transition-based-dependency-parsing-with-stack-long-short) | .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/09/03/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/09/03/evernote-links.html",
            "date": " ‚Ä¢ Sep 3, 2015"
        }
        
    
  
    
        ,"post184": {
            "title": "Evernote web clips, 12/8/2015",
            "content": "Parsing S-Expressions in Scala . Function Memoization in Scala . Clang Plugins ‚Äî Clang 3.8 documentation .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/08/12/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/08/12/evernote-links.html",
            "date": " ‚Ä¢ Aug 12, 2015"
        }
        
    
  
    
        ,"post185": {
            "title": "Evernote web clips, 12/6/2015",
            "content": "I have now converged on a stable recipe for deep neural net training Kaldi.‚Ä¶ . Start of parser . Untitled note . karpathy/gist:7bae8033dcf5ca2630ba . Use of exp in the Reparametrization ¬∑ Issue #3 ¬∑ y0ast/VAE-Torch . chrisnatale / IHTAI / wiki / Home ‚Äî Bitbucket . littleowen/Conceptor . duguyue100/conceptors .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/06/12/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/06/12/evernote-links.html",
            "date": " ‚Ä¢ Jun 12, 2015"
        }
        
    
  
    
        ,"post186": {
            "title": "Evernote web clips, 4/6/2015",
            "content": "ƒåetnost jmen a p≈ô√≠jmen√≠ - Ministerstvo vnitra ƒåesk√© republiky . NomesLex-PT 01 in English - DMIR Group at INESC-ID . [Sansa Stark | Reaction Images](http://knowyourmeme.com/photos/588075-reaction-images) | . OpenCL alternatives for CUDA Linear Algebra Libraries . What are important points about deep learning applied to speech recognition, for a business audience? - Quora . Deep Learning, NLP, and Representations . From Machine Learning to Machine Reasoning . Learning Continuous Phrase Representations for Translation Modeling . Hinton‚Äôs Dark Knowledge . High-Performance OCR for Printed English and Fraktur using LSTM Networks . C3D: Generic Features for Video Analysis . dlwh/epic . Senna . Natural Language Processing (almost) from Scratch . Conv Nets: A Modular Perspective . Understanding Convolutions . Visualizing Representations: Deep Learning and Human Beings .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/06/04/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/06/04/evernote-links.html",
            "date": " ‚Ä¢ Jun 4, 2015"
        }
        
    
  
    
        ,"post187": {
            "title": "Evernote web clips, 2015-06-03",
            "content": "cubicdaiya/dtl . facebook/Stack-RNN . An Introduction to Conditional Random Fields . Using word2vec for different NLP tasks ‚Ä¢ /r/MachineLearning . gensim: topic modelling for humans . erickrf/nlpnet . SENNA . Natural Language Processing (almost) from Scratch . The Agency . Demystifying LSTM Neural Networks . A good source to learn Recurrent Neural Nets and Long Short Term Memory Nets? ‚Ä¢ /r/MachineLearning . An illustrated introduction to the t-SNE algorithm - O&#39;Reilly Media . Feeding an image to a RNN or dealing with images of different dimensions? ‚Ä¢ /r/MachineLearning .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/06/03/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/06/03/evernote-links.html",
            "date": " ‚Ä¢ Jun 3, 2015"
        }
        
    
  
    
        ,"post188": {
            "title": "Evernote web clips, 31/5/2015",
            "content": "pyklatt - An advanced Python implementation of a Klatt synthesizer . Untitled note . Formant Estimation with LPC Coefficients . proteusvacuum/KlattSynth .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/05/31/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/05/31/evernote-links.html",
            "date": " ‚Ä¢ May 31, 2015"
        }
        
    
  
    
        ,"post189": {
            "title": "Evernote notes, TTS",
            "content": "Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups . Multi-distribution deep belief¬†network for speech synthesis . Modeling spectral envelopes using restricted Boltzmann machines for statistical parametric speech synthesis . Speech recognition with deep recurrent neural networks . Hybrid speech recognition with Deep Bidirectional LSTM . Connectionist temporal classification: labelling un-segmented sequence data with recurrent neural networks . mohammadpz/CTC-Connectionist-Temporal-Classification . Feature engineering in context-dependent deep neural networks for conversational speech transcription . A Novel Approach to On-Line Handwriting Recognition Based on Bidirectional Long Short-Term Memory Networks .",
            "url": "https://jimregan.github.io/notes/evernote/tts/asr/2015/05/30/tts-evernote.html",
            "relUrl": "/evernote/tts/asr/2015/05/30/tts-evernote.html",
            "date": " ‚Ä¢ May 30, 2015"
        }
        
    
  
    
        ,"post190": {
            "title": "Evernote web clips, 30/5/2015",
            "content": "Modeling spectral envelopes using restricted Boltzmann machines for statistical parametric speech synthesis . Multi-distribution deep belief network for speech synthesis . Deep Neural Networks for Acoustic Modeling in Speech Recognition . Grapheme-based Synthesizer . glecorve/rnnlm2wfst . Statistical Parametric Speech Synthesis Using Deep Neural Networks . NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE . Combining a vector space representation of linguistic context with a deep neural network for text-to-speech synthesis . TTS Synthesis with Bidirectional LSTM based Recurrent Neural Networks . Implementation of Neural Turing Machines ‚Ä¢ /r/MachineLearning . Sequence to Sequence Learning with Neural Networks . Discriminative models, not discriminative training . kastnerkyle/test_ctc.py . glecorve/rnnlm2wfst . DEEP NEURAL NETWORK (DNN) FOR TTS SYNTHESIS - Microsoft Research .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/05/30/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/05/30/evernote-links.html",
            "date": " ‚Ä¢ May 30, 2015"
        }
        
    
  
    
        ,"post191": {
            "title": "Evernote web clips, 29/5/2015",
            "content": "aalto-speech/AaltoASR . nouiz/lisa_emotiw . dpkingma/nips14-ssl . stanfordnlp/treelstm . CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers . mattpap/IScala . brian473/neural_rl . dcodeIO/ByteBuffer.js .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/05/29/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/05/29/evernote-links.html",
            "date": " ‚Ä¢ May 29, 2015"
        }
        
    
  
    
        ,"post192": {
            "title": "Simple lttoolbox transducer",
            "content": "hexdump /tmp/test2.bin 0000000 1a 40 61 40 62 40 63 40 64 40 65 40 66 40 67 40 0000010 68 40 69 40 6a 40 6b 40 6c 40 6d 40 6e 40 6f 40 0000020 70 40 71 40 72 40 73 40 74 40 75 40 76 40 77 40 0000030 78 40 79 40 7a 01 01 40 6e 08 01 01 01 40 74 01 0000040 00 40 67 40 67 40 70 40 70 40 63 40 63 40 62 40 0000050 62 40 73 40 73 02 12 40 69 40 6e 40 63 40 6f 40 0000060 40 40 69 40 6e 40 63 40 6f 40 6e 40 64 40 69 40 0000070 74 40 69 40 6f 40 6e 40 61 40 6c 00 01 05 06 01 0000080 05 01 01 06 01 01 07 01 01 01 01 01 02 01 00 0d 0000090 40 6d 40 61 40 69 40 6e 40 40 40 73 40 74 40 61 00000a0 40 6e 40 64 40 61 40 72 40 64 00 01 05 06 01 03 00000b0 01 01 04 01 01 04 01 01 01 01 01 02 01 00¬†¬†¬†¬†¬† 00000be . ^Z@a@b@c@d@e@f@g@h@i@j@k@l@m@n@o@p@q@r@s@t@u@v@w@x@y@z ^A^A@^A^A^A@t^A^@@g@g@p@p@c@c@b@b@s@s^B^R@i@n@c@o@@@i @n@c@o@n@d@i@t@i@o@n@a@l^@^A^E^F^A^E^A^A^F^A^A^G^A^A ^A^A^A^B^A^@^M@m@a@i@n@@@s@t@a@n@d@a@r@d^@^A^E^F^A^C ^A^A^D^A^A^D^A^A^A^A^A^B^A^@ . $ lt-print /tmp/test2.bin 0¬†¬†¬†¬† 1¬†¬†¬†¬† b¬†¬†¬†¬† b¬†¬†¬†¬† 1¬†¬†¬†¬† 2¬†¬†¬†¬† a¬†¬†¬†¬† a¬†¬†¬†¬† 2¬†¬†¬†¬† 3¬†¬†¬†¬† r¬†¬†¬†¬† r¬†¬†¬†¬† 3¬†¬†¬†¬† 4¬†¬†¬†¬† Œµ¬†¬†¬†¬† s¬†¬†¬†¬† 4¬†¬†¬†¬† 5¬†¬†¬†¬† Œµ¬†¬†¬†¬† &lt;n&gt;¬†¬†¬†¬† 5 -- 0¬†¬†¬†¬† 1¬†¬†¬†¬† f¬†¬†¬†¬† f¬†¬†¬†¬† 1¬†¬†¬†¬† 2¬†¬†¬†¬† o¬†¬†¬†¬† o¬†¬†¬†¬† 2¬†¬†¬†¬† 3¬†¬†¬†¬† o¬†¬†¬†¬† o¬†¬†¬†¬† 3¬†¬†¬†¬† 4¬†¬†¬†¬† Œµ¬†¬†¬†¬† s¬†¬†¬†¬† 4¬†¬†¬†¬† 5¬†¬†¬†¬† Œµ¬†¬†¬†¬† &lt;n&gt;¬†¬†¬†¬† 5 . ^@ ^A^E^F^A^E^A^A^F^A^A^G^A^A^A^A^A^B^A ^@ ^M . $ cat /tmp/test.dix . &lt;dictionary&gt; ¬† &lt;alphabet&gt;abcdefghijklmnopqrstuvwxyz&lt;/alphabet&gt; ¬† &lt;sdefs&gt; ¬†¬†¬† &lt;sdef n=&quot;n&quot;/&gt; ¬† &lt;/sdefs&gt; ¬† &lt;pardefs&gt; ¬†¬†¬† &lt;pardef n=&quot;one&quot;&gt; ¬†¬†¬†¬†¬† &lt;e&gt;&lt;p&gt;&lt;l&gt;&lt;/l&gt;&lt;r&gt;s&lt;s n=&quot;n&quot;/&gt;&lt;/r&gt;&lt;/p&gt;&lt;/e&gt; ¬†¬†¬† &lt;/pardef&gt; ¬† &lt;/pardefs&gt; ¬† &lt;section id=&quot;main&quot; type=&quot;standard&quot;&gt; ¬†¬†¬† &lt;e&gt;&lt;i&gt;foo&lt;/i&gt;&lt;par n=&quot;one&quot;/&gt;&lt;/e&gt; ¬† &lt;/section&gt; ¬† &lt;section id=&quot;inco&quot; type=&quot;inconditional&quot;&gt; ¬†¬†¬† &lt;e&gt;&lt;i&gt;bar&lt;/i&gt;&lt;par n=&quot;one&quot;/&gt;&lt;/e&gt; ¬† &lt;/section&gt; &lt;/dictionary&gt; .",
            "url": "https://jimregan.github.io/notes/evernote/2015/05/28/simple-lttoolbox-transducer.html",
            "relUrl": "/evernote/2015/05/28/simple-lttoolbox-transducer.html",
            "date": " ‚Ä¢ May 28, 2015"
        }
        
    
  
    
        ,"post193": {
            "title": "neural notes",
            "content": "Weakly Supervised Memory Networks . Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks . wojzaremba/lstm . Reinforcement Learning Neural Turing Machines . kaishengtai/torch-ntm . stanfordnlp/treelstm . Neural Machine Translation by Jointly Learning to Align and Translate . lisa-groundhog/GroundHog . rsennrich/nplm . shawntan/neural-turing-machines, implementation of neural turing machines, gcgibson/NTM . Learning to Execute . Sequence to Sequence Learning with Neural Networks .",
            "url": "https://jimregan.github.io/notes/evernote/2015/05/28/neural-notes-evernote-links.html",
            "relUrl": "/evernote/2015/05/28/neural-notes-evernote-links.html",
            "date": " ‚Ä¢ May 28, 2015"
        }
        
    
  
    
        ,"post194": {
            "title": "Evernote web clips, 27/5/2015",
            "content": "The Unreasonable Effectiveness of Recurrent Neural Networks . fchollet/keras . Implementation of Neural Turing Machines ‚Ä¢ /r/MachineLearning . [Keras: Theano-Based Deep Learning Library | Hacker News](https://news.ycombinator.com/item?id=9283105) | . INL/BlackLab . INL/BlackLab . INL/BlackLab . Circular_buffer example - 1.58.0 . Neural Machine Translation by Jointly Learning to Align and Translate .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/05/27/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/05/27/evernote-links.html",
            "date": " ‚Ä¢ May 27, 2015"
        }
        
    
  
    
        ,"post195": {
            "title": "Evernote web clips, 1/3/2015",
            "content": "SAMPA for Polish . Which GPU(s) to Get for Deep Learning: My Experience and Advice for Using GPUs in Deep Learning .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/03/01/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/03/01/evernote-links.html",
            "date": " ‚Ä¢ Mar 1, 2015"
        }
        
    
  
    
        ,"post196": {
            "title": "Evernote web clips, 19/5/2015",
            "content": "TrainingTesseract3 . C√©dric Verstraeten . Introduction to Artificial Neural Networks Part 2 - Learning . Pauls Online Notes : Calculus III - Partial Derivatives . Medieval Unicode Font Initiative - Wikipedia, the free encyclopedia .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/02/19/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/02/19/evernote-links.html",
            "date": " ‚Ä¢ Feb 19, 2015"
        }
        
    
  
    
        ,"post197": {
            "title": "Evernote web clips, 15/2/2015",
            "content": "Finger Trees - Andrew Gibiansky . Machine Learning: Neural Networks - Andrew Gibiansky . Machine Learning: the Basics - Andrew Gibiansky . Creating Language Kernels for IPython - Andrew Gibiansky . Convolutional Neural Networks - Andrew Gibiansky . K Nearest Neighbors: Simplest Machine Learning - Andrew Gibiansky . Hessian Free Optimization - Andrew Gibiansky . Fully Connected Neural Network Algorithms - Andrew Gibiansky . Convolutional Neural Networks - Andrew Gibiansky . Homophony Groups in Haskell - Andrew Gibiansky . Gradient Descent Typeclasses in Haskell - Andrew Gibiansky . Cool Linear Algebra: Singular Value Decomposition - Andrew Gibiansky . Recurrent Neural Networks - Andrew Gibiansky . Speech Recognition with Neural Networks - Andrew Gibiansky . Sequence Transduction with Recurrent Neural Networks . Speech Recognition with Neural Networks - Andrew Gibiansky .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/02/15/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/02/15/evernote-links.html",
            "date": " ‚Ä¢ Feb 15, 2015"
        }
        
    
  
    
        ,"post198": {
            "title": "Evernote web clips, 8/2/2015",
            "content": "SuDoKu Grabber with OpenCV: Recognizing digits - AI Shack . SuDoKu Grabber with OpenCV: Extracting digits - AI Shack . SuDoKu Grabber with OpenCV: Extracting the grid - AI Shack . SuDoKu Grabber with OpenCV: The Plot - AI Shack . Caffe: Add TRec unit . Caffe: Load weights from multiple caffemodels . On Academia‚Ä¶ ¬´ muellis blog . Running the code with Ocelot - Udacity .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/02/08/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/02/08/evernote-links.html",
            "date": " ‚Ä¢ Feb 8, 2015"
        }
        
    
  
    
        ,"post199": {
            "title": "Evernote web clips, 6/2/2015",
            "content": "Android: Simple Shape Recognition using OpenCV, JavaCV . SuDoKu Grabber with OpenCV: Grid detection - AI Shack . [The D2RQ Mapping Language | The D2RQ Platform](http://d2rq.org/d2rq-language#example-join) | . d2rp example . Metacademy - Deep learning from the bottom up . How to detect simple geometric shapes using OpenCV . [Note to self: Compiling C++ programs using libraries installed with homebrew | The NonConditional Beast](http://nonconditional.com/2013/10/note-to-self-compiling-programs-using-boost-installed-with-homebrew/) | . Deep Learning via Semi-Supervised Embedding . Representation Learning: A Review and New Perspectives . Recursive Autoencoder with Theano - Google Groups .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/02/06/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/02/06/evernote-links.html",
            "date": " ‚Ä¢ Feb 6, 2015"
        }
        
    
  
    
        ,"post200": {
            "title": "Evernote web clips, 15/1/2015",
            "content": "[School of Shred: Paul Gilbert on the Art and Science of Playing Lead Guitar - Page 3 | Guitar World](http://www.guitarworld.com/school-shred-paul-gilbert-teaches-isightful-lesson-art-and-science-lead-guitar-playing?page=0,2) | . [School of Shred: Paul Gilbert on the Art and Science of Playing Lead Guitar - Page 2 | Guitar World](http://www.guitarworld.com/school-shred-paul-gilbert-teaches-isightful-lesson-art-and-science-lead-guitar-playing?page=0,1) | . [School of Shred: Paul Gilbert on the Art and Science of Playing Lead Guitar | Guitar World](http://www.guitarworld.com/school-shred-paul-gilbert-teaches-isightful-lesson-art-and-science-lead-guitar-playing) | . Drop 2 Chords &amp; Voicings For Guitar . Guitar Chalk Sessions: A Clean Guide to Understanding Seventh Chords . . Dlaczego s≈Çownik nie stoi na stra≈ºy czysto≈õci jƒôzyka? - Wielki s≈Çownik od kuchni . GDSSecurity/Docker-Secure-Deployment-Guidelines . Creating and publishing a node.js module - Quick Left . Felix‚Äôs Node.js Beginners Guide .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/01/15/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/01/15/evernote-links.html",
            "date": " ‚Ä¢ Jan 15, 2015"
        }
        
    
  
    
        ,"post201": {
            "title": "Evernote web clips, 14/1/2015",
            "content": "Constructing Deterministic Finite-State Automata in Recurrent Neural Networks . Finite-state computation in analog neural networks: steps towards biologically plausible models? . Comparing two acquisition systems for automatically building an English‚ÄìCroatian parallel corpus from multilingual websites . Quality Estimation for Synthetic Parallel Data Generation . Abu-MaTran at WMT 2014 Translation Task: Two-step Data Selection and RBMT-Style Synthetic Rules . [Custom Runners | Cloud9 User Documentation](https://docs.c9.io/custom_runners.html) | . [Jazz Guitar Corner: Jazz Guitar Chord Exercises ‚Äî with Tab and Audio | Guitar World](http://www.guitarworld.com/jazz-guitar-corner-jazz-guitar-chord-exercises-tab-and-audio) | . To Fall in Love With Anyone, Do This - NYTimes.com . Here Are the 36 Questions That Will Allegedly Make You Fall in Love . No. 37: Big Wedding or Small? - NYTimes.com . How to Get Read on Medium ‚Äî Medium . The Grumpy Programmer: October 2014 . Scripting Languages You May Not Know - Dice News .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/01/14/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/01/14/evernote-links.html",
            "date": " ‚Ä¢ Jan 14, 2015"
        }
        
    
  
    
        ,"post202": {
            "title": "Evernote web clips, 12/1/2015",
            "content": "Text in Russian: Saint Petersburg . Text in Russian: The coldest town on Earth . Text in Russian: Banya / Russian Sauna . Text in Russian: Russian bear .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/russian/2015/01/12/evernote-links.html",
            "relUrl": "/evernote/web%20clip/russian/2015/01/12/evernote-links.html",
            "date": " ‚Ä¢ Jan 12, 2015"
        }
        
    
  
    
        ,"post203": {
            "title": "Evernote web clips, 8/1/2015",
            "content": "Wikimedia Blog ¬ª Blog Archive ¬ª Scaling Wikidata: success means making the pie bigger . [The 88 movies we‚Äôre most excited about in 2015 | Film | The Guardian](http://www.theguardian.com/film/2015/jan/06/2015-key-movies-films-year-ahead) | . azakai: HOWTO: Port a C/C++ Library to JavaScript (xml.js) . Getting Started With Emscripten ¬∑ jallwine/emscripten_test Wiki . wiki.dbpedia.org : meetings¬†/¬†Dublin¬†2015 . [What reviewers write, and what they (really) mean | Peter Simons - Academia.edu](https://www.academia.edu/9468277/What_reviewers_write_and_what_they_really_mean) | .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/01/08/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/01/08/evernote-links.html",
            "date": " ‚Ä¢ Jan 8, 2015"
        }
        
    
  
    
        ,"post204": {
            "title": "Evernote web clips, 1/1/2015",
            "content": "[Word Embeddings For Fashion | Technology on Heels with Lyst Engineering](https://making.lyst.com/2014/11/11/word-embeddings-for-fashion/) | . Neat Algorithms - Paxos - Will You Harry Me . Radim ≈òeh≈Ø≈ôek : Word2vec Tutorial . Life Lessons From Highly Successful People - Business Insider .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/01/01/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/01/01/evernote-links.html",
            "date": " ‚Ä¢ Jan 1, 2015"
        }
        
    
  
    
        ,"post205": {
            "title": "Evernote web clips, 29/12/2014",
            "content": "A Faster Scrabble Move Generation Algorithm . [Gaddag Data Structure ‚Äì A Way To Quickly Find Scrabble Words | NullWords Blog](http://nullwords.wordpress.com/2013/02/27/gaddag-data-structure/) | . [Jacky Tian | Blog](http://blog.xjtian.com/post/50516439182/a-smarter-scrabble-ai-part-1-lexical) | . GADDAG.java .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/gaddag/scrabble/2014/12/29/evernote-links.html",
            "relUrl": "/evernote/web%20clip/gaddag/scrabble/2014/12/29/evernote-links.html",
            "date": " ‚Ä¢ Dec 29, 2014"
        }
        
    
  
    
        ,"post206": {
            "title": "Evernote web clips, 28/12/2014",
            "content": "Distilling the Knowledge in a Neural Network . Implementation of Lucas-Kanade tracker in cpp . lk_track.py . SLAM for Dummies . Nikita Zhiltsov / –ù–∏–∫–∏—Ç–∞ –ñ–∏–ª—å—Ü–æ–≤: My Visiting Project at Emory University: Entity Search over Linked Data . Chapter¬†10.¬†Code case study: parsing a binary data format .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/12/28/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/12/28/evernote-links.html",
            "date": " ‚Ä¢ Dec 28, 2014"
        }
        
    
  
    
        ,"post207": {
            "title": "Evernote, 21/12/2014",
            "content": "phash.cc . #include &lt;iostream&gt; #include &lt;string&gt; #include &lt;pHash.h&gt; #define PROPS_URL &quot;&lt;http://...&gt;&quot; int main (int argc, char** argv) { ¬†¬†¬†¬† ulong64 hash = 0; ¬†¬†¬†¬† string name; ¬†¬†¬†¬† while(std::getline(std::cin, name)) ¬†¬†¬†¬† { ¬†¬†¬†¬†¬†¬†¬†¬†¬† ph_dct_imagehash(name.c_str(), hash); ¬†¬†¬†¬†¬†¬†¬†¬†¬† std::cout &lt;&lt; &quot;&lt;http://&quot; &lt;&lt; name &lt;&lt; &quot;&gt; &quot;; ¬†¬†¬†¬†¬†¬†¬†¬†¬† std::cout &lt;&lt; PROPS_URL; ¬†¬†¬†¬†¬†¬†¬†¬†¬† std::cout &lt;&lt; &quot; &quot;&quot; &lt;&lt; hash &lt;&lt; &quot; &quot; .&quot; &lt;&lt; endl; ¬†¬†¬†¬†¬†¬†¬†¬†¬† hash = 0; ¬†¬†¬†¬† } ¬†¬†¬†¬† return 0; } .",
            "url": "https://jimregan.github.io/notes/evernote/phash/2014/12/21/phash.html",
            "relUrl": "/evernote/phash/2014/12/21/phash.html",
            "date": " ‚Ä¢ Dec 21, 2014"
        }
        
    
  
    
        ,"post208": {
            "title": "Evernote web clips, 18/12/2014",
            "content": "Fun mosaic effect with Go . Cultural Studies and Modern Languages: an Introduction ‚Äî University of Bristol ‚Äî FutureLearn . Introduction to Dutch ‚Äî University of Groningen ‚Äî FutureLearn .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/12/18/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/12/18/evernote-links.html",
            "date": " ‚Ä¢ Dec 18, 2014"
        }
        
    
  
    
        ,"post209": {
            "title": "Evernote web clips, 13/12/2014",
            "content": "Rich feature hierarchies for accurate object detection and semantic segmentation . AUDFPRINT - Audio fingerprint database creation + query . [Using Docker to Encapsulate Complicated Program is Successful | Internet Archive Blogs](http://blog.archive.org/2014/11/14/docker-to-encapsulate-complicated-program-successful/) | .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/12/13/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/12/13/evernote-links.html",
            "date": " ‚Ä¢ Dec 13, 2014"
        }
        
    
  
    
        ,"post210": {
            "title": "Evernote web clips, 12/12/2014",
            "content": "Addressing the Rare Word Problem in Neural Machine Translation . presslabs/gitfs . gitfs/Vagrantfile at master ¬∑ PressLabs/gitfs . [From word2vec to doc2vec: an approach driven by Chinese restaurant process | Kifi Engineering Blog](https://web.archive.org/web/20160309231845/http://eng.kifi.com/from-word2vec-to-doc2vec-an-approach-driven-by-chinese-restaurant-process/) | . word2vec Explained: deriving Mikolov et al.‚Äôs negative-sampling word-embedding method . gensim: models.word2vec ‚Äì Deep learning with word2vec . Sequence to Sequence Learning with Neural Networks . Distributed Representations of Sentences and Documents . Writing and transliterating Swahili in Arabic script with Andika! . [Fast Randomized SVD | Blog | Research at Facebook](https://research.facebook.com/blog/294071574113354/fast-randomized-svd/) | . [Question Answering with Subgraph Embeddings | Publications | Research at Facebook](https://research.facebook.com/publications/1473550739586509/question-answering-with-subgraph-embeddings/) | . [C3D: Generic Features for Video Analysis | Blog | Research at Facebook](https://research.facebook.com/blog/736987489723834/c3d-generic-features-for-video-analysis/) | . Machine Learning: The High-Interest Credit Card of Technical Debt . The Psychology of Color in Marketing and Branding . GloVe: Global Vectors for Word Representation . Distributing the Singular Value Decomposition with Spark ‚Äì Databricks . Spark/mllib SVD example . How do I turn off the unlimited whitespace in IntelliJ editor? - Stack Overflow .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/12/12/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/12/12/evernote-links.html",
            "date": " ‚Ä¢ Dec 12, 2014"
        }
        
    
  
    
        ,"post211": {
            "title": "Evernote web clips, 6/11/2014",
            "content": "KALDI: Decision tree internals . Recurrent Neural Network Language Models . Deeplearning4j - Open-source, distributed deep learning for the JVM . Hac - A Java class library for hierarchical agglomerative clustering . Tangle: API Reference . Blazing fast AST generation using boost::spirit . Deep Learning, NLP, and Representations . Parse::RecDescent - search.cpan.org . An Introduction to the Boost Spirit Parser framework - CodeProject .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/11/06/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/11/06/evernote-links.html",
            "date": " ‚Ä¢ Nov 6, 2014"
        }
        
    
  
    
        ,"post212": {
            "title": "Evernote web clips, 2/11/2014",
            "content": "www.boddie.org.uk/david - Impression Documents and Tools . Spectrum +3 CP/M Plus manual . Reverse engineering the Quark Xpress file format .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/11/02/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/11/02/evernote-links.html",
            "date": " ‚Ä¢ Nov 2, 2014"
        }
        
    
  
    
        ,"post213": {
            "title": "Evernote web clips, 30/10/2014",
            "content": "Training Acoustic Model For CMUSphinx - CMUSphinx Wiki . [Russian Audiobook Morphology-Based Model | CMU Sphinx - Speech Recognition Toolkit](https://cmusphinx.github.io/2011/09/russian-audiobook-morphology-based-model/) | .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/10/30/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/10/30/evernote-links.html",
            "date": " ‚Ä¢ Oct 30, 2014"
        }
        
    
  
    
        ,"post214": {
            "title": "Evernote web clips, 28/10/2014",
            "content": "Pagestream . Impression Document Description Format .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/10/28/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/10/28/evernote-links.html",
            "date": " ‚Ä¢ Oct 28, 2014"
        }
        
    
  
    
        ,"post215": {
            "title": "Evernote web clips, 27/10/2014",
            "content": "LibriVox . OpenGRM.org . Lecture 6: OpenFST . OpenFst: src/include/fst/concat.h Source File . Tutorial for OpenFST and PyFST . OpenFST: Part II. Library Use and Design . The Problem With Positive Thinking - NYTimes.com . ConcatDoc &lt; FST &lt; TWiki . espeak ttsengine.cpp . /sources/flite/sapi/FliteTTSEngineObj/FliteTTSEngineObj.cpp . TTS Engine Vendor Porting Guide (SAPI 5.3) . XML TTS Tutorial (SAPI 5.3) . Overview of SAPI Grammar: Solitaire Example (SAPI 5.3) . Helper SpConvertStreamFormatEnum (SAPI 5.3) .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/10/27/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/10/27/evernote-links.html",
            "date": " ‚Ä¢ Oct 27, 2014"
        }
        
    
  
    
        ,"post216": {
            "title": "Evernote web clips, 17/10/2014",
            "content": "Changing Bits: Lucene‚Äôs TokenStreams are actually graphs! . Appendix:Lower Sorbian nouns - Wiktionary . [How to Write a Spelling Corrector | Felipe Farinon](http://scarvenger.wordpress.com/2007/12/11/how-to-write-a-spelling-corrector/) | .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/10/17/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/10/17/evernote-links.html",
            "date": " ‚Ä¢ Oct 17, 2014"
        }
        
    
  
    
        ,"post217": {
            "title": "Evernote web clips, 7/9/2014",
            "content": "command center: The byte order fallacy . nnFileFormat - tesseract-ocr-extradocs - Extra documentation about Tesseract OCR - Google Project Hosting . Distributed systems theory for the distributed systems engineer : Paper Trail .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/09/07/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/09/07/evernote-links.html",
            "date": " ‚Ä¢ Sep 7, 2014"
        }
        
    
  
    
        ,"post218": {
            "title": "Evernote web clips, 1/9/2014",
            "content": "HfstTwolC &lt; KitWiki &lt; TWiki . koskenni/pytwolc . CA : Two-Level Rule Compiler - Xerox XRCE .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/09/01/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/09/01/evernote-links.html",
            "date": " ‚Ä¢ Sep 1, 2014"
        }
        
    
  
    
        ,"post219": {
            "title": "Evernote web clips, 8/8/2014",
            "content": "vptree.hs . Convert Between std::string and std::wstring, UTF-8 and UTF-16 - CodeProject . Google Fonts Uncial Antiqua . Appendix:Scots irregular verbs .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/08/08/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/08/08/evernote-links.html",
            "date": " ‚Ä¢ Aug 8, 2014"
        }
        
    
  
    
        ,"post220": {
            "title": "Evernote web clips, 2/8/2014",
            "content": "LLVM Tutorial . robovm/robovm . BlueRiverInteractive/robovm-ios-bindings . parslet -Get Started . A Gentle Introduction to IO Streams in C++ . Implementing a JIT Compiler with Haskell and LLVM . . As Yet Untitled ‚Äî Git: Grafting repositories . hivex - Windows Registry &quot;hive&quot; extraction library .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/08/02/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/08/02/evernote-links.html",
            "date": " ‚Ä¢ Aug 2, 2014"
        }
        
    
  
    
        ,"post221": {
            "title": "Lolita vocabulary",
            "content": "etiolate make pale . coeval of the same age, from the same time . palliative serving to mitigate . fascinum ivory phallus . somatic relating to the body of an organism . tiddle fondle . axillary of or pertaining to the axilla or armpit . russet reddish-brown . voluptas pleasure . fr√©tillement wriggling . tant pis too bad, never mind . Il √©tait malin, celui qui a invent√© ce truc-l√† He was clever, whoever invented this thing . grue prostitute .",
            "url": "https://jimregan.github.io/notes/evernote/2014/07/23/lolita-vocab-evernote-links.html",
            "relUrl": "/evernote/2014/07/23/lolita-vocab-evernote-links.html",
            "date": " ‚Ä¢ Jul 23, 2014"
        }
        
    
  
    
        ,"post222": {
            "title": "Evernote web clips, 23/7/2014",
            "content": "PL101: Create your own programming language . PL101: Create your own programming language . PL101: Create your own programming language . PL101: Create your own programming language . PL101: Create your own programming language . PL101: Create your own programming language . PL101: Create your own programming language . PL101: Create your own programming language . Parsoid - MediaWiki . Parsoid/MediaWiki DOM spec - MediaWiki .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/07/23/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/07/23/evernote-links.html",
            "date": " ‚Ä¢ Jul 23, 2014"
        }
        
    
  
    
        ,"post223": {
            "title": "Evernote web clips, 22/7/2014",
            "content": "The End of the Russian Fairy Tale . Rosja idzie w zaparte: fa≈Çszywi eksperci i informacje w rzƒÖdowych mediach . Koniec rosyjskiej bajki. Wkr√≥tce wszystko stanie siƒô jasne . Separaty≈õci wpu≈õcili ekspert√≥w na miejsce katastrofy. Na Ukrainƒô lecƒÖ policjanci z Australii . Ukraina . . Basic Binding using RoboVM and libGDXSeven Armed Squid . [Caffe | MNIST Tutorial](http://caffe.berkeleyvision.org/gathered/examples/mnist.html) | . [article | Perl 5 to Perl 6](http://perlgeek.de/en/article/5-to-6) | . Reading: It&#39;s All Good: Lolita . gocircuit/escher . simple_example.cc .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/07/22/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/07/22/evernote-links.html",
            "date": " ‚Ä¢ Jul 22, 2014"
        }
        
    
  
    
        ,"post224": {
            "title": "Evernote web clips, 16/7/2014",
            "content": "Public API Specification - NIF 2.0 . PDFBox text extraction . PDFBox create . Getting Started with Xtext . latex_equations.md .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/07/16/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/07/16/evernote-links.html",
            "date": " ‚Ä¢ Jul 16, 2014"
        }
        
    
  
    
        ,"post225": {
            "title": "Evernote web clips, 13/7/2014",
            "content": "[5 Essential Jazz Guitar Soloing Patterns | The Jazz Guitar Blog](http://www.jazzguitar.be/blog/5-essential-jazz-guitar-soloing-patterns/) | . Jazz Guitar Chord Theory Part 1 . [Guitar Scales | The Altered Scale For Guitar](https://www.jazzguitar.be/blog/altered-scale-for-guitar/) | . [17 Essential Jazz Guitar Chords For Beginners | Chord Chart](http://www.jazzguitar.be/blog/17-essential-jazz-guitar-chords-beginners/) | . [Gypsy Jazz Guitar | Django Reinhardt Arpeggios, Tricks &amp; Licks](https://www.jazzguitar.be/blog/django-reinhardt/) | . Exotic Guitar Scales .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/07/13/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/07/13/evernote-links.html",
            "date": " ‚Ä¢ Jul 13, 2014"
        }
        
    
  
    
        ,"post226": {
            "title": "Evernote web clips, 10/7/2014",
            "content": "Folder2IndexApp.java . APIExample . sven efftinge‚Äôs blog: 5 simple steps to Fowler‚Äôs DSL with Xtext 2.0 . Elastic Bunch Graph Matching - Scholarpedia . Polish ¬ª I4D - IVONA 4 Developers . Enclosing the public domain: The restriction of public domain books in a digital environment .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/07/10/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/07/10/evernote-links.html",
            "date": " ‚Ä¢ Jul 10, 2014"
        }
        
    
  
    
        ,"post227": {
            "title": "Evernote web clips, 28/4/2014",
            "content": "Ania DƒÖbrowska - Jej zapach . Ania DƒÖbrowska - Przy sƒÖsiednim stoliku .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/04/28/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/04/28/evernote-links.html",
            "date": " ‚Ä¢ Apr 28, 2014"
        }
        
    
  
    
        ,"post228": {
            "title": "Evernote web clips, 26/4/2014",
            "content": "LuaJ add lua function in Java - Stack Overflow . lua - Force an integer type in luajava - Stack Overflow . nltk.probability.FreqDist . [public:gaussian_mixture_models_em_algorithm_-demo](https://web.archive.org/web/20160911013157/http://juergenwiki.de/work/wiki/doku.php?id=public:gaussian_mixture_models_em_algorithm-_demo) . c++ - OpenCV: color extraction based on Gaussian mixture model - Stack Overflow . ~sepisoad/vala-totrials/ValaTutorials : contents of io/gio_based/simple_text_file_reading/main.vala at revision 22 .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/04/26/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/04/26/evernote-links.html",
            "date": " ‚Ä¢ Apr 26, 2014"
        }
        
    
  
    
        ,"post229": {
            "title": "Evernote web clips, 25/4/2014",
            "content": "Image Recoloring using Gaussian Mixture Model and Expectation Maximization . _gpc.py . _gpr.py . 1.7 Gaussian Processes ‚Äî scikit-learn 0.14 documentation .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/04/25/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/04/25/evernote-links.html",
            "date": " ‚Ä¢ Apr 25, 2014"
        }
        
    
  
    
        ,"post230": {
            "title": "Evernote web clips, 24/4/2014",
            "content": "Neural networks and deep learning . java - How can I pass objects to an exposed luaj function? - Stack Overflow .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/04/24/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/04/24/evernote-links.html",
            "date": " ‚Ä¢ Apr 24, 2014"
        }
        
    
  
    
        ,"post231": {
            "title": "Evernote web clips, 23/4/2014",
            "content": "The Science of Scientific Writing ¬ª American Scientist . File Exchange - MATLAB Central . A Gentle Introduction to Infrared Photography - Part 1 ‚Äî Twelve-Tone Infrared Photography . Infrared basics for digital photographers . FLIR Tools Software for Use with FLIR Infrared Cameras and Thermal Imagers . Open Source Thermal Imaging . IRINFO - Understanding Proprietary Infrared Image Files .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/04/23/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/04/23/evernote-links.html",
            "date": " ‚Ä¢ Apr 23, 2014"
        }
        
    
  
    
        ,"post232": {
            "title": "jsoup Evernote web clips, 21/4/2014",
            "content": "Use selector-syntax to find elements: jsoup Java HTML parser . Use DOM methods to navigate a document: jsoup Java HTML parser . jsoup Java HTML Parser, with best of DOM, CSS, and jquery . Working with URLs: jsoup Java HTML parser . Extract attributes, text, and HTML from elements . Example program: list links: jsoup Java HTML parser . Set attribute values: jsoup Java HTML parser . Jsoup.clean without adding html entities - Stack Overflow . jsoup: Java HTML Parser . Whitelist (jsoup 1.7.4-SNAPSHOT API) . How To Parse HTML in JAVA -JSOUP Examples .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/jsoup/2014/04/21/jsoup-evernote-links.html",
            "relUrl": "/evernote/web%20clip/jsoup/2014/04/21/jsoup-evernote-links.html",
            "date": " ‚Ä¢ Apr 21, 2014"
        }
        
    
  
    
        ,"post233": {
            "title": "Evernote web clips, 21/4/2014",
            "content": "LOCOCONZ-PAS.txt . hypercard.org - Open Source HyperCard-related stuff . q_c.txt . dkpro-jwpl . TemplateNameExtractor.java . MicroDesign 3 page (.MDP) and area (.MDA) file specifications . LocoScript 1 file format .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/04/21/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/04/21/evernote-links.html",
            "date": " ‚Ä¢ Apr 21, 2014"
        }
        
    
  
    
        ,"post234": {
            "title": "lttoolbox oneOrMore",
            "content": "oneOrMore . This is code from lttoolbox, licence GPL 2 . void Transducer::oneOrMore(int const epsilon_tag) { ¬† joinFinals(epsilon_tag); ¬† int state = newState(); ¬† linkStates(state, initial, epsilon_tag); ¬† initial = state; ¬† state = newState(); ¬† linkStates(*finals.begin(), state, epsilon_tag); ¬† finals.clear(); ¬† finals.insert(state); ¬† linkStates(state, initial, epsilon_tag); } void Transducer::joinFinals(int const epsilon_tag) { ¬† if(finals.size() &gt; 1) ¬† { ¬†¬†¬† int state = newState(); ¬†¬†¬† for(set&lt;int&gt;::iterator it = finals.begin(), limit = finals.end(); ¬†¬†¬†¬†¬†¬†¬† it != limit; it++) ¬†¬†¬† { ¬†¬†¬†¬†¬† linkStates(*it, state, epsilon_tag); ¬†¬†¬† } ¬†¬†¬† finals.clear(); ¬†¬†¬† finals.insert(state); ¬† } ¬† else if(finals.size() == 0) ¬† { ¬†¬†¬† wcerr &lt;&lt; L&quot;Error: empty set of final states&quot; &lt;&lt;endl; ¬†¬†¬† exit(EXIT_FAILURE); ¬† } } void Transducer::linkStates(int const source, int const destino, ¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬†¬† int const etiqueta) { ¬† if(transitions.find(source) != transitions.end() &amp;&amp; ¬†¬†¬†¬† transitions.find(destino) != transitions.end()) ¬† { ¬†¬†¬† // new code ¬†¬†¬† pair&lt;multimap&lt;int, int&gt;::iterator, multimap&lt;int, int&gt;::iterator&gt; range; ¬†¬†¬† range = transitions[source].equal_range(etiqueta); ¬†¬†¬† for(;range.first != range.second; range.first++) ¬†¬†¬† { ¬†¬†¬†¬†¬† if(range.first-&gt;first == etiqueta &amp;&amp; range.first-&gt;second == destino) ¬†¬†¬†¬†¬† { ¬†¬†¬†¬†¬†¬†¬† return; ¬†¬†¬†¬†¬† } ¬†¬†¬† } ¬†¬†¬† // end of new code ¬†¬†¬† transitions[source].insert(pair&lt;int, int&gt;(etiqueta, destino)); ¬† } ¬† else ¬† { ¬†¬†¬† wcerr &lt;&lt; L&quot;Error: Trying to link nonexistent states (&quot; &lt;&lt; source; ¬†¬†¬† wcerr &lt;&lt; L&quot;, &quot; &lt;&lt; destino &lt;&lt; L&quot;, &quot; &lt;&lt; etiqueta &lt;&lt; L&quot;)&quot; &lt;&lt; endl; ¬†¬†¬† exit(EXIT_FAILURE); ¬† } } .",
            "url": "https://jimregan.github.io/notes/evernote/lttoolbox/2014/03/23/one-or-more.html",
            "relUrl": "/evernote/lttoolbox/2014/03/23/one-or-more.html",
            "date": " ‚Ä¢ Mar 23, 2014"
        }
        
    
  
    
        ,"post235": {
            "title": "Evernote web clips, 22/6/2013",
            "content": "Quick notes on how to use RapidXML . rapid xml example . Archive of Formal Proofs .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2013/06/22/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2013/06/22/evernote-links.html",
            "date": " ‚Ä¢ Jun 22, 2013"
        }
        
    
  
    
        ,"post236": {
            "title": "Evernote web clips, 12/2/2013",
            "content": "IBM Model 1 . IBM Model 1 defines the probability of a sentence $s_1^J$, with length $J$, being translated to a sentence $t_1^I$, with length $I$, with the alignment $a_1^J$ as: . $Pr(t,a|s) = frac{ epsilon}{(J+1)^{I}} prod_{j=1}^{J}{tr(t_j|s_{a(j)})}$ . ASM/AAM . LeungMalikFilterBank .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2013/02/12/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2013/02/12/evernote-links.html",
            "date": " ‚Ä¢ Feb 12, 2013"
        }
        
    
  
    
        ,"post237": {
            "title": "Evernote web clips, 28/1/2013",
            "content": "mysql&gt; SELECT COUNT(DISTINCT p.product_id) AS total FROM oc_product p LEFT JOIN oc_product_description pd ON (p.product_id = pd.product_id) LEFT JOIN oc_product_to_store p2s ON (p.product_id = p2s.product_id) LEFT JOIN oc_product_to_category p2c ON (p.product_id = p2c.product_id) WHERE pd.language_id = &#39;1&#39; AND p.status = &#39;1&#39; AND p.date_available &lt;= NOW() AND p2s.store_id = &#39;0&#39; AND (p2c.category_id = &#39;2101&#39;); +-+ | total | +-+ |¬†¬†¬† 19 | +-+ 1 row in set (15.58 sec) . Keynote DTD . keynote-apxl.html .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2013/01/28/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2013/01/28/evernote-links.html",
            "date": " ‚Ä¢ Jan 28, 2013"
        }
        
    
  
    
        ,"post238": {
            "title": "Evernote web clips, 2012-09-17",
            "content": "[How to clear font caches in Leopard | Macworld](http://www.macworld.com/article/1139383/fontcacheclear.html) | . If you want to remove the font cache for all users, use this command, and provide your admin password when asked: sudo atsutil databases -remove . Once you‚Äôve cleared the caches, you should stop and restart the ATS server with these commands: . $ atsutil server -shutdown . $ atsutil server -ping . OpenIMAJ DoubleKMeans .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2012/09/17/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2012/09/17/evernote-links.html",
            "date": " ‚Ä¢ Sep 17, 2012"
        }
        
    
  
    
        ,"post239": {
            "title": "Evernote web clips, 16/9/2012",
            "content": "[Home | Natural Language Processing Laboratory](http://web.archive.org/web/20110907050907/http://nlp.sbu.ac.ir/site) | . [Multilingual Central Repository | adimen.si.ehu.es](http://adimen.si.ehu.es/web/MCR) | . MultiWordNet - Related works . MLSN: Download . Japanese Wordnet . FinnWordNet: Download files - Department of General Linguistics . Estonian Wordnet . Thai WordNet license . Sanskrit WordNet . Slovensk√° terminologick√° datab√°za .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/wordnet/2012/09/16/evernote-links.html",
            "relUrl": "/evernote/web%20clip/wordnet/2012/09/16/evernote-links.html",
            "date": " ‚Ä¢ Sep 16, 2012"
        }
        
    
  
    
        ,"post240": {
            "title": "SUMO relations",
            "content": "SUMO relations . ¬† ¬† . equivalenceRelation¬† | = | . subsumingRelation¬† | + | . instanceRelation | @ | . antiSubsumingRelation | [ | . antiEquivalenceRelation | : | .",
            "url": "https://jimregan.github.io/notes/evernote/sumo/2012/09/10/sumo-relations.html",
            "relUrl": "/evernote/sumo/2012/09/10/sumo-relations.html",
            "date": " ‚Ä¢ Sep 10, 2012"
        }
        
    
  
    
        ,"post241": {
            "title": "Linking lexical resources and ontologies on the semantic web with lemon",
            "content": "@inproceedings{McCrae:2011:LLR:2008892.2008914, author = {McCrae, John and Spohr, Dennis and Cimiano, Philipp}, title = {Linking lexical resources and ontologies on the semantic web with lemon}, booktitle = {Proceedings of the 8th extended semantic web conference on The semantic web: research and applications - Volume Part I}, series = {ESWC&#39;11}, year = {2011}, isbn = {978-3-642-21033-4}, location = {Heraklion, Crete, Greece}, pages = {245--259}, numpages = {15}, url = {http://dl.acm.org/citation.cfm?id=2008892.2008914}, acmid = {2008914}, publisher = {Springer-Verlag}, address = {Berlin, Heidelberg}, } .",
            "url": "https://jimregan.github.io/notes/evernote/2012/08/17/lemon-citation.html",
            "relUrl": "/evernote/2012/08/17/lemon-citation.html",
            "date": " ‚Ä¢ Aug 17, 2012"
        }
        
    
  
    
        ,"post242": {
            "title": "ImageTerrier command",
            "content": "ImageTerrier command . /usr/bin/java -Xshare:off -Xmx6G -Djava.awt.headless=true -XX:-UseGCOverheadLimit -Dbundle.size=1000 -Dmemory.reserved=400000000 -cp /Users/jim/Downloads/ImageTerrierTools-3.0.1-jar-with-dependencies.jar org.imageterrier.basictools.BasicIndexer -o idx -qt RANDOM -p BYTE -k 100000 -t POSITION -pm SPATIAL_SCALE_ORI -nb 8,8,8,8 -mins 0.0,0.0,0.0,-3.14157 -maxs 1000.0,1000.0,150.0,3.14157 . .",
            "url": "https://jimregan.github.io/notes/evernote/imageterrier/2012/06/12/imageterrier-command-evernote-links.html",
            "relUrl": "/evernote/imageterrier/2012/06/12/imageterrier-command-evernote-links.html",
            "date": " ‚Ä¢ Jun 12, 2012"
        }
        
    
  
    
        ,"post243": {
            "title": "Evernote web clips, 12/6/2012",
            "content": "Tesseract iterator . tess.SetImage(...); tess.Recognize(0); tesseract::ResultIterator* ri = tess.GetIterator(); tesseract::ChoiceIterator* ci; if(ri != 0) { do { const char* symbol = ri-&gt;GetUTF8Text(tesseract::RIL_SYMBOL); if(symbol != 0) { float conf = ri-&gt;Confidence(tesseract::RIL_SYMBOL); std::cout &lt;&lt; &quot; tnext symbol: &quot; &lt;&lt; symbol &lt;&lt; &quot; tconf: &quot; &lt;&lt; conf &lt;&lt; &quot; n&quot;; const tesseract::ResultIterator itr = *ri; ci = new tesseract::ChoiceIterator(itr); do { const char* choice = ci-&gt;GetUTF8Text(); std::cout &lt;&lt; &quot; t t&quot; &lt;&lt; choice &lt;&lt; &quot; conf: &quot; &lt;&lt; ci-&gt;Confidence() &lt;&lt; &quot; n&quot;; } while(ci-&gt;Next()); delete ci; } delete[] symbol; } while((ri-&gt;Next(tesseract::RIL_SYMBOL))); } . System/36-Compatible RPG II User‚Äôs Guide and Reference .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/rpg/tesseract/2012/06/12/evernote-links.html",
            "relUrl": "/evernote/web%20clip/rpg/tesseract/2012/06/12/evernote-links.html",
            "date": " ‚Ä¢ Jun 12, 2012"
        }
        
    
  
    
        ,"post244": {
            "title": "Evernote web clips, 21/5/2012",
            "content": "How to write a Paper or Presentation . 10 Scala One Liners to Impress Your Friends . VP_tree.py .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2012/05/21/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2012/05/21/evernote-links.html",
            "date": " ‚Ä¢ May 21, 2012"
        }
        
    
  
    
        ,"post245": {
            "title": "Evernote web clips, 19/5/2012",
            "content": "10 CoffeeScript One Liners to Impress Your Friends . Processing real world HTML as if it were XML in scala . SSTable and Log Structured Storage: LevelDB . User:Rednaxela/kD-Tree - RoboWiki . bytefish/libfacerec .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2012/05/19/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2012/05/19/evernote-links.html",
            "date": " ‚Ä¢ May 19, 2012"
        }
        
    
  
    
        ,"post246": {
            "title": "Evernote web clips, 18/5/2012",
            "content": "CMU Sphinx: Long audio aligner for foreign languages . A Tour of Scala: Sequence Comprehensions . ScalaNLP . VP trees: A data structure for finding stuff fast . Reading XML using Groovy‚Äôs XmlSlurper wayback . R2R Framework ‚Äì Translating RDF data¬†from the Web to a target vocabulary . eldur/jwbf . TOPIC MODELING FOR WIKIPEDIA LINK DISAMBIGUATION .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2012/05/18/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2012/05/18/evernote-links.html",
            "date": " ‚Ä¢ May 18, 2012"
        }
        
    
  
    
        ,"post247": {
            "title": "Pascal, Software",
            "content": "Software . Two types - Operating Systems, Applications . O.S. ‚Äì Set of instructions which control the computer ‚Äî MS DOS, OS/2 . App. ‚Äì Set of instructions to make computer perform specific tasks . Algorithm ‚Äì set of instructions which lead to a solution . Program ‚Äì algorithm expressed in a language thaat a computer can understand . Programs are all about data manipulation . must be able to store data &amp; instructions . | data and instructions stored in memory . | . Computer memory is a 2 state device ‚Äì think of one state as 1, other as 0 ‚Äì binary . Data and instructions are converted to binary using a coding scheme . Schemes ‚Äì ASCII, EBCDIC . Programs are at levels, which depend on levels (how far away from the machine) . lowest ‚Äì machine code . | next ‚Äì assembler . | next ‚Äì higher level language . | . Binary programming is difficult. Solutions to problems (programs) are usually written in English like structures called high level languages, which are converted to machine code using a compiler. . Source program (Pascal Statement) . | Compiler . | Object Program (Machine Language) . |",
            "url": "https://jimregan.github.io/notes/college%20notes/1997/09/18/pascal-software.html",
            "relUrl": "/college%20notes/1997/09/18/pascal-software.html",
            "date": " ‚Ä¢ Sep 18, 1997"
        }
        
    
  
    
        ,"post248": {
            "title": "Pascal, Introduction to programming",
            "content": "Introduction to Programming . Computer ‚Äì programmable electronic device that can store information, process it and display results . Hardware ‚Äì Any physical component . Software ‚Äì set of instruction which enables computer to perform functions . History . Newgrange, abacus ‚Äì 2000 years . | Logarithms ‚Äì 1500 years . | Pascal‚Äôs adder, Leibnitz calculator ‚Äì 1600s . | Jacquard‚Äôs Loom ‚Äì 1801 . | Difference machine, Analytical engine ‚Äì 1820s . | Hollerith equipment ‚Äì 1900 . | Mark 1 ‚Äì 1944 . | Atanasoff Berry Computer ‚Äì 1942 . | . Input ¬†¬†¬†--&gt; CPU --&gt; Secondary &lt;-- Memory (CU, ALU, Main Memory) Output &lt;-- . CPU ‚Äì all calculations and manipulations carried out . CU takes instructions in given sequence . controls movement of data inside computer | . | ALU performs mathematical functions &amp; logical decisions . | Main memory allows data to be stored for processing &amp; holds results . | .",
            "url": "https://jimregan.github.io/notes/college%20notes/1997/09/18/pascal-intro.html",
            "relUrl": "/college%20notes/1997/09/18/pascal-intro.html",
            "date": " ‚Ä¢ Sep 18, 1997"
        }
        
    
  
    
        ,"post249": {
            "title": "Pascal Books",
            "content": "Turbo Pascal - Programming &amp; Problem Solving . (Library) Introduction to Pascal, Welsh Elder 3rd ed. 1988 Prentice Hall 0-13-491549-6 . (library) Simple Pascal McGregor Watt 1989 Pitman 0-273-01704-7 .",
            "url": "https://jimregan.github.io/notes/college%20notes/1997/09/18/pascal-books.html",
            "relUrl": "/college%20notes/1997/09/18/pascal-books.html",
            "date": " ‚Ä¢ Sep 18, 1997"
        }
        
    
  
    
        ,"post250": {
            "title": "Music",
            "content": "The Sundays - Summertime . The Pastels - The Hits Hurt . The Marbles - Car Crash . The Devlins - Waiting .",
            "url": "https://jimregan.github.io/notes/college%20notes/1997/09/18/music.html",
            "relUrl": "/college%20notes/1997/09/18/music.html",
            "date": " ‚Ä¢ Sep 18, 1997"
        }
        
    
  
    
        ,"post251": {
            "title": "Maths course outline",
            "content": "Foundation Systems (Numeration Systems) . | Logic . | Sets and Relations . | Vectors and Matrix Algebra . | Calculus . | Statistics . | Integers, Semi Groups and Groups . | (If available) Essential Computer Mathematics Seymour Lipschutz Schaun Outline Series . Discrete Mathematics for Computing Peter Grossman ISBN 0 333 646 94 0 Macmillan Press Ltd . Mathematics for Computing McKeon Smith . Any book on discrete mathematics . 20% X-Mas . 5% 2 Midterms (Nov, Mar) .",
            "url": "https://jimregan.github.io/notes/college%20notes/1997/09/18/maths-course-outline.html",
            "relUrl": "/college%20notes/1997/09/18/maths-course-outline.html",
            "date": " ‚Ä¢ Sep 18, 1997"
        }
        
    
  
    
        ,"post252": {
            "title": "Business systems, course outline",
            "content": "CP102 . Business Systems . Course Outline . Topic 1 ¬†- Business Organisations . Business functions (work areas) | . Topic 2 ¬†- Nature of Management . Topic 3 ¬†- Business and its external environment . Topic 4 ¬†- Corporate strategy and planning . Topic 5 ¬†- Organising . Topic 6 ¬†- Directing . Topic 7 ¬†- Controlling . Topic 8 ¬†- Marketing and sales management . Topic 9 ¬†- Production and operations management . Topic 10 ¬†- Human Resource Management . Topic 11 ¬†- Administration Management . Topic 12 ¬†- Role of the Systems Analyst . Topic 13 ¬†- Organisations and information . Topic 14 ¬†- Project feasibility and management . Topic 15 ¬†- Data collection and sampling . Topic 16 ¬†- Methods of Communication . Topic 17 ¬†- Interviews . Topic 18 ¬†- Questionnaires . Topic 19 ¬†- Prototyping . Topic 20 ¬†- Presentations . Topic 21 ¬†- The systems life cycle . Topic 22 ¬†- Systems analysis and design tools . Topic 23 - File management . Assessment . Continuous Assessment Excercises (30%) . Final Written Examination (70%) - 2 hours . Course Texts . Modern Business Administration Robert C Appelby (6th Edition) Pitman Publishing 1994 ISBN 0-273-60282-9 . Systems Analysis And Design K.E. Kendall &amp; J.E. Kendall (Third Edition) Prentice-Hall, 1995 .",
            "url": "https://jimregan.github.io/notes/college%20notes/1997/09/18/bus-sys-course-outline.html",
            "relUrl": "/college%20notes/1997/09/18/bus-sys-course-outline.html",
            "date": " ‚Ä¢ Sep 18, 1997"
        }
        
    
  
    
        ,"post253": {
            "title": "Tortured teenage scribblings",
            "content": "Jimmy had been camping at Richard‚Äôs house after the Trax, and the next day Eccentric were auditioning singers (they fired PJ - crap). He said they taught him a thousand riffs he forgot, and that they‚Äôre sound &amp; said we can use their equipment any time we want. Jimmy tried out as their singer, but they don‚Äôt play ‚Äúhis music‚Äù. One guy came in, they played Die Laughing, he hadn‚Äôt a clue so he started doing a death metal growl: ‚ÄúEh‚Ä¶ it‚Äôs Therapy?‚Äù ‚ÄúOh‚Ä¶ I thought it sounded punky‚Äù. . Sat. we were here, &amp; Paul C came over. Chatted. He‚Äôs going to the Gaeltacht by himself today. Willie &amp; Liam Dunne are going in a few weeks. He‚Äôs going to Feothanach. (Joe went there). .",
            "url": "https://jimregan.github.io/notes/old%20diary/1996/07/01/tortured-teenage-scribblings.html",
            "relUrl": "/old%20diary/1996/07/01/tortured-teenage-scribblings.html",
            "date": " ‚Ä¢ Jul 1, 1996"
        }
        
    
  
    
        ,"post254": {
            "title": "The Easter Holidays",
            "content": "The first few days of the Easter Holidays were quite uneventful. I sat around all day watching TV. Then on Holy Thursday I had to pack messages at Crazy Prices. This was quite boring too. I had to do it again on Easter Saturday. At lunch time we were eating at the Apollo. I had finished. One of the lads asked my patrol leader to pass the vinegar. As he was doing this he knocked the leader‚Äôs coffee on top of me. That evening, after I found out we had no scouts, I went into Romcos and played my first ever game of Street Fighter 2. The next day we went on a parade to mass. . The next Sunday we went climbing Galteemore. I almost died of tiredness on the way up and from the idiots from other units on the way down. But when we got to the bottom we stopped for a rest and we played on a heather-covered hill. Then we went to our buses. . When I got home I found that I had missed both episodes of ‚ÄúThe Simpsons‚Äù and after a while I watched Mr Bean. . Then, after a couple of hours I went to sleep, dreading school the next day. .",
            "url": "https://jimregan.github.io/notes/old%20diary/1993/04/18/tortured-teenage-scribblings.html",
            "relUrl": "/old%20diary/1993/04/18/tortured-teenage-scribblings.html",
            "date": " ‚Ä¢ Apr 18, 1993"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats.¬†&#8617; . |",
          "url": "https://jimregan.github.io/notes/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  

  

  

  
  

  
      ,"page13": {
          "title": "",
          "content": "Sitemap: {{ ‚Äúsitemap.xml‚Äù | absolute_url }} | .",
          "url": "https://jimregan.github.io/notes/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}