{
  
    
        "post0": {
            "title": "Interesting links, 07/09/2022",
            "content": "Towards End-to-end Unsupervised Speech Recognition . @misc{https://doi.org/10.48550/arxiv.2204.02492, doi = {10.48550/ARXIV.2204.02492}, url = {https://arxiv.org/abs/2204.02492}, author = {Liu, Alexander H. and Hsu, Wei-Ning and Auli, Michael and Baevski, Alexei}, title = {Towards End-to-end Unsupervised Speech Recognition}, year = {2022}, } . Segmental Audio Word2Vec: Representing Utterances as Sequences of Vectors with Applications in Spoken Term Detection . @misc{https://doi.org/10.48550/arxiv.1808.02228, doi = {10.48550/ARXIV.1808.02228}, url = {https://arxiv.org/abs/1808.02228}, author = {Wang, Yu-Hsuan and Lee, Hung-yi and Lee, Lin-shan}, title = {Segmental Audio Word2Vec: Representing Utterances as Sequences of Vectors with Applications in Spoken Term Detection}, year = {2018}, } . zhenghuatan/rVADfast . SpeechT5: Unified-Modal Encoder-Decoder Pre-Training for Spoken Language Processing, microsoft/SpeechT5 . @misc{https://doi.org/10.48550/arxiv.2110.07205, doi = {10.48550/ARXIV.2110.07205}, url = {https://arxiv.org/abs/2110.07205}, author = {Ao, Junyi and Wang, Rui and Zhou, Long and Wang, Chengyi and Ren, Shuo and Wu, Yu and Liu, Shujie and Ko, Tom and Li, Qing and Zhang, Yu and Wei, Zhihua and Qian, Yao and Li, Jinyu and Wei, Furu}, title = {SpeechT5: Unified-Modal Encoder-Decoder Pre-Training for Spoken Language Processing}, year = {2021}, } . . How to load the pretrained models in pytorch . Multilingual and Multimodal Learning for Brazilian Portuguese . RoomReader: A Multimodal Corpus of Online Multiparty Conversational Interactions . Investigating Independence vs. Control: Agenda-Setting in Russian News Coverage on Social Media . Diachronic Parsing of Pre-Standard Irish . probabilisticai/probai-2022, videos . . Using AI to decode speech from brain activity . . add wav2vec2_alignment . Add fairseq FastSpeech2 . Add Emformer . data2vec-vision Onnx ready-made configuration . Add a TF in-graph tokenizer for BERT . add MobileNetV2 model . Adding Omnivore Model to HF . Layoutlmv2 tesseractconfig . pyannote/embedding . ASR chunking . . LITHME . CLARIN Annual Conference 2022 . . google/lyra â€” A Very Low-Bitrate Codec for Speech Compression . salesforce/awd-lstm-lm . MKD: a Multi-Task Knowledge Distillation Approach for Pretrained Language Models . Transflower: probabilistic autoregressive dance generation with multimodal attention, code . Pre-Training Transformer Decoder for End-to-End ASR Model with Unpaired Speech Data . An investigation of phone-based subword units for end-to-end speech recognition . Sequence-to-sequence learning with Transducers . Pushing the Limits of Semi-Supervised Learning for Automatic Speech Recognition . ONLINE ASR WITH EMFORMER RNN-T . We published Tuda german model from https://t.co/4xPzWgW6fwhttps://t.co/7mdkimirTjit is big (4.4G) and slightly more accurate than Vosk on audiobooks and well covers CV test9.48 (Tuda-de test), 25.82 (podcast) 4.97 (cv-test) 11.01 (mls) 35.20 (mtedx) . &mdash; AlphaCephei (@alphacep) August 10, 2022 code . Recordings Database . spaces/k2-fsa/automatic-speech-recognition . csukuangfj/optimized_transducer . Recurrent Neural Aligner: An Encoder-Decoder Neural Network Model for Sequence to Sequence Mapping . Integrating Lattice-Free MMI into End-to-End Speech Recognition . clarin-eric/parla-clarin . clarin-eric/ParlaMint . MASC-MEG . But what is the Fourier Transform? A visual introduction. . AudioLM: a Language Modeling Approach to Audio Generation . . Pre-Training Transformer Decoder for End-to-End ASR Model with Unpaired Speech Data . Layer-wise analysis of a self-supervised speech representation . . L2-ARCTIC .",
            "url": "https://jimregan.github.io/notes/links/2022/09/07/misc-links.html",
            "relUrl": "/links/2022/09/07/misc-links.html",
            "date": " â€¢ Sep 7, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Interesting links, 13/07/2022",
            "content": "patrick-kidger/equinox â€” Callable PyTrees and filtered transforms =&gt; neural networks in JAX. . patrick-kidger/diffrax â€” Numerical differential equation solvers in JAX. Autodifferentiable and GPU-capable. . . M-Adapter: Modality Adaptation for End-to-End Speech-to-Text Translation . @misc{https://doi.org/10.48550/arxiv.2207.00952, doi = {10.48550/ARXIV.2207.00952}, url = {https://arxiv.org/abs/2207.00952}, author = {Zhao, Jinming and Yang, Hao and Shareghi, Ehsan and Haffari, Gholamreza}, title = {M-Adapter: Modality Adaptation for End-to-End Speech-to-Text Translation}, publisher = {arXiv}, year = {2022}, copyright = {arXiv.org perpetual, non-exclusive license} } . . Check out our latest breakthrough in machine translation that Mark Zuckerberg just announced. We built and open sourced a state-of-the-art AI model that now translates between 200 different languages. . &mdash; Meta AI (@MetaAI) July 6, 2022 Code is open source, model is not . . Trillson in transformers . . Emformer: Efficient Memory Transformer Based Acoustic Model for Low Latency Streaming Speech Recognition . @INPROCEEDINGS{9414560, author={Shi, Yangyang and Wang, Yongqiang and Wu, Chunyang and Yeh, Ching-Feng and Chan, Julian and Zhang, Frank and Le, Duc and Seltzer, Mike}, booktitle={ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, title={Emformer: Efficient Memory Transformer Based Acoustic Model for Low Latency Streaming Speech Recognition}, year={2021}, volume={}, number={}, pages={6783-6787}, doi={10.1109/ICASSP39728.2021.9414560}} . . lumaku/ctc-segmentation â€” Segment an audio file and obtain utterance alignments. . . This past week I spent some time learning about SentenceTransformers (https://t.co/5ZAV7lJq7u), and I&#39;m pretty blown away by what sentence embeddings can be used for.If you&#39;re curious to see what researchers have been getting up to with it, here&#39;s a ðŸ§µ with some highlights: . &mdash; Nima Boscarino (@NimaBoscarino) June 10, 2022 . How much data do you need for a good MFA alignment? . If you care only about alignments of the training data, 3-5 hours should be enough. Caveat: increasing the number of speakers/varieties in the training data will likely need more training data | . | If you care about generating models for more widespread use, 8-10 should be enough for generalizing to the same variety The more speakers the better, but also more speakers should need more data | I usually recommend about 20 hours for a decently performant model | . | . . google-research/t5x â€” essentially a new and improved implementation of the T5 codebase (based on Mesh TensorFlow) in JAX and Flax. . google/seqio â€” Task-based datasets, preprocessing, and evaluation for sequence models. . . r/weirddalle . . Towards End-to-end Unsupervised Speech Recognition . @misc{https://doi.org/10.48550/arxiv.2204.02492, doi = {10.48550/ARXIV.2204.02492}, url = {https://arxiv.org/abs/2204.02492}, author = {Liu, Alexander H. and Hsu, Wei-Ning and Auli, Michael and Baevski, Alexei}, title = {Towards End-to-end Unsupervised Speech Recognition}, publisher = {arXiv}, year = {2022}, copyright = {Creative Commons Attribution 4.0 International} } . . Unified Speech-Text Pre-training for Speech Translation and Recognition . @misc{tang2022unified, title={Unified Speech-Text Pre-training for Speech Translation and Recognition}, author={Yun Tang and Hongyu Gong and Ning Dong and Changhan Wang and Wei-Ning Hsu and Jiatao Gu and Alexei Baevski and Xian Li and Abdelrahman Mohamed and Michael Auli and Juan Pino}, year={2022}, eprint={2204.05409}, archivePrefix={arXiv}, primaryClass={cs.CL} } . .",
            "url": "https://jimregan.github.io/notes/links/2022/07/13/misc-links.html",
            "relUrl": "/links/2022/07/13/misc-links.html",
            "date": " â€¢ Jul 13, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "WER calculations for minute and hour splits",
            "content": "import matplotlib.pyplot as plt import pandas as pd . HOURS_DATA = &quot;&quot;&quot; 2 0.02571327932370553 4 0.014705882352941176 6 0.01655512504402959 8 0.014705882352941176 10 0.013825290595280029 12 0.012152166255723846 14 0.011271574498062698 16 0.010302923564635434 &quot;&quot;&quot; . hours = [] wer = [] for line in HOURS_DATA.split(&quot; n&quot;): if &quot; t&quot; in line: parts = line.split(&quot; t&quot;) hours.append(int(parts[0])) wer.append(float(parts[1]) * 100) . df = pd.DataFrame(data={&quot;Hours&quot;: hours, &quot;WER&quot;: wer}) . ax = plt.gca() df.plot(kind=&#39;line&#39;,x=&#39;Hours&#39;,y=&#39;WER&#39;,ax=ax) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fc7ef72add0&gt; . MINS_DATA = &quot;&quot;&quot; 5 0.05336386051426559 10 0.05309968298696724 15 0.05301162381120113 20 0.03346248679112364 25 0.03355054596688975 30 0.03355054596688975 35 0.03222965833039803 40 0.03126100739697076 45 0.03196548080309968 50 0.028883409651285663 55 0.029059528002817893 60 0.028531172948221203 65 0.02694610778443114 70 0.029411764705882353 75 0.02588939767523776 80 0.027738640366326173 85 0.026681930257132794 90 0.025977456851003874 95 0.02386403663261712 100 0.02536104262064107 105 0.025096865093342725 110 0.02588939767523776 115 0.02712222613596337 120 0.02571327932370553 &quot;&quot;&quot; . df . Hours WER . 0 2 | 2.571328 | . 1 4 | 1.470588 | . 2 6 | 1.655513 | . 3 8 | 1.470588 | . 4 10 | 1.382529 | . 5 12 | 1.215217 | . 6 14 | 1.127157 | . 7 16 | 1.030292 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; mins = [] wer = [] for line in MINS_DATA.split(&quot; n&quot;): if &quot; t&quot; in line: parts = line.split(&quot; t&quot;) mins.append(int(parts[0])) wer.append(float(parts[1]) * 100) . pd.options.display.float_format = &#39;{:,.2f}&#39;.format df = pd.DataFrame(data={&quot;Minutes&quot;: mins, &quot;WER&quot;: wer}) . df . Minutes WER . 0 5 | 5.34 | . 1 10 | 5.31 | . 2 15 | 5.30 | . 3 20 | 3.35 | . 4 25 | 3.36 | . 5 30 | 3.36 | . 6 35 | 3.22 | . 7 40 | 3.13 | . 8 45 | 3.20 | . 9 50 | 2.89 | . 10 55 | 2.91 | . 11 60 | 2.85 | . 12 65 | 2.69 | . 13 70 | 2.94 | . 14 75 | 2.59 | . 15 80 | 2.77 | . 16 85 | 2.67 | . 17 90 | 2.60 | . 18 95 | 2.39 | . 19 100 | 2.54 | . 20 105 | 2.51 | . 21 110 | 2.59 | . 22 115 | 2.71 | . 23 120 | 2.57 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; import numpy as np ax = plt.gca() ax.set_xticks(np.arange(5, 125, 5)) ax.set_xticklabels(labels=mins, minor=True) df.plot(kind=&#39;line&#39;, x=&#39;Minutes&#39;, y=&#39;WER&#39;, ax=ax, figsize=(12.8, 4.8)) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f400bffbdd0&gt; . MINS_DATA = &quot;&quot;&quot; 5 0.05336386051426559 10 0.05309968298696724 15 0.05301162381120113 20 0.03346248679112364 25 0.03355054596688975 30 0.03355054596688975 &quot;&quot;&quot; MINS2 = &quot;&quot;&quot; 5 4.11 10 4.08 15 3.72 20 3.49 25 3.43 30 3.34 &quot;&quot;&quot; . mins = [] wer = [] for line in MINS_DATA.split(&quot; n&quot;): if &quot; t&quot; in line: parts = line.split(&quot; t&quot;) mins.append(int(parts[0])) wer.append(float(parts[1]) * 100) . mins2 = [] wer2 = [] for line in MINS2.split(&quot; n&quot;): if &quot; t&quot; in line: parts = line.split(&quot; t&quot;) mins2.append(int(parts[0])) wer2.append(float(parts[1])) . len(mins) . 12 . fig, ax = plt.subplots() ax.plot(mins, wer) ax.plot(mins, wer2) newx = ax.lines[0].get_ydata() newy = ax.lines[0].get_xdata() # set new x- and y- data for the line ax.lines[0].set_xdata(newx) ax.lines[0].set_ydata(newy) newx = ax.lines[1].get_ydata() newy = ax.lines[1].get_xdata() # set new x- and y- data for the line ax.lines[1].set_xdata(newx) ax.lines[1].set_ydata(newy) ax.set_xlim([0, 10]) ax.set_ylim([0, 10]) . (0.0, 10.0) . import numpy as np import pandas as pd ax = plt.gca() df = pd.DataFrame(data={&quot;300&quot;: wer, &quot;1000&quot;: wer2}, index=mins) . [&lt;matplotlib.lines.Line2D at 0x7f8728e72210&gt;] .",
            "url": "https://jimregan.github.io/notes/2022/05/07/speaker-adaptation-wer-hours-minutes.html",
            "relUrl": "/2022/05/07/speaker-adaptation-wer-hours-minutes.html",
            "date": " â€¢ May 7, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "Adapt `cmu_us_awb_arctic` to fairseq",
            "content": "RAWTEXT = &quot;../input/cmu-us-awb-arctic-tts-dataset/cmu_us_awb_arctic/etc/txt.done.data&quot; . NORMS = { &quot;0.75&quot;: &quot;zero point seven five&quot;, &quot;t.h&quot;: &quot;t h&quot;, &quot;1880&quot;: &quot;eighteen eighty&quot;, &quot;16&quot;: &quot;sixteenth&quot;, &quot;1908&quot;: &quot;nineteen oh eight&quot;, &quot;18&quot;: &quot;eighteenth&quot;, &quot;17&quot;: &quot;seventeenth&quot;, &quot;29th&quot;: &quot;twenty ninth&quot;, &quot;mrs&quot;: &quot;misses&quot;, &quot;etc&quot;: &quot;etcetera&quot;, &quot;etc.&quot;: &quot;etcetera&quot;, &quot;to-day&quot;: &quot;today&quot;, &quot;to-day&#39;s&quot;: &quot;today&#39;s&quot;, &quot;to-morrow&quot;: &quot;tomorrow&quot; } . def _check_apos(word): if word.endswith(&quot;&#39;s&quot;): return word elif word.endswith(&quot;s&#39;&quot;): return word elif word.endswith(&quot;&#39;d&quot;): return word elif word.endswith(&quot;&#39;ve&quot;): return word elif word.endswith(&quot;&#39;re&quot;): return word elif word.endswith(&quot;&#39;ll&quot;): return word elif word.endswith(&quot;n&#39;t&quot;): return word elif word.endswith(&quot;&#39;ve&quot;): return word elif word in [&quot;i&#39;m&quot;, &quot;&#39;em&quot;, &quot;o&#39;brien&quot;]: return word else: return word.replace(&quot;&#39;&quot;, &quot;&quot;) def fix_apos(text): words = [_check_apos(w) for w in text.split(&quot; &quot;)] return &quot; &quot;.join(words) . def normalise(text): if text[-1] == &quot;.&quot;: text = text[:-1] text = text.lower() words = [] text = text.replace(&quot;,&quot;, &quot;&quot;) for word in text.split(&quot; &quot;): if word in NORMS: words.append(NORMS[word]) else: words.append(word) text = &quot; &quot;.join(words) text = text.replace(&quot;.&quot;, &quot;&quot;) text = text.replace(&quot;?&quot;, &quot;&quot;) text = text.replace(&quot;!&quot;, &quot;&quot;) text = text.replace(&quot;:&quot;, &quot;&quot;) text = text.replace(&quot;;&quot;, &quot;&quot;) text = text.replace(&quot;--&quot;, &quot; &quot;) text = text.replace(&quot; &quot;, &quot; &quot;) text = text.replace(&quot; - &quot;, &quot; &quot;) text = text.replace(&quot;to- morrow&quot;, &quot;tomorrow&quot;) text = fix_apos(text) text = text.replace(&quot;-&quot;, &quot; &quot;) return text.strip().upper() . data = {} with open(RAWTEXT) as inf: for line in inf.readlines(): first_space = line.find(&#39; &#39;) first_quote = line.find(&#39;&quot;&#39;) last_quote = line.rfind(&#39;&quot;&#39;) id = line[first_space+1:first_quote].strip() text = line[first_quote+1:last_quote] data[id] = normalise(text) . with open(&quot;text.tsv&quot;, &quot;w&quot;) as of: for id in data.keys(): of.write(f&quot;{id} t{data[id]} n&quot;) . from pathlib import Path import soundfile as sf total = 0 WAVPATH = Path(&quot;../input/cmu-us-awb-arctic-tts-dataset/cmu_us_awb_arctic/wav/&quot;) with open(&quot;frames.tsv&quot;, &quot;w&quot;) as of: for wav in WAVPATH.glob(&quot;*.wav&quot;): frames, sr = sf.read(str(wav)) assert sr == 16000 total += len(frames) of.write(f&quot;{wav.stem}.wav t{len(frames)} n&quot;) print(&quot;Total:&quot;, total / 16000) . Total: 4777.0 . lines=!wc -l frames.tsv|awk &#39;{print $1}&#39; !tail -n 114 frames.tsv |head -n 57 &gt; test.tsv !tail -n 114 frames.tsv |tail -n 57 &gt; dev.tsv !head -n $((1138-114)) frames.tsv &gt; train.tsv . def do_fairseq(text): words = text.split(&quot; &quot;) owords = [&quot; &quot;.join(w) for w in words] return &quot; | &quot;.join(owords) + &quot; |&quot; . for part in [&quot;test&quot;, &quot;train&quot;, &quot;dev&quot;]: ids = [] with open(f&quot;{part}.ltr&quot;, &quot;w&quot;) as of, open(f&quot;{part}.tsv&quot;) as inf: for line in inf.readlines(): if &quot; t&quot; in line: parts = line.strip().split(&quot; t&quot;) id = parts[0].replace(&quot;.wav&quot;, &quot;&quot;) of.write(do_fairseq(data[id]) + &quot; n&quot;) .",
            "url": "https://jimregan.github.io/notes/kaggle/awb/2022/05/07/cmu-us-awb-arctic-fairseq-files.html",
            "relUrl": "/kaggle/awb/2022/05/07/cmu-us-awb-arctic-fairseq-files.html",
            "date": " â€¢ May 7, 2022"
        }
        
    
  
    
        ,"post4": {
            "title": "Create LJSpeech splits",
            "content": "Split into train/test/valid . !echo /kaggle/input/ljspeech-for-asr/wav16/ &gt; valid.tsv !cat ../input/ljspeech-for-asr/frames.tsv | tail -n $((1310)) | tail -n $((1310 / 2)) |awk -F&#39; t&#39; &#39;{print $1 &quot;.wav t&quot; $2}&#39; &gt;&gt; valid.tsv . !echo /kaggle/input/ljspeech-for-asr/wav16/ &gt; test.tsv !cat ../input/ljspeech-for-asr/frames.tsv | tail -n $((1310)) | head -n $((1310 / 2)) |awk -F&#39; t&#39; &#39;{print $1 &quot;.wav t&quot; $2}&#39; &gt;&gt; test.tsv . !echo /kaggle/input/ljspeech-for-asr/wav16/ &gt; train.tsv !cat ../input/ljspeech-for-asr/frames.tsv | head -n $((13100 - 1310)) |awk -F&#39; t&#39; &#39;{print $1 &quot;.wav t&quot; $2}&#39; &gt;&gt; train.tsv . Load frame lengths . train_frames = {} with open(&quot;train.tsv&quot;) as f: for line in f.readlines(): if not &quot; t&quot; in line: continue pieces = line.strip().split(&quot; t&quot;) assert len(pieces) == 2 id = pieces[0].replace(&quot;.wav&quot;, &quot;&quot;) train_frames[id] = int(pieces[1]) . MINS = [i * 5 for i in range(1, 25)] HOURS = [i * 2 for i in range(1, 9)] . WAVDIR = &quot;/kaggle/input/ljspeech-for-asr/wav16&quot; . Minute splits . for min in MINS: frames = min * 60 * 16000 idlist = [k for k in train_frames.keys()] outtsv = f&quot;{min}mins.tsv&quot; with open(outtsv, &quot;w&quot;) as of: current = 0 of.write(f&quot;{WAVDIR} n&quot;) while frames &gt; 0 and frames &gt; current: id = idlist.pop(0) current = train_frames[id] of.write(f&quot;{id}.wav t{current} n&quot;) frames = frames - current max = 0 maxid = &quot;&quot; for id in idlist: time = train_frames[id] if time &gt; current: continue if time &gt; max: max = time maxid = id of.write(f&quot;{maxid}.wav t{max} n&quot;) . Hour splits . for min in HOURS: frames = min * 60 * 60 * 16000 idlist = [k for k in train_frames.keys()] outtsv = f&quot;{min}hrs.tsv&quot; with open(outtsv, &quot;w&quot;) as of: current = 0 of.write(f&quot;{WAVDIR} n&quot;) while frames &gt; 0 and frames &gt; current: id = idlist.pop(0) current = train_frames[id] of.write(f&quot;{id}.wav t{current} n&quot;) frames = frames - current max = 0 maxid = &quot;&quot; for id in idlist: time = train_frames[id] if time &gt; current: continue if time &gt; max: max = time maxid = id of.write(f&quot;{maxid}.wav t{max} n&quot;) . Generate ltr files . def fairseqify(text): text = text.strip().replace(&quot; &quot;, &quot; &quot;) words = text.split(&quot; &quot;) spread = [&quot; &quot;.join(a) for a in words] return &quot; | &quot;.join(spread) + &quot; |&quot; . transcripts = {} with open(&quot;../input/ljspeech-for-asr/transcripts.tsv&quot;) as tf: for line in tf.readlines(): line = line.strip() if not &quot; t&quot; in line: pass parts = line.split(&quot; t&quot;) assert len(parts) == 2 transcripts[parts[0]] = fairseqify(parts[1]) . import glob for tsv in glob.glob(&quot;*.tsv&quot;): out = tsv.replace(&quot;.tsv&quot;, &quot;.ltr&quot;) with open(tsv) as inf, open(out, &quot;w&quot;) as outf: for line in inf.readlines()[1:]: id, _ = line.split(&quot; t&quot;) id = id.replace(&quot;.wav&quot;, &quot;&quot;) outf.write(f&quot;{transcripts[id]} n&quot;) . Tidy up . !for i in *mins.tsv;do b=$(basename $i &quot;.tsv&quot;);mkdir $b; mv $b.tsv $b/train.tsv; mv $b.ltr $b/train.ltr; cp test.* valid.* $b/;done !for i in *hrs.tsv;do b=$(basename $i &quot;.tsv&quot;);mkdir $b; mv $b.tsv $b/train.tsv; mv $b.ltr $b/train.ltr; cp test.* valid.* $b/;done .",
            "url": "https://jimregan.github.io/notes/kaggle/ljspeech/2022/05/05/create-ljspeech-splits.html",
            "relUrl": "/kaggle/ljspeech/2022/05/05/create-ljspeech-splits.html",
            "date": " â€¢ May 5, 2022"
        }
        
    
  
    
        ,"post5": {
            "title": "LJSpeech for ASR",
            "content": "Step 1: Convert sampling rate to 16,000 . !mkdir wav16 . %%capture !for wav in ../input/the-lj-speech-dataset/LJSpeech-1.1/wavs/*wav; do ffmpeg -i $wav -ar 16000 wav16/$(basename $wav &#39;.wav&#39;).wav;done . Step 2: (Further) normalise the transcripts . PATH = &quot;../input/the-lj-speech-dataset/LJSpeech-1.1/metadata.csv&quot; . def fix_text(text): text = text.lower() text = text.replace(&quot; -- &quot;, &quot; &quot;) text = text.replace(&quot;Ã¼&quot;, &quot;u&quot;) text = text.replace(&quot;etc.&quot;, &quot;etcetera&quot;) text = text.replace(&quot;i.e.&quot;, &quot;i e &quot;) text = text.replace(&quot;;&quot;, &quot;&quot;) text = text.replace(&quot;. &quot;, &quot; &quot;) text = text.replace(&quot;,&quot;, &quot;&quot;) text = text.replace(&quot; &quot;&quot;, &quot;&quot;) text = text.replace(&quot; &quot;, &quot; &quot;) alpha = &quot;abcdefghijklmnopqrstuvwxyz&quot; i = 0 buf = [] while i &lt; len(text): if text[i] in alpha or text[i] == &quot; &quot;: buf.append(text[i]) elif text[i:i+2] == &quot;&#39;s&quot; or text[i-1:i+2] == &quot;s&#39; &quot;: buf.append(text[i]) elif i == len(text)-1 and text[-2:] == &quot;s&#39;&quot;: buf.append(text[i]) elif text[i:i+2] == &quot;&#39;d&quot; or text[i:i+3] == &quot;&#39;ve&quot;: buf.append(text[i]) elif text[i] == &quot;-&quot; and text[i-1] in alpha: buf.append(&quot; &quot;) else: pass i += 1 text = &quot;&quot;.join(buf) return text . items = {} with open(PATH) as f: for line in f.readlines(): arr = line.split(&quot;|&quot;) if len(arr) != 3: print(line) id = arr[0] text = fix_text(arr[2]) items[id] = text . OUTPATH = &quot;transcripts.tsv&quot; with open(OUTPATH, &quot;w&quot;) as outf: for key in items.keys(): outf.write(f&quot;{key} t{items[key]} n&quot;) . Step 3: Extract number of frames . This is needed by fairseq . from pathlib import Path import soundfile as sf . WAVPATH = Path(&quot;wav16&quot;) . times = {} for wavfile in WAVPATH.glob(&quot;*.wav&quot;): data, sr = sf.read(str(wavfile)) times[wavfile.stem] = len(data) . with open(&quot;frames.tsv&quot;, &quot;w&quot;) as framef: for key in times.keys(): framef.write(f&quot;{key} t{times[key]} n&quot;) .",
            "url": "https://jimregan.github.io/notes/kaggle/ljspeech/2022/05/04/ljspeech-for-asr.html",
            "relUrl": "/kaggle/ljspeech/2022/05/04/ljspeech-for-asr.html",
            "date": " â€¢ May 4, 2022"
        }
        
    
  
    
        ,"post6": {
            "title": "Split Liepa2",
            "content": "DATAPATH = &quot;/mnt/cloud/lithuanian-asr/data&quot; . !pip install pympi-ling . Collecting pympi-ling Downloading pympi_ling-1.70.2-py2.py3-none-any.whl (24 kB) Installing collected packages: pympi-ling Successfully installed pympi-ling-1.70.2 . import pympi from pathlib import Path from pydub import AudioSegment . def get_eaf_data(filename): filepath = Path(filename) base = filepath.stem eaf = pympi.Elan.Eaf(filename) tiers = [] def is_simple_layout(tiers): if len(tiers) == 1 and &#39;speech&#39; in tiers: return True elif len(tiers) == 2 and &#39;speech&#39; in tiers and &#39;noise&#39; in tiers: return True elif len(tiers) == 3 and &#39;speech&#39; in tiers and &#39;noise&#39; in tiers and &#39;ss&#39; in tiers: return True else: return False if is_simple_layout(eaf.tiers): tiernames = [&#39;speech&#39;] simple = True else: skip = [&#39;noise&#39;, &#39;ss&#39;] tiernames = [a for a in eaf.tiers.keys() if a not in skip] simple = False for tiername in tiernames: for tier in eaf.tiers[tiername][0].keys(): current = {} id = f&quot;{base}_{tier}&quot; if not simple: id = f&quot;{base}_{tiername}_{tier}&quot; current[&quot;id&quot;] = id data = eaf.tiers[tiername][0][tier] current[&quot;start&quot;] = eaf.timeslots[data[0]] current[&quot;end&quot;] = eaf.timeslots[data[1]] current[&quot;text&quot;] = data[2].replace(&quot; t&quot;, &quot; &quot;).replace(&quot; n&quot;, &quot; &quot;).strip() if current[&quot;text&quot;] != &quot;&quot;: tiers.append(current) return tiers . def write_split_wavs(outdir, filename, data): outpath = Path(outdir) original = AudioSegment.from_wav(filename) for piece in data: outfile = outpath / f&quot;{piece[&#39;id&#39;]}.wav&quot; audio = original[piece[&quot;start&quot;]:piece[&quot;end&quot;]] audio.export(str(outfile), format=&quot;wav&quot;) . def append_to_tsv(tsv_file, data): with open(tsv_file, &quot;a&quot;) as f: for item in data: f.write(f&quot;{item[&#39;id&#39;]} t{item[&#39;text&#39;]} n&quot;) . SAMPLE = &quot;/mnt/cloud/lithuanian-asr/data/R_RS_F3_AS113_01.eaf&quot; SAMPLE_WAV = SAMPLE.replace(&quot;.eaf&quot;, &quot;.wav&quot;) data = get_eaf_data(SAMPLE) write_split_wavs(&quot;/tmp/foo&quot;, SAMPLE_WAV, data) . for eaf_file in Path(DATAPATH).glob(&quot;*.eaf&quot;): data = get_eaf_data(eaf_file) wav_file = str(eaf_file).replace(&quot;.eaf&quot;, &quot;.wav&quot;) write_split_wavs(&quot;/mnt/cloud/liepa-split&quot;, wav_file, data) append_to_tsv(&quot;/mnt/cloud/liepa-split/text.tsv&quot;, data) .",
            "url": "https://jimregan.github.io/notes/liepa/lithuanian/asr/corpus/elan/eaf/2022/05/04/liepa2-split.html",
            "relUrl": "/liepa/lithuanian/asr/corpus/elan/eaf/2022/05/04/liepa2-split.html",
            "date": " â€¢ May 4, 2022"
        }
        
    
  
    
        ,"post7": {
            "title": "Convert Waxholm to wav",
            "content": "%%capture !sudo apt-get install git-lfs . !git lfs install . Error: Failed to call git rev-parse --git-dir: exit status 128 Git LFS initialized. . !git clone https://huggingface.co/datasets/KTH/waxholm . Cloning into &#39;waxholm&#39;... remote: Enumerating objects: 7501, done. remote: Counting objects: 100% (7501/7501), done. remote: Compressing objects: 100% (7422/7422), done. remote: Total 7501 (delta 84), reused 7487 (delta 77), pack-reused 0 Receiving objects: 100% (7501/7501), 207.52 MiB | 24.12 MiB/s, done. Resolving deltas: 100% (84/84), done. Updating files: 100% (7334/7334), done. Filtering content: 100% (2522/2522), 282.66 MiB | 1.39 MiB/s, done. . !mkdir wav . import soundfile as sf def smp_headers(filename: str): with open(filename, &quot;rb&quot;) as f: f.seek(0) raw_headers = f.read(1024) raw_headers = raw_headers.rstrip(b&#39; x00&#39;) asc_headers = raw_headers.decode(&quot;ascii&quot;) asc_headers.rstrip(&#39; x00&#39;) tmp = [a for a in asc_headers.split(&quot; r n&quot;)] back = -1 while abs(back) &gt; len(tmp) + 1: if tmp[back] == &#39;=&#39;: break back -= 1 tmp = tmp[0:back-1] return dict(a.split(&quot;=&quot;) for a in tmp) def smp_read_sf(filename: str): headers = smp_headers(filename) if headers[&quot;msb&quot;] == &quot;last&quot;: ENDIAN = &quot;LITTLE&quot; else: ENDIAN = &quot;BIG&quot; data, sr = sf.read(filename, channels=int(headers[&quot;nchans&quot;]), samplerate=16000, endian=ENDIAN, start=512, dtype=&quot;int16&quot;, format=&quot;RAW&quot;, subtype=&quot;PCM_16&quot;) return (data, sr) def write_wav(filename, arr): import wave with wave.open(filename, &quot;w&quot;) as f: f.setnchannels(1) f.setsampwidth(2) f.setframerate(16000) f.writeframes(arr) . from pathlib import Path for smp in Path(&quot;./waxholm/scenes_formatted&quot;).glob(&quot;**/*.smp&quot;): arr, sr = smp_read_sf(str(smp)) write_wav(f&quot;wav/{smp.stem}.wav&quot;, arr) . import IPython.display as ipd ipd.Audio(&#39;wav/fp2001.1.00.wav&#39;) . Your browser does not support the audio element.",
            "url": "https://jimregan.github.io/notes/kaggle/waxholm/2022/05/04/convert-waxholm-to-wav.html",
            "relUrl": "/kaggle/waxholm/2022/05/04/convert-waxholm-to-wav.html",
            "date": " â€¢ May 4, 2022"
        }
        
    
  
    
        ,"post8": {
            "title": "Interesting links, 02/05/2022",
            "content": "Wavelet Browser â€” from PyWavelets . Identity Vector Extraction by Perceptual Wavelet Packet Entropy and Convolutional Neural Network for Voice Authentication . @Article{e20080600, AUTHOR = {Lei, Lei and She, Kun}, TITLE = {Identity Vector Extraction by Perceptual Wavelet Packet Entropy and Convolutional Neural Network for Voice Authentication}, JOURNAL = {Entropy}, VOLUME = {20}, YEAR = {2018}, NUMBER = {8}, ARTICLE-NUMBER = {600}, URL = {https://www.mdpi.com/1099-4300/20/8/600}, ISSN = {1099-4300}, DOI = {10.3390/e20080600} } . Speaker Recognition Using Wavelet Packet Entropy, I-Vector, and Cosine Distance Scoring . @Article{Lei2017, author={Lei, Lei and Kun, She}, title={Speaker Recognition Using Wavelet Packet Entropy, I-Vector, and Cosine Distance Scoring}, journal={Journal of Electrical and Computer Engineering}, year={2017}, month={May}, day={14}, publisher={Hindawi}, volume={2017}, pages={1735698}, issn={2090-0147}, doi={10.1155/2017/1735698}, } . Fairseq wav2vec2 hydra migration .",
            "url": "https://jimregan.github.io/notes/links/2022/05/02/misc-links.html",
            "relUrl": "/links/2022/05/02/misc-links.html",
            "date": " â€¢ May 2, 2022"
        }
        
    
  
    
        ,"post9": {
            "title": "Fix LJSpeech text",
            "content": "Updated here . PATH = &quot;/home/joregan/ljspeech/LJSpeech-1.1/metadata.csv&quot; . def fix_text(text): text = text.lower() text = text.replace(&quot; -- &quot;, &quot; &quot;) text = text.replace(&quot;Ã¼&quot;, &quot;u&quot;) text = text.replace(&quot;etc.&quot;, &quot;etcetera&quot;) text = text.replace(&quot;i.e.&quot;, &quot;i e &quot;) text = text.replace(&quot;;&quot;, &quot;&quot;) text = text.replace(&quot;. &quot;, &quot; &quot;) text = text.replace(&quot;,&quot;, &quot;&quot;) text = text.replace(&quot; &quot;&quot;, &quot;&quot;) text = text.replace(&quot; &quot;, &quot; &quot;) alpha = &quot;abcdefghijklmnopqrstuvwxyz&quot; i = 0 buf = [] while i &lt; len(text): if text[i] in alpha or text[i] == &quot; &quot;: buf.append(text[i]) elif text[i:i+2] == &quot;&#39;s&quot; or text[i-1:i+2] == &quot;s&#39; &quot;: buf.append(text[i]) elif i == len(text)-1 and text[-2:] == &quot;s&#39;&quot;: buf.append(text[i]) elif text[i:i+2] == &quot;&#39;d&quot; or text[i:i+3] == &quot;&#39;ve&quot;: buf.append(text[i]) elif text[i] == &quot;-&quot; and text[i-1] in alpha: buf.append(&quot; &quot;) else: pass i += 1 text = &quot;&quot;.join(buf) return text . items = {} with open(PATH) as f: for line in f.readlines(): arr = line.split(&quot;|&quot;) if len(arr) != 3: print(line) id = arr[0] text = fix_text(arr[2]) items[id] = text . OUTPATH = &quot;/home/joregan/ljspeech/LJSpeech-1.1/text.tsv&quot; with open(OUTPATH, &quot;w&quot;) as outf: for key in items.keys(): outf.write(f&quot;{key} t{items[key]} n&quot;) .",
            "url": "https://jimregan.github.io/notes/ljspeech/2022/05/02/fix-ljspeech.html",
            "relUrl": "/ljspeech/2022/05/02/fix-ljspeech.html",
            "date": " â€¢ May 2, 2022"
        }
        
    
  
    
        ,"post10": {
            "title": "Recreating PSST challenge parameters in YAML",
            "content": "The following cell is an attempt to recreate the parameters for the PSST challenge in YAML. . common: fp16: true log_format: json log_interval: 50 checkpoint: no_epoch_checkpoints: true best_checkpoint_metric: uer task: _name: audio_finetuning data: ??? max_sample_size: 1120000 normalize: false labels: ltr dataset: num_workers: 1 max_tokens: 1120000 skip_invalid_size_inputs_valid_test: true validate_after_updates: 1000 validate_interval: 1 valid_subset: valid distributed_training: ddp_backend: no_c10d distributed_world_size: 1 criterion: _name: ctc zero_infinity: true optimization: max_update: 12000 lr: [0.00005] sentence_avg: true weight_decay: 0.0 update_freq: [] optimizer: _name: adam adam_betas: (0.9,0.98) adam_eps: 1e-08 lr_scheduler: _name: tri_stage phase_ratio: [0.33, 0.33, 0.33] final_lr_scale: 0.05 model: _name: wav2vec_ctc w2v_path: ??? apply_mask: true mask_prob: 0.65 mask_channel_prob: 0.25 mask_channel_length: 64 layerdrop: 0.1 activation_dropout: 0.1 feature_grad_mult: 0.0 freeze_finetune_updates: 0 final_dropout: 0.1 attention_dropout: 0.1 . This cell is a modification of base_10m.yaml from the fairseq source . # @package _group_ common: fp16: true log_format: json log_interval: 50 checkpoint: save_interval: 1000 save_interval_updates: 50 keep_interval_updates: 1 no_epoch_checkpoints: true best_checkpoint_metric: uer task: _name: audio_pretraining data: ??? max_sample_size: 1120000 normalize: false labels: ltr dataset: num_workers: 1 max_tokens: 1120000 skip_invalid_size_inputs_valid_test: true validate_after_updates: 1000 validate_interval: 1 valid_subset: valid distributed_training: ddp_backend: no_c10d distributed_world_size: 1 criterion: _name: ctc zero_infinity: true optimization: max_update: 12000 lr: [0.00005] sentence_avg: true update_freq: [4] optimizer: _name: adam adam_betas: (0.9,0.98) adam_eps: 1e-08 lr_scheduler: _name: tri_stage phase_ratio: [0.1, 0.4, 0.5] final_lr_scale: 0.05 model: _name: wav2vec_ctc w2v_path: ??? apply_mask: true mask_prob: 0.65 mask_channel_prob: 0.25 mask_channel_length: 64 layerdrop: 0.1 activation_dropout: 0.1 feature_grad_mult: 0.0 final_dropout: 0.1 attention_dropout: 0.1 freeze_finetune_updates: 0 .",
            "url": "https://jimregan.github.io/notes/fairseq/psst/yaml/2022/05/02/fairseq-config.html",
            "relUrl": "/fairseq/psst/yaml/2022/05/02/fairseq-config.html",
            "date": " â€¢ May 2, 2022"
        }
        
    
  
    
        ,"post11": {
            "title": "Hyphenisation with pyphen",
            "content": "!pip install pyphen . Collecting pyphen Downloading pyphen-0.12.0-py3-none-any.whl (2.0 MB) |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.0 MB 3.8 MB/s Installing collected packages: pyphen Successfully installed pyphen-0.12.0 . import pyphen . &#39;sv&#39; in pyphen.LANGUAGES . True . dic = pyphen.Pyphen(lang=&#39;sv&#39;) . dic.inserted(&quot;internetbaserad&quot;).replace(&quot;-&quot;, &quot; &quot;) . &#39;in ter net ba se rad&#39; .",
            "url": "https://jimregan.github.io/notes/pyphen/hyphenisation/snippet/2022/04/26/pyphen-sv.html",
            "relUrl": "/pyphen/hyphenisation/snippet/2022/04/26/pyphen-sv.html",
            "date": " â€¢ Apr 26, 2022"
        }
        
    
  
    
        ,"post12": {
            "title": "Instaloader to ntriples",
            "content": "import lzma . from pathlib import Path BASE = Path(&quot;/Users/joregan/Playing/instascr&quot;) . import json . from datetime import datetime datestr = datetime.today().strftime(&#39;%Y%m%d&#39;) . print(data[&#39;node&#39;].keys()) . dict_keys([&#39;__typename&#39;, &#39;id&#39;, &#39;gating_info&#39;, &#39;fact_check_overall_rating&#39;, &#39;fact_check_information&#39;, &#39;media_overlay_info&#39;, &#39;sensitivity_friction_info&#39;, &#39;sharing_friction_info&#39;, &#39;dimensions&#39;, &#39;display_url&#39;, &#39;display_resources&#39;, &#39;is_video&#39;, &#39;media_preview&#39;, &#39;tracking_token&#39;, &#39;edge_media_to_tagged_user&#39;, &#39;accessibility_caption&#39;, &#39;edge_media_to_caption&#39;, &#39;shortcode&#39;, &#39;edge_media_to_comment&#39;, &#39;edge_media_to_sponsor_user&#39;, &#39;comments_disabled&#39;, &#39;taken_at_timestamp&#39;, &#39;edge_media_preview_like&#39;, &#39;owner&#39;, &#39;location&#39;, &#39;viewer_has_liked&#39;, &#39;viewer_has_saved&#39;, &#39;viewer_has_saved_to_collection&#39;, &#39;viewer_in_photo_of_you&#39;, &#39;viewer_can_reshare&#39;, &#39;thumbnail_src&#39;, &#39;thumbnail_resources&#39;, &#39;edge_sidecar_to_children&#39;]) . testf = &#39;/Users/joregan/Playing/instascr/mollyryanxo/2020-06-06_20-36-58_UTC.json.xz&#39; jsons = lzma.open(testf).read().decode(&#39;utf-8&#39;) data = json.loads(jsons) username = data[&#39;node&#39;][&#39;owner&#39;][&#39;username&#39;] #for edge in data[&#39;node&#39;][&#39;edge_sidecar_to_children&#39;][&#39;edges&#39;]: # if &#39;video_url&#39; in edge[&#39;node&#39;]: # print(edge[&#39;node&#39;][&#39;video_url&#39;]) . def get_from_data(data): urls = set() if &#39;node&#39; not in data: print(f&quot;Error reading file&quot;) if &#39;edge_sidecar_to_children&#39; in data[&#39;node&#39;]: for edge in data[&#39;node&#39;][&#39;edge_sidecar_to_children&#39;][&#39;edges&#39;]: urls.add(edge[&#39;node&#39;][&#39;display_url&#39;]) if &#39;video_url&#39; in data[&#39;node&#39;]: urls.add(data[&#39;node&#39;][&#39;video_url&#39;]) urls.add(data[&#39;node&#39;][&#39;display_url&#39;]) if &#39;video_url&#39; in data[&#39;node&#39;]: urls.add(data[&#39;node&#39;][&#39;video_url&#39;]) return list(urls) . get_from_data(data) . datestr = &quot;20220417&quot; . from pathlib import Path BASE = Path(&quot;/Users/joregan/Playing/instascr&quot;) . with open(f&quot;/Users/joregan/Playing/400bcacf78036990182af6bbd7e41a71/instascrape-{datestr}.nt&quot;, &quot;w&quot;) as outf: for xzfile in BASE.glob(&quot;**/*.xz&quot;): jsons = lzma.open(xzfile).read().decode(&#39;utf-8&#39;) data = json.loads(jsons) if not &#39;owner&#39; in data[&#39;node&#39;]: print(f&quot;Skipping {str(xzfile)}&quot;) continue if not &#39;shortcode&#39; in data[&#39;node&#39;]: print(f&quot;Missing shortcode: {str(xzfile)}&quot;) continue username = data[&#39;node&#39;][&#39;owner&#39;][&#39;username&#39;] short = data[&#39;node&#39;][&#39;shortcode&#39;] urls = get_from_data(data) for url in urls: outf.write(f&quot;&lt;{url}&gt; &lt;http://xmlns.com/foaf/0.1/page&gt; &lt;https://www.instagram.com/p/{short}/?taken-by={username}&gt; n&quot;) .",
            "url": "https://jimregan.github.io/notes/instaloader/rdf/2022/04/16/extract-instaloader.html",
            "relUrl": "/instaloader/rdf/2022/04/16/extract-instaloader.html",
            "date": " â€¢ Apr 16, 2022"
        }
        
    
  
    
        ,"post13": {
            "title": "Interesting links, 15/04/2022",
            "content": "StackEdit â€” online markdown editor . jimregan/psst-partial-timit â€” excessively detailed set of experiments for the PSST Challenge . PnG BERT: Augmented BERT on Phonemes and Graphemes for Neural TTS . EchoThief and IR Survey .",
            "url": "https://jimregan.github.io/notes/links/2022/04/15/misc-links.html",
            "relUrl": "/links/2022/04/15/misc-links.html",
            "date": " â€¢ Apr 15, 2022"
        }
        
    
  
    
        ,"post14": {
            "title": "Prepping TIMIT for Fairseq (for PSST)",
            "content": "from datasets import load_dataset, concatenate_datasets import soundfile as sf . PAD = &quot;&lt;pad&gt;&quot; UNK = &quot;&lt;unk&gt;&quot; SIL = &quot;&lt;sil&gt;&quot; SPN = &quot;&lt;spn&gt;&quot; . VOCAB_ITEMS =&quot;&quot;&quot; AA AE AH AO AW AX AY EH ER EY IH IY OW OY UH UW UX B CH D DH DX EL EM EN F G HH JH K L M N NG NX P Q R S SH T TH V W WH Y Z ZH . , ? ! &quot;&quot;&quot; . _VOCAB_SPLIT = VOCAB_ITEMS.split(&quot; n&quot;)[1:-1] . VOCAB = {e[1]:e[0] for e in enumerate(_VOCAB_SPLIT)} . TIMIT_MAPPING = { &#39;ax&#39;: &#39;AH&#39;, &#39;ax-h&#39;: &#39;AH&#39;, &#39;axr&#39;: &#39;ER&#39;, &#39;dx&#39;: &#39;T&#39;, &#39;el&#39;: [&#39;AH&#39;, &#39;L&#39;], &#39;em&#39;: [&#39;AH&#39;, &#39;M&#39;], &#39;en&#39;: [&#39;AH&#39;, &#39;N&#39;], &#39;eng&#39;: [&#39;IH&#39;, &#39;NG&#39;], &#39;hv&#39;: &#39;HH&#39;, &#39;ix&#39;: &#39;IH&#39;, &#39;nx&#39;: [&#39;N&#39;, &#39;T&#39;], &#39;pau&#39;: &#39;&lt;sil&gt;&#39;, &#39;epi&#39;: &#39;&lt;sil&gt;&#39;, &#39;ux&#39;: &#39;UW&#39; } TIMIT_IGNORE = [&#39;bcl&#39;, &#39;dcl&#39;, &#39;gcl&#39;, &#39;kcl&#39;, &#39;pcl&#39;, &#39;tcl&#39;] TIMIT_DISCARD = [&#39;dx&#39;, &#39;nx&#39;, &#39;q&#39;] . def map_timit_to_cmudict(timit): output = [] start = 1 if timit[0] == &quot;h#&quot; else 0 end = -1 if timit[-1] == &quot;h#&quot; else None timit = timit[start:end] for phone in timit: if phone in TIMIT_MAPPING: if type(TIMIT_MAPPING[phone]) == list: output += TIMIT_MAPPING[phone] else: output.append(TIMIT_MAPPING[phone]) elif phone in TIMIT_IGNORE: pass else: if not phone.upper() in VOCAB: print(&quot;Invalid phone&quot;, phone.upper()) output.append(phone.upper()) return output . timit = load_dataset(&#39;timit_asr&#39;) . def is_discardable(batch): for phoneme in batch[&quot;phonetic_detail&quot;][&quot;utterance&quot;]: if phoneme in TIMIT_DISCARD: return False return True . timit_filt = timit[&quot;train&quot;].filter(lambda eg: is_discardable(eg)) . timit_filt2 = timit[&quot;test&quot;].filter(lambda eg: is_discardable(eg)) . timit = concatenate_datasets([timit_filt, timit_filt2]) . MAX_TOKENS = 1120000 . manifest_path = &quot;manifest.tsv&quot; transcript_path = &quot;transcript&quot; . BASE = timit[0][&quot;file&quot;].split(&quot;/data/&quot;)[0] + &quot;/data/&quot; . resplit = timit.train_test_split(test_size=0.1) . for split in [&quot;train&quot;, &quot;test&quot;]: fsplit = split if fsplit == &quot;test&quot;: fsplit = &quot;valid&quot; with open(f&quot;{fsplit}.tsv&quot;, &quot;w&quot;) as manifest, open(f&quot;{fsplit}.ltr&quot;, &quot;w&quot;) as transcript: manifest.write(BASE + &quot; n&quot;) for item in resplit[split]: frames, sr = sf.read(item[&quot;file&quot;]) manifest.write(f&quot;{item[&#39;file&#39;].replace(BASE, &#39;&#39;)} t{len(frames)} n&quot;) utt = item[&#39;phonetic_detail&#39;][&#39;utterance&#39;] mapped = map_timit_to_cmudict(utt) transcript.write(f&quot;{&#39; &#39;.join(mapped)} n&quot;) .",
            "url": "https://jimregan.github.io/notes/timit/fairseq/psst/2022/04/04/timit-fairseq.html",
            "relUrl": "/timit/fairseq/psst/2022/04/04/timit-fairseq.html",
            "date": " â€¢ Apr 4, 2022"
        }
        
    
  
    
        ,"post15": {
            "title": "Interesting links, 16/03/2022",
            "content": "Transformer Memory as a Differentiable Search Index . Itâ€™s Raw! Audio Generation with State-Space Models, code . Learning Discrete Representations via Constrained Clustering for Effective and Efficient Dense Retrieval, code . Hierarchical Perceiver . mSLAM: Massively multilingual joint pre-training for speech and text . Who spoke when! How to Build your own Speaker Diarization Module, code . Do massive multilingual models that recognize language-specific units (e.g. words, phonemes) work on *all* speech?IMO, no! Multilingual =/= Universal.Check out our #INTERSPEECH2021 paper, Differentiable Allophone Graphs for Language-Universal ASR! https://t.co/haRflRUGSh 1/N pic.twitter.com/YBx3lPtgNJ . &mdash; Brian Yan (@brianyan918) July 29, 2021 Differentiable Allophone Graphs for Language-Universal Speech Recognition . NLP Seminar 220216 - Omar Sanseviero (Hugging Face) . 11L â€“ Speech recognition and Graph Transformer Networks . How can I get duration of all video files in a folder containing multiple subfolders? . exiftool -n -q -p &#39;${Duration;our $sum;$_=ConvertDuration($sum+=$_)}&#39; ./*.mp4| tail -n1 . Breathing and Speech Planning in Spontaneous Speech Synthesis . mchaput/whoosh . Yann LeCun: â€œEnergy-Based Self-Supervised Learning . Pseudo-Labeling for Massively Multilingual Speech Recognition . Implicit Language Model in LSTM for OCR . Exploring neural transducers for end-to-end speech recognition . Advancing Connectionist Temporal Classification with Attention Modeling . Advancing Acoustic-to-Word CTC Model . Direct Acoustics-to-Word Models for English Conversational Speech Recognition . Do End-to-End Speech Recognition Models Care About Context? . A study on effects of implicit and explicit language model information for DBLSTM-CTC based handwriting recognition . microsoft/mutransformers . How to Train a Joint Embedding using Pytorch . adefossez/julius â€” Fast PyTorch based DSP for audio and 1D signals . Julius Orion Smith III Home Page . ageron/handson-ml2 . asteroid-team/Libri_VAD . microsoft/DNS-Challenge â€” This repo contains the scripts, models, and required files for the Deep Noise Suppression (DNS) Challenge. . The Norwegian Parliamentary Speech Corpus . Who Takes the Parliamentary Floor? The Role of Gender in Speech-making in the Swedish Riksdag .",
            "url": "https://jimregan.github.io/notes/links/2022/03/16/misc-links.html",
            "relUrl": "/links/2022/03/16/misc-links.html",
            "date": " â€¢ Mar 16, 2022"
        }
        
    
  
    
        ,"post16": {
            "title": "Filter Riksdag by year",
            "content": "import json from pathlib import Path _API_DIR = Path(&quot;/Users/joregan/riksdag/riksdag-api-out&quot;) . def endswith_list(text, items): for it in items: if text.endswith(it): return True return False . def viddata_get_single_stream(videodata, hires=True): videos = [] if videodata is None: return [] if &#39;streams&#39; not in videodata: #raise Exception(&quot;videodata is missing &#39;streams&#39;&quot;) return [] if videodata[&#39;streams&#39;] is None: return [] if &#39;files&#39; not in videodata[&#39;streams&#39;]: #raise Exception(&quot;videodata[&#39;streams&#39;] is missing &#39;files&#39;&quot;) return [] if type(videodata[&#39;streams&#39;][&#39;files&#39;]) == list: for vfile in videodata[&#39;streams&#39;][&#39;files&#39;]: for bw in vfile[&#39;bandwidth&#39;]: if hires and bw[&#39;name&#39;] == &#39;HÃ¶g kvalitet&#39;: videos.append(bw[&#39;downloadurl&#39;]) elif not hires and bw[&#39;name&#39;] == &#39;LÃ¥g kvalitet&#39;: videos.append(bw[&#39;downloadurl&#39;]) else: #raise Exception(f&quot;Expected a list, got {type(videodata[&#39;streams&#39;][&#39;files&#39;])}&quot;) return [] return videos def viddata_get_streams(videodata, hires=True): output = [] if &#39;videodata&#39; not in videodata: #raise Exception(&quot;&#39;videodata&#39; missing&quot;) return [] for vdata in videodata[&#39;videodata&#39;]: output += viddata_get_single_stream(vdata, hires) return output def viddata_from_file(videofile, hires=True): with open(videofile) as jsonf: data = json.load(jsonf) return viddata_get_streams(data, hires) . def json_matches_years(filename, years): ret_val = False with open(filename) as f: data = json.load(f) if not &quot;videodata&quot; in data: #raise Exception(f&quot;File {filename} missing key &#39;videodata&#39;&quot;) return False videodata = data[&quot;videodata&quot;] if videodata is None: print(f&quot;Empty videodata: {filename}&quot;) return False for vdata in videodata: if vdata is None: print(f&quot;Empty videodata: {filename}&quot;) return False if &quot;debatedate&quot; in vdata and vdata[&quot;debatedate&quot;] is not None and vdata[&quot;debatedate&quot;] != &quot;&quot;: date = vdata[&quot;debatedate&quot;] if endswith_list(date.strip(), years): return True return False . matches = [] for file in _API_DIR.glob(&quot;H*&quot;): if json_matches_years(file, [&quot;2017&quot;, &quot;2018&quot;]): matches.append(str(file)) . Empty videodata: /Users/joregan/riksdag/riksdag-api-out/H8C120210621zz . with open(&quot;2017-2018.txt&quot;, &quot;w&quot;) as outf: for m in matches: outf.write(m + &quot; n&quot;) . with open(&quot;2017-2018-videos.txt&quot;, &quot;w&quot;) as outf: for file in _API_DIR.glob(&quot;H*&quot;): if json_matches_years(file, [&quot;2017&quot;, &quot;2018&quot;]): videos = viddata_from_file(file) vidsout = &quot; t&quot;.join(videos) outf.write(f&quot;{file.stem} t{vidsout} n&quot;) . Empty videodata: /Users/joregan/riksdag/riksdag-api-out/H8C120210621zz . def get_speaker_data(data): output = [] if not &quot;videodata&quot; in data or data[&quot;videodata&quot;] is None: #raise Exception(f&quot;File {filename} missing key &#39;videodata&#39;&quot;) return [] for vdata in data[&quot;videodata&quot;]: if vdata is not None and &quot;speakers&quot; in vdata and vdata[&quot;speakers&quot;] is not None: for speaker in vdata[&quot;speakers&quot;]: output.append(speaker) return output . with open(&quot;/Users/joregan/riksdag/riksdag-api-out/H501CU20&quot;) as inp: vdata = json.load(inp) speakers = get_speaker_data(vdata) sample_speech = speakers[0][&quot;anftext&quot;] . from bs4 import BeautifulSoup . !pip install mosestokenizer . from mosestokenizer import MosesSentenceSplitter splitter = MosesSentenceSplitter(&quot;sv&quot;) . stdbuf was not found; communication with perl may hang due to stdio buffering. . def split_text(sample_speech, by_paras=False): soup = BeautifulSoup(sample_speech, &#39;html.parser&#39;) paras = [] for para in soup.findAll(&quot;p&quot;): if not para.text.strip().startswith(&quot;STYLEREF Kantrubrik&quot;): paras.append(para.text.strip()) splitparas = [splitter([p]) for p in paras if p.strip() != &quot;&quot;] if by_paras: return splitparas else: flattened = [sent for sents in splitparas for sent in sents] return flattened . with open(&quot;2017-2018-text.txt&quot;, &quot;w&quot;) as outf: for file in _API_DIR.glob(&quot;H*&quot;): if json_matches_years(file, [&quot;2017&quot;, &quot;2018&quot;]): with open(file) as inp: vdata = json.load(inp) speakers = get_speaker_data(vdata) for speaker in speakers: if &quot;anftext&quot; in speaker: text = split_text(speaker[&quot;anftext&quot;]) for line in text: outf.write(line + &quot; n&quot;) . Empty videodata: /Users/joregan/riksdag/riksdag-api-out/H8C120210621zz . with open(&quot;all-text.txt&quot;, &quot;w&quot;) as outf: for file in _API_DIR.glob(&quot;H*&quot;): with open(file) as inp: vdata = json.load(inp) speakers = get_speaker_data(vdata) for speaker in speakers: if &quot;anftext&quot; in speaker: text = split_text(speaker[&quot;anftext&quot;]) for line in text: outf.write(line + &quot; n&quot;) .",
            "url": "https://jimregan.github.io/notes/riksdag/2022/03/15/filter-by-year.html",
            "relUrl": "/riksdag/2022/03/15/filter-by-year.html",
            "date": " â€¢ Mar 15, 2022"
        }
        
    
  
    
        ,"post17": {
            "title": "Getting timestamps on long audio",
            "content": "First, an audio sample. Using this video from youtube. Youtube says it&#39;s 11 minutes, 51 seconds, so that should be enough to check that striding works. . !pip install youtube-dl . !youtube-dl -x --audio-format best -o &#39;%(id)s.%(ext)s&#39; https://www.youtube.com/watch?v=Kw5jkyLGFGc . !ffmpeg -i Kw5jkyLGFGc.m4a -acodec pcm_s16le -ac 1 -ar 16000 Kw5jkyLGFGc.wav . Here starts the actual ASR stuff. . !pip install transformers . _SWE_MODEL = &quot;KBLab/wav2vec2-large-voxrex-swedish&quot; . from transformers import pipeline . pipe = pipeline(model=_SWE_MODEL) . For working with strides, there&#39;s information in a blog post. . There isn&#39;t much information on getting timestamps from a pipeline, but the detail is in the pull request. . output = pipe(&quot;/content/Kw5jkyLGFGc.wav&quot;, chunk_length_s=10) . output = pipe(&quot;/content/Kw5jkyLGFGc.wav&quot;, chunk_length_s=10, return_timestamps=&quot;word&quot;) . import json with open(&quot;/content/Kw5jkyLGFGc.json&quot;, &quot;w&quot;) as f: json.dump(output, f) .",
            "url": "https://jimregan.github.io/notes/long%20audio/wav2vec2/huggingface/timestamps/2022/03/08/getting-timestamps-on-long-audio-with-wav2vec2-and-huggingface.html",
            "relUrl": "/long%20audio/wav2vec2/huggingface/timestamps/2022/03/08/getting-timestamps-on-long-audio-with-wav2vec2-and-huggingface.html",
            "date": " â€¢ Mar 8, 2022"
        }
        
    
  
    
        ,"post18": {
            "title": "difflib opcodes",
            "content": "texta = &quot;this is a small test&quot; textb = &quot;this isa small text&quot; . from difflib import SequenceMatcher def print_replacements(texta, textb): sm = SequenceMatcher(a=texta, b=textb) for op, a_start, a_end, b_start, b_end in sm.get_opcodes(): frag_a = texta[a_start:a_end] frag_b = textb[b_start:b_end] a_pre = a_start - 1 if a_start &gt; 0 else 0 b_pre = b_start - 1 if b_start &gt; 0 else 0 a_post = a_end + 1 if a_end &lt; (len(texta) - 1) else a_end b_post = b_end + 1 if b_end &lt; (len(textb) - 1) else b_end if op == &quot;equal&quot;: continue elif op == &quot;delete&quot;: if frag_a == &quot; &quot;: continue print(f&quot;del t{texta[a_pre:a_post]} t{textb[b_pre:b_post]}&quot;) elif op == &quot;insert&quot;: if frag_b == &quot; &quot;: continue print(f&quot;ins t{texta[a_pre:a_post]} t{textb[b_pre:b_post]}&quot;) elif op == &quot;replace&quot;: print(f&quot;repl t{frag_a} t{frag_b}&quot;) . print_replacements(texta, textb) . repl s x .",
            "url": "https://jimregan.github.io/notes/difflib/2022/03/08/difflib-find-pieces.html",
            "relUrl": "/difflib/2022/03/08/difflib-find-pieces.html",
            "date": " â€¢ Mar 8, 2022"
        }
        
    
  
    
        ,"post19": {
            "title": "Read SMP file (with soundfile)",
            "content": "import soundfile as sf def fix_text(text): return text.replace(&quot;{&quot;, &quot;Ã¤&quot;).replace(&quot;}&quot;, &quot;Ã¥&quot;).replace(&quot;|&quot;, &quot;Ã¶&quot;) def smp_headers(filename): with open(filename, &quot;rb&quot;) as f: f.seek(0) raw_headers = f.read(1024) raw_headers = raw_headers.rstrip(b&#39; x00&#39;) asc_headers = raw_headers.decode(&quot;ascii&quot;) asc_headers.rstrip(&#39; x00&#39;) tmp = [a for a in asc_headers.split(&quot; r n&quot;)] back = -1 while abs(back) &gt; len(tmp) + 1: if tmp[back] == &#39;=&#39;: break back -= 1 tmp = tmp[0:back-1] return dict(a.split(&quot;=&quot;) for a in tmp) def smp_read_sf(filename): headers = smp_headers(filename) if headers[&quot;msb&quot;] == &quot;last&quot;: ENDIAN = &quot;LITTLE&quot; else: ENDIAN = &quot;BIG&quot; data, sr = sf.read(filename, channels=int(headers[&quot;nchans&quot;]), samplerate=16000, endian=ENDIAN, start=512, dtype=&quot;int16&quot;, format=&quot;RAW&quot;, subtype=&quot;PCM_16&quot;) return (data, sr) def write_wav(filename, arr): import wave with wave.open(filename, &quot;w&quot;) as f: f.setnchannels(1) f.setsampwidth(2) f.setframerate(16000) f.writeframes(arr) arr, sr = smp_read_sf(&quot;fp2060.pr.09.smp&quot;) write_wav(&quot;out.wav&quot;, arr) . import IPython IPython.display.Audio(&quot;out.wav&quot;) . Your browser does not support the audio element.",
            "url": "https://jimregan.github.io/notes/smp/soundfile/snack/wavesurfer/2022/03/02/read-smp-file.html",
            "relUrl": "/smp/soundfile/snack/wavesurfer/2022/03/02/read-smp-file.html",
            "date": " â€¢ Mar 2, 2022"
        }
        
    
  
    
        ,"post20": {
            "title": "Interesting links, 02/03/2022",
            "content": "Fonetik 2022 . The EMU-webApp . TorchStudio Features â€” Looks interesting, doesnâ€™t seem to run on ARM Mac though . Fast Development of ASR in African Languages using Self Supervised Speech Representation Learning . The Effects of Automatic Speech Recognition Quality on Human Transcription Latency â€œOur studies with 160 participants recruited on Amazonâ€™s Mechanical Turk indicate that starting with the ASR output is worse unless it is sufficiently accurate (Word Error Rate (WER) is under 30%)â€ . Differentiable Allophone Graphs for Language-Universal Speech Recognition, tweet . birgermoell/lm-swedish . Boosting Wav2Vec2 with n-grams in ðŸ¤— Transformers . Irish ASR demo . QPSR . Gunnar Fant publications . Neural Instrument Cloning from very few samples . AI-Nordics/the-nordic-pile . Berzelius . chinedufn/swift-bridge â€” swift-bridge facilitates Rust and Swift interop. . qarmin/czkawka â€” Multi functional app to find duplicates, empty folders, similar images etc. . PyO3/pyo3 â€” Rust bindings for the Python interpreter . N-gram Language Model with NLTK . speechbrain.lm.counting module . Google cloud ASR languages . FLAME, pytorch . Bried intro to Linen . NbAiLab/NPSC â€” Norwegian Parliamentary Speech Corpus . XGLM: HuggingFace . fsspec . FNet: Mixing Tokens with Fourier Transforms, code, HF . HF: wav2vec update for tiny audio . Adding vs. concatenating positional embeddings &amp; Learned positional encodings . Math - Differential Calculus . BirgerMoell/ToMaHawk . Making automatic speech recognition work on large files with Wav2Vec2 in ðŸ¤— Transformers . Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation, OpenReview, code . 02 â€“ Neural nets: rotation and squashing . Audio augmentation . facebookresearch/AugLy . iver56/audiomentations . asteroid-team/torch-audiomentations . Spijkervet/torchaudio-augmentations . spotify/pedalboard . facebookresearch/WavAugment . VOiCES Corpus . Fonetik . FM-modulation unit for tape-recording . Voice fundamental frequency tracking . Formant frequency tracking . Detection of voicing and Automatic segmentation schemes . Evaluation of spectrographic data sampling techniques . Structural classification of Swedish phonemes . In search of the conversational homunculus . Automatic classification of â€˜frontâ€™ and â€˜backâ€™ pronunciation variants of /r/ in the GÃ¶taland dialects of Swedish .",
            "url": "https://jimregan.github.io/notes/links/2022/03/02/misc-links.html",
            "relUrl": "/links/2022/03/02/misc-links.html",
            "date": " â€¢ Mar 2, 2022"
        }
        
    
  
    
        ,"post21": {
            "title": "QPSR gap checking",
            "content": "import json . with open(&quot;qpsr.json&quot;) as f: data = json.load(f) . res = {} for item in data: if not &quot;pages&quot; in item: print(f&quot;Missing pages: {item[&#39;title&#39;]} ({item[&#39;year&#39;]})&quot;) pages = &quot;?-?&quot; else: pages = item[&quot;pages&quot;] year = item[&quot;year&quot;] if not &quot;volume&quot; in item: print(f&quot;Missing volume: {item[&#39;title&#39;]} ({item[&#39;year&#39;]})&quot;) vol = &quot;??&quot; else: vol = item[&quot;volume&quot;] if not &quot;edition&quot; in item: print(f&quot;Missing edition: {item[&#39;title&#39;]} ({item[&#39;year&#39;]})&quot;) ed = &quot;??&quot; else: ed = item[&quot;edition&quot;] if not &quot;-&quot; in pages: if pages.isdigit(): start = end = pages else: raise IOError(f&quot;No &#39;-&#39; in pages: {pages} ({key})&quot;) else: start, end = pages.split(&quot;-&quot;) if item[&quot;title&quot;] == &quot;.&quot;: print(item[&quot;pdf&quot;]) key = f&quot;{year}_{vol}_{ed}&quot; if not key in res: res[key] = [{&quot;start&quot;: start, &quot;end&quot;: end}] else: res[key].append({&quot;start&quot;: start, &quot;end&quot;: end}) . from functools import cmp_to_key def compare(item1, item2): if item1[&quot;end&quot;] &lt; item2[&quot;start&quot;]: return -1 elif item1[&quot;start&quot;] &gt; item2[&quot;end&quot;]: return 1 else: return 0 def same_or_next(a, b): return (a == b) or (a == b-1) output = {} last_pages = {} for item in res.keys(): for subitem in res[item]: subitem[&quot;start&quot;] = int(subitem[&quot;start&quot;]) subitem[&quot;end&quot;] = int(subitem[&quot;end&quot;]) tmp = res[item] tmp = sorted(tmp, key=cmp_to_key(compare)) last_pages[item] = tmp[-1][&quot;end&quot;] cnt = 0 outtmp = [] if tmp[0][&#39;start&#39;] &gt; 1: outtmp.append({&quot;start&quot;: 1, &quot;end&quot;: tmp[0][&#39;start&#39;]-1}) while cnt &lt; len(tmp) - 1: if not same_or_next(tmp[cnt][&quot;end&quot;], tmp[cnt+1][&quot;start&quot;]): toadd = {&quot;start&quot;: tmp[cnt][&quot;end&quot;]+1, &quot;end&quot;: tmp[cnt+1][&quot;start&quot;]-1} if toadd[&quot;start&quot;] == toadd[&quot;end&quot;]: toadd = {&quot;page&quot;: toadd[&quot;start&quot;]} outtmp.append(toadd) cnt += 1 output[item] = outtmp . with open(&quot;pages.txt&quot;, &quot;w&quot;) as f: for (ed, page) in last_pages.items(): f.write(f&#39;{ed.replace(&quot;_&quot;, &quot; &quot;)} t{page} n&#39;) . def _single_page(page): if &quot;page&quot; in page: return str(page[&quot;page&quot;]) else: return f&quot;{page[&#39;start&#39;]}-{page[&#39;end&#39;]}&quot; def _join_pages(pagelist): return &quot;, &quot;.join([_single_page(a) for a in pagelist]) merged = {a: _join_pages(b) for (a, b) in output.items()} . with open(&quot;missing-pages.txt&quot;, &quot;w&quot;) as f: for (a, b) in merged.items(): if b and b != &quot;&quot;: f.write(f&quot;{a} t{b} n&quot;) . with open(&quot;number-of-articles.txt&quot;, &quot;w&quot;) as f: for (a, b) in res.items(): f.write(f&quot;{a} t{len(b)} n&quot;) . import json with open(&quot;gaps.json&quot;, &quot;w&quot;) as out: out.write(json.dumps(output, indent=4)) .",
            "url": "https://jimregan.github.io/notes/qpsr/tmh/2022/02/23/qpsr-check-gaps.html",
            "relUrl": "/qpsr/tmh/2022/02/23/qpsr-check-gaps.html",
            "date": " â€¢ Feb 23, 2022"
        }
        
    
  
    
        ,"post22": {
            "title": "QPSR scraper",
            "content": "import requests from bs4 import BeautifulSoup . def get_years(): _TOP = &quot;https://www.speech.kth.se/qpsr/&quot; _TOP_HTML = requests.get(_TOP) assert _TOP_HTML.status_code == 200 _TOP_SOUP = BeautifulSoup(_TOP_HTML.text, &#39;html.parser&#39;) by_years = _TOP_SOUP.find_all(&quot;select&quot;, {&quot;name&quot;: &quot;year&quot;}) years = [opt.text for by_year in by_years for opt in by_year.find_all(&quot;option&quot;)] return years . _TITLES = &quot;&quot;&quot; http://www.speech.kth.se/prod/publications/files/3605.pdf tProductive Vocabulary Size Development in Children Aged 18-24 Months â€“ Gender Differences tIda Andersson, Jenny Gauding, Anna Graca, Katarina Holm, Linda Ã–hlin, Ulrika Marklund, Anna Ericsson http://www.speech.kth.se/prod/publications/files/3607.pdf tChildrenâ€™s perception of their modified speech â€“ preliminary findings tSofia StrÃ¶mbergsson http://www.speech.kth.se/prod/publications/files/3579.pdf tImitation of bird song in folklore â€“ onomatopoeia or not? tÃ…sa Abelin http://www.speech.kth.se/prod/publications/files/3586.pdf tAnticipatory lip roundingâ€“ a pilot study using The Wave Speech Research System tGabrielsson, D., Kirchner, S., Nilsson, K., Norberg, A., Widlund, C. http://www.speech.kth.se/prod/publications/files/qpsr/2007/2007_50_1_121-124.pdf tSIMULEKT â€“ modelling Swedish regional intonation tGÃ¶sta Bruce, Susanne SchÃ¶tz, BjÃ¶rn GranstrÃ¶m http://www.speech.kth.se/prod/publications/files/qpsr/2007/2007_50_1_033-036.pdf tFilibuster â€“ a new Swedish text-to-speech system tChristina Ericsson, Jesper Klein, KÃ¥re SjÃ¶lander, Lars SÃ¶nnebo http://www.speech.kth.se/prod/publications/files/qpsr/2007/2007_50_1_049-052.pdf tSwedish word accents in a â€˜confirmationâ€™ context tGilbert Ambrazaitis http://www.speech.kth.se/prod/publications/files/qpsr/2007/2007_50_1_053-056.pdf tEstimates of Infantsâ€™ Vocabulary Composition and the Role of Adult-instructions for Early Word-learning tKlintfors E., Lacerda F., Sundberg U. http://www.speech.kth.se/prod/publications/files/qpsr/2007/2007_50_1_061-064.pdf tMushyPeek â€“ an experiment framework for controlled investigation of human-human interaction control behaviour tJens Edlund, Jonas Beskow, Mattias Heldner http://www.speech.kth.se/prod/publications/files/qpsr/2007/2007_50_1_077-080.pdf tWhat you Hear is what you See â€“ a study of visual vs. auditive noise tAnna Berg, Annelie Brandt http://www.speech.kth.se/prod/publications/files/qpsr/2007/2007_50_1_093-096.pdf tLinguistic challenges for bilingual schoolchildren in RosengÃ¥rd tPetra BodÃ©n, Gudrun Svensson http://www.speech.kth.se/prod/publications/files/qpsr/2007/2007_50_1_097-100.pdf tVoxalys â€“ a Pedagogical Praat Plugin for Voice Analysis tJonas Lindh http://www.speech.kth.se/prod/publications/files/qpsr/2006/2006_48_1_035-043.pdf tMusical structure: A translation of IstvÃ¡n Ipolyi: InnfÃ¸ring i MusikksprÃ¥kets Opprinnelse og Struktur tFalkenberg Hansen, K. http://www.speech.kth.se/prod/publications/files/qpsr/2002/2002_44_1_085-088.pdf tStÃ¸d and Vowel Length: Acoustic and Cognitive Reality? tGrÃ¸nnum, N. http://www.speech.kth.se/prod/publications/files/qpsr/2002/2002_44_1_145-148.pdf tStress judgements by naÃ¯ve listeners tMolin, J. http://www.speech.kth.se/prod/publications/files/qpsr/1995/1995_36_2-3_063-070.pdf tMatching the rule parameters of PHRASE ARCH to performances of â€TrÃ¤umereiâ€: a preliminary study tFriberg, A. http://www.speech.kth.se/prod/publications/files/qpsr/1975/1975_16_4_027-035.pdf tLippenablesehilfe fÃ¼r GehÃ¶rlose: Visuelle oder taktile Darbietung von ErgÃ¤nzungsinformation? tTraunmuller, H. &quot;&quot;&quot; . MISSING = {} for missed in _TITLES.split(&quot; n&quot;): if not &quot; t&quot; in missed: continue parts = missed.split(&quot; t&quot;) MISSING[parts[0]] = parts[1:] . def read_page(page): if page.startswith(&quot;http&quot;): url = page year = page[len(page)-4:] else: url = f&quot;https://www.speech.kth.se/qpsr/show_by_year.php?year={page}&quot; year = page req = requests.get(url) assert req.status_code == 200 soup = BeautifulSoup(req.text, &#39;html.parser&#39;) pubs = [] for pub in soup.find_all(&quot;p&quot;, class_=&quot;publications_apa_entry&quot;): data = {} data[&quot;year&quot;] = year raw_text = pub.text author = pub.find(&quot;span&quot;, class_=&quot;publications_apa_author&quot;) if author.text == &quot;, . (Ed.).&quot;: data[&quot;author&quot;] = &quot;&quot; else: data[&quot;author&quot;] = author.text raw_text = raw_text.replace(author.text, &quot;&quot;).lstrip() if not raw_text.startswith(f&quot;({year}).&quot;): raise Exception(f&quot;Expected year {year}, but got {raw_text[1:5]} - &quot; + pub.text) raw_text = raw_text[8:] pub_title = pub.find(&quot;span&quot;, class_=&quot;publications_apa_title&quot;) data[&quot;publication_full&quot;] = pub_title.text pub_pieces = pub_title.text.split(&quot;, &quot;) if pub_pieces[-1].isdigit(): data[&quot;volume&quot;] = pub_pieces[-1] data[&quot;publication&quot;] = &quot;, &quot;.join(pub_pieces[0:-1]) pub_title_start = raw_text.find(pub_title.text) pub_title_end = pub_title_start + len(pub_title.text) data[&quot;title&quot;] = raw_text[0:pub_title_start].strip() if data[&quot;title&quot;].endswith(&quot;. In&quot;): data[&quot;title&quot;] = data[&quot;title&quot;][0:-3] for pdf_link in pub.find_all(&quot;a&quot;): if pdf_link is None or not pdf_link.has_attr(&quot;href&quot;): print(&quot;Missing link: &quot; + pub.text) else: if pdf_link[&quot;href&quot;].endswith(&quot;pdf&quot;): data[&quot;pdf&quot;] = pdf_link[&quot;href&quot;] else: if pdf_link.has_attr(&quot;onclick&quot;): abs_start = pdf_link[&quot;onclick&quot;].find(&quot;abstract_&quot;) abs_end = pdf_link[&quot;onclick&quot;][abs_start:].find(&quot;&#39;&quot;) abs_id = pdf_link[&quot;onclick&quot;][abs_start:abs_start+abs_end] abs_soup = soup.find(&quot;p&quot;, {&quot;id&quot;: abs_id}) abs_text = abs_soup.text.strip() if abs_text.startswith(&quot;Abstract:&quot;): abs_text = abs_text[9:].strip() abs_text = abs_text.replace(&quot; r n&quot;, &quot; &quot;).replace(&quot; r&quot;, &quot; &quot;).replace(&quot; n&quot;, &quot; &quot;) data[&quot;abstract&quot;] = abs_text if &quot;pdf&quot; in data and data[&quot;pdf&quot;].endswith(&quot;/1937.pdf&quot;): data[&quot;pages&quot;] = &quot;1-6&quot; data[&quot;volume&quot;] = &quot;49&quot; data[&quot;edition&quot;] = &quot;1&quot; data[&quot;title&quot;] = &quot;Sopranos with a singerâ€™s formant? Historical, Physiological, and Acoustical Aspects of Castrato Singing&quot; data[&quot;author_full&quot;] = &quot;Johan Sundberg, Marianne TrovÃ©n, Bernhard Richter&quot; data[&quot;author&quot;] = &quot;Sundberg, J., TrovÃ©n, M., Richter, B.&quot; pubs.append(data) continue raw_text = raw_text[pub_title_end:].strip() if raw_text.endswith(&quot; [pdf]&quot;): raw_text = raw_text[0:-6] if raw_text[-1:] == &quot;.&quot;: raw_text = raw_text[0:-1] if &quot;, &quot; in raw_text: if raw_text.startswith(&quot;(pp.&quot;): parts = raw_text.split(&quot;). &quot;) data[&quot;pages&quot;] = parts[0][5:] # manual fix if data[&quot;pdf&quot;].endswith(&quot;/3597.pdf&quot;): data[&quot;volume&quot;] = &quot;51&quot; data[&quot;edition&quot;] = &quot;1&quot; elif data[&quot;pdf&quot;].endswith(&quot;/2002_44_1_153-156.pdf&quot;): data[&quot;volume&quot;] = &quot;44&quot; data[&quot;edition&quot;] = &quot;1&quot; else: parts = raw_text.split(&quot;, &quot;) if parts[0].startswith(&quot;(&quot;): to_mark = parts[0].find(&quot;)&quot;) data[&quot;edition&quot;] = parts[0][1:to_mark] if &quot; [abstract]&quot; in parts[1]: data[&quot;pages&quot;] = parts[1].replace(&quot; [abstract]&quot;, &quot;&quot;) if data[&quot;pages&quot;].endswith(&quot;.&quot;): data[&quot;pages&quot;] = data[&quot;pages&quot;][0:-1] else: data[&quot;pages&quot;] = parts[1] if &quot;pages&quot; in data and &quot;. [html]&quot; in data[&quot;pages&quot;]: data[&quot;pages&quot;] = data[&quot;pages&quot;].replace(&quot;. [html]&quot;, &quot;&quot;) if &quot;pdf&quot; in data: if data[&quot;pdf&quot;].endswith(&quot;2007_50_1_065-068.pdf&quot;): data[&quot;title&quot;] = &quot;The Parrot Effect â€“ a study of the ability to imitate a foreign language&quot; data[&quot;author_full&quot;] = &quot;Johanna Persson, Linda Westholm&quot; data[&quot;edition&quot;] = &quot;1&quot; data[&quot;pages&quot;] = &quot;065-068&quot; elif data[&quot;pdf&quot;].endswith(&quot;2007_50_1_113-116.pdf&quot;): data[&quot;title&quot;] = &quot;Automatic classification of &#39;front&#39; and &#39;back&#39; pronunciation variants of /r/ in the GÃ¶taland dialects of Swedish&quot; data[&quot;author_full&quot;] = &quot;Johan Frid&quot; elif data[&quot;pdf&quot;].endswith(&quot;2007_50_1_073-076.pdf&quot;): data[&quot;title&quot;] = &quot;Emotional McGurk effect in Swedish&quot; data[&quot;pages&quot;] = &quot;073-076&quot; data[&quot;volume&quot;] = &quot;50&quot; data[&quot;edition&quot;] = &quot;1&quot; data[&quot;author_full&quot;] = &quot;Ã…sa Abelin&quot; data[&quot;author_full&quot;] = &quot;Abelin, Ã….&quot; elif data[&quot;pdf&quot;] in MISSING: data[&quot;title&quot;] = MISSING[data[&quot;pdf&quot;]][0] data[&quot;author_full&quot;] = MISSING[data[&quot;pdf&quot;]][1] pubs.append(data) return pubs . import json all = [] for year in get_years(): all += read_page(year) with open(&quot;qpsr.json&quot;, &quot;w&quot;) as out: out.write(json.dumps(all, indent=4)) .",
            "url": "https://jimregan.github.io/notes/qpsr/tmh/2022/02/22/qpsr-scraper.html",
            "relUrl": "/qpsr/tmh/2022/02/22/qpsr-scraper.html",
            "date": " â€¢ Feb 22, 2022"
        }
        
    
  
    
        ,"post23": {
            "title": "Interesting links, 20/02/2022",
            "content": "autopilot-rs/autopy â€” A simple, cross-platform GUI automation module for Python and Rust. . JupyterLite: Jupyter â¤ï¸ WebAssembly â¤ï¸ Python . How we made Jupyter Notebooks collaborative with Yjs . VertaAI/modeldb â€” Open Source ML Model Versioning, Metadata, and Experiment Management . google/compare_gan . pfnet-research/sngan_projection . Spectral Normalization for Generative Adversarial Networks, code . Progressive Growing of GANs for Improved Quality, Stability, and Variation . Spoken dialogue data collected in the WAXHOLM project, dataset, phoneset . NST Pronunciation Lexicon for Swedish . shivammehta007/Neural-HMM . Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation . urvashik/knnlm . SlimIPL: Language-Model-Free Iterative Pseudo-Labeling . Joint Masked CPC and CTC Training for ASR . The Curious Case of Neural Text Degeneration . lukakerr/Pine . AI Sweden Youtube . LibriVox - An SgÃ©aluidhe Gaedhealach by DÃºbhglas de h-Ãde, scan . Eclipse Mosquitto . mSLAM: Massively multilingual joint pre-training for speech and text . Wav2Vec2 Time Stamps #15687 . Distilling the Knowledge of BERT for Sequence-to-Sequence ASR . google-research/t5x . google-research/mozolm â€” MozoLM: A language model (LM) serving library . Any-to-One Sequence-to-Sequence Voice Conversion using Self-Supervised Discrete Speech Representations . spaces/microsoft/wavlm-speaker-verification . Multistream CNN for Robust Acoustic Modeling, code, script . W2v-BERT: Combining Contrastive Learning and Masked Language Modeling for Self-Supervised Speech Pre-Training . VocalTractLab . chdh/klatt-syn . makcedward/nlpaug . Star Temporal Classification: Sequence Classification with Partially Labeled Data . Differentiable Allophone Graphs for Language-Universal Speech Recognition, twitter thread . BPE-Dropout: Simple and Effective Subword Regularization . Subword Regularization: Improving Neural Network Translation Models with Multiple Subword Candidates . Non-Autoregressive Predictive Coding for Learning Speech Representations from Local Dependencies, code . facebookresearch/CPC_audio . FastPitchFormant: Source-Filter Based Decomposed Modeling for Speech Synthesis .",
            "url": "https://jimregan.github.io/notes/links/2022/02/20/misc-links.html",
            "relUrl": "/links/2022/02/20/misc-links.html",
            "date": " â€¢ Feb 20, 2022"
        }
        
    
  
    
        ,"post24": {
            "title": "Festus Dockerfile",
            "content": "FROM ubuntu:18.04 ENV DEBIAN_FRONTEND=&quot;noninteractive&quot; RUN apt update &amp;&amp; apt install -y g++ git &amp;&amp; apt install -y apt-transport-https ca-certificates RUN apt install -y curl gnupg pkg-config zip zlib1g-dev unzip python # This stuff doesn&#39;t work, the apt repo seems broken #RUN curl https://bazel.build/bazel-release.pub.gpg | apt-key add - #RUN echo &quot;deb [arch=amd64] https://storage.googleapis.com/bazel-apt stable jdk1.8&quot; | tee /etc/apt/sources.list.d/bazel.list #RUN apt update #RUN apt install -y bazel RUN curl -L https://github.com/bazelbuild/bazel/releases/download/6.0.0-pre.20220201.3/bazel-6.0.0-pre.20220201.3-linux-arm64 &gt; /usr/local/bin/bazel RUN chmod a+x /usr/local/bin/bazel RUN bazel version RUN git clone https://github.com/google/language-resources/ RUN cd language-resources &amp;&amp; cat WORKSPACE | sed -e &#39;s/googletest-master/googletest-main/;s!googletest/archive/master!googletest/archive/main!;s!re2-master!re2-main!;s!/re2/archive/master!/re2/archive/main!;s/benchmark-master/benchmark-main/;s!benchmark/archive/master!benchmark/archive/main!;s/abseil-py-master/abseil-py-main/;s!abseil-py/archive/master!abseil-py/archive/main!;&#39; &gt; TMP &amp;&amp; mv TMP WORKSPACE &amp;&amp; cd festus &amp;&amp; bazel build //festus:ngramfinalize &amp;&amp; bazel build //festus:make-alignable-symbols &amp;&amp; bazel build //festus:fst2re &amp;&amp; bazel build //festus:fstnbinom &amp;&amp; bazel build //festus:fstrmepscycle &amp;&amp; bazel build //festus:best-labeling &amp;&amp; bazel build //festus:lexicon-diagnostics &amp;&amp; bazel build //festus:make-runtime-fsts .",
            "url": "https://jimregan.github.io/notes/docker/festus/todo/2022/02/15/festus-dockerfile.html",
            "relUrl": "/docker/festus/todo/2022/02/15/festus-dockerfile.html",
            "date": " â€¢ Feb 15, 2022"
        }
        
    
  
    
        ,"post25": {
            "title": "Running speaker diarisation with pyannote audio",
            "content": "conda install pytorch torchaudio -c pytorch conda install numpy cffi conda install libsndfile=1.0.28 -c conda-forge pip install https://github.com/pyannote/pyannote-audio/archive/develop.zip pip install speechbrain pip install pydub pip install librosa pip install ipykernel . import librosa import torch . !youtube-dl --write-sub --sub-lang &#39;sv&#39; -o &#39;%(id)s.%(ext)s&#39; j8AH29Ad-zU . from pyannote.audio import Pipeline SAMPLE = &quot;j8AH29Ad-zU.mp4&quot; pipeline = Pipeline.from_pretrained(&quot;pyannote/speaker-diarization&quot;) . audio, sr = librosa.load(SAMPLE, mono=False) audiot = torch.from_numpy(audio) diarization = pipeline({&quot;waveform&quot;: audiot, &quot;sample_rate&quot;: sr}) . [W NNPACK.cpp:79] Could not initialize NNPACK! Reason: Unsupported hardware. . diarization.uri = &#39;j8AH29Ad-zU&#39; . with open(&quot;j8AH29Ad-zU.rttm&quot;, &quot;w&quot;) as f: diarization.write_rttm(f) .",
            "url": "https://jimregan.github.io/notes/diarisation/pyannote/2022/02/07/pyannote-diarization.html",
            "relUrl": "/diarisation/pyannote/2022/02/07/pyannote-diarization.html",
            "date": " â€¢ Feb 7, 2022"
        }
        
    
  
    
        ,"post26": {
            "title": "Read Waxholm corpus",
            "content": "def fix_text(text): return text.replace(&quot;{&quot;, &quot;Ã¤&quot;).replace(&quot;}&quot;, &quot;Ã¥&quot;).replace(&quot;|&quot;, &quot;Ã¶&quot;) . TESTF = &quot;/Users/joregan/Playing/waxholm/scenes_formatted//fp2033/fp2033.6.20.smp.mix&quot; . class FR: def __init__(self, text): if not text.startswith(&quot;FR&quot;): raise IOError(&quot;Unknown line type (does not begin with &#39;FR&#39;): &quot; + text) parts = text.split(&quot; t&quot;) if len(parts) == 5: self.type = &#39;B&#39; if len(parts) == 4: self.type = &#39;I&#39; if len(parts) == 3: self.type = &#39;E&#39; if parts[1].strip() != &quot;OK&quot;: raise IOError(&quot;Unexpected line: &quot; + text) self.frame = parts[0][2:].strip() if len(parts) &gt; 3: self.phone_type = parts[1].strip()[0:1] self.phone = parts[1].strip()[1:] if not parts[2].strip().startswith(&quot;&gt;pm &quot;): raise IOError(&quot;Unexpected line: &quot; + text) self.pm_type = parts[2].strip()[4:5] self.pm = parts[2].strip()[5:] if len(parts) == 5: if not parts[3].strip().startswith(&quot;&gt;w &quot;): raise IOError(&quot;Unexpected line: &quot; + text) self.word = fix_text(parts[3].strip()[3:]) if parts[-1].strip().endswith(&quot; sec&quot;): self.seconds = parts[-1].strip()[0:-4] def __repr__(self): parts = [] parts.append(f&quot;type: {self.type}&quot;) parts.append(f&quot;frame: {self.frame}&quot;) if self.type != &#39;E&#39;: parts.append(f&quot;phone: {self.phone}&quot;) if &#39;word&#39; in self.__dict__: parts.append(f&quot;word: {self.word}&quot;) if &#39;pm_type&#39; in self.__dict__: parts.append(f&quot;pm_type: {self.pm_type}&quot;) if &#39;pm&#39; in self.__dict__: parts.append(f&quot;pm: {self.pm}&quot;) parts.append(f&quot;sec: {self.seconds}&quot;) return f&quot;FR(&quot; + &quot;, &quot;.join(parts) + &quot;)&quot; . class Mix(): def __init__(self, filepath): self.fr = [] with open(filepath) as inpf: saw_text = False saw_phoneme = False saw_labels = False for line in inpf.readlines(): if line.startswith(&quot;Waxholm dialog.&quot;): self.filepath = line[15:].strip() if line.startswith(&quot;TEXT:&quot;): saw_text = True if saw_text: self.text = fix_text(line.strip()) saw_text = False if line.startswith(&quot;FR &quot;): if saw_labels: saw_labels = False self.fr.append(FR(line)) if line.startswith(&quot;Labels: &quot;): self.labels = line[8:].strip() saw_labels = True if saw_labels and line.startswith(&quot; &quot;): self.labels += line.strip() . def smp_probe(filename): with open(filename, &quot;rb&quot;) as f: return f.read(9) == b&quot;file=samp&quot; . def smp_headers(filename): with open(filename, &quot;rb&quot;) as f: f.seek(0) raw_headers = f.read(1024) raw_headers = raw_headers.rstrip(b&#39; x00&#39;) asc_headers = raw_headers.decode(&quot;ascii&quot;) asc_headers.rstrip(&#39; x00&#39;) tmp = [a for a in asc_headers.split(&quot; r n&quot;)] back = -1 while abs(back) &gt; len(tmp) + 1: if tmp[back] == &#39;=&#39;: break back -= 1 tmp = tmp[0:back-1] return dict(a.split(&quot;=&quot;) for a in tmp) . import soundfile as sf def smp_read_sf(filename): headers = smp_headers(filename) if headers[&quot;msb&quot;] == &quot;last&quot;: ENDIAN = &quot;LITTLE&quot; else: ENDIAN = &quot;BIG&quot; data, sr = sf.read(filename, channels=int(headers[&quot;nchans&quot;]), samplerate=16000, endian=ENDIAN, start=512, dtype=&quot;int16&quot;, format=&quot;RAW&quot;, subtype=&quot;PCM_16&quot;) return (data, sr) . def write_wav(filename, arr): import wave with wave.open(filename, &quot;w&quot;) as f: f.setnchannels(1) f.setsampwidth(2) f.setframerate(16000) f.writeframes(arr) arr, sr = smp_read_sf(&quot;/Users/joregan/Playing/waxholm/scenes_formatted//fp2060/fp2060.pr.09.smp&quot;) write_wav(&quot;out.wav&quot;, arr) .",
            "url": "https://jimregan.github.io/notes/waxholm/2022/02/01/waxholm.html",
            "relUrl": "/waxholm/2022/02/01/waxholm.html",
            "date": " â€¢ Feb 1, 2022"
        }
        
    
  
    
        ,"post27": {
            "title": "Extract Riksdag videos from API",
            "content": "import requests import json . sample = requests.get(&quot;https://www.riksdagen.se/api/videostream/get/H210308&quot;) . data = json.loads(sample.text) . data[&#39;videodata&#39;][0] . def viddata_get_single_stream(videodata, hires=True): videos = [] if videodata is None: return [] if &#39;streams&#39; not in videodata: #raise Exception(&quot;videodata is missing &#39;streams&#39;&quot;) return [] if videodata[&#39;streams&#39;] is None: return [] if &#39;files&#39; not in videodata[&#39;streams&#39;]: #raise Exception(&quot;videodata[&#39;streams&#39;] is missing &#39;files&#39;&quot;) return [] if type(videodata[&#39;streams&#39;][&#39;files&#39;]) == list: for vfile in videodata[&#39;streams&#39;][&#39;files&#39;]: for bw in vfile[&#39;bandwidth&#39;]: if hires and bw[&#39;name&#39;] == &#39;HÃ¶g kvalitet&#39;: videos.append(bw[&#39;downloadurl&#39;]) elif not hires and bw[&#39;name&#39;] == &#39;LÃ¥g kvalitet&#39;: videos.append(bw[&#39;downloadurl&#39;]) else: #raise Exception(f&quot;Expected a list, got {type(videodata[&#39;streams&#39;][&#39;files&#39;])}&quot;) return [] return videos def viddata_get_streams(videodata, hires=True): output = [] if &#39;videodata&#39; not in videodata: #raise Exception(&quot;&#39;videodata&#39; missing&quot;) return [] for vdata in videodata[&#39;videodata&#39;]: output += viddata_get_single_stream(vdata, hires) return output . [] . def fix_speaker_name(name, party): if name.endswith(f&quot; ({party})&quot;): name = name[0:name.rfind(f&quot; ({party})&quot;)] return name def extract_speakers(data): speakers = [] for viddata in data[&#39;videodata&#39;]: for speaker in viddata[&#39;speakers&#39;]: speaker[&#39;text&#39;] = fix_speaker_name(speaker[&#39;text&#39;], speaker[&#39;party&#39;]) speakers.append(speaker) return speakers #print(data[&#39;videodata&#39;][0]) speakers = extract_speakers(data) viddata_get_streams(data) . viddata_get_streams(data, False) . [&#39;https://mhdownload.riksdagen.se/VOD/176288_3000_889175.mp4&#39;] . from pathlib import Path import glob urls = [] for f in glob.glob(&#39;**&#39;): fpath = Path(f) if not fpath.is_file(): continue with open(f) as inf: data = json.load(inf) for url in viddata_get_streams(data): urls.append(url) .",
            "url": "https://jimregan.github.io/notes/riksdag/speech/2022/01/31/extract-riksdag-videos-from-api.html",
            "relUrl": "/riksdag/speech/2022/01/31/extract-riksdag-videos-from-api.html",
            "date": " â€¢ Jan 31, 2022"
        }
        
    
  
    
        ,"post28": {
            "title": "Interesting links, 23/01/2022",
            "content": "data2vec, paper, code . r/panelshows . jik876/hifi-gan . Hindi TTS demo space . Open-Speech-EkStep/vakyansh-tts . mjansche/ctc_sampling . X-SAMPA to IPA converter . Lexin multilingual dictionary, data . Sprakbanken_Swe lexicon . clean_and_segment_data.sh . DT2112 . BostadsfÃ¶rmedlingen i Stockholm AB . Continual learning using lattice-free MMI for speech recognition .",
            "url": "https://jimregan.github.io/notes/links/2022/01/23/misc-links.html",
            "relUrl": "/links/2022/01/23/misc-links.html",
            "date": " â€¢ Jan 23, 2022"
        }
        
    
  
    
        ,"post29": {
            "title": "Fix NST lexicon accents",
            "content": "_VOWELS = [ &quot;}:&quot;, &quot;2:&quot;, &quot;9&quot;, &quot;a&quot;, &quot;a*U&quot;, &quot;A:&quot;, &quot;e&quot;, &quot;E&quot;, &quot;E*U&quot;, &quot;e:&quot;, &quot;E:&quot;, &quot;I&quot;, &quot;i:&quot;, &quot;O&quot;, &quot;o:&quot;, &quot;U&quot;, &quot;u:&quot;, &quot;u0&quot;, &quot;Y&quot;, &quot;y:&quot; ] . _SAMPLE = &quot;&quot;&quot; AFTENPOSTEN &quot;a f t e n %p O s t e n AFTONBLADET &quot;a f t O n %b l A: d e t AFTONBLADETS &quot;a f t O n %b l A: d e t s AFTONBRISVÃ„GEN &quot;a f t O n b r i: s %v E: g e n AFTONGATAN &quot;a f t O N %g A: t a n AFTONVÃ„GEN &quot;a f t O n %v E: g e n AFZELIIVÃ„GEN a f &quot;s e: l I %v E: g e n AFZELIUS a f &quot;s e: l I u0 s AGADIR a g a &quot;d i: r AGAMEMNON a g a &quot;m E m n O n AGARD &quot;A: g a d` AGARDH &quot;A: g a d` AGARDHSGATAN &quot;A: g a d` s` %g A: t a n AGARDSSON &quot;A: g a d` s` O n AGASSI a &quot;g a s I AGASSIS a &quot;g a s I s AGATA a &quot;g A: t a AGATAS a &quot;g A: t a s &quot;&quot;&quot; . def split_phone(inphone): _STRESSMARKS = [&#39;&quot;&quot;&#39;, &#39;&quot;&#39;, &#39;%&#39;] outmark = &#39;&#39; outphone = inphone for sm in _STRESSMARKS: if inphone.startswith(sm): outmark = sm outphone = inphone.replace(sm, &#39;&#39;) return (outmark, outphone) . out_words = [] for line in _SAMPLE.split(&#39; n&#39;): if line == &#39;&#39;: continue phones_out = [] parts = line.split(&#39; t&#39;) assert len(parts) == 2 current_mark = &#39;&#39; for phone in parts[1].split(&#39; &#39;): tmp_mark, actual_phone = split_phone(phone) if tmp_mark != &#39;&#39;: current_mark = tmp_mark if actual_phone in _VOWELS and current_mark != &#39;&#39;: phones_out.append(current_mark + actual_phone) current_mark = &#39;&#39; else: phones_out.append(actual_phone) new_phones = &#39; &#39;.join(phones_out) out_words.append(f&quot;{parts[0]} t{new_phones}&quot;) . out_words . [&#39;AFTENPOSTEN t&#34;a f t e n p %O s t e n&#39;, &#39;AFTONBLADET t&#34;a f t O n b l %A: d e t&#39;, &#39;AFTONBLADETS t&#34;a f t O n b l %A: d e t s&#39;, &#39;AFTONBRISVÃ„GEN t&#34;a f t O n b r i: s v %E: g e n&#39;, &#39;AFTONGATAN t&#34;a f t O N g %A: t a n&#39;, &#39;AFTONVÃ„GEN t&#34;a f t O n v %E: g e n&#39;, &#39;AFZELIIVÃ„GEN ta f s &#34;e: l I v %E: g e n&#39;, &#39;AFZELIUS ta f s &#34;e: l I u0 s&#39;, &#39;AGADIR ta g a d &#34;i: r&#39;, &#39;AGAMEMNON ta g a m &#34;E m n O n&#39;, &#39;AGARD t&#34;A: g a d`&#39;, &#39;AGARDH t&#34;A: g a d`&#39;, &#39;AGARDHSGATAN t&#34;A: g a d` s` g %A: t a n&#39;, &#39;AGARDSSON t&#34;A: g a d` s` O n&#39;, &#39;AGASSI ta g &#34;a s I&#39;, &#39;AGASSIS ta g &#34;a s I s&#39;, &#39;AGATA ta g &#34;A: t a&#39;, &#39;AGATAS ta g &#34;A: t a s&#39;] .",
            "url": "https://jimregan.github.io/notes/g2p/nst/2022/01/20/swe-lexicon-fix-accents.html",
            "relUrl": "/g2p/nst/2022/01/20/swe-lexicon-fix-accents.html",
            "date": " â€¢ Jan 20, 2022"
        }
        
    
  
    
        ,"post30": {
            "title": "Sweachum reader",
            "content": "SAMPLE = &quot;&quot;&quot; &lt;corpus id=&quot;sweachum&quot;&gt; &lt;text datefrom=&quot;20120101&quot; dateto=&quot;20121231&quot; timefrom=&quot;000000&quot; timeto=&quot;235959&quot; lix=&quot;55.44&quot; ovix=&quot;65.03&quot; nk=&quot;2.01&quot; subject=&quot;Filosofi&quot; type=&quot;PhD&quot; date=&quot;2012&quot;&gt; &lt;sentence id=&quot;b60ceaf85-b604d04ed&quot; _geocontext=&quot;|&quot;&gt; &lt;ne ex=&quot;ENAMEX&quot; type=&quot;PRS&quot; subtype=&quot;HUM&quot; name=&quot;Marton&quot;&gt; &lt;w pos=&quot;PM&quot; msd=&quot;PM.NOM&quot; lemma=&quot;|&quot; lex=&quot;|&quot; sense=&quot;|&quot; prefix=&quot;|&quot; suffix=&quot;|&quot; compwf=&quot;|&quot; complemgram=&quot;|&quot; ref=&quot;01&quot; deprel=&quot;ROOT&quot;&gt;Marton&lt;/w&gt; &lt;/ne&gt; &lt;w pos=&quot;MID&quot; msd=&quot;MID&quot; lemma=&quot;|&quot; lex=&quot;|&quot; sense=&quot;|&quot; prefix=&quot;|&quot; suffix=&quot;|&quot; compwf=&quot;|&quot; complemgram=&quot;|&quot; ref=&quot;02&quot; dephead=&quot;01&quot; deprel=&quot;IK&quot;&gt;,&lt;/w&gt; &lt;w pos=&quot;PM&quot; msd=&quot;PM.NOM&quot; lemma=&quot;|&quot; lex=&quot;|&quot; sense=&quot;|&quot; prefix=&quot;|&quot; suffix=&quot;|&quot; compwf=&quot;|&quot; complemgram=&quot;|&quot; ref=&quot;03&quot; dephead=&quot;01&quot; deprel=&quot;ET&quot;&gt;F.&lt;/w&gt; &lt;w pos=&quot;KN&quot; msd=&quot;KN.AN&quot; lemma=&quot;|&amp;amp;|&quot; lex=&quot;|o..kna.2|&quot; sense=&quot;|och..1:-1.000|&quot; prefix=&quot;|&quot; suffix=&quot;|&quot; compwf=&quot;|&quot; complemgram=&quot;|&quot; ref=&quot;04&quot; dephead=&quot;03&quot; deprel=&quot;HD&quot;&gt;&amp;amp;&lt;/w&gt; &lt;w pos=&quot;NN&quot; msd=&quot;NN.UTR.SIN.IND.NOM&quot; lemma=&quot;|&quot; lex=&quot;|&quot; sense=&quot;|&quot; prefix=&quot;|&quot; suffix=&quot;|&quot; compwf=&quot;|&quot; complemgram=&quot;|&quot; ref=&quot;05&quot; dephead=&quot;03&quot; deprel=&quot;HD&quot;&gt;amp&lt;/w&gt; &lt;w pos=&quot;MID&quot; msd=&quot;MID&quot; lemma=&quot;|&quot; lex=&quot;|&quot; sense=&quot;|&quot; prefix=&quot;|&quot; suffix=&quot;|&quot; compwf=&quot;|&quot; complemgram=&quot;|&quot; ref=&quot;06&quot; dephead=&quot;01&quot; deprel=&quot;IS&quot;&gt;;&lt;/w&gt; &lt;w pos=&quot;PM&quot; msd=&quot;PM.NOM&quot; lemma=&quot;|&quot; lex=&quot;|&quot; sense=&quot;|&quot; prefix=&quot;|&quot; suffix=&quot;|&quot; compwf=&quot;|&quot; complemgram=&quot;|&quot; ref=&quot;07&quot; dephead=&quot;01&quot; deprel=&quot;AN&quot;&gt;Booth&lt;/w&gt; &lt;w pos=&quot;MID&quot; msd=&quot;MID&quot; lemma=&quot;|&quot; lex=&quot;|&quot; sense=&quot;|&quot; prefix=&quot;|&quot; suffix=&quot;|&quot; compwf=&quot;|&quot; complemgram=&quot;|&quot; ref=&quot;08&quot; dephead=&quot;07&quot; deprel=&quot;IK&quot;&gt;,&lt;/w&gt; &lt;w pos=&quot;PM&quot; msd=&quot;PM.NOM&quot; lemma=&quot;|&quot; lex=&quot;|&quot; sense=&quot;|&quot; prefix=&quot;|&quot; suffix=&quot;|&quot; compwf=&quot;|&quot; complemgram=&quot;|&quot; ref=&quot;09&quot; dephead=&quot;07&quot; deprel=&quot;ET&quot;&gt;S&lt;/w&gt; &lt;w pos=&quot;MAD&quot; msd=&quot;MAD&quot; lemma=&quot;|&quot; lex=&quot;|&quot; sense=&quot;|&quot; prefix=&quot;|&quot; suffix=&quot;|&quot; compwf=&quot;|&quot; complemgram=&quot;|&quot; ref=&quot;10&quot; dephead=&quot;01&quot; deprel=&quot;IP&quot;&gt;.&lt;/w&gt; &lt;/sentence&gt; &lt;/text&gt; &lt;/corpus&gt; &quot;&quot;&quot; . Corpus is here, CC BY 4.0 . import xml.etree.ElementTree as ET import xml.sax.saxutils as saxutils import io . source = io.StringIO(SAMPLE) tree = ET.parse(source) root = tree.getroot() . words = [] for word in root.findall(&#39;.//w&#39;): words.append(word.text.strip()) . words . [&#39;Marton&#39;, &#39;,&#39;, &#39;F.&#39;, &#39;&amp;&#39;, &#39;amp&#39;, &#39;;&#39;, &#39;Booth&#39;, &#39;,&#39;, &#39;S&#39;, &#39;.&#39;] . def _clean_amps(inlist): htmlamp = [&#39;&amp;&#39;, &#39;amp&#39;, &#39;;&#39;] outlist = [] i = 0 while i &lt; len(inlist): if inlist[i:i+3] == htmlamp: outlist.append(&#39;&amp;&#39;) i += 3 continue else: outlist.append(inlist[i]) i += 1 return outlist . _clean_amps(words) . [&#39;Marton&#39;, &#39;,&#39;, &#39;F.&#39;, &#39;&amp;&#39;, &#39;Booth&#39;, &#39;,&#39;, &#39;S&#39;, &#39;.&#39;] . def _get_or_blank(text): if text == &quot;|&quot;: return &quot;&quot; if text[0:1] == &quot;|&quot; and text[-1:] == &quot;|&quot;: text = text[1:-1] return text class Word(): def __init__(self, text, pos, msd, lemma, lex, sense, prefix, suffix, compwf, complemgram, ref, dephead, deprel): self.text = text self.pos = _get_or_blank(pos) self.msd = _get_or_blank(msd) self.lex = _get_or_blank(lex) .",
            "url": "https://jimregan.github.io/notes/sweachum/corpus/2022/01/10/sweachum.html",
            "relUrl": "/sweachum/corpus/2022/01/10/sweachum.html",
            "date": " â€¢ Jan 10, 2022"
        }
        
    
  
    
        ,"post31": {
            "title": "Clean Irish text",
            "content": "def _ga_lc_word(text): if text[0:1] in &quot;nt&quot; and text[1:2] in &quot;AÃEÃ‰IÃOÃ“UÃš&quot;: return text[0:1] + &quot;-&quot; + text[1:].lower() else: return text.lower() def ga_lower(text): words = [_ga_lc_word(word) for word in text.split()] return &quot; &quot;.join(words) . test = &quot;Cuairt an tAthair&quot; assert ga_lower(test) == &quot;cuairt an t-athair&quot; . import re def clean_text(text): # keep only word-internal apostrophes text = re.sub(&quot;^&#39;+&quot;, &quot;&quot;, text) text = re.sub(&quot;[&#39;]+$&quot;, &quot;&quot;, text) text = text.replace(&quot;&#39; &quot;, &quot; &quot;).replace(&quot; &#39;&quot;, &quot; &quot;) text = text.replace(&quot;â€™&quot;, &quot;&#39;&quot;) text = re.sub(&quot;[â€˜â€œâ€ &quot; ( ) [ ] { }]&quot;, &quot;&quot;, text) # keep punctuation that can correspond to silence text = re.sub(&quot;([,; .!?])&quot;, &quot; 1&quot;, text) # leave spaced hyphens, which also can be silences, except at EOS text = re.sub(&quot; -$&quot;, &quot;&quot;, text) return ga_lower(text) . test = &quot;&#39;cuairt (an) â€œtAthairâ€&#39;&#39;&quot; assert clean_text(test) == &quot;cuairt an t-athair&quot; . test = &quot;&#39;cuairt, (an) â€œtAthairâ€!&quot; assert clean_text(test) == &quot;cuairt , an t-athair !&quot; . test = &quot;&#39;cuairt, (an) â€œtAthairâ€! -&quot; assert clean_text(test) == &quot;cuairt , an t-athair !&quot; . Actually using it. . from pathlib import Path . OUT = Path(&quot;&lt;SNIP&gt;&quot;) SRC = Path(&quot;&lt;SNIP&gt;&quot;) . for filename in SRC.glob(&quot;*.txt&quot;): base = filename.stem wav = OUT / f&quot;{base}.wav&quot; if wav.is_file(): out = OUT / f&quot;{base}.txt&quot; with open(out, &quot;w&quot;) as outf, open(filename) as inf: text = inf.read() clean = clean_text(text) outf.write(clean) .",
            "url": "https://jimregan.github.io/notes/irish/cleaning/alignment/2021/12/06/clean-irish-for-mfa-with-silences.html",
            "relUrl": "/irish/cleaning/alignment/2021/12/06/clean-irish-for-mfa-with-silences.html",
            "date": " â€¢ Dec 6, 2021"
        }
        
    
  
    
        ,"post32": {
            "title": "NER with gaELECTRA",
            "content": "This is a lightly edited version of this notebook. . If you&#39;re opening this Notebook on colab, you will probably need to install ðŸ¤— Transformers and ðŸ¤— Datasets. Uncomment the following cell and run it. . %%capture !pip install datasets transformers seqeval . If you&#39;re opening this notebook locally, make sure your environment has an install from the last version of those libraries. . To be able to share your model with the community and generate results like the one shown in the picture below via the inference API, there are a few more steps to follow. . First you have to store your authentication token from the Hugging Face website (sign up here if you haven&#39;t already!) then execute the following cell and input your username and password: . (Huggingface notebooks skip this bit, but you need to set credential.helper before anything else works). . !git config --global credential.helper store . from huggingface_hub import notebook_login notebook_login() . Login successful Your token has been saved to /root/.huggingface/token . Then you need to install Git-LFS. Uncomment the following instructions: . !apt install git-lfs . Reading package lists... Done Building dependency tree Reading state information... Done git-lfs is already the newest version (2.3.4-1). 0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded. . Make sure your version of Transformers is at least 4.11.0 since the functionality was introduced in that version: . import transformers print(transformers.__version__) . 4.12.5 . You can find a script version of this notebook to fine-tune your model in a distributed fashion using multiple GPUs or TPUs here. . Fine-tuning a model on a token classification task . In this notebook, we will see how to fine-tune one of the ðŸ¤— Transformers model to a token classification task, which is the task of predicting a label for each token. . . The most common token classification tasks are: . NER (Named-entity recognition) Classify the entities in the text (person, organization, location...). | POS (Part-of-speech tagging) Grammatically classify the tokens (noun, verb, adjective...) | Chunk (Chunking) Grammatically classify the tokens and group them into &quot;chunks&quot; that go together | . We will see how to easily load a dataset for these kinds of tasks and use the Trainer API to fine-tune a model on it. . This notebook is built to run on any token classification task, with any model checkpoint from the Model Hub as long as that model has a version with a token classification head and a fast tokenizer (check on this table if this is the case). It might just need some small adjustments if you decide to use a different dataset than the one used here. Depending on you model and the GPU you are using, you might need to adjust the batch size to avoid out-of-memory errors. Set those three parameters, then the rest of the notebook should run smoothly: . task = &quot;ner&quot; # Should be one of &quot;ner&quot;, &quot;pos&quot; or &quot;chunk&quot; model_checkpoint = &quot;DCU-NLP/electra-base-irish-cased-generator-v1&quot; batch_size = 16 . Loading the dataset . We will use the ðŸ¤— Datasets library to download the data and get the metric we need to use for evaluation (to compare our model to the benchmark). This can be easily done with the functions load_dataset and load_metric. . from datasets import load_dataset, load_metric . For our example here, we&#39;ll use the CONLL 2003 dataset. The notebook should work with any token classification dataset provided by the ðŸ¤— Datasets library. If you&#39;re using your own dataset defined from a JSON or csv file (see the Datasets documentation on how to load them), it might need some adjustments in the names of the columns used. . datasets = load_dataset(&quot;wikiann&quot;, &quot;ga&quot;) . Reusing dataset wikiann (/root/.cache/huggingface/datasets/wikiann/ga/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e) . The datasets object itself is DatasetDict, which contains one key for the training, validation and test set. . datasets . DatasetDict({ validation: Dataset({ features: [&#39;tokens&#39;, &#39;ner_tags&#39;, &#39;langs&#39;, &#39;spans&#39;], num_rows: 1000 }) test: Dataset({ features: [&#39;tokens&#39;, &#39;ner_tags&#39;, &#39;langs&#39;, &#39;spans&#39;], num_rows: 1000 }) train: Dataset({ features: [&#39;tokens&#39;, &#39;ner_tags&#39;, &#39;langs&#39;, &#39;spans&#39;], num_rows: 1000 }) }) . We can see the training, validation and test sets all have a column for the tokens (the input texts split into words) and one column of labels for each kind of task we introduced before. . To access an actual element, you need to select a split first, then give an index: . datasets[&quot;train&quot;][0] . {&#39;langs&#39;: [&#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;], &#39;ner_tags&#39;: [0, 1, 2, 2, 0, 0, 0, 0, 5, 0, 0, 0], &#39;spans&#39;: [&#39;PER: PÃ¡draig Mac Piarais&#39;, &#39;LOC: Ã‰ireannach&#39;], &#39;tokens&#39;: [&#39;**&#39;, &#39;PÃ¡draig&#39;, &#39;Mac&#39;, &#39;Piarais&#39;, &#39;,&#39;, &#39;36&#39;, &#39;,&#39;, &#39;rÃ©abhlÃ³idÃ­&#39;, &#39;Ã‰ireannach&#39;, &#39;agus&#39;, &#39;[[file&#39;, &#39;.&#39;]} . The labels are already coded as integer ids to be easily usable by our model, but the correspondence with the actual categories is stored in the features of the dataset: . datasets[&quot;train&quot;].features[f&quot;ner_tags&quot;] . Sequence(feature=ClassLabel(num_classes=7, names=[&#39;O&#39;, &#39;B-PER&#39;, &#39;I-PER&#39;, &#39;B-ORG&#39;, &#39;I-ORG&#39;, &#39;B-LOC&#39;, &#39;I-LOC&#39;], names_file=None, id=None), length=-1, id=None) . So for the NER tags, 0 corresponds to &#39;O&#39;, 1 to &#39;B-PER&#39; etc... On top of the &#39;O&#39; (which means no special entity), there are four labels for NER here, each prefixed with &#39;B-&#39; (for beginning) or &#39;I-&#39; (for intermediate), that indicate if the token is the first one for the current group with the label or not: . &#39;PER&#39; for person | &#39;ORG&#39; for organization | &#39;LOC&#39; for location | &#39;MISC&#39; for miscellaneous | . Since the labels are lists of ClassLabel, the actual names of the labels are nested in the feature attribute of the object above: . label_list = datasets[&quot;train&quot;].features[f&quot;{task}_tags&quot;].feature.names label_list . [&#39;O&#39;, &#39;B-PER&#39;, &#39;I-PER&#39;, &#39;B-ORG&#39;, &#39;I-ORG&#39;, &#39;B-LOC&#39;, &#39;I-LOC&#39;] . To get a sense of what the data looks like, the following function will show some examples picked randomly in the dataset (automatically decoding the labels in passing). . from datasets import ClassLabel, Sequence import random import pandas as pd from IPython.display import display, HTML def show_random_elements(dataset, num_examples=10): assert num_examples &lt;= len(dataset), &quot;Can&#39;t pick more elements than there are in the dataset.&quot; picks = [] for _ in range(num_examples): pick = random.randint(0, len(dataset)-1) while pick in picks: pick = random.randint(0, len(dataset)-1) picks.append(pick) df = pd.DataFrame(dataset[picks]) for column, typ in dataset.features.items(): if isinstance(typ, ClassLabel): df[column] = df[column].transform(lambda i: typ.names[i]) elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel): df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x]) display(HTML(df.to_html())) . show_random_elements(datasets[&quot;train&quot;]) . tokens ner_tags langs spans . 0 [Burghley, House, ,, Belton, House] | [B-ORG, I-ORG, O, B-ORG, I-ORG] | [ga, ga, ga, ga, ga] | [ORG: Burghley House, ORG: Belton House] | . 1 [Ollscoil, Chathair, Bhaile, Ãtha, Cliath] | [B-ORG, I-ORG, I-ORG, I-ORG, I-ORG] | [ga, ga, ga, ga, ga] | [ORG: Ollscoil Chathair Bhaile Ãtha Cliath] | . 2 [DÃºchasach, do, rÃ©igiÃºn, na, MeÃ¡nmhara, .] | [O, O, O, B-LOC, I-LOC, O] | [ga, ga, ga, ga, ga, ga] | [LOC: na MeÃ¡nmhara] | . 3 [PÃ¡irc, an, ChrÃ³caigh, ,, Baile, Ãtha, Cliath] | [B-ORG, I-ORG, I-ORG, O, B-LOC, I-LOC, I-LOC] | [ga, ga, ga, ga, ga, ga, ga] | [ORG: PÃ¡irc an ChrÃ³caigh, LOC: Baile Ãtha Cliath] | . 4 [TrÃ¡igh, MhÃ³r, ,, An, Tuirc] | [B-ORG, I-ORG, O, B-LOC, I-LOC] | [ga, ga, ga, ga, ga] | [ORG: TrÃ¡igh MhÃ³r, LOC: An Tuirc] | . 5 [BhÃ­, turas, An, RÃ­ocht, Aontaithe, agus, Ã‰ire, acu, Ã³n, Eanair, go, dtÃ­, mBealtaine, .] | [O, O, B-LOC, I-LOC, I-LOC, O, B-LOC, O, O, O, O, O, O, O] | [ga, ga, ga, ga, ga, ga, ga, ga, ga, ga, ga, ga, ga, ga] | [LOC: An RÃ­ocht Aontaithe, LOC: Ã‰ire] | . 6 [TÃ¡, an, staid, tÃ³gtha, ar, shuÃ­omh, BhÃ³thair, LansdÃºin, .] | [O, O, O, O, O, O, B-ORG, I-ORG, O] | [ga, ga, ga, ga, ga, ga, ga, ga, ga] | [ORG: BhÃ³thair LansdÃºin] | . 7 [athsheoladh, PÃ³l, I, na, RÃºise] | [O, B-PER, I-PER, I-PER, I-PER] | [ga, ga, ga, ga, ga] | [PER: PÃ³l I na RÃºise] | . 8 [Liam, Ã“, Leathlobhair] | [B-PER, I-PER, I-PER] | [ga, ga, ga] | [PER: Liam Ã“ Leathlobhair] | . 9 [athsheoladh, SÃ©amas, II, Shasana] | [O, B-PER, I-PER, I-PER] | [ga, ga, ga, ga] | [PER: SÃ©amas II Shasana] | . Preprocessing the data . Before we can feed those texts to our model, we need to preprocess them. This is done by a ðŸ¤— Transformers Tokenizer which will (as the name indicates) tokenize the inputs (including converting the tokens to their corresponding IDs in the pretrained vocabulary) and put it in a format the model expects, as well as generate the other inputs that model requires. . To do all of this, we instantiate our tokenizer with the AutoTokenizer.from_pretrained method, which will ensure: . we get a tokenizer that corresponds to the model architecture we want to use, | we download the vocabulary used when pretraining this specific checkpoint. | . That vocabulary will be cached, so it&#39;s not downloaded again the next time we run the cell. . from transformers import AutoTokenizer tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_space=True) . loading configuration file https://huggingface.co/DCU-NLP/electra-base-irish-cased-generator-v1/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/5239b8cd72f5caa8610a21bf2b225bb65fe3529da8491628fe2fb57a9feb5807.f9336c0d71d0b04cbbee5746d7d5e3444a26fcf7a3ff5262d8e655443181d939 Model config ElectraConfig { &#34;architectures&#34;: [ &#34;ElectraForMaskedLM&#34; ], &#34;attention_probs_dropout_prob&#34;: 0.1, &#34;classifier_dropout&#34;: null, &#34;embedding_size&#34;: 768, &#34;hidden_act&#34;: &#34;gelu&#34;, &#34;hidden_dropout_prob&#34;: 0.1, &#34;hidden_size&#34;: 256, &#34;initializer_range&#34;: 0.02, &#34;intermediate_size&#34;: 1024, &#34;layer_norm_eps&#34;: 1e-12, &#34;max_position_embeddings&#34;: 512, &#34;model_type&#34;: &#34;electra&#34;, &#34;num_attention_heads&#34;: 4, &#34;num_hidden_layers&#34;: 12, &#34;pad_token_id&#34;: 0, &#34;position_embedding_type&#34;: &#34;absolute&#34;, &#34;summary_activation&#34;: &#34;gelu&#34;, &#34;summary_last_dropout&#34;: 0.1, &#34;summary_type&#34;: &#34;first&#34;, &#34;summary_use_proj&#34;: true, &#34;transformers_version&#34;: &#34;4.12.5&#34;, &#34;type_vocab_size&#34;: 2, &#34;use_cache&#34;: true, &#34;vocab_size&#34;: 30101 } https://huggingface.co/DCU-NLP/electra-base-irish-cased-generator-v1/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp2i5o9fje storing https://huggingface.co/DCU-NLP/electra-base-irish-cased-generator-v1/resolve/main/vocab.txt in cache at /root/.cache/huggingface/transformers/212cfff55e4717258e776a1735350b6b4f369ab225dfe43bc9e68b77fe83d013.45aeed8a99309e07fa03353cdc46e256411be991056eacba22ce6491dc8cd515 creating metadata file for /root/.cache/huggingface/transformers/212cfff55e4717258e776a1735350b6b4f369ab225dfe43bc9e68b77fe83d013.45aeed8a99309e07fa03353cdc46e256411be991056eacba22ce6491dc8cd515 loading file https://huggingface.co/DCU-NLP/electra-base-irish-cased-generator-v1/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/212cfff55e4717258e776a1735350b6b4f369ab225dfe43bc9e68b77fe83d013.45aeed8a99309e07fa03353cdc46e256411be991056eacba22ce6491dc8cd515 loading file https://huggingface.co/DCU-NLP/electra-base-irish-cased-generator-v1/resolve/main/tokenizer.json from cache at None loading file https://huggingface.co/DCU-NLP/electra-base-irish-cased-generator-v1/resolve/main/added_tokens.json from cache at None loading file https://huggingface.co/DCU-NLP/electra-base-irish-cased-generator-v1/resolve/main/special_tokens_map.json from cache at None loading file https://huggingface.co/DCU-NLP/electra-base-irish-cased-generator-v1/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/a6f921ced163632560dda531384ca2933ff36b280e3b91dc14e25d76d3da8449.c70618325b9fc2d2d041e439766d360b48a086a8841cc2896322f6b8aefc0225 loading configuration file https://huggingface.co/DCU-NLP/electra-base-irish-cased-generator-v1/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/5239b8cd72f5caa8610a21bf2b225bb65fe3529da8491628fe2fb57a9feb5807.f9336c0d71d0b04cbbee5746d7d5e3444a26fcf7a3ff5262d8e655443181d939 Model config ElectraConfig { &#34;architectures&#34;: [ &#34;ElectraForMaskedLM&#34; ], &#34;attention_probs_dropout_prob&#34;: 0.1, &#34;classifier_dropout&#34;: null, &#34;embedding_size&#34;: 768, &#34;hidden_act&#34;: &#34;gelu&#34;, &#34;hidden_dropout_prob&#34;: 0.1, &#34;hidden_size&#34;: 256, &#34;initializer_range&#34;: 0.02, &#34;intermediate_size&#34;: 1024, &#34;layer_norm_eps&#34;: 1e-12, &#34;max_position_embeddings&#34;: 512, &#34;model_type&#34;: &#34;electra&#34;, &#34;num_attention_heads&#34;: 4, &#34;num_hidden_layers&#34;: 12, &#34;pad_token_id&#34;: 0, &#34;position_embedding_type&#34;: &#34;absolute&#34;, &#34;summary_activation&#34;: &#34;gelu&#34;, &#34;summary_last_dropout&#34;: 0.1, &#34;summary_type&#34;: &#34;first&#34;, &#34;summary_use_proj&#34;: true, &#34;transformers_version&#34;: &#34;4.12.5&#34;, &#34;type_vocab_size&#34;: 2, &#34;use_cache&#34;: true, &#34;vocab_size&#34;: 30101 } loading configuration file https://huggingface.co/DCU-NLP/electra-base-irish-cased-generator-v1/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/5239b8cd72f5caa8610a21bf2b225bb65fe3529da8491628fe2fb57a9feb5807.f9336c0d71d0b04cbbee5746d7d5e3444a26fcf7a3ff5262d8e655443181d939 Model config ElectraConfig { &#34;architectures&#34;: [ &#34;ElectraForMaskedLM&#34; ], &#34;attention_probs_dropout_prob&#34;: 0.1, &#34;classifier_dropout&#34;: null, &#34;embedding_size&#34;: 768, &#34;hidden_act&#34;: &#34;gelu&#34;, &#34;hidden_dropout_prob&#34;: 0.1, &#34;hidden_size&#34;: 256, &#34;initializer_range&#34;: 0.02, &#34;intermediate_size&#34;: 1024, &#34;layer_norm_eps&#34;: 1e-12, &#34;max_position_embeddings&#34;: 512, &#34;model_type&#34;: &#34;electra&#34;, &#34;num_attention_heads&#34;: 4, &#34;num_hidden_layers&#34;: 12, &#34;pad_token_id&#34;: 0, &#34;position_embedding_type&#34;: &#34;absolute&#34;, &#34;summary_activation&#34;: &#34;gelu&#34;, &#34;summary_last_dropout&#34;: 0.1, &#34;summary_type&#34;: &#34;first&#34;, &#34;summary_use_proj&#34;: true, &#34;transformers_version&#34;: &#34;4.12.5&#34;, &#34;type_vocab_size&#34;: 2, &#34;use_cache&#34;: true, &#34;vocab_size&#34;: 30101 } . The following assertion ensures that our tokenizer is a fast tokenizers (backed by Rust) from the ðŸ¤— Tokenizers library. Those fast tokenizers are available for almost all models, and we will need some of the special features they have for our preprocessing. . import transformers assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast) . You can check which type of models have a fast tokenizer available and which don&#39;t on the big table of models. . You can directly call this tokenizer on one sentence: . tokenizer(&quot;Is abairt amhÃ¡in Ã© seo!&quot;) . {&#39;input_ids&#39;: [102, 311, 3280, 556, 186, 222, 711, 103], &#39;token_type_ids&#39;: [0, 0, 0, 0, 0, 0, 0, 0], &#39;attention_mask&#39;: [1, 1, 1, 1, 1, 1, 1, 1]} . Depending on the model you selected, you will see different keys in the dictionary returned by the cell above. They don&#39;t matter much for what we&#39;re doing here (just know they are required by the model we will instantiate later), you can learn more about them in this tutorial if you&#39;re interested. . If, as is the case here, your inputs have already been split into words, you should pass the list of words to your tokenzier with the argument is_split_into_words=True: . tokenizer([&quot;Hello&quot;, &quot;,&quot;, &quot;this&quot;, &quot;is&quot;, &quot;one&quot;, &quot;sentence&quot;, &quot;split&quot;, &quot;into&quot;, &quot;words&quot;, &quot;.&quot;], is_split_into_words=True) . {&#39;input_ids&#39;: [102, 6148, 855, 116, 8536, 198, 13064, 25549, 4666, 333, 19211, 209, 12322, 19942, 29909, 118, 103], &#39;token_type_ids&#39;: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], &#39;attention_mask&#39;: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} . Note that transformers are often pretrained with subword tokenizers, meaning that even if your inputs have been split into words already, each of those words could be split again by the tokenizer. Let&#39;s look at an example of that: . example = datasets[&quot;train&quot;][4] print(example[&quot;tokens&quot;]) . [&#39;TÃ¡&#39;, &#39;Ãras&#39;, &#39;an&#39;, &#39;UachtarÃ¡in&#39;, &#39;(&#39;, &#39;Ã¡it&#39;, &#39;chÃ³naithe&#39;, &#39;oifigiÃºil&#39;, &#39;UachtarÃ¡n&#39;, &#39;na&#39;, &#39;hÃ‰ireann&#39;, &#39;)&#39;, &#39;,&#39;, &#34;&#39;&#39;Deerfield&#34;, &#34;&#39;&#39;&#34;, &#39;(&#39;, &#39;Ã¡it&#39;, &#39;chÃ³naithe&#39;, &#39;oifigiÃºil&#39;, &#39;AmbasadÃ³ir&#39;, &#39;StÃ¡it&#39;, &#39;Aontaithe&#39;, &#39;MheiriceÃ¡&#39;, &#39;)&#39;, &#39;,&#39;, &#39;ZÃº&#39;, &#39;Bhaile&#39;, &#39;Ãtha&#39;, &#39;Cliath&#39;, &#39;,&#39;, &#39;agus&#39;, &#39;CeanncheathrÃº&#39;, &#39;an&#39;, &#39;Gharda&#39;, &#39;SÃ­ochÃ¡na&#39;, &#39;go&#39;, &#39;lÃ©ir&#39;, &#39;laistigh&#39;, &#39;den&#39;, &#39;phÃ¡irc&#39;, &#39;.&#39;] . tokenized_input = tokenizer(example[&quot;tokens&quot;], is_split_into_words=True) tokens = tokenizer.convert_ids_to_tokens(tokenized_input[&quot;input_ids&quot;]) print(tokens) . [&#39;[CLS]&#39;, &#39;TÃ¡&#39;, &#39;Ãras&#39;, &#39;an&#39;, &#39;UachtarÃ¡in&#39;, &#39;(&#39;, &#39;Ã¡it&#39;, &#39;chÃ³naithe&#39;, &#39;oifigiÃºil&#39;, &#39;UachtarÃ¡n&#39;, &#39;na&#39;, &#39;hÃ‰ireann&#39;, &#39;)&#39;, &#39;,&#39;, &#34;&#39;&#34;, &#34;&#39;&#34;, &#39;De&#39;, &#39;##er&#39;, &#39;##field&#39;, &#34;&#39;&#34;, &#34;&#39;&#34;, &#39;(&#39;, &#39;Ã¡it&#39;, &#39;chÃ³naithe&#39;, &#39;oifigiÃºil&#39;, &#39;AmbasadÃ³ir&#39;, &#39;StÃ¡it&#39;, &#39;Aontaithe&#39;, &#39;MheiriceÃ¡&#39;, &#39;)&#39;, &#39;,&#39;, &#39;Z&#39;, &#39;##Ãº&#39;, &#39;Bhaile&#39;, &#39;Ãtha&#39;, &#39;Cliath&#39;, &#39;,&#39;, &#39;agus&#39;, &#39;CeanncheathrÃº&#39;, &#39;an&#39;, &#39;Gharda&#39;, &#39;SÃ­ochÃ¡na&#39;, &#39;go&#39;, &#39;lÃ©ir&#39;, &#39;laistigh&#39;, &#39;den&#39;, &#39;phÃ¡irc&#39;, &#39;.&#39;, &#39;[SEP]&#39;] . Here the words &quot;Zwingmann&quot; and &quot;sheepmeat&quot; have been split in three subtokens. . This means that we need to do some processing on our labels as the input ids returned by the tokenizer are longer than the lists of labels our dataset contain, first because some special tokens might be added (we can a [CLS] and a [SEP] above) and then because of those possible splits of words in multiple tokens: . len(example[f&quot;{task}_tags&quot;]), len(tokenized_input[&quot;input_ids&quot;]) . (41, 49) . Thankfully, the tokenizer returns outputs that have a word_ids method which can help us. . print(tokenized_input.word_ids()) . [None, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 13, 13, 13, 13, 14, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, None] . As we can see, it returns a list with the same number of elements as our processed input ids, mapping special tokens to None and all other tokens to their respective word. This way, we can align the labels with the processed input ids. . word_ids = tokenized_input.word_ids() aligned_labels = [-100 if i is None else example[f&quot;{task}_tags&quot;][i] for i in word_ids] print(len(aligned_labels), len(tokenized_input[&quot;input_ids&quot;])) . 49 49 . Here we set the labels of all special tokens to -100 (the index that is ignored by PyTorch) and the labels of all other tokens to the label of the word they come from. Another strategy is to set the label only on the first token obtained from a given word, and give a label of -100 to the other subtokens from the same word. We propose the two strategies here, just change the value of the following flag: . label_all_tokens = True . We&#39;re now ready to write the function that will preprocess our samples. We feed them to the tokenizer with the argument truncation=True (to truncate texts that are bigger than the maximum size allowed by the model) and is_split_into_words=True (as seen above). Then we align the labels with the token ids using the strategy we picked: . def tokenize_and_align_labels(examples): tokenized_inputs = tokenizer(examples[&quot;tokens&quot;], truncation=True, is_split_into_words=True) labels = [] for i, label in enumerate(examples[f&quot;{task}_tags&quot;]): word_ids = tokenized_inputs.word_ids(batch_index=i) previous_word_idx = None label_ids = [] for word_idx in word_ids: # Special tokens have a word id that is None. We set the label to -100 so they are automatically # ignored in the loss function. if word_idx is None: label_ids.append(-100) # We set the label for the first token of each word. elif word_idx != previous_word_idx: label_ids.append(label[word_idx]) # For the other tokens in a word, we set the label to either the current label or -100, depending on # the label_all_tokens flag. else: label_ids.append(label[word_idx] if label_all_tokens else -100) previous_word_idx = word_idx labels.append(label_ids) tokenized_inputs[&quot;labels&quot;] = labels return tokenized_inputs . This function works with one or several examples. In the case of several examples, the tokenizer will return a list of lists for each key: . tokenize_and_align_labels(datasets[&#39;train&#39;][:5]) . {&#39;input_ids&#39;: [[102, 2663, 2663, 3406, 1216, 19858, 116, 3662, 116, 19321, 1900, 138, 468, 468, 4421, 118, 103], [102, 2663, 2663, 9344, 10452, 188, 188, 170, 2409, 160, 171, 103], [102, 695, 24864, 29907, 7366, 188, 116, 7766, 188, 103], [102, 188, 188, 188, 3556, 557, 409, 188, 188, 188, 103], [102, 300, 9724, 115, 8377, 170, 498, 6907, 2701, 2501, 140, 879, 171, 116, 188, 188, 924, 291, 8708, 188, 188, 170, 498, 6907, 2701, 24116, 1370, 1343, 2731, 171, 116, 2047, 29922, 1854, 1133, 1157, 116, 138, 24507, 115, 4950, 3668, 173, 646, 1331, 290, 8617, 118, 103]], &#39;token_type_ids&#39;: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], &#39;attention_mask&#39;: [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], &#39;labels&#39;: [[-100, 0, 0, 1, 2, 2, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, -100], [-100, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, -100], [-100, 1, 1, 1, 0, 0, 0, 0, 0, -100], [-100, 0, 0, 0, 5, 5, 5, 0, 0, 0, -100], [-100, 0, 3, 4, 4, 0, 0, 0, 0, 3, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 6, 0, 0, 3, 3, 4, 4, 4, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, -100]]} . To apply this function on all the sentences (or pairs of sentences) in our dataset, we just use the map method of our dataset object we created earlier. This will apply the function on all the elements of all the splits in dataset, so our training, validation and testing data will be preprocessed in one single command. . tokenized_datasets = datasets.map(tokenize_and_align_labels, batched=True) . Even better, the results are automatically cached by the ðŸ¤— Datasets library to avoid spending time on this step the next time you run your notebook. The ðŸ¤— Datasets library is normally smart enough to detect when the function you pass to map has changed (and thus requires to not use the cache data). For instance, it will properly detect if you change the task in the first cell and rerun the notebook. ðŸ¤— Datasets warns you when it uses cached files, you can pass load_from_cache_file=False in the call to map to not use the cached files and force the preprocessing to be applied again. . Note that we passed batched=True to encode the texts by batches together. This is to leverage the full benefit of the fast tokenizer we loaded earlier, which will use multi-threading to treat the texts in a batch concurrently. . Fine-tuning the model . Now that our data is ready, we can download the pretrained model and fine-tune it. Since all our tasks are about token classification, we use the AutoModelForTokenClassification class. Like with the tokenizer, the from_pretrained method will download and cache the model for us. The only thing we have to specify is the number of labels for our problem (which we can get from the features, as seen before): . from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer, AutoConfig config = AutoConfig.from_pretrained(model_checkpoint, id2label={i: label for i, label in enumerate(label_list)}, label2id={label: i for i, label in enumerate(label_list)}) model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, config=config) . loading configuration file https://huggingface.co/DCU-NLP/electra-base-irish-cased-generator-v1/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/5239b8cd72f5caa8610a21bf2b225bb65fe3529da8491628fe2fb57a9feb5807.f9336c0d71d0b04cbbee5746d7d5e3444a26fcf7a3ff5262d8e655443181d939 Model config ElectraConfig { &#34;architectures&#34;: [ &#34;ElectraForMaskedLM&#34; ], &#34;attention_probs_dropout_prob&#34;: 0.1, &#34;classifier_dropout&#34;: null, &#34;embedding_size&#34;: 768, &#34;hidden_act&#34;: &#34;gelu&#34;, &#34;hidden_dropout_prob&#34;: 0.1, &#34;hidden_size&#34;: 256, &#34;id2label&#34;: { &#34;0&#34;: &#34;O&#34;, &#34;1&#34;: &#34;B-PER&#34;, &#34;2&#34;: &#34;I-PER&#34;, &#34;3&#34;: &#34;B-ORG&#34;, &#34;4&#34;: &#34;I-ORG&#34;, &#34;5&#34;: &#34;B-LOC&#34;, &#34;6&#34;: &#34;I-LOC&#34; }, &#34;initializer_range&#34;: 0.02, &#34;intermediate_size&#34;: 1024, &#34;label2id&#34;: { &#34;B-LOC&#34;: 5, &#34;B-ORG&#34;: 3, &#34;B-PER&#34;: 1, &#34;I-LOC&#34;: 6, &#34;I-ORG&#34;: 4, &#34;I-PER&#34;: 2, &#34;O&#34;: 0 }, &#34;layer_norm_eps&#34;: 1e-12, &#34;max_position_embeddings&#34;: 512, &#34;model_type&#34;: &#34;electra&#34;, &#34;num_attention_heads&#34;: 4, &#34;num_hidden_layers&#34;: 12, &#34;pad_token_id&#34;: 0, &#34;position_embedding_type&#34;: &#34;absolute&#34;, &#34;summary_activation&#34;: &#34;gelu&#34;, &#34;summary_last_dropout&#34;: 0.1, &#34;summary_type&#34;: &#34;first&#34;, &#34;summary_use_proj&#34;: true, &#34;transformers_version&#34;: &#34;4.12.5&#34;, &#34;type_vocab_size&#34;: 2, &#34;use_cache&#34;: true, &#34;vocab_size&#34;: 30101 } https://huggingface.co/DCU-NLP/electra-base-irish-cased-generator-v1/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpct8a4eaz storing https://huggingface.co/DCU-NLP/electra-base-irish-cased-generator-v1/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/8711d609c9402986d8c3bc7016d08db57bbf19a81067ef583c7badeb001f89b0.6c2cc587a2dcba7325cbf8221f9756c114c56f4cfb05f6fc1607064ba0d510b2 creating metadata file for /root/.cache/huggingface/transformers/8711d609c9402986d8c3bc7016d08db57bbf19a81067ef583c7badeb001f89b0.6c2cc587a2dcba7325cbf8221f9756c114c56f4cfb05f6fc1607064ba0d510b2 loading weights file https://huggingface.co/DCU-NLP/electra-base-irish-cased-generator-v1/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/8711d609c9402986d8c3bc7016d08db57bbf19a81067ef583c7badeb001f89b0.6c2cc587a2dcba7325cbf8221f9756c114c56f4cfb05f6fc1607064ba0d510b2 Some weights of the model checkpoint at DCU-NLP/electra-base-irish-cased-generator-v1 were not used when initializing ElectraForTokenClassification: [&#39;generator_predictions.LayerNorm.bias&#39;, &#39;generator_predictions.LayerNorm.weight&#39;, &#39;generator_lm_head.bias&#39;, &#39;generator_predictions.dense.bias&#39;, &#39;generator_lm_head.weight&#39;, &#39;generator_predictions.dense.weight&#39;] - This IS expected if you are initializing ElectraForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model). - This IS NOT expected if you are initializing ElectraForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model). Some weights of ElectraForTokenClassification were not initialized from the model checkpoint at DCU-NLP/electra-base-irish-cased-generator-v1 and are newly initialized: [&#39;classifier.weight&#39;, &#39;classifier.bias&#39;] You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference. . The warning is telling us we are throwing away some weights (the vocab_transform and vocab_layer_norm layers) and randomly initializing some other (the pre_classifier and classifier layers). This is absolutely normal in this case, because we are removing the head used to pretrain the model on a masked language modeling objective and replacing it with a new head for which we don&#39;t have pretrained weights, so the library warns us we should fine-tune this model before using it for inference, which is exactly what we are going to do. . To instantiate a Trainer, we will need to define three more things. The most important is the TrainingArguments, which is a class that contains all the attributes to customize the training. It requires one folder name, which will be used to save the checkpoints of the model, and all other arguments are optional: . model_name = model_checkpoint.split(&quot;/&quot;)[-1] args = TrainingArguments( f&quot;electra-base-irish-cased-discriminator-v1-finetuned-{task}&quot;, evaluation_strategy = &quot;epoch&quot;, learning_rate=2e-5, per_device_train_batch_size=batch_size, per_device_eval_batch_size=batch_size, num_train_epochs=5, weight_decay=0.01, push_to_hub=True, ) . PyTorch: setting up devices The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-). . Here we set the evaluation to be done at the end of each epoch, tweak the learning rate, use the batch_size defined at the top of the notebook and customize the number of epochs for training, as well as the weight decay. . The last argument to setup everything so we can push the model to the Hub regularly during training. Remove it if you didn&#39;t follow the installation steps at the top of the notebook. If you want to save your model locally in a name that is different than the name of the repository it will be pushed, or if you want to push your model under an organization and not your name space, use the hub_model_id argument to set the repo name (it needs to be the full name, including your namespace: for instance &quot;sgugger/bert-finetuned-ner&quot; or &quot;huggingface/bert-finetuned-ner&quot;). . Then we will need a data collator that will batch our processed examples together while applying padding to make them all the same size (each pad will be padded to the length of its longest example). There is a data collator for this task in the Transformers library, that not only pads the inputs, but also the labels: . from transformers import DataCollatorForTokenClassification data_collator = DataCollatorForTokenClassification(tokenizer) . The last thing to define for our Trainer is how to compute the metrics from the predictions. Here we will load the seqeval metric (which is commonly used to evaluate results on the CONLL dataset) via the Datasets library. . metric = load_metric(&quot;seqeval&quot;) . This metric takes list of labels for the predictions and references: . labels = [label_list[i] for i in example[f&quot;{task}_tags&quot;]] metric.compute(predictions=[labels], references=[labels]) . {&#39;LOC&#39;: {&#39;f1&#39;: 1.0, &#39;number&#39;: 1, &#39;precision&#39;: 1.0, &#39;recall&#39;: 1.0}, &#39;ORG&#39;: {&#39;f1&#39;: 1.0, &#39;number&#39;: 4, &#39;precision&#39;: 1.0, &#39;recall&#39;: 1.0}, &#39;overall_accuracy&#39;: 1.0, &#39;overall_f1&#39;: 1.0, &#39;overall_precision&#39;: 1.0, &#39;overall_recall&#39;: 1.0} . So we will need to do a bit of post-processing on our predictions: . select the predicted index (with the maximum logit) for each token | convert it to its string label | ignore everywhere we set a label of -100 | . The following function does all this post-processing on the result of Trainer.evaluate (which is a namedtuple containing predictions and labels) before applying the metric: . import numpy as np def compute_metrics(p): predictions, labels = p predictions = np.argmax(predictions, axis=2) # Remove ignored index (special tokens) true_predictions = [ [label_list[p] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels) ] true_labels = [ [label_list[l] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels) ] results = metric.compute(predictions=true_predictions, references=true_labels) return { &quot;precision&quot;: results[&quot;overall_precision&quot;], &quot;recall&quot;: results[&quot;overall_recall&quot;], &quot;f1&quot;: results[&quot;overall_f1&quot;], &quot;accuracy&quot;: results[&quot;overall_accuracy&quot;], } . Note that we drop the precision/recall/f1 computed for each category and only focus on the overall precision/recall/f1/accuracy. . Then we just need to pass all of this along with our datasets to the Trainer: . trainer = Trainer( model, args, train_dataset=tokenized_datasets[&quot;train&quot;], eval_dataset=tokenized_datasets[&quot;validation&quot;], data_collator=data_collator, tokenizer=tokenizer, compute_metrics=compute_metrics ) . Cloning https://huggingface.co/jimregan/electra-base-irish-cased-discriminator-v1-finetuned-ner into local empty directory. . We can now finetune our model by just calling the train method: . trainer.train() . The following columns in the training set don&#39;t have a corresponding argument in `ElectraForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running training ***** Num examples = 1000 Num Epochs = 5 Instantaneous batch size per device = 16 Total train batch size (w. parallel, distributed &amp; accumulation) = 16 Gradient Accumulation steps = 1 Total optimization steps = 315 . . [315/315 06:59, Epoch 5/5] Epoch Training Loss Validation Loss Precision Recall F1 Accuracy . 1 | No log | 1.323088 | 0.104612 | 0.041704 | 0.059634 | 0.544900 | . 2 | No log | 0.971045 | 0.387882 | 0.335874 | 0.360010 | 0.748616 | . 3 | No log | 0.772262 | 0.471313 | 0.445740 | 0.458170 | 0.815239 | . 4 | No log | 0.689249 | 0.525684 | 0.491031 | 0.507767 | 0.834663 | . 5 | No log | 0.665405 | 0.541392 | 0.516143 | 0.528466 | 0.841982 | . &lt;/div&gt; &lt;/div&gt; The following columns in the evaluation set don&#39;t have a corresponding argument in `ElectraForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running Evaluation ***** Num examples = 1000 Batch size = 16 The following columns in the evaluation set don&#39;t have a corresponding argument in `ElectraForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running Evaluation ***** Num examples = 1000 Batch size = 16 The following columns in the evaluation set don&#39;t have a corresponding argument in `ElectraForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running Evaluation ***** Num examples = 1000 Batch size = 16 The following columns in the evaluation set don&#39;t have a corresponding argument in `ElectraForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running Evaluation ***** Num examples = 1000 Batch size = 16 The following columns in the evaluation set don&#39;t have a corresponding argument in `ElectraForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running Evaluation ***** Num examples = 1000 Batch size = 16 Training completed. Do not forget to share your model on huggingface.co/models =) . TrainOutput(global_step=315, training_loss=1.046156238374256, metrics={&#39;train_runtime&#39;: 421.4027, &#39;train_samples_per_second&#39;: 11.865, &#39;train_steps_per_second&#39;: 0.748, &#39;total_flos&#39;: 9365012561232.0, &#39;train_loss&#39;: 1.046156238374256, &#39;epoch&#39;: 5.0}) . &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; The evaluate method allows you to evaluate again on the evaluation dataset or on another dataset: . trainer.evaluate() . The following columns in the evaluation set don&#39;t have a corresponding argument in `ElectraForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running Evaluation ***** Num examples = 1000 Batch size = 16 . . [63/63 00:15] {&#39;epoch&#39;: 5.0, &#39;eval_accuracy&#39;: 0.8419817960026273, &#39;eval_f1&#39;: 0.5284664830119375, &#39;eval_loss&#39;: 0.6654045581817627, &#39;eval_precision&#39;: 0.5413922859830668, &#39;eval_recall&#39;: 0.5161434977578475, &#39;eval_runtime&#39;: 15.7195, &#39;eval_samples_per_second&#39;: 63.615, &#39;eval_steps_per_second&#39;: 4.008} . To get the precision/recall/f1 computed for each category now that we have finished training, we can apply the same function as before on the result of the predict method: . predictions, labels, _ = trainer.predict(tokenized_datasets[&quot;validation&quot;]) predictions = np.argmax(predictions, axis=2) # Remove ignored index (special tokens) true_predictions = [ [label_list[p] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels) ] true_labels = [ [label_list[l] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels) ] results = metric.compute(predictions=true_predictions, references=true_labels) results . The following columns in the test set don&#39;t have a corresponding argument in `ElectraForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running Prediction ***** Num examples = 1000 Batch size = 16 . . [63/63 00:30] {&#39;LOC&#39;: {&#39;f1&#39;: 0.611111111111111, &#39;number&#39;: 1059, &#39;precision&#39;: 0.5901495162708883, &#39;recall&#39;: 0.6336166194523135}, &#39;ORG&#39;: {&#39;f1&#39;: 0.32798573975044565, &#39;number&#39;: 624, &#39;precision&#39;: 0.36947791164658633, &#39;recall&#39;: 0.2948717948717949}, &#39;PER&#39;: {&#39;f1&#39;: 0.5703275529865126, &#39;number&#39;: 547, &#39;precision&#39;: 0.6028513238289206, &#39;recall&#39;: 0.5411334552102377}, &#39;overall_accuracy&#39;: 0.8419817960026273, &#39;overall_f1&#39;: 0.5284664830119375, &#39;overall_precision&#39;: 0.5413922859830668, &#39;overall_recall&#39;: 0.5161434977578475} . You can now upload the result of the training to the Hub, just execute this instruction: . trainer.push_to_hub() . Saving model checkpoint to electra-base-irish-cased-discriminator-v1-finetuned-ner Configuration saved in electra-base-irish-cased-discriminator-v1-finetuned-ner/config.json Model weights saved in electra-base-irish-cased-discriminator-v1-finetuned-ner/pytorch_model.bin tokenizer config file saved in electra-base-irish-cased-discriminator-v1-finetuned-ner/tokenizer_config.json Special tokens file saved in electra-base-irish-cased-discriminator-v1-finetuned-ner/special_tokens_map.json To https://huggingface.co/jimregan/electra-base-irish-cased-discriminator-v1-finetuned-ner ff80640..8e0c67b main -&gt; main To https://huggingface.co/jimregan/electra-base-irish-cased-discriminator-v1-finetuned-ner 8e0c67b..de8c10a main -&gt; main . &#39;https://huggingface.co/jimregan/electra-base-irish-cased-discriminator-v1-finetuned-ner/commit/8e0c67b1396fb46c77f0d4ec21922a123d9faf94&#39; . You can now share this model with all your friends, family, favorite pets: they can all load it with the identifier &quot;your-username/the-name-you-picked&quot; so for instance: . from transformers import AutoModelForTokenClassification model = AutoModelForTokenClassification.from_pretrained(&quot;sgugger/my-awesome-model&quot;) . &lt;/div&gt; .",
            "url": "https://jimregan.github.io/notes/irish/ner/bert/gaelectra/2021/12/01/token_classification_gaelectra.html",
            "relUrl": "/irish/ner/bert/gaelectra/2021/12/01/token_classification_gaelectra.html",
            "date": " â€¢ Dec 1, 2021"
        }
        
    
  
    
        ,"post33": {
            "title": "NER with gaBERT",
            "content": "This is a lightly edited version of this notebook. . If you&#39;re opening this Notebook on colab, you will probably need to install ðŸ¤— Transformers and ðŸ¤— Datasets. Uncomment the following cell and run it. . %%capture !pip install datasets transformers seqeval . If you&#39;re opening this notebook locally, make sure your environment has an install from the last version of those libraries. . To be able to share your model with the community and generate results like the one shown in the picture below via the inference API, there are a few more steps to follow. . First you have to store your authentication token from the Hugging Face website (sign up here if you haven&#39;t already!) then execute the following cell and input your username and password: . (Huggingface notebooks skip this bit, but you need to set credential.helper before anything else works). . !git config --global credential.helper store . from huggingface_hub import notebook_login notebook_login() . Login successful Your token has been saved to /root/.huggingface/token . Then you need to install Git-LFS. Uncomment the following instructions: . !apt install git-lfs . Reading package lists... Done Building dependency tree Reading state information... Done The following NEW packages will be installed: git-lfs 0 upgraded, 1 newly installed, 0 to remove and 37 not upgraded. Need to get 2,129 kB of archives. After this operation, 7,662 kB of additional disk space will be used. Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 git-lfs amd64 2.3.4-1 [2,129 kB] Fetched 2,129 kB in 1s (2,915 kB/s) Selecting previously unselected package git-lfs. (Reading database ... 155222 files and directories currently installed.) Preparing to unpack .../git-lfs_2.3.4-1_amd64.deb ... Unpacking git-lfs (2.3.4-1) ... Setting up git-lfs (2.3.4-1) ... Processing triggers for man-db (2.8.3-2ubuntu0.1) ... . Make sure your version of Transformers is at least 4.11.0 since the functionality was introduced in that version: . import transformers print(transformers.__version__) . 4.12.5 . You can find a script version of this notebook to fine-tune your model in a distributed fashion using multiple GPUs or TPUs here. . Fine-tuning a model on a token classification task . In this notebook, we will see how to fine-tune one of the ðŸ¤— Transformers model to a token classification task, which is the task of predicting a label for each token. . . The most common token classification tasks are: . NER (Named-entity recognition) Classify the entities in the text (person, organization, location...). | POS (Part-of-speech tagging) Grammatically classify the tokens (noun, verb, adjective...) | Chunk (Chunking) Grammatically classify the tokens and group them into &quot;chunks&quot; that go together | . We will see how to easily load a dataset for these kinds of tasks and use the Trainer API to fine-tune a model on it. . This notebook is built to run on any token classification task, with any model checkpoint from the Model Hub as long as that model has a version with a token classification head and a fast tokenizer (check on this table if this is the case). It might just need some small adjustments if you decide to use a different dataset than the one used here. Depending on you model and the GPU you are using, you might need to adjust the batch size to avoid out-of-memory errors. Set those three parameters, then the rest of the notebook should run smoothly: . task = &quot;ner&quot; # Should be one of &quot;ner&quot;, &quot;pos&quot; or &quot;chunk&quot; model_checkpoint = &quot;DCU-NLP/bert-base-irish-cased-v1&quot; batch_size = 16 . Loading the dataset . We will use the ðŸ¤— Datasets library to download the data and get the metric we need to use for evaluation (to compare our model to the benchmark). This can be easily done with the functions load_dataset and load_metric. . from datasets import load_dataset, load_metric . For our example here, we&#39;ll use the CONLL 2003 dataset. The notebook should work with any token classification dataset provided by the ðŸ¤— Datasets library. If you&#39;re using your own dataset defined from a JSON or csv file (see the Datasets documentation on how to load them), it might need some adjustments in the names of the columns used. . datasets = load_dataset(&quot;wikiann&quot;, &quot;ga&quot;) . Downloading and preparing dataset wikiann/ga (download: 223.17 MiB, generated: 690.65 KiB, post-processed: Unknown size, total: 223.84 MiB) to /root/.cache/huggingface/datasets/wikiann/ga/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e... Dataset wikiann downloaded and prepared to /root/.cache/huggingface/datasets/wikiann/ga/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e. Subsequent calls will reuse this data. . The datasets object itself is DatasetDict, which contains one key for the training, validation and test set. . datasets . DatasetDict({ validation: Dataset({ features: [&#39;tokens&#39;, &#39;ner_tags&#39;, &#39;langs&#39;, &#39;spans&#39;], num_rows: 1000 }) test: Dataset({ features: [&#39;tokens&#39;, &#39;ner_tags&#39;, &#39;langs&#39;, &#39;spans&#39;], num_rows: 1000 }) train: Dataset({ features: [&#39;tokens&#39;, &#39;ner_tags&#39;, &#39;langs&#39;, &#39;spans&#39;], num_rows: 1000 }) }) . We can see the training, validation and test sets all have a column for the tokens (the input texts split into words) and one column of labels for each kind of task we introduced before. . To access an actual element, you need to select a split first, then give an index: . datasets[&quot;train&quot;][0] . {&#39;langs&#39;: [&#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;], &#39;ner_tags&#39;: [0, 1, 2, 2, 0, 0, 0, 0, 5, 0, 0, 0], &#39;spans&#39;: [&#39;PER: PÃ¡draig Mac Piarais&#39;, &#39;LOC: Ã‰ireannach&#39;], &#39;tokens&#39;: [&#39;**&#39;, &#39;PÃ¡draig&#39;, &#39;Mac&#39;, &#39;Piarais&#39;, &#39;,&#39;, &#39;36&#39;, &#39;,&#39;, &#39;rÃ©abhlÃ³idÃ­&#39;, &#39;Ã‰ireannach&#39;, &#39;agus&#39;, &#39;[[file&#39;, &#39;.&#39;]} . The labels are already coded as integer ids to be easily usable by our model, but the correspondence with the actual categories is stored in the features of the dataset: . datasets[&quot;train&quot;].features[f&quot;ner_tags&quot;] . Sequence(feature=ClassLabel(num_classes=7, names=[&#39;O&#39;, &#39;B-PER&#39;, &#39;I-PER&#39;, &#39;B-ORG&#39;, &#39;I-ORG&#39;, &#39;B-LOC&#39;, &#39;I-LOC&#39;], names_file=None, id=None), length=-1, id=None) . So for the NER tags, 0 corresponds to &#39;O&#39;, 1 to &#39;B-PER&#39; etc... On top of the &#39;O&#39; (which means no special entity), there are four labels for NER here, each prefixed with &#39;B-&#39; (for beginning) or &#39;I-&#39; (for intermediate), that indicate if the token is the first one for the current group with the label or not: . &#39;PER&#39; for person | &#39;ORG&#39; for organization | &#39;LOC&#39; for location | &#39;MISC&#39; for miscellaneous | . Since the labels are lists of ClassLabel, the actual names of the labels are nested in the feature attribute of the object above: . label_list = datasets[&quot;train&quot;].features[f&quot;{task}_tags&quot;].feature.names label_list . [&#39;O&#39;, &#39;B-PER&#39;, &#39;I-PER&#39;, &#39;B-ORG&#39;, &#39;I-ORG&#39;, &#39;B-LOC&#39;, &#39;I-LOC&#39;] . To get a sense of what the data looks like, the following function will show some examples picked randomly in the dataset (automatically decoding the labels in passing). . from datasets import ClassLabel, Sequence import random import pandas as pd from IPython.display import display, HTML def show_random_elements(dataset, num_examples=10): assert num_examples &lt;= len(dataset), &quot;Can&#39;t pick more elements than there are in the dataset.&quot; picks = [] for _ in range(num_examples): pick = random.randint(0, len(dataset)-1) while pick in picks: pick = random.randint(0, len(dataset)-1) picks.append(pick) df = pd.DataFrame(dataset[picks]) for column, typ in dataset.features.items(): if isinstance(typ, ClassLabel): df[column] = df[column].transform(lambda i: typ.names[i]) elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel): df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x]) display(HTML(df.to_html())) . show_random_elements(datasets[&quot;train&quot;]) . tokens ner_tags langs spans . 0 [An, Bhantiarna, Jane, Grey] | [B-PER, I-PER, I-PER, I-PER] | [ga, ga, ga, ga] | [PER: An Bhantiarna Jane Grey] | . 1 [athsheoladh, PÃ¡pa, PÃ³l, IV] | [O, B-PER, I-PER, I-PER] | [ga, ga, ga, ga] | [PER: PÃ¡pa PÃ³l IV] | . 2 [Launceston, ,, Devonport, ,, agus, Burnie] | [B-LOC, O, B-LOC, O, O, B-LOC] | [ga, ga, ga, ga, ga, ga] | [LOC: Launceston, LOC: Devonport, LOC: Burnie] | . 3 [Holborn, ,, Hyde, Park] | [B-LOC, O, B-ORG, I-ORG] | [ga, ga, ga, ga] | [LOC: Holborn, ORG: Hyde Park] | . 4 [athsheoladh, Ollscoil, Chathair, Bhaile, Ãtha, Cliath] | [O, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG] | [ga, ga, ga, ga, ga, ga] | [ORG: Ollscoil Chathair Bhaile Ãtha Cliath] | . 5 [Broadgate, ,, Billingsgate, ,, Bishopsgate, ,, Blackfriars] | [B-ORG, O, B-LOC, O, B-LOC, O, B-LOC] | [ga, ga, ga, ga, ga, ga, ga] | [ORG: Broadgate, LOC: Billingsgate, LOC: Bishopsgate, LOC: Blackfriars] | . 6 [Major, AntÃ´nio, Couto, Pereira, Staidiam] | [B-ORG, I-ORG, I-ORG, I-ORG, I-ORG] | [ga, ga, ga, ga, ga] | [ORG: Major AntÃ´nio Couto Pereira Staidiam] | . 7 [RuairÃ­, Ã“, Cuinn] | [B-PER, I-PER, I-PER] | [ga, ga, ga] | [PER: RuairÃ­ Ã“ Cuinn] | . 8 [&#39;, &#39;&#39;, Razoul, &#39;&#39;, &#39;, -, Jim, Cummings] | [O, O, O, O, O, O, B-PER, I-PER] | [ga, ga, ga, ga, ga, ga, ga, ga] | [PER: Jim Cummings] | . 9 [Is, iomaÃ­, laoch, de, chuid, an, gharrfhicsin, a, chuaigh, i, dtÃ¡in, an, phopchultÃºir, dhomhanda, ,, go, hÃ¡irithe, iad, siÃºd, ar, chuir, Hollywood, suim, iontu, .] | [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O, O] | [ga, ga, ga, ga, ga, ga, ga, ga, ga, ga, ga, ga, ga, ga, ga, ga, ga, ga, ga, ga, ga, ga, ga, ga, ga] | [LOC: Hollywood] | . Preprocessing the data . Before we can feed those texts to our model, we need to preprocess them. This is done by a ðŸ¤— Transformers Tokenizer which will (as the name indicates) tokenize the inputs (including converting the tokens to their corresponding IDs in the pretrained vocabulary) and put it in a format the model expects, as well as generate the other inputs that model requires. . To do all of this, we instantiate our tokenizer with the AutoTokenizer.from_pretrained method, which will ensure: . we get a tokenizer that corresponds to the model architecture we want to use, | we download the vocabulary used when pretraining this specific checkpoint. | . That vocabulary will be cached, so it&#39;s not downloaded again the next time we run the cell. . from transformers import AutoTokenizer tokenizer = AutoTokenizer.from_pretrained(model_checkpoint) . The following assertion ensures that our tokenizer is a fast tokenizers (backed by Rust) from the ðŸ¤— Tokenizers library. Those fast tokenizers are available for almost all models, and we will need some of the special features they have for our preprocessing. . import transformers assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast) . You can check which type of models have a fast tokenizer available and which don&#39;t on the big table of models. . You can directly call this tokenizer on one sentence: . tokenizer(&quot;Is abairt amhÃ¡in Ã© seo!&quot;) . {&#39;input_ids&#39;: [102, 311, 3280, 556, 186, 222, 711, 103], &#39;token_type_ids&#39;: [0, 0, 0, 0, 0, 0, 0, 0], &#39;attention_mask&#39;: [1, 1, 1, 1, 1, 1, 1, 1]} . Depending on the model you selected, you will see different keys in the dictionary returned by the cell above. They don&#39;t matter much for what we&#39;re doing here (just know they are required by the model we will instantiate later), you can learn more about them in this tutorial if you&#39;re interested. . If, as is the case here, your inputs have already been split into words, you should pass the list of words to your tokenzier with the argument is_split_into_words=True: . tokenizer([&quot;Hello&quot;, &quot;,&quot;, &quot;this&quot;, &quot;is&quot;, &quot;one&quot;, &quot;sentence&quot;, &quot;split&quot;, &quot;into&quot;, &quot;words&quot;, &quot;.&quot;], is_split_into_words=True) . {&#39;input_ids&#39;: [101, 7592, 1010, 2023, 2003, 2028, 6251, 3975, 2046, 2616, 1012, 102], &#39;attention_mask&#39;: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} . Note that transformers are often pretrained with subword tokenizers, meaning that even if your inputs have been split into words already, each of those words could be split again by the tokenizer. Let&#39;s look at an example of that: . example = datasets[&quot;train&quot;][4] print(example[&quot;tokens&quot;]) . [&#39;TÃ¡&#39;, &#39;Ãras&#39;, &#39;an&#39;, &#39;UachtarÃ¡in&#39;, &#39;(&#39;, &#39;Ã¡it&#39;, &#39;chÃ³naithe&#39;, &#39;oifigiÃºil&#39;, &#39;UachtarÃ¡n&#39;, &#39;na&#39;, &#39;hÃ‰ireann&#39;, &#39;)&#39;, &#39;,&#39;, &#34;&#39;&#39;Deerfield&#34;, &#34;&#39;&#39;&#34;, &#39;(&#39;, &#39;Ã¡it&#39;, &#39;chÃ³naithe&#39;, &#39;oifigiÃºil&#39;, &#39;AmbasadÃ³ir&#39;, &#39;StÃ¡it&#39;, &#39;Aontaithe&#39;, &#39;MheiriceÃ¡&#39;, &#39;)&#39;, &#39;,&#39;, &#39;ZÃº&#39;, &#39;Bhaile&#39;, &#39;Ãtha&#39;, &#39;Cliath&#39;, &#39;,&#39;, &#39;agus&#39;, &#39;CeanncheathrÃº&#39;, &#39;an&#39;, &#39;Gharda&#39;, &#39;SÃ­ochÃ¡na&#39;, &#39;go&#39;, &#39;lÃ©ir&#39;, &#39;laistigh&#39;, &#39;den&#39;, &#39;phÃ¡irc&#39;, &#39;.&#39;] . tokenized_input = tokenizer(example[&quot;tokens&quot;], is_split_into_words=True) tokens = tokenizer.convert_ids_to_tokens(tokenized_input[&quot;input_ids&quot;]) print(tokens) . [&#39;[CLS]&#39;, &#39;TÃ¡&#39;, &#39;Ãras&#39;, &#39;an&#39;, &#39;UachtarÃ¡in&#39;, &#39;(&#39;, &#39;Ã¡it&#39;, &#39;chÃ³naithe&#39;, &#39;oifigiÃºil&#39;, &#39;UachtarÃ¡n&#39;, &#39;na&#39;, &#39;hÃ‰ireann&#39;, &#39;)&#39;, &#39;,&#39;, &#34;&#39;&#34;, &#34;&#39;&#34;, &#39;De&#39;, &#39;##er&#39;, &#39;##field&#39;, &#34;&#39;&#34;, &#34;&#39;&#34;, &#39;(&#39;, &#39;Ã¡it&#39;, &#39;chÃ³naithe&#39;, &#39;oifigiÃºil&#39;, &#39;AmbasadÃ³ir&#39;, &#39;StÃ¡it&#39;, &#39;Aontaithe&#39;, &#39;MheiriceÃ¡&#39;, &#39;)&#39;, &#39;,&#39;, &#39;Z&#39;, &#39;##Ãº&#39;, &#39;Bhaile&#39;, &#39;Ãtha&#39;, &#39;Cliath&#39;, &#39;,&#39;, &#39;agus&#39;, &#39;CeanncheathrÃº&#39;, &#39;an&#39;, &#39;Gharda&#39;, &#39;SÃ­ochÃ¡na&#39;, &#39;go&#39;, &#39;lÃ©ir&#39;, &#39;laistigh&#39;, &#39;den&#39;, &#39;phÃ¡irc&#39;, &#39;.&#39;, &#39;[SEP]&#39;] . Here the words &quot;Zwingmann&quot; and &quot;sheepmeat&quot; have been split in three subtokens. . This means that we need to do some processing on our labels as the input ids returned by the tokenizer are longer than the lists of labels our dataset contain, first because some special tokens might be added (we can a [CLS] and a [SEP] above) and then because of those possible splits of words in multiple tokens: . len(example[f&quot;{task}_tags&quot;]), len(tokenized_input[&quot;input_ids&quot;]) . (41, 49) . Thankfully, the tokenizer returns outputs that have a word_ids method which can help us. . print(tokenized_input.word_ids()) . [None, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 13, 13, 13, 13, 14, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, None] . As we can see, it returns a list with the same number of elements as our processed input ids, mapping special tokens to None and all other tokens to their respective word. This way, we can align the labels with the processed input ids. . word_ids = tokenized_input.word_ids() aligned_labels = [-100 if i is None else example[f&quot;{task}_tags&quot;][i] for i in word_ids] print(len(aligned_labels), len(tokenized_input[&quot;input_ids&quot;])) . 49 49 . Here we set the labels of all special tokens to -100 (the index that is ignored by PyTorch) and the labels of all other tokens to the label of the word they come from. Another strategy is to set the label only on the first token obtained from a given word, and give a label of -100 to the other subtokens from the same word. We propose the two strategies here, just change the value of the following flag: . label_all_tokens = True . We&#39;re now ready to write the function that will preprocess our samples. We feed them to the tokenizer with the argument truncation=True (to truncate texts that are bigger than the maximum size allowed by the model) and is_split_into_words=True (as seen above). Then we align the labels with the token ids using the strategy we picked: . def tokenize_and_align_labels(examples): tokenized_inputs = tokenizer(examples[&quot;tokens&quot;], truncation=True, is_split_into_words=True) labels = [] for i, label in enumerate(examples[f&quot;{task}_tags&quot;]): word_ids = tokenized_inputs.word_ids(batch_index=i) previous_word_idx = None label_ids = [] for word_idx in word_ids: # Special tokens have a word id that is None. We set the label to -100 so they are automatically # ignored in the loss function. if word_idx is None: label_ids.append(-100) # We set the label for the first token of each word. elif word_idx != previous_word_idx: label_ids.append(label[word_idx]) # For the other tokens in a word, we set the label to either the current label or -100, depending on # the label_all_tokens flag. else: label_ids.append(label[word_idx] if label_all_tokens else -100) previous_word_idx = word_idx labels.append(label_ids) tokenized_inputs[&quot;labels&quot;] = labels return tokenized_inputs . This function works with one or several examples. In the case of several examples, the tokenizer will return a list of lists for each key: . tokenize_and_align_labels(datasets[&#39;train&#39;][:5]) . Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation. . {&#39;input_ids&#39;: [[102, 2663, 2663, 3406, 1216, 19858, 116, 3662, 116, 19321, 1900, 138, 468, 468, 4421, 118, 103], [102, 2663, 2663, 9344, 10452, 188, 188, 170, 2409, 160, 171, 103], [102, 695, 24864, 29907, 7366, 188, 116, 7766, 188, 103], [102, 188, 188, 188, 3556, 557, 409, 188, 188, 188, 103], [102, 300, 9724, 115, 8377, 170, 498, 6907, 2701, 2501, 140, 879, 171, 116, 188, 188, 924, 291, 8708, 188, 188, 170, 498, 6907, 2701, 24116, 1370, 1343, 2731, 171, 116, 2047, 29922, 1854, 1133, 1157, 116, 138, 24507, 115, 4950, 3668, 173, 646, 1331, 290, 8617, 118, 103]], &#39;token_type_ids&#39;: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], &#39;attention_mask&#39;: [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], &#39;labels&#39;: [[-100, 0, 0, 1, 2, 2, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, -100], [-100, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, -100], [-100, 1, 1, 1, 0, 0, 0, 0, 0, -100], [-100, 0, 0, 0, 5, 5, 5, 0, 0, 0, -100], [-100, 0, 3, 4, 4, 0, 0, 0, 0, 3, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 6, 0, 0, 3, 3, 4, 4, 4, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, -100]]} . To apply this function on all the sentences (or pairs of sentences) in our dataset, we just use the map method of our dataset object we created earlier. This will apply the function on all the elements of all the splits in dataset, so our training, validation and testing data will be preprocessed in one single command. . tokenized_datasets = datasets.map(tokenize_and_align_labels, batched=True) . Even better, the results are automatically cached by the ðŸ¤— Datasets library to avoid spending time on this step the next time you run your notebook. The ðŸ¤— Datasets library is normally smart enough to detect when the function you pass to map has changed (and thus requires to not use the cache data). For instance, it will properly detect if you change the task in the first cell and rerun the notebook. ðŸ¤— Datasets warns you when it uses cached files, you can pass load_from_cache_file=False in the call to map to not use the cached files and force the preprocessing to be applied again. . Note that we passed batched=True to encode the texts by batches together. This is to leverage the full benefit of the fast tokenizer we loaded earlier, which will use multi-threading to treat the texts in a batch concurrently. . Fine-tuning the model . Now that our data is ready, we can download the pretrained model and fine-tune it. Since all our tasks are about token classification, we use the AutoModelForTokenClassification class. Like with the tokenizer, the from_pretrained method will download and cache the model for us. The only thing we have to specify is the number of labels for our problem (which we can get from the features, as seen before): . from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer, AutoConfig config = AutoConfig.from_pretrained(model_checkpoint, id2label={i: label for i, label in enumerate(label_list)}, label2id={label: i for i, label in enumerate(label_list)}) model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, config=config) . Some weights of the model checkpoint at DCU-NLP/bert-base-irish-cased-v1 were not used when initializing BertForTokenClassification: [&#39;cls.predictions.transform.dense.weight&#39;, &#39;cls.predictions.decoder.weight&#39;, &#39;cls.seq_relationship.bias&#39;, &#39;cls.predictions.decoder.bias&#39;, &#39;cls.predictions.transform.dense.bias&#39;, &#39;cls.predictions.transform.LayerNorm.weight&#39;, &#39;cls.predictions.bias&#39;, &#39;cls.seq_relationship.weight&#39;, &#39;cls.predictions.transform.LayerNorm.bias&#39;] - This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model). - This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model). Some weights of BertForTokenClassification were not initialized from the model checkpoint at DCU-NLP/bert-base-irish-cased-v1 and are newly initialized: [&#39;classifier.weight&#39;, &#39;classifier.bias&#39;] You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference. . The warning is telling us we are throwing away some weights (the vocab_transform and vocab_layer_norm layers) and randomly initializing some other (the pre_classifier and classifier layers). This is absolutely normal in this case, because we are removing the head used to pretrain the model on a masked language modeling objective and replacing it with a new head for which we don&#39;t have pretrained weights, so the library warns us we should fine-tune this model before using it for inference, which is exactly what we are going to do. . To instantiate a Trainer, we will need to define three more things. The most important is the TrainingArguments, which is a class that contains all the attributes to customize the training. It requires one folder name, which will be used to save the checkpoints of the model, and all other arguments are optional: . model_name = model_checkpoint.split(&quot;/&quot;)[-1] args = TrainingArguments( f&quot;bert-base-irish-cased-v1-finetuned-{task}&quot;, evaluation_strategy = &quot;epoch&quot;, learning_rate=2e-5, per_device_train_batch_size=batch_size, per_device_eval_batch_size=batch_size, num_train_epochs=5, weight_decay=0.01, push_to_hub=True, ) . Here we set the evaluation to be done at the end of each epoch, tweak the learning rate, use the batch_size defined at the top of the notebook and customize the number of epochs for training, as well as the weight decay. . The last argument to setup everything so we can push the model to the Hub regularly during training. Remove it if you didn&#39;t follow the installation steps at the top of the notebook. If you want to save your model locally in a name that is different than the name of the repository it will be pushed, or if you want to push your model under an organization and not your name space, use the hub_model_id argument to set the repo name (it needs to be the full name, including your namespace: for instance &quot;sgugger/bert-finetuned-ner&quot; or &quot;huggingface/bert-finetuned-ner&quot;). . Then we will need a data collator that will batch our processed examples together while applying padding to make them all the same size (each pad will be padded to the length of its longest example). There is a data collator for this task in the Transformers library, that not only pads the inputs, but also the labels: . from transformers import DataCollatorForTokenClassification data_collator = DataCollatorForTokenClassification(tokenizer) . The last thing to define for our Trainer is how to compute the metrics from the predictions. Here we will load the seqeval metric (which is commonly used to evaluate results on the CONLL dataset) via the Datasets library. . metric = load_metric(&quot;seqeval&quot;) . This metric takes list of labels for the predictions and references: . labels = [label_list[i] for i in example[f&quot;{task}_tags&quot;]] metric.compute(predictions=[labels], references=[labels]) . {&#39;LOC&#39;: {&#39;f1&#39;: 1.0, &#39;number&#39;: 1, &#39;precision&#39;: 1.0, &#39;recall&#39;: 1.0}, &#39;ORG&#39;: {&#39;f1&#39;: 1.0, &#39;number&#39;: 4, &#39;precision&#39;: 1.0, &#39;recall&#39;: 1.0}, &#39;overall_accuracy&#39;: 1.0, &#39;overall_f1&#39;: 1.0, &#39;overall_precision&#39;: 1.0, &#39;overall_recall&#39;: 1.0} . So we will need to do a bit of post-processing on our predictions: . select the predicted index (with the maximum logit) for each token | convert it to its string label | ignore everywhere we set a label of -100 | . The following function does all this post-processing on the result of Trainer.evaluate (which is a namedtuple containing predictions and labels) before applying the metric: . import numpy as np def compute_metrics(p): predictions, labels = p predictions = np.argmax(predictions, axis=2) # Remove ignored index (special tokens) true_predictions = [ [label_list[p] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels) ] true_labels = [ [label_list[l] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels) ] results = metric.compute(predictions=true_predictions, references=true_labels) return { &quot;precision&quot;: results[&quot;overall_precision&quot;], &quot;recall&quot;: results[&quot;overall_recall&quot;], &quot;f1&quot;: results[&quot;overall_f1&quot;], &quot;accuracy&quot;: results[&quot;overall_accuracy&quot;], } . Note that we drop the precision/recall/f1 computed for each category and only focus on the overall precision/recall/f1/accuracy. . Then we just need to pass all of this along with our datasets to the Trainer: . trainer = Trainer( model, args, train_dataset=tokenized_datasets[&quot;train&quot;], eval_dataset=tokenized_datasets[&quot;validation&quot;], data_collator=data_collator, tokenizer=tokenizer, compute_metrics=compute_metrics ) . Cloning https://huggingface.co/jimregan/bert-base-irish-cased-v1-finetuned-ner into local empty directory. . We can now finetune our model by just calling the train method: . trainer.train() . The following columns in the training set don&#39;t have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running training ***** Num examples = 1000 Num Epochs = 5 Instantaneous batch size per device = 16 Total train batch size (w. parallel, distributed &amp; accumulation) = 16 Gradient Accumulation steps = 1 Total optimization steps = 315 . . [315/315 42:13, Epoch 5/5] Epoch Training Loss Validation Loss Precision Recall F1 Accuracy . 1 | No log | 0.490215 | 0.557930 | 0.526906 | 0.541974 | 0.845829 | . 2 | No log | 0.322674 | 0.716948 | 0.741704 | 0.729116 | 0.899127 | . 3 | No log | 0.271966 | 0.789521 | 0.783857 | 0.786679 | 0.918645 | . 4 | No log | 0.258545 | 0.812830 | 0.829596 | 0.821127 | 0.926433 | . 5 | No log | 0.246760 | 0.819060 | 0.836323 | 0.827602 | 0.930656 | . &lt;/div&gt; &lt;/div&gt; The following columns in the evaluation set don&#39;t have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running Evaluation ***** Num examples = 1000 Batch size = 16 The following columns in the evaluation set don&#39;t have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running Evaluation ***** Num examples = 1000 Batch size = 16 The following columns in the evaluation set don&#39;t have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running Evaluation ***** Num examples = 1000 Batch size = 16 The following columns in the evaluation set don&#39;t have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running Evaluation ***** Num examples = 1000 Batch size = 16 The following columns in the evaluation set don&#39;t have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running Evaluation ***** Num examples = 1000 Batch size = 16 Training completed. Do not forget to share your model on huggingface.co/models =) . TrainOutput(global_step=315, training_loss=0.3794897654699901, metrics={&#39;train_runtime&#39;: 2539.5447, &#39;train_samples_per_second&#39;: 1.969, &#39;train_steps_per_second&#39;: 0.124, &#39;total_flos&#39;: 82316282047824.0, &#39;train_loss&#39;: 0.3794897654699901, &#39;epoch&#39;: 5.0}) . &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; The evaluate method allows you to evaluate again on the evaluation dataset or on another dataset: . trainer.evaluate() . The following columns in the evaluation set don&#39;t have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running Evaluation ***** Num examples = 1000 Batch size = 16 . . [63/63 01:31] {&#39;epoch&#39;: 5.0, &#39;eval_accuracy&#39;: 0.9306559069156423, &#39;eval_f1&#39;: 0.8276015087641446, &#39;eval_loss&#39;: 0.2467602640390396, &#39;eval_precision&#39;: 0.8190601668862538, &#39;eval_recall&#39;: 0.8363228699551569, &#39;eval_runtime&#39;: 92.5448, &#39;eval_samples_per_second&#39;: 10.806, &#39;eval_steps_per_second&#39;: 0.681} . To get the precision/recall/f1 computed for each category now that we have finished training, we can apply the same function as before on the result of the predict method: . predictions, labels, _ = trainer.predict(tokenized_datasets[&quot;validation&quot;]) predictions = np.argmax(predictions, axis=2) # Remove ignored index (special tokens) true_predictions = [ [label_list[p] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels) ] true_labels = [ [label_list[l] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels) ] results = metric.compute(predictions=true_predictions, references=true_labels) results . The following columns in the test set don&#39;t have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running Prediction ***** Num examples = 1000 Batch size = 16 . . [63/63 03:13] {&#39;LOC&#39;: {&#39;f1&#39;: 0.8707735062528948, &#39;number&#39;: 1059, &#39;precision&#39;: 0.8545454545454545, &#39;recall&#39;: 0.8876298394711992}, &#39;ORG&#39;: {&#39;f1&#39;: 0.7434210526315789, &#39;number&#39;: 624, &#39;precision&#39;: 0.7635135135135135, &#39;recall&#39;: 0.7243589743589743}, &#39;PER&#39;: {&#39;f1&#39;: 0.8356890459363958, &#39;number&#39;: 547, &#39;precision&#39;: 0.8085470085470086, &#39;recall&#39;: 0.8647166361974405}, &#39;overall_accuracy&#39;: 0.9306559069156423, &#39;overall_f1&#39;: 0.8276015087641446, &#39;overall_precision&#39;: 0.8190601668862538, &#39;overall_recall&#39;: 0.8363228699551569} . You can now upload the result of the training to the Hub, just execute this instruction: . trainer.push_to_hub() . Saving model checkpoint to bert-base-irish-cased-v1-finetuned-ner Configuration saved in bert-base-irish-cased-v1-finetuned-ner/config.json Model weights saved in bert-base-irish-cased-v1-finetuned-ner/pytorch_model.bin tokenizer config file saved in bert-base-irish-cased-v1-finetuned-ner/tokenizer_config.json Special tokens file saved in bert-base-irish-cased-v1-finetuned-ner/special_tokens_map.json To https://huggingface.co/jimregan/bert-base-irish-cased-v1-finetuned-ner 1e8d5f1..335cab8 main -&gt; main To https://huggingface.co/jimregan/bert-base-irish-cased-v1-finetuned-ner 335cab8..346f537 main -&gt; main . &#39;https://huggingface.co/jimregan/bert-base-irish-cased-v1-finetuned-ner/commit/335cab89dba6a89a8bc06c22d70abeec27c1f60c&#39; . You can now share this model with all your friends, family, favorite pets: they can all load it with the identifier &quot;your-username/the-name-you-picked&quot; so for instance: . from transformers import AutoModelForTokenClassification model = AutoModelForTokenClassification.from_pretrained(&quot;sgugger/my-awesome-model&quot;) . &lt;/div&gt; .",
            "url": "https://jimregan.github.io/notes/irish/ner/bert/gabert/2021/12/01/token_classification_gabert.html",
            "relUrl": "/irish/ner/bert/gabert/2021/12/01/token_classification_gabert.html",
            "date": " â€¢ Dec 1, 2021"
        }
        
    
  
    
        ,"post34": {
            "title": "NER with bertreach",
            "content": "This is a lightly edited version of this notebook. . If you&#39;re opening this Notebook on colab, you will probably need to install ðŸ¤— Transformers and ðŸ¤— Datasets. Uncomment the following cell and run it. . %%capture !pip install datasets transformers seqeval . If you&#39;re opening this notebook locally, make sure your environment has an install from the last version of those libraries. . To be able to share your model with the community and generate results like the one shown in the picture below via the inference API, there are a few more steps to follow. . First you have to store your authentication token from the Hugging Face website (sign up here if you haven&#39;t already!) then execute the following cell and input your username and password: . (Huggingface notebooks skip this bit, but you need to set credential.helper before anything else works). . !git config --global credential.helper store . from huggingface_hub import notebook_login notebook_login() . Login successful Your token has been saved to /root/.huggingface/token . Then you need to install Git-LFS. Uncomment the following instructions: . !apt install git-lfs . Reading package lists... Done Building dependency tree Reading state information... Done git-lfs is already the newest version (2.3.4-1). 0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded. . Make sure your version of Transformers is at least 4.11.0 since the functionality was introduced in that version: . import transformers print(transformers.__version__) . 4.12.5 . You can find a script version of this notebook to fine-tune your model in a distributed fashion using multiple GPUs or TPUs here. . Fine-tuning a model on a token classification task . In this notebook, we will see how to fine-tune one of the ðŸ¤— Transformers model to a token classification task, which is the task of predicting a label for each token. . . The most common token classification tasks are: . NER (Named-entity recognition) Classify the entities in the text (person, organization, location...). | POS (Part-of-speech tagging) Grammatically classify the tokens (noun, verb, adjective...) | Chunk (Chunking) Grammatically classify the tokens and group them into &quot;chunks&quot; that go together | . We will see how to easily load a dataset for these kinds of tasks and use the Trainer API to fine-tune a model on it. . This notebook is built to run on any token classification task, with any model checkpoint from the Model Hub as long as that model has a version with a token classification head and a fast tokenizer (check on this table if this is the case). It might just need some small adjustments if you decide to use a different dataset than the one used here. Depending on you model and the GPU you are using, you might need to adjust the batch size to avoid out-of-memory errors. Set those three parameters, then the rest of the notebook should run smoothly: . task = &quot;ner&quot; # Should be one of &quot;ner&quot;, &quot;pos&quot; or &quot;chunk&quot; model_checkpoint = &quot;jimregan/BERTreach&quot; batch_size = 16 . Loading the dataset . We will use the ðŸ¤— Datasets library to download the data and get the metric we need to use for evaluation (to compare our model to the benchmark). This can be easily done with the functions load_dataset and load_metric. . from datasets import load_dataset, load_metric . For our example here, we&#39;ll use the CONLL 2003 dataset. The notebook should work with any token classification dataset provided by the ðŸ¤— Datasets library. If you&#39;re using your own dataset defined from a JSON or csv file (see the Datasets documentation on how to load them), it might need some adjustments in the names of the columns used. . datasets = load_dataset(&quot;wikiann&quot;, &quot;ga&quot;) . Reusing dataset wikiann (/root/.cache/huggingface/datasets/wikiann/ga/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e) . The datasets object itself is DatasetDict, which contains one key for the training, validation and test set. . datasets . DatasetDict({ validation: Dataset({ features: [&#39;tokens&#39;, &#39;ner_tags&#39;, &#39;langs&#39;, &#39;spans&#39;], num_rows: 1000 }) test: Dataset({ features: [&#39;tokens&#39;, &#39;ner_tags&#39;, &#39;langs&#39;, &#39;spans&#39;], num_rows: 1000 }) train: Dataset({ features: [&#39;tokens&#39;, &#39;ner_tags&#39;, &#39;langs&#39;, &#39;spans&#39;], num_rows: 1000 }) }) . We can see the training, validation and test sets all have a column for the tokens (the input texts split into words) and one column of labels for each kind of task we introduced before. . To access an actual element, you need to select a split first, then give an index: . datasets[&quot;train&quot;][0] . {&#39;langs&#39;: [&#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;], &#39;ner_tags&#39;: [0, 1, 2, 2, 0, 0, 0, 0, 5, 0, 0, 0], &#39;spans&#39;: [&#39;PER: PÃ¡draig Mac Piarais&#39;, &#39;LOC: Ã‰ireannach&#39;], &#39;tokens&#39;: [&#39;**&#39;, &#39;PÃ¡draig&#39;, &#39;Mac&#39;, &#39;Piarais&#39;, &#39;,&#39;, &#39;36&#39;, &#39;,&#39;, &#39;rÃ©abhlÃ³idÃ­&#39;, &#39;Ã‰ireannach&#39;, &#39;agus&#39;, &#39;[[file&#39;, &#39;.&#39;]} . The labels are already coded as integer ids to be easily usable by our model, but the correspondence with the actual categories is stored in the features of the dataset: . datasets[&quot;train&quot;].features[f&quot;ner_tags&quot;] . Sequence(feature=ClassLabel(num_classes=7, names=[&#39;O&#39;, &#39;B-PER&#39;, &#39;I-PER&#39;, &#39;B-ORG&#39;, &#39;I-ORG&#39;, &#39;B-LOC&#39;, &#39;I-LOC&#39;], names_file=None, id=None), length=-1, id=None) . So for the NER tags, 0 corresponds to &#39;O&#39;, 1 to &#39;B-PER&#39; etc... On top of the &#39;O&#39; (which means no special entity), there are four labels for NER here, each prefixed with &#39;B-&#39; (for beginning) or &#39;I-&#39; (for intermediate), that indicate if the token is the first one for the current group with the label or not: . &#39;PER&#39; for person | &#39;ORG&#39; for organization | &#39;LOC&#39; for location | &#39;MISC&#39; for miscellaneous | . Since the labels are lists of ClassLabel, the actual names of the labels are nested in the feature attribute of the object above: . label_list = datasets[&quot;train&quot;].features[f&quot;{task}_tags&quot;].feature.names label_list . [&#39;O&#39;, &#39;B-PER&#39;, &#39;I-PER&#39;, &#39;B-ORG&#39;, &#39;I-ORG&#39;, &#39;B-LOC&#39;, &#39;I-LOC&#39;] . To get a sense of what the data looks like, the following function will show some examples picked randomly in the dataset (automatically decoding the labels in passing). . from datasets import ClassLabel, Sequence import random import pandas as pd from IPython.display import display, HTML def show_random_elements(dataset, num_examples=10): assert num_examples &lt;= len(dataset), &quot;Can&#39;t pick more elements than there are in the dataset.&quot; picks = [] for _ in range(num_examples): pick = random.randint(0, len(dataset)-1) while pick in picks: pick = random.randint(0, len(dataset)-1) picks.append(pick) df = pd.DataFrame(dataset[picks]) for column, typ in dataset.features.items(): if isinstance(typ, ClassLabel): df[column] = df[column].transform(lambda i: typ.names[i]) elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel): df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x]) display(HTML(df.to_html())) . show_random_elements(datasets[&quot;train&quot;]) . tokens ner_tags langs spans . 0 [Burghley, House, ,, Belton, House] | [B-ORG, I-ORG, O, B-ORG, I-ORG] | [ga, ga, ga, ga, ga] | [ORG: Burghley House, ORG: Belton House] | . 1 [Ollscoil, Chathair, Bhaile, Ãtha, Cliath] | [B-ORG, I-ORG, I-ORG, I-ORG, I-ORG] | [ga, ga, ga, ga, ga] | [ORG: Ollscoil Chathair Bhaile Ãtha Cliath] | . 2 [DÃºchasach, do, rÃ©igiÃºn, na, MeÃ¡nmhara, .] | [O, O, O, B-LOC, I-LOC, O] | [ga, ga, ga, ga, ga, ga] | [LOC: na MeÃ¡nmhara] | . 3 [PÃ¡irc, an, ChrÃ³caigh, ,, Baile, Ãtha, Cliath] | [B-ORG, I-ORG, I-ORG, O, B-LOC, I-LOC, I-LOC] | [ga, ga, ga, ga, ga, ga, ga] | [ORG: PÃ¡irc an ChrÃ³caigh, LOC: Baile Ãtha Cliath] | . 4 [TrÃ¡igh, MhÃ³r, ,, An, Tuirc] | [B-ORG, I-ORG, O, B-LOC, I-LOC] | [ga, ga, ga, ga, ga] | [ORG: TrÃ¡igh MhÃ³r, LOC: An Tuirc] | . 5 [BhÃ­, turas, An, RÃ­ocht, Aontaithe, agus, Ã‰ire, acu, Ã³n, Eanair, go, dtÃ­, mBealtaine, .] | [O, O, B-LOC, I-LOC, I-LOC, O, B-LOC, O, O, O, O, O, O, O] | [ga, ga, ga, ga, ga, ga, ga, ga, ga, ga, ga, ga, ga, ga] | [LOC: An RÃ­ocht Aontaithe, LOC: Ã‰ire] | . 6 [TÃ¡, an, staid, tÃ³gtha, ar, shuÃ­omh, BhÃ³thair, LansdÃºin, .] | [O, O, O, O, O, O, B-ORG, I-ORG, O] | [ga, ga, ga, ga, ga, ga, ga, ga, ga] | [ORG: BhÃ³thair LansdÃºin] | . 7 [athsheoladh, PÃ³l, I, na, RÃºise] | [O, B-PER, I-PER, I-PER, I-PER] | [ga, ga, ga, ga, ga] | [PER: PÃ³l I na RÃºise] | . 8 [Liam, Ã“, Leathlobhair] | [B-PER, I-PER, I-PER] | [ga, ga, ga] | [PER: Liam Ã“ Leathlobhair] | . 9 [athsheoladh, SÃ©amas, II, Shasana] | [O, B-PER, I-PER, I-PER] | [ga, ga, ga, ga] | [PER: SÃ©amas II Shasana] | . Preprocessing the data . Before we can feed those texts to our model, we need to preprocess them. This is done by a ðŸ¤— Transformers Tokenizer which will (as the name indicates) tokenize the inputs (including converting the tokens to their corresponding IDs in the pretrained vocabulary) and put it in a format the model expects, as well as generate the other inputs that model requires. . To do all of this, we instantiate our tokenizer with the AutoTokenizer.from_pretrained method, which will ensure: . we get a tokenizer that corresponds to the model architecture we want to use, | we download the vocabulary used when pretraining this specific checkpoint. | . That vocabulary will be cached, so it&#39;s not downloaded again the next time we run the cell. . from transformers import RobertaTokenizerFast tokenizer = RobertaTokenizerFast.from_pretrained(model_checkpoint, add_prefix_space=True) . loading file https://huggingface.co/jimregan/BERTreach/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/9f02739afcb15f79a914d1dc3852921b35c28165868f21dc938b1219ff615ae7.dc1449771f2e5fcd30cf6d6723ec65f8c1106371f6ba60c9466df8d5e1567bca loading file https://huggingface.co/jimregan/BERTreach/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/0bd2316742dd7dd681cffbf4529ec3e97708bf173b741af7c38e60b3f649ed5a.2cbdc9a92c69faaa4556153a1d778a80b85e34b0d4cedb5774e31773edef57fd loading file https://huggingface.co/jimregan/BERTreach/resolve/main/tokenizer.json from cache at None loading file https://huggingface.co/jimregan/BERTreach/resolve/main/added_tokens.json from cache at None loading file https://huggingface.co/jimregan/BERTreach/resolve/main/special_tokens_map.json from cache at None loading file https://huggingface.co/jimregan/BERTreach/resolve/main/tokenizer_config.json from cache at None loading configuration file https://huggingface.co/jimregan/BERTreach/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/82da4bf21418a60a0d196c50342fe927af2c9187b87d319e7def1608dfdc0954.f6ebc79ab803ca349ef7b469b0fbe6aa40d053e3c1c2da0501521c46c2a51bb7 Model config RobertaConfig { &#34;architectures&#34;: [ &#34;RobertaForMaskedLM&#34; ], &#34;attention_probs_dropout_prob&#34;: 0.1, &#34;bos_token_id&#34;: 0, &#34;classifier_dropout&#34;: null, &#34;eos_token_id&#34;: 2, &#34;gradient_checkpointing&#34;: false, &#34;hidden_act&#34;: &#34;gelu&#34;, &#34;hidden_dropout_prob&#34;: 0.1, &#34;hidden_size&#34;: 768, &#34;initializer_range&#34;: 0.02, &#34;intermediate_size&#34;: 3072, &#34;layer_norm_eps&#34;: 1e-12, &#34;max_position_embeddings&#34;: 514, &#34;model_type&#34;: &#34;roberta&#34;, &#34;num_attention_heads&#34;: 12, &#34;num_hidden_layers&#34;: 6, &#34;pad_token_id&#34;: 1, &#34;position_embedding_type&#34;: &#34;absolute&#34;, &#34;transformers_version&#34;: &#34;4.12.5&#34;, &#34;type_vocab_size&#34;: 1, &#34;use_cache&#34;: true, &#34;vocab_size&#34;: 52000 } loading configuration file https://huggingface.co/jimregan/BERTreach/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/82da4bf21418a60a0d196c50342fe927af2c9187b87d319e7def1608dfdc0954.f6ebc79ab803ca349ef7b469b0fbe6aa40d053e3c1c2da0501521c46c2a51bb7 Model config RobertaConfig { &#34;architectures&#34;: [ &#34;RobertaForMaskedLM&#34; ], &#34;attention_probs_dropout_prob&#34;: 0.1, &#34;bos_token_id&#34;: 0, &#34;classifier_dropout&#34;: null, &#34;eos_token_id&#34;: 2, &#34;gradient_checkpointing&#34;: false, &#34;hidden_act&#34;: &#34;gelu&#34;, &#34;hidden_dropout_prob&#34;: 0.1, &#34;hidden_size&#34;: 768, &#34;initializer_range&#34;: 0.02, &#34;intermediate_size&#34;: 3072, &#34;layer_norm_eps&#34;: 1e-12, &#34;max_position_embeddings&#34;: 514, &#34;model_type&#34;: &#34;roberta&#34;, &#34;num_attention_heads&#34;: 12, &#34;num_hidden_layers&#34;: 6, &#34;pad_token_id&#34;: 1, &#34;position_embedding_type&#34;: &#34;absolute&#34;, &#34;transformers_version&#34;: &#34;4.12.5&#34;, &#34;type_vocab_size&#34;: 1, &#34;use_cache&#34;: true, &#34;vocab_size&#34;: 52000 } . The following assertion ensures that our tokenizer is a fast tokenizers (backed by Rust) from the ðŸ¤— Tokenizers library. Those fast tokenizers are available for almost all models, and we will need some of the special features they have for our preprocessing. . import transformers assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast) . You can check which type of models have a fast tokenizer available and which don&#39;t on the big table of models. . You can directly call this tokenizer on one sentence: . tokenizer(&quot;Is abairt amhÃ¡in Ã© seo!&quot;) . {&#39;input_ids&#39;: [0, 574, 3152, 799, 350, 369, 5, 2], &#39;attention_mask&#39;: [1, 1, 1, 1, 1, 1, 1, 1]} . Depending on the model you selected, you will see different keys in the dictionary returned by the cell above. They don&#39;t matter much for what we&#39;re doing here (just know they are required by the model we will instantiate later), you can learn more about them in this tutorial if you&#39;re interested. . If, as is the case here, your inputs have already been split into words, you should pass the list of words to your tokenzier with the argument is_split_into_words=True: . tokenizer([&quot;Hello&quot;, &quot;,&quot;, &quot;this&quot;, &quot;is&quot;, &quot;one&quot;, &quot;sentence&quot;, &quot;split&quot;, &quot;into&quot;, &quot;words&quot;, &quot;.&quot;], is_split_into_words=True) . {&#39;input_ids&#39;: [0, 838, 25201, 1094, 10285, 381, 15195, 50991, 5359, 809, 786, 2512, 22339, 38628, 968, 2], &#39;attention_mask&#39;: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} . Note that transformers are often pretrained with subword tokenizers, meaning that even if your inputs have been split into words already, each of those words could be split again by the tokenizer. Let&#39;s look at an example of that: . example = datasets[&quot;train&quot;][4] print(example[&quot;tokens&quot;]) . [&#39;TÃ¡&#39;, &#39;Ãras&#39;, &#39;an&#39;, &#39;UachtarÃ¡in&#39;, &#39;(&#39;, &#39;Ã¡it&#39;, &#39;chÃ³naithe&#39;, &#39;oifigiÃºil&#39;, &#39;UachtarÃ¡n&#39;, &#39;na&#39;, &#39;hÃ‰ireann&#39;, &#39;)&#39;, &#39;,&#39;, &#34;&#39;&#39;Deerfield&#34;, &#34;&#39;&#39;&#34;, &#39;(&#39;, &#39;Ã¡it&#39;, &#39;chÃ³naithe&#39;, &#39;oifigiÃºil&#39;, &#39;AmbasadÃ³ir&#39;, &#39;StÃ¡it&#39;, &#39;Aontaithe&#39;, &#39;MheiriceÃ¡&#39;, &#39;)&#39;, &#39;,&#39;, &#39;ZÃº&#39;, &#39;Bhaile&#39;, &#39;Ãtha&#39;, &#39;Cliath&#39;, &#39;,&#39;, &#39;agus&#39;, &#39;CeanncheathrÃº&#39;, &#39;an&#39;, &#39;Gharda&#39;, &#39;SÃ­ochÃ¡na&#39;, &#39;go&#39;, &#39;lÃ©ir&#39;, &#39;laistigh&#39;, &#39;den&#39;, &#39;phÃ¡irc&#39;, &#39;.&#39;] . tokenized_input = tokenizer(example[&quot;tokens&quot;], is_split_into_words=True) tokens = tokenizer.convert_ids_to_tokens(tokenized_input[&quot;input_ids&quot;]) print(tokens) . [&#39;&lt;s&gt;&#39;, &#39;Ä TÃƒÂ¡&#39;, &#39;Ä ÃƒÄ£ras&#39;, &#39;Ä an&#39;, &#39;Ä UachtarÃƒÂ¡in&#39;, &#39;Ä (&#39;, &#39;Ä ÃƒÂ¡it&#39;, &#39;Ä chÃƒÂ³naithe&#39;, &#39;Ä oifigiÃƒÂºil&#39;, &#39;Ä UachtarÃƒÂ¡n&#39;, &#39;Ä na&#39;, &#39;Ä hÃƒÄ«ireann&#39;, &#39;Ä )&#39;, &#39;Ä ,&#39;, &#34;Ä &#39;&#39;&#34;, &#39;De&#39;, &#39;er&#39;, &#39;field&#39;, &#34;Ä &#39;&#39;&#34;, &#39;Ä (&#39;, &#39;Ä ÃƒÂ¡it&#39;, &#39;Ä chÃƒÂ³naithe&#39;, &#39;Ä oifigiÃƒÂºil&#39;, &#39;Ä AmbasadÃƒÂ³ir&#39;, &#39;Ä StÃƒÂ¡it&#39;, &#39;Ä Aontaithe&#39;, &#39;Ä MheiriceÃƒÂ¡&#39;, &#39;Ä )&#39;, &#39;Ä ,&#39;, &#39;Ä Z&#39;, &#39;ÃƒÂº&#39;, &#39;Ä Bhaile&#39;, &#39;Ä ÃƒÄ£tha&#39;, &#39;Ä Cliath&#39;, &#39;Ä ,&#39;, &#39;Ä agus&#39;, &#39;Ä CeanncheathrÃƒÂº&#39;, &#39;Ä an&#39;, &#39;Ä Gharda&#39;, &#39;Ä SÃƒÅƒochÃƒÂ¡na&#39;, &#39;Ä go&#39;, &#39;Ä lÃƒÂ©ir&#39;, &#39;Ä laistigh&#39;, &#39;Ä den&#39;, &#39;Ä phÃƒÂ¡irc&#39;, &#39;Ä .&#39;, &#39;&lt;/s&gt;&#39;] . Here the words &quot;Zwingmann&quot; and &quot;sheepmeat&quot; have been split in three subtokens. . This means that we need to do some processing on our labels as the input ids returned by the tokenizer are longer than the lists of labels our dataset contain, first because some special tokens might be added (we can a [CLS] and a [SEP] above) and then because of those possible splits of words in multiple tokens: . len(example[f&quot;{task}_tags&quot;]), len(tokenized_input[&quot;input_ids&quot;]) . (41, 47) . Thankfully, the tokenizer returns outputs that have a word_ids method which can help us. . print(tokenized_input.word_ids()) . [None, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 13, 13, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, None] . As we can see, it returns a list with the same number of elements as our processed input ids, mapping special tokens to None and all other tokens to their respective word. This way, we can align the labels with the processed input ids. . word_ids = tokenized_input.word_ids() aligned_labels = [-100 if i is None else example[f&quot;{task}_tags&quot;][i] for i in word_ids] print(len(aligned_labels), len(tokenized_input[&quot;input_ids&quot;])) . 47 47 . Here we set the labels of all special tokens to -100 (the index that is ignored by PyTorch) and the labels of all other tokens to the label of the word they come from. Another strategy is to set the label only on the first token obtained from a given word, and give a label of -100 to the other subtokens from the same word. We propose the two strategies here, just change the value of the following flag: . label_all_tokens = True . We&#39;re now ready to write the function that will preprocess our samples. We feed them to the tokenizer with the argument truncation=True (to truncate texts that are bigger than the maximum size allowed by the model) and is_split_into_words=True (as seen above). Then we align the labels with the token ids using the strategy we picked: . def tokenize_and_align_labels(examples): tokenized_inputs = tokenizer(examples[&quot;tokens&quot;], truncation=True, is_split_into_words=True) labels = [] for i, label in enumerate(examples[f&quot;{task}_tags&quot;]): word_ids = tokenized_inputs.word_ids(batch_index=i) previous_word_idx = None label_ids = [] for word_idx in word_ids: # Special tokens have a word id that is None. We set the label to -100 so they are automatically # ignored in the loss function. if word_idx is None: label_ids.append(-100) # We set the label for the first token of each word. elif word_idx != previous_word_idx: label_ids.append(label[word_idx]) # For the other tokens in a word, we set the label to either the current label or -100, depending on # the label_all_tokens flag. else: label_ids.append(label[word_idx] if label_all_tokens else -100) previous_word_idx = word_idx labels.append(label_ids) tokenized_inputs[&quot;labels&quot;] = labels return tokenized_inputs . This function works with one or several examples. In the case of several examples, the tokenizer will return a list of lists for each key: . tokenize_and_align_labels(datasets[&#39;train&#39;][:5]) . Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation. . {&#39;input_ids&#39;: [[0, 5236, 14, 3650, 1619, 21240, 1094, 8584, 1094, 40980, 3337, 306, 6292, 74, 1806, 968, 2], [0, 5236, 14, 15068, 12965, 15693, 384, 4010, 17, 4294, 2], [0, 1146, 80, 1494, 15796, 691, 1094, 17961, 691, 2], [0, 691, 15693, 6207, 48172, 15693, 691, 2], [0, 1281, 11516, 275, 9918, 384, 756, 9978, 4030, 3476, 304, 1147, 4294, 1094, 15693, 1855, 553, 10428, 15693, 384, 756, 9978, 4030, 34067, 1647, 1927, 3616, 4294, 1094, 3999, 276, 2268, 1461, 1397, 1094, 306, 49963, 275, 5247, 4226, 341, 896, 1813, 460, 8981, 968, 2]], &#39;attention_mask&#39;: [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], &#39;labels&#39;: [[-100, 0, 0, 1, 2, 2, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, -100], [-100, 0, 0, 3, 4, 0, 0, 0, 0, 0, -100], [-100, 1, 1, 1, 0, 0, 0, 0, 0, -100], [-100, 0, 0, 5, 5, 0, 0, -100], [-100, 0, 3, 4, 4, 0, 0, 0, 0, 3, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 6, 0, 0, 3, 3, 4, 4, 4, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, -100]]} . To apply this function on all the sentences (or pairs of sentences) in our dataset, we just use the map method of our dataset object we created earlier. This will apply the function on all the elements of all the splits in dataset, so our training, validation and testing data will be preprocessed in one single command. . tokenized_datasets = datasets.map(tokenize_and_align_labels, batched=True) . Even better, the results are automatically cached by the ðŸ¤— Datasets library to avoid spending time on this step the next time you run your notebook. The ðŸ¤— Datasets library is normally smart enough to detect when the function you pass to map has changed (and thus requires to not use the cache data). For instance, it will properly detect if you change the task in the first cell and rerun the notebook. ðŸ¤— Datasets warns you when it uses cached files, you can pass load_from_cache_file=False in the call to map to not use the cached files and force the preprocessing to be applied again. . Note that we passed batched=True to encode the texts by batches together. This is to leverage the full benefit of the fast tokenizer we loaded earlier, which will use multi-threading to treat the texts in a batch concurrently. . Fine-tuning the model . Now that our data is ready, we can download the pretrained model and fine-tune it. Since all our tasks are about token classification, we use the AutoModelForTokenClassification class. Like with the tokenizer, the from_pretrained method will download and cache the model for us. The only thing we have to specify is the number of labels for our problem (which we can get from the features, as seen before): . from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer, AutoConfig config = AutoConfig.from_pretrained(model_checkpoint, id2label={i: label for i, label in enumerate(label_list)}, label2id={label: i for i, label in enumerate(label_list)}) model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, config=config) . loading configuration file https://huggingface.co/jimregan/BERTreach/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/82da4bf21418a60a0d196c50342fe927af2c9187b87d319e7def1608dfdc0954.f6ebc79ab803ca349ef7b469b0fbe6aa40d053e3c1c2da0501521c46c2a51bb7 Model config RobertaConfig { &#34;architectures&#34;: [ &#34;RobertaForMaskedLM&#34; ], &#34;attention_probs_dropout_prob&#34;: 0.1, &#34;bos_token_id&#34;: 0, &#34;classifier_dropout&#34;: null, &#34;eos_token_id&#34;: 2, &#34;gradient_checkpointing&#34;: false, &#34;hidden_act&#34;: &#34;gelu&#34;, &#34;hidden_dropout_prob&#34;: 0.1, &#34;hidden_size&#34;: 768, &#34;id2label&#34;: { &#34;0&#34;: &#34;O&#34;, &#34;1&#34;: &#34;B-PER&#34;, &#34;2&#34;: &#34;I-PER&#34;, &#34;3&#34;: &#34;B-ORG&#34;, &#34;4&#34;: &#34;I-ORG&#34;, &#34;5&#34;: &#34;B-LOC&#34;, &#34;6&#34;: &#34;I-LOC&#34; }, &#34;initializer_range&#34;: 0.02, &#34;intermediate_size&#34;: 3072, &#34;label2id&#34;: { &#34;B-LOC&#34;: 5, &#34;B-ORG&#34;: 3, &#34;B-PER&#34;: 1, &#34;I-LOC&#34;: 6, &#34;I-ORG&#34;: 4, &#34;I-PER&#34;: 2, &#34;O&#34;: 0 }, &#34;layer_norm_eps&#34;: 1e-12, &#34;max_position_embeddings&#34;: 514, &#34;model_type&#34;: &#34;roberta&#34;, &#34;num_attention_heads&#34;: 12, &#34;num_hidden_layers&#34;: 6, &#34;pad_token_id&#34;: 1, &#34;position_embedding_type&#34;: &#34;absolute&#34;, &#34;transformers_version&#34;: &#34;4.12.5&#34;, &#34;type_vocab_size&#34;: 1, &#34;use_cache&#34;: true, &#34;vocab_size&#34;: 52000 } https://huggingface.co/jimregan/BERTreach/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpv5o9vvd8 storing https://huggingface.co/jimregan/BERTreach/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/dd1b4fd9cac1b246d8d0fd055990d19837145ab67cc89c1c8a1af624e6679469.1da935a4b98fa14d6de9a52c0e4217ff97b262012d6f20bce405f3128b3b539d creating metadata file for /root/.cache/huggingface/transformers/dd1b4fd9cac1b246d8d0fd055990d19837145ab67cc89c1c8a1af624e6679469.1da935a4b98fa14d6de9a52c0e4217ff97b262012d6f20bce405f3128b3b539d loading weights file https://huggingface.co/jimregan/BERTreach/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/dd1b4fd9cac1b246d8d0fd055990d19837145ab67cc89c1c8a1af624e6679469.1da935a4b98fa14d6de9a52c0e4217ff97b262012d6f20bce405f3128b3b539d Some weights of the model checkpoint at jimregan/BERTreach were not used when initializing RobertaForTokenClassification: [&#39;lm_head.decoder.weight&#39;, &#39;lm_head.layer_norm.weight&#39;, &#39;lm_head.decoder.bias&#39;, &#39;lm_head.bias&#39;, &#39;lm_head.dense.bias&#39;, &#39;lm_head.layer_norm.bias&#39;, &#39;lm_head.dense.weight&#39;] - This IS expected if you are initializing RobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model). - This IS NOT expected if you are initializing RobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model). Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at jimregan/BERTreach and are newly initialized: [&#39;classifier.weight&#39;, &#39;classifier.bias&#39;] You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference. . The warning is telling us we are throwing away some weights (the vocab_transform and vocab_layer_norm layers) and randomly initializing some other (the pre_classifier and classifier layers). This is absolutely normal in this case, because we are removing the head used to pretrain the model on a masked language modeling objective and replacing it with a new head for which we don&#39;t have pretrained weights, so the library warns us we should fine-tune this model before using it for inference, which is exactly what we are going to do. . To instantiate a Trainer, we will need to define three more things. The most important is the TrainingArguments, which is a class that contains all the attributes to customize the training. It requires one folder name, which will be used to save the checkpoints of the model, and all other arguments are optional: . model_name = model_checkpoint.split(&quot;/&quot;)[-1] args = TrainingArguments( f&quot;BERTreach-finetuned-{task}&quot;, evaluation_strategy = &quot;epoch&quot;, learning_rate=2e-5, per_device_train_batch_size=batch_size, per_device_eval_batch_size=batch_size, num_train_epochs=5, weight_decay=0.01, push_to_hub=True, ) . PyTorch: setting up devices The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-). . Here we set the evaluation to be done at the end of each epoch, tweak the learning rate, use the batch_size defined at the top of the notebook and customize the number of epochs for training, as well as the weight decay. . The last argument to setup everything so we can push the model to the Hub regularly during training. Remove it if you didn&#39;t follow the installation steps at the top of the notebook. If you want to save your model locally in a name that is different than the name of the repository it will be pushed, or if you want to push your model under an organization and not your name space, use the hub_model_id argument to set the repo name (it needs to be the full name, including your namespace: for instance &quot;sgugger/bert-finetuned-ner&quot; or &quot;huggingface/bert-finetuned-ner&quot;). . Then we will need a data collator that will batch our processed examples together while applying padding to make them all the same size (each pad will be padded to the length of its longest example). There is a data collator for this task in the Transformers library, that not only pads the inputs, but also the labels: . from transformers import DataCollatorForTokenClassification data_collator = DataCollatorForTokenClassification(tokenizer) . The last thing to define for our Trainer is how to compute the metrics from the predictions. Here we will load the seqeval metric (which is commonly used to evaluate results on the CONLL dataset) via the Datasets library. . metric = load_metric(&quot;seqeval&quot;) . This metric takes list of labels for the predictions and references: . labels = [label_list[i] for i in example[f&quot;{task}_tags&quot;]] metric.compute(predictions=[labels], references=[labels]) . {&#39;LOC&#39;: {&#39;f1&#39;: 1.0, &#39;number&#39;: 1, &#39;precision&#39;: 1.0, &#39;recall&#39;: 1.0}, &#39;ORG&#39;: {&#39;f1&#39;: 1.0, &#39;number&#39;: 4, &#39;precision&#39;: 1.0, &#39;recall&#39;: 1.0}, &#39;overall_accuracy&#39;: 1.0, &#39;overall_f1&#39;: 1.0, &#39;overall_precision&#39;: 1.0, &#39;overall_recall&#39;: 1.0} . So we will need to do a bit of post-processing on our predictions: . select the predicted index (with the maximum logit) for each token | convert it to its string label | ignore everywhere we set a label of -100 | . The following function does all this post-processing on the result of Trainer.evaluate (which is a namedtuple containing predictions and labels) before applying the metric: . import numpy as np def compute_metrics(p): predictions, labels = p predictions = np.argmax(predictions, axis=2) # Remove ignored index (special tokens) true_predictions = [ [label_list[p] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels) ] true_labels = [ [label_list[l] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels) ] results = metric.compute(predictions=true_predictions, references=true_labels) return { &quot;precision&quot;: results[&quot;overall_precision&quot;], &quot;recall&quot;: results[&quot;overall_recall&quot;], &quot;f1&quot;: results[&quot;overall_f1&quot;], &quot;accuracy&quot;: results[&quot;overall_accuracy&quot;], } . Note that we drop the precision/recall/f1 computed for each category and only focus on the overall precision/recall/f1/accuracy. . Then we just need to pass all of this along with our datasets to the Trainer: . trainer = Trainer( model, args, train_dataset=tokenized_datasets[&quot;train&quot;], eval_dataset=tokenized_datasets[&quot;validation&quot;], data_collator=data_collator, tokenizer=tokenizer, compute_metrics=compute_metrics ) . Cloning https://huggingface.co/jimregan/BERTreach-finetuned-ner into local empty directory. . We can now finetune our model by just calling the train method: . trainer.train() . The following columns in the training set don&#39;t have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running training ***** Num examples = 1000 Num Epochs = 5 Instantaneous batch size per device = 16 Total train batch size (w. parallel, distributed &amp; accumulation) = 16 Gradient Accumulation steps = 1 Total optimization steps = 315 . . [315/315 20:00, Epoch 5/5] Epoch Training Loss Validation Loss Precision Recall F1 Accuracy . 1 | No log | 0.724926 | 0.364474 | 0.390508 | 0.377042 | 0.758436 | . 2 | No log | 0.585039 | 0.452903 | 0.494831 | 0.472940 | 0.807228 | . 3 | No log | 0.519152 | 0.494885 | 0.545583 | 0.518999 | 0.828796 | . 4 | No log | 0.504173 | 0.520788 | 0.559211 | 0.539316 | 0.834835 | . 5 | No log | 0.494351 | 0.520052 | 0.566729 | 0.542388 | 0.836561 | . &lt;/div&gt; &lt;/div&gt; The following columns in the evaluation set don&#39;t have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running Evaluation ***** Num examples = 1000 Batch size = 16 The following columns in the evaluation set don&#39;t have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running Evaluation ***** Num examples = 1000 Batch size = 16 The following columns in the evaluation set don&#39;t have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running Evaluation ***** Num examples = 1000 Batch size = 16 The following columns in the evaluation set don&#39;t have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running Evaluation ***** Num examples = 1000 Batch size = 16 The following columns in the evaluation set don&#39;t have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running Evaluation ***** Num examples = 1000 Batch size = 16 Training completed. Do not forget to share your model on huggingface.co/models =) . TrainOutput(global_step=315, training_loss=0.5451592823815724, metrics={&#39;train_runtime&#39;: 1204.9135, &#39;train_samples_per_second&#39;: 4.15, &#39;train_steps_per_second&#39;: 0.261, &#39;total_flos&#39;: 40232543021088.0, &#39;train_loss&#39;: 0.5451592823815724, &#39;epoch&#39;: 5.0}) . &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; The evaluate method allows you to evaluate again on the evaluation dataset or on another dataset: . trainer.evaluate() . The following columns in the evaluation set don&#39;t have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running Evaluation ***** Num examples = 1000 Batch size = 16 . . [63/63 00:44] {&#39;epoch&#39;: 5.0, &#39;eval_accuracy&#39;: 0.8365605828220859, &#39;eval_f1&#39;: 0.5423881268270744, &#39;eval_loss&#39;: 0.49435117840766907, &#39;eval_precision&#39;: 0.5200517464424321, &#39;eval_recall&#39;: 0.5667293233082706, &#39;eval_runtime&#39;: 45.3099, &#39;eval_samples_per_second&#39;: 22.07, &#39;eval_steps_per_second&#39;: 1.39} . To get the precision/recall/f1 computed for each category now that we have finished training, we can apply the same function as before on the result of the predict method: . predictions, labels, _ = trainer.predict(tokenized_datasets[&quot;validation&quot;]) predictions = np.argmax(predictions, axis=2) # Remove ignored index (special tokens) true_predictions = [ [label_list[p] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels) ] true_labels = [ [label_list[l] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels) ] results = metric.compute(predictions=true_predictions, references=true_labels) results . The following columns in the test set don&#39;t have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running Prediction ***** Num examples = 1000 Batch size = 16 . . [63/63 01:29] {&#39;LOC&#39;: {&#39;f1&#39;: 0.602130616025938, &#39;number&#39;: 1026, &#39;precision&#39;: 0.5736981465136805, &#39;recall&#39;: 0.6335282651072125}, &#39;ORG&#39;: {&#39;f1&#39;: 0.45705024311183146, &#39;number&#39;: 572, &#39;precision&#39;: 0.4259818731117825, &#39;recall&#39;: 0.493006993006993}, &#39;PER&#39;: {&#39;f1&#39;: 0.5199240986717268, &#39;number&#39;: 530, &#39;precision&#39;: 0.5229007633587787, &#39;recall&#39;: 0.5169811320754717}, &#39;overall_accuracy&#39;: 0.8365605828220859, &#39;overall_f1&#39;: 0.5423881268270744, &#39;overall_precision&#39;: 0.5200517464424321, &#39;overall_recall&#39;: 0.5667293233082706} . You can now upload the result of the training to the Hub, just execute this instruction: . trainer.push_to_hub() . Saving model checkpoint to BERTreach-finetuned-ner Configuration saved in BERTreach-finetuned-ner/config.json Model weights saved in BERTreach-finetuned-ner/pytorch_model.bin tokenizer config file saved in BERTreach-finetuned-ner/tokenizer_config.json Special tokens file saved in BERTreach-finetuned-ner/special_tokens_map.json To https://huggingface.co/jimregan/BERTreach-finetuned-ner cbc2561..d938626 main -&gt; main To https://huggingface.co/jimregan/BERTreach-finetuned-ner d938626..bc9642b main -&gt; main . &#39;https://huggingface.co/jimregan/BERTreach-finetuned-ner/commit/d938626d52f5779f475e84e8c628740fda278353&#39; . You can now share this model with all your friends, family, favorite pets: they can all load it with the identifier &quot;your-username/the-name-you-picked&quot; so for instance: . from transformers import AutoModelForTokenClassification model = AutoModelForTokenClassification.from_pretrained(&quot;sgugger/my-awesome-model&quot;) . &lt;/div&gt; .",
            "url": "https://jimregan.github.io/notes/irish/ner/bert/bertreach/2021/12/01/token_classification_bertreach.html",
            "relUrl": "/irish/ner/bert/bertreach/2021/12/01/token_classification_bertreach.html",
            "date": " â€¢ Dec 1, 2021"
        }
        
    
  
    
        ,"post35": {
            "title": "Interesting links, 29/11/2021",
            "content": "AcmhainnÃ­ Gaedhilge . Voces Uladh - mo sheanfhoclÃ³irÃ­n do Ghaeilge Uladh . Taisce Focal.doc . Mion-Ä‹aint na Miá¸‹e agus Ulaá¸‹ : PÃ¡draig Ã“ Dubhthaigh . The Irish Language in Rathlin Island, Co. Antrim : Nils M. Holmer . Duanaire na Miá¸‹e : Laoide, Seosamh, d. 1939 . SeaÄ‹rÃ¡n ÄŠairn tSiaá¸‹ail : aá¹rÃ¡n ilÄ‹eardaiá¸‹eaÄ‹ta agus seanÄ‹as sÃ­or-Ä‹uartaiá¸‹eÄ‹ta : Ã“ hÃr, MicheÃ¡l . LÃ©ightheoracht . Sean-GhnÃ¡s Mhuinntir Mhusgrave . Cnuasacht BÃ©aloideas Uladh . BBC - Irish - Ceann Dubhrann - sraith le John GhrÃ¡inne Ã³ Rann na Feirste . BBC Radio Ulster - Ceann Dubhrann, 05/07/2011, Ceann Dubhrann - eipeasÃ³id 1 . An Embryonic English-Ulster Irish Dictionary . Stair Faoi Cheilt . GAELDICT - Gaelic Textbase - An MilliÃºn Focal Conallach . Tobar na Gaedhilge . Cruinneas Gaedhilge . Focla agus Cainnteanna Gaedhilge I .",
            "url": "https://jimregan.github.io/notes/links/2021/11/29/misc-links.html",
            "relUrl": "/links/2021/11/29/misc-links.html",
            "date": " â€¢ Nov 29, 2021"
        }
        
    
  
    
        ,"post36": {
            "title": "SgÃ©ilÃ­nÃ­ na Finne",
            "content": "The original site is mirrored here . URLS = &quot;&quot;&quot; http://web.archive.org/web/20160720003620/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal01.html http://web.archive.org/web/20160612133120/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal02.html http://web.archive.org/web/20160612133013/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal03.html http://web.archive.org/web/20160612133127/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal04.html http://web.archive.org/web/20160612132904/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal05.html http://web.archive.org/web/20160612133018/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal06.html http://web.archive.org/web/20160612133132/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal07.html http://web.archive.org/web/20160612133302/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal08.html http://web.archive.org/web/20160612132911/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal09.html http://web.archive.org/web/20160612133023/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal10.html http://web.archive.org/web/20160612133308/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal11.html http://web.archive.org/web/20160612133028/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal12.html http://web.archive.org/web/20160612133137/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal13.html http://web.archive.org/web/20160612133033/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal14.html http://web.archive.org/web/20160612133313/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal15.html http://web.archive.org/web/20160612132916/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal16.html http://web.archive.org/web/20160612133144/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal17.html http://web.archive.org/web/20160612133149/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal18.html http://web.archive.org/web/20160612133154/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal19.html http://web.archive.org/web/20160612132921/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal20.html http://web.archive.org/web/20160612133039/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal21.html http://web.archive.org/web/20160612133159/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal22.html http://web.archive.org/web/20160612132926/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal23.html http://web.archive.org/web/20160612133204/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal24.html http://web.archive.org/web/20160612133044/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal25.html http://web.archive.org/web/20160612133059/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal26.html http://web.archive.org/web/20160612132931/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal27.html http://web.archive.org/web/20160612133318/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal28.html http://web.archive.org/web/20160612133323/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal29.html http://web.archive.org/web/20160612132936/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal30.html http://web.archive.org/web/20160612132941/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal31.html http://web.archive.org/web/20160612132946/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal32.html http://web.archive.org/web/20160612133328/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal33.html http://web.archive.org/web/20160612132951/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal34.html http://web.archive.org/web/20160612133209/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal35.html http://web.archive.org/web/20160612133218/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal36.html http://web.archive.org/web/20160608213843/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal37.html &quot;&quot;&quot; . MODERN = &quot;&quot;&quot; ruadh rua ruaidh ruaÃ­ chomhnuidhe chÃ³naÃ­ cheann-tuigheadh cheann tuÃ­adh rabh raibh da dÃ¡ muinteardha muinteartha chroidhe chroÃ­ saoghal saol Ã©irghe Ã©irÃ­ leath-mheasardha leathmheasartha brÃºighte brÃºite crÃ¡idhte crÃ¡ite bÃ¡idhte bÃ¡ite de&#39;n den &quot;&quot;&quot; . For the most part, the modernised forms are the standard forms. Others, such as &#39;ruaÃ­&#39;, exist as dialectal forms, while &#39;ceann tuÃ­adh&#39; does not, but this matches what was spoken. . UNATTESTED = &quot;&quot;&quot; cheann-tuigheadh &quot;&quot;&quot; . STANDARD = &quot;&quot;&quot; ruaidh rua caidÃ© cad Ã© cheann-tuigheadh cheann tuÃ­ &quot;&quot;&quot; . PREPEND_SCEAL = &quot;02 03&quot; PREPEND_CEACHT = &quot;04 05&quot; PREPEND_UIMHIR = &quot;06 07 08 09 10 11 12 13 14 15 16 18 23&quot; . _tmp_mod = [a.split(&quot; t&quot;) for a in MODERN.split(&quot; n&quot;) if &quot; t&quot; in a] . modern = {a[0]: a[1] for a in _tmp_mod} . _END_TB = &quot;&lt;!-- END WAYBACK TOOLBAR INSERT --&gt;&quot; . import requests from bs4 import BeautifulSoup . test = &quot;http://web.archive.org/web/20160612132931/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal27.html&quot; req = requests.get(test) . req.status_code . 200 . text = req.text if _END_TB in text: text = text.split(_END_TB)[1] if &quot;&lt;hr&gt;&quot; in text: text = text.split(&quot;&lt;hr&gt;&quot;)[0].strip() . text . extt = BeautifulSoup(text, &quot;lxml&quot;) . extt.text . header = extt.find(&quot;font&quot;, {&quot;size&quot;: 5}) . titles = header.find_all(&quot;b&quot;) . if len(titles) == 1: title = titles[0].text . title . &#39;CrÃ­onnacht Madaidh.&#39; . for i in extt.find_all(&quot;font&quot;, {&quot;size&quot;: 5}): i.decompose() . extt .",
            "url": "https://jimregan.github.io/notes/irish/scraper/todo/2021/11/26/sgeilini-na-finne.html",
            "relUrl": "/irish/scraper/todo/2021/11/26/sgeilini-na-finne.html",
            "date": " â€¢ Nov 26, 2021"
        }
        
    
  
    
        ,"post37": {
            "title": "Interesting links, 25/11/2021",
            "content": "ELS-RD/transformer-deploy â€” Deploy optimized transformer based models in production . davidbrochart/nbterm . Fine-tuning XLS-R for Multi-Lingual ASR with ðŸ¤— Transformers, fairseq, Facebook AI blog . facebookresearch/covost . CoVoST 2 and Massively Multilingual Speech-to-Text Translation . Pygments lexer . jusText 3 â€” jusText is a tool for removing boilerplate content . Onion â€” onion (ONe Instance ONly) is a tool for removing duplicate parts from large collections of texts. . rsling/texrex â€” texrex web page cleaning &amp; ClaraX random walk crawler . Common Crawled web corpora . Representation Learning with Contrastive Predictive Coding, facebookresearch/CPC_audio . bshall/VectorQuantizedCPC . menelik3/cmudict-ipa â€” The CMU Pronouncing Dictionary converted to IPA . A cross-linguistic database of phonetic transcription systems . glottobank/potential-of-cognate-detection â€” Source code and data accompanying the paper â€œThe Potential of Automatic Word Comparison for Historical Linguisticsâ€ . glottobank/tukano â€” Repository for computer-guided reconstruction with Jena wordlist standard for Tukano language data . Cpc vox populi #965 . flashlight/flashlight/app/asr/tools/alignment . wav2letter/recipes/lexicon_free . CMU Advanced NLP 2021 Prompting + Sequence-to-sequence Pre-training . ming024/FastSpeech2 â€” An implementation of Microsoftâ€™s â€œFastSpeech 2: Fast and High-Quality End-to-End Text to Speechâ€ . [Phrase Retrieval and Beyond | Princeton NLP Group](https://princeton-nlp.github.io/phrase-retrieval-and-beyond/) | . princeton-nlp/PURE A Frustratingly Easy Approach for Entity and Relation Extraction . princeton-nlp/LM-BFF LM-BFF. Better Few-shot Fine-tuning of Language Models . Docusaurus . camelot-dev/camelot â€” A Python library to extract tabular data from PDFs . neural-network-and-data-loading.ipynb . jina-ai/finetuner â€” Finetuning any DNN for better embedding on neural search tasks . ddbourgin/numpy-ml . jina-ai/jina â€” Cloud-native neural search framework for ð™–ð™£ð™® kind of data . kaldialign/setup.py . nnmnkwii_gallery/01-DNN-based statistical speech synthesis (en).ipynb . Character-level Convolutional Networks for Text Classification . toganlabs/seanchlo_keyboard/ . Todo . Die araner mundart/Lautlehre . Die araner mundart/WÃ¶rterbuch/Ã¦ È§ â€“ Wikisource . Lâ€™Accent dans le gaÃ«lique du Munster - Wikisource . patrickvonplaten/Wav2Vec2_PyCTCDecode . kensho-technologies/pyctcdecode . Whatâ€™s New in v3.2 . kaldi/run_segmentation_long_utts.sh . kaldi/egs/wsj/s5/steps/cleanup . kaldi/clean_and_segment_data.sh . kaldi/decode_segmentation.sh . Paracrawl . [OSCAR 21.09 | OSCAR](https://oscar-corpus.com/post/oscar-v21-09/) | . kaldialign/calign.pxd . ga-conj-1a .",
            "url": "https://jimregan.github.io/notes/links/2021/11/25/misc-links.html",
            "relUrl": "/links/2021/11/25/misc-links.html",
            "date": " â€¢ Nov 25, 2021"
        }
        
    
  
    
        ,"post38": {
            "title": "Interesting links, 23/11/2021",
            "content": "Tutorial on ASR inference and alignment with CTC model . gaBERT â€“ an Irish Language Model . Speech Resynthesis from Discrete Disentangled Self-Supervised Representations . facebookresearch/libri-light, blog . Libri-light Data Preparation and Download . fairseq/examples/textless_nlp/gslm/speech2unit/clustering . fairseq/cpc_feature_reader.py . fairseq/examples/textless_nlp/gslm . fairseq/resynthesize_speech.py . flashlight/InferenceAndAlignmentCTC.ipynb . libri-light/make_vad_inputs.py . libri-light/data_preparation . Data Preparation Â· flashlight/wav2letter Wiki . libri-light/wl_decoder.py . format-corpus/pdfCabinetOfHorrors . [Text and tables Extraction from docx in Python | by Mukesh Kumar | Medium](https://medium.com/@Mukesh_Kumar/text-extraction-from-docx-readable-pdf-and-scanned-pdf-formats-in-python-b6c5712271ee) | . language-resources/make-alignable-symbols.cc .",
            "url": "https://jimregan.github.io/notes/links/2021/11/23/misc-links.html",
            "relUrl": "/links/2021/11/23/misc-links.html",
            "date": " â€¢ Nov 23, 2021"
        }
        
    
  
    
        ,"post39": {
            "title": "Interesting links, 18/11/2021",
            "content": "Comhairle Gaeilge . PEIG.ie . SeÃ³ BÃ³thair - Conradh na Gaeilge . Gaeilge.ie . An Ghaeilge . An Gum . XML Sitemap . Gluaiseacht . Tuiscint don EalaÃ­n - An Gum . XML Sitemap Feed . [An Tairseach | COGG](https://www.cogg.ie/tairseach/) | . [AcmhainnÃ­ TacaÃ­ochta | COGG](https://www.cogg.ie/acmhainni-tacaiochtaâ€”gaeilge-na-sraithe-sinsearai/) | . TÃ­reolaÃ­ocht na hArdteiste . Studyclix . [AcmhainnÃ­ Teanga ar LÃ­ne | COGG](https://www.cogg.ie/focloiri/) | . Ranganna.com . Gaeilge na Sraithe SinsearaÃ­ . LÃ©ann Teanga - An ReiviÃº . www.acadamh.ie . An Taibhdhearc . [Taighde COGG | COGG](https://www.cogg.ie/taighde-cogg/) | . Wayback Machine . Acadamh - NUI Galway .",
            "url": "https://jimregan.github.io/notes/links/todo/irish/scraper/2021/11/18/irish-to-scrape.html",
            "relUrl": "/links/todo/irish/scraper/2021/11/18/irish-to-scrape.html",
            "date": " â€¢ Nov 18, 2021"
        }
        
    
  
    
        ,"post40": {
            "title": "Interesting links, 17/11/2021",
            "content": "lumaku/ctc-segmentation â€” Segment an audio file and obtain utterance alignments. (Python package) . My Munster Irish Library . Multilingual Transfer of Acoustic Word Embeddings Improves When Training on Languages Related to the Target Zero-Resource Language, pdf . @inproceedings{jacobs21_interspeech, author={Christiaan Jacobs and Herman Kamper}, title=, year=2021, booktitle={Proc. Interspeech 2021}, pages={1549--1553}, doi={10.21437/Interspeech.2021-461} } . Towards Unsupervised Phone and Word Segmentation Using Self-Supervised Vector-Quantized Neural Networks, pdf . @inproceedings{kamper21_interspeech, author={Herman Kamper and Benjamin van Niekerk}, title=, year=2021, booktitle={Proc. Interspeech 2021}, pages={1539--1543}, doi={10.21437/Interspeech.2021-50} } . bshall/VectorQuantizedCPC â€” Vector-Quantized Contrastive Predictive Coding for Acoustic Unit Discovery and Voice Conversion . worldveil/dejavu â€” Audio fingerprinting and recognition in Python . Self-Supervised End-to-End ASR for Low Resource L2 Swedish, pdf, data to appear in Kielipankki . @inproceedings{alghezi21_interspeech, author={Ragheb Al-Ghezi and Yaroslav Getman and Aku Rouhe and Raili HildÃ©n and Mikko Kurimo}, title=, year=2021, booktitle={Proc. Interspeech 2021}, pages={1429--1433}, doi={10.21437/Interspeech.2021-1710} } . xinjli/allosaurus â€” Allosaurus is a pretrained universal phone recognizer for more than 2000 languages . cldf/cldf[https://github.com/cldf/cldf] CLDF â€” Cross-Linguistic Data Formats . kylebgorman/perceptronix â€” Sparse and dense linear models, for C++ and Python, with funny optimizations . AI - Here for Good â€” National Artificial Intelligence Strategy for Ireland . National-AI-Strategy.pdf . neulab/awesome-align â€” A neural word aligner based on multilingual BERT . xinjli/allosaurus â€” Allosaurus is a pretrained universal phone recognizer for more than 2000 languages . neuspell/neuspell â€” A Neural Spelling Correction Toolkit . Gender in Irish between continuity and change . Re-open . kaldi-long-audio-alignment/build-trigram.sh . voxpopuli/voxpopuli/segmentation . voxpopuli/get_segment_pyannote_speaker.py . amsehili/auditok â€” An audio/acoustic activity detection and audio segmentation tool . voxpopuli/run_pyannote_sd.py . silero-vad.ipynb . kaldi/make_biased_lm_graphs.sh at master . kaldi/learn_lexicon_greedy.sh at master . kaldi/egs/wsj/s5/steps/segmentation at master . Wymysorys . Wymysorys pronunciation . Wp/wym/Adam Mickiewicz . A Andrason and T Krol WYMYSORYS GRAMMAR . Language attitudes in Wilamowice part 2 wym . JÃ³zef Gara - SÅ‚ownik jÄ™zyka wilamowskiego . JÃ³zef Gara - ZbiÃ³r wierszy o wilamowskich obrzÄ™dach i obyczajach.pdf . Vilamovian terms with IPA pronunciation - Wiktionary . Slownik jezyka wilamowskiego . Aragonese . Arredol . Academia de lâ€™Aragon .",
            "url": "https://jimregan.github.io/notes/links/2021/11/17/misc-links.html",
            "relUrl": "/links/2021/11/17/misc-links.html",
            "date": " â€¢ Nov 17, 2021"
        }
        
    
  
    
        ,"post41": {
            "title": "Split sentences from datasets",
            "content": "!pip install mosestokenizer . from datasets import load_dataset . script = &quot;/home/jim/Playing/notes/_drafts/nos.py&quot; nos = load_dataset(script, &#39;documents&#39;) . from mosestokenizer import * . sentences = 0 with MosesSentenceSplitter(&#39;ga&#39;) as splitsents: with open(&quot;/tmp/nos.txt&quot;, &quot;w&quot;) as outf: for item in nos[&#39;train&#39;]: outf.write(item[&#39;title&#39;] + &quot; n&quot;) sentences += 1 if not item[&#39;text&#39;]: continue sents = splitsents([item[&#39;text&#39;]]) sentences += len(sents) for sentence in sents: outf.write(sentence + &quot; n&quot;) . sentences .",
            "url": "https://jimregan.github.io/notes/datasets/2021/11/16/split-sentences-datasets.html",
            "relUrl": "/datasets/2021/11/16/split-sentences-datasets.html",
            "date": " â€¢ Nov 16, 2021"
        }
        
    
  
    
        ,"post42": {
            "title": "Convert to flac for wav2vec",
            "content": "BASE_PATH = &quot;/home/jim/Playing/unlabelled&quot; . files = [] with open(f&quot;{BASE_PATH}/ina/no-music&quot;) as inf: for line in inf.readlines(): stripped = line.strip() if stripped.startswith(&quot;./&quot;): stripped = stripped[2:] if stripped.endswith(&quot;.csv&quot;): stripped = stripped[0:-4] files.append(stripped) . exts = [&quot;m4a&quot;, &quot;mkv&quot;, &quot;mp3&quot;, &quot;MP3&quot;, &quot;mp4&quot;, &quot;wav&quot;] . from pathlib import Path . data = {} for file in files: for ext in exts: pathstr = f&quot;{BASE_PATH}/{file}.{ext}&quot; cur_path = Path(pathstr) if cur_path.is_file(): data[file] = pathstr . from pydub import AudioSegment . for basename, fname in data.items(): outstr = f&quot;{BASE_PATH}/flac/{basename}.flac&quot; audio = AudioSegment.from_file(fname) audio.export(outstr, format=&quot;flac&quot;, parameters=[&quot;-ac&quot;, &quot;1&quot;, &quot;-ar&quot;, &quot;16000&quot;]) . count = 1 with open(f&quot;{BASE_PATH}/vad_input.txt&quot;, &quot;w&quot;) as outf: for basename, fname in data.items(): outstr = f&quot;{BASE_PATH}/flac/{basename}.flac&quot; audio = AudioSegment.from_file(outstr) outf.write(f&quot;train{count:04d} {outstr} {audio.duration_seconds} n&quot;) count += 1 .",
            "url": "https://jimregan.github.io/notes/pydub/2021/11/12/convert-flac-for-fairseq.html",
            "relUrl": "/pydub/2021/11/12/convert-flac-for-fairseq.html",
            "date": " â€¢ Nov 12, 2021"
        }
        
    
  
    
        ,"post43": {
            "title": "Allosaurus to list",
            "content": "def allosaurus_to_list(filename): output = [] with open(filename) as f: for l in f.readlines(): line = l.strip().split(&quot; &quot;) output.append([line[0], line[2]]) return output . %%writefile test.txt 0.510 0.045 n 0.600 0.045 i 0.900 0.045 a 0.990 0.045 l 1.050 0.045 d 1.110 0.045 pÊ² 1.170 0.045 a 1.290 0.045 j 1.410 0.045 d . Writing test.txt . l = allosaurus_to_list(&quot;test.txt&quot;) . starts = [&#39;0.00&#39;] + [f[0] for f in l[0:-1]] . massaged = . [&#39;0.00&#39;, &#39;0.510&#39;, &#39;0.600&#39;, &#39;0.900&#39;, &#39;0.990&#39;, &#39;1.050&#39;, &#39;1.110&#39;, &#39;1.170&#39;, &#39;1.290&#39;] .",
            "url": "https://jimregan.github.io/notes/allosaurus/2021/11/11/allosaurus-to-list.html",
            "relUrl": "/allosaurus/2021/11/11/allosaurus-to-list.html",
            "date": " â€¢ Nov 11, 2021"
        }
        
    
  
    
        ,"post44": {
            "title": "Interesting links, 9/11/2021",
            "content": "Open English WordNet, github . babysor/MockingBird â€” Chinese voice cloning . Paste to Markdown . Middle Irish for Festus . erikrose/parsimonious . Irish lemmatiser for SpaCy, commit + data, commit . PyTorch Implementation of Daft-Exprt Robust Prosody Transfer Across Speakers for Expressive Speech Synthesis . kylebgorman/SOTA-taggers â€” Code for Gorman &amp; Bedrickâ€™s â€œWe need to talk about standard splitsâ€ (ACL â€˜19) . kylebgorman/latin_scansion . google/WikipediaHomographData . kylebgorman/swipe â€” A pitch tracker using Camachoâ€™s SWIPEâ€™ algorithm, written in C . kylebgorman/perceptronix . microsoft/UniSpeech â€” UniSpeech - Large Scale Self-Supervised Learning for Speech . facebookresearch/speech-resynthesis â€” An official reimplementation of the method described in the INTERSPEECH 2021 paper - Speech Resynthesis from Discrete Disentangled Self-Supervised Representations. arXiv â€” not open source . flashlight/InferenceAndAlignmentCTC.ipynb . facebookresearch/libri-light . Leveraging Phone Mask Training for Phonetic-Reduction-Robust E2E Uyghur Speech Recognition, pdf . @inproceedings{ma21_interspeech, author={Guodong Ma and Pengfei Hu and Jian Kang and Shen Huang and Hao Huang}, title=, year=2021, booktitle={Proc. Interspeech 2021}, pages={306--310}, doi={10.21437/Interspeech.2021-964} } . https://www.isca-speech.org/archive/interspeech_2021/hsu21_interspeech.html, pdf . @inproceedings{hsu21_interspeech, author={Wei-Ning Hsu and Anuroop Sriram and Alexei Baevski and Tatiana Likhomanenko and Qiantong Xu and Vineel Pratap and Jacob Kahn and Ann Lee and Ronan Collobert and Gabriel Synnaeve and Michael Auli}, title=, year=2021, booktitle={Proc. Interspeech 2021}, pages={721--725}, doi={10.21437/Interspeech.2021-236} } . wav2vec-C A Self-Supervised Model for Speech Representation Learning, pdf . @inproceedings{sadhu21_interspeech, author={Samik Sadhu and Di He and Che-Wei Huang and Sri Harish Mallidi and Minhua Wu and Ariya Rastrow and Andreas Stolcke and Jasha Droppo and Roland Maas}, title=, year=2021, booktitle={Proc. Interspeech 2021}, pages={711--715}, doi={10.21437/Interspeech.2021-717} } . audino A Modern Annotation Tool for Audio and Speech, midas-research/audino . CNN Explainer . Description dâ€™un parler irlandais de Kerry . Die araner mundart . Getting to Know the Mel Spectrogram . The Most Important Music Theory And How It Helps You Play Better . Diatonic Triads Diatonic 7th Chords . C: C E G B | Cmaj7 | . Dm: D F A C | Dm7 | . Em: E G B D | Em7 | . F: F A C E | Fmaj7 | . G: G B D F | G7 | . Am: A C E G | Am7 | . Bo: B D F A | Bm7b5 (BÃ¸) | .",
            "url": "https://jimregan.github.io/notes/links/2021/11/09/misc-links.html",
            "relUrl": "/links/2021/11/09/misc-links.html",
            "date": " â€¢ Nov 9, 2021"
        }
        
    
  
    
        ,"post45": {
            "title": "Basic wiki template parser using parsimonious",
            "content": "from parsimonious.grammar import Grammar grammar = Grammar( &quot;&quot;&quot; tplcall = tplopen tpltext (tplinner)+ tplclose tplinner = named / positional named = bar tpltext eq tpltext positional = bar tpltext tpltext = (&quot;{{=}}&quot; / ~r&quot;[^ } |=]&quot;)* tplchar = ~r&quot;[^ } |=]&quot; tplopen = &quot;{{&quot; tplclose = &quot;}}&quot; eq = &quot;=&quot; bar = &quot;|&quot; &quot;&quot;&quot; ) . test1 = &quot;{{tpl|foo|bar=baz||fooish{{=}}bar}}&quot; . print(grammar.parse(test1)) . &lt;Node called &#34;tplcall&#34; matching &#34;{{tpl|foo|bar=baz||fooish{{=}}bar}}&#34;&gt; &lt;Node called &#34;tplopen&#34; matching &#34;{{&#34;&gt; &lt;Node called &#34;tpltext&#34; matching &#34;tpl&#34;&gt; &lt;Node matching &#34;t&#34;&gt; &lt;RegexNode matching &#34;t&#34;&gt; &lt;Node matching &#34;p&#34;&gt; &lt;RegexNode matching &#34;p&#34;&gt; &lt;Node matching &#34;l&#34;&gt; &lt;RegexNode matching &#34;l&#34;&gt; &lt;Node matching &#34;|foo|bar=baz||fooish{{=}}bar&#34;&gt; &lt;Node called &#34;tplinner&#34; matching &#34;|foo&#34;&gt; &lt;Node called &#34;positional&#34; matching &#34;|foo&#34;&gt; &lt;Node called &#34;bar&#34; matching &#34;|&#34;&gt; &lt;Node called &#34;tpltext&#34; matching &#34;foo&#34;&gt; &lt;Node matching &#34;f&#34;&gt; &lt;RegexNode matching &#34;f&#34;&gt; &lt;Node matching &#34;o&#34;&gt; &lt;RegexNode matching &#34;o&#34;&gt; &lt;Node matching &#34;o&#34;&gt; &lt;RegexNode matching &#34;o&#34;&gt; &lt;Node called &#34;tplinner&#34; matching &#34;|bar=baz&#34;&gt; &lt;Node called &#34;named&#34; matching &#34;|bar=baz&#34;&gt; &lt;Node called &#34;bar&#34; matching &#34;|&#34;&gt; &lt;Node called &#34;tpltext&#34; matching &#34;bar&#34;&gt; &lt;Node matching &#34;b&#34;&gt; &lt;RegexNode matching &#34;b&#34;&gt; &lt;Node matching &#34;a&#34;&gt; &lt;RegexNode matching &#34;a&#34;&gt; &lt;Node matching &#34;r&#34;&gt; &lt;RegexNode matching &#34;r&#34;&gt; &lt;Node called &#34;eq&#34; matching &#34;=&#34;&gt; &lt;Node called &#34;tpltext&#34; matching &#34;baz&#34;&gt; &lt;Node matching &#34;b&#34;&gt; &lt;RegexNode matching &#34;b&#34;&gt; &lt;Node matching &#34;a&#34;&gt; &lt;RegexNode matching &#34;a&#34;&gt; &lt;Node matching &#34;z&#34;&gt; &lt;RegexNode matching &#34;z&#34;&gt; &lt;Node called &#34;tplinner&#34; matching &#34;|&#34;&gt; &lt;Node called &#34;positional&#34; matching &#34;|&#34;&gt; &lt;Node called &#34;bar&#34; matching &#34;|&#34;&gt; &lt;Node called &#34;tpltext&#34; matching &#34;&#34;&gt; &lt;Node called &#34;tplinner&#34; matching &#34;|fooish{{=}}bar&#34;&gt; &lt;Node called &#34;positional&#34; matching &#34;|fooish{{=}}bar&#34;&gt; &lt;Node called &#34;bar&#34; matching &#34;|&#34;&gt; &lt;Node called &#34;tpltext&#34; matching &#34;fooish{{=}}bar&#34;&gt; &lt;Node matching &#34;f&#34;&gt; &lt;RegexNode matching &#34;f&#34;&gt; &lt;Node matching &#34;o&#34;&gt; &lt;RegexNode matching &#34;o&#34;&gt; &lt;Node matching &#34;o&#34;&gt; &lt;RegexNode matching &#34;o&#34;&gt; &lt;Node matching &#34;i&#34;&gt; &lt;RegexNode matching &#34;i&#34;&gt; &lt;Node matching &#34;s&#34;&gt; &lt;RegexNode matching &#34;s&#34;&gt; &lt;Node matching &#34;h&#34;&gt; &lt;RegexNode matching &#34;h&#34;&gt; &lt;Node matching &#34;{{=}}&#34;&gt; &lt;Node matching &#34;{{=}}&#34;&gt; &lt;Node matching &#34;b&#34;&gt; &lt;RegexNode matching &#34;b&#34;&gt; &lt;Node matching &#34;a&#34;&gt; &lt;RegexNode matching &#34;a&#34;&gt; &lt;Node matching &#34;r&#34;&gt; &lt;RegexNode matching &#34;r&#34;&gt; &lt;Node called &#34;tplclose&#34; matching &#34;}}&#34;&gt; .",
            "url": "https://jimregan.github.io/notes/wiki/parsimonious/2021/11/08/basic-wiki-template-parser-with-parsimonious.html",
            "relUrl": "/wiki/parsimonious/2021/11/08/basic-wiki-template-parser-with-parsimonious.html",
            "date": " â€¢ Nov 8, 2021"
        }
        
    
  
    
        ,"post46": {
            "title": "Basic parser for Finck",
            "content": "!pip install parsimonious . from parsimonious.grammar import Grammar grammar = Grammar( &quot;&quot;&quot; node = seealso / translation seealso = italictxt comma ws see ws italictxt fullstop translation = italictxt fullstop ws german german = openq qtext closeq italictxt = italics phntext italics italics = &quot;*&quot; see = &quot;s.&quot; comma = &quot;,&quot; fullstop = &quot;.&quot; trscr = ~r&quot;[-Ã¦Å¡aiÅ•É™hxkÅ¡Å•Ì¥cÄºlÄlÌ„È§Ä“mvÅ„unÌ„]+&quot; phntext = ~r&#39;[^ *]+&#39; qtext = ~r&#39;[^&quot;]+&#39; num = ~r&#39;[0-9]+&#39; ref = &quot;St.-B.&quot; / &quot;W.&quot; gen = &quot;gen.&quot; ctext = ~r&#39;[^,]+&#39; openq = &quot;â€ž&quot; closeq = &#39;&quot;&#39; ws = ~&quot; s*&quot; &quot;&quot;&quot;) . test = &quot;*Ã¦vÅ„É™xÉ™*, s.Â *auÉ™nÌ„*.&quot; test2 = &#39;*á¸±Å•eÈ·Ä­m É™ n-Ã¦Å¡-aiÅ•É™ nÉ™ gorp*. â€žIch glaube an eine auferstehung des fleisches.&quot;&#39; . print(grammar.parse(test2)) . &lt;Node called &#34;node&#34; matching &#34;*á¸±Å•eÈ·Ä­m É™ n-Ã¦Å¡-aiÅ•É™ nÉ™ gorp*. â€žIch glaube an eine auferstehung des fleisches.&#34;&#34;&gt; &lt;Node called &#34;translation&#34; matching &#34;*á¸±Å•eÈ·Ä­m É™ n-Ã¦Å¡-aiÅ•É™ nÉ™ gorp*. â€žIch glaube an eine auferstehung des fleisches.&#34;&#34;&gt; &lt;Node called &#34;italictxt&#34; matching &#34;*á¸±Å•eÈ·Ä­m É™ n-Ã¦Å¡-aiÅ•É™ nÉ™ gorp*&#34;&gt; &lt;Node called &#34;italics&#34; matching &#34;*&#34;&gt; &lt;RegexNode called &#34;phntext&#34; matching &#34;á¸±Å•eÈ·Ä­m É™ n-Ã¦Å¡-aiÅ•É™ nÉ™ gorp&#34;&gt; &lt;Node called &#34;italics&#34; matching &#34;*&#34;&gt; &lt;Node called &#34;fullstop&#34; matching &#34;.&#34;&gt; &lt;RegexNode called &#34;ws&#34; matching &#34; &#34;&gt; &lt;Node called &#34;german&#34; matching &#34;â€žIch glaube an eine auferstehung des fleisches.&#34;&#34;&gt; &lt;Node called &#34;openq&#34; matching &#34;â€ž&#34;&gt; &lt;RegexNode called &#34;qtext&#34; matching &#34;Ich glaube an eine auferstehung des fleisches.&#34;&gt; &lt;Node called &#34;closeq&#34; matching &#34;&#34;&#34;&gt; .",
            "url": "https://jimregan.github.io/notes/finck/parsimonious/2021/11/07/parsimonious-for-finck.html",
            "relUrl": "/finck/parsimonious/2021/11/07/parsimonious-for-finck.html",
            "date": " â€¢ Nov 7, 2021"
        }
        
    
  
    
        ,"post47": {
            "title": "Interesting links, 3/11/2021",
            "content": "Wikisource . Crime and Punishment . Misc . Lochlann Vol III . cldf/cookbook . CUNY-CL/wikipron . CUNY-CL/wikipron-modeling/ .",
            "url": "https://jimregan.github.io/notes/links/2021/11/03/misc-links.html",
            "relUrl": "/links/2021/11/03/misc-links.html",
            "date": " â€¢ Nov 3, 2021"
        }
        
    
  
    
        ,"post48": {
            "title": "Irish IPA and alternatives from enwiktionary",
            "content": "https://dumps.wikimedia.org/enwiktionary/ . !wget https://dumps.wikimedia.org/enwiktionary/20211101/enwiktionary-20211101-pages-articles.xml.bz2 . --2021-11-02 17:31:36-- https://dumps.wikimedia.org/enwiktionary/20211101/enwiktionary-20211101-pages-articles.xml.bz2 Resolving dumps.wikimedia.org (dumps.wikimedia.org)... 208.80.154.7, 2620:0:861:1:208:80:154:7 Connecting to dumps.wikimedia.org (dumps.wikimedia.org)|208.80.154.7|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 892543646 (851M) [application/octet-stream] Saving to: â€˜enwiktionary-20211101-pages-articles.xml.bz2â€™ enwiktionary-202111 100%[===================&gt;] 851.20M 4.25MB/s in 3m 21s 2021-11-02 17:34:58 (4.23 MB/s) - â€˜enwiktionary-20211101-pages-articles.xml.bz2â€™ saved [892543646/892543646] . %%writefile extract-ipa.pl #!/usr/bin/perl use warnings; use strict; use utf8; binmode(STDIN, &quot;:utf8&quot;); binmode(STDOUT, &quot;:utf8&quot;); binmode(STDERR, &quot;:utf8&quot;); my $title = &#39;&#39;; while(&lt;&gt;) { chomp; if(/&lt;title&gt;([^&lt;]*)&lt; /title&gt;/) { $title = $1; } if(m! { {IPA |ga |!) { print &quot;$title t$_ n&quot;; } } . Writing extract-ipa.pl . !bzcat enwiktionary-20211101-pages-articles.xml.bz2|perl extract-ipa.pl &gt; wikt-ipa.txt . @phdthesis{hughes1986gaelic, title={The gaelic of Tangaveane and Commeen, County Donegal (texts, phonology, aspects of grammar and a vocabulary).}, author={Hughes, Arthur John}, year={1986}, school={Queen&#39;s University of Belfast} } . %%writefile extract-ulster.pl #!/usr/bin/perl while(&lt;&gt;) { chomp; print &quot;# $_ n&quot;; if(/^([^ t]+) t * ? { {a |[^}]+ } } { {IPA |ga |([^|]+) |qual1=before { {m |ga |sÃ© } }, { {m |ga |sÃ­ } }, { {m |ga |sibh } }, { {m |ga |siad } } | /([^ /]+) / |qual2=elsewhere } }/) { print &quot;$1 t$2 t t t tbefore sÃ©, sÃ­, sibh, siad n&quot;; print &quot;$1 t$3 t t t telsewhere n&quot;; } elsif(/^([^ t]+) t * { {a |([^}]+) } } { {IPA |ga |([^}]+) } }$/) { my $word = $1; my $dial = $2; my $pron = $3; $pron =~ s/ ///g; if($dial eq &#39;Ulster&#39;) { $dial = &quot;&quot;; } else { $dial = &quot; t t t t t t t t t t$dial&quot;; } if($pron =~ / |/) { for my $pp (split(/ |/, $pron)) { print &quot;$word t$pp&quot; . $dial . &quot; n&quot;; } } else { $pron =~ s/ [//g; $pron =~ s/ ]//g; print &quot;$word t$pron&quot; . $dial . &quot; n&quot;; } } } . %%writefile extract-alt-form.pl #!/usr/bin/perl use warnings; use strict; use utf8; binmode(STDIN, &quot;:utf8&quot;); binmode(STDOUT, &quot;:utf8&quot;); binmode(STDERR, &quot;:utf8&quot;); my $title = &#39;&#39;; my $polish_seen = 0; while(&lt;&gt;) { chomp; if(/&lt;title&gt;([^&lt;]*)&lt; /title&gt;/) { $title = $1; } if(m! { {alternative form of |ga |!) { print &quot;$title t$_ n&quot;; } } . Writing extract-alt-form.pl . !bzcat enwiktionary-20211101-pages-articles.xml.bz2|perl extract-alt-form.pl &gt; wikt-alts.txt .",
            "url": "https://jimregan.github.io/notes/irish/ipa/wiktionary/2021/11/02/irish-ipa-from-enwiktionary.html",
            "relUrl": "/irish/ipa/wiktionary/2021/11/02/irish-ipa-from-enwiktionary.html",
            "date": " â€¢ Nov 2, 2021"
        }
        
    
  
    
        ,"post49": {
            "title": "Interesting links, 1/11/2021",
            "content": "Grapheme-to-Phoneme Transduction for Cross-Language ASR, preprint . uiuc-sst/g2ps . Zero-shot Cross-Lingual Phonetic Recognition with External Language Embedding . tkipf/gcn â€” Implementation of Graph Convolutional Networks in TensorFlow . hpcaitech/ColossalAI . fairseq - add TTS . mgaido91/FBK-fairseq-ST . lumaku/ctc-segmentation â€” Segment an audio file and obtain utterance alignments . microsoft/unilm . microsoft/layoutxlm-base . microsoft/icecaps â€” Intelligent Conversation Engine: Code and Pre-trained Systems. Version 0.2.0. . chenzhuo1011/libri_css â€” Continuous speech separation . microsoft/UniSpeech â€” UniSpeech - Large Scale Self-Supervised Learning for Speech, transformers .",
            "url": "https://jimregan.github.io/notes/links/2021/11/01/misc-links.html",
            "relUrl": "/links/2021/11/01/misc-links.html",
            "date": " â€¢ Nov 1, 2021"
        }
        
    
  
    
        ,"post50": {
            "title": "Textgrid to .lab, take 2",
            "content": "from praatio import textgrid . from pathlib import Path . def get_combined_words_and_phones(filename): from praatio import textgrid tg = textgrid.openTextgrid(filename, False) if not tg.tierNameList: return [] if tg.tierNameList == [&#39;words&#39;, &#39;phones&#39;]: word_tier = &#39;words&#39; elif tg.tierNameList == [&#39;Word&#39;, &#39;phones&#39;]: word_tier = &#39;Word&#39; word = tg.tierDict[word_tier] phones = tg.tierDict[&#39;phones&#39;] i = 0 j = 0 out = [] def it_to_dict(it): ret = {} ret[&#39;start&#39;] = it.start ret[&#39;end&#39;] = it.end ret[&#39;label&#39;] = it.label return ret while i &lt; len(word.entryList) and j &lt; len(phones.entryList): cur_word = it_to_dict(word.entryList[i]) cur_word[&#39;phones&#39;] = [] while j &lt; len(phones.entryList) and phones.entryList[j].end &lt;= cur_word[&#39;end&#39;]: end_time = phones.entryList[j].end tmp_phone = it_to_dict(phones.entryList[j]) cur_word[&#39;phones&#39;].append(tmp_phone) j += 1 if end_time == cur_word[&#39;end&#39;]: i += 1 out.append(cur_word) continue return out . This phone merging is only intended to merge a silence or spoken noise &#39;phone&#39; to the left, but for the most part this doesn&#39;t do what I&#39;d wanted, as it often means a silence &#39;word&#39; has been inserted. . def merge_phones(word): outphones = [] if len(word[&#39;phones&#39;]) == 1: return word[&#39;phones&#39;] for i in range(0, len(word[&#39;phones&#39;])): if i &gt; 0 and word[&#39;phones&#39;][i][&#39;label&#39;] in [&quot;&quot;, &quot;sil&quot;, &quot;spn&quot;]: outphones[-1][&#39;end&#39;] = word[&#39;phones&#39;][i][&#39;end&#39;] else: outphones.append(word[&#39;phones&#39;][i]) return outphones . def tg_to_lab(filename, target=&quot;phones&quot;): combined = get_combined_words_and_phones(filename) merged = [merge_phones(x) for x in combined] flattened = [item for sublist in merged for item in sublist] out = [] for tmp_phone in flattened: start = int(tmp_phone[&#39;start&#39;] * 10000000) end = int(tmp_phone[&#39;end&#39;] * 10000000) label = tmp_phone[&#39;label&#39;] out.append(f&quot;{start} {end} {label}&quot;) return out . inpath = Path(&quot;/home/jim/Playing/mfa_alignments/snc-out&quot;) outpath = Path(&quot;/home/jim/Playing/mfa_alignments/snc-lab&quot;) for filename in inpath.glob(&quot;*.TextGrid&quot;): out = outpath / f&quot;{filename.stem}.lab&quot; lab = tg_to_lab(filename) with open(out, &quot;w&quot;) as outf: for line in lab: outf.write(line + &quot; n&quot;) .",
            "url": "https://jimregan.github.io/notes/textgrid/lab/2021/10/27/textgrid-to-lab-merging.html",
            "relUrl": "/textgrid/lab/2021/10/27/textgrid-to-lab-merging.html",
            "date": " â€¢ Oct 27, 2021"
        }
        
    
  
    
        ,"post51": {
            "title": "Interesting links, 25/10/2021",
            "content": "Swedish conversation fillers . Vad heter det? / Vahettere | Hur/vad var det nu, dÃ¥ | Vad skulle jag sÃ¤ga nu, dÃ¥ | Du vet (yâ€™know) | Typ/liksom (â€¦like) | SÃ¥ att (so thatâ€¦) | . jmccrae/irish_saffron . chartbeat-labs/textacy . Swagger editor . Using OntoLex-Lemon for Representing and Interlinking Lexicographic Collections of Bavarian Dialects . @inproceedings{abgaz-2020-using, title = &quot;Using {O}nto{L}ex-Lemon for Representing and Interlinking Lexicographic Collections of {B}avarian Dialects&quot;, author = &quot;Abgaz, Yalemisew&quot;, booktitle = &quot;Proceedings of the 7th Workshop on Linked Data in Linguistics (LDL-2020)&quot;, month = may, year = &quot;2020&quot;, address = &quot;Marseille, France&quot;, publisher = &quot;European Language Resources Association&quot;, url = &quot;https://aclanthology.org/2020.ldl-1.9&quot;, pages = &quot;61--69&quot;, language = &quot;English&quot;, ISBN = &quot;979-10-95546-36-8&quot;, } . pdf, code (not open source) . ming024/FastSpeech2 â€” An implementation of Microsoftâ€™s â€œFastSpeech 2: Fast and High-Quality End-to-End Text to Speechâ€ . bigscience-workshop/promptsource . aimhubio/aim . from aim.hugging_face import AimCallback # ... aim_callback = AimCallback(repo=&#39;/path/to/logs/dir&#39;, experiment=&#39;mnli&#39;) trainer = Trainer( model=model, args=training_args, train_dataset=train_dataset if training_args.do_train else None, eval_dataset=eval_dataset if training_args.do_eval else None, callbacks=[aim_callback], # ... ) . d99kris/spacy-cpp . r9y9/nnmnkwii . R2R .",
            "url": "https://jimregan.github.io/notes/links/2021/10/25/misc-links.html",
            "relUrl": "/links/2021/10/25/misc-links.html",
            "date": " â€¢ Oct 25, 2021"
        }
        
    
  
    
        ,"post52": {
            "title": "Interesting links, 23/10/2021",
            "content": "Phrase Retrieval and Beyond, princeton-nlp/DensePhrases . gong-io/gecko â€” Gecko - A Tool for Effective Annotation of Human Conversations . camelot-dev/camelot â€” A Python library to extract tabular data from PDFs . SheetJS/sheetjs â€” Spreadsheet Data Toolkit . html2pdf.js . trekhleb/javascript-algorithms . norvig/paip-lisp â€” Lisp code for the textbook â€œParadigms of Artificial Intelligence Programmingâ€ . electron/asar â€” Simple extensive tar-like archive format with indexing . ElementAI/picard â€” PICARD - Parsing Incrementally for Constrained Auto-Regressive Decoding from Language Models . aimhubio/aim â€” an easy-to-use and performant open-source experiment tracker. . jina-ai/finetuner â€” Finetuning any DNN for better embedding on neural search tasks .",
            "url": "https://jimregan.github.io/notes/links/2021/10/23/misc-links.html",
            "relUrl": "/links/2021/10/23/misc-links.html",
            "date": " â€¢ Oct 23, 2021"
        }
        
    
  
    
        ,"post53": {
            "title": "TextGrid to lab",
            "content": "from praatio import textgrid . from pathlib import Path . def tg_to_lab(filename, target=&quot;phones&quot;): tg = textgrid.openTextgrid(filename, False) if not tg.tierNameList or target not in tg.tierNameList: return [] phones = tg.tierDict[target] out = [] def it_to_dict(it): ret = {} ret[&#39;start&#39;] = it.start ret[&#39;end&#39;] = it.end ret[&#39;label&#39;] = it.label return ret for phone in phones.entryList: tmp_phone = it_to_dict(phone) start = int(tmp_phone[&#39;start&#39;] * 10000000) end = int(tmp_phone[&#39;end&#39;] * 10000000) label = tmp_phone[&#39;label&#39;] out.append(f&quot;{start} {end} {label}&quot;) return out . inpath = Path(&quot;/PATH/TO/FILES/INPUT&quot;) outpath = Path(&quot;/PATH/TO/FILES/OUTPUT&quot;) for filename in inpath.glob(&quot;*.TextGrid&quot;): out = outpath / f&quot;{filename.stem}.lab&quot; lab = tg_to_lab(filename) with open(out, &quot;w&quot;) as outf: for line in lab: outf.write(line + &quot; n&quot;) .",
            "url": "https://jimregan.github.io/notes/textgrid/lab/phonetic/todo/2021/10/22/textgrid-to-lab.html",
            "relUrl": "/textgrid/lab/phonetic/todo/2021/10/22/textgrid-to-lab.html",
            "date": " â€¢ Oct 22, 2021"
        }
        
    
  
    
        ,"post54": {
            "title": "Interesting links, 20/10/2021",
            "content": "Whose Language is it?: Struggles for Language Ownership in an Irish Language Classroom . Beaker Browser, beakerbrowser/beaker . Simple and Effective Zero-shot Cross-lingual Phoneme Recognition, models .",
            "url": "https://jimregan.github.io/notes/links/2021/10/20/misc-links.html",
            "relUrl": "/links/2021/10/20/misc-links.html",
            "date": " â€¢ Oct 20, 2021"
        }
        
    
  
    
        ,"post55": {
            "title": "Flashlight docker, 20/10/2021",
            "content": "$ docker pull flml/flashlight:cuda-latest cuda-latest: Pulling from flml/flashlight Digest: sha256:fbf98d7b813c05605a930c99d28942106232de0f2051ba8bd6f9066e22d5c1b6 . $ docker run -it flml/flashlight:cuda-latest bash . # export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/intel/compilers_and_libraries_2020.4.304/linux/mkl/lib/intel64_lin/:/opt/arrayfire/lib/ # ldconfig .",
            "url": "https://jimregan.github.io/notes/flashlight/docker/2021/10/20/flashlight-docker.html",
            "relUrl": "/flashlight/docker/2021/10/20/flashlight-docker.html",
            "date": " â€¢ Oct 20, 2021"
        }
        
    
  
    
        ,"post56": {
            "title": "Irish number normalisation with Pynini",
            "content": "!pip install -q condacolab import condacolab condacolab.install() . â¬ Downloading https://github.com/jaimergp/miniforge/releases/latest/download/Mambaforge-colab-Linux-x86_64.sh... ðŸ“¦ Installing... ðŸ“Œ Adjusting configuration... ðŸ©¹ Patching environment... â² Done in 0:00:39 ðŸ” Restarting kernel... . %%capture !conda install -c conda-forge pynini . %%capture !pip install pyicu . import pynini . import icu formatter = icu.RuleBasedNumberFormat(icu.URBNFRuleSetTag.SPELLOUT, icu.Locale(&#39;ga&#39;)) . for i in range(0, 10): print(formatter.format(i)) . a nÃ¡id a haon a dÃ³ a trÃ­ a ceathair a cÃºig a sÃ© a seacht a hocht a naoi . pynini.cross(&quot;0&quot;, &quot;a nÃ¡id&quot;) | pynini.cross(&quot;1&quot;, &quot;a haon&quot;) . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; FST 15 15 0 0 15&#45;&gt;0 0:0 8 8 15&#45;&gt;8 0:0 1 1 0&#45;&gt;1 48:97 9 9 8&#45;&gt;9 49:97 2 2 1&#45;&gt;2 0:32 3 3 2&#45;&gt;3 0:110 4 4 3&#45;&gt;4 0:195 5 5 4&#45;&gt;5 0:161 6 6 5&#45;&gt;6 0:105 7 7 6&#45;&gt;7 0:100 10 10 9&#45;&gt;10 0:32 11 11 10&#45;&gt;11 0:104 12 12 11&#45;&gt;12 0:97 13 13 12&#45;&gt;13 0:111 14 14 13&#45;&gt;14 0:110 i = 1 print(f&quot;{i:03d}&quot;) . 001 . count_1_999 = pynini.union(*[pynini.cross(f&quot;{i:03d}&quot;, formatter.format(i)) for i in range(1, 1000)]) . count_1_999_x1000 = pynini.union(*[pynini.cross(f&quot;{i:03d}&quot;, formatter.format(i * 1000)) for i in range(1, 1000)]) . (&quot;999&quot; @ count_1_999_x1000).string() . &#39;naoi gcÃ©ad nÃ³cha is naoi mÃ­le&#39; . count_1_999_x1000000 = pynini.union(*[pynini.cross(f&quot;{i:03d}&quot;, formatter.format(i * 1000000)) for i in range(1, 1000)]) . drop_000 = pynini.cross(&quot;000&quot;, &quot;&quot;) . ins_space = pynini.cross(&quot;&quot;, &quot; &quot;) . ins_space_or_is = (pynini.cross(&quot;&quot;, &quot; &quot;) | pynini.cross(&quot;&quot;, &quot; is &quot;)) . (&quot;999&quot; @ count_1_999_x1000000).string() . &#39;naoi gcÃ©ad nÃ³cha is naoi milliÃºn&#39; . count_1_999999 = (count_1_999_x1000 + drop_000 | count_1_999_x1000 + ins_space + count_1_999 | drop_000 + count_1_999) . (&quot;000001&quot; @ count_1_999999).string() . &#39;a haon&#39; . We want a fairly large number for this to be worth it; unfortunately, memory limits get in the way, so building up in sections is the only way forward. . IOW, pynini gives no advantage over thrax. . #count_0_1000000000000 = pynini.union(*[pynini.cross(f&quot;{i:03d}&quot;, formatter.format(i)) for i in range(0, 1000000000000)]) . I can still generate list parts, though . with open(&quot;count-1-999.tsv&quot;, &quot;w&quot;) as outf: for i in range(1, 1000): outf.write(f&quot;{i:03d} t{formatter.format(i)} n&quot;) . with open(&quot;count-1-999-thousands.tsv&quot;, &quot;w&quot;) as outf: for i in range(1, 1000): outf.write(f&quot;{i:03d} t{formatter.format(i * 1000)} n&quot;) . with open(&quot;count-1-999-billions.tsv&quot;, &quot;w&quot;) as outf: for i in range(1, 1000): outf.write(f&quot;{i:03d} t{formatter.format(i * 1000000000)} n&quot;) .",
            "url": "https://jimregan.github.io/notes/colab/pynini/2021/10/19/irish-numbers-with-pynini.html",
            "relUrl": "/colab/pynini/2021/10/19/irish-numbers-with-pynini.html",
            "date": " â€¢ Oct 19, 2021"
        }
        
    
  
    
        ,"post57": {
            "title": "Interesting links, 18/10/2021",
            "content": "xtermjs/xterm.js . l0phtcrack is open source. Havenâ€™t used it since 1998, but good to know. . bigscience/T0pp Â· Hugging Face . What every software engineer should know about search . McRank | LambdaRank | MatrixNet | Neural Vector Spaces for Unsupervised Information Retrieval | . Focus - Free edition .",
            "url": "https://jimregan.github.io/notes/links/2021/10/18/misc-links.html",
            "relUrl": "/links/2021/10/18/misc-links.html",
            "date": " â€¢ Oct 18, 2021"
        }
        
    
  
    
        ,"post58": {
            "title": "Merge TextGrid files",
            "content": "Turns out there&#39;s an example . from praatio import textgrid . from pathlib import Path . _BARE = Path(&quot;/home/jim/Playing/snc-comparison/bare/&quot;) _AUG = Path(&quot;/home/jim/Playing/snc-comparison/augmented/&quot;) _MRG = Path(&quot;/home/jim/Playing/snc-comparison/merged/&quot;) . for tg_file in _BARE.glob(&quot;*.TextGrid&quot;): aug_tg_file = _AUG / f&quot;{tg_file.stem}.TextGrid&quot; mrg_tg_file = _MRG / f&quot;{tg_file.stem}.TextGrid&quot; tg_bare = textgrid.openTextgrid(tg_file, False) tg_aug = textgrid.openTextgrid(aug_tg_file, False) tg_bare.addTier(textgrid.IntervalTier(&quot;words1&quot;, tg_aug.tierDict[&#39;words&#39;].entryList)) tg_bare.addTier(textgrid.IntervalTier(&quot;phones1&quot;, tg_aug.tierDict[&#39;phones&#39;].entryList)) tg_bare.save(mrg_tg_file, &quot;long_textgrid&quot;, True) .",
            "url": "https://jimregan.github.io/notes/praat/mfa/2021/10/18/merge-textgrids.html",
            "relUrl": "/praat/mfa/2021/10/18/merge-textgrids.html",
            "date": " â€¢ Oct 18, 2021"
        }
        
    
  
    
        ,"post59": {
            "title": "Download files as zip",
            "content": "See here . from zipfile import ZipFile from pathlib import Path zipname = &#39;audio.zip&#39; dirp = Path(&quot;/home/jim/Playing/mfa-corp/snc&quot;) filenames = dirp.glob(&#39;*.wav&#39;) with ZipFile(zipname, &#39;w&#39;) as zipf: for name in filenames: zipf.write(name) . from IPython.display import FileLink display(FileLink(&#39;audio.zip&#39;)) . audio.zip",
            "url": "https://jimregan.github.io/notes/jupyter/2021/10/18/download-files-as-zip.html",
            "relUrl": "/jupyter/2021/10/18/download-files-as-zip.html",
            "date": " â€¢ Oct 18, 2021"
        }
        
    
  
    
        ,"post60": {
            "title": "Expand Connaught lexicon",
            "content": "dictionary = open(&quot;/home/jim/Playing/mfa_alignments/snc.dict&quot;) dictionary2 = open(&quot;/home/jim/Playing/mfa_alignments/snc.dict.exp&quot;, &quot;w&quot;) . alts = { &quot;acu&quot;: &quot;acub&quot;, &quot;againn&quot;: &quot;ainn&quot;, &quot;agam&quot;: &quot;am&quot;, &quot;agamsa&quot;: &quot;amsa&quot;, &quot;agat&quot;: &quot;ad&quot;, &quot;agatsa&quot;: &quot;adsa&quot;, &quot;arÃ­s&quot;: &quot;arÃ­st&quot;, &quot;bÃ³thar&quot;: &quot;bÃ³r&quot;, &quot;ceistigh&quot;: &quot;ceisnigh&quot;, &quot;claÃ­&quot;: &quot;cladh&quot;, &quot;cluiche&quot;: &quot;cluife&quot;, &quot;contae&quot;: &quot;condae&quot;, &quot;croitheadh&quot;: &quot;crathadh&quot;, &quot;dada&quot;: &quot;tada&quot;, &quot;daoibh&quot;: &quot;dhaoib&quot;, &quot;de&quot;: &quot;dhe&quot;, &quot;de&quot;: &quot;ge&quot;, &quot;dearthÃ¡ir&quot;: &quot;driothÃ¡ir&quot;, &quot;dheirfiÃºr&quot;: &quot;dhrifiÃºr&quot;, &quot;dheirfiÃºracha&quot;: &quot;dhrifiÃºracha&quot;, &quot;dom&quot;: &quot;dhom&quot;, &quot;domsa&quot;: &quot;dhomsa&quot;, &quot;droichead&quot;: [&quot;draed&quot;, &quot;draighead&quot;], &quot;duit&quot;: &quot;dhuit&quot;, &quot;duitse&quot;: &quot;dhuitse&quot;, &quot;dÃ­bh&quot;: &quot;dÃ­ofa&quot;, &quot;dÃ­obh&quot;: &quot;dÃ­ob&quot;, &quot;dÃ³cha&quot;: &quot;dÃ³iche&quot;, &quot;dÃ³ibh&quot;: &quot;dÃ³ib&quot;, &quot;dÃ³igh&quot;: &quot;dÃ³iche&quot;, &quot;dÃºinn&quot;: &quot;dhÃºinn&quot;, &quot;fÃ©in&quot;: &quot;fhÃ©in&quot;, &quot;foighne&quot;: &quot;foighid&quot;, &quot;folach&quot;: &quot;falach&quot;, &quot;foscadh&quot;: &quot;fascadh&quot;, &quot;gnaithe&quot;: &quot;gnaÃ­the&quot;, &quot;iÃºdÃ¡s&quot;: &quot;iÃºdas&quot;, &quot;leo&quot;: [&quot;leob&quot;, &quot;leofa&quot;], &quot;lÃ©i&quot;: [&quot;lÃ©ithe&quot;, &quot;lÃ©Ã­&quot;], &quot;litir&quot;: &quot;leitir&quot;, &quot;luigh&quot;: &quot;loigh&quot;, &quot;luÃ­&quot;: &quot;loighe&quot;, &quot;mÃ©&quot;: &quot;me&quot;, &quot;naimhdeach&quot;: &quot;nÃ¡imhdeach&quot;, &quot;namhaid&quot;: &quot;nÃ¡imhid&quot;, &quot;nuacht&quot;: &quot;nuaÃ­ocht&quot;, &quot;nuachta&quot;: &quot;nuaÃ­ochta&quot;, &quot;nÃ³imÃ©ad&quot;: [&quot;mÃ³imÃ©ad&quot;, &quot;mhÃ³imÃ©ad&quot;], &quot;nÃ³imÃ©id&quot;: [&quot;mÃ³imÃ©id&quot;, &quot;mhÃ³imÃ©id&quot;], &quot;orthu&quot;: &quot;orthub&quot;, &quot;scafÃ¡nta&quot;: &quot;scufÃ¡nta&quot;, &quot;scornach&quot;: &quot;scÃ³rnach&quot;, &quot;sÃ©&quot;: &quot;se&quot;, &quot;sibh&quot;: &quot;sib&quot;, &quot;taispeÃ¡in&quot;: &quot;taspÃ¡in&quot;, &quot;taispeÃ¡nfaidh&quot;: &quot;taspÃ¡nfaidh&quot;, &quot;teacht&quot;: &quot;tÃ­ocht&quot;, &quot;theacht&quot;: &quot;thÃ­ocht&quot;, } nonwords = { &quot;bÃ³r&quot;: &quot;b oo r&quot;, &quot;draed&quot;: &quot;d r ee d&quot;, &quot;draighead&quot;: &quot;d r ai d&quot;, &quot;ge&quot;: &quot;g @&quot;, &quot;lÃ©Ã­&quot;: &quot;lj ee ii&quot;, } maybe_missing = { &quot;duit&quot;: &quot;d i tj&quot;, &quot;nuaÃ­ocht&quot;: &quot;n uu i@ x t&quot;, &quot;nuaÃ­ochta&quot;: &quot;n uu i@ x t @&quot;, &quot;am&quot;: &quot;a m&quot;, # a&#39;m &quot;mÃ³imÃ©ad&quot;: &quot;m oo mj ee d&quot;, &quot;mÃ³imÃ©id&quot;: &quot;m oo mj ee dj&quot;, &quot;mhÃ³imÃ©ad&quot;: &quot;v oo mj ee d&quot;, &quot;mhÃ³imÃ©id&quot;: &quot;v oo mj ee dj&quot;, &quot;taspÃ¡nfaidh&quot;: &quot;t @ s p aa nn h @&quot;, # 0 t @ s . 1 p aa nn . 0 h @ } _ALTS = {**nonwords, **maybe_missing} _SOUGHT = [] _SKIP_ALTS = [] for (a, b) in alts.items(): if type(b) == list: for x in b: if x not in _ALTS.keys(): _SOUGHT.append(x) else: if b not in _ALTS.keys(): _SOUGHT.append(b) _REVERSE_ALTS = {} for item in alts.items(): if type(item[1]) == list: items = item[1] else: items = [item[1]] for sitem in items: if sitem not in _REVERSE_ALTS.keys(): _REVERSE_ALTS[sitem] = set() _REVERSE_ALTS[sitem].add(item[0]) . def deletable_schwa_single(word, phones): out = [] out.append((word, phones)) if len(phones) == 1 and phones[0] == &#39;@&#39;: out.append((word, [&quot;sil&quot;])) else: if phones[0] == &#39;@&#39;: out.append((word, phones[1:])) if phones[-1] == &#39;@&#39;: out.append((word, phones[1:-1])) if phones[-1] == &#39;@&#39;: out.append((word, phones[:-1])) return out def deletable_schwa(wordlist): out = [] for item in wordlist: out += deletable_schwa_single(item[0], item[1]) return out . def nasal_o(item): # FIXME: way too simplistic word = item[0] phones = item[1] phonestr = &quot; &quot;.join(phones) out = [item] if &quot;mÃ³&quot; in word and &quot;m oo&quot; in phonestr: outph = phonestr.replace(&quot;m oo&quot;, &quot;m uu&quot;).split(&quot; &quot;) out.append((word, outph)) if &quot;mhÃ³&quot; in word and &quot;v oo&quot; in phonestr: outph = phonestr.replace(&quot;v oo&quot;, &quot;v uu&quot;).split(&quot; &quot;) out.append((word, outph)) if &quot;nÃ³&quot; in word and &quot;n oo&quot; in phonestr: outph = phonestr.replace(&quot;n oo&quot;, &quot;n uu&quot;).split(&quot; &quot;) out.append((word, outph)) return out . def endswith_list(text, endings): for ending in endings: if text.endswith(ending): return True return False def handle_igh(item): if type(item) != tuple: raise Exception(&quot;item is not a tuple: &quot; + item) word = item[0] phones = item[1] out = [item] if word.endswith(&quot;igh&quot;) and phones[-1] == &quot;@&quot;: out.append((word, phones[0:-1] + [&quot;ii&quot;])) if word.endswith(&quot;igh&quot;) and phones[-1] == &quot;ii&quot;: if not endswith_list(word, [&quot;uigh&quot;, &quot;aoigh&quot;]): out.append((word, phones[0:-1] + [&quot;@&quot;])) if word.endswith(&quot;dh&quot;) and phones[-1] == &quot;@&quot;: out.append((word, phones + [&quot;x&quot;])) out.append((word, phones + [&quot;tj&quot;])) out.append((word, phones + [&quot;v&quot;])) if word.endswith(&quot;dh&quot;) and phones[-1] == &quot;x&quot;: out.append((word, phones[0:-1])) out.append((word, phones[0:-1] + [&quot;tj&quot;])) out.append((word, phones[0:-1] + [&quot;v&quot;])) return out . for line in dictionary.readlines(): line = line.strip() pieces = line.split(&quot; t&quot;) word = pieces[0] phones = pieces[1].split(&quot; &quot;) entries = list() tmptup = (word, phones) entries.append(tmptup) if word in _SOUGHT: for replacement_word in _REVERSE_ALTS[word]: tmp_replace = [(replacement_word, b) for (a, b) in entries] entries.extend(tmp_replace) elif word in alts.keys(): if type(alts[word]) == list: tmp_words = alts[word] else: tmp_words = [alts[word]] for tmp_word in tmp_words: if tmp_word not in _SOUGHT: entries.append((word, _ALTS[tmp_word].split(&quot; &quot;))) if word.endswith(&quot;acha&quot;) or word.endswith(&quot;anna&quot;): entries.append((word, phones[:-1] + [&quot;ii&quot;])) if word.endswith(&quot;igh&quot;) or word.endswith(&quot;dh&quot;): tmp_igh = [] for entry in entries: tmp_igh.extend(handle_igh(entry)) entries.extend(tmp_igh) tmp_nasal = [] for entry in entries: tmp_nasal.extend(nasal_o(entry)) entries.extend(tmp_nasal) tmp_schwa = deletable_schwa(entries) entries.extend(tmp_schwa) joined = [&quot; &quot;.join([a] + b) for (a, b) in entries] sort_join = sorted(joined) for entry in set(sort_join): dictionary2.write(entry + &quot; n&quot;) . dictionary.close() dictionary2.close() .",
            "url": "https://jimregan.github.io/notes/irish/phonetic/2021/10/17/expand-connaught-lexicon.html",
            "relUrl": "/irish/phonetic/2021/10/17/expand-connaught-lexicon.html",
            "date": " â€¢ Oct 17, 2021"
        }
        
    
  
    
        ,"post61": {
            "title": "Connaught -igh check",
            "content": "import IPython . 0018 Ã©irigh &lt;igh&gt; -&gt; /É™/ 0020 thosaigh &lt;igh&gt; -&gt; /É™/ 0040 d&#39;imigh &lt;igh&gt; -&gt; /É™/ 0041 Shuigh &lt;igh&gt; -&gt; /i:/ 0043 DhÃºisigh &lt;igh&gt; -&gt; /É™/ 0044 chuaigh &lt;igh&gt; -&gt; /É™/ 0050 d&#39;imigh &lt;igh&gt; -&gt; /É™/ 0079 Breathnaigh &lt;igh&gt; -&gt; /É™/ 0092 chuimhnigh &lt;igh&gt; -&gt; /É™/ 0094 D&#39;Ã­sligh &lt;igh&gt; -&gt; /É™/ 0107 Ã©adaigh &lt;igh&gt; -&gt; /É™/ 0108 chuaigh &lt;igh&gt; -&gt; /É™/ 0108 thosaigh &lt;igh&gt; -&gt; /É™/ 0122 chuimhnigh &lt;igh&gt; -&gt; /É™/ x ii nj @ 0140 Shocraigh &lt;igh&gt; -&gt; /É™/ 0143 d&#39;Ã©irigh &lt;igh&gt; -&gt; /É™/ 0152 tigh &lt;igh&gt; -&gt; /i:/ 0167 ndÃ³igh nn uu 0180 Ghlaoigh &lt;igh&gt; -&gt; /i:/ 0180 istigh &lt;igh&gt; -&gt; /É™/ 0183 bhailigh &lt;igh&gt; -&gt; /É™/ 0186 Corraigh &lt;igh&gt; -&gt; /É™/ 0186 istigh &lt;igh&gt; -&gt; /É™/ 0206 dÃ³igh &lt;igh&gt; -&gt; /É™/ 0231 dÃ³igh &lt;igh&gt; -&gt; /É™/ [Éª] 0234 chompÃ¡naigh &lt;igh&gt; -&gt; /i:/ 0237 airigh &lt;igh&gt; -&gt; /É™/ 0248 ndÃ³igh nn uu 0258 dÃ³igh &lt;igh&gt; -&gt; /i:/ 0261 amuigh (@) m u 0267 d&#39;Ã©irigh &lt;igh&gt; -&gt; /É™/ 0267 orlaigh &lt;igh&gt; -&gt; /i:/ 0268 dhÃºisigh &lt;igh&gt; -&gt; /É™/ 0269 chorraigh &lt;igh&gt; -&gt; /É™/ 0272 amuigh @ m u 0281 tharrthaigh &lt;igh&gt; -&gt; /É™/ 0284 ndÃ³igh nn uu 0286 d&#39;Ã©irigh &lt;igh&gt; -&gt; /É™/ 0287 brionglÃ³idigh &lt;igh&gt; -&gt; /i:/ 0288 Mhothaigh &lt;igh&gt; -&gt; /É™/ 0289 d&#39;eirigh &lt;igh&gt; -&gt; /É™/ 0295 Bhreathnaigh &lt;igh&gt; -&gt; /É™/ 0303 Chuaigh &lt;igh&gt; -&gt; /É™/ 0321 ghlaoigh &lt;igh&gt; -&gt; /i:/ 0327 choinnigh &lt;igh&gt; -&gt; /É™/ 0343 rÃ¡inigh &lt;igh&gt; -&gt; /É™/ 0351 amuigh @ m u 0354 chuaigh &lt;igh&gt; -&gt; /É™/ 0366 amuigh @ m u 0367 amuigh @ m u 0368 amuigh @ m u 0369 d&#39;imigh &lt;igh&gt; -&gt; /É™/ 0370 ndÃ³igh nn uu 0371 d&#39;imigh &lt;igh&gt; -&gt; /É™/ 0373 d&#39;imigh &lt;igh&gt; -&gt; /É™/ 0400 d&#39;Ã©irigh &lt;igh&gt; -&gt; /É™/ 0404 suigh &lt;igh&gt; -&gt; /i:/ 0405 shuigh &lt;igh&gt; -&gt; /i:/ 0407 Ã©adaigh &lt;igh&gt; -&gt; /É™/ 0409 nigh &lt;igh&gt; -&gt; /i:/ 0422 shuigh &lt;igh&gt; -&gt; /i:/ 0423 thosaigh &lt;igh&gt; -&gt; /É™/ 0428 d&#39;fhuadaigh &lt;igh&gt; -&gt; /É™/ 0435 ghlaoigh &lt;igh&gt; -&gt; /i:/ 0436 ghlaoigh &lt;igh&gt; -&gt; /i:/ 0449 d&#39;Ã©irigh &lt;igh&gt; -&gt; /É™/ 0453 Chuaigh &lt;igh&gt; -&gt; /É™/ 0461 tigh &lt;igh&gt; -&gt; /i:/ 0477 mharaigh &lt;igh&gt; -&gt; /É™/ 0480 mharaigh &lt;igh&gt; -&gt; /É™/ 0484 d&#39;Ã©irigh &lt;igh&gt; -&gt; /É™/ 0499 teallaigh &lt;igh&gt; -&gt; /i:/ 0502 Neachtanaigh &lt;igh&gt; -&gt; /i:/ 0506 ghlaoigh &lt;igh&gt; -&gt; /i:/ 0527 Thiontaigh &lt;igh&gt; -&gt; /É™/ 0531 Chuaigh &lt;igh&gt; -&gt; /É™/ 0542 airigh &lt;igh&gt; -&gt; /É™/ 0544 Chuaigh &lt;igh&gt; -&gt; /É™/ 0546 Cheistigh &lt;igh&gt; -&gt; /É™/ 0548 Chuardaigh &lt;igh&gt; -&gt; /É™/ 0568 D&#39;imigh &lt;igh&gt; -&gt; /É™/ 0572 Luigh &lt;igh&gt; -&gt; /i:/ 0581 mharaigh &lt;igh&gt; -&gt; /É™/ 0587 d&#39;Ã©irigh &lt;igh&gt; -&gt; /É™/ 0612 mhionnaigh &lt;igh&gt; -&gt; /É™/ 0615 mhionnaigh &lt;igh&gt; -&gt; /É™/ 0616 mhionnaigh &lt;igh&gt; -&gt; /É™/ 0628 mhionnaigh &lt;igh&gt; -&gt; /É™/ 0629 mhionnaigh &lt;igh&gt; -&gt; /É™/ 0642 Chuaigh &lt;igh&gt; -&gt; /É™/ 0647 Chuaigh &lt;igh&gt; -&gt; /É™/ 0649 Dheasaigh &lt;igh&gt; -&gt; /É™/ 0650 istigh &lt;igh&gt; -&gt; /É™/ 0650 amuigh @ m u 0652 Ã©adaigh &lt;igh&gt; -&gt; /i:/ 0652 dhathaigh &lt;igh&gt; -&gt; /É™/ 0664 Domhnaigh &lt;igh&gt; -&gt; /É™/ 0671 ndÃ³igh nn uu 0675 Ã©irigh &lt;igh&gt; -&gt; /É™/ 0678 Chuaigh &lt;igh&gt; -&gt; /É™/ 0678 shuigh &lt;igh&gt; -&gt; /i:/ 0690 chuaigh &lt;igh&gt; -&gt; /É™/ 0691 Chuardaigh &lt;igh&gt; -&gt; /É™/ 0701 chuaigh &lt;igh&gt; -&gt; /É™/ 0704 D&#39;imigh &lt;igh&gt; -&gt; /É™/ 0711 chuaigh &lt;igh&gt; -&gt; /É™/ 0715 theastaigh &lt;igh&gt; -&gt; /É™/ 0720 chuaigh &lt;igh&gt; -&gt; /É™/ 0724 chuaigh &lt;igh&gt; -&gt; /É™/ 0726 chuaigh &lt;igh&gt; -&gt; /É™/ 0729 chuaigh &lt;igh&gt; -&gt; /É™/ 0736 lÃ©igh &lt;Ã©igh&gt; -&gt; /e:/ 0745 D&#39;umhlaigh &lt;igh&gt; -&gt; /É™/ 0745 d&#39;imigh &lt;igh&gt; -&gt; /É™/ 0746 lÃ©igh &lt;Ã©igh&gt; -&gt; /e:/ 0758 d&#39;imigh &lt;igh&gt; -&gt; /É™/ 0760 d&#39;imigh &lt;igh&gt; -&gt; /É™/ 0762 d&#39;imigh &lt;igh&gt; -&gt; /É™/ 0772 chuaigh &lt;igh&gt; -&gt; /É™/ 0773 amuigh @ m u 0805 mharaigh &lt;igh&gt; -&gt; /É™/ 0808 mharaigh &lt;igh&gt; -&gt; /É™/ 0822 choinnigh &lt;igh&gt; -&gt; /É™/ 1316 Turlaigh &lt;igh&gt; -&gt; /i:/ 1325 Mhaigh &lt;igh&gt; -&gt; /i:/ 1339 chuaigh &lt;igh&gt; -&gt; /É™/ 1369 chuaigh &lt;igh&gt; -&gt; /É™/ 1373 Turlaigh &lt;igh&gt; -&gt; /i:/ 1383 tosaigh &lt;igh&gt; -&gt; /i:/ 1395 tosaigh &lt;igh&gt; -&gt; /É™/ 1408 chuimhnigh &lt;igh&gt; -&gt; /É™/ 1427 Ã©adaigh &lt;igh&gt; -&gt; /É™/ 1436 Bhailigh &lt;igh&gt; -&gt; /É™/ 1439 Ã©adaigh &lt;igh&gt; -&gt; /É™/ 1440 Ã©adaigh &lt;igh&gt; -&gt; /É™/ 1442 ShÃ¡igh h aa 1443 Chuimhnigh &lt;igh&gt; -&gt; /É™/ 1449 chuimhnigh &lt;igh&gt; -&gt; /É™/ 1455 thiontaigh &lt;igh&gt; -&gt; /É™/ 1455 thÃ©altaigh &lt;igh&gt; -&gt; /É™/ 1458 thÃ©altaigh &lt;igh&gt; -&gt; /É™/ 1458 chuaigh &lt;igh&gt; -&gt; /É™/ 1461 Turlaigh &lt;igh&gt; -&gt; /i:/ 1464 istigh &lt;igh&gt; -&gt; /É™/ 1466 chuaigh &lt;igh&gt; -&gt; /É™/ 1467 d&#39;Ã©irigh &lt;igh&gt; -&gt; /É™/ 1467 istigh &lt;igh&gt; -&gt; /É™/ 1469 thosaigh &lt;igh&gt; -&gt; /É™/ 1474 chuimhnigh &lt;igh&gt; -&gt; /É™/ 1483 chuimhnigh &lt;igh&gt; -&gt; /É™/ 1486 chuaigh &lt;igh&gt; -&gt; /É™/ 1493 chuaigh &lt;igh&gt; -&gt; /É™/ 1497 folaigh &lt;igh&gt; -&gt; /i:/ 1510 imigh &lt;igh&gt; -&gt; /É™/ 1511 d&#39;imigh &lt;igh&gt; -&gt; /É™/ 1519 chuimhnigh &lt;igh&gt; -&gt; /É™/ 1519 d&#39;umhlaigh &lt;igh&gt; -&gt; /É™/ 1527 Turlaigh &lt;igh&gt; -&gt; /i:/ 1528 d&#39;Ã©irigh &lt;igh&gt; -&gt; /É™/ 1537 chuimhnigh &lt;igh&gt; -&gt; /É™/ 1539 GhÃ©araigh &lt;igh&gt; -&gt; /É™/ 1540 thosaigh &lt;igh&gt; -&gt; /É™/ 1551 chuimhnigh &lt;igh&gt; -&gt; /É™/ 1554 Thiontaigh &lt;igh&gt; -&gt; /É™/ 1555 ndeachaigh &lt;igh&gt; -&gt; /É™/ 1556 mhothaigh &lt;igh&gt; -&gt; /É™/ 1573 ualaigh &lt;igh&gt; -&gt; /i:/ 1577 Ã©adaigh &lt;igh&gt; -&gt; /É™/ 1578 d&#39;imigh &lt;igh&gt; -&gt; /É™/ 1581 Mhothaigh &lt;igh&gt; -&gt; /É™/ 1584 imigh &lt;igh&gt; -&gt; /É™/ 1586 Luigh &lt;igh&gt; -&gt; /i:/ 1587 bhealaigh &lt;igh&gt; -&gt; /i:/ 1588 istigh &lt;igh&gt; -&gt; /É™/ 1589 D&#39;imigh &lt;igh&gt; -&gt; /É™/ 1599 malraigh &lt;igh&gt; -&gt; /i:/ 1600 amuigh &lt;igh&gt; -&gt; /É™/ 1601 Mhaigh &lt;igh&gt; -&gt; /i:/ 1602 Maigh &lt;igh&gt; -&gt; /i:/ 1605 Mhaigh &lt;igh&gt; -&gt; /i:/ 1613 theastaigh &lt;igh&gt; -&gt; /É™/ 1619 Chuaigh &lt;igh&gt; -&gt; /É™/ 1622 hÃ³gÃ¡naigh &lt;igh&gt; -&gt; /i:/ 1627 Chuaigh &lt;igh&gt; -&gt; /É™/ 1628 Chuaigh &lt;igh&gt; -&gt; /É™/ 1630 Thosaigh &lt;igh&gt; -&gt; /É™/ 1635 Chuaigh &lt;igh&gt; -&gt; /É™/ 1639 D&#39;Ã©irigh &lt;igh&gt; -&gt; /É™/ 1643 ghnÃ³thaigh &lt;igh&gt; -&gt; /i:/ 1647 Mhaigh w aa 1647 Maigh m aa 1653 chruthaigh &lt;igh&gt; -&gt; /É™/ 1654 d&#39;Ã©irigh &lt;igh&gt; -&gt; /É™/ 1658 Maigh &lt;igh&gt; -&gt; /i:/ 1661 d&#39;Ã©irigh &lt;igh&gt; -&gt; /É™/ 1664 d&#39;imigh &lt;igh&gt; -&gt; /É™/ 1667 Maigh m aa 1669 bhealaigh &lt;igh&gt; -&gt; /i:/ 1669 Ã©adaigh &lt;igh&gt; -&gt; /É™/ 1670 Shuigh &lt;igh&gt; -&gt; /i:/ 1673 D&#39;Ã©irigh &lt;igh&gt; -&gt; /É™/ 1673 chuaigh &lt;igh&gt; -&gt; /É™/ 1673 thosaigh &lt;igh&gt; -&gt; /É™/ 1673 Mhaigh &lt;igh&gt; -&gt; /i:/ 1674 chrÃ­ochnaigh &lt;igh&gt; -&gt; /É™/ 1676 Thosaigh &lt;igh&gt; -&gt; /É™/ 1678 thosaigh &lt;igh&gt; -&gt; /É™/ 1683 istigh &lt;igh&gt; -&gt; /É™/ 1690 teallaigh &lt;igh&gt; -&gt; /i:/ 1692 Ã©adaigh &lt;igh&gt; -&gt; /É™/ 1704 thosaigh &lt;igh&gt; -&gt; /É™/ 1721 d&#39;iontaigh &lt;igh&gt; -&gt; /É™/ 1724 Ã‰irigh &lt;igh&gt; -&gt; /É™/ 1725 D&#39;Ã©irigh &lt;igh&gt; -&gt; /É™/ 1730 bhealaigh &lt;igh&gt; -&gt; /i:/ 1737 Ã©adaigh &lt;igh&gt; -&gt; /É™/ 1738 d&#39;Ã©irigh &lt;igh&gt; -&gt; /É™/ 1745 D&#39;imigh &lt;igh&gt; -&gt; /É™/ 1746 thriomaigh &lt;igh&gt; -&gt; /É™/ 1749 thosaigh &lt;igh&gt; -&gt; /É™/ 1750 mhothaigh &lt;igh&gt; -&gt; /É™/ 1752 d&#39;airigh &lt;igh&gt; -&gt; /É™/ 1763 thosaigh &lt;igh&gt; -&gt; /É™/ 1769 D&#39;imigh &lt;igh&gt; -&gt; /É™/ 1771 Chuaigh &lt;igh&gt; -&gt; /É™/ 1775 Chuaigh &lt;igh&gt; -&gt; /É™/ 1779 Chuaigh &lt;igh&gt; -&gt; /É™/ 1787 earraigh &lt;igh&gt; -&gt; /i:/ 1816 ndÃ³igh nn uu 1825 amuigh @ m u 1830 Chuaigh &lt;igh&gt; -&gt; /É™/ 1832 Nigh &lt;igh&gt; -&gt; /i:/ 1835 Dheasaigh &lt;igh&gt; -&gt; /É™/ 1838 shuigh &lt;igh&gt; -&gt; /i:/ 1839 thosaigh &lt;igh&gt; -&gt; /É™/ 1840 teallaigh &lt;igh&gt; -&gt; /i:/ 1843 Ghlaoigh &lt;igh&gt; -&gt; /i:/ 1844 Chuaigh &lt;igh&gt; -&gt; /É™/ 1846 D&#39;Ã­sligh &lt;igh&gt; -&gt; /É™/ 1867 mhalraigh &lt;igh&gt; -&gt; /i:/ 1877 D&#39;Ã­sligh &lt;igh&gt; -&gt; /É™/ 1877 thiontaigh &lt;igh&gt; -&gt; /É™/ 1877 d&#39;Ã©irigh &lt;igh&gt; -&gt; /É™/ 1877 d&#39;Ã­sligh &lt;igh&gt; -&gt; /É™/ 1877 thiontaigh &lt;igh&gt; -&gt; /É™/ 1878 luigh &lt;igh&gt; -&gt; /i:/ 1878 neadaigh &lt;igh&gt; -&gt; /É™/ 1881 uaignigh &lt;igh&gt; -&gt; /i:/ 1883 chompÃ¡naigh &lt;igh&gt; -&gt; /i:/ 1884 d&#39;Ã©irigh &lt;igh&gt; -&gt; /É™/ 1886 D&#39;Ã©irigh &lt;igh&gt; -&gt; /É™/ 1886 luigh &lt;igh&gt; -&gt; /i:/ 1893 mhalraigh &lt;igh&gt; -&gt; /i:/ 1903 Chuaigh &lt;igh&gt; -&gt; /É™/ 1908 Bheannaigh &lt;igh&gt; -&gt; /É™/ 1910 malraigh &lt;igh&gt; -&gt; /i:/ 1913 Bhreathnaigh &lt;igh&gt; -&gt; /É™/ 1920 amuigh @ m u . 1577: troighe -&gt; troiche? . 1647: sniff at end . 1653, 1667: sniff/paper slide . 1738: leanbh -&gt; leana . 1839: pÃ­obaire -&gt; paobaire? . ids = &quot;1932 1950 1951 1952 1955 1989 1999 2001 2002 2003 2007 2010 2012 2022 2024 2028 2029 2030&quot; idlist = ids.split(&quot; &quot;) print(len(idlist)) . for fid in idlist[0:10]: print(fid + &quot; n&quot;) !cat /home/jim/Playing/snc_ga_co/txt/SNC_Gearrscealta_an_Phiarsaigh_{fid}.txt IPython.display.display(IPython.display.Audio(f&quot;/home/jim/Playing/snc_ga_co/original_wav/SNC0001SNC_Gearrscealta_an_Phiarsaigh_{fid}.wav&quot;)) . def clearp(text): return text.replace(&quot;,&quot;, &quot;&quot;).replace(&quot;.&quot;, &quot;&quot;).replace(&quot;;&quot;, &quot;&quot;).replace(&quot;:&quot;, &quot;&quot;) for fid in idlist[0:5]: ftext = !cat /home/jim/Playing/snc_ga_co/txt/SNC_Gearrscealta_an_Phiarsaigh_{fid}.txt text = clearp(ftext[0]) for word in text.split(&quot; &quot;): if word.endswith(&quot;igh&quot;): print(f&quot;{fid} t{word} t&lt;igh&gt; -&gt; /É™/&quot;) .",
            "url": "https://jimregan.github.io/notes/irish/phonetic/2021/10/16/connaught-igh-check.html",
            "relUrl": "/irish/phonetic/2021/10/16/connaught-igh-check.html",
            "date": " â€¢ Oct 16, 2021"
        }
        
    
  
    
        ,"post62": {
            "title": "Plotting segmentation from TextGrid with librosa",
            "content": "%%capture !pip install seaborn . Based on Onset-based Segmentation with Backtracking . %matplotlib inline import seaborn import numpy as np, scipy, matplotlib.pyplot as plt, IPython.display as ipd import librosa, librosa.display plt.rcParams[&#39;figure.figsize&#39;] = (13, 5) . Change to match files: . _TEXTGRID = &quot;&quot; _AUDIO = &quot;&quot; . from praatio import textgrid tg = textgrid.openTextgrid(_TEXTGRID, False) . x, sr = librosa.load(_AUDIO) . ends = [tg.tierDict[&#39;phones&#39;].entryList[0].start] + [end.end for end in tg.tierDict[&#39;phones&#39;].entryList] . phones = [end.label for end in tg.tierDict[&#39;phones&#39;].entryList] . S = librosa.stft(x, n_fft=2048, hop_length=512) logS = librosa.amplitude_to_db(np.abs(S), ref=np.max) librosa.display.specshow(logS, sr=sr, x_axis=&#39;time&#39;, y_axis=&#39;log&#39;) for xc in ends: plt.axvline(x=xc, color=&#39;w&#39;) .",
            "url": "https://jimregan.github.io/notes/textgrid/spectrogram/librosa/2021/10/15/plotting-segmentation-from-textgrid-with-librosa.html",
            "relUrl": "/textgrid/spectrogram/librosa/2021/10/15/plotting-segmentation-from-textgrid-with-librosa.html",
            "date": " â€¢ Oct 15, 2021"
        }
        
    
  
    
        ,"post63": {
            "title": "Extract a dictionary from MFA-aligned TextGrids",
            "content": "%%capture !pip install praatio . def irish_lc(word): if word[0:1] in &quot;nt&quot; and word[1:2] in &quot;AEIOUÃÃ‰ÃÃ“Ãš&quot;: return word[0:1] + &quot;-&quot; + word[1:].lower() else: return word.lower() . assert irish_lc(&quot;nAthair&quot;) == &quot;n-athair&quot; assert irish_lc(&quot;nDeas&quot;) == &quot;ndeas&quot; . def get_combined_words_and_phones(filename): from praatio import textgrid tg = textgrid.openTextgrid(filename, False) if not tg.tierNameList or tg.tierNameList != [&#39;Word&#39;, &#39;phones&#39;]: return [] word = tg.tierDict[&#39;Word&#39;] phones = tg.tierDict[&#39;phones&#39;] i = 0 j = 0 out = [] def it_to_dict(it): ret = {} ret[&#39;start&#39;] = it.start ret[&#39;end&#39;] = it.end ret[&#39;label&#39;] = it.label return ret while i &lt; len(word.entryList) and j &lt; len(phones.entryList): cur_word = it_to_dict(word.entryList[i]) cur_word[&#39;phones&#39;] = [] while j &lt; len(phones.entryList) and phones.entryList[j].end &lt;= cur_word[&#39;end&#39;]: end_time = phones.entryList[j].end tmp_phone = it_to_dict(phones.entryList[j]) cur_word[&#39;phones&#39;].append(tmp_phone) j += 1 if end_time == cur_word[&#39;end&#39;]: i += 1 out.append(cur_word) continue return out . def get_wordlist_from_combined(items, wordnorm=None): tmp = [] for item in items: word = item[&#39;label&#39;] if wordnorm is None: word = word.lower() else: word = wordnorm(word) phones = &quot; &quot;.join([a[&#39;label&#39;] for a in item[&#39;phones&#39;]]) if phones == &quot;sil&quot;: continue tmp.append((word, phones)) return tmp . from pathlib import Path wd = Path(&quot;PATH TO FILES&quot;) tg_data = {} for tg in wd.glob(&quot;*.TextGrid&quot;): tg_data[tg.stem] = get_wordlist_from_combined(get_combined_words_and_phones(tg), wordnorm=irish_lc) . dictionary = set() for (tg_name, tg_words) in tg_data.items(): dictionary.update(set(tg_words)) . joined = [&quot; &quot;.join(a) for a in dictionary] . with open(&quot;output.dict&quot;, &quot;w&quot;) as outf: for word in sorted(joined): outf.write(word + &quot; n&quot;) .",
            "url": "https://jimregan.github.io/notes/textgrid/mfa/2021/10/15/extract-dictionary-from-mfa-textgrids.html",
            "relUrl": "/textgrid/mfa/2021/10/15/extract-dictionary-from-mfa-textgrids.html",
            "date": " â€¢ Oct 15, 2021"
        }
        
    
  
    
        ,"post64": {
            "title": "Interesting links, 12/10/2021",
            "content": "Can Cognate Prediction Be Modelled as a Low-Resource Machine Translation Task?, pdf, code . @inproceedings{fourrier-etal-2021-cognate, title = &quot;Can Cognate Prediction Be Modelled as a Low-Resource Machine Translation Task?&quot;, author = &quot;Fourrier, Cl{ &#39;e}mentine and Bawden, Rachel and Sagot, Beno{ ^ i}t&quot;, booktitle = &quot;Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021&quot;, month = aug, year = &quot;2021&quot;, address = &quot;Online&quot;, publisher = &quot;Association for Computational Linguistics&quot;, url = &quot;https://aclanthology.org/2021.findings-acl.75&quot;, doi = &quot;10.18653/v1/2021.findings-acl.75&quot;, pages = &quot;847--861&quot;, } . OntoEA: Ontology-guided Entity Alignment via Joint Knowledge Graph Embedding, pdf, code . @inproceedings{xiang-etal-2021-ontoea, title = &quot;{O}nto{EA}: Ontology-guided Entity Alignment via Joint Knowledge Graph Embedding&quot;, author = &quot;Xiang, Yuejia and Zhang, Ziheng and Chen, Jiaoyan and Chen, Xi and Lin, Zhenxi and Zheng, Yefeng&quot;, booktitle = &quot;Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021&quot;, month = aug, year = &quot;2021&quot;, address = &quot;Online&quot;, publisher = &quot;Association for Computational Linguistics&quot;, url = &quot;https://aclanthology.org/2021.findings-acl.96&quot;, doi = &quot;10.18653/v1/2021.findings-acl.96&quot;, pages = &quot;1117--1128&quot;, } . As Good as New. How to Successfully Recycle English GPT-2 to Make Models for Other Languages, pdf, code . @inproceedings{de-vries-nissim-2021-good, title = &quot;As Good as New. How to Successfully Recycle {E}nglish {GPT}-2 to Make Models for Other Languages&quot;, author = &quot;de Vries, Wietse and Nissim, Malvina&quot;, booktitle = &quot;Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021&quot;, month = aug, year = &quot;2021&quot;, address = &quot;Online&quot;, publisher = &quot;Association for Computational Linguistics&quot;, url = &quot;https://aclanthology.org/2021.findings-acl.74&quot;, doi = &quot;10.18653/v1/2021.findings-acl.74&quot;, pages = &quot;836--846&quot;, } . Parallel Attention Network with Sequence Matching for Video Grounding, pdf, (code link is broken) . @inproceedings{zhang-etal-2021-parallel, title = &quot;Parallel Attention Network with Sequence Matching for Video Grounding&quot;, author = &quot;Zhang, Hao and Sun, Aixin and Jing, Wei and Zhen, Liangli and Zhou, Joey Tianyi and Goh, Siow Mong Rick&quot;, booktitle = &quot;Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021&quot;, month = aug, year = &quot;2021&quot;, address = &quot;Online&quot;, publisher = &quot;Association for Computational Linguistics&quot;, url = &quot;https://aclanthology.org/2021.findings-acl.69&quot;, doi = &quot;10.18653/v1/2021.findings-acl.69&quot;, pages = &quot;776--790&quot;, } . REPT: Bridging Language Models and Machine Reading Comprehension via Retrieval-Based Pre-training, pdf, code . @inproceedings{jiao-etal-2021-rept, title = &quot;{REPT}: Bridging Language Models and Machine Reading Comprehension via Retrieval-Based Pre-training&quot;, author = &quot;Jiao, Fangkai and Guo, Yangyang and Niu, Yilin and Ji, Feng and Li, Feng-Lin and Nie, Liqiang&quot;, booktitle = &quot;Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021&quot;, month = aug, year = &quot;2021&quot;, address = &quot;Online&quot;, publisher = &quot;Association for Computational Linguistics&quot;, url = &quot;https://aclanthology.org/2021.findings-acl.13&quot;, doi = &quot;10.18653/v1/2021.findings-acl.13&quot;, pages = &quot;150--163&quot;, } . Cross-Lingual Transfer in Zero-Shot Cross-Language Entity Linking, pdf, [code[(https://github.com/elliotschu/crosslingual-el) (not open source) . @inproceedings{schumacher-etal-2021-cross, title = &quot;Cross-Lingual Transfer in Zero-Shot Cross-Language Entity Linking&quot;, author = &quot;Schumacher, Elliot and Mayfield, James and Dredze, Mark&quot;, booktitle = &quot;Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021&quot;, month = aug, year = &quot;2021&quot;, address = &quot;Online&quot;, publisher = &quot;Association for Computational Linguistics&quot;, url = &quot;https://aclanthology.org/2021.findings-acl.52&quot;, doi = &quot;10.18653/v1/2021.findings-acl.52&quot;, pages = &quot;583--595&quot;, } . WikiTableT: A Large-Scale Data-to-Text Dataset for Generating Wikipedia Article Sections, pdf, code . @inproceedings{chen-etal-2021-wikitablet, title = &quot;{W}iki{T}able{T}: A Large-Scale Data-to-Text Dataset for Generating {W}ikipedia Article Sections&quot;, author = &quot;Chen, Mingda and Wiseman, Sam and Gimpel, Kevin&quot;, booktitle = &quot;Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021&quot;, month = aug, year = &quot;2021&quot;, address = &quot;Online&quot;, publisher = &quot;Association for Computational Linguistics&quot;, url = &quot;https://aclanthology.org/2021.findings-acl.17&quot;, doi = &quot;10.18653/v1/2021.findings-acl.17&quot;, pages = &quot;193--209&quot;, } . Discrete Cosine Transform as Universal Sentence Encoder, pdf . @inproceedings{almarwani-diab-2021-discrete, title = &quot;Discrete Cosine Transform as Universal Sentence Encoder&quot;, author = &quot;Almarwani, Nada and Diab, Mona&quot;, booktitle = &quot;Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)&quot;, month = aug, year = &quot;2021&quot;, address = &quot;Online&quot;, publisher = &quot;Association for Computational Linguistics&quot;, url = &quot;https://aclanthology.org/2021.acl-short.53&quot;, doi = &quot;10.18653/v1/2021.acl-short.53&quot;, pages = &quot;419--426&quot;, } . mTVR: Multilingual Moment Retrieval in Videos, pdf, dataset . @inproceedings{lei-etal-2021-mtvr, title = &quot;m{TVR}: Multilingual Moment Retrieval in Videos&quot;, author = &quot;Lei, Jie and Berg, Tamara and Bansal, Mohit&quot;, booktitle = &quot;Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)&quot;, month = aug, year = &quot;2021&quot;, address = &quot;Online&quot;, publisher = &quot;Association for Computational Linguistics&quot;, url = &quot;https://aclanthology.org/2021.acl-short.92&quot;, doi = &quot;10.18653/v1/2021.acl-short.92&quot;, pages = &quot;726--734&quot;, } . nmT5 - Is parallel data still relevant for pre-training massively multilingual language models?, pdf . @inproceedings{kale-etal-2021-nmt5, title = &quot;nm{T}5 - Is parallel data still relevant for pre-training massively multilingual language models?&quot;, author = &quot;Kale, Mihir and Siddhant, Aditya and Al-Rfou, Rami and Xue, Linting and Constant, Noah and Johnson, Melvin&quot;, booktitle = &quot;Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)&quot;, month = aug, year = &quot;2021&quot;, address = &quot;Online&quot;, publisher = &quot;Association for Computational Linguistics&quot;, url = &quot;https://aclanthology.org/2021.acl-short.87&quot;, doi = &quot;10.18653/v1/2021.acl-short.87&quot;, pages = &quot;683--691&quot;, } . Anchor-based Bilingual Word Embeddings for Low-Resource Languages, pdf, website . @inproceedings{eder-etal-2021-anchor, title = &quot;Anchor-based Bilingual Word Embeddings for Low-Resource Languages&quot;, author = &quot;Eder, Tobias and Hangya, Viktor and Fraser, Alexander&quot;, booktitle = &quot;Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)&quot;, month = aug, year = &quot;2021&quot;, address = &quot;Online&quot;, publisher = &quot;Association for Computational Linguistics&quot;, url = &quot;https://aclanthology.org/2021.acl-short.30&quot;, doi = &quot;10.18653/v1/2021.acl-short.30&quot;, pages = &quot;227--232&quot;, } . DefSent: Sentence Embeddings using Definition Sentences, pdf, code (not open source) . @inproceedings{tsukagoshi-etal-2021-defsent, title = &quot;{D}ef{S}ent: Sentence Embeddings using Definition Sentences&quot;, author = &quot;Tsukagoshi, Hayato and Sasano, Ryohei and Takeda, Koichi&quot;, booktitle = &quot;Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)&quot;, month = aug, year = &quot;2021&quot;, address = &quot;Online&quot;, publisher = &quot;Association for Computational Linguistics&quot;, url = &quot;https://aclanthology.org/2021.acl-short.52&quot;, doi = &quot;10.18653/v1/2021.acl-short.52&quot;, pages = &quot;411--418&quot;, } . Is Sparse Attention more Interpretable? pdf . @inproceedings{meister-etal-2021-sparse, title = &quot;Is Sparse Attention more Interpretable?&quot;, author = &quot;Meister, Clara and Lazov, Stefan and Augenstein, Isabelle and Cotterell, Ryan&quot;, booktitle = &quot;Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)&quot;, month = aug, year = &quot;2021&quot;, address = &quot;Online&quot;, publisher = &quot;Association for Computational Linguistics&quot;, url = &quot;https://aclanthology.org/2021.acl-short.17&quot;, doi = &quot;10.18653/v1/2021.acl-short.17&quot;, pages = &quot;122--129&quot;, } . Bilingual Mutual Information Based Adaptive Training for Neural Machine Translation, pdf, code (not open source) . @inproceedings{xu-etal-2021-bilingual, title = &quot;Bilingual Mutual Information Based Adaptive Training for Neural Machine Translation&quot;, author = &quot;Xu, Yangyifan and Liu, Yijin and Meng, Fandong and Zhang, Jiajun and Xu, Jinan and Zhou, Jie&quot;, booktitle = &quot;Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)&quot;, month = aug, year = &quot;2021&quot;, address = &quot;Online&quot;, publisher = &quot;Association for Computational Linguistics&quot;, url = &quot;https://aclanthology.org/2021.acl-short.65&quot;, doi = &quot;10.18653/v1/2021.acl-short.65&quot;, pages = &quot;511--516&quot;, } . X-Fact: A New Benchmark Dataset for Multilingual Fact Checking, pdf, dataset . @inproceedings{gupta-srikumar-2021-x, title = &quot;{X}-Fact: A New Benchmark Dataset for Multilingual Fact Checking&quot;, author = &quot;Gupta, Ashim and Srikumar, Vivek&quot;, booktitle = &quot;Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)&quot;, month = aug, year = &quot;2021&quot;, address = &quot;Online&quot;, publisher = &quot;Association for Computational Linguistics&quot;, url = &quot;https://aclanthology.org/2021.acl-short.86&quot;, doi = &quot;10.18653/v1/2021.acl-short.86&quot;, pages = &quot;675--682&quot;, } . An Improved Model for Voicing Silent Speech, pdf, code . @inproceedings{gaddy-klein-2021-improved, title = &quot;An Improved Model for Voicing Silent Speech&quot;, author = &quot;Gaddy, David and Klein, Dan&quot;, booktitle = &quot;Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)&quot;, month = aug, year = &quot;2021&quot;, address = &quot;Online&quot;, publisher = &quot;Association for Computational Linguistics&quot;, url = &quot;https://aclanthology.org/2021.acl-short.23&quot;, doi = &quot;10.18653/v1/2021.acl-short.23&quot;, pages = &quot;175--181&quot;, } . Higher-order Derivatives of Weighted Finite-state Machines, pdf, code . @inproceedings{zmigrod-etal-2021-higher, title = &quot;Higher-order Derivatives of Weighted Finite-state Machines&quot;, author = &quot;Zmigrod, Ran and Vieira, Tim and Cotterell, Ryan&quot;, booktitle = &quot;Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)&quot;, month = aug, year = &quot;2021&quot;, address = &quot;Online&quot;, publisher = &quot;Association for Computational Linguistics&quot;, url = &quot;https://aclanthology.org/2021.acl-short.32&quot;, doi = &quot;10.18653/v1/2021.acl-short.32&quot;, pages = &quot;240--248&quot;, } .",
            "url": "https://jimregan.github.io/notes/links/2021/10/12/misc-links.html",
            "relUrl": "/links/2021/10/12/misc-links.html",
            "date": " â€¢ Oct 12, 2021"
        }
        
    
  
    
        ,"post65": {
            "title": "Octave v. numpy",
            "content": "%%capture !apt install octave . import numpy as np . Convolve . %%writefile conv1.m % https://www.mathworks.com/help/matlab/ref/conv.html u = [1 1 1]; v = [1 1 0 0 0 1 1]; w = conv(u,v) . Writing conv1.m . !octave conv1.m . octave: X11 DISPLAY environment variable not set octave: disabling GUI features w = 1 2 2 1 0 1 2 2 1 . u = [1, 1, 1] v = [1, 1, 0, 0, 0, 1, 1] w = np.convolve(u, v) w . array([1, 2, 2, 1, 0, 1, 2, 2, 1]) . Matrix multiplication . %%writefile matmul.m % https://www.tutorialspoint.com/matlab/matlab_matrix_multiplication.htm a = [ 1 2 3; 2 3 4; 1 2 5] b = [ 2 1 3 ; 5 0 -2; 2 3 -1] prod = a * b . Writing matmul.m . !octave matmul.m . octave: X11 DISPLAY environment variable not set octave: disabling GUI features a = 1 2 3 2 3 4 1 2 5 b = 2 1 3 5 0 -2 2 3 -1 prod = 18 10 -4 27 14 -4 22 16 -6 . a = np.array([[1, 2, 3], [2, 3, 4], [1, 2, 5]]) b = np.array([[2, 1, 3], [5, 0, -2], [2, 3, -1]]) prod = a @ b prod . array([[18, 10, -4], [27, 14, -4], [22, 16, -6]]) . Element-wise multiplication . %%writefile ew_matmul.m % https://www.tutorialspoint.com/matlab/matlab_matrix_multiplication.htm a = [ 1 2 3; 2 3 4; 1 2 5] b = [ 2 1 3 ; 5 0 -2; 2 3 -1] prod = a .* b . Writing ew_matmul.m . !octave ew_matmul.m . octave: X11 DISPLAY environment variable not set octave: disabling GUI features a = 1 2 3 2 3 4 1 2 5 b = 2 1 3 5 0 -2 2 3 -1 prod = 2 2 9 10 0 -8 2 6 -5 . prod = a * b prod . array([[ 2, 2, 9], [10, 0, -8], [ 2, 6, -5]]) .",
            "url": "https://jimregan.github.io/notes/matlab/octave/numpy/2021/10/11/octave_v_numpy.html",
            "relUrl": "/matlab/octave/numpy/2021/10/11/octave_v_numpy.html",
            "date": " â€¢ Oct 11, 2021"
        }
        
    
  
    
        ,"post66": {
            "title": "What Makes the Cepstral Peak Prominence Different to Other Acoustic Correlates of Vocal Quality?",
            "content": "What Makes the Cepstral Peak Prominence Different to Other Acoustic Correlates of Vocal Quality? . @article{riesgo2020makes, title={{What Makes the Cepstral Peak Prominence Different to Other Acoustic Correlates of Vocal Quality?}}, author={Riesgo, Carlos A Ferrer and N{ &quot;o}th, Elmar}, journal={Journal of Voice}, volume={34}, number={5}, pages={806.E1--E6}, doi={10.1016/j.jvoice.2019.01.004}, year={2020} } .",
            "url": "https://jimregan.github.io/notes/journal%20club/2021/10/11/journal-club.html",
            "relUrl": "/journal%20club/2021/10/11/journal-club.html",
            "date": " â€¢ Oct 11, 2021"
        }
        
    
  
    
        ,"post67": {
            "title": "Extract phonemes from merlin lab files",
            "content": "def break_phones(string): i = 0 mark = 0 toks = [] pieces = { 0: &#39;^&#39;, 1: &#39;-&#39;, 2: &#39;+&#39;, 3: &#39;=&#39;, 4: &#39;@&#39; } piece = 0 while i &lt;= len(string): if string[i:i+1] == pieces[piece]: if piece &lt; 4: toks.append(string[mark:i]) else: if string[i+1:i+2].isdigit(): toks.append(string[mark:i]) else: toks.append(&quot;@&quot;) break piece += 1 mark = i + 1 i += 1 return toks . assert break_phones(&#39;nnj^ii-lj+sil=@@3_2/&#39;) == [&#39;nnj&#39;, &#39;ii&#39;, &#39;lj&#39;, &#39;sil&#39;, &#39;@&#39;] assert break_phones(&quot;x^sil-nnj+ii=lj@1_4&quot;) == [&#39;x&#39;, &#39;sil&#39;, &#39;nnj&#39;, &#39;ii&#39;, &#39;lj&#39;] assert break_phones(&quot;oo^r-sil+x=x@1_1&quot;) == [&#39;oo&#39;, &#39;r&#39;, &#39;sil&#39;, &#39;x&#39;, &#39;x&#39;] . def read_phonemes_lab(filename): phn_bits = [] with open(filename, &quot;r&quot;) as f: for line in f.readlines(): _, _, phones = line.split(&#39; &#39;) phones = break_phones(phones) phn_bits.append(phones) return phn_bits . def check_len(phone_list): length = str(len(phone_list)) return (length[-1] == &quot;0&quot; or length[-1] == &quot;5&quot;) . def prune_phones(phone_list): if not check_len(phone_list): return [] return [a[2] for a in phone_list[::5]] . lab_phonemes_raw = {a: read_phonemes_lab(b) for (a, b) in label_files.items()} . lab_phonemes = {a: prune_phones(b) for (a, b) in lab_phonemes_raw.items()} .",
            "url": "https://jimregan.github.io/notes/lab/merlin/2021/10/08/extract-phonemes-from-merlin-lab-files.html",
            "relUrl": "/lab/merlin/2021/10/08/extract-phonemes-from-merlin-lab-files.html",
            "date": " â€¢ Oct 8, 2021"
        }
        
    
  
    
        ,"post68": {
            "title": "Interesting links, 7/10/2021",
            "content": "CMU Advanced NLP 2021 (10): Prompting + Sequence-to-sequence Pre-training . gong-io/gecko â€” Gecko - A Tool for Effective Annotation of Human Conversations . datasets - opus_dogc.py . def _generate_examples(self, filepath): xml_lang = &quot;{http://www.w3.org/XML/1998/namespace}lang&quot; with open(filepath, encoding=&quot;utf-8&quot;) as f: id_ = 0 for _, elem in ET.iterparse(f): if elem.tag == &quot;tuv&quot;: language = elem.attrib[xml_lang] sentence = elem.find(&quot;seg&quot;).text if language == &quot;ca&quot;: ca_sentence = sentence elif language == &quot;es&quot;: es_sentence = sentence elif elem.tag == &quot;tu&quot;: yield id_, { &quot;translation&quot;: {&quot;ca&quot;: ca_sentence, &quot;es&quot;: es_sentence}, } id_ += 1 elem.clear() . _parse_tmx() . spaCy : en : test_noun_chunks.py . spacy/lang/en/syntax_iterators.py . Add task template for automatic speech recognition . task = AutomaticSpeechRecognition(audio_file_column=&quot;file&quot;, transcription_column=&quot;text&quot;) ds.prepare_for_task(task) . Create Audio feature #2324 . BigSSL: Exploring the Frontier of Large-Scale Semi-Supervised Learning for Automatic Speech Recognition . We summarize the results of a host of efforts using giant automatic speech recognition (ASR) models pre-trained using large, diverse unlabeled datasets containing approximately a million hours of audio. We find that the combination of pre-training, self-training and scaling up model size greatly increases data efficiency, even for extremely large tasks with tens of thousands of hours of labeled data. In particular, on an ASR task with 34k hours of labeled data, by fine-tuning an 8 billion parameter pre-trained Conformer model we can match state-of-the-art (SoTA) performance with only 3% of the training data and significantly improve SoTA with the full training set. We also report on the universal benefits gained from using big pre-trained and self-trained models for a large set of downstream tasks that cover a wide range of speech domains and span multiple orders of magnitudes of dataset sizes, including obtaining SoTA performance on many public benchmarks. In addition, we utilize the learned representation of pre-trained networks to achieve SoTA results on non-ASR tasks. . Turn-to-Diarize: Online Speaker Diarization Constrained by Transformer Transducer Speaker Turn Detection . In this paper, we present a novel speaker diarization system for streaming on-device applications. In this system, we use a transformer transducer to detect the speaker turns, represent each speaker turn by a speaker embedding, then cluster these embeddings with constraints from the detected speaker turns. Compared with conventional clustering-based diarization systems, our system largely reduces the computational cost of clustering due to the sparsity of speaker turns. Unlike other supervised speaker diarization systems which require annotations of time-stamped speaker labels for training, our system only requires including speaker turn tokens during the transcribing process, which largely reduces the human efforts involved in data collection. . flite_sapi_usenglish.c, FliteTTSEngineObj.cpp . Wav2vec2 pretraining 2 #13520 . Seoladh GaelscÃ©al - nuacht24 . nuacht24 . Ar ChanÃºintÃ­ na Gaeilge (audio) . rspeer/python-ftfy â€” Fixes mojibake and other glitches in Unicode text, after the fact. . tkipf/gcn â€” Implementation of Graph Convolutional Networks in TensorFlow . Grapheme-to-Phoneme Transduction for Cross-Language ASR, preprint . @InProceedings{hasegawa20g2p, author=&quot;Hasegawa-Johnson, Mark and Rolston, Leanne and Goudeseune, Camille and Levow, Gina-Anne and Kirchhoff, Katrin&quot;, editor=&quot;Espinosa-Anke, Luis and Mart{ &#39;i}n-Vide, Carlos and Spasi{ &#39;{c}}, Irena&quot;, title=&quot;Grapheme-to-Phoneme Transduction for Cross-Language ASR&quot;, booktitle=&quot;Statistical Language and Speech Processing&quot;, year=&quot;2020&quot;, publisher=&quot;Springer International Publishing&quot;, address=&quot;Cham&quot;, pages=&quot;3--19&quot;, doi=&quot;10.1007/978-3-030-59430-5_1&quot;, isbn=&quot;978-3-030-59430-5&quot; } .",
            "url": "https://jimregan.github.io/notes/links/2021/10/07/misc-links.html",
            "relUrl": "/links/2021/10/07/misc-links.html",
            "date": " â€¢ Oct 7, 2021"
        }
        
    
  
    
        ,"post69": {
            "title": "Loading Foinse dataset",
            "content": "!pip install datasets . from datasets import load_dataset . foinse = load_dataset(&quot;jimregan/foinse&quot;, &quot;documents&quot;) . Downloading and preparing dataset foinse_dataset/documents to /root/.cache/huggingface/datasets/foinse_dataset/documents/1.1.0/1f38b24860415793797d1e25734a8f044b0621b08c7618392c4aae9740097b34... Dataset foinse_dataset downloaded and prepared to /root/.cache/huggingface/datasets/foinse_dataset/documents/1.1.0/1f38b24860415793797d1e25734a8f044b0621b08c7618392c4aae9740097b34. Subsequent calls will reuse this data. . foinse . DatasetDict({ train: Dataset({ features: [&#39;title&#39;, &#39;url&#39;, &#39;author&#39;, &#39;date_text&#39;, &#39;text&#39;, &#39;category&#39;, &#39;subcategory&#39;, &#39;summary&#39;], num_rows: 4283 }) }) .",
            "url": "https://jimregan.github.io/notes/irish/foinse/datasets/2021/10/05/loading-foinse-dataset.html",
            "relUrl": "/irish/foinse/datasets/2021/10/05/loading-foinse-dataset.html",
            "date": " â€¢ Oct 5, 2021"
        }
        
    
  
    
        ,"post70": {
            "title": "Foinse scraper pieces, ctd",
            "content": "Continued . link = &quot;http://web.archive.org/web/20171209002240/http://www.foinse.ie/sport/eile/6412-an-dornalai-john-joe-nevin-rangaithe-ag-uimhir-a-haon-anois&quot; . import requests from bs4 import BeautifulSoup . def extract_summary(inlist): if len(inlist) &gt; 2: if inlist[-2] == &quot;Did you understand this story? Here are the main points:&quot;: return inlist[-1] return &quot;&quot; . def filter_para_list(inlist): out = [] for para in inlist: if para == &quot;&quot;: continue elif para.strip() == &quot;Foinse - News as Gaeilge&quot;: return out elif para.strip() == &quot;Did you understand this story? Here are the main points:&quot;: return out else: out.append(para) return out . def get_content(url, text=&quot;&quot;): out = {} if text: page_content = text else: page = requests.get(url) if page.status_code != 200: return {} page_content = page.text soup = BeautifulSoup(page_content, &quot;lxml&quot;) content = soup.find(&quot;div&quot;, {&quot;class&quot;: &quot;item-page&quot;}) if not content: content = soup.find(&quot;div&quot;, {&quot;id&quot;: &quot;ja-main&quot;}) if not content: return {} breadcrumbs = soup.find(&quot;div&quot;, {&quot;class&quot;: &quot;ja-breadcrums&quot;}) if breadcrumbs: here = breadcrumbs.find(&quot;a&quot;, {&quot;class&quot;: &quot;pathway&quot;}) if not here: here = breadcrumbs.find(&quot;span&quot;, {&quot;class&quot;: &quot;pathway&quot;}) if here: out[&quot;category&quot;] = here.text.strip() # junk jc = content.find(&quot;div&quot;, {&quot;id&quot;: &quot;jc&quot;}) if jc: jc.extract() pagenav = content.find(&quot;ul&quot;, {&quot;class&quot;: &quot;pagenav&quot;}) if pagenav: pagenav.extract() for js in content.find_all(&quot;script&quot;, {&quot;type&quot;: &quot;text/javascript&quot;}): js.extract() h2 = content.find(&quot;h2&quot;) if h2: title = h2.text.strip() if title: out[&quot;title&quot;] = title h2.extract() h1 = content.find(&quot;h1&quot;) if h1: heading = h1.text.strip() if heading: out[&quot;subcategory&quot;] = heading h1.extract() published_tag = content.find(&quot;dd&quot;, {&quot;class&quot;: &quot;published&quot;}) if not published_tag: published_tag = content.find(&quot;span&quot;, {&quot;class&quot;: &quot;createdate&quot;}) if published_tag: out[&quot;published&quot;] = published_tag.text.strip() author_tag = content.find(&quot;dd&quot;, {&quot;class&quot;: &quot;createdby&quot;}) if not author_tag: author_tag = content.find(&quot;span&quot;, {&quot;class&quot;: &quot;createby&quot;}) if author_tag: out[&quot;author&quot;] = author_tag.text.strip() artinfo = content.find(&quot;dl&quot;, {&quot;class&quot;: &quot;article-info&quot;}) if not artinfo: artinfo = content.find(&quot;div&quot;, {&quot;class&quot;: &quot;article-meta&quot;}) if artinfo: artinfo.extract() paragraphs_tags = content.find_all(&quot;p&quot;) paragraphs = [p.text.replace(&quot; xa0&quot;, &quot; &quot;).strip() for p in paragraphs_tags] out[&quot;text&quot;] = paragraphs raw_text = content.text raw_out = [] for raw_line in raw_text.split(&quot; n&quot;): line = raw_line.replace(&quot; xa0&quot;, &quot; &quot;).strip() if line == &quot;&quot;: continue raw_out.append(line) if paragraphs != raw_out: out[&quot;text&quot;] = raw_out summary = extract_summary(out[&quot;text&quot;]) if summary: out[&quot;summary&quot;] = summary out[&quot;text&quot;] = filter_para_list(out[&quot;text&quot;]) vocab_list = [] for vocab in content.find_all(&quot;a&quot;, {&quot;class&quot;: &quot;glossarylink&quot;}): item = {} item[&quot;en&quot;] = vocab.get(&quot;title&quot;).strip() item[&quot;ga&quot;] = vocab.text.strip() vocab_list.append(item) out[&quot;vocab&quot;] = vocab_list return out . page = requests.get(link) soup = BeautifulSoup(page.text, &quot;lxml&quot;) content = soup.find(&quot;div&quot;, {&quot;class&quot;: &quot;item-page&quot;}) if not content: print(&quot;Empty&quot;) . Oh, hey, I&#39;ve already downloaded this stuff and made a list of likely good articles. Might not work out well for anyone else. . BASE_DIR = &quot;/home/jim/Playing/foinseunpacked&quot; file = open(f&quot;{BASE_DIR}/attempt1&quot;, &quot;r&quot;) pages = [] for link in file.readlines(): pages.append(link.strip()) . foinse_data = [] with open(&quot;/home/jim/foinse-bad.txt&quot;, &quot;w&quot;) as bad_list: for page in pages: print(page) page_path = BASE_DIR + page.strip()[6:] with open(page_path, &quot;r&quot;) as pagef: plines = pagef.readlines() ptext = &quot; n&quot;.join(plines) content = get_content(page_path, ptext) if content: foinse_data.append(content) else: bad_list.write(page + &quot; n&quot;) . import json with open(&#39;foinse.json&#39;, &#39;w&#39;) as outfile: json.dump(foinse_data, outfile) .",
            "url": "https://jimregan.github.io/notes/irish/scraper/foinse/2021/10/05/foinse-scraper-pieces-ctd.html",
            "relUrl": "/irish/scraper/foinse/2021/10/05/foinse-scraper-pieces-ctd.html",
            "date": " â€¢ Oct 5, 2021"
        }
        
    
  
    
        ,"post71": {
            "title": "Interspeech papers",
            "content": "A Comparison of Acoustic Correlates of Voice Quality Across Different Recording Devices: A Cautionary Tale . Joshua Penney, Andy Gibson, Felicity Cox, Michael Proctor, Anita Szakay . PDF . @inproceedings{penney21_interspeech, author={Joshua Penney and Andy Gibson and Felicity Cox and Michael Proctor and Anita Szakay}, title={{A Comparison of Acoustic Correlates of Voice Quality Across Different Recording Devices: A Cautionary Tale}}, year=2021, booktitle={Proc. Interspeech 2021}, pages={1389--1393}, doi={10.21437/Interspeech.2021-729} } . . Emotional Prosody Control for Speech Generation . Sarath Sivaprasad, Saiteja Kosgi, Vineet Gandhi . PDF, samples . @inproceedings{sivaprasad21_interspeech, author={Sarath Sivaprasad and Saiteja Kosgi and Vineet Gandhi}, title={{Emotional Prosody Control for Speech Generation}}, year=2021, booktitle={Proc. Interspeech 2021}, pages={4653--4657}, doi={10.21437/Interspeech.2021-307} } . . Excitation Source Feature Based Dialect Identification in Ao â€” A Low Resource Language . Moakala Tzudir, Shikha Baghel, Priyankoo Sarmah, S.R. Mahadeva Prasanna . PDF . @inproceedings{tzudir21_interspeech, author={Moakala Tzudir and Shikha Baghel and Priyankoo Sarmah and S.R. Mahadeva Prasanna}, title={{Excitation Source Feature Based Dialect Identification in Ao â€” A Low Resource Language}}, year=2021, booktitle={Proc. Interspeech 2021}, pages={1524--1528}, doi={10.21437/Interspeech.2021-1672} } . . Phoneme Recognition Through Fine Tuning of Phonetic Representations: A Case Study on Luhya Language Varieties . Kathleen Siminyu, Xinjian Li, Antonios Anastasopoulos, David R. Mortensen, Michael R. Marlo, Graham Neubig . PDF, arXiv . @inproceedings{siminyu21_interspeech, author={Kathleen Siminyu and Xinjian Li and Antonios Anastasopoulos and David R. Mortensen and Michael R. Marlo and Graham Neubig}, title={{Phoneme Recognition Through Fine Tuning of Phonetic Representations: A Case Study on Luhya Language Varieties}}, year=2021, booktitle={Proc. Interspeech 2021}, pages={271--275}, doi={10.21437/Interspeech.2021-1434} } . . How Reliable Are Phonetic Data Collected Remotely? Comparison of Recording Devices and Environments on Acoustic Measurements . Chunyu Ge, Yixuan Xiong, Peggy Mok . PDF . @inproceedings{ge21b_interspeech, author={Chunyu Ge and Yixuan Xiong and Peggy Mok}, title={{How Reliable Are Phonetic Data Collected Remotely? Comparison of Recording Devices and Environments on Acoustic Measurements}}, year=2021, booktitle={Proc. Interspeech 2021}, pages={3984--3988}, doi={10.21437/Interspeech.2021-1122} } . . Sound Change in Spontaneous Bilingual Speech: A Corpus Study on the Cantonese n-l Merger in Cantonese-English Bilinguals . Rachel Soo, Khia A. Johnson, Molly Babel . PDF . @inproceedings{soo21_interspeech, author={Rachel Soo and Khia A. Johnson and Molly Babel}, title={{Sound Change in Spontaneous Bilingual Speech: A Corpus Study on the Cantonese n-l Merger in Cantonese-English Bilinguals}}, year=2021, booktitle={Proc. Interspeech 2021}, pages={421--425}, doi={10.21437/Interspeech.2021-1754} } . . (Not read) . Parsing Speech for Grouping and Prominence, and the Typology of Rhythm . Michael Wagner, Alvaro Iturralde Zurita, Sijia Zhang . PDF . @inproceedings{wagner21_interspeech, author={Michael Wagner and Alvaro Iturralde Zurita and Sijia Zhang}, title={{Parsing Speech for Grouping and Prominence, and the Typology of Rhythm}}, year=2021, booktitle={Proc. Interspeech 2021}, pages={2656--2660}, doi={10.21437/Interspeech.2021-1684} } .",
            "url": "https://jimregan.github.io/notes/journal%20club/2021/10/04/journal-club.html",
            "relUrl": "/journal%20club/2021/10/04/journal-club.html",
            "date": " â€¢ Oct 4, 2021"
        }
        
    
  
    
        ,"post72": {
            "title": "Interspeech papers",
            "content": "End-to-End Spelling Correction Conditioned on Acoustic Feature for Code-Switching Speech Recognition . Shuai Zhang, Jiangyan Yi, Zhengkun Tian, Ye Bai, Jianhua Tao, Xuefei Liu, Zhengqi Wen . PDF . @inproceedings{zhang21d_interspeech, author={Shuai Zhang and Jiangyan Yi and Zhengkun Tian and Ye Bai and Jianhua Tao and Xuefei Liu and Zhengqi Wen}, title={{End-to-End Spelling Correction Conditioned on Acoustic Feature for Code-Switching Speech Recognition}}, year=2021, booktitle={Proc. Interspeech 2021}, pages={266--270}, doi={10.21437/Interspeech.2021-1242} } . Spell checking as conditioned language model for code-switching in ASR. . Dataset: . ASRU 2019 Mandarin-English code-switching Challenge dataset 500 hours Mandarin | 200 hours code-switching | only used code-switching | . | . Augmentation: . ASR text: 10-fold cross validation | beam size 10 | . | audio: SpecAugment | dropout | . | . Metric: . Mix error rate (MER): WER for English, CER for Mandarin | . Experimental setup: . ASR Kaldi | 40-dim Mel filter-bank | 25ms windowing | 10ms frame shift | 3 * 2D CNN downsampling layers w/ stride 2 for acoustic features | attention dimensions 256 for both encode and decoder | 4 heards | position-wise feed-forward networks dim 1024 | 12 encoder blocks, 6 decoder blocks | . | LM 6-gram, KenLM | unidirectional LSTM | . | Spelling correction Encoder/decoder dims 256, num. heads: 4 | position-wise feed-forward networks dim 512 | dimension conversion layer to unify text &amp; acoustic features | uniform label smoothing, 0.1 | residual dropout: 0.1 applied to each sub-block | learning rate set by warm up | average last 5 checkpoints | wordpiece vocab: 1k for English, Chinese characters appearing more than 5 times in training set | . | . . Phoneme Recognition Through Fine Tuning of Phonetic Representations: A Case Study on Luhya Language Varieties . Kathleen Siminyu, Xinjian Li, Antonios Anastasopoulos, David R. Mortensen, Michael R. Marlo, Graham Neubig . PDF, arXiv . @inproceedings{siminyu21_interspeech, author={Kathleen Siminyu and Xinjian Li and Antonios Anastasopoulos and David R. Mortensen and Michael R. Marlo and Graham Neubig}, title={{Phoneme Recognition Through Fine Tuning of Phonetic Representations: A Case Study on Luhya Language Varieties}}, year=2021, booktitle={Proc. Interspeech 2021}, pages={271--275}, doi={10.21437/Interspeech.2021-1434} } . Fine tuning of allosaurus (â€œuniversal phone recognizerâ€) for three varieties of Luhya. . Data: . Saamia bible.is via CMU Wilderness | 18.2 hours | . | Bukusu Dictionary pronunciations | 3.7 hours | . | East Tusom Tusom2021 | 55.3 minutes | . | G2P with epitran | Splits: Bukusu: 6442 (train), 1001 (dev), 2458 (test) | Saamia: 7254 (train), 1000 (dev), 1500 (test) | East Tusom: 1600 (train), 400 (dev), 392 (test) | . | . Experiment: . sizes: 10, 25, 50, 100, 250, 500 and 1000 (approx. doubling progression) | fine-tuning is done on one model: same encoder 6 layer bilstm | hidden size 1024 per layer | . | 250 epochs of fine tuning | . Results: PER (relative improvement) . Â  Bukusu Saamia East Tusom . Allosaurus | 72.8 | 63.7 | 67.5 | . &amp; constraint | 52.5 | 37.4 | 56.7 | . &amp; fine-tuning (100) | 41.2 (21.5%) | 15.5 (58.5%) | 44.8 (20.9%) | . &amp; fine-tuning (1000) | 17.3 (67.0%) | 11.7 (65.7%) | 34.6 (38.9%) | . &amp; fine-tuning (all) | 5.2 (90.1%) | 9.2 (75.4%) | 33.1 (41.6%) | . . Exploring wav2vec 2.0 on Speaker Verification and Language Identification . Zhiyun Fan, Meng Li, Shiyu Zhou, Bo Xu . PDF . @inproceedings{fan21_interspeech, author={Zhiyun Fan and Meng Li and Shiyu Zhou and Bo Xu}, title={{Exploring wav2vec 2.0 on Speaker Verification and Language Identification}}, year=2021, booktitle={Proc. Interspeech 2021}, pages={1509--1513}, doi={10.21437/Interspeech.2021-1280} } . Finetunes monolingual English wav2vec model for speaker verification and/or language ID. . Fine tuning average pooling layer and fully connected layer | Loss: cross-entropy (AM-softmax for speaker classification) | . | Fine tuning, multi-task (speaker + language) average pooling, two parallel fully connected layers | loss is weighted sum of individual losses | . | Datasets VoxCeleb1 (speaker verification) | AP17-OLR (language ID) | . | Metric Equal error rate (EER) | . | . Results (single): . SV: 3.61 | LID: 3.47 | . Results (multitask): . SV: 4.18 | LID: 4.88 | . . Low Resource ASR: The Surprising Effectiveness of High Resource Transliteration . Shreya Khare, Ashish Mittal, Anuj Diwan, Sunita Sarawagi, Preethi Jyothi, Samarth Bharadwaj . pdf . @inproceedings{khare21_interspeech, author={Shreya Khare and Ashish Mittal and Anuj Diwan and Sunita Sarawagi and Preethi Jyothi and Samarth Bharadwaj}, title={{Low Resource ASR: The Surprising Effectiveness of High Resource Transliteration}}, year=2021, booktitle={Proc. Interspeech 2021}, pages={1529--1533}, doi={10.21437/Interspeech.2021-2062} } . Uses text in a second language transliterated to target language to augment training data for ASR. . We observe that for languages like Hindi and Telugu where the KL distance in phone distribution is small and the transliteration PER is low, we get consistent gains across different architectures and training data sizes. . G2P: epitran, g2ps | Tools: ESPnet, wav2vec2 | Datasets Microsoft Speech Corpus (Indian Languages): Gujarati and Telugu | Hindi ASR Challenge dataset | OpenSLR Large Bengali dataset | Zeroth Korean | ALFFA Amharic | . | . thereâ€™s a significant improvement in performance across both training settings with using Hindi instead of English during pretraining. Using both transliterated English and Hindi data during pretraining for the 10-hour Gujarati task further reduces WERs from 55.8% to 32.4% . . Improving Accent Identification and Accented Speech Recognition Under a Framework of Self-Supervised Learning pdf . @inproceedings{deng21b_interspeech, author={Keqi Deng and Songjun Cao and Long Ma}, title={{Improving Accent Identification and Accented Speech Recognition Under a Framework of Self-Supervised Learning}}, year=2021, booktitle={Proc. Interspeech 2021}, pages={1504--1508}, doi={10.21437/Interspeech.2021-1186} } . Fine tuning wav2vec2 for accented speech recognition/accent ID . Dataset: . LibriSpeech (pretrain) | AESRC2020 (finetune) | . . TODO . Robust wav2vec 2.0: Analyzing Domain Shift in Self-Supervised Pre-Training . AST: Audio Spectrogram Transformer . Raw Waveform Encoder with Multi-Scale Globally Attentive Locally Recurrent Networks for End-to-End Speech Recognition . Y-Vector: Multiscale Waveform Encoder for Speaker Embedding . Speech Acoustic Modelling Using Raw Source and Filter Components . Leveraging Phone Mask Training for Phonetic-Reduction-Robust E2E Uyghur Speech Recognition . Rethinking Evaluation in ASR: Are Our Models Robust Enough? . wav2vec-C: A Self-Supervised Model for Speech Representation Learning . Multimodal Speech Summarization Through Semantic Concept Learning . A Noise Robust Method for Word-Level Pronunciation Assessment . Improving RNN-T for Domain Scaling Using Semi-Supervised Training with Neural TTS . Phonetically Motivated Self-Supervised Speech Representation Learning . slimIPL: Language-Model-Free Iterative Pseudo-Labeling . Semi-Supervision in ASR: Sequential MixMatch and Factorized TTS-Based Augmentation . A Comparison of Supervised and Unsupervised Pre-Training of End-to-End Models . Momentum Pseudo-Labeling for Semi-Supervised Speech Recognition . On the Learning Dynamics of Semi-Supervised Training for ASR . Improving Streaming Transformer Based ASR Under a Framework of Self-Supervised Learning . Data Augmentation Methods for End-to-End Speech Recognition on Distant-Talk Scenarios . Multi-Channel Transformer Transducer for Speech Recognition . Scaling Sparsemax Based Channel Selection for Speech Recognition with ad-hoc Microphone Arrays . IR-GAN: Room Impulse Response Generator for Far-Field Speech Recognition . Noise Robust Acoustic Modeling for Single-Channel Speech Recognition Based on a Stream-Wise Transformer Architecture . Phoneme-Aware and Channel-Wise Attentive Learning for Text Dependent Speaker Verification .",
            "url": "https://jimregan.github.io/notes/links/2021/10/04/interspeech-papers.html",
            "relUrl": "/links/2021/10/04/interspeech-papers.html",
            "date": " â€¢ Oct 4, 2021"
        }
        
    
  
    
        ,"post73": {
            "title": "Lâ€™Accent dans le gaÃ«lique du Munster",
            "content": "Original . Transcription Irish French IPA Standard Modern . lÌ¬um | liom | avec moi | lÊ²ÊŠmË  | Â  | Â  | . flâ±uÄ‰ | fliuch | mouillÃ©, humide | fÊ²lÊ²ÊŠx | Â  | Â  | . qilÄÌn | cuileÃ¡n | jeune chien | kÉªËˆlÊ²aËnÌªË  | coileÃ¡n | Â  | . qiÅlÃ¡n | caisleÃ¡n | chÃ¢teau | kÉ™ËˆÊƒlÊ²É‘ËnÌªË  | Â  | Â  | . táµ˜â‚‘rÅ¡áº¡Ä‰ | tuirseach | fatiguÃ© | tÌªË É™É¾Ë ËˆÊƒax | Â  | Â  | . bon-ÄtÌ¬ | bunÃ¡it | principale rÃ©sidence, fondation | Â  | Â  | Â  | . mÃºâ±ntÌ¬Ã³â±r | mÃºinteÃ³ir | professeur | mË uËnÌ Ê²ËˆtÊ²oËÉ¾Ê² | mÃºinteoir | Â  | . drifâ±Ãºr | deirbhshiur | sÅ“ur | dÊ²É¾Ê²É™ËˆfÊ²uËÉ¾Ë  | deirfiÃºr | drifiÃºr | . â‚‘mâ‚‘dáº¡Ì„Ìn | amadÃ¡n | un fou | É‘mË É™ËˆdÌªË É‘ËnË  | Â  | Â  | . mÃ ontâ‚‘Ä‰áº¡Ì„Ìn | manntachÃ¡n | qui a les dents Ã©brÃ©chÃ©es | Â  | mantachÃ¡n | Â  | . Oâ€™ SÃ¹leÆ€Ã¡â±n | Oâ€™ SÃºilleabhÃ¡in | nom propre | Â  | Ã“ SÃºilleabhÃ¡in | Â  | . cliâ‚‘Æ€áº¡Ì„Ìn | cliabhÃ¡n | berceau | Â  | Â  | Â  | . balÉ™Æ€áº¡Ì„Ìn | balbhÃ¡n | muet | Â  | Â  | Â  | . bâ‚‘gáº¡Ì„Ìn | beagÃ¡n | un peu, peu | Â  | Â  | Â  | . qá»‹láº¡Ì„Ìn | cuileÃ¡n | jeune chien | kÉªËˆlÊ²aËnÌªË  | coileÃ¡n | Â  | . bâ‚‘ráº¡Ì„Ìnâ‚‘/brÄÌn | biorÃ¡n | Ã©pingle, un rien | bÊ²ÉªËˆÉ¾Ë É‘ËnÌªË , bÉ¾Ê²É‘ËnÌªË  | Â  | Â  | . brâ‚‘dáº¡Ì„Ìn | bradÃ¡n | saumon | bË É¾Ë É™ËˆdÌªË aËnÌªË  | Â  | Â  | . qiÅ¡láº¡Ì„Ìn | caisleÃ¡n | chÃ¢teau | Â  | Â  | Â  | . pÇ«rtáº¡Ì„Ìn | portÃ¡n | crabe | Â  | Â  | Â  | . â‚‘ráº¡Ì„Ìn | arÃ¡n | pain | É™ËˆÉ¾Ë É‘ËnÌªË  | Â  | Â  | . cupáº¡Ì„Ìn | cupÃ¡n | coupe | kÊŠËˆpË É‘ËnË  | Â  | Â  | . áº¹láº¡Ì„Ìn | oileÃ¡n | Ã®le | É™ËˆlÊ²É‘ËnË  | Â  | Â  | . scáº¡Ì„háº¡Ì„Ìn | scÃ¡thÃ¡n | mirroir, Ã  cÃ´tÃ© de | sË kÉ‘ËËˆhÉ‘ËnÌªË  | Â  | Â  | . scâ‚‘hÄÌn | scathÃ¡n | buisson | Â  | scothÃ¡n | Â  | . má»Ì„rÄÌn | mÃ³rÃ¡n | beaucoup | mË oËËˆÉ¾Ë É‘ËnÌªË  | Â  | Â  | . awrÄÌn | abhrÃ¡n | poÃ¨me, chant | É™uËˆÉ¾Ë É‘ËnÌªË  | amhrÃ¡n | Â  | . bÇ«Ä‰tÄÌn | bochtÃ¡n | un pauvre | Â  | Â  | Â  | . capâ‚‘lÄ«Ìn | capaillÃ­n | petit cheval | Â  | Â  | Â  | . lanâ‚‘Æ€Ä«Ìn | leanbhÃ­n | petit enfant | lÊ²anÉ™ËˆvÊ²iËnÊ² | Â  | Â  | . cÄ…lÄ«Ìn | cailÃ­n | fillette | kaËˆlÊ²iËnÊ² | Â  | Â  | . gâ‚‘rtÄ«Ìn | guirtÃ­n | petit champ | Â  | goirtÃ­n | Â  | . trâ‚‘hÄ«Ìn | troighthÃ­n | petit pied | Â  | troighÃ­n | Â  | . áº¡yntÄ«Ìn | aintÃ­n | tante | É‘ËnÊ²ËˆtÊ²iËnÊ² (Ã¡intÃ­n) | Â  | Â  | . spalpÄ«Ìn | spailpÃ­n | journalier, laboureur errant | Â  | Â  | Â  | . crÅ«Å¡cÄ«Ìn | crÃºiscÃ­n | cruche | Â  | Â  | Â  | . cÃ¡bÄ«Ìn | cÃ¡ibÃ­n | vieux chapeau | kaËËˆbÊ²iËnÊ² | Â  | Â  | . drÅlÄ«Ìn | dreoilÃ­n | roitelet | Â  | Â  | Â  | . bÇ­rhÄ«Ìn | bÃ³ithrÃ­n | petit sentier | Â  | Â  | Â  | . trÄÊ°nÄ«Ìn | trÃ¡ithnÃ­n | brin dâ€™herbe | Â  | Â  | Â  | . crÄ«Æ€Ä«Ìn | craoibhÃ­n | petite branche | Â  | Â  | Â  | . fÄ¯nÌ¬á»Ì„Ìg | fuinneÃ³g | fenÃªtre | fË É™ËˆnÌ Ê²oËÉ¡ | fuinneog | Â  | . fwÄ«nÌ¬Å¡á»Ì„Ìg | fuinnseÃ³g | frÃªne | Â  | fuinseog | Â  | . cesá»Ì„Ìg | casÃ³g | veston | kÉ™ËˆsË oËÉ¡ | Â  | Â  | . fwiÅ¡á»Ìg | fuiseÃ³g | alouette | fË É™ËˆÊƒoËÉ¡ | fuiseog | Â  | . iÅ¡Ã³Ì¦g | an fhuiseÃ³g | lâ€™alouette | Â  | an fhuiseog | Â  | . qÄ«nlá»Ì„Ìir | coinnleÃ³ir | chandelier | Â  | coinnleoir | Â  | . dlÄ«dÇ«Ìir | dligheadÃ³ir | homme de loi | Â  | dlÃ­odÃ³ir | Â  | . mÃºâ±ntÇ­Ìâ±r | mÃºinteÃ³ir | professeur | Â  | mÃºinteoir | Â  | . ÄÄ™rÅ¡oâ±r | aidhbheirseÃ³ir | lâ€™adversaire (le diable) | Â  | Ã¡ibhirseoir | Â  | . slÄnâ‚‘hÇ­Ìâ±r | slÃ¡nuightheÃ³ir | le sauveur | Â  | slÃ¡naitheoir | Â  | . Å¡cÌ¬â‚‘bÇ­l | sgiobÃ³l | grenier | ÊƒcÉªËˆbË oËlÌªË  | sciobÃ³l | Â  | .",
            "url": "https://jimregan.github.io/notes/irish/munster/2021/10/03/laccent-dans-le-gaelique-du-munster.html",
            "relUrl": "/irish/munster/2021/10/03/laccent-dans-le-gaelique-du-munster.html",
            "date": " â€¢ Oct 3, 2021"
        }
        
    
  
    
        ,"post74": {
            "title": "Interesting links, 1/10/2021",
            "content": "Irish lemmatiser (merged) . Irish lemmatisation data (merged) . Best Python based AutoML frameworks in 2021 . jonmagic/copy-excel-paste-markdown . . The New Corpus of Ireland â€“ ELRC-SHARE . The UCD BÃ³rd na Gaeilge Corpus of bilingual PDFs and Word documents â€“ ELRC-SHARE . ToiliÃº don ScagthÃ¡stÃ¡il Scoile um Amhairc &amp; Ã‰isteachta â€“ ELRC-SHARE . Tuairisc a thug MÃ¡ire Nic Shiubhlaigh, Aisteoir Tionscanta de chuid Amharlann na Mainistreach, ar ghÃ©illeadh gharastÃºn mhonarcha Jacob â€“ ELRC-SHARE . TuarascÃ¡il BhliantÃºil Chomhairle Chontae Longfoirt (2017) â€“ ELRC-SHARE . TuarascÃ¡laca BliantÃºla na Roinne LeanaÃ­ agus GnÃ³thaÃ­ Ã“ige â€“ ELRC-SHARE . Foirm FSS Iarratais Duine ar a ShonraÃ­ â€“ ELRC-SHARE . Irish Monolingual Corpus from contents of health.gov.ie web site â€“ ELRC-SHARE . LÃ¡ithreÃ¡nGrÃ©asÃ¡inOÃ‰G â€“ ELRC-SHARE . LeabhrÃ¡n dâ€™Aonad Altranais Pobail Teach UÃ­ Riada â€“ ELRC-SHARE . Legal acts of Ireland as Irish Monolingual Corpus â€“ ELRC-SHARE . Litir Ã³ Oifig an ChoimisinÃ©ara Teanga â€“ ELRC-SHARE . Manufactured data based on ParaCrawl 8 v2 â€“ ELRC-SHARE . Material in Irish and English from RTÃ‰ â€“ ELRC-SHARE . OifigÃ­ Ombudsman in Ã‰irinn â€“ ELRC-SHARE . Pleananna ITBÃC le comÃ³radh a dhÃ©anamh ar 1916 â€“ ELRC-SHARE . PÃ³staer faoi scoil ag clÃ¡rÃº â€“ ELRC-SHARE . PreasrÃ¡iteas faoi foirgneamh nua scoile â€“ ELRC-SHARE . PreasrÃ¡iteas faoi UachtarÃ¡n nua â€“ ELRC-SHARE . PreasrÃ¡iteas: MÃ­ IÃºil â€“ ELRC-SHARE . PreasrÃ¡itis Gaois, Fiontar &amp; Scoil na Gaeilge, DCU (1) â€“ ELRC-SHARE . PreasrÃ¡itis Gaois, Fiontar &amp; Scoil na Gaeilge, DCU (2) â€“ ELRC-SHARE . PreasrÃ¡itis Oifig an ChoimisinÃ©ara Teanga â€“ ELRC-SHARE . PreasrÃ¡itis Ollscoil MhÃ¡ Nuad Earrach 2019 â€“ ELRC-SHARE . PreasrÃ¡itis Ollscoil MhÃ¡ Nuad Samhradh 2019 â€“ ELRC-SHARE . PRINCIPLE Anonymized English-Irish DCHG parallel translation memory dataset â€“ ELRC-SHARE . PRINCIPLE An tAonad AistriÃºchÃ¡in agus Ateangaireachta Ã“EG/NUIG Translation Unit dataset â€“ ELRC-SHARE . PRINCIPLE Dept of Justice parallel English-Irish secondary legislation â€“ ELRC-SHARE . PRINCIPLE Dept of Justice parallel English-Irish secondary legislation (evaluated) â€“ ELRC-SHARE . PRINCIPLE English-Irish Annual Reports from the Houses of the Oireachtas â€“ ELRC-SHARE . PRINCIPLE English-Irish eJustice Corpus (Evaluated) â€“ ELRC-SHARE . PRINCIPLE English-Irish glossary of terms relating to primary legislation in Ireland â€“ ELRC-SHARE . PRINCIPLE English-Irish Houses of the Oireachtas ancillary material dataset â€“ ELRC-SHARE . Compilation of Irish-Polish parallel corpora resources used for training of NTEU Machine Translation engines. â€“ ELRC-SHARE . COVID-19 ANTIBIOTIC dataset. Multilingual (CEF languages) â€“ ELRC-SHARE . COVID-19 EC-EUROPA v1 dataset. Bilingual (EN-GA) â€“ ELRC-SHARE . COVID-19 EC-EUROPA v1 dataset. Multilingual (CEF languages) â€“ ELRC-SHARE . COVID-19 EU presscorner v1 dataset. Bilingual (EN-GA) â€“ ELRC-SHARE . COVID-19 EU presscorner v2 dataset. Bilingual (EN-GA) â€“ ELRC-SHARE . English-Irish website parallel corpus (Processed) â€“ ELRC-SHARE . FaisnÃ©is faoi IDS â€“ ELRC-SHARE . PRINCIPLE Dept of Justice parallel English-Irish secondary legislation â€“ ELRC-SHARE . Bilingual corpus from the European Vaccination Portal (GA-EN) â€“ ELRC-SHARE .",
            "url": "https://jimregan.github.io/notes/links/2021/10/01/misc-links.html",
            "relUrl": "/links/2021/10/01/misc-links.html",
            "date": " â€¢ Oct 1, 2021"
        }
        
    
  
    
        ,"post75": {
            "title": "Convert LASID",
            "content": "Set up ICU . %%capture !pip install pyicu . import icu def transliterator_from_rules(name, rules): fromrules = icu.Transliterator.createFromRules(name, rules) icu.Transliterator.registerInstance(fromrules) return icu.Transliterator.createInstance(name) . Download data . _URL = &quot;https://www3.smo.uhi.ac.uk/oduibhin/oideasra/lasid/lasid.zip&quot; . %%capture !wget {_URL} . %%capture !unzip lasid.zip . LASID transliterators . lasid_icu = &quot;&quot;&quot; x07 â†’ áµ ; t â†’ áµ‰ ; # x09 x0e â†’ á´µ ; x11 â†’ Ê° ; x12 â†’ â± ; x13 â†’ áµ’ ; x14 â†’ áµ’Ì¤ ; x15 â†’ Ê³ ; x16 â†’ Ë¢ ; x17 â†’ á¶´ ; x18 â†’ áµ— ; x19 â†’ áµ˜ ; x1a â†’ áµ˜Ì¯ ; x1c â†’ áµ› ; x1d â†’ Ê· ; x1e â†’ á¶¾ ; x1f â†’ áµŠ ; # â†’ á¶  ; # x23 $ â†’ áµ  ; # x24 % â†’ áµ ; # x25 &amp; â†’ áµž ; # x26 Ë  for IPA &#39; â†’ â€™ ; # x27 : â†’ Ë ; # x3a &lt; â†’ â±Ìˆ ; # x3c = â†’ â±Ì¯ ; # x3d ? â†’ Ê” ; # x3f @ â†’ Ê² ; # x40 E â†’ á´‡ ; # x45 I â†’ Éª ; # x49 L â†’ ÊŸ ; N â†’ É´ ; R â†’ Ê€ ; ^ â†’ áµ ; # x5e _ â†’ Ç° ; # crane, 021 # x5f ` â†’ É›Ì€Ìƒ ; # limekiln, 078: x60 | â†’ â¿ ; # lamb, 055: x7c ~ â†’ áµ‘ ; # dreaming, 078; maybe â¿Ì  ? # x7e x7f â†’ á´‡Ìƒ ; x80 â†’ Ï† ; # É¸ x81 â†’ Ã¼ ; x83 â†’ É› u0300 ; x84 â†’ eÌ€ u0323 ; # FIXME x85 â†’ eÌ€Ìƒ ; # this is ï¿½, so it needs to be escaped x86 â†’ uÌœÌƒ ; # lamb, 038 x87 â†’ uÌœ ; # finger-nails, 043 x88 â†’ Êˆ ; # looks like tÌœ : toothache, 033 x89 â†’ áµƒ ; # eggs, 066 x8a â†’ Ã¨ ; x8b â†’ Ã¯ ; x8c â†’ É”ÌœÌƒ ; # grandmother, 007 x8d â†’ É”Ìœ ; x8e â†’ É”Ì† ; # before i go, 078 x8f â†’ oÌœÌƒ ; # as cute, 062 x91 â†’ Ã¦ ; x92 â†’ oÌœ ; x93 â†’ É– ; x94 â†’ Ã¶ ; x95 â†’ É‘ÌœÌƒ ; x96 â†’ Ã» ; # milking, 067 x97 â†’ É‘ u0323 ; # FIXME (maybe Î±Ì© or É‘Ìœ ?) x98 â†’ vÌ  ; x99 â†’ tÌ  ; # toothache, 021 x9a â†’ rÌ  ; x9b â†’ Ã¸ ; x9c â†’ É´Ì  ; # sick, 034 x9d â†’ Å‹Ì  ; # grazing, 002 x9e â†’ nÌ  ; x9f â†’ lÌ  ; # plumage, 068 xa4 â†’ kÌ  ; # plumage, 068 xa5 â†’ gÌ  ; xa6 â†’ dÌ  ; # wedge, 021 xa7 â†’ uÌ† ; xa8 â†’ oÌˆÌ† ; xa9 â†’ oÌ† ; xaa â†’ iÌ† ; xab â†’ É›Ì† ; xac â†’ eÌ† ; xad â†’ oÌ¤ ; xae â†’ Î» ; xaf â†’ É‘ ; # Î± in the software xb0 â†’ É” ; xb1 â†’ É‘Ì† u0323 ; # FIXME xb2 â†’ É™ ; xb4 â†’ áµˆ ; # tail, 007 xb6 â†’ É‘Ì† ; # Î±Ì† in the software xb7 â†’ aÌ† ; xb8 â†’ Î» u0323 ; # FIXME xb9 â†’ É› ; xba â†’ Êƒ u030c ; # calling, 067 xbb â†’ Å¡ ; xbc â†’ Å™ ; xbd â†’ É‘Ìƒ ; xbe â†’ eÌƒ ; # tied, 88N xc1 â†’ â€² ; # superscript prime xc5 â†’ á´Ì  ; # fart, 071 xc6 â†’ aÌƒ ; # calf, 046 xc7 â†’ t u0323 ; # probably tÌž xc8 â†’ Î»Ì¯ ; # mane, 067 xc9 â†’ oÌ¯ ; # hare, 088 xca â†’ â±¢ ; # loaf, 001 xcb â†’ É« ; # loaf, 003 xcc â†’ mÌ¥ ; # awake, 001 xcd â†’ Ê€Ì¥ ; # thieving, 003 xce â†’ Ëˆ ; xcf â†’ ËŒ ; # cattle, 040 xd0 â†’ Ã° ; # boar, 88N xd1 â†’ s u0323 ; # FIXME # slime 008 xd2 â†’ r u0323 ; # FIXME # bulls 067 xd3 â†’ ÉªÌ† ; # suit of clothes 039 xd4 â†’ á´‡Ì€ ; xd5 â†’ p u0323 ; # FIXME # castrating 053 xd7 â†’ ÉªÌƒ ; # slime, 007 xd8 â†’ ÉªÌˆ ; # calf 027 xdb â†’ o u0323 ; # FIXME # cow 028 xdc â†’ Å‹ u0323 ; # FIXME # tied 078 xdd â†’ oÌˆÌ¤ ; xde â†’ k u0323 ; # FIXME xdf â†’ i u0323 ; # FIXME # sick 069 xe1 â†’ g u0323 ; # FIXME xe2 â†’ e u0323 ; # FIXME xe3 â†’ d u0323 ; # FIXME # agut 052 xe4 â†’ oÌƒ ; # I shall tie 062 xe5 â†’ b u0323 ; # FIXME # castrating 071 xe6 â†’ É‘Ìƒ u0323 ; #FIXME # barking 049 xe7 â†’ É‘ u0323 ; # FIXME # slime 008 xe8 â†’ yÌƒ ; xea â†’ Î»Ìƒ ; xeb â†’ uÌˆÌƒ ; # churn-dash, 011 xec â†’ uÌƒ ; xed â†’ É”Ìƒ ; # cow 074 xee â†’ oÌ¤Ìƒ ; # barking 055 xef â†’ â€² ; xf0 â†’ â€³ ; xf1 â†’ oÌˆÌ¤Ìƒ ; # dreaming, 078 xf2 â†’ oÌˆÌƒ ; # sheep shears 074 xf3 â†’ iÌˆÌƒ ; # churn-dash, 034 xf4 â†’ iÌƒ ; # sick 001 xf5 â†’ É£Ìƒ ; # tied 075 xf6 â†’ É›Ìƒ ; # tied 067 xf7 â†’ nÌ¥ ; # awake, 059 xf8 â†’ rÌ¥ ; # slime 002 xf9 â†’ Êƒ ; xfb â†’ Â· ; # slime 058 xfa â†’ É£ ; xfc â†’ Ï‡ ; # limekiln, 080 xfd â†’ Ê’ ; # sheep shears 054 xfe â†’ Å‹ ; &quot;&quot;&quot; . lasid_titles_icu = &quot;&quot;&quot; xb5 â†’ Ã ; xd6 â†’ Ã ; x90 â†’ Ã‰ ; xe0 â†’ Ã“ ; xe9 â†’ Ãš ; &quot;&quot;&quot; . I&#39;m not sure if there&#39;s something wrong with this, or if it&#39;s that there are just no spaces in a lot of the transcriptions, but this is best avoided. . lasid_spacing = &quot;&quot;&quot; $sp = &#39; u0020&#39;; $sp $sp $sp $sp $sp â†’ _; [^[0-9]] { $sp â†’ ; ::null; _ â†’ $sp ; &quot;&quot;&quot; . lasid = transliterator_from_rules(&#39;lasid_icu&#39;, lasid_icu) titles = transliterator_from_rules(&#39;lasid_titles&#39;, lasid_titles_icu) spacing = transliterator_from_rules(&#39;lasid_spacing&#39;, lasid_spacing) . def translit_phon(text, spaces=True): # could have been any 8-bit encoding line = lasid.transliterate(text.decode(&#39;ISO-8859-1&#39;).rstrip()) if spaces: return spacing.transliterate(line) else: return line . def translit_irish(text, spaces=True): line = titles.transliterate(text.decode(&#39;ISO-8859-1&#39;).rstrip()) if spaces: return spacing.transliterate(line) else: return line . Process . file = open(&quot;mapdata.dat&quot;, &quot;rb&quot;) . data = {} cur = {} ga = &#39;&#39; id = &#39;&#39; en = &#39;&#39; . for line in file.readlines(): if b&#39;{M&#39; in line: prev_en = en text = line.decode(&#39;ISO-8859-1&#39;).rstrip() id = text[3:7].strip() en = text[7:-1].strip() tmp = {} tmp[&#39;en&#39;] = prev_en tmp[&#39;id&#39;] = id tmp[&#39;ga&#39;] = ga tmp[&#39;data&#39;] = cur data[id] = tmp cur = {} elif b&#39;{F&#39; in line: raw = translit_irish(line, False) ga = raw[3:-1].strip() elif line.decode(&#39;ISO-8859-1&#39;)[0:1].isnumeric(): pid = line.decode(&#39;ISO-8859-1&#39;)[0:3] ptext = translit_phon(line[3:-1], False) if ptext[-1] == &#39;*&#39;: ptext = ptext[0:-1] cur[pid] = ptext.strip() . import json with open(&#39;lasid.json&#39;, &#39;w&#39;) as outfile: json.dump(data, outfile) .",
            "url": "https://jimregan.github.io/notes/irish/lasid/2021/09/28/lasid.html",
            "relUrl": "/irish/lasid/2021/09/28/lasid.html",
            "date": " â€¢ Sep 28, 2021"
        }
        
    
  
    
        ,"post76": {
            "title": "Task list, 28/9/2021",
            "content": "Today . separation script: spleeter: see run_spleeter.py . | Extend abair xml to return list of timestamps; segment long recordings: notebook . | Rebase w2v notebook on this or this . | Add LM and timings: see here, repo, file, this issue, parlance/ctcdecode, wav2vec2_kenlm.py . | Fingerprint for known audio: dejavu . | Pass over input data, with this or something similar . | MFA, based on this . | . Look into: . Add official ASR CTC example to examples/pytorch/speech-recognition | Rewrite padding logic from pure python to numpy | Non-Adversarial Unsupervised Word Translation | Phonetic-and-Semantic Embedding of Spoken Words with Applications in Spoken Content Retrieval | grtzsohalf/Audio-Phonetic-and-Semantic-Embedding | SpeechToolsWorkers | . Personal . Run this See this: | . --match-filter &quot;license=&#39;Creative Commons Attribution license (reuse allowed)&#39;&quot; . Living audio . Longer term . TG4 Foghlaim scraper Lessons . | Scrape more Ros na RÃºn . | Compare this with stuff from last year . | Segmentation: run_cleanup_segmentation.sh, tedlium, AMI . | VOSK LM . | CUNY-CL . | . Look at: . 2dot71mily/youtube_captions_corrections | microsoft/Recognizers-Text | hiromis/notes | Alexander-H-Liu/NPC | andi611/Mockingjay-Speech-Representation | jina-ai/jina | Continue this â€” p. 18 | scrapinghub/portia | wav2vec2-large-voxrex, Kungbib/swedish-bert-models | .",
            "url": "https://jimregan.github.io/notes/tasklist/2021/09/27/tasklist.html",
            "relUrl": "/tasklist/2021/09/27/tasklist.html",
            "date": " â€¢ Sep 27, 2021"
        }
        
    
  
    
        ,"post77": {
            "title": "Pronunciations from Simple Lessons in Irish, part 1",
            "content": "Source . Section Word Modern Transcription Wiktionary Abair Ulster Abair Connacht Abair Munster . 10 | sÃ¡l | Â  | saul | sË É‘ËlË  | ËˆsË aËÊŸË  | ËˆsË É‘ËÊŸË  | ËˆsË É‘ËlË  | . 14 | tobar | Â  | thÅ­bÄƒr | ËˆtÌªË É”bË É™É¾Ë  | ËˆtË obË É™É¾Ë  | ËˆtË obË É™É¾Ë  | ËˆtË obË É™É¾Ë  | . 17 | mine | Â  | minâ€²-Ä› | ËˆmÊ²ÉªnÊ²É™ | ËˆmÊ²inÊ²É™ | ËˆmÊ²inÊ²É™ | ËˆmÊ²inÊ²É™ | . 17 | mÃ­le | Â  | meelâ€²-Ä› | ËˆmÊ²iËlÊ²É™ | ËˆmÊ²iËlÊ²É™ | ËˆmÊ²iËlÊ²É™ | ËˆmÊ²iËlÊ²É™ | . 19 | an | Â  | Äƒn | É™nË  | ËˆÉ™É´Ë  | É™É´Ë  | É™nË  | . 19 | gort | Â  | gÅ­rth | É¡É”É¾Ë tÌªË  | ËˆgË oÉ¾Ë tË  | ËˆgË auÉ¾Ë tË  | ËˆgË oÉ¾Ë tË  | . 20 | cÃº | Â  | koo | kuË | ËˆkË uË | ËˆkË uË | ËˆkË uË | . 20 | Ã³g | Â  | Åg | oËÉ¡ | ËˆoËgË  | ËˆoËgË  | ËˆoËgË  | . 21 | Ã¡rd | ard | aurdh | É‘ËÉ¾Ë dÌªË  | ËˆaËÉ¾Ë dË  | ËˆÉ‘ËÉ¾Ë dË  | ËˆÉ‘ËÉ¾Ë dË  | . 21 | mÃ© | Â  | mae | mÊ²eË | ËˆmÊ²eË | ËˆmÊ²e | mÊ²e | . 21 | bÃ³ | Â  | bÅ | bË oË | ËˆbË oË | ËˆbË oË | ËˆbË oË | . 21 | mÃ³r | Â  | mÅr | mË oËÉ¾Ë  | ËˆmË oËÉ¾Ë  | ËˆmË oËÉ¾Ë  | ËˆmË uËÉ¾Ë  | . 21 | bos | Â  | bÅ­s | Â  | ËˆbË asË  | ËˆbË osË  | ËˆbË osË  | . 21 | cos | Â  | kÅ­s | kÉ”sË  | ËˆkË osË  | ËˆkË osË  | ËˆkË osË  | . 21 | glas | Â  | glos | É¡lË asË  | ËˆgË ÊŸË asË  | ËˆgË ÊŸË asË  | ËˆgË lË asË  | . 21 | srÃ³n | Â  | srÅn | sË É¾Ë oËnË  | ËˆsË É¾Ë oËÉ´Ë  | ËˆsË É¾Ë oËÉ´Ë  | ËˆsË É¾Ë oËnË  | . 21 | glÃºn | glÃºin | gloon | É¡lÌªË uËnÊ² | ËˆgË ÊŸË uËÉ´Ë  | ËˆgË ÊŸË uËÉ´Ë  | ËˆgË lË uËnË  | . 21 | tÃº | Â  | thoo | tÌªË uË | ËˆtË uË | ËˆtË uË | ËˆtË uË | . 21 | Ãºr | Â  | oor | uËÉ¾Ë  | ËˆuËÉ¾Ë  | ËˆuËÉ¾Ë  | ËˆuËÉ¾Ë  | . 21 | Art | Â  | orth | Â  | ËˆaÉ¾Ë tË  | ËˆaÉ¾Ë tË  | ËˆaÉ¾Ë tË  | . 21 | Ãšna | Â  | oonâ€²-Äƒ | ËˆuËnË É™ | ËˆuËÉ´Ë É™ | ËˆuËÉ´Ë É™ | ËˆuËnË É™ | . 21 | agus | Â  | og-Äƒs | ËˆÉ‘É¡É™sË  | ËˆagË É™sË  | ËˆagË É™sË  | ËˆagË É™sË  | . 25 | atÃ¡ | Â  | Äƒ-thauâ€² | É™ËˆtÌªË É‘Ë | É™ËˆtË aË | É™ËˆtË É‘Ë | É™ËˆtË É‘Ë | . 25 | tÃ¡ | Â  | thau | tÌªË É‘Ë | ËˆtË aË | ËˆtË É‘Ë | ËˆtË É‘Ë | . 29 | asal | Â  | osâ€²-Äƒl | ËˆasË É™lË  | ËˆasË É™ÊŸË  | ËˆasË É™ÊŸË  | ËˆasË É™lË  | . 29 | fÃ¡l | Â  | faul | fË É‘ËlË  | ËˆfË aËÊŸË  | ËˆfË É‘ËÊŸË  | ËˆfË É‘ËlË  | . 29 | doras | Â  | dhÅ­râ€²-Äƒs | ËˆdÌªË É”É¾Ë É™sË  | ËˆdË oÉ¾Ë É™sË  | ËˆdË oÉ¾Ë É™sË  | ËˆdË oÉ¾Ë É™sË  | . 29 | glan | Â  | glon | É¡lË anË  | ËˆgË ÊŸË aÉ´Ë  | ËˆgË ÊŸË aÉ´Ë  | ËˆgË lË anË  | . 29 | dÃºn | Â  | dhoon | dÌªË uËnË  | ËˆdË uËÉ´Ë  | ËˆdË uËÉ´Ë  | ËˆdË uËnË  | . 29 | tobar | Â  | thÅ­b`-Äƒr | ËˆtÌªË É”bË É™É¾Ë  | ËˆtË obË É™É¾Ë  | ËˆtË obË É™É¾Ë  | ËˆtË obË É™É¾Ë  | . 35 | ag | Â  | og | Â  | Â  | Â  | Â  | . 35 | ag | Â  | eð˜¨ | É™ÉŸ | ËˆeÉŸ | eÉŸ | É™ÉŸ | . 35 | fÃ³s | Â  | fÅs | fË oËsË  | ËˆfË oËsË  | ËˆfË oËsË  | ËˆfË oËsË  | . 35 | bog | Â  | bug | bË É”É¡ | ËˆbË ogË  | ËˆbË ogË  | ËˆbË ogË  | . 35 | sÃ© | Â  | shae | ÊƒeË | ËˆÊƒeË | Êƒe | ËˆÊƒeË | . 35 | brÃ³g | Â  | brÅg | bË É¾Ë oËÉ¡ | ËˆbË É¾Ë oËgË  | ËˆbË É¾Ë oËgË  | ËˆbË É¾Ë oËgË  | . 35 | sÃ­ | Â  | shee | ÊƒiË | ËˆÊƒiË | ËˆÊƒiË | ËˆÊƒiË | . 35 | dÃºn | Â  | dhoon | dÌªË uËnË  | ËˆdË uËÉ´Ë  | ËˆdË uËÉ´Ë  | ËˆdË uËnË  | . 35 | stÃ³l | Â  | sthÅl | sË tÌªË oËlË  | ËˆsË tË oËÊŸË  | ËˆsË tË oËÊŸË  | ËˆsË tË oËlË  | . 35 | fada | Â  | fodh-Äƒ | ËˆfË adÌªË É™ | ËˆfË adË É™ | ËˆfË adË É™ | ËˆfË adË É™ | . 35 | te | Â  | ð˜µe | tÊ²É› | ËˆtÊ²e | ËˆtÊ²e | ËˆtÊ²e | . 35 | fÃ¡g | Â  | faug | fË É‘ËÉ¡ | ËˆfË aËgË  | ËˆfË É‘ËgË  | ËˆfË É‘ËgË  | . 35 | tÃ­r | Â  | ð˜µeeð˜³ | tÊ²iËÉ¾Ê² | ËˆtÊ²iËÉ¾Ê² | ËˆtÊ²iËÉ¾Ê² | ËˆtÊ²iËÉ¾Ê² | . 35 | tirim | Â  | ð˜µið˜³â€²-im | ËˆtÊ²ÉªÉ¾Ê²É™mÊ² | ËˆtÊ²iÉ¾Ê²É™mÊ² | ËˆtÊ²iÉ¾Ê²É™mÊ² | ËˆtÊ²iÉ¾Ê²É™mÊ² | . 39 | ar | Â  | or | Â  | Â  | Â  | Â  | . 39 | ar | Â  | eð˜³ | É›É¾Ê² | ËˆeÉ¾Ê² | eÉ¾Ê² | É™É¾Ë  | . 39 | glas | Â  | glos | É¡lË asË  | ËˆgË ÊŸË asË  | ËˆgË ÊŸË asË  | ËˆgË lË asË  | . 39 | bÃ¡d | Â  | baudh | bË É‘ËdÌªË  | ËˆbË aËdË  | ËˆbË É‘ËdË  | ËˆbË É‘ËdË  | . 39 | mÃ¡la | Â  | maulâ€²-Äƒ | ËˆmË É‘ËlÌªË É™ | ËˆmË aËÊŸË É™ | ËˆmË É‘ËÊŸË É™ | ËˆmË É‘ËlË É™ | . 39 | cÃ³ta | Â  | kÅthâ€²-Äƒ | ËˆkoËtÌªË É™ | ËˆkË oËtË É™ | ËˆkË oËtË É™ | ËˆkË oËtË É™ | . 50 | mÃ¡la | Â  | maul-aâ€² | ËˆmË É‘ËlÌªË É™ | ËˆmË aËÊŸË É™ | ËˆmË É‘ËÊŸË É™ | ËˆmË É‘ËlË É™ | . 50 | milis | Â  | milâ€²ish | ËˆmÊ²ÉªlÊ²É™Êƒ | ËˆmÊ²ilÊ²É™Êƒ | ËˆmÊ²ilÊ²É™Êƒ | ËˆmÊ²ilÊ²iÊƒ | . 50 | Ãšna | Â  | ooâ€²-na | Â  | ËˆuËÉ´Ë É™ | ËˆuËÉ´Ë É™ | ËˆuËnË É™ | . 50 | minic | Â  | minâ€²ik | ËˆmÊ²ÉªnÊ²Éªc | ËˆmÊ²inÊ²ic | ËˆmÊ²inÊ²É™c | ËˆmÊ²inÊ²É™c | . 50 | bÃ¡n | Â  | baun | bË É‘ËnÌªË  | ËˆbË aËÉ´Ë  | ËˆbË É‘ËÉ´Ë  | ËˆbË É‘ËnË  | . 50 | asal | Â  | osâ€²-al | ËˆasË É™lË  | ËˆasË É™ÊŸË  | ËˆasË É™ÊŸË  | ËˆasË É™lË  | . 50 | olc | Â  | Å­lk | É”lË k | ËˆoÊŸË kË  | ËˆoÊŸË kË  | ËˆolË kË  | . 50 | blas | Â  | blos | bË lË asË  | ËˆbË ÊŸË asË  | ËˆbË ÊŸË asË  | ËˆbË lË asË  | . 51 | lag | Â  | Log | lÌªË aÉ¡ | ËˆÊŸË agË  | ËˆÊŸË agË  | ËˆlË agË  | . 51 | log | Â  | LÅ­g | lÌªË É”É¡ | ËˆÊŸË ogË  | ËˆÊŸË ogË  | ËˆlË ogË  | . 51 | slÃ¡n | Â  | sLaun | sË lÌªË É‘ËnÌªË  | ËˆsË ÊŸË aËÉ´Ë  | ËˆsË ÊŸË É‘ËÉ´Ë  | ËˆsË lË É‘ËnË  | . 51 | dlÃºn | Â  | dhLoon | Â  | ËˆdË ÊŸË uËÉ´Ë  | ËˆdË ÊŸË uËÉ´Ë  | ËˆdË lË uËnË  | . 51 | tlÃº | Â  | thLoo | tÌªË lË uË | ËˆtË ÊŸË uË | ËˆtË ÊŸË uË | ËˆtË lÌªË uË | . 51 | lÃ­n | Â  | ð˜­een | Â  | ËˆÊŸÊ²iËnÊ² | ËˆÊŸÊ²iËnÊ² | ËˆlÊ²iËnÊ² | . 51 | slÃ­m | Â  | shð˜­eem | Â  | ËˆÊƒlÊ²iËmÊ² | ËˆÊƒlÊ²iËmÊ² | ËˆÊƒlÊ²iËmÊ² | . 51 | fille | Â  | fið˜­â€²-e | ËˆfÊ²iËlÌ Ê²É™ | ËˆfÊ²iÊŸÊ²É™ | ËˆfÊ²iÊŸÊ²É™ | ËˆfÊ²ilÊ²É™ | . 51 | NÃºs | Â  | Noos | Â  | ËˆÉ´Ë uËsË  | ËˆÉ´Ë uËsË  | ËˆnË uËsË  | . 51 | snag | Â  | sNog | sË nÌªË aÉ¡ | ËˆsË É´Ë agË  | ËˆsË É´Ë agË  | ËˆsË nË agË  | . 51 | NÃ³ra | Â  | NÅrâ€²Äƒ | ËˆnÌªË oËÉ¾Ë É™ | ËˆÉ´Ë oËÉ¾Ë É™ | ËˆÉ´Ë uËÉ¾Ë É™ | ËˆnË oËÉ¾Ë É™ | . 51 | Finne | Â  | fið˜¯â€²-Ä• | ËˆfÊ²ÉªnÌ Ê²É™ | ËˆfÊ²iÉ´Ê²É™ | ËˆfÊ²iÉ´Ê²É™ | ËˆfÊ²inÊ²É™ | . 51 | binne | Â  | bið˜¯â€²-Ä• | ËˆbÊ²ÉªnÌ Ê²É™ | ËˆbÊ²iÉ´Ê²É™ | ËˆbÊ²iÉ´Ê²É™ | ËˆbÊ²inÊ²É™ | . 51 | nÃ­ | Â  | ð˜¯ee | nÌ Ê²iË | ËˆÉ´Ê²iË | ËˆÉ´Ê²iË | ËˆnÊ²iË | . 52 | balla | Â  | boLâ€²-Äƒ | ËˆbË alÌªË É™ | ËˆbË oÊŸË É™ | ËˆbË aÊŸË É™ | Â  | . 52 | falla | Â  | foLâ€²-Äƒ | ËˆfË É‘lÌªË É™ | Â  | Â  | ËˆfË alË É™ | . 52 | bÃ¡n | Â  | baun | bË É‘ËnÌªË  | ËˆbË aËÉ´Ë  | ËˆbË É‘ËÉ´Ë  | ËˆbË É‘ËnË  | . 52 | capall | Â  | kopâ€²-ÄƒL | ËˆkapË É™lÌªË  | ËˆkË apË É™ÊŸË  | ËˆkË apË É™ÊŸË  | ËˆkË apË É™lË  | . 52 | Conn | Â  | kÅ­N | Â  | ËˆkË oÉ´Ë  | ËˆkË auÉ´Ë  | ËˆkË oËnË  | . 52 | fan | Â  | fon | fË anË  | ËˆfË aÉ´Ë  | ËˆfË aÉ´Ë  | ËˆfË anË  | . 52 | glan | Â  | glon | É¡lË anË  | ËˆgË ÊŸË aÉ´Ë  | ËˆgË ÊŸË aÉ´Ë  | ËˆgË lË anË  | . 52 | lÃ¡ | Â  | Lau | lÌªË É‘Ë | ËˆÊŸË aË | ËˆÊŸË É‘Ë | ËˆlË É‘Ë | . 52 | lÃ¡n | Â  | Laun | lÌªË É‘ËnË  | ËˆÊŸË aËÉ´Ë  | ËˆÊŸË É‘ËÉ´Ë  | ËˆlË É‘ËnË  | . 52 | milis | Â  | milâ€²-ish | ËˆmÊ²ÉªlÊ²É™Êƒ | ËˆmÊ²ilÊ²É™Êƒ | ËˆmÊ²ilÊ²É™Êƒ | ËˆmÊ²ilÊ²iÊƒ | . 52 | nÃ¡ | Â  | Nau | nÌªË É‘Ë | ËˆÉ´Ë aË | ËˆÉ´Ë É‘Ë | ËˆnË É‘Ë | . 52 | slÃ¡n | Â  | sLaun | sË lÌªË É‘ËnÌªË  | ËˆsË ÊŸË aËÉ´Ë  | ËˆsË ÊŸË É‘ËÉ´Ë  | ËˆsË lË É‘ËnË  | . 52 | solas | Â  | sÅ­lâ€²-Äƒs | ËˆsË É”lË É™sË  | ËˆsË oÊŸË É™sË  | ËˆsË uÊŸË É™sË  | ËˆsË olË É™sË  | . 55 | blas | Â  | blos | bË lË asË  | ËˆbË ÊŸË asË  | ËˆbË ÊŸË asË  | ËˆbË lË asË  | . 55 | GrÃ¡nÃ¡rd | GrÃ¡nard | graunâ€²-aurdh | Â  | ËˆgË É¾Ë aËÉ´Ë aËÉ¾Ë dË  | ËˆgË É¾Ë É‘ËÉ´Ë É‘ËÉ¾Ë dË  | gË É¾Ë É‘ËËˆnË É‘ËÉ¾Ë dË  | . 55 | bris | Â  | brish | bÊ²É¾Ê²ÉªÊƒ | ËˆbÊ²É¾Ê²iÊƒ | ËˆbÊ²É¾Ê²iÊƒ | ËˆbÊ²É¾Ê²iÊƒ | . 55 | lag | Â  | Log | lÌªË aÉ¡ | ËˆÊŸË agË  | ËˆÊŸË agË  | ËˆlË agË  | . 55 | dÃºnta | Â  | dhooNâ€²-thÄƒ | ËˆdÌªË uËnÌªË tÌªË É™ | ËˆdË uËÉ´Ë tË É™ | ËˆdË uËÉ´Ë tË É™ | ËˆdË uËnË tË É™ | . 55 | mol | Â  | mÅ­l | mË É”lË  | ËˆmË oÊŸË  | ËˆmË oÊŸË  | ËˆmË olË  | . 59 | nÃ­l | Â  | ð˜¯eel | nÌ Ê²iËlÊ² | ËˆÉ´Ê²iËlÊ² | ËˆÉ´Ê²iËlÊ² | ËˆnÊ²iËlÊ² | . 60 | fir | Â  | fið˜³ | fÊ²ÉªÉ¾Ê² | ËˆfÊ²iÉ¾Ê² | ËˆfÊ²iÉ¾Ê² | ËˆfÊ²iÉ¾Ê² | . 61 | ag | Â  | Äƒ | É™ | Â  | Â  | Â  | . 61 | fÃ¡s | Â  | faus | fË É‘ËsË  | ËˆfË aËsË  | ËˆfË É‘ËsË  | ËˆfË É‘ËsË  | . 61 | dul | Â  | dul | dÌªË ÊŠlË  | Â  | Â  | ËˆdË ulË  | . 61 | dul | goil | gul | É¡É”lÊ² | Â  | ËˆgË olÊ² | Â  | . 61 | imirt | Â  | imâ€²ið˜³ð˜µ | ËˆÉªmÊ²É™É¾Ë tÊ² | ËˆimÊ²É™É¾Ë tÊ² | ËˆimÊ²É™É¾Ë tÊ² | ËˆimÊ²É™É¾Ë tÊ² | . 62 | do | Â  | dhÅ­ | dÌªË É” | ËˆdË É™ | dË o | dË o | . 62 | nÃ­l | Â  | neel | nÌ Ê²iËlÊ² | ËˆÉ´Ê²iËlÊ² | ËˆÉ´Ê²iËlÊ² | ËˆnÊ²iËlÊ² | . 62 | doâ€™n | don | dhÇ”n | dÌªË É™nË  | ËˆdË oÉ´Ë  | ËˆdË oÉ´Ë  | ËˆdË onË  | . 62 | Ã³ | Â  | Å | oË | ËˆoË | ËˆoË | ËˆoË | . 62 | dul | Â  | dhul | dÌªË ÊŠlË  | ËˆdË uÊŸË  | ËˆdË uÊŸË  | ËˆdË ulË  | . 62 | fÃ¡s | Â  | faus | fË É‘ËsË  | ËˆfË aËsË  | ËˆfË É‘ËsË  | ËˆfË É‘ËsË  | . 62 | olann | Â  | Å­lâ€²-ÄƒN | ËˆÉ”lË É™nÌªË  | ËˆoÊŸË É™É´Ë  | ËˆoÊŸË É™É´Ë  | ËˆolË É™nË  | .",
            "url": "https://jimregan.github.io/notes/irish/ogrowney/2021/09/27/simple-lessons-in-irish-pronunciation1.html",
            "relUrl": "/irish/ogrowney/2021/09/27/simple-lessons-in-irish-pronunciation1.html",
            "date": " â€¢ Sep 27, 2021"
        }
        
    
  
    
        ,"post78": {
            "title": "Interesting links, 27/9/2021",
            "content": "KTH Academic year 2021-22 . Irish pronunciation: practice and theory . A grammar of the Irish language . perfall/Edyson . Low Resource ASR: The Surprising Effectiveness of High Resource Transliteration pdf . @inproceedings{khare21_interspeech, author={Shreya Khare and Ashish Mittal and Anuj Diwan and Sunita Sarawagi and Preethi Jyothi and Samarth Bharadwaj}, title={{Low Resource ASR: The Surprising Effectiveness of High Resource Transliteration}}, year=2021, booktitle={Proc. Interspeech 2021}, pages={1529--1533}, doi={10.21437/Interspeech.2021-2062} } . Exploring wav2vec 2.0 on Speaker Verification and Language Identification pdf . @inproceedings{fan21_interspeech, author={Zhiyun Fan and Meng Li and Shiyu Zhou and Bo Xu}, title={{Exploring wav2vec 2.0 on Speaker Verification and Language Identification}}, year=2021, booktitle={Proc. Interspeech 2021}, pages={1509--1513}, doi={10.21437/Interspeech.2021-1280} } . Improving Accent Identification and Accented Speech Recognition Under a Framework of Self-Supervised Learning pdf . @inproceedings{deng21b_interspeech, author={Keqi Deng and Songjun Cao and Long Ma}, title={{Improving Accent Identification and Accented Speech Recognition Under a Framework of Self-Supervised Learning}}, year=2021, booktitle={Proc. Interspeech 2021}, pages={1504--1508}, doi={10.21437/Interspeech.2021-1186} } .",
            "url": "https://jimregan.github.io/notes/links/2021/09/27/misc-links.html",
            "relUrl": "/links/2021/09/27/misc-links.html",
            "date": " â€¢ Sep 27, 2021"
        }
        
    
  
    
        ,"post79": {
            "title": "Cognitive and Structural Correlates of Conversational Speech Timing in Mild Cognitive Impairment and Mild-to-Moderate Alzheimerâ€™s Disease - Relevance for Early Detection Approaches",
            "content": "Cognitive and Structural Correlates of Conversational Speech Timing in Mild Cognitive Impairment and Mild-to-Moderate Alzheimerâ€™s Disease: Relevance for Early Detection Approaches . Background | . The present study examines whether the temporal characteristics of speech in a collaborative referencing task are associated with cognitive function and the volumes of brain regions involved in speech production and known to be reduced in MCI and AD pathology. . Method | Results | Conclusion | . Introduction . Speech and language impairments are indeed salient characteristics of MCI and early AD link . However, the cognitive and structural underpinnings of these speech-based measures in classification approaches have not been systematically investigated and are not fully established. link . Deficits in the lexical, semantic, executive, discourse and pragmatic domains of language are commonly observed in MCI and early AD link . AD speech is characterized by slower speech rate (global speed of speech including pauses), a higher number of silent pauses, longer pauses and shorter interpausal units (or chunks of speech bounded by silent pauses link . Expectations . | Participants . | Neuropsychological Tests . | Speech Annotation and Measure Extraction . | . The pause threshold used in the automatic procedure was set at 100 ms to ensure its distinction with silent plosives link . The significance level was set at Î± = 0.006 link . Classification used cgplibrary . our exploratory analyses showed moderate accuracy rates for the speech-based classifiers in the pairwise contrasts link . Limitations . Abbreviations â€” might have been more useful earlier .",
            "url": "https://jimregan.github.io/notes/journal%20club/2021/09/27/journal-club.html",
            "relUrl": "/journal%20club/2021/09/27/journal-club.html",
            "date": " â€¢ Sep 27, 2021"
        }
        
    
  
    
        ,"post80": {
            "title": "Foinse scraper pieces",
            "content": "link = &quot;http://web.archive.org/web/20130922081459/http://www.foinse.ie/nuacht/nuacht-is-deanai/6765-suil-go-gcruthofar-158-post-nua-le-tograi-ata-ceadaithe-ag-unag&quot; . import requests from bs4 import BeautifulSoup . page = requests.get(link) assert page.status_code == 200 . In purely text terms, much of the junk can be discarded using these comments: . if &quot;&lt;!-- CONTENT --&gt;&quot; in page.text: trim = page.text.split(&quot;&lt;!-- CONTENT --&gt;&quot;)[1] . if trim and &quot;&lt;!-- //CONTENT --&gt;&quot; in trim: trim = trim.split(&quot;&lt;!-- //CONTENT --&gt;&quot;)[0] . ... but it&#39;s easier with BeautifulSoup to just extract &lt;div class=&quot;item-page&quot;&gt; . soup = BeautifulSoup(page.text, &quot;lxml&quot;) . content = soup.find(&quot;div&quot;, {&quot;class&quot;: &quot;item-page&quot;}) . title = content.find(&quot;h2&quot;).text.strip() . &#39;SÃºil go gcruthÃ³far 158 post nua le tograÃ­ atÃ¡ ceadaithe ag ÃšnaG&#39; . published_tag = content.find(&quot;dd&quot;, {&quot;class&quot;: &quot;published&quot;}) . if published_tag: published = published_tag.text.strip() . author_tag = content.find(&quot;dd&quot;, {&quot;class&quot;: &quot;createdby&quot;}) if author_tag: author = author_tag.text.strip() . author . &#39;ScrÃ­ofa ag Foinse&#39; . paragraphs_tags = content.find_all(&quot;p&quot;, {&quot;class&quot;: &quot;MsoNormal&quot;}) . paragraphs = [p.text.replace(&quot; xa0&quot;, &quot; &quot;).strip() for p in paragraphs_tags] . vocab_list = [] for p in paragraphs_tags: for vocab in p.find_all(&quot;a&quot;, {&quot;class&quot;: &quot;glossarylink&quot;}): item = {} item[&quot;en&quot;] = vocab.get(&quot;title&quot;).strip() item[&quot;ga&quot;] = vocab.text.strip() vocab_list.append(item) . check = &quot;http://web.archive.org/web/20171222073817/http://www.foinse.ie/nuacht/nuacht-is-deanai/6822-seanoiri-ag-dul-i-mbun-agoide-maidir-le-ciorruithe&quot; . page2 = requests.get(check) assert page2.status_code == 200 . def get_content(url): out = {} page = requests.get(url) if page.status_code != 200: return {} soup = BeautifulSoup(page.text, &quot;lxml&quot;) content = soup.find(&quot;div&quot;, {&quot;class&quot;: &quot;item-page&quot;}) if not content: return {} title = content.find(&quot;h2&quot;).text.strip() if title: out[&quot;title&quot;] = title published_tag = content.find(&quot;dd&quot;, {&quot;class&quot;: &quot;published&quot;}) if published_tag: out[&quot;published&quot;] = published_tag.text.strip() author_tag = content.find(&quot;dd&quot;, {&quot;class&quot;: &quot;createdby&quot;}) if author_tag: out[&quot;author&quot;] = author_tag.text.strip() paragraphs_tags = content.find_all(&quot;p&quot;, {&quot;class&quot;: &quot;MsoNormal&quot;}) paragraphs = [p.text.replace(&quot; xa0&quot;, &quot; &quot;).strip() for p in paragraphs_tags] out[&quot;text&quot;] = paragraphs vocab_list = [] for p in paragraphs_tags: for vocab in p.find_all(&quot;a&quot;, {&quot;class&quot;: &quot;glossarylink&quot;}): item = {} item[&quot;en&quot;] = vocab.get(&quot;title&quot;).strip() item[&quot;ga&quot;] = vocab.text.strip() vocab_list.append(item) out[&quot;vocab&quot;] = vocab_list return out . def filter_para_list(inlist): out = [] for para in inlist: if para == &quot;&quot;: continue elif para.strip() == &quot;Foinse - News as Gaeilge&quot;: return out else: out.append(para) return out . def extract_summary(inlist): if len(inlist) &gt; 2: if inlist[-2] == &quot;Did you understand this story? Here are the main points:&quot;: return inlist[-1] return &quot;&quot; .",
            "url": "https://jimregan.github.io/notes/irish/scraper/foinse/2021/09/27/foinse_scraper_pieces.html",
            "relUrl": "/irish/scraper/foinse/2021/09/27/foinse_scraper_pieces.html",
            "date": " â€¢ Sep 27, 2021"
        }
        
    
  
    
        ,"post81": {
            "title": "Interesting links, 26/9/2021",
            "content": "A Framework for Any-to-Any Voice Conversion with Self-Supervised Pretrained Representations . howard1337/S2VC . yistLin/universal-vocoder; paper: Towards achieving robust universal neural vocoding . cywang97/unispeech; paper: UniSpeech: Unified Speech Representation Learning with Labeled and Unlabeled Data . microsoft/unilm â€” UniLM AI - Large-scale Self-supervised Pre-training across Tasks, Languages, and Modalities . Continual-wav2vec2: an Application of Continual Learning for Self-Supervised Automatic Speech Recognition . Interactive demo: LayoutLMv2 . Improving Pretrained Cross-Lingual Language Models via Self-Labeled Word Alignment; CZWin32768/XLM-Align . waydroid/waydroid . huseinzol05/malaya-speech . Fine-tuning XLSR-Wav2Vec2 for WOLOF ASR with ðŸ¤— . model = Wav2Vec2ForCTC.from_pretrained( &quot;facebook/wav2vec2-large-xlsr-53&quot;, attention_dropout=0.1, hidden_dropout=0.1, feat_proj_dropout=0.0, mask_time_prob=0.05, layerdrop=0.1, gradient_checkpointing=True, ctc_loss_reduction=&quot;mean&quot;, pad_token_id=processor.tokenizer.pad_token_id, vocab_size=len(processor.tokenizer) ) training_args = TrainingArguments( output_dir=&quot;./wav2vec2-large-xlsr-WOLOF&quot;, group_by_length=True, per_device_train_batch_size=16, gradient_accumulation_steps=2, evaluation_strategy=&quot;steps&quot;, num_train_epochs=40, fp16=True, save_steps=500, eval_steps=500, logging_steps=500, learning_rate=3e-4, warmup_steps=1000, save_total_limit=2, ) . run_spleeter.py . Few-shot Intent Classification and Slot Filling with Retrieved Examples . Comparing CTC and LFMMI for out-of-domain adaptation of wav2vec 2.0 acoustic model . Unsupervised Cross-Modal Alignment of Speech and Text Embedding Spaces .",
            "url": "https://jimregan.github.io/notes/links/2021/09/26/misc-links.html",
            "relUrl": "/links/2021/09/26/misc-links.html",
            "date": " â€¢ Sep 26, 2021"
        }
        
    
  
    
        ,"post82": {
            "title": "Interesting links, 25/9/2021",
            "content": "Add an official audio classification example #13722 . To use your own dataset, convert your data into a csv or json format with the fields file and label like so: . worldveil/dejavu â€” Audio fingerprinting and recognition in Python Blog . Perlence/PyGuitarPro â€” Read, write and manipulate GP3, GP4 and GP5 files . alphaTab . microsoft/muzic â€” Muzic: Music Understanding and Generation with Artificial Intelligence . ESPNet Colab . open-mmlab/mmaction2 â€” OpenMMLabâ€™s Next Generation Video Understanding Toolbox and Benchmark . Assisting the Human Fact-Checkers: Detecting All Previously Fact-Checked Claims in a Document . tree-sitter/tree-sitter . lima-vm/lima â€” Linux virtual machines, on macOS (aka â€œLinux-on-Macâ€, â€œmacOS subsystem for Linuxâ€, â€œcontainerd for Macâ€, unofficially) . openai/triton â€” a language and compiler for writing highly efficient custom Deep-Learning primitives . JohnSnowLabs/spark-nlp . Haskell Liftoff . mingrammer/diagrams â€” Diagram as Code for prototyping cloud system architectures . babysor/MockingBird â€” Clone a voice in 5 seconds to generate arbitrary speech in real-time . PaddlePaddle/PaddleOCR . jina-ai/jina . iperov/DeepFaceLive â€” Real-time face swap for PC streaming or video calls . paulgavrikov/visualkeras/ . HarisIqbal88/PlotNeuralNet â€” Latex code for making neural networks diagrams . keplr-io/quiver â€” Interactive convnet features visualization for Keras . asappresearch/sew â€” SEW (Squeezed and Efficient Wav2vec) Performance-Efficiency Trade-offs in Unsupervised Pre-training for Speech Recognition . Efficient Nearest Neighbor Language Models . google/fnet-base â€” FNet is a transformers model with attention replaced with fourier transforms . Block Pruning For Faster Transformers . aterenin/phdthesis . pzelasko/kaldialign . bytedance/music_source_separation . mlflow/mlflow . willmcgugan/rich â€” Rich is a Python library for rich text and beautiful formatting in the terminal. . smacke/ffsubsync â€” Automagically synchronize subtitles with video. . chriskiehl/Gooey â€” Turn (almost) any Python command line program into a full GUI application with one line . deanmalmgren/textract . scrapinghub/portia . bohanli/BERT-flow â€” TensorFlow implementation of On the Sentence Embeddings from Pre-trained Language Models (EMNLP 2020) . 5 Podcasts To Listen To If Youâ€™re Learning Swedish . brapodcast.se . Podcast om Wikipedia . DeepFovea: Neural Reconstruction for Foveated Rendering and Video Compression using Learned Statistics of Natural Videos . PySimpleGUI/PySimpleGUI . tyiannak/pyAudioAnalysis .",
            "url": "https://jimregan.github.io/notes/links/2021/09/25/misc-links.html",
            "relUrl": "/links/2021/09/25/misc-links.html",
            "date": " â€¢ Sep 25, 2021"
        }
        
    
  
    
        ,"post83": {
            "title": "Utterance XML to json",
            "content": "import xml.etree.ElementTree as ET . class Utterance: def __init__(self, input, sentences): self.input = input self.sentences = sentences . class Sentence: def __init__(self, input, tokens): self.input = input self.tokens = tokens . class Token: def __init__(self, input, words): self.input = input self.words = words . class Word: def __init__(self, input, source, syllables, pos=&quot;&quot;): self.input = input self.source = source self.pos = pos self.syllables = syllables if self.syllables is None: self.syllables = [] def get_phonemes(self): return &quot; &quot;.join([a.get_phonemes() for a in self.syllables]) def get_clean_word(self): word = self.input if word[0:1] in &quot;nt&quot; and word[1:2] in &quot;AÃEÃ‰IÃOÃ“UÃš&quot;: return word[0:1] + &quot;-&quot; + word[1:].lower() else: return word.lower() . class Syllable: def __init__(self, stress: int = 0, phonemes = None): self.stress = stress self.phonemes = phonemes if self.phonemes is None: self.phonemes = [] def get_phonemes(self): return &quot; &quot;.join([a.symbol for a in self.phonemes]) . class Phoneme: def __init__(self, symbol: str = &quot;&quot;, end: float = 0.0): self.symbol = symbol self.end = end . def from_xml(source): tree = ET.parse(source) root = tree.getroot() if &#39;input_string&#39; in root.attrib: input = root.attrib[&#39;input_string&#39;] else: input = &#39;&#39; sentences = [] for sentence in root.findall(&#39;./sentence&#39;): if &#39;input_string&#39; in sentence.attrib: input = sentence.attrib[&#39;input_string&#39;] else: input = &#39;&#39; tokens = [] for token in sentence.findall(&#39;./token&#39;): if &#39;input_string&#39; in token.attrib: input = token.attrib[&#39;input_string&#39;] else: input = &#39;&#39; words = [] for word in token.findall(&#39;./word&#39;): if &#39;input_string&#39; in word.attrib: input = word.attrib[&#39;input_string&#39;] else: input = &quot;&quot; if &#39;trans_source&#39; in word.attrib: source = word.attrib[&#39;trans_source&#39;] else: source = &quot;&quot; if &#39;pos&#39; in word.attrib: pos = word.attrib[&#39;pos&#39;] else: pos = &quot;&quot; syllables = [] for syllable in word.findall(&#39;./syllable&#39;): phonemes = [] if &#39;stress&#39; in syllable.attrib: if syllable.attrib[&#39;stress&#39;] == &#39;None&#39;: stress = 0 else: stress = int(syllable.attrib[&#39;stress&#39;]) else: stress = 0 for phoneme in syllable.findall(&#39;./phoneme&#39;): if &#39;symbol&#39; in phoneme.attrib: symbol = phoneme.attrib[&#39;symbol&#39;] else: symbol = &#39;&#39; if &#39;end&#39; in phoneme.attrib: end = float(phoneme.attrib[&#39;end&#39;]) else: symbol = 0.0 phonemes.append(Phoneme(symbol, end)) syllables.append(Syllable(stress, phonemes)) words.append(Word(input, source, syllables, pos)) tokens.append(Token(input, words)) sentences.append(Sentence(input, tokens)) return Utterance(input, sentences) . def get_dictionary(utt): prons = {} for sent in utt.sentences: for tok in sent.tokens: for word in tok.words: if not word.get_clean_word() in prons.keys(): prons[word.get_clean_word()] = set() prons[word.get_clean_word()].add(word.get_phonemes()) return prons . utt = from_xml(&quot;/home/jim/tmp/pmg_ga_co/RCPiarsachALL/xml/MI0001RCPiarsachBairbre_0021.xml&quot;) . import json json.dumps(utt, default=lambda o: o.__dict__) . get_dictionary(utt) . co_pron_replacements = { &quot;thosaigh&quot;: &quot;h o s @&quot;, &quot;fÃ©in&quot;: &quot;h ee nj&quot;, &quot;haghaidh&quot;: &quot;h ai&quot; } . co_text_word_fixes = { &quot;RCPiarsachBairbre_0021.xml&quot;: [(&quot;ar&quot;, &quot;ar ar&quot;), (&quot;sÃºl&quot;, &quot;sÃºile&quot;), (&quot;mÃ¡thair&quot;, &quot;mothair&quot;)], } . import IPython.display as ipd ipd.Audio(&#39;/home/jim/tmp/pmg_ga_co/RCPiarsachALL/wav44_trimmed/MI0001RCPiarsachBairbre_0021.wav&#39;) .",
            "url": "https://jimregan.github.io/notes/irish/abair/mfa/2021/09/23/utterance-xml-to-mfa.html",
            "relUrl": "/irish/abair/mfa/2021/09/23/utterance-xml-to-mfa.html",
            "date": " â€¢ Sep 23, 2021"
        }
        
    
  
    
        ,"post84": {
            "title": "Swedish youtube scrape 1",
            "content": "Original on Kaggle . !pip install youtube-dl . !youtube-dl -o &#39;%(id)s.%(ext)s&#39; --match-filter &quot;license=&#39;Creative Commons Attribution license (reuse allowed)&#39;&quot; https://www.youtube.com/channel/UCagnPy0JPimGTqTzv1YQBpQ . [youtube:tab] UCagnPy0JPimGTqTzv1YQBpQ: Downloading webpage [download] Downloading playlist: RiksantikvarieÃ¤mbetet - Home [youtube:tab] playlist RiksantikvarieÃ¤mbetet - Home: Downloading 2 videos [download] Downloading video 1 of 2 [youtube:tab] heritageboard: Downloading webpage [download] Downloading playlist: RiksantikvarieÃ¤mbetet - Videos [youtube:tab] Downloading page 1 [youtube:tab] Downloading page 2 [youtube:tab] Downloading page 3 [youtube:tab] Downloading page 4 [youtube:tab] Downloading page 5 [youtube:tab] Downloading page 6 [youtube:tab] Downloading page 7 [youtube:tab] Downloading page 8 [youtube:tab] Downloading page 9 [youtube:tab] Downloading page 10 [youtube:tab] Downloading page 11 [youtube:tab] Downloading page 12 [youtube:tab] Downloading page 13 [youtube:tab] Downloading page 14 [youtube:tab] Downloading page 15 [youtube:tab] Downloading page 16 [youtube:tab] playlist RiksantikvarieÃ¤mbetet - Videos: Downloading 481 videos [download] Downloading video 1 of 481 [youtube] uU4M5-ajGt4: Downloading webpage [youtube] uU4M5-ajGt4: Downloading MPD manifest [download] OmvÃ¤rld och insikt - Museipanelen does not pass filter license=&#39;Creative Commons Attribution license (reuse allowed)&#39;, skipping .. [download] Downloading video 2 of 481 [youtube] Kvz2xeTHN50: Downloading webpage [download] Destination: Kvz2xeTHN50.f137.mp4 [download] 100% of 412.77MiB in 00:30 [download] Destination: Kvz2xeTHN50.f140.m4a [download] 100% of 20.05MiB in 00:01 [ffmpeg] Merging formats into &#34;Kvz2xeTHN50.mp4&#34; Deleting original file Kvz2xeTHN50.f137.mp4 (pass -k to keep) Deleting original file Kvz2xeTHN50.f140.m4a (pass -k to keep) [download] Downloading video 3 of 481 [youtube] RafIRgJ-qPw: Downloading webpage [youtube] RafIRgJ-qPw: Downloading MPD manifest [download] OmvÃ¤rld och insikt - Museipanelen does not pass filter license=&#39;Creative Commons Attribution license (reuse allowed)&#39;, skipping .. [download] Downloading video 4 of 481 [youtube] lnw92d5msqQ: Downloading webpage [youtube] lnw92d5msqQ: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 342 [download] Destination: lnw92d5msqQ.f247.webm [download] 100% of 178.10MiB in 02:07 [download] Destination: lnw92d5msqQ.f140.m4a [download] 100% of 28.11MiB in 00:01 [ffmpeg] Merging formats into &#34;lnw92d5msqQ.mkv&#34; Deleting original file lnw92d5msqQ.f247.webm (pass -k to keep) Deleting original file lnw92d5msqQ.f140.m4a (pass -k to keep) [download] Downloading video 5 of 481 [youtube] iJol2hdgYdw: Downloading webpage [youtube] iJol2hdgYdw: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 140 [download] Destination: iJol2hdgYdw.f248.webm [download] 100% of 82.07MiB in 00:50 [download] Destination: iJol2hdgYdw.f140.m4a [download] 100% of 10.96MiB in 00:00 [ffmpeg] Merging formats into &#34;iJol2hdgYdw.mkv&#34; Deleting original file iJol2hdgYdw.f248.webm (pass -k to keep) Deleting original file iJol2hdgYdw.f140.m4a (pass -k to keep) [download] Downloading video 6 of 481 [youtube] BoJ1-urZ5b4: Downloading webpage [youtube] BoJ1-urZ5b4: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 267 [download] Destination: BoJ1-urZ5b4.f248.webm [download] 100% of 130.54MiB in 01:36 [download] Destination: BoJ1-urZ5b4.f140.m4a [download] 100% of 20.99MiB in 00:01 [ffmpeg] Merging formats into &#34;BoJ1-urZ5b4.mkv&#34; Deleting original file BoJ1-urZ5b4.f248.webm (pass -k to keep) Deleting original file BoJ1-urZ5b4.f140.m4a (pass -k to keep) [download] Downloading video 7 of 481 [youtube] qDVkZW7BTQs: Downloading webpage [youtube] qDVkZW7BTQs: Downloading MPD manifest [download] Dag 3 - 03: Nonesthic â€“ en plattform fÃ¶r virtuella besÃ¶k i kulturarvsbyggnader &amp; â€Pop In &amp; Playâ€ does not pass filter license=&#39;Creative Commons Attribution license (reuse allowed)&#39;, skipping .. [download] Downloading video 8 of 481 [youtube] kfz1WOs30LE: Downloading webpage [youtube] kfz1WOs30LE: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 217 [download] Destination: kfz1WOs30LE.f248.webm [download] 100% of 36.33MiB in 01:17 [download] Destination: kfz1WOs30LE.f140.m4a [download] 100% of 17.08MiB in 00:01 [ffmpeg] Merging formats into &#34;kfz1WOs30LE.mkv&#34; Deleting original file kfz1WOs30LE.f248.webm (pass -k to keep) Deleting original file kfz1WOs30LE.f140.m4a (pass -k to keep) [download] Downloading video 9 of 481 [youtube] MPHHH_bN7ic: Downloading webpage [youtube] MPHHH_bN7ic: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 288 [download] Destination: MPHHH_bN7ic.f248.webm [download] 100% of 177.75MiB in 01:38 [download] Destination: MPHHH_bN7ic.f140.m4a [download] 100% of 22.62MiB in 00:03 [ffmpeg] Merging formats into &#34;MPHHH_bN7ic.mkv&#34; Deleting original file MPHHH_bN7ic.f248.webm (pass -k to keep) Deleting original file MPHHH_bN7ic.f140.m4a (pass -k to keep) [download] Downloading video 10 of 481 [youtube] 1Wbzean_07g: Downloading webpage [youtube] 1Wbzean_07g: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 240 [download] Destination: 1Wbzean_07g.f248.webm [download] 100% of 201.56MiB in 01:32 [download] Destination: 1Wbzean_07g.f140.m4a [download] 100% of 18.83MiB in 00:01 [ffmpeg] Merging formats into &#34;1Wbzean_07g.mkv&#34; Deleting original file 1Wbzean_07g.f248.webm (pass -k to keep) Deleting original file 1Wbzean_07g.f140.m4a (pass -k to keep) [download] Downloading video 11 of 481 [youtube] CnfKrwDxGag: Downloading webpage [youtube] CnfKrwDxGag: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 211 [download] Destination: CnfKrwDxGag.f248.webm [download] 100% of 128.89MiB in 01:14 [download] Destination: CnfKrwDxGag.f140.m4a [download] 100% of 17.25MiB in 00:01 [ffmpeg] Merging formats into &#34;CnfKrwDxGag.mkv&#34; Deleting original file CnfKrwDxGag.f248.webm (pass -k to keep) Deleting original file CnfKrwDxGag.f140.m4a (pass -k to keep) [download] Downloading video 12 of 481 [youtube] j8_pzb0Zj0c: Downloading webpage [youtube] j8_pzb0Zj0c: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 217 [download] Destination: j8_pzb0Zj0c.f248.webm [download] 100% of 69.01MiB in 01:19 [download] Destination: j8_pzb0Zj0c.f140.m4a [download] 100% of 17.75MiB in 00:01 [ffmpeg] Merging formats into &#34;j8_pzb0Zj0c.mkv&#34; Deleting original file j8_pzb0Zj0c.f248.webm (pass -k to keep) Deleting original file j8_pzb0Zj0c.f140.m4a (pass -k to keep) [download] Downloading video 13 of 481 [youtube] 5pJdR7pXEKA: Downloading webpage [youtube] 5pJdR7pXEKA: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 227 [download] Destination: 5pJdR7pXEKA.f248.webm [download] 100% of 129.12MiB in 01:25 [download] Destination: 5pJdR7pXEKA.f140.m4a [download] 100% of 18.58MiB in 06:54 [ffmpeg] Merging formats into &#34;5pJdR7pXEKA.mkv&#34; Deleting original file 5pJdR7pXEKA.f248.webm (pass -k to keep) Deleting original file 5pJdR7pXEKA.f140.m4a (pass -k to keep) [download] Downloading video 14 of 481 [youtube] k4dQAQ4grow: Downloading webpage [youtube] k4dQAQ4grow: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 212 [download] Destination: k4dQAQ4grow.f248.webm [download] 100% of 54.52MiB in 01:14 [download] Destination: k4dQAQ4grow.f140.m4a [download] 100% of 17.36MiB in 00:02 [ffmpeg] Merging formats into &#34;k4dQAQ4grow.mkv&#34; Deleting original file k4dQAQ4grow.f248.webm (pass -k to keep) Deleting original file k4dQAQ4grow.f140.m4a (pass -k to keep) [download] Downloading video 15 of 481 [youtube] kHX0PvydWQQ: Downloading webpage [youtube] kHX0PvydWQQ: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 207 [download] Destination: kHX0PvydWQQ.f248.webm [download] 100% of 120.15MiB in 01:15 [download] Destination: kHX0PvydWQQ.f140.m4a [download] 100% of 16.96MiB in 00:01 [ffmpeg] Merging formats into &#34;kHX0PvydWQQ.mkv&#34; Deleting original file kHX0PvydWQQ.f248.webm (pass -k to keep) Deleting original file kHX0PvydWQQ.f140.m4a (pass -k to keep) [download] Downloading video 16 of 481 [youtube] 2dmtx_ytJBc: Downloading webpage [youtube] 2dmtx_ytJBc: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 235 [download] Destination: 2dmtx_ytJBc.f248.webm [download] 100% of 169.85MiB in 01:28 [download] Destination: 2dmtx_ytJBc.f140.m4a [download] 100% of 19.24MiB in 05:52 [ffmpeg] Merging formats into &#34;2dmtx_ytJBc.mkv&#34; Deleting original file 2dmtx_ytJBc.f248.webm (pass -k to keep) Deleting original file 2dmtx_ytJBc.f140.m4a (pass -k to keep) [download] Downloading video 17 of 481 [youtube] mdsyDk4oG2I: Downloading webpage [youtube] mdsyDk4oG2I: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 183 [download] Destination: mdsyDk4oG2I.f248.webm [download] 100% of 68.80MiB in 01:04 [download] Destination: mdsyDk4oG2I.f140.m4a [download] 100% of 14.34MiB in 00:01 [ffmpeg] Merging formats into &#34;mdsyDk4oG2I.mkv&#34; Deleting original file mdsyDk4oG2I.f248.webm (pass -k to keep) Deleting original file mdsyDk4oG2I.f140.m4a (pass -k to keep) [download] Downloading video 18 of 481 [youtube] 3ydSZ9Uk-3A: Downloading webpage [youtube] 3ydSZ9Uk-3A: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 280 [download] Destination: 3ydSZ9Uk-3A.f248.webm [download] 100% of 41.92MiB in 01:37 [download] Destination: 3ydSZ9Uk-3A.f140.m4a [download] 100% of 22.00MiB in 00:02 [ffmpeg] Merging formats into &#34;3ydSZ9Uk-3A.mkv&#34; Deleting original file 3ydSZ9Uk-3A.f248.webm (pass -k to keep) Deleting original file 3ydSZ9Uk-3A.f140.m4a (pass -k to keep) [download] Downloading video 19 of 481 [youtube] tiM2l9rYrVw: Downloading webpage [youtube] tiM2l9rYrVw: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 252 [download] Destination: tiM2l9rYrVw.f248.webm [download] 100% of 95.93MiB in 01:34 [download] Destination: tiM2l9rYrVw.f140.m4a [download] 100% of 19.82MiB in 00:01 [ffmpeg] Merging formats into &#34;tiM2l9rYrVw.mkv&#34; Deleting original file tiM2l9rYrVw.f248.webm (pass -k to keep) Deleting original file tiM2l9rYrVw.f140.m4a (pass -k to keep) [download] Downloading video 20 of 481 [youtube] FPdgF5zRPcc: Downloading webpage [youtube] FPdgF5zRPcc: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 248 [download] Destination: FPdgF5zRPcc.f248.webm [download] 100% of 30.54MiB in 01:25 [download] Destination: FPdgF5zRPcc.f140.m4a [download] 100% of 19.52MiB in 00:03 [ffmpeg] Merging formats into &#34;FPdgF5zRPcc.mkv&#34; Deleting original file FPdgF5zRPcc.f248.webm (pass -k to keep) Deleting original file FPdgF5zRPcc.f140.m4a (pass -k to keep) [download] Downloading video 21 of 481 [youtube] XhoTQzu4VAE: Downloading webpage [youtube] XhoTQzu4VAE: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 157 [download] Destination: XhoTQzu4VAE.f248.webm [download] 100% of 100.06MiB in 00:58 [download] Destination: XhoTQzu4VAE.f140.m4a [download] 100% of 12.28MiB in 00:01 [ffmpeg] Merging formats into &#34;XhoTQzu4VAE.mkv&#34; Deleting original file XhoTQzu4VAE.f248.webm (pass -k to keep) Deleting original file XhoTQzu4VAE.f140.m4a (pass -k to keep) [download] Downloading video 22 of 481 [youtube] -5DwojwgLe0: Downloading webpage [youtube] -5DwojwgLe0: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 310 [download] Destination: -5DwojwgLe0.f248.webm [download] 100% of 52.16MiB in 01:47 [download] Destination: -5DwojwgLe0.f140.m4a [download] 100% of 24.42MiB in 00:01 [ffmpeg] Merging formats into &#34;-5DwojwgLe0.mkv&#34; Deleting original file -5DwojwgLe0.f248.webm (pass -k to keep) Deleting original file -5DwojwgLe0.f140.m4a (pass -k to keep) [download] Downloading video 23 of 481 [youtube] Lfz3yDI2rdY: Downloading webpage [youtube] Lfz3yDI2rdY: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 15 [download] Destination: Lfz3yDI2rdY.f248.webm [download] 100% of 10.16MiB in 00:05 [download] Destination: Lfz3yDI2rdY.f140.m4a [download] 100% of 1.12MiB in 00:01 [ffmpeg] Merging formats into &#34;Lfz3yDI2rdY.mkv&#34; Deleting original file Lfz3yDI2rdY.f248.webm (pass -k to keep) Deleting original file Lfz3yDI2rdY.f140.m4a (pass -k to keep) [download] Downloading video 24 of 481 [youtube] vOu-MuP4mLA: Downloading webpage [youtube] vOu-MuP4mLA: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 39 [download] Destination: vOu-MuP4mLA.f303.webm [download] 100% of 36.90MiB in 00:15 [download] Destination: vOu-MuP4mLA.f140.m4a [download] 100% of 2.99MiB in 00:00 [ffmpeg] Merging formats into &#34;vOu-MuP4mLA.mkv&#34; Deleting original file vOu-MuP4mLA.f303.webm (pass -k to keep) Deleting original file vOu-MuP4mLA.f140.m4a (pass -k to keep) [download] Downloading video 25 of 481 [youtube] QtFRPmTRyWw: Downloading webpage [youtube] QtFRPmTRyWw: Downloading MPD manifest [download] Destination: QtFRPmTRyWw.f137.mp4 [download] 100% of 148.39MiB in 00:05 [download] Destination: QtFRPmTRyWw.f140.m4a [download] 100% of 7.13MiB in 00:00 [ffmpeg] Merging formats into &#34;QtFRPmTRyWw.mp4&#34; Deleting original file QtFRPmTRyWw.f137.mp4 (pass -k to keep) Deleting original file QtFRPmTRyWw.f140.m4a (pass -k to keep) [download] Downloading video 26 of 481 [youtube] Gci-BbB0i5g: Downloading webpage [youtube] Gci-BbB0i5g: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 206 [download] Destination: Gci-BbB0i5g.f248.webm [download] 100% of 34.73MiB in 01:12 [download] Destination: Gci-BbB0i5g.f140.m4a [download] 100% of 16.87MiB in 00:01 [ffmpeg] Merging formats into &#34;Gci-BbB0i5g.mkv&#34; Deleting original file Gci-BbB0i5g.f248.webm (pass -k to keep) Deleting original file Gci-BbB0i5g.f140.m4a (pass -k to keep) [download] Downloading video 27 of 481 [youtube] 8jSE5bzQVbk: Downloading webpage [youtube] 8jSE5bzQVbk: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 504 [download] Destination: 8jSE5bzQVbk.f248.webm [download] 100% of 388.26MiB in 03:09 [download] Destination: 8jSE5bzQVbk.f140.m4a [download] 100% of 41.41MiB in 00:03 [ffmpeg] Merging formats into &#34;8jSE5bzQVbk.mkv&#34; Deleting original file 8jSE5bzQVbk.f248.webm (pass -k to keep) Deleting original file 8jSE5bzQVbk.f140.m4a (pass -k to keep) [download] Downloading video 28 of 481 [youtube] hm7RZHfFKeA: Downloading webpage [youtube] hm7RZHfFKeA: Downloading MPD manifest [download] OmvÃ¤rld och insikt - Museipanelen does not pass filter license=&#39;Creative Commons Attribution license (reuse allowed)&#39;, skipping .. [download] Downloading video 29 of 481 [youtube] xMZu6MR5BrM: Downloading webpage [youtube] xMZu6MR5BrM: Downloading MPD manifest [dashsegments] Total fragments: 206 [download] Destination: xMZu6MR5BrM.f137.mp4 [download] 100% of 136.54MiB in 01:18 [download] Destination: xMZu6MR5BrM.f140.m4a [download] 100% of 16.81MiB in 00:01 [ffmpeg] Merging formats into &#34;xMZu6MR5BrM.mp4&#34; Deleting original file xMZu6MR5BrM.f137.mp4 (pass -k to keep) Deleting original file xMZu6MR5BrM.f140.m4a (pass -k to keep) [download] Downloading video 30 of 481 [youtube] YeNcvCrF_V4: Downloading webpage [youtube] YeNcvCrF_V4: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 295 [download] Destination: YeNcvCrF_V4.f244.webm [download] 100% of 12.36MiB in 01:38 [download] Destination: YeNcvCrF_V4.f140.m4a [download] 100% of 23.24MiB in 00:04 [ffmpeg] Merging formats into &#34;YeNcvCrF_V4.mkv&#34; Deleting original file YeNcvCrF_V4.f244.webm (pass -k to keep) Deleting original file YeNcvCrF_V4.f140.m4a (pass -k to keep) [download] Downloading video 31 of 481 [youtube] HQiNjDVARxI: Downloading webpage [youtube] HQiNjDVARxI: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 273 [download] Destination: HQiNjDVARxI.f248.webm [download] 100% of 65.31MiB in 01:36 [download] Destination: HQiNjDVARxI.f140.m4a [download] 100% of 22.34MiB in 00:02 [ffmpeg] Merging formats into &#34;HQiNjDVARxI.mkv&#34; Deleting original file HQiNjDVARxI.f248.webm (pass -k to keep) Deleting original file HQiNjDVARxI.f140.m4a (pass -k to keep) [download] Downloading video 32 of 481 [youtube] A_pmPIyDfXw: Downloading webpage [youtube] A_pmPIyDfXw: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 403 [download] Destination: A_pmPIyDfXw.f248.webm [download] 100% of 262.74MiB in 02:36 [download] Destination: A_pmPIyDfXw.f140.m4a [download] 100% of 33.03MiB in 00:01 [ffmpeg] Merging formats into &#34;A_pmPIyDfXw.mkv&#34; Deleting original file A_pmPIyDfXw.f248.webm (pass -k to keep) Deleting original file A_pmPIyDfXw.f140.m4a (pass -k to keep) [download] Downloading video 33 of 481 [youtube] sQyC8woJwR8: Downloading webpage [youtube] sQyC8woJwR8: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 158 [download] Destination: sQyC8woJwR8.f248.webm [download] 100% of 38.34MiB in 00:55 [download] Destination: sQyC8woJwR8.f140.m4a [download] 100% of 12.88MiB in 04:21 [ffmpeg] Merging formats into &#34;sQyC8woJwR8.mkv&#34; Deleting original file sQyC8woJwR8.f248.webm (pass -k to keep) Deleting original file sQyC8woJwR8.f140.m4a (pass -k to keep) [download] Downloading video 34 of 481 [youtube] mwNFSiKza00: Downloading webpage [youtube] mwNFSiKza00: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 30 [download] Destination: mwNFSiKza00.f248.webm [download] 100% of 15.28MiB in 00:11 [download] Destination: mwNFSiKza00.f140.m4a [download] 100% of 2.38MiB in 00:00 [ffmpeg] Merging formats into &#34;mwNFSiKza00.mkv&#34; Deleting original file mwNFSiKza00.f248.webm (pass -k to keep) Deleting original file mwNFSiKza00.f140.m4a (pass -k to keep) [download] Downloading video 35 of 481 [youtube] GKpnihA9Am0: Downloading webpage [youtube] GKpnihA9Am0: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 283 [download] Destination: GKpnihA9Am0.f248.webm [download] 100% of 70.30MiB in 01:39 [download] Destination: GKpnihA9Am0.f140.m4a [download] 100% of 23.21MiB in 00:02 [ffmpeg] Merging formats into &#34;GKpnihA9Am0.mkv&#34; Deleting original file GKpnihA9Am0.f248.webm (pass -k to keep) Deleting original file GKpnihA9Am0.f140.m4a (pass -k to keep) [download] Downloading video 36 of 481 [youtube] ELz_eDr2Jxg: Downloading webpage [youtube] ELz_eDr2Jxg: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 180 [download] Destination: ELz_eDr2Jxg.f248.webm [download] 100% of 34.08MiB in 01:03 [download] Destination: ELz_eDr2Jxg.f140.m4a [download] 100% of 14.72MiB in 00:02 [ffmpeg] Merging formats into &#34;ELz_eDr2Jxg.mkv&#34; Deleting original file ELz_eDr2Jxg.f248.webm (pass -k to keep) Deleting original file ELz_eDr2Jxg.f140.m4a (pass -k to keep) [download] Downloading video 37 of 481 [youtube] eS3vz6en90Q: Downloading webpage [youtube] eS3vz6en90Q: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 252 [download] Destination: eS3vz6en90Q.f248.webm [download] 100% of 41.49MiB in 01:29 [download] Destination: eS3vz6en90Q.f140.m4a [download] 100% of 20.60MiB in 00:02 [ffmpeg] Merging formats into &#34;eS3vz6en90Q.mkv&#34; Deleting original file eS3vz6en90Q.f248.webm (pass -k to keep) Deleting original file eS3vz6en90Q.f140.m4a (pass -k to keep) [download] Downloading video 38 of 481 [youtube] Gpr7RETcS6A: Downloading webpage [youtube] Gpr7RETcS6A: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 229 [download] Destination: Gpr7RETcS6A.f248.webm [download] 100% of 50.44MiB in 01:21 [download] Destination: Gpr7RETcS6A.f140.m4a [download] 100% of 18.73MiB in 00:02 [ffmpeg] Merging formats into &#34;Gpr7RETcS6A.mkv&#34; Deleting original file Gpr7RETcS6A.f248.webm (pass -k to keep) Deleting original file Gpr7RETcS6A.f140.m4a (pass -k to keep) [download] Downloading video 39 of 481 [youtube] P0GRef2Nn0g: Downloading webpage [youtube] P0GRef2Nn0g: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 55 [download] Destination: P0GRef2Nn0g.f136.mp4 [download] 100% of 80.24MiB in 00:21 [download] Destination: P0GRef2Nn0g.f251.webm [download] 100% of 4.52MiB in 00:00 [ffmpeg] Merging formats into &#34;P0GRef2Nn0g.mkv&#34; Deleting original file P0GRef2Nn0g.f136.mp4 (pass -k to keep) Deleting original file P0GRef2Nn0g.f251.webm (pass -k to keep) [download] Downloading video 40 of 481 [youtube] BJpmB6tpKKY: Downloading webpage [youtube] BJpmB6tpKKY: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 445 [download] Destination: BJpmB6tpKKY.f137.mp4 [download] 100% of 1.48GiB in 03:52 [download] Destination: BJpmB6tpKKY.f251.webm [download] 100% of 39.22MiB in 00:03 [ffmpeg] Merging formats into &#34;BJpmB6tpKKY.mkv&#34; Deleting original file BJpmB6tpKKY.f137.mp4 (pass -k to keep) Deleting original file BJpmB6tpKKY.f251.webm (pass -k to keep) [download] Downloading video 41 of 481 [youtube] wIwi4JxORsQ: Downloading webpage [youtube] wIwi4JxORsQ: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 560 [download] Destination: wIwi4JxORsQ.f247.webm [download] 100% of 103.88MiB in 03:58 [download] Destination: wIwi4JxORsQ.f140.m4a [download] 100% of 46.02MiB in 00:07 [ffmpeg] Merging formats into &#34;wIwi4JxORsQ.mkv&#34; Deleting original file wIwi4JxORsQ.f247.webm (pass -k to keep) Deleting original file wIwi4JxORsQ.f140.m4a (pass -k to keep) [download] Downloading video 42 of 481 [youtube] 1M9i1bhqG4k: Downloading webpage [youtube] 1M9i1bhqG4k: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 425 [download] Destination: 1M9i1bhqG4k.f248.webm [download] 100% of 322.71MiB in 02:43 [download] Destination: 1M9i1bhqG4k.f140.m4a [download] 100% of 34.91MiB in 00:03 [ffmpeg] Merging formats into &#34;1M9i1bhqG4k.mkv&#34; Deleting original file 1M9i1bhqG4k.f248.webm (pass -k to keep) Deleting original file 1M9i1bhqG4k.f140.m4a (pass -k to keep) [download] Downloading video 43 of 481 [youtube] 4lSp2mN9c0c: Downloading webpage [youtube] 4lSp2mN9c0c: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 290 [download] Destination: 4lSp2mN9c0c.f247.webm [download] 100% of 183.10MiB in 02:24 [download] Destination: 4lSp2mN9c0c.f140.m4a [download] 100% of 23.76MiB in 00:02 [ffmpeg] Merging formats into &#34;4lSp2mN9c0c.mkv&#34; Deleting original file 4lSp2mN9c0c.f247.webm (pass -k to keep) Deleting original file 4lSp2mN9c0c.f140.m4a (pass -k to keep) [download] Downloading video 44 of 481 [youtube] S8JHEfd6UYo: Downloading webpage [youtube] S8JHEfd6UYo: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 260 [download] Destination: S8JHEfd6UYo.f248.webm [download] 100% of 32.58MiB in 01:30 [download] Destination: S8JHEfd6UYo.f140.m4a [download] 100% of 21.28MiB in 00:03 [ffmpeg] Merging formats into &#34;S8JHEfd6UYo.mkv&#34; Deleting original file S8JHEfd6UYo.f248.webm (pass -k to keep) Deleting original file S8JHEfd6UYo.f140.m4a (pass -k to keep) [download] Downloading video 45 of 481 [youtube] wJjAaArYzJs: Downloading webpage [youtube] wJjAaArYzJs: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 217 [download] Destination: wJjAaArYzJs.f248.webm [download] 100% of 93.03MiB in 01:18 [download] Destination: wJjAaArYzJs.f140.m4a [download] 100% of 17.75MiB in 00:02 [ffmpeg] Merging formats into &#34;wJjAaArYzJs.mkv&#34; Deleting original file wJjAaArYzJs.f248.webm (pass -k to keep) Deleting original file wJjAaArYzJs.f140.m4a (pass -k to keep) [download] Downloading video 46 of 481 [youtube] HjUJKVFLfGc: Downloading webpage [youtube] HjUJKVFLfGc: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 335 [download] Destination: HjUJKVFLfGc.f248.webm [download] 100% of 62.32MiB in 01:56 [download] Destination: HjUJKVFLfGc.f140.m4a [download] 100% of 27.44MiB in 00:01 [ffmpeg] Merging formats into &#34;HjUJKVFLfGc.mkv&#34; Deleting original file HjUJKVFLfGc.f248.webm (pass -k to keep) Deleting original file HjUJKVFLfGc.f140.m4a (pass -k to keep) [download] Downloading video 47 of 481 [youtube] 5-WvzW6Goq0: Downloading webpage [youtube] 5-WvzW6Goq0: Downloading MPD manifest [download] Museipanelen does not pass filter license=&#39;Creative Commons Attribution license (reuse allowed)&#39;, skipping .. [download] Downloading video 48 of 481 [youtube] -O8QKVL4IWY: Downloading webpage [youtube] -O8QKVL4IWY: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 223 [download] Destination: -O8QKVL4IWY.f248.webm [download] 100% of 41.78MiB in 01:21 [download] Destination: -O8QKVL4IWY.f140.m4a [download] 100% of 18.24MiB in 00:02 [ffmpeg] Merging formats into &#34;-O8QKVL4IWY.mkv&#34; Deleting original file -O8QKVL4IWY.f248.webm (pass -k to keep) Deleting original file -O8QKVL4IWY.f140.m4a (pass -k to keep) [download] Downloading video 49 of 481 [youtube] _aPZ9kc7pSE: Downloading webpage [youtube] _aPZ9kc7pSE: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 313 [download] Destination: _aPZ9kc7pSE.f247.webm [download] 58.1% of ~170.35MiB at 28.65MiB/s ETA 01:30[download] Got server HTTP error: HTTP Error 404: Not Found. Retrying fragment 183 (attempt 1 of 10)... [download] 83.4% of ~170.80MiB at 24.78MiB/s ETA 00:36[download] Got server HTTP error: HTTP Error 404: Not Found. Retrying fragment 262 (attempt 1 of 10)... [download] Got server HTTP error: HTTP Error 404: Not Found. Retrying fragment 262 (attempt 2 of 10)... [download] 100% of 169.40MiB in 03:39 [download] Destination: _aPZ9kc7pSE.f140.m4a [download] 100% of 24.60MiB in 00:01 [ffmpeg] Merging formats into &#34;_aPZ9kc7pSE.mkv&#34; Deleting original file _aPZ9kc7pSE.f247.webm (pass -k to keep) Deleting original file _aPZ9kc7pSE.f140.m4a (pass -k to keep) [download] Downloading video 50 of 481 [youtube] c_wqdJMJbhc: Downloading webpage [youtube] c_wqdJMJbhc: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 203 [download] Destination: c_wqdJMJbhc.f248.webm [download] 100% of 34.47MiB in 01:23 [download] Destination: c_wqdJMJbhc.f140.m4a [download] 100% of 16.64MiB in 00:03 [ffmpeg] Merging formats into &#34;c_wqdJMJbhc.mkv&#34; Deleting original file c_wqdJMJbhc.f248.webm (pass -k to keep) Deleting original file c_wqdJMJbhc.f140.m4a (pass -k to keep) [download] Downloading video 51 of 481 [youtube] pigyLnE0DmA: Downloading webpage [youtube] pigyLnE0DmA: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 425 [download] Destination: pigyLnE0DmA.f248.webm [download] 100% of 107.17MiB in 02:34 [download] Destination: pigyLnE0DmA.f140.m4a [download] 100% of 34.87MiB in 08:25 [ffmpeg] Merging formats into &#34;pigyLnE0DmA.mkv&#34; Deleting original file pigyLnE0DmA.f248.webm (pass -k to keep) Deleting original file pigyLnE0DmA.f140.m4a (pass -k to keep) [download] Downloading video 52 of 481 [youtube] ngxK_PvUSIo: Downloading webpage [youtube] ngxK_PvUSIo: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 357 [download] Destination: ngxK_PvUSIo.f248.webm [download] 100% of 70.31MiB in 02:05 [download] Destination: ngxK_PvUSIo.f140.m4a [download] 100% of 29.26MiB in 00:01 [ffmpeg] Merging formats into &#34;ngxK_PvUSIo.mkv&#34; Deleting original file ngxK_PvUSIo.f248.webm (pass -k to keep) Deleting original file ngxK_PvUSIo.f140.m4a (pass -k to keep) [download] Downloading video 53 of 481 [youtube] c_0BcUmqM50: Downloading webpage [youtube] c_0BcUmqM50: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 11 [download] Destination: c_0BcUmqM50.f248.webm [download] 100% of 5.73MiB in 00:04 ERROR: unable to download video data: HTTP Error 403: Forbidden .",
            "url": "https://jimregan.github.io/notes/kaggle/swedish/2021/09/21/scrape-swedish-youtube-take1.html",
            "relUrl": "/kaggle/swedish/2021/09/21/scrape-swedish-youtube-take1.html",
            "date": " â€¢ Sep 21, 2021"
        }
        
    
  
    
        ,"post85": {
            "title": "Check RiksantikvarieÃ¤mbetet youtube for licence",
            "content": "Original on Kaggle . %%capture !pip install youtube-dl . !youtube-dl -j --flat-playlist &quot;https://www.youtube.com/c/heritageboard/playlists?view=1&amp;sort=dd&amp;shelf_id=0&quot; &gt; rplist.json . !cat rplist.json | awk -F&#39;&quot;url&quot;: &quot;&#39; &#39;{print $2}&#39;|awk -F&#39;&quot;&#39; &#39;{print $1}&#39; | while read i;do youtube-dl -j --flat-playlist $i &gt;&gt; pl_videos.json || echo $i &gt;&gt; retry;done . !youtube-dl -j --flat-playlist &quot;https://www.youtube.com/c/heritageboard/videos?view=0&amp;sort=dd&amp;shelf_id=0&quot; &gt; uploads.json . import json import requests cc_by = [] other = [] retry = [] seen = [] . lic = &#39;&quot;Creative Commons Attribution licence (reuse allowed)&quot;&#39; def inner(cur_id): if cur_id in seen: return req = requests.get(f&quot;https://www.youtube.com/watch?v={cur_id}&quot;) if req.status_code != 200: retry.append(cur_id) if lic in req.text: cc_by.append(cur_id) else: other.append(cur_id) seen.append(cur_id) . with open(&quot;pl_videos.json&quot;) as pl_videos: for line in pl_videos.readlines(): line_data = json.loads(line.strip()) inner(line_data[&#39;id&#39;]) with open(&quot;uploads.json&quot;) as pl_videos: for line in pl_videos.readlines(): line_data = json.loads(line.strip()) inner(line_data[&#39;id&#39;]) . with open(&#39;proc.json&#39;, &#39;w&#39;) as outfile: json.dump({&#39;cc-by&#39;: cc_by, &#39;other&#39;: other, &#39;retry&#39;: retry}, outfile) . print(len(cc_by)) . 469 . other . [&#39;qDVkZW7BTQs&#39;, &#39;LvsH1IURj5E&#39;, &#39;uU4M5-ajGt4&#39;, &#39;RafIRgJ-qPw&#39;, &#39;hm7RZHfFKeA&#39;, &#39;5-WvzW6Goq0&#39;, &#39;6PsuJIIDAEA&#39;, &#39;rB0uJG3fUwg&#39;, &#39;BK0fsTtfF9s&#39;, &#39;_tVo6Iwbx8E&#39;, &#39;qLXM4OgGO5c&#39;, &#39;tVK_NaGnxio&#39;, &#39;cgc0Z1QAzS8&#39;, &#39;oSWLwD79Xps&#39;, &#39;h8IIilrFdHk&#39;, &#39;fdrI7O9v0f4&#39;, &#39;KbacshS5qN0&#39;, &#39;URaZRJM5wQE&#39;, &#39;ZpBgogulsvk&#39;, &#39;Vbbb97vlPfw&#39;, &#39;4OvMqfWayk4&#39;, &#39;2er5uIiXF18&#39;, &#39;2STecAi0gRQ&#39;, &#39;bIC9bJntqrI&#39;, &#39;NKD_P7d82NE&#39;, &#39;Rkqi0TTN_94&#39;, &#39;p85fNZ7vi2A&#39;, &#39;s7_bkrhfwoE&#39;, &#39;oN8srXalBmU&#39;, &#39;FIat0r_xg5U&#39;, &#39;D25NgXwNTtM&#39;, &#39;l86yzp3kqc0&#39;, &#39;9EhOyBTjcFg&#39;, &#39;7TueN2uz-pc&#39;, &#39;BTIl1PDy4LQ&#39;, &#39;zEXwU9pO-aA&#39;, &#39;ctl3W8dAbNA&#39;, &#39;t1uFA5nMVc0&#39;, &#39;M5VkaMFLMKI&#39;, &#39;IVZE-B0C80k&#39;, &#39;H8Fj3W7ZtGM&#39;, &#39;v1rpeMJ6fac&#39;, &#39;i7rTsXMu6KY&#39;, &#39;Zxpgq1jc4no&#39;] . retry . [] . cc_by . [&#39;XhoTQzu4VAE&#39;, &#39;3ydSZ9Uk-3A&#39;, &#39;tiM2l9rYrVw&#39;, &#39;FPdgF5zRPcc&#39;, &#39;mdsyDk4oG2I&#39;, &#39;-5DwojwgLe0&#39;, &#39;2dmtx_ytJBc&#39;, &#39;kHX0PvydWQQ&#39;, &#39;k4dQAQ4grow&#39;, &#39;5pJdR7pXEKA&#39;, &#39;j8_pzb0Zj0c&#39;, &#39;CnfKrwDxGag&#39;, &#39;1Wbzean_07g&#39;, &#39;MPHHH_bN7ic&#39;, &#39;kfz1WOs30LE&#39;, &#39;BoJ1-urZ5b4&#39;, &#39;iJol2hdgYdw&#39;, &#39;vOu-MuP4mLA&#39;, &#39;kCPJh_v70bA&#39;, &#39;Lfz3yDI2rdY&#39;, &#39;zAAgEFoJvkw&#39;, &#39;A_pmPIyDfXw&#39;, &#39;8jSE5bzQVbk&#39;, &#39;1UaXcix1HIE&#39;, &#39;S8JHEfd6UYo&#39;, &#39;1M9i1bhqG4k&#39;, &#39;4lSp2mN9c0c&#39;, &#39;BJpmB6tpKKY&#39;, &#39;wIwi4JxORsQ&#39;, &#39;P0GRef2Nn0g&#39;, &#39;Gpr7RETcS6A&#39;, &#39;eS3vz6en90Q&#39;, &#39;ELz_eDr2Jxg&#39;, &#39;GKpnihA9Am0&#39;, &#39;sQyC8woJwR8&#39;, &#39;ZujFZjPpC5s&#39;, &#39;ngxK_PvUSIo&#39;, &#39;pigyLnE0DmA&#39;, &#39;c_wqdJMJbhc&#39;, &#39;-O8QKVL4IWY&#39;, &#39;HjUJKVFLfGc&#39;, &#39;HQiNjDVARxI&#39;, &#39;xMZu6MR5BrM&#39;, &#39;Gci-BbB0i5g&#39;, &#39;RAnaS3ctS5g&#39;, &#39;jp-rNPkHsE0&#39;, &#39;48pg0lHtciQ&#39;, &#39;BKIiBYFyK4M&#39;, &#39;iRh1bwx4c6w&#39;, &#39;lnw92d5msqQ&#39;, &#39;UhkrLH-8zOc&#39;, &#39;GHDHpIxnXUs&#39;, &#39;e8I8vtKbVf0&#39;, &#39;DmkOurgeDaU&#39;, &#39;ykJFS30nh0w&#39;, &#39;hp4Xocu5YFM&#39;, &#39;zuUX9FjCXrM&#39;, &#39;zM9c-zidvkk&#39;, &#39;g6YtbuvGmDA&#39;, &#39;Hh7axQNXXBE&#39;, &#39;opnUyJaoC5g&#39;, &#39;YH9oPx8j1HU&#39;, &#39;QtFRPmTRyWw&#39;, &#39;smcfjOlINro&#39;, &#39;oBopkQbtIXo&#39;, &#39;BsZzjOX1Ff4&#39;, &#39;HtV9ZJDc_R8&#39;, &#39;W5HTPh23Yo8&#39;, &#39;SY8SLSuqVtI&#39;, &#39;khfupiNLUSA&#39;, &#39;bHgLR73tKp0&#39;, &#39;kJjUVydQkKg&#39;, &#39;1uFO8S_phd0&#39;, &#39;6G3jRE_AnrA&#39;, &#39;5En68jOlr6I&#39;, &#39;-rLL_8FSiYo&#39;, &#39;8pN6I79RNZc&#39;, &#39;s3UMHClphyM&#39;, &#39;43jtyTxwQzE&#39;, &#39;SinXSm4TM8Y&#39;, &#39;hmOy5lJo9a0&#39;, &#39;fUEiIYNVuoQ&#39;, &#39;_AajW3ALi94&#39;, &#39;0jJMNx592LE&#39;, &#39;x_g2FElUUus&#39;, &#39;ReFwmH29_b4&#39;, &#39;OdvnZJhhgK8&#39;, &#39;TpyQwsMLni0&#39;, &#39;to7Oq-MYHX4&#39;, &#39;b2gEr_FnfUU&#39;, &#39;x0FGBxJuNXM&#39;, &#39;nj9Fbwf6UnY&#39;, &#39;LWh0F4C8Ffo&#39;, &#39;qSajIPCuZkA&#39;, &#39;6r7JtdRpRzo&#39;, &#39;JF1c97PkudY&#39;, &#39;vHw6VQT9WiE&#39;, &#39;KXHH6b-XrUE&#39;, &#39;mE_VViu1bUA&#39;, &#39;rFjxjWwUcsk&#39;, &#39;zwxruQCvNO4&#39;, &#39;UakyimUn-Xg&#39;, &#39;oPib9P3f4b0&#39;, &#39;r_X8eEEj_jI&#39;, &#39;158AslrkcOo&#39;, &#39;grrMwlqd9ps&#39;, &#39;d3fhWTkpm5s&#39;, &#39;2kj5A0UN8lQ&#39;, &#39;6-a5b9QZtsM&#39;, &#39;aMXI-nMxUs0&#39;, &#39;h65A1Xss5Yg&#39;, &#39;m9YTLHXLp_s&#39;, &#39;F07D-jSspa4&#39;, &#39;l1i9y0zji_g&#39;, &#39;7LOfIq8bfw0&#39;, &#39;vccSlA0gsIo&#39;, &#39;t1_XNFop7gc&#39;, &#39;iHpHdIJynhE&#39;, &#39;El57R6AACkY&#39;, &#39;y54Rj-gZzM8&#39;, &#39;63D1-PSkTxw&#39;, &#39;sMDkQ7cY3P4&#39;, &#39;jNunAK9p1gc&#39;, &#39;aIGJFNmRRZw&#39;, &#39;4KYv6x2ugw0&#39;, &#39;mwNqA9KDxpc&#39;, &#39;67BOTkByWa4&#39;, &#39;KyXA5H5wTMg&#39;, &#39;ZTzBMhgZDqg&#39;, &#39;HFHacP5fvZw&#39;, &#39;eEn1mYkf95k&#39;, &#39;6TchEw5P-lw&#39;, &#39;pF7qnON0BtA&#39;, &#39;r0zWEoK5JUQ&#39;, &#39;7u2uUQ2VK5c&#39;, &#39;Tj6pV1IQ4vE&#39;, &#39;rEpZmf_G4vM&#39;, &#39;qEIKDTxHuZc&#39;, &#39;HcsNWPVtbcQ&#39;, &#39;QBlQYUxMMy0&#39;, &#39;5NW_mtCLPGk&#39;, &#39;dw4aVpZVUY0&#39;, &#39;6BMvzW_7cwg&#39;, &#39;jdi04wuTdyM&#39;, &#39;JYOmFRDobdQ&#39;, &#39;YqwWq7pTFTc&#39;, &#39;MWfy_Wa_Pw4&#39;, &#39;TuAdSfBqcZM&#39;, &#39;Xq74U7vyY9U&#39;, &#39;usXdw1VXJv4&#39;, &#39;M05UCd7MyjU&#39;, &#39;AeAPY9EpWl8&#39;, &#39;33U5sD_y4CM&#39;, &#39;Y9FwoL_Ec8U&#39;, &#39;cbW_MECwJaA&#39;, &#39;6Vmxy_xjG_0&#39;, &#39;UBcCWGzrk84&#39;, &#39;oiQlv5gWQ3M&#39;, &#39;oFbybConp3o&#39;, &#39;1lfs92cqQCU&#39;, &#39;ZQI6gp8NRwQ&#39;, &#39;eOdYZGU7gZE&#39;, &#39;l-G4p9OmM88&#39;, &#39;Vi2qf44WWOw&#39;, &#39;aeaYTs7BpIs&#39;, &#39;tqa7qJo_IOw&#39;, &#39;zkIICffvEb0&#39;, &#39;vaS30NelmOQ&#39;, &#39;FrqKYOCJB2o&#39;, &#39;F_yZh5ylilk&#39;, &#39;d_9oqMyOQYU&#39;, &#39;2vBOid_XI7c&#39;, &#39;EwlAOWMGHhk&#39;, &#39;I0F2FEvf7NQ&#39;, &#39;Co2FtbHfJyI&#39;, &#39;Jt4lMNO0awU&#39;, &#39;dVXr2HMvGDs&#39;, &#39;pODBAY8wLtI&#39;, &#39;qUBeTlFLRTs&#39;, &#39;O1yPrfdly_8&#39;, &#39;icBkFBzSL2Y&#39;, &#39;Fc61_W5mRv8&#39;, &#39;whw9yeqJRM8&#39;, &#39;BvxsYEPIqUs&#39;, &#39;KVC8MeIMOho&#39;, &#39;MadIzepvF54&#39;, &#39;069S4_2bpcQ&#39;, &#39;uz-eYa9nYxU&#39;, &#39;qchF4bE4c2I&#39;, &#39;Eo7X2zYYQfY&#39;, &#39;u8qMKrY_xR4&#39;, &#39;eRi_eLkOuqg&#39;, &#39;K9SK5Jbgghc&#39;, &#39;jrc98ml9raE&#39;, &#39;8V4HkgIL1hU&#39;, &#39;eR_s2QdvdVI&#39;, &#39;vucA517bBX4&#39;, &#39;wuXfhGA5HsE&#39;, &#39;Ok62QIuFEEE&#39;, &#39;gSb9EIpLt4k&#39;, &#39;BgT-OpKb42I&#39;, &#39;XVElEVZKgE8&#39;, &#39;9rvxGbvFnZ0&#39;, &#39;qFQWBMB5NaM&#39;, &#39;IeHxOb4ENaw&#39;, &#39;m8qS-SNPGBQ&#39;, &#39;sGUDVqLJJJY&#39;, &#39;taGUqz0wPVU&#39;, &#39;sHhfZgJ2IDg&#39;, &#39;OTm4x6A-Ly4&#39;, &#39;j-jZCcfT2Gs&#39;, &#39;NAeuV3quheI&#39;, &#39;RgR_1ivBlVY&#39;, &#39;wNLx1rTJWAQ&#39;, &#39;qM80mCa0Ep8&#39;, &#39;NnHrXgVhXPw&#39;, &#39;euNgPNTsUzc&#39;, &#39;hddEeI7y06A&#39;, &#39;wGHaLcVtgI8&#39;, &#39;-_1ZzfePCC4&#39;, &#39;hhowOXG47hc&#39;, &#39;JHnQK1Dhww0&#39;, &#39;iof4P5Noy7Q&#39;, &#39;AIUSbUOeU-I&#39;, &#39;2qCBtMVYo80&#39;, &#39;j1gPqlQaUiA&#39;, &#39;Z7BptF_8Iek&#39;, &#39;5T7BpU4_dGM&#39;, &#39;D3FTkHyxwNc&#39;, &#39;as8T2fD3gPE&#39;, &#39;aIAX1UXZaBA&#39;, &#39;nzSjUYmyuFA&#39;, &#39;hrN9EQyrkIk&#39;, &#39;BPue1t0Sb7o&#39;, &#39;v12uhdIbb9U&#39;, &#39;RrElbPusHjQ&#39;, &#39;3thjaV8yOnI&#39;, &#39;eydgXuWCMF4&#39;, &#39;_z9R9uSWeqI&#39;, &#39;Gq5fIJ1YuuU&#39;, &#39;fmrlF-4dPkk&#39;, &#39;CeJYqC72GCw&#39;, &#39;ItAZPb6lkpw&#39;, &#39;dz1Lc98C4Bo&#39;, &#39;72p2rqgJMyw&#39;, &#39;IuaMZgS_nFU&#39;, &#39;lkGSo0dEdrc&#39;, &#39;HzUFXjph-Cw&#39;, &#39;2WyfLH6XYAI&#39;, &#39;wrN8l2kAVfg&#39;, &#39;06sj0Fz5fxQ&#39;, &#39;lNy92TM5vMw&#39;, &#39;Rl2N-NDMieM&#39;, &#39;oMGmmX5LbW4&#39;, &#39;DyNjhA9Y7Ng&#39;, &#39;Zcpjo6V7Mc8&#39;, &#39;UMRYbVf52oQ&#39;, &#39;SFSREVDMWMI&#39;, &#39;YwgguuuBlWM&#39;, &#39;zFiFxoHAgTk&#39;, &#39;eQXGqtVYpwY&#39;, &#39;r45giI3pj8c&#39;, &#39;xiyOjgalwUY&#39;, &#39;aBwCh_PGeE4&#39;, &#39;Dxj9yfK76do&#39;, &#39;1qGsQWzBVPE&#39;, &#39;wyCG_-uSwiI&#39;, &#39;uRQ-a56YECE&#39;, &#39;fH67lpDRTFE&#39;, &#39;YYnklEAQcHM&#39;, &#39;UM40uEN2RWw&#39;, &#39;sLTY3EE5wJA&#39;, &#39;MS2Q_mAMrRI&#39;, &#39;kw7Qi7tYC0A&#39;, &#39;D5EWY8X1NSc&#39;, &#39;HTvvoL2WkpM&#39;, &#39;8t-h7b_XUTY&#39;, &#39;Zg5NxJzG9zY&#39;, &#39;pFRq0rM-pGU&#39;, &#39;BnFtHgDiHdk&#39;, &#39;5cnsfhxYRzY&#39;, &#39;zJh9ulEGpts&#39;, &#39;TY8aPYC0S0o&#39;, &#39;XMDz2g2-Hv8&#39;, &#39;utfUezAXRfk&#39;, &#39;VE3ci2LtunI&#39;, &#39;u4V7EAqWqhA&#39;, &#39;U6bXL6_wX74&#39;, &#39;TQefMvN0psc&#39;, &#39;uw7FBD0Z_BM&#39;, &#39;IlZaQ_7Wva4&#39;, &#39;kL1KMZWueLw&#39;, &#39;4aajXWM7Uu4&#39;, &#39;dX3yLyQrph4&#39;, &#39;A5qknrf0MF8&#39;, &#39;zU2uRGyDOgs&#39;, &#39;PR6PT2hi5Vc&#39;, &#39;UlGaIqVG9rM&#39;, &#39;u2VDtVTEdQo&#39;, &#39;MdK4fZRZHEE&#39;, &#39;mbIZj41CT8o&#39;, &#39;uaX3j3IjSo4&#39;, &#39;tZXFWFHzSLc&#39;, &#39;zgE6KIUskq8&#39;, &#39;K7Wbfqcx1Zo&#39;, &#39;uBTTEHt1m90&#39;, &#39;xMwGF_JBg_o&#39;, &#39;7X0M5ywpIX0&#39;, &#39;HHm-QeE20_E&#39;, &#39;U8f4EE2j5ak&#39;, &#39;XA6MQXGCkUE&#39;, &#39;7pe5SGXRaEc&#39;, &#39;9AptlKhcB8k&#39;, &#39;W8shUT2TQC8&#39;, &#39;Yw7AeyxnC_k&#39;, &#39;9wXrw4Ow8tc&#39;, &#39;BXiJXcoxfEc&#39;, &#39;AHjQC6a21s8&#39;, &#39;tmFIQVlTeDU&#39;, &#39;aFLw67Ru1hw&#39;, &#39;URAwZpxpDAw&#39;, &#39;d3cquS60HW0&#39;, &#39;TtJSv_iKJJw&#39;, &#39;7jZuodD_2D4&#39;, &#39;KFQLaBZoEIw&#39;, &#39;kFiagliVoIs&#39;, &#39;vNGPIrHmHPc&#39;, &#39;8MvyICliEZ4&#39;, &#39;TxISo-NKT4I&#39;, &#39;uh08FNimajY&#39;, &#39;Suli-ebCCy8&#39;, &#39;mKWLEDjkfiA&#39;, &#39;ueqlXyT5HVw&#39;, &#39;a5yvt9ngUrU&#39;, &#39;thHNUpj1gYQ&#39;, &#39;-ffLpRNIqK0&#39;, &#39;3A2-UB-T8iA&#39;, &#39;I53BODAEKg0&#39;, &#39;BtIf5F1fjlQ&#39;, &#39;fdMHvUkeQyQ&#39;, &#39;rOHDEHByG-k&#39;, &#39;a6Cfmf9Gp7M&#39;, &#39;dOJklyLVQDQ&#39;, &#39;KFJs8WEdvfo&#39;, &#39;0I0hPqBPScU&#39;, &#39;ChkulqIRcpw&#39;, &#39;xUzkkywFIuU&#39;, &#39;tLQW-Vvjmmo&#39;, &#39;2zbk_nFzFl0&#39;, &#39;l59TLJTi_PQ&#39;, &#39;0ZG55J1vg8s&#39;, &#39;gMB-iS6--uA&#39;, &#39;yHm9y9bwjf4&#39;, &#39;-xXWvGsDkhs&#39;, &#39;HjNQXXpvLa0&#39;, &#39;4M8le6nzfP4&#39;, &#39;nePqawiDQ5o&#39;, &#39;ijPx0opan-k&#39;, &#39;PZGZRnuoAxk&#39;, &#39;wnKXkArwDww&#39;, &#39;kM_CEz40m54&#39;, &#39;G4q22Vnisy0&#39;, &#39;MIPfMUR_U8Q&#39;, &#39;WMA0Vt15QQg&#39;, &#39;G5UseKKUW2A&#39;, &#39;MHNi-R83jac&#39;, &#39;2a5JZj5rlgY&#39;, &#39;aAi-fPpYmeA&#39;, &#39;QDaKSC45SCA&#39;, &#39;QLQGJ15jfpU&#39;, &#39;0I8NTCpVcMw&#39;, &#39;o-RSL_BJoHI&#39;, &#39;TDzgL8XFeJs&#39;, &#39;L8x0VNnLZpo&#39;, &#39;5sT4uVqL-Yo&#39;, &#39;C9YgJeNt5zs&#39;, &#39;ED5PpOJC6Ws&#39;, &#39;AzMIPBUzLvg&#39;, &#39;FpAmmPsIzMQ&#39;, &#39;m5HIvRJo_Xg&#39;, &#39;R3R6kyDDyh4&#39;, &#39;p5m56GVUyBg&#39;, &#39;MiXxNaW9wHs&#39;, &#39;HySnGLJgG6g&#39;, &#39;LIIg7PpAgI0&#39;, &#39;W9a6NASUulA&#39;, &#39;JRcVCZgA4F4&#39;, &#39;sx_LbHRPv1Q&#39;, &#39;kwfIBN0pu8o&#39;, &#39;olcTSGQvDNk&#39;, &#39;rezkrkV8Uv8&#39;, &#39;lsM2VYv2d_A&#39;, &#39;u28CPnlUsgA&#39;, &#39;Kvz2xeTHN50&#39;, &#39;YeNcvCrF_V4&#39;, &#39;mwNFSiKza00&#39;, &#39;wJjAaArYzJs&#39;, &#39;_aPZ9kc7pSE&#39;, &#39;c_0BcUmqM50&#39;, &#39;-7ZSBmL3YfM&#39;, &#39;EZ3586U0_ao&#39;, &#39;FFt3mV7S8oc&#39;, &#39;ycVs_ITfbdY&#39;, &#39;NLtij5qUcHA&#39;, &#39;pmsisULzYes&#39;, &#39;zgTk_4yuNco&#39;, &#39;79CzFXfFiF4&#39;, &#39;_x2WDQ0uc-w&#39;, &#39;R5fvJTl7nzE&#39;, &#39;SBuBGxzYXt8&#39;, &#39;CR2Jo4GFVOw&#39;, &#39;yhs3lMFgeLA&#39;, &#39;kZNFwX0yA1M&#39;, &#39;JmLRRc-Xz9Q&#39;, &#39;oph6i3_9MRw&#39;, &#39;5df3okXC3Gs&#39;, &#39;XhD4xqfrO0Y&#39;, &#39;Di4uTAoccaQ&#39;, &#39;fni2R8xDwdo&#39;, &#39;u-qF_G3Ntss&#39;, &#39;AzCcbhSCb0Y&#39;, &#39;H5GRVIRHeAY&#39;, &#39;_UYzHQek-T4&#39;, &#39;hHk6l4Rrsuk&#39;, &#39;Xv-2wxofozk&#39;, &#39;jUBIzYNYF9E&#39;, &#39;LtMCCLB_AB0&#39;, &#39;y1Y_BhuV5zc&#39;, &#39;Epk4xeJ3AIE&#39;, &#39;6Ru__nrF0Fk&#39;, &#39;m350f5BOslM&#39;, &#39;iH96d73pLMI&#39;, &#39;ZAlnj1i3SCs&#39;, &#39;jOYzvvNreX4&#39;, &#39;GRfUq1pZ6H8&#39;, &#39;sDRvasGmgEU&#39;, &#39;zp_Uentx3dY&#39;, &#39;3BwN5qd5p-U&#39;, &#39;6b12eiSMjHc&#39;, &#39;_XMeIpN5BRQ&#39;, &#39;5HE_6vP8XkM&#39;, &#39;E3estyoUfNs&#39;, &#39;GeO1ijPv2nE&#39;, &#39;pOLTb7BfnkE&#39;, &#39;1tWAES5ecH8&#39;, &#39;hhsBrmLP_hw&#39;, &#39;AwvU3Y5b6vQ&#39;, &#39;XB8JSDYi-Ic&#39;, &#39;P2OY7YSXE50&#39;, &#39;RBVu7y1e0mA&#39;, &#39;3grbAJM5i60&#39;, &#39;Cr_g4rszmn0&#39;, &#39;G2qU9tIQRcw&#39;, &#39;Z0QShQd4nKk&#39;, &#39;EjT6kZfFNgo&#39;, &#39;vvaMF3rmFEk&#39;, &#39;zsmG3oY2T08&#39;, &#39;5u5AyT6FHtY&#39;, &#39;RHoUrcdxKeA&#39;, &#39;cRDKjacWPck&#39;, &#39;139PY_5VCaY&#39;, &#39;pfleyFhCGtQ&#39;, &#39;eBrV-CPCJSs&#39;, &#39;zRtZknBuioU&#39;, &#39;eL5qJsAHg2c&#39;, &#39;l0gCaOituDU&#39;, &#39;0_AiNU7bh84&#39;, &#39;uruUQ38Sfaw&#39;, &#39;jOJDXu44KMc&#39;] .",
            "url": "https://jimregan.github.io/notes/kaggle/swedish/2021/09/21/check-riksantikvarieambetet-youtube-for-licence.html",
            "relUrl": "/kaggle/swedish/2021/09/21/check-riksantikvarieambetet-youtube-for-licence.html",
            "date": " â€¢ Sep 21, 2021"
        }
        
    
  
    
        ,"post86": {
            "title": "The New Statistics Why and How",
            "content": "The New Statistics: Why and How . @article{cumming2014newstatistics, author = {Geoff Cumming}, title ={The New Statistics: Why and How}, journal = {Psychological Science}, volume = {25}, number = {1}, pages = {7-29}, year = {2014}, doi = {10.1177/0956797613504966}, note ={PMID: 24220629} } . The problem: . Research Integrity . Published research is a biased selection of all research; | data analysis and reporting are often selective and biased; and | in many research fields, studies are rarely replicated, so false conclusions persist. | . a decision to report research [â€¦] must be independent of the results. . Agree, butâ€¦ . The best way to ensure this is to make a commitment to report research in advance of conducting it . Not sure I agree. . No matter how intriguing, however, the results of such pilot work rarely deserve even a brief mention in a report. . Strongly disagree. . PHONEME TRANSPOSITION AND TEMPORAL ENCODING IN HUMAN SPEECH RECOGNITION - example pre-registration that seems relevant to the lab. .",
            "url": "https://jimregan.github.io/notes/journal%20club/2021/09/20/journal-club.html",
            "relUrl": "/journal%20club/2021/09/20/journal-club.html",
            "date": " â€¢ Sep 20, 2021"
        }
        
    
  
    
        ,"post87": {
            "title": "Interesting links, 19/9/2021",
            "content": "German ASR: Fine-Tuning Wav2Vec2 . torchaudio.resample is faster than librosa.resample | disable group_by_length if thereâ€™s a long delay before training starts Made no difference to the outcome | . | . . ASR Systems as Models of Phonetic Category Perception in Adults . PHONEME TRANSPOSITION AND TEMPORAL ENCODING IN HUMAN SPEECH RECOGNITION . . 19th-Century Cockney and RP .",
            "url": "https://jimregan.github.io/notes/links/2021/09/19/misc-links.html",
            "relUrl": "/links/2021/09/19/misc-links.html",
            "date": " â€¢ Sep 19, 2021"
        }
        
    
  
    
        ,"post88": {
            "title": "Interesting links, 16/9/2021",
            "content": "A comparative acoustic analysis of purring in four cats . @inproceedings{Schotz539090, author = {Sch{ &quot;o}tz, Susanne and Eklund, Robert}, booktitle = {Proceedings from Fonetik 2011, Quarterly Progress and Status Report TMH-QPSR, Volume 51, 2011}, pages = {5--8}, publisher = {Universitetsservice}, title = {A comparative acoustic analysis of purring in four cats}, series = {Quarterly Progress and Status Report TMH-QPSR}, number = {51}, URL = {http://www.speech.kth.se/fonetik2011/}, year = {2011} } . spotify/pedalboard - library for adding effects to audio, supports VST3 and Audio Unit plugins. . Jam3/math-as-code - â€œa cheat-sheet for mathematical notation in code formâ€ . VOSK language model adaptation . Svito-zar/gesticulator: â€œGesticulator: A framework for semantically-aware speech-driven gesture generationâ€ . Remember the context! ASR slot error correction through memorization . Setup - ngrok . optuna/optuna: A hyperparameter optimization framework . dataqa/dataqa: Labelling platform for text using distant supervision . That XOR Trick . abhishekkrthakur/colabcode: Run VSCode (codeserver) on Google Colab or Kaggle Notebooks . tarun-bisht/wav2vec2-asr: wav2vec2 asr with transformers .",
            "url": "https://jimregan.github.io/notes/links/2021/09/16/misc-links.html",
            "relUrl": "/links/2021/09/16/misc-links.html",
            "date": " â€¢ Sep 16, 2021"
        }
        
    
  
    
        ,"post89": {
            "title": "XOR number guessing",
            "content": "def make_1ton_missing_number(n, to_remove): return [a for a in range(1, n + 1) if a != to_remove] . n = 12 l = make_1ton_missing_number(n, 8) . l . [1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12] . def get_missing_number(l1ton, n): res = 0 for val in range(1, n + 1): res ^= val for val in l1ton: res ^= val return res . get_missing_number(l, n) . 8 . 8 ^ 8 . 0 . 0 ^ 8 . 8 .",
            "url": "https://jimregan.github.io/notes/xor/misc/2021/09/15/xor-number-guessing.html",
            "relUrl": "/xor/misc/2021/09/15/xor-number-guessing.html",
            "date": " â€¢ Sep 15, 2021"
        }
        
    
  
    
        ,"post90": {
            "title": "Utterance XML to json",
            "content": "sample = &quot;&quot;&quot; &lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt; &lt;utterance input_string=&quot;&quot;&gt; &lt;sentence input_string=&quot;&quot;&gt; &lt;token input_string=&quot;SILENCE_TOKEN&quot;&gt; &lt;word input_string=&quot;SILENCE_TOKEN&quot; trans_source=&quot;src&quot; trans_output_format=&quot;final&quot;&gt; &lt;syllable &gt; &lt;phoneme symbol=&quot;sil&quot; end=&quot;1.19&quot;/&gt; &lt;/syllable&gt; &lt;/word&gt; &lt;/token&gt; &lt;/sentence&gt; &lt;/utterance&gt; &quot;&quot;&quot; . import xml.etree.ElementTree as ET . class Utterance: def __init__(self, input, sentences): self.input = input self.sentences = sentences . class Sentence: def __init__(self, input, tokens): self.input = input self.tokens = tokens . class Token: def __init__(self, input, words): self.input = input self.words = words . class Word: def __init__(self, input, source, syllables): self.input = input self.source = source self.syllables = syllables if self.syllables is None: self.syllables = [] def get_phonemes(self): return &quot; &quot;.join([a.get_phonemes() for a in self.syllables]) def get_clean_word(self): word = self.input if word[0:1] in &quot;nt&quot; and word[1:2] in &quot;AÃEÃ‰IÃOÃ“UÃš&quot;: return word[0:1] + &quot;-&quot; + word[1:].lower() else: return word.lower() . class Syllable: def __init__(self, stress: int = 0, phonemes = None): self.stress = stress self.phonemes = phonemes if self.phonemes is None: self.phonemes = [] def get_phonemes(self): return &quot; &quot;.join([a.symbol for a in self.phonemes]) . class Phoneme: def __init__(self, symbol: str = &quot;&quot;, end: float = 0.0): self.symbol = symbol self.end = end . import io sio = io.StringIO(sample.strip()) . def from_xml(source): tree = ET.parse(source) root = tree.getroot() if &#39;input_string&#39; in root.attrib: input = root.attrib[&#39;input_string&#39;] else: input = &#39;&#39; sentences = [] for sentence in root.findall(&#39;./sentence&#39;): if &#39;input_string&#39; in sentence.attrib: input = sentence.attrib[&#39;input_string&#39;] else: input = &#39;&#39; tokens = [] for token in sentence.findall(&#39;./token&#39;): if &#39;input_string&#39; in token.attrib: input = token.attrib[&#39;input_string&#39;] else: input = &#39;&#39; words = [] for word in token.findall(&#39;./word&#39;): if &#39;input_string&#39; in word.attrib: input = word.attrib[&#39;input_string&#39;] else: input = &quot;&quot; if &#39;trans_source&#39; in word.attrib: source = word.attrib[&#39;trans_source&#39;] else: source = &quot;&quot; syllables = [] for syllable in word.findall(&#39;./syllable&#39;): phonemes = [] if &#39;stress&#39; in syllable.attrib: if syllable.attrib[&#39;stress&#39;] == &#39;None&#39;: stress = 0 else: stress = int(syllable.attrib[&#39;stress&#39;]) else: stress = 0 for phoneme in syllable.findall(&#39;./phoneme&#39;): if &#39;symbol&#39; in phoneme.attrib: symbol = phoneme.attrib[&#39;symbol&#39;] else: symbol = &#39;&#39; if &#39;end&#39; in phoneme.attrib: end = float(phoneme.attrib[&#39;end&#39;]) else: symbol = 0.0 phonemes.append(Phoneme(symbol, end)) syllables.append(Syllable(stress, phonemes)) words.append(Word(input, source, syllables)) tokens.append(Token(input, words)) sentences.append(Sentence(input, tokens)) return Utterance(input, sentences) . utt = from_xml(sio) . import json json.dumps(utt, default=lambda o: o.__dict__) . &#39;{&#34;input&#34;: &#34;SILENCE_TOKEN&#34;, &#34;sentences&#34;: [{&#34;input&#34;: &#34;SILENCE_TOKEN&#34;, &#34;tokens&#34;: [{&#34;input&#34;: &#34;SILENCE_TOKEN&#34;, &#34;words&#34;: [{&#34;input&#34;: &#34;SILENCE_TOKEN&#34;, &#34;source&#34;: &#34;src&#34;, &#34;syllables&#34;: [{&#34;stress&#34;: 0, &#34;phonemes&#34;: [{&#34;symbol&#34;: &#34;sil&#34;, &#34;end&#34;: 1.19}]}]}]}]}]}&#39; . for sent in utt.sentences: for tok in sent.tokens: for word in tok.words: print(f&#39;{word.get_clean_word()} {word.get_phonemes()}&#39;) . silence_token sil .",
            "url": "https://jimregan.github.io/notes/irish/abair/mfa/2021/09/15/utterance-xml-to-mfa.html",
            "relUrl": "/irish/abair/mfa/2021/09/15/utterance-xml-to-mfa.html",
            "date": " â€¢ Sep 15, 2021"
        }
        
    
  
    
        ,"post91": {
            "title": "Interesting links, roughly 15/9/2021",
            "content": "H5P â€“ used for learning materials on TG4 and Tuairisc . Commits on transformers: Add SpeechEncoderDecoder &amp; Speech2Text2, Add the AudioClassificationPipeline, Add Wav2Vec2 &amp; Hubert ForSequenceClassification (based on converting s3rpl checkpoints) . monologg/JointBERT â€“ (Unofficial) Pytorch implementation of JointBERT: BERT for Joint Intent Classification and Slot Filling . deezer/spleeter â€“ Deezer source separation library including pretrained models. . VoxLingua107: a Dataset for Spoken Language Recognition â€“ no Irish . Appen/UHV-OTS-Speech â€“ A data annotation pipeline to generate high-quality, large-scale speech datasets with machine pre-labeling and fully manual auditing. Paper . The Effects of Automatic Speech Recognition Quality on Human Transcription Latency . @inproceedings{gaur16latency, author = {Yashesh Gaur and Walter S. Lasecki and Florian Metze and Jeffrey P. Bigham}, editor = {Gregory R. Gay and Tiago Jo{ ~{a}}o Guerreiro}, title = , booktitle = {Proceedings of the 13th Web for All Conference, {W4A} &#39;16, Montreal, Canada, April 11-13, 2016}, pages = {23:1--23:8}, publisher = , year = {2016}, doi = {10.1145/2899475.2899478}, } . BirgerMoell/tmh . as-ideas/DeepPhonemizer See: Transformer based Grapheme-to-Phoneme Conversion . Unifying Speech and Gesture Synthesis . Locals create CD-ROM celebrating Gaeltacht area of Dun Chaochain . Facebookâ€™s latest: Textless NLP: Generating expressive speech from raw audio Demo Code, Generative Spoken Language Modeling from Raw Audio, Speech Resynthesis from Discrete Disentangled Self-Supervised Representations, Text-Free Prosody-Aware Generative Spoken Language Modeling . AIdeaLab/wav2vec2_docker â€“ pretraining wav2vec docker for sagemaker . as-ideas/DeepForcedAligner . citizensinformation.ie mojibake . kingabzpro/fine-tuning-xlsr-wav2vec2-for-wolof-asr-with . ceyda/wav2vec2-base-760 â€“ Turkish wav2vec2 base model . Excessive GPU-GPU communication with GPT2 making multi-GPU training slow? . Vosk LM . Svito-zar/gesticulator . run_cleanup_segmentation.sh from malach, based on AMI, in turn based on Tedlium . Numbers . Classroom materials .",
            "url": "https://jimregan.github.io/notes/links/2021/09/15/misc-links.html",
            "relUrl": "/links/2021/09/15/misc-links.html",
            "date": " â€¢ Sep 15, 2021"
        }
        
    
  
    
        ,"post92": {
            "title": "T5G2P -- Using Text-to-Text Transfer Transformer for Grapheme-to-Phoneme Conversion",
            "content": "T5G2P: Using Text-to-Text Transfer Transformer for Grapheme-to-Phoneme Conversion . @inproceedings{rezackova21_interspeech, author={MarkÃ©ta Å˜ezÃ¡ÄkovÃ¡ and Jan Å vec and Daniel Tihelka}, title=, year=2021, booktitle={Proc. Interspeech 2021}, pages={6--10}, doi={10.21437/Interspeech.2021-546} } . Phonological Corpus of Czech â€“ seems similar enough to the described corpus for Czech. .",
            "url": "https://jimregan.github.io/notes/journal%20club/2021/09/13/journal-club.html",
            "relUrl": "/journal%20club/2021/09/13/journal-club.html",
            "date": " â€¢ Sep 13, 2021"
        }
        
    
  
    
        ,"post93": {
            "title": "CoNLL 2017 Irish data",
            "content": "CoNLL 2017 Shared Task - Automatically Annotated Raw Texts and Word Embeddings . There was a web page with raw text; the Irish data has some stuff that looks weird. There are items that look like they were poorly split, but there are items from Logos Poetry like this: . 41] NÃ¡ trÃ©ig neamh ar nÃ­ nach lat; . where the line numbering and brace were intentional. Not that there arenâ€™t odd splits because of poor sentence splitting. The sentence at line 4467 of ga-common_crawl-000.conllu.xz is: . do giallaibh) .i. tech lÃ¡n do ghiallaibh aigi. . which comes from here: . NÃ³ Eochaid DomplÃ©n .i. domus (.i. tech) plena (.i. do giallaibh) .i. tech lÃ¡n do ghiallaibh aigi. Is de rohainmniged Eochaid DomplÃ©n de. . (i.e., itâ€™s not even modern Irish). .",
            "url": "https://jimregan.github.io/notes/irish/2021/09/13/conll-2017.html",
            "relUrl": "/irish/2021/09/13/conll-2017.html",
            "date": " â€¢ Sep 13, 2021"
        }
        
    
  
    
        ,"post94": {
            "title": "Read a .wav file with Vosk API",
            "content": "import vosk import wave . from vosk import Model, KaldiRecognizer, SetLogLevel model = Model(&quot;model&quot;) rec = KaldiRecognizer(model, 16000) rec.SetWords(True) . wave_file = WAV_FILE . wf = wave.open(wave_file) . while True: data = wf.readframes(4000) if len(data) == 0: break if rec.AcceptWaveform(data): print(rec.Result()) else: print(rec.PartialResult()) rec.Result() .",
            "url": "https://jimregan.github.io/notes/vosk/2021/09/10/vosk-wav.html",
            "relUrl": "/vosk/2021/09/10/vosk-wav.html",
            "date": " â€¢ Sep 10, 2021"
        }
        
    
  
    
        ,"post95": {
            "title": "TG4 Foghlaim scraper pieces",
            "content": "import requests from bs4 import BeautifulSoup . landing = &quot;https://www.tg4.ie/ga/brandai-eile/foghlaim/ceachtanna/&quot; . landing_page = requests.get(landing) assert landing_page.status_code == 200 . soup = BeautifulSoup(landing_page.text, &quot;lxml&quot;) . lessons = [] for lesson_item in soup.find_all(&quot;a&quot;, {&quot;class&quot;: &quot;prog-panel&quot;}): lessons.append(lesson_item.get(&quot;href&quot;)) . def _reamhobair_text(url): out = [] page = requests.get(url) assert page.status_code == 200 soup = BeautifulSoup(page.text, &quot;lxml&quot;) for part in soup.find(&quot;div&quot;, {&quot;class&quot;: &quot;arconix-toggle-content&quot;}): #out.append(part.text) print(part) return out . _reamhobair_text(&quot;https://www.tg4.ie/ga/brandai-eile/foghlaim/ceachtanna/an-scoil/reamhobair/&quot;) . def _reamhobair_questions(url): import json out = [] page = requests.get(url) assert page.status_code == 200 soup = BeautifulSoup(page.text, &quot;lxml&quot;) for script_tag in soup.find_all(&quot;script&quot;): if script_tag.text.startswith(&quot;H5PIntegration=&quot;): if script_tag.text.endswith(&quot;;&quot;): json_inner = json.loads(script_tag.text[15:-1]) else: json_inner = json.loads(script_tag.text[15:]) if &quot;contents&quot; in json_inner: for k in json_inner[&quot;contents&quot;].keys(): if &quot;library&quot; in json_inner[&quot;contents&quot;][k].keys(): if &quot;jsonContent&quot; in json_inner[&quot;contents&quot;][k].keys(): jsc = json_inner[&quot;contents&quot;][k][&quot;jsonContent&quot;] if type(jsc) == str and &quot;questions&quot; in jsc: jsc_l = json.loads(jsc) out.append((k, json_inner[&quot;contents&quot;][k][&quot;library&quot;], jsc_l[&quot;questions&quot;])) else: continue return out _reamhobair_questions(&quot;https://www.tg4.ie/ga/brandai-eile/foghlaim/ceachtanna/an-scoil/reamhobair/&quot;) . _reamhobair_questions(&quot;https://www.tg4.ie/ga/brandai-eile/foghlaim/ceachtanna/ras-na-bpointi/mir-a-haon/&quot;) .",
            "url": "https://jimregan.github.io/notes/irish/scraper/tg4/incomplete/2021/09/07/tg4-foghlaim-scraper.html",
            "relUrl": "/irish/scraper/tg4/incomplete/2021/09/07/tg4-foghlaim-scraper.html",
            "date": " â€¢ Sep 7, 2021"
        }
        
    
  
    
        ,"post96": {
            "title": "Interesting links, 6/9/2021",
            "content": "Kungbib/swedish-bert-models. Paper: Playing with Words at the National Library of Sweden â€“ Making a Swedish BERT Huggingface: KBLab . NST Swedish Dictation (22 kHz) . SCRIBE - Spoken Corpus of British English . The available audio recordings and annotations were released on eleven CD-ROMs (labelled SCRIBE_0 to SCRIBE_11) in April . These were originally distributed by the Speech Group at the National Physical Laboratory, but after this was closed down the disks were passed to the MOD Speech Research Unit at Malvern which passed the disks on to a private contractor (who kept them in his garage). | google/cld3 . google-research/text-to-text-transfer-transformer . superb benchmark models . . Scraping notes: . GaelchultÃºr eolaire . Cogg: Ãiseanna TacaÃ­ochta don Oideachas Speisialta, Bain SÃºp As, Leabhair Dhigiteacha . TG4: an-scoil/reamhobair, cursai-idirnaisiunta/reamhobair/, fadhbanna/reamhobair/, cursai-timpeallachta, cursai-airgid/mir-a-do, ponc/ponc-reamhobair . FÃ­s agus Foghlaim . Comhar . CoiscÃ©im . Club Leabhar: PODCHRAOLTAÃ LÃ‰IRMHEASTÃ“IREACHTA AR LEABHAIR NA MÃOSA, AGALLAIMH ATÃ DÃ‰ANTA AGAINN LE HÃšDAIR AGUS LE CRITICEOIRÃ LITEARTHA, Tintin mar charachtar an scÃ©il .",
            "url": "https://jimregan.github.io/notes/links/scraping/2021/09/06/misc-links.html",
            "relUrl": "/links/scraping/2021/09/06/misc-links.html",
            "date": " â€¢ Sep 6, 2021"
        }
        
    
  
    
        ,"post97": {
            "title": "The processing of rhythmic structures in music and prosody by children with developmental dyslexia and developmental language disorder",
            "content": "The processing of rhythmic structures in music and prosody by children with developmental dyslexia and developmental language disorder . @article{caccia2021process, author = {Caccia, Martina and Lorusso, Maria Luisa}, title = {The processing of rhythmic structures in music and prosody by children with developmental dyslexia and developmental language disorder}, journal = {Developmental Science}, volume = {24}, number = {1}, pages = {e12981}, doi = {https://doi.org/10.1111/desc.12981}, year = {2021} } .",
            "url": "https://jimregan.github.io/notes/journal%20club/2021/09/06/journal-club.html",
            "relUrl": "/journal%20club/2021/09/06/journal-club.html",
            "date": " â€¢ Sep 6, 2021"
        }
        
    
  
    
        ,"post98": {
            "title": "Playing .wav files",
            "content": "from pathlib import Path import wave ncb_path = Path(&quot;/media/storage/phonetics/corpas_ncb/corpas_full_split_210415/&quot;) . files = [] for wf in ncb_path.glob(&quot;*.wav&quot;): cur = {} cur[&quot;id&quot;] = wf.stem wav = wave.open(str(wf)) fr = wav.getframerate() cur[&quot;framerate&quot;] = fr cur[&quot;duration&quot;] = wav.getnframes() / fr files.append(cur) . import json with open(&quot;out.json&quot;, &quot;w&quot;) as outf: json.dump(files, outf) .",
            "url": "https://jimregan.github.io/notes/test/2021/09/05/wav-playing.html",
            "relUrl": "/test/2021/09/05/wav-playing.html",
            "date": " â€¢ Sep 5, 2021"
        }
        
    
  
    
        ,"post99": {
            "title": "Playing with pyannote.audio 2",
            "content": "%%capture !pip install condacolab . Requirement already satisfied: condacolab in /usr/local/lib/python3.7/dist-packages (0.1.3) . import condacolab condacolab.install() . â¬ Downloading https://github.com/jaimergp/miniforge/releases/latest/download/Mambaforge-colab-Linux-x86_64.sh... ðŸ“¦ Installing... ðŸ“Œ Adjusting configuration... ðŸ©¹ Patching environment... â² Done in 0:00:39 ðŸ” Restarting kernel... . !conda create -n pyannote python=3.8.5 !conda activate pyannote !conda install numpy cffi !conda install libsndfile=1.0.28 -c conda-forge !pip install https://github.com/pyannote/pyannote-audio/archive/develop.zip . %%capture !wget https://podcast.rasset.ie/podcasts/audio/2021/0626/20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.mp3 . %%capture !ffmpeg -i /content/20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.mp3 -acodec pcm_s16le -ac 1 -ar 16000 /content/20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.wav . from pyannote.audio.pipelines import VoiceActivityDetection pipeline = VoiceActivityDetection(segmentation=&quot;pyannote/segmentation&quot;) HYPER_PARAMETERS = { # onset/offset activation thresholds &quot;onset&quot;: 0.5, &quot;offset&quot;: 0.5, # remove speech regions shorter than that many seconds. &quot;min_duration_on&quot;: 0.0, # fill non-speech regions shorter than that many seconds. &quot;min_duration_off&quot;: 0.0 } pipeline.instantiate(HYPER_PARAMETERS) vad = pipeline(&quot;/content/20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.wav&quot;) . ImportError Traceback (most recent call last) &lt;ipython-input-5-e82545d3d9d2&gt; in &lt;module&gt;() -&gt; 1 from pyannote.audio.pipelines import VoiceActivityDetection 2 pipeline = VoiceActivityDetection(segmentation=&#34;pyannote/segmentation&#34;) 3 HYPER_PARAMETERS = { 4 # onset/offset activation thresholds 5 &#34;onset&#34;: 0.5, &#34;offset&#34;: 0.5, /usr/local/lib/python3.7/site-packages/pyannote/audio/__init__.py in &lt;module&gt;() 27 28 &gt; 29 from .core.inference import Inference 30 from .core.io import Audio 31 from .core.model import Model /usr/local/lib/python3.7/site-packages/pyannote/audio/core/inference.py in &lt;module&gt;() 28 import torch 29 from einops import rearrange &gt; 30 from pytorch_lightning.utilities.memory import is_oom_error 31 32 from pyannote.audio.core.io import AudioFile /usr/local/lib/python3.7/site-packages/pytorch_lightning/__init__.py in &lt;module&gt;() 18 _PROJECT_ROOT = os.path.dirname(_PACKAGE_ROOT) 19 &gt; 20 from pytorch_lightning import metrics # noqa: E402 21 from pytorch_lightning.callbacks import Callback # noqa: E402 22 from pytorch_lightning.core import LightningDataModule, LightningModule # noqa: E402 /usr/local/lib/python3.7/site-packages/pytorch_lightning/metrics/__init__.py in &lt;module&gt;() 13 # limitations under the License. 14 &gt; 15 from pytorch_lightning.metrics.classification import ( # noqa: F401 16 Accuracy, 17 AUC, /usr/local/lib/python3.7/site-packages/pytorch_lightning/metrics/classification/__init__.py in &lt;module&gt;() 12 # See the License for the specific language governing permissions and 13 # limitations under the License. &gt; 14 from pytorch_lightning.metrics.classification.accuracy import Accuracy # noqa: F401 15 from pytorch_lightning.metrics.classification.auc import AUC # noqa: F401 16 from pytorch_lightning.metrics.classification.auroc import AUROC # noqa: F401 /usr/local/lib/python3.7/site-packages/pytorch_lightning/metrics/classification/accuracy.py in &lt;module&gt;() 16 from torchmetrics import Accuracy as _Accuracy 17 &gt; 18 from pytorch_lightning.metrics.utils import deprecated_metrics, void 19 20 /usr/local/lib/python3.7/site-packages/pytorch_lightning/metrics/utils.py in &lt;module&gt;() 27 from torchmetrics.utilities.distributed import reduce as _reduce 28 &gt; 29 from pytorch_lightning.utilities import rank_zero_deprecation 30 from pytorch_lightning.utilities.imports import _TORCHMETRICS_GREATER_EQUAL_0_3, _TORCHMETRICS_LOWER_THAN_0_3 31 /usr/local/lib/python3.7/site-packages/pytorch_lightning/utilities/__init__.py in &lt;module&gt;() 16 import numpy 17 &gt; 18 from pytorch_lightning.utilities.apply_func import move_data_to_device # noqa: F401 19 from pytorch_lightning.utilities.distributed import AllGatherGrad, rank_zero_info, rank_zero_only # noqa: F401 20 from pytorch_lightning.utilities.enums import ( # noqa: F401 /usr/local/lib/python3.7/site-packages/pytorch_lightning/utilities/apply_func.py in &lt;module&gt;() 28 29 if _TORCHTEXT_AVAILABLE: &gt; 30 if _compare_version(&#34;torchtext&#34;, operator.ge, &#34;0.9.0&#34;): 31 from torchtext.legacy.data import Batch 32 else: /usr/local/lib/python3.7/site-packages/pytorch_lightning/utilities/imports.py in _compare_version(package, op, version) 52 &#34;&#34;&#34; 53 try: &gt; 54 pkg = importlib.import_module(package) 55 except (ModuleNotFoundError, DistributionNotFound): 56 return False /usr/lib/python3.7/importlib/__init__.py in import_module(name, package) 125 break 126 level += 1 --&gt; 127 return _bootstrap._gcd_import(name[level:], package, level) 128 129 /usr/local/lib/python3.7/dist-packages/torchtext/__init__.py in &lt;module&gt;() 3 from . import datasets 4 from . import utils -&gt; 5 from . import vocab 6 from . import legacy 7 /usr/local/lib/python3.7/dist-packages/torchtext/vocab.py in &lt;module&gt;() 11 from typing import Dict, List, Optional, Iterable 12 from collections import Counter, OrderedDict &gt; 13 from torchtext._torchtext import ( 14 Vocab as VocabPybind, 15 ) ImportError: /usr/local/lib/python3.7/dist-packages/torchtext/_torchtext.so: undefined symbol: _ZN2at6detail10noopDeleteEPv NOTE: If your import is failing due to a missing package, you can manually install dependencies using either !pip or !apt. To view examples of installing some common dependencies, click the &#34;Open Examples&#34; button below. .",
            "url": "https://jimregan.github.io/notes/diarisation/pyannote/2021/09/05/playing-with-pyannote-audio2.html",
            "relUrl": "/diarisation/pyannote/2021/09/05/playing-with-pyannote-audio2.html",
            "date": " â€¢ Sep 5, 2021"
        }
        
    
  
    
        ,"post100": {
            "title": "Playing with inaSpeechSegmenter",
            "content": "%%capture !pip install inaSpeechSegmenter . from inaSpeechSegmenter import Segmenter . %%capture !wget https://podcast.rasset.ie/podcasts/audio/2021/0626/20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.mp3 . seg = Segmenter() . segmentation = seg(&#39;20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.mp3&#39;) . /usr/local/lib/python3.7/dist-packages/pyannote/algorithms/utils/viterbi.py:88: FutureWarning: arrays to stack must be passed as a &#34;sequence&#34; type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future. for e, c in six.moves.zip(emission.T, consecutive) /usr/local/lib/python3.7/dist-packages/pyannote/algorithms/utils/viterbi.py:97: FutureWarning: arrays to stack must be passed as a &#34;sequence&#34; type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future. for e, c in six.moves.zip(constraint.T, consecutive) . segmentation[0:6] . [(&#39;noEnergy&#39;, 0.0, 0.88), (&#39;music&#39;, 0.88, 4.72), (&#39;female&#39;, 4.72, 6.82), (&#39;male&#39;, 6.82, 11.34), (&#39;music&#39;, 11.34, 15.38), (&#39;male&#39;, 15.38, 26.68)] . !pip install pydub . Collecting pydub Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB) Installing collected packages: pydub Successfully installed pydub-0.25.1 . from pydub import AudioSegment audio = AudioSegment.from_mp3(&#39;20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.mp3&#39;) . clip1 = audio[int(0.88 * 1000):int(4.72 * 1000)] . clip1.export(&quot;clip1.ogg&quot;, format=&quot;ogg&quot;) . &lt;_io.BufferedRandom name=&#39;clip1.ogg&#39;&gt; . import IPython IPython.display.Audio(&quot;clip1.ogg&quot;) . clip2 = audio[int(4.72 * 1000):int(11.34 * 1000)] clip2.export(&quot;clip2.ogg&quot;, format=&quot;ogg&quot;) IPython.display.Audio(&quot;clip2.ogg&quot;) . clip3 = audio[int(981.08 * 1000):int(992.74 * 1000)] clip3.export(&quot;clip3.ogg&quot;, format=&quot;ogg&quot;) IPython.display.Audio(&quot;clip3.ogg&quot;) .",
            "url": "https://jimregan.github.io/notes/inaspeechsegmenter/segmentation/2021/09/05/playing-with-inaspeechsegmenter.html",
            "relUrl": "/inaspeechsegmenter/segmentation/2021/09/05/playing-with-inaspeechsegmenter.html",
            "date": " â€¢ Sep 5, 2021"
        }
        
    
  
    
        ,"post101": {
            "title": "Playing with Asteroid",
            "content": "%%capture !pip install -U asteroid . %%capture !wget https://podcast.rasset.ie/podcasts/audio/2021/0626/20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.mp3 . %%capture !ffmpeg -i /content/20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.mp3 -acodec pcm_s16le -ac 1 -ar 16000 /content/20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.wav . !asteroid-infer &quot;mpariente/ConvTasNet_WHAM!_sepclean&quot; --files /content/20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.wav --resample --ola-window 8000 --ola-hop 4000 . 100% 19.3M/19.3M [00:03&lt;00:00, 5.35MB/s] .",
            "url": "https://jimregan.github.io/notes/asteroid/separation/2021/09/05/playing-with-asteroid.html",
            "relUrl": "/asteroid/separation/2021/09/05/playing-with-asteroid.html",
            "date": " â€¢ Sep 5, 2021"
        }
        
    
  
    
        ,"post102": {
            "title": "NÃ³s scraper pieces",
            "content": "sample = &#39;http://nos.ie/cultur/scannain/fisean-out-of-innocence-agallamh-le-heoin-o-dubhghaill/&#39; . import requests from bs4 import BeautifulSoup . page = requests.get(sample) . soup = BeautifulSoup(page.text, &#39;lxml&#39;) . vid = soup.find(&#39;div&#39;, {&#39;id&#39;, &#39;video-wrapper&#39;}) . _get_video(soup) . &#39;https://www.youtube.com/embed/lXr1QZPY7aY&#39; . def _get_video(soup): vid = soup.find(&#39;div&#39;, {&#39;id&#39;: &#39;video-wrapper&#39;}) if vid: iframe = vid.find(&#39;iframe&#39;) if iframe: return iframe.get(&#39;src&#39;, &#39;&#39;) return &#39;&#39; . def _get_details(soup): details = {} pubdet = soup.find(&quot;div&quot;, {&quot;id&quot;: &quot;single-publish-details&quot;}) ptags = [p for p in pubdet.find_all(&#39;p&#39;)] if ptags[0].b: details[&#39;author&#39;] = ptags[0].b.get_text(strip=True) if ptags[1]: details[&#39;date&#39;] = ptags[1].get_text(strip=True) broll = pubdet.find(&quot;div&quot;, {&quot;class&quot;: &quot;blogroll-tag-category&quot;}) cats = set() for cat in broll.find_all(&quot;a&quot;, {&quot;class&quot;: &quot;featured-category&quot;}): if cat.get_text(strip=True) != &quot;&quot;: cats.add(cat.get_text(strip=True)) if len(cats) &gt; 0: details[&#39;categories&#39;] = list(cats) tags = set() for tag in broll.find_all(&quot;a&quot;, {&quot;class&quot;: &quot;featured-tag&quot;}): if tag.get_text(strip=True) != &quot;&quot;: tags.add(tag.get_text(strip=True)) if len(tags) &gt; 0: details[&#39;tags&#39;] = list(tags) return details . _get_subhead(soup) . &#39;&#39; . def _get_subhead(soup): out = [] content = soup.find(&quot;div&quot;, {&quot;id&quot;: &quot;single-area-center&quot;}) if content.h1 and content.h1.span: return content.h1.span.get_text(strip=True) else: return &#39;&#39; . def _mksoup(url): page = requests.get(url) soup = BeautifulSoup(page.text, &#39;lxml&#39;) return soup . def _read_menu(): page = requests.get(&quot;http://nos.ie/&quot;) soup = BeautifulSoup(page.text, &#39;lxml&#39;) menu = soup.find(&quot;ul&quot;, {&quot;id&quot;: &quot;menu-main-menu&quot;}) cat_pages = set() for li in menu.find_all(&quot;li&quot;): if li.a: cat_pages.add(li.a[&#39;href&#39;]) return cat_pages . links = _read_menu() . a = _get_article_list(links) . len(a) . 296 . def _get_article_list(urls): rest = set() articles = set() for url in urls: page = requests.get(url) soup = BeautifulSoup(page.text, &#39;lxml&#39;) new = _get_remainder(soup) rest = rest.union(new) art = _collect_articles(soup) articles = articles.union(art) for url in rest: page = requests.get(url) soup = BeautifulSoup(page.text, &#39;lxml&#39;) art = _collect_articles(soup) articles = articles.union(art) return list(articles) . def _get_remainder(soup): import re pagination = soup.find(&quot;div&quot;, {&quot;class&quot;: &quot;pagination&quot;}) if not pagination: return [] current = pagination.find(&quot;span&quot;, {&quot;class&quot;: &quot;current&quot;}) if not (current and current.get_text(strip=True) == &quot;1&quot;): return [] cats = [a for a in pagination.find_all(&#39;a&#39;)] last_cat = cats[-1] last_url = last_cat.get(&#39;href&#39;, &#39;&#39;) if not last_url: return [] print(last_url) m = re.match(&quot;(.*/)([0-9]+)/$&quot;, last_url) if not m: return [] base = m.group(1) num = int(m.group(2)) + 1 return [f&#39;{base}{i}/&#39; for i in range(2, num)] . def _collect_articles(soup): out = set() for art in soup.find_all(&quot;article&quot;, {&quot;class&quot;: &quot;blogroll-post&quot;}): a = art.find(&#39;a&#39;) out.add(a.get(&#39;href&#39;)) return list(out) . top = _read_menu() . page = requests.get(&quot;http://nos.ie/category/cultur/ceol/&quot;) soup = BeautifulSoup(page.text, &#39;lxml&#39;) _collect_articles(soup) . arts = _get_article_list(top) .",
            "url": "https://jimregan.github.io/notes/irish/scraper/nos/2021/09/04/nos-scraper-pieces.html",
            "relUrl": "/irish/scraper/nos/2021/09/04/nos-scraper-pieces.html",
            "date": " â€¢ Sep 4, 2021"
        }
        
    
  
    
        ,"post103": {
            "title": "Interesting links, 3/9/2021",
            "content": "2dot71mily/youtube_captions_corrections: dataset here . facebookresearch/detr: End-to-End Object Detection with Transformers . timmahrt/praatIO: A python library for working with praat, textgrids, time aligned audio transcripts, and audio files. It is primarily used for extracting features from and making manipulations on audio files given hierarchical time-aligned transcriptions (utterance &gt; word &gt; syllable &gt; phone, etc). . nypl-openaudio/transcript-editor: Web-based tool for correcting speech-to-text generated transcripts. Runs Together We Listen . WGBH-MLA/transcript-editor: Web-based tool for correcting speech-to-text generated transcripts. . CNN Explainer . https://github.com/m3hrdadfi/soxan: Wav2Vec for speech recognition, classification, and audio classification . Irish relative clause . Indirect vs Direct Relative Clause â€“ Irish for English Speakers/Gaeilge do BhÃ©arlÃ³irÃ­ . Notes on Nolan (the Relative Clause) . Irish Gaelic dialects .",
            "url": "https://jimregan.github.io/notes/links/2021/09/03/misc-links.html",
            "relUrl": "/links/2021/09/03/misc-links.html",
            "date": " â€¢ Sep 3, 2021"
        }
        
    
  
    
        ,"post104": {
            "title": "Scraper pieces for beo.ie",
            "content": "sample_url = &#39;http://beo.ie/alt-an-eaglais-fein-a-bheas-thios-leis-ma-chuirtear-ba.aspx&#39; . import requests from bs4 import BeautifulSoup . page = requests.get(sample_url) . soup = BeautifulSoup(page.text, &#39;html.parser&#39;) . def _get_translations(soup): out = [] for gloss in soup.find_all(&#39;span&#39;, {&#39;class&#39;: &#39;gloss&#39;}): if gloss.get(&#39;title&#39;) != None and gloss.text: out.append({&#39;en&#39;: gloss.get(&#39;title&#39;), &#39;ga&#39;: gloss.text}) return out . def _get_captioned_images(soup): out = [] for pic in soup.find_all(&#39;div&#39;, {&#39;class&#39;: &#39;pic&#39;}): title = pic.find(&#39;div&#39;, {&#39;class&#39;: &#39;title&#39;}) if title: imgtag = pic.find(&#39;img&#39;) out.append({&#39;image&#39;: f&quot;http://beo.ie/{imgtag.get(&#39;src&#39;)}&quot;, &#39;caption&#39;: title.text}) return out . def _get_title(soup): title = soup.find(&#39;title&#39;).text if title and title.startswith(&#39;Beo! - &#39;): return(title[7:]) else: return None . def _get_blurb(soup): return soup.find(&#39;div&#39;, {&#39;class&#39;, &#39;blurb&#39;}).text.strip() . def _get_author(soup): dauth = soup.find(&#39;div&#39;, {&#39;class&#39;: &#39;author&#39;}) return dauth.find(&#39;span&#39;, {&#39;class&#39;: &#39;smallscreenInline&#39;}).text.strip() . def _get_paragraphs(soup): out = [] content = soup.find(&#39;div&#39;, {&#39;class&#39;: &#39;content&#39;}) for p in content.find_all(&#39;p&#39;): text = p.text.strip() if text: out.append(text) return out . edition_sample = &#39;http://beo.ie/eagran-2014-09.aspx&#39; . def _get_article_links(url): out = set() page = requests.get(url) soup = BeautifulSoup(page.text, &#39;html.parser&#39;) for article in soup.find_all(&#39;div&#39;, {&#39;class&#39;: &#39;articleListing&#39;}): for a in article.find_all(&#39;a&#39;): link = a.get(&#39;href&#39;) if link: out.add(f&quot;http://beo.ie/{link}&quot;) return list(out) . def _get_edition_links(): out = set() for i in range(1, 15): url = f&quot;http://beo.ie/Editions.aspx?Year=20{i:02}&quot; page = requests.get(url) soup = BeautifulSoup(page.text, &#39;html.parser&#39;) eds = soup.find(&#39;ul&#39;, {&#39;class&#39;: &#39;editions&#39;}) for ed in eds.find_all(&#39;a&#39;): if ed.get(&#39;href&#39;): out.add(f&quot;http://beo.ie/{ed.get(&#39;href&#39;)}&quot;) return list(out) .",
            "url": "https://jimregan.github.io/notes/irish/text/2021/09/01/beo-scraper-pieces.html",
            "relUrl": "/irish/text/2021/09/01/beo-scraper-pieces.html",
            "date": " â€¢ Sep 1, 2021"
        }
        
    
  
    
        ,"post105": {
            "title": "Convert .lab to textgrid",
            "content": "!pip install praatio . Collecting praatio Downloading praatio-5.0.0-py3-none-any.whl (76 kB) |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 76 kB 2.9 MB/s Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from praatio) (3.7.4.3) Installing collected packages: praatio Successfully installed praatio-5.0.0 . def _read_lab(filename: str, skip_empty_labels: bool = True): ret = [] with open(filename) as file: for line in file.readlines(): if line.strip() == &#39;&#39;: continue if line.startswith(&#39;#&#39;): continue l = line.rstrip().split(&#39; &#39;) if skip_empty_labels and len(l) != 3: continue tmp = {} tmp[&#39;start&#39;] = l[0] tmp[&#39;end&#39;] = l[1] if len(l) == 3: tmp[&#39;phone&#39;] = l[2] else: tmp[&#39;phone&#39;] = &#39;&#39; ret.append(tmp) return ret . %%writefile sample.lab 0 9700000 sil 9700000 10900000 i 10900000 12400000 mj 12400000 13100000 lj 13100000 15200000 au 15200000 16300000 r 16300000 18100000 sil 18100000 19100000 sil 19100000 23700000 . Writing sample.lab . ll = _read_lab(&#39;sample.lab&#39;, False) . from praatio import textgrid . from praatio.utilities.constants import Interval . out = [] for l in ll: out.append(Interval(int(l[&#39;start&#39;])/10000000.0, int(l[&#39;end&#39;])/10000000.0, l[&#39;phone&#39;])) . tier_start = out[0][0] tier_end = out[-1][1] . out . [Interval(start=0.0, end=0.97, label=&#39;sil&#39;), Interval(start=0.97, end=1.09, label=&#39;i&#39;), Interval(start=1.09, end=1.24, label=&#39;mj&#39;), Interval(start=1.24, end=1.31, label=&#39;lj&#39;), Interval(start=1.31, end=1.52, label=&#39;au&#39;), Interval(start=1.52, end=1.63, label=&#39;r&#39;), Interval(start=1.63, end=1.81, label=&#39;sil&#39;), Interval(start=1.81, end=1.91, label=&#39;sil&#39;), Interval(start=1.91, end=2.37, label=&#39;&#39;)] . tg = textgrid.Textgrid() phone_tier = textgrid.IntervalTier(&#39;phones&#39;, out, tier_start, tier_end) tg.addTier(phone_tier) tg.save(&#39;out.TextGrid&#39;, format=&quot;long_textgrid&quot;, includeBlankSpaces=False) . !cat out.TextGrid . File type = &#34;ooTextFile&#34; Object class = &#34;TextGrid&#34; xmin = 0 xmax = 2.37 tiers? &lt;exists&gt; size = 1 item []: item [1]: class = &#34;IntervalTier&#34; name = &#34;phones&#34; xmin = 0 xmax = 2.37 intervals: size = 9 intervals [1]: xmin = 0 xmax = 0.97 text = &#34;sil&#34; intervals [2]: xmin = 0.97 xmax = 1.09 text = &#34;i&#34; intervals [3]: xmin = 1.09 xmax = 1.24 text = &#34;mj&#34; intervals [4]: xmin = 1.24 xmax = 1.31 text = &#34;lj&#34; intervals [5]: xmin = 1.31 xmax = 1.52 text = &#34;au&#34; intervals [6]: xmin = 1.52 xmax = 1.63 text = &#34;r&#34; intervals [7]: xmin = 1.63 xmax = 1.81 text = &#34;sil&#34; intervals [8]: xmin = 1.81 xmax = 1.91 text = &#34;sil&#34; intervals [9]: xmin = 1.91 xmax = 2.37 text = &#34;&#34; .",
            "url": "https://jimregan.github.io/notes/lab/speech/textgrid/2021/08/31/lab_to_textgrid.html",
            "relUrl": "/lab/speech/textgrid/2021/08/31/lab_to_textgrid.html",
            "date": " â€¢ Aug 31, 2021"
        }
        
    
  
    
        ,"post106": {
            "title": "Read .lab files",
            "content": "%%writefile test.lab # 0 230 f 230 350 o 350 470 n . Writing test.lab . def _read_lab(filename: str): ret = [] with open(filename) as file: for line in file.readlines(): if line.strip() == &#39;&#39;: continue if line.startswith(&#39;#&#39;): continue l = line.rstrip().split(&#39; &#39;) if len(l) != 3: continue tmp = {} tmp[&#39;start&#39;] = l[0] tmp[&#39;end&#39;] = l[1] tmp[&#39;phone&#39;] = l[2] ret.append(tmp) return ret . _read_lab(&#39;test.lab&#39;) . [{&#39;end&#39;: &#39;230&#39;, &#39;phone&#39;: &#39;f&#39;, &#39;start&#39;: &#39;0&#39;}, {&#39;end&#39;: &#39;350&#39;, &#39;phone&#39;: &#39;o&#39;, &#39;start&#39;: &#39;230&#39;}, {&#39;end&#39;: &#39;470&#39;, &#39;phone&#39;: &#39;n&#39;, &#39;start&#39;: &#39;350&#39;}] .",
            "url": "https://jimregan.github.io/notes/lab/speech/2021/08/30/read_lab_file.html",
            "relUrl": "/lab/speech/2021/08/30/read_lab_file.html",
            "date": " â€¢ Aug 30, 2021"
        }
        
    
  
    
        ,"post107": {
            "title": "Parse Swedish gigaword XML",
            "content": "example = &quot;&quot;&quot; &lt;corpus id=&quot;1960-0000&quot;&gt; &lt;text date=&quot;1965-02-14&quot; datefrom=&quot;19650214&quot; dateto=&quot;19650214&quot; genre=&quot;news&quot; publisher=&quot;Stockholms Tidningen &quot; timefrom=&quot;000000&quot; timeto=&quot;235959&quot; topic=&quot;Politik och samhÃ¤llsfrÃ¥gor&quot; year=&quot;1965&quot;&gt; &lt;sentence id=&quot;aa9c2ac8-ae5dd1a1&quot;&gt; &lt;w dephead=&quot;4&quot; deprel=&quot;RA&quot; lemma=&quot;|i|&quot; lex=&quot;|i..pp.1|&quot; msd=&quot;PP&quot; pos=&quot;PP&quot; prefix=&quot;|&quot; ref=&quot;1&quot; saldo=&quot;|i..2|&quot; suffix=&quot;|&quot;&gt;I&lt;/w&gt; &lt;w dephead=&quot;3&quot; deprel=&quot;DT&quot; lemma=&quot;|&quot; lex=&quot;|&quot; msd=&quot;HD.UTR.SIN.IND&quot; pos=&quot;HD&quot; prefix=&quot;|&quot; ref=&quot;2&quot; saldo=&quot;|&quot; suffix=&quot;|&quot;&gt;vilken&lt;/w&gt; &lt;/sentence&gt; &lt;/text&gt; &lt;/corpus&gt; &quot;&quot;&quot; . import xml.etree.ElementTree as ET def _attrib(node, attrib: str) -&gt; str: if attrib in node.attrib: return node.attrib[attrib].strip() else: return &quot;&quot; def _iattrib(node, attrib: str) -&gt; str: if attrib in node.attrib: try: return int(node.attrib[attrib].strip()) except ValueError: return 0 else: return 0 class Corpus: def __init__(self, source): tree = ET.parse(source) root = tree.getroot() self.id = _attrib(root, &#39;id&#39;) self.texts = [] for text_node in root.findall(&#39;./text&#39;): self.texts.append(Text(text_node)) class Text: def __init__(self, node): self.date = _attrib(node, &#39;date&#39;) self.datefrom = _iattrib(node, &#39;datefrom&#39;) self.dateto = _iattrib(node, &#39;dateto&#39;) self.genre = _attrib(node, &#39;genre&#39;) self.publisher = _attrib(node, &#39;publisher&#39;) self.timefrom = _iattrib(node, &#39;timefrom&#39;) self.timeto = _iattrib(node, &#39;timeto&#39;) self.topic = _attrib(node, &#39;topic&#39;) self.year = _iattrib(node, &#39;year&#39;) self.sentences = [] for sent_node in node.findall(&#39;./sentence&#39;): self.sentences.append(Sentence(sent_node)) class Sentence: def __init__(self, node): self.id = _attrib(node, &#39;id&#39;) self.words = [] for w_node in node.findall(&#39;./w&#39;): self.words.append(Word(w_node)) class Word: def __init__(self, node): self.dephead = _attrib(node, &#39;dephead&#39;) self.deprel = _attrib(node, &#39;deprel&#39;) self.lemma = _attrib(node, &#39;lemma&#39;) self.lex = _attrib(node, &#39;lex&#39;) self.msd = _attrib(node, &#39;msd&#39;) self.pos = _attrib(node, &#39;pos&#39;) self.prefix = _attrib(node, &#39;prefix&#39;) self.ref = _attrib(node, &#39;ref&#39;) self.saldo = _attrib(node, &#39;saldo&#39;) self.suffix = _attrib(node, &#39;suffix&#39;) self.word = node.text.strip() . import io sio = io.StringIO(example) corp = Corpus(sio) . import json json.dumps(corp, default=lambda o: o.__dict__) . &#39;{&#34;id&#34;: &#34;1960-0000&#34;, &#34;texts&#34;: [{&#34;date&#34;: &#34;1965-02-14&#34;, &#34;datefrom&#34;: 19650214, &#34;dateto&#34;: 19650214, &#34;genre&#34;: &#34;news&#34;, &#34;publisher&#34;: &#34;Stockholms Tidningen&#34;, &#34;timefrom&#34;: 0, &#34;timeto&#34;: 235959, &#34;topic&#34;: &#34;Politik och samh u00e4llsfr u00e5gor&#34;, &#34;year&#34;: 1965, &#34;sentences&#34;: [{&#34;id&#34;: &#34;aa9c2ac8-ae5dd1a1&#34;, &#34;words&#34;: [{&#34;dephead&#34;: &#34;4&#34;, &#34;deprel&#34;: &#34;RA&#34;, &#34;lemma&#34;: &#34;|i|&#34;, &#34;lex&#34;: &#34;|i..pp.1|&#34;, &#34;msd&#34;: &#34;PP&#34;, &#34;pos&#34;: &#34;PP&#34;, &#34;prefix&#34;: &#34;|&#34;, &#34;ref&#34;: &#34;1&#34;, &#34;saldo&#34;: &#34;|i..2|&#34;, &#34;suffix&#34;: &#34;|&#34;, &#34;word&#34;: &#34;I&#34;}, {&#34;dephead&#34;: &#34;3&#34;, &#34;deprel&#34;: &#34;DT&#34;, &#34;lemma&#34;: &#34;|&#34;, &#34;lex&#34;: &#34;|&#34;, &#34;msd&#34;: &#34;HD.UTR.SIN.IND&#34;, &#34;pos&#34;: &#34;HD&#34;, &#34;prefix&#34;: &#34;|&#34;, &#34;ref&#34;: &#34;2&#34;, &#34;saldo&#34;: &#34;|&#34;, &#34;suffix&#34;: &#34;|&#34;, &#34;word&#34;: &#34;vilken&#34;}]}]}]}&#39; .",
            "url": "https://jimregan.github.io/notes/swedish/gigaword/xml/2021/08/30/parse_swedish_gigaword.html",
            "relUrl": "/swedish/gigaword/xml/2021/08/30/parse_swedish_gigaword.html",
            "date": " â€¢ Aug 30, 2021"
        }
        
    
  
    
        ,"post108": {
            "title": "Playing with pyannote.audio",
            "content": "Only the dia pipeline seems to work. . %%capture !pip install -q pyannote.audio==1.1 . %%capture !wget https://podcast.rasset.ie/podcasts/audio/2021/0626/20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.mp3 . %%capture !ffmpeg -i /content/20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.mp3 -acodec pcm_s16le -ac 1 -ar 16000 /content/20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.wav . import torch pipeline = torch.hub.load(&#39;pyannote/pyannote-audio&#39;, &#39;dia&#39;) diarization = pipeline({&#39;audio&#39;: &#39;/content/20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.wav&#39;}) . diarization . with open(&#39;/content/20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.rttm&#39;, &#39;w&#39;) as f: diarization.write_rttm(f) . %%capture !pip install youtube-dl . %%capture !youtube-dl f3wKxcP7hYE . %%capture !ffmpeg -i &#39;Sraith 2 Eip 1-f3wKxcP7hYE.mp4&#39; -acodec pcm_s16le -ac 1 -ar 16000 f3wKxcP7hYE.wav . diarization2 = pipeline({&#39;audio&#39;: &#39;/content/f3wKxcP7hYE.wav&#39;}) . diarization2 . No good; first 8 seconds are silence (ok), next 30 are theme music (not ok). . with open(&#39;/content/f3wKxcP7hYE.rttm&#39;, &#39;w&#39;) as f2: diarization2.write_rttm(f2) .",
            "url": "https://jimregan.github.io/notes/diarisation/pyannote/2021/08/27/playing-with-pyannote-audio.html",
            "relUrl": "/diarisation/pyannote/2021/08/27/playing-with-pyannote-audio.html",
            "date": " â€¢ Aug 27, 2021"
        }
        
    
  
    
        ,"post109": {
            "title": "Utterance XML to json",
            "content": "sample = &quot;&quot;&quot; &lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt; &lt;utterance input_string=&quot;&quot;&gt; &lt;sentence input_string=&quot;&quot;&gt; &lt;token input_string=&quot;SILENCE_TOKEN&quot;&gt; &lt;word input_string=&quot;SILENCE_TOKEN&quot; trans_source=&quot;src&quot; trans_output_format=&quot;final&quot;&gt; &lt;syllable &gt; &lt;phoneme symbol=&quot;sil&quot; end=&quot;1.19&quot;/&gt; &lt;/syllable&gt; &lt;/word&gt; &lt;/token&gt; &lt;/sentence&gt; &lt;/utterance&gt; &quot;&quot;&quot; . import xml.etree.ElementTree as ET . class Utterance: def __init__(self, input, sentences): self.input = input self.sentences = sentences . class Sentence: def __init__(self, input, tokens): self.input = input self.tokens = tokens . class Token: def __init__(self, input, words): self.input = input self.words = words . class Word: def __init__(self, input, source, syllables): self.input = input self.source = source self.syllables = syllables if self.syllables is None: self.syllables = [] . class Syllable: def __init__(self, stress: int = 0, phonemes = None): self.stress = stress self.phonemes = phonemes if self.phonemes is None: self.phonemes = [] . class Phoneme: def __init__(self, symbol: str = &quot;&quot;, end: float = 0.0): self.symbol = symbol self.end = end . import io sio = io.StringIO(sample.strip()) . def from_xml(source): tree = ET.parse(source) root = tree.getroot() if &#39;input_string&#39; in root.attrib: input = root.attrib[&#39;input_string&#39;] else: input = &#39;&#39; sentences = [] for sentence in root.findall(&#39;./sentence&#39;): if &#39;input_string&#39; in sentence.attrib: input = sentence.attrib[&#39;input_string&#39;] else: input = &#39;&#39; tokens = [] for token in sentence.findall(&#39;./token&#39;): if &#39;input_string&#39; in token.attrib: input = token.attrib[&#39;input_string&#39;] else: input = &#39;&#39; words = [] for word in token.findall(&#39;./word&#39;): if &#39;input_string&#39; in word.attrib: input = word.attrib[&#39;input_string&#39;] else: input = &quot;&quot; if &#39;trans_source&#39; in word.attrib: source = word.attrib[&#39;trans_source&#39;] else: source = &quot;&quot; syllables = [] for syllable in word.findall(&#39;./syllable&#39;): phonemes = [] if &#39;stress&#39; in syllable.attrib: stress = int(syllable.attrib[&#39;stress&#39;]) else: stress = 0 for phoneme in syllable.findall(&#39;./phoneme&#39;): if &#39;symbol&#39; in phoneme.attrib: symbol = phoneme.attrib[&#39;symbol&#39;] else: symbol = &#39;&#39; if &#39;end&#39; in phoneme.attrib: end = float(phoneme.attrib[&#39;end&#39;]) else: symbol = 0.0 phonemes.append(Phoneme(symbol, end)) syllables.append(Syllable(stress, phonemes)) words.append(Word(input, source, syllables)) tokens.append(Token(input, words)) sentences.append(Sentence(input, tokens)) return Utterance(input, sentences) . utt = from_xml(sio) . import json json.dumps(utt, default=lambda o: o.__dict__) . &#39;{&#34;input&#34;: &#34;SILENCE_TOKEN&#34;, &#34;sentences&#34;: [{&#34;input&#34;: &#34;SILENCE_TOKEN&#34;, &#34;tokens&#34;: [{&#34;input&#34;: &#34;SILENCE_TOKEN&#34;, &#34;words&#34;: [{&#34;input&#34;: &#34;SILENCE_TOKEN&#34;, &#34;source&#34;: &#34;src&#34;, &#34;syllables&#34;: [{&#34;stress&#34;: 0, &#34;phonemes&#34;: [{&#34;symbol&#34;: &#34;sil&#34;, &#34;end&#34;: 1.19}]}]}]}]}]}&#39; .",
            "url": "https://jimregan.github.io/notes/irish/abair/2021/08/22/utterance_xml_to_json.html",
            "relUrl": "/irish/abair/2021/08/22/utterance_xml_to_json.html",
            "date": " â€¢ Aug 22, 2021"
        }
        
    
  
    
        ,"post110": {
            "title": "Soundcloud - RaidiÃ³ na Gaeltachta/RaidiÃ³ FÃ¡ilte",
            "content": "!pip install youtube-dl !youtube-dl -o &#39;%(id)s.%(ext)s&#39; https://soundcloud.com/rte-rnag/ !youtube-dl -o &#39;%(id)s.%(ext)s&#39; https://soundcloud.com/raidio-f .",
            "url": "https://jimregan.github.io/notes/kaggle/irish/soundcloud/dataset/unlabelled/rnag/raidiofailte/2021/08/21/soundcloud-raidio-na-gaeltachta.html",
            "relUrl": "/kaggle/irish/soundcloud/dataset/unlabelled/rnag/raidiofailte/2021/08/21/soundcloud-raidio-na-gaeltachta.html",
            "date": " â€¢ Aug 21, 2021"
        }
        
    
  
    
        ,"post111": {
            "title": "Download CÃºla4 ar Scoil video",
            "content": "urls = &quot;&quot;&quot; https://www.youtube.com/playlist?list=PLbcLsUBW9b3DvFSKW94bXDkVT0rIIbDTk https://www.youtube.com/playlist?list=PLbcLsUBW9b3ArxQoB-GhdSzGtYhhU-KGT https://www.youtube.com/playlist?list=PLbcLsUBW9b3CZJpM59kQ76Wxdfm3buABK https://www.youtube.com/playlist?list=PLbcLsUBW9b3ATOk7Kdzxb5KGM1wOFmwby https://www.youtube.com/playlist?list=PLbcLsUBW9b3DknBLzIWl0tRC_jYpmYdc5 https://www.youtube.com/playlist?list=PLbcLsUBW9b3B0D2MrdXYyxT9kgADvHfIJ https://www.youtube.com/playlist?list=PLbcLsUBW9b3AgMxkiet3mnzspREWj6o54 https://www.youtube.com/playlist?list=PLbcLsUBW9b3BWCOmTz3PNNsH2B71h2EeR https://www.youtube.com/playlist?list=PLbcLsUBW9b3A-N-5701r8dhxstLqBQFKm https://www.youtube.com/playlist?list=PLbcLsUBW9b3CZAzppIH9EidEIIvNdZFsL https://www.youtube.com/playlist?list=PLbcLsUBW9b3B5DD8uXW0rJySgsqAeed1C https://www.youtube.com/playlist?list=PLbcLsUBW9b3DVprPwU4hHT73VdmmY45bc https://www.youtube.com/playlist?list=PLbcLsUBW9b3AcCrGgD04ryY6bnN8h7GSr https://www.youtube.com/playlist?list=PLbcLsUBW9b3COzIi5Rnl0F9yRZVR3tf_1 https://www.youtube.com/playlist?list=PLbcLsUBW9b3BHkhYBvNIlQknE-wpBT5vp https://www.youtube.com/playlist?list=PLbcLsUBW9b3AJVck8CCw35QGPYHxPXi-F &quot;&quot;&quot; . for url in urls.strip().split(&#39; n&#39;): !youtube-dl -i -o &#39;%(id)s.%(ext)s&#39; {url} .",
            "url": "https://jimregan.github.io/notes/irish/dataset/cula4/2021/08/21/download-cula4-ar-scoil-video.html",
            "relUrl": "/irish/dataset/cula4/2021/08/21/download-cula4-ar-scoil-video.html",
            "date": " â€¢ Aug 21, 2021"
        }
        
    
  
    
        ,"post112": {
            "title": "Download BBC Gaeilge clips",
            "content": "for i in range(1, 27): !youtube-dl -o &#39;%(id)s.%(ext)s&#39; &#39;https://www.bbc.co.uk/programmes/b007cpvp/clips?page={i}&#39; .",
            "url": "https://jimregan.github.io/notes/irish/dataset/bbc/2021/08/21/download-bbc-gaeilge-clips.html",
            "relUrl": "/irish/dataset/bbc/2021/08/21/download-bbc-gaeilge-clips.html",
            "date": " â€¢ Aug 21, 2021"
        }
        
    
  
    
        ,"post113": {
            "title": "Soundcloud - Raidio na Life",
            "content": "Original on Kaggle (private) . !pip install youtube-dl !youtube-dl https://soundcloud.com/rnl .",
            "url": "https://jimregan.github.io/notes/kaggle/irish/soundcloud/dataset/unlabelled/raidionalife/2021/08/01/soundcloud-raidio-na-life.html",
            "relUrl": "/kaggle/irish/soundcloud/dataset/unlabelled/raidionalife/2021/08/01/soundcloud-raidio-na-life.html",
            "date": " â€¢ Aug 1, 2021"
        }
        
    
  
    
        ,"post114": {
            "title": "Soundcloud - NÃ“S",
            "content": "Original on Kaggle (private) . !pip install youtube-dl !youtube-dl https://soundcloud.com/nosmag .",
            "url": "https://jimregan.github.io/notes/kaggle/irish/soundcloud/dataset/unlabelled/nos/2021/08/01/soundcloud-nos-pod.html",
            "relUrl": "/kaggle/irish/soundcloud/dataset/unlabelled/nos/2021/08/01/soundcloud-nos-pod.html",
            "date": " â€¢ Aug 1, 2021"
        }
        
    
  
    
        ,"post115": {
            "title": "Soundcloud - Cois Life",
            "content": "Original on Kaggle (private) . !pip install youtube-dl !youtube-dl https://soundcloud.com/cois-life-teoranta .",
            "url": "https://jimregan.github.io/notes/kaggle/irish/soundcloud/dataset/unlabelled/coislife/2021/08/01/soundcloud-cois-life.html",
            "relUrl": "/kaggle/irish/soundcloud/dataset/unlabelled/coislife/2021/08/01/soundcloud-cois-life.html",
            "date": " â€¢ Aug 1, 2021"
        }
        
    
  
    
        ,"post116": {
            "title": "Soundcloud - Club Leabhar",
            "content": "Original on Kaggle . !pip install youtube-dl !youtube-dl https://soundcloud.com/clubleabhar .",
            "url": "https://jimregan.github.io/notes/kaggle/irish/clubleabhar/dataset/unlabelled/2021/08/01/soundcloud-club-leabhar.html",
            "relUrl": "/kaggle/irish/clubleabhar/dataset/unlabelled/2021/08/01/soundcloud-club-leabhar.html",
            "date": " â€¢ Aug 1, 2021"
        }
        
    
  
    
        ,"post117": {
            "title": "Download Ros na RÃºn season 2",
            "content": "Original on Kaggle . %%capture !pip install youtube-dl . !youtube-dl -f bestaudio PLtVSQEQG0xVHeyao6vZyaY3kXGfbFFiAk .",
            "url": "https://jimregan.github.io/notes/kaggle/irish/rosnarun/dataset/unlabelled/2021/08/01/ros-na-run-s2.html",
            "relUrl": "/kaggle/irish/rosnarun/dataset/unlabelled/2021/08/01/ros-na-run-s2.html",
            "date": " â€¢ Aug 1, 2021"
        }
        
    
  
    
        ,"post118": {
            "title": "RnaG PodchraoltaÃ­",
            "content": "!curl https://www.rte.ie/radio/rnag/articles/eolas/2021/0712/1234521-podchraoltai/|grep &#39;il/Download&lt;/a&gt;&#39;|awk -F&#39;href=&quot;&#39; &#39;{print $2}&#39;|awk -F&#39;&quot;&#39; &#39;{print $1}&#39;|sed -e &#39;s/http:/https:/&#39; &gt; urls !cat urls |while read i;do wget $(curl $i|grep &#39;&lt;enclosure&#39;|awk -F&#39;url=&quot;&#39; &#39;{print $2}&#39;|awk -F&#39;&quot;&#39; &#39;{print $1}&#39;);done . https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-adhmhaidin-adhmhaidin_c21985558_21985605_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-adhmhaidin-nuachtnisi_c21985559_21985606_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-adhmhaidin-nuachtande_c21985560_21985607_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-adhmhaidin-nuachtantu_c21985561_21985608_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-adhmhaidin-nuachtania_c21985562_21985609_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-adhmhaidin-promhscalt_c21985563_21985610_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-adhmhaidin-promhscalt_c21985564_21985611_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-adhmhaidin-drcolmhenr_c21985565_21985612_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-adhmhaidin-tomssochin_c21985566_21985613_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-adhmhaidin-gearidnnic_c21985567_21985614_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-adhmhaidin-murtcualin_c21985568_21985615_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-adhmhaidin-sendebuitl_c21985569_21985616_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-adhmhaidin-anthonymol_c21985570_21985617_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-adhmhaidin-eoincathai_c21985571_21985618_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-adhmhaidin-adhmhaidin_c21985442_21985543_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-adhmhaidin-nuachtnisi_c21985443_21985544_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-adhmhaidin-nuachtande_c21985445_21985546_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-adhmhaidin-promhscalt_c21985447_21985548_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-adhmhaidin-antuairisc_c21985448_21985549_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-adhmhaidin-gearidnnic_c21985449_21985550_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-adhmhaidin-jimkeoghat_c21985450_21985551_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-adhmhaidin-gearidtuat_c21985451_21985552_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-adhmhaidin-eoincathai_c21985452_21985553_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-adhmhaidin-catherinec_c21985453_21985554_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-adhmhaidin-sencadhain_c21985454_21985555_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-adhmhaidin-crnanighal_c21985455_21985556_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-adhmhaidin-samuscosam_c21985456_21985557_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-adhmhaidin-adhmhaidin_c21984630_21984658_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-adhmhaidin-nuachtnisi_c21984631_21984659_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-adhmhaidin-nuachtantu_c21984632_21984660_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-adhmhaidin-nuachtania_c21984633_21984661_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-adhmhaidin-nuachtande_c21984634_21984662_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-adhmhaidin-promhscalt_c21984635_21984663_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-adhmhaidin-antuairisc_c21984636_21984664_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-adhmhaidin-gearidnnic_c21984637_21984665_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-adhmhaidin-eoincathin_c21984638_21984666_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-adhmhaidin-dithdemrdh_c21984639_21984667_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-adhmhaidin-drciarnfea_c21984640_21984668_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-adhmhaidin-aengussnod_c21984641_21984669_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-adhmhaidin-johnshamui_c21984642_21984670_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-adhmhaidin-johnconnol_c21984643_21984671_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-adhmhaidin-adhmhaidin_c21984065_21984079_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-adhmhaidin-nuachtnisi_c21984066_21984080_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-adhmhaidin-nuachtande_c21984067_21984081_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-adhmhaidin-nuachtantu_c21984068_21984082_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-adhmhaidin-nuachtania_c21984069_21984083_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-adhmhaidin-promhscalt_c21984070_21984084_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-adhmhaidin-antuairisc_c21984071_21984085_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-adhmhaidin-eoincathin_c21984072_21984086_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-adhmhaidin-pilnnchiar_c21984073_21984087_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-adhmhaidin-breandnmac_c21984074_21984088_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-adhmhaidin-rnndomhnai_c21984075_21984089_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-adhmhaidin-thomasotoo_c21984076_21984090_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-adhmhaidin-francesnic_c21984077_21984091_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-adhmhaidin-mirnuchidi_c21984078_21984092_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-adhmhaidin-adhmhaidin_c21983518_21983580_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-adhmhaidin-nuachtnisi_c21983519_21983581_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-adhmhaidin-nuachtania_c21983520_21983582_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-adhmhaidin-nuachtande_c21983521_21983583_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-adhmhaidin-nuachtantu_c21983522_21983584_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-adhmhaidin-promhscalt_c21983523_21983585_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-adhmhaidin-antuairisc_c21983524_21983586_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-adhmhaidin-eoghancorr_c21983525_21983587_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-adhmhaidin-anthonydoo_c21983526_21983588_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-adhmhaidin-jasonmongi_c21983527_21983589_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-adhmhaidin-cathalseoi_c21983528_21983590_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-adhmhaidin-johndownin_c21983529_21983591_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-adhmhaidin-slinenchat_c21983530_21983592_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-adhmhaidin-seosaimhcu_c21983531_21983593_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-adhmhaidin-adhmhaidin_c21982311_21982326_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-adhmhaidin-nuachtnisi_c21982312_21982327_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-adhmhaidin-nuachtantu_c21982313_21982328_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-adhmhaidin-nuachtania_c21982314_21982329_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-adhmhaidin-nuachtande_c21982315_21982330_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-adhmhaidin-promhscalt_c21982316_21982331_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-adhmhaidin-antuairisc_c21982317_21982332_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-adhmhaidin-drniallcle_c21982318_21982333_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-adhmhaidin-eoincathin_c21982319_21982334_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-adhmhaidin-pidbrowneo_c21982320_21982335_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-adhmhaidin-niallmurch_c21982321_21982336_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-adhmhaidin-pilnnchiar_c21982322_21982337_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-adhmhaidin-kevinohara_c21982323_21982338_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-adhmhaidin-aindriasmu_c21982324_21982339_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-adhmhaidin-niallmuill_c21982325_21982340_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-adhmhaidin-adhmhaidin_c21981849_21981901_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-adhmhaidin-nuachtnisi_c21981850_21981902_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-adhmhaidin-nuachtande_c21981851_21981903_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-adhmhaidin-nuachtantu_c21981852_21981904_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-adhmhaidin-nuachtania_c21981853_21981905_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-adhmhaidin-promhscalt_c21981854_21981906_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-ansaolodheas-ansaoldhea_c21988383_21988390_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-ansaolodheas-malachamac_c21988384_21988391_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-ansaolodheas-cathalfian_c21988385_21988392_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-ansaolodheas-jacquidesi_c21988386_21988393_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-ansaolodheas-gearidnnic_c21988387_21988394_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-ansaolodheas-michelmacg_c21988388_21988395_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-ansaolodheas-aoifenchob_c21988389_21988396_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-ansaolodheas-ansaoldhea_c21987459_21987473_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-ansaolodheas-michelglia_c21987460_21987474_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-ansaolodheas-edelnloibh_c21987461_21987475_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-ansaolodheas-padalypdra_c21987462_21987476_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-ansaolodheas-dnalliathi_c21987463_21987477_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-ansaolodheas-caitlnbrea_c21987464_21987478_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-ansaolodheas-crthachfao_c21987465_21987479_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-ansaolodheas-ansaoldhea_c21987011_21987017_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-ansaolodheas-gearidnnic_c21987012_21987018_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-ansaolodheas-peadarriad_c21987013_21987019_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-ansaolodheas-niallluasa_c21987014_21987020_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-ansaolodheas-aoifenghra_c21987015_21987021_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-ansaolodheas-gearidnnic_c21987016_21987022_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0726/20210726_rteraidion-ansaolodheas-ansaoldhea_c21986466_21986472_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0726/20210726_rteraidion-ansaolodheas-michelmuir_c21986467_21986473_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0726/20210726_rteraidion-ansaolodheas-michelcrod_c21986468_21986474_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0726/20210726_rteraidion-ansaolodheas-diarmaiddu_c21986469_21986475_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0726/20210726_rteraidion-ansaolodheas-mikeosheac_c21986470_21986476_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0726/20210726_rteraidion-ansaolodheas-valeriench_c21986471_21986477_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-ansaolodheas-ansaoldhea_c21985661_21985682_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-ansaolodheas-pdraigcear_c21985662_21985683_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-ansaolodheas-niamhndhri_c21985663_21985684_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-ansaolodheas-ritanbheag_c21985664_21985685_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-ansaolodheas-breandncob_c21985665_21985686_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-ansaolodheas-michelcrod_c21985666_21985687_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-ansaolodheas-aoifenchob_c21985667_21985688_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-ansaolodheas-ansaoldhea_c21985439_21985441_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-ansaolodheas-ansaoldhea_c21984759_21984765_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-ansaolodheas-johndownin_c21984760_21984766_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-ansaolodheas-nramarianm_c21984761_21984767_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-ansaolodheas-mirtnmacio_c21984762_21984768_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-ansaolodheas-samusciobh_c21984763_21984769_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-ansaolodheas-diarmuiddo_c21984764_21984770_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-ansaolodheas-ansaoldhea_c21984294_21984300_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-ansaolodheas-liamrchinl_c21984295_21984301_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-ansaolodheas-macdaramac_c21984296_21984302_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-ansaolodheas-donnchafia_c21984297_21984303_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-ansaolodheas-johngoduib_c21984298_21984304_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-ansaolodheas-pdraigcdri_c21984299_21984305_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-ansaolodheas-ansaoldhea_c21983702_21983707_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-ansaolodheas-michelmuir_c21983703_21983708_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-ansaolodheas-senceallai_c21983704_21983709_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-ansaolodheas-seghansuil_c21983705_21983710_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-ansaolodheas-miresebrea_c21983706_21983711_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0716/20210716_rteraidion-ansaolodheas-ansaoldhea_c21983345_21983346_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-ansaolodheas-ansaoldhea_c21982591_21982593_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-ansaolodheas-ansaoldhea_c21982052_21982073_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-ansaolodheas-senlionird_c21982053_21982074_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-ansaolodheas-slenchonai_c21982054_21982075_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-ansaolodheas-fredanicgi_c21982055_21982076_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-ansaolodheas-ruthnriada_c21982056_21982077_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-ansaolodheas-deirdrenic_c21982057_21982078_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-ansaolodheas-liambeagla_c21982058_21982079_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0713/20210713_rteraidion-ansaolodheas-ansaoldhea_c21981432_21981438_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0713/20210713_rteraidion-ansaolodheas-breandnmac_c21981433_21981439_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0713/20210713_rteraidion-ansaolodheas-samusdrisc_c21981434_21981440_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0713/20210713_rteraidion-ansaolodheas-mireniccra_c21981435_21981441_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0713/20210713_rteraidion-ansaolodheas-breandnbea_c21981436_21981442_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0713/20210713_rteraidion-ansaolodheas-michelceal_c21981437_21981443_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-ansaolodheas-ansaoldhea_c21980962_21980968_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-ansaolodheas-dithdemord_c21980963_21980969_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-ansaolodheas-padalytdbe_c21980964_21980970_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-ansaolodheas-andreapala_c21980965_21980971_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-ansaolodheas-mabhuainif_c21980966_21980972_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-ansaolodheas-michelcinn_c21980967_21980973_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-ansaolodheas-ansaolodhe_c21980827_21980839_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-ansaolodheas-deaglnragi_c21980828_21980840_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-ansaolodheas-aoifenchro_c21980829_21980841_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-ansaolodheas-ineuchuill_c21980830_21980842_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-ansaolodheas-amonnbraon_c21980831_21980843_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-ansaolodheas-oifenchobh_c21980832_21980844_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0708/20210708_rteraidion-ansaolodheas-ansaoldhea_c21979524_21979531_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0708/20210708_rteraidion-ansaolodheas-dnalgruagi_c21979525_21979532_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0708/20210708_rteraidion-ansaolodheas-angelaughr_c21979526_21979533_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0708/20210708_rteraidion-ansaolodheas-johnkenned_c21979527_21979534_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0708/20210708_rteraidion-ansaolodheas-sensilleab_c21979528_21979535_232_drm_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0708/20210708_rteraidion-ansaolodheas-ruthnriada_c21979529_21979536_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0708/20210708_rteraidion-ansaolodheas-drbreandnc_c21979530_21979537_232_drm_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0707/20210707_rteraidion-ansaolodheas-ansaoldhea_c21979272_21979273_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0706/20210706_rteraidion-ansaolodheas-ansaoldhea_c21978234_21978239_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0706/20210706_rteraidion-ansaolodheas-antathairc_c21978235_21978240_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0706/20210706_rteraidion-ansaolodheas-macdaramac_c21978236_21978241_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0706/20210706_rteraidion-ansaolodheas-sensuillea_c21978237_21978242_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-barrscealta-barrscalta_c21988305_21988432_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-barrscealta-inenbhreis_c21988306_21988433_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-barrscealta-nicolanbha_c21988307_21988434_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-barrscealta-marybnmhic_c21988308_21988435_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-barrscealta-ciarnrabha_c21988309_21988436_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-barrscealta-lorcnmirtn_c21988310_21988437_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-barrscealta-eimearngha_c21988311_21988438_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-barrscealta-maryaggiea_c21988312_21988439_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-barrscealta-barrscalta_c21987865_21987872_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-barrscealta-pilnnicgei_c21987866_21987873_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-barrscealta-andrteaghl_c21987867_21987874_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-barrscealta-michealdui_c21987868_21987875_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-barrscealta-conalldomh_c21987869_21987876_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-barrscealta-fearnaromh_c21987870_21987877_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-barrscealta-geneeoghai_c21987871_21987878_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-barrscealta-barrscalta_c21987378_21987385_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-barrscealta-inenbhreis_c21987379_21987386_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-barrscealta-michelhean_c21987380_21987387_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-barrscealta-aoifenicse_c21987381_21987388_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-barrscealta-taynanicga_c21987382_21987389_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-barrscealta-anradomhna_c21987383_21987390_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-barrscealta-antathaire_c21987384_21987391_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-barrscealta-barrscalta_c21986924_21986930_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-barrscealta-inenbhreis_c21986925_21986931_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-barrscealta-ancomhairl_c21986926_21986932_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-barrscealta-edwardmaol_c21986927_21986933_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-barrscealta-ansirsintj_c21986928_21986934_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-barrscealta-sylvesterm_c21986929_21986935_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-barrscealta-barrscalta_c21985619_21985696_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-barrscealta-francesnic_c21985620_21985697_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-barrscealta-caitlnnbhr_c21985621_21985698_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-barrscealta-deirdrenbh_c21985622_21985699_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-barrscealta-eoghanmacg_c21985623_21985700_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-barrscealta-gearidnnic_c21985624_21985701_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-barrscealta-slenfhearr_c21985625_21985702_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-barrscealta-maryaggiea_c21985626_21985703_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-barrscealta-barrscalta_c21985027_21985033_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-barrscealta-maighradua_c21985028_21985034_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-barrscealta-andrteaghl_c21985029_21985035_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-barrscealta-anteachtad_c21985030_21985036_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-barrscealta-cathalmacs_c21985031_21985037_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-barrscealta-fearnaromh_c21985032_21985038_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-barrscealta-barrscalta_c21984708_21984715_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-barrscealta-francesnic_c21984709_21984716_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-barrscealta-antathairb_c21984710_21984717_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-barrscealta-marjorienc_c21984711_21984718_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-barrscealta-siobhnocon_c21984712_21984719_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-barrscealta-annienmhio_c21984713_21984720_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-barrscealta-dianenchan_c21984714_21984721_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-barrscealta-pilnnicgid_c21984183_21984190_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-barrscealta-paddybrown_c21984184_21984191_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-barrscealta-ansirsintj_c21984185_21984192_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-barrscealta-willieghri_c21984186_21984193_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-barrscealta-rnndochart_c21984187_21984194_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-barrscealta-dnallceall_c21984188_21984195_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-barrscealta-barrscalta_c21983753_21983759_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-barrscealta-nascaltanu_c21983754_21983760_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-barrscealta-msdoogiedu_c21983755_21983761_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-barrscealta-turasireac_c21983756_21983762_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-barrscealta-sriantasli_c21983757_21983763_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-barrscealta-crsaspirtl_c21983758_21983764_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0716/20210716_rteraidion-barrscealta-barrscalta_c21982973_21982979_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0716/20210716_rteraidion-barrscealta-maighradua_c21982974_21982980_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0716/20210716_rteraidion-barrscealta-eilsndhoch_c21982975_21982981_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0716/20210716_rteraidion-barrscealta-antdarsenc_c21982976_21982982_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0716/20210716_rteraidion-barrscealta-maryaggiea_c21982977_21982983_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0716/20210716_rteraidion-barrscealta-charliever_c21982978_21982984_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-barrscealta-barrscalta_c21982443_21982450_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-barrscealta-pilnnicgid_c21982444_21982451_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-barrscealta-andrteaghl_c21982445_21982452_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-barrscealta-anteachtad_c21982446_21982453_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-barrscealta-caoimhnbao_c21982447_21982454_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-barrscealta-ancomhairl_c21982448_21982455_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-barrscealta-ciaranstii_c21982449_21982456_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-barrscealta-scaltanuac_c21980995_21981010_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-barrscealta-mrturasire_c21980996_21981011_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-barrscealta-kayleighnm_c21980997_21981012_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-barrscealta-antathairm_c21980998_21981013_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-barrscealta-nacluichga_c21980999_21981014_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-barrscealta-barrscalta_c21980223_21980230_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-barrscealta-pilnnicgid_c21980224_21980231_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-barrscealta-dnallcnimh_c21980225_21980232_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-barrscealta-conorgallc_c21980226_21980233_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-barrscealta-patriciada_c21980227_21980234_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-barrscealta-dannydomhn_c21980228_21980235_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-barrscealta-maryaggiea_c21980229_21980236_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0708/20210708_rteraidion-barrscealta-barrscalta_c21979436_21979442_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0708/20210708_rteraidion-barrscealta-francesnic_c21979437_21979443_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0708/20210708_rteraidion-barrscealta-annabeanug_c21979438_21979444_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0708/20210708_rteraidion-barrscealta-andrteaghl_c21979439_21979445_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0604/20210604_rteraidion-bladhairernag-igecilleac_c21963252_21963259_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0604/20210604_rteraidion-bladhairernag-jessiesmit_c21963253_21963260_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0604/20210604_rteraidion-bladhairernag-ancraoltir_c21963256_21963263_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0604/20210604_rteraidion-bladhairernag-johnfearra_c21963257_21963264_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0604/20210604_rteraidion-bladhairernag-michaelcur_c21963316_21963324_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0603/20210603_rteraidion-bladhairernag-filenageal_c21962703_21963068_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0603/20210603_rteraidion-bladhairernag-jamiesugru_c21962705_21963070_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0603/20210603_rteraidion-bladhairernag-eimearmcgo_c21962706_21963071_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0603/20210603_rteraidion-bladhairernag-marcusmacc_c21962707_21963072_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0528/20210528_rteraidion-bladhairernag-nadescalta_c21959922_21959928_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0528/20210528_rteraidion-bladhairernag-leahndhoch_c21959924_21959930_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0528/20210528_rteraidion-bladhairernag-conorbrumm_c21959925_21959931_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0528/20210528_rteraidion-bladhairernag-conormaccr_c21959926_21959932_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0527/20210527_rteraidion-bladhairernag-susancolem_c21959338_21959344_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0527/20210527_rteraidion-bladhairernag-ilsndhuibh_c21959339_21959345_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0527/20210527_rteraidion-bladhairernag-deirdrench_c21959340_21959346_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0527/20210527_rteraidion-bladhairernag-namonaghan_c21959341_21959347_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0527/20210527_rteraidion-bladhairernag-diarmuidma_c21959342_21959348_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0521/20210521_rteraidion-bladhairernag-nadescalta_c21956962_21957052_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0521/20210521_rteraidion-bladhairernag-clarenchea_c21956964_21957054_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0521/20210521_rteraidion-bladhairernag-pamelapren_c21956965_21957055_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0521/20210521_rteraidion-bladhairernag-gaeltharsi_c21956966_21957056_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0520/20210520_rteraidion-bladhairernag-lisanicanb_c21956281_21956288_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0520/20210520_rteraidion-bladhairernag-comrtasnag_c21956282_21956289_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0520/20210520_rteraidion-bladhairernag-taiscevint_c21956283_21956290_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0520/20210520_rteraidion-bladhairernag-richieconr_c21956284_21956291_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0520/20210520_rteraidion-bladhairernag-tessaflemi_c21956285_21956292_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0520/20210520_rteraidion-bladhairernag-rosienghai_c21956286_21956293_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0514/20210514_rteraidion-bladhairernag-bladhairec_c21954020_21954027_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0514/20210514_rteraidion-bladhairernag-nadescalta_c21954021_21954028_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0514/20210514_rteraidion-bladhairernag-ceolbeobil_c21954022_21954029_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0514/20210514_rteraidion-bladhairernag-edelnbhrao_c21954023_21954030_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0514/20210514_rteraidion-bladhairernag-pdraigcong_c21954024_21954031_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0514/20210514_rteraidion-bladhairernag-mrteilifse_c21954025_21954032_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0514/20210514_rteraidion-bladhairernag-claresands_c21954026_21954033_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0513/20210513_rteraidion-bladhairernag-bladhairec_c21953402_21953408_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0513/20210513_rteraidion-bladhairernag-filenascco_c21953403_21953409_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0513/20210513_rteraidion-bladhairernag-aoisachath_c21953404_21953410_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0513/20210513_rteraidion-bladhairernag-claramurra_c21953405_21953411_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0513/20210513_rteraidion-bladhairernag-franktorma_c21953406_21953412_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0513/20210513_rteraidion-bladhairernag-gearidcobh_c21953407_21953413_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0507/20210507_rteraidion-bladhairernag-bladhairec_c21950931_21951100_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0507/20210507_rteraidion-bladhairernag-nadescalta_c21950932_21951101_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0507/20210507_rteraidion-bladhairernag-aoisachath_c21950933_21951102_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0507/20210507_rteraidion-bladhairernag-mrceoilemm_c21950934_21951103_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0507/20210507_rteraidion-bladhairernag-cultrlannm_c21950935_21951104_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0507/20210507_rteraidion-bladhairernag-comhdhilna_c21950936_21951105_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0506/20210506_rteraidion-bladhairernag-bladhairec_c21950342_21950351_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0506/20210506_rteraidion-bladhairernag-deirdrendh_c21950343_21950352_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0506/20210506_rteraidion-bladhairernag-comrtasnab_c21950344_21950353_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0506/20210506_rteraidion-bladhairernag-branmacglo_c21950345_21950354_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0506/20210506_rteraidion-bladhairernag-ceolbeomar_c21950346_21950355_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0506/20210506_rteraidion-bladhairernag-buachailln_c21950347_21950356_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0506/20210506_rteraidion-bladhairernag-ceolbeomar_c21950348_21950357_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0506/20210506_rteraidion-bladhairernag-pdraigjack_c21950349_21950358_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0506/20210506_rteraidion-bladhairernag-ceolbeocat_c21950350_21950359_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0430/20210430_rteraidion-bladhairernag-bladhairec_c21948145_21948153_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0430/20210430_rteraidion-bladhairernag-nadescalta_c21948146_21948154_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0430/20210430_rteraidion-bladhairernag-jonnydillo_c21948147_21948155_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0430/20210430_rteraidion-bladhairernag-diarmuidma_c21948148_21948156_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0430/20210430_rteraidion-bladhairernag-geariddris_c21948149_21948157_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0430/20210430_rteraidion-bladhairernag-paddyglack_c21948150_21948158_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0430/20210430_rteraidion-bladhairernag-cianmaonla_c21948151_21948159_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0430/20210430_rteraidion-bladhairernag-aonachmhac_c21948152_21948160_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0429/20210429_rteraidion-bladhairernag-bladhairec_c21947633_21947911_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0429/20210429_rteraidion-bladhairernag-seoirsnnmh_c21947634_21947912_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0429/20210429_rteraidion-bladhairernag-aoisachath_c21947635_21947913_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0429/20210429_rteraidion-bladhairernag-darraghcao_c21947636_21947914_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0429/20210429_rteraidion-bladhairernag-brdnfoxant_c21947637_21947915_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0429/20210429_rteraidion-bladhairernag-muireannni_c21947638_21947916_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0429/20210429_rteraidion-bladhairernag-nascoilnas_c21947639_21947917_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0423/20210423_rteraidion-bladhairernag-bladhairec_c21943846_21943852_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0423/20210423_rteraidion-bladhairernag-hughmacgio_c21943847_21943853_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0423/20210423_rteraidion-bladhairernag-helendiamo_c21943848_21943854_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0423/20210423_rteraidion-bladhairernag-eoinmuirch_c21943849_21943855_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0423/20210423_rteraidion-bladhairernag-ruthnicaoi_c21943850_21943856_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0423/20210423_rteraidion-bladhairernag-risnagusei_c21943851_21943857_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0422/20210422_rteraidion-bladhairernag-bladhairec_c21943159_21943166_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0422/20210422_rteraidion-bladhairernag-mollyheste_c21943160_21943167_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0422/20210422_rteraidion-bladhairernag-garrymacdo_c21943161_21943168_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0422/20210422_rteraidion-bladhairernag-culchaintl_c21943162_21943169_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0422/20210422_rteraidion-bladhairernag-ciaraoconn_c21943163_21943170_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0422/20210422_rteraidion-bladhairernag-gaeltharsi_c21943164_21943171_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0422/20210422_rteraidion-bladhairernag-andrcillia_c21943165_21943172_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0416/20210416_rteraidion-bladhairernag-bladhairec_c21940555_21940562_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0416/20210416_rteraidion-bladhairernag-juliejayna_c21940556_21940563_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0416/20210416_rteraidion-bladhairernag-aoisachath_c21940557_21940564_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0416/20210416_rteraidion-bladhairernag-bhalnamban_c21940558_21940565_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0416/20210416_rteraidion-bladhairernag-paulinesca_c21940559_21940566_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0416/20210416_rteraidion-bladhairernag-gaeltharsi_c21940560_21940567_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0725/20210725_rteraidion-cartlannbhothar-citpheatsa_c21986304_21986305_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0718/20210718_rteraidion-cartlannbhothar-katepheats_c21984168_21984169_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0711/20210711_rteraidion-cartlannbhothar-mirencheoc_c21981051_21981052_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0627/20210627_rteraidion-cartlannbhothar-cartlannbh_c21974782_21974852_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0620/20210620_rteraidion-cartlannbhothar-cartlannbh_c21971339_21972928_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0620/20210620_rteraidion-cartlannbhothar-samuspound_c21971340_21972929_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0620/20210620_rteraidion-cartlannbhothar-muirisgogc_c21971341_21972930_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0620/20210620_rteraidion-cartlannbhothar-seanchasan_c21971342_21972931_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0613/20210613_rteraidion-cartlannbhothar-cartlannbh_c21967487_21967522_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0606/20210606_rteraidion-cartlannbhothar-leabharanp_c21965134_21965135_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0530/20210530_rteraidion-cartlannbhothar-clriomln30_c21961256_21961259_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0530/20210530_rteraidion-cartlannbhothar-nracitinna_c21961257_21961260_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0530/20210530_rteraidion-cartlannbhothar-nrauchoiti_c21961258_21961261_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0523/20210523_rteraidion-cartlannbhothar-cartlannbh_c21957611_21957615_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0523/20210523_rteraidion-cartlannbhothar-tadhgdrisc_c21957612_21957616_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0523/20210523_rteraidion-cartlannbhothar-michelmaol_c21957613_21957617_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0523/20210523_rteraidion-cartlannbhothar-annradeblc_c21957614_21957618_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0516/20210516_rteraidion-cartlannbhothar-cartlannbh_c21954551_21954552_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0509/20210509_rteraidion-cartlannbhothar-cartlannbh_c21951494_21951647_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0425/20210425_rteraidion-cartlannbhothar-cartlannbh_c21945215_21945216_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0418/20210418_rteraidion-cartlannbhothar-clriomln18_c21941195_21941196_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0404/20210404_rteraidion-cartlannbhothar-cartlannbh_c21934559_21934560_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0321/20210321_rteraidion-cartlannbhothar-cartlannbh_c21927145_21927146_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0314/20210314_rteraidion-cartlannbhothar-cartlannbh_c21924362_21924363_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0221/20210221_rteraidion-cartlannbhothar-cartlannbh_c21913398_21913399_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0207/20210207_rteraidion-cartlannbhothar-cartlannbh_c21907422_21907423_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0117/20210117_rteraidion-cartlannbhothar-cuasabhoda_c21894664_21894665_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/1230/20201230_rteraidion-cartlannbhothar-cartlannbh_c21888929_21888933_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/1230/20201230_rteraidion-cartlannbhothar-tommhicgro_c21888930_21888934_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/1230/20201230_rteraidion-cartlannbhothar-siobhngrom_c21888931_21888935_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/1230/20201230_rteraidion-cartlannbhothar-peigsayers_c21888932_21888936_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/1220/20201220_rteraidion-cartlannbhothar-cartlannbh_c21886239_21886240_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/1025/20201025_rteraidion-cartlannbhothar-clriomln25_c21856360_21856365_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/1025/20201025_rteraidion-cartlannbhothar-dnallliath_c21856361_21856366_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/1025/20201025_rteraidion-cartlannbhothar-plarluacha_c21856362_21856367_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/1025/20201025_rteraidion-cartlannbhothar-simcionnfh_c21856363_21856368_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/1025/20201025_rteraidion-cartlannbhothar-sendehra_c21856364_21856369_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/1018/20201018_rteraidion-cartlannbhothar-cartlannbh_c21854576_21854577_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/1011/20201011_rteraidion-cartlannbhothar-cartlannbh_c21849866_21849867_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/0927/20200927_rteraidion-cartlannbhothar-cartlannbh_c21842121_21842122_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/0920/20200920_rteraidion-cartlannbhothar-cartlannbh_c21837633_21837637_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/0920/20200920_rteraidion-cartlannbhothar-cearnaigha_c21837634_21837638_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/0920/20200920_rteraidion-cartlannbhothar-mirenshcai_c21837635_21837639_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/0920/20200920_rteraidion-cartlannbhothar-donnchasha_c21837636_21837640_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-irisaniar-irisaniard_c21988256_21988263_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-irisaniar-andrneasan_c21988260_21988264_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-irisaniar-michaelfra_c21988261_21988265_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-irisaniar-senbnbreat_c21988262_21988266_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-irisaniar-irisaniard_c21987809_21987816_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-irisaniar-caomhnmacc_c21987811_21987817_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-irisaniar-deborahugh_c21987812_21987818_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-irisaniar-barrafthar_c21987813_21987819_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-irisaniar-pidtombnbr_c21987814_21987820_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-irisaniar-senbnbreat_c21987815_21987821_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-irisaniar-irisaniard_c21987335_21987342_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-irisaniar-mirnurinne_c21987336_21987343_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-irisaniar-angardabib_c21987337_21987344_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-irisaniar-bernienche_c21987338_21987345_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-irisaniar-senbnbreat_c21987339_21987346_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-irisaniar-aifrickeog_c21987341_21987347_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-irisaniar-tomsmaccon_c21986984_21986993_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-irisaniar-senbnbreat_c21986985_21986994_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0726/20210726_rteraidion-irisaniar-jimkeoghat_c21986327_21986332_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0726/20210726_rteraidion-irisaniar-breanndnbe_c21986328_21986333_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0726/20210726_rteraidion-irisaniar-chloenmhil_c21986329_21986334_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0726/20210726_rteraidion-irisaniar-senbnbreat_c21986330_21986335_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-irisaniar-irisaniard_c21984136_21984146_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-irisaniar-michelsmac_c21984137_21984147_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-irisaniar-desmondfen_c21984141_21984148_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-irisaniar-maryseoigh_c21984145_21984149_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-irisaniar-antollamhc_c21982413_21982417_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-irisaniar-michelsmac_c21982414_21982418_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-irisaniar-siobhnngha_c21982415_21982419_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-irisaniar-angardamic_c21982416_21982420_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-irisaniar-antiriseoi_c21981925_21981928_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-irisaniar-tomsruairc_c21981926_21981929_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-irisaniar-jenniferni_c21981927_21981930_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0713/20210713_rteraidion-irisaniar-endacongha_c21981362_21981365_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0713/20210713_rteraidion-irisaniar-bredanmhui_c21981363_21981366_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0713/20210713_rteraidion-irisaniar-bairbrenic_c21981364_21981367_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-irisaniar-geariddevn_c21980815_21980818_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-irisaniar-ritagibbon_c21980816_21980819_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-irisaniar-donnchamac_c21980817_21980820_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0702/20210702_rteraidion-irisaniar-irisaniard_c21976845_21976851_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0702/20210702_rteraidion-irisaniar-mairadfarr_c21976846_21976852_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0702/20210702_rteraidion-irisaniar-franorourk_c21976847_21976853_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0702/20210702_rteraidion-irisaniar-deirdrendh_c21976850_21976854_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0701/20210701_rteraidion-irisaniar-irisaniard_c21976185_21976215_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0701/20210701_rteraidion-irisaniar-deirdrensh_c21976211_21976216_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0701/20210701_rteraidion-irisaniar-pdraigmacd_c21976212_21976217_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0701/20210701_rteraidion-irisaniar-darachtuai_c21976213_21976218_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0701/20210701_rteraidion-irisaniar-muireannnd_c21976214_21976219_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0630/20210630_rteraidion-irisaniar-irisaniard_c21975584_21975593_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0630/20210630_rteraidion-irisaniar-breandnseo_c21975587_21975594_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0630/20210630_rteraidion-irisaniar-angardasti_c21975591_21975595_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0630/20210630_rteraidion-irisaniar-bridgebark_c21975592_21975596_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0625/20210625_rteraidion-irisaniar-antathairp_c21974114_21974115_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0623/20210623_rteraidion-irisaniar-pdraigloid_c21973019_21973024_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0623/20210623_rteraidion-irisaniar-colmanragh_c21973020_21973025_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0623/20210623_rteraidion-irisaniar-mairadmacc_c21973021_21973026_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0623/20210623_rteraidion-irisaniar-louisendhi_c21973022_21973027_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0623/20210623_rteraidion-irisaniar-annemarieu_c21973023_21973028_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0622/20210622_rteraidion-irisaniar-cilnneacht_c21972408_21972413_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0622/20210622_rteraidion-irisaniar-johnconnol_c21972409_21972414_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0622/20210622_rteraidion-irisaniar-ruairnillb_c21972410_21972415_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0622/20210622_rteraidion-irisaniar-inenfhgart_c21972411_21972416_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0622/20210622_rteraidion-irisaniar-samusrchin_c21972412_21972417_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0618/20210618_rteraidion-irisaniar-colmcuaiga_c21969857_21969862_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0618/20210618_rteraidion-irisaniar-brianstaun_c21969858_21969863_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0618/20210618_rteraidion-irisaniar-mirtncathi_c21969859_21969864_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0618/20210618_rteraidion-irisaniar-frankfahyc_c21969860_21969865_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0617/20210617_rteraidion-irisaniar-johnbhabaj_c21969299_21969318_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0617/20210617_rteraidion-irisaniar-fergusmacs_c21969300_21969319_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0617/20210617_rteraidion-irisaniar-donnchahal_c21969301_21969320_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0617/20210617_rteraidion-irisaniar-aislingnic_c21969302_21969321_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0616/20210616_rteraidion-irisaniar-mireumhaol_c21968788_21968792_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0616/20210616_rteraidion-irisaniar-orladebrca_c21968789_21968793_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0616/20210616_rteraidion-irisaniar-angardasal_c21968790_21968794_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0615/20210615_rteraidion-irisaniar-daramaoild_c21968302_21968307_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0615/20210615_rteraidion-irisaniar-emernrogin_c21968303_21968308_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0615/20210615_rteraidion-irisaniar-mirenneach_c21968304_21968309_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0615/20210615_rteraidion-irisaniar-edelnchurr_c21968305_21968310_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0614/20210614_rteraidion-irisaniar-samusbreat_c21967529_21967533_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0614/20210614_rteraidion-irisaniar-daramcgees_c21967530_21967534_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0611/20210611_rteraidion-irisaniar-aoifepower_c21966698_21966703_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0611/20210611_rteraidion-irisaniar-barryfthar_c21966699_21966704_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0611/20210611_rteraidion-irisaniar-lasairfhon_c21966700_21966705_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0611/20210611_rteraidion-irisaniar-andrsiobhn_c21966701_21966706_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0611/20210611_rteraidion-irisaniar-martndonnc_c21966702_21966707_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0610/20210610_rteraidion-irisaniar-inenchiari_c21966108_21966111_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0610/20210610_rteraidion-irisaniar-senhanaigh_c21966109_21966112_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0610/20210610_rteraidion-irisaniar-gearidcrib_c21966110_21966113_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0608/20210608_rteraidion-irisaniar-mireineuai_c21964956_21964960_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0608/20210608_rteraidion-irisaniar-cilliandon_c21964957_21964961_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-tusaite-tsite29721_c21988022_21988036_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-tusaite-tsitetuara_c21988023_21988037_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-tusaite-tsitepolai_c21988024_21988038_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-tusaite-tsiterbuai_c21988025_21988039_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-tusaite-tsitecscir_c21988026_21988040_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-tusaite-tsitemrnal_c21988027_21988041_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-tusaite-tsitemrnan_c21988028_21988042_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-tusaite-tsite28721_c21987525_21987533_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-tusaite-tsitenasco_c21987526_21987534_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-tusaite-tsitepolai_c21987527_21987535_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-tusaite-tsiteceapa_c21987528_21987536_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-tusaite-tsitegarch_c21987529_21987537_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-tusaite-tsitejoeca_c21987530_21987538_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-tusaite-tsiteansca_c21987531_21987539_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-tusaite-tsitemrnam_c21987532_21987540_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-tusaite-tsite27721_c21987049_21987054_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-tusaite-tsitepolai_c21987050_21987055_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-tusaite-tsitevacsa_c21987051_21987056_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-tusaite-tsitecosdo_c21987052_21987057_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-tusaite-tsiteanpai_c21987053_21987058_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0726/20210726_rteraidion-tusaite-tsite26721_c21986532_21986536_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0726/20210726_rteraidion-tusaite-tsiteathos_c21986533_21986537_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0726/20210726_rteraidion-tusaite-tsitevacsa_c21986534_21986538_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0726/20210726_rteraidion-tusaite-tsitebagai_c21986535_21986539_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-tusaite-tsite23721_c21985898_21985905_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-tusaite-tsitepolai_c21985899_21985906_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-tusaite-tsitetreoi_c21985900_21985907_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-tusaite-tsitefiosr_c21985901_21985908_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-tusaite-tsitesilsi_c21985902_21985909_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-tusaite-tsitescalt_c21985903_21985910_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-tusaite-tsitecrsas_c21985904_21985911_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-tusaite-tsite22721_c21985214_21985221_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-tusaite-tsitepolai_c21985215_21985222_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-tusaite-tsitedeacr_c21985216_21985223_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-tusaite-tsitenuach_c21985217_21985224_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-tusaite-tsitecluic_c21985218_21985225_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-tusaite-tsiteleasu_c21985219_21985226_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-tusaite-tsitemrnan_c21985220_21985227_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-tusaite-tsite21721_c21984807_21984814_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-tusaite-tsitepolai_c21984808_21984815_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-tusaite-tsitebsdes_c21984809_21984816_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-tusaite-tsiteathos_c21984810_21984817_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-tusaite-tsiteleasu_c21984811_21984818_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-tusaite-tsitemrnam_c21984812_21984819_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-tusaite-tsitemrnal_c21984813_21984820_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-tusaite-tsite20721_c21984357_21984363_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-tusaite-tsitedeaai_c21984358_21984364_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-tusaite-tsitepolai_c21984359_21984365_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-tusaite-tsitereach_c21984360_21984366_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-tusaite-tsiteancoi_c21984361_21984367_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-tusaite-tsiteanpai_c21984362_21984368_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-tusaite-tsite19721_c21983790_21983795_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-tusaite-tsitemaols_c21983791_21983796_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-tusaite-tsitedeire_c21983792_21983797_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-tusaite-tsiteeasao_c21983793_21983798_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-tusaite-tsitebsdea_c21983794_21983799_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0716/20210716_rteraidion-tusaite-tsite16721_c21983160_21983166_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0716/20210716_rteraidion-tusaite-tsitepolai_c21983161_21983167_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0716/20210716_rteraidion-tusaite-tsiteceart_c21983162_21983168_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0716/20210716_rteraidion-tusaite-tsitesilsi_c21983163_21983169_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0716/20210716_rteraidion-tusaite-tsitescalt_c21983164_21983170_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0716/20210716_rteraidion-tusaite-tsitecrsas_c21983165_21983171_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-tusaite-tsite15721_c21982632_21982639_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-tusaite-tsitepolai_c21982633_21982640_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-tusaite-tsitelonna_c21982634_21982641_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-tusaite-tsitedroch_c21982635_21982642_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-tusaite-tsitemrnal_c21982636_21982643_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-tusaite-tsitemrnan_c21982637_21982644_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-tusaite-tsitedeaai_c21982638_21982645_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-tusaite-tsite14721_c21982121_21982127_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-tusaite-tsitepolai_c21982122_21982128_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-tusaite-tsiteconco_c21982123_21982129_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-tusaite-tsitereach_c21982124_21982130_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-tusaite-tsitetarma_c21982125_21982131_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-tusaite-tsitemrnam_c21982126_21982132_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0713/20210713_rteraidion-tusaite-tsite13721_c21981552_21981558_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0713/20210713_rteraidion-tusaite-tsitepolai_c21981553_21981559_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0713/20210713_rteraidion-tusaite-tsiteathos_c21981554_21981560_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0713/20210713_rteraidion-tusaite-tsitebreat_c21981555_21981561_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0713/20210713_rteraidion-tusaite-tsitesaigh_c21981556_21981562_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0713/20210713_rteraidion-tusaite-tsiteanpai_c21981557_21981563_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-tusaite-tsite12721_c21981073_21981093_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-tusaite-tsiteathos_c21981074_21981094_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-tusaite-tsitestdas_c21981075_21981095_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-tusaite-tsiteandar_c21981076_21981096_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-tusaite-tsitenaeur_c21981077_21981097_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-tusaite-tsite9721_c21980451_21980457_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-tusaite-tsitefotho_c21980452_21980458_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-tusaite-tsitepolai_c21980453_21980459_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-tusaite-tsitesilsi_c21980454_21980460_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0706/20210706_rteraidion-ancheadghluineile-clr3tinnch_c21978343_21978617_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0629/20210629_rteraidion-ancheadghluineile-clr2aedrae_c21977827_21977828_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0622/20210622_rteraidion-ancheadghluineile-clr1evelyn_c21973179_21975128_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-aistionaer-antidsceas_c21985799_21985809_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-aistionaer-oilithreac_c21985800_21985810_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-aistionaer-seandaoine_c21985801_21985811_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-aistionaer-mchmagusla_c21985802_21985812_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-aistionaer-seanlitrea_c21985803_21985813_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0724/20210724_rteraidion-bailiuchanbhairbre-bailichnbh_c21986295_21986296_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0717/20210717_rteraidion-bailiuchanbhairbre-clr6cuairt_c21984170_21984171_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0710/20210710_rteraidion-bailiuchanbhairbre-clr5btharg_c21981049_21981050_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0703/20210703_rteraidion-bailiuchanbhairbre-clr4anscoi_c21977529_21977530_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0626/20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0619/20210619_rteraidion-bailiuchanbhairbre-bailichnbh_c21971319_21975130_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0612/20210612_rteraidion-bailiuchanbhairbre-bailichnbh_c21967481_21975129_232_.mp3 .",
            "url": "https://jimregan.github.io/notes/irish/kaggle/dataset/2021/08/01/rnag-podchraoltai.html",
            "relUrl": "/irish/kaggle/dataset/2021/08/01/rnag-podchraoltai.html",
            "date": " â€¢ Aug 1, 2021"
        }
        
    
  
    
        ,"post119": {
            "title": "Unpack Swedish Gigaword",
            "content": "Original on Kaggle . !for i in ../input/download-swedish-gigaword/*.tar;do tar xvf $i;done .",
            "url": "https://jimregan.github.io/notes/kaggle/swedish/incomplete/2021/07/31/unpack-swedish-gigaword.html",
            "relUrl": "/kaggle/swedish/incomplete/2021/07/31/unpack-swedish-gigaword.html",
            "date": " â€¢ Jul 31, 2021"
        }
        
    
  
    
        ,"post120": {
            "title": "Soundcloud - Foras na Gaeilge",
            "content": "Original on Kaggle (private) . !pip install youtube-dl !youtube-dl https://soundcloud.com/forasnagaeilge .",
            "url": "https://jimregan.github.io/notes/kaggle/irish/soundcloud/dataset/unlabelled/forasnagaeilge/2021/07/31/soundcloud-foras-na-gaeilge.html",
            "relUrl": "/kaggle/irish/soundcloud/dataset/unlabelled/forasnagaeilge/2021/07/31/soundcloud-foras-na-gaeilge.html",
            "date": " â€¢ Jul 31, 2021"
        }
        
    
  
    
        ,"post121": {
            "title": "Download Swedish Gigaword",
            "content": "Original on Kaggle . !wget http://spraakbanken.gu.se/lb/resurser/meningsmangder/gigaword-1950-59.tar !wget http://spraakbanken.gu.se/lb/resurser/meningsmangder/gigaword-1960-69.tar !wget http://spraakbanken.gu.se/lb/resurser/meningsmangder/gigaword-1970-79.tar !wget http://spraakbanken.gu.se/lb/resurser/meningsmangder/gigaword-1980-89.tar !wget http://spraakbanken.gu.se/lb/resurser/meningsmangder/gigaword-1990-99.tar !wget http://spraakbanken.gu.se/lb/resurser/meningsmangder/gigaword-2000-09.tar !wget http://spraakbanken.gu.se/lb/resurser/meningsmangder/gigaword-2010-15.tar .",
            "url": "https://jimregan.github.io/notes/swedish/kaggle/2021/07/31/download-swedish-gigaword.html",
            "relUrl": "/swedish/kaggle/2021/07/31/download-swedish-gigaword.html",
            "date": " â€¢ Jul 31, 2021"
        }
        
    
  
    
        ,"post122": {
            "title": "Github asset release from Colab",
            "content": "!pip install -q condacolab import condacolab condacolab.install() . â¬ Downloading https://github.com/jaimergp/miniforge/releases/latest/download/Mambaforge-colab-Linux-x86_64.sh... ðŸ“¦ Installing... ðŸ“Œ Adjusting configuration... ðŸ©¹ Patching environment... â² Done in 0:00:44 ðŸ” Restarting kernel... . !conda install gh --channel conda-forge . !pip install youtube-dl . !youtube-dl -i --write-sub --sub-lang ga -o &#39;%(id)s.%(ext)s&#39; PLbcLsUBW9b3BvuTbtMKBXmuyJq6Ygg3Rg . !ls ./*.vtt|zip subtitles.zip -@ . from google.colab import files files.download(&#39;subtitles.zip&#39;) . !ls ./*.mp4 ./*.mkv |zip videos.zip -@ . !echo $KEY |gh auth login --with-token . !git clone $REPO . %cd $REPO . !gh release upload v0.1 ../videos.zip . Successfully uploaded 1 asset to v0.1 .",
            "url": "https://jimregan.github.io/notes/github/colab/2021/07/30/github-release-from-colab.html",
            "relUrl": "/github/colab/2021/07/30/github-release-from-colab.html",
            "date": " â€¢ Jul 30, 2021"
        }
        
    
  
    
        ,"post123": {
            "title": "ICU RBNF format in Python",
            "content": "%%capture !pip install pyicu . import icu formatter = icu.RuleBasedNumberFormat(icu.URBNFRuleSetTag.SPELLOUT, icu.Locale(&#39;ga&#39;)) formatter.format(23) . &#39;fiche a trÃ­&#39; .",
            "url": "https://jimregan.github.io/notes/irish/icu/rbnf/2021/07/22/icu-rbnf-format.html",
            "relUrl": "/irish/icu/rbnf/2021/07/22/icu-rbnf-format.html",
            "date": " â€¢ Jul 22, 2021"
        }
        
    
  
    
        ,"post124": {
            "title": "Getting lmt to work",
            "content": "tl;dr -- lmt needs there to be either: . markdown after the last file piece | two newline characters | . !git clone https://github.com/driusan/lmt . fatal: destination path &#39;lmt&#39; already exists and is not an empty directory. . %cd lmt . /content/lmt . %%capture !apt install golang . !go build . import os os.environ[&#39;PATH&#39;] = f&#39;{os.environ[&quot;PATH&quot;]}:/content/lmt&#39; . %cd /content . /content . %%writefile test.go.md # Thing go test.go package main import ( fmt ) . Overwriting test.go.md . !lmt test.go.md . !cat test.go . cat: test.go: No such file or directory . %%writefile test2.go.md # Thing go test2.go package main import ( fmt ) . Overwriting test2.go.md . !lmt test2.go.md . !cat test2.go . cat: test2.go: No such file or directory . %%writefile test3.go.md # Thing go test3.go package main import ( fmt ) # Blah . Writing test3.go.md . !lmt test3.go.md !cat test3.go . //line test3.go.md:4 package main import ( fmt ) . %%writefile test4.go.md # Thing go test4.go package main import ( fmt ) . Writing test4.go.md . !lmt test4.go.md !cat test4.go . //line test4.go.md:4 package main import ( fmt ) .",
            "url": "https://jimregan.github.io/notes/lmt/2021/07/22/getting-lmt-to-work.html",
            "relUrl": "/lmt/2021/07/22/getting-lmt-to-work.html",
            "date": " â€¢ Jul 22, 2021"
        }
        
    
  
    
        ,"post125": {
            "title": "Render offline map with ipyleaflet and ipywebrtc",
            "content": "%%capture !pip install ipyleaflet ipywebrtc . from ipyleaflet import * thurles_point = (52.6801064,-7.804442099999999) thurles = Map(center=(52.8001064,-7.804442099999999), zoom=8, basemap=basemaps.Esri.DeLorme) marker = Marker(location=thurles_point, draggable=False) thurles.add_layer(marker) . The map needs to be rendered for ipywebrtc to work . thurles . from ipywebrtc import WidgetStream, ImageRecorder thurles_stream = WidgetStream(widget=thurles, max_fps=1) . thurles_img = ImageRecorder(stream=thurles_stream) thurles_img.recording = True thurles_img.autosave = False thurles_img.download() . import PIL.Image import PIL.ImageFilter import io thurles_pil = PIL.Image.open(io.BytesIO(thurles_img.image.value)) . thurles_pil .",
            "url": "https://jimregan.github.io/notes/ipyleaflet/ipywebrtc/map/2021/07/15/ipyleaflet-and-ipywebrtc.html",
            "relUrl": "/ipyleaflet/ipywebrtc/map/2021/07/15/ipyleaflet-and-ipywebrtc.html",
            "date": " â€¢ Jul 15, 2021"
        }
        
    
  
    
        ,"post126": {
            "title": "Swedish data from nb.no",
            "content": "Original on Kaggle (private) . !wget https://www.nb.no/sbfil/talegjenkjenning/22kHz/sv.22khz.txt.tar.gz . !tar zxvf sv.22khz.txt.tar.gz . !cat ./txt/dsm_txt/sw_mod_010.txt . !wget https://www.nb.no/sbfil/talegjenkjenning/16kHz_2020/se_2020/lydfiler_16_1.tar.gz . !tar zxvf lydfiler_16_1.tar.gz . !wget https://www.nb.no/sbfil/talegjenkjenning/16kHz_2020/se_2020/ADB_SWE_0467.tar.gz . !tar zxvf ADB_SWE_0467.tar.gz . !wget http://www.nb.no/sbfil/talegjenkjenning/16kHz/sve.16khz.0467-1.tar.gz . !tar zxvf sve.16khz.0467-1.tar.gz . !wget https://www.nb.no/sbfil/talesyntese/sve.ibm.talesyntese.tar.gz . !tar zxvf sve.ibm.talesyntese.tar.gz . !cat se10x016-08071999-1334_r4670016.json . ls -al se/se16x735-04111999-1559/se16x735-04111999-1559_u0107303-1.wav .",
            "url": "https://jimregan.github.io/notes/kaggle/swedish/incomplete/2021/07/09/nbno-swedish-data-links.html",
            "relUrl": "/kaggle/swedish/incomplete/2021/07/09/nbno-swedish-data-links.html",
            "date": " â€¢ Jul 9, 2021"
        }
        
    
  
    
        ,"post127": {
            "title": "Syllabify Phonetisaurus output",
            "content": "def is_schwa(phone, is_timit=True): if is_timit: return phone in [&quot;ax&quot;, &quot;axr&quot;, &quot;ix&quot;] else: return phone == &quot;AH0&quot; # CMUdict doesn&#39;t have syllabic consonants def is_syllabic_consonant(phone, is_timit=True): SYLLC = [&quot;el&quot;, &quot;em&quot;, &quot;en&quot;, &quot;er&quot;, &quot;er1&quot;, &quot;er2&quot;] if is_timit and phone in SYLLC: return True else: return False def is_vowel(phone): VOWELS = [&quot;aa&quot;, &quot;ae&quot;, &quot;ah&quot;, &quot;ao&quot;, &quot;aw&quot;, &quot;ax&quot;, &quot;axr&quot;, &quot;ay&quot;, &quot;eh&quot;, &quot;ey&quot;, &quot;ih&quot;, &quot;ix&quot;, &quot;iy&quot;, &quot;ow&quot;, &quot;oy&quot;, &quot;uh&quot;, &quot;uw&quot;] if phone[-1] in &quot;012&quot;: return phone[:-1].lower() in VOWELS else: return phone.lower() in VOWELS def is_vocalic(phone): return is_vowel(phone) or is_syllabic_consonant(phone) # http://web.archive.org/web/20100614180508/http://semarch.linguistics.fas.nyu.edu/barker/Syllables/syllabify.pl def sonority(phone): STOPS = [&quot;p&quot;, &quot;b&quot;, &quot;t&quot;, &quot;d&quot;, &quot;k&quot;, &quot;g&quot;] AFFRICATES = [&quot;ch&quot;, &quot;jh&quot;] FRICATIVES = [&quot;th&quot;, &quot;dh&quot;, &quot;f&quot;, &quot;v&quot;, &quot;s&quot;, &quot;z&quot;, &quot;sh&quot;, &quot;zh&quot;] NASALS = [&quot;m&quot;, &quot;n&quot;, &quot;ng&quot;] LIQUIDS = [&quot;l&quot;, &quot;r&quot;] GLIDES = [&quot;w&quot;, &quot;y&quot;] # &#39;s&#39; is special if phone == &quot;s&quot;: return 1 elif phone in STOPS: return 1 elif phone in AFFRICATES: return 2 elif phone in FRICATIVES: return 3 elif phone in NASALS: return 4 elif phone in LIQUIDS: return 5 elif phone == &quot;hh&quot;: return 6 elif phone in GLIDES: return 6 else: return 7 . def last_phoneme(graphone): grapheme, phoneme = graphone.split(&#39;}&#39;) return phoneme.split(&#39;|&#39;)[-1] def first_phoneme(graphone): grapheme, phoneme = graphone.split(&#39;}&#39;) return phoneme.split(&#39;|&#39;)[0] . assert last_phoneme(&#39;x}e|k|s&#39;) == &#39;s&#39; assert first_phoneme(&#39;x}e|k|s&#39;) == &#39;e&#39; . def voicing_mismatch(phone1, phone2): VOICED = [&quot;b&quot;, &quot;d&quot;, &quot;g&quot;, &quot;jh&quot;, &quot;dh&quot;, &quot;v&quot;, &quot;z&quot;, &quot;zh&quot;] DEVOICED = [&quot;p&quot;, &quot;t&quot;, &quot;k&quot;, &quot;ch&quot;, &quot;th&quot;, &quot;f&quot;, &quot;s&quot;, &quot;sh&quot;] if phone1 in VOICED and phone2 in DEVOICED: return True elif phone2 in VOICED and phone1 in DEVOICED: return True else: return False . def merge_graphones(graphones): graphemes = [] phonemes = [] for graphone in graphones: graphemes_string, phonemes_string = graphone.split(&#39;}&#39;) cur_graphemes = graphemes_string.split(&#39;|&#39;) cur_phonemes = phonemes_string.split(&#39;|&#39;) graphemes += cur_graphemes phonemes += cur_phonemes if len(graphemes) &gt; 1: pruned_graphemes = [a for a in graphemes if a != &#39;_&#39;] if len(pruned_graphemes) == 0: pruned_graphemes = [&#39;_&#39;] else: pruned_graphemes = graphemes if len(phonemes) &gt; 1: pruned_phonemes = [a for a in phonemes if a != &#39;_&#39;] if len(pruned_phonemes) == 0: pruned_phonemes = [&#39;_&#39;] else: pruned_phonemes = phonemes return &#39;}&#39;.join((&#39;|&#39;.join(pruned_graphemes), &#39;|&#39;.join(pruned_phonemes))) . assert merge_graphones(&quot;a}a t|h}th x}k|s&quot;.split(&#39; &#39;)) == &#39;a|t|h|x}a|th|k|s&#39; assert merge_graphones(&quot;a}a t|h}th x}k|s e}_&quot;.split(&#39; &#39;)) == &#39;a|t|h|x|e}a|th|k|s&#39; assert merge_graphones(&quot;a}_ t|h}_ x}_ e}_&quot;.split(&#39; &#39;)) == &#39;a|t|h|x|e}_&#39; assert merge_graphones(&quot;_}a _}th _}k|s&quot;.split(&#39; &#39;)) == &#39;_}a|th|k|s&#39; . def syllabify(graphones): sonority_up = True last_sonority_up = True last_sonority = 0 isvowel = False last_isvowel = False saw_vowel = False stack = [] output = [] last_phoneme = &quot;&quot; labials = [&quot;p&quot;, &quot;b&quot;, &quot;m&quot;, &quot;f&quot;, &quot;v&quot;] s_sh = [&quot;s&quot;, &quot;sh&quot;] for graphone in graphones[::-1]: phoneme = first_phoneme(graphone) phone_sonority = sonority(phoneme) isvowel = is_vocalic(phoneme) sonority_up = last_sonority &lt; phone_sonority # For timit if graphone == &#39;_&#39;: stack.append(graphone) continue if last_sonority == 3 and phone_sonority == 1: sonority_up = True if last_phoneme == &#39;w&#39; and phoneme in labials: last_sonority_up = False sonority_up = True if last_phoneme == &quot;m&quot; and not sonority_up and not phoneme in s_sh: last_sonority_up = False sonority_up = True if phoneme == &quot;m&quot; and not sonority_up and last_sonority &lt; 7: last_sonority_up = False sonority_up = True if phoneme == &quot;n&quot; and not sonority_up and last_sonority &lt; 6: last_sonority_up = False sonority_up = True if last_phoneme == &quot;m&quot; and not sonority_up and not phoneme in s_sh: last_sonority_up = False sonority_up = True if not sonority_up and phoneme == &quot;ng&quot;: last_sonority_up = False sonority_up = True if last_sonority == 7 and phone_sonority == 7: last_sonority_up = True sonority_up = True if sonority_up and last_sonority == 1 and sonority == 1 and phoneme != &quot;s&quot;: sonority_up = True # avoid bs/ps onsets if last_phoneme in [&quot;s&quot;, &quot;sh&quot;, &quot;z&quot;, &quot;zh&quot;] and phoneme in &quot;bp&quot;: last_sonority_up = False sonority_up = True if last_phoneme == &#39;l&#39; and phoneme in [&#39;d&#39;, &#39;t&#39;, &#39;dh&#39;, &#39;th&#39;]: last_sonority_up = False sonority_up = True def splitsyll(): if not saw_vowel: return False if isvowel and saw_vowel: return True if last_isvowel and isvowel: return True if voicing_mismatch(phoneme, last_phoneme): return True if not last_sonority_up and sonority_up: return True return False if splitsyll(): output.append(merge_graphones(stack[::-1])) stack = [] saw_vowel = False stack.append(graphone) last_sonority_up = sonority_up last_phoneme = phoneme last_sonority = phone_sonority last_isvowel = isvowel saw_vowel = saw_vowel or isvowel output.append(merge_graphones(stack[::-1])) return output[::-1] . assert syllabify(&#39;a}ax b}b o|u}aw1 t}t&#39;.split(&#39; &#39;)) == [&#39;a}ax&#39;, &#39;b|o|u|t}b|aw1|t&#39;] . with open(&#39;TIMIT.clean.corpus&#39;, &#39;r&#39;) as f, open(&#39;TIMIT.syllable.corpus&#39;, &#39;w&#39;) as of: for line in f.readlines(): graphones = line.split(&#39; &#39;) syll = syllabify(graphones) print(&#39; &#39;.join(syll), file=of) .",
            "url": "https://jimregan.github.io/notes/colab/timit/phonetisaurus/syllabification/2021/07/03/syllabify-phonetisaurus-output.html",
            "relUrl": "/colab/timit/phonetisaurus/syllabification/2021/07/03/syllabify-phonetisaurus-output.html",
            "date": " â€¢ Jul 3, 2021"
        }
        
    
  
    
        ,"post128": {
            "title": "Run phonetisaurus on TIMIT",
            "content": "The first few cells set up phonetisaurus; they are adapted from the instructions in the git README. . %%capture !apt-get -y install git g++ autoconf-archive make libtool # Python bindings !apt-get -y install python-setuptools python-dev # mitlm (to build a quick play model) !apt-get -y install gfortran . %%capture !wget http://www.openfst.org/twiki/pub/FST/FstDownload/openfst-1.6.2.tar.gz !tar -xvzf openfst-1.6.2.tar.gz %cd openfst-1.6.2 # Minimal configure, compatible with current defaults for Kaldi !./configure --enable-static --enable-shared --enable-far --enable-ngram-fsts !make -j 4 # Now wait a while... !make install . import os ldlibpath = os.environ[&#39;LD_LIBRARY_PATH&#39;] #_STORED_LD = &quot;/usr/local/nvidia/lib:/usr/local/nvidia/lib64&quot; newld = f&#39;{ldlibpath}:/usr/local/lib:/usr/local/lib/fst&#39; os.environ[&#39;LD_LIBRARY_PATH&#39;]=newld %env LD_LIBRARY_PATH . &#39;/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/lib:/usr/local/lib/fst&#39; . %%capture %cd /content !git clone https://github.com/AdolfVonKleist/Phonetisaurus.git %cd Phonetisaurus !./configure !make !make install . %cd /content/ . /content . We also need MITLM . %%capture !git clone https://github.com/mitlm/mitlm %cd mitlm !autoreconf -i !./configure !make !make install . %cd /content . /content . The TIMIT dictionary is relatively clean, so there are only a few small changes that are needed for phonetisaurus. . !cat TIMITDIC.txt|grep -v &#39;^;&#39;|tr -d &#39;/&#39;|sed -e &#39;s/ */ /g;s/~adj//;s/~v_past//;s/~v_pres//;s/~v//;s/~n//;&#39; &gt; TIMIT.cleaned !cat TIMIT.cleaned | perl -pe &#39;s/ s+/ /g; s/^ s+//; s/ s+$//; @_ = split (/ s+/); $w = shift (@_); $_ = $w.&quot; t&quot;.join (&quot; &quot;, @_).&quot; n&quot;;&#39; &gt; TIMIT.clean . !phonetisaurus-align --input=TIMIT.clean --ofile=TIMIT.clean.corpus --seq1_del=false . GitRevision: 0.9.1 Loading input file: TIMIT.clean Alignment failed: x Starting EM... Finished first iter... Iteration: 1 Change: 2.70318 Iteration: 2 Change: 0.0603504 Iteration: 3 Change: 0.0425539 Iteration: 4 Change: 0.0206814 Iteration: 5 Change: 0.0114756 Iteration: 6 Change: 0.00711536 Iteration: 7 Change: 0.0042429 Iteration: 8 Change: 0.00297546 Iteration: 9 Change: 0.00223923 Iteration: 10 Change: 0.00151825 Iteration: 11 Change: 0.00115204 Last iteration: 0.001 Loading corpus TIMIT.clean.corpus... 0.037 Smoothing[1] = ModKN 0.037 Smoothing[2] = ModKN 0.037 Smoothing[3] = ModKN 0.037 Smoothing[4] = ModKN 0.037 Smoothing[5] = ModKN 0.037 Smoothing[6] = ModKN 0.037 Smoothing[7] = ModKN 0.037 Smoothing[8] = ModKN 0.037 Set smoothing algorithms... 0.037 Y 6.063492e-01 0.037 Y 6.304450e-01 0.037 Y 7.305669e-01 0.037 Y 7.950124e-01 0.037 Y 8.524463e-01 0.038 Y 9.033717e-01 0.038 Y 9.355036e-01 0.038 Y 9.092702e-01 0.038 Estimating full n-gram model... 0.040 Saving LM to timit.arpa... GitRevision: 0.9.1 Initializing... Converting... . That thing I just said about the TIMIT dictionary being relatively clean? Nah. There are some errors, particularly with &#39;c&#39; being transcribed as &#39;ao&#39; (which is a vowel sound). Also, the default output of phonetisaurus-align only does 1:1, 1:0, 0:1, 2:1, and 1:2 mappings of graphemes and phonemes, which means some of the alignments look quite strange. . %%writefile clean_ngrams.pl #!/usr/bin/perl # Fix some of the alignments from phonetisaurus-align to be more recognisable to humans # Also fixes some transcription errors in the TIMIT dictionary (mostly c -&gt; ao) use warnings; use strict; use utf8; my $raw_replacements = &lt;&lt;_HERE_; e}_ l}el e|l}el e}_ d}ed e|d}ed e}_ d}d e|d}d e}iy1 e}_ e|e}iy1 i}ix o|n}n i|o}ix n}n r}_ t|-}r t}t r}r t|-|t}t -|k}n n|a}ae1 -}_ k|n}n a}ae1 a|c}ax c}k a}ax c|c}k c}k h}_ c|h}k c}k q|u}w c|q}k u}w n}n|t c}s n}n c}t|s i|c}ih1 k|-}k i}ih1 c|k}k -}_ a|k}ey1 e|-}k a}ey1 k}k e|-}_ -|k}n n|a}ae2 -}_ k|n}n a}ae2 a|t}ax e}_ -|e}t y}ay1 a}ax t}t e}_ -}_ e|y}ay1 t|u}ch r}axr t}ch u|r}axr e}_ d}d e|d}d a}ae1 e}_ a|e}ae1 a}ih e}_ a|e}ih -|c}ao -}_ c}k x}eh1|k -}s x}eh1|k|s -}_ e}_ l|l}el e|l|l}el w|h}hh y}w|ay1 w|h}hh|w y}ay1 a|d}ax j|o}jh u|r}er1 a}ax d|j}jh o|u|r}er1 a|d}ae2 u}jh|uw a}ae2 d}jh u}uw u}y|uh a|b}b u|a}y|uh b}b x}k -}s x}k|s -}_ u|r}er1 r}_ u|r|r}er1 o|r}axr r}_ o|r|r}axr u|r}axr r}_ u|r|r}axr e|r}axr r}_ e|r|r}axr a|r}axr r}_ h|o}iy1 e}_ a|r|r|h}axr o|e}iy1 e|r}er r}_ e|r|r}er i|r}er1 r}_ i|r|r}er1 u}_ a}aa1 u|a}aa1 w|h}hh i}w|er1 r}_ w|h}hh|w i|r}er1 b|o}b r}r b}b o|r}r e}_ a|r}er1 e|a|r}er1 q|u}k a}w|ey2 q}k u}w a}ey2 q|u}k a}w|ao1 q}k u}w a}ao1 w|h}hh a}w|ax w|h}hh|w a}ax t|u}ch r}axr t}ch u|r}axr d|u}jh a}uw|ax d}jh u}uw a}ax c|i}sh a}iy|ey2 c}sh i}iy a}ey2 i}ix a|t}t i|a}ix t}t w|h}hh e}w|iy1 a|t}t w|h}hh|w e|a}iy1 t}t q|u}k a}w|aa1 q}k u}w a}aa1 q|u}k a}w|ao2 q}k u}w a}ao2 q|u}k a}w|ae1 q}k u}w a}ae1 w|h}hh a}w|aa1 w|h}hh|w a}aa1 w|h}hh a}w|aa2 w|h}hh|w a}aa2 w|h}hh e}w|ae1 w|h}hh|w a}ae1 w|h}hh e}w|ae2 w|h}hh|w a}ae2 w|h}hh i}w|ay1 w|h}hh|w a}ay1 w|h}hh o}w|aa1 w|h}hh|w o}aa1 y|a}y c|h}aa1 t}t y}y a}aa1 c|h}_ t}t i}iy1 e}_ i|e}iy1 m|a}m &#39;}_ a}ae1 m}m a|&#39;|a}ae1 g|u}g e}_ g}g u|e}_ r}r h}_ r|h}r s}z s|a}ix s|s}z a}ix _HERE_ my %replacements = (); for my $rl (split(&#39; n&#39;, $raw_replacements)) { next if($rl !~ / t/); my @tmp = split(/ t/, $rl); $replacements{$tmp[0]} = $tmp[1]; } my $regex_inner = join(&#39;|&#39;, map { quotemeta $_ } keys %replacements); while(&lt;&gt;) { chomp; while(/(?:^| )($regex_inner)(?:$| )/g) { my $m = $1; my $qm = quotemeta($m); s/$qm/$replacements{$m}/; } my @phns = split/ /; my @out = (); for my $phn (@phns) { if($phn =~ /^([-&#39;]) |/) { my $ch = $1; push @out, &quot;$ch}_&quot;; push @out, substr($phn,2); } elsif($phn =~ /^([^ |]) |([-&#39;]) }(.*)$/) { my $ch1 = $1; my $ch2 = $2; my $ch3 = $3; push @out, &quot;$ch1}$ch3&quot;; push @out, &quot;$ch2}_&quot;; } elsif($phn eq &#39;c}ao&#39;) { if($phns[0] eq &#39;n}n&#39;) { push @out, &#39;c}s&#39;; } else { push @out, &#39;c}k&#39;; } } else { push @out, $phn; } } print join(&#39; &#39;, @out) . &quot; n&quot;; } . Writing clean_ngrams.pl . !cat TIMIT.clean.corpus | perl clean_ngrams.pl &gt; TIMIT.cleaner.corpus . !estimate-ngram -o 8 -t TIMIT.cleaner.corpus -wl timit.arpa # Convert to OpenFst format (10s-20s): !phonetisaurus-arpa2wfst --lm=timit.arpa --ofile=timit.fst . 0.001 Loading corpus TIMIT.cleaner.corpus... 0.026 Smoothing[1] = ModKN 0.026 Smoothing[2] = ModKN 0.026 Smoothing[3] = ModKN 0.026 Smoothing[4] = ModKN 0.026 Smoothing[5] = ModKN 0.026 Smoothing[6] = ModKN 0.026 Smoothing[7] = ModKN 0.026 Smoothing[8] = ModKN 0.026 Set smoothing algorithms... 0.026 Y 6.390977e-01 0.026 Y 6.202592e-01 0.026 Y 7.251729e-01 0.026 Y 7.967686e-01 0.027 Y 8.548704e-01 0.027 Y 9.046288e-01 0.027 Y 9.354281e-01 0.027 Y 9.105453e-01 0.027 Estimating full n-gram model... 0.029 Saving LM to timit.arpa... GitRevision: 0.9.1 Initializing... Converting... . .",
            "url": "https://jimregan.github.io/notes/colab/timit/phonetisaurus/2021/07/03/run-phonetisaurus-on-timit.html",
            "relUrl": "/colab/timit/phonetisaurus/2021/07/03/run-phonetisaurus-on-timit.html",
            "date": " â€¢ Jul 3, 2021"
        }
        
    
  
    
        ,"post129": {
            "title": "Run phonetisaurus on TIMIT via Kaggle",
            "content": "Original on Kaggle . The first few cells set up phonetisaurus; they are adapted from the instructions in the git README. . %%capture !apt-get -y install git g++ autoconf-archive make libtool # Python bindings !apt-get -y install python-setuptools python-dev !apt-get -y install gfortran . %%capture %cd /tmp !wget http://www.openfst.org/twiki/pub/FST/FstDownload/openfst-1.6.2.tar.gz !tar -xvzf openfst-1.6.2.tar.gz %cd openfst-1.6.2 !./configure --enable-static --enable-shared --enable-far --enable-ngram-fsts !make -j 4 # Now wait a while... !make install . import os ldlibpath = os.environ[&#39;LD_LIBRARY_PATH&#39;] newld = f&#39;{ldlibpath}:/usr/local/lib:/usr/local/lib/fst&#39; os.environ[&#39;LD_LIBRARY_PATH&#39;]=newld %env LD_LIBRARY_PATH . &#39;/opt/conda/lib:/usr/local/lib:/usr/local/lib/fst&#39; . %%capture %cd /tmp !git clone https://github.com/AdolfVonKleist/Phonetisaurus.git %cd Phonetisaurus !./configure !make !make install . %cd /tmp/ . /tmp . We also need MITLM . %%capture !git clone https://github.com/mitlm/mitlm %cd mitlm !autoreconf -i !./configure !make !make install . %cd /kaggle/working . /kaggle/working . The TIMIT dictionary is relatively clean, so there are only a few small changes that are needed for phonetisaurus. . !cat ../input/darpa-timit-acousticphonetic-continuous-speech/TIMITDIC.TXT|grep -v &#39;^;&#39;|tr -d &#39;/&#39;|sed -e &#39;s/ */ /g;s/~adj//;s/~v_past//;s/~v_pres//;s/~v//;s/~n//;&#39; &gt; /tmp/TIMIT.cleaned !cat /tmp/TIMIT.cleaned | perl -pe &#39;s/ s+/ /g; s/^ s+//; s/ s+$//; @_ = split (/ s+/); $w = shift (@_); $_ = $w.&quot; t&quot;.join (&quot; &quot;, @_).&quot; n&quot;;&#39; &gt; /tmp/TIMIT.clean . !phonetisaurus-align --input=/tmp/TIMIT.clean --ofile=TIMIT.clean.corpus --seq1_del=false . GitRevision: 0.9.1 Loading input file: /tmp/TIMIT.clean Alignment failed: x Starting EM... Finished first iter... Iteration: 1 Change: 2.70318 Iteration: 2 Change: 0.0603504 Iteration: 3 Change: 0.0425539 Iteration: 4 Change: 0.0206814 Iteration: 5 Change: 0.0114756 Iteration: 6 Change: 0.00711536 Iteration: 7 Change: 0.0042429 Iteration: 8 Change: 0.00297546 Iteration: 9 Change: 0.00223923 Iteration: 10 Change: 0.00151825 Iteration: 11 Change: 0.00115204 Last iteration: . That thing I just said about the TIMIT dictionary being relatively clean? Nah. There are some errors, particularly with &#39;c&#39; being transcribed as &#39;ao&#39; (which is a vowel sound). Also, the default output of phonetisaurus-align only does 1:1, 1:0, 0:1, 2:1, and 1:2 mappings of graphemes and phonemes, which means some of the alignments look quite strange. . %%writefile clean_ngrams.pl #!/usr/bin/perl # Fix some of the alignments from phonetisaurus-align to be more recognisable to humans # Also fixes some transcription errors in the TIMIT dictionary (mostly c -&gt; ao) use warnings; use strict; use utf8; my $raw_replacements = &lt;&lt;_HERE_; e}_ l}el e|l}el e}_ d}ed e|d}ed e}_ d}d e|d}d e}iy1 e}_ e|e}iy1 i}ix o|n}n i|o}ix n}n r}_ t|-}r t}t r}r t|-|t}t -|k}n n|a}ae1 -}_ k|n}n a}ae1 a|c}ax c}k a}ax c|c}k c}k h}_ c|h}k c}k q|u}w c|q}k u}w n}n|t c}s n}n c}t|s i|c}ih1 k|-}k i}ih1 c|k}k -}_ a|k}ey1 e|-}k a}ey1 k}k e|-}_ -|k}n n|a}ae2 -}_ k|n}n a}ae2 a|t}ax e}_ -|e}t y}ay1 a}ax t}t e}_ -}_ e|y}ay1 t|u}ch r}axr t}ch u|r}axr e}_ d}d e|d}d a}ae1 e}_ a|e}ae1 a}ih e}_ a|e}ih -|c}ao -}_ c}k x}eh1|k -}s x}eh1|k|s -}_ e}_ l|l}el e|l|l}el w|h}hh y}w|ay1 w|h}hh|w y}ay1 a|d}ax j|o}jh u|r}er1 a}ax d|j}jh o|u|r}er1 a|d}ae2 u}jh|uw a}ae2 d}jh u}uw u}y|uh a|b}b u|a}y|uh b}b x}k -}s x}k|s -}_ u|r}er1 r}_ u|r|r}er1 o|r}axr r}_ o|r|r}axr u|r}axr r}_ u|r|r}axr e|r}axr r}_ e|r|r}axr a|r}axr r}_ h|o}iy1 e}_ a|r|r|h}axr o|e}iy1 e|r}er r}_ e|r|r}er i|r}er1 r}_ i|r|r}er1 u}_ a}aa1 u|a}aa1 w|h}hh i}w|er1 r}_ w|h}hh|w i|r}er1 b|o}b r}r b}b o|r}r e}_ a|r}er1 e|a|r}er1 q|u}k a}w|ey2 q}k u}w a}ey2 q|u}k a}w|ao1 q}k u}w a}ao1 w|h}hh a}w|ax w|h}hh|w a}ax t|u}ch r}axr t}ch u|r}axr d|u}jh a}uw|ax d}jh u}uw a}ax c|i}sh a}iy|ey2 c}sh i}iy a}ey2 i}ix a|t}t i|a}ix t}t w|h}hh e}w|iy1 a|t}t w|h}hh|w e|a}iy1 t}t q|u}k a}w|aa1 q}k u}w a}aa1 q|u}k a}w|ao2 q}k u}w a}ao2 q|u}k a}w|ae1 q}k u}w a}ae1 w|h}hh a}w|aa1 w|h}hh|w a}aa1 w|h}hh a}w|aa2 w|h}hh|w a}aa2 w|h}hh e}w|ae1 w|h}hh|w a}ae1 w|h}hh e}w|ae2 w|h}hh|w a}ae2 w|h}hh i}w|ay1 w|h}hh|w a}ay1 w|h}hh o}w|aa1 w|h}hh|w o}aa1 y|a}y c|h}aa1 t}t y}y a}aa1 c|h}_ t}t i}iy1 e}_ i|e}iy1 m|a}m &#39;}_ a}ae1 m}m a|&#39;|a}ae1 g|u}g e}_ g}g u|e}_ r}r h}_ r|h}r s}z s|a}ix s|s}z a}ix _HERE_ my %replacements = (); for my $rl (split(&#39; n&#39;, $raw_replacements)) { next if($rl !~ / t/); my @tmp = split(/ t/, $rl); $replacements{$tmp[0]} = $tmp[1]; } my $regex_inner = join(&#39;|&#39;, map { quotemeta $_ } keys %replacements); while(&lt;&gt;) { chomp; while(/(?:^| )($regex_inner)(?:$| )/g) { my $m = $1; my $qm = quotemeta($m); s/$qm/$replacements{$m}/; } my @phns = split/ /; my @out = (); for my $phn (@phns) { if($phn =~ /^([-&#39;]) |/) { my $ch = $1; push @out, &quot;$ch}_&quot;; push @out, substr($phn,2); } elsif($phn =~ /^([^ |]) |([-&#39;]) }(.*)$/) { my $ch1 = $1; my $ch2 = $2; my $ch3 = $3; push @out, &quot;$ch1}$ch3&quot;; push @out, &quot;$ch2}_&quot;; } elsif($phn eq &#39;c}ao&#39;) { if($phns[0] eq &#39;n}n&#39;) { push @out, &#39;c}s&#39;; } else { push @out, &#39;c}k&#39;; } } else { push @out, $phn; } } print join(&#39; &#39;, @out) . &quot; n&quot;; } . Writing clean_ngrams.pl . !cat TIMIT.clean.corpus | perl clean_ngrams.pl &gt; TIMIT.cleaner.corpus . !estimate-ngram -o 8 -t TIMIT.cleaner.corpus -wl timit.arpa # Convert to OpenFst format (10s-20s): !phonetisaurus-arpa2wfst --lm=timit.arpa --ofile=timit.fst . 0.001 Loading corpus TIMIT.cleaner.corpus... 0.026 Smoothing[1] = ModKN 0.026 Smoothing[2] = ModKN 0.026 Smoothing[3] = ModKN 0.026 Smoothing[4] = ModKN 0.026 Smoothing[5] = ModKN 0.026 Smoothing[6] = ModKN 0.026 Smoothing[7] = ModKN 0.026 Smoothing[8] = ModKN 0.026 Set smoothing algorithms... 0.026 Y 6.390977e-01 0.026 Y 6.202592e-01 0.026 Y 7.251729e-01 0.026 Y 7.967686e-01 0.027 Y 8.548704e-01 0.027 Y 9.046288e-01 0.027 Y 9.354281e-01 0.027 Y 9.105453e-01 0.027 Estimating full n-gram model... 0.029 Saving LM to timit.arpa... GitRevision: 0.9.1 Initializing... Converting... . .",
            "url": "https://jimregan.github.io/notes/kaggle/timit/phonetisaurus/2021/07/03/run-phonetisaurus-on-timit-kaggle.html",
            "relUrl": "/kaggle/timit/phonetisaurus/2021/07/03/run-phonetisaurus-on-timit-kaggle.html",
            "date": " â€¢ Jul 3, 2021"
        }
        
    
  
    
        ,"post130": {
            "title": "Install phonetisaurus on Colab",
            "content": "%%capture !apt-get -y install git g++ autoconf-archive make libtool # Python bindings !apt-get -y install python-setuptools python-dev # mitlm (to build a quick play model) !apt-get -y install gfortran . %%capture !wget http://www.openfst.org/twiki/pub/FST/FstDownload/openfst-1.6.2.tar.gz !tar -xvzf openfst-1.6.2.tar.gz %cd openfst-1.6.2 # Minimal configure, compatible with current defaults for Kaldi !./configure --enable-static --enable-shared --enable-far --enable-ngram-fsts !make -j 4 # Now wait a while... !make install . import os ldlibpath = os.environ[&#39;LD_LIBRARY_PATH&#39;] #_STORED_LD = &quot;/usr/local/nvidia/lib:/usr/local/nvidia/lib64&quot; newld = f&#39;{ldlibpath}:/usr/local/lib:/usr/local/lib/fst&#39; os.environ[&#39;LD_LIBRARY_PATH&#39;]=newld %env LD_LIBRARY_PATH . &#39;/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/lib:/usr/local/lib/fst&#39; . %%capture %cd /content !git clone https://github.com/AdolfVonKleist/Phonetisaurus.git %cd Phonetisaurus !./configure !make !make install . %cd /content/ . /content .",
            "url": "https://jimregan.github.io/notes/phonetisaurus/colab/2021/07/03/install-phonetisaurus.html",
            "relUrl": "/phonetisaurus/colab/2021/07/03/install-phonetisaurus.html",
            "date": " â€¢ Jul 3, 2021"
        }
        
    
  
    
        ,"post131": {
            "title": "English hyphenation from Wiktionary",
            "content": "Original on Kaggle . %%capture !wget https://dumps.wikimedia.org/enwiktionary/20210620/enwiktionary-20210620-pages-articles-multistream.xml.bz2 . !bzcat enwiktionary-20210620-pages-articles-multistream.xml.bz2|grep &#39;hyphenation|en&#39; &gt; /tmp/rawhyph . !grep &#39;{{a|U.S.&#39; /tmp/rawhyph|sed -e &#39;s/{a|U.S.}//;s/{}//&#39; . * {{hyphenation|en|caption=|tub|er|vil}} . !cat /tmp/rawhyph|sed -e &#39;s/{a|U.S.}//;s/{}//;&#39;|sed -e &quot;s/&#39;&#39;&#39;:&#39;&#39;&#39;/|/g&quot;|awk -F&#39;{{hyphenation |en |&#39; &#39;{print $2}&#39;|awk -F&#39;}}&#39; &#39;{print $1}&#39;|perl -ane &#39;chomp;@l=split/ |/;if($l[0] =~ /=/){shift @l};if($l[$#l] =~ /=/){pop @l};print join(&quot;&quot;, @l) . &quot; t&quot; . join(&quot; &quot;, @l). &quot; n&quot;&#39;|sort|uniq &gt; hyphenation.tsv .",
            "url": "https://jimregan.github.io/notes/english/wiktionary/hyphenation/2021/06/24/english-hyphenation-from-wiktionary.html",
            "relUrl": "/english/wiktionary/hyphenation/2021/06/24/english-hyphenation-from-wiktionary.html",
            "date": " â€¢ Jun 24, 2021"
        }
        
    
  
    
        ,"post132": {
            "title": "Sine curve unit circle on Colab",
            "content": "%%capture # https://docs.manim.community/en/stable/installation/colab.html !sudo apt update !sudo apt install libcairo2-dev ffmpeg texlive texlive-latex-extra texlive-fonts-extra texlive-latex-recommended texlive-science tipa libpango1.0-dev !pip install manim !pip install IPython --upgrade . from manim import * . Manim Community v0.7.0 . %%manim -v WARNING --disable_caching -qm SineCurveUnitCircle # https://docs.manim.community/en/stable/examples.html#sinecurveunitcircle class SineCurveUnitCircle(Scene): # contributed by heejin_park, https://infograph.tistory.com/230 def construct(self): self.show_axis() self.show_circle() self.move_dot_and_draw_curve() self.wait() def show_axis(self): x_start = np.array([-6,0,0]) x_end = np.array([6,0,0]) y_start = np.array([-4,-2,0]) y_end = np.array([-4,2,0]) x_axis = Line(x_start, x_end) y_axis = Line(y_start, y_end) self.add(x_axis, y_axis) self.add_x_labels() self.origin_point = np.array([-4,0,0]) self.curve_start = np.array([-3,0,0]) def add_x_labels(self): x_labels = [ MathTex(&quot; pi&quot;), MathTex(&quot;2 pi&quot;), MathTex(&quot;3 pi&quot;), MathTex(&quot;4 pi&quot;), ] for i in range(len(x_labels)): x_labels[i].next_to(np.array([-1 + 2*i, 0, 0]), DOWN) self.add(x_labels[i]) def show_circle(self): circle = Circle(radius=1) circle.move_to(self.origin_point) self.add(circle) self.circle = circle def move_dot_and_draw_curve(self): orbit = self.circle origin_point = self.origin_point dot = Dot(radius=0.08, color=YELLOW) dot.move_to(orbit.point_from_proportion(0)) self.t_offset = 0 rate = 0.25 def go_around_circle(mob, dt): self.t_offset += (dt * rate) # print(self.t_offset) mob.move_to(orbit.point_from_proportion(self.t_offset % 1)) def get_line_to_circle(): return Line(origin_point, dot.get_center(), color=BLUE) def get_line_to_curve(): x = self.curve_start[0] + self.t_offset * 4 y = dot.get_center()[1] return Line(dot.get_center(), np.array([x,y,0]), color=YELLOW_A, stroke_width=2 ) self.curve = VGroup() self.curve.add(Line(self.curve_start,self.curve_start)) def get_curve(): last_line = self.curve[-1] x = self.curve_start[0] + self.t_offset * 4 y = dot.get_center()[1] new_line = Line(last_line.get_end(),np.array([x,y,0]), color=YELLOW_D) self.curve.add(new_line) return self.curve dot.add_updater(go_around_circle) origin_to_circle_line = always_redraw(get_line_to_circle) dot_to_curve_line = always_redraw(get_line_to_curve) sine_curve_line = always_redraw(get_curve) self.add(dot) self.add(orbit, origin_to_circle_line, dot_to_curve_line, sine_curve_line) self.wait(8.5) dot.remove_updater(go_around_circle) . . Your browser does not support the video tag.",
            "url": "https://jimregan.github.io/notes/manim/colab/2021/06/23/manim_sine_curve_colab.html",
            "relUrl": "/manim/colab/2021/06/23/manim_sine_curve_colab.html",
            "date": " â€¢ Jun 23, 2021"
        }
        
    
  
    
        ,"post133": {
            "title": "Scoring librispeech with Kaldi on Kaggle",
            "content": "Original here. This basically recreates this blog post, but with different test sets, and on Kaggle, where setting up Kaldi is a little more involved than usual. . Results: . test-clean test-other . tgsmall LM | 7.13 | 17.92 | . rnnlm rescored: | 5.85 | 15.98 | . Unpack Kaldi . %cd /opt . /opt . %%capture !tar xvf /kaggle/input/extract-prebuilt-kaldi-from-docker/kaldi.tar . import os os.environ[&#39;LD_LIBRARY_PATH&#39;] = &#39;/opt/conda/lib:/opt/kaldi/tools/openfst-1.6.7/lib:/opt/kaldi/src/lib:&#39; EXISTING_PATH = os.environ[&#39;PATH&#39;] . %cd / . / . %%capture !tar xvf /kaggle/input/extract-cuda-from-kaldi-docker/cuda.tar . import os os.environ[&#39;LD_LIBRARY_PATH&#39;] = f&#39;{os.environ[&quot;LD_LIBRARY_PATH&quot;]}:/usr/local/cuda-10.0/targets/x86_64-linux/lib/&#39; . %cd /opt/kaldi/egs . /opt/kaldi/egs . Install flac . %%capture !apt install -y flac . Create a work directory . !mkdir -p usels/s5 %cd usels/s5 . /opt/kaldi/egs/usels/s5 . !mkdir /kaggle/working/data !mkdir /kaggle/working/exp !ln -s /kaggle/working/data !ln -s /kaggle/working/exp . !ln -s ../../wsj/s5/steps !ln -s ../../wsj/s5/utils !ln -s ../../librispeech/s5/local . !mkdir conf . %%writefile conf/mfcc_hires.conf # config for high-resolution MFCC features, intended for neural network training # Note: we keep all cepstra, so it has the same info as filterbank features, # but MFCC is more easily compressible (because less correlated) which is why # we prefer this method. --use-energy=false # use average of log energy, not energy. --num-mel-bins=40 # similar to Google&#39;s setup. --num-ceps=40 # there is no dimensionality reduction. --low-freq=20 # low cutoff frequency for mel bins... this is high-bandwidth data, so # there might be some information at the low end. --high-freq=-400 # high cutoff frequently, relative to Nyquist of 8000 (=7600) . Writing conf/mfcc_hires.conf . Setting up paths . (In the scripts, you just source path.sh) . %env KALDI_ROOT=/opt/kaldi . env: KALDI_ROOT=/opt/kaldi . !cat ../../wsj/s5/path.sh . export KALDI_ROOT=`pwd`/../../.. [ -f $KALDI_ROOT/tools/env.sh ] &amp;&amp; . $KALDI_ROOT/tools/env.sh export PATH=$PWD/utils/:$KALDI_ROOT/tools/openfst/bin:$PWD:$PATH [ ! -f $KALDI_ROOT/tools/config/common_path.sh ] &amp;&amp; echo &gt;&amp;2 &#34;The standard file $KALDI_ROOT/tools/config/common_path.sh is not present -&gt; Exit!&#34; &amp;&amp; exit 1 . $KALDI_ROOT/tools/config/common_path.sh export LC_ALL=C . %env LC_ALL=C #PWD = !pwd PWD = &#39;/opt/kaldi/egs/usels/s5&#39; KALDI_ROOT = &#39;/opt/kaldi&#39; WSJ_PATH = f&#39;{PWD}/utils/:{KALDI_ROOT}/tools/openfst/bin:{PWD}:{EXISTING_PATH}&#39; . env: LC_ALL=C . !cat $KALDI_ROOT/tools/config/common_path.sh . # we assume KALDI_ROOT is already defined [ -z &#34;$KALDI_ROOT&#34; ] &amp;&amp; echo &gt;&amp;2 &#34;The variable KALDI_ROOT must be already defined&#34; &amp;&amp; exit 1 # The formatting of the path export command is intentionally weird, because # this allows for easy diff&#39;ing export PATH= ${KALDI_ROOT}/src/bin: ${KALDI_ROOT}/src/chainbin: ${KALDI_ROOT}/src/featbin: ${KALDI_ROOT}/src/fgmmbin: ${KALDI_ROOT}/src/fstbin: ${KALDI_ROOT}/src/gmmbin: ${KALDI_ROOT}/src/ivectorbin: ${KALDI_ROOT}/src/kwsbin: ${KALDI_ROOT}/src/latbin: ${KALDI_ROOT}/src/lmbin: ${KALDI_ROOT}/src/nnet2bin: ${KALDI_ROOT}/src/nnet3bin: ${KALDI_ROOT}/src/nnetbin: ${KALDI_ROOT}/src/online2bin: ${KALDI_ROOT}/src/onlinebin: ${KALDI_ROOT}/src/rnnlmbin: ${KALDI_ROOT}/src/sgmm2bin: ${KALDI_ROOT}/src/sgmmbin: ${KALDI_ROOT}/src/tfrnnlmbin: ${KALDI_ROOT}/src/cudadecoderbin: $PATH . raw_kaldi_paths=!cat $KALDI_ROOT/tools/config/common_path.sh|grep &#39;/src/&#39;|awk -F&#39;:&#39; &#39;{print $1}&#39;|awk -F&#39;/&#39; &#39;{print &quot;/opt/kaldi/src/&quot;$NF}&#39; . KALDI_PATHS=raw_kaldi_paths.nlstr.replace(&#39; n&#39;,&#39;:&#39;) . !cat $KALDI_ROOT/tools/env.sh . export PATH=/opt/kaldi/tools/python:${PATH} export PHONETISAURUS=&#34;/tmp/output/opt/kaldi/tools/phonetisaurus-g2p&#34; export PATH=&#34;$PATH:${PHONETISAURUS}:${PHONETISAURUS}/src/scripts&#34; . PHONETISAURUS = &quot;/tmp/output/opt/kaldi/tools/phonetisaurus-g2p&quot; TOOLS_PATH = f&#39;/opt/kaldi/tools/python:{PHONETISAURUS}:{PHONETISAURUS}/src/scripts&#39; . %env PATH = f&quot;{WSJ_PATH}:{KALDI_PATHS}:{TOOLS_PATH}&quot; . env: PATH=f&#34;/opt/kaldi/egs/usels/s5/utils/:/opt/kaldi/tools/openfst/bin:/opt/kaldi/egs/usels/s5:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/kaldi/src/bin:/opt/kaldi/src/chainbin:/opt/kaldi/src/featbin:/opt/kaldi/src/fgmmbin:/opt/kaldi/src/fstbin:/opt/kaldi/src/gmmbin:/opt/kaldi/src/ivectorbin:/opt/kaldi/src/kwsbin:/opt/kaldi/src/latbin:/opt/kaldi/src/lmbin:/opt/kaldi/src/nnet2bin:/opt/kaldi/src/nnet3bin:/opt/kaldi/src/nnetbin:/opt/kaldi/src/online2bin:/opt/kaldi/src/onlinebin:/opt/kaldi/src/rnnlmbin:/opt/kaldi/src/sgmm2bin:/opt/kaldi/src/sgmmbin:/opt/kaldi/src/tfrnnlmbin:/opt/kaldi/src/cudadecoderbin:/opt/kaldi/tools/python:/tmp/output/opt/kaldi/tools/phonetisaurus-g2p:/tmp/output/opt/kaldi/tools/phonetisaurus-g2p/src/scripts&#34; . !cat ../../wsj/s5/cmd.sh . # you can change cmd.sh depending on what type of queue you are using. # If you have no queueing system and want to run on a local machine, you # can change all instances &#39;queue.pl&#39; to run.pl (but be careful and run # commands one by one: most recipes will exhaust the memory on your # machine). queue.pl works with GridEngine (qsub). slurm.pl works # with slurm. Different queues are configured differently, with different # queue names and different ways of specifying things like memory; # to account for these differences you can create and edit the file # conf/queue.conf to match your queue&#39;s configuration. Search for # conf/queue.conf in http://kaldi-asr.org/doc/queue.html for more information, # or search for the string &#39;default_config&#39; in utils/queue.pl or utils/slurm.pl. export train_cmd=queue.pl export decode_cmd=&#34;queue.pl --mem 2G&#34; # the use of cuda_cmd is deprecated, used only in &#39;nnet1&#39;, export cuda_cmd=&#34;queue.pl --gpu 1&#34; if [ &#34;$(hostname -d)&#34; == &#34;fit.vutbr.cz&#34; ]; then queue_conf=$HOME/queue_conf/default.conf # see example /homes/kazi/iveselyk/queue_conf/default.conf, export train_cmd=&#34;queue.pl --config $queue_conf --mem 2G --matylda 0.2&#34; export decode_cmd=&#34;queue.pl --config $queue_conf --mem 3G --matylda 0.1&#34; export cuda_cmd=&#34;queue.pl --config $queue_conf --gpu 1 --mem 10G --tmp 40G&#34; fi . %env train_cmd=run.pl %env decode_cmd=run.pl . env: train_cmd=run.pl env: decode_cmd=run.pl . !ln -s ../../wsj/s5/cmd.sh !ln -s ../../wsj/s5/path.sh !ln -s utils/queue.pl !ln -s utils/run.pl . !rm *.pl . Data prep . !local/data_prep.sh /kaggle/input/librispeech-test-clean-and-other/LibriSpeech/test-other data/test-other !local/data_prep.sh /kaggle/input/librispeech-test-clean-and-other/LibriSpeech/test-clean data/test-clean . utils/validate_data_dir.sh: Successfully validated data-directory data/test-other local/data_prep.sh: successfully prepared data in data/test-other utils/validate_data_dir.sh: Successfully validated data-directory data/test-clean local/data_prep.sh: successfully prepared data in data/test-clean . !utils/copy_data_dir.sh data/test-clean data/test-clean_hires !utils/copy_data_dir.sh data/test-other data/test-other_hires . utils/copy_data_dir.sh: copied data from data/test-clean to data/test-clean_hires utils/validate_data_dir.sh: Successfully validated data-directory data/test-clean_hires utils/copy_data_dir.sh: copied data from data/test-other to data/test-other_hires utils/validate_data_dir.sh: Successfully validated data-directory data/test-other_hires . !ln -s utils/parse_options.sh . !steps/make_mfcc.sh --nj 20 --mfcc-config conf/mfcc_hires.conf --cmd &quot;$train_cmd&quot; data/test-clean_hires !steps/compute_cmvn_stats.sh data/test-clean_hires !utils/fix_data_dir.sh data/test-clean_hires !steps/make_mfcc.sh --nj 20 --mfcc-config conf/mfcc_hires.conf --cmd &quot;$train_cmd&quot; data/test-other_hires !steps/compute_cmvn_stats.sh data/test-other_hires !utils/fix_data_dir.sh data/test-other_hires . steps/make_mfcc.sh --nj 20 --mfcc-config conf/mfcc_hires.conf --cmd run.pl data/test-clean_hires utils/validate_data_dir.sh: Successfully validated data-directory data/test-clean_hires steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance. steps/make_mfcc.sh: Succeeded creating MFCC features for test-clean_hires steps/compute_cmvn_stats.sh data/test-clean_hires Succeeded creating CMVN stats for test-clean_hires fix_data_dir.sh: kept all 2620 utterances. fix_data_dir.sh: old files are kept in data/test-clean_hires/.backup steps/make_mfcc.sh --nj 20 --mfcc-config conf/mfcc_hires.conf --cmd run.pl data/test-other_hires utils/validate_data_dir.sh: Successfully validated data-directory data/test-other_hires steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance. steps/make_mfcc.sh: Succeeded creating MFCC features for test-other_hires steps/compute_cmvn_stats.sh data/test-other_hires Succeeded creating CMVN stats for test-other_hires fix_data_dir.sh: kept all 2939 utterances. fix_data_dir.sh: old files are kept in data/test-other_hires/.backup . Extract i-vectors . !ln -s /kaggle/input/kaldi-librispeech-model/exp/nnet3_cleaned/ exp/nnet3_cleaned !ln -s /kaggle/input/kaldi-librispeech-model/exp/chain_cleaned/ exp/chain_cleaned . %env nspk=$(wc -l &lt;data/test-clean_hires/spk2utt) !steps/online/nnet2/extract_ivectors_online.sh --cmd &quot;$train_cmd&quot; --nj &quot;${nspk}&quot; data/test-clean_hires exp/nnet3_cleaned/extractor exp/nnet3_cleaned_out/ivectors_test-clean_hires %env nspk=$(wc -l &lt;data/test-other_hires/spk2utt) !steps/online/nnet2/extract_ivectors_online.sh --cmd &quot;$train_cmd&quot; --nj &quot;${nspk}&quot; data/test-other_hires exp/nnet3_cleaned/extractor exp/nnet3_cleaned_out/ivectors_test-other_hires . env: nspk=$(wc -l &lt;data/test-clean_hires/spk2utt) steps/online/nnet2/extract_ivectors_online.sh --cmd run.pl --nj $(wc -l &lt;data/test-clean_hires/spk2utt) data/test-clean_hires exp/nnet3_cleaned/extractor exp/nnet3_cleaned_out/ivectors_test-clean_hires steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to exp/nnet3_cleaned_out/ivectors_test-clean_hires using the extractor in exp/nnet3_cleaned/extractor. env: nspk=$(wc -l &lt;data/test-other_hires/spk2utt) steps/online/nnet2/extract_ivectors_online.sh --cmd run.pl --nj $(wc -l &lt;data/test-other_hires/spk2utt) data/test-other_hires exp/nnet3_cleaned/extractor exp/nnet3_cleaned_out/ivectors_test-other_hires steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to exp/nnet3_cleaned_out/ivectors_test-other_hires using the extractor in exp/nnet3_cleaned/extractor. . Build decoding graph . Just linking this directory won&#39;t work, as it expects to be able to write to it (Kaldi scripts, smh) . !cp -r /kaggle/input/kaldi-librispeech-model/data/lang_test_tgsmall data . %env tdnndir=exp/chain_cleaned/tdnn_1d_sp %env graph_dir=exp/chain_cleaned_out/graph_tgsmall !utils/mkgraph.sh --self-loop-scale 1.0 --remove-oov data/lang_test_tgsmall $tdnndir $graph_dir . env: tdnndir=exp/chain_cleaned/tdnn_1d_sp env: graph_dir=exp/chain_cleaned_out/graph_tgsmall tree-info exp/chain_cleaned/tdnn_1d_sp/tree tree-info exp/chain_cleaned/tdnn_1d_sp/tree fstpushspecial fstdeterminizestar --use-log=true fstminimizeencoded fsttablecompose data/lang_test_tgsmall/L_disambig.fst data/lang_test_tgsmall/G.fst fstisstochastic data/lang_test_tgsmall/tmp/LG.fst -0.0459745 -0.0466771 [info]: LG not stochastic. fstcomposecontext --context-size=2 --central-position=1 --read-disambig-syms=data/lang_test_tgsmall/phones/disambig.int --write-disambig-syms=data/lang_test_tgsmall/tmp/disambig_ilabels_2_1.int data/lang_test_tgsmall/tmp/ilabels_2_1.113735 data/lang_test_tgsmall/tmp/LG.fst fstisstochastic data/lang_test_tgsmall/tmp/CLG_2_1.fst -0.0459745 -0.0466771 [info]: CLG not stochastic. make-h-transducer --disambig-syms-out=exp/chain_cleaned_out/graph_tgsmall/disambig_tid.int --transition-scale=1.0 data/lang_test_tgsmall/tmp/ilabels_2_1 exp/chain_cleaned/tdnn_1d_sp/tree exp/chain_cleaned/tdnn_1d_sp/final.mdl fstdeterminizestar --use-log=true fsttablecompose exp/chain_cleaned_out/graph_tgsmall/Ha.fst &#39;fstrmsymbols --remove-arcs=true --apply-to-output=true data/lang_test_tgsmall/oov.int data/lang_test_tgsmall/tmp/CLG_2_1.fst|&#39; fstminimizeencoded fstrmsymbols exp/chain_cleaned_out/graph_tgsmall/disambig_tid.int fstrmepslocal fstrmsymbols --remove-arcs=true --apply-to-output=true data/lang_test_tgsmall/oov.int data/lang_test_tgsmall/tmp/CLG_2_1.fst fstisstochastic exp/chain_cleaned_out/graph_tgsmall/HCLGa.fst 3.39453 -0.209239 HCLGa is not stochastic add-self-loops --self-loop-scale=1.0 --reorder=true exp/chain_cleaned/tdnn_1d_sp/final.mdl exp/chain_cleaned_out/graph_tgsmall/HCLGa.fst fstisstochastic exp/chain_cleaned_out/graph_tgsmall/HCLG.fst 3.05078 -0.127788 [info]: final HCLG is not stochastic. . Decode . !mkdir exp/tdnn_1d_sp %pushd exp/tdnn_1d_sp !for i in /kaggle/input/kaldi-librispeech-model/exp/chain_cleaned/tdnn_1d_sp/*;do ln -s $i;done %popd . /kaggle/working/exp/tdnn_1d_sp /opt/kaldi/egs/usels/s5 popd -&gt; /opt/kaldi/egs/usels/s5 . %env tdnndir=exp/tdnn_1d_sp !steps/nnet3/decode.sh --acwt 1.0 --post-decode-acwt 10.0 --nj 8 --cmd &quot;$decode_cmd&quot; --online-ivector-dir exp/nnet3_cleaned_out/ivectors_test-clean_hires $graph_dir data/test-clean_hires $tdnndir/decode_test-clean_tgsmall !steps/nnet3/decode.sh --acwt 1.0 --post-decode-acwt 10.0 --nj 8 --cmd &quot;$decode_cmd&quot; --online-ivector-dir exp/nnet3_cleaned_out/ivectors_test-other_hires $graph_dir data/test-other_hires $tdnndir/decode_test-other_tgsmall . env: tdnndir=exp/tdnn_1d_sp steps/nnet3/decode.sh --acwt 1.0 --post-decode-acwt 10.0 --nj 8 --cmd run.pl --online-ivector-dir exp/nnet3_cleaned_out/ivectors_test-clean_hires exp/chain_cleaned_out/graph_tgsmall data/test-clean_hires exp/tdnn_1d_sp/decode_test-clean_tgsmall steps/nnet3/decode.sh: feature type is raw steps/diagnostic/analyze_lats.sh --cmd run.pl --iter final exp/chain_cleaned_out/graph_tgsmall exp/tdnn_1d_sp/decode_test-clean_tgsmall steps/diagnostic/analyze_lats.sh: see stats in exp/tdnn_1d_sp/decode_test-clean_tgsmall/log/analyze_alignments.log Overall, lattice depth (10,50,90-percentile)=(1,2,5) and mean=2.8 steps/diagnostic/analyze_lats.sh: see stats in exp/tdnn_1d_sp/decode_test-clean_tgsmall/log/analyze_lattice_depth_stats.log score best paths score confidence and timing with sclite Decoding done. steps/nnet3/decode.sh --acwt 1.0 --post-decode-acwt 10.0 --nj 8 --cmd run.pl --online-ivector-dir exp/nnet3_cleaned_out/ivectors_test-other_hires exp/chain_cleaned_out/graph_tgsmall data/test-other_hires exp/tdnn_1d_sp/decode_test-other_tgsmall steps/nnet3/decode.sh: feature type is raw steps/diagnostic/analyze_lats.sh --cmd run.pl --iter final exp/chain_cleaned_out/graph_tgsmall exp/tdnn_1d_sp/decode_test-other_tgsmall steps/diagnostic/analyze_lats.sh: see stats in exp/tdnn_1d_sp/decode_test-other_tgsmall/log/analyze_alignments.log Overall, lattice depth (10,50,90-percentile)=(1,3,13) and mean=6.3 steps/diagnostic/analyze_lats.sh: see stats in exp/tdnn_1d_sp/decode_test-other_tgsmall/log/analyze_lattice_depth_stats.log score best paths score confidence and timing with sclite Decoding done. . Score . !steps/score_kaldi.sh --cmd &quot;run.pl&quot; data/test-clean_hires $graph_dir $tdnndir/decode_test-clean_tgsmall !steps/score_kaldi.sh --cmd &quot;run.pl&quot; data/test-other_hires $graph_dir $tdnndir/decode_test-other_tgsmall . steps/score_kaldi.sh --cmd run.pl data/test-clean_hires exp/chain_cleaned_out/graph_tgsmall exp/tdnn_1d_sp/decode_test-clean_tgsmall steps/score_kaldi.sh: scoring with word insertion penalty=0.0,0.5,1.0 steps/score_kaldi.sh --cmd run.pl data/test-other_hires exp/chain_cleaned_out/graph_tgsmall exp/tdnn_1d_sp/decode_test-other_tgsmall steps/score_kaldi.sh: scoring with word insertion penalty=0.0,0.5,1.0 . !cat exp/tdnn_1d_sp/decode_test-clean_tgsmall/scoring_kaldi/best_wer !cat exp/tdnn_1d_sp/decode_test-other_tgsmall/scoring_kaldi/best_wer . %WER 7.13 [ 3747 / 52576, 648 ins, 242 del, 2857 sub ] exp/tdnn_1d_sp/decode_test-clean_tgsmall/wer_17_0.5 %WER 17.92 [ 9378 / 52343, 1384 ins, 723 del, 7271 sub ] exp/tdnn_1d_sp/decode_test-other_tgsmall/wer_17_1.0 . Rescoring . !cp -r /kaggle/input/kaldi-librispeech-model/exp/rnnlm_lstm_1a/ exp . !ln -s /opt/kaldi/scripts/rnnlm . %env decode_dir=exp/tdnn_1d_sp/decode_test-clean_tgsmall !rnnlm/lmrescore_pruned.sh --cmd &quot;$decode_cmd&quot; --weight 0.45 --max-ngram-order 4 data/lang_test_tgsmall exp/rnnlm_lstm_1a data/test-clean_hires ${decode_dir} $tdnndir/decode_test-clean_rescore %env decode_dir=exp/tdnn_1d_sp/decode_test-other_tgsmall !rnnlm/lmrescore_pruned.sh --cmd &quot;$decode_cmd&quot; --weight 0.45 --max-ngram-order 4 data/lang_test_tgsmall exp/rnnlm_lstm_1a data/test-other_hires ${decode_dir} $tdnndir/decode_test-other_rescore . env: decode_dir=exp/tdnn_1d_sp/decode_test-clean_tgsmall rnnlm/lmrescore_pruned.sh --cmd run.pl --weight 0.45 --max-ngram-order 4 data/lang_test_tgsmall exp/rnnlm_lstm_1a data/test-clean_hires exp/tdnn_1d_sp/decode_test-clean_tgsmall exp/tdnn_1d_sp/decode_test-clean_rescore local/score.sh --cmd run.pl data/test-clean_hires data/lang_test_tgsmall exp/tdnn_1d_sp/decode_test-clean_rescore env: decode_dir=exp/tdnn_1d_sp/decode_test-other_tgsmall rnnlm/lmrescore_pruned.sh --cmd run.pl --weight 0.45 --max-ngram-order 4 data/lang_test_tgsmall exp/rnnlm_lstm_1a data/test-other_hires exp/tdnn_1d_sp/decode_test-other_tgsmall exp/tdnn_1d_sp/decode_test-other_rescore local/score.sh --cmd run.pl data/test-other_hires data/lang_test_tgsmall exp/tdnn_1d_sp/decode_test-other_rescore . !steps/score_kaldi.sh --cmd &quot;run.pl&quot; data/test-clean_hires $graph_dir $tdnndir/decode_test-clean_rescore !steps/score_kaldi.sh --cmd &quot;run.pl&quot; data/test-other_hires $graph_dir $tdnndir/decode_test-other_rescore . steps/score_kaldi.sh --cmd run.pl data/test-clean_hires exp/chain_cleaned_out/graph_tgsmall exp/tdnn_1d_sp/decode_test-clean_rescore steps/score_kaldi.sh: scoring with word insertion penalty=0.0,0.5,1.0 steps/score_kaldi.sh --cmd run.pl data/test-other_hires exp/chain_cleaned_out/graph_tgsmall exp/tdnn_1d_sp/decode_test-other_rescore steps/score_kaldi.sh: scoring with word insertion penalty=0.0,0.5,1.0 . !cat $tdnndir/decode_test-clean_rescore/scoring_kaldi/best_wer !cat $tdnndir/decode_test-other_rescore/scoring_kaldi/best_wer . %WER 5.85 [ 3078 / 52576, 617 ins, 198 del, 2263 sub ] exp/tdnn_1d_sp/decode_test-clean_rescore/wer_17_0.5 %WER 15.98 [ 8362 / 52343, 1381 ins, 588 del, 6393 sub ] exp/tdnn_1d_sp/decode_test-other_rescore/wer_17_1.0 . .",
            "url": "https://jimregan.github.io/notes/asr/kaldi/kaggle/2021/06/22/run-kaldi-on-librispeech-test.html",
            "relUrl": "/asr/kaldi/kaggle/2021/06/22/run-kaldi-on-librispeech-test.html",
            "date": " â€¢ Jun 22, 2021"
        }
        
    
  
    
        ,"post134": {
            "title": "Kaldi LibriSpeech model on Kaggle",
            "content": "Setting up the LibriSpeech Kaldi model on Kaggle: see here . %%capture !wget http://kaldi-asr.org/models/13/0013_librispeech_v1_chain.tar.gz !wget http://kaldi-asr.org/models/13/0013_librispeech_v1_extractor.tar.gz !wget http://kaldi-asr.org/models/13/0013_librispeech_v1_lm.tar.gz . %%capture !for i in *.tar.gz;do tar zxvf $i;done . !find . -type l !find . -type l -exec ls -al {} ; . ./exp/chain_cleaned/tdnn_1d_sp/configs/lda.mat ./exp/nnet3_cleaned/extractor/final.ie lrwxrwxrwx 1 61208 fax 10 Feb 2 2020 ./exp/chain_cleaned/tdnn_1d_sp/configs/lda.mat -&gt; ../lda.mat lrwxrwxrwx 1 61208 fax 5 Feb 2 2020 ./exp/nnet3_cleaned/extractor/final.ie -&gt; 10.ie . !rm exp/chain_cleaned/tdnn_1d_sp/configs/lda.mat !rm exp/nnet3_cleaned/extractor/final.ie !cp exp/chain_cleaned/tdnn_1d_sp/lda.mat exp/chain_cleaned/tdnn_1d_sp/configs/lda.mat !cp exp/nnet3_cleaned/extractor/10.ie exp/nnet3_cleaned/extractor/final.ie .",
            "url": "https://jimregan.github.io/notes/kaggle/kaldi/librispeech/2021/06/21/kaldi-librispeech-model.html",
            "relUrl": "/kaggle/kaldi/librispeech/2021/06/21/kaldi-librispeech-model.html",
            "date": " â€¢ Jun 21, 2021"
        }
        
    
  
    
        ,"post135": {
            "title": "wav2vec-u CV-sv - w2vu_generate",
            "content": "This is based on this. The main difference is the script that&#39;s being run, and setting up flashlight&#39;s python bindings . I already had the GAN model in gdrive; those files are available here. . Preparation . !pip install condacolab . Collecting condacolab Using cached condacolab-0.1.2-py3-none-any.whl (6.0 kB) Installing collected packages: condacolab Successfully installed condacolab-0.1.2 . import condacolab condacolab.install() . âœ¨ðŸ°âœ¨ Everything looks OK! . %%capture !conda install -c pykaldi pykaldi -y . !git clone https://github.com/pytorch/fairseq/ . fatal: destination path &#39;fairseq&#39; already exists and is not an empty directory. . !git clone https://github.com/kpu/kenlm . fatal: destination path &#39;kenlm&#39; already exists and is not an empty directory. . %%capture !apt-get -y install libeigen3-dev liblzma-dev zlib1g-dev libbz2-dev . The python build doesn&#39;t build utils, so this is (probably) necessary . %cd /content/kenlm !mkdir build %cd build !cmake .. !make -j 4 . %%capture %cd /content/kenlm !python setup.py install %cd /tmp . import os os.environ[&#39;PATH&#39;] = f&quot;{os.environ[&#39;PATH&#39;]}:/content/kenlm/build/bin/&quot; os.environ[&#39;FAIRSEQ_ROOT&#39;] = &#39;/content/fairseq&#39; . %cd /content/fairseq/ . /content/fairseq . For next cell, see here . %%capture !pip install --editable ./ !python setup.py build develop . os.environ[&#39;HYDRA_FULL_ERROR&#39;] = &#39;1&#39; . %%capture !pip install editdistance . https://colab.research.google.com/github/corrieann/kaggle/blob/master/kaggle_api_in_colab.ipynb . %%capture !pip install kaggle . from google.colab import files uploaded = files.upload() for fn in uploaded.keys(): print(&#39;User uploaded file &quot;{name}&quot; with length {length} bytes&#39;.format( name=fn, length=len(uploaded[fn]))) # Then move kaggle.json into the folder where the API expects to find it. !mkdir -p ~/.kaggle/ &amp;&amp; mv kaggle.json ~/.kaggle/ &amp;&amp; chmod 600 ~/.kaggle/kaggle.json . Upload widget is only available when the cell has been executed in the current browser session. Please rerun this cell to enable. Saving kaggle.json to kaggle.json User uploaded file &#34;kaggle.json&#34; with length 64 bytes . %cd /content . /content . !kaggle datasets download &quot;jimregan/w2vu-cvsv-audio-processed&quot; . Downloading w2vu-cvsv-audio-processed.zip to /content 100% 4.31G/4.31G [01:24&lt;00:00, 102MB/s] 100% 4.31G/4.31G [01:24&lt;00:00, 54.7MB/s] . %%capture !unzip /content/w2vu-cvsv-audio-processed.zip . !kaggle datasets download -d jimregan/w2vu-cvsv-prepared-text . Downloading w2vu-cvsv-prepared-text.zip to /content 80% 14.0M/17.4M [00:00&lt;00:00, 33.7MB/s] 100% 17.4M/17.4M [00:00&lt;00:00, 44.2MB/s] . %%capture !unzip w2vu-cvsv-prepared-text.zip . !rm *.zip . !cp /content/preppedtext/phones/dict* /content/precompute_pca512_cls128_mean . %cd /content . /content . !git clone https://github.com/flashlight/flashlight . Cloning into &#39;flashlight&#39;... remote: Enumerating objects: 17649, done. remote: Counting objects: 100% (1523/1523), done. remote: Compressing objects: 100% (718/718), done. remote: Total 17649 (delta 827), reused 1336 (delta 761), pack-reused 16126 Receiving objects: 100% (17649/17649), 14.23 MiB | 24.82 MiB/s, done. Resolving deltas: 100% (12298/12298), done. . %%capture !apt install -q libfftw3-dev . Reading package lists... Building dependency tree... Reading state information... libfftw3-dev is already the newest version (3.3.7-1). cmake is already the newest version (3.10.2-1ubuntu2.18.04.1). 0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded. . %cd flashlight/bindings/python . /content/flashlight/bindings/python . %%capture !pip install packaging . !USE_MKL=0 KENLM_ROOT=/content/kenlm python setup.py install . w2vu-generate . import torch torch.version.cuda . &#39;10.2&#39; . torch.backends.cudnn.version() . 7605 . %cd /content/fairseq . /content/fairseq . from google.colab import drive drive.mount(&#39;/content/drive&#39;) . Mounted at /content/drive . %cd /content/fairseq/examples/wav2vec/unsupervised . /content/fairseq/examples/wav2vec/unsupervised . %%writefile rungan.sh python w2vu_generate.py --config-dir config/generate --config-name viterbi fairseq.common.user_dir=/content/fairseq/examples/wav2vec/unsupervised fairseq.task.data=/content/precompute_pca512_cls128_mean fairseq.common_eval.path=/content/drive/MyDrive/w2vu/checkpoint_best.pt fairseq.dataset.gen_subset=valid results_path=/content/drive/MyDrive/w2vures . Overwriting rungan.sh . !bash rungan.sh . [2021-06-19 19:24:18,601][__main__][INFO] - {&#39;_name&#39;: None, &#39;fairseq&#39;: {&#39;_name&#39;: None, &#39;common&#39;: {&#39;_name&#39;: None, &#39;no_progress_bar&#39;: False, &#39;log_interval&#39;: 100, &#39;log_format&#39;: None, &#39;log_file&#39;: None, &#39;tensorboard_logdir&#39;: None, &#39;wandb_project&#39;: None, &#39;azureml_logging&#39;: False, &#39;seed&#39;: 1, &#39;cpu&#39;: False, &#39;tpu&#39;: False, &#39;bf16&#39;: False, &#39;memory_efficient_bf16&#39;: False, &#39;fp16&#39;: False, &#39;memory_efficient_fp16&#39;: False, &#39;fp16_no_flatten_grads&#39;: False, &#39;fp16_init_scale&#39;: 128, &#39;fp16_scale_window&#39;: None, &#39;fp16_scale_tolerance&#39;: 0.0, &#39;on_cpu_convert_precision&#39;: False, &#39;min_loss_scale&#39;: 0.0001, &#39;threshold_loss_scale&#39;: None, &#39;amp&#39;: False, &#39;amp_batch_retries&#39;: 2, &#39;amp_init_scale&#39;: 128, &#39;amp_scale_window&#39;: None, &#39;user_dir&#39;: &#39;/content/fairseq/examples/wav2vec/unsupervised&#39;, &#39;empty_cache_freq&#39;: 0, &#39;all_gather_list_size&#39;: 16384, &#39;model_parallel_size&#39;: 1, &#39;quantization_config_path&#39;: None, &#39;profile&#39;: False, &#39;reset_logging&#39;: False, &#39;suppress_crashes&#39;: False, &#39;use_plasma_view&#39;: False, &#39;plasma_path&#39;: &#39;/tmp/plasma&#39;}, &#39;common_eval&#39;: {&#39;_name&#39;: None, &#39;path&#39;: &#39;/content/drive/MyDrive/w2vu/checkpoint_best.pt&#39;, &#39;post_process&#39;: None, &#39;quiet&#39;: True, &#39;model_overrides&#39;: &#39;{}&#39;, &#39;results_path&#39;: None}, &#39;distributed_training&#39;: {&#39;_name&#39;: None, &#39;distributed_world_size&#39;: 1, &#39;distributed_num_procs&#39;: 1, &#39;distributed_rank&#39;: 0, &#39;distributed_backend&#39;: &#39;nccl&#39;, &#39;distributed_init_method&#39;: None, &#39;distributed_port&#39;: -1, &#39;device_id&#39;: 0, &#39;distributed_no_spawn&#39;: False, &#39;ddp_backend&#39;: pytorch_ddp, &#39;ddp_comm_hook&#39;: none, &#39;bucket_cap_mb&#39;: 25, &#39;fix_batches_to_gpus&#39;: False, &#39;find_unused_parameters&#39;: False, &#39;fast_stat_sync&#39;: False, &#39;heartbeat_timeout&#39;: -1, &#39;broadcast_buffers&#39;: False, &#39;slowmo_momentum&#39;: None, &#39;slowmo_algorithm&#39;: &#39;LocalSGD&#39;, &#39;localsgd_frequency&#39;: 3, &#39;nprocs_per_node&#39;: 1, &#39;pipeline_model_parallel&#39;: False, &#39;pipeline_balance&#39;: None, &#39;pipeline_devices&#39;: None, &#39;pipeline_chunks&#39;: 0, &#39;pipeline_encoder_balance&#39;: None, &#39;pipeline_encoder_devices&#39;: None, &#39;pipeline_decoder_balance&#39;: None, &#39;pipeline_decoder_devices&#39;: None, &#39;pipeline_checkpoint&#39;: never, &#39;zero_sharding&#39;: none, &#39;fp16&#39;: &#39;${common.fp16}&#39;, &#39;memory_efficient_fp16&#39;: &#39;${common.memory_efficient_fp16}&#39;, &#39;tpu&#39;: &#39;${common.tpu}&#39;, &#39;no_reshard_after_forward&#39;: False, &#39;fp32_reduce_scatter&#39;: False, &#39;cpu_offload&#39;: False, &#39;use_sharded_state&#39;: False}, &#39;dataset&#39;: {&#39;_name&#39;: None, &#39;num_workers&#39;: 1, &#39;skip_invalid_size_inputs_valid_test&#39;: False, &#39;max_tokens&#39;: None, &#39;batch_size&#39;: 1, &#39;required_batch_size_multiple&#39;: 8, &#39;required_seq_len_multiple&#39;: 1, &#39;dataset_impl&#39;: None, &#39;data_buffer_size&#39;: 10, &#39;train_subset&#39;: &#39;train&#39;, &#39;valid_subset&#39;: &#39;valid&#39;, &#39;combine_valid_subsets&#39;: None, &#39;ignore_unused_valid_subsets&#39;: False, &#39;validate_interval&#39;: 1, &#39;validate_interval_updates&#39;: 0, &#39;validate_after_updates&#39;: 0, &#39;fixed_validation_seed&#39;: None, &#39;disable_validation&#39;: False, &#39;max_tokens_valid&#39;: &#39;${dataset.max_tokens}&#39;, &#39;batch_size_valid&#39;: &#39;${dataset.batch_size}&#39;, &#39;max_valid_steps&#39;: None, &#39;curriculum&#39;: 0, &#39;gen_subset&#39;: &#39;valid&#39;, &#39;num_shards&#39;: 1, &#39;shard_id&#39;: 0}, &#39;optimization&#39;: {&#39;_name&#39;: None, &#39;max_epoch&#39;: 0, &#39;max_update&#39;: 0, &#39;stop_time_hours&#39;: 0.0, &#39;clip_norm&#39;: 0.0, &#39;sentence_avg&#39;: False, &#39;update_freq&#39;: [1], &#39;lr&#39;: [0.25], &#39;stop_min_lr&#39;: -1.0, &#39;use_bmuf&#39;: False}, &#39;checkpoint&#39;: {&#39;_name&#39;: None, &#39;save_dir&#39;: &#39;checkpoints&#39;, &#39;restore_file&#39;: &#39;checkpoint_last.pt&#39;, &#39;finetune_from_model&#39;: None, &#39;reset_dataloader&#39;: False, &#39;reset_lr_scheduler&#39;: False, &#39;reset_meters&#39;: False, &#39;reset_optimizer&#39;: False, &#39;optimizer_overrides&#39;: &#39;{}&#39;, &#39;save_interval&#39;: 1, &#39;save_interval_updates&#39;: 0, &#39;keep_interval_updates&#39;: -1, &#39;keep_interval_updates_pattern&#39;: -1, &#39;keep_last_epochs&#39;: -1, &#39;keep_best_checkpoints&#39;: -1, &#39;no_save&#39;: False, &#39;no_epoch_checkpoints&#39;: False, &#39;no_last_checkpoints&#39;: False, &#39;no_save_optimizer_state&#39;: False, &#39;best_checkpoint_metric&#39;: &#39;loss&#39;, &#39;maximize_best_checkpoint_metric&#39;: False, &#39;patience&#39;: -1, &#39;checkpoint_suffix&#39;: &#39;&#39;, &#39;checkpoint_shard_count&#39;: 1, &#39;load_checkpoint_on_all_dp_ranks&#39;: False, &#39;write_checkpoints_asynchronously&#39;: False, &#39;model_parallel_size&#39;: &#39;${common.model_parallel_size}&#39;}, &#39;bmuf&#39;: {&#39;_name&#39;: None, &#39;block_lr&#39;: 1.0, &#39;block_momentum&#39;: 0.875, &#39;global_sync_iter&#39;: 50, &#39;warmup_iterations&#39;: 500, &#39;use_nbm&#39;: False, &#39;average_sync&#39;: False, &#39;distributed_world_size&#39;: &#39;${distributed_training.distributed_world_size}&#39;}, &#39;generation&#39;: {&#39;_name&#39;: None, &#39;beam&#39;: 5, &#39;nbest&#39;: 1, &#39;max_len_a&#39;: 0.0, &#39;max_len_b&#39;: 200, &#39;min_len&#39;: 1, &#39;match_source_len&#39;: False, &#39;unnormalized&#39;: False, &#39;no_early_stop&#39;: False, &#39;no_beamable_mm&#39;: False, &#39;lenpen&#39;: 1.0, &#39;unkpen&#39;: 0.0, &#39;replace_unk&#39;: None, &#39;sacrebleu&#39;: False, &#39;score_reference&#39;: False, &#39;prefix_size&#39;: 0, &#39;no_repeat_ngram_size&#39;: 0, &#39;sampling&#39;: False, &#39;sampling_topk&#39;: -1, &#39;sampling_topp&#39;: -1.0, &#39;constraints&#39;: None, &#39;temperature&#39;: 1.0, &#39;diverse_beam_groups&#39;: -1, &#39;diverse_beam_strength&#39;: 0.5, &#39;diversity_rate&#39;: -1.0, &#39;print_alignment&#39;: None, &#39;print_step&#39;: False, &#39;lm_path&#39;: None, &#39;lm_weight&#39;: 0.0, &#39;iter_decode_eos_penalty&#39;: 0.0, &#39;iter_decode_max_iter&#39;: 10, &#39;iter_decode_force_max_iter&#39;: False, &#39;iter_decode_with_beam&#39;: 1, &#39;iter_decode_with_external_reranker&#39;: False, &#39;retain_iter_history&#39;: False, &#39;retain_dropout&#39;: False, &#39;retain_dropout_modules&#39;: None, &#39;decoding_format&#39;: None, &#39;no_seed_provided&#39;: False}, &#39;eval_lm&#39;: {&#39;_name&#39;: None, &#39;output_word_probs&#39;: False, &#39;output_word_stats&#39;: False, &#39;context_window&#39;: 0, &#39;softmax_batch&#39;: 9223372036854775807}, &#39;interactive&#39;: {&#39;_name&#39;: None, &#39;buffer_size&#39;: 0, &#39;input&#39;: &#39;-&#39;}, &#39;model&#39;: &#39;???&#39;, &#39;task&#39;: {&#39;_name&#39;: &#39;unpaired_audio_text&#39;, &#39;labels&#39;: &#39;phn&#39;, &#39;data&#39;: &#39;/content/precompute_pca512_cls128_mean&#39;, &#39;sort_by_length&#39;: False, &#39;shuffle&#39;: False, &#39;text_data&#39;: &#39;&#39;}, &#39;criterion&#39;: None, &#39;optimizer&#39;: None, &#39;lr_scheduler&#39;: None, &#39;scoring&#39;: None, &#39;bpe&#39;: None, &#39;tokenizer&#39;: None}, &#39;lm_weight&#39;: 2.0, &#39;w2l_decoder&#39;: &lt;DecoderType.VITERBI: 1&gt;, &#39;kaldi_decoder_config&#39;: None, &#39;lexicon&#39;: None, &#39;lm_model&#39;: None, &#39;unit_lm&#39;: False, &#39;beam_threshold&#39;: 50.0, &#39;beam_size_token&#39;: 100.0, &#39;beam&#39;: 5, &#39;nbest&#39;: 1, &#39;word_score&#39;: 1.0, &#39;unk_weight&#39;: -inf, &#39;sil_weight&#39;: 0.0, &#39;targets&#39;: None, &#39;results_path&#39;: &#39;/content/drive/MyDrive/w2vures&#39;, &#39;post_process&#39;: &#39;silence&#39;, &#39;vocab_usage_power&#39;: 2.0, &#39;viterbi_transcript&#39;: None, &#39;min_lm_ppl&#39;: 0.0, &#39;min_vt_uer&#39;: 0.0, &#39;blank_weight&#39;: 0.0, &#39;blank_mode&#39;: &#39;set&#39;, &#39;sil_is_blank&#39;: False, &#39;unsupervised_tuning&#39;: False, &#39;is_ax&#39;: False, &#39;job_logging_cfg&#39;: {&#39;version&#39;: 1, &#39;formatters&#39;: {&#39;simple&#39;: {&#39;format&#39;: &#39;[%(asctime)s][%(name)s][%(levelname)s] - %(message)s&#39;}}, &#39;handlers&#39;: {&#39;console&#39;: {&#39;class&#39;: &#39;logging.StreamHandler&#39;, &#39;formatter&#39;: &#39;simple&#39;, &#39;stream&#39;: &#39;ext://sys.stdout&#39;}, &#39;file&#39;: {&#39;class&#39;: &#39;logging.FileHandler&#39;, &#39;formatter&#39;: &#39;simple&#39;, &#39;filename&#39;: &#39;w2vu_generate.log&#39;}}, &#39;root&#39;: {&#39;level&#39;: &#39;INFO&#39;, &#39;handlers&#39;: [&#39;console&#39;, &#39;file&#39;]}, &#39;disable_existing_loggers&#39;: False}} [2021-06-19 19:24:18,629][__main__][INFO] - | loading model(s) from /content/drive/MyDrive/w2vu/checkpoint_best.pt [2021-06-19 19:24:22,829][unsupervised.data.extracted_features_dataset][INFO] - loaded 2019, skipped 0 samples [2021-06-19 19:24:22,829][unsupervised.tasks.unpaired_audio_text][INFO] - split valid has unpaired text? False [2021-06-19 19:24:22,833][__main__][INFO] - | /content/precompute_pca512_cls128_mean valid 2019 examples [2021-06-19 19:24:41,807][__main__][INFO] - WER: 158.79173813943652 [2021-06-19 19:24:41,808][__main__][INFO] - | Processed 2019 sentences (80270 tokens) in 18.9s (106.61 sentences/s, 4238.35 tokens/s) [2021-06-19 19:24:41,809][__main__][INFO] - | Generate valid with beam=5, lm_weight=2.0, word_score=1.0, sil_weight=0.0, blank_weight=0.0, WER: 158.79173813943652, LM_PPL: inf, num feats: 130753, length: 80270, UER to viterbi: 0, score: inf .",
            "url": "https://jimregan.github.io/notes/colab/wav2vec-u/2021/06/19/wav2vec-u-cv-swedish-w2vu-generate.html",
            "relUrl": "/colab/wav2vec-u/2021/06/19/wav2vec-u-cv-swedish-w2vu-generate.html",
            "date": " â€¢ Jun 19, 2021"
        }
        
    
  
    
        ,"post136": {
            "title": "Download Swedish Literature Bank",
            "content": "Original on Kaggle . !wget http://spraakbanken.gu.se/lb/resurser/meningsmangder/lb.xml.bz2 . !wget https://svn.spraakdata.gu.se/sb-arkiv/pub/frekvens/stats_LB.txt .",
            "url": "https://jimregan.github.io/notes/kaggle/swedish/2021/06/18/download-swedish-literature-bank.html",
            "relUrl": "/kaggle/swedish/2021/06/18/download-swedish-literature-bank.html",
            "date": " â€¢ Jun 18, 2021"
        }
        
    
  
    
        ,"post137": {
            "title": "Diarisation with pyannote.audio",
            "content": "!pip install pyannote.audio==1.1 . !wget http://www.bealoideasbeo.ie/bealoideas/httpdocs/fuaim/iomlan/teip/010T0013.mp3 . !ffmpeg -i 010T0013.mp3 -acodec pcm_s16le -ac 1 -ar 16000 010T0013.wav . import pyannote.core . import torch import pyannote.core pipeline = torch.hub.load(&#39;pyannote/pyannote-audio&#39;, &#39;dia&#39;) diarization = pipeline({&#39;audio&#39;: &#39;010T0013.wav&#39;}) . json = pyannote.core.json.dumps(diarization) . with open(&#39;010T0013.json&#39;, &#39;w&#39;) as f: f.write(json) .",
            "url": "https://jimregan.github.io/notes/diarisation/pyannote/2021/06/17/diarisation-with-pyannote.html",
            "relUrl": "/diarisation/pyannote/2021/06/17/diarisation-with-pyannote.html",
            "date": " â€¢ Jun 17, 2021"
        }
        
    
  
    
        ,"post138": {
            "title": "Poleval 2021 through wav2vec2",
            "content": "%%capture !pip install gdown . !gdown https://drive.google.com/uc?id=1b6MyyqgA9D1U7DX3Vtgda7f9ppkxjCXJ . Downloading... From: https://drive.google.com/uc?id=1b6MyyqgA9D1U7DX3Vtgda7f9ppkxjCXJ To: /content/poleval_wav.train.tar.gz 2.14GB [00:38, 55.7MB/s] . %%capture !tar zxvf poleval_wav.train.tar.gz &amp;&amp; rm poleval_wav.train.tar.gz . %%capture !pip install librosa webrtcvad . # VAD wrapper is taken from PyTorch Speaker Verification: # https://github.com/HarryVolek/PyTorch_Speaker_Verification # Copyright (c) 2019, HarryVolek # License: BSD-3-Clause # based on https://github.com/wiseman/py-webrtcvad/blob/master/example.py # Copyright (c) 2016 John Wiseman # License: MIT import collections import contextlib import numpy as np import sys import librosa import wave import webrtcvad #from hparam import hparam as hp sr = 16000 def read_wave(path, sr): &quot;&quot;&quot;Reads a .wav file. Takes the path, and returns (PCM audio data, sample rate). Assumes sample width == 2 &quot;&quot;&quot; with contextlib.closing(wave.open(path, &#39;rb&#39;)) as wf: num_channels = wf.getnchannels() assert num_channels == 1 sample_width = wf.getsampwidth() assert sample_width == 2 sample_rate = wf.getframerate() assert sample_rate in (8000, 16000, 32000, 48000) pcm_data = wf.readframes(wf.getnframes()) data, _ = librosa.load(path, sr) assert len(data.shape) == 1 assert sr in (8000, 16000, 32000, 48000) return data, pcm_data class Frame(object): &quot;&quot;&quot;Represents a &quot;frame&quot; of audio data.&quot;&quot;&quot; def __init__(self, bytes, timestamp, duration): self.bytes = bytes self.timestamp = timestamp self.duration = duration def frame_generator(frame_duration_ms, audio, sample_rate): &quot;&quot;&quot;Generates audio frames from PCM audio data. Takes the desired frame duration in milliseconds, the PCM data, and the sample rate. Yields Frames of the requested duration. &quot;&quot;&quot; n = int(sample_rate * (frame_duration_ms / 1000.0) * 2) offset = 0 timestamp = 0.0 duration = (float(n) / sample_rate) / 2.0 while offset + n &lt; len(audio): yield Frame(audio[offset:offset + n], timestamp, duration) timestamp += duration offset += n def vad_collector(sample_rate, frame_duration_ms, padding_duration_ms, vad, frames): &quot;&quot;&quot;Filters out non-voiced audio frames. Given a webrtcvad.Vad and a source of audio frames, yields only the voiced audio. Uses a padded, sliding window algorithm over the audio frames. When more than 90% of the frames in the window are voiced (as reported by the VAD), the collector triggers and begins yielding audio frames. Then the collector waits until 90% of the frames in the window are unvoiced to detrigger. The window is padded at the front and back to provide a small amount of silence or the beginnings/endings of speech around the voiced frames. Arguments: sample_rate - The audio sample rate, in Hz. frame_duration_ms - The frame duration in milliseconds. padding_duration_ms - The amount to pad the window, in milliseconds. vad - An instance of webrtcvad.Vad. frames - a source of audio frames (sequence or generator). Returns: A generator that yields PCM audio data. &quot;&quot;&quot; num_padding_frames = int(padding_duration_ms / frame_duration_ms) # We use a deque for our sliding window/ring buffer. ring_buffer = collections.deque(maxlen=num_padding_frames) # We have two states: TRIGGERED and NOTTRIGGERED. We start in the # NOTTRIGGERED state. triggered = False voiced_frames = [] for frame in frames: is_speech = vad.is_speech(frame.bytes, sample_rate) if not triggered: ring_buffer.append((frame, is_speech)) num_voiced = len([f for f, speech in ring_buffer if speech]) # If we&#39;re NOTTRIGGERED and more than 90% of the frames in # the ring buffer are voiced frames, then enter the # TRIGGERED state. if num_voiced &gt; 0.9 * ring_buffer.maxlen: triggered = True start = ring_buffer[0][0].timestamp # We want to yield all the audio we see from now until # we are NOTTRIGGERED, but we have to start with the # audio that&#39;s already in the ring buffer. for f, s in ring_buffer: voiced_frames.append(f) ring_buffer.clear() else: # We&#39;re in the TRIGGERED state, so collect the audio data # and add it to the ring buffer. voiced_frames.append(frame) ring_buffer.append((frame, is_speech)) num_unvoiced = len([f for f, speech in ring_buffer if not speech]) # If more than 90% of the frames in the ring buffer are # unvoiced, then enter NOTTRIGGERED and yield whatever # audio we&#39;ve collected. if num_unvoiced &gt; 0.9 * ring_buffer.maxlen: triggered = False yield (start, frame.timestamp + frame.duration) ring_buffer.clear() voiced_frames = [] # If we have any leftover voiced audio when we run out of input, # yield it. if voiced_frames: yield (start, frame.timestamp + frame.duration) def VAD_chunk(aggressiveness, path): audio, byte_audio = read_wave(path, sr) vad = webrtcvad.Vad(int(aggressiveness)) frames = frame_generator(20, byte_audio, sr) frames = list(frames) times = vad_collector(sr, 20, 200, vad, frames) speech_times = [] speech_segs = [] for i, time in enumerate(times): start = np.round(time[0],decimals=2) end = np.round(time[1],decimals=2) j = start while j + .4 &lt; end: end_j = np.round(j+.4,decimals=2) speech_times.append((j, end_j)) speech_segs.append(audio[int(j*sr):int(end_j*sr)]) j = end_j else: speech_times.append((j, end)) speech_segs.append(audio[int(j*sr):int(end*sr)]) return speech_times, speech_segs . . # Based on code from PyTorch Speaker Verification: # https://github.com/HarryVolek/PyTorch_Speaker_Verification # Copyright (c) 2019, HarryVolek # Additions Copyright (c) 2021, Jim O&#39;Regan # License: MIT import numpy as np # wav2vec2&#39;s max duration is 40 seconds, using 39 by default # to be a little safer def vad_concat(times, segs, max_duration=39.0): &quot;&quot;&quot; Concatenate continuous times and their segments, where the end time of a segment is the same as the start time of the next Parameters: times: list of tuple (start, end) segs: list of segments (audio frames) max_duration: maximum duration of the resulting concatenated segments; the kernel size of wav2vec2 is 40 seconds, so the default max_duration is 39, to ensure the resulting list of segments will fit Returns: concat_times: list of tuple (start, end) concat_segs: list of segments (audio frames) &quot;&quot;&quot; absolute_maximum=40.0 if max_duration &gt; absolute_maximum: raise Exception(&#39;`max_duration` {:.2f} larger than kernel size (40 seconds)&#39;.format(max_duration)) # we take 0.0 to mean &quot;don&#39;t concatenate&quot; do_concat = (max_duration != 0.0) concat_seg = [] concat_times = [] seg_concat = segs[0] time_concat = times[0] for i in range(0, len(times)-1): can_concat = (times[i+1][1] - time_concat[0]) &lt; max_duration if time_concat[1] == times[i+1][0] and do_concat and can_concat: seg_concat = np.concatenate((seg_concat, segs[i+1])) time_concat = (time_concat[0], times[i+1][1]) else: concat_seg.append(seg_concat) seg_concat = segs[i+1] concat_times.append(time_concat) time_concat = times[i+1] else: concat_seg.append(seg_concat) concat_times.append(time_concat) return concat_times, concat_seg . . def make_dataset(concat_times, concat_segs): starts = [s[0] for s in concat_times] ends = [s[1] for s in concat_times] return {&#39;start&#39;: starts, &#39;end&#39;: ends, &#39;speech&#39;: concat_segs} . %%capture !pip install datasets . from datasets import Dataset def vad_to_dataset(path, max_duration): t,s = VAD_chunk(3, path) if max_duration &gt; 0.0: ct, cs = vad_concat(t, s, max_duration) dset = make_dataset(ct, cs) else: dset = make_dataset(t, s) return Dataset.from_dict(dset) . %%capture !pip install -q transformers . %%capture from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC # load model and tokenizer processor = Wav2Vec2Processor.from_pretrained(&quot;mbien/wav2vec2-large-xlsr-polish&quot;) model = Wav2Vec2ForCTC.from_pretrained(&quot;mbien/wav2vec2-large-xlsr-polish&quot;) model.to(&quot;cuda&quot;) . def speech_file_to_array_fn(batch): import torchaudio speech_array, sampling_rate = torchaudio.load(batch[&quot;path&quot;]) batch[&quot;speech&quot;] = speech_array[0].numpy() batch[&quot;sampling_rate&quot;] = sampling_rate batch[&quot;target_text&quot;] = batch[&quot;sentence&quot;] return batch def evaluate(batch): import torch inputs = processor(batch[&quot;speech&quot;], sampling_rate=16_000, return_tensors=&quot;pt&quot;, padding=True) with torch.no_grad(): logits = model(inputs.input_values.to(&quot;cuda&quot;), attention_mask=inputs.attention_mask.to(&quot;cuda&quot;)).logits pred_ids = torch.argmax(logits, dim=-1) batch[&quot;pred_strings&quot;] = processor.batch_decode(pred_ids) return batch . import json def process_wave(filename, duration): import json dataset = vad_to_dataset(filename, duration) result = dataset.map(evaluate, batched=True, batch_size=16) speechless = result.remove_columns([&#39;speech&#39;]) d=speechless.to_dict() tlog = list() for i in range(0, len(d[&#39;end&#39;]) - 1): out = dict() out[&#39;start&#39;] = d[&#39;start&#39;][i] out[&#39;end&#39;] = d[&#39;end&#39;][i] out[&#39;transcript&#39;] = d[&#39;pred_strings&#39;][i] tlog.append(out) with open(&#39;{}.tlog&#39;.format(filename), &#39;w&#39;) as outfile: json.dump(tlog, outfile) . import glob for f in glob.glob(&#39;/content/poleval_final_dataset_wav/train/*.wav&#39;): print(f) process_wave(f, 10.0) . !find . -name &#39;*tlog&#39;|zip poleval-train.zip -@ .",
            "url": "https://jimregan.github.io/notes/wav2vec2/poleval/colab/2021/06/16/poleval-through-wav2vec2.html",
            "relUrl": "/wav2vec2/poleval/colab/2021/06/16/poleval-through-wav2vec2.html",
            "date": " â€¢ Jun 16, 2021"
        }
        
    
  
    
        ,"post139": {
            "title": "Poleval 2021 punctuation restoration data",
            "content": "Original here . !pip install gdown . !gdown https://drive.google.com/uc?id=1PYfEhg-zGwnJ07HIaimlD3EgILPOBojq !gdown https://drive.google.com/uc?id=1b6MyyqgA9D1U7DX3Vtgda7f9ppkxjCXJ !gdown https://drive.google.com/uc?id=1gwQRvrUtFqz3xGnmEN8znAzkBwC12Czu !gdown https://drive.google.com/uc?id=16MaKgexMtMhQL6sftMsS3H1pPjJqY_zx . Downloading... From: https://drive.google.com/uc?id=1PYfEhg-zGwnJ07HIaimlD3EgILPOBojq To: /kaggle/working/poleval_fa.train.tar.gz 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.45M/1.45M [00:00&lt;00:00, 95.9MB/s] Downloading... From: https://drive.google.com/uc?id=1b6MyyqgA9D1U7DX3Vtgda7f9ppkxjCXJ To: /kaggle/working/poleval_wav.train.tar.gz 2.14GB [00:24, 86.7MB/s] Downloading... From: https://drive.google.com/uc?id=1gwQRvrUtFqz3xGnmEN8znAzkBwC12Czu To: /kaggle/working/poleval_wav.validation.tar.gz 537MB [00:08, 64.6MB/s] Downloading... From: https://drive.google.com/uc?id=16MaKgexMtMhQL6sftMsS3H1pPjJqY_zx To: /kaggle/working/poleval_text.rest.tar.gz 48.8MB [00:01, 29.6MB/s] .",
            "url": "https://jimregan.github.io/notes/asr/polish/kaggle/2021/06/16/poleval-2021-punctuation-restoration-data.html",
            "relUrl": "/asr/polish/kaggle/2021/06/16/poleval-2021-punctuation-restoration-data.html",
            "date": " â€¢ Jun 16, 2021"
        }
        
    
  
    
        ,"post140": {
            "title": "Poleval 2021 wav durations",
            "content": "%cd /tmp . /tmp . %%capture !tar zxvf /kaggle/input/poleval-2021-punctuation-restoration-data/poleval_wav.train.tar.gz . !for i in poleval_final_dataset_wav/train/*.wav;do ffmpeg -i $i 2&gt;&amp;1 | grep &quot;Duration&quot;;done . Duration: 00:01:50.34, bitrate: 256 kb/s Duration: 00:01:24.78, bitrate: 256 kb/s Duration: 00:01:17.90, bitrate: 256 kb/s Duration: 00:01:53.58, bitrate: 256 kb/s Duration: 00:01:09.72, bitrate: 256 kb/s Duration: 00:02:34.74, bitrate: 256 kb/s Duration: 00:01:22.14, bitrate: 256 kb/s Duration: 00:01:58.56, bitrate: 256 kb/s Duration: 00:01:45.78, bitrate: 256 kb/s Duration: 00:02:14.04, bitrate: 256 kb/s Duration: 00:01:34.72, bitrate: 256 kb/s Duration: 00:01:11.61, bitrate: 256 kb/s Duration: 00:01:07.25, bitrate: 256 kb/s Duration: 00:01:26.52, bitrate: 256 kb/s Duration: 00:01:40.56, bitrate: 256 kb/s Duration: 00:02:03.72, bitrate: 256 kb/s Duration: 00:02:13.02, bitrate: 256 kb/s Duration: 00:01:42.19, bitrate: 256 kb/s Duration: 00:01:26.94, bitrate: 256 kb/s Duration: 00:01:17.22, bitrate: 256 kb/s Duration: 00:01:55.62, bitrate: 256 kb/s Duration: 00:01:14.52, bitrate: 256 kb/s Duration: 00:01:22.14, bitrate: 256 kb/s Duration: 00:01:38.28, bitrate: 256 kb/s Duration: 00:01:44.52, bitrate: 256 kb/s Duration: 00:01:27.66, bitrate: 256 kb/s Duration: 00:01:55.97, bitrate: 256 kb/s Duration: 00:01:31.44, bitrate: 256 kb/s Duration: 00:01:54.71, bitrate: 256 kb/s Duration: 00:01:52.38, bitrate: 256 kb/s Duration: 00:01:56.28, bitrate: 256 kb/s Duration: 00:01:39.15, bitrate: 256 kb/s Duration: 00:02:26.28, bitrate: 256 kb/s Duration: 00:01:33.30, bitrate: 256 kb/s Duration: 00:01:57.72, bitrate: 256 kb/s Duration: 00:01:21.96, bitrate: 256 kb/s Duration: 00:01:39.36, bitrate: 256 kb/s Duration: 00:01:22.32, bitrate: 256 kb/s Duration: 00:01:34.36, bitrate: 256 kb/s Duration: 00:02:29.35, bitrate: 256 kb/s Duration: 00:01:22.13, bitrate: 256 kb/s Duration: 00:01:37.74, bitrate: 256 kb/s Duration: 00:01:47.04, bitrate: 256 kb/s Duration: 00:02:51.36, bitrate: 256 kb/s Duration: 00:01:05.40, bitrate: 256 kb/s Duration: 00:01:23.10, bitrate: 256 kb/s Duration: 00:01:33.22, bitrate: 256 kb/s Duration: 00:01:21.00, bitrate: 256 kb/s Duration: 00:01:21.15, bitrate: 256 kb/s Duration: 00:01:24.22, bitrate: 256 kb/s Duration: 00:01:31.62, bitrate: 256 kb/s Duration: 00:01:28.98, bitrate: 256 kb/s Duration: 00:01:15.30, bitrate: 256 kb/s Duration: 00:01:32.40, bitrate: 256 kb/s Duration: 00:01:08.44, bitrate: 256 kb/s Duration: 00:01:17.88, bitrate: 256 kb/s Duration: 00:01:15.66, bitrate: 256 kb/s Duration: 00:01:54.19, bitrate: 256 kb/s Duration: 00:01:41.34, bitrate: 256 kb/s Duration: 00:01:26.24, bitrate: 256 kb/s Duration: 00:02:12.45, bitrate: 256 kb/s Duration: 00:01:12.23, bitrate: 256 kb/s Duration: 00:01:13.10, bitrate: 256 kb/s Duration: 00:01:12.90, bitrate: 256 kb/s Duration: 00:01:14.70, bitrate: 256 kb/s Duration: 00:01:33.24, bitrate: 256 kb/s Duration: 00:01:20.70, bitrate: 256 kb/s Duration: 00:02:06.66, bitrate: 256 kb/s Duration: 00:01:34.74, bitrate: 256 kb/s Duration: 00:01:38.64, bitrate: 256 kb/s Duration: 00:02:02.07, bitrate: 256 kb/s Duration: 00:01:25.25, bitrate: 256 kb/s Duration: 00:01:06.68, bitrate: 256 kb/s Duration: 00:01:35.94, bitrate: 256 kb/s Duration: 00:02:09.75, bitrate: 256 kb/s Duration: 00:02:04.29, bitrate: 256 kb/s Duration: 00:01:44.12, bitrate: 256 kb/s Duration: 00:01:22.44, bitrate: 256 kb/s Duration: 00:01:00.60, bitrate: 256 kb/s Duration: 00:01:25.44, bitrate: 256 kb/s Duration: 00:02:00.00, bitrate: 256 kb/s Duration: 00:02:30.72, bitrate: 256 kb/s Duration: 00:01:51.30, bitrate: 256 kb/s Duration: 00:02:00.41, bitrate: 256 kb/s Duration: 00:01:46.62, bitrate: 256 kb/s Duration: 00:01:22.50, bitrate: 256 kb/s Duration: 00:01:33.20, bitrate: 256 kb/s Duration: 00:01:29.58, bitrate: 256 kb/s Duration: 00:01:47.70, bitrate: 256 kb/s Duration: 00:02:40.32, bitrate: 256 kb/s Duration: 00:01:26.70, bitrate: 256 kb/s Duration: 00:02:05.34, bitrate: 256 kb/s Duration: 00:01:23.64, bitrate: 256 kb/s Duration: 00:01:20.16, bitrate: 256 kb/s Duration: 00:02:21.60, bitrate: 256 kb/s Duration: 00:01:19.26, bitrate: 256 kb/s Duration: 00:01:54.04, bitrate: 256 kb/s Duration: 00:01:34.02, bitrate: 256 kb/s Duration: 00:01:21.96, bitrate: 256 kb/s Duration: 00:01:42.66, bitrate: 256 kb/s Duration: 00:01:44.45, bitrate: 256 kb/s Duration: 00:01:58.26, bitrate: 256 kb/s Duration: 00:00:59.18, bitrate: 256 kb/s Duration: 00:02:40.20, bitrate: 256 kb/s Duration: 00:01:49.02, bitrate: 256 kb/s Duration: 00:01:17.52, bitrate: 256 kb/s Duration: 00:01:13.98, bitrate: 256 kb/s Duration: 00:01:11.77, bitrate: 256 kb/s Duration: 00:01:13.38, bitrate: 256 kb/s Duration: 00:01:34.98, bitrate: 256 kb/s Duration: 00:02:47.88, bitrate: 256 kb/s Duration: 00:01:03.36, bitrate: 256 kb/s Duration: 00:00:56.88, bitrate: 256 kb/s Duration: 00:01:29.54, bitrate: 256 kb/s Duration: 00:01:28.84, bitrate: 256 kb/s Duration: 00:02:08.34, bitrate: 256 kb/s Duration: 00:00:55.47, bitrate: 256 kb/s Duration: 00:02:00.84, bitrate: 256 kb/s Duration: 00:01:43.44, bitrate: 256 kb/s Duration: 00:02:03.39, bitrate: 256 kb/s Duration: 00:01:12.30, bitrate: 256 kb/s Duration: 00:00:59.40, bitrate: 256 kb/s Duration: 00:01:21.18, bitrate: 256 kb/s Duration: 00:01:11.52, bitrate: 256 kb/s Duration: 00:02:04.74, bitrate: 256 kb/s Duration: 00:01:31.44, bitrate: 256 kb/s Duration: 00:01:07.68, bitrate: 256 kb/s Duration: 00:01:23.10, bitrate: 256 kb/s Duration: 00:02:44.94, bitrate: 256 kb/s Duration: 00:01:52.43, bitrate: 256 kb/s Duration: 00:01:16.86, bitrate: 256 kb/s Duration: 00:01:34.56, bitrate: 256 kb/s Duration: 00:01:57.12, bitrate: 256 kb/s Duration: 00:02:18.18, bitrate: 256 kb/s Duration: 00:01:28.26, bitrate: 256 kb/s Duration: 00:01:31.38, bitrate: 256 kb/s Duration: 00:02:25.02, bitrate: 256 kb/s Duration: 00:01:19.92, bitrate: 256 kb/s Duration: 00:01:14.04, bitrate: 256 kb/s Duration: 00:01:14.16, bitrate: 256 kb/s Duration: 00:01:15.00, bitrate: 256 kb/s Duration: 00:01:44.92, bitrate: 256 kb/s Duration: 00:01:30.66, bitrate: 256 kb/s Duration: 00:01:57.90, bitrate: 256 kb/s Duration: 00:01:59.76, bitrate: 256 kb/s Duration: 00:01:32.58, bitrate: 256 kb/s Duration: 00:01:16.56, bitrate: 256 kb/s Duration: 00:01:34.38, bitrate: 256 kb/s Duration: 00:01:37.96, bitrate: 256 kb/s Duration: 00:01:49.74, bitrate: 256 kb/s Duration: 00:01:15.54, bitrate: 256 kb/s Duration: 00:01:23.04, bitrate: 256 kb/s Duration: 00:02:08.38, bitrate: 256 kb/s Duration: 00:01:41.76, bitrate: 256 kb/s Duration: 00:01:12.54, bitrate: 256 kb/s Duration: 00:01:24.96, bitrate: 256 kb/s Duration: 00:01:52.43, bitrate: 256 kb/s Duration: 00:00:58.51, bitrate: 256 kb/s Duration: 00:01:48.06, bitrate: 256 kb/s Duration: 00:01:10.27, bitrate: 256 kb/s Duration: 00:02:35.73, bitrate: 256 kb/s Duration: 00:02:28.26, bitrate: 256 kb/s Duration: 00:02:08.96, bitrate: 256 kb/s Duration: 00:01:19.91, bitrate: 256 kb/s Duration: 00:01:20.21, bitrate: 256 kb/s Duration: 00:01:11.68, bitrate: 256 kb/s Duration: 00:01:38.46, bitrate: 256 kb/s Duration: 00:01:58.80, bitrate: 256 kb/s Duration: 00:01:16.68, bitrate: 256 kb/s Duration: 00:01:18.36, bitrate: 256 kb/s Duration: 00:01:18.07, bitrate: 256 kb/s Duration: 00:01:29.64, bitrate: 256 kb/s Duration: 00:02:06.12, bitrate: 256 kb/s Duration: 00:01:05.64, bitrate: 256 kb/s Duration: 00:01:25.80, bitrate: 256 kb/s Duration: 00:02:22.32, bitrate: 256 kb/s Duration: 00:02:00.00, bitrate: 256 kb/s Duration: 00:01:13.98, bitrate: 256 kb/s Duration: 00:01:14.42, bitrate: 256 kb/s Duration: 00:01:22.50, bitrate: 256 kb/s Duration: 00:02:00.79, bitrate: 256 kb/s Duration: 00:02:13.68, bitrate: 256 kb/s Duration: 00:02:18.24, bitrate: 256 kb/s Duration: 00:01:21.49, bitrate: 256 kb/s Duration: 00:01:34.21, bitrate: 256 kb/s Duration: 00:01:34.80, bitrate: 256 kb/s Duration: 00:02:17.52, bitrate: 256 kb/s Duration: 00:01:20.28, bitrate: 256 kb/s Duration: 00:01:27.78, bitrate: 256 kb/s Duration: 00:01:56.28, bitrate: 256 kb/s Duration: 00:01:14.46, bitrate: 256 kb/s Duration: 00:01:11.94, bitrate: 256 kb/s Duration: 00:01:32.82, bitrate: 256 kb/s Duration: 00:02:18.66, bitrate: 256 kb/s Duration: 00:01:45.96, bitrate: 256 kb/s Duration: 00:01:29.30, bitrate: 256 kb/s Duration: 00:01:52.20, bitrate: 256 kb/s Duration: 00:01:15.72, bitrate: 256 kb/s Duration: 00:01:20.40, bitrate: 256 kb/s Duration: 00:01:33.54, bitrate: 256 kb/s Duration: 00:01:43.32, bitrate: 256 kb/s Duration: 00:01:53.76, bitrate: 256 kb/s Duration: 00:01:12.06, bitrate: 256 kb/s Duration: 00:01:26.27, bitrate: 256 kb/s Duration: 00:01:19.68, bitrate: 256 kb/s Duration: 00:01:24.82, bitrate: 256 kb/s Duration: 00:01:33.53, bitrate: 256 kb/s Duration: 00:01:28.74, bitrate: 256 kb/s Duration: 00:01:53.16, bitrate: 256 kb/s Duration: 00:01:29.64, bitrate: 256 kb/s Duration: 00:01:28.56, bitrate: 256 kb/s Duration: 00:01:44.38, bitrate: 256 kb/s Duration: 00:02:02.46, bitrate: 256 kb/s Duration: 00:01:09.29, bitrate: 256 kb/s Duration: 00:01:35.80, bitrate: 256 kb/s Duration: 00:00:59.95, bitrate: 256 kb/s Duration: 00:01:46.32, bitrate: 256 kb/s Duration: 00:01:32.40, bitrate: 256 kb/s Duration: 00:01:23.82, bitrate: 256 kb/s Duration: 00:01:45.02, bitrate: 256 kb/s Duration: 00:01:57.90, bitrate: 256 kb/s Duration: 00:01:37.32, bitrate: 256 kb/s Duration: 00:01:58.44, bitrate: 256 kb/s Duration: 00:01:28.66, bitrate: 256 kb/s Duration: 00:01:33.78, bitrate: 256 kb/s Duration: 00:01:49.23, bitrate: 256 kb/s Duration: 00:01:35.34, bitrate: 256 kb/s Duration: 00:01:44.63, bitrate: 256 kb/s Duration: 00:01:46.50, bitrate: 256 kb/s Duration: 00:01:56.04, bitrate: 256 kb/s Duration: 00:01:13.72, bitrate: 256 kb/s Duration: 00:01:14.76, bitrate: 256 kb/s Duration: 00:01:29.16, bitrate: 256 kb/s Duration: 00:01:13.38, bitrate: 256 kb/s Duration: 00:01:27.08, bitrate: 256 kb/s Duration: 00:01:50.10, bitrate: 256 kb/s Duration: 00:02:05.27, bitrate: 256 kb/s Duration: 00:01:59.07, bitrate: 256 kb/s Duration: 00:01:25.03, bitrate: 256 kb/s Duration: 00:01:25.89, bitrate: 256 kb/s Duration: 00:01:37.68, bitrate: 256 kb/s Duration: 00:01:12.53, bitrate: 256 kb/s Duration: 00:01:40.26, bitrate: 256 kb/s Duration: 00:01:25.80, bitrate: 256 kb/s Duration: 00:01:31.44, bitrate: 256 kb/s Duration: 00:01:02.29, bitrate: 256 kb/s Duration: 00:01:42.06, bitrate: 256 kb/s Duration: 00:01:47.82, bitrate: 256 kb/s Duration: 00:01:13.86, bitrate: 256 kb/s Duration: 00:01:27.44, bitrate: 256 kb/s Duration: 00:01:18.84, bitrate: 256 kb/s Duration: 00:01:28.38, bitrate: 256 kb/s Duration: 00:02:04.50, bitrate: 256 kb/s Duration: 00:01:27.49, bitrate: 256 kb/s Duration: 00:01:41.28, bitrate: 256 kb/s Duration: 00:01:30.06, bitrate: 256 kb/s Duration: 00:02:03.42, bitrate: 256 kb/s Duration: 00:01:39.54, bitrate: 256 kb/s Duration: 00:01:05.76, bitrate: 256 kb/s Duration: 00:02:08.76, bitrate: 256 kb/s Duration: 00:02:29.34, bitrate: 256 kb/s Duration: 00:01:15.00, bitrate: 256 kb/s Duration: 00:01:07.26, bitrate: 256 kb/s Duration: 00:02:16.06, bitrate: 256 kb/s Duration: 00:01:35.58, bitrate: 256 kb/s Duration: 00:01:37.62, bitrate: 256 kb/s Duration: 00:02:07.32, bitrate: 256 kb/s Duration: 00:01:33.66, bitrate: 256 kb/s Duration: 00:01:42.30, bitrate: 256 kb/s Duration: 00:01:52.02, bitrate: 256 kb/s Duration: 00:01:36.24, bitrate: 256 kb/s Duration: 00:01:20.70, bitrate: 256 kb/s Duration: 00:01:09.47, bitrate: 256 kb/s Duration: 00:01:34.27, bitrate: 256 kb/s Duration: 00:01:33.12, bitrate: 256 kb/s Duration: 00:01:21.32, bitrate: 256 kb/s Duration: 00:01:43.56, bitrate: 256 kb/s Duration: 00:01:13.26, bitrate: 256 kb/s Duration: 00:01:20.10, bitrate: 256 kb/s Duration: 00:01:18.96, bitrate: 256 kb/s Duration: 00:01:50.76, bitrate: 256 kb/s Duration: 00:01:53.16, bitrate: 256 kb/s Duration: 00:01:16.25, bitrate: 256 kb/s Duration: 00:02:17.51, bitrate: 256 kb/s Duration: 00:01:26.58, bitrate: 256 kb/s Duration: 00:01:03.96, bitrate: 256 kb/s Duration: 00:01:14.45, bitrate: 256 kb/s Duration: 00:01:39.06, bitrate: 256 kb/s Duration: 00:01:17.10, bitrate: 256 kb/s Duration: 00:01:23.46, bitrate: 256 kb/s Duration: 00:01:20.46, bitrate: 256 kb/s Duration: 00:01:40.62, bitrate: 256 kb/s Duration: 00:01:10.45, bitrate: 256 kb/s Duration: 00:01:59.04, bitrate: 256 kb/s Duration: 00:02:12.95, bitrate: 256 kb/s Duration: 00:01:11.28, bitrate: 256 kb/s Duration: 00:01:47.52, bitrate: 256 kb/s Duration: 00:01:38.05, bitrate: 256 kb/s Duration: 00:01:53.45, bitrate: 256 kb/s Duration: 00:01:49.08, bitrate: 256 kb/s Duration: 00:01:20.13, bitrate: 256 kb/s Duration: 00:01:31.20, bitrate: 256 kb/s Duration: 00:01:54.96, bitrate: 256 kb/s Duration: 00:02:13.74, bitrate: 256 kb/s Duration: 00:01:52.56, bitrate: 256 kb/s Duration: 00:02:05.04, bitrate: 256 kb/s Duration: 00:01:47.28, bitrate: 256 kb/s Duration: 00:01:30.70, bitrate: 256 kb/s Duration: 00:01:48.54, bitrate: 256 kb/s Duration: 00:01:19.80, bitrate: 256 kb/s Duration: 00:02:17.28, bitrate: 256 kb/s Duration: 00:01:53.04, bitrate: 256 kb/s Duration: 00:01:14.34, bitrate: 256 kb/s Duration: 00:01:24.78, bitrate: 256 kb/s Duration: 00:01:40.56, bitrate: 256 kb/s Duration: 00:01:26.22, bitrate: 256 kb/s Duration: 00:01:21.66, bitrate: 256 kb/s Duration: 00:01:49.48, bitrate: 256 kb/s Duration: 00:01:41.46, bitrate: 256 kb/s Duration: 00:01:13.74, bitrate: 256 kb/s Duration: 00:01:52.38, bitrate: 256 kb/s Duration: 00:01:26.94, bitrate: 256 kb/s Duration: 00:01:45.30, bitrate: 256 kb/s Duration: 00:01:26.58, bitrate: 256 kb/s Duration: 00:02:02.10, bitrate: 256 kb/s Duration: 00:01:22.73, bitrate: 256 kb/s Duration: 00:01:42.84, bitrate: 256 kb/s Duration: 00:02:14.52, bitrate: 256 kb/s Duration: 00:02:09.66, bitrate: 256 kb/s Duration: 00:01:30.98, bitrate: 256 kb/s Duration: 00:02:09.54, bitrate: 256 kb/s Duration: 00:01:18.60, bitrate: 256 kb/s Duration: 00:01:33.24, bitrate: 256 kb/s Duration: 00:01:33.78, bitrate: 256 kb/s Duration: 00:02:07.74, bitrate: 256 kb/s Duration: 00:01:22.02, bitrate: 256 kb/s Duration: 00:01:50.98, bitrate: 256 kb/s Duration: 00:01:32.10, bitrate: 256 kb/s Duration: 00:01:59.40, bitrate: 256 kb/s Duration: 00:01:25.20, bitrate: 256 kb/s Duration: 00:01:40.26, bitrate: 256 kb/s Duration: 00:01:07.08, bitrate: 256 kb/s Duration: 00:01:48.38, bitrate: 256 kb/s Duration: 00:01:26.28, bitrate: 256 kb/s Duration: 00:02:14.94, bitrate: 256 kb/s Duration: 00:02:10.54, bitrate: 256 kb/s Duration: 00:01:37.50, bitrate: 256 kb/s Duration: 00:02:26.70, bitrate: 256 kb/s Duration: 00:01:57.72, bitrate: 256 kb/s Duration: 00:01:20.94, bitrate: 256 kb/s Duration: 00:01:36.06, bitrate: 256 kb/s Duration: 00:01:48.78, bitrate: 256 kb/s Duration: 00:01:32.76, bitrate: 256 kb/s Duration: 00:01:45.64, bitrate: 256 kb/s Duration: 00:02:19.26, bitrate: 256 kb/s Duration: 00:01:13.75, bitrate: 256 kb/s Duration: 00:01:54.90, bitrate: 256 kb/s Duration: 00:01:16.12, bitrate: 256 kb/s Duration: 00:01:42.84, bitrate: 256 kb/s Duration: 00:01:22.68, bitrate: 256 kb/s Duration: 00:01:25.62, bitrate: 256 kb/s Duration: 00:01:33.18, bitrate: 256 kb/s Duration: 00:01:34.74, bitrate: 256 kb/s Duration: 00:01:45.42, bitrate: 256 kb/s Duration: 00:01:41.04, bitrate: 256 kb/s Duration: 00:01:58.14, bitrate: 256 kb/s Duration: 00:02:11.52, bitrate: 256 kb/s Duration: 00:02:01.04, bitrate: 256 kb/s Duration: 00:01:39.36, bitrate: 256 kb/s Duration: 00:01:26.70, bitrate: 256 kb/s Duration: 00:01:59.28, bitrate: 256 kb/s Duration: 00:02:12.72, bitrate: 256 kb/s Duration: 00:01:33.96, bitrate: 256 kb/s Duration: 00:01:44.03, bitrate: 256 kb/s Duration: 00:01:44.10, bitrate: 256 kb/s Duration: 00:01:06.12, bitrate: 256 kb/s Duration: 00:02:28.46, bitrate: 256 kb/s Duration: 00:02:06.78, bitrate: 256 kb/s Duration: 00:01:57.18, bitrate: 256 kb/s Duration: 00:01:20.52, bitrate: 256 kb/s Duration: 00:01:42.84, bitrate: 256 kb/s Duration: 00:01:33.54, bitrate: 256 kb/s Duration: 00:01:41.10, bitrate: 256 kb/s Duration: 00:02:47.74, bitrate: 256 kb/s Duration: 00:02:25.32, bitrate: 256 kb/s Duration: 00:01:50.58, bitrate: 256 kb/s Duration: 00:01:39.18, bitrate: 256 kb/s Duration: 00:01:52.80, bitrate: 256 kb/s Duration: 00:01:23.58, bitrate: 256 kb/s Duration: 00:01:10.36, bitrate: 256 kb/s Duration: 00:01:36.30, bitrate: 256 kb/s Duration: 00:01:36.06, bitrate: 256 kb/s Duration: 00:01:34.32, bitrate: 256 kb/s Duration: 00:02:53.40, bitrate: 256 kb/s Duration: 00:02:19.55, bitrate: 256 kb/s Duration: 00:01:07.02, bitrate: 256 kb/s Duration: 00:01:24.84, bitrate: 256 kb/s Duration: 00:01:26.36, bitrate: 256 kb/s Duration: 00:01:36.30, bitrate: 256 kb/s Duration: 00:01:28.65, bitrate: 256 kb/s Duration: 00:01:59.64, bitrate: 256 kb/s Duration: 00:01:59.82, bitrate: 256 kb/s Duration: 00:02:19.69, bitrate: 256 kb/s Duration: 00:01:48.42, bitrate: 256 kb/s Duration: 00:01:27.89, bitrate: 256 kb/s Duration: 00:02:45.30, bitrate: 256 kb/s Duration: 00:01:53.34, bitrate: 256 kb/s Duration: 00:01:52.80, bitrate: 256 kb/s Duration: 00:01:37.80, bitrate: 256 kb/s Duration: 00:02:03.54, bitrate: 256 kb/s Duration: 00:01:35.70, bitrate: 256 kb/s Duration: 00:02:00.42, bitrate: 256 kb/s Duration: 00:02:21.60, bitrate: 256 kb/s Duration: 00:01:24.95, bitrate: 256 kb/s Duration: 00:02:11.34, bitrate: 256 kb/s Duration: 00:01:07.16, bitrate: 256 kb/s Duration: 00:01:29.94, bitrate: 256 kb/s Duration: 00:02:53.46, bitrate: 256 kb/s Duration: 00:02:24.96, bitrate: 256 kb/s Duration: 00:01:21.24, bitrate: 256 kb/s Duration: 00:03:23.48, bitrate: 256 kb/s Duration: 00:02:08.40, bitrate: 256 kb/s Duration: 00:01:32.40, bitrate: 256 kb/s Duration: 00:01:55.92, bitrate: 256 kb/s Duration: 00:01:58.79, bitrate: 256 kb/s Duration: 00:01:18.36, bitrate: 256 kb/s Duration: 00:02:33.36, bitrate: 256 kb/s Duration: 00:01:05.83, bitrate: 256 kb/s Duration: 00:01:47.94, bitrate: 256 kb/s Duration: 00:01:45.60, bitrate: 256 kb/s Duration: 00:01:19.14, bitrate: 256 kb/s Duration: 00:01:27.18, bitrate: 256 kb/s Duration: 00:02:19.32, bitrate: 256 kb/s Duration: 00:01:36.90, bitrate: 256 kb/s Duration: 00:02:06.90, bitrate: 256 kb/s Duration: 00:01:49.46, bitrate: 256 kb/s Duration: 00:02:03.24, bitrate: 256 kb/s Duration: 00:01:34.80, bitrate: 256 kb/s Duration: 00:01:57.24, bitrate: 256 kb/s Duration: 00:01:25.26, bitrate: 256 kb/s Duration: 00:01:13.69, bitrate: 256 kb/s Duration: 00:01:16.56, bitrate: 256 kb/s Duration: 00:01:36.72, bitrate: 256 kb/s Duration: 00:01:27.18, bitrate: 256 kb/s Duration: 00:01:25.86, bitrate: 256 kb/s Duration: 00:01:17.35, bitrate: 256 kb/s Duration: 00:01:01.50, bitrate: 256 kb/s Duration: 00:01:09.85, bitrate: 256 kb/s Duration: 00:02:00.78, bitrate: 256 kb/s Duration: 00:01:33.40, bitrate: 256 kb/s Duration: 00:01:23.94, bitrate: 256 kb/s Duration: 00:02:27.96, bitrate: 256 kb/s Duration: 00:01:23.64, bitrate: 256 kb/s Duration: 00:01:37.66, bitrate: 256 kb/s Duration: 00:01:24.82, bitrate: 256 kb/s Duration: 00:01:22.38, bitrate: 256 kb/s Duration: 00:01:35.88, bitrate: 256 kb/s Duration: 00:01:13.75, bitrate: 256 kb/s Duration: 00:01:37.38, bitrate: 256 kb/s Duration: 00:01:11.58, bitrate: 256 kb/s Duration: 00:01:32.88, bitrate: 256 kb/s Duration: 00:01:51.42, bitrate: 256 kb/s Duration: 00:01:52.52, bitrate: 256 kb/s Duration: 00:01:17.40, bitrate: 256 kb/s Duration: 00:01:34.50, bitrate: 256 kb/s Duration: 00:01:55.11, bitrate: 256 kb/s Duration: 00:01:57.60, bitrate: 256 kb/s Duration: 00:01:33.01, bitrate: 256 kb/s Duration: 00:01:51.90, bitrate: 256 kb/s Duration: 00:02:30.22, bitrate: 256 kb/s Duration: 00:01:36.48, bitrate: 256 kb/s Duration: 00:02:14.91, bitrate: 256 kb/s Duration: 00:01:59.64, bitrate: 256 kb/s Duration: 00:04:04.50, bitrate: 256 kb/s Duration: 00:01:50.70, bitrate: 256 kb/s Duration: 00:02:13.20, bitrate: 256 kb/s Duration: 00:02:20.94, bitrate: 256 kb/s Duration: 00:01:26.52, bitrate: 256 kb/s Duration: 00:02:15.18, bitrate: 256 kb/s Duration: 00:01:14.82, bitrate: 256 kb/s Duration: 00:01:23.16, bitrate: 256 kb/s Duration: 00:01:15.60, bitrate: 256 kb/s Duration: 00:01:38.18, bitrate: 256 kb/s Duration: 00:01:20.40, bitrate: 256 kb/s Duration: 00:01:25.14, bitrate: 256 kb/s Duration: 00:01:35.28, bitrate: 256 kb/s Duration: 00:02:10.26, bitrate: 256 kb/s Duration: 00:01:23.93, bitrate: 256 kb/s Duration: 00:01:17.46, bitrate: 256 kb/s Duration: 00:01:01.61, bitrate: 256 kb/s Duration: 00:01:43.42, bitrate: 256 kb/s Duration: 00:01:13.81, bitrate: 256 kb/s Duration: 00:02:34.32, bitrate: 256 kb/s Duration: 00:01:16.14, bitrate: 256 kb/s Duration: 00:01:25.92, bitrate: 256 kb/s Duration: 00:01:10.22, bitrate: 256 kb/s Duration: 00:01:16.48, bitrate: 256 kb/s Duration: 00:01:09.60, bitrate: 256 kb/s Duration: 00:02:37.31, bitrate: 256 kb/s Duration: 00:01:19.32, bitrate: 256 kb/s Duration: 00:02:04.02, bitrate: 256 kb/s Duration: 00:01:27.90, bitrate: 256 kb/s Duration: 00:01:34.92, bitrate: 256 kb/s Duration: 00:02:00.42, bitrate: 256 kb/s Duration: 00:01:25.94, bitrate: 256 kb/s Duration: 00:01:26.40, bitrate: 256 kb/s Duration: 00:01:56.28, bitrate: 256 kb/s Duration: 00:02:10.80, bitrate: 256 kb/s Duration: 00:02:05.10, bitrate: 256 kb/s Duration: 00:01:25.93, bitrate: 256 kb/s Duration: 00:01:18.02, bitrate: 256 kb/s Duration: 00:01:15.66, bitrate: 256 kb/s Duration: 00:02:11.24, bitrate: 256 kb/s Duration: 00:01:11.04, bitrate: 256 kb/s Duration: 00:01:27.68, bitrate: 256 kb/s Duration: 00:01:21.46, bitrate: 256 kb/s Duration: 00:01:24.18, bitrate: 256 kb/s Duration: 00:01:10.14, bitrate: 256 kb/s Duration: 00:01:29.52, bitrate: 256 kb/s Duration: 00:01:38.94, bitrate: 256 kb/s Duration: 00:01:33.12, bitrate: 256 kb/s Duration: 00:01:39.18, bitrate: 256 kb/s Duration: 00:01:33.82, bitrate: 256 kb/s Duration: 00:01:13.68, bitrate: 256 kb/s Duration: 00:01:36.42, bitrate: 256 kb/s Duration: 00:01:37.08, bitrate: 256 kb/s Duration: 00:01:02.38, bitrate: 256 kb/s Duration: 00:01:24.54, bitrate: 256 kb/s Duration: 00:02:15.18, bitrate: 256 kb/s Duration: 00:02:34.62, bitrate: 256 kb/s Duration: 00:01:31.68, bitrate: 256 kb/s Duration: 00:03:07.56, bitrate: 256 kb/s Duration: 00:01:20.16, bitrate: 256 kb/s Duration: 00:01:59.40, bitrate: 256 kb/s Duration: 00:01:33.95, bitrate: 256 kb/s Duration: 00:01:51.87, bitrate: 256 kb/s Duration: 00:01:23.40, bitrate: 256 kb/s Duration: 00:01:03.60, bitrate: 256 kb/s Duration: 00:01:20.34, bitrate: 256 kb/s Duration: 00:01:47.70, bitrate: 256 kb/s Duration: 00:02:43.50, bitrate: 256 kb/s Duration: 00:01:24.47, bitrate: 256 kb/s Duration: 00:01:37.56, bitrate: 256 kb/s Duration: 00:01:54.42, bitrate: 256 kb/s Duration: 00:01:15.66, bitrate: 256 kb/s Duration: 00:01:33.31, bitrate: 256 kb/s Duration: 00:02:07.32, bitrate: 256 kb/s Duration: 00:01:39.18, bitrate: 256 kb/s Duration: 00:01:46.16, bitrate: 256 kb/s Duration: 00:01:50.40, bitrate: 256 kb/s Duration: 00:02:35.70, bitrate: 256 kb/s Duration: 00:01:51.54, bitrate: 256 kb/s Duration: 00:01:41.46, bitrate: 256 kb/s Duration: 00:01:29.52, bitrate: 256 kb/s Duration: 00:02:40.62, bitrate: 256 kb/s Duration: 00:02:14.76, bitrate: 256 kb/s Duration: 00:01:25.32, bitrate: 256 kb/s Duration: 00:01:04.68, bitrate: 256 kb/s Duration: 00:01:30.54, bitrate: 256 kb/s Duration: 00:01:18.90, bitrate: 256 kb/s Duration: 00:01:05.45, bitrate: 256 kb/s Duration: 00:01:21.24, bitrate: 256 kb/s Duration: 00:02:01.09, bitrate: 256 kb/s Duration: 00:02:14.21, bitrate: 256 kb/s Duration: 00:01:17.22, bitrate: 256 kb/s Duration: 00:01:46.44, bitrate: 256 kb/s Duration: 00:02:39.54, bitrate: 256 kb/s Duration: 00:02:03.31, bitrate: 256 kb/s Duration: 00:01:38.52, bitrate: 256 kb/s Duration: 00:02:04.98, bitrate: 256 kb/s Duration: 00:01:51.54, bitrate: 256 kb/s Duration: 00:02:44.94, bitrate: 256 kb/s Duration: 00:01:40.32, bitrate: 256 kb/s Duration: 00:01:25.62, bitrate: 256 kb/s Duration: 00:01:28.33, bitrate: 256 kb/s Duration: 00:01:13.20, bitrate: 256 kb/s Duration: 00:01:18.30, bitrate: 256 kb/s Duration: 00:01:47.40, bitrate: 256 kb/s Duration: 00:02:05.10, bitrate: 256 kb/s Duration: 00:02:42.72, bitrate: 256 kb/s Duration: 00:01:22.80, bitrate: 256 kb/s Duration: 00:01:37.02, bitrate: 256 kb/s Duration: 00:01:27.73, bitrate: 256 kb/s Duration: 00:01:42.96, bitrate: 256 kb/s Duration: 00:01:24.12, bitrate: 256 kb/s Duration: 00:01:25.67, bitrate: 256 kb/s Duration: 00:01:30.23, bitrate: 256 kb/s Duration: 00:01:19.14, bitrate: 256 kb/s Duration: 00:01:24.06, bitrate: 256 kb/s Duration: 00:01:26.64, bitrate: 256 kb/s Duration: 00:01:33.39, bitrate: 256 kb/s Duration: 00:01:40.68, bitrate: 256 kb/s Duration: 00:01:41.38, bitrate: 256 kb/s Duration: 00:02:34.62, bitrate: 256 kb/s Duration: 00:01:27.36, bitrate: 256 kb/s Duration: 00:01:58.68, bitrate: 256 kb/s Duration: 00:01:36.78, bitrate: 256 kb/s Duration: 00:01:58.26, bitrate: 256 kb/s Duration: 00:01:09.21, bitrate: 256 kb/s Duration: 00:01:24.78, bitrate: 256 kb/s Duration: 00:01:17.65, bitrate: 256 kb/s Duration: 00:01:34.80, bitrate: 256 kb/s Duration: 00:01:20.58, bitrate: 256 kb/s Duration: 00:01:22.38, bitrate: 256 kb/s Duration: 00:01:59.06, bitrate: 256 kb/s Duration: 00:01:22.26, bitrate: 256 kb/s Duration: 00:01:09.12, bitrate: 256 kb/s Duration: 00:01:41.94, bitrate: 256 kb/s Duration: 00:01:34.32, bitrate: 256 kb/s Duration: 00:01:07.88, bitrate: 256 kb/s Duration: 00:01:41.28, bitrate: 256 kb/s Duration: 00:01:43.08, bitrate: 256 kb/s Duration: 00:01:45.51, bitrate: 256 kb/s Duration: 00:01:24.96, bitrate: 256 kb/s Duration: 00:01:42.42, bitrate: 256 kb/s Duration: 00:02:27.78, bitrate: 256 kb/s Duration: 00:01:59.34, bitrate: 256 kb/s Duration: 00:01:37.52, bitrate: 256 kb/s Duration: 00:01:51.12, bitrate: 256 kb/s Duration: 00:02:26.16, bitrate: 256 kb/s Duration: 00:02:15.36, bitrate: 256 kb/s Duration: 00:02:04.08, bitrate: 256 kb/s Duration: 00:01:30.06, bitrate: 256 kb/s Duration: 00:02:04.98, bitrate: 256 kb/s Duration: 00:02:35.94, bitrate: 256 kb/s Duration: 00:02:03.72, bitrate: 256 kb/s Duration: 00:01:45.78, bitrate: 256 kb/s Duration: 00:01:34.56, bitrate: 256 kb/s Duration: 00:01:30.78, bitrate: 256 kb/s Duration: 00:01:34.98, bitrate: 256 kb/s Duration: 00:02:13.56, bitrate: 256 kb/s Duration: 00:02:09.02, bitrate: 256 kb/s Duration: 00:01:11.76, bitrate: 256 kb/s Duration: 00:02:07.80, bitrate: 256 kb/s Duration: 00:01:23.94, bitrate: 256 kb/s Duration: 00:01:17.64, bitrate: 256 kb/s Duration: 00:01:12.24, bitrate: 256 kb/s Duration: 00:01:43.32, bitrate: 256 kb/s Duration: 00:01:50.88, bitrate: 256 kb/s Duration: 00:01:01.98, bitrate: 256 kb/s Duration: 00:01:48.24, bitrate: 256 kb/s Duration: 00:02:04.69, bitrate: 256 kb/s Duration: 00:01:18.72, bitrate: 256 kb/s Duration: 00:03:08.58, bitrate: 256 kb/s Duration: 00:01:38.58, bitrate: 256 kb/s Duration: 00:01:12.72, bitrate: 256 kb/s Duration: 00:01:58.56, bitrate: 256 kb/s Duration: 00:01:33.90, bitrate: 256 kb/s Duration: 00:00:49.74, bitrate: 256 kb/s Duration: 00:01:13.38, bitrate: 256 kb/s Duration: 00:00:49.83, bitrate: 256 kb/s Duration: 00:01:44.04, bitrate: 256 kb/s Duration: 00:02:37.92, bitrate: 256 kb/s Duration: 00:02:17.52, bitrate: 256 kb/s Duration: 00:01:10.38, bitrate: 256 kb/s Duration: 00:01:37.44, bitrate: 256 kb/s Duration: 00:01:23.40, bitrate: 256 kb/s Duration: 00:01:52.86, bitrate: 256 kb/s Duration: 00:01:54.84, bitrate: 256 kb/s Duration: 00:01:29.04, bitrate: 256 kb/s Duration: 00:01:28.62, bitrate: 256 kb/s Duration: 00:01:14.82, bitrate: 256 kb/s Duration: 00:01:31.02, bitrate: 256 kb/s Duration: 00:01:04.92, bitrate: 256 kb/s Duration: 00:01:40.78, bitrate: 256 kb/s Duration: 00:01:27.60, bitrate: 256 kb/s Duration: 00:01:37.38, bitrate: 256 kb/s Duration: 00:01:17.00, bitrate: 256 kb/s Duration: 00:01:20.34, bitrate: 256 kb/s Duration: 00:01:03.12, bitrate: 256 kb/s Duration: 00:01:24.18, bitrate: 256 kb/s Duration: 00:02:44.70, bitrate: 256 kb/s Duration: 00:01:48.06, bitrate: 256 kb/s Duration: 00:01:49.08, bitrate: 256 kb/s Duration: 00:01:26.28, bitrate: 256 kb/s Duration: 00:01:56.34, bitrate: 256 kb/s Duration: 00:01:20.52, bitrate: 256 kb/s Duration: 00:01:23.10, bitrate: 256 kb/s Duration: 00:01:13.42, bitrate: 256 kb/s Duration: 00:01:57.42, bitrate: 256 kb/s Duration: 00:01:42.30, bitrate: 256 kb/s Duration: 00:02:21.42, bitrate: 256 kb/s Duration: 00:01:29.34, bitrate: 256 kb/s Duration: 00:02:02.64, bitrate: 256 kb/s Duration: 00:01:37.96, bitrate: 256 kb/s Duration: 00:01:40.62, bitrate: 256 kb/s Duration: 00:01:51.60, bitrate: 256 kb/s Duration: 00:02:05.76, bitrate: 256 kb/s Duration: 00:01:08.64, bitrate: 256 kb/s Duration: 00:01:51.54, bitrate: 256 kb/s Duration: 00:01:19.08, bitrate: 256 kb/s Duration: 00:02:02.58, bitrate: 256 kb/s Duration: 00:01:42.84, bitrate: 256 kb/s Duration: 00:01:52.02, bitrate: 256 kb/s Duration: 00:01:15.42, bitrate: 256 kb/s Duration: 00:01:53.58, bitrate: 256 kb/s Duration: 00:01:15.68, bitrate: 256 kb/s Duration: 00:02:07.92, bitrate: 256 kb/s Duration: 00:01:56.10, bitrate: 256 kb/s Duration: 00:01:48.67, bitrate: 256 kb/s Duration: 00:01:24.42, bitrate: 256 kb/s Duration: 00:01:33.60, bitrate: 256 kb/s Duration: 00:02:18.02, bitrate: 256 kb/s Duration: 00:01:11.86, bitrate: 256 kb/s Duration: 00:01:18.66, bitrate: 256 kb/s Duration: 00:01:51.30, bitrate: 256 kb/s Duration: 00:01:32.40, bitrate: 256 kb/s Duration: 00:01:52.32, bitrate: 256 kb/s Duration: 00:00:58.62, bitrate: 256 kb/s Duration: 00:02:19.68, bitrate: 256 kb/s Duration: 00:01:20.52, bitrate: 256 kb/s Duration: 00:02:10.20, bitrate: 256 kb/s Duration: 00:02:06.78, bitrate: 256 kb/s Duration: 00:02:08.10, bitrate: 256 kb/s Duration: 00:02:51.96, bitrate: 256 kb/s Duration: 00:01:01.65, bitrate: 256 kb/s Duration: 00:01:09.72, bitrate: 256 kb/s Duration: 00:01:53.40, bitrate: 256 kb/s Duration: 00:01:26.34, bitrate: 256 kb/s Duration: 00:01:44.88, bitrate: 256 kb/s Duration: 00:02:13.56, bitrate: 256 kb/s Duration: 00:01:58.80, bitrate: 256 kb/s Duration: 00:01:48.62, bitrate: 256 kb/s Duration: 00:02:03.54, bitrate: 256 kb/s Duration: 00:01:46.02, bitrate: 256 kb/s Duration: 00:01:03.60, bitrate: 256 kb/s Duration: 00:01:36.38, bitrate: 256 kb/s Duration: 00:01:19.98, bitrate: 256 kb/s Duration: 00:01:15.00, bitrate: 256 kb/s Duration: 00:01:47.04, bitrate: 256 kb/s Duration: 00:00:59.64, bitrate: 256 kb/s Duration: 00:01:34.02, bitrate: 256 kb/s Duration: 00:01:39.06, bitrate: 256 kb/s Duration: 00:02:23.64, bitrate: 256 kb/s Duration: 00:01:49.74, bitrate: 256 kb/s Duration: 00:01:50.68, bitrate: 256 kb/s Duration: 00:02:03.84, bitrate: 256 kb/s Duration: 00:01:40.62, bitrate: 256 kb/s Duration: 00:01:47.58, bitrate: 256 kb/s Duration: 00:00:54.18, bitrate: 256 kb/s Duration: 00:01:37.68, bitrate: 256 kb/s Duration: 00:01:22.24, bitrate: 256 kb/s Duration: 00:00:54.54, bitrate: 256 kb/s Duration: 00:01:37.74, bitrate: 256 kb/s Duration: 00:02:02.22, bitrate: 256 kb/s Duration: 00:01:38.64, bitrate: 256 kb/s Duration: 00:01:32.88, bitrate: 256 kb/s Duration: 00:02:04.14, bitrate: 256 kb/s Duration: 00:01:05.56, bitrate: 256 kb/s Duration: 00:01:53.58, bitrate: 256 kb/s Duration: 00:01:59.76, bitrate: 256 kb/s Duration: 00:01:21.54, bitrate: 256 kb/s Duration: 00:01:54.10, bitrate: 256 kb/s Duration: 00:01:59.88, bitrate: 256 kb/s Duration: 00:00:29.94, bitrate: 256 kb/s Duration: 00:01:24.86, bitrate: 256 kb/s Duration: 00:01:20.82, bitrate: 256 kb/s Duration: 00:01:58.20, bitrate: 256 kb/s Duration: 00:01:15.96, bitrate: 256 kb/s Duration: 00:01:53.28, bitrate: 256 kb/s Duration: 00:01:05.94, bitrate: 256 kb/s Duration: 00:01:20.34, bitrate: 256 kb/s Duration: 00:01:53.88, bitrate: 256 kb/s Duration: 00:02:10.80, bitrate: 256 kb/s Duration: 00:00:56.76, bitrate: 256 kb/s Duration: 00:01:32.88, bitrate: 256 kb/s Duration: 00:01:01.92, bitrate: 256 kb/s Duration: 00:01:49.38, bitrate: 256 kb/s Duration: 00:01:19.14, bitrate: 256 kb/s Duration: 00:00:54.48, bitrate: 256 kb/s Duration: 00:01:31.26, bitrate: 256 kb/s Duration: 00:01:35.22, bitrate: 256 kb/s Duration: 00:01:08.40, bitrate: 256 kb/s Duration: 00:02:02.40, bitrate: 256 kb/s Duration: 00:01:19.14, bitrate: 256 kb/s Duration: 00:02:09.30, bitrate: 256 kb/s Duration: 00:01:27.62, bitrate: 256 kb/s Duration: 00:01:59.46, bitrate: 256 kb/s Duration: 00:02:50.64, bitrate: 256 kb/s Duration: 00:00:47.76, bitrate: 256 kb/s Duration: 00:01:31.92, bitrate: 256 kb/s Duration: 00:01:13.44, bitrate: 256 kb/s Duration: 00:01:23.22, bitrate: 256 kb/s Duration: 00:01:31.74, bitrate: 256 kb/s Duration: 00:01:43.16, bitrate: 256 kb/s Duration: 00:01:29.64, bitrate: 256 kb/s Duration: 00:02:13.62, bitrate: 256 kb/s Duration: 00:02:01.80, bitrate: 256 kb/s Duration: 00:02:21.18, bitrate: 256 kb/s Duration: 00:01:55.92, bitrate: 256 kb/s Duration: 00:01:03.00, bitrate: 256 kb/s Duration: 00:01:29.82, bitrate: 256 kb/s Duration: 00:01:42.00, bitrate: 256 kb/s Duration: 00:02:18.78, bitrate: 256 kb/s Duration: 00:01:40.80, bitrate: 256 kb/s Duration: 00:02:55.74, bitrate: 256 kb/s Duration: 00:01:28.08, bitrate: 256 kb/s Duration: 00:01:57.78, bitrate: 256 kb/s Duration: 00:01:58.38, bitrate: 256 kb/s Duration: 00:01:12.00, bitrate: 256 kb/s .",
            "url": "https://jimregan.github.io/notes/asr/polish/kaggle/2021/06/16/poleval-2021-durations.html",
            "relUrl": "/asr/polish/kaggle/2021/06/16/poleval-2021-durations.html",
            "date": " â€¢ Jun 16, 2021"
        }
        
    
  
    
        ,"post141": {
            "title": "Irish Texts from South West Donegal, Abair comparison.",
            "content": "The table below compares the transcription of Texts 1 &amp; 2: (â€œPoitÃ­nâ€ and â€œAn mhÃ³inâ€) from Oâ€™Neillâ€™s1 â€œIrish Texts from South West Donegalâ€, comparing it with Abairâ€™s transcription. . Texts 1â€”4 were contributed by Seamus Ã“ Beirn (Jim Phat James), aged c. 70 years, cobbler, from the townland of MÃ­n na Gaoithe, Teelin. . A special feature of his speech is the clearness and strength of the affricates tâ€²Êƒ and dâ€²Ê’ due to the deliberate manner in which each word is enunciated. . The phonetic rules were mostly to help with automatic comparison, though the places where verb froms were pronounced differently before a pronoun was interesting enough to note. . Original Transcript Abair G2P Abair source Adjusted word (standardised) Adjusted Abair Rule . a | Â  | É™ | l | Â  | Â  | É™ â†’ âˆ… / v # _ | . a | Ã¨ | É™ | l | Â  | Â  | Â  | . a | É™ | É™ | l | Â  | Â  | Â  | . a | áµŠ | É™ | l | Â  | Â  | Â  | . ach | É‘x | Ëˆah | l | Â  | Â  | Â  | . acÃº | É”ku | ËˆakË uË | Â  | acu | akË u | Â  | . adharc | Ëˆne:rk | ËˆeËÉ¾Ë kË  | l | Â  | Â  | Â  | . ag | É™ | ËˆeÉŸ | l | Â  | Â  | ÉŸ â†’ âˆ… / _ # [+stop] | . ag | Éªgâ€² | ËˆeÉŸ | l | Â  | Â  | Â  | . againn | ËˆÎµiÎ½â€² | ËˆÉ™gË É™É´Ê² | l | Â  | Â  | Â  | . agamsa | Ã¨imsÉ™ | ËˆÉ™gË É™mË sË É™ | l | Â  | Â  | Â  | . agat | Ã¨it | ËˆÉ™gË É™tË  | l | Â  | Â  | Â  | . agat | É›it | ËˆÉ™gË É™tË  | l | Â  | Â  | Â  | . agat | É›jÉ™d | ËˆÉ™gË É™tË  | l | Â  | Â  | Â  | . agus | ogÉ™s | ËˆagË É™sË  | l | Â  | Â  | Â  | . agus | É”gas | ËˆagË É™sË  | l | Â  | Â  | Â  | . agus | É”ges | ËˆagË É™sË  | l | Â  | Â  | Â  | . agus | É”gÉ™s | ËˆagË É™sË  | l | Â  | Â  | Â  | . aige | É›gâ€²É™ | ËˆeÉŸÉ™ | l | Â  | Â  | Â  | . air | erâ€²Ê” | ËˆeÉ¾Ê² | l | Â  | Â  | Â  | . air | Ã¨râ€² | ËˆeÉ¾Ê² | l | Â  | Â  | Â  | . air | É›râ€² | ËˆeÉ¾Ê² | l | Â  | Â  | Â  | . am | ËˆnÉ‘m | ËˆamË  | l | Â  | Â  | Â  | . amach | É™Ëˆmax | É™ËˆmË ah | l | Â  | Â  | Â  | . amach | É™ËˆmÉ‘h | É™ËˆmË ah | l | Â  | Â  | Â  | . amach | É™ËˆmÉ‘x | É™ËˆmË ah | l | Â  | Â  | Â  | . an | n | ËˆÉ™É´Ë  | l | Â  | Â  | É™ â†’ âˆ… / v # _ | . an | nÌ¥ | ËˆÉ™É´Ë  | l | Â  | Â  | É™ â†’ âˆ… / v # _ | . an | É™ | ËˆÉ™É´Ë  | l | Â  | Â  | Â  | . ann | oÌ¤n | ËˆaÉ´Ë  | l | Â  | Â  | Â  | . annsin | nÌ¥ËˆÊƒÉªnâ€² | ËˆaËˆÉ´Ê²ÊƒinÊ² | Â  | ansin | É™É´Ë ËˆÊƒinÊ² | É™ â†’ âˆ… / v # _ | . annsin | ËˆÊƒÉªnâ€² | ËˆaËˆÉ´Ê²ÊƒinÊ² | Â  | Â  | Â  | Â  | . anois | (É™)ËˆnÉªÊƒ | É™ËˆÉ´Ë iÊƒ | l | Â  | Â  | Â  | . aon | e:Ëˆn | ËˆeËÉ´Ë  | l | Â  | Â  | Â  | . ar | É™ | ËˆeÉ¾Ê² | l | Â  | Â  | Â  | . ar | É™r | ËˆeÉ¾Ê² | l | Â  | Â  | Â  | . ar | É›r | ËˆeÉ¾Ê² | l | Â  | Â  | Â  | . arais | É™ËˆraÊƒ | ËˆaÉ¾Ë É™Êƒ | Â  | ar ais | ËˆeÉ¾Ê² ËˆaÊƒ | Â  | . araist | É™ËˆraÊƒdâ€² | ËˆaÉ¾Ë É™ÊƒtÊ² | Â  | ar ais | ËˆeÉ¾Ê² ËˆaÊƒ | Â  | . armaÃ­ | ËˆÉ‘rmÊ·i | ËˆaÉ¾Ë É™mË iË | Â  | Â  | Â  | Â  | . as | iÌˆs | ËˆasË  | l | Â  | Â  | Â  | . astoigh | É™ËˆsdihÊ” | ËˆasË tË É™ | Â  | istigh | isË ËˆtË ij | Â  | . astoigh | É™ËˆÊƒdihÊ” | ËˆasË tË É™ | Â  | istigh | isË ËˆtË ij | Â  | . atÃ¡ | É™ | É™ËˆtË aË | l | Â  | Â  | Â  | . atÃ¡ | É™tÉ‘: | É™ËˆtË aË | l | Â  | Â  | Â  | . atÃ¡ | ËˆtÉ‘: | É™ËˆtË aË | l | Â  | Â  | Â  | . ba | boÌ¤ | ËˆbË É™ | l | Â  | Â  | Â  | . ba Ã© | byje: | ËˆbË É™ ËˆeË | l | Â  | Â  | Â  | . bachtadh | ËˆbÉ‘xdu | ËˆbË aÉ¾Ë tË uË | Â  | bachta | ËˆbË aÉ¾Ë tË É™ | Â  | . barraille | ËˆbÉ‘rÉ™lâ€²É™ | ËˆbË aËËˆÉ¾Ë aÊŸÊ²É™ | Â  | bairille | ËˆbË aÉ¾Ê²ÊŸÊ²É™ | Â  | . barraillÃ­ | ËˆbÉ‘rÉ™lâ€²i | ËˆbË aËËˆÉ¾Ë aÊŸÊ²iË | Â  | bairillÃ­ | ËˆbË aÉ¾Ê²É™ÊŸÊ²iË | Â  | . bascÃ³id | ËˆbÉ‘sgÉ”dâ€²á¶¾ | ËˆbË asË kË É”dÊ² | Â  | bascaed | ËˆbË asË kË edË  | Â  | . beachÃ³g | Ëˆbâ€²ahÉ”g | ËˆbÊ²ahÉ”gË  | Â  | Â  | Â  | Â  | . beag | Ëˆbâ€²Ã¸g | ËˆbÊ²ogË  | l | Â  | Â  | Â  | . bealtaine | Ëˆbâ€²a:ltÉªnâ€²É™ | ËˆbÊ²oÊŸË tË É™nÊ²É™ | l | Â  | Â  | Â  | . bhachta | ËˆwÉ‘xdÉ™ | ËˆwaÉ¾Ë tË É™ | l+m | Â  | Â  | Â  | . bhachtadh | ËˆwÉ‘xdu | ËˆwaÉ¾Ë tË uË | Â  | bhachta | Â  | Â  | . bhaint | wÃ¯â€²nt | ËˆwanÊ²tÊ² | l | Â  | Â  | Â  | . bharraille | ËˆwÉ‘rÉ™lâ€²É™ | ËˆwaËËˆÉ¾Ë aÊŸÊ²É™ | Â  | bhairille | ËˆwaÉ¾Ê²ÊŸÊ²É™ | Â  | . bheireadh | vÉ›râ€²É™dâ€² | ËˆvÊ²eÉ¾Ê²uË | l | Â  | Â  | &lt;eadh&gt; â†’ É™dÊ² / _ # pronoun | . bhfaghaidh | ËˆwÉ‘: | ËˆweËiË | Â  | bhfaighidh | ËˆwiË | Â  | . bhfeiceadh | ËˆvÉ›kâ€²u | ËˆvÊ²ecuË | Â  | Â  | Â  | Â  | . bhfosclaidh | ËˆwÉ”sgli | ËˆwoËˆsË kË ÊŸË eË | Â  | bhfosclaÃ­ | ËˆwoËˆsË kË ÊŸË iË | Â  | . bhfuil | Ëˆwilâ€² | ËˆwilÊ² | l | Â  | Â  | Â  | . bhinn | ËˆÎ½Ã¯Î½â€² | ËˆvÊ²iÉ´Ê² | l | Â  | Â  | Â  | . bhraich | ËˆvreihÊ” | ËˆwÉ¾Ë aÃ§ | l+m | Â  | Â  | Â  | . bhun | ËˆwoÌ¤n | ËˆwuÉ´Ë  | l | Â  | Â  | Â  | . bhÃ©adh | vÉ›uw | ËˆvÊ²eËÉ£ | Â  | Â  | Â  | Â  | . bhÃ©arfaidh | verhÉ™ | ËˆvÊ²eËÉ¾Ë hiË | l | Â  | Â  | Â  | . bhÃ©arfaidh | vÃ¨rhÉ™ | ËˆvÊ²eËÉ¾Ë hiË | l | Â  | Â  | Â  | . bhÃ©arfaidh | vÉ›:rhÉ™ | ËˆvÊ²eËÉ¾Ë hiË | l | Â  | Â  | Â  | . bhÃ©arfaidh | vÉ›rhÉ™ | ËˆvÊ²eËÉ¾Ë hiË | l | Â  | Â  | Â  | . bhÃ­ | vi: | ËˆvÊ²iË | l | Â  | Â  | Â  | . bhÃ­odh | vi:dâ€² | ËˆvÊ²iËuË | l | Â  | Â  | &lt;odh&gt; â†’ (É™)dÊ² / _ # pronoun | . bhÃ­odh | viuw | ËˆvÊ²iËuË | l | Â  | Â  | Â  | . binn | Ëˆbâ€²Ã¯nâ€² | ËˆbÊ²iÉ´Ê² | l | Â  | Â  | Â  | . bith | Ëˆbâ€²i | ËˆbÊ²iË | l | Â  | Â  | Â  | . bladhaire | Ëˆblá´‡irâ€²É™ | ËˆbË ÊŸË eËÉ¾Ê²É™ | l | Â  | Â  | Â  | . bocsa | ËˆboÌ¤ks | ËˆbË okË sË É™ | Â  | bosca | ËˆbË okË sË É™ | Â  | . bracha | ËˆbrÉ‘xÉ™ | ËˆbË É¾Ë ahÉ™ | Â  | braiche | ËˆbË É¾Ë aÃ§É™ | Â  | . briste | Ëˆbâ€²râ€²Ã¯Êƒdâ€²É™ | ËˆbÊ²É¾Ê²iÊƒtÊ²É™ | l | Â  | Â  | Â  | . bruach | Ëˆbri:x | ËˆbË É¾Ë uah | l | Â  | Â  | Â  | . bruach | ËˆbryÉ™x | ËˆbË É¾Ë uah | l | Â  | Â  | Â  | . brÃ³inte | ËˆbrÉ”:nâ€²tâ€²É™ | ËˆbË É¾Ë oËnÊ²tÊ²É™ | Â  | brÃ³nna | bË É¾Ë oËÉ´Ë É™ | Â  | . bÃ¡rr | ËˆbÉ‘:r | ËˆbË aËÉ¾Ë  | Â  | barr | ËˆbË aËÉ¾Ë  | Â  | . caidÃ© | gÉ™Ëˆdâ€²á¶¾e: | kË É™ËˆdÊ²eË | l | Â  | Â  | Â  | . cailleadh | Ëˆkalâ€²lâ€²u | ËˆkË aÊŸÊ²uË | l | Â  | Â  | Â  | . caithfidh | ËˆkaihÉª | ËˆkË ahjiË | l | Â  | Â  | Â  | . caithfidh | ËˆkÉ‘ihi | ËˆkË ahjiË | l | Â  | Â  | Â  | . caithfidh | ËˆkÉ‘ihÉª | ËˆkË ahjiË | l | Â  | Â  | Â  | . caithte | ËˆkoÌ¤tâ€²á¶´É™ | ËˆkË ahtÊ²É™ | Â  | caite | ËˆkË atÊ²É™ | Â  | . ceig | Ëˆkâ€²Ã¨gâ€² | ËˆceÉŸ | Â  | Â  | Â  | Â  | . ceÃ³l | Ëˆkâ€²Ê²É”:l | ËˆcoËÊŸË  | Â  | ceol | ËˆcoËÊŸË  | Â  | . chaith | ËˆxÉ‘ih | Ëˆxahj | l | Â  | Â  | Â  | . chaitheamh | ËˆxÉ‘hu | ËˆxahjuË | l | Â  | Â  | Â  | . cheann | Ëˆxâ€²oÌ¤n | ËˆÃ§iÉ´Ë  | l | Â  | Â  | Â  | . cheig | Ëˆxâ€²É›gâ€² | ËˆÃ§eÉŸ | Â  | Â  | Â  | Â  | . cheithre | Ëˆxâ€²É›râ€²É™ | ËˆxeÉ¾Ê²É™ | l | Â  | Â  | Â  | . chiadhna | Ëˆxâ€²iÉ™nÉ™ | ËˆÃ§iÉ™É£É´Ë É™ | Â  | chÃ©anna | ËˆÃ§eËÉ¾Ë É´Ë É™ | Â  | . chiall | Ëˆxâ€²i:É™l | ËˆÃ§iaÊŸË  | l | Â  | Â  | Â  | . chionn | xâ€²oÌ¤n | ËˆÃ§iÉ´Ë  | l+m | Â  | Â  | Â  | . chor | ËˆxÉ”r | ËˆxaÉ¾Ë  | l | Â  | Â  | Â  | . chuireadh | xoÌ¤râ€²É™dâ€² | ËˆxuÉ¾Ê²uË | l | Â  | Â  | &lt;eadh&gt; â†’ É™dÊ² / _ # pronoun | . chuireas | ËˆxoÌ¤râ€²É™s | ËˆxuÉ¾Ê²É™sË  | l | Â  | Â  | Â  | . chur | ËˆxoÌ¤r | ËˆxuÉ¾Ë  | l | Â  | Â  | Â  | . chÃ©ad | Ëˆxâ€²e(:)d | ËˆÃ§eËdË  | l | Â  | Â  | Â  | . clampaÃ­ | ËˆklÉ‘mbi | ËˆkË ÊŸË amË pË iË | Â  | Â  | Â  | Â  | . crapannaÃ­ | ËˆkrÉ‘pÉ™ni | ËˆkË É¾Ë apË É™É´Ë iË | Â  | Â  | Â  | Â  | . croiceann | ËˆkrÉ›kâ€²É™n | ËˆkË É¾Ë ocÉ™É´Ë  | Â  | craiceann | ËˆkË É¾Ë acÉ™É´Ë  | Â  | . cruacha | ËˆkruÉ™x | ËˆkË É¾Ë uÉ™Ëˆxa | Â  | Â  | Â  | Â  | . cruachta | ËˆkruÉ™xdÉ™ | ËˆkË É¾Ë uÉ™ËˆÉ¾Ë tË a | Â  | Â  | Â  | Â  | . crÃ³igeÃ¡in | ËˆkrÉ”:áµŠgâ€²É™nâ€² | ËˆkË É¾Ë oËÉŸaËnÊ² | Â  | grÃ³igeÃ¡in | ËˆgË É¾Ë oËÉŸaËnÊ² | Â  | . crÃ³igfidh | ËˆkrÉ”:áµŠkâ€²É™ | ËˆkË É¾Ë oËÉŸiË | Â  | grÃ³igfidh | ËˆgË É¾Ë oËÉŸiË | Â  | . cubhar | Ëˆku:r | ËˆkË uwÉ™É¾Ë  | Â  | cÃºr | ËˆkË uËÉ¾Ë  | Â  | . cumhdach | Ëˆku:dÉ‘x | ËˆkË uËdË ah | l | Â  | Â  | Â  | . cur | ËˆkoÌ¤r | ËˆkË uÉ¾Ë  | l | Â  | Â  | Â  | . cÃ¡ithte | Ëˆka:tâ€²ÊƒÉ™ | ËˆkË aËhtÊ²É™ | Â  | cÃ¡ite | kË aËtÊ²É™ | Â  | . dâ€™fhÃ¡sfadh | dÉ‘:shÉ™dâ€² | ËˆdË aËsË uË | Â  | Â  | Â  | &lt;adh&gt; â†’ É™dÊ² / _ # pronoun | . dabhach | ËˆdÉ”uÊ·É‘x | ËˆdË auh | l | Â  | Â  | Â  | . daoithe | di:Ê°É™ | ËˆdË iËhÉ™ | Â  | di | ËˆdË i | Â  | . daoithe | dihÉ™ | ËˆdË iËhÉ™ | Â  | di | ËˆdË i | Â  | . dara | ËˆdÉ‘rÉ™ | ËˆdË aÉ¾Ë É™ | l | Â  | Â  | Â  | . deâ€™n | É”n | ËˆdË enË  | l | Â  | Â  | d â†’ âˆ… / t # _ | . deasach | Ëˆdâ€²á¶¾asÉ‘x | ËˆdÊ²asË ah | l | Â  | Â  | Â  | . den | dÉ” | ËˆdË enË  | l | Â  | Â  | Â  | . den | dÉ”n | ËˆdË enË  | l | Â  | Â  | Â  | . dhâ€™fhÃ¡s | ËˆÉ£É‘:s | ËˆÉ£aËsË  | Â  | dâ€™fhÃ¡s | ËˆdË aËsË  | Â  | . dhÃ¡ | ËˆÉ£É‘: | ËˆÉ£aË | l | Â  | Â  | Â  | . dhÃ©anamh | Ëˆja:nu | ËˆjeËÉ´Ë uË | l | Â  | Â  | Â  | . dhÃ©anfaidh | ja:nhÉ™ | ËˆÉ£eËÉ´Ë hiË | l | Â  | Â  | Â  | . dhÃ©in | Ëˆje:nâ€² | ËˆjeËnÊ² | l+m | Â  | Â  | Â  | . do | dÉ” | ËˆdË É™ | l | Â  | Â  | Â  | . domh | du | ËˆdË uË | l | Â  | Â  | Â  | . dorga | ËˆdÉ”rÉ™gÉ™ | ËˆdË oËˆÉ¾Ë gË a | Â  | dorÃº | ËˆdË oÉ¾Ë uË | Â  | . dtaobh | du: | ËˆdÊ²iËw | l | Â  | Â  | Â  | . dtig | Ëˆdâ€²Éªgâ€² | ËˆdÊ²iÉŸ | l | Â  | Â  | Â  | . dtig | Ëˆdâ€²á¶¾Éªgâ€² | ËˆdÊ²iÉŸ | l | Â  | Â  | Â  | . dtiocfadh | dâ€²á¶¾oÌ¤ku | ËˆdÊ²okË uË | l | Â  | Â  | Â  | . dtiocfadh | dâ€²á¶¾oÌ¤ku | ËˆdÊ²okË uË | l | Â  | Â  | Â  | . dtugadh | doÌ¤gÉ™dâ€² | ËˆdË ugË uË | l+m | Â  | Â  | &lt;adh&gt; â†’ É™dÊ² / _ # pronoun | . dtÃ©ighidh | Ëˆdâ€²á¶¾e:áµŠ | ËˆdÊ²eËjiË | Â  | dtÃ© | ËˆdÊ²eË | Â  | . dtÃ­ | ËˆdÊ’â€²i: | ËˆdÊ²iË | l | Â  | Â  | Â  | . dtÃ­ | Ëˆdâ€²Ê’i: | ËˆdÊ²iË | l | Â  | Â  | Â  | . dtÃ³lamh | ËˆdÉ”:luw | ËˆdË oËÊŸË uË | l+m | Â  | Â  | Â  | . dtÃ³lamh | ËˆdÉ”:lÉ™fâ€² | ËˆdË oËÊŸË uË | l+m | Â  | Â  | Â  | . duine | ËˆdÉªnâ€² | ËˆdË inÊ²É™ | l | Â  | Â  | É™ â†’ âˆ… / _ # v | . dÃ³igh | dÉ”:i | ËˆdË oËj | l | Â  | Â  | Â  | . dÃ³igh | ËˆdÉ”:i | ËˆdË oËj | l | Â  | Â  | Â  | . dÃ³rtadh | ËˆdÉ”:rtu | ËˆdË oËËˆÉ¾Ë tË eË | Â  | doirteadh | ËˆdË oÉ¾Ë tÊ²uË | Â  | . eagla | Ã¸glÉ™ | ËˆogË ÊŸË É™ | l | Â  | Â  | Â  | . eile | ËˆÉ›lâ€²i: | ËˆelÊ²É™ | l | Â  | Â  | Â  | . eile | Îµlâ€²É™ | ËˆelÊ²É™ | l | Â  | Â  | Â  | . eÃ³rna | Ëˆnâ€²É”:rn | ËˆoËÉ¾Ë É´Ë É™ | Â  | eorna | ËˆoËÉ¾Ë É´Ë É™ | É™ â†’ âˆ… / _ # v | . eÃ³rna | Ëˆnâ€²É”:rnÉ™ | ËˆoËÉ¾Ë É´Ë É™ | Â  | Â  | Â  | Â  | . eÃ³rna | Ëˆnâ€²É”:rnÉ™ | ËˆoËÉ¾Ë É´Ë É™ | Â  | eorna | ËˆoËÉ¾Ë É´Ë É™ | Â  | . fad | fÉ‘d | ËˆfË adË  | l | Â  | Â  | Â  | . faoi | fÊ·i | ËˆfË iË | l | Â  | Â  | Â  | . faoin | fÊ·i:n | ËˆfË inÊ² | l | Â  | Â  | Â  | . fhad | ad | ËˆadË  | l | Â  | Â  | Â  | . fhad | ËˆÉ‘d | ËˆadË  | l | Â  | Â  | Â  | . fhios | iÌˆs | ËˆisË  | l | Â  | Â  | Â  | . fhÃ©il | lâ€² | ËˆeËlÊ² | l | Â  | Â  | Â  | . fhÃ³d | o:d | ËˆoËdË  | l+m | Â  | Â  | Â  | . fichead | Ëˆfâ€²ihÉ™d | ËˆfÊ²ihjÉ™dË  | l | Â  | Â  | Â  | . fiog | Ëˆfâ€²Ã¸g | ËˆfÊ²igË  | Â  | Â  | Â  | Â  | . fuar | ËˆfyÉ™r | ËˆfË iaÉ¾Ë  | l | Â  | Â  | Â  | . fÃ¡ | fÉ‘ | ËˆfË aË | l | Â  | Â  | Â  | . fÃ¡gfaidh | ËˆfÉ‘:khÉ™ | ËˆfË aËgË hÉ™ | l | Â  | Â  | Â  | . fÃ¡gfaidh | ËˆfÉ‘:kÉ™ | ËˆfË aËgË hÉ™ | l | Â  | Â  | Â  | . fÃ¡gÃ¡il | ËˆfÉ‘:gÉ‘lâ€² | ËˆfË aËgË alÊ² | l | Â  | Â  | Â  | . fÃ³d | Ëˆfo:d | ËˆfË oËdË  | l | Â  | Â  | Â  | . gabhÃ¡il | gÉ”lâ€² | ËˆgË olÊ² | l | Â  | Â  | Â  | . gcionn | gâ€²oÌ¤n | ËˆÉŸoÉ´Ë  | l | Â  | Â  | Â  | . gclocha | gloÌ¤hÉ™ | ËˆgË ÊŸË ahÉ™ | l+m | Â  | Â  | Â  | . gconnadae | ËˆgoÌ¤ndei | ËˆgË oÉ´Ë É™dË eË | Â  | gcontae | ËˆgË É™É´Ë ËˆtË e | Â  | . gcruachaidh | ËˆgruÉ™xÉ™ | ËˆgË É¾Ë uÉ™ËˆxeË | Â  | gcruacha | ËˆgË É¾Ë uÉ™Ëˆxa | Â  | . geÃ¡rradh | Ëˆgâ€²É‘:ru | ËˆÉŸaËÉ¾Ë uË | Â  | gearradh | ËˆÉŸaÉ¾Ë uË | Â  | . geÃ¡rraidh | Ëˆgâ€²É‘:ri | ËˆÉŸaËÉ¾Ë iË | Â  | gearra | ËˆÉŸaÉ¾Ë É™ | Â  | . geÃ¡rrfaidh | Ëˆgâ€²É‘:rhÉ™ | ËˆÉŸaËÉ¾Ë iË | Â  | gearrfaidh | ËˆÉŸaÉ¾Ë iË | Â  | . geÃ¡rrtha | Ëˆgâ€²É‘:rhÉ™ | ËˆÉŸaËÉ¾Ë hÉ™ | Â  | gearrtha | ËˆÉŸaËÉ¾Ë Ëˆha | Â  | . ghabhÃ¡il | ËˆÉ£É”(:)lâ€² | ËˆÉ£olÊ² | l | Â  | Â  | Â  | . gheimhridh | ËˆjÉ›vrâ€²i | ËˆjivÊ²É¾Ê²i | l | Â  | Â  | Â  | . gheÃ¡rradh | ËˆjÉ‘:ru | ËˆjaËÉ¾Ë uË | Â  | ghearradh | ËˆjaÉ¾Ë uË | Â  | . ghlas | ËˆÉ£lÉ‘s | ËˆÉ£ÊŸË asË  | l | Â  | Â  | Â  | . ghoirid | ËˆÉ£oÌ¤râ€²idâ€²á¶¾ | ËˆÉ£oÉ¾Ê²É™dÊ² | Â  | Â  | Â  | Â  | . ghrian | ËˆjáµŠrâ€²iÉ™n | ËˆÉ£É¾Ê²iaÉ´Ë  | l | Â  | Â  | Â  | . gloine | ËˆglÃ¶nâ€²É™ | ËˆgË ÊŸË inÊ²É™ | l | Â  | Â  | Â  | . go | go | ËˆgË É™ | l | Â  | Â  | Â  | . go | gÉ” | ËˆgË É™ | l | Â  | Â  | Â  | . go | gÉ™ | ËˆgË É™ | l | Â  | Â  | Â  | . goidÃ© | gÉ™Ëˆdâ€²á¶¾e: | ËˆgË É™dÊ²eË | l | Â  | Â  | Â  | . grian | Ëˆgâ€²râ€²iÉ™n | ËˆÉŸÉ¾Ê²iaÉ´Ë  | l | Â  | Â  | Â  | . gÃ©ar | Ëˆgâ€²É›:áµŠr | ËˆÉŸeËÉ¾Ë  | l | Â  | Â  | Â  | . gÃ©arrfaidh | Ëˆgâ€²É‘:rhÉ™ | ËˆÉŸeËËˆÉ¾Ë eË | Â  | gearrfaidh | ËˆÉŸaÉ¾Ë iË | Â  | . h-Ã¡irid | Ëˆha:ridâ€²á¶¾ | ËˆhaËÉ¾Ê²É™dÊ² | Â  | hÃ¡irithe | ËˆhaËÉ¾Ê²ihjÉ™ | Â  | . h-Ã¡iteacha | Ëˆha:nâ€²tâ€²ahÉ™ | ËˆhaËtÊ²É™hÉ™ | h-Ã¡iteacha | Â  | Â  | Â  | . h-Ã© | hÃ¨ | ËˆheË | l+m | Â  | Â  | Â  | . huaire | ËˆhuÉ™râ€²É™ | ËˆhuaÉ¾Ê²É™ | l | Â  | Â  | Â  | . i | Â  | Ëˆi | l | Â  | Â  | Â  | . i | É™ | Ëˆi | l | Â  | Â  | Â  | . iad | iÉ™d | ËˆiadË  | l | Â  | Â  | Â  | . iad | É™d | ËˆiadË  | l | Â  | Â  | Â  | . ina | nÉ™ | ËˆiÉ´Ë É™ | l | Â  | Â  | Â  | . ina | É™Î½É™ | ËˆiÉ´Ë É™ | l | Â  | Â  | Â  | . innse | iÌˆÎ½â€²ÊƒÉ™ | ËˆiËˆÉ´Ê²Êƒe | Â  | insint | ËŒinÊ²ËˆÊƒinÊ²tÊ² | Â  | . inntÃ­ | ËˆÉªnâ€²tâ€²i | ËˆiËˆÉ´Ê²tÊ²iË | Â  | inti | iÉ´Ê²tÊ²i | Â  | . ins | nÌ¥s | ËˆinÊ²Êƒ | Â  | Â  | Â  | Â  | . ins | nÌ¥s | ËˆinÊ²Êƒ | Â  | Â  | Â  | É™ â†’ âˆ… / v # _ | . ins | nÌ¥s | ËˆinÊ²Êƒ | Â  | sa | ËˆsË É™ | Â  | . ins an | nÌ¥sÉ™ | ËˆinÊ²Êƒ ËˆÉ™É´Ë  | Â  | Â  | Â  | Â  | . insa | nÌ¥sÉ™ | ËˆinÊ²ËˆsË É™ | Â  | Â  | Â  | Â  | . insa | nÌ¥sÉ™ | ËˆinÊ²ËˆsË É™ | Â  | sa | ËˆsË É™ | Â  | . isteach | É™ËˆÊƒdâ€²ah | iÊƒËˆtÊ²ah | l | Â  | Â  | Â  | . isteach | É™ËˆÊƒdâ€²ax | iÊƒËˆtÊ²ah | l | Â  | Â  | Â  | . le | lâ€²É› | ËˆlÊ²e | l | Â  | Â  | Â  | . leagfaidh | Ëˆlâ€²oÌ¤khÉ™ | ËˆÊŸÊ²agË iË | Â  | Â  | Â  | Â  | . leat | lâ€²at | ËˆlÊ²atË  | l | Â  | Â  | Â  | . leis | lâ€²eÊƒ | ËˆlÊ²iÊƒ | l | Â  | Â  | Â  | . leis | lâ€²É› | ËˆlÊ²iÊƒ | l | Â  | Â  | Êƒ â†’ âˆ… / _ # Êƒ | . leithead | Ëˆlâ€²É›hÉ™d | ËˆÊŸÊ²aihjÉ™dË  | l | Â  | Â  | Â  | . lena | lâ€²É›nÉ™ | ËˆlÊ²eÉ´Ë É™ | l | Â  | Â  | Â  | . leÃ³fa | lâ€²É”:fÉ™ | ËˆÊŸÊ²oËfË É™ | Â  | leo | ËˆlÊ²o | Â  | . lomadh | ËˆloÌ¤mu | ËˆÊŸË omË uË | l | Â  | Â  | Â  | . lomta | ËˆloÌ¤mt | ËˆÊŸË omË tË É™ | Â  | Â  | Â  | Â  | . lÃ¡ | ËˆlÉ‘: | ËˆÊŸË aË | l | Â  | Â  | Â  | . lÃ¡imhe | ËˆlÉ‘:vÉ™ | ËˆÊŸË aËvÊ²É™ | l | Â  | Â  | Â  | . lÃ¡mh | ËˆlÉ‘:w | ËˆÊŸË aËw | l | Â  | Â  | Â  | . lÃ¡mha | ËˆlÉ‘:wÉ™ | ËˆÊŸË aËwÉ™ | l | Â  | Â  | Â  | . lÃ¡n | lÉ‘:n | ËˆÊŸË aËÉ´Ë  | l | Â  | Â  | Â  | . lÃ©ithe | lâ€²É›:hÉ™ | ËˆlÊ²eËhjÉ™ | l | Â  | Â  | Â  | . lÃ­onadh | Ëˆlâ€²i:nÉ™dâ€² | ËˆÊŸÊ²iËÉ´Ë uË | l | Â  | Â  | Â  | . maith | ËˆmÉ‘i | ËˆmË ahj | l | Â  | Â  | Â  | . mar | moÌ¤r | ËˆmË aÉ¾Ë  | l | Â  | Â  | Â  | . marâ€™s | moÌ¤Å™Å¡ | Ëˆm_ea_er_ez_e | l | Â  | Â  | Â  | . marâ€™s | mÉ™s | ËˆmË aÉ¾Ë sË  | l | Â  | Â  | Â  | . marbh | Ëˆmaru | ËˆmË aÉ¾Ë É™w | l | Â  | Â  | Â  | . mheileadh | vÉ™lâ€²hÉ™dâ€² | ËˆvÊ²elÊ²uË | Â  | Â  | Â  | &lt;eadh&gt; â†’ É™dÊ² / _ # pronoun | . mhÃ¡rta | ËˆwÉ‘:rtÉ™ | ËˆwaËÉ¾Ë tË É™ | l+m | Â  | Â  | Â  | . mhÃ³in | Ëˆwo:nâ€² | ËˆwoËnÊ² | l+m | Â  | Â  | Â  | . mhÃ³in | Ëˆwo:áµŠnâ€² | ËˆwoËnÊ² | l+m | Â  | Â  | Â  | . midhe | Ëˆmâ€²i:É™ | ËˆmÊ²iËÉ™ | Â  | mÃ­ | ËˆmÊ²iË | Â  | . mÃ¡ | mÉ‘ | ËˆmË a | l | Â  | Â  | Â  | . mÃ¡la | ËˆmÉ‘:lÉ™ | ËˆmË aËÊŸË É™ | l | Â  | Â  | Â  | . mÃ­ | Ëˆmâ€²i: | ËˆmÊ²iË | l | Â  | Â  | Â  | . mÃ³in | mo:nâ€² | ËˆmË oËnÊ² | l | Â  | Â  | Â  | . mÃ³nadh | mo:nu | ËˆmË oËÉ´Ë uË | l | Â  | Â  | Â  | . mÃ³r | Ëˆmo:r | ËˆmË oËÉ¾Ë  | l | Â  | Â  | Â  | . n | n | nË  | l | Â  | Â  | Â  | . n | nÌ¥ | nË  | l | Â  | Â  | Â  | . na | nÉ™ | ËˆÉ´Ë É™ | l | Â  | Â  | Â  | . naoi | Ëˆni: | ËˆÉ´Ë iË | l | Â  | Â  | Â  | . ndam | ËˆnÉ‘mÊ· | ËˆÉ´Ë amË  | Â  | ndamba | ËˆÉ´Ë amË bË É™ | Â  | . ndÃ©antar | Ëˆnâ€²a:ntÉ™r | ËˆnÊ²eËÉ´Ë tË É™É¾Ë  | l | Â  | Â  | Â  | . nuair | nuÉ™râ€² | ËˆÉ´Ë uËÉ¾Ê² | l | Â  | Â  | Â  | . nÃ¡ | nÉ‘: | ËˆÉ´Ë aË | l | Â  | Â  | Â  | . nÃ­ | nâ€²i: | ËˆÉ´Ê²iË | l | Â  | Â  | Â  | . nÃ­l | Ëˆnâ€²i:lâ€² | ËˆÉ´Ê²iËlÊ² | l | Â  | Â  | Â  | . nÃ­odh | Ëˆnâ€²i:wÉ™dâ€² | ËˆnÊ²iËuË | l | Â  | Â  | &lt;odh&gt; â†’ É™dÊ² / _ # pronoun | . nÃ³ | nÉ‘: | ËˆÉ´Ë oË | l | Â  | Â  | Â  | . ocht | É”xd | ËˆaxtË  | l | Â  | Â  | Â  | . orthaÃ­ | É”rhi | ËˆoËÉ¾Ë hiË | Â  | uirthi | ËˆaÉ¾Ë hjiË | Â  | . phoitÃ­n | Ëˆfotâ€²inâ€² | ËˆfË otÊ²inÊ² | l+m | Â  | Â  | Â  | . phoitÃ­n | ËˆfÉ”tâ€²inâ€² | ËˆfË otÊ²inÊ² | l+m | Â  | Â  | Â  | . phortaigh | ËˆfÉ”rti | ËˆfË aÉ¾Ë tË iË | l | Â  | Â  | Â  | . poitÃ­n | ËˆpÉ”tâ€²inâ€² | ËˆpË otÊ²inÊ² | l | Â  | Â  | Â  | . pÃ¡draig | ËˆpÉ‘:drikâ€² | ËˆpË aËdË É¾Ë É™ÉŸ | l | Â  | Â  | Â  | . rabh | ro | ËˆÉ¾Ë au | Â  | raibh | ËˆÉ¾Ë oËw | Â  | . rachadh | rÉ‘hu | ËˆÉ¾Ë ahuË | l | Â  | Â  | Â  | . rachadh | rÉ‘hÉ™dâ€² | ËˆÉ¾Ë ahuË | l | Â  | Â  | &lt;adh&gt; â†’ É™dÊ² / _ # pronoun | . rachaidh | ËˆrÉ‘hÉ™ | ËˆÉ¾Ë aËhij | l | Â  | Â  | Â  | . raithte | Ëˆratâ€²Êƒ | ËˆÉ¾Ë ahtÊ²É™ | Â  | rÃ¡ite | ËˆÉ¾Ë aËtÊ²É™ | É™ â†’ âˆ… / _ # v | . rannadh | ËˆrÉ‘nhu | ËˆÉ¾Ë aÉ´Ë uË | Â  | roinnt | ËˆÉ¾Ë oÉ´Ê²tÊ² | Â  | . rathaidh | nÌ¥Ëˆrahi | ËˆÉ¾Ë ahiË | Â  | Â  | Â  | Â  | . rathaidh | ËˆrÉ‘hi | ËˆÉ¾Ë ahiË | Â  | ratha | ËˆÉ¾Ë ahÉ™ | Â  | . riclÃ­nÃ­ | ËˆrÃ¯kâ€²lâ€²i:nâ€²i | ËˆÉ¾Ë iclÊ²iËnÊ²iË | Â  | Â  | Â  | Â  | . rotha | ËˆrÉ”h | ËˆÉ¾Ë ohÉ™ | Â  | Â  | Â  | Â  | . rud | roÌ¤d | ËˆÉ¾Ë udË  | l | Â  | Â  | Â  | . rud | ËˆroÌ¤d | ËˆÉ¾Ë udË  | l | Â  | Â  | Â  | . rÃ©idh | Ëˆre:i | ËˆÉ¾Ë eËj | l | Â  | Â  | Â  | . rÃ©ir | Ëˆre: | ËˆÉ¾Ë eËÉ¾Ê² | l | Â  | Â  | Â  | . rÃ©ir | Ëˆrâ€²e: | ËˆÉ¾Ë eËÉ¾Ê² | l | Â  | Â  | Â  | . sa | sÉ™ | ËˆsË É™ | l | Â  | Â  | Â  | . seachtmhaine | ËˆÊƒaxdÉªnâ€²É™ | ËˆÊƒaÉ¾Ë tË wÉ™nÊ²É™ | Â  | seachtaine | ËˆÊƒaÉ¾Ë tË É™nÊ²É™ | Â  | . seo | ÊƒÉ” | ËˆÊƒo | l | Â  | Â  | Â  | . shoin | xÉªnâ€² | ËˆhoËˆinÊ² | Â  | shin | ËˆhinÊ² | Â  | . shÃ­olthuigheadh | ËˆhiÉ™lhiuw | ËˆhiËÊŸË hÉ™juË | Â  | shÃ­othlaÃ­odh | ËˆhiËhÊŸË iÉ™É£ | Â  | . siad | ÊƒÉ™d | ËˆÊƒiËdË  | l | Â  | Â  | Â  | . sin | ÊƒÉªnâ€² | ËˆÊƒinÊ² | l | Â  | Â  | Â  | . sinâ€™s | ÊƒÉªnâ€²s | ËˆÊƒinÊ²Êƒ | Â  | Â  | Â  | Â  | . sioc | ËˆÊƒoÌ¤k | ËˆÊƒikË  | l | Â  | Â  | Â  | . slat | ËˆslÉ‘t | ËˆsË ÊŸË atË  | l | Â  | Â  | Â  | . sleaghÃ¡n | ËˆÊƒlâ€²a:n | ËˆÊƒlÊ²aÉ£aËÉ´Ë  | Â  | sleÃ¡n | ËˆÊƒlÊ²aËÉ´Ë  | Â  | . sprÃ©idhfidh | Ëˆsbâ€²râ€²e:fâ€²É™ | ËˆsË pÊ²É¾Ê²eËjiË | Â  | sprÃ©ifidh | ËˆsË pÊ²É¾Ê²eËiË | Â  | . spÃ¡d | ËˆsbÉ‘:d | ËˆsË pË aËdË  | l | Â  | Â  | Â  | . spÃ¡d | ËˆsbÊ·É‘:d | ËˆsË pË aËdË  | l | Â  | Â  | Â  | . still | ËˆsdÃ¯l | ËˆÊƒtÊ²iÊŸÊ² | Â  | Â  | Â  | Â  | . stÃ¡luighidh | ËˆsdÉ‘:li | ËˆsË tË aËÊŸË É™jiË | Â  | stÃ¡laÃ­ | ËˆsË tË aËÊŸË iË | Â  | . suas | ÊƒuÉ™s | ËˆsË uasË  | l | Â  | Â  | Â  | . sÃ¡bhÃ¡ilte | ËˆsÉ‘:wÉ‘lâ€²tâ€² | ËˆsË aËwaÊŸÊ²tÊ²É™ | l | Â  | Â  | Â  | . sÃ¡bhÃ¡ilte | ËˆsÉ‘:wÉ‘lâ€²tâ€²á¶´É™ | ËˆsË aËwaÊŸÊ²tÊ²É™ | l | Â  | Â  | Â  | . sÃ© | ÊƒÉ› | ËˆÊƒeË | l | Â  | Â  | Â  | . sÃ­ | tÉ‘:Êƒi: | ËˆÊƒiË | l | Â  | Â  | Â  | . sÃ­ | Êƒi(:) | ËˆÊƒiË | l | Â  | Â  | Â  | . sÃ­os | ËˆÊƒi:s | ËˆÊƒiËsË  | l | Â  | Â  | Â  | . sÃ­os | ËˆÊƒiáµŠs | ËˆÊƒiËsË  | l | Â  | Â  | Â  | . t-am | ËˆtÉ‘(:)m | ËˆtË aËmË  | l | Â  | Â  | Â  | . t-iomlÃ¡n | Ëˆtâ€²á¶´oÌ¤mlan | ËˆtÊ²uËmË ÊŸË aÉ´Ë  | Â  | Â  | Â  | Â  | . t-uachtar | ËˆtuÉ™xdÉ™r | ËˆtË uaxtË É™É¾Ë  | l+m | Â  | Â  | Â  | . t-uisce | tÉªÊƒgâ€²É™ | ËˆtË iÊƒcÉ™ | l | Â  | Â  | Â  | . talamh | ËˆtÉ‘lu | ËˆtË oÊŸË uË | l | Â  | Â  | Â  | . tamallt | tÉ‘mÉ™lt | ËˆtË amË É™ÊŸË tË  | Â  | tamall | ËˆtË amË É™ÊŸË  | Â  | . taobh | ti:w | ËˆtË iËw | l | Â  | Â  | Â  | . tarraingt | tÉ‘rÉ™nâ€²tâ€² | ËˆtË aÉ¾Ë inÊ²tÊ² | l | Â  | Â  | Â  | . teinidh | Ëˆtâ€²ÊƒÉªnâ€²i | ËˆtÊ²enÊ²iË | Â  | tine | Â  | Â  | . thart | hÉ‘rt | ËˆhaÉ¾Ë tË  | l | Â  | Â  | Â  | . theacht | haxd | ËˆhjaxtË  | l | Â  | Â  | Â  | . thig | hÉªgâ€² | ËˆhjiÉŸ | l | Â  | Â  | Â  | . thiocfadh | hoÌ¤ku | ËˆhjokË uË | l | Â  | Â  | Â  | . thoirt | ËˆhoÌ¤rtâ€² | ËˆhaÉ¾Ë tÊ² | l+m | Â  | Â  | Â  | . thriomuigheadh | Ëˆxâ€²râ€²iÌˆmÊ·iedâ€² | ËˆrÌªÊ²imË É™juË | Â  | thriomaÃ­odh | ËˆrÌªÊ²imË iÉ™É£ | Â  | . thriomuigheann | Ëˆxâ€²râ€²oÌ¤mÊ·iÉ™n | ËˆrÌªÊ²imË É™jÉ™É´Ë  | Â  | thriomaÃ­onn | ËˆrÌªÊ²imË iÉ™É´Ë  | Â  | . thÃ©igheadh | Ëˆhe:wÉ™dâ€² | ËˆheËjuË | Â  | thÃ©adh | ËˆhjeËh | Â  | . thÃ©igheann | Ëˆhe:áµŠn | ËˆheËjÉ™É´Ë  | Â  | thÃ©ann | ËˆheËÉ´Ë  | Â  | . tionntochaidh | Ëˆtâ€²á¶´oÌ¤ntahÉ™ | ËˆtÊ²iÉ´Ë tË É™hiË | Â  | tiontÃ³idh | ËˆtÊ²iÉ´Ë tË É”j | Â  | . toithe | tihÉ™ | ËˆtË ohÉ™ | Â  | tithe | ËˆtÊ²ihjiË | Â  | . toithe | ËˆtihÉ™ | ËˆtË ohÉ™ | Â  | tithe | ËˆtÊ²ihjiË | Â  | . tosochaidh | ËˆtÉ”sahÉ™ | ËˆtË osË É™hiË | Â  | tosÃ³idh | ËˆtË osË É”j | Â  | . triomochaidh | Ëˆtâ€²á¶´râ€²Ã¯mÉ‘hÉ™ | ËˆtÊ²É¾Ê²imË É™hiË | Â  | triomÃ³idh | ËˆtÊ²É¾Ê²imË É”j | Â  | . trÃ­ | tâ€²Êƒrâ€²i: | ËˆtÊ²É¾Ê²iË | l | Â  | Â  | Â  | . tsleaghÃ¡in | â€²tâ€²Êƒlâ€²a:nâ€² | ËˆtÊ²lÊ²aÉ£aËnÊ² | Â  | tsleÃ¡in | ËˆtÊ²lÊ²aËnÊ² | Â  | . tuairim | tuÉ™râ€²Éªmâ€² | ËˆtË uaÉ¾Ê²imÊ² | l | Â  | Â  | Â  | . tusa | ËˆtÃ¶sÉ™ | ËˆtË usË É™ | l | Â  | Â  | Â  | . tÃ¡ | ËˆtÉ‘(:) | ËˆtË aË | l | Â  | Â  | Â  | . tÃ­r | Ëˆtâ€²á¶´i:râ€² | ËˆtÊ²iËÉ¾Ê² | l | Â  | Â  | Â  | . tÃº | tu(áµŠ) | ËˆtË uË | l | Â  | Â  | Â  | . uair | nuÉ™râ€² | ËˆuaÉ¾Ê² | l | Â  | Â  | Â  | . uair | ËˆnuÉ™râ€² | ËˆuaÉ¾Ê² | l | Â  | Â  | Â  | . uile | ËˆnÉªlâ€²É™ | ËˆilÊ²É™ | l | Â  | Â  | Â  | . uisce | ÉªÊƒgâ€²É™ | ËˆiÊƒcÉ™ | l | Â  | Â  | Â  | . well | wÉ›lâ€² | ËˆweÊŸÊ² | Â  | Â  | Â  | Â  | . worm | ËˆwÃ¯râ€²É™m | ËˆwoËÉ¾Ë É™mË  | Â  | Â  | Â  | Â  | . Ã¡ | a | aË | l | Â  | Â  | Â  | . Ã¡iteacha | Ëˆa:nâ€²tâ€²axÉ™ | ËˆaËtÊ²É™hÉ™ | Â  | Ã¡iteanna | ËˆaËtÊ²É™É´Ë É™ | Â  | . Ã©adan | Ëˆe:áµŠdÉ‘n | ËˆeËdË É™É´Ë  | l | Â  | Â  | Â  | . Ã©adan | ËˆÉ›:dÉ‘n | ËˆeËdË É™É´Ë  | l | Â  | Â  | Â  | . Ã©adan | ËˆÉ›:áµŠdÉ‘n | ËˆeËdË É™É´Ë  | l | Â  | Â  | Â  | . Ã­ | Â  | ËˆiË | l | Â  | Â  | Â  | . Ã­ | i: | ËˆiË | l | Â  | Â  | Â  | . Ã³ | É‘ | ËˆoË | l | Â  | Â  | Â  | . Ã³ | É” | ËˆoË | l | Â  | Â  | Â  | . Oâ€™Neill, John E. â€œIrish Texts from South West Donegal.â€ Zeitschrift FÃ¼r Celtische Philologie, vol. 33, 1974, doi:10.1515/zcph.1974.33.1.285.Â &#8617; . |",
            "url": "https://jimregan.github.io/notes/irish/donegal/2021/06/14/irish-texts-from-south-west-donegal-texts-1-2.html",
            "relUrl": "/irish/donegal/2021/06/14/irish-texts-from-south-west-donegal-texts-1-2.html",
            "date": " â€¢ Jun 14, 2021"
        }
        
    
  
    
        ,"post142": {
            "title": "Tuairisc scraper pieces",
            "content": "_SITEMAP=&#39;https://tuairisc.ie/sitemap.xml&#39; . import requests from bs4 import BeautifulSoup . def _read_main_sitemap(): output = [] sm = requests.get(_SITEMAP) if sm.status_code != 200: raise Exception(&quot;Failed to read sitemap&quot;) base_soup = BeautifulSoup(sm.text, &#39;lxml&#39;) for submap in base_soup.findAll(&#39;sitemap&#39;): location = submap.find(&#39;loc&#39;).text if &#39;sitemap-pt&#39; in location: output.append(_read_sub_sitemap(location)) return output . def _read_sub_sitemap(url): output = [] sm = requests.get(url) if sm.status_code != 200: raise Exception(&quot;Failed to read sitemap&quot;) base_soup = BeautifulSoup(sm.text, &quot;lxml&quot;) for submap in base_soup.findAll(&quot;url&quot;): output.append(submap.find(&quot;loc&quot;).text) return output . def _fetch_article(url): page = requests.get(url) if page.status_code != 200: raise Exception(&quot;Failed to read page: &quot; + url) return page.text . def _get_article_text(content): base_soup = BeautifulSoup(content, &quot;lxml&quot;) main = base_soup.find(&quot;div&quot;, {&quot;class&quot;: &quot;article--full__content&quot;}) paras = [p.text.strip() for p in main.findAll(&quot;p&quot;) if p.text.strip() != &#39;&#39;] return(paras) . def _get_pub_date(content): base_soup = BeautifulSoup(content, &quot;lxml&quot;) date = base_soup.find(&quot;time&quot;, {&quot;itemprop&quot;: &quot;datePublished&quot;}) return date[&quot;datetime&quot;] . _get_article_text(_fetch_article(&#39;https://tuairisc.ie/nuair-a-thainig-john-hume-go-hollscoil-na-banriona-thuig-me-gur-i-lathair-ceannaire-agus-faidh-a-bhi-me/&#39;)) . _get_pub_date(_fetch_article(&#39;https://tuairisc.ie/nuair-a-thainig-john-hume-go-hollscoil-na-banriona-thuig-me-gur-i-lathair-ceannaire-agus-faidh-a-bhi-me/&#39;)) . &#39;2020-08-04 05:44&#39; .",
            "url": "https://jimregan.github.io/notes/irish/scraper/tuairisc/2021/06/13/tuairisc-scraper.html",
            "relUrl": "/irish/scraper/tuairisc/2021/06/13/tuairisc-scraper.html",
            "date": " â€¢ Jun 13, 2021"
        }
        
    
  
    
        ,"post143": {
            "title": "Download w2v-u Swedish model trained on Colab",
            "content": "Original . %%capture !pip install gdown . !gdown https://drive.google.com/uc?id=1-3fYwuDq-l7UpowGtzq3X4Dg-jTrb5jQ !gdown https://drive.google.com/uc?id=1E3LB7rlmk00zhsgYEYFq8y-2Ck6QU-wx . Downloading... From: https://drive.google.com/uc?id=1-3fYwuDq-l7UpowGtzq3X4Dg-jTrb5jQ To: /kaggle/working/checkpoint_last.pt 13.0MB [00:00, 57.6MB/s] Downloading... From: https://drive.google.com/uc?id=1E3LB7rlmk00zhsgYEYFq8y-2Ck6QU-wx To: /kaggle/working/checkpoint_best.pt 13.0MB [00:00, 65.7MB/s] .",
            "url": "https://jimregan.github.io/notes/kaggle/w2vu/2021/06/09/download-w2vu-sv-model-trained-on-colab.html",
            "relUrl": "/kaggle/w2vu/2021/06/09/download-w2vu-sv-model-trained-on-colab.html",
            "date": " â€¢ Jun 9, 2021"
        }
        
    
  
    
        ,"post144": {
            "title": "wav2vec-u notes",
            "content": "The skippable blah . wav2vec unsupervised has caught a bit of attention. . There has been a mixed bag of expectations: there was a blog post, they even had a video: . Facebook AIâ€™s new open source speech recognition model, wav2vec Unsupervised, uses no transcribed data at all. Weâ€™ve tested it on many languages, such as Swahili, that have proven challenging for other systems. Learn more in our blog post here: https://t.co/b6ic50AsM6 pic.twitter.com/x3Tx9nxq5i . &mdash; Meta AI (@MetaAI) June 1, 2021 So, a few people have had the expectation that it would be quite a bit easier than it turned out to. . Iâ€™ve been beating my head against multiple walls for over a decade, with various pieces of research software for various purposes, so my expectations were a little different. Just looking at the directory, the third subdirectory is kaldi_self_train, which is the first red flag: this will not be easy. Scrolling down, among the first instructions are zsh scripts. zsh is a great shell, and using it as a shell was a sign of sophistication in the late 90s, but it isnâ€™t the most universal shell, so if your scripts are zsh scripts, thatâ€™s a pretty good sign youâ€™ve never tried to run them on a second computer. That said, trying to use any kind of software on Linux in the late 90s involved some sort of beating of heads against walls, so that contributes too. . I like Kaggle. A lot. I like the workflow, and being able to use the output of one notebook as the input to another. I like being able to run something, and not have to babysit it in case it disconnects, like with Colab. So Iâ€™ve tried to do as much of this as possible on Kaggle. . But the GPU images on Kaggle are seriously broken. It could be by design: the handful of things Iâ€™ve tried that are run purely as a notebook seem to work well. Maybe conda is deliberately cobbled, maybe itâ€™s unintentional, but it fails more often than not. So anything that involves using a GPU: switch to Colab. . Caveat . These are my notes for my own use, because once Iâ€™ve done a full trial run, I have some data I want to try out. Iâ€™m deliberately not adding additional text, mostly because I want the trial run to go as quickly as possible; thatâ€™s failing for other reasons, but such is life. . What Iâ€™ve done was based on my understanding, or best guess. I can guarantee that I was not smoking any illegal substances, but considering where I live, I canâ€™t guarantee that there was no second-hand smoke. . There is an issue on fairseqâ€™s github where Alexei Baevski has said that better instructions are coming in a week or so, so maybe bide your time; he also offered to answer questions on that thread, so if you have questions, your best bet is to ask there. . Step 0: Data . In an ideal world, Kaggleâ€™s dataset uploader would Do The Right Thing when given a link to a zip file, or, rather, one of two Right Things: just download it, or download and unzip. Instead, it creates a directory for every file in the zip. . ðŸ¤¦ . Cool, Iâ€™ll just do that in a notebook. . wav2vec-u (and just about everything else in the world of ASR, ever) needs audio sampled at 16 kHz, and uses soundfile, so MP3s are not welcome, so Iâ€™ll do that in another notebook. . Step 0.1: ltr/wrd/phn files . Preparing these files is mentioned in passing, as though theyâ€™re self-explanatory. Which they are, if you happen to have played with phoneme-based ASR as well as wav2letter. So, not really. . What I ended up doing is this; I should have changed the tab separation in the dict.* files to a space, because thatâ€™s whatâ€™s usually given to Kaldi, but IIRC, it handles tab. So change: . paste /tmp/$i.wl /tmp/$i.wl.phn &gt; dict.$i . to: . paste /tmp/$i.wl /tmp/$i.wl.phn | tr &#39; t&#39; &#39; &#39; &gt; dict.$i . or equivalent. . Caveat: I canâ€™t say for sure if these are actually correct outputs, and Iâ€™m not even sure theyâ€™re actually used by default, aside from the prepare_audio.sh script dying if theyâ€™re missing. . There are some notes in that notebook where I tracked down and corrected for espeakâ€™s language switching; feel free to ignore that if youâ€™re not borderline OCD. . Step 0.2: Preparing TSVs . Another thing thatâ€™s glossed over a bit is the TSV files, which are more pseudo-TSV. . â€œSimilar to wav2vec 2.0â€ is more-or-less true, in that you can figure it out if you look at this script; basically, the format is: . /path/to/my/audio/ file1.wav [number of frames] file2.wav [number of frames] ... (etc.) . I used this notebook to convert Common Voice TSV to these pseudo-TSVs, but the number of frames arenâ€™t read by anything, so you can get away with a file list, as long as the first line is the path. . Step 1: VAD/Silence trimming . Thereâ€™s a passing mention of rVAD, like itâ€™s a common piece of software that you should just be able to install. Itâ€™s not: itâ€™s here. Or, you know, save yourself the trouble and copy the relevant steps from the notebook . This went fairly smoothly; I wrestled with Kaggle a bit, but I think any problems here were of my own creation. . Step 2: prepare_audio.sh . My notebook for prepare_audio.sh is quite short; basically, you need the dict.*, *.wrd, *.ltr, and *.phn files from Step 0.1, and: . pip install npy-append-array faiss-gpu . (also, possibly, apt install zsh) . Also: wow! This used GPU on Kaggle, and actually worked. . Step 3: prepare_text.sh . This needs Kaldi to compile FSTs. On Kaggle, I used this notebook to extract a pre-built version from the official docker images. DNN parts wonâ€™t run, because theyâ€™re compiled for an earlier version of CUDA, but theyâ€™re not necessary for this step. . If youâ€™re using Colab, this question on Stack Overflow is for you: . !pip install kora -q import kora.install.kaldi . The version of Kaldi there is also from the official docker image (thatâ€™s where I got the idea), but it also downloads and unpacks it for you. Which is nice. . My notebook for running prepare_text.sh has more notes than usual: check it out . Step 4: GAN training . This doesnâ€™t work on Kaggle, because GPU. It does, however, run on CPUâ€”albeit 8-9 times slowerâ€”so Iâ€™ve been chaining together calls, starting with this, leading up to (at the time of writing) this. . The good news is, it runs fine on Colab: notebook here. . (By â€œfineâ€, I mean â€œwith this patch added, running from this branch where everything has been moved around.â€ Close enough.) . Fin . Iâ€™m still waiting for GAN training to finish, so I canâ€™t comment on anything else. .",
            "url": "https://jimregan.github.io/notes/wav2vec-u/2021/06/05/wav2vec-u-notes.html",
            "relUrl": "/wav2vec-u/2021/06/05/wav2vec-u-notes.html",
            "date": " â€¢ Jun 5, 2021"
        }
        
    
  
    
        ,"post145": {
            "title": "wav2vec-u Common Voice Swedish - GAN training, CPU8",
            "content": "Original here . Preparation . !cp ../input/w2vu-cvsv-checkpoints-cpu7/checkpoint_best.pt . !cp ../input/w2vu-cvsv-checkpoints-cpu7/checkpoint_last.pt . . %%capture !conda install -c pykaldi pykaldi -y . %cd /tmp . !git clone https://github.com/jimregan/fairseq/ --branch issue3581 . !git clone https://github.com/kpu/kenlm . %%capture !apt-get -y install libeigen3-dev liblzma-dev zlib1g-dev libbz2-dev . %%capture %cd /tmp/kenlm !python setup.py install %cd /tmp . import os os.environ[&#39;PATH&#39;] = f&quot;{os.environ[&#39;PATH&#39;]}:/tmp/kenlm/build/bin/&quot; os.environ[&#39;FAIRSEQ_ROOT&#39;] = &#39;/tmp/fairseq&#39; . %cd /tmp/fairseq/ . %%capture !python setup.py install . %cd /tmp/fairseq/ . os.environ[&#39;HYDRA_FULL_ERROR&#39;] = &#39;1&#39; . %%capture !pip install editdistance . GAN . %%writefile rungan.sh PREFIX=w2v_unsup_gan_xp TASK_DATA=/kaggle/input/wav2vec-u-cv-swedish-audio/precompute_pca512_cls128_mean_pooled/ TEXT_DATA=/kaggle/input/wav2vec-u-cv-swedish-text-prep/preppedtext/phones/ KENLM_PATH=/kaggle/input/wav2vec-u-cv-swedish-text-prep/preppedtext/phones/lm.phones.filtered.04.bin PREFIX=$PREFIX fairseq-hydra-train -m --config-dir fairseq/config/model/wav2vecu/gan --config-name w2vu task.data=${TASK_DATA} task.text_data=${TEXT_DATA} task.kenlm_path=${KENLM_PATH} checkpoint.no_epoch_checkpoints=false checkpoint.keep_last_epochs=5 checkpoint.save_dir=/kaggle/working &#39;common.seed=range(0,5)&#39; . !bash rungan.sh .",
            "url": "https://jimregan.github.io/notes/kaggle/wav2vec-u/2021/06/05/wav2vec-u-cv-swedish-gan-cpu8.html",
            "relUrl": "/kaggle/wav2vec-u/2021/06/05/wav2vec-u-cv-swedish-gan-cpu8.html",
            "date": " â€¢ Jun 5, 2021"
        }
        
    
  
    
        ,"post146": {
            "title": "CC-Aligned Irish contains porn",
            "content": "I re-ran this notebook and forgot to take the opportunity to see why M2M100 thinks everything is porn. . Now I know. . !wget http://www.statmt.org/cc-aligned/en_XX-ga_IE.tsv.xz . --2021-06-05 18:10:06-- http://www.statmt.org/cc-aligned/en_XX-ga_IE.tsv.xz Resolving www.statmt.org (www.statmt.org)... 129.215.197.184 Connecting to www.statmt.org (www.statmt.org)|129.215.197.184|:80... connected. HTTP request sent, awaiting response... 200 OK Length: 150347648 (143M) [application/x-xz] Saving to: â€˜en_XX-ga_IE.tsv.xzâ€™ en_XX-ga_IE.tsv.xz 100%[===================&gt;] 143.38M 128KB/s in 18m 23s 2021-06-05 18:28:30 (133 KB/s) - â€˜en_XX-ga_IE.tsv.xzâ€™ saved [150347648/150347648] . !unxz en_XX-ga_IE.tsv.xz . unxz: en_XX-ga_IE.tsv: File exists . !cat en_XX-ga_IE.tsv|grep -a -i brazzers|wc -l . 461 . !cat en_XX-ga_IE.tsv|grep -a -i brazzers|cut -c -120 . brazzers-n.com http://brazzers-n.com/en/tgb/6350-%E0%A6%86%E0%A6%B0%E0%A6%AC%2C+%E0%A6%AC%E0%A7%87%E0%A6%B6%E0%A7%8D%E0% brazzers-n.com http://brazzers-n.com/en/tgb/3981-%E0%A4%AD%E0%A4%B5%E0%A5%8D%E0%A4%AF+%E0%A4%95%E0%A4%BF%E0%A4%B6%E0%A5% brazzers-n.com http://brazzers-n.com/en/tgb/13264-%E0%B0%AA%E0%B0%BE%E0%B0%A0%E0%B0%B6%E0%B0%BE%E0%B0%B2+%E0%B0%AB%E0%B0 brazzers-n.com http://brazzers-n.com/en/tgb/16024-%D0%93%D2%AF%D0%BD+Creampie/ Deep Creampie - BRAZZERS porn Studio. Por brazzers-n.com http://brazzers-n.com/en/tgb/7978-%D0%94%D0%B0%D0%BB%D0%B4+%D0%93%D0%B0%D0%BB%D0%B7%D1%83%D1%83%D0%B3%D0% brazzers-n.com http://brazzers-n.com/en/tgb/6324-CFNM+%D0%A1%D0%B5%D0%BA%D1%81/ CFNM Sex - BRAZZERS porn Studio. Porn cl porndig-n.com http://porndig-n.com/en/bikini Bikini porn video porndig|Menu|Main (current)|Random video|All categories|E hotpornadult.com http://hotpornadult.com/ HotPornAdult - porn in HD|Free porn videos online|Sliding menu|HotPornAdult|Ma brazzers-n.com http://brazzers-n.com/en/tgb/17530-%E0%A6%AA%E0%A7%87%E0%A6%9B%E0%A6%A8+%E0%A6%A5%E0%A7%87%E0%A6%95%E0%A7 ecml.at http://edl.ecml.at/LanguageFun/LanguageQuiz/tabid/1873/language/en-GB/Default.aspx European Day of Languages &gt; L brazzers-n.com http://brazzers-n.com/en/tgb/14265-%D0%A5%D1%83%D1%83%D1%87%D0%B8%D0%BD+Dicks/ Old Dicks - BRAZZERS porn brazzers-n.com http://brazzers-n.com/en/tgb/12184-%D0%95%D0%B2%D1%80%D0%BE+%D0%93%D1%80%D1%83%D0%BF%D0%BF/ Euro Group - brazzers-n.com http://brazzers-n.com/en/tgb/6922-%E0%A6%9C%E0%A6%BE%E0%A6%AA%E0%A6%BE%E0%A6%A8%E0%A6%BF+%E0%A6%A6%E0%A7% foto-semya.ru https://foto-semya.ru/ bohsia doggie telugubrothersistersexvides asa akira hot|bohsia doggie|bohsia doggie lenkino.mobi http://lenkino.mobi/en/mv/1916008-danielle-dynamite-masturbates.html Danielle Dynamite Masturbates|Apostate brazzers-n.com http://brazzers-n.com/en/tgb/16058-%E0%A6%AA%E0%A6%B0%E0%A6%BF%E0%A6%9A%E0%A6%BE%E0%A6%B0%E0%A6%BF%E0%A6% 24video-xxx.com http://24video-xxx.com/en/hairy-pussy Hairy pussy this category contains selected videos in HD quality. brazzers-n.com http://brazzers-n.com/en/tgb/733-Chubby/ Chubby - BRAZZERS porn Studio. Porn clips brazzers Studio and no brazzers-n.com http://brazzers-n.com/en/tgb/9953-%E0%A6%95%E0%A7%81%E0%A6%96%E0%A7%8D%E0%A6%AF%E0%A6%BE%E0%A6%A4/ Infamo brazzers-n.com http://brazzers-n.com/en/mb/3319014-eva.html Eva|Menu|Main (current)|Random video|Chat|All categories|Eng brazzers-n.com http://brazzers-n.com/en/tgb/952-%E0%A6%B2%E0%A6%BE%E0%A6%B2+%E0%A6%B8%E0%A6%AC%E0%A7%81%E0%A6%9C/ Red Gr brazzers-n.com http://brazzers-n.com/en/tgb/10228-Girl+Loves+Anal/ Girl Loves Anal - BRAZZERS porn Studio. Porn clips br hdbox.ws https://hdbox.ws/en/sat-tv-novosti/5092-transpondernye-novosti-sputnikovogo-televideniya-20-fevralya-2018.html hotpornadult.com http://hotpornadult.com/en/tag/ Free porn videos online|Sliding menu|HotPornAdult|Main (current)|Random brazzers-n.com http://brazzers-n.com/en/tgb/12851-%E0%A6%B8%E0%A7%8D%E0%A6%AC%E0%A6%B0%E0%A7%8D%E0%A6%A3%E0%A6%95%E0%A7% pornoload-n.com http://pornoload-n.com/en/tag/431-%C4%90%E1%BB%93/page/7/ Hard Sex - Pornload best website with adult vi brazzers-n.com http://brazzers-n.com/en/vibrator/ Vibrator brazzers|Menu|Main (current)|Random video|Chat|All categories pornoload-n.com http://pornoload-n.com/en/tag/11490-Famous/ Famous - Pornload best website with adult videos and porn cl ruporn-tv.com http://ruporn-tv.com/en/blonde Blonde|Menu|Main (current)|Random|Category|English|Ð ÑƒÑÑÐºÐ¸Ð¹|English|A pornk.mobi http://pornk.mobi/en/bikini Bikini porn pornk|Menu|Main (current)|Topics porn|Random video|Chat|English|Ð Ñƒï¿½ eporner-n.com http://eporner-n.com/en/facialized Cum on face _ EPORNER|Menu|Main (current)|All categories|Random|English brazzers-n.com http://brazzers-n.com/en/tgb/16337-%E0%A8%A6%E0%A8%BF%E0%A8%A8/ Daytime - BRAZZERS porn Studio. Porn clip brazzers-n.com http://brazzers-n.com/en/tgb/12184-%E0%A8%AF%E0%A9%82%E0%A8%B0%E0%A9%8B+%E0%A8%97%E0%A8%B0%E0%A9%81%E0%A9 gonzofap.com http://gonzofap.com/en/ Gonzo Fap|English|Afrikaans|Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©|AzÉ™rbaycanca|Ð‘ÐµÐ»Ð°Ñ€ÑƒÑÐºÐ°Ñ|Ð‘ÑŠï¿½ pornoload-n.com http://pornoload-n.com/en/hardcore Hardcore|Menu|PornoLoad|Main (current)|Random video|All categories|En oisquipedia.org https://oisquipedia.org/encheu_a_boca_dela_de_porra_0532 Encheu A Boca Dela De Porra - English Porn Vide ruporn-tv.com http://ruporn-tv.com/en/p/6/ Russian porn online watch free video on Ruporn.tv - page 6|Menu|Main (current ecml.at http://edl.ecml.at/LanguageFun/FAQsonsignlanguage/tabid/2741/language/en-GB/Default.aspx European Day of Languag cucek.net http://cucek.net/en/porn-orgasms Porn orgasms|Sliding menu|Cucek.NET|Main (current)|Random video|All categorie ecml.at http://edl.ecml.at/LanguageFun/LanguageFacts/tabid/1859/language/en-GB/Default.aspx European Day of Languages &gt; trahtubetv.com http://trahtubetv.com/en/tag/351-Pounded/ Pounded - Fuck tube. Check out hot pussies. Porn videos for fre brazzers-n.com http://brazzers-n.com/en/tgb/12398-%E0%B9%80%E0%B8%82%E0%B9%88%E0%B8%B2%E0%B8%AA%E0%B8%B9%E0%B8%87%E0%B8% brazzers-n.com http://brazzers-n.com/en/tgb/344-%E0%A6%AB%E0%A6%BF%E0%A6%B8%E0%A6%A8%E0%A7%87%E0%A6%9F/ Fishnet - BRAZZE pornoload-n.com http://pornoload-n.com/en/tag/9763-%D0%97%D0%B2%D1%83%D1%87%D0%B0%D0%BD%D0%B8%D0%B5/ Sounding - Pornload brazzers-n.com http://brazzers-n.com/en/tgb/5075-%E0%A6%95%E0%A7%83%E0%A6%B7%E0%A6%95%E0%A6%A6%E0%A7%87%E0%A6%B0/ Farmer estudiogrum.com https://estudiogrum.com/en/home English Porn Video - Free Porn Videos Xvideos, Pornhub, xnxx - Ladyboy P brazzers-n.com http://brazzers-n.com/en/azeri/ Azeri brazzers|Menu|Main (current)|Random video|Chat|All categories|Engli pornoload-n.com http://pornoload-n.com/en/page/8/ Pornload best website with adult videos and porn clips adult free - pa brazzers-n.com http://brazzers-n.com/en/tgb/23432-%E0%A6%9B%E0%A7%8B%E0%A6%9F+%E0%A6%B2%E0%A6%BE%E0%A6%B2+%E0%A6%9A%E0%A brazzers-n.com http://brazzers-n.com/en/tgb/12940-%E0%A6%AC%E0%A6%A1%E0%A6%BC%E0%A7%8B+%E0%A6%AA%E0%A7%8B%E0%A6%81%E0%A6 hotpornohub.com http://hotpornohub.com/en/next/3/ Cool porn video from hotpornohub.com! - page 3|Sliding menu|HotPornoHu brazzers-n.com http://brazzers-n.com/en/tgb/7808-%E0%A6%97%E0%A6%B0%E0%A6%AE%2C+%E0%A6%AA%E0%A7%80%E0%A6%A8%E0%A6%B8%E0% brazzers-n.com http://brazzers-n.com/en/tgb/12939-%E0%A6%AE%E0%A6%BE%E0%A6%87+%E0%A6%8F%E0%A6%B0/ Huge Titties - BRAZZER brazzers-n.com http://brazzers-n.com/en/tgb/11635-%E0%A6%AA%E0%A6%B0%E0%A6%BF%E0%A6%A3%E0%A6%A4%2C+%E0%A6%AA%E0%A7%8B%E0 erkiss-tv.com http://erkiss-tv.com/en/bikini/ Bikini porn on the phone|Menu|Main (current)|Random|Chat|Category|English| brazzers-n.com http://brazzers-n.com/en/tgb/21088-%D0%9D%D1%83%D0%BB%D0%B8%D0%BC%D0%B6+%D0%A8%D2%AF%D1%82%D1%8D%D1%8D%D0 brazzers-n.com http://brazzers-n.com/en/tgb/12030-%E0%A6%AE%E0%A6%BE%E0%A6%87+%E0%A6%8F%E0%A6%B0+%E0%A6%AE%E0%A6%BE%E0%A brazzers-n.com http://brazzers-n.com/en/tgb/11741-%E0%A6%A8%E0%A6%BF%E0%A6%96%E0%A7%81%E0%A6%81%E0%A6%A4+%E0%A6%B8%E0%A7 xyutv-a.com http://xyutv-a.com/en/tag/2528-%E0%A6%95%E0%A7%81%E0%A6%A4%E0%A7%8D%E0%A6%A4%E0%A6%BE/ Motherfucker - fuck T hotpornadult.com http://hotpornadult.com/en/ HotPornAdult - porn in HD|Free porn videos online|Sliding menu|HotPornAdult trahtubetv.com http://trahtubetv.com/en/mi/9353721-vol.258-typorno.com.html vol.258 typorno.com|Menu|Tractor|Main (curre brazzers-n.com http://brazzers-n.com/en/tgb/8595-%E0%A6%97%E0%A6%B0%E0%A6%AE+%E0%A6%A7%E0%A6%BE%E0%A6%AA/ Hot Step - BRA xnxx-hd.pro http://xnxx-hd.pro/en/tag/4659-%E0%A6%AE%E0%A6%BE/ Busty Mother - Porno HD online in high quality|100% free 24video-net.com http://24video-net.com/en/footwork Footwork|Menu|24video|Main (current)|Random video|All categories|Engl ruporn-tv.com http://ruporn-tv.com/en/tag/1023-%E0%A4%8F%E0%A4%AE%E0%A4%86%E0%A4%88%E0%A4%8F%E0%A4%B2%E0%A4%8F+%E0%A4%AE pornoload-n.com http://pornoload-n.com/en/page/9/ Pornload best website with adult videos and porn clips adult free - pa porndig-n.com http://porndig-n.com/ PornDig: Porn tube video HD online Sex Free porn|Menu|Main (current)|Random video|Al brazzers-n.com http://brazzers-n.com/en/tgb/9-%E0%A6%AC%E0%A6%BE%E0%A6%B8%E0%A7%8D%E0%A6%A4%E0%A6%AC/ Real - BRAZZERS po pornoload-n.com http://pornoload-n.com/en/page/5/ Pornload best website with adult videos and porn clips adult free - pa brazzers-n.com http://brazzers-n.com/en/tgb/17424-%E0%A6%AB%E0%A7%8D%E0%A6%B2%E0%A6%BE%E0%A6%B6+%E0%A6%97%E0%A6%BE%E0%A6 reachporn.com https://www.reachporn.com/ Reach Porn Â» List Of The Best Porn Sites On The Net|Reach the best porn sites sozrelxxx.com http://sozrelxxx.com/en/c/ The list of all categories|ripe for porn|View all|English|Ð ÑƒÑÑÐºÐ¸Ð¹|Englis cucek.net http://cucek.net/en/hardcore Hardcore|Sliding menu|Cucek.NET|Main (current)|Random video|All categories|Englis brazzers-n.com http://brazzers-n.com/en/tgb/5025-%D0%A1%D1%83%D0%B2%D0%B4%D0%B0%D0%BD+%D0%97%D2%AF%D2%AF%D0%BB%D1%82/ Pe brazzers-n.com http://brazzers-n.com/en/tgb/9523-%D0%9D%D1%8E+%D0%94%D0%BE%D0%BC%D0%B0/ Nude House - BRAZZERS porn Studi trahtubetv.com http://trahtubetv.com/en/tag/55-%E0%A6%B8%E0%A7%81%E0%A6%A8%E0%A7%8D%E0%A6%A6%E0%A6%B0%E0%A6%BF+%E0%A6%B8 brazzers-n.com http://brazzers-n.com/en/tgb/19143-%D0%90%D1%80%D0%BC%D0%B5%D0%BD%D0%B8%D0%B9+%D0%9E%D1%85%D0%B8%D0%BD/ A biqle-ru.com http://biqle-ru.com/en/mk/50810-zombie-joi.html Zombie JOI|Menu|Main (current)|Random|Category|English|Ð Ñƒ hdbox.ws https://hdbox.ws/en/sat-tv-novosti/5065-transpondernye-novosti-sputnikovogo-televideniya-30-yanvarya-2018.html ecml.at http://edl.ecml.at/Home/WhyaEuropeanDayofLanguages/tabid/1763/language/en-GB/Default.aspx Why a European Day of brazzers-n.com http://brazzers-n.com/en/tgb/7754-%E0%A6%9F%E0%A6%BE%E0%A6%87%E0%A6%9F+%E0%A6%AF%E0%A7%8B%E0%A6%A8%E0%A6% brazzers-n.com http://brazzers-n.com/en/tgb/12173-%E0%A6%AA%E0%A7%8B%E0%A6%81%E0%A6%A6%2C+%E0%A6%AA%E0%A6%AA/ Ass Pop - brazzers-n.com http://brazzers-n.com/en/tgb/18830-Gaping+%D0%9D%D0%BE%D0%B9%D1%82%D0%BE%D0%BD+Pussy/ Gaping Wet Pussy - brazzers-n.com http://brazzers-n.com/en/tgb/17511-%E0%A6%9A%E0%A6%B0%E0%A6%AE+%E0%A6%B9%E0%A6%BF%E0%A6%B2/ Extreme Heels brazzers-n.com http://brazzers-n.com/en/tgb/15787-%E0%A4%8F%E0%A4%AE%E0%A5%87%E0%A4%9A%E0%A5%8D%E0%A4%AF%E0%A5%8B%E0%A4% xnxx-hd.pro http://xnxx-hd.pro/en/tag/16818-%E0%A4%AC%E0%A4%A1%E0%A4%BC%E0%A5%87+%E0%A4%B8%E0%A5%8D%E0%A4%A4%E0%A4%A8+%E brazzers-n.com http://brazzers-n.com/en/tgb/3373-%D0%A8%D0%B0%D1%80+%D0%91%D0%B8%D0%BA%D0%B8%D0%BD%D0%B8/ Yellow Bikini ruporn-tv.com http://ruporn-tv.com/en/tag/582-Fellatio/ Fellatio - Russian porn online watch free video on Ruporn.tv|Men pornoload-n.com http://pornoload-n.com/en/ch/ Chat|Menu|PornoLoad|Main (current)|Random video|All categories|English|Ð ï¿½ biqle-ru.com http://biqle-ru.com/en/mk/27008-,-brazzers--franceska-james , Brazzers - Franceska James&#39;s anal adventure|M gannuaire.com https://gannuaire.com/en/home Just Porn Xvideos, Free Porn Videos, Free Porn Download, Bb Ladies|DE|EN|CS| brazzers-n.com http://brazzers-n.com/en/tgb/9550-Craziest/ Craziest - BRAZZERS porn Studio. Porn clips brazzers Studio a brazzers-n.com http://brazzers-n.com/en/tgb/3714-POV+Fuck/ POV Fuck - BRAZZERS porn Studio. Porn clips brazzers Studio a affinicasts.com https://affinicasts.com/lexi-luna-bikini-0-1-223 Lexi Luna Bikini - English Porn Video - Free Porn Video ecml.at http://edl.ecml.at/LanguageFun/Celebritiesspeakinglanguages/tabid/3113/language/en-GB/Default.aspx European Day pornoload-n.com http://pornoload-n.com/ Pornload best website with adult videos and porn clips adult free|Menu|PornoLoad brazzers-n.com http://brazzers-n.com/en/hardcore/ Hardcore brazzers|Menu|Main (current)|Random video|Chat|All categories brazzers-n.com http://brazzers-n.com/en/tgb/21948-Big+C%C3%ADocha+M%C3%BAinteoir/ Big Boobs Teacher - BRAZZERS porn Stud brazzers-n.com http://brazzers-n.com/en/tgb/3096-%E0%A6%AD%E0%A6%BE%E0%A6%B2%2C+%E0%A6%AC%E0%A7%8D%E0%A6%B2%E0%A6%9C%E0% brazzers-n.com http://brazzers-n.com/en/celebrity/ Celebrity brazzers|Menu|Main (current)|Random video|Chat|All categori brazzers-n.com http://brazzers-n.com/en/tgb/13598-%E0%A6%AC%E0%A7%8D%E0%A6%B2%E0%A6%9C%E0%A6%AC+%E0%A6%AE%E0%A6%BE%E0%A6 brazzers-n.com http://brazzers-n.com/en/tgb/22448-%E0%A6%AE%E0%A7%81%E0%A6%96+%E0%A6%9A%E0%A6%A1%E0%A6%BC/ Face Slap - B brazzers-n.com http://brazzers-n.com/en/tgb/654-Bachelorette/ Bachelorette - BRAZZERS porn Studio. Porn clips brazzers S brazzers-n.com http://brazzers-n.com/en/tgb/14011-%D0%91%D0%B0%D0%B9%D0%B3%D0%B0%D0%BB%D0%B8%D0%B9%D0%BD+%D3%A8%D1%81%D0 brazzers-n.com http://brazzers-n.com/en/tgb/4224-%E0%A6%B8%E0%A7%87%E0%A6%95%E0%A7%8D%E0%A6%B8+%E0%A6%95%E0%A7%8D%E0%A6% brazzers-n.com http://brazzers-n.com/en/tgb/23569-%E0%A6%9A%E0%A7%81%E0%A6%B2%2C+%E0%A6%AA%E0%A7%8B%E0%A6%81%E0%A6%A6%2C brazzers-n.com http://brazzers-n.com/en/tgb/8670-%D0%AD%D0%BC%D1%87+%D0%A1%D1%83%D0%B2%D0%B8%D0%BB%D0%B0%D0%B3%D1%87/ Do brazzers-n.com http://brazzers-n.com/en/tgb/7986-%D0%91%D0%B0%D1%8F%D1%80%D1%82%D0%B0%D0%B9/ Excited - BRAZZERS porn Stu brazzers-n.com http://brazzers-n.com/en/tgb/6338-%E0%A6%B0%E0%A6%BE%E0%A6%B8%E0%A7%8D%E0%A6%A4%E0%A6%BE%E0%A6%B0+%E0%A6% brazzers-n.com http://brazzers-n.com/en/tgb/17449-%E0%A6%95%E0%A7%8D%E0%A6%AF%E0%A6%BE%E0%A6%AE%E0%A7%87%E0%A6%B0%E0%A6% redtube-n.com http://redtube-n.com/en/tag/ Menu|Main (current)|All categories|Random|English|Ð ÑƒÑÑÐºÐ¸Ð¹|English|AzÉ™ dojki-n.com http://dojki-n.com/en/nudists/pp/2/ Nudist videos online in hd quality - page 2|Menu|Main (current)|Random v ecml.at http://edl.ecml.at/LanguageFun/Hello/tabid/1876/language/en-GB/Default.aspx European Day of Languages &gt; Language brazzers-n.com http://brazzers-n.com/en/tgb/21973-%E0%A6%8F%E0%A6%95%E0%A6%BE%E0%A6%A7%E0%A6%BF%E0%A6%95+Squirting/ Mult youporn-n.com http://youporn-n.com/en/tis/11242-Brazzers%2C/ Brazzers Ass - Excellent Porn videos, sex movies, XXX Porn, sozrelxxx.com http://sozrelxxx.com/en/blowjob Super Blowjob video in excellent quality online|ripe for porn|Arab|Beach|B brazzers-n.com http://brazzers-n.com/en/tgb/19032-%E0%A6%A1%E0%A7%81%E0%A6%AC/ Dipping - BRAZZERS porn Studio. Porn clip brazzers-n.com http://brazzers-n.com/en/tgb/4846-%E0%A6%AE%E0%A6%BE%E0%A6%A4%E0%A7%8D%E0%A6%B0%E0%A6%BE%E0%A6%A4%E0%A6%B brazzers-n.com http://brazzers-n.com/en/tgb/15098-%2C+%E0%A6%97%E0%A6%AD%E0%A7%80%E0%A6%B0%2C+%E0%A6%AA%E0%A7%8B%E0%A6%8 brazzers-n.com http://brazzers-n.com/en/tgb/9090-%E0%A6%A4%E0%A6%B0%E0%A7%81%E0%A6%A3%2C+%E0%A6%AE%E0%A7%87%E0%A6%AF%E0% brazzers-n.com http://brazzers-n.com/en/tgb/8788-%E0%B0%AA%E0%B1%86%E0%B0%A6%E0%B1%8D%E0%B0%A7+%E0%B0%B0%E0%B1%8A%E0%B0% brazzers-n.com http://brazzers-n.com/en/tgb/32-Glamour/ Glamour - BRAZZERS porn Studio. Porn clips brazzers Studio and n ecml.at http://edl.ecml.at/Participate/Promoteyourevent/tabid/1768/language/en-GB/Default.aspx European Day of Languages brazzers-n.com http://brazzers-n.com/en/tgb/22267-%E0%A6%B9%E0%A7%8B%E0%A6%9F%E0%A7%87%E0%A6%B2+%E0%A6%AB%E0%A7%8D%E0%A6 brazzers-n.com http://brazzers-n.com/en/tgb/17023-%E0%A6%AD%E0%A6%BE%E0%A6%97%E0%A7%8D%E0%A6%AF%E0%A6%AC%E0%A6%BE%E0%A6% vporn-com.com http://vporn-com.com/en/ms/3397020-striptease.html Striptease|Menu|Main (current)|Random video|All categor ecml.at http://edl.ecml.at/Home/Movingintothepolyglotage/tabid/2970/language/en-GB/Default.aspx European Day of Language brazzers-n.com http://brazzers-n.com/en/threesome Threesome brazzers|Menu|Main (current)|Random video|Chat|All categorie brazzers-n.com http://brazzers-n.com/en/tgb/12851-%E0%B0%AD%E0%B0%BE%E0%B0%B0%E0%B1%8D%E0%B0%AF+%E0%B0%87%E0%B0%B0%E0%B1 brazzers-n.com http://brazzers-n.com/en/columbia/ Columbia brazzers|Menu|Main (current)|Random video|Chat|All categories xyutv-a.com http://xyutv-a.com/en/tag/6404-Sexy+Poibl%C3%AD/ Sexy Public - fuck TV PORN VIDEOS ONLINE - WATCH FREE best vporn-com.com http://vporn-com.com/en/tag/3821-%D0%97%D0%B0%D0%BB%D1%83%D1%83+%D0%AD%D0%BC%D1%8D%D0%B3%D1%82%D1%8D%D0%B9 brazzers-n.com http://brazzers-n.com/en/tgb/13598-%2C/ Suck Tits - BRAZZERS porn Studio. Porn clips brazzers Studio and brazzers-n.com http://brazzers-n.com/en/tgb/10582-%E0%A6%B8%E0%A7%87%E0%A6%95%E0%A7%8D%E0%A6%B8%E0%A6%BF%2C+%E0%A6%B8%E0 lenkino.mobi http://lenkino.mobi/en/mv/10405951-spandexporn-michaela.html SpandexPorn Michaela|720 HD video|Adult toys|A online-casino-10.pro http://online-casino-10.pro/ online-casino-10.pro - Free Czech Porn Videos And Amateur Sex Videos|M brazzers-n.com http://brazzers-n.com/en/tgb/21449-%E0%A6%A4%E0%A6%BF%E0%A6%A8%E0%A7%87+%E0%A6%AE%E0%A6%BF%E0%A6%B2%E0%A7 vporn-com.com http://vporn-com.com/en/tag/8471-Fraincis+Cum/ French Cum - porn - Best porn videos and Sex XXX movies, HD brazzers-n.com http://brazzers-n.com/en/tgb/16058-%D9%81%D9%8A+%D8%B3%D9%86+%D8%A7%D9%84%D9%85%D8%B1%D8%A7%D9%87%D9%82%D brazzers-n.com http://brazzers-n.com/en/tgb/13566-%E0%A6%AE%E0%A7%8D%E0%A6%AF%E0%A6%BE%E0%A6%B8%E0%A7%87%E0%A6%9C+%E0%A6 lenkino.mobi http://lenkino.mobi/en/otslaivanie/ Otslaivanie in lenkino|Adult toys|Apostate|Bisexual|Blonde|Bukkake|Cart brazzers-n.com http://brazzers-n.com/en/tgb/14756-%D0%97%D0%B0%D0%BB%D1%83%D1%83+%D0%A1%D0%BE%D0%BD%D0%B8%D1%80%D1%85%D0 pornyfree.com https://pornyfree.com/ Free Porn HD 4k,1080p,720p , Latest Porno Are Here|Skip to content|Follow me on:|We cucek.net http://cucek.net/en/rimjob/ Rimjob|Sliding menu|Cucek.NET|Main (current)|Random video|All categories|English|ï¿½ brazzers-n.com http://brazzers-n.com/en/tgb/10899-%E0%A6%AC%E0%A6%A1%E0%A6%BC%E0%A7%8B+%E0%A6%AE%E0%A6%BE%E0%A6%87/ Voye ruporn-tv.com http://ruporn-tv.com/en/tag/17899-%2C%2C+%E0%A6%86%E0%A6%AF%E0%A6%BC%E0%A6%A8%E0%A6%BE%2C/ Teen Mirror - R ruporn-tv.com http://ruporn-tv.com/en/erotic/ Erotic|Menu|Main (current)|Random|Category|English|Ð ÑƒÑÑÐºÐ¸Ð¹|English| hdbox.ws https://hdbox.ws/en/sat-tv-novosti/4737-transpondernye-novosti-za-08-08-2017.html ï»¿ Transponder news for 08.0 24video-xxx.com http://24video-xxx.com/en/tag/11458-R%C3%B8yking+120s/ Smoking 120s - 24video.xxx com porn watch online, brazzers-n.com http://brazzers-n.com/en/tgb/10485-%E0%A6%A6%E0%A7%87%E0%A6%96%E0%A6%BE/ Meet up - BRAZZERS porn Studio. tube8-n.com http://tube8-n.com/en/vibrator Vibrator porn videos|Menu|Main (current)|View all|At random|English|Ð ÑƒÑÑï¿½ hotpornohub.com http://hotpornohub.com/en/tag/ Sliding menu|HotPornoHub|Main (current)|Random video|All categories|Engli biqle-ru.com http://biqle-ru.com/en/arab-porn/ Arab porn porn videos|Menu|Main (current)|Random|Category|English|Ð ÑƒÑï¿½ brazzers-n.com http://brazzers-n.com/en/tgb/19015-%E0%A6%A1%E0%A6%BE%E0%A6%95%E0%A7%8D%E0%A6%A4%E0%A6%BE%E0%A6%B0/ Old D brazzers-n.com http://brazzers-n.com/en/tgb/19771-%E0%A8%B5%E0%A8%BF%E0%A8%86%E0%A8%B9+%E0%A8%A8%E0%A9%82%E0%A9%B0+%E0%A youjizzhd.net https://youjizzhd.net/en/porn-orgasms/ Porn orgasms on youjizz|Menu|Main (current)|Random video|All catego brazzers-n.com http://brazzers-n.com/en/tgb/17716-%E0%A6%AA%E0%A7%8B%E0%A6%81%E0%A6%A6+%E0%A6%97%E0%A7%81%E0%A6%A6+%E0%A ecml.at http://edl.ecml.at/LanguageFun/Selfevaluateyourlanguageskills/tabid/2194/language/en-GB/Default.aspx European Da brazzers-n.com http://brazzers-n.com/en/tgb/20192-%E0%A4%B8%E0%A4%B9+%E0%A4%95%E0%A4%B5%E0%A4%B0+Slut/ Cum Covered Slut brazzers-n.com http://brazzers-n.com/en/tgb/17-%D0%A2%D0%BE%D0%BC+%D0%A5%D1%83%D0%BB%D0%B0%D0%BD/ Big Ass - BRAZZERS por brazzers-n.com http://brazzers-n.com/en/tgb/1256-%D0%9E%D0%BD%D0%BB%D0%B0%D0%B9%D0%BD/ Online - BRAZZERS porn Studio. Po brazzers-n.com http://brazzers-n.com/en/tgb/21088-%E0%A6%A4%E0%A6%BF%E0%A6%A8%E0%A7%87+%E0%A6%AE%E0%A6%BF%E0%A6%B2%E0%A7 brazzers-n.com http://brazzers-n.com/en/tgb/10213-%E0%A6%86%E0%A6%AE%E0%A6%BE%E0%A6%B0+%E0%A6%B8%E0%A7%87%E0%A6%95%E0%A7 brazzers-n.com http://brazzers-n.com/en/tgb/18868-%D0%AD%D1%80%D0%BE%D1%82%D0%B8%D0%BA%D0%B0%D0%BB%D1%8B%D2%9B+%D0%91%D0 brazzers-n.com http://brazzers-n.com/en/tgb/5025-%E0%B9%80%E0%B8%9E%E0%B8%B4%E0%B8%A3%E0%B9%8C%E0%B8%A5%E0%B8%AD%E0%B8%A brazzers-n.com http://brazzers-n.com/en/tgb/5827-%E0%A6%B8%E0%A6%B0%E0%A6%95%E0%A6%BE%E0%A6%B0%E0%A7%80+%E0%A6%AB%E0%A7% vporn-com.com http://vporn-com.com/en/tag/4951-%D0%A5%D0%B0%D1%80+%D2%AE%D1%81%D1%82%D1%8D%D0%B9+%D0%A8%D1%83%D0%BB%D1%8 brazzers-n.com http://brazzers-n.com/en/tgb/12700-%E0%A6%B8%E0%A6%BE%E0%A6%A6%E0%A6%BE+%E0%A6%A6%E0%A7%88%E0%A6%A4%E0%A7 brazzers-n.com http://brazzers-n.com/en/tgb/12414-%E0%A6%B8%E0%A7%81%E0%A6%A8%E0%A7%8D%E0%A6%A6%E0%A6%B0%E0%A6%BF+%E0%A6 trahtubetv.com http://trahtubetv.com/en/mi/9686996-crazy-squealing-orgasm-dachix.com.html Crazy Squealing Orgasm dachix. brazzers-n.com http://brazzers-n.com/en/piercing/ Piercing brazzers|Menu|Main (current)|Random video|Chat|All categories ruporn-tv.com http://ruporn-tv.com/en/tag/2047-%E0%A4%97%E0%A5%81%E0%A4%B2%E0%A4%BE%E0%A4%AE+%E0%A4%AA%E0%A5%8D%E0%A4%B0 lenkino.mobi http://lenkino.mobi/en/tg/6394-%E0%A4%B8%E0%A5%80%E0%A4%96%E0%A4%A8%E0%A5%87/ Learning - Porn videos in HD 24video-xxx.com http://24video-xxx.com/en/c/full/ The list of all categories|To switch the language|Ð ÑƒÑÑÐºÐ¸Ð¹|Engli brazzers-n.com http://brazzers-n.com/en/tgb/5954-%D0%A2%D0%BE%D0%BC+%D0%98%D0%BB%D0%B6%D0%B8%D0%B3+Latina/ Big Ass Latin dojki-n.com http://dojki-n.com/en/tag/23086-%D0%98%D1%85+%D0%91%D1%80%D0%B8%D1%82%D0%B0%D0%BD%D0%B8%D0%B9%D0%BD+Sluts/ B brazzers-n.com http://brazzers-n.com/en/tgb/18928-%E0%A4%B6%E0%A4%BF%E0%A4%95%E0%A5%8D%E0%A4%B7%E0%A4%95+%E0%A4%89%E0%A4 trahtubetv.com http://trahtubetv.com/en/bikini Bikini|Menu|Tractor|Main (current)|Random video|All categories|English|Ð  trahtubetv.com http://trahtubetv.com/en/tag/758-Sciorta/ Skirt - Fuck tube. Check out hot pussies. Porn videos for free| tube8-n.com http://tube8-n.com/en/naked-porn-star Naked porn star porn videos|Menu|Main (current)|View all|At random|Eng cucek.net http://cucek.net/en/mcuc/11219659-scarlett-johansson%2C-john-g%2C-barea-follando-en-el-semad-sexed.su.html Sca brazzers-n.com http://brazzers-n.com/en/tgb/559-%E0%A6%95%E0%A6%BE%E0%A6%B2%E0%A7%8B+%E0%A6%AC%E0%A6%B9%E0%A7%81+%E0%A6% trahtubetv.com http://trahtubetv.com/en/massage Massage|Menu|Tractor|Main (current)|Random video|All categories|English| pornoload-n.com http://pornoload-n.com/en/tag/2615-%E0%A4%B5%E0%A4%BF%E0%A4%B6%E0%A4%BE%E0%A4%B2+%E0%A4%B8%E0%A5%8D%E0%A brazzers-n.com http://brazzers-n.com/en/tgb/12884-%E0%A6%95%E0%A7%8D%E0%A6%B0%E0%A7%80%E0%A6%A4%E0%A6%A6%E0%A6%BE%E0%A6% dojki-n.com http://dojki-n.com/en/tag/16482-%E0%A4%AE%E0%A5%87%E0%A4%B0%E0%A5%87+%E0%A4%B8%E0%A4%AC%E0%A4%B8%E0%A5%87+%E cucek.net http://cucek.net/en/rimjob Rimjob|Sliding menu|Cucek.NET|Main (current)|Random video|All categories|English|Ð  brazzers-n.com http://brazzers-n.com/en/tgb/20752-%E0%A4%85%E0%A4%9A%E0%A5%8D%E0%A4%9B%E0%A4%BE+%E0%A4%97%E0%A5%8D%E0%A4 trahtubetv.com http://trahtubetv.com/en/tag/12353-Busty+%E0%A4%B8%E0%A4%9A%E0%A4%BF%E0%A4%B5/ Busty Secretary - Fuck tub brazzers-n.com http://brazzers-n.com/en/tgb/5954-Asal+M%C3%B3r+Latina/ Big Ass Latina - BRAZZERS porn Studio. Porn clips pornk.mobi http://pornk.mobi/en/yoga/ Yoga porn pornk|Menu|Main (current)|Topics porn|Random video|Chat|English|Ð ÑƒÑÑ brazzers-n.com http://brazzers-n.com/en/tgb/4593-%E0%A6%B2%E0%A6%82+%E0%A6%AA%E0%A6%A6/ Long Legged - BRAZZERS porn Stud bizneswkatalogu.pl http://bizneswkatalogu.pl/en/ Lustful.TV|English|Afrikaans|Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©|AzÉ™rbaycanca|Ð‘ÐµÐ»Ð°Ñ€Ñƒï¿½ trahtubetv.com http://trahtubetv.com/en/tag/41-%E0%A6%97%E0%A7%81%E0%A6%A6/pi/11/ Pussy - Fuck tube. Check out hot pussi brazzers-n.com http://brazzers-n.com/en/tgb/11039-%E0%A6%A7%E0%A6%B0%E0%A7%8D%E0%A6%B7%E0%A6%A3%2C+%E0%A6%B8%E0%A7%8D%E0 brazzers-n.com http://brazzers-n.com/en/tgb/19357-%E0%A6%85%E0%A6%AA%E0%A7%87%E0%A6%B6%E0%A6%BE%E0%A6%A6%E0%A6%BE%E0%A6% erkiss-tv.com http://erkiss-tv.com/en/canadians/ Canadians porn on phone|Menu|Main (current)|Random|Chat|Category|Englis brazzers-n.com http://brazzers-n.com/en/tgb/8788-%D2%AE%D0%BB%D0%BA%D0%B5%D0%BD+%D0%A1%D0%B8%D1%81%D1%8C%D0%BA%D0%B8+%D0 brazzers-n.com http://brazzers-n.com/en/footwork/pgb/3/ Footwork brazzers - page 3|Menu|Main (current)|Random video|Chat brazzers-n.com http://brazzers-n.com/en/tgb/4872-Public+Fuck/ Public Fuck - BRAZZERS porn Studio. Porn clips brazzers St brazzers-n.com http://brazzers-n.com/en/pgb/3/ BRAZZERS porn Studio. Porn clips brazzers Studio and not only. - page 3|M hdbox.ws https://hdbox.ws/en/wetek-play/414-spisok-kanalov-36e-dlya-resivera-wetek-play-ot-05-11-2015.html Channel list pornk.mobi http://pornk.mobi/en/canadians/ Canadians porn pornk|Menu|Main (current)|Topics porn|Random video|Chat|Englis ruporn-tv.com http://ruporn-tv.com/en/tag/17050-%E0%A4%AC%E0%A4%82%E0%A4%A7%E0%A4%95+%E0%A4%AA%E0%A4%B0%E0%A4%AA%E0%A5%8 brazzers-n.com http://brazzers-n.com/en/tgb/36-%E0%A6%AC%E0%A6%A1%E0%A6%BC%E0%A7%8B+%E0%A6%AE%E0%A6%BE%E0%A6%87/ Big Tit brazzers-n.com http://brazzers-n.com/en/tgb/530-%D0%9D%D2%AF%D2%AF%D1%80+%D0%A5%D1%83%D1%83%D0%B4%D0%B0%D1%81+%D0%A5%D0% brazzers-n.com http://brazzers-n.com/en/tgb/13141-Caliente/ Caliente - BRAZZERS porn Studio. Porn clips brazzers Studio brazzers-n.com http://brazzers-n.com/en/tgb/2896-%E0%A6%B8%E0%A7%8D%E0%A6%A4%E0%A7%8D%E0%A6%B0%E0%A7%80/ Granny Fucks - brazzers-n.com http://brazzers-n.com/en/tgb/2045-Feminization/ Feminization - BRAZZERS porn Studio. Porn clips brazzers cucek.net http://cucek.net/en/mcuc/9325057-cunilingus-fantasti.cc.html Cunilingus fantasti.cc|Sliding menu|Cucek.NET|Mai brazzers-n.com http://brazzers-n.com/en/tgb/7168-%E0%A8%AE%E0%A8%BF%E0%A8%B2%E0%A9%8D%E0%A8%AB%E0%A8%BC+%E0%A8%9A%E0%A8% biqle-ru.com http://biqle-ru.com/en/mk/3350324-vor-der-cam-mastubiert.html Vor der Cam Mastubiert|Menu|Main (current)|Ra brazzers-n.com http://brazzers-n.com/en/tgb/4631-%E0%A6%B6%E0%A7%8D%E0%A6%B0%E0%A7%8B%E0%A6%A3%E0%A7%80%E0%A6%9A%E0%A6%9 x-artvideo.net https://x-artvideo.net/ x-artvideo - X-art Video is a free daily porn tube that offers free porn movies o pornoload-n.com http://pornoload-n.com/en/rimjob Rimjob|Menu|PornoLoad|Main (current)|Random video|All categories|Englis brazzers-n.com http://brazzers-n.com/en/tgb/10241-%E0%A6%AC%E0%A6%A1%E0%A6%BC%E0%A7%8B+%E0%A6%AE%E0%A6%BE%E0%A6%87+%E0%A brazzers-n.com http://brazzers-n.com/en/tgb/12764-%E0%A6%AD%E0%A6%BF%E0%A6%9C%E0%A6%BE%2C+%E0%A6%97%E0%A7%8B%E0%A6%B2%E0 hotpornohub.com http://hotpornohub.com/en/fatties/ Bbw porn videos in excellent quality|Sliding menu|HotPornoHub|Main (c pornk.mobi http://pornk.mobi/en/cheerleaders/ Cheerleaders porn pornk|Menu|Main (current)|Topics porn|Random video|Chat| ruporn-tv.com http://ruporn-tv.com/en/tag/328-%E0%A8%95%E0%A8%AE+++%E0%A8%A4%E0%A9%87+%E0%A8%AA%E0%A8%BF%E0%A8%9B%E0%A9% pornoload-n.com http://pornoload-n.com/en/tag/457-Oifig/page/10/ Office - Pornload best website with adult videos and po brazzers-n.com http://brazzers-n.com/en/tgb/18261-%E0%A6%85%E0%A6%A8%E0%A7%8D%E0%A6%A7%E0%A6%95%E0%A6%BE%E0%A6%B0+%E0%A6 brazzers-n.com http://brazzers-n.com/en/tgb/18869-%E0%A6%89%E0%A6%A4%E0%A7%8D%E0%A6%AF%E0%A6%95%E0%A7%8D%E0%A6%A4+%E0%A6 brazzers-n.com http://brazzers-n.com/en/tgb/3375-%E0%A6%AE%E0%A6%BE%E0%A6%96%E0%A6%A8%E0%A7%87%E0%A6%B0+%E0%A6%AE%E0%A6% brazzers-n.com http://brazzers-n.com/en/tgb/15712-%E0%A4%95%E0%A4%BF%E0%A4%B6%E0%A5%8B%E0%A4%B0+%E0%A4%AC%E0%A4%A1%E0%A4 brazzers-n.com http://brazzers-n.com/en/tgb/4427-%E0%A6%AF%E0%A7%8C%E0%A6%A8/ Sexually - BRAZZERS porn Studio. Porn clip brazzers-n.com http://brazzers-n.com/en/tgb/12398-%E0%A6%B9%E0%A6%BE%E0%A6%81%E0%A6%9F%E0%A7%81+%E0%A6%89%E0%A6%9A%E0%A7 brazzers-n.com http://brazzers-n.com/en/tgb/16614-%E0%A6%B9%E0%A6%BE%E0%A6%B0%E0%A7%8D%E0%A6%A1%2C/ Hard Strapon - BRAZZ brazzers-n.com http://brazzers-n.com/en/bdsm BDSM brazzers|Menu|Main (current)|Random video|Chat|All categories|English| brazzers-n.com http://brazzers-n.com/en/tgb/12601-%E0%A6%AE%E0%A7%81%E0%A6%96%E0%A6%97%E0%A6%A4+%E0%A6%AA%E0%A7%82%E0%A6 brazzers-n.com http://brazzers-n.com/en/tgb/14420-%D0%A1%D0%BE%D0%BB%D0%BE+%D0%94%D1%83%D1%80/ Solo Orgasm - BRAZZERS po brazzers-n.com http://brazzers-n.com/en/tgb/5183-%E0%A6%AA%E0%A7%8D%E0%A6%B0%E0%A6%9A%E0%A6%A3%E0%A7%8D%E0%A6%A1+%E0%A6% brazzers-n.com http://brazzers-n.com/en/tgb/21424-%E0%A6%86%E0%A6%81%E0%A6%9F+%E0%A6%AC%E0%A6%A1%E0%A6%BC%E0%A7%8B+%E0%A lenkino.mobi http://lenkino.mobi/en/anal Anal on lenkino|Anonymous chat !|18 years|Amateurs|Arab porn|Bathroom|Beach|Cum biqle-ru.com http://biqle-ru.com/en/t/1680-%E0%A8%86%E0%A8%AE/ Roughly - Porno HD online in high quality on biqle, witho brazzers-n.com http://brazzers-n.com/en/tgb/20975-%D0%92%D1%82%D0%B5%D1%87%D0%B0/ Escape - BRAZZERS porn Studio. Porn cl brazzers-n.com http://brazzers-n.com/en/tgb/23507-%E0%A6%B2%E0%A7%87%E0%A6%B8%E0%A6%AC%E0%A6%BF%E0%A6%AF%E0%A6%BC%E0%A6% trahtubetv.com http://trahtubetv.com/en/anal/pi/6/ Anal - page 6|Menu|Tractor|Main (current)|Random video|All categories brazzers-n.com http://brazzers-n.com/en/tgb/13264-%E0%A6%B8%E0%A7%8D%E0%A6%95%E0%A7%81%E0%A6%B2%2C/ School Fuck - BRAZZE vporn-com.com http://vporn-com.com/en/latex/ Latex only on anysex|Menu|Main (current)|Random video|All categories|Englis brazzers-n.com http://brazzers-n.com/en/tgb/19829-%E0%A4%97%E0%A5%81%E0%A4%82%E0%A4%A1%E0%A4%BE%2C/ Punk Lesbian - BRAZZ xvideos-a.com http://xvideos-a.com/en/moa/3597716-verronica-tempting-handjob.html Verronica Tempting Handjob|Navigation| brazzers-n.com http://brazzers-n.com/en/tgb/10899-%E0%B0%A4%E0%B0%B0%E0%B1%81%E0%B0%B2%E0%B1%81+%E0%B0%B8%E0%B1%86%E0%B0 ruporn-tv.com http://ruporn-tv.com/en/tag/3298-%E0%A4%B8%E0%A4%B9%E0%A4%AA%E0%A4%BE%E0%A4%A0%E0%A5%80/ Classmate - Russi brazzers-n.com http://brazzers-n.com/en/tgb/12967-%E0%A6%AA%E0%A6%B0%E0%A6%BF%E0%A6%A3%E0%A6%A4+%E0%A6%AE%E0%A7%87%E0%A6 ecml.at http://edl.ecml.at/LanguageFun/Talktome/tabid/1878/language/en-GB/Default.aspx European Day of Languages &gt; Langu brazzers-n.com http://brazzers-n.com/en/tgb/8788-%E0%A6%AC%E0%A6%A1%E0%A6%BC%E0%A7%8B+%E0%A6%AE%E0%A6%BE%E0%A6%87+%E0%A6 brazzers-n.com http://brazzers-n.com/en/tgb/10099-%E0%A6%B8%E0%A7%81%E0%A6%A8%E0%A7%8D%E0%A6%A6%E0%A6%B0%E0%A7%80+%E0%A6 brazzers-n.com http://brazzers-n.com/en/tgb/19789-%E0%A6%95%E0%A6%BE%E0%A6%B2%E0%A7%8B+%E0%A6%95%E0%A6%AE%E0%A7%8D%E0%A6 hdbox.ws https://hdbox.ws/en/sat-tv-novosti/5311-transpondernye-novosti-sputnikovogo-televideniya-11-maya-2018.html ï»¿ hotpornohub.com http://hotpornohub.com/en/mov/11135847-closeup-creampie.html closeup Creampie|Sliding menu|HotPornoHub|M ecml.at http://edl.ecml.at/Participate/Materials/tabid/1769/language/en-GB/Default.aspx European Day of Languages &gt; Part hotpornohub.com http://hotpornohub.com/en/fatties Bbw porn videos in excellent quality|Sliding menu|HotPornoHub|Main (cu brazzers-n.com http://brazzers-n.com/en/tgb/15845-%E0%A6%B8%E0%A6%95+%E0%A6%AA%E0%A7%82%E0%A6%9C%E0%A6%BE/ Sock Worship pornoload-n.com http://pornoload-n.com/en/tag/11115-%D0%92+%D0%A8%D0%BA%D0%BE%D0%BB%D0%B5/ At School - Pornload best web pikeals.org https://pikeals.org/en/home English Porn Video - Free Porn Videos Xvideos, Pornhub, xnxx - Snapchat Cosplay| brazzers-n.com http://brazzers-n.com/en/tgb/14315-%E0%A6%B8%E0%A7%8D%E0%A6%A4%E0%A7%8D%E0%A6%B0%E0%A7%80+%E0%A6%9D%E0%A6 brazzers-n.com http://brazzers-n.com/en/tgb/112-%E0%A8%97%E0%A9%B0%E0%A8%A6%E0%A9%87+%E0%A8%A6%E0%A9%80+%E0%A8%9A%E0%A9% erkiss-tv.com http://erkiss-tv.com/en/tag_phone/1586-%E0%A6%AE%E0%A6%BE%E0%A6%B0%E0%A7%8D%E0%A6%9C%E0%A6%A8/ Rubbing - P ecml.at http://edl.ecml.at/Participate/Howtoparticipate/tabid/1766/language/en-GB/Default.aspx European Day of Languages ruporn-tv.com http://ruporn-tv.com/en/tag/381-%E0%A4%AC%E0%A4%BF%E0%A4%B2%E0%A5%8D%E0%A4%B2%E0%A5%80+%E0%A4%95%E0%A4%AE% brazzers-n.com http://brazzers-n.com/en/tgb/18853-%E0%A6%AA%E0%A6%A4%E0%A6%BF%E0%A6%A4+%E0%A6%9C%E0%A6%AE%E0%A6%BF/ Wast brazzers-n.com http://brazzers-n.com/en/tgb/21233-%E0%A6%85%E0%A6%AA%E0%A7%87%E0%A6%B6%E0%A6%BE%E0%A6%A6%E0%A6%BE%E0%A6% ruporn-tv.com http://ruporn-tv.com/en/tag/1494-%E0%A4%96%E0%A5%82%E0%A4%AC%E0%A4%B8%E0%A5%82%E0%A4%B0%E0%A4%A4+%E0%A4%B5 hdbox.ws https://hdbox.ws/en/sat-tv-novosti/3008-transpondernye-novosti-za-07-10-2016.html Â» Transponder news for 07.10 brazzers-n.com http://brazzers-n.com/en/tgb/10899-%E0%A4%A6%E0%A5%83%E0%A4%B6%E0%A5%8D%E0%A4%AF%E0%A4%B0%E0%A4%A4%E0%A4% brazzers-n.com http://brazzers-n.com/en/tgb/19829-%E0%A6%AC%E0%A6%BE%E0%A6%9C%E0%A7%87+%E0%A6%95%E0%A6%A5%E0%A6%BE%2C/ P brazzers-n.com http://brazzers-n.com/en/tgb/15812-%E0%A6%AC%E0%A7%8D%E0%A6%B0%E0%A6%BF%E0%A6%9F%E0%A6%BF%E0%A6%B6+%E0%A6 fuckedtonight.com http://www.fuckedtonight.com/en/ Free porn @ Fucked Tonight|FuckedTonight|English|Î•Î»Î»Î·Î½Î¹ÎºÎ¬|Gal brazzers-n.com http://brazzers-n.com/en/tgb/4173-%E0%A6%B8%E0%A7%8D%E0%A6%AC%E0%A6%B0%E0%A7%8D%E0%A6%A3%E0%A6%95%E0%A7%8 brazzers-n.com http://brazzers-n.com/en/tgb/21533-%E0%A4%B9%E0%A5%82%E0%A4%95%E0%A4%B0%2C/ Hooker Creampie - BRAZZERS po vporn-com.com http://vporn-com.com/en/tag/458-%D0%94%D0%BE%D1%82%D1%83%D1%83%D1%80+%D1%85%D1%83%D0%B2%D1%86%D0%B0%D1%81/ sozrelxxx.com http://sozrelxxx.com/en/tag/23492-%D3%98%D1%83%D0%B5%D1%81%D2%9B%D0%BE%D0%B9%D0%BB%D1%8B%D2%9B+%D0%96%D0%B brazzers-n.com http://brazzers-n.com/en/tgb/12632-%E0%A6%AC%E0%A6%BE%E0%A6%B9+%E0%A6%AC%E0%A7%83%E0%A6%A6%E0%A7%8D%E0%A6 pornoload-n.com http://pornoload-n.com/en/tag/8784-%E0%A6%86%E0%A6%AC%E0%A6%B9%E0%A6%BE%E0%A6%93%E0%A6%AF%E0%A6%BC%E0%A6 eporner-n.com http://eporner-n.com/en/negros Negros _ EPORNER|Menu|Main (current)|All categories|Random|English|Ð ÑƒÑÑ ecml.at http://edl.ecml.at/Participate/Whocanparticipate/tabid/1765/language/en-GB/Default.aspx European Day of Language biqle-ru.com http://biqle-ru.com/en/t/35-%D0%97%D0%B0%D0%BB%D1%83%D1%83/ Young - Porno HD online in high quality on biql ecml.at http://edl.ecml.at/Participate/tabid/1764/language/en-GB/Default.aspx Participate|Home (Basque)|What is it?|Why erkiss-tv.com http://erkiss-tv.com/en/gangbang-gangbang Gangbang gangbang porn on phone|Menu|Main (current)|Random|Chat| pornoload-n.com http://pornoload-n.com/en/tag/255-Big+Dick Big Dick - Pornload best website with adult videos and porn c brazzers-n.com http://brazzers-n.com/en/tgb/16181-%E0%A6%A8%E0%A6%97%E0%A7%8D%E0%A6%A8+%E0%A6%AA%E0%A6%B0%E0%A7%8D%E0%A6 brazzers-n.com http://brazzers-n.com/en/feedback/ Feedback|Menu|Main (current)|Random video|Chat|All categories|English| xyutv-a.com http://xyutv-a.com/en/tag/1773-I+an+linn+Sn%C3%A1mha/ In the Pool - fuck TV PORN VIDEOS ONLINE - WATCH FREE lenkino.mobi http://lenkino.mobi/en/pg/4/ Porn videos in HD quality. This Lenkino porn online! Watch porn for free! - pa nakedgirls.org https://nakedgirls.org/ Naked Girls - Hot Nude Women &amp; Naked Teen Girls Videos|Skip to content|Home|Categ brazzers-n.com http://brazzers-n.com/en/tgb/1600-%E0%A6%8F%E0%A6%B6%E0%A6%BF%E0%A6%AF%E0%A6%BC%E0%A6%BE%E0%A6%A8/ Asian tube8-n.com http://tube8-n.com/en/otslaivanie Otslaivanie porn videos|Menu|Main (current)|View all|At random|English|Ð ï¿½ brazzers-n.com http://brazzers-n.com/en/tgb/7858-%E0%A6%AA%E0%A7%81%E0%A6%B0%E0%A7%81%2C+%E0%A6%86%E0%A6%AC%E0%A6%B2%E0% brazzers-n.com http://brazzers-n.com/en/tgb/16899-%E0%A6%AC%E0%A6%BE%E0%A6%B8%E0%A7%8D%E0%A6%A4%E0%A6%AC+%E0%A6%AA%E0%A7 ecml.at http://edl.ecml.at/Events/PictureGallery2012/tabid/3090/language/en-GB/Default.aspx Picture Gallery 2012|Home (B pornozal-net.com http://pornozal-net.com/en/tag/ Menu|Pornosu Porn|Main (current)|Random|Our categories|English|Ð ÑƒÑÑ online-casino-10.pro http://online-casino-10.pro/en/reference/online_services/ online-casino-10.pro - Free Czech Porn Vi dojki-n.com http://dojki-n.com/en/latina Latina videos online in hd quality|Menu|Main (current)|Random video|All categor ruporn-tv.com http://ruporn-tv.com/en/moms Moms|Menu|Main (current)|Random|Category|English|Ð ÑƒÑÑÐºÐ¸Ð¹|English|AzÉ™r brazzers-n.com http://brazzers-n.com/en/footwork/ Footwork brazzers|Menu|Main (current)|Random video|Chat|All categories ruporn-tv.com http://ruporn-tv.com/en/m/10201287-nackt-im-wald.html Nackt im Wald|Menu|Main (current)|Random|Category|En ruporn-tv.com http://ruporn-tv.com/en/tag/17143-%E0%A4%A1%E0%A5%88%E0%A4%B0%E0%A4%BF%E0%A4%B2/ Darryl - Russian porn onl ruporn-tv.com http://ruporn-tv.com/en/tag/12421-%2C+%E0%A4%95%E0%A4%BE%E0%A4%AE/ MILF Work - Russian porn online watch f fucked-movies.com http://fucked-movies.com/en/ Fucked Movies|English|Afrikaans|Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©|AzÉ™rbaycanca|Ð‘ÐµÐ»Ð°Ñ€Ñƒ xnxx-hd.pro http://xnxx-hd.pro/en/tag/16818-%E0%A6%AC%E0%A6%A1%E0%A6%BC%E0%A7%8B+%E0%A6%AE%E0%A6%BE%E0%A6%87+%E0%A6%A8%E brazzers-n.com http://brazzers-n.com/en/tgb/18992-%D0%9E%D1%85%D0%B8%D0%BD+%D0%A5%D0%B0%D1%88%D0%B3%D0%B8%D1%80%D1%87/ G biqle-ru.com http://biqle-ru.com/en/closeup Closeup porn videos|Menu|Main (current)|Random|Category|English|Ð ÑƒÑÑÐºÐ¸ brazzers-n.com http://brazzers-n.com/en/tgb/19541-%E0%A6%AC%E0%A6%BE%E0%A6%81%E0%A6%A1%E0%A6%BC%E0%A6%BE%E0%A6%B0+%E0%A6 pornoload-n.com http://pornoload-n.com/en/tag/19078-Melena/ Melena - Pornload best website with adult videos and porn cl brazzers-n.com http://brazzers-n.com/en/tgb/5183-%E0%B0%A8%E0%B0%B2%E0%B1%81%E0%B0%97%E0%B1%81%E0%B0%B0%E0%B1%81+%E0%B0% brazzers-n.com http://brazzers-n.com/en/tgb/7168-%E0%A6%B8%E0%A7%81%E0%A6%A8%E0%A7%8D%E0%A6%A6%E0%A6%B0%E0%A6%BF+%E0%A6% brazzers-n.com http://brazzers-n.com/en/tgb/11752-%E0%A6%9F%E0%A7%8D%E0%A6%AF%E0%A6%BE%E0%A6%95%E0%A7%8D%E0%A6%B8%E0%A6% brazzers-n.com http://brazzers-n.com/en/tgb/6306-%E0%A6%96%E0%A7%81%E0%A6%AC%2C+%E0%A6%B8%E0%A7%87%E0%A6%95%E0%A7%8D%E0% brazzers-n.com http://brazzers-n.com/en/tgb/590-%E0%A6%86%E0%A6%99%E0%A7%81%E0%A6%B2+%E0%A6%97%E0%A7%81%E0%A6%A6/ Finger pornk.mobi http://pornk.mobi/en/strapon/ Strapon porn pornk|Menu|Main (current)|Topics porn|Random video|Chat|English|Ð  brazzers-n.com http://brazzers-n.com/en/tgb/11643-%E0%A6%B8%E0%A7%8D%E0%A6%A4%E0%A7%8D%E0%A6%B0%E0%A7%80%2C+Cheats+%E0%A vporn-com.com http://vporn-com.com/en/tag/7184-%E0%A6%A1%E0%A6%AC%E0%A6%B2%2C+%E0%A6%B8%E0%A7%8D%E0%A6%9F%E0%A6%BE%E0%A6 lenkino.mobi http://lenkino.mobi/en/pg/6/ Porn videos in HD quality. This Lenkino porn online! Watch porn for free! - pa ecml.at http://edl.ecml.at/Contact/tabid/1519/language/en-GB/Default.aspx European Day of Languages &gt; Contact|Home (Basq brazzers-n.com http://brazzers-n.com/en/tgb/8238-%E0%A6%B0%E0%A6%BE%E0%A6%A4/ Nights - BRAZZERS porn Studio. Porn clips brazzers-n.com http://brazzers-n.com/en/tgb/6150-Hard+Ass+Fuck/ Hard Ass Fuck - BRAZZERS porn Studio. Porn clips brazzer pornoload-n.com http://pornoload-n.com/en/tag/7401-%E0%A8%B5%E0%A9%87%E0%A8%B8%E0%A8%BC%E0%A8%B5%E0%A8%BE+%E0%A8%A6%E0%A brazzers-n.com http://brazzers-n.com/en/tgb/9967-%E0%A6%85%E0%A6%AA%E0%A7%87%E0%A6%B6%E0%A6%BE%E0%A6%A6%E0%A6%BE%E0%A6%B brazzers-n.com http://brazzers-n.com/en/tgb/1545-%E0%A6%AC%E0%A6%BF%E0%A6%A6%E0%A6%BE%E0%A6%B0%E0%A6%A3/ Cleavage - BRAZ lenkino.mobi http://lenkino.mobi/en/tg/19868-%E0%A4%AC%E0%A4%A6%E0%A4%B8%E0%A5%82%E0%A4%B0%E0%A4%A4+%E0%A4%B5%E0%A5%89%E brazzers-n.com http://brazzers-n.com/en/tgb/9369-%E0%A6%AC%E0%A6%BE%E0%A6%81%E0%A6%A1%E0%A6%BC%E0%A6%BE%E0%A6%B0+%E0%A6% brazzers-n.com http://brazzers-n.com/en/tgb/5399-%E0%A6%97%E0%A6%B0%E0%A6%AE%2C+%E0%A6%AA%E0%A6%BE%E0%A6%AF%E0%A6%BC%E0% brazzers-n.com http://brazzers-n.com/en/tgb/13919-%E0%A6%AC%E0%A7%8D%E0%A6%B2%E0%A6%9C%E0%A6%AC+%E0%A6%AA%E0%A6%BE%E0%A6 brazzers-n.com http://brazzers-n.com/en/tgb/18500-%E0%A6%AF%E0%A7%8C%E0%A6%A8%E0%A6%A4%E0%A6%BE+%E0%A6%86%E0%A6%AE%E0%A6 brazzers-n.com http://brazzers-n.com/en/tgb/10664-%E0%A6%97%E0%A7%8B%E0%A6%B2%E0%A6%BE%E0%A6%AA%E0%A7%80+%E0%A6%AA%E0%A7 brazzers-n.com http://brazzers-n.com/en/tgb/4628-%E0%A6%9D%E0%A6%B0%E0%A6%A8%E0%A6%BE+%E0%A6%AE%E0%A6%9C%E0%A6%BE/ Showe 24video-xxx.com http://24video-xxx.com/en/tag/8784-Wetter+M%C3%A4dchen/ Weather Girl - 24video.xxx com porn watch online brazzers-n.com http://brazzers-n.com/en/tgb/18853-%E0%A8%B5%E0%A8%BF%E0%A8%B0%E0%A8%BE%E0%A8%A8/ Wasteland - BRAZZERS po brazzers-n.com http://brazzers-n.com/en/tgb/9408-%E0%A6%95%E0%A6%A6%E0%A6%B0%E0%A7%8D%E0%A6%AF+%E0%A6%AE%E0%A7%81%E0%A6% lenkino.mobi http://lenkino.mobi/en/rimjob/ Rimjob on lenkino|Anonymous chat !|18 years|720 HD video|BDSM|Big Tits|Casti hdbox.ws https://hdbox.ws/en/sat-tv-novosti/3714-transpondernye-novosti-za-23-11-2016.html Â» Transponder news for 23.11 lenkino.mobi http://lenkino.mobi/en/720-hd-video/ 720 HD video on lenkino|Arab porn|BDSM|Bikini|Bondage|Celebrity|Chines ruporn-tv.com http://ruporn-tv.com/en/moms/ Moms|Menu|Main (current)|Random|Category|English|Ð ÑƒÑÑÐºÐ¸Ð¹|English|AzÉ™ brazzers-n.com http://brazzers-n.com/en/tgb/21948-%D2%AE%D0%BB%D0%BA%D0%B5%D0%BD+%D0%A1%D0%B8%D1%81%D1%8C%D0%BA%D0%B8+%D brazzers-n.com http://brazzers-n.com/en/mb/5552913-milf,-molto-troia.html Milf, molto Troia|Menu|Main (current)|Random v brazzers-n.com http://brazzers-n.com/en/tgb/3663-%E0%A6%AC%E0%A6%A1%E0%A6%BC+%E0%A6%B8%E0%A7%81%E0%A6%A8%E0%A7%8D%E0%A6% brazzers-n.com http://brazzers-n.com/en/ BRAZZERS porn Studio. Porn clips brazzers Studio and not only.|Menu|Main (curre ruporn-tv.com http://ruporn-tv.com/en/tag/3862-Par+Elske/ Couple Make Love - Russian porn online watch free video on Rup brazzers-n.com http://brazzers-n.com/en/tgb/20235-%D0%A2%D0%BE%D0%BC+%D0%98%D0%BB%D0%B6%D0%B8%D0%B3+Slut/ Big Ass Slut - brazzers-n.com http://brazzers-n.com/en/tgb/583-%E0%A6%87%E0%A6%A4%E0%A6%B0/ Hooker - BRAZZERS porn Studio. Porn clips b brazzers-n.com http://brazzers-n.com/en/tgb/44-%D0%93%D1%83%D1%80%D0%B2%D0%B0%D0%BB%D1%81%D0%B0%D0%BD+%D0%B3%D1%80%D1%83 trahtubetv.com http://trahtubetv.com/en/tag/3351-Te+Altra/ Hot Nurse - Fuck tube. Check out hot pussies. Porn videos for brazzers-n.com http://brazzers-n.com/en/tgb/353-%E0%A6%97%E0%A6%B0%E0%A6%AE+%E0%A6%B8%E0%A7%81%E0%A6%A8%E0%A7%8D%E0%A6%A erkiss-tv.com http://erkiss-tv.com/en/tag_phone/1977-%E0%A6%AC%E0%A6%A1%E0%A6%BC+%E0%A6%AE%E0%A7%8B%E0%A6%B0%E0%A6%97+%E brazzers-n.com http://brazzers-n.com/en/tgb/7870-%E0%A6%B8%E0%A7%81%E0%A6%A8%E0%A7%8D%E0%A6%A6%E0%A6%B0%E0%A6%BF+%E0%A6% vporn-com.com http://vporn-com.com/en/tag/16192-%E0%A6%95%E0%A6%BE%E0%A6%B2%E0%A7%8B+%E0%A6%AA%E0%A7%8D%E0%A6%AF%E0%A6%B ecml.at http://edl.ecml.at/Home/Whatisit/tabid/1760/language/en-GB/Default.aspx What is it?|Home (Basque)|What is it?|Wh 24video-xxx.com http://24video-xxx.com/en/tag/562-%D0%A5%D0%B0%D1%80%2C/ Black and - 24video.xxx com porn watch online, brazzers-n.com http://brazzers-n.com/en/tgb/11849-%E0%A6%A8%E0%A6%BF%E0%A6%9F%E0%A7%8B%E0%A6%B2+%E0%A6%AC%E0%A6%A1%E0%A6 brazzers-n.com http://brazzers-n.com/en/venezuelan/ Venezuelan brazzers|Menu|Main (current)|Random video|Chat|All catego pornoload-n.com http://pornoload-n.com/en/tag/36-%E0%A6%AC%E0%A6%A1%E0%A6%BC%E0%A7%8B+%E0%A6%AE%E0%A6%BE%E0%A6%87/page/4 vuku-cc.com http://vuku-cc.com/en/tag/ Menu|Main (current)|Random video|All categories|English|Ð ÑƒÑÑÐºÐ¸Ð¹|English|Az brazzers-n.com http://brazzers-n.com/en/tgb/720-%E0%A6%9F%E0%A6%BE%E0%A6%87%E0%A6%9F+%E0%A6%AD%E0%A6%97+%E0%A6%B0%E0%A6% brazzers-n.com http://brazzers-n.com/en/tgb/11930-%E0%A6%AE%E0%A7%8D%E0%A6%AF%E0%A6%BE%E0%A6%A1%E0%A6%BF%E0%A6%B8%E0%A6% hdbox.ws https://hdbox.ws/en/soft/2288-skachat-plagin-emulyator-oscam-11272-arm-wetek-pod-libreelec-i-openelec.html Â» D brazzers-n.com http://brazzers-n.com/en/tgb/8193-%E0%A6%AC%E0%A7%83%E0%A6%A6%E0%A7%8D%E0%A6%A7%E0%A6%BE%2C+%E0%A6%AA%E0% brazzers-n.com http://brazzers-n.com/en/tgb/18928-%E0%A6%B6%E0%A6%BF%E0%A6%95%E0%A7%8D%E0%A6%B7%E0%A6%95+%E0%A6%A4%E0%A6 ruporn-tv.com http://ruporn-tv.com/en/tag/12421-MILF+Arbeid/ MILF Work - Russian porn online watch free video on Ruporn. brazzers-n.com http://brazzers-n.com/en/tgb/13249-%E0%A6%95%E0%A6%BF%E0%A6%AD%E0%A6%BE%E0%A6%AC%E0%A7%87+%E0%A6%AC%E0%A7 hdbox.ws https://hdbox.ws/en/sat-tv-novosti/5089-transpondernye-novosti-sputnikovogo-televideniya-17-fevralya-2018.html xvideos-a.com http://xvideos-a.com/en/vibrator/ View Vibrator|Navigation|On the main (current)|Random video|Sections|Eng brazzers-n.com http://brazzers-n.com/en/tgb/18868-%E0%A6%AA%E0%A7%8D%E0%A6%B0%E0%A7%87%E0%A6%AE%E0%A6%AE%E0%A7%82%E0%A6% brazzers-n.com http://brazzers-n.com/en/tgb/20478-%E0%A8%95%E0%A8%BE%E0%A8%B2%E0%A9%87+%E0%A8%85%E0%A8%A7%E0%A8%BF%E0%A8 brazzers-n.com http://brazzers-n.com/en/tgb/424-Tits+N%C3%A1d%C3%BArtha/ Natural Tits - BRAZZERS porn Studio. Porn clips brazzers-n.com http://brazzers-n.com/en/tgb/10968-%E0%A6%B8%E0%A7%87%E0%A6%95%E0%A7%8D%E0%A6%B8%2C+%E0%A6%95%E0%A7%8D%E0 brazzers-n.com http://brazzers-n.com/en/tgb/15712-%E0%A6%AA%E0%A7%8B%E0%A6%81%E0%A6%A6%2C+Big+Dick%2C/ Teen with Big Dic brazzers-n.com http://brazzers-n.com/en/bdsm/ BDSM brazzers|Menu|Main (current)|Random video|Chat|All categories|English brazzers-n.com http://brazzers-n.com/en/tgb/4871-%E0%A6%AA%E0%A7%8D%E0%A6%B0%E0%A7%87%E0%A6%AE+%E0%A6%9F%E0%A6%BE%E0%A6% eporner-n.com http://eporner-n.com/en/fisting Fisting _ EPORNER|Menu|Main (current)|All categories|Random|English|Ð ÑƒÑ pornoload-n.com http://pornoload-n.com/en/movie/9725122-hairy-monica-2.html Hairy Monica 2|Menu|PornoLoad|Main (current) brazzers-n.com http://brazzers-n.com/en/tgb/19745-%E0%A6%97%E0%A6%B0%E0%A6%AE%2C+%E0%A6%87%E0%A6%A4%E0%A6%BE%E0%A6%B2%E0 brazzers-n.com http://brazzers-n.com/en/tgb/21973-%E0%A8%95%E0%A8%88+Squirting/ Multiple Squirting - BRAZZERS porn Studi lenkino.mobi http://lenkino.mobi/en/tg/2050-%E0%A4%97%E0%A5%81%E0%A4%A6%E0%A4%BE+%E0%A4%AA%E0%A5%8D%E0%A4%AF%E0%A4%BE%E0 brazzers-n.com http://brazzers-n.com/en/tgb/16056-%E0%A6%B9%E0%A6%BF%E0%A6%A8%E0%A7%8D%E0%A6%A6%E0%A6%BF+%E0%A6%97%E0%A6 pornk.mobi http://pornk.mobi/en/negros Negros porn pornk|Menu|Main (current)|Topics porn|Random video|Chat|English|Ð Ñƒï¿½ yaxochu.ru http://yaxochu.ru/en/tag/ Sliding menu|I want...|Main (current)|Category|Random video|English|Ð ÑƒÑÑÐºÐ¸Ð¹| pornoload-n.com http://pornoload-n.com/en/massage/ Massage|Menu|PornoLoad|Main (current)|Random video|All categories|Eng brazzers-n.com http://brazzers-n.com/en/tgb/21924-%E0%A6%9C%E0%A6%BE%E0%A6%AA%E0%A6%BE%E0%A6%A8%E0%A6%BF+%E0%A6%B8%E0%A7 brazzers-n.com http://brazzers-n.com/en/mb/11116607-kigurumi.html kigurumi|Menu|Main (current)|Random video|Chat|All cat brazzers-n.com http://brazzers-n.com/en/otslaivanie/ Otslaivanie brazzers|Menu|Main (current)|Random video|Chat|All cate ruporn-tv.com http://ruporn-tv.com/en/tag/1505-Rubia+Folla/ Blonde Fucks - Russian porn online watch free video on Rupor brazzers-n.com http://brazzers-n.com/en/tgb/15787-%D0%A1%D0%BE%D0%BD%D0%B8%D1%80%D1%85%D0%BE%D0%B3%D1%87%D0%B4%D1%8B%D0% brazzers-n.com http://brazzers-n.com/en/tgb/41-%E0%A6%97%E0%A7%81%E0%A6%A6/ Pussy - BRAZZERS porn Studio. Porn clips bra pornk.mobi http://pornk.mobi/en/bikini/ Bikini porn pornk|Menu|Main (current)|Topics porn|Random video|Chat|English|Ð Ñƒ brazzers-n.com http://brazzers-n.com/en/cb/ The list of all categories|Menu|Main (current)|Random video|Chat|All categor brazzers-n.com http://brazzers-n.com/en/tgb/18721-%E0%A6%B9%E0%A6%BE%E0%A6%81%E0%A6%9F%E0%A7%81+%E0%A6%89%E0%A6%9A%E0%A7 xnxx-hd.pro http://xnxx-hd.pro/en/cts/ The list of all categories|100% free porn videos sex content|Search|Main (current brazzers-n.com http://brazzers-n.com/en/tgb/1972-%E0%A6%AC%E0%A6%BF%E0%A6%B0%E0%A6%95%E0%A7%8D%E0%A6%A4+%E0%A6%95%E0%A6% lenkino.mobi http://lenkino.mobi/en/rimjob Rimjob on lenkino|Anonymous chat !|Amateurs|Big Tits|Bisexual|Cartoon adult|C 24video-xxx.com http://24video-xxx.com/en/m/3377548-moms.html Moms|To switch the language|Ð ÑƒÑÑÐºÐ¸Ð¹|English|AzÉ™rba brazzers-n.com http://brazzers-n.com/en/fisting/ Fisting brazzers|Menu|Main (current)|Random video|Chat|All categories|E dojki-n.com http://dojki-n.com/en/threesome Threesome sex videos online in hd quality|Menu|Main (current)|Random video|A brazzers-n.com http://brazzers-n.com/en/tgb/8579-%E0%A6%86%E0%A6%B6%E0%A7%8D%E0%A6%9A%E0%A6%B0%E0%A7%8D%E0%A6%AF%E0%A6%9 brazzers-n.com http://brazzers-n.com/en/tgb/4203-%E0%A6%AD%E0%A6%BE%E0%A6%97%E0%A7%8D%E0%A6%AF%E0%A6%AC%E0%A6%BE%E0%A6%A ruporn-tv.com http://ruporn-tv.com/en/tag/8058-%E0%A8%B5%E0%A8%BF%E0%A8%86%E0%A8%B9/ Wedding - Russian porn online watch brazzers-n.com http://brazzers-n.com/en/tgb/2703-%E0%A6%95%E0%A6%B0%E0%A7%8D%E0%A6%AE%E0%A6%9A%E0%A6%BE%E0%A6%B0%E0%A7%8 xnxx-hd.pro http://xnxx-hd.pro/en/striptease/ Striptease high quality videos for You.|100% free porn videos sex content| pornoload-n.com http://pornoload-n.com/en/tag/429-Coileach+M%C3%B3r/ Big Cock - Pornload best website with adult videos trahtubetv.com http://trahtubetv.com/en/yoga/ Yoga|Menu|Tractor|Main (current)|Random video|All categories|English|Ð Ñƒï¿½ brazzers-n.com http://brazzers-n.com/en/tgb/9098-%E0%A6%8F%E0%A6%95+%E0%A6%AE%E0%A6%B9%E0%A6%BF%E0%A6%B2%E0%A6%BE+%E0%A6 ruporn-tv.com http://ruporn-tv.com/en/vibrator/p/6/ Vibrator - page 6|Menu|Main (current)|Random|Category|English|Ð ÑƒÑ brazzers-n.com http://brazzers-n.com/en/tgb/22349-%E0%A6%B8%E0%A7%8D%E0%A6%AC%E0%A6%BE%E0%A6%AE%E0%A7%80/ Teagan - BRAZZ brazzers-n.com http://brazzers-n.com/en/tgb/15966-%E0%A6%AC%E0%A6%BE%E0%A6%B8%E0%A7%8D%E0%A6%A4%E0%A6%AC+%E0%A6%AE%E0%A7 brazzers-n.com http://brazzers-n.com/en/tgb/15712-%D9%81%D9%8A+%D8%B3%D9%86+%D8%A7%D9%84%D9%85%D8%B1%D8%A7%D9%87%D9%82%D brazzers-n.com http://brazzers-n.com/en/tgb/16875-%E0%A6%B0%E0%A6%BE%E0%A6%A4%E0%A7%87%E0%A6%B0+%E0%A6%B8%E0%A6%AE%E0%A6 ecml.at http://edl.ecml.at/LanguageFun/LanguageTreasures/tabid/1533/language/en-GB/Default.aspx Language Treasures|Home brazzers-n.com http://brazzers-n.com/en/tgb/13598-%D0%94%D0%B0%D1%80%D0%BE%D0%B2+%D0%90%D0%BB%D0%BB%D0%B0/ Suck Tits - B vporn-com.com http://vporn-com.com/en/tag/7184-Duplo+Recheado/ Double Stuffed - porn - Best porn videos and Sex XXX movi hotpornohub.com http://hotpornohub.com/en/dildo Dildo porn videos in excellent quality|Sliding menu|HotPornoHub|Main (cu pornoload-n.com http://pornoload-n.com/en/movie/9135781-piss.html piss|Menu|PornoLoad|Main (current)|Random video|All ca ecml.at http://edl.ecml.at/Participate/Materials/Logo/tabid/1526/language/en-GB/Default.aspx Logo|Home|What is it?|Why a dojki-n.com http://dojki-n.com/en/amateurs Amateurs videos online in hd quality|Menu|Main (current)|Random video|All cat ruporn-tv.com http://ruporn-tv.com/en/tag/3499-%D0%97%D1%83%D0%B7%D0%B0%D0%B0%D0%BD+Chubby/ Thick Chubby - Russian porn cucek.net http://cucek.net/en/pg/5/ No Boobs. While there, enjoy selective porn. - page 5|Sliding menu|Cucek.NET|Main (c brazzers-n.com http://brazzers-n.com/en/tgb/20099-%E0%A6%AA%E0%A6%A6%E0%A6%AC%E0%A7%8D%E0%A6%B0%E0%A6%9C%E0%A7%87+%E0%A6 pornoload-n.com http://pornoload-n.com/en/movie/524228-redheaded-moms-crave-orgasm.html Redheaded moms crave orgasm|Menu hdbox.ws https://hdbox.ws/en/sat-tv-novosti/4060-transpondernye-novosti-za-05-01-2017.html Â» Transponder news for 05.01 online-casino-10.pro http://online-casino-10.pro/en/ FakeTaxi - English Escort Girl Amber Jayne - online-casino-10.pro|M xnxx-hd.pro http://xnxx-hd.pro/en/mvi/54585-hairy-pussy-whores-ufa.html Hairy pussy whores Ufa|100% free porn videos sex lustful.tv http://www.lustful.tv/en/ Free porn @ Lustful TV|LustfulTV|English|Î•Î»Î»Î·Î½Î¹ÎºÎ¬|Galego|×™×™Ö´×“×™×©|à¸ ï¿½ hotpornadult.com http://hotpornadult.com/en/tag/733-Pullea/ Chubby - HotPornAdult - porn in HD|Free porn videos online|S brazzers-n.com http://brazzers-n.com/en/tgb/4273-%E0%A6%B8%E0%A6%A4%E0%A7%8D%E0%A6%AF+%E0%A6%AC%E0%A6%BE+Dare/ Truth or 24video-net.com http://24video-net.com/en/tag/124-Fucked Fucked - 24video xxx porn watch online, porn videos for free 24 biqle-ru.com http://biqle-ru.com/en/cs/ The list of all categories|Menu|Main (current)|Random|Category|English|Ð ÑƒÑÑï¿½ pornk.mobi http://pornk.mobi/en/pcts/full/ The list of all categories|Menu|Main (current)|Topics porn|Random video|Chat| pornoload-n.com http://pornoload-n.com/en/movie/3754286-voyeur-pissing-13.html Voyeur pissing 13|Menu|PornoLoad|Main (cu sozrelxxx.com http://sozrelxxx.com/en/feedback/ Feedback|ripe for porn|Bondage|British|Cartoon adult|Changed|Dildo|Dirty dojki-n.com http://dojki-n.com/en/hairy-pussy Hairy pussy videos online in hd quality|Menu|Main (current)|Random video|A brazzers-n.com http://brazzers-n.com/en/tgb/22723-%E0%A6%95%E0%A6%BE%E0%A6%B2%E0%A7%8B%2C+%E0%A6%B8%E0%A7%81%E0%A6%A8%E0 pornoload-n.com http://pornoload-n.com/en/movie/11258860-turkije.html turkije|Menu|PornoLoad|Main (current)|Random video brazzers-n.com http://brazzers-n.com/en/tgb/2526-%E0%A6%AA%E0%A6%B0%E0%A6%BF%E0%A6%A3%E0%A6%A4%2C+%E0%A6%B8%E0%A7%8D%E0% drtuber-n.com http://drtuber-n.com/en/striptease/ Striptease porn videos DrTuber|Sliding menu|Main (current)|Random vide brazzers-n.com http://brazzers-n.com/en/tgb/17799-%E0%A6%B8%E0%A7%81%E0%A6%A8%E0%A7%8D%E0%A6%A6%E0%A6%B0%E0%A6%BF+%E0%A6 brazzers-n.com http://brazzers-n.com/en/tgb/9965-%E0%A6%B8%E0%A7%81%E0%A6%A8%E0%A7%8D%E0%A6%A6%E0%A6%B0%E0%A6%BF+%E0%A6% hotpornohub.com http://hotpornohub.com/en/next/6/ Cool porn video from hotpornohub.com! - page 6|Sliding menu|HotPornoHu brazzers-n.com http://brazzers-n.com/en/tgb/9050-18%2C+%E0%A6%AA%E0%A7%8B%E0%A6%81%E0%A6%A6%2C/ 18 Anal - BRAZZERS porn brazzers-n.com http://brazzers-n.com/en/tgb/10246-%E0%A6%85%E0%A6%AA%E0%A7%87%E0%A6%B6%E0%A6%BE%E0%A6%A6%E0%A6%BE%E0%A6% trahtubetv.com http://trahtubetv.com/en/blonde Blonde|Menu|Tractor|Main (current)|Random video|All categories|English|Ð  pornoload-n.com http://pornoload-n.com/en/celebrity/ Celebrity|Menu|PornoLoad|Main (current)|Random video|All categories xnxx-hd.pro http://xnxx-hd.pro/en/tag/16818-%E0%A8%B5%E0%A9%B1%E0%A8%A1%E0%A9%87+%E0%A8%9A%E0%A9%82%E0%A8%9A%E0%A8%95+%E brazzers-n.com http://brazzers-n.com/en/tgb/1212-%E0%A6%AE%E0%A7%87%E0%A6%AF%E0%A6%BC%E0%A7%87%E0%A6%A6%E0%A7%87%E0%A6%B ruporn-tv.com http://ruporn-tv.com/en/tag/7326-T%C3%AB+Par%C3%AB+Gjat%C3%AB+Gjith%C3%AB/ See Thru - Russian porn online 24video-xxx.com http://24video-xxx.com/en/porn-orgasms Porn orgasms this category contains selected videos in HD quality pornk.mobi http://pornk.mobi/en/big-breasts/ Big breast porn pornk|Menu|Main (current)|Topics porn|Random video|Chat|Eng brazzers-n.com http://brazzers-n.com/en/tgb/84-%D0%A2%D0%BE%D0%BC+%D0%9E%D1%85%D0%B8%D0%BD+%D0%A5%D1%83%D0%BB%D0%B0%D0%B ecml.at http://edl.ecml.at/Events/PictureGallery2013/tabid/3122/language/en-GB/Default.aspx European Day of Languages &gt; brazzers-n.com http://brazzers-n.com/en/tgb/4962-%E0%A6%AC%E0%A6%A1%E0%A6%BF%E0%A6%AC%E0%A6%BF%E0%A6%B2%E0%A7%8D%E0%A6%A brazzers-n.com http://brazzers-n.com/en/tgb/3101-%E0%A6%A6%E0%A7%81%E0%A6%B7%E0%A7%8D%E0%A6%9F%E0%A7%81+%E0%A6%85%E0%A6% brazzers-n.com http://brazzers-n.com/en/tgb/20478-%E0%A6%95%E0%A6%BE%E0%A6%B2%E0%A7%8B+%E0%A6%B6%E0%A6%BF%E0%A6%95%E0%A7 xhamster-n.com http://xhamster-n.com/en/otslaivanie/ Otslaivanie free|Sliding menu|Main (current)|Random video|All categ brazzers-n.com http://brazzers-n.com/en/tgb/12973-%E0%A6%AB%E0%A6%BE%E0%A6%B2%E0%A6%BE%2C+%E0%A6%AE%E0%A7%87%E0%A6%B0%E0 brazzers-n.com http://brazzers-n.com/en/tgb/19634-%E0%A6%AE%E0%A6%BE/ Seduced by a Cougar - BRAZZERS porn Studio. Porn c brazzers-n.com http://brazzers-n.com/en/tgb/21794-%E0%A6%AA%E0%A7%8B%E0%A6%81%E0%A6%A6+%E0%A6%96%E0%A7%87%E0%A6%B2%E0%A6 24video-xxx.com http://24video-xxx.com/en/footwork/ The footwork in this category, collected the best video in HD qualit brazzers-n.com http://brazzers-n.com/en/tgb/19378-%E0%A6%B9%E0%A7%8D%E0%A6%AF%E0%A6%BE%E0%A6%B0%E0%A6%BF%E0%A6%B8/ Harri cucek.net http://cucek.net/en/mcuc/10978279-busty-flexibe-babe-fucking-ruporn.tv.html Busty flexibe babe fucking ruporn. brazzers-n.com http://brazzers-n.com/en/tgb/9820-Bavarian/ Bavarian - BRAZZERS porn Studio. Porn clips brazzers Studio a brazzers-n.com http://brazzers-n.com/en/tgb/12297-%E0%A6%AA%E0%A7%8D%E0%A6%B0%E0%A6%BE%E0%A6%95%E0%A7%83%E0%A6%A4%E0%A6% ruporn-tv.com http://ruporn-tv.com/en/tag/255-%E0%A4%AC%E0%A4%BF%E0%A4%97+%E0%A4%A1%E0%A4%BF%E0%A4%95/ Big Dick - Russia vporn-com.com http://vporn-com.com/en/gangbang Gangbang only on anysex|Menu|Main (current)|Random video|All categories|E .",
            "url": "https://jimregan.github.io/notes/badmt/irish/2021/06/05/cc-aligned-irish-porn.html",
            "relUrl": "/badmt/irish/2021/06/05/cc-aligned-irish-porn.html",
            "date": " â€¢ Jun 5, 2021"
        }
        
    
  
    
        ,"post147": {
            "title": "Extract CUDA from Kaldi docker image",
            "content": "%cd /tmp . !git clone https://github.com/jjlin/docker-image-extract/ . !docker-image-extract/docker-image-extract kaldiasr/kaldi:gpu-latest . %cd output/ . !find . -name &#39;*cudnn*&#39; -or -name &#39;*cuda*&#39; . !tar cvf /kaggle/working/cuda.tar ./usr/local/cuda-10.0/ ./usr/include/cudnn.h ./usr/include/x86_64-linux-gnu/cudnn_v7.h ./usr/include/linux/cuda.h ./usr/lib/x86_64-linux-gnu/libcudnn* .",
            "url": "https://jimregan.github.io/notes/asr/kaggle/2021/06/04/extract-cuda-from-kaldi-docker.html",
            "relUrl": "/asr/kaggle/2021/06/04/extract-cuda-from-kaldi-docker.html",
            "date": " â€¢ Jun 4, 2021"
        }
        
    
  
    
        ,"post148": {
            "title": "Multidict scraper",
            "content": "import requests from bs4 import BeautifulSoup def scrapepage(pageid): page = requests.get(f&#39;https://multidict.net/clilstore/page.php?id={pageid}&#39;) soup = BeautifulSoup(page.text, &#39;html.parser&#39;) body = soup.find(&#39;body&#39;) bodytext = body.find(&#39;div&#39;, {&#39;class&#39;: &#39;body-indent&#39;}) text = [tmp.text for tmp in bodytext.findAll(&#39;p&#39;)] iframe = bodytext.findAll(&#39;iframe&#39;) return iframe[0][&#39;src&#39;], text . print(scrapepage(&#39;8839&#39;)) . headers = { &quot;accept&quot;: &quot;text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9&quot;, &quot;accept-language&quot;: &quot;en-US,en;q=0.9,pl;q=0.8,ga;q=0.7,en-GB;q=0.6&quot;, &quot;cache-control&quot;: &quot;max-age=0&quot;, &quot;content-type&quot;: &quot;application/x-www-form-urlencoded&quot;, &quot;sec-ch-ua&quot;: &quot; &quot; Not A;Brand &quot;;v= &quot;99 &quot;, &quot;Chromium &quot;;v= &quot;90 &quot;, &quot;Google Chrome &quot;;v= &quot;90 &quot;&quot;, &quot;sec-ch-ua-mobile&quot;: &quot;?0&quot;, &quot;sec-fetch-dest&quot;: &quot;document&quot;, &quot;sec-fetch-mode&quot;: &quot;navigate&quot;, &quot;sec-fetch-site&quot;: &quot;same-origin&quot;, &quot;sec-fetch-user&quot;: &quot;?1&quot;, &quot;upgrade-insecure-requests&quot;: &quot;1&quot; } . s = requests.Session() s.headers.update(headers) s.get(&quot;https://multidict.net/clilstore/&quot;) s.headers.update({&#39;referer&#39;: &quot;https://multidict.net/clilstore/&quot;}) x = s.post(&quot;https://multidict.net/clilstore/&quot;, data=&quot;sl=ga&amp;filterForm=1&amp;title=&amp;text=&amp;showAll=showAll&quot;) . listsoup = BeautifulSoup(x.text, &#39;html.parser&#39;) . table = listsoup.find(&#39;table&#39;, {&#39;id&#39;: &#39;main&#39;}) . links = table.findAll(&#39;a&#39;) . def attrstartswith(tag, attr, needle): return tag.attrs and attr in tag.attrs and tag.attrs[attr].startswith(needle) . def collectlinks(links): out = [] for link in links: if attrstartswith(link, &#39;href&#39;, &#39;/cs/&#39;): out.append(link.attrs[&#39;href&#39;][4:]) return out .",
            "url": "https://jimregan.github.io/notes/asr/irish/todo/2021/06/02/multidict-scraper.html",
            "relUrl": "/asr/irish/todo/2021/06/02/multidict-scraper.html",
            "date": " â€¢ Jun 2, 2021"
        }
        
    
  
    
        ,"post149": {
            "title": "wav2vec-u Common Voice Swedish - GAN training, CPU1",
            "content": "Original here . Preparation . %%capture !conda install -c pykaldi pykaldi -y . %cd /tmp . /tmp . !git clone https://github.com/jimregan/fairseq/ --branch issue3581 . !git clone https://github.com/kpu/kenlm . %%capture !apt-get -y install libeigen3-dev liblzma-dev zlib1g-dev libbz2-dev . %%capture %cd /tmp/kenlm !python setup.py install %cd /tmp . import os os.environ[&#39;PATH&#39;] = f&quot;{os.environ[&#39;PATH&#39;]}:/tmp/kenlm/build/bin/&quot; os.environ[&#39;FAIRSEQ_ROOT&#39;] = &#39;/tmp/fairseq&#39; . %cd /tmp/fairseq/ . /tmp/fairseq . %%capture !python setup.py install . %cd /tmp/fairseq/ . /tmp/fairseq . os.environ[&#39;HYDRA_FULL_ERROR&#39;] = &#39;1&#39; . %%capture !pip install editdistance . GAN . %%writefile rungan.sh PREFIX=w2v_unsup_gan_xp TASK_DATA=/kaggle/input/wav2vec-u-cv-swedish-audio/precompute_pca512_cls128_mean_pooled/ TEXT_DATA=/kaggle/input/wav2vec-u-cv-swedish-text-prep/preppedtext/phones/ KENLM_PATH=/kaggle/input/wav2vec-u-cv-swedish-text-prep/preppedtext/phones/lm.phones.filtered.04.bin PREFIX=$PREFIX fairseq-hydra-train -m --config-dir fairseq/config/model/wav2vecu/gan --config-name w2vu task.data=${TASK_DATA} task.text_data=${TEXT_DATA} task.kenlm_path=${KENLM_PATH} checkpoint.no_epoch_checkpoints=false checkpoint.keep_last_epochs=20 checkpoint.save_dir=/kaggle/working &#39;common.seed=range(0,5)&#39; . Writing rungan.sh . !bash rungan.sh .",
            "url": "https://jimregan.github.io/notes/kaggle/wav2vec-u/2021/06/01/wav2vec-u-cv-swedish-gan-cpu1.html",
            "relUrl": "/kaggle/wav2vec-u/2021/06/01/wav2vec-u-cv-swedish-gan-cpu1.html",
            "date": " â€¢ Jun 1, 2021"
        }
        
    
  
    
        ,"post150": {
            "title": "wav2vec-u CV-sv - GAN",
            "content": "The original attempt on Kaggle won&#39;t run because of an issue with CuDNN, but this notebook runs fine on Colab. . Preparation . !pip install condacolab . Collecting condacolab Downloading https://files.pythonhosted.org/packages/ee/47/6f9fe13087c31aba889c4b09f9beaa558bf216bf9108c9ccef44e6c9dcfe/condacolab-0.1.2-py3-none-any.whl Installing collected packages: condacolab Successfully installed condacolab-0.1.2 . import condacolab condacolab.install() . â¬ Downloading https://github.com/jaimergp/miniforge/releases/latest/download/Mambaforge-colab-Linux-x86_64.sh... ðŸ“¦ Installing... ðŸ“Œ Adjusting configuration... ðŸ©¹ Patching environment... â² Done in 0:00:36 ðŸ” Restarting kernel... . %%capture !conda install -c pykaldi pykaldi -y . !git clone https://github.com/jimregan/fairseq/ --branch issue3581 . Cloning into &#39;fairseq&#39;... remote: Enumerating objects: 28296, done. remote: Total 28296 (delta 0), reused 0 (delta 0), pack-reused 28296 Receiving objects: 100% (28296/28296), 11.77 MiB | 24.69 MiB/s, done. Resolving deltas: 100% (21286/21286), done. . !git clone https://github.com/kpu/kenlm . Cloning into &#39;kenlm&#39;... remote: Enumerating objects: 13824, done. remote: Counting objects: 100% (137/137), done. remote: Compressing objects: 100% (79/79), done. remote: Total 13824 (delta 76), reused 92 (delta 45), pack-reused 13687 Receiving objects: 100% (13824/13824), 5.49 MiB | 20.76 MiB/s, done. Resolving deltas: 100% (7956/7956), done. . %%capture !apt-get -y install libeigen3-dev liblzma-dev zlib1g-dev libbz2-dev . %%capture %cd /content/kenlm !python setup.py install %cd /tmp . import os os.environ[&#39;PATH&#39;] = f&quot;{os.environ[&#39;PATH&#39;]}:/content/kenlm/build/bin/&quot; os.environ[&#39;FAIRSEQ_ROOT&#39;] = &#39;/content/fairseq&#39; . %cd /content/fairseq/ . /content/fairseq . %%capture !python setup.py install . os.environ[&#39;HYDRA_FULL_ERROR&#39;] = &#39;1&#39; . %%capture !pip install editdistance . https://colab.research.google.com/github/corrieann/kaggle/blob/master/kaggle_api_in_colab.ipynb . %%capture !pip install kaggle . from google.colab import files uploaded = files.upload() for fn in uploaded.keys(): print(&#39;User uploaded file &quot;{name}&quot; with length {length} bytes&#39;.format( name=fn, length=len(uploaded[fn]))) # Then move kaggle.json into the folder where the API expects to find it. !mkdir -p ~/.kaggle/ &amp;&amp; mv kaggle.json ~/.kaggle/ &amp;&amp; chmod 600 ~/.kaggle/kaggle.json . Upload widget is only available when the cell has been executed in the current browser session. Please rerun this cell to enable. Saving kaggle.json to kaggle.json User uploaded file &#34;kaggle.json&#34; with length 64 bytes . %cd /content . /content . !kaggle datasets download &quot;jimregan/w2vu-cvsv-prepared-text&quot; . Downloading w2vu-cvsv-prepared-text.zip to /content 75% 13.0M/17.4M [00:00&lt;00:00, 55.1MB/s] 100% 17.4M/17.4M [00:00&lt;00:00, 64.5MB/s] . %%capture !unzip /content/w2vu-cvsv-prepared-text.zip . !kaggle datasets download -d jimregan/w2vu-cvsv-precompute-pca512-cls128-mean-pooled . Downloading w2vu-cvsv-precompute-pca512-cls128-mean-pooled.zip to /content 98% 386M/394M [00:04&lt;00:00, 90.1MB/s] 100% 394M/394M [00:04&lt;00:00, 102MB/s] . %%capture !unzip w2vu-cvsv-precompute-pca512-cls128-mean-pooled.zip . !rm *.zip . GAN . import torch torch.version.cuda . &#39;10.1&#39; . torch.backends.cudnn.version() . 7603 . %cd /content/fairseq . /content/fairseq . from google.colab import drive drive.mount(&#39;/content/drive&#39;) . %%writefile rungan.sh PREFIX=w2v_unsup_gan_xp TASK_DATA=/content/precompute_pca512_cls128_mean_pooled TEXT_DATA=/content/preppedtext/phones/ KENLM_PATH=/content/preppedtext/phones/lm.phones.filtered.04.bin PREFIX=$PREFIX CUDA_LAUNCH_BLOCKING=1 fairseq-hydra-train -m --config-dir fairseq/config/model/wav2vecu/gan --config-name w2vu task.data=${TASK_DATA} task.text_data=${TEXT_DATA} task.kenlm_path=${KENLM_PATH} checkpoint.no_epoch_checkpoints=true checkpoint.save_dir=/content/drive/MyDrive/w2vu &#39;common.seed=range(0,5)&#39; . Writing rungan.sh . !bash rungan.sh . [2021-06-04 00:06:14,189][fairseq.tasks.unpaired_audio_text][INFO] - REF: É› n f Å“ Ê‚ É™ n a d Éµ Ê‚ É™ k t f Ã¸Ë r d eË t s É” m h É› n d É™ p oË É• Å“ r k É” n s É› t É™ n [2021-06-04 00:06:14,192][fairseq.tasks.unpaired_audio_text][INFO] - HYP: oË b iË Êƒ Å“ m É• m Å“ É• Éª Éµ É• Éµ m Éµ s Éµ uË Éµ s Éµ É› Ê‚ a tË sx [2021-06-04 00:06:14,198][fairseq.tasks.unpaired_audio_text][INFO] - LM [REF]: -53.44462585449219, 0.05339602260269112 [2021-06-04 00:06:14,198][fairseq.tasks.unpaired_audio_text][INFO] - LM [HYP]: -61.104984283447266, 0.006571721232914821 [2021-06-04 00:06:14,844][valid][INFO] - {&#34;epoch&#34;: 8, &#34;valid_loss&#34;: &#34;0.93&#34;, &#34;valid_ntokens&#34;: &#34;3039.79&#34;, &#34;valid_nsentences&#34;: &#34;144.214&#34;, &#34;valid_lm_score_sum&#34;: &#34;-71760.8&#34;, &#34;valid_num_pred_chars&#34;: &#34;28972&#34;, &#34;valid_vocab_seen_pct&#34;: &#34;0.949477&#34;, &#34;valid_uer&#34;: &#34;92.9812&#34;, &#34;valid_weighted_lm_ppl&#34;: &#34;229.386&#34;, &#34;valid_lm_ppl&#34;: &#34;206.793&#34;, &#34;valid_wps&#34;: &#34;15426&#34;, &#34;valid_wpb&#34;: &#34;3039.8&#34;, &#34;valid_bsz&#34;: &#34;144.2&#34;, &#34;valid_num_updates&#34;: &#34;128&#34;, &#34;valid_best_weighted_lm_ppl&#34;: &#34;189.002&#34;} [2021-06-04 00:06:14,846][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 8 @ 128 updates [2021-06-04 00:06:14,847][fairseq.trainer][INFO] - Saving checkpoint to /content/drive/MyDrive/w2vu/checkpoint8.pt [2021-06-04 00:06:14,911][fairseq.trainer][INFO] - Finished saving checkpoint to /content/drive/MyDrive/w2vu/checkpoint8.pt [2021-06-04 00:06:14,974][fairseq.checkpoint_utils][INFO] - Saved checkpoint /content/drive/MyDrive/w2vu/checkpoint8.pt (epoch 8 @ 128 updates, score 229.38563413598007) (writing took 0.12713056299980963 seconds) .",
            "url": "https://jimregan.github.io/notes/kaggle/colab/wav2vec-u/2021/05/30/wav2vec-u-cv-swedish-gan.html",
            "relUrl": "/kaggle/colab/wav2vec-u/2021/05/30/wav2vec-u-cv-swedish-gan.html",
            "date": " â€¢ May 30, 2021"
        }
        
    
  
    
        ,"post151": {
            "title": "Find datives in Unimorph",
            "content": "Unimorph&#39;s Irish extraction from Wiktionary is basically useless: nouns don&#39;t include gender, they extract contexts instead of forms, and only extract the first of multiple contexts; their tagset is bizarre and incomplete regarding Irish. About the only thing it&#39;s even potentially good for is finding the dative forms of nouns (without doing a full wiktionary extraction). . with open(&#39;../input/unimorph-gle/gle&#39;, &#39;r&#39;) as crap: for line in crap.readlines(): if line.strip() == &#39;&#39;: continue parts = line.split(&#39; t&#39;) if len(parts) &lt; 3: print(f&#39;Junk: &lt;{parts[0]}&gt; &lt;{parts[1]}&gt;&#39;) if parts[2] == &#39;N;DAT;SG&#39; and parts[0] != parts[1]: print(f&#39;{parts[0]} t{parts[1]}&#39;) elif parts[2] == &#39;N;DAT;SG;DEF&#39;: form = parts[2].replace(&#39;leis an &#39;, &#39;&#39;) if len(form) &gt; 3 and form[0:2] == &#39;bhf&#39; or form[0:1] == &#39;n-&#39;: if parts[0] != form[2:]: print(f&#39;{parts[0]} t{form[2:]}&#39;) elif len(form) &gt; 2 and form[0:1] in [&#39;mb&#39;, &#39;gc&#39;, &#39;nd&#39;, &#39;ng&#39;, &#39;bp&#39;, &#39;dt&#39;]: if parts[0] != form[1:]: print(f&#39;{parts[0]} t{form[1:]}&#39;) else: continue .",
            "url": "https://jimregan.github.io/notes/irish/unimorph/2021/05/29/find-datives-in-unimorph-gle.html",
            "relUrl": "/irish/unimorph/2021/05/29/find-datives-in-unimorph-gle.html",
            "date": " â€¢ May 29, 2021"
        }
        
    
  
    
        ,"post152": {
            "title": "Compiling Kaldi on Kaggle",
            "content": "Original . Kaldi is a bit of a beast to install. I tried to get around it by extracting files from the official docker image: tl;dr, it works fine for the tools that run on CPU, but the GPU-based tools depend on CUDA 10.0, while Kaggle&#39;s GPU images use CUDA 11.0. . I&#39;m building this in /opt to match the docker extraction notebook. . %cd /opt . !git clone https://github.com/kaldi-asr/kaldi . I&#39;m installing cudatoolkit to make sure it&#39;s there, and the same version as the one in the gpu docker image, because issues with that are why I&#39;m compiling this in the first place. You can quite possibly get away with not running this step, but I&#39;m not taking a chance on it. If you are going to re-run this, make sure to check the gpu docker image to match the version for cudatoolkit. . #!conda install cudatoolkit=11.0 -y . !conda install cudatoolkit-dev=11.0 . %%capture !apt-get -y install liblapack-dev sox . First step is to follow the instructions in kaldi/tools . %cd /opt/kaldi/tools . The INSTALL file says to run extras/check_dependencies.sh, fix anything that&#39;s missing, and then run make. It&#39;s unlikely that new dependencies will be added (Kaldi more in maintenance mode than active development), but just in case, uncomment the line in the next cell and run it. . #!./extras/check_dependencies.sh . This is what I was missing from the check_dependencies check: . %%capture !apt-get -y install automake autoconf gfortran subversion . %%capture !make . Next,we need a maths library: . %%capture !extras/install_openblas.sh . Now is the time to build any of the optional dependencies you might want. I want phonetisaurus. . %%capture !bash extras/install_phonetisaurus.sh . I had problems with phonetisaurus-apply from the branch installed by install_phonetisaurus.sh, so I&#39;m replacing it with an updated version from the phonetisaurus repo: . %%writefile /opt/kaldi/tools/phonetisaurus-g2p/src/scripts/phonetisaurus-apply #!/usr/bin/env python # -*- mode: python; coding: utf-8 -*- from __future__ import print_function from __future__ import unicode_literals import os, logging, subprocess, time, re from datetime import datetime from collections import defaultdict import tempfile class G2PModelTester () : &quot;&quot;&quot;G2P Model training wrapper class. Phonetisaurus G2P modeling training wrapper class. This wraps the alignment, joint n-gram training, and ARPA to WFST conversion steps into one command. &quot;&quot;&quot; def __init__ (self, model, **kwargs) : self.model = model self.lexicon_file = kwargs.get (&quot;lexicon&quot;, None) self.nbest = kwargs.get (&quot;nbest&quot;, 1) self.thresh = kwargs.get (&quot;thresh&quot;, 99) self.beam = kwargs.get (&quot;beam&quot;, 10000) self.greedy = kwargs.get (&quot;greedy&quot;, False) self.accumulate = kwargs.get (&quot;accumulate&quot;, False) self.pmass = kwargs.get (&quot;pmass&quot;, 0.0) self.probs = kwargs.get (&quot;probs&quot;, False) self.verbose = kwargs.get (&quot;verbose&quot;, False) self.logger = self.setupLogger () def setupLogger (self) : &quot;&quot;&quot;Setup the logger and logging level. Setup the logger and logging level. We only support verbose and non-verbose mode. Args: verbose (bool): Verbose mode, or not. Returns: Logger: A configured logger instance. &quot;&quot;&quot; level = logging.DEBUG if self.verbose else logging.INFO logging.basicConfig ( level=level, format=&quot; 033[94m%(levelname)s:%(name)s:&quot; &quot;%(asctime)s 033[0m: %(message)s&quot;, datefmt=&quot;%Y-%m-%d %H:%M:%S&quot; ) return logging.getLogger (&quot;phonetisaurus-apply&quot;) def _loadLexicon (self) : &quot;&quot;&quot;Load the lexicon from a file. Load the reference lexicon from a file, and store it in a defaultdict (list). &quot;&quot;&quot; _lexicon = defaultdict (list) if not self.lexicon_file : return _lexicon self.logger.debug (&quot;Loading lexicon from file...&quot;) with open (self.lexicon_file, &quot;r&quot;) as ifp : for line in ifp : # py2py3 compatbility, if sys.version_info[0] &lt; 3: line = line.decode(&quot;utf8&quot;).strip () else: line = line.strip () word, pron = re.split (r&quot; t&quot;, line, 1) _lexicon [word].append (pron) return _lexicon def checkPhonetisaurusConfig (self) : &quot;&quot;&quot;Run some basic checks before training. Run some basic checks regarding the $PATH, environment, and provided data before starting training. Raises: EnvironmentError: raised if binaries are not found. &quot;&quot;&quot; self.logger.debug (&quot;Checking command configuration...&quot;) for program in [&quot;phonetisaurus-g2pfst&quot;] : if not self.which (program) : raise EnvironmentError(&quot;Phonetisaurus command, &#39;{0}&#39;, &quot; &quot;not found in path.&quot;.format (program)) if self.lexicon_file and not os.path.exists (self.lexicon_file) : self.logger.error (&quot;Could not find provided lexicon file.&quot;) sys.exit (1) for key,val in sorted (vars (self).items ()) : self.logger.debug (u&quot;{0}: {1}&quot;.format (key, val)) self.lexicon = self._loadLexicon () return def which (self, program) : &quot;&quot;&quot;Basic &#39;which&#39; implementation for python. Basic &#39;which&#39; implementation for python from stackoverflow: * https://stackoverflow.com/a/377028/6739158 Args: program (str): The program name to search the $PATH for. Returns: path/None: The path to the executable, or None. &quot;&quot;&quot; def is_exe (fpath) : return os.path.isfile (fpath) and os.access (fpath, os.X_OK) fpath, fname = os.path.split (program) if fpath: if is_exe (program): return program else: for path in os.environ[&quot;PATH&quot;].split (os.pathsep) : path = path.strip (&#39;&quot;&#39;) exe_file = os.path.join (path, program) if is_exe (exe_file): return exe_file return None def makeG2PCommand (self, word_list) : &quot;&quot;&quot;Build the G2P command. Build the G2P command from the provided arguments. Returns: list: The command in subprocess list format. &quot;&quot;&quot; command = [ u&quot;phonetisaurus-g2pfst&quot;, u&quot;--model={0}&quot;.format (self.model), u&quot;--nbest={0}&quot;.format (self.nbest), u&quot;--beam={0}&quot;.format (self.beam), u&quot;--thresh={0}&quot;.format (self.thresh), u&quot;--accumulate={0}&quot;.format (str (self.accumulate).lower ()), u&quot;--pmass={0}&quot;.format (self.pmass), u&quot;--nlog_probs={0}&quot;.format (str(not self.probs).lower ()), u&quot;--wordlist={0}&quot;.format (word_list) ] self.logger.debug (u&quot; &quot;.join (command)) return command def runG2PCommand (self, word_list_file) : &quot;&quot;&quot;Generate and run the actual G2P command. Generate and run the actual G2P command. Each synthesized entry will be yielded back on-the-fly via the subprocess stdout readline method. Args: word_list_file (str): The input word list. &quot;&quot;&quot; g2p_command = self.makeG2PCommand (word_list_file) self.logger.debug (&quot;Applying G2P model...&quot;) with open (os.devnull, &quot;w&quot;) as devnull : proc = subprocess.Popen ( g2p_command, stdout=subprocess.PIPE, stderr=devnull if not self.verbose else None ) for line in proc.stdout : parts = re.split (r&quot; t&quot;, line.decode (&quot;utf8&quot;).strip ()) if not len (parts) == 3 : self.logger.warning ( u&quot;No pronunciation for word: &#39;{0}&#39;&quot;.format (parts [0]) ) continue yield parts return def applyG2POnly (self, word_list_file) : &quot;&quot;&quot;Apply the G2P model to a word list. Apply the G2P model to a word list. No filtering or application of a reference lexicon is used here. Args: word_list_file (str): The input word list. &quot;&quot;&quot; for word, score, pron in self.runG2PCommand (word_list_file) : line = u&quot;&quot; if self.verbose : line = u&quot;{0} t{1:.2f} t{2}&quot;.format ( word, float (score), pron ) else : line = u&quot;{0} t{1}&quot;.format (word, pron) # py2py3 compatbility, if sys.version_info[0] &lt; 3: print (line.encode (&quot;utf8&quot;)) else : print (line) return def applyG2PWithLexicon (self, word_list_file) : &quot;&quot;&quot;Apply the G2P model to a word list, combined with lexicon. Apply the G2P model to a word list, but combine this with a reference lexicon. Words for which a reference entry exists will not be sent to the G2P, unless the additional &#39;--greedy&#39; flag is set to True. Args: word_list_file (str): The input word list. &quot;&quot;&quot; target_lexicon = defaultdict (list) tmpwordlist = tempfile.NamedTemporaryFile(mode=&#39;w&#39;, delete=False) #First, find any words in the target list for which we already # have a canonical pronunciation in the reference lexicon. with open (word_list_file, &quot;r&quot;) as ifp : for word in ifp : # py2py3 compatbility, if sys.version_info[0] &lt; 3: word = word.decode (&quot;utf8&quot;).strip () else: word = word.strip () # already in &#39;utf8&#39;. if word in self.lexicon : target_lexicon [word] = [(0.0,pron) for pron in self.lexicon [word]] #In greedy mode we still send words to the G2P, even # if we have canonical entries in the reference lexicon. if self.greedy : print (word.encode (&quot;utf8&quot;), file=tmpwordlist) else : # py2py3 compatbility, if sys.version_info[0] &lt; 3: print (word.encode (&quot;utf8&quot;), file=tmpwordlist) else: print (word, file=tmpwordlist) tmpwordlist.close () #Second, iterate through the G2P output, and filter against # any possible duplicates previously found in the reference lexicon. for word, score, pron in self.runG2PCommand (tmpwordlist.name) : prons = set ([p for s,p in target_lexicon [word]]) if pron in prons : continue target_lexicon [word].append ((score, pron)) #Finally, sort everything that is left and print it. for word in sorted (target_lexicon.keys ()) : for score, pron in target_lexicon [word] : line = u&quot;&quot; if self.verbose : line = u&quot;{0} t{1:.2f} t{2}&quot;.format ( word, float (score), pron ) else : line = u&quot;{0} t{1}&quot;.format (word, pron) # py2py3 compatbility, if sys.version_info[0] &lt; 3: print (line.encode (&quot;utf8&quot;)) else : print (line) os.unlink (tmpwordlist.name) return def ApplyG2PModel (self, word_list_file) : &quot;&quot;&quot;Apply the G2P model to a word list. Apply the G2P model to a word list. Args: word_list_file (str): The input word list. &quot;&quot;&quot; self.checkPhonetisaurusConfig () if not os.path.exists (word_list_file) or not os.path.isfile (word_list_file) : raise IOError(&quot;Word list file not found.&quot;) if len (self.lexicon) == 0 : self.applyG2POnly (word_list_file) else : self.applyG2PWithLexicon (word_list_file) return if __name__ == &quot;__main__&quot; : import sys, argparse example = &quot;{0} --model train/model.fst --word test&quot;.format (sys.argv [0]) parser = argparse.ArgumentParser (description=example) parser.add_argument (&quot;--model&quot;, &quot;-m&quot;, help=&quot;Phonetisaurus G2P fst model.&quot;, required=True) parser.add_argument (&quot;--lexicon&quot;, &quot;-l&quot;, help=&quot;Optional reference lexicon.&quot;, required=False) parser.add_argument (&quot;--nbest&quot;, &quot;-n&quot;, help=&quot;Maximum number of hypotheses &quot; &quot;to produce. Overridden if --pmass is set.&quot;, default=1, type=int) parser.add_argument (&quot;--beam&quot;, &quot;-b&quot;, help=&quot;Search &#39;beam&#39;.&quot;, default=10000, type=int) parser.add_argument (&quot;--thresh&quot;, &quot;-t&quot;, help=&quot;Pruning threshold for n-best.&quot;, default=99.0, type=float) parser.add_argument (&quot;--greedy&quot;, &quot;-g&quot;, help=&quot;Use the G2P even if a &quot; &quot;reference lexicon has been provided.&quot;, default=False, action=&quot;store_true&quot;) parser.add_argument (&quot;--accumulate&quot;, &quot;-a&quot;, help=&quot;Accumulate probabilities &quot; &quot;across unique pronunciations.&quot;, default=False, action=&quot;store_true&quot;) parser.add_argument (&quot;--pmass&quot;, &quot;-p&quot;, help=&quot;Select the maximum number of &quot; &quot;hypotheses summing to P total mass for a word.&quot;, default=0.0, type=float) parser.add_argument (&quot;--probs&quot;, &quot;-pr&quot;, help=&quot;Print exp(-val) &quot; &quot;instead of default -log values.&quot;, default=False, action=&quot;store_true&quot;) parser.add_argument (&quot;--word_list&quot;, &quot;-wl&quot;, help=&quot;Input word or word list to apply &quot; &quot;G2P model to.&quot;, type=str) parser.add_argument (&quot;--verbose&quot;, &quot;-v&quot;, help=&quot;Verbose mode.&quot;, default=False, action=&quot;store_true&quot;) args = parser.parse_args () tester = G2PModelTester ( args.model, **{key:val for key,val in args.__dict__.items () if not key in [&quot;model&quot;,&quot;word_list&quot;]} ) tester.ApplyG2PModel (args.word_list) . %cd /opt/kaldi/src/ . Be sure to uncomment and run the next cell, to make sure nothing&#39;s changed; it&#39;s unlikely that anything will have changed, though. The following cell does configure, make depend, and make, which is all that the current INSTALL says. . . !./configure --shared --use-cuda --mathlib=OPENBLAS !make depend -j 8 !make -j 8 . %cd /opt . Second last step, clean up the object files: . !find /opt/kaldi -type f ( -name &quot;*.o&quot; -o -name &quot;*.la&quot; -o -name &quot;*.a&quot; ) -exec rm {} ; . !tar cvf /kaggle/working/kaldi.tar kaldi/ .",
            "url": "https://jimregan.github.io/notes/kaggle/kaldi/2021/05/28/compile-kaldi.html",
            "relUrl": "/kaggle/kaldi/2021/05/28/compile-kaldi.html",
            "date": " â€¢ May 28, 2021"
        }
        
    
  
    
        ,"post153": {
            "title": "Common Voice Swedish - prepare audio",
            "content": "Original here . %cd /tmp . /tmp . %%capture !pip install git+https://github.com/pytorch/fairseq/ . %%capture !git clone https://github.com/pytorch/fairseq/ . %cd fairseq/examples/wav2vec/unsupervised/scripts . /tmp/fairseq/examples/wav2vec/unsupervised/scripts . !mkdir tsv !for i in train test valid; do echo /kaggle/input/wav2vec-u-cv-swedish-vads/wav/$i/common-voice-swedish-16bit-wav/ &gt; tsv/$i.tsv; cat /kaggle/input/fork-of-wav2vec-u-cv-swedish-tsv/$i.tsv|sed &#39;1d&#39; &gt;&gt; tsv/$i.tsv;done !cp /kaggle/input/wav2vec-u-cv-swedish-prep-ltr-phn-wrd/dic* tsv/ !cp /kaggle/input/wav2vec-u-cv-swedish-prep-ltr-phn-wrd/*.wrd tsv/ !cp /kaggle/input/wav2vec-u-cv-swedish-prep-ltr-phn-wrd/*.ltr tsv/ !cp /kaggle/input/wav2vec-u-cv-swedish-prep-ltr-phn-wrd/*.phn tsv/ . %%capture !pip install npy-append-array . !pip install faiss-gpu . %%capture !apt-get -y install zsh . !zsh prepare_audio.sh tsv /kaggle/working /kaggle/input/download-xlsr-53-wav2vec2-model/xlsr_53_56k.pt . using 512 dim for PCA 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2331/2331 [01:21&lt;00:00, 28.76it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2019/2019 [01:07&lt;00:00, 29.98it/s] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2027/2027 [01:08&lt;00:00, 29.41it/s] Faiss Specs: [faiss_spec(pca=0, norm=False, n_clus=128, sphere=False, spec_str=&#39;CLUS128&#39;)] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2331/2331 [01:10&lt;00:00, 33.09it/s] (223140, 1024) Processing spec faiss_spec(pca=0, norm=False, n_clus=128, sphere=False, spec_str=&#39;CLUS128&#39;) Computing kmeans Clustering 223140 points in 1024D to 128 clusters, redo 3 times, 50 iterations Preprocessing in 0.17 s Outer iteration 0 / 3 Objective improved: keep new clusters Outer iteration 1 / 3 Objective improved: keep new clusters Outer iteration 2 / 3 Objective improved: keep new clusters Faiss Spec: faiss_spec(pca=0, norm=False, n_clus=128, sphere=False, spec_str=&#39;CLUS128&#39;) Loaded centroids (128, 1024) 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2331/2331 [00:58&lt;00:00, 40.05it/s] Faiss Spec: faiss_spec(pca=0, norm=False, n_clus=128, sphere=False, spec_str=&#39;CLUS128&#39;) Loaded centroids (128, 1024) 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2019/2019 [00:57&lt;00:00, 35.24it/s] Faiss Spec: faiss_spec(pca=0, norm=False, n_clus=128, sphere=False, spec_str=&#39;CLUS128&#39;) Loaded centroids (128, 1024) 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2027/2027 [00:51&lt;00:00, 39.40it/s] Reading features Computing PCA data path: /kaggle/working/train 0%| | 0/1 [00:00&lt;?, ?it/s]apply_pca.py:66: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1603729047590/work/torch/csrc/utils/tensor_numpy.cpp:141.) x = torch.from_numpy(features[start:end]).cuda() 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01&lt;00:00, 1.53s/it] data path: /kaggle/working/precompute_pca512/train 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2331/2331 [00:05&lt;00:00, 402.56it/s] data path: /kaggle/working/precompute_pca512_cls128_mean/train 0%| | 0/2331 [00:00&lt;?, ?it/s]mean_pool.py:69: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1603729047590/work/torch/csrc/utils/tensor_numpy.cpp:141.) x = torch.from_numpy(feats).cuda() 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2331/2331 [00:03&lt;00:00, 692.56it/s] data path: /kaggle/working/valid 0%| | 0/1 [00:00&lt;?, ?it/s]apply_pca.py:66: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1603729047590/work/torch/csrc/utils/tensor_numpy.cpp:141.) x = torch.from_numpy(features[start:end]).cuda() 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01&lt;00:00, 1.60s/it] data path: /kaggle/working/precompute_pca512/valid 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2019/2019 [00:04&lt;00:00, 447.45it/s] data path: /kaggle/working/precompute_pca512_cls128_mean/valid 0%| | 0/2019 [00:00&lt;?, ?it/s]mean_pool.py:69: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1603729047590/work/torch/csrc/utils/tensor_numpy.cpp:141.) x = torch.from_numpy(feats).cuda() 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2019/2019 [00:03&lt;00:00, 592.35it/s] data path: /kaggle/working/test 0%| | 0/1 [00:00&lt;?, ?it/s]apply_pca.py:66: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1603729047590/work/torch/csrc/utils/tensor_numpy.cpp:141.) x = torch.from_numpy(features[start:end]).cuda() 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01&lt;00:00, 1.22s/it] data path: /kaggle/working/precompute_pca512/test 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2027/2027 [00:05&lt;00:00, 379.47it/s] data path: /kaggle/working/precompute_pca512_cls128_mean/test 0%| | 0/2027 [00:00&lt;?, ?it/s]mean_pool.py:69: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1603729047590/work/torch/csrc/utils/tensor_numpy.cpp:141.) x = torch.from_numpy(feats).cuda() 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2027/2027 [00:03&lt;00:00, 569.65it/s] .",
            "url": "https://jimregan.github.io/notes/kaggle/wav2vec-u/2021/05/27/wav2vec-u-cv-swedish-audio.html",
            "relUrl": "/kaggle/wav2vec-u/2021/05/27/wav2vec-u-cv-swedish-audio.html",
            "date": " â€¢ May 27, 2021"
        }
        
    
  
    
        ,"post154": {
            "title": "wav2vec-u CV-sv - prepare text",
            "content": "Original here . %cd /opt . /opt . %%capture !tar xvf /kaggle/input/extract-prebuilt-kaldi-from-docker/kaldi.tar . %cd /tmp . /tmp . !git clone https://github.com/pytorch/fairseq/ . %%capture !pip install phonemizer . %%capture !pip install git+https://github.com/pytorch/fairseq/ . %%capture !apt-get -y install espeak . !git clone https://github.com/kpu/kenlm . %%capture !apt-get -y install libeigen3-dev liblzma-dev zlib1g-dev libbz2-dev . %%capture %cd kenlm !mkdir build %cd build !cmake .. !make -j 4 %cd /tmp . import os os.environ[&#39;PATH&#39;] = f&quot;{os.environ[&#39;PATH&#39;]}:/tmp/kenlm/build/bin/&quot; os.environ[&#39;FAIRSEQ_ROOT&#39;] = &#39;/tmp/fairseq&#39; . !cat /kaggle/input/wav2vec-u-cv-swedish-audio/*.wrd | grep -v &#39;^$&#39; | sort| uniq &gt; /kaggle/working/sentences.txt . %cd fairseq/examples/wav2vec/unsupervised . /tmp/fairseq/examples/wav2vec/unsupervised . %%capture !apt-get -y install zsh . !mkdir /kaggle/working/preppedtext . %cd scripts . /tmp/fairseq/examples/wav2vec/unsupervised/scripts . The next part requires a FastText language id model; I don&#39;t know where the 187 language model comes from, but there is a model for 176 languages here . !wget https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin . !cat normalize_and_filter_text.py|sed -e &#39;s/187/176/&#39; &gt; tmp !mv tmp normalize_and_filter_text.py . os.environ[&#39;HYDRA_FULL_ERROR&#39;] = &#39;1&#39; . import os os.environ[&#39;LD_LIBRARY_PATH&#39;] = &#39;/opt/conda/lib:/opt/kaldi/tools/openfst-1.6.7/lib:/opt/kaldi/src/lib&#39; . There are two lines with missing variables in prepare_text.sh - pull request - so replace the file. . While I&#39;m replacing the file: most of the first part of the script is unneeded, as I already have a phonetic dictionary, so I&#39;m using that instead. . With the calls of the preprocess.py script, make sure to check the threshold: there&#39;s a divide by zero if the threshold is set too high. . Config options for kaldi_initializer.py . in_labels: a naming component, for the Kaldi lexicons/fsts (required) | wav2letter_lexicon: path to wav2letter lexicon | out_labels: a naming component, for the Kaldi lexicons/fsts: set to in_label if missing | kaldi_root: path to Kaldi: /opt/kaldi for my kaggle image | fst_dir: path where generated fsts will be saved | data_dir: path to phones data | lm_arpa: path to the lm in ARPA format | blank_symbol: CTC blank symbol (&lt;s&gt; here) | silence_symbol: Kaldi symbol for silence (&lt;SIL&gt; is set for two of the scripts) | . A config file needs to exist for this, even though the options set in it seem to be ignored. . !mkdir /tmp/fairseq/examples/speech_recognition/kaldi/config/ . %%writefile /tmp/fairseq/examples/speech_recognition/kaldi/config/config.yaml kaldi_root: &quot;/opt/kaldi&quot; . Writing /tmp/fairseq/examples/speech_recognition/kaldi/config/config.yaml . %%writefile prepare_text.sh #!/usr/bin/env zsh # Copyright (c) Facebook, Inc. and its affiliates. # # This source code is licensed under the MIT license found in the # LICENSE file in the root directory of this source tree. lg=$1 text_path=$2 target_dir=$3 #ph_lg=${lg:l} #if test &quot;$lg&quot; = &#39;fr&#39;; then # ph_lg=&#39;fr-fr&#39; #elif test &quot;$lg&quot; = &#39;en&#39;; then # ph_lg=&#39;en-us&#39; #elif test &quot;$lg&quot; = &#39;pt&#39;; then # ph_lg=&#39;pt-br&#39; #fi ph_lg=&quot;sv&quot; echo $lg echo $ph_lg echo $text_path echo $target_dir mkdir -p $target_dir #python normalize_and_filter_text.py --lang $lg &lt; $text_path | grep -v &#39; - - -&#39; &gt;! $target_dir/lm.upper.lid.txt #python $FAIRSEQ_ROOT/fairseq_cli/preprocess.py --dataset-impl mmap --trainpref $target_dir/lm.upper.lid.txt --only-source --destdir $target_dir --thresholdsrc 2 --padding-factor 1 --dict-only #cut -f1 -d&#39; &#39; $target_dir/dict.txt | grep -v -x &#39;[[:punct:]]*&#39; | grep -Pv &#39; d d d d d+&#39; &gt;! $target_dir/words.txt cp /kaggle/input/wav2vec-u-cv-swedish-audio/train.wrd $target_dir/lm.upper.lid.txt cut -f1 -d&#39; &#39; /kaggle/input/wav2vec-u-cv-swedish-audio/dict.train &gt;! $target_dir/words.txt #one=$(echo &quot;1&quot; | PHONEMIZER_ESPEAK_PATH=$(which espeak) phonemize -p &#39; &#39; -w &#39;&#39; -l $ph_lg --language-switch remove-flags) #sed &#39;s/$/ 1/&#39; $target_dir/words.txt | PHONEMIZER_ESPEAK_PATH=$(which espeak) phonemize -o $target_dir/phones.txt -p &#39; &#39; -w &#39;&#39; -l $ph_lg -j 70 --language-switch remove-flags cut -f2- -d&#39; &#39; /kaggle/input/wav2vec-u-cv-swedish-audio/dict.train &gt;! $target_dir/phones.txt #echo &quot;one is ${one}&quot; #sed -i &quot;s/${one}$//&quot; $target_dir/phones.txt #paste $target_dir/words.txt $target_dir/phones.txt &gt;! $target_dir/lexicon.lst cp /kaggle/input/wav2vec-u-cv-swedish-audio/dict.train $target_dir/lexicon.lst #python $FAIRSEQ_ROOT/fairseq_cli/preprocess.py --dataset-impl mmap --trainpref $target_dir/phones.txt --only-source --destdir $target_dir/phones --thresholdsrc 1000 --padding-factor 1 --dict-only python $FAIRSEQ_ROOT/fairseq_cli/preprocess.py --dataset-impl mmap --trainpref $target_dir/phones.txt --only-source --destdir $target_dir/phones --thresholdsrc 2 --padding-factor 1 --dict-only python filter_lexicon.py -d $target_dir/phones/dict.txt &lt; $target_dir/lexicon.lst &gt;! $target_dir/lexicon_filtered.lst python phonemize_with_sil.py -s 0.25 --surround --lexicon $target_dir/lexicon_filtered.lst &lt; $target_dir/lm.upper.lid.txt &gt;! $target_dir/phones/lm.phones.filtered.txt cp $target_dir/phones/dict.txt $target_dir/phones/dict.phn.txt echo &quot;&lt;SIL&gt; 0&quot; &gt;&gt; $target_dir/phones/dict.phn.txt python $FAIRSEQ_ROOT/fairseq_cli/preprocess.py --dataset-impl mmap --trainpref $target_dir/phones/lm.phones.filtered.txt --workers 70 --only-source --destdir $target_dir/phones --srcdict $target_dir/phones/dict.phn.txt lmplz -o 4 &lt; $target_dir/lm.upper.lid.txt --discount_fallback --prune 0 0 0 3 &gt;! $target_dir/kenlm.wrd.o40003.arpa build_binary $target_dir/kenlm.wrd.o40003.arpa $target_dir/kenlm.wrd.o40003.bin lg=$lg python $FAIRSEQ_ROOT/examples/speech_recognition/kaldi/kaldi_initializer.py fst_dir=$target_dir/fst/phn_to_words_sil lm_arpa=$target_dir/kenlm.wrd.o40003.arpa wav2letter_lexicon=$target_dir/lexicon_filtered.lst data_dir=$target_dir/phones &quot;blank_symbol=&#39;&lt;SIL&gt;&#39;&quot; &quot;in_labels=&#39;phn&#39;&quot; &quot;kaldi_root=&#39;/opt/kaldi&#39;&quot; lg=$lg python $FAIRSEQ_ROOT/examples/speech_recognition/kaldi/kaldi_initializer.py fst_dir=$target_dir/fst/phn_to_words lm_arpa=$target_dir/kenlm.wrd.o40003.arpa wav2letter_lexicon=$target_dir/lexicon_filtered.lst data_dir=$target_dir/phones &quot;in_labels=&#39;phn&#39;&quot; &quot;kaldi_root=&#39;/opt/kaldi&#39;&quot; lmplz -o 4 &lt; $target_dir/phones/lm.phones.filtered.txt --discount_fallback &gt;! $target_dir/phones/lm.phones.filtered.04.arpa build_binary -s $target_dir/phones/lm.phones.filtered.04.arpa $target_dir/phones/lm.phones.filtered.04.bin lmplz -o 6 &lt; $target_dir/phones/lm.phones.filtered.txt --discount_fallback &gt;! $target_dir/phones/lm.phones.filtered.06.arpa build_binary -s $target_dir/phones/lm.phones.filtered.06.arpa $target_dir/phones/lm.phones.filtered.06.bin lg=$lg python $FAIRSEQ_ROOT/examples/speech_recognition/kaldi/kaldi_initializer.py fst_dir=$target_dir/fst/phn_to_phn_sil lm_arpa=$target_dir/phones/lm.phones.filtered.06.arpa data_dir=$target_dir/phones &quot;blank_symbol=&#39;&lt;SIL&gt;&#39;&quot; &quot;in_labels=&#39;phn&#39;&quot; &quot;kaldi_root=&#39;/opt/kaldi&#39;&quot; . Overwriting prepare_text.sh . add-self-loop-simple.cc attempts to use std::endl with KALDI_LOG, which doesn&#39;t work, so rewrite that (I&#39;m not sure if this actually prevents anything from working, but it is really distracting). . %%writefile /tmp/fairseq/examples/speech_recognition/kaldi/add-self-loop-simple.cc /* * Copyright (c) Facebook, Inc. and its affiliates. * * This source code is licensed under the MIT license found in the * LICENSE file in the root directory of this source tree. */ #include &lt;iostream&gt; #include &quot;fstext/fstext-lib.h&quot; // @manual #include &quot;util/common-utils.h&quot; // @manual /* * This program is to modify a FST without self-loop by: * for each incoming arc with non-eps input symbol, add a self-loop arc * with that non-eps symbol as input and eps as output. * * This is to make sure the resultant FST can do deduplication for repeated * symbols, which is very common in acoustic model * */ namespace { int32 AddSelfLoopsSimple(fst::StdVectorFst* fst) { typedef fst::MutableArcIterator&lt;fst::StdVectorFst&gt; IterType; int32 num_states_before = fst-&gt;NumStates(); fst::MakePrecedingInputSymbolsSame(false, fst); int32 num_states_after = fst-&gt;NumStates(); KALDI_LOG &lt;&lt; &quot;There are &quot; &lt;&lt; num_states_before &lt;&lt; &quot; states in the original FST; &quot; &lt;&lt; &quot; after MakePrecedingInputSymbolsSame, there are &quot; &lt;&lt; num_states_after &lt;&lt; &quot; states &quot;; auto weight_one = fst::StdArc::Weight::One(); int32 num_arc_added = 0; fst::StdArc self_loop_arc; self_loop_arc.weight = weight_one; int32 num_states = fst-&gt;NumStates(); std::vector&lt;std::set&lt;int32&gt;&gt; incoming_non_eps_label_per_state(num_states); for (int32 state = 0; state &lt; num_states; state++) { for (IterType aiter(fst, state); !aiter.Done(); aiter.Next()) { fst::StdArc arc(aiter.Value()); if (arc.ilabel != 0) { incoming_non_eps_label_per_state[arc.nextstate].insert(arc.ilabel); } } } for (int32 state = 0; state &lt; num_states; state++) { if (!incoming_non_eps_label_per_state[state].empty()) { auto&amp; ilabel_set = incoming_non_eps_label_per_state[state]; for (auto it = ilabel_set.begin(); it != ilabel_set.end(); it++) { self_loop_arc.ilabel = *it; self_loop_arc.olabel = 0; self_loop_arc.nextstate = state; fst-&gt;AddArc(state, self_loop_arc); num_arc_added++; } } } return num_arc_added; } void print_usage() { std::cout &lt;&lt; &quot;add-self-loop-simple usage: n&quot; &quot; tadd-self-loop-simple &lt;in-fst&gt; &lt;out-fst&gt; n&quot;; } } // namespace int main(int argc, char** argv) { if (argc != 3) { print_usage(); exit(1); } auto input = argv[1]; auto output = argv[2]; auto fst = fst::ReadFstKaldi(input); auto num_states = fst-&gt;NumStates(); KALDI_LOG &lt;&lt; &quot;Loading FST from &quot; &lt;&lt; input &lt;&lt; &quot; with &quot; &lt;&lt; num_states &lt;&lt; &quot; states.&quot;; int32 num_arc_added = AddSelfLoopsSimple(fst); KALDI_LOG &lt;&lt; &quot;Adding &quot; &lt;&lt; num_arc_added &lt;&lt; &quot; self-loop arcs &quot;; fst::WriteFstKaldi(*fst, std::string(output)); KALDI_LOG &lt;&lt; &quot;Writing FST to &quot; &lt;&lt; output; delete fst; } . Overwriting /tmp/fairseq/examples/speech_recognition/kaldi/add-self-loop-simple.cc . !zsh prepare_text.sh sv /kaggle/working/sentences.txt /kaggle/working/preppedtext . sv sv /kaggle/working/sentences.txt /kaggle/working/preppedtext === 1/5 Counting and sorting n-grams === Reading /kaggle/working/preppedtext/lm.upper.lid.txt -5101520253035404550556065707580859095--100 **************************************************************************************************** Unigram tokens 14359 types 3160 === 2/5 Calculating and sorting adjusted counts === Chain sizes: 1:37920 2:2571431424 3:4821433856 4:7714294272 Statistics: 1 3160 D1=0.722623 D2=1.14413 D3+=1.45956 2 10285 D1=0.848104 D2=1.2466 D3+=1.46191 3 12632 D1=0.943362 D2=1.24166 D3+=1.32723 4 19/11699 D1=0.970399 D2=1.4843 D3+=2.12351 Memory estimate for binary LM: type kB probing 617 assuming -p 1.5 probing 764 assuming -r models -p 1.5 trie 309 without quantization trie 182 assuming -q 8 -b 8 quantization trie 293 assuming -a 22 array pointer compression trie 166 assuming -a 22 -q 8 -b 8 array pointer compression and quantization === 3/5 Calculating and sorting initial probabilities === Chain sizes: 1:37920 2:164560 3:252640 4:456 -5101520253035404550556065707580859095--100 #################################################################################################### === 4/5 Calculating and writing order-interpolated probabilities === Chain sizes: 1:37920 2:164560 3:252640 4:456 -5101520253035404550556065707580859095--100 #################################################################################################### === 5/5 Writing ARPA model === -5101520253035404550556065707580859095--100 **************************************************************************************************** Name:lmplz VmPeak:14925024 kB VmRSS:6488 kB RSSMax:2975268 kB user:0.194576 sys:0.839708 CPU:1.03431 real:1.03864 Reading /kaggle/working/preppedtext/kenlm.wrd.o40003.arpa -5101520253035404550556065707580859095--100 **************************************************************************************************** SUCCESS [2021-05-30 15:50:13,771][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words_sil/kaldi_dict.phn.txt [2021-05-30 15:50:13,771][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words_sil/G_kenlm.wrd.o40003.fst /opt/kaldi/src/lmbin/arpa2fst --disambig-symbol=#0 --write-symbol-table=/kaggle/working/preppedtext/fst/phn_to_words_sil/kaldi_dict.kenlm.wrd.o40003.txt /kaggle/working/preppedtext/kenlm.wrd.o40003.arpa /kaggle/working/preppedtext/fst/phn_to_words_sil/G_kenlm.wrd.o40003.fst LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:94) Reading data section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 1-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 2-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 3-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 4-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:RemoveRedundantStates():arpa-lm-compiler.cc:359) Reduced num-states from 22665 to 12144 [2021-05-30 15:50:13,918][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words_sil/kaldi_lexicon.phn.kenlm.wrd.o40003.txt (in units file: /kaggle/working/preppedtext/fst/phn_to_words_sil/kaldi_dict.phn.txt) [2021-05-30 15:50:14,005][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words_sil/H.phn.fst [2021-05-30 15:50:14,045][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words_sil/L.phn.kenlm.wrd.o40003.fst (in units: /kaggle/working/preppedtext/fst/phn_to_words_sil/kaldi_dict.phn_disambig.txt) [2021-05-30 15:50:14,244][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words_sil/LG.phn.kenlm.wrd.o40003.fst [2021-05-30 15:50:15,269][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words_sil/HLGa.phn.kenlm.wrd.o40003.fst [2021-05-30 15:50:17,600][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words_sil/HLG.phn.kenlm.wrd.o40003.fst [2021-05-30 15:50:26,782][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words/kaldi_dict.phn.txt [2021-05-30 15:50:26,783][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words/G_kenlm.wrd.o40003.fst /opt/kaldi/src/lmbin/arpa2fst --disambig-symbol=#0 --write-symbol-table=/kaggle/working/preppedtext/fst/phn_to_words/kaldi_dict.kenlm.wrd.o40003.txt /kaggle/working/preppedtext/kenlm.wrd.o40003.arpa /kaggle/working/preppedtext/fst/phn_to_words/G_kenlm.wrd.o40003.fst LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:94) Reading data section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 1-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 2-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 3-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 4-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:RemoveRedundantStates():arpa-lm-compiler.cc:359) Reduced num-states from 22665 to 12144 [2021-05-30 15:50:26,992][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words/kaldi_lexicon.phn.kenlm.wrd.o40003.txt (in units file: /kaggle/working/preppedtext/fst/phn_to_words/kaldi_dict.phn.txt) [2021-05-30 15:50:27,047][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words/H.phn.fst [2021-05-30 15:50:27,088][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words/L.phn.kenlm.wrd.o40003.fst (in units: /kaggle/working/preppedtext/fst/phn_to_words/kaldi_dict.phn_disambig.txt) [2021-05-30 15:50:27,281][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words/LG.phn.kenlm.wrd.o40003.fst [2021-05-30 15:50:28,293][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words/HLGa.phn.kenlm.wrd.o40003.fst [2021-05-30 15:50:31,245][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words/HLG.phn.kenlm.wrd.o40003.fst === 1/5 Counting and sorting n-grams === Reading /kaggle/working/preppedtext/phones/lm.phones.filtered.txt -5101520253035404550556065707580859095--100 **************************************************************************************************** Unigram tokens 63676 types 44 === 2/5 Calculating and sorting adjusted counts === Chain sizes: 1:528 2:2571437824 3:4821446144 4:7714313728 Substituting fallback discounts for order 0: D1=0.5 D2=1 D3+=1.5 Statistics: 1 44 D1=0.5 D2=1 D3+=1.5 2 1053 D1=0.421189 D2=1.06361 D3+=1.49793 3 8534 D1=0.558099 D2=1.17765 D3+=1.45173 4 23058 D1=0.643934 D2=1.15876 D3+=1.53884 Memory estimate for binary LM: type kB probing 631 assuming -p 1.5 probing 687 assuming -r models -p 1.5 trie 203 without quantization trie 88 assuming -q 8 -b 8 quantization trie 196 assuming -a 22 array pointer compression trie 81 assuming -a 22 -q 8 -b 8 array pointer compression and quantization === 3/5 Calculating and sorting initial probabilities === Chain sizes: 1:528 2:16848 3:170680 4:553392 -5101520253035404550556065707580859095--100 #################################################################################################### === 4/5 Calculating and writing order-interpolated probabilities === Chain sizes: 1:528 2:16848 3:170680 4:553392 -5101520253035404550556065707580859095--100 #################################################################################################### === 5/5 Writing ARPA model === -5101520253035404550556065707580859095--100 **************************************************************************************************** Name:lmplz VmPeak:14916784 kB VmRSS:7056 kB RSSMax:2973864 kB user:0.209899 sys:0.716931 CPU:0.926881 real:0.936705 Reading /kaggle/working/preppedtext/phones/lm.phones.filtered.04.arpa -5101520253035404550556065707580859095--100 **************************************************************************************************** SUCCESS === 1/5 Counting and sorting n-grams === Reading /kaggle/working/preppedtext/phones/lm.phones.filtered.txt -5101520253035404550556065707580859095--100 **************************************************************************************************** Unigram tokens 63676 types 44 === 2/5 Calculating and sorting adjusted counts === Chain sizes: 1:528 2:929673728 3:1743138176 4:2789021184 5:4067322624 6:5578042368 Substituting fallback discounts for order 0: D1=0.5 D2=1 D3+=1.5 Statistics: 1 44 D1=0.5 D2=1 D3+=1.5 2 1053 D1=0.421189 D2=1.06361 D3+=1.49793 3 8534 D1=0.558099 D2=1.17765 D3+=1.45173 4 23058 D1=0.704256 D2=1.25425 D3+=1.63465 5 35879 D1=0.821218 D2=1.34714 D3+=1.61281 6 43593 D1=0.834579 D2=1.24241 D3+=1.56972 Memory estimate for binary LM: type kB probing 2373 assuming -p 1.5 probing 2775 assuming -r models -p 1.5 trie 907 without quantization trie 401 assuming -q 8 -b 8 quantization trie 838 assuming -a 22 array pointer compression trie 331 assuming -a 22 -q 8 -b 8 array pointer compression and quantization === 3/5 Calculating and sorting initial probabilities === Chain sizes: 1:528 2:16848 3:170680 4:553392 5:1004612 6:1394976 -5101520253035404550556065707580859095--100 #################################################################################################### === 4/5 Calculating and writing order-interpolated probabilities === Chain sizes: 1:528 2:16848 3:170680 4:553392 5:1004612 6:1394976 -5101520253035404550556065707580859095--100 #################################################################################################### === 5/5 Writing ARPA model === -5101520253035404550556065707580859095--100 **************************************************************************************************** Name:lmplz VmPeak:14949572 kB VmRSS:6500 kB RSSMax:2354520 kB user:0.256512 sys:0.588288 CPU:0.84484 real:0.81585 Reading /kaggle/working/preppedtext/phones/lm.phones.filtered.06.arpa -5101520253035404550556065707580859095--100 **************************************************************************************************** SUCCESS [2021-05-30 15:50:35,812][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_phn_sil/kaldi_dict.phn.txt [2021-05-30 15:50:35,812][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_phn_sil/G_lm.phones.filtered.06.fst /opt/kaldi/src/lmbin/arpa2fst --disambig-symbol=#0 --write-symbol-table=/kaggle/working/preppedtext/fst/phn_to_phn_sil/kaldi_dict.lm.phones.filtered.06.txt /kaggle/working/preppedtext/phones/lm.phones.filtered.06.arpa /kaggle/working/preppedtext/fst/phn_to_phn_sil/G_lm.phones.filtered.06.fst LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:94) Reading data section. LOG (arpa2fst[5.5.0~1-2b62]:HeaderAvailable():arpa-lm-compiler.cc:300) Reverting to slower state tracking because model is large: 6-gram with symbols up to 47 LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 1-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 2-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 3-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 4-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 5-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 6-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:RemoveRedundantStates():arpa-lm-compiler.cc:359) Reduced num-states from 67529 to 67528 [2021-05-30 15:50:36,696][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_phn_sil/kaldi_lexicon.phn.lm.phones.filtered.06.txt (in units file: /kaggle/working/preppedtext/fst/phn_to_phn_sil/kaldi_dict.phn.txt) [2021-05-30 15:50:36,713][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_phn_sil/H.phn.fst [2021-05-30 15:50:36,754][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_phn_sil/L.phn.lm.phones.filtered.06.fst (in units: /kaggle/working/preppedtext/fst/phn_to_phn_sil/kaldi_dict.phn_disambig.txt) [2021-05-30 15:50:36,802][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_phn_sil/LG.phn.lm.phones.filtered.06.fst [2021-05-30 15:50:37,700][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_phn_sil/HLGa.phn.lm.phones.filtered.06.fst [2021-05-30 15:50:40,759][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_phn_sil/HLG.phn.lm.phones.filtered.06.fst .",
            "url": "https://jimregan.github.io/notes/kaggle/wav2vec-u/2021/05/26/wav2vec-u-cv-swedish-text-prep.html",
            "relUrl": "/kaggle/wav2vec-u/2021/05/26/wav2vec-u-cv-swedish-text-prep.html",
            "date": " â€¢ May 26, 2021"
        }
        
    
  
    
        ,"post155": {
            "title": "wav2vec-u Common Voice Swedish - prepare ltr/phn/wrd",
            "content": "Original here . In the section Preparation of speech and text data of the readme, it says: . Similar to wav2vec 2.0, data folders contain {train,valid,test}.{tsv,wrd,phn} files, where audio paths are stored in tsv files, and word, letter or phoneme transcriptions are stored in .{wrd,ltr,phn}. The .wrd and .ltr files are outputs of libri_labels.py . %%capture !pip install phonemizer . %%capture !apt-get -y install espeak . %%capture !apt-get -y install zsh . This is just my best guess at what the .wrd files contain - it seems to match up with what libri_labels.py does: given input like . 1272-128104-0000 MISTER QUILTER IS THE APOSTLE OF THE MIDDLE CLASSES AND WE ARE GLAD TO WELCOME HIS GOSPEL . it does &quot; &quot;.join(items[1:]), which is basically the same . !cat /kaggle/input/download-common-voice-swedish/cv-corpus-6.1-2020-12-11/sv-SE/test.tsv | awk -F&#39; t&#39; &#39;{print $3}&#39;|grep -v &#39;^sentence$&#39; | perl -C7 -ane &#39;chomp;$_=lc($_);s/[^ p{L} p{N} p{M}&#39;&quot; &#39;&quot;&#39; -]/ /g;s/ +/ /g;s/ $//;s/^ //;print &quot;$_ n&quot;;&#39; &gt; test.wrd !cat /kaggle/input/download-common-voice-swedish/cv-corpus-6.1-2020-12-11/sv-SE/dev.tsv | awk -F&#39; t&#39; &#39;{print $3}&#39;|grep -v &#39;^sentence$&#39; | perl -C7 -ane &#39;chomp;$_=lc($_);s/[^ p{L} p{N} p{M}&#39;&quot; &#39;&quot;&#39; -]/ /g;s/ +/ /g;s/ $//;s/^ //;print &quot;$_ n&quot;;&#39; &gt; valid.wrd !cat /kaggle/input/download-common-voice-swedish/cv-corpus-6.1-2020-12-11/sv-SE/train.tsv | awk -F&#39; t&#39; &#39;{print $3}&#39;|grep -v &#39;^sentence$&#39; | perl -C7 -ane &#39;chomp;$_=lc($_);s/[^ p{L} p{N} p{M}&#39;&quot; &#39;&quot;&#39; -]/ /g;s/ +/ /g;s/ $//;s/^ //;print &quot;$_ n&quot;;&#39; &gt; train.wrd . for i in [&#39;train&#39;, &#39;test&#39;, &#39;valid&#39;]: with open(f&#39;/kaggle/working/{i}.wrd&#39;, &#39;r&#39;) as inf, open(f&#39;/kaggle/working/{i}.ltr&#39;, &#39;w&#39;) as out: for line in inf.readlines(): print(&quot; &quot;.join(list(line.strip().replace(&quot; &quot;, &quot;|&quot;))) + &quot; |&quot;, file=out) . !head train.ltr . v a d | Ã¤ r | d e t | i | e u r o | d u | s k a | v e t a | a t t | d e t | Ã¤ r | d u | s o m | h a r | f e l | g Ã¥ | n e r | p Ã¥ | k n Ã¤ | f Ã¶ r s t | m Ã¥ s t e | j a g | s l Ã¥ | s Ã¶ n d e r | d e n | d Ã¤ r | s t o r a | s k r o t h Ã¶ g e n | d e t | b l i r | s v Ã¥ r t | v a d | f Ã¶ r | j Ã¤ v l a | f r Ã¥ g a | Ã¤ r | d e t | j a g | Ã¥ t e r v Ã¤ n d e r | i n t e | t i l l | s k i t h Ã¥ l e t | t i t t a | p Ã¥ | s Ã¶ m m a r n a | f e s | d u | p r e c i s | a k t r i s e r | h a r | e t t | b Ã¤ s t | f Ã¶ r e d a t u m | . There are some warnings about switching, so echo the filename first to known where the errors are . !for i in train test valid; do echo $i.wrd; cat $i.wrd | PHONEMIZER_ESPEAK_PATH=$(which espeak) phonemize -o $i.phn -p &#39; &#39; -w &#39;&#39; -l sv -j 70 --language-switch remove-flags ;done . train.wrd [WARNING] 2 utterances containing language switches on lines 254, 1457 [WARNING] extra phones may appear in the &#34;sv&#34; phoneset [WARNING] language switch flags have been removed (applying &#34;remove-flags&#34; policy) test.wrd [WARNING] 1 utterances containing language switches on lines 81 [WARNING] extra phones may appear in the &#34;sv&#34; phoneset [WARNING] language switch flags have been removed (applying &#34;remove-flags&#34; policy) valid.wrd [WARNING] 1 utterances containing language switches on lines 1831 [WARNING] extra phones may appear in the &#34;sv&#34; phoneset [WARNING] language switch flags have been removed (applying &#34;remove-flags&#34; policy) . !cat test.wrd|awk &#39;BEGIN{ln=1}{if(ln==81){print $0};ln++}&#39; !cat train.wrd|awk &#39;BEGIN{ln=1}{if(ln==254||ln==1457){print $0};ln++}&#39; !cat valid.wrd|awk &#39;BEGIN{ln=1}{if(ln==1831){print $0};ln++}&#39; . det Ã¤r taskigt och sÃ¥ unik design internet slutade fungera det finns inget internet . !cat test.phn|awk &#39;BEGIN{ln=1}{if(ln==81){print $0};ln++}&#39; !cat train.phn|awk &#39;BEGIN{ln=1}{if(ln==254||ln==1457){print $0};ln++}&#39; !cat valid.phn|awk &#39;BEGIN{ln=1}{if(ln==1831){print $0};ln++}&#39; . d eË t É›Ë r t a s k Éª É¡ t É” k s oË Éµ n iË k d Éª z aÉª n Éª n t É™ n É› t s l Ê‰ t a d É™ f Éµ n É¡ eË r a d eË t f Éª n s Éª Å‹ É™ t Éª n t É™ n É› t . &quot;design&quot; and &quot;internet&quot; are clearly the English words that are causing the switch in their respective sentences, but I&#39;m not sure what the problem in test.wrd is: &quot;taskigt&quot;? . design /dÉ›Ëˆsajn/ | internet /ËˆÉªntÉ›rnÉ›t/, /ÉªntÉ›rËˆnÉ›t/ | . !echo taskigt|espeak -v sv --ipa 2&gt; /dev/null . (en)tËˆaskÉªÉ¡t(sv) . !cat test.phn|sed -e &#39;s/^ //;s/t a s k Éª É¡ t/t a s k Éª t/&#39; &gt; tmp !mv tmp test.phn !cat train.phn|sed -e &#39;s/^ //;s/d Éª z aÉª n/d É› s a j n/;s/Éª n t É™ n É› t/Éª n t É› r n É› t/&#39; &gt; tmp !mv tmp train.phn !cat valid.phn|sed -e &#39;s/^ //;s/Éª n t É™ n É› t/Éª n t É› r n É› t/&#39; &gt; tmp !mv tmp valid.phn . !for i in train test valid; do cat $i.wrd|tr &#39; &#39; &#39; n&#39;|sort|uniq |grep -v &#39;^internet$&#39;|grep -v &#39;^design$&#39;|grep -v &#39;^taskigt$&#39; &gt; /tmp/$i.wl; cat /tmp/$i.wl | PHONEMIZER_ESPEAK_PATH=$(which espeak) phonemize -o /tmp/$i.wl.phn -p &#39; &#39; -w &#39;&#39; -l sv -j 70 --language-switch remove-flags;paste /tmp/$i.wl /tmp/$i.wl.phn &gt; dict.$i; done !printf &quot;taskigt tt a s k Éª t n&quot; &gt;&gt; dict.test !printf &quot;design td É› s a j n n&quot; &gt;&gt; dict.train !printf &quot;internet tÉª n t É› r n É› t n&quot; &gt;&gt; dict.train !printf &quot;internet tÉª n t É› r n É› t n&quot; &gt;&gt; dict.valid . !for i in dic*;do cat $i |sort &gt; tmp;mv tmp $i;done . cat: valid: No such file or directory .",
            "url": "https://jimregan.github.io/notes/kaggle/wav2vec-u/2021/05/26/wav2vec-u-cv-swedish-prep-ltr-phn-wrd.html",
            "relUrl": "/kaggle/wav2vec-u/2021/05/26/wav2vec-u-cv-swedish-prep-ltr-phn-wrd.html",
            "date": " â€¢ May 26, 2021"
        }
        
    
  
    
        ,"post156": {
            "title": "Attempt to install Merlin on Kaggle",
            "content": "!git clone https://github.com/CSTR-Edinburgh/merlin . Merlin needs bandmat, but there&#39;s an issue with Python 3.7 and Cython, so build it separately: . %%capture !pip install git+https://github.com/MattShannon/bandmat . %cd merlin . /kaggle/working/merlin . %%capture !pip install -r requirements.txt . %cd tools . /kaggle/working/merlin/tools . %%capture !apt-get -y install csh automake autoconf . !./compile_tools.sh . %cd /kaggle/working/merlin . /kaggle/working/merlin . %cd egs/slt_arctic . /kaggle/working/merlin/egs/slt_arctic . !cat README . About the SLT Arctic corpus The CMU_ARCTIC databases were constructed at the Language Technologies Institute at Carnegie Mellon University as phonetically balanced, US English single speaker databases designed for unit selection speech synthesis research. The databases consist of around 1150 utterances carefully selected from out-of-copyright texts from Project Gutenberg. The databses include US English male (bdl) and female (slt) speakers (both experienced voice talent) as well as other accented speakers. Each subdirectory of this directory contains the scripts for a sequence of experiments. s1: To run slt_arctic_demo with WORLD vocoder. s2: To run slt_arctic_demo with MagPhase vocoder (includes acoustic feature extraction). . %cd s1 . /kaggle/working/merlin/egs/slt_arctic/s1 . !ls . 01_setup.sh RESULTS.md scripts 02_prepare_conf_files.sh conf slt_arctic_full_data 03_train_duration_model.sh experiments slt_arctic_full_data.zip 04_train_acoustic_model.sh merlin_synthesis.sh testrefs 05_run_merlin.sh run_demo.sh README.md run_full_voice.sh . !./01_setup.sh . ################################ Usage: Chose any of the below datasets To run on short data: ./01_setup.sh slt_arctic_demo ./01_setup.sh awb_arctic_demo (or) To run on full data: ./01_setup.sh slt_arctic_full ./01_setup.sh awb_arctic_full ./01_setup.sh bdl_arctic_full ################################ . !./01_setup.sh slt_arctic_full . Step 1: downloading data..... % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 247M 100 247M 0 0 23.1M 0 0:00:10 0:00:10 --:--:-- 26.5M unzipping files...... data is ready! Merlin default voice settings configured in conf/global_settings.cfg setup done...! . !./02_prepare_conf_files.sh . ################################ Usage: ./02_prepare_conf_files.sh &lt;path_to_global_conf_file&gt; default path to global conf file: conf/global_settings.cfg Config files will be prepared based on settings in global conf file ################################ . !cat conf/global_settings.cfg . MerlinDir=/kaggle/working/merlin WorkDir=/kaggle/working/merlin/egs/slt_arctic/s1 Voice=slt_arctic_full Labels=state_align QuestionFile=questions-radio_dnn_416.hed Vocoder=WORLD SamplingFreq=16000 FileIDList=file_id_list_full.scp Train=1000 Valid=66 Test=66 . !./02_prepare_conf_files.sh conf/global_settings.cfg . Step 2: preparing config files for acoustic, duration models... Duration configuration settings stored in conf/duration_slt_arctic_full.conf Acoustic configuration settings stored in conf/acoustic_slt_arctic_full.conf preparing config files for synthesis... Duration configuration settings stored in conf/test_dur_synth_slt_arctic_full.conf Acoustic configuration settings stored in conf/test_synth_slt_arctic_full.conf . !./03_train_duration_model.sh . ################################ Usage: ./03_train_duration_model.sh &lt;path_to_duration_conf_file&gt; Default path to duration conf file: conf/duration_slt_arctic_full.conf ################################ . !./03_train_duration_model.sh conf/duration_slt_arctic_full.conf . Step 3: training duration model... Architecture: x86_64 Distribution: Ubuntu 18.04.5 LTS HOSTNAME=37a070d6fe91 USER= PATH: /opt/conda/bin /usr/local/sbin /usr/local/bin /usr/sbin /usr/bin /sbin /bin LD_LIBRARY_PATH: /opt/conda/lib PYTHONPATH: /kaggle/lib/kagglegym /kaggle/lib PYTHONBIN: python MERLIN_THEANO_FLAGS: cuda.root=/usr/local/8.0 floatX=float32 on_unused_input=ignore No GPU is available! Running on CPU... /opt/conda/lib/python3.7/site-packages/theano/configparser.py:255: UserWarning: Theano does not recognise this flag: cuda.root warnings.warn(f&#34;Theano does not recognise this flag: {key}&#34;) Traceback (most recent call last): File &#34;/kaggle/working/merlin/src/run_merlin.py&#34;, line 74, in &lt;module&gt; from models.deep_rnn import DeepRecurrentNetwork File &#34;/kaggle/working/merlin/src/models/deep_rnn.py&#34;, line 9, in &lt;module&gt; from theano.tensor.shared_randomstreams import RandomStreams ModuleNotFoundError: No module named &#39;theano.tensor.shared_randomstreams&#39; .",
            "url": "https://jimregan.github.io/notes/kaggle/merlin/2021/05/26/merlin-attempt.html",
            "relUrl": "/kaggle/merlin/2021/05/26/merlin-attempt.html",
            "date": " â€¢ May 26, 2021"
        }
        
    
  
    
        ,"post157": {
            "title": "wav2vec-u Common Voice Swedish - vad",
            "content": "Original here . %cd /tmp . /tmp . !git clone https://github.com/pytorch/fairseq/ . %cd fairseq/examples/wav2vec/unsupervised . /tmp/fairseq/examples/wav2vec/unsupervised . !git clone https://github.com/zhenghuatan/rVADfast . !cat scripts/vads.py|sed -e &#39;s!/path/to/rVADfast_py_2.0!/tmp/fairseq/examples/wav2vec/unsupervised/rVADfast!&#39; &gt; tmp !mv tmp scripts/vads.py . !for i in train valid test;do cat /kaggle/input/fork-of-wav2vec-u-cv-swedish-tsv/$i.tsv|python scripts/vads.py &gt; /kaggle/working/$i.vads;done . 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2331/2331 [1:01:46&lt;00:00, 1.59s/it] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2019/2019 [53:39&lt;00:00, 1.59s/it] 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2027/2027 [57:26&lt;00:00, 1.70s/it] . !mkdir /kaggle/working/wav !mkdir /kaggle/working/wav/train !mkdir /kaggle/working/wav/test !mkdir /kaggle/working/wav/valid . !for i in train test valid; do python scripts/remove_silence.py --tsv /kaggle/input/fork-of-wav2vec-u-cv-swedish-tsv/$i.tsv --vads /kaggle/working/$i.vads --out /kaggle/working/wav/$i;done .",
            "url": "https://jimregan.github.io/notes/kaggle/wav2vec-u/2021/05/25/wav2vec-u-cv-swedish-vads.html",
            "relUrl": "/kaggle/wav2vec-u/2021/05/25/wav2vec-u-cv-swedish-vads.html",
            "date": " â€¢ May 25, 2021"
        }
        
    
  
    
        ,"post158": {
            "title": "wav2vec-u Common Voice Swedish - prepare tsv",
            "content": "Original here . import soundfile input = { &#39;train&#39;: &#39;/kaggle/input/download-common-voice-swedish/cv-corpus-6.1-2020-12-11/sv-SE/train.tsv&#39;, &#39;test&#39;: &#39;/kaggle/input/download-common-voice-swedish/cv-corpus-6.1-2020-12-11/sv-SE/test.tsv&#39;, &#39;valid&#39;: &#39;/kaggle/input/download-common-voice-swedish/cv-corpus-6.1-2020-12-11/sv-SE/dev.tsv&#39; } for split in input.keys(): with open(input[split], &#39;r&#39;) as tsv: with open(f&#39;/kaggle/working/{split}.tsv&#39;, &#39;w&#39;) as out: print(&#39;/kaggle/input/common-voice-swedish-16bit-wav/&#39;, file=out) for line in tsv.readlines(): data = line.split(&#39; t&#39;) if data[1] == &#39;path&#39;: continue file = data[1] file = file.replace(&#39;.mp3&#39;, &#39;.wav&#39;) path = f&#39;/kaggle/input/common-voice-swedish-16bit-wav/{file}&#39; frames = soundfile.info(path).frames print(&quot;{} t{}&quot;.format(file, frames), file=out) .",
            "url": "https://jimregan.github.io/notes/kaggle/wav2vec-u/2021/05/25/wav2vec-u-cv-swedish-tsv.html",
            "relUrl": "/kaggle/wav2vec-u/2021/05/25/wav2vec-u-cv-swedish-tsv.html",
            "date": " â€¢ May 25, 2021"
        }
        
    
  
    
        ,"post159": {
            "title": "Download Common Voice Swedish",
            "content": "Original notebook here . This link won&#39;t work any more, so you&#39;ll need a fresh link from Common Voice Datasets . !wget &#39;https://mozilla-common-voice-datasets.s3.dualstack.us-west-2.amazonaws.com/cv-corpus-6.1-2020-12-11/sv-SE.tar.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=ASIAQ3GQRTO3KA6TWRBY%2F20210525%2Fus-west-2%2Fs3%2Faws4_request&amp;X-Amz-Date=20210525T103604Z&amp;X-Amz-Expires=43200&amp;X-Amz-Security-Token=FwoGZXIvYXdzEHwaDAOxZbXj8dSCv%2B%2B1%2FyKSBFuQ4WGxxfHEd51rf4QvMe6fipqbY4nXKUe7Hi%2FCoUFR%2BgXEgXjMjzgKih3fiiBllsdJ1w%2BO4dQ6mKmIYdYWwfXWezdctGJ13gGNYRX2RO8EpTEHOcG48Jvc8pF97Wrv4vZ3Kmlo0jf3Y6rKLZ3HHiKbkQBQgCT40vylI0wPZg5pFXZm6o%2B8zXun1NncwAzRtbmsDSuYT0tJ4zLXpzTZhJ0Ln%2F5gZVxPnZv5WleN0sFcYBMsqTnt9hNyaCQFbnQuCv1BfE6m6KBCG8cSc23YN%2FALgcd4EzxvPaIRM%2F0vFjPTHQFuipe3du7u6TW5gJemh0xaJnLczIx7FbmkrWuZ6HXQH77U7S4YQEX3BSLrBhkcIS7QeTv9oZ5D7yfCbRAXc2V2qzVANcAoipgYxP2By0iA0C90t3ggu5YvTwSAnrHxtSDMalsXU6%2BVcEo87VDb2DkOZ9OtpApZdpstX7QXHmC5QdR7Gg7M4aiW9jbZMyAH%2FQAowc2pZHqh%2BrJqySYOLYMWEApqDZ94VaCkuguuXODS25l%2F07IqAaCzT5LO%2FjPyuFBs7nXlDZXZo64295Iu6VDprtvutUvHbxQy6qkiMYT%2Fkt297E%2FsorK9YjNhj17PjtGPx6EW4WZIHLikvpkQ3aEiVN5%2ByLu9sbj8lwdzWnf9mSGp3T5oedv27ARY1SvmWn9uQH1FB6Tet%2ByaM5u1KIBKKJGbs4UGMipKgz7uHdY53WDR2h1mkBlucbyh484Wj%2BldCrqic%2FgIKjqhay57WHKZe2w%3D&amp;X-Amz-Signature=549006bf559d20bba1fbc6523f7b7b02ef8b2b7a68f229b1875bd02336e3c3b6&amp;X-Amz-SignedHeaders=host&#39; -O sv-SE.tar.gz . !tar zxvf sv-SE.tar.gz !rm sv-SE.tar.gz .",
            "url": "https://jimregan.github.io/notes/kaggle/wav2vec-u/2021/05/25/download-common-voice-swedish.html",
            "relUrl": "/kaggle/wav2vec-u/2021/05/25/download-common-voice-swedish.html",
            "date": " â€¢ May 25, 2021"
        }
        
    
  
    
        ,"post160": {
            "title": "Convert Common Voice Swedish to 16bit wav",
            "content": "Original here . !for i in ../input/download-common-voice-swedish/cv-corpus-6.1-2020-12-11/sv-SE/clips/*.mp3;do o=$(basename $i &#39;.mp3&#39;); ffmpeg -i &quot;$i&quot; -acodec pcm_s16le -ac 1 -ar 16000 $o.wav;done .",
            "url": "https://jimregan.github.io/notes/kaggle/wav2vec-u/2021/05/25/common-voice-swedish-16bit-wav.html",
            "relUrl": "/kaggle/wav2vec-u/2021/05/25/common-voice-swedish-16bit-wav.html",
            "date": " â€¢ May 25, 2021"
        }
        
    
  
    
        ,"post161": {
            "title": "Tuairisc question page scraper",
            "content": "import requests from bs4 import BeautifulSoup . url1 = &#39;https://tuairisc.ie/leamhthuiscint-faoiseamh-agus-saoirse-sa-snamh/&#39; . def _get_url(url): r = requests.get(url) if r.status_code != 200: raise Exception(&quot;Failed to open landing page&quot;) return r.content . def _stop_reading(elem): from bs4.element import NavigableString if isinstance(elem, NavigableString): return False elems = [c for c in elem.children] return len(elems) == 1 and elems[0].name == &#39;h2&#39; and &#39; &#39;.join(elems[0][&#39;class&#39;]) == &#39;heading-banner education__banner&#39; . t1 = _get_url(url1) . soup = BeautifulSoup(t1, &#39;html.parser&#39;) . desc = soup.find(&#39;meta&#39;, {&#39;property&#39;: &#39;og:description&#39;})[&#39;content&#39;] title = soup.find(&#39;meta&#39;, {&#39;property&#39;: &#39;og:title&#39;})[&#39;content&#39;] . article_outer = soup.find(&#39;article&#39;) . article = article_outer.find(&#39;div&#39;, {&#39;itemprop&#39;: &#39;articleBody&#39;}) . def _extract_text(article): from bs4.element import NavigableString paragraphs = [] for i in article.children: if isinstance(i, NavigableString): continue if _stop_reading(i): return paragraphs paragraphs.append(i.text.replace(&#39; xa0&#39;, &#39; &#39;)) . def _extract_questions(article): out = [] for p in article.find(&#39;ol&#39;).findAll(&#39;li&#39;): out.append(p.text) return out . qs = _extract_questions(article) . qs . x.findAll(&#39;li&#39;) .",
            "url": "https://jimregan.github.io/notes/irish/tuairisc/incomplete/2021/05/24/tuairisc-question-page-scraper.html",
            "relUrl": "/irish/tuairisc/incomplete/2021/05/24/tuairisc-question-page-scraper.html",
            "date": " â€¢ May 24, 2021"
        }
        
    
  
    
        ,"post162": {
            "title": "Training Kaldi on Kaggle - Data Prep",
            "content": "%cd /opt . /opt . %%capture !tar xvf /kaggle/input/extract-prebuilt-kaldi-from-docker/kaldi.tar . %cd kaldi/egs . /opt/kaldi/egs . !git clone https://github.com/danijel3/ClarinStudioKaldi . Cloning into &#39;ClarinStudioKaldi&#39;... remote: Enumerating objects: 778, done. remote: Counting objects: 100% (3/3), done. remote: Compressing objects: 100% (3/3), done. remote: Total 778 (delta 0), reused 0 (delta 0), pack-reused 775 Receiving objects: 100% (778/778), 35.26 MiB | 19.96 MiB/s, done. Resolving deltas: 100% (262/262), done. . %cd ClarinStudioKaldi . /opt/kaldi/egs/ClarinStudioKaldi . %%capture !conda install -c bioconda perl-perlio-gzip -y . import os os.environ[&#39;LD_LIBRARY_PATH&#39;] = &#39;/opt/conda/lib:/opt/kaldi/tools/openfst-1.6.7/lib:/opt/kaldi/src/lib&#39; . !cat path.sh|sed -e &#39;s/~ /apps/ /opt/&#39; &gt; tmp !mv tmp path.sh . !echo &gt; local_clarin/clarin_pl_clean.sh . !mkdir /kaggle/working/data !ln -s /kaggle/working/data . %%writefile /opt/kaldi/tools/phonetisaurus-g2p/src/scripts/phonetisaurus-apply #!/usr/bin/env python # -*- mode: python; coding: utf-8 -*- from __future__ import print_function from __future__ import unicode_literals import os, logging, subprocess, time, re from datetime import datetime from collections import defaultdict import tempfile class G2PModelTester () : &quot;&quot;&quot;G2P Model training wrapper class. Phonetisaurus G2P modeling training wrapper class. This wraps the alignment, joint n-gram training, and ARPA to WFST conversion steps into one command. &quot;&quot;&quot; def __init__ (self, model, **kwargs) : self.model = model self.lexicon_file = kwargs.get (&quot;lexicon&quot;, None) self.nbest = kwargs.get (&quot;nbest&quot;, 1) self.thresh = kwargs.get (&quot;thresh&quot;, 99) self.beam = kwargs.get (&quot;beam&quot;, 10000) self.greedy = kwargs.get (&quot;greedy&quot;, False) self.accumulate = kwargs.get (&quot;accumulate&quot;, False) self.pmass = kwargs.get (&quot;pmass&quot;, 0.0) self.probs = kwargs.get (&quot;probs&quot;, False) self.verbose = kwargs.get (&quot;verbose&quot;, False) self.logger = self.setupLogger () def setupLogger (self) : &quot;&quot;&quot;Setup the logger and logging level. Setup the logger and logging level. We only support verbose and non-verbose mode. Args: verbose (bool): Verbose mode, or not. Returns: Logger: A configured logger instance. &quot;&quot;&quot; level = logging.DEBUG if self.verbose else logging.INFO logging.basicConfig ( level=level, format=&quot; 033[94m%(levelname)s:%(name)s:&quot; &quot;%(asctime)s 033[0m: %(message)s&quot;, datefmt=&quot;%Y-%m-%d %H:%M:%S&quot; ) return logging.getLogger (&quot;phonetisaurus-apply&quot;) def _loadLexicon (self) : &quot;&quot;&quot;Load the lexicon from a file. Load the reference lexicon from a file, and store it in a defaultdict (list). &quot;&quot;&quot; _lexicon = defaultdict (list) if not self.lexicon_file : return _lexicon self.logger.debug (&quot;Loading lexicon from file...&quot;) with open (self.lexicon_file, &quot;r&quot;) as ifp : for line in ifp : # py2py3 compatbility, if sys.version_info[0] &lt; 3: line = line.decode(&quot;utf8&quot;).strip () else: line = line.strip () word, pron = re.split (r&quot; t&quot;, line, 1) _lexicon [word].append (pron) return _lexicon def checkPhonetisaurusConfig (self) : &quot;&quot;&quot;Run some basic checks before training. Run some basic checks regarding the $PATH, environment, and provided data before starting training. Raises: EnvironmentError: raised if binaries are not found. &quot;&quot;&quot; self.logger.debug (&quot;Checking command configuration...&quot;) for program in [&quot;phonetisaurus-g2pfst&quot;] : if not self.which (program) : raise EnvironmentError(&quot;Phonetisaurus command, &#39;{0}&#39;, &quot; &quot;not found in path.&quot;.format (program)) if self.lexicon_file and not os.path.exists (self.lexicon_file) : self.logger.error (&quot;Could not find provided lexicon file.&quot;) sys.exit (1) for key,val in sorted (vars (self).items ()) : self.logger.debug (u&quot;{0}: {1}&quot;.format (key, val)) self.lexicon = self._loadLexicon () return def which (self, program) : &quot;&quot;&quot;Basic &#39;which&#39; implementation for python. Basic &#39;which&#39; implementation for python from stackoverflow: * https://stackoverflow.com/a/377028/6739158 Args: program (str): The program name to search the $PATH for. Returns: path/None: The path to the executable, or None. &quot;&quot;&quot; def is_exe (fpath) : return os.path.isfile (fpath) and os.access (fpath, os.X_OK) fpath, fname = os.path.split (program) if fpath: if is_exe (program): return program else: for path in os.environ[&quot;PATH&quot;].split (os.pathsep) : path = path.strip (&#39;&quot;&#39;) exe_file = os.path.join (path, program) if is_exe (exe_file): return exe_file return None def makeG2PCommand (self, word_list) : &quot;&quot;&quot;Build the G2P command. Build the G2P command from the provided arguments. Returns: list: The command in subprocess list format. &quot;&quot;&quot; command = [ u&quot;phonetisaurus-g2pfst&quot;, u&quot;--model={0}&quot;.format (self.model), u&quot;--nbest={0}&quot;.format (self.nbest), u&quot;--beam={0}&quot;.format (self.beam), u&quot;--thresh={0}&quot;.format (self.thresh), u&quot;--accumulate={0}&quot;.format (str (self.accumulate).lower ()), u&quot;--pmass={0}&quot;.format (self.pmass), u&quot;--nlog_probs={0}&quot;.format (str(not self.probs).lower ()), u&quot;--wordlist={0}&quot;.format (word_list) ] self.logger.debug (u&quot; &quot;.join (command)) return command def runG2PCommand (self, word_list_file) : &quot;&quot;&quot;Generate and run the actual G2P command. Generate and run the actual G2P command. Each synthesized entry will be yielded back on-the-fly via the subprocess stdout readline method. Args: word_list_file (str): The input word list. &quot;&quot;&quot; g2p_command = self.makeG2PCommand (word_list_file) self.logger.debug (&quot;Applying G2P model...&quot;) with open (os.devnull, &quot;w&quot;) as devnull : proc = subprocess.Popen ( g2p_command, stdout=subprocess.PIPE, stderr=devnull if not self.verbose else None ) for line in proc.stdout : parts = re.split (r&quot; t&quot;, line.decode (&quot;utf8&quot;).strip ()) if not len (parts) == 3 : self.logger.warning ( u&quot;No pronunciation for word: &#39;{0}&#39;&quot;.format (parts [0]) ) continue yield parts return def applyG2POnly (self, word_list_file) : &quot;&quot;&quot;Apply the G2P model to a word list. Apply the G2P model to a word list. No filtering or application of a reference lexicon is used here. Args: word_list_file (str): The input word list. &quot;&quot;&quot; for word, score, pron in self.runG2PCommand (word_list_file) : line = u&quot;&quot; if self.verbose : line = u&quot;{0} t{1:.2f} t{2}&quot;.format ( word, float (score), pron ) else : line = u&quot;{0} t{1}&quot;.format (word, pron) # py2py3 compatbility, if sys.version_info[0] &lt; 3: print (line.encode (&quot;utf8&quot;)) else : print (line) return def applyG2PWithLexicon (self, word_list_file) : &quot;&quot;&quot;Apply the G2P model to a word list, combined with lexicon. Apply the G2P model to a word list, but combine this with a reference lexicon. Words for which a reference entry exists will not be sent to the G2P, unless the additional &#39;--greedy&#39; flag is set to True. Args: word_list_file (str): The input word list. &quot;&quot;&quot; target_lexicon = defaultdict (list) tmpwordlist = tempfile.NamedTemporaryFile(mode=&#39;w&#39;, delete=False) #First, find any words in the target list for which we already # have a canonical pronunciation in the reference lexicon. with open (word_list_file, &quot;r&quot;) as ifp : for word in ifp : # py2py3 compatbility, if sys.version_info[0] &lt; 3: word = word.decode (&quot;utf8&quot;).strip () else: word = word.strip () # already in &#39;utf8&#39;. if word in self.lexicon : target_lexicon [word] = [(0.0,pron) for pron in self.lexicon [word]] #In greedy mode we still send words to the G2P, even # if we have canonical entries in the reference lexicon. if self.greedy : print (word.encode (&quot;utf8&quot;), file=tmpwordlist) else : # py2py3 compatbility, if sys.version_info[0] &lt; 3: print (word.encode (&quot;utf8&quot;), file=tmpwordlist) else: print (word, file=tmpwordlist) tmpwordlist.close () #Second, iterate through the G2P output, and filter against # any possible duplicates previously found in the reference lexicon. for word, score, pron in self.runG2PCommand (tmpwordlist.name) : prons = set ([p for s,p in target_lexicon [word]]) if pron in prons : continue target_lexicon [word].append ((score, pron)) #Finally, sort everything that is left and print it. for word in sorted (target_lexicon.keys ()) : for score, pron in target_lexicon [word] : line = u&quot;&quot; if self.verbose : line = u&quot;{0} t{1:.2f} t{2}&quot;.format ( word, float (score), pron ) else : line = u&quot;{0} t{1}&quot;.format (word, pron) # py2py3 compatbility, if sys.version_info[0] &lt; 3: print (line.encode (&quot;utf8&quot;)) else : print (line) os.unlink (tmpwordlist.name) return def ApplyG2PModel (self, word_list_file) : &quot;&quot;&quot;Apply the G2P model to a word list. Apply the G2P model to a word list. Args: word_list_file (str): The input word list. &quot;&quot;&quot; self.checkPhonetisaurusConfig () if not os.path.exists (word_list_file) or not os.path.isfile (word_list_file) : raise IOError(&quot;Word list file not found.&quot;) if len (self.lexicon) == 0 : self.applyG2POnly (word_list_file) else : self.applyG2PWithLexicon (word_list_file) return if __name__ == &quot;__main__&quot; : import sys, argparse example = &quot;{0} --model train/model.fst --word test&quot;.format (sys.argv [0]) parser = argparse.ArgumentParser (description=example) parser.add_argument (&quot;--model&quot;, &quot;-m&quot;, help=&quot;Phonetisaurus G2P fst model.&quot;, required=True) parser.add_argument (&quot;--lexicon&quot;, &quot;-l&quot;, help=&quot;Optional reference lexicon.&quot;, required=False) parser.add_argument (&quot;--nbest&quot;, &quot;-n&quot;, help=&quot;Maximum number of hypotheses &quot; &quot;to produce. Overridden if --pmass is set.&quot;, default=1, type=int) parser.add_argument (&quot;--beam&quot;, &quot;-b&quot;, help=&quot;Search &#39;beam&#39;.&quot;, default=10000, type=int) parser.add_argument (&quot;--thresh&quot;, &quot;-t&quot;, help=&quot;Pruning threshold for n-best.&quot;, default=99.0, type=float) parser.add_argument (&quot;--greedy&quot;, &quot;-g&quot;, help=&quot;Use the G2P even if a &quot; &quot;reference lexicon has been provided.&quot;, default=False, action=&quot;store_true&quot;) parser.add_argument (&quot;--accumulate&quot;, &quot;-a&quot;, help=&quot;Accumulate probabilities &quot; &quot;across unique pronunciations.&quot;, default=False, action=&quot;store_true&quot;) parser.add_argument (&quot;--pmass&quot;, &quot;-p&quot;, help=&quot;Select the maximum number of &quot; &quot;hypotheses summing to P total mass for a word.&quot;, default=0.0, type=float) parser.add_argument (&quot;--probs&quot;, &quot;-pr&quot;, help=&quot;Print exp(-val) &quot; &quot;instead of default -log values.&quot;, default=False, action=&quot;store_true&quot;) parser.add_argument (&quot;--word_list&quot;, &quot;-wl&quot;, help=&quot;Input word or word list to apply &quot; &quot;G2P model to.&quot;, type=str) parser.add_argument (&quot;--verbose&quot;, &quot;-v&quot;, help=&quot;Verbose mode.&quot;, default=False, action=&quot;store_true&quot;) args = parser.parse_args () tester = G2PModelTester ( args.model, **{key:val for key,val in args.__dict__.items () if not key in [&quot;model&quot;,&quot;word_list&quot;]} ) tester.ApplyG2PModel (args.word_list) . Overwriting /opt/kaldi/tools/phonetisaurus-g2p/src/scripts/phonetisaurus-apply . !chmod a+x /opt/kaldi/tools/phonetisaurus-g2p/src/scripts/phonetisaurus-apply . %%writefile local_clarin/clarin_prepare_dict.sh #!/bin/bash # Copyright 2010-2012 Microsoft Corporation # 2012-2014 Johns Hopkins University (Author: Daniel Povey) # 2015 Guoguo Chen # Modified 2017 Danijel Korzinek # Licensed under the Apache License, Version 2.0 (the &quot;License&quot;); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # THIS CODE IS PROVIDED *AS IS* BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY # KIND, EITHER EXPRESS OR IMPLIED, INCLUDING WITHOUT LIMITATION ANY IMPLIED # WARRANTIES OR CONDITIONS OF TITLE, FITNESS FOR A PARTICULAR PURPOSE, # MERCHANTABLITY OR NON-INFRINGEMENT. # See the Apache 2 License for the specific language governing permissions and # limitations under the License. # Call this script from one level above, e.g. from the s3/ directory. It puts # its output in data/local/. # The parts of the output of this that will be needed are # [in data/local/dict/ ] # lexicon.txt # extra_questions.txt # nonsilence_phones.txt # optional_silence.txt # silence_phones.txt # run this from ../ echo &quot;$0 $@&quot; # Print the command line for logging . utils/parse_options.sh || exit 1; . ./path.sh if [ $# -ne 2 ]; then echo &quot;Usage: ./local/prepare_lang.sh &lt;word_list&gt; &lt;dict_dir&gt;&quot; echo &quot;Creates a folder &lt;dict_dir&gt; with lexicon derived from&quot; echo &quot; word list &lt;word_list&gt;.&quot; exit 1 fi word_list=$1 dir=$2 mkdir -p $dir # Make phones symbol-table (adding in silence and verbal and non-verbal noises at this point). # We are adding suffixes _B, _E, _S for beginning, ending, and singleton phones. # silence phones, one per line. (echo sil) &gt; $dir/silence_phones.txt echo sil &gt; $dir/optional_silence.txt # nonsilence phones; on each line is a list of phones that correspond # really to the same base phone. printf &quot;I nS nZ na nb nd ndZ ndz ndzi ne nen nf ng ni nj nk nl nm nn nni no non np nr ns nsi nt ntS nts ntsi nu nv nw nx nz nzi n&quot; &gt; $dir/nonsilence_phones.txt # A few extra questions that will be added to those obtained by automatically clustering # the &quot;real&quot; phones. These ask about stress; there&#39;s also one for silence. cat $dir/silence_phones.txt| awk &#39;{printf(&quot;%s &quot;, $1);} END{printf &quot; n&quot;;}&#39; &gt; $dir/extra_questions.txt || exit 1; cat $dir/nonsilence_phones.txt | perl -e &#39;while(&lt;&gt;){ foreach $p (split(&quot; &quot;, $_)) { $p =~ m:^([^ d]+)( d*)$: || die &quot;Bad phone $_&quot;; $q{$2} .= &quot;$p &quot;; } } foreach $l (values %q) {print &quot;$l n&quot;;}&#39; &gt;&gt; $dir/extra_questions.txt || exit 1; #Transcribe the wordlist export LD_LIBRARY_PATH=$KALDI_ROOT/tools/openfst/lib export PATH=$PATH:/opt/kaldi/tools/phonetisaurus-g2p/ /opt/kaldi/tools/phonetisaurus-g2p/src/scripts/phonetisaurus-apply --model local_clarin/model.fst --lexicon local_clarin/lexicon.txt --word_list $word_list -p 0.8 &gt; $dir/lexicon_raw_nosil.txt || exit 1 sort -u $dir/lexicon_raw_nosil.txt -o $dir/lexicon_raw_nosil.txt # Add the silences, noises etc. # the sort | uniq is to remove a duplicated pron. # lexicon.txt is without the _B, _E, _S, _I markers. (echo -e &#39;&lt;unk&gt; tsil&#39; ) | cat - $dir/lexicon_raw_nosil.txt | sort -u &gt; $dir/lexicon.txt || exit 1; # Cleanup rm -f $dir/lexiconp.txt rm -f $dir/lexicon_raw_nosil.txt echo &quot;Dictionary preparation succeeded&quot; . Overwriting local_clarin/clarin_prepare_dict.sh . %%writefile local_clarin/clarin_pl_data_prep.sh #!/bin/bash . ./path.sh #you can change this here, if you want it on a different partition, for example AUDIO_DL_PATH=audio if [ ! -d $AUDIO_DL_PATH ] ; then mkdir -p $AUDIO_DL_PATH ; fi pushd $AUDIO_DL_PATH if [ ! -f audio.tar.gz ] ; then echo &quot;Downloading audio from the Clarin-pl website (~4.6GB)...&quot; curl -O http://mowa.clarin-pl.eu/korpusy/audio.tar.gz else echo &quot;File already downloaded! Checking if download is consistent...&quot; curl -O http://mowa.clarin-pl.eu/korpusy/audio.md5sum if ! md5sum -c audio.md5sum ; then echo &quot;Download doesn&#39;t match the one on the server! &quot; echo &quot;Erase the audio.tar.gz file (and audio folder) and run this script again!&quot; exit -1 fi fi if [ ! -d audio ] ; then echo &quot;Extracting files...&quot; tar xf audio.tar.gz else echo &quot;Files already extracted?&quot; echo &quot;Remove the audio dir to extract them again...&quot; fi popd if [ ! -d data ] ; then mkdir data ; fi echo Generating file lists using proper paths... python3 local_clarin/generate_lists.py $AUDIO_DL_PATH/audio data local_clarin echo Generating spk2utt... utils/utt2spk_to_spk2utt.pl data/train/utt2spk &gt; data/train/spk2utt utils/utt2spk_to_spk2utt.pl data/test/utt2spk &gt; data/test/spk2utt utils/utt2spk_to_spk2utt.pl data/dev/utt2spk &gt; data/dev/spk2utt echo Preparing dictionary... if [ ! -d data/local ] ; then mkdir data/local ; fi cut -f2- -d&#39; &#39; &lt; data/train/text | tr &#39; &#39; &#39; n&#39; | sort -u &gt; data/local/train.wlist if [ x&quot;$(which ngram)&quot; != x&quot;&quot; ] then ngram -lm local_clarin/arpa.lm.gz -unk -write-vocab data/local/lm.wlist else perl local_clarin/extract_vocab.pl local_clarin/arpa.lm.gz &gt; data/local/lm.wlist fi tail -n +5 data/local/lm.wlist | cat data/local/train.wlist - | sort -u &gt; data/local/all.wlist if [ ! -f local_clarin/model.fst ] ; then gunzip -c local_clarin/model.fst.gz &gt; local_clarin/model.fst ; fi local_clarin/clarin_prepare_dict.sh data/local/all.wlist data/local/dict_nosp || exit 1 . Overwriting local_clarin/clarin_pl_data_prep.sh . %%writefile runmfcc.sh #!/bin/bash . ./path.sh ## set the paths in this file correctly! # link to scripts from the standard Kaldi distribution # we try to use these as much as possible if [ ! -f $KALDI_ROOT/egs/wsj/s5/conf ] ; then ln -s $KALDI_ROOT/egs/wsj/s5/conf ; fi if [ ! -f $KALDI_ROOT/egs/wsj/s5/local ] ; then ln -s $KALDI_ROOT/egs/wsj/s5/local ; fi if [ ! -f $KALDI_ROOT/egs/wsj/s5/utils ] ; then ln -s $KALDI_ROOT/egs/wsj/s5/utils ; fi if [ ! -f $KALDI_ROOT/egs/wsj/s5/steps ] ; then ln -s $KALDI_ROOT/egs/wsj/s5/steps ; fi # exits script if error occurs anywhere # you might not want to do this for interactive shells. set -e export nj=40 ##number of concurrent processes export nj_test=30 ## number of concurrent processes for test has to be &lt;=30 # This is a shell script, but it&#39;s recommended that you run the commands one by # one by copying and pasting into the shell. #run some initial data preparation (look at the file for more details): local_clarin/clarin_pl_data_prep.sh #prepare the lang directory utils/prepare_lang.sh data/local/dict_nosp &quot;&lt;unk&gt;&quot; data/local/tmp_nosp data/lang_nosp #make G.fst utils/format_lm.sh data/lang_nosp local_clarin/arpa.lm.gz data/local/dict_nosp/lexicon.txt data/lang_nosp_test # Make normalized MFCC features. steps/make_mfcc.sh --nj $nj data/train steps/compute_cmvn_stats.sh data/train steps/make_mfcc.sh --nj $nj data/test steps/compute_cmvn_stats.sh data/test . Writing runmfcc.sh . !bash runmfcc.sh .",
            "url": "https://jimregan.github.io/notes/kaggle/kaldi/2021/05/24/kaldi-clarinstudio-polish-data-prep.html",
            "relUrl": "/kaggle/kaldi/2021/05/24/kaldi-clarinstudio-polish-data-prep.html",
            "date": " â€¢ May 24, 2021"
        }
        
    
  
    
        ,"post163": {
            "title": "Kaldi on Kaggle, ClarinStudio PL Mono iters 30-40",
            "content": "%cd /opt . /opt . %%capture !tar xvf /kaggle/input/extract-prebuilt-kaldi-from-docker/kaldi.tar . %cd kaldi/egs . /opt/kaldi/egs . !git clone https://github.com/danijel3/ClarinStudioKaldi . Cloning into &#39;ClarinStudioKaldi&#39;... remote: Enumerating objects: 778, done. remote: Counting objects: 100% (3/3), done. remote: Compressing objects: 100% (3/3), done. remote: Total 778 (delta 0), reused 0 (delta 0), pack-reused 775 Receiving objects: 100% (778/778), 35.26 MiB | 22.14 MiB/s, done. Resolving deltas: 100% (262/262), done. . %cd ClarinStudioKaldi . /opt/kaldi/egs/ClarinStudioKaldi . %%capture !conda install -c bioconda perl-perlio-gzip -y . import os os.environ[&#39;LD_LIBRARY_PATH&#39;] = &#39;/opt/conda/lib:/opt/kaldi/tools/openfst-1.6.7/lib:/opt/kaldi/src/lib&#39; . !cat path.sh|sed -e &#39;s/~ /apps/ /opt/&#39; &gt; tmp !mv tmp path.sh . !echo &gt; local_clarin/clarin_pl_clean.sh . !ln -s ../wsj/s5/steps !ln -s ../wsj/s5/conf !ln -s ../wsj/s5/local !ln -s ../wsj/s5/utils . !cp -r /kaggle/input/kaldi-clarinstudio-polish-train-mono-1-30/data /kaggle/working/ !cp -r /kaggle/input/kaldi-clarinstudio-polish-train-mono-1-30/exp /kaggle/working/ . !ln -s /kaggle/working/exp !ln -s /kaggle/working/data . !find /kaggle/working/exp -name &#39;*.log&#39; -delete . !/opt/kaldi/src/gmmbin/gmm-info --print-args=false exp/mono0/30.mdl | grep gaussians | awk &#39;{print $NF}&#39; . 925 . %%writefile train_mono.sh #!/usr/bin/env bash # Copyright 2012 Johns Hopkins University (Author: Daniel Povey) # 2019 Xiaohui Zhang # Apache 2.0 # Trimmed down from WSJ train_mono.sh, to continue from 30 # Begin configuration section. nj=4 cmd=run.pl scale_opts=&quot;--transition-scale=1.0 --acoustic-scale=0.1 --self-loop-scale=0.1&quot; num_iters=40 # Number of iterations of training max_iter_inc=30 # Last iter to increase #Gauss on. regular_beam=10 # beam used after the first iteration retry_beam=40 totgauss=1000 # Target #Gaussians. careful=false boost_silence=1.0 # Factor by which to boost silence likelihoods in alignment realign_iters=&quot;1 2 3 4 5 6 7 8 9 10 12 14 16 18 20 23 26 29 32 35 38&quot;; config= # name of config file. stage=-4 power=0.25 # End configuration section. echo &quot;$0 $@&quot; # Print the command line for logging if [ -f path.sh ]; then . ./path.sh; fi . parse_options.sh || exit 1; if [ $# != 3 ]; then echo &quot;Usage: steps/train_mono.sh [options] &lt;data-dir&gt; &lt;lang-dir&gt; &lt;exp-dir&gt;&quot; echo &quot; e.g.: steps/train_mono.sh data/train.1k data/lang exp/mono&quot; echo &quot;main options (for others, see top of script file)&quot; echo &quot; --config &lt;config-file&gt; # config containing options&quot; echo &quot; --nj &lt;nj&gt; # number of parallel jobs&quot; echo &quot; --cmd (utils/run.pl|utils/queue.pl &lt;queue opts&gt;) # how to run jobs.&quot; exit 1; fi data=$1 lang=$2 dir=$3 oov_sym=`cat $lang/oov.int` || exit 1; mkdir -p $dir/log echo $nj &gt; $dir/num_jobs sdata=$data/split$nj; [[ -d $sdata &amp;&amp; $data/feats.scp -ot $sdata ]] || split_data.sh $data $nj || exit 1; feats=&quot;ark,s,cs:apply-cmvn $cmvn_opts --utt2spk=ark:$sdata/JOB/utt2spk scp:$sdata/JOB/cmvn.scp scp:$sdata/JOB/feats.scp ark:- | add-deltas $delta_opts ark:- ark:- |&quot; cp $lang/phones.txt $dir || exit 1; numgauss=`gmm-info --print-args=false $dir/0.mdl | grep gaussians | awk &#39;{print $NF}&#39;` incgauss=$[($totgauss-$numgauss)/$max_iter_inc] # per-iter increment for #Gauss # update from last run #numgauss=`gmm-info --print-args=false $dir/30.mdl | grep gaussians | awk &#39;{print $NF}&#39;` #numgauss=925 igauss=1 while [ $igauss -lt 30 ];do numgauss=$[$numgauss+$incgauss]; igauss=$[$igauss+1] done # beam is only set to $initial_beam for first run beam=$regular_beam x=30 while [ $x -lt $num_iters ]; do echo &quot;$0: Pass $x&quot; if [ $stage -le $x ]; then if echo $realign_iters | grep -w $x &gt;/dev/null; then echo &quot;$0: Aligning data&quot; mdl=&quot;gmm-boost-silence --boost=$boost_silence `cat $lang/phones/optional_silence.csl` $dir/$x.mdl - |&quot; $cmd JOB=1:$nj $dir/log/align.$x.JOB.log gmm-align-compiled $scale_opts --beam=$beam --retry-beam=$retry_beam --careful=$careful &quot;$mdl&quot; &quot;ark:gunzip -c $dir/fsts.JOB.gz|&quot; &quot;$feats&quot; &quot;ark,t:|gzip -c &gt;$dir/ali.JOB.gz&quot; || exit 1; fi $cmd JOB=1:$nj $dir/log/acc.$x.JOB.log gmm-acc-stats-ali $dir/$x.mdl &quot;$feats&quot; &quot;ark:gunzip -c $dir/ali.JOB.gz|&quot; $dir/$x.JOB.acc || exit 1; $cmd $dir/log/update.$x.log gmm-est --write-occs=$dir/$[$x+1].occs --mix-up=$numgauss --power=$power $dir/$x.mdl &quot;gmm-sum-accs - $dir/$x.*.acc|&quot; $dir/$[$x+1].mdl || exit 1; rm $dir/$x.mdl $dir/$x.*.acc $dir/$x.occs 2&gt;/dev/null fi if [ $x -le $max_iter_inc ]; then numgauss=$[$numgauss+$incgauss]; fi beam=$regular_beam x=$[$x+1] done ( cd $dir; rm final.{mdl,occs} 2&gt;/dev/null; ln -s $x.mdl final.mdl; ln -s $x.occs final.occs ) steps/diagnostic/analyze_alignments.sh --cmd &quot;$cmd&quot; $lang $dir utils/summarize_warnings.pl $dir/log steps/info/gmm_dir_info.pl $dir echo &quot;$0: Done training monophone system in $dir&quot; exit 0 . Writing train_mono.sh . !bash train_mono.sh --nj 40 data/train data/lang_nosp exp/mono0 .",
            "url": "https://jimregan.github.io/notes/kaldi/kaggle/clarinstudio/2021/05/23/kaldi-clarinstudio-polish-train-mono-30-40.html",
            "relUrl": "/kaldi/kaggle/clarinstudio/2021/05/23/kaldi-clarinstudio-polish-train-mono-30-40.html",
            "date": " â€¢ May 23, 2021"
        }
        
    
  
    
        ,"post164": {
            "title": "Run ffmpeg silence detection on Wolne Lektury audio",
            "content": "Original on Kaggle . !for i in ../input/wolne-lektury-audio-zip/*.zip; do unzip $i -d /tmp; for j in /tmp/*.mp3; do base=$(basename &quot;$j&quot; &quot;.mp3&quot;); ffmpeg -i $j -af silencedetect=noise=-30dB:d=0.5 -f null - 2&gt; $base.txt; done; rm /tmp/*.mp3; done .",
            "url": "https://jimregan.github.io/notes/asr/polish/kaggle/2021/05/23/ffmpeg-silence-detection-wolne-lektury.html",
            "relUrl": "/asr/polish/kaggle/2021/05/23/ffmpeg-silence-detection-wolne-lektury.html",
            "date": " â€¢ May 23, 2021"
        }
        
    
  
    
        ,"post165": {
            "title": "CoreNLP English model on Kaggle",
            "content": "Original on Kaggle (complete with downloaded model). . !pip install stanza . import stanza stanza.install_corenlp(dir=&quot;corenlp&quot;) . Downloading http://nlp.stanford.edu/software/stanford-corenlp-latest.zip: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 504M/504M [02:28&lt;00:00, 3.39MB/s] . stanza.download_corenlp_models(model=&#39;english&#39;, version=&#39;4.1.0&#39;, dir=&quot;corenlp&quot;) . Downloading http://nlp.stanford.edu/software/stanford-corenlp-4.1.0-models-english.jar: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 671M/671M [03:37&lt;00:00, 3.08MB/s] .",
            "url": "https://jimregan.github.io/notes/kaggle/corenlp/english/2021/05/22/stanza-corenlp-english-model.html",
            "relUrl": "/kaggle/corenlp/english/2021/05/22/stanza-corenlp-english-model.html",
            "date": " â€¢ May 22, 2021"
        }
        
    
  
    
        ,"post166": {
            "title": "Quiggin to IPA",
            "content": "import icu def transliterator_from_rules(name, rules): fromrules = icu.Transliterator.createFromRules(name, rules) icu.Transliterator.registerInstance(fromrules) return icu.Transliterator.createInstance(name) . quiggin_to_wikipedia = &quot;&quot;&quot; bâ€² â†’ bÊ²; b â†’ bË ; kâ€² â†’ c; k â†’ k; Ã§ â†’ Ã§; dâ€² â†’ dÊ²; d â†’ dÌªË ; e : â†’ eË; É› â†’ É›; e â†’ É›; É™ â†’ É™; Î±i â†’ É™i; Î±u â†’ É™u; Î± : â†’ aË; Î±Ìƒ : â†’ aË; Ã¦ â†’ a; Î± â†’ a; fâ€² â†’ fÊ²; f â†’ fË ; É¡â€² â†’ ÉŸ; gâ€² â†’ ÉŸ; É¡ â†’ É¡; g â†’ É¡; â„Š â†’ É£; h â†’ h; i : â†’ iË; iÉ™ â†’ iÉ™; Ã¯ â†’ Éª; Ä© â†’ Éª; i â†’ Éª; y â†’ Éª; j â†’ j; Lâ€² â†’ lÌ Ê²; lâ€² â†’ lÊ²; L â†’ lÌªË ; l â†’ lË ; mâ€² â†’ mÊ²; m â†’ mË ; nâ€² â†’ nÊ²; n â†’ nË ; Nâ€² â†’ nÌ Ê²; N â†’ nÌªË ; É² â†’ É²; Å‹ â†’ Å‹; o : â†’ oË; É” : â†’ oË; É” â†’ É”; oÌ¤ â†’ É”; pâ€² â†’ pÊ²; p â†’ pË ; râ€² â†’ É¾Ê²; r â†’ É¾Ë ; R â†’ É¾Ë ; s â†’ sË ; Êƒ â†’ Êƒ; tâ€² â†’ tÊ²; t â†’ tÌªË ; u : â†’ uË; uÉ™ â†’ uÉ™; Å¨ â†’ ÊŠ; U â†’ ÊŠ; v â†’ vÊ²; wÌ¥&#39;`&#39; â†’ w; wÌ¥ â†’ w; w â†’ w; Ï‡ â†’ x; &quot;&quot;&quot; . quiggin = transliterator_from_rules(&#39;quiggin&#39;, quiggin_to_wikipedia) . quiggin.transliterate(&quot;É™ tâ€²Î±spÉ™l&quot;) . &#39;É™ tÊ²asË pË É™lË &#39; . sample = &quot;&quot;&quot; ÊƒÎ±nÉ”klÉ™. 1.â€ƒlâ€²eÊƒ É™ NÃ¯lâ€²É™ wÎ±duw Î± Ï‡rÎ±Ìƒ:v. 2.â€ƒbâ€²i: É™ Ã§iÉ™L heinâ€² É›gâ€² É™ NÃ¯lâ€²É™ â„Šynâ€²É™ Î±gÉ™s kâ€²iÉ™L É™r Lâ€²eÃ§ É›gâ€² É™ Nâ€²Î±r virâ€²É™. 3.â€ƒNâ€²i: wi:râ€² É™ mÎ±duw ruÉ™ tâ€²Î±Ï‡tâ€²irâ€²É™ Nâ€²i: bâ€²Î±:r NÎ± É› heinâ€². 4.â€ƒmÎ±rÉ™guw NÉ™ bÎ±:Êƒtâ€²i:, Lâ€²igâ€² dÅ¨wÌ¥`, Lâ€²ikâ€²É™ mâ€²É™ didâ€². 5.â€ƒÉ™s NÎ±Ìƒ:widâ€² É™ Ã§Ã¯rdâ€² gÉ™n É™ fâ€²jÉ”:lâ€²É™mâ€². 6.â€ƒÊƒi:lâ€²i: Nâ€² tâ€²É›É™N dUwÌ¥ gÉ™r bâ€²e: É›É™n heinâ€² É™ tâ€²É›É™n É™s bÎ±:nâ€²É™ erâ€² bâ€²iÃ§. 7.â€ƒÊƒkâ€²É›É™l É™ iNâ€²ÊƒÉ™ dÉ™ Ï‡Î±pÉ™L sÉ™ kÎ±pÉ™L É™r to:nâ€² É™ NÎ±:rdâ€²É™. 8.â€ƒNâ€²i:râ€² vÄ©Êƒtâ€²É™ dÉ™ fâ€²Î±dÉ™r pÉ”:l. 9.â€ƒtu:s kâ€²Î±hÉ™ kâ€²É”:. &quot;&quot;&quot; . print(quiggin.transliterate(sample)) . ÊƒanË É”klË É™. 1.â€ƒlÊ²É›Êƒ É™ nÌªË ÉªlÊ²É™ wadÌªË uw a xÉ¾Ë aËvÊ². 2.â€ƒbÊ²iË É™ Ã§iÉ™lÌªË  hÉ›ÉªnÊ² É›ÉŸ É™ nÌªË ÉªlÊ²É™ É£ÉªnÊ²É™ aÉ¡É™sË  ciÉ™lÌªË  É™É¾Ë  lÌ Ê²É›Ã§ É›ÉŸ É™ nÌ Ê²aÉ¾Ë  vÊ²ÉªÉ¾Ê²É™. 3.â€ƒnÌ Ê²iË wiËÉ¾Ê² É™ mË adÌªË uw É¾Ë uÉ™ tÊ²axtÊ²ÉªÉ¾Ê²É™ nÌ Ê²iË bÊ²aËÉ¾Ë  nÌªË a É› hÉ›ÉªnÊ². 4.â€ƒmË aÉ¾Ë É™É¡uw nÌªË É™ bË aËÊƒtÊ²iË, lÌ Ê²ÉªÉŸ dÌªË ÊŠw, lÌ Ê²ÉªcÉ™ mÊ²É™ dÌªË ÉªdÊ². 5.â€ƒÉ™sË  nÌªË aËwÉªdÊ² É™ Ã§ÉªÉ¾Ë dÊ² É¡É™nË  É™ fÊ²joËlÊ²É™mÊ². 6.â€ƒÊƒiËlÊ²iË nÌ Ê² tÊ²É›É™nÌªË  dÌªË ÊŠw É¡É™É¾Ë  bÊ²eË É›É™nË  hÉ›ÉªnÊ² É™ tÊ²É›É™nË  É™sË  bË aËnÊ²É™ É›É¾Ê² bÊ²ÉªÃ§. 7.â€ƒÊƒcÉ›É™lË  É™ ÉªnÌ Ê²ÊƒÉ™ dÌªË É™ xapË É™lÌªË  sË É™ kapË É™lÌªË  É™É¾Ë  tÌªË oËnÊ² É™ nÌªË aËÉ¾Ë dÊ²É™. 8.â€ƒnÌ Ê²iËÉ¾Ê² vÊ²ÉªÊƒtÊ²É™ dÌªË É™ fÊ²adÌªË É™É¾Ë  pË oËlË . 9.â€ƒtÌªË uËsË  cahÉ™ coË. .",
            "url": "https://jimregan.github.io/notes/irish/quiggin/icu/ipa/phonetic/2021/05/21/quiggin-to-ipa.html",
            "relUrl": "/irish/quiggin/icu/ipa/phonetic/2021/05/21/quiggin-to-ipa.html",
            "date": " â€¢ May 21, 2021"
        }
        
    
  
    
        ,"post167": {
            "title": "Running rbg2p on Colab",
            "content": "!pip install -q condacolab import condacolab condacolab.install() . â¬ Downloading https://github.com/jaimergp/miniforge/releases/latest/download/Mambaforge-colab-Linux-x86_64.sh... ðŸ“¦ Installing... ðŸ“Œ Adjusting configuration... ðŸ©¹ Patching environment... â² Done in 0:00:30 ðŸ” Restarting kernel... . %%capture !conda install -c conda-forge go go-cgo -y . %%capture !pip install --upgrade setuptools wheel . !go get github.com/sergi/go-diff !go get github.com/stts-se/rbg2p . go: downloading github.com/sergi/go-diff v1.2.0 . !git clone https://github.com/stts-se/rbg2p . Cloning into &#39;rbg2p&#39;... remote: Enumerating objects: 3918, done. remote: Counting objects: 100% (123/123), done. remote: Compressing objects: 100% (85/85), done. remote: Total 3918 (delta 59), reused 77 (delta 29), pack-reused 3795 Receiving objects: 100% (3918/3918), 678.17 KiB | 2.32 MiB/s, done. Resolving deltas: 100% (1233/1233), done. . import os os.environ[&quot;PATH&quot;]=f&#39;{os.environ[&quot;PATH&quot;]}:/root/go/bin&#39; . %cd rbg2p . /content/rbg2p . %%writefile maori.g2p CHARACTER_SET &quot;aeghikmnoprtuwÄÄ“Ä«ÅÅ«&quot; DEFAULT_PHONEME &quot;_&quot; PHONEME_DELIMITER &quot; &quot; wh -&gt; f h -&gt; h k -&gt; k m -&gt; m ng -&gt; Å‹ n -&gt; n p -&gt; p r -&gt; É¾ t -&gt; t w -&gt; w au -&gt; au Ä -&gt; aË a -&gt; a Ä“ -&gt; É›Ë e -&gt; É› Ä« -&gt; iË i -&gt; i Å -&gt; É”Ë o -&gt; É” Å« -&gt; Ê‰Ë u -&gt; Ê‰ g -&gt; âˆ… . Writing maori.g2p . !echo kaumÄtua | go run cmd/g2p/g2p.go ../maori.g2p . 0 ERROR(S) FOR ../maori.g2p 0 WARNING(S) FOR ../maori.g2p ALL 0 TESTS PASSED FOR ../maori.g2p Reading input from stdin... kaumÄtua k au m aË t Ê‰ a TOTAL INPUT : 1 ERRORS : 0 TRANSCRIBED : 1 .",
            "url": "https://jimregan.github.io/notes/rbg2p/colab/2021/05/20/running-rbg2p.html",
            "relUrl": "/rbg2p/colab/2021/05/20/running-rbg2p.html",
            "date": " â€¢ May 20, 2021"
        }
        
    
  
    
        ,"post168": {
            "title": "Kilkenny vs. Waterford",
            "content": "Comparing Kilkenny Irish with Waterford Irish. . The Kilkenny Irish comes from these tweets: (Google Books says Ã‰igse, vol. 26, p. 35 1) . CÃºpla sampla spÃ©isiÃºil breise: pic.twitter.com/tYckKMrPM7 . &mdash; Corbmacc (@erisceres) May 17, 2021 Iâ€™ve marked the clear differences in bold face; differences in transcription (sâ€²/Êƒ, É‘Ë/aË) are not marked, nor are expected differences (âŸ¨aoâŸ© â†’ [ai] in Waterford Irish; /râ€²/ â†’ [Ê’] in Kilkenny Irish). . The Waterford side of the comparison is from Breatnach 2; references as in the index. I chose the first (that matched), except with some common words, where I used the first place I came across them. . ansoin and ansan are clearly different, but Breatnach (t. 20) gives Ã³ shoin (/oË xinâ€²/). . raibh /re/ is a bit of a stretch; Breatnach says this is only before pronouns, and considers it a back-formation from the unstressed form /rÉ™/ (/revâ€²/ stressed). . /duËrâ€²tâ€²/ for dÃºirt in Waterford is a little unexpected: the usual rule is râ€² â†’ [r] / _ [+dental]. . K. Word K. Phonetic W. Phonetic TIoRCW ref. W. Word . a | É™ | É™ | t. 349 | Â  | . acu | É™ku | É™Ëˆku | 163 | aca | . ag | egâ€² | egâ€² | p. 146 n. 4 | Â  | . ag | É™ | É™ | 317 | Â  | . ag | gâ€² | gâ€² | 42 | Â  | . agus | É‘gÉ™s | agÉ™(s) | 303 | Â  | . Ã¡it | É‘Ëtâ€² | aËtâ€² | 53 | Â  | . an | É™n | É™n | 250 | Â  | . an | É™ | É™ | t. 339 | Â  | . an | (É™)n | n | 496 | Â  | . ag an | gâ€²en | gâ€²en | t. 78 | aige â€™n | . anall | É™nÉ™ul | (É™)Ëˆnaul | 111 | Â  | . anchuid | anÉ™Ëˆxidâ€² | anÉ™ + xidâ€² | 171 + t. 253 | ana- + chuid | . ann | uËn | aun | 110 | Â  | . anonn | É™nuËn | (É™)Ëˆnaun | 111 | Â  | . ansoin | É™nsinâ€² | É™nson | 320 | annsan | . ar | eÊ’ | erâ€² | 42 | Â  | . bean | bâ€²an | bâ€²an | 44 | Â  | . bhean | vâ€²an | vâ€²an | 483 | Â  | . bhfuil | bilâ€² | bilâ€² | 399 | Â  | . bhÃ­ | vâ€²iË | vâ€²iË | 21 | Â  | . broim | brÉ™imâ€² | brÉ™imâ€² | 545 | Â  | . cadÃ© | dâ€²eË | dâ€²eË | 302 | dÃ© | . chuir | xiÊ’ | xirâ€² | 28 | Â  | . chun | xuËn | xuËn | 308 | chÃºn | . cÃ© | kâ€²eË | kâ€²eË | t. 56 | cia | . conas | kunÉ™s | kunÉ™s | 66 | cionnus | . cuir | kir | kirâ€² | 260 | Â  | . dÃ©in | tâ€²eËnâ€² | dâ€²eËnâ€² | 34 | Â  | . deir | dâ€²er | dâ€²erâ€² | 303 | Â  | . duine | dinâ€²É™ | dinâ€²É™ | 77 | Â  | . dÃºirt | duËrtâ€² | duËrâ€²tâ€² | 72 | adubhairt | . Ã©inne | eËÅ‹â€²É™ | aiÅ‹â€²É™ | 106 | aonduine | . fadÃ³ | fÉ™doË | fÉ™ËˆdoË | 62 | fadâ€™ Ã³ | . fear | fâ€²ar | fâ€²ar | 44 | Â  | . feicim | hekâ€²É™mâ€² | fâ€²ekâ€²É™mâ€² | 553 | faicim | . fhios | (É™)s | É™ Å‹anÉ™s | 231 | i ngan-fhios | . lig | lâ€²igâ€² | lâ€²igâ€² | 426 | lÃ©ig | . lÃ¡mh | lÉ‘Ë | laË lâ€²É™, laËvâ€² | p. 134 n. 2 | lÃ¡imh lÃ©, lÃ¡imh | . leis | lâ€²esâ€² | lâ€²eÊƒ | 39 | Â  | . mnÃ¡ | mnÉ‘Ë | mÉ™ËˆnaË | 227 | Â  | . nÃ­ | nâ€²iË | nâ€²iË | p. 67 n. 2 | Â  | . orthu | orhÉ™ | orhÉ™ | 57 | ortha | . raibh | re | re | p. 119 n. 6 | Â  | . rÃ©idh | reË | reËgâ€² | 36 | Â  | . siar | sâ€²iÉ™r | ÊƒiÉ™r | 180 | Â  | . suÃ­ | siË | siË | 24 | suidhe | . sÃ© | sâ€²e | Êƒe | t. 305 | Â  | . scian | sâ€²gâ€²iÉ™n | Êƒgâ€²iÉ™n | 87 | Â  | . t-ainm | tanâ€²É™mâ€² | anâ€²É™mâ€² | 44 | ainm | . thine | hinâ€²É™ | tâ€²inâ€²É™ | 26 + 210 | teine | . thÃ¡ | hÉ‘Ë | haË | t. 323 | atÃ¡ | . trÃ­ | tâ€²Ê’iË | tâ€²siË | 219 | Â  | . tÃº | tu | tuË, tÉ™ | 134, 80 | Â  | . TÃ¡ droch-chaoi ar mo chÃ³ip fÃ©in den alt iontach so le R.A. Breathnach.Breatnach (R. A.): IarsmaÃ­ de Ghaeilig Chontae Chill Choinnigh. In Ã‰igse 26 (1992) pp. 21 42. pic.twitter.com/wkIu4EUBpl . &mdash; SÄ±onnaÄ‹ (@SeaghanSionnach) May 19, 2021 Breatnach, R. A., (1992). â€˜IarsmaÃ­ de Ghaeilig Chontae Chill Choinnighâ€™. In Ã‰igse, 26, pp. 21â€”42.Â &#8617; . | Breatnach, R. B., (1947). The Irish of Ring, Co. Waterford: A Phonetic Study. Dublin Institute for Advanced Studies.Â &#8617; . |",
            "url": "https://jimregan.github.io/notes/irish/kilkenny/waterford/2021/05/19/kilkenny-vs-waterford.html",
            "relUrl": "/irish/kilkenny/waterford/2021/05/19/kilkenny-vs-waterford.html",
            "date": " â€¢ May 19, 2021"
        }
        
    
  
    
        ,"post169": {
            "title": "Converting Ã“ Raghallaigh (2010)",
            "content": "This notebook contains a re-implementation of the &quot;global&quot; phonetiser from Brian Ã“ Raghallaigh&#39;s Ph.D. thesis using rbg2p, along with the &quot;local&quot; phonetiser for Kerry. . The global phonetiser here is essentially the same as the earlier one, except the output phonemes are lowercase, and there are no spaces between output phonemes, to work around some slight limitations of rbg2p. . Brian Ã“ Raghallaigh (2010). Multi-dialect phonetisation for Irish text-to-speech synthesis: a modular approach. (Doctoral thesis, Trinity College, Dublin), Appendix B.1 . %%writefile oraghallaigh.g2p CHARACTER_SET &quot;aÃ¡bcdeÃ©fghiÃ­jklmnoÃ³pqrstuÃºvwxyz&#39;-â€™&quot; DEFAULT_PHONEME &quot;_&quot; PHONEME_DELIMITER &quot;&quot; VAR CONS [bcdfghjklmnpqrstvwxyz] VAR CONSS [bcdfghjklmnpqrstvwxyz]* VAR CONSP [bcdfghjklmnpqrstvwxyz]+ VAR NONSYLLABIC [Ã¡bcdfghjklmnÃ³pqrstÃºvwxyz] // broad future/conditional endings VAR BFCE (Ã¡|adh|aidh|aidÃ­s|aimid|aimis|ainn|as) // slender future/conditional endings VAR SFCE (eÃ¡|eadh|idh|idÃ­s|imid|imis|inn) VAR FMP [fmp] VAR LNRP [lnr]+ VAR DNLST [dnlst] VAR RDNLR (rd|rn|rl|rr) VAR VOWEL [aÃ¡eÃ©iÃ­oÃ³uÃº] VAR VOWELS [aÃ¡eÃ©iÃ­oÃ³uÃº]* VAR VOWELP [aÃ¡eÃ©iÃ­oÃ³uÃº]+ // left context short broad vowel VAR LCSBV (ea|io|iu|a|o|u) // left context short slender vowel VAR LCSSV (ai|eai|ei|e|iui|i|oi|ui) // left context broad vowel VAR LCBV (adh|ae|ao|aÃ¡|ea|eÃ¡|eo|Ã©a|io|iu|iÃº|Ã­o|oÃ³|uÃ­o|ua|u|Ãº) // left context slender vowel VAR LCSV (aei|aidh|ai|aÃ­|aoi|Ã¡i|eai|eÃ¡i|ei|eoi|e|Ã©i|Ã©|iai|iui|iÃºi|i|Ã­|oi|Ã³i|uai|ui|uÃ­|Ãºi) VAR LCSVS (aei|aidh|ai|aÃ­|aoi|Ã¡i|eai|eÃ¡i|ei|eoi|e|Ã©i|Ã©|iai|iui|iÃºi|i|Ã­|oi|Ã³i|uai|ui|uÃ­|Ãºi)* // right context slender vowel VAR RCSV (eai|ea|eÃ¡i|eÃ¡|ei|eoi|eo|e|Ã©a|Ã©i|Ã©|iai|ia|io|iui|iu|iÃºi|iÃº|i|Ã­o|Ã­) // left context long vowel VAR LCLV (aei|ae|aoi|ao|Ã¡i|Ã¡|eÃ¡i|eÃ¡|eoi|eÃ³|eo|Ã©i|Ã©|iÃºi|iÃº|Ã­o|Ã­|Ã³i|Ã³|uÃ­o|uÃ­|Ãºi|Ãº) // left context slender long vowel VAR LCSLV (aei|aidh|aoi|Ã¡i|eÃ¡i|eoi|Ã©i|Ã©|iÃºi|Ã­|Ã³i|uai|uÃ­|Ãºi) Ã¡dh -&gt; aa Ã¡i -&gt; aa Ã¡ -&gt; aa abh -&gt; abh adh -&gt; adh / _ # adh -&gt; ai agh -&gt; ai aei -&gt; ee ae -&gt; ee aÃ­odh -&gt; Ã­odh / _ # aÃ­o -&gt; aÃ­o aÃ­ -&gt; ii aidh -&gt; idh / _ # aidh -&gt; ai aigh -&gt; igh / _ # aigh -&gt; ai aithe -&gt; ithe / _ # ai -&gt; âˆ… / # CONSS VOWELS (abh|adh|agh|amh|Ã³dh|ogh|omh|umh) _ CONSP ai -&gt; âˆ… / # CONSS (obh|odh) _ CONSP ai -&gt; aa / # CONSS _ RDNLR ai -&gt; a / # CONSS _ ai -&gt; @@ / VOWELP CONSP _ ai -&gt; a amh -&gt; amh / _ # amh -&gt; au aoi -&gt; ao ao -&gt; ao a -&gt; âˆ… / # CONSS VOWELS (abh|adh|agh|amh|Ã³dh|ogh|omh|umh) _ CONSP a -&gt; âˆ… / # CONSS (obh|odh) _ CONSP # addition a -&gt; âˆ… / # CONSS VOWELS ogh _ # omh -&gt; OO / (gc|ch|c) _ (ai|a) r a -&gt; aa / # CONSS _ RDNLR a -&gt; a / # CONSS _ a -&gt; @@ / VOWELP CONSP _ a -&gt; a Ã©a -&gt; ee Ã©i -&gt; ee Ã© -&gt; ee eÃ¡i -&gt; aa eÃ¡ -&gt; aa eabh -&gt; abh eadh -&gt; adh / _ # eadh -&gt; au eagh -&gt; ai eai -&gt; a eamh -&gt; amh / _ # eamh -&gt; au / # CONSS _ # VOWEL, or VOWELS ?? ea -&gt; âˆ… / # CONSS VOWEL igh _ CONSP ea -&gt; aa / # CONSS _ RDNLR ea -&gt; a / # CONSS _ ea -&gt; @@ / VOWELP CONSP _ ea -&gt; a eidh -&gt; eidh eigh -&gt; eigh ei -&gt; ee / # CONSS _ RDNLR # ei -&gt; ee / # CONSS _ RDNLR NONSYLLABIC ei -&gt; e / # CONSS _ ei -&gt; e eÃ³dh -&gt; oo eoi -&gt; oo eÃ³ -&gt; oo eo -&gt; oo e -&gt; e / # CONSS _ e -&gt; @@ / VOWELP CONSP _ e -&gt; e Ã­odh -&gt; Ã­odh / _ # Ã­o -&gt; ii Ã­ -&gt; ii iadh -&gt; i@ iath -&gt; i@ iai -&gt; i@ ia -&gt; i@ idh -&gt; idh igh -&gt; igh io -&gt; io ithe -&gt; ithe / _ # iÃºi -&gt; uu iÃº -&gt; uu iubh -&gt; ubh iumh -&gt; uu iui -&gt; uu iu -&gt; u i -&gt; âˆ… / # CONSS VOWEL idh _ CONSP # i -&gt; âˆ… / # CONSS VOWEL igh _ CONSP i -&gt; @@ / VOWELP CONSP _ i -&gt; I Ã³dh -&gt; Ã³dh / _ # Ã³i -&gt; oo Ã³ -&gt; oo obh -&gt; obh odh -&gt; odh ogh -&gt; ogh oÃ­ -&gt; ii oidh -&gt; oidh oigh -&gt; oigh oi -&gt; oo / # CONSS _ RDNLR oi -&gt; @@ / # VOWELP CONSP _ oi -&gt; oi omh -&gt; omh o -&gt; oo / # CONSS _ RDNLR # o -&gt; oo / # CONSS _ RDNLR NONSYLLABIC o -&gt; o / # VOWELP CONSP _ o -&gt; o Ãºi -&gt; uu Ãº -&gt; uu uath -&gt; u@ uai -&gt; u@ ua -&gt; u@ ubh -&gt; ubh ue -&gt; e ui -&gt; uu / # CONSS _ RDNLR # ui -&gt; uu / # CONSS _ RDNLR NONSYLLABIC ui -&gt; i / # CONSS _ ui -&gt; @@ / VOWELP CONSP _ ui -&gt; ui uÃ­o -&gt; ii uÃ­ -&gt; ii umh -&gt; uu u -&gt; uu / # CONSS _ RDNLR u -&gt; u / # CONSS _ u -&gt; @@ / VOWELP CONSP _ u -&gt; u bf -&gt; p / _ BFCE # bf -&gt; pj / _ SFCE # bhf -&gt; vj / # _ CONSS RCSV # bhf -&gt; vj / # _ CONSS RCSV NONSYLLABIC bhf -&gt; v / # _ bhf -&gt; f / _ BFCE # bhf -&gt; fj / _ SFCE # bh -&gt; @@ v / # LCSBV LNRP _ bh -&gt; @@ v / NONSYLLABIC LCSBV LNRP _ bh -&gt; @@ vj / # LCSSV LNRP _ bh -&gt; @@ vj / NONSYLLABIC LCSSV LNRP _ bh -&gt; vj / # _ CONSS RCSV # bh -&gt; vj / # _ CONSS RCSV NONSYLLABIC bh -&gt; v / # _ bh -&gt; vj / _ CONSS RCSV # bh -&gt; vj / _ CONSS RCSV NONSYLLABIC bh -&gt; vj / # LCSV CONSP _ bh -&gt; vj / NONSYLLABIC LCSV CONSP _ bh -&gt; vj / # LCSV _ bh -&gt; vj / NONSYLLABIC LCSV _ bh -&gt; v bp -&gt; bj / # _ CONSS RCSV # bp -&gt; bj / # _ CONSS RCSV NONSYLLABIC bp -&gt; b / # _ bth -&gt; p / LCBV CONSS _ bth -&gt; pj / LCSV CONSS _ b -&gt; @@ b / # LCSBV LNRP _ b -&gt; @@ b / NONSYLLABIC LCSBV LNRP _ b -&gt; @@ bj / # LCSSV LNRP _ b -&gt; @@ bj / NONSYLLABIC LCSSV LNRP _ b -&gt; bj / _ CONSS RCSV # b -&gt; bj / _ CONSS RCSV NONSYLLABIC b -&gt; bj / # LCSV CONSP _ b -&gt; bj / NONSYLLABIC LCSV CONSP _ b -&gt; bj / # LCSV _ b -&gt; bj / NONSYLLABIC LCSV _ b -&gt; b cf -&gt; k / _ BFCE # cf -&gt; kj / _ SFCE # chf -&gt; x / _ BFCE # chf -&gt; xj / _ SFCE # ch -&gt; @@ x / # LCSBV LNRP _ ch -&gt; @@ x / NONSYLLABIC LCSBV LNRP _ ch -&gt; @@ xj / # LCSSV LNRP _ ch -&gt; @@ xj / NONSYLLABIC LCSSV LNRP _ ch -&gt; xj / # _ CONSS RCSV # ch -&gt; xj / # _ CONSS RCSV NONSYLLABIC ch -&gt; x / # _ ch -&gt; xj / _ CONSS RCSV # ch -&gt; xj / _ CONSS RCSV NONSYLLABIC ch -&gt; xj / # LCSV CONSP _ ch -&gt; xj / NONSYLLABIC LCSV CONSP _ ch -&gt; xj / # LCSV _ ch -&gt; xj / NONSYLLABIC LCSV _ ch -&gt; x cth -&gt; k / LCBV CONSS _ cth -&gt; kj / LCSV CONSS _ c -&gt; kj / _ CONSS RCSV # c -&gt; kj / _ CONSS RCSV NONSYLLABIC c -&gt; kj / # LCSV CONSP _ c -&gt; kj / NONSYLLABIC LCSV CONSP _ c -&gt; kj / # LCSV _ c -&gt; kj / NONSYLLABIC LCSV _ c -&gt; k df -&gt; t / _ BFCE # df -&gt; tj / _ SFCE # dha -&gt; âˆ… / # LCLV _ dha -&gt; âˆ… / NONSYLLABIC LCLV _ dh -&gt; gfj / # LCSLV _ dh -&gt; gfj / NONSYLLABIC LCSLV _ dh -&gt; gfj / # CONSS LCSVS _ # dh -&gt; âˆ… / # LCLV _ dh -&gt; âˆ… / NONSYLLABIC LCLV _ dh -&gt; gfj / # _ CONSS RCSV # dh -&gt; gfj / # _ CONSS RCSV NONSYLLABIC dh -&gt; gf / # _ dh -&gt; gfj / _ CONSS RCSV # dh -&gt; gfj / _ CONSS RCSV NONSYLLABIC dh -&gt; gfj / # LCSV CONSP _ dh -&gt; gfj / NONSYLLABIC LCSV CONSP _ dh -&gt; gfj / # LCSV _ dh -&gt; gfj / NONSYLLABIC LCSV _ dh -&gt; gf dt -&gt; dj / # _ CONSS RCSV # dt -&gt; dj / # _ CONSS RCSV NONSYLLABIC dt -&gt; d / # _ dt -&gt; t / LCBV CONSS _ dt -&gt; tj / LCSV CONSS _ d -&gt; dj / _ CONSS RCSV # d -&gt; dj / _ CONSS RCSV NONSYLLABIC d -&gt; dj / # LCSV CONSP _ d -&gt; dj / NONSYLLABIC LCSV CONSP _ d -&gt; dj / # LCSV _ d -&gt; dj / NONSYLLABIC LCSV _ d -&gt; d fh -&gt; âˆ… f -&gt; h / VOWEL _ BFCE # f -&gt; hj / VOWEL _ SFCE # f -&gt; @@ f / # LCSBV LNRP _ f -&gt; @@ f / NONSYLLABIC LCSBV LNRP _ f -&gt; @@ fj / # LCSSV LNRP _ f -&gt; @@ fj / NONSYLLABIC LCSSV LNRP _ f -&gt; fj / _ CONSS RCSV # f -&gt; fj / _ CONSS RCSV NONSYLLABIC f -&gt; fj / # LCSV CONSP _ f -&gt; fj / NONSYLLABIC LCSV CONSP _ f -&gt; fj / # LCSV _ f -&gt; fj / NONSYLLABIC LCSV _ f -&gt; f gc -&gt; gj / # _ CONSS RCSV # gc -&gt; gj / # _ CONSS RCSV NONSYLLABIC gc -&gt; g / # _ gf -&gt; k / _ BFCE # gf -&gt; kj / _ SFCE # gh -&gt; gfj / # _ CONSS RCSV # gh -&gt; gfj / # _ CONSS RCSV NONSYLLABIC gh -&gt; gf / # _ gh -&gt; gfj / # LCSLV _ gh -&gt; gfj / NONSYLLABIC LCSLV _ gh -&gt; gfj / # CONSS LCSVS _ # gh -&gt; âˆ… / # LCLV _ gh -&gt; âˆ… / NONSYLLABIC LCLV _ gh -&gt; gfj / _ CONSS RCSV # gh -&gt; gfj / _ CONSS RCSV NONSYLLABIC gh -&gt; gfj / # LCSV CONSP _ gh -&gt; gfj / NONSYLLABIC LCSV CONSP _ gh -&gt; gfj / # LCSV _ gh -&gt; gfj / NONSYLLABIC LCSV _ gh -&gt; gf gth -&gt; k / LCBV CONSS _ gth -&gt; kj / LCSV CONSS _ g -&gt; @@ g / # LCSBV LNRP _ g -&gt; @@ g / NONSYLLABIC LCSBV LNRP _ g -&gt; @@ gj / # LCSSV LNRP _ g -&gt; @@ gj / NONSYLLABIC LCSSV LNRP _ g -&gt; gj / _ CONSS RCSV # g -&gt; gj / _ CONSS RCSV NONSYLLABIC g -&gt; gj / # LCSV CONSP _ g -&gt; gj / NONSYLLABIC LCSV CONSP _ g -&gt; gj / # LCSV _ g -&gt; gj / NONSYLLABIC LCSV _ g -&gt; g h -&gt; hj / _ CONSS RCSV # h -&gt; hj / _ CONSS RCSV NONSYLLABIC h -&gt; hj / # LCSV CONSP _ h -&gt; hj / NONSYLLABIC LCSV CONSP _ h -&gt; hj / # LCSV _ h -&gt; hj / NONSYLLABIC LCSV _ h -&gt; h j -&gt; djzj k -&gt; kj / _ CONSS RCSV # k -&gt; kj / _ CONSS RCSV NONSYLLABIC k -&gt; kj / # LCSV CONSP _ k -&gt; kj / NONSYLLABIC LCSV CONSP _ k -&gt; kj / # LCSV _ k -&gt; kj / NONSYLLABIC LCSV _ k -&gt; k llf -&gt; ll_d / _ BFCE # llf -&gt; llj_d / _ SFCE # llth -&gt; ll_d / LCBV CONSS _ llth -&gt; llj_d / LCSV CONSS _ ll -&gt; llj / _ CONSS RCSV # ll -&gt; llj / _ CONSS RCSV NONSYLLABIC ll -&gt; llj / # LCSV CONSP _ ll -&gt; llj / NONSYLLABIC LCSV CONSP _ ll -&gt; llj / # LCSV _ ll -&gt; llj / NONSYLLABIC LCSV _ ll -&gt; ll lf -&gt; ll_d / _ BFCE # lf -&gt; lj_d / _ SFCE # lth -&gt; ll_d / LCBV CONSS _ lth -&gt; lj_d / LCSV CONSS _ l -&gt; lj / _ CONSS RCSV # l -&gt; lj / _ CONSS RCSV NONSYLLABIC l -&gt; lj / # LCSV CONSP _ l -&gt; lj / NONSYLLABIC LCSV CONSP _ l -&gt; lj / # LCSV _ l -&gt; lj / NONSYLLABIC LCSV _ l -&gt; ll mb -&gt; mj / # _ CONSS RCSV # mb -&gt; mj / # _ CONSS RCSV NONSYLLABIC mb -&gt; m / # _ mf -&gt; m_d / _ BFCE # mf -&gt; mj_d / _ SFCE # mhf -&gt; f / _ BFCE # mhf -&gt; fj / _ SFCE # mh -&gt; vj / # _ CONSS RCSV # mh -&gt; vj / # _ CONSS RCSV NONSYLLABIC mh -&gt; v / # _ mh -&gt; @@ v / # LCSBV LNRP _ mh -&gt; @@ v / NONSYLLABIC LCSBV LNRP _ mh -&gt; @@ vj / # LCSSV LNRP _ mh -&gt; @@ vj / NONSYLLABIC LCSSV LNRP _ mh -&gt; vj / _ CONSS RCSV # mh -&gt; vj / _ CONSS RCSV NONSYLLABIC mh -&gt; vj / # LCSV CONSP _ mh -&gt; vj / NONSYLLABIC LCSV CONSP _ mh -&gt; vj / # LCSV _ mh -&gt; vj / NONSYLLABIC LCSV _ mh -&gt; v mth -&gt; m_d / LCBV CONSS _ mth -&gt; mj_d / LCSV CONSS _ m -&gt; @@ m / # LCSBV LNRP _ m -&gt; @@ m / NONSYLLABIC LCSBV LNRP _ m -&gt; @@ mj / # LCSSV LNRP _ m -&gt; @@ mj / NONSYLLABIC LCSSV LNRP _ m -&gt; mj / _ CONSS RCSV # m -&gt; mj / _ CONSS RCSV NONSYLLABIC m -&gt; mj / # LCSV CONSP _ m -&gt; mj / NONSYLLABIC LCSV CONSP _ m -&gt; mj / # LCSV _ m -&gt; mj / NONSYLLABIC LCSV _ m -&gt; m nnf -&gt; nn_d / _ BFCE # nnf -&gt; nnj_d / _ SFCE # nnth -&gt; nn_d / LCBV CONSS _ nnth -&gt; nnj_d / LCSV CONSS _ nn -&gt; nnj / _ CONSS RCSV # nn -&gt; nnj / _ CONSS RCSV NONSYLLABIC nn -&gt; nnj / # LCSV CONSP _ nn -&gt; nnj / NONSYLLABIC LCSV CONSP _ nn -&gt; nnj / # LCSV _ nn -&gt; nnj / NONSYLLABIC LCSV _ nn -&gt; nn n- -&gt; nj / # _ RCSV # n- -&gt; nj / # _ RCSV NONSYLLABIC n- -&gt; nn / # _ nd -&gt; nnj / # _ CONSS RCSV # nd -&gt; nnj / # _ CONSS RCSV NONSYLLABIC nd -&gt; nn / # _ nf -&gt; nn_d / _ BFCE # nf -&gt; nj_d / _ SFCE # ngf -&gt; ng_d / _ BFCE # ngf -&gt; ngj_d / _ SFCE # ngth -&gt; ng_d / LCBV CONSS _ ngth -&gt; ngj_d / LCSV CONSS _ ng -&gt; ngj / # _ CONSS RCSV # ng -&gt; ngj / # _ CONSS RCSV NONSYLLABIC ng -&gt; ng / # _ ng -&gt; nj / # LCSV _ t # ng -&gt; nj / NONSYLLABIC LCSV _ t # ng -&gt; ngj / _ CONSS RCSV # ng -&gt; ngj / _ CONSS RCSV NONSYLLABIC ng -&gt; ngj / # LCSV CONSP _ ng -&gt; ngj / NONSYLLABIC LCSV CONSP _ ng -&gt; ngj / # LCSV _ ng -&gt; ngj / NONSYLLABIC LCSV _ ng -&gt; ng nth -&gt; nn_d / LCBV CONSS _ nth -&gt; nj_d / LCSV CONSS _ n -&gt; ngj / # LCSV _ c n -&gt; ngj / NONSYLLABIC LCSV _ c n -&gt; ng / _ c n -&gt; nj / _ CONSS RCSV # n -&gt; nj / _ CONSS RCSV NONSYLLABIC n -&gt; nj / # LCSV CONSP _ n -&gt; nj / NONSYLLABIC LCSV CONSP _ n -&gt; nj / # LCSV _ n -&gt; nj / NONSYLLABIC LCSV _ n -&gt; nn pf -&gt; p / _ BFCE # pf -&gt; pj / _ SFCE # ph -&gt; fj / # _ CONSS RCSV # ph -&gt; fj / # _ CONSS RCSV NONSYLLABIC ph -&gt; f / # _ ph -&gt; fj / _ CONSS RCSV # ph -&gt; fj / _ CONSS RCSV NONSYLLABIC ph -&gt; fj / # LCSV CONSP _ ph -&gt; fj / NONSYLLABIC LCSV CONSP _ ph -&gt; fj / # LCSV _ ph -&gt; fj / NONSYLLABIC LCSV _ ph -&gt; f pth -&gt; p / LCBV CONSS _ pth -&gt; pj / LCSV CONSS _ p -&gt; pj / _ CONSS RCSV # p -&gt; pj / _ CONSS RCSV NONSYLLABIC p -&gt; pj / # LCSV CONSP _ p -&gt; pj / NONSYLLABIC LCSV CONSP _ p -&gt; pj / # LCSV _ p -&gt; pj / NONSYLLABIC LCSV _ p -&gt; p # really? there&#39;s a &#39;W&#39; in the phoneset q -&gt; k v rrf -&gt; rr_d / _ BFCE # rrf -&gt; rrj_d / _ SFCE # rrth -&gt; rr_d / LCBV CONSS _ rrth -&gt; rrj_d / LCSV CONSS _ rr -&gt; rrj / _ CONSS RCSV # rr -&gt; rrj / _ CONSS RCSV NONSYLLABIC rr -&gt; rrj / # LCSV CONSP _ rr -&gt; rrj / NONSYLLABIC LCSV CONSP _ rr -&gt; rrj / # LCSV _ rr -&gt; rrj / NONSYLLABIC LCSV _ rr -&gt; rr rf -&gt; r_d / _ BFCE # rf -&gt; rj_d / _ SFCE # rth -&gt; r_d / LCBV CONSS _ rth -&gt; rj_d / LCSV CONSS _ r -&gt; r / # s _ r -&gt; r / # _ r -&gt; r / _ DNLST r -&gt; rj / _ CONSS RCSV # r -&gt; rj / _ CONSS RCSV NONSYLLABIC r -&gt; rj / # LCSV CONSP _ r -&gt; rj / NONSYLLABIC LCSV CONSP _ r -&gt; rj / # LCSV _ r -&gt; rj / NONSYLLABIC LCSV _ r -&gt; r sf -&gt; s / _ BFCE # sf -&gt; sj / _ SFCE # shl -&gt; lj_d / _ CONSS RCSV # shl -&gt; lj_d / _ CONSS RCSV NONSYLLABIC shl -&gt; ll_d shm -&gt; mj_d / _ CONSS RCSV # shm -&gt; mj_d / _ CONSS RCSV NONSYLLABIC shm -&gt; m_d shn -&gt; nj_d / _ CONSS RCSV # shn -&gt; nj_d / _ CONSS RCSV NONSYLLABIC shn -&gt; nn_d shr -&gt; rj_d / _ CONSS RCSV # shr -&gt; rj_d / _ CONSS RCSV NONSYLLABIC shr -&gt; r_d sh -&gt; xj / # _ CONSS RCSV # sh -&gt; xj / # _ CONSS RCSV NONSYLLABIC sh -&gt; h / # _ sh -&gt; xj / _ CONSS RCSV # sh -&gt; xj / _ CONSS RCSV NONSYLLABIC sh -&gt; xj / # LCSV CONSP _ sh -&gt; xj / NONSYLLABIC LCSV CONSP _ sh -&gt; xj / # LCSV _ sh -&gt; xj / NONSYLLABIC LCSV _ sh -&gt; h s -&gt; s / # _ r s -&gt; s / # _ FMP CONSS RCSV # s -&gt; s / # _ FMP CONSS RCSV NONSYLLABIC s -&gt; sj / _ CONSS RCSV # s -&gt; sj / _ CONSS RCSV NONSYLLABIC s -&gt; sj / # LCSV CONSP _ s -&gt; sj / NONSYLLABIC LCSV CONSP _ s -&gt; sj / # LCSV _ s -&gt; sj / NONSYLLABIC LCSV _ s -&gt; s t- -&gt; tj / # _ RCSV # t- -&gt; tj / # _ RCSV NONSYLLABIC t- -&gt; t / # _ tf -&gt; t / _ BFCE # tf -&gt; tj / _ SFCE # // &quot;hack for compound boundaries&quot; th -&gt; âˆ… / _ CONS h thb -&gt; pj / _ CONSS RCSV # thb -&gt; pj / _ CONSS RCSV NONSYLLABIC thb -&gt; p thc -&gt; kj / _ CONSS RCSV # thc -&gt; kj / _ CONSS RCSV NONSYLLABIC thc -&gt; k thd -&gt; tj / _ CONSS RCSV # thd -&gt; tj / _ CONSS RCSV NONSYLLABIC thd -&gt; t thf -&gt; h / _ BFCE # thf -&gt; xj / _ SFCE # thl -&gt; lj_d / _ CONSS RCSV # thl -&gt; lj_d / _ CONSS RCSV NONSYLLABIC thl -&gt; ll_d thm -&gt; mj_d / _ CONSS RCSV # thm -&gt; mj_d / _ CONSS RCSV NONSYLLABIC thm -&gt; m_d thn -&gt; nj_d / _ CONSS RCSV # thn -&gt; nj_d / _ CONSS RCSV NONSYLLABIC thn -&gt; nn_d thp -&gt; pj / _ CONSS RCSV # thp -&gt; pj / _ CONSS RCSV NONSYLLABIC thp -&gt; p thr -&gt; rj_d / _ CONSS RCSV # thr -&gt; rj_d / _ CONSS RCSV NONSYLLABIC thr -&gt; r_d ths -&gt; sj / _ CONSS RCSV # ths -&gt; sj / _ CONSS RCSV NONSYLLABIC ths -&gt; s tht -&gt; tj / _ CONSS RCSV # tht -&gt; tj / _ CONSS RCSV NONSYLLABIC tht -&gt; t th -&gt; hj / # _ CONSS RCSV # th -&gt; hj / # _ CONSS RCSV NONSYLLABIC th -&gt; h / # _ th -&gt; hj / _ CONSS RCSV # th -&gt; hj / _ CONSS RCSV NONSYLLABIC th -&gt; hj / # LCSV CONSP _ th -&gt; hj / NONSYLLABIC LCSV CONSP _ th -&gt; hj / # LCSV _ th -&gt; hj / NONSYLLABIC LCSV _ th -&gt; h ts -&gt; tj / # _ CONSS RCSV # ts -&gt; tj / # _ CONSS RCSV NONSYLLABIC ts -&gt; t / # _ t -&gt; tj / _ CONSS RCSV # t -&gt; tj / _ CONSS RCSV NONSYLLABIC t -&gt; tj / # LCSV CONSP _ t -&gt; tj / NONSYLLABIC LCSV CONSP _ t -&gt; tj / # LCSV _ t -&gt; tj / NONSYLLABIC LCSV _ t -&gt; t v -&gt; vj / _ CONSS RCSV # v -&gt; vj / _ CONSS RCSV NONSYLLABIC v -&gt; vj / # LCSV CONSP _ v -&gt; vj / NONSYLLABIC LCSV CONSP _ v -&gt; vj / # LCSV _ v -&gt; vj / NONSYLLABIC LCSV _ v -&gt; v w -&gt; v x- -&gt; e kj s x -&gt; zj y -&gt; gfj z -&gt; zj / _ CONSS RCSV # z -&gt; zj / _ CONSS RCSV NONSYLLABIC z -&gt; zj / # LCSV CONSP _ z -&gt; zj / NONSYLLABIC LCSV CONSP _ z -&gt; zj / # LCSV _ z -&gt; zj / NONSYLLABIC LCSV _ z -&gt; z &#39; -&gt; âˆ… â€™ -&gt; âˆ… - -&gt; âˆ… TEST Ã¡dh -&gt; aa TEST Ã¡iseanna -&gt; aa sj @@ nn @@ TEST Ã¡thas -&gt; aa h @@ s TEST abhainn -&gt; abh nnj TEST bualadh -&gt; b u@ ll adh TEST sadhbh -&gt; s ai v TEST saghas -&gt; s ai s TEST gaeilge -&gt; g ee lj gj @@ TEST saolaÃ­odh -&gt; s ao ll Ã­odh TEST gardaÃ­ -&gt; g aa r d ii TEST dÃºnfaidh -&gt; d uu nn_d idh TEST aidhm -&gt; ai mj TEST cheadaigh -&gt; xj a d igh TEST aighneas -&gt; ai nj @@ s TEST diÃºltaithe -&gt; dj uu ll t ithe TEST seabhaic -&gt; sj abh kj TEST feadhain -&gt; fj au nj TEST teaghais -&gt; tj ai sj TEST eamhain -&gt; au nj TEST lobhair -&gt; ll obh rj TEST leÃ³dhais -&gt; lj oo sj TEST bodhair -&gt; b odh rj TEST eoghain -&gt; oo nj TEST broghais -&gt; b r ogh sj TEST comhair -&gt; k oo rj TEST ciumhais -&gt; kj uu sj TEST airde -&gt; aa r dj @@ TEST cait -&gt; k a tj TEST sodair -&gt; s o d @@ rj TEST ait -&gt; a tj TEST dÃ©anamh -&gt; dj ee nn amh TEST amharc -&gt; au r k TEST gaoil -&gt; g ao lj TEST gaol -&gt; g ao ll TEST seabhac -&gt; sj abh k TEST ceadharlach -&gt; kj au r ll @@ x TEST teaghasÃ¡n -&gt; tj ai s aa nn TEST lobhar -&gt; ll obh r TEST leÃ³dhas -&gt; lj oo s TEST bodhar -&gt; b odh r TEST eoghan -&gt; oo nn TEST bogha -&gt; b ogh TEST comhar -&gt; k oo r TEST dumhach -&gt; d uu x TEST ard -&gt; aa r d TEST cat -&gt; k a t TEST sodar -&gt; s o d @@ r TEST at -&gt; a t TEST Ã©an -&gt; ee nn TEST Ã©inÃ­nÃ­ -&gt; ee nj ii nj ii TEST Ã© -&gt; ee TEST sheÃ¡in -&gt; xj aa nj TEST seÃ¡n -&gt; sj aa nn TEST seabhac -&gt; sj abh k TEST seinneadh -&gt; sj e nnj adh TEST ceadharlach -&gt; kj au r ll @@ x TEST teaghlach -&gt; tj ai ll @@ x TEST beairic -&gt; bj a rj @@ kj TEST Ã¡ireamh -&gt; aa rj amh TEST sleamhnÃ¡n -&gt; sj lj au nn aa nn TEST oighear -&gt; oigh r TEST ceard -&gt; kj aa r d TEST cead -&gt; kj a d TEST Ã¡ireamhÃ¡n -&gt; aa rj @@ v aa nn TEST eas -&gt; a s TEST feidhm -&gt; fj eidh mj TEST leigheas -&gt; lj eigh s TEST ceird -&gt; kj ee r dj TEST deis -&gt; dj e sj TEST eitpheil -&gt; e tj fj e lj TEST ceoil -&gt; kj oo lj TEST bainseÃ³ -&gt; b a nj sj oo TEST ceol -&gt; kj oo ll TEST uile -&gt; i lj @@ TEST ceannaÃ­odh -&gt; kj a nn Ã­odh TEST sÃ­os -&gt; sj ii s TEST sÃ­ -&gt; sj ii TEST siadhail -&gt; sj i@ lj TEST sciath -&gt; sj kj i@ TEST riail -&gt; r i@ lj TEST siad -&gt; sj i@ d TEST seinnfidh -&gt; sj e nnj_d idh TEST cheannaigh -&gt; xj a nn igh TEST fios -&gt; fj io s TEST imithe -&gt; i mj ithe TEST siÃºil -&gt; sj uu lj TEST siÃºl -&gt; sj uu ll TEST tiubh -&gt; tj ubh TEST ciumhais -&gt; kj uu sj TEST giuirlÃ©id -&gt; gj uu r lj ee dj TEST fiuch -&gt; fj u x TEST leighis -&gt; lj eigh sj TEST foighid -&gt; f oigh dj TEST aithris -&gt; a rj_d @@ sj TEST sin -&gt; sj i nj TEST cheannÃ³dh -&gt; xj a nn Ã³dh TEST Ã³il -&gt; oo lj TEST Ã³l -&gt; oo ll TEST lobhadh -&gt; ll obh adh TEST todhchaÃ­ -&gt; t odh x ii TEST toghadh -&gt; t ogh adh TEST oÃ­che -&gt; ii xj @@ TEST oidhe -&gt; oidh @@ TEST oighear -&gt; oigh r TEST boird -&gt; b oo r dj TEST soir -&gt; s oi rj TEST comhar -&gt; k oo r TEST bord -&gt; b oo r d TEST bos -&gt; b o s TEST sÃºil -&gt; s uu lj TEST sÃºl -&gt; s uu ll TEST uathÃºil -&gt; u@ uu lj TEST uaine -&gt; u@ nj @@ TEST uan -&gt; u@ nn TEST subh -&gt; s ubh TEST bhuel -&gt; v e ll TEST guird -&gt; g uu r dj TEST cuid -&gt; k i dj TEST uile -&gt; i lj @@ TEST bruÃ­on -&gt; b r ii nn TEST bruÃ­ne -&gt; b r ii nj @@ TEST cumhacht -&gt; k uu x t TEST burdÃºn -&gt; b uu r d uu nn TEST cur -&gt; k u r TEST bus -&gt; b u s TEST scuabfaidh -&gt; s k u@ p idh TEST clibfidh -&gt; kj lj i pj idh TEST scuabfadh -&gt; s k u@ p adh TEST clibfeadh -&gt; kj lj i pj adh TEST bhfÃ¡inne -&gt; v aa nnj @@ TEST bhfianaise -&gt; vj i@ nn @@ sj @@ TEST scrÃ­obhfaidh -&gt; sj kj rj ii f idh TEST dÃ­bhfidh -&gt; dj ii fj idh TEST scrÃ­obhfadh -&gt; sj kj rj ii f adh TEST dÃ­bhfeadh -&gt; dj ii fj adh TEST searbh -&gt; sj a r @@ v TEST seirbhÃ­s -&gt; sj e rj @@ vj ii sj TEST bhrostaigh -&gt; v r o s t igh TEST bhris -&gt; vj rj i sj TEST coibhÃ­n -&gt; k oi vj ii nj TEST bpÃ¡istÃ­ -&gt; b aa sj tj ii TEST bpÃ©isteanna -&gt; bj ee sj tj @@ nn @@ TEST scuabtha -&gt; s k u@ p @@ TEST clibthe -&gt; kj lj i pj @@ TEST borb -&gt; b o r @@ b TEST seirbiach -&gt; sj e rj @@ bj i@ x TEST brÃ³na -&gt; b r oo nn @@ TEST brian -&gt; bj rj i@ nn TEST leÃ³dhas -&gt; lj oo s TEST t-uisce -&gt; t ui sj kj @@ TEST t-Ã©abhlÃ³idÃ­ -&gt; tj ee v ll oo dj ii TEST atfaidh -&gt; a t idh TEST titfidh -&gt; tj i tj idh TEST athdhÃ©anamh -&gt; a gfj ee nn amh TEST meathfadh -&gt; mj a h adh TEST rithfeadh -&gt; r i xj adh TEST blÃ¡thra -&gt; b ll aa r_d @@ TEST tharla -&gt; h aa r ll @@ TEST thit -&gt; hj i tj TEST tseachtain -&gt; tj a x t @@ nj TEST tsagairt -&gt; t a g @@ r tj TEST teann -&gt; tj a nn TEST tit -&gt; tj i tj TEST togra -&gt; t o g r @@ TEST sadhbh -&gt; s ai v TEST bhÃ©al -&gt; vj ee ll TEST bhÃ©il -&gt; vj ee lj . %%writefile oraghallaigh-cd.g2p CHARACTER_SET &quot;abcdefghiÃ­jklmnoÃ³prstuvwxz@.012-_&quot; DEFAULT_PHONEME &quot;_&quot; PHONEME_DELIMITER &quot; &quot; VAR BC (p|b|f|v|m_d|m|t_|t|d_|d|ll_d|ll|l_d|l|nn_d|nn|n_d|n|rr_d|r_d|rr|r|s|z|k|g|x|gf|ng_d|ng|h) VAR LLJ (llj|nnj|rrj|mj) VAR LL (ll|nn|rr|m) aa -&gt; aa abh -&gt; au adh -&gt; @ x agh -&gt; ai aÃ­o -&gt; i@ amh -&gt; @ v ai -&gt; ai ao -&gt; ee au -&gt; au a -&gt; ai / _ LLJ a -&gt; au / _ LL a -&gt; a ee -&gt; i@ / _ BC ee -&gt; ee eidh -&gt; e gj / _ # eidh -&gt; ai eigh -&gt; ai e -&gt; e idh -&gt; @ gj igh -&gt; @ gj Ã­odh -&gt; i@ x ithe -&gt; @ . 0 h @ i@ -&gt; i@ ii -&gt; ii io -&gt; i i -&gt; ii / _ LLJ # i -&gt; i obh -&gt; au Ã³dh -&gt; oo x odh -&gt; au ogh -&gt; au oidh -&gt; ai oigh -&gt; ai oi -&gt; ii / _ LLJ # oi -&gt; i omh -&gt; au oo -&gt; oo o -&gt; au / _ LL # o -&gt; o ubh -&gt; u v / _ # ubh -&gt; @ v u@ -&gt; u@ ui -&gt; ii / _ LLJ ui -&gt; i uu -&gt; uu u -&gt; u @@ -&gt; @ pj -&gt; pj p -&gt; p bj -&gt; bj b -&gt; b fj -&gt; fj f -&gt; f vj -&gt; vj v -&gt; v w -&gt; w mj_d -&gt; mj_d m_d -&gt; m_d mj -&gt; mj m -&gt; m tjsj -&gt; tjsj djzj -&gt; djzj t_- -&gt; t_- tj -&gt; tj t -&gt; t d_- -&gt; d_- dj -&gt; dj d -&gt; d llj_d -&gt; lj_d ll_d -&gt; l_d llj -&gt; lj ll -&gt; l lj_d -&gt; lj_d l_d -&gt; l_d lj -&gt; lj l -&gt; l nnj_d -&gt; nj_d nn_d -&gt; n_d nnj -&gt; nj nn -&gt; n nj_d -&gt; nj_d n_d -&gt; n_d rrj_d -&gt; rj_d rj_d -&gt; rj_d rr_d -&gt; r_d r_d -&gt; r_d rrj -&gt; rj rj -&gt; rj rr -&gt; r r -&gt; r sj -&gt; sj s -&gt; s zj -&gt; zj z -&gt; z kj -&gt; kj k -&gt; k gj -&gt; gj g -&gt; g xj -&gt; xj x -&gt; x gfj -&gt; âˆ… / _ # gfj -&gt; gfj ngj_d -&gt; ngj h ng_d -&gt; ng h ngj -&gt; nj / _ # ngj -&gt; ngj ng -&gt; ng nj -&gt; nj n -&gt; n hj -&gt; h h -&gt; h 0 -&gt; 0 1 -&gt; 1 2 -&gt; 2 . -&gt; . - -&gt; âˆ… @ -&gt; âˆ… c -&gt; âˆ… j -&gt; âˆ… Ã­ -&gt; âˆ… Ã³ -&gt; âˆ… _ -&gt; âˆ… TEST faas -&gt; f aa s TEST abhnnj -&gt; au nj TEST saghd -&gt; s ai d TEST saÃ­oxt -&gt; s i@ x t TEST djeennamh -&gt; dj ee n @ v TEST taig -&gt; t ai g TEST saoll -&gt; s ee l TEST saulj -&gt; s au lj TEST kallj -&gt; k ai lj TEST krann -&gt; k r au n TEST kad -&gt; k a d TEST eenn -&gt; i@ n TEST sjee -&gt; sj ee TEST beidh -&gt; b e gj TEST fjeidhmj -&gt; fj ai mj TEST ljeighs -&gt; lj ai s TEST djesj -&gt; dj e sj TEST bjrjisjidh -&gt; bj rj i sj @ gj TEST xjannigh -&gt; xj a n @ gj TEST kjannÃ­odh -&gt; kj a n i@ x TEST kjannithe -&gt; kj a n @ h @ TEST i@rr -&gt; i@ r TEST sjiinj -&gt; sj ii nj TEST fjios -&gt; fj i s TEST imj -&gt; ii mj TEST sjinj -&gt; sj i nj TEST llobhr -&gt; l au r TEST kjannÃ³dh -&gt; kj a n oo x TEST bodhr -&gt; b au r TEST toghxaann -&gt; t au x aa n TEST oidhrjaxt -&gt; ai rj a x t TEST oighr -&gt; ai r TEST koillj -&gt; k ii lj TEST koillj@@ -&gt; k i lj @ TEST domhnn -&gt; d au n TEST moor -&gt; m oo r TEST poll -&gt; p au l TEST polladh -&gt; p o l @ x TEST ubh@@gaann -&gt; @ v @ g aa n TEST bu@ -&gt; b u@ TEST suimj -&gt; s ii mj TEST kuidj -&gt; k i dj TEST kuur -&gt; k uu r TEST kur -&gt; k u r TEST farjsj@@ngj -&gt; f a rj sj @ nj .",
            "url": "https://jimregan.github.io/notes/irish/g2p/kerry/2021/05/17/o-raghallaigh-thesis-attempt-2-cd.html",
            "relUrl": "/irish/g2p/kerry/2021/05/17/o-raghallaigh-thesis-attempt-2-cd.html",
            "date": " â€¢ May 17, 2021"
        }
        
    
  
    
        ,"post170": {
            "title": "Kilkenny Irish example",
            "content": "ScÃ©al beagÃ¡n i nGaeilig OsraÃ­ (Contae Chill Choinnigh). pic.twitter.com/KhG3fd7fkE . &mdash; Corbmacc (@erisceres) May 17, 2021 The picture is nice; transcriptions are better: . vâ€²iË toËrÉ™ uËn fÉ™doË É‘gÉ™s vâ€²i anÉ™Ëˆxidâ€² mnÉ‘Ë egâ€²É™n toËrÉ™, É‘gÉ™s vâ€²iË sâ€²iÉ™d É™ siË eÊ’ É™ loxdÉ™, É™n É‘Ëtâ€² É™ re n toËrÉ™. welâ€², lâ€²igâ€² dinâ€²É™ brÉ™imâ€² É‘gÉ™s nâ€²iË res egâ€² eËÅ‹â€²É™ kâ€²eË lâ€²igâ€² É™n brÉ™imâ€² duËrtâ€² fâ€²ar É™ vâ€²iË gâ€²en toËrÉ™ â€˜welâ€²â€™, É™ dâ€²er sâ€²e, â€˜É™n bâ€²an É™ lâ€²igâ€² É™ brÉ™imâ€² hÉ‘Ë kÉ™ipâ€² tâ€²Ê’iË hinâ€²É™â€™ É™nsinâ€² xiÊ’ É™n vâ€²an Ç lÉ‘Ë sâ€²iÉ™r xuËn É™ kÉ™ipâ€², É‘gÇs vâ€²iËs É™ku elâ€²É™ (É™)nsinâ€² É™n bâ€²an É™ lâ€²igâ€² É™n brÉ™imâ€². . BhÃ­ tÃ³rramh ann fadÃ³ agus bhÃ­ anchuid mnÃ¡ ag an tÃ³rramh, agus bhÃ­ siad ag suÃ­ ar an lochta, an Ã¡it a raibh an tÃ³rramh. Well, lig duine broim agus nÃ­ raibh a fhios ag Ã©inne cÃ© lig an broim. DÃºirt fear a bhÃ­ ag an tÃ³rramh â€˜Wellâ€™, a deir sÃ©, â€˜an bean (sic) a lig an broim, thÃ¡ a caidhp trÃ­ thine.â€™ Ansoin chuir an bhean a lÃ¡mh siar chun a caidhp, agus bhÃ­ a fhios acu uile ansoin an bean a lig an broim. .",
            "url": "https://jimregan.github.io/notes/irish/twitter/kilkenny/2021/05/17/kilkenny-irish.html",
            "relUrl": "/irish/twitter/kilkenny/2021/05/17/kilkenny-irish.html",
            "date": " â€¢ May 17, 2021"
        }
        
    
  
    
        ,"post171": {
            "title": "Ã“ Raghallaigh in ICU",
            "content": "$wb=[^[:L:][:M:]]; $alpha = [abcdefghijklmnopqrstuvwxyz]; $cons = [bcdfghjklmnpqrstvwxyz]; $nonsyllabic = [Ã¡bcdfghjklmnÃ³pqrstÃºvwxyz#] # broad future/conditional endings $bfce = [Ã¡{adh}{aidh}{aidÃ­s}{aimid}{aimis}{ainn}{as}]; # slender future/conditional endings $sfce = [{eÃ¡}{eadh}{idh}{idÃ­s}{imid}{imis}{inn}]; $l = [{ll}l]; $mn = [mn]; $fmp = [fmp]; $lnr = [lnr]; $lrst = [lrst]; $dnlst = [dnlst]; $dnst = [dnst]; $rdnlr = [{rd}{rn}{rl}{rr}]; $vowel = [aÃ¡eÃ©iÃ­oÃ³uÃº]; # left context short broad vowel $lcsbv = [{ea}{io}{iu}aou]; # left context short slender vowel $lcssv = [{ai}{eai}{ei}e{iui}i{oi}{ui}]; # left context broad vowel $lcbv = [{adh}{ae}{ao}aÃ¡{ea}{eÃ¡}{eo}{Ã©a}{io}{iu}{iÃº}{Ã­o}oÃ³{uÃ­o}uÃº]; # right context broad vowel $rcbv = [{aei}{ae}{ai}{aoi}{ao}{a}{Ã¡i}Ã¡{oi}o{Ã³i}Ã³{ui}{uÃ­o}{uÃ­}u{Ãºi}Ãº]; # left context slender vowel $lcsv = [{aei}{aidh}{ai}{aÃ­}{aoi}{Ã¡i}{eai}{eÃ¡i}{ei}{eoi}e{Ã©i}Ã©{iai}{iui}{iÃºi}iÃ­{oi}{Ã³i}{uai}{ui}{uÃ­}{Ãºi}]; # right context slender vowel $rcsv = [{aei}{ea}{eÃ¡i}{eÃ¡}{ei}{eoi}e{Ã©a}{Ã©i}Ã©{iai}{ia}{io}{iui}{iu}{iÃºi}{iÃº}i{Ã­o}Ã­]; # left context long vowel $lclv = [{aei}{ae}{aoi}{ao}{Ã¡i}{Ã¡}{eÃ¡i}{eÃ¡}{eoi}{eÃ³}{eo}{Ã©i}Ã©{iÃºi}{iÃº}{Ã­o}Ã­{Ã³i}Ã³{uÃ­o}{uÃ­}{Ãºi}Ãº]; # left context slender long vowel $lcslv = [{aei}{aidh}{aoi}{Ã¡i}{eÃ¡i}{eoi}{Ã©i}Ã©{iÃºi}Ã­{Ã³i}{uai}{uÃ­}{Ãºi}]; Ã¡dh â†’ AA _; Ã¡i â†’ AA _; Ã¡ â†’ AA _; abh â†’ ABH _; adh } $wb â†’ ADH _; adh â†’ AI _; agh â†’ AI _; aei â†’ EE _; ae â†’ EE _; aÃ­odh } $wb â†’ ÃODH; aÃ­o â†’ AÃO _; aÃ­ â†’ II _; aidh } $wb â†’ IDH; aidh â†’ AI _; aigh } $wb â†’ IGH; aigh â†’ AI _; aithe } $wb â†’ ITHE; $wb $cons* $vowel* abh { ai } $cons+ â†’ &#39;&#39;; $wb $cons* $vowel* adh { ai } $cons+ â†’ &#39;&#39;; $wb $cons* $vowel* agh { ai } $cons+ â†’ &#39;&#39;; $wb $cons* $vowel* amh { ai } $cons+ â†’ &#39;&#39;; $wb $cons* obh { ai } $cons+ â†’ &#39;&#39;; $wb $cons* $vowel* Ã³dh { ai } $cons+ â†’ &#39;&#39;; $wb $cons* odh { ai } $cons+ â†’ &#39;&#39;; $wb $cons* $vowel* ogh { ai } $cons+ â†’ &#39;&#39;; $wb $cons* $vowel* omh { ai } $cons+ â†’ &#39;&#39;; $wb $cons* $vowel* umh { ai } $cons+ â†’ &#39;&#39;; $wb $cons* { ai } $rdnlr â†’ AA _; $wb $cons* { ai â†’ A _; $vowel+ $cons+ { ai â†’ @@; ai â†’ A; amh { $wb â†’ AMH; amh â†’ AU _; aoi â†’ AO; ao â†’ AO; $wb $cons* $vowel* abh { a } $cons+ â†’ &#39;&#39;; $wb $cons* $vowel* adh { a } $cons+ â†’ &#39;&#39;; $wb $cons* $vowel* agh { a } $cons+ â†’ &#39;&#39;; $wb $cons* $vowel* amh { a } $cons+ â†’ &#39;&#39;; $wb $cons* obh { a } $cons+ â†’ &#39;&#39;; $wb $cons* $vowel* Ã³dh { a } $cons+ â†’ &#39;&#39;; $wb $cons* odh { a } $cons+ â†’ &#39;&#39;; $wb $cons* $vowel* ogh { a } $cons+ â†’ &#39;&#39;; $wb $cons* $vowel* omh { a } $cons+ â†’ &#39;&#39;; $wb $cons* $vowel* umh { a } $cons+ â†’ &#39;&#39;; $wb $cons* { a } $rdnlr â†’ AA _; $wb $cons* { a â†’ A _; $vowel+ $cons+ { a â†’ @ _; a â†’ A _; Ã©a â†’ EE _; Ã©i â†’ EE _; Ã© â†’ EE _; eÃ¡i â†’ AA _; eÃ¡ â†’ AA _; eabh â†’ ABH _; eadh } $wb â†’ ADH; eadh â†’ AU _; eagh â†’ AI _; eai â†’ A _; eamh } $wb â†’ AMH; $wb $cons* eamh â†’ AU _; $wb $cons* $vowel igh { ea } $cons+ â†’ &#39;&#39;; . abhainn ABH NNJ bualadh B U@ LL ADH sadhbh S AI V saghas S AI S gaeilge G EE LJ GJ @@ saolaÃ­odh S AO LL ÃODH gardaÃ­ G AA R D II dÃºnfaidh D UU NN_D IDH aidhm AI MJ cheadaigh XJ A D IGH aighneas AI NJ @@ S diÃºltaithe DJ UU LL T ITHE seabhaic SJ ABH KJ feadhain FJ AU NJ teaghais TJ AI SJ eamhain AU NJ lobhair LL OBH RJ leÃ³dhais LJ OO SJ bodhair B ODH RJ eoghain OO NJ broghais B R OGH SJ comhair K OO RJ ciumhais KJ UU SJ airde AA RJ DJ @@ cait K A TJ sodair S O D @@ RJ ait A TJ dÃ©anamh DJ EE NN AMH amharc AU R K gaoil G AO LJ gaol G AO L seabhac SJ ABH K ceadharlach KJ AU R LL @@ X teaghasÃ¡n TJ AI S AA NN lobhar LL OBH R leÃ³dhas LL OO S bodhar B ODH R eoghan OO NN bogha B OGH comhar K OO R dumhach D UU X ard AA R D cat K A T sodar S O D @@ R at A T Ã©an EE NN Ã©inÃ­nÃ­ EE NJ II NJ II Ã© EE .",
            "url": "https://jimregan.github.io/notes/irish/g2p/incomplete/2021/05/16/oraghallaigh-icu.html",
            "relUrl": "/irish/g2p/incomplete/2021/05/16/oraghallaigh-icu.html",
            "date": " â€¢ May 16, 2021"
        }
        
    
  
    
        ,"post172": {
            "title": "Converting Ã“ Raghallaigh (2010)",
            "content": "This notebook contains a re-implementation of the &quot;global&quot; phonetiser from Brian Ã“ Raghallaigh&#39;s Ph.D. thesis using rbg2p. . Brian Ã“ Raghallaigh (2010). Multi-dialect phonetisation for Irish text-to-speech synthesis: a modular approach. (Doctoral thesis, Trinity College, Dublin), Appendix B.1 . @phdthesis{oraghallaigh2010multidialect, author = {Brian Ã“~Raghallaigh}, title = {Multi-dialect phonetisation for {I}rish text-to-speech synthesis: a modular approach}, school = {Trinity College, Dublin}, year = 2010, address = {Dublin, Ireland}, month = 9, } . The initial run (after small conversion errors were corrected) gave the following set of errors: . FAILED TEST: for &#39;comhair&#39;, expected /K OO RJ/, got /K OMH RJ/ FAILED TEST: for &#39;airde&#39;, expected /AA RJ DJ @@/, got /AA R DJ @@/ FAILED TEST: for &#39;bogha&#39;, expected /B OGH/, got /B OGH @@/ FAILED TEST: for &#39;comhar&#39;, expected /K OO R/, got /K OMH R/ FAILED TEST: for &#39;ceird&#39;, expected /KJ EE RJ DJ/, got /KJ EE R DJ/ FAILED TEST: for &#39;riail&#39;, expected /RJ I@ LJ/, got /R I@ LJ/ FAILED TEST: for &#39;giuirlÃ©id&#39;, expected /GJ UU RJ LJ EE DJ/, got /GJ UU R LJ EE DJ/ FAILED TEST: for &#39;boird&#39;, expected /B OO RJ DJ/, got /B OO R DJ/ FAILED TEST: for &#39;bantaboic&#39;, expected /B A NN T @@ B @@ KJ/, got /B A NN T @@ B OI KJ/ FAILED TEST: for &#39;comhar&#39;, expected /K OO R/, got /K OMH R/ FAILED TEST: for &#39;bantaboc&#39;, expected /B A NN T @@ B @@ K/, got /B A NN T @@ B O K/ FAILED TEST: for &#39;guird&#39;, expected /G UU RJ DJ/, got /G UU R DJ/ FAILED TEST: for &#39;bhfianaise&#39;, expected /VJ I@ NN @@ SJ @@/, got /V I@ NN @@ SJ @@/ FAILED TEST: for &#39;leathbhosca&#39;, expected /LJ A V @@ S K @@/, got /LJ A V O S K @@/ FAILED TEST: for &#39;rithfeadh&#39;, expected /RJ I XJ ADH/, got /R I XJ ADH/ FAILED TEST: for &#39;tsagairt&#39;, expected /T A G @@ RJ TJ/, got /T A G @@ R TJ/ 16 OF 168 TESTS FAILED FOR briain.g2p exit status 1 . The most consistent source of errors is slender &#39;r&#39; in environments (word initially, before &#39;d&#39;, etc.) where the rule is that they should be left broad; I corrected the tests (which were intended only as tests of the vowels). . Of the remainder, bogha represents a missing rule, while comhar/comhair does not fit with the given rule, so I added a somewhat lexicalised rule to handle it (and its mutated forms) specifically. . This leaves these words: . FAILED TEST: for &#39;bantaboic&#39;, expected /B A NN T @@ B @@ KJ/, got /B A NN T @@ B OI KJ/ FAILED TEST: for &#39;bantaboc&#39;, expected /B A NN T @@ B @@ K/, got /B A NN T @@ B O K/ FAILED TEST: for &#39;leathbhosca&#39;, expected /LJ A V @@ S K @@/, got /LJ A V O S K @@/ . leathbhosca is a compound, and keeping bhosca as V O S K @@ is correct; otherwise, the rule which for other short vowels converts to schwa is specifically converted to O, so I disabled these rules. . %%writefile oraghallaigh.g2p CHARACTER_SET &quot;aÃ¡bcdeÃ©fghiÃ­jklmnoÃ³pqrstuÃºvwxyz&#39;-â€™&quot; DEFAULT_PHONEME &quot;_&quot; PHONEME_DELIMITER &quot; &quot; #VAR ALPHA [abcdefghijklmnopqrstuvwxyz] VAR CONS [bcdfghjklmnpqrstvwxyz] VAR CONSS [bcdfghjklmnpqrstvwxyz]* VAR CONSP [bcdfghjklmnpqrstvwxyz]+ # including &#39;#&#39; doesn&#39;t work, so those rules were duplicated #VAR NONSYLLABIC (Ã¡|b|c|d|f|g|h|j|k|l|m|n|Ã³|p|q|r|s|t|Ãº|v|w|x|y|z|#) VAR NONSYLLABIC [Ã¡bcdfghjklmnÃ³pqrstÃºvwxyz] // broad future/conditional endings VAR BFCE (Ã¡|adh|aidh|aidÃ­s|aimid|aimis|ainn|as) // slender future/conditional endings VAR SFCE (eÃ¡|eadh|idh|idÃ­s|imid|imis|inn) #VAR L (ll|l) #VAR MN [mn] VAR FMP [fmp] #VAR LNR [lnr] VAR LNRP [lnr]+ #VAR LRST [lrst] VAR DNLST [dnlst] #VAR DNST [dnst] VAR RDNLR (rd|rn|rl|rr) VAR VOWEL [aÃ¡eÃ©iÃ­oÃ³uÃº] VAR VOWELS [aÃ¡eÃ©iÃ­oÃ³uÃº]* VAR VOWELP [aÃ¡eÃ©iÃ­oÃ³uÃº]+ // left context short broad vowel VAR LCSBV (ea|io|iu|a|o|u) // left context short slender vowel VAR LCSSV (ai|eai|ei|e|iui|i|oi|ui) // left context broad vowel VAR LCBV (adh|ae|ao|aÃ¡|ea|eÃ¡|eo|Ã©a|io|iu|iÃº|Ã­o|oÃ³|uÃ­o|ua|u|Ãº) // right context broad vowel #VAR RCBV (aei|ae|ai|aoi|ao|a|Ã¡i|Ã¡|oi|o|Ã³i|Ã³|ui|uÃ­o|uÃ­|u|Ãºi|Ãº) // left context slender vowel VAR LCSV (aei|aidh|ai|aÃ­|aoi|Ã¡i|eai|eÃ¡i|ei|eoi|e|Ã©i|Ã©|iai|iui|iÃºi|i|Ã­|oi|Ã³i|uai|ui|uÃ­|Ãºi) VAR LCSVS (aei|aidh|ai|aÃ­|aoi|Ã¡i|eai|eÃ¡i|ei|eoi|e|Ã©i|Ã©|iai|iui|iÃºi|i|Ã­|oi|Ã³i|uai|ui|uÃ­|Ãºi)* // right context slender vowel VAR RCSV (eai|ea|eÃ¡i|eÃ¡|ei|eoi|eo|e|Ã©a|Ã©i|Ã©|iai|ia|io|iui|iu|iÃºi|iÃº|i|Ã­o|Ã­) // left context long vowel VAR LCLV (aei|ae|aoi|ao|Ã¡i|Ã¡|eÃ¡i|eÃ¡|eoi|eÃ³|eo|Ã©i|Ã©|iÃºi|iÃº|Ã­o|Ã­|Ã³i|Ã³|uÃ­o|uÃ­|Ãºi|Ãº) // left context slender long vowel VAR LCSLV (aei|aidh|aoi|Ã¡i|eÃ¡i|eoi|Ã©i|Ã©|iÃºi|Ã­|Ã³i|uai|uÃ­|Ãºi) Ã¡dh -&gt; AA Ã¡i -&gt; AA Ã¡ -&gt; AA abh -&gt; ABH adh -&gt; ADH / _ # adh -&gt; AI agh -&gt; AI aei -&gt; EE ae -&gt; EE aÃ­odh -&gt; ÃODH / _ # aÃ­o -&gt; AÃO aÃ­ -&gt; II aidh -&gt; IDH / _ # aidh -&gt; AI aigh -&gt; IGH / _ # aigh -&gt; AI aithe -&gt; ITHE / _ # ai -&gt; âˆ… / # CONSS VOWELS abh _ CONSP ai -&gt; âˆ… / # CONSS VOWELS adh _ CONSP ai -&gt; âˆ… / # CONSS VOWELS agh _ CONSP ai -&gt; âˆ… / # CONSS VOWELS amh _ CONSP ai -&gt; âˆ… / # CONSS obh _ CONSP ai -&gt; âˆ… / # CONSS VOWELS Ã³dh _ CONSP ai -&gt; âˆ… / # CONSS odh _ CONSP ai -&gt; âˆ… / # CONSS VOWELS ogh _ CONSP ai -&gt; âˆ… / # CONSS VOWELS omh _ CONSP ai -&gt; âˆ… / # CONSS VOWELS umh _ CONSP ai -&gt; AA / # CONSS _ RDNLR ai -&gt; A / # CONSS _ ai -&gt; @@ / VOWELP CONSP _ ai -&gt; A amh -&gt; AMH / _ # amh -&gt; AU aoi -&gt; AO ao -&gt; AO a -&gt; âˆ… / # CONSS VOWELS abh _ CONSP a -&gt; âˆ… / # CONSS VOWELS adh _ CONSP a -&gt; âˆ… / # CONSS VOWELS agh _ CONSP a -&gt; âˆ… / # CONSS VOWELS amh _ CONSP a -&gt; âˆ… / # CONSS obh _ CONSP a -&gt; âˆ… / # CONSS VOWELS Ã³dh _ CONSP a -&gt; âˆ… / # CONSS odh _ CONSP a -&gt; âˆ… / # CONSS VOWELS ogh _ CONSP a -&gt; âˆ… / # CONSS VOWELS omh _ CONSP a -&gt; âˆ… / # CONSS VOWELS umh _ CONSP # addition a -&gt; âˆ… / # CONSS VOWELS ogh _ # omh -&gt; OO / (gc|ch|c) _ (ai|a) r a -&gt; AA / # CONSS _ RDNLR a -&gt; A / # CONSS _ a -&gt; @@ / VOWELP CONSP _ a -&gt; A Ã©a -&gt; EE Ã©i -&gt; EE Ã© -&gt; EE eÃ¡i -&gt; AA eÃ¡ -&gt; AA eabh -&gt; ABH eadh -&gt; ADH / _ # eadh -&gt; AU eagh -&gt; AI eai -&gt; A eamh -&gt; AMH / _ # eamh -&gt; AU / # CONSS _ # VOWEL, or VOWELS ?? ea -&gt; âˆ… / # CONSS VOWEL igh _ CONSP ea -&gt; AA / # CONSS _ RDNLR ea -&gt; A / # CONSS _ ea -&gt; @@ / VOWELP CONSP _ ea -&gt; A eidh -&gt; EIDH eigh -&gt; EIGH ei -&gt; EE / # CONSS _ RDNLR # ei -&gt; EE / # CONSS _ RDNLR NONSYLLABIC ei -&gt; E / # CONSS _ ei -&gt; E eÃ³dh -&gt; OO eoi -&gt; OO eÃ³ -&gt; OO eo -&gt; OO e -&gt; E / # CONSS _ e -&gt; @@ / VOWELP CONSP _ e -&gt; E Ã­odh -&gt; ÃODH / _ # Ã­o -&gt; II Ã­ -&gt; II iadh -&gt; I@ iath -&gt; I@ iai -&gt; I@ ia -&gt; I@ idh -&gt; IDH igh -&gt; IGH io -&gt; IO ithe -&gt; ITHE / _ # iÃºi -&gt; UU iÃº -&gt; UU iubh -&gt; UBH iumh -&gt; UU iui -&gt; UU iu -&gt; U i -&gt; âˆ… / # CONSS VOWEL idh _ CONSP # i -&gt; âˆ… / # CONSS VOWEL igh _ CONSP i -&gt; @@ / VOWELP CONSP _ i -&gt; I Ã³dh -&gt; Ã“DH / _ # Ã³i -&gt; OO Ã³ -&gt; OO obh -&gt; OBH odh -&gt; ODH ogh -&gt; OGH oÃ­ -&gt; II oidh -&gt; OIDH oigh -&gt; OIGH oi -&gt; OO / # CONSS _ RDNLR oi -&gt; @@ / # VOWELP CONSP _ oi -&gt; OI omh -&gt; OMH o -&gt; OO / # CONSS _ RDNLR # o -&gt; OO / # CONSS _ RDNLR NONSYLLABIC o -&gt; O / # VOWELP CONSP _ o -&gt; O Ãºi -&gt; UU Ãº -&gt; UU uath -&gt; U@ uai -&gt; U@ ua -&gt; U@ ubh -&gt; UBH ue -&gt; E ui -&gt; UU / # CONSS _ RDNLR # ui -&gt; UU / # CONSS _ RDNLR NONSYLLABIC ui -&gt; I / # CONSS _ ui -&gt; @@ / VOWELP CONSP _ ui -&gt; UI uÃ­o -&gt; II uÃ­ -&gt; II umh -&gt; UU u -&gt; UU / # CONSS _ RDNLR u -&gt; U / # CONSS _ u -&gt; @@ / VOWELP CONSP _ u -&gt; U bf -&gt; P / _ BFCE # bf -&gt; PJ / _ SFCE # bhf -&gt; VJ / # _ CONSS RCSV # bhf -&gt; VJ / # _ CONSS RCSV NONSYLLABIC bhf -&gt; V / # _ bhf -&gt; F / _ BFCE # bhf -&gt; FJ / _ SFCE # bh -&gt; @@ V / # LCSBV LNRP _ bh -&gt; @@ V / NONSYLLABIC LCSBV LNRP _ bh -&gt; @@ VJ / # LCSSV LNRP _ bh -&gt; @@ VJ / NONSYLLABIC LCSSV LNRP _ bh -&gt; VJ / # _ CONSS RCSV # bh -&gt; VJ / # _ CONSS RCSV NONSYLLABIC bh -&gt; V / # _ bh -&gt; VJ / _ CONSS RCSV # bh -&gt; VJ / _ CONSS RCSV NONSYLLABIC bh -&gt; VJ / # LCSV CONSP _ bh -&gt; VJ / NONSYLLABIC LCSV CONSP _ bh -&gt; VJ / # LCSV _ bh -&gt; VJ / NONSYLLABIC LCSV _ bh -&gt; V bp -&gt; BJ / # _ CONSS RCSV # bp -&gt; BJ / # _ CONSS RCSV NONSYLLABIC bp -&gt; B / # _ bth -&gt; P / LCBV CONSS _ bth -&gt; PJ / LCSV CONSS _ b -&gt; @@ B / # LCSBV LNRP _ b -&gt; @@ B / NONSYLLABIC LCSBV LNRP _ b -&gt; @@ BJ / # LCSSV LNRP _ b -&gt; @@ BJ / NONSYLLABIC LCSSV LNRP _ b -&gt; BJ / _ CONSS RCSV # b -&gt; BJ / _ CONSS RCSV NONSYLLABIC b -&gt; BJ / # LCSV CONSP _ b -&gt; BJ / NONSYLLABIC LCSV CONSP _ b -&gt; BJ / # LCSV _ b -&gt; BJ / NONSYLLABIC LCSV _ b -&gt; B cf -&gt; K / _ BFCE # cf -&gt; KJ / _ SFCE # chf -&gt; X / _ BFCE # chf -&gt; XJ / _ SFCE # ch -&gt; @@ X / # LCSBV LNRP _ ch -&gt; @@ X / NONSYLLABIC LCSBV LNRP _ ch -&gt; @@ XJ / # LCSSV LNRP _ ch -&gt; @@ XJ / NONSYLLABIC LCSSV LNRP _ ch -&gt; XJ / # _ CONSS RCSV # ch -&gt; XJ / # _ CONSS RCSV NONSYLLABIC ch -&gt; X / # _ ch -&gt; XJ / _ CONSS RCSV # ch -&gt; XJ / _ CONSS RCSV NONSYLLABIC ch -&gt; XJ / # LCSV CONSP _ ch -&gt; XJ / NONSYLLABIC LCSV CONSP _ ch -&gt; XJ / # LCSV _ ch -&gt; XJ / NONSYLLABIC LCSV _ ch -&gt; X cth -&gt; K / LCBV CONSS _ cth -&gt; KJ / LCSV CONSS _ c -&gt; KJ / _ CONSS RCSV # c -&gt; KJ / _ CONSS RCSV NONSYLLABIC c -&gt; KJ / # LCSV CONSP _ c -&gt; KJ / NONSYLLABIC LCSV CONSP _ c -&gt; KJ / # LCSV _ c -&gt; KJ / NONSYLLABIC LCSV _ c -&gt; K df -&gt; T / _ BFCE # df -&gt; TJ / _ SFCE # dha -&gt; âˆ… / # LCLV _ dha -&gt; âˆ… / NONSYLLABIC LCLV _ dh -&gt; GFJ / # LCSLV _ dh -&gt; GFJ / NONSYLLABIC LCSLV _ dh -&gt; GFJ / # CONSS LCSVS _ # dh -&gt; âˆ… / # LCLV _ dh -&gt; âˆ… / NONSYLLABIC LCLV _ dh -&gt; GFJ / # _ CONSS RCSV # dh -&gt; GFJ / # _ CONSS RCSV NONSYLLABIC dh -&gt; GF / # _ dh -&gt; GFJ / _ CONSS RCSV # dh -&gt; GFJ / _ CONSS RCSV NONSYLLABIC dh -&gt; GFJ / # LCSV CONSP _ dh -&gt; GFJ / NONSYLLABIC LCSV CONSP _ dh -&gt; GFJ / # LCSV _ dh -&gt; GFJ / NONSYLLABIC LCSV _ dh -&gt; GF dt -&gt; DJ / # _ CONSS RCSV # dt -&gt; DJ / # _ CONSS RCSV NONSYLLABIC dt -&gt; D / # _ dt -&gt; T / LCBV CONSS _ dt -&gt; TJ / LCSV CONSS _ d -&gt; DJ / _ CONSS RCSV # d -&gt; DJ / _ CONSS RCSV NONSYLLABIC d -&gt; DJ / # LCSV CONSP _ d -&gt; DJ / NONSYLLABIC LCSV CONSP _ d -&gt; DJ / # LCSV _ d -&gt; DJ / NONSYLLABIC LCSV _ d -&gt; D fh -&gt; âˆ… f -&gt; H / VOWEL _ BFCE # f -&gt; HJ / VOWEL _ SFCE # f -&gt; @@ F / # LCSBV LNRP _ f -&gt; @@ F / NONSYLLABIC LCSBV LNRP _ f -&gt; @@ FJ / # LCSSV LNRP _ f -&gt; @@ FJ / NONSYLLABIC LCSSV LNRP _ f -&gt; FJ / _ CONSS RCSV # f -&gt; FJ / _ CONSS RCSV NONSYLLABIC f -&gt; FJ / # LCSV CONSP _ f -&gt; FJ / NONSYLLABIC LCSV CONSP _ f -&gt; FJ / # LCSV _ f -&gt; FJ / NONSYLLABIC LCSV _ f -&gt; F gc -&gt; GJ / # _ CONSS RCSV # gc -&gt; GJ / # _ CONSS RCSV NONSYLLABIC gc -&gt; G / # _ gf -&gt; K / _ BFCE # gf -&gt; KJ / _ SFCE # gh -&gt; GFJ / # _ CONSS RCSV # gh -&gt; GFJ / # _ CONSS RCSV NONSYLLABIC gh -&gt; GF / # _ gh -&gt; GFJ / # LCSLV _ gh -&gt; GFJ / NONSYLLABIC LCSLV _ gh -&gt; GFJ / # CONSS LCSVS _ # gh -&gt; âˆ… / # LCLV _ gh -&gt; âˆ… / NONSYLLABIC LCLV _ gh -&gt; GFJ / _ CONSS RCSV # gh -&gt; GFJ / _ CONSS RCSV NONSYLLABIC gh -&gt; GFJ / # LCSV CONSP _ gh -&gt; GFJ / NONSYLLABIC LCSV CONSP _ gh -&gt; GFJ / # LCSV _ gh -&gt; GFJ / NONSYLLABIC LCSV _ gh -&gt; GF gth -&gt; K / LCBV CONSS _ gth -&gt; KJ / LCSV CONSS _ g -&gt; @@ G / # LCSBV LNRP _ g -&gt; @@ G / NONSYLLABIC LCSBV LNRP _ g -&gt; @@ GJ / # LCSSV LNRP _ g -&gt; @@ GJ / NONSYLLABIC LCSSV LNRP _ g -&gt; GJ / _ CONSS RCSV # g -&gt; GJ / _ CONSS RCSV NONSYLLABIC g -&gt; GJ / # LCSV CONSP _ g -&gt; GJ / NONSYLLABIC LCSV CONSP _ g -&gt; GJ / # LCSV _ g -&gt; GJ / NONSYLLABIC LCSV _ g -&gt; G h -&gt; HJ / _ CONSS RCSV # h -&gt; HJ / _ CONSS RCSV NONSYLLABIC h -&gt; HJ / # LCSV CONSP _ h -&gt; HJ / NONSYLLABIC LCSV CONSP _ h -&gt; HJ / # LCSV _ h -&gt; HJ / NONSYLLABIC LCSV _ h -&gt; H j -&gt; DJZJ k -&gt; KJ / _ CONSS RCSV # k -&gt; KJ / _ CONSS RCSV NONSYLLABIC k -&gt; KJ / # LCSV CONSP _ k -&gt; KJ / NONSYLLABIC LCSV CONSP _ k -&gt; KJ / # LCSV _ k -&gt; KJ / NONSYLLABIC LCSV _ k -&gt; K llf -&gt; LL_D / _ BFCE # llf -&gt; LLJ_D / _ SFCE # llth -&gt; LL_D / LCBV CONSS _ llth -&gt; LLJ_D / LCSV CONSS _ ll -&gt; LLJ / _ CONSS RCSV # ll -&gt; LLJ / _ CONSS RCSV NONSYLLABIC ll -&gt; LLJ / # LCSV CONSP _ ll -&gt; LLJ / NONSYLLABIC LCSV CONSP _ ll -&gt; LLJ / # LCSV _ ll -&gt; LLJ / NONSYLLABIC LCSV _ ll -&gt; LL lf -&gt; LL_D / _ BFCE # lf -&gt; LJ_D / _ SFCE # lth -&gt; LL_D / LCBV CONSS _ lth -&gt; LJ_D / LCSV CONSS _ l -&gt; LJ / _ CONSS RCSV # l -&gt; LJ / _ CONSS RCSV NONSYLLABIC l -&gt; LJ / # LCSV CONSP _ l -&gt; LJ / NONSYLLABIC LCSV CONSP _ l -&gt; LJ / # LCSV _ l -&gt; LJ / NONSYLLABIC LCSV _ l -&gt; LL mb -&gt; MJ / # _ CONSS RCSV # mb -&gt; MJ / # _ CONSS RCSV NONSYLLABIC mb -&gt; M / # _ mf -&gt; M_D / _ BFCE # mf -&gt; MJ_D / _ SFCE # mhf -&gt; F / _ BFCE # mhf -&gt; FJ / _ SFCE # mh -&gt; VJ / # _ CONSS RCSV # mh -&gt; VJ / # _ CONSS RCSV NONSYLLABIC mh -&gt; V / # _ mh -&gt; @@ V / # LCSBV LNRP _ mh -&gt; @@ V / NONSYLLABIC LCSBV LNRP _ mh -&gt; @@ VJ / # LCSSV LNRP _ mh -&gt; @@ VJ / NONSYLLABIC LCSSV LNRP _ mh -&gt; VJ / _ CONSS RCSV # mh -&gt; VJ / _ CONSS RCSV NONSYLLABIC mh -&gt; VJ / # LCSV CONSP _ mh -&gt; VJ / NONSYLLABIC LCSV CONSP _ mh -&gt; VJ / # LCSV _ mh -&gt; VJ / NONSYLLABIC LCSV _ mh -&gt; V mth -&gt; M_D / LCBV CONSS _ mth -&gt; MJ_D / LCSV CONSS _ m -&gt; @@ M / # LCSBV LNRP _ m -&gt; @@ M / NONSYLLABIC LCSBV LNRP _ m -&gt; @@ MJ / # LCSSV LNRP _ m -&gt; @@ MJ / NONSYLLABIC LCSSV LNRP _ m -&gt; MJ / _ CONSS RCSV # m -&gt; MJ / _ CONSS RCSV NONSYLLABIC m -&gt; MJ / # LCSV CONSP _ m -&gt; MJ / NONSYLLABIC LCSV CONSP _ m -&gt; MJ / # LCSV _ m -&gt; MJ / NONSYLLABIC LCSV _ m -&gt; M nnf -&gt; NN_D / _ BFCE # nnf -&gt; NNJ_D / _ SFCE # nnth -&gt; NN_D / LCBV CONSS _ nnth -&gt; NNJ_D / LCSV CONSS _ nn -&gt; NNJ / _ CONSS RCSV # nn -&gt; NNJ / _ CONSS RCSV NONSYLLABIC nn -&gt; NNJ / # LCSV CONSP _ nn -&gt; NNJ / NONSYLLABIC LCSV CONSP _ nn -&gt; NNJ / # LCSV _ nn -&gt; NNJ / NONSYLLABIC LCSV _ nn -&gt; NN n- -&gt; NJ / # _ RCSV # n- -&gt; NJ / # _ RCSV NONSYLLABIC n- -&gt; NN / # _ nd -&gt; NNJ / # _ CONSS RCSV # nd -&gt; NNJ / # _ CONSS RCSV NONSYLLABIC nd -&gt; NN / # _ nf -&gt; NN_D / _ BFCE # nf -&gt; NJ_D / _ SFCE # ngf -&gt; NG_D / _ BFCE # ngf -&gt; NGJ_D / _ SFCE # ngth -&gt; NG_D / LCBV CONSS _ ngth -&gt; NGJ_D / LCSV CONSS _ ng -&gt; NGJ / # _ CONSS RCSV # ng -&gt; NGJ / # _ CONSS RCSV NONSYLLABIC ng -&gt; NG / # _ ng -&gt; NJ / # LCSV _ t # ng -&gt; NJ / NONSYLLABIC LCSV _ t # ng -&gt; NGJ / _ CONSS RCSV # ng -&gt; NGJ / _ CONSS RCSV NONSYLLABIC ng -&gt; NGJ / # LCSV CONSP _ ng -&gt; NGJ / NONSYLLABIC LCSV CONSP _ ng -&gt; NGJ / # LCSV _ ng -&gt; NGJ / NONSYLLABIC LCSV _ ng -&gt; NG nth -&gt; NN_D / LCBV CONSS _ nth -&gt; NJ_D / LCSV CONSS _ n -&gt; NGJ / # LCSV _ c n -&gt; NGJ / NONSYLLABIC LCSV _ c n -&gt; NG / _ c n -&gt; NJ / _ CONSS RCSV # n -&gt; NJ / _ CONSS RCSV NONSYLLABIC n -&gt; NJ / # LCSV CONSP _ n -&gt; NJ / NONSYLLABIC LCSV CONSP _ n -&gt; NJ / # LCSV _ n -&gt; NJ / NONSYLLABIC LCSV _ n -&gt; NN pf -&gt; P / _ BFCE # pf -&gt; PJ / _ SFCE # ph -&gt; FJ / # _ CONSS RCSV # ph -&gt; FJ / # _ CONSS RCSV NONSYLLABIC ph -&gt; F / # _ ph -&gt; FJ / _ CONSS RCSV # ph -&gt; FJ / _ CONSS RCSV NONSYLLABIC ph -&gt; FJ / # LCSV CONSP _ ph -&gt; FJ / NONSYLLABIC LCSV CONSP _ ph -&gt; FJ / # LCSV _ ph -&gt; FJ / NONSYLLABIC LCSV _ ph -&gt; F pth -&gt; P / LCBV CONSS _ pth -&gt; PJ / LCSV CONSS _ p -&gt; PJ / _ CONSS RCSV # p -&gt; PJ / _ CONSS RCSV NONSYLLABIC p -&gt; PJ / # LCSV CONSP _ p -&gt; PJ / NONSYLLABIC LCSV CONSP _ p -&gt; PJ / # LCSV _ p -&gt; PJ / NONSYLLABIC LCSV _ p -&gt; P # really? there&#39;s a &#39;W&#39; in the phoneset q -&gt; K V rrf -&gt; RR_D / _ BFCE # rrf -&gt; RRJ_D / _ SFCE # rrth -&gt; RR_D / LCBV CONSS _ rrth -&gt; RRJ_D / LCSV CONSS _ rr -&gt; RRJ / _ CONSS RCSV # rr -&gt; RRJ / _ CONSS RCSV NONSYLLABIC rr -&gt; RRJ / # LCSV CONSP _ rr -&gt; RRJ / NONSYLLABIC LCSV CONSP _ rr -&gt; RRJ / # LCSV _ rr -&gt; RRJ / NONSYLLABIC LCSV _ rr -&gt; RR rf -&gt; R_D / _ BFCE # rf -&gt; RJ_D / _ SFCE # rth -&gt; R_D / LCBV CONSS _ rth -&gt; RJ_D / LCSV CONSS _ r -&gt; R / # s _ r -&gt; R / # _ // This rule blocks tests for airde and ceird r -&gt; R / _ DNLST r -&gt; RJ / _ CONSS RCSV # r -&gt; RJ / _ CONSS RCSV NONSYLLABIC r -&gt; RJ / # LCSV CONSP _ r -&gt; RJ / NONSYLLABIC LCSV CONSP _ r -&gt; RJ / # LCSV _ r -&gt; RJ / NONSYLLABIC LCSV _ r -&gt; R sf -&gt; S / _ BFCE # sf -&gt; SJ / _ SFCE # shl -&gt; LJ_D / _ CONSS RCSV # shl -&gt; LJ_D / _ CONSS RCSV NONSYLLABIC shl -&gt; LL_D shm -&gt; MJ_D / _ CONSS RCSV # shm -&gt; MJ_D / _ CONSS RCSV NONSYLLABIC shm -&gt; M_D shn -&gt; NJ_D / _ CONSS RCSV # shn -&gt; NJ_D / _ CONSS RCSV NONSYLLABIC shn -&gt; NN_D shr -&gt; RJ_D / _ CONSS RCSV # shr -&gt; RJ_D / _ CONSS RCSV NONSYLLABIC shr -&gt; R_D sh -&gt; XJ / # _ CONSS RCSV # sh -&gt; XJ / # _ CONSS RCSV NONSYLLABIC sh -&gt; H / # _ sh -&gt; XJ / _ CONSS RCSV # sh -&gt; XJ / _ CONSS RCSV NONSYLLABIC sh -&gt; XJ / # LCSV CONSP _ sh -&gt; XJ / NONSYLLABIC LCSV CONSP _ sh -&gt; XJ / # LCSV _ sh -&gt; XJ / NONSYLLABIC LCSV _ sh -&gt; H s -&gt; S / # _ r s -&gt; S / # _ FMP CONSS RCSV # s -&gt; S / # _ FMP CONSS RCSV NONSYLLABIC s -&gt; SJ / _ CONSS RCSV # s -&gt; SJ / _ CONSS RCSV NONSYLLABIC s -&gt; SJ / # LCSV CONSP _ s -&gt; SJ / NONSYLLABIC LCSV CONSP _ s -&gt; SJ / # LCSV _ s -&gt; SJ / NONSYLLABIC LCSV _ s -&gt; S t- -&gt; TJ / # _ RCSV # t- -&gt; TJ / # _ RCSV NONSYLLABIC t- -&gt; T / # _ tf -&gt; T / _ BFCE # tf -&gt; TJ / _ SFCE # // &quot;hack for compound boundaries&quot; th -&gt; âˆ… / _ CONS h thb -&gt; PJ / _ CONSS RCSV # thb -&gt; PJ / _ CONSS RCSV NONSYLLABIC thb -&gt; P thc -&gt; KJ / _ CONSS RCSV # thc -&gt; KJ / _ CONSS RCSV NONSYLLABIC thc -&gt; K thd -&gt; TJ / _ CONSS RCSV # thd -&gt; TJ / _ CONSS RCSV NONSYLLABIC thd -&gt; T thf -&gt; H / _ BFCE # thf -&gt; XJ / _ SFCE # thl -&gt; LJ_D / _ CONSS RCSV # thl -&gt; LJ_D / _ CONSS RCSV NONSYLLABIC thl -&gt; LL_D thm -&gt; MJ_D / _ CONSS RCSV # thm -&gt; MJ_D / _ CONSS RCSV NONSYLLABIC thm -&gt; M_D thn -&gt; NJ_D / _ CONSS RCSV # thn -&gt; NJ_D / _ CONSS RCSV NONSYLLABIC thn -&gt; NN_D thp -&gt; PJ / _ CONSS RCSV # thp -&gt; PJ / _ CONSS RCSV NONSYLLABIC thp -&gt; P thr -&gt; RJ_D / _ CONSS RCSV # thr -&gt; RJ_D / _ CONSS RCSV NONSYLLABIC thr -&gt; R_D ths -&gt; SJ / _ CONSS RCSV # ths -&gt; SJ / _ CONSS RCSV NONSYLLABIC ths -&gt; S tht -&gt; TJ / _ CONSS RCSV # tht -&gt; TJ / _ CONSS RCSV NONSYLLABIC tht -&gt; T th -&gt; HJ / # _ CONSS RCSV # th -&gt; HJ / # _ CONSS RCSV NONSYLLABIC th -&gt; H / # _ th -&gt; HJ / _ CONSS RCSV # th -&gt; HJ / _ CONSS RCSV NONSYLLABIC th -&gt; HJ / # LCSV CONSP _ th -&gt; HJ / NONSYLLABIC LCSV CONSP _ th -&gt; HJ / # LCSV _ th -&gt; HJ / NONSYLLABIC LCSV _ th -&gt; H ts -&gt; TJ / # _ CONSS RCSV # ts -&gt; TJ / # _ CONSS RCSV NONSYLLABIC ts -&gt; T / # _ t -&gt; TJ / _ CONSS RCSV # t -&gt; TJ / _ CONSS RCSV NONSYLLABIC t -&gt; TJ / # LCSV CONSP _ t -&gt; TJ / NONSYLLABIC LCSV CONSP _ t -&gt; TJ / # LCSV _ t -&gt; TJ / NONSYLLABIC LCSV _ t -&gt; T v -&gt; VJ / _ CONSS RCSV # v -&gt; VJ / _ CONSS RCSV NONSYLLABIC v -&gt; VJ / # LCSV CONSP _ v -&gt; VJ / NONSYLLABIC LCSV CONSP _ v -&gt; VJ / # LCSV _ v -&gt; VJ / NONSYLLABIC LCSV _ v -&gt; V w -&gt; V x- -&gt; E KJ S x -&gt; ZJ y -&gt; GFJ z -&gt; ZJ / _ CONSS RCSV # z -&gt; ZJ / _ CONSS RCSV NONSYLLABIC z -&gt; ZJ / # LCSV CONSP _ z -&gt; ZJ / NONSYLLABIC LCSV CONSP _ z -&gt; ZJ / # LCSV _ z -&gt; ZJ / NONSYLLABIC LCSV _ z -&gt; Z &#39; -&gt; âˆ… â€™ -&gt; âˆ… - -&gt; âˆ… TEST Ã¡dh -&gt; AA TEST Ã¡iseanna -&gt; AA SJ @@ NN @@ TEST Ã¡thas -&gt; AA H @@ S TEST abhainn -&gt; ABH NNJ TEST bualadh -&gt; B U@ LL ADH TEST sadhbh -&gt; S AI V TEST saghas -&gt; S AI S TEST gaeilge -&gt; G EE LJ GJ @@ TEST saolaÃ­odh -&gt; S AO LL ÃODH TEST gardaÃ­ -&gt; G AA R D II TEST dÃºnfaidh -&gt; D UU NN_D IDH TEST aidhm -&gt; AI MJ TEST cheadaigh -&gt; XJ A D IGH TEST aighneas -&gt; AI NJ @@ S TEST diÃºltaithe -&gt; DJ UU LL T ITHE TEST seabhaic -&gt; SJ ABH KJ TEST feadhain -&gt; FJ AU NJ TEST teaghais -&gt; TJ AI SJ TEST eamhain -&gt; AU NJ TEST lobhair -&gt; LL OBH RJ TEST leÃ³dhais -&gt; LJ OO SJ TEST bodhair -&gt; B ODH RJ TEST eoghain -&gt; OO NJ TEST broghais -&gt; B R OGH SJ TEST comhair -&gt; K OO RJ TEST ciumhais -&gt; KJ UU SJ # wiktionary has: ËˆÉ‘ËÉ¾Ë dÊ²É™ ËˆiËÉ¾Ë dÊ²É™ ËˆÉ‘ËÉ¾Ë dÊ²É™ ËˆaiÉ¾Ê²dÊ²É™ ËˆÃ¦ËÉ¾Ë dÊ²É™ ËˆÊŒÉ¾Ë dÊ²É™, so rule seems right #TEST airde -&gt; AA RJ DJ @@ TEST airde -&gt; AA R DJ @@ TEST cait -&gt; K A TJ TEST sodair -&gt; S O D @@ RJ TEST ait -&gt; A TJ TEST dÃ©anamh -&gt; DJ EE NN AMH TEST amharc -&gt; AU R K TEST gaoil -&gt; G AO LJ TEST gaol -&gt; G AO LL TEST seabhac -&gt; SJ ABH K TEST ceadharlach -&gt; KJ AU R LL @@ X TEST teaghasÃ¡n -&gt; TJ AI S AA NN TEST lobhar -&gt; LL OBH R TEST leÃ³dhas -&gt; LJ OO S TEST bodhar -&gt; B ODH R TEST eoghan -&gt; OO NN TEST bogha -&gt; B OGH TEST comhar -&gt; K OO R TEST dumhach -&gt; D UU X TEST ard -&gt; AA R D TEST cat -&gt; K A T TEST sodar -&gt; S O D @@ R TEST at -&gt; A T TEST Ã©an -&gt; EE NN TEST Ã©inÃ­nÃ­ -&gt; EE NJ II NJ II TEST Ã© -&gt; EE TEST sheÃ¡in -&gt; XJ AA NJ TEST seÃ¡n -&gt; SJ AA NN TEST seabhac -&gt; SJ ABH K TEST seinneadh -&gt; SJ E NNJ ADH TEST ceadharlach -&gt; KJ AU R LL @@ X TEST teaghlach -&gt; TJ AI LL @@ X TEST beairic -&gt; BJ A RJ @@ KJ TEST Ã¡ireamh -&gt; AA RJ AMH TEST sleamhnÃ¡n -&gt; SJ LJ AU NN AA NN TEST oighear -&gt; OIGH R TEST ceard -&gt; KJ AA R D TEST cead -&gt; KJ A D TEST Ã¡ireamhÃ¡n -&gt; AA RJ @@ V AA NN TEST eas -&gt; A S TEST feidhm -&gt; FJ EIDH MJ TEST leigheas -&gt; LJ EIGH S # wiktionary gives cÉ™iÉ¾Ë dÊ² and cÉªÉ¾Ë dÊ²; the rule seems right #TEST ceird -&gt; KJ EE RJ DJ TEST ceird -&gt; KJ EE R DJ TEST deis -&gt; DJ E SJ TEST eitpheil -&gt; E TJ FJ E LJ TEST ceoil -&gt; KJ OO LJ TEST bainseÃ³ -&gt; B A NJ SJ OO TEST ceol -&gt; KJ OO LL TEST uile -&gt; I LJ @@ TEST ceannaÃ­odh -&gt; KJ A NN ÃODH TEST sÃ­os -&gt; SJ II S TEST sÃ­ -&gt; SJ II TEST siadhail -&gt; SJ I@ LJ TEST sciath -&gt; SJ KJ I@ #TEST riail -&gt; RJ I@ LJ TEST riail -&gt; R I@ LJ TEST siad -&gt; SJ I@ D TEST seinnfidh -&gt; SJ E NNJ_D IDH TEST cheannaigh -&gt; XJ A NN IGH TEST fios -&gt; FJ IO S TEST imithe -&gt; I MJ ITHE TEST siÃºil -&gt; SJ UU LJ TEST siÃºl -&gt; SJ UU LL TEST tiubh -&gt; TJ UBH TEST ciumhais -&gt; KJ UU SJ #TEST giuirlÃ©id -&gt; GJ UU RJ LJ EE DJ TEST giuirlÃ©id -&gt; GJ UU R LJ EE DJ TEST fiuch -&gt; FJ U X TEST leighis -&gt; LJ EIGH SJ TEST foighid -&gt; F OIGH DJ TEST aithris -&gt; A RJ_D @@ SJ TEST sin -&gt; SJ I NJ TEST cheannÃ³dh -&gt; XJ A NN Ã“DH TEST Ã³il -&gt; OO LJ TEST Ã³l -&gt; OO LL TEST lobhadh -&gt; LL OBH ADH TEST todhchaÃ­ -&gt; T ODH X II TEST toghadh -&gt; T OGH ADH TEST oÃ­che -&gt; II XJ @@ TEST oidhe -&gt; OIDH @@ TEST oighear -&gt; OIGH R #TEST boird -&gt; B OO RJ DJ TEST boird -&gt; B OO R DJ TEST soir -&gt; S OI RJ TEST comhar -&gt; K OO R TEST bord -&gt; B OO R D TEST bos -&gt; B O S TEST sÃºil -&gt; S UU LJ TEST sÃºl -&gt; S UU LL TEST uathÃºil -&gt; U@ UU LJ TEST uaine -&gt; U@ NJ @@ TEST uan -&gt; U@ NN TEST subh -&gt; S UBH // not LJ ? TEST bhuel -&gt; V E LL #TEST guird -&gt; G UU RJ DJ TEST guird -&gt; G UU R DJ TEST cuid -&gt; K I DJ TEST uile -&gt; I LJ @@ TEST bruÃ­on -&gt; B R II NN TEST bruÃ­ne -&gt; B R II NJ @@ TEST cumhacht -&gt; K UU X T TEST burdÃºn -&gt; B UU R D UU NN TEST cur -&gt; K U R TEST bus -&gt; B U S TEST scuabfaidh -&gt; S K U@ P IDH TEST clibfidh -&gt; KJ LJ I PJ IDH TEST scuabfadh -&gt; S K U@ P ADH TEST clibfeadh -&gt; KJ LJ I PJ ADH TEST bhfÃ¡inne -&gt; V AA NNJ @@ TEST bhfianaise -&gt; VJ I@ NN @@ SJ @@ TEST scrÃ­obhfaidh -&gt; SJ KJ RJ II F IDH TEST dÃ­bhfidh -&gt; DJ II FJ IDH TEST scrÃ­obhfadh -&gt; SJ KJ RJ II F ADH TEST dÃ­bhfeadh -&gt; DJ II FJ ADH TEST searbh -&gt; SJ A R @@ V TEST seirbhÃ­s -&gt; SJ E RJ @@ VJ II SJ TEST bhrostaigh -&gt; V R O S T IGH TEST bhris -&gt; VJ RJ I SJ TEST coibhÃ­n -&gt; K OI VJ II NJ TEST bpÃ¡istÃ­ -&gt; B AA SJ TJ II TEST bpÃ©isteanna -&gt; BJ EE SJ TJ @@ NN @@ TEST scuabtha -&gt; S K U@ P @@ TEST clibthe -&gt; KJ LJ I PJ @@ TEST borb -&gt; B O R @@ B TEST seirbiach -&gt; SJ E RJ @@ BJ I@ X TEST brÃ³na -&gt; B R OO NN @@ TEST brian -&gt; BJ RJ I@ NN TEST leÃ³dhas -&gt; LJ OO S TEST t-uisce -&gt; T UI SJ KJ @@ TEST t-Ã©abhlÃ³idÃ­ -&gt; TJ EE V LL OO DJ II TEST atfaidh -&gt; A T IDH TEST titfidh -&gt; TJ I TJ IDH TEST athdhÃ©anamh -&gt; A GFJ EE NN AMH TEST meathfadh -&gt; MJ A H ADH #TEST rithfeadh -&gt; RJ I XJ ADH TEST rithfeadh -&gt; R I XJ ADH TEST blÃ¡thra -&gt; B LL AA R_D @@ TEST tharla -&gt; H AA R LL @@ TEST thit -&gt; HJ I TJ TEST tseachtain -&gt; TJ A X T @@ NJ #TEST tsagairt -&gt; T A G @@ RJ TJ # wiktionary (sagairt): ËˆsË aÉ¡É™É¾Ë tÊ² ËˆsË Ã¦É¡É™É¾Ë tÊ² TEST tsagairt -&gt; T A G @@ R TJ TEST teann -&gt; TJ A NN TEST tit -&gt; TJ I TJ TEST togra -&gt; T O G R @@ TEST sadhbh -&gt; S AI V # disabled; the rule for &#39;o&#39; in an unaccented syllable # does not produce schwa; also, &#39;leathbhosca&#39; is a compound; # the &#39;o&#39; should not be reduced #TEST leathbhosca -&gt; LJ A V @@ S K @@ #TEST bantaboic -&gt; B A NN T @@ B @@ KJ #TEST bantaboc -&gt; B A NN T @@ B @@ K TEST bhÃ©al -&gt; VJ EE LL TEST bhÃ©il -&gt; VJ EE LJ .",
            "url": "https://jimregan.github.io/notes/irish/g2p/2021/05/16/o-raghallaigh-thesis-attempt-1.html",
            "relUrl": "/irish/g2p/2021/05/16/o-raghallaigh-thesis-attempt-1.html",
            "date": " â€¢ May 16, 2021"
        }
        
    
  
    
        ,"post173": {
            "title": "Clarin-Studio Polish Train mono 1-30",
            "content": "Original on Kaggle . %cd /opt . %%capture !tar xvf /kaggle/input/extract-prebuilt-kaldi-from-docker/kaldi.tar . %cd kaldi/egs . /opt/kaldi/egs . !git clone https://github.com/danijel3/ClarinStudioKaldi . %cd ClarinStudioKaldi . /opt/kaldi/egs/ClarinStudioKaldi . !conda install -c bioconda perl-perlio-gzip -y . import os #os.environ[&#39;LD_LIBRARY_PATH&#39;] = f&#39;{os.environ[&quot;LD_LIBRARY_PATH&quot;]}:/opt/kaldi/tools/openfst-1.6.7/lib:/opt/kaldi/src/lib&#39; os.environ[&#39;LD_LIBRARY_PATH&#39;] = &#39;/opt/conda/lib:/opt/kaldi/tools/openfst-1.6.7/lib:/opt/kaldi/src/lib&#39; . !cat path.sh|sed -e &#39;s/~ /apps/ /opt/&#39; &gt; tmp !mv tmp path.sh . !echo &gt; local_clarin/clarin_pl_clean.sh . !ln -s ../wsj/s5/steps !ln -s ../wsj/s5/conf !ln -s ../wsj/s5/local !ln -s ../wsj/s5/utils . !cp -r /kaggle/input/kaldi-clarinstudio-polish-data-prep/data /kaggle/working/ . !mkdir /kaggle/working/exp !ln -s /kaggle/working/exp !ln -s /kaggle/working/data . !bash steps/train_mono.sh --nj 40 --num_iters 30 data/train data/lang_nosp exp/mono0 .",
            "url": "https://jimregan.github.io/notes/clarinpl/kaggle/2021/05/16/kaldi-clarinstudio-polish-train-mono-1-30.html",
            "relUrl": "/clarinpl/kaggle/2021/05/16/kaldi-clarinstudio-polish-train-mono-1-30.html",
            "date": " â€¢ May 16, 2021"
        }
        
    
  
    
        ,"post174": {
            "title": "Clarin-Studio Polish GMM",
            "content": "Original on Kaggle . %cd /opt . /opt . %%capture !tar xvf /kaggle/input/extract-prebuilt-kaldi-from-docker/kaldi.tar . %cd kaldi/egs . /opt/kaldi/egs . !git clone https://github.com/danijel3/ClarinStudioKaldi . %cd ClarinStudioKaldi . /opt/kaldi/egs/ClarinStudioKaldi . !conda install -c bioconda perl-perlio-gzip -y . import os #os.environ[&#39;LD_LIBRARY_PATH&#39;] = f&#39;{os.environ[&quot;LD_LIBRARY_PATH&quot;]}:/opt/kaldi/tools/openfst-1.6.7/lib:/opt/kaldi/src/lib&#39; os.environ[&#39;LD_LIBRARY_PATH&#39;] = &#39;/opt/conda/lib:/opt/kaldi/tools/openfst-1.6.7/lib:/opt/kaldi/src/lib&#39; . !cat path.sh|sed -e &#39;s/~ /apps/ /opt/&#39; &gt; tmp !mv tmp path.sh . !echo &gt; local_clarin/clarin_pl_clean.sh . !sh run.sh . !mv exp /kaggle/working/ .",
            "url": "https://jimregan.github.io/notes/clarinpl/kaggle/2021/05/15/kaldi-clarinstudio-polish-gmm.html",
            "relUrl": "/clarinpl/kaggle/2021/05/15/kaldi-clarinstudio-polish-gmm.html",
            "date": " â€¢ May 15, 2021"
        }
        
    
  
    
        ,"post175": {
            "title": "Extract pre-built Kaldi on Kaggle",
            "content": "Original here . %cd /tmp . /tmp . !git clone https://github.com/jjlin/docker-image-extract/ . !docker-image-extract/docker-image-extract kaldiasr/kaldi:gpu-latest . Getting API token... Getting image manifest for kaldiasr/kaldi:gpu-latest... Fetching and extracting layer 976a760c94fcdd7d105269ae621e8269e7bb25a58c52ae667b4029a6bc7e33cb... Fetching and extracting layer c58992f3c37bb64aeba18910408cda9a7a63e212fe27e95065a8d54130ca5926... Fetching and extracting layer 0ca0e5e7f12e6eb512246aea5579fcb771fe7203bc60944384d5cd7962f87ddb... Fetching and extracting layer f2a274cc00ca5f671b1740c43672dbc96504760cee585e7604029a3fe56854a8... Fetching and extracting layer 708a53113e13a385afdeddfe409f4b7b71e65b1e5cff48ba33906c8803e19808... Fetching and extracting layer 465b2edc87fbc8c5fb06541c382eefd1edbfcac71521273855dbe0841a5aaf4a... Fetching and extracting layer 4189f57a58ef61e7e283534fb6d0dd4b2b818a037d82c0e1a2994cea35b01883... Fetching and extracting layer 35de2d1091bb82248c486931c94f18336d55dfee05d32d549305626c2e54ca82... Fetching and extracting layer 719d77537fdce03bba6ed02fcbc2e4b84d58906af53a95102326d7aa290549bf... Fetching and extracting layer 3745e7bcc1b3b7ef8b9afe38e20019cdd052d2ed5fa6b32f063e693620179f90... Fetching and extracting layer d990bd9da1ddb55d091b2fcc12a80dc7d3b04e1ba14c2e79f6e0ec9f487773fe... Fetching and extracting layer 15f2cb6c17ae91014b292d6db2438f202e2fb2f9527cb6730f5a38f639526641... Fetching and extracting layer d3305c2a9a9794962ae8183ae36e93f656f290fcec1216407bf4f417e09e512b... Image contents extracted into ./output. . %cd output/opt/ . /tmp/output/opt . import os os.environ[&#39;LD_LIBRARY_PATH&#39;] = &#39;/opt/conda/lib:/opt/kaldi/tools/openfst-1.6.7/lib:/opt/kaldi/src/lib&#39; . %pushd kaldi/tools !bash extras/install_phonetisaurus.sh %popd . !tar cvf /kaggle/working/kaldi.tar kaldi/ .",
            "url": "https://jimregan.github.io/notes/kaggle/kaldi/wav2vec-u/2021/05/15/extract-prebuilt-kaldi-from-docker.html",
            "relUrl": "/kaggle/kaldi/wav2vec-u/2021/05/15/extract-prebuilt-kaldi-from-docker.html",
            "date": " â€¢ May 15, 2021"
        }
        
    
  
    
        ,"post176": {
            "title": "G2P with MFA",
            "content": "Original on Kaggle . %%capture import os os.chdir(&#39;/tmp&#39;) !wget https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/releases/download/v1.0.1/montreal-forced-aligner_linux.tar.gz !tar zxvf montreal-forced-aligner_linux.tar.gz !ln -s /tmp/montreal-forced-aligner/lib/libpython3.6m.so.1.0 /tmp/montreal-forced-aligner/lib/libpython3.6m.so . os.chdir(&#39;/kaggle/working&#39;) os.environ[&#39;LD_LIBRARY_PATH&#39;] = f&#39;{os.environ[&quot;LD_LIBRARY_PATH&quot;]}:/tmp/montreal-forced-aligner/lib/&#39; os.environ[&#39;PATH&#39;] = f&#39;{os.environ[&quot;PATH&quot;]}:/tmp/montreal-forced-aligner/bin/&#39; . %%capture !apt-get -y install libgfortran3 . !mkdir /tmp/example . The example below is from section 488 (p. 239) of Gaeilge Chorca Dhuibhne by Diarmuid Ã“ SÃ©. . The provided transcription is: É™s kiËnâ€² lâ€²É™m nÉ™ ËˆheËnâ€²Éª vâ€²eh É™ bÉªnâ€²tâ€² vuËn erâ€² . %%writefile /tmp/example/test1.lab is cuimhin liom na haoinne a bheith ag baint mhÃ³na air . Writing /tmp/example/test1.lab . Ibid, Section 488, p. 238 . xuËÉ™rËˆdiËs Ëˆgax É‘Ëtâ€² . %%writefile /tmp/example/test2.lab chuardaÃ­os gach Ã¡it . Writing /tmp/example/test2.lab . MFA insists on having .wav files, which it reads, even though it makes no use of them for G2P . %%capture !apt-get -y install sox . !sox -n -r 16000 -b 16 -c 1 -L /tmp/example/test1.wav trim 0.0 6.000 !sox -n -r 16000 -b 16 -c 1 -L /tmp/example/test2.wav trim 0.0 6.000 . !mfa_generate_dictionary ../input/train-irish-mfa-model-fuaimeanna/g2p-munster.zip /tmp/example/ output . Setting up corpus information... . !cat output . cuimhin k Éª vË  nÊ² Ã¡it É‘Ë tÊ² a É™ mhÃ³na vË  oË nÌªË  É™ bheith vÊ² É› baint bË  Éª nÊ² tÊ² air a É¾Ê² is Éª Êƒ na nÌªË  É™ gach É¡ É™ x chuardaÃ­os x uÉ™ É¾Ë  dÌªË  iË ÊŒ sË  ag a É¡ liom lÊ² ÊŒ mË  haoinne Éª nÊ² É› . Word Pronunciation Alt. Transcript Generated Correct? In context? Rule/Reason . is | É™s | É™sË  (~ ÉªÊƒ) | Éª Êƒ | âœ”ï¸ | âŒ | Exception: ios but correct before a slender consonant | . cuimhin | kiËnâ€² | kiËnÊ² | k Éª vË  nÊ² | âŒ | âŒ | Missing grapheme: uimhi | . liom | lâ€²É™m | lÊ²É™mË  (~ lÊ²ÊŒmË ) | lÊ² ÊŒ mË  | âœ”ï¸ | âœ”ï¸ | (See, e.g., section 291: lâ€²um) | . na | nÉ™ | nÌªË É™ | nÌªË  É™ | âœ”ï¸ | âœ”ï¸ | | . haoinne | ËˆheËnâ€²Éª | heËnÊ²Éª | Éª nÊ² É› | âŒ | âŒ | | . a | É™ | | É™ | âœ”ï¸ | âœ”ï¸ | | . bheith | vâ€²eh | vÊ²É›(h) | vÊ² É› | âœ”ï¸ | âŒ | Section 9: h â†’ âˆ… / _ # -V | . ag | É™ | É™ (~ ÉªÉŸ) | a É¡ | âŒ | âŒ | Éªgâ€², section 60 | . baint | bÉªnâ€²tâ€² | bË ÉªnÊ²tÊ² | bË  Éª nÊ² tÊ² | âœ”ï¸ | âœ”ï¸ | | . mhÃ³na | vuËn | vË uËnÌªË (É™) | vË  oË nÌªË  É™ | âœ”ï¸ | âŒ | Ã³ â†’ oË ~ uË / _ [+nasal], É™ â†’ âˆ… / _ # | . air | erâ€² | eÉ¾Ê² | a É¾Ê² | âŒ | âŒ | Exception: eir | . chuardaÃ­os | xuËÉ™rËˆdiËs | xuÉ™É¾Ë dÌªË iËsË  | x uÉ™ É¾Ë  dÌªË  iË ÊŒ sË  | âŒ | âŒ | Missing grapheme aÃ­o | . gach | Ëˆgax | É¡ax (~ É¡É™x) | É¡ É™ x | âœ”ï¸ | âœ”ï¸ | See section 810 | . Ã¡it | É‘Ëtâ€² | É‘ËtÊ² | É‘Ë tÊ² | âœ”ï¸ | âœ”ï¸ | | .",
            "url": "https://jimregan.github.io/notes/kaggle/g2p/mfa/2021/05/14/g2p-with-mfa.html",
            "relUrl": "/kaggle/g2p/mfa/2021/05/14/g2p-with-mfa.html",
            "date": " â€¢ May 14, 2021"
        }
        
    
  
    
        ,"post177": {
            "title": "Training MFA on fuaimeanna.ie",
            "content": "Original . Part, the first . Setting up MFA . %%capture import os os.chdir(&#39;/tmp&#39;) !wget https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/releases/download/v1.0.1/montreal-forced-aligner_linux.tar.gz !tar zxvf montreal-forced-aligner_linux.tar.gz !ln -s /tmp/montreal-forced-aligner/lib/libpython3.6m.so.1.0 /tmp/montreal-forced-aligner/lib/libpython3.6m.so . os.chdir(&#39;/kaggle/working&#39;) os.environ[&#39;LD_LIBRARY_PATH&#39;] = f&#39;{os.environ[&quot;LD_LIBRARY_PATH&quot;]}:/tmp/montreal-forced-aligner/lib/&#39; os.environ[&#39;PATH&#39;] = f&#39;{os.environ[&quot;PATH&quot;]}:/tmp/montreal-forced-aligner/bin/&#39; . %%capture !apt-get -y install libgfortran3 . To create the same data, fork and run this notebook . !mkdir /tmp/m !mkdir /tmp/c !mkdir /tmp/u !cp ../input/scrape-fuaimeanna-private/wav/*s1.wav /tmp/u !cp ../input/scrape-fuaimeanna-private/wav/*s2.wav /tmp/m !cp ../input/scrape-fuaimeanna-private/wav/*s3.wav /tmp/c . %%writefile fuaimeanna-write.pl #!/usr/bin/perl use warnings; use strict; use utf8; binmode(STDIN, &quot;:utf8&quot;); binmode(STDOUT, &quot;:utf8&quot;); binmode(STDERR, &quot;:utf8&quot;); my %cr_files = ( &#39;mo shmidiÃº&#39; =&gt; &#39;mo chuid smidiÃº&#39;, &#39;mo shmior&#39; =&gt; &#39;mo chuid smior&#39;, &#39;mo shmÃ³lach&#39; =&gt; &#39;mo smÃ³lach&#39;, &#39;shmachtaigh&#39; =&gt; &#39;smachtaigh&#39;, &#39;shmaoinigh&#39; =&gt; &#39;smaoinigh&#39;, &#39;shmear&#39; =&gt; &#39;smear&#39;, &#39;deamhain&#39; =&gt; &#39;diabhail&#39;, &#39;folach&#39; =&gt; &#39;i bhfolach&#39;, &#39;captaen&#39; =&gt; &#39;caiptÃ­n&#39;, &#39;oirthe&#39; =&gt; &#39;feilte&#39;, ); my %empty = ( &#39;/sounds/gob_i3_s3.mp3&#39; =&gt; 1, &#39;/sounds/iioctha_i3_s3.mp3&#39; =&gt; 1, &#39;/sounds/mo_shuiiochaan_i3_s3.mp3&#39; =&gt; 1, &#39;/sounds/riail_i3_s3.mp3&#39; =&gt; 1 ); open(LEXM, &#39;&gt;&gt;&#39;, &#39;/tmp/lexicon-munster.raw&#39;); binmode LEXM, &#39;:utf8&#39;; open(LEXU, &#39;&gt;&gt;&#39;, &#39;/tmp/lexicon-ulster.raw&#39;); binmode LEXU, &#39;:utf8&#39;; open(LEXC, &#39;&gt;&gt;&#39;, &#39;/tmp/lexicon-connaught.raw&#39;); binmode LEXC, &#39;:utf8&#39;; sub write_text { my $file = shift; my $text = shift; open(OUTF, &#39;&gt;&gt;&#39;, $file); binmode OUTF, &#39;:utf8&#39;; print OUTF $text; close OUTF; } sub write_pron { my $file = shift; my $text = shift; my $pron = shift; if ($text eq &#39;ar tÃ­&#39;) { $pron =~ s/ . Ëˆ / # /g; } $pron =~ s/ [ËˆËŒ] / /g; $pron =~ s/^[ËˆËŒ] //g; $pron =~ s/ . / /g; my @words = split/ /, $text; my @prons = split/ # /, $pron; if($#words != $#prons) { print STDERR &quot;ERROR: $file $text $pron n&quot;; } if($#words == 0) { print $file &quot;$text $pron n&quot;; } else { for(my $i = 0; $i &lt;= $#words; $i++) { print $file &quot;$words[$i] $prons[$i] n&quot;; } } } while(&lt;STDIN&gt;) { chomp; my @line = split/ t/; next if($line[0] eq &#39;Orthographic&#39;); my $text = lc($line[0]); next if($line[0] eq &quot;d&#39;fhÃ¡g&quot;); my $uout = $line[1]; $uout =~ s!/sounds/!!; $uout =~ s/ .mp3$/.txt/; my $cout = $line[3]; $cout =~ s!/sounds/!!; $cout =~ s/ .mp3$/.txt/; my $mout = $line[5]; $mout =~ s!/sounds/!!; $mout =~ s/ .mp3$/.txt/; $uout = &#39;/tmp/u/&#39; . $uout; $cout = &#39;/tmp/c/&#39; . $cout; $mout = &#39;/tmp/m/&#39; . $mout; my $pronu = $line[2]; my $pronc = $line[4]; my $pronm = $line[6]; if($text eq &#39;Gaeilge&#39;) { write_text($uout, &quot;gaeilic&quot;); write_text($cout, &quot;gaeilge&quot;); write_text($mout, &quot;gaelainn&quot;); write_pron( *LEXU, &quot;gaeilic&quot;, $pronu); write_pron( *LEXC, &quot;gaeilge&quot;, $pronc); write_pron( *LEXM, &quot;gaelainn&quot;, $pronm); next; } if($line[0] eq &#39;bocht&#39; || $line[0] eq &#39;teacht&#39; || $line[0] eq &#39;teocht&#39;) { $pronu =~ s/x tÌªË /É¾Ë  tÌªË /; } write_text($uout, $text); write_pron( *LEXU, $text, $pronu); write_text($mout, $text); write_pron( *LEXM, $text, $pronm); if(!exists $empty{$line[3]}) { my $cfix = exists $cr_files{$text} ? $cr_files{$text} : $text; write_text($cout, $cfix); write_pron( *LEXC, $cfix, $pronc); } } . Writing fuaimeanna-write.pl . !cat ../input/scrape-fuaimeanna-private/all-fuaimeanna-data.tsv | perl fuaimeanna-write.pl . !cat /tmp/lexicon-connaught.raw | sort | uniq &gt; /tmp/lexicon-connaught.txt !cat /tmp/lexicon-ulster.raw | sort | uniq &gt; /tmp/lexicon-ulster.txt !cat /tmp/lexicon-munster.raw | sort | uniq &gt; /tmp/lexicon-munster.txt !cat /tmp/lexicon-connaught.raw /tmp/lexicon-ulster.raw /tmp/lexicon-munster.raw | sort | uniq &gt; /tmp/lexicon-all.txt . !mkdir /tmp/all !cp /tmp/c/* /tmp/all !cp /tmp/m/* /tmp/all !cp /tmp/u/* /tmp/all !mkdir /tmp/mfa-temp . Run MFA . !mfa_train_and_align -t /tmp/mfa-temp -o ./munster-model /tmp/m /tmp/lexicon-munster.txt /tmp/textgrid-munster !mfa_train_and_align -t /tmp/mfa-temp -o ./ulster-model /tmp/u /tmp/lexicon-ulster.txt /tmp/textgrid-ulster !mfa_train_and_align -t /tmp/mfa-temp -o ./connaught-model /tmp/c /tmp/lexicon-connaught.txt /tmp/textgrid-connaught !mfa_train_and_align -t /tmp/mfa-temp -o ./all-model /tmp/all /tmp/lexicon-all.txt /tmp/textgrid-all . !mfa_train_g2p -t /tmp/mfa-temp /tmp/lexicon-ulster.txt ./g2p-ulster !mfa_train_g2p -t /tmp/mfa-temp /tmp/lexicon-munster.txt ./g2p-munster !mfa_train_g2p -t /tmp/mfa-temp /tmp/lexicon-connaught.txt ./g2p-connaught !mfa_train_g2p -t /tmp/mfa-temp /tmp/lexicon-all.txt ./g2p-all .",
            "url": "https://jimregan.github.io/notes/kaggle/mfa/fuaimeanna/2021/05/13/train-irish-mfa-model-fuaimeanna.html",
            "relUrl": "/kaggle/mfa/fuaimeanna/2021/05/13/train-irish-mfa-model-fuaimeanna.html",
            "date": " â€¢ May 13, 2021"
        }
        
    
  
    
        ,"post178": {
            "title": "Scrape fuaimeanna.ie",
            "content": "Not-quite original version . %%writefile fuaimeanna.pl #!/usr/bin/perl # License: Apache 2.0 # Scrapes sounds from fuaimeanna.ie # Creates a set of labels in &#39;label/&#39; (which must exist) # along with three files: # run-wget.sh, which downloads the sounds to mp3/ (it creates it) # run-ffmpeg.sh, which converts the sounds in mp3/ to wav files in wav/ # all-fuaimeanna-data.tsv, which contains all of the data use warnings; use strict; use utf8; use URI; use Web::Scraper; use Data::Dumper; binmode(STDOUT, &quot;:utf8&quot;); binmode(STDERR, &quot;:utf8&quot;); open(WGET, &quot;&gt;&quot;, &quot;run-wget.sh&quot;); binmode(WGET, &quot;:utf8&quot;); open(FFMPEG, &quot;&gt;&quot;, &quot;run-ffmpeg.sh&quot;); binmode(FFMPEG, &quot;:utf8&quot;); open(ALL, &quot;&gt;&quot;, &quot;all-fuaimeanna-data.tsv&quot;); binmode(ALL, &quot;:utf8&quot;); my $phones = scraper { process &#39;div[class=&quot;friotal&quot;]&#39;, &#39;sounds[]&#39; =&gt; scraper { process &#39;span[class=&quot;ortho&quot;]&#39;, &#39;orth&#39; =&gt; &#39;TEXT&#39;; process &#39;span[class=&quot;taifead&quot;] span[class=&quot;player&quot;] a audio source&#39;, &#39;sounds[]&#39; =&gt; &#39;@src&#39;; process &#39;span[class=&quot;phonological&quot;]&#39;, &#39;dialects[]&#39; =&gt; scraper { process &#39;a[class=&quot;phoneme&quot;]&#39;, &#39;phonemes[]&#39; =&gt; &#39;TEXT&#39;; }; }; }; if(! -d &quot;label&quot;) { die &quot;Directory &#39;label&#39; does not exist n&quot;; } # write shell headers to output files print WGET &quot;#!/bin/sh n&quot;; print WGET &quot;mkdir mp3 n&quot;; print FFMPEG &quot;#!/bin/sh n&quot;; print FFMPEG &quot;mkdir wav n&quot;; # write .tsv header print ALL &quot;Orthographic t&quot;; print ALL &quot;Audio (Gaoth Dobhair) tIPA (Gaoth Dobhair) t&quot;; print ALL &quot;Audio (CeathrÃº Rua) tIPA (CeathrÃº Rua) t&quot;; print ALL &quot;Audio (Corca Dhuibhne) tIPA (Corca Dhuibhne) n&quot;; for my $i (1..77) { my $res = $phones-&gt;scrape(URI-&gt;new(&quot;http://www.fuaimeanna.ie/en/Recordings.aspx?Page=$i&quot;)); for my $sound (@{$res-&gt;{&#39;sounds&#39;}}) { my $word = $sound-&gt;{&#39;orth&#39;}; $word =~ s/^&lt;//; $word =~ s/&gt;$//; if($#{$sound-&gt;{&#39;sounds&#39;}} != 2 &amp;&amp; $#{$sound-&gt;{&#39;dialects&#39;}} != 2) { print STDERR &quot;Error reading &lt;$word&gt; on page $i&quot;; } print ALL &quot;$word t&quot;; for my $j (0..2) { my $sound_raw = ${$sound-&gt;{&#39;sounds&#39;}}[$j]; my $phones_raw = join(&#39; &#39;, @{${$sound-&gt;{&#39;dialects&#39;}}[$j]-&gt;{&#39;phonemes&#39;}}); # put everything in a tsv file first, because it doesn&#39;t make sense to hammer their server again print ALL $sound_raw . &quot; t&quot; . $phones_raw; print ALL &quot; t&quot; unless ($j == 2); my $sound_base = $sound_raw; $sound_base =~ s!/sounds/!!; $sound_base =~ s/ .mp3//; my $phones_out = $phones_raw; # discard word boundary $phones_out =~ s/ # / /g; $phones_out =~ s/ .//g; $phones_out =~ s/Ëˆ//g; $phones_out =~ s/ s+/ /g; $phones_out =~ s/^ //; $phones_out =~ s/ $//; # write the script line print WGET &quot;wget http://www.fuaimeanna.ie$sound_raw -O mp3/$sound_base.mp3 n&quot;; print FFMPEG &quot;ffmpeg -i &quot;mp3/$sound_base.mp3 &quot; -acodec pcm_s16le -ac 1 -ar 16000 wav/$sound_base.wav n&quot;; # write the phones to the label file my $label_file = &quot;label/$sound_base.phones&quot;; open(OUT, &quot;&gt;&quot;, $label_file); binmode(OUT, &quot;:utf8&quot;); print OUT &quot;$phones_out&quot;; close(OUT); } # add a newline to the tsv file print ALL &quot; n&quot;; } } . !mkdir label . %%capture !apt-get -y install libweb-scraper-perl liburi-perl . !chmod a+x fuaimeanna.pl . !./fuaimeanna.pl . %%capture !sh run-wget.sh !sh run-ffmpeg.sh .",
            "url": "https://jimregan.github.io/notes/kaggle/fuaimeanna/scraper/2021/05/13/scrape-fuaimeanna-ie.html",
            "relUrl": "/kaggle/fuaimeanna/scraper/2021/05/13/scrape-fuaimeanna-ie.html",
            "date": " â€¢ May 13, 2021"
        }
        
    
  
    
        ,"post179": {
            "title": "CMU Wilderness no longer works",
            "content": "tl;dr - grabbing the audio doesn&#39;t work . !git clone https://github.com/festvox/datasets-CMU_Wilderness . Cloning into &#39;datasets-CMU_Wilderness&#39;... remote: Enumerating objects: 791, done. remote: Total 791 (delta 0), reused 0 (delta 0), pack-reused 791 Receiving objects: 100% (791/791), 91.48 MiB | 11.83 MiB/s, done. Resolving deltas: 100% (32/32), done. . %cd datasets-CMU_Wilderness . /kaggle/working/datasets-CMU_Wilderness . %%capture !yes|apt install sptk html2text sox libncurses-dev . %%capture !bin/do_found make_dependencies . !bin/do_found fast_make_align indices/ABIWBT.tar.gz . /bin/bash: bin/do_found: No such file or directory .",
            "url": "https://jimregan.github.io/notes/kaggle/cmuwilderness/bibleis/2021/05/09/cmu-wilderness-does-not-work.html",
            "relUrl": "/kaggle/cmuwilderness/bibleis/2021/05/09/cmu-wilderness-does-not-work.html",
            "date": " â€¢ May 9, 2021"
        }
        
    
  
    
        ,"post180": {
            "title": "Run deepspeech on Wolne Lektury audio (20-000-mil-podmorskiej-zeglugi pt. 1)",
            "content": "Original on Kaggle . !cp ../input/wolne-lektury-deepspeech/*.json . . !pip install deepspeech . deepspeech --model ../input/polish-deepspeech-models/output_graph_pl.pbmm --scorer ../input/polish-deepspeech-models/kenlm_pl.scorer --json --audio ../input/wolne-lektury-deepspeech/20-000-mil-podmorskiej-zeglugi_026_nowa-propozycja-kapitana-nemo.wav &gt; 20-000-mil-podmorskiej-zeglugi_026_nowa-propozycja-kapitana-nemo.json; rm $out $j; done;done . !for i in $(ls ../input/wolne-lektury-deepspeech/*.mp3|grep -v zeglugi_026_nowa-propozycja-kapitana); do base=$(basename &quot;$i&quot; &quot;.mp3&quot;); out=&quot;$base.wav&quot;; ffmpeg -i $i -acodec pcm_s16le -ac 1 -ar 16000 $out; deepspeech --model ../input/polish-deepspeech-models/output_graph_pl.pbmm --scorer ../input/polish-deepspeech-models/kenlm_pl.scorer --json --audio $out &gt; $base.json; rm $out $j; done .",
            "url": "https://jimregan.github.io/notes/asr/polish/kaggle/2021/05/07/deepspeech-wolne-lektury-20-000-mil-podmorskiej-zeglugi-pt-1.html",
            "relUrl": "/asr/polish/kaggle/2021/05/07/deepspeech-wolne-lektury-20-000-mil-podmorskiej-zeglugi-pt-1.html",
            "date": " â€¢ May 7, 2021"
        }
        
    
  
    
        ,"post181": {
            "title": "Azure ASR's JSONL output to JSON",
            "content": "import glob import json for i in glob.glob(&#39;../input/mo-sgeal-fein-wikisource-azure-asr-output/*.jsonl&#39;): outf = i.replace(&#39;jsonl&#39;, &#39;json&#39;).split(&#39;/&#39;)[-1] with open(i) as f: curfile = [] for line in f.readlines(): cur = {} json_data = json.loads(line) cur[&#39;start&#39;] = json_data[&#39;Offset&#39;] cur[&#39;duration&#39;] = json_data[&#39;Duration&#39;] cur[&#39;text&#39;] = json_data[&#39;NBest&#39;][0][&#39;Lexical&#39;] curfile.append(cur) with open(outf, &#39;w&#39;) as of: json.dump(curfile, of) .",
            "url": "https://jimregan.github.io/notes/azure/irish/asr/2021/05/04/msf-azure-jsonl-to-json.html",
            "relUrl": "/azure/irish/asr/2021/05/04/msf-azure-jsonl-to-json.html",
            "date": " â€¢ May 4, 2021"
        }
        
    
  
    
        ,"post182": {
            "title": "Azure speech recognition for Irish",
            "content": "%%capture !pip install azure-cognitiveservices-speech . %%capture !pip install youtube-dl . %%capture !youtube-dl https://www.youtube.com/watch?v=cfjdfaqWY3Y . %%capture !ffmpeg -i CÃºla4 Ar Scoil _ Ãbhar - Mata _ TÃ©ama - Bia-cfjdfaqWY3Y.mkv -acodec pcm_s16le -ac 1 -ar 16000 cfjdfaqWY3Y.wav . import IPython IPython.display.Audio(&#39;/content/cfjdfaqWY3Y.wav&#39;) . import azure.cognitiveservices.speech as speechsdk . Use either Key1 or Key2 (on Azure Portal, in &quot;Keys and Endpoints&quot; from the menu on the left hand side of the screen). . _SUBS=&#39;&#39; . _LOC=&#39;westeurope&#39; . speech_config = speechsdk.SpeechConfig(region=_LOC, subscription=_SUBS) . audio_input=speechsdk.audio.AudioConfig(filename=&#39;cfjdfaqWY3Y.wav&#39;) . speech_config.speech_recognition_language = &#39;ga-IE&#39; speech_config.request_word_level_timestamps() speech_config.output_format = speechsdk.OutputFormat(1) speech_config.endpoint_id=&#39;https://westeurope.api.cognitive.microsoft.com/sts/v1.0/issuetoken&#39; . speech_config.set_property(speechsdk.PropertyId.Speech_LogFilename, &quot;azure.log&quot;) . # Copyright (c) Microsoft. All rights reserved. # Licensed under the MIT license. See LICENSE.md file in the project root for full license information. import time def speech_recognize_continuous_from_file(speech_config, audio_config): &quot;&quot;&quot;performs continuous speech recognition with input from an audio file&quot;&quot;&quot; speech_config = speech_config audio_config = audio_config speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, language=&#39;ga-IE&#39;, audio_config=audio_config) done = False def stop_cb(evt): &quot;&quot;&quot;callback that signals to stop continuous recognition upon receiving an event `evt`&quot;&quot;&quot; print(&#39;CLOSING on {}&#39;.format(evt)) nonlocal done done = True def cancelled(evt): result = evt.result cancellation_details = result.cancellation_details print(&quot;Speech Recognition canceled: {}&quot;.format(cancellation_details.reason)) if cancellation_details.reason == speechsdk.CancellationReason.Error: print(&quot;Error details: {}&quot;.format(cancellation_details.error_details)) # Connect callbacks to the events fired by the speech recognizer speech_recognizer.recognizing.connect(lambda evt: print(&#39;RECOGNIZING: {}&#39;.format(evt))) speech_recognizer.recognized.connect(lambda evt: print(&#39;RECOGNIZED: {}&#39;.format(evt))) speech_recognizer.session_started.connect(lambda evt: print(&#39;SESSION STARTED: {}&#39;.format(evt))) speech_recognizer.session_stopped.connect(lambda evt: print(&#39;SESSION STOPPED {}&#39;.format(evt))) speech_recognizer.canceled.connect(cancelled) # stop continuous recognition on either session stopped or canceled events speech_recognizer.session_stopped.connect(stop_cb) speech_recognizer.canceled.connect(stop_cb) # Start continuous speech recognition speech_recognizer.start_continuous_recognition() while not done: time.sleep(.5) speech_recognizer.stop_continuous_recognition() . speech_recognize_continuous_from_file(speech_config, audio_input) . Debugging with curl . !curl -v -X POST &quot;https://{_LOC}.api.cognitive.microsoft.com/sts/v1.0/issueToken&quot; -H &quot;Ocp-Apim-Subscription-Key: {_SUBS}&quot; -H &quot;Content-type: application/x-www-form-urlencoded&quot; -H &quot;Content-Length: 0&quot; . _TOK=&#39;&#39; . !curl -v -X POST &quot;https://{_LOC}.stt.speech.microsoft.com/speech/recognition/interactive/cognitiveservices/v1?language=ga-IE&quot; -H &quot;Authorization: Bearer {_TOK}&quot; -H &quot;Transfer-Encoding: chunked&quot; -H &quot;Content-type: audio/wav; codec=audio/pcm; samplerate=16000&quot; --data-binary @cfjdfaqWY3Y.wav . Next step, get at the innards (TODO) . transcript_display_list = [] transcript_ITN_list = [] confidence_list = [] words = [] def parse_azure_result(evt): import json response = json.loads(evt.result.json) transcript_display_list.append(response[&#39;DisplayText&#39;]) confidence_list_temp = [item.get(&#39;Confidence&#39;) for item in response[&#39;NBest&#39;]] max_confidence_index = confidence_list_temp.index(max(confidence_list_temp)) confidence_list.append(response[&#39;NBest&#39;][max_confidence_index][&#39;Confidence&#39;]) transcript_ITN_list.append(response[&#39;NBest&#39;][max_confidence_index][&#39;ITN&#39;]) words.extend(response[&#39;NBest&#39;][max_confidence_index][&#39;Words&#39;]) logger.debug(evt) .",
            "url": "https://jimregan.github.io/notes/azure/irish/asr/2021/05/04/azure-asr-with-irish.html",
            "relUrl": "/azure/irish/asr/2021/05/04/azure-asr-with-irish.html",
            "date": " â€¢ May 4, 2021"
        }
        
    
  
    
        ,"post183": {
            "title": "Azure speech recognition for Irish, part 2",
            "content": "%%capture !pip install azure-cognitiveservices-speech !pip install youtube-dl . %%capture !youtube-dl https://www.youtube.com/watch?v=cfjdfaqWY3Y . import azure.cognitiveservices.speech as speechsdk . Use either Key1 or Key2 (on Azure Portal, in &quot;Keys and Endpoints&quot; from the menu on the left hand side of the screen). . _SUBS=input(&#39;put your subscription key here: &#39;) . _LOC=&#39;westeurope&#39; . speech_config = speechsdk.SpeechConfig(region=_LOC, subscription=_SUBS) . !wget https://upload.wikimedia.org/wikipedia/commons/6/60/MSF_chapter_3.ogg https://upload.wikimedia.org/wikipedia/commons/e/ee/MSF_chapter_4.ogg https://upload.wikimedia.org/wikipedia/commons/b/b3/MSF_chapter_5.ogg https://upload.wikimedia.org/wikipedia/commons/2/21/MSF_chapter_6.ogg https://upload.wikimedia.org/wikipedia/commons/7/71/MSF_chapter_7.ogg https://upload.wikimedia.org/wikipedia/commons/d/d5/MSF_chapter_8.ogg . !ffmpeg -i MSF_chapter_5.ogg -acodec pcm_s16le -ac 1 -ar 16000 MSF_chapter_5.wav . speech_config.speech_recognition_language = &#39;ga-IE&#39; speech_config.request_word_level_timestamps() speech_config.output_format = speechsdk.OutputFormat(1) speech_config.endpoint_id=f&#39;https://{_LOC}.api.cognitive.microsoft.com/sts/v1.0/issuetoken&#39; . # Copyright (c) Microsoft. All rights reserved. # Licensed under the MIT license. See LICENSE.md file in the project root for full license information. import time import json def speech_recognize_continuous_from_file(speech_config, filename): &quot;&quot;&quot;performs continuous speech recognition with input from an audio file&quot;&quot;&quot; speech_config = speech_config audio_config = speechsdk.audio.AudioConfig(filename=filename) outfilename = filename.replace(&#39;.wav&#39;, &#39;.json&#39;) outfile = open(outfilename, &#39;a&#39;) speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, language=&#39;ga-IE&#39;, audio_config=audio_config) done = False def stop_cb(evt): &quot;&quot;&quot;callback that signals to stop continuous recognition upon receiving an event `evt`&quot;&quot;&quot; print(&#39;CLOSING on {}&#39;.format(evt)) nonlocal done done = True def cancelled(evt): result = evt.result cancellation_details = result.cancellation_details print(&quot;Speech Recognition canceled: {}&quot;.format(cancellation_details.reason)) if cancellation_details.reason == speechsdk.CancellationReason.Error: print(&quot;Error details: {}&quot;.format(cancellation_details.error_details)) def recognised(evt): response = json.loads(evt.result.json) outfile.write(&#39;{} n&#39;.format(evt.result.json)) # Connect callbacks to the events fired by the speech recognizer speech_recognizer.recognizing.connect(lambda evt: print(&#39;RECOGNIZING: {}&#39;.format(evt))) speech_recognizer.recognized.connect(recognised) speech_recognizer.session_started.connect(lambda evt: print(&#39;SESSION STARTED: {}&#39;.format(evt))) speech_recognizer.session_stopped.connect(lambda evt: print(&#39;SESSION STOPPED {}&#39;.format(evt))) speech_recognizer.canceled.connect(cancelled) # stop continuous recognition on either session stopped or canceled events speech_recognizer.session_stopped.connect(stop_cb) speech_recognizer.canceled.connect(stop_cb) # Start continuous speech recognition speech_recognizer.start_continuous_recognition() while not done: time.sleep(.5) speech_recognizer.stop_continuous_recognition() outfile.close() . for i in &quot;345678&quot;: speech_recognize_continuous_from_file(speech_config, f&#39;MSF_chapter_{i}.wav&#39;) .",
            "url": "https://jimregan.github.io/notes/azure/irish/asr/2021/05/04/azure-asr-with-irish-part2.html",
            "relUrl": "/azure/irish/asr/2021/05/04/azure-asr-with-irish-part2.html",
            "date": " â€¢ May 4, 2021"
        }
        
    
  
    
        ,"post184": {
            "title": "Playing with auditok",
            "content": "%%capture !pip install auditok . %%capture !yes|apt install python3-pyaudio . %%capture !pip install youtube-dl . !youtube-dl https://www.youtube.com/watch?v=D44-x6PTd_Q . [youtube] D44-x6PTd_Q: Downloading webpage [youtube] D44-x6PTd_Q: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 22 [download] Destination: Sraith PictiÃºr - An Ghaeilge Seoid luachmhar-D44-x6PTd_Q.f247.webm [download] 22.7% of ~12.60MiB at 5.49MiB/s ETA 00:13[download] Got server HTTP error: HTTP Error 404: Not Found. Retrying fragment 6 (attempt 1 of 10)... [download] 100% of 15.12MiB in 00:18 [download] Destination: Sraith PictiÃºr - An Ghaeilge Seoid luachmhar-D44-x6PTd_Q.f140.m4a [download] 100% of 1.73MiB in 00:00 [ffmpeg] Merging formats into &#34;Sraith PictiÃºr - An Ghaeilge Seoid luachmhar-D44-x6PTd_Q.mkv&#34; Deleting original file Sraith PictiÃºr - An Ghaeilge Seoid luachmhar-D44-x6PTd_Q.f247.webm (pass -k to keep) Deleting original file Sraith PictiÃºr - An Ghaeilge Seoid luachmhar-D44-x6PTd_Q.f140.m4a (pass -k to keep) . import auditok input = &#39;Sraith PictiÃºr - An Ghaeilge Seoid luachmhar-D44-x6PTd_Q.mkv&#39; audio_regions = auditok.split( input, min_dur=1, max_dur=10, max_silence=0.9, energy_threshold=20 ) for i, r in enumerate(audio_regions): print(&quot;Region {i}: {r.meta.start:.3f}s -- {r.meta.end:.3f}s&quot;.format(i=i, r=r)) . Region 0: 0.300s -- 6.550s Region 1: 7.450s -- 12.950s Region 2: 13.150s -- 15.700s Region 3: 15.900s -- 19.200s Region 4: 19.350s -- 29.350s Region 5: 29.700s -- 34.200s Region 6: 34.300s -- 38.600s Region 7: 39.000s -- 43.650s Region 8: 43.700s -- 46.550s Region 9: 46.750s -- 49.500s Region 10: 49.550s -- 52.950s Region 11: 53.000s -- 56.050s Region 12: 56.250s -- 59.500s Region 13: 59.700s -- 62.550s Region 14: 63.150s -- 69.600s Region 15: 69.650s -- 73.100s Region 16: 73.400s -- 77.450s Region 17: 77.800s -- 81.150s Region 18: 81.350s -- 89.100s Region 19: 89.500s -- 92.750s Region 20: 92.950s -- 96.250s Region 21: 96.500s -- 99.600s Region 22: 99.850s -- 104.350s Region 23: 104.500s -- 108.050s . regs = auditok.load(input) regs.split_and_plot( min_dur=1, max_dur=10, max_silence=0.9, energy_threshold=20, dpi=600 ) . [AudioRegion(duration=6.250, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=5.500, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=2.550, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.300, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=10.000, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=4.500, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=4.300, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=4.650, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=2.850, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=2.750, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.400, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.050, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.250, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=2.850, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=6.450, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.450, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=4.050, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.350, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=7.750, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.250, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.300, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.100, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=4.500, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.550, sampling_rate=44100, sample_width=2, channels=2)] .",
            "url": "https://jimregan.github.io/notes/auditok/2021/05/03/playing-with-auditok.html",
            "relUrl": "/auditok/2021/05/03/playing-with-auditok.html",
            "date": " â€¢ May 3, 2021"
        }
        
    
  
    
        ,"post185": {
            "title": "rclone and Sharepoint",
            "content": "%%capture !curl https://rclone.org/install.sh |bash . curl_out=!curl --cookie -i -L &#39;https://uniwersytetlodzki-my.sharepoint.com/:f:/g/personal/pelcra_uni_lodz_pl/EpPehikqGqZJltrAKlVp3k0BOeyzEgBBO_ZwmFC9WaLbWw&#39;|grep &#39;var _spPageContextInfo=&#39; . import json for s in curl_out: if &#39;var _spPageContextInfo=&#39; in s: start = s[s.index(&#39;access_token=&#39;)+len(&#39;access_token=&#39;):] access_token = start[:start.index(&#39;&quot;&#39;)] . _URL=&#39;https://uniwersytetlodzki-my.sharepoint.com/personal/pelcra_uni_lodz_pl/Documents&#39; . _COOKIE=&#39;FedAuth=77u/PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0idXRmLTgiPz48U1A+VjksMGguZnxtZW1iZXJzaGlwfHVybiUzYXNwbyUzYWFub24jNTZiNDAwY2Y5OWYxMjQwYTkyYjRhNWU3ZTkwYjJlNWVlY2Q3MzYyMGJlNmNiMjI4OTllNjhiMWU4Zjc2Nzk4ZCwwIy5mfG1lbWJlcnNoaXB8dXJuJTNhc3BvJTNhYW5vbiM1NmI0MDBjZjk5ZjEyNDBhOTJiNGE1ZTdlOTBiMmU1ZWVjZDczNjIwYmU2Y2IyMjg5OWU2OGIxZThmNzY3OThkLDEzMjY0NDY0NTU3MDAwMDAwMCwwLDEzMjY0NTUwNjU4MDQxOTgzNCwwLjAuMC4wLDI1OCxkZGIyZmM4NS0xYzE4LTRjMmItOTkyYS1lODQxMWJmZmMwZTcsLCw0ODEyYzQ5Zi02MGY0LTIwMDAtZTE0Mi02YzYwM2MyZGE3YzQsNDgxMmM0OWYtNjBmNC0yMDAwLWUxNDItNmM2MDNjMmRhN2M0LDVrVml3YU9rSGtxaWZjbzVzKytYSlEsMCwwLDAsLCwsMjY1MDQ2Nzc0Mzk5OTk5OTk5OSwwLCwsLCwsc0JtSkR4RTZJd3I5VmsraGJHclFSUDhSNzJIUXh2UWlqNDZ6WnFPdXArUVZnVWhkNkVmQWljNUZ1YUYwMEdGUjRFRnhMRUJsRlNTZ3lnNElkTUdSSnpwbGZUT0JGSkw0Tyt4cjRHS01WdjZ1YnhJWTFzMkFWYWpySVgzbXRGWm9zOHkrYjk0SnhPZElibVVxaUJWZzVaZHVTcWxSMnlFdzc0Y3BueERjVHdQU3FVYTk3VG5qOTRWM0s4YkdkUnA1QVVGSGtacjg2Q0YvZVY5R2Y1OGlTd1ZKUWx2VEc5OVByaU9JWE94Umc4N2FZc2ZFTWZzcG9JL05tYlU0cm9sQ1ZnVzVVNUl3NXJlY29PNzkxUXZZbDBlUlZNcXBVSHI0UEdBOVhLaEJVb3I5YTJpMFpQZEhZRE9SQnlVcWtHRDQvb0NXY21JamdGQVhNM2RtTFgwWGJBPT08L1NQPg==; path=/; SameSite=None; secure; HttpOnly&#39; . !rclone config create pelcra webdav url {_URL} webdav-vendor other access_token {access_token} #cookie &quot;{_COOKIE}&quot; . Remote config -- [pelcra] type = webdav url = https://uniwersytetlodzki-my.sharepoint.com/personal/pelcra_uni_lodz_pl/Documents webdav-vendor = other access_token = eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJhdWQiOiIwMDAwMDAwMy0wMDAwLTBmZjEtY2UwMC0wMDAwMDAwMDAwMDAvdW5pd2Vyc3l0ZXRsb2R6a2ktbXkuc2hhcmVwb2ludC5jb21ANjM0NDFhZWYtZGEwZS00Mzk3LWJiN2UtZjlkNDcwNWU5NjNiIiwiaXNzIjoiMDAwMDAwMDMtMDAwMC0wZmYxLWNlMDAtMDAwMDAwMDAwMDAwIiwibmJmIjoxNjIwMjU0MjMwLCJleHAiOjE2MjAyNzU4MzAsImlzbG9vcGJhY2siOiJUcnVlIiwibmFtZWlkIjoiMCMuZnxtZW1iZXJzaGlwfHVybiUzYXNwbyUzYWFub24jNTZiNDAwY2Y5OWYxMjQwYTkyYjRhNWU3ZTkwYjJlNWVlY2Q3MzYyMGJlNmNiMjI4OTllNjhiMWU4Zjc2Nzk4ZCIsIm5paSI6Im1pY3Jvc29mdC5zaGFyZXBvaW50IiwiaXN1c2VyIjoidHJ1ZSIsImNhY2hla2V5IjoiMGguZnxtZW1iZXJzaGlwfHVybiUzYXNwbyUzYWFub24jNTZiNDAwY2Y5OWYxMjQwYTkyYjRhNWU3ZTkwYjJlNWVlY2Q3MzYyMGJlNmNiMjI4OTllNjhiMWU4Zjc2Nzk4ZCIsInR0IjoiMCIsInVzZVBlcnNpc3RlbnRDb29raWUiOiIyIn0.A50UZ17CCLwueDg9UAJx4NY4FM-3p_vRN59OrxDxFz4u0026prooftoken=eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsIng1dCI6IkcydDJKYzlkMVZ6RkdjdzZUZy02YUhZVXk2VSJ9.eyJhdWQiOiIwMDAwMDAwMy0wMDAwLTBmZjEtY2UwMC0wMDAwMDAwMDAwMDBAKiIsImlzcyI6IjAwMDAwMDAzLTAwMDAtMGZmMS1jZTAwLTAwMDAwMDAwMDAwMEAqIiwibmJmIjoiMTYyMDI0NjgzMCIsImV4cCI6IjE2MjA4NTE2MzAiLCJwcmYiOiJLMUs2Z21oMFNpZDBaL2E0SjJReXpDSVJLMXBTWGlyOXAzcitoM1UwTjZRNWo2UEc2REZPaG5OU2dPU3FwZDRXK1ZpenppSTlCcWc2d2kvSE83Zk9scGhmaE9pU3NLN1p6clFGMUxlOFk3dnJJejdNb1RLQ3Njbjh5cUhvSklVbjFmVFlIcGltb1E0NnJQdVlJV0pJK3UwOXVHTVBpSS9ZcWlCYzhHd0VBTit0bnoyZ2tIcXM3OGhXbGo2Y3dBNzNTckJwTHBTdG53QzZaRXRoUVV1N3l6eGhuRVlXdkNhNUFPdVlWaXRiMndTZWpib0g5QlBCc0puemVEL1ZMUDFqZXh2Qk9DRVpYN25XRjU4SC9Sck1tdWdZb2ZxMGQzZnhlTG56d0RJbDFEYjdqcFc3L20vaURJV1FQRUZScmFmUW1pbFJmYjRSTFUxVFFGWWptVHJmU1E9PSIsImlzdXNlciI6InRydWUifQ.o1x0-K2UNkorQjKyT5o0HXJiOJxHP3vlYscEzjKN2KQHzp95ja3ml5yzqPtSXdCwYxjCdJjWgtAvS5YlQzLBX2Eac8odydBxDa8EHyuVxIa6T-n7dD4R1WHVebyXt62shIP61s_TeiJkwiD0Sl_nPIzqY9zkrKEg_cSe0isEi0mCv6ynYXCWetYpaMdv4ifaGAl5aK7v6zxNKzwVoxBUfEIcJLV8MjdeV1i1Puuinpj69GUispryx7ruDs0g5CLVjOeAk0wwaoTeRzL4y04EKTKdt4UsdeAAXzE1Rby4na3xqDkeewPUCYxZHQL89tGOUcmiwjJKeB7Fos39XIhrRg -- . !rclone ls --use-cookies -vv &#39;pelcra:SHARE/CLARIN/SPOKES/PELCRA_EMO&#39; --dump bodies . 2021/05/05 22:54:48 DEBUG : Using config file from &#34;/root/.config/rclone/rclone.conf&#34; 2021/05/05 22:54:48 DEBUG : rclone: Version &#34;v1.55.1&#34; starting with parameters [&#34;rclone&#34; &#34;ls&#34; &#34;--use-cookies&#34; &#34;-vv&#34; &#34;pelcra:SHARE/CLARIN/SPOKES/PELCRA_EMO&#34; &#34;--dump&#34; &#34;bodies&#34;] 2021/05/05 22:54:48 DEBUG : Creating backend with remote &#34;pelcra:SHARE/CLARIN/SPOKES/PELCRA_EMO&#34; 2021/05/05 22:54:48 DEBUG : You have specified to dump information. Please be noted that the Accept-Encoding as shown may not be correct in the request and the response may not show Content-Encoding if the go standard libraries auto gzip encoding was in effect. In this case the body of the request will be gunzipped before showing it. 2021/05/05 22:54:48 DEBUG : &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 2021/05/05 22:54:48 DEBUG : HTTP REQUEST (req 0xc000596a00) 2021/05/05 22:54:48 DEBUG : PROPFIND /personal/pelcra_uni_lodz_pl/Documents/SHARE/CLARIN/SPOKES/PELCRA_EMO HTTP/1.1 Host: uniwersytetlodzki-my.sharepoint.com User-Agent: rclone/v1.55.1 Depth: 1 Referer: https://uniwersytetlodzki-my.sharepoint.com/personal/pelcra_uni_lodz_pl/Documents/ Accept-Encoding: gzip 2021/05/05 22:54:48 DEBUG : &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 2021/05/05 22:54:49 DEBUG : &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; 2021/05/05 22:54:49 DEBUG : HTTP RESPONSE (req 0xc000596a00) 2021/05/05 22:54:49 DEBUG : HTTP/2.0 403 Forbidden Content-Length: 13 Content-Type: text/plain; charset=utf-8 Date: Wed, 05 May 2021 22:54:48 GMT Microsoftsharepointteamservices: 16.0.0.21221 Ms-Cv: n8UOqHwAACDhQmsT9SmG6Q.0 P3p: CP=&#34;ALL IND DSP COR ADM CONo CUR CUSo IVAo IVDo PSA PSD TAI TELo OUR SAMo CNT COM INT NAV ONL PHY PRE PUR UNI&#34; Request-Id: a80ec59f-007c-2000-e142-6b13f52986e9 Sprequestguid: a80ec59f-007c-2000-e142-6b13f52986e9 X-Content-Type-Options: nosniff X-Forms_based_auth_required: https://uniwersytetlodzki-my.sharepoint.com/_forms/default.aspx?ReturnUrl=/_layouts/15/error.aspx&amp;Source=%2fpersonal%2fpelcra_uni_lodz_pl%2fDocuments%2fSHARE%2fCLARIN%2fSPOKES%2fPELCRA_EMO X-Forms_based_auth_return_url: https://uniwersytetlodzki-my.sharepoint.com/_layouts/15/error.aspx X-Idcrl_auth_params_v1: IDCRL Type=&#34;BPOSIDCRL&#34;, EndPoint=&#34;/personal/pelcra_uni_lodz_pl/_vti_bin/idcrl.svc/&#34;, RootDomain=&#34;sharepoint.com&#34;, Policy=&#34;MBI&#34; X-Ms-Invokeapp: 1; RequireReadOnly X-Msdavext_error: 917656; Access+denied.+Before+opening+files+in+this+location%2c+you+must+first+browse+to+the+web+site+and+select+the+option+to+login+automatically. X-Msedge-Ref: Ref A: 8A3CC80AA56A42C4A2112F4377B61AA6 Ref B: HK2EDGE0921 Ref C: 2021-05-05T22:54:49Z X-Powered-By: ASP.NET X-Sharepointhealthscore: 3 403 FORBIDDEN 2021/05/05 22:54:49 DEBUG : &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; 2021/05/05 22:54:49 Failed to create file system for &#34;pelcra:SHARE/CLARIN/SPOKES/PELCRA_EMO&#34;: read metadata failed: 403 FORBIDDEN: 403 Forbidden . !rclone ls :http: --http-url &#39;https://uniwersytetlodzki-my.sharepoint.com/:f:/g/personal/pelcra_uni_lodz_pl/EpPehikqGqZJltrAKlVp3k0BOeyzEgBBO_ZwmFC9WaLbWw&#39; --use-cookies -vv . !rclone config dump .",
            "url": "https://jimregan.github.io/notes/rclone/sharepoint/2021/05/02/rclone-and-sharepoint.html",
            "relUrl": "/rclone/sharepoint/2021/05/02/rclone-and-sharepoint.html",
            "date": " â€¢ May 2, 2021"
        }
        
    
  
    
        ,"post186": {
            "title": "Ruby kernel on Colab",
            "content": "!apt-get install ruby-dev !sudo apt install libtool libffi-dev ruby ruby-dev make !sudo apt install libzmq3-dev libczmq-dev !gem install ffi-rzmq !gem install specific_install !gem specific_install https://github.com/SciRuby/iruby !iruby register . !jupyter kernelspec list . Available kernels: ruby /root/.local/share/jupyter/kernels/ruby ir /usr/local/share/jupyter/kernels/ir python2 /usr/local/share/jupyter/kernels/python2 python3 /usr/local/share/jupyter/kernels/python3 .",
            "url": "https://jimregan.github.io/notes/colab/misc/2021/05/01/colab-ruby-kernel.html",
            "relUrl": "/colab/misc/2021/05/01/colab-ruby-kernel.html",
            "date": " â€¢ May 1, 2021"
        }
        
    
  
    
        ,"post187": {
            "title": "Two speechbrain speech enhancement models",
            "content": "The Colab notebook (with outputs) is here; the models are on the Huggingface hub: mtl-mimic-voicebank and speechbrain/metricgan-plus-voicebank . The first twenty seconds of mtl-mimic-voicebank aren&#39;t great (but they are quieter in the recording); the rest is fantastic. The output from metricgan-plus-voicebank is bad from start to finish. . %%capture !pip install torchaudio speechbrain . !wget http://assets.doegen.ie/sound/MP3_versions/aud_Ul1-LA_1202d1u1.mp3 . import IPython IPython.display.Audio(&#39;aud_Ul1-LA_1202d1u1.mp3&#39;) . import torchaudio from speechbrain.pretrained import SpectralMaskEnhancement enhance_model = SpectralMaskEnhancement.from_hparams( source=&quot;speechbrain/mtl-mimic-voicebank&quot;, savedir=&quot;pretrained_models/mtl-mimic-voicebank&quot;, ) enhanced = enhance_model.enhance_file(&quot;aud_Ul1-LA_1202d1u1.mp3&quot;) # Saving enhanced signal on disk torchaudio.save(&#39;enhanced.wav&#39;, enhanced.unsqueeze(0), 16000) . IPython.display.Audio(&#39;enhanced.wav&#39;) . import torch enhance_model = SpectralMaskEnhancement.from_hparams( source=&quot;speechbrain/metricgan-plus-voicebank&quot;, savedir=&quot;pretrained_models/metricgan-plus-voicebank&quot;, ) noisy = enhance_model.load_audio(&quot;aud_Ul1-LA_1202d1u1.mp3&quot;).unsqueeze(0) # Add relative length tensor enhanced = enhance_model.enhance_batch(noisy, lengths=torch.tensor([1.])) # Saving enhanced signal on disk torchaudio.save(&#39;enhanced2.wav&#39;, enhanced, 16000) . IPython.display.Audio(&#39;enhanced2.wav&#39;) .",
            "url": "https://jimregan.github.io/notes/speechbrain/speech%20enhancement/2021/04/30/speechbrain_speech_enhancements.html",
            "relUrl": "/speechbrain/speech%20enhancement/2021/04/30/speechbrain_speech_enhancements.html",
            "date": " â€¢ Apr 30, 2021"
        }
        
    
  
    
        ,"post188": {
            "title": "Polish phonetic comparison",
            "content": "from difflib import SequenceMatcher import icu . plipa = icu.Transliterator.createInstance(&#39;pl-pl_FONIPA&#39;) . The errors in E2E models are quite often phonetic confusions, so we do the opposite of traditional ASR and generate the phonetic representation from the output as a basis for comparison. . def phonetic_check(word1, word2, ignore_spaces=False): &quot;&quot;&quot;Uses ICU&#39;s IPA transliteration to check if words are the same&quot;&quot;&quot; tl1 = plipa.transliterate(word1) if not ignore_spaces else plipa.transliterate(word1.replace(&#39; &#39;, &#39;&#39;)) tl2 = plipa.transliterate(word2) if not ignore_spaces else plipa.transliterate(word2.replace(&#39; &#39;, &#39;&#39;)) return tl1 == tl2 . phonetic_check(&quot;jÃ³rz&quot;, &quot;jusz&quot;, False) . True . The Polish y is phonetically a raised schwa; like the schwa in English, it&#39;s often deleted in fast speech. This function returns true if the only differences between the first word and the second is are deletions of y, except at the end of the word (which is typically the plural ending). . def no_igrek(word1, word2): &quot;&quot;&quot;Checks if a word-internal y has been deleted&quot;&quot;&quot; sm = SequenceMatcher(None, word1, word2) for oc in sm.get_opcodes(): if oc[0] == &#39;equal&#39;: continue elif oc[0] == &#39;delete&#39; and word1[oc[1]:oc[2]] != &#39;y&#39;: return False elif oc[0] == &#39;delete&#39; and word1[oc[1]:oc[2]] == &#39;y&#39; and oc[2] == len(word1): return False elif oc[0] == &#39;insert&#39; or oc[0] == &#39;replace&#39;: return False return True . no_igrek(&#39;uniwersytet&#39;, &#39;uniwerstet&#39;) . True . no_igrek(&#39;uniwerstety&#39;, &#39;uniwerstet&#39;) . False . phonetic_alternatives = [ [&#39;u&#39;, &#39;Ã³&#39;], [&#39;rz&#39;, &#39;Å¼&#39;] ] def reverse_alts(phonlist): return [ [i[1], i[0]] for i in phonlist ] . sm = SequenceMatcher(None, &quot;juÅ¼&quot;, &quot;jurz&quot;) for oc in sm.get_opcodes(): print(oc) . (&#39;equal&#39;, 0, 2, 0, 2) (&#39;replace&#39;, 2, 3, 2, 4) . Reads a CTM-like file, returning a list of lists containing the filename, start time, end time, and word. . def read_ctmish(filename): output = [] with open(filename, &#39;r&#39;) as f: for line in f.readlines(): pieces = line.strip().split(&#39; &#39;) if len(pieces) &lt;= 4: continue for piece in pieces[4:]: output.append([pieces[0], pieces[2], pieces[3], piece]) return output . Returns the contents of a plain text file as a list of lists containing the line number and the word, for use in locating mismatches . def read_text(filename): output = [] counter = 0 with open(filename, &#39;r&#39;) as f: for line in f.readlines(): counter += 1 for word in line.strip().split(&#39; &#39;) output.append([counter, word]) return output . ctmish = read_ctmish(&quot;/mnt/c/Users/Jim O &#39;Regan/git/notes/PlgU9JyTLPE.ctm&quot;) . rec_words = [i[3] for i in ctmish] .",
            "url": "https://jimregan.github.io/notes/asr/polish/phonetic/todo/2021/04/29/phonetic-comparison.html",
            "relUrl": "/asr/polish/phonetic/todo/2021/04/29/phonetic-comparison.html",
            "date": " â€¢ Apr 29, 2021"
        }
        
    
  
    
        ,"post189": {
            "title": "Doegen recordings scraper",
            "content": "import requests from bs4 import BeautifulSoup import json . _BASE = &#39;https://doegen.ie/counties&#39; def do_get(url): r = requests.get(url, headers = {&#39;User-agent&#39;: &#39;Mozilla/5.0&#39;}) if r.status_code != 200: raise Exception(&quot;Failed to open landing page&quot;) return r.content . soup = BeautifulSoup(do_get(_BASE), &#39;html.parser&#39;) . counties = soup.find(&#39;ul&#39;, {&#39;class&#39;: &#39;vocabindex&#39;}).find_all(&#39;li&#39;) . pages = [] for county in counties: item = {} anchor = county.find(&#39;a&#39;) href = anchor[&#39;href&#39;] item[&#39;link&#39;] = f&#39;https://doegen.ie{href}&#39; if anchor.find(&#39;span&#39;).text.strip() != &#39;(0)&#39;: item[&#39;county&#39;] = anchor.text.split()[1] pages.append(item) . def proc_page(url): result = {} html = do_get(url) soup = BeautifulSoup(html, &#39;html.parser&#39;) main = soup.find(&#39;div&#39;, {&#39;id&#39;: &#39;main&#39;}) content = main.find(&#39;div&#39;, {&#39;class&#39;: &#39;content&#39;}) source = content.find(&#39;source&#39;) if source == None: return {} result[&#39;mp3&#39;] = source[&#39;src&#39;] result[&#39;transcript&#39;] = content.find(&#39;div&#39;, id=&#39;transcript&#39;).text if content.find(&#39;div&#39;, id=&#39;translation&#39;) != None: result[&#39;translation&#39;] = content.find(&#39;div&#39;, id=&#39;translation&#39;).text if content.find(&#39;div&#39;, id=&#39;footnote&#39;) != None: result[&#39;footnote&#39;] = content.find(&#39;div&#39;, id=&#39;footnote&#39;).text result[&#39;recording_metadata&#39;] = content.find(&#39;div&#39;, id=&#39;recording_metadata&#39;).text return result . def proc_county(item): content = do_get(item[&#39;link&#39;]) soup = BeautifulSoup(content, &#39;html.parser&#39;) main = soup.find(&#39;div&#39;, id=&#39;main&#39;) nodes = main.find_all(&#39;div&#39;, {&#39;class&#39;: &#39;node&#39;}) stories = [] for node in nodes: story = {} anchor = node.find(&#39;a&#39;) story[&#39;link&#39;] = f&quot;https://doegen.ie{anchor[&#39;href&#39;]}&quot; story[&#39;content&#39;] = proc_page(story[&#39;link&#39;]) if story[&#39;content&#39;] == {}: continue tags = node.find(&#39;div&#39;, {&#39;class&#39;: &#39;terms&#39;}).find_all(&#39;a&#39;, rel=&#39;tag&#39;) text = anchor.text if &#39; - &#39; in text: tmp = text.split(&#39; - &#39;) if len(tmp) == 2: story[&#39;title&#39;] = tmp[0] story[&#39;speaker_name&#39;] = tmp[1] name_parts = tmp[1].split(&#39; &#39;) first = name_parts[0] for tag in tags: if first in tag.text: story[&#39;speaker_url&#39;] = f&quot;https://doegen.ie{tag[&#39;href&#39;]}&quot; else: story[&#39;raw&#39;] = text else: story[&#39;raw&#39;] = text stories.append(story) item[&#39;stories&#39;] = stories . for page in pages: proc_county(page) . with open(&#39;doegen.json&#39;, &#39;w&#39;) as f: json.dump(pages, f) .",
            "url": "https://jimregan.github.io/notes/irish/scraper/2021/04/29/doegen-scraper.html",
            "relUrl": "/irish/scraper/2021/04/29/doegen-scraper.html",
            "date": " â€¢ Apr 29, 2021"
        }
        
    
  
    
        ,"post190": {
            "title": "Praat via parselmouth",
            "content": "import numpy as np import matplotlib.pyplot as plt import seaborn as sns import requests import parselmouth import tempfile . sns.set() # Use seaborn&#39;s default style to make attractive graphs plt.rcParams[&#39;figure.dpi&#39;] = 300 # Show nicely large images in this notebook . def load_from_teanglann(word, dialect): valid_dialects = [&#39;C&#39;, &#39;M&#39;, &#39;U&#39;] if dialect not in valid_dialects and dialect.upper()[0] not in valid_dialects: raise Exception(f&#39;Dialect must be one of &quot;C&quot;, &quot;M&quot; or &quot;U&quot;; got &quot;{dialect}&quot;&#39;) url = f&#39;https://www.teanglann.ie/Can{dialect}/{word}.mp3&#39; r = requests.get(url) if r.status_code != 200: raise Exception(f&#39;Failed to fetch {url}&#39;) file = tempfile.NamedTemporaryFile(mode=&#39;w+b&#39;) file.write(r.content) return file . def draw_spectrogram(spectrogram, dynamic_range=70): X, Y = spectrogram.x_grid(), spectrogram.y_grid() sg_db = 10 * np.log10(spectrogram.values) plt.pcolormesh(X, Y, sg_db, vmin=sg_db.max() - dynamic_range, cmap=&#39;afmhot&#39;) plt.ylim([spectrogram.ymin, spectrogram.ymax]) plt.xlabel(&quot;time [s]&quot;) plt.ylabel(&quot;frequency [Hz]&quot;) def draw_intensity(intensity): plt.plot(intensity.xs(), intensity.values.T, linewidth=3, color=&#39;w&#39;) plt.plot(intensity.xs(), intensity.values.T, linewidth=1) plt.grid(False) plt.ylim(0) plt.ylabel(&quot;intensity [dB]&quot;) . file=load_from_teanglann(&#39;athdhreas&#39;, &#39;U&#39;) snd = parselmouth.Sound(file_path=file.name) intensity = snd.to_intensity() spectrogram = snd.to_spectrogram() plt.figure() draw_spectrogram(spectrogram) plt.twinx() #draw_intensity(intensity) plt.xlim([snd.xmin, snd.xmax]) plt.show() . def draw_pitch(pitch): # Extract selected pitch contour, and # replace unvoiced samples by NaN to not plot pitch_values = pitch.selected_array[&#39;frequency&#39;] pitch_values[pitch_values==0] = np.nan plt.plot(pitch.xs(), pitch_values, &#39;o&#39;, markersize=5, color=&#39;w&#39;) plt.plot(pitch.xs(), pitch_values, &#39;o&#39;, markersize=2) plt.grid(False) plt.ylim(0, pitch.ceiling) plt.ylabel(&quot;fundamental frequency [Hz]&quot;) pitch = snd.to_pitch() # If desired, pre-emphasize the sound fragment before calculating the spectrogram pre_emphasized_snd = snd.copy() pre_emphasized_snd.pre_emphasize() spectrogram = pre_emphasized_snd.to_spectrogram(window_length=0.03, maximum_frequency=8000) plt.figure() draw_spectrogram(spectrogram) plt.twinx() #draw_pitch(pitch) plt.xlim([snd.xmin, snd.xmax]) plt.show() .",
            "url": "https://jimregan.github.io/notes/praat/parselmouth/2021/04/24/parselmouth.html",
            "relUrl": "/praat/parselmouth/2021/04/24/parselmouth.html",
            "date": " â€¢ Apr 24, 2021"
        }
        
    
  
    
        ,"post191": {
            "title": "BuNaMo to json",
            "content": "from lxml import etree . class BuNaMoWrongDocument(Exception): &quot;&quot;&quot;Exception raised for wrong document type&quot;&quot;&quot; def __init__(self, expected, got): self.expected = expected self.got = got self.message = f&quot;Expected root element &lt;{self.expected}&gt; but got &lt;{self.got}&gt;&quot; super().__init__(self.message) . Various functions to read one of the types of XML file. The open parts of speech (noun, adjective, verb) can have multiple forms, so those functions return attributes (a dictionary) and forms (a list of dictionaries) separately. . Close parts of speech (possessives and prepositions) are simpler, and most of the attributes are needless, so they return a simple dictionary containing the forms. . def read_adjective(file): tree = etree.parse(file) root = tree.getroot() valid_tags = [&#39;sgNom&#39;, &#39;sgGenMasc&#39;, &#39;sgGenFem&#39;, &#39;plNom&#39;, &#39;graded&#39;, &#39;abstractNoun&#39;, &#39;sgVocMasc&#39;, &#39;sgVocFem&#39;] attribs = {} forms = [] if root.tag != &#39;adjective&#39;: raise BuNaMoWrongDocument(&#39;adjective&#39;, root.tag) attribs[&#39;default&#39;] = root.get(&#39;default&#39;) attribs[&#39;declension&#39;] = root.get(&#39;declension&#39;) attribs[&#39;disambig&#39;] = root.get(&#39;disambig&#39;) attribs[&#39;isPre&#39;] = root.get(&#39;isPre&#39;) for child in root: if child.tag not in valid_tags: raise Exception(&#39;Unexpected tag &#39; + child.tag) tmp = {} tmp[&#39;props&#39;] = child.tag tmp[&#39;form&#39;] = child.get(&#39;default&#39;) forms.append(tmp) return attribs, forms def read_noun(file): tree = etree.parse(file) root = tree.getroot() valid_tags = [&#39;sgNom&#39;, &#39;sgGen&#39;, &#39;plNom&#39;, &#39;plGen&#39;, &#39;count&#39;, &#39;sgDat&#39;] attribs = {} forms = [] if root.tag != &#39;noun&#39;: raise BuNaMoWrongDocument(&#39;noun&#39;, root.tag) attribs[&#39;default&#39;] = root.get(&#39;default&#39;) attribs[&#39;declension&#39;] = root.get(&#39;declension&#39;) attribs[&#39;disambig&#39;] = root.get(&#39;disambig&#39;) attribs[&#39;isProper&#39;] = root.get(&#39;isProper&#39;) attribs[&#39;isDefinite&#39;] = root.get(&#39;isDefinite&#39;) attribs[&#39;allowArticledGenitive&#39;] = root.get(&#39;allowArticledGenitive&#39;) for child in root: if child.tag not in valid_tags: raise Exception(&#39;Unexpected tag &#39; + child.tag) tmp = {} tmp[&#39;props&#39;] = child.tag tmp[&#39;form&#39;] = child.get(&#39;default&#39;) tmp[&#39;gender&#39;] = child.get(&#39;gender&#39;) tmp[&#39;strength&#39;] = child.get(&#39;strength&#39;) forms.append(tmp) return attribs, forms def read_verb(file): tree = etree.parse(file) root = tree.getroot() valid_tags = [&#39;verbalNoun&#39;, &#39;verbalAdjective&#39;, &#39;tenseForm&#39;, &#39;moodForm&#39;] attribs = {} forms = [] if root.tag != &#39;verb&#39;: raise BuNaMoWrongDocument(&#39;verb&#39;, root.tag) attribs[&#39;default&#39;] = root.get(&#39;default&#39;) attribs[&#39;disambig&#39;] = root.get(&#39;disambig&#39;) for child in root: if child.tag not in valid_tags: raise Exception(&#39;Unexpected tag &#39; + child.tag) tmp = {} tmp[&#39;props&#39;] = child.tag tmp[&#39;form&#39;] = child.get(&#39;default&#39;) tmp[&#39;tense&#39;] = child.get(&#39;tense&#39;) tmp[&#39;mood&#39;] = child.get(&#39;mood&#39;) tmp[&#39;dependency&#39;] = child.get(&#39;dependency&#39;) tmp[&#39;person&#39;] = child.get(&#39;person&#39;) forms.append(tmp) return attribs, forms def read_nounphrase(file): tree = etree.parse(file) root = tree.getroot() valid_tags = [&#39;sgNom&#39;, &#39;sgGen&#39;, &#39;plNom&#39;, &#39;plGen&#39;, &#39;sgNomArt&#39;, &#39;sgGenArt&#39;, &#39;plNomArt&#39;, &#39;plGenArt&#39;] attribs = {} forms = [] if root.tag != &#39;nounPhrase&#39;: raise BuNaMoWrongDocument(&#39;nounPhrase&#39;, root.tag) attribs[&#39;default&#39;] = root.get(&#39;default&#39;) attribs[&#39;declension&#39;] = root.get(&#39;declension&#39;) attribs[&#39;disambig&#39;] = root.get(&#39;disambig&#39;) attribs[&#39;isProper&#39;] = root.get(&#39;isProper&#39;) attribs[&#39;isDefinite&#39;] = root.get(&#39;isDefinite&#39;) attribs[&#39;allowArticledGenitive&#39;] = root.get(&#39;allowArticledGenitive&#39;) attribs[&#39;forceNominative&#39;] = root.get(&#39;forceNominative&#39;) for child in root: if child.tag not in valid_tags: raise Exception(&#39;Unexpected tag &#39; + child.tag) tmp = {} tmp[&#39;props&#39;] = child.tag tmp[&#39;form&#39;] = child.get(&#39;default&#39;) tmp[&#39;gender&#39;] = child.get(&#39;gender&#39;) tmp[&#39;strength&#39;] = child.get(&#39;strength&#39;) forms.append(tmp) return attribs, forms def read_possessive(file): tree = etree.parse(file) root = tree.getroot() valid_tags = [&#39;full&#39;, &#39;apos&#39;] attribs = {} forms = [] if root.tag != &#39;possessive&#39;: raise BuNaMoWrongDocument(&#39;possessive&#39;, root.tag) attribs[&#39;default&#39;] = root.get(&#39;default&#39;) attribs[&#39;disambig&#39;] = root.get(&#39;disambig&#39;) attribs[&#39;mutation&#39;] = root.get(&#39;mutation&#39;) for child in root: if child.tag not in valid_tags: raise Exception(&#39;Unexpected tag &#39; + child.tag) if child.tag == &#39;apos&#39;: attribs[&#39;apos&#39;] = child.get(&#39;default&#39;) return attribs def read_preposition(file): tree = etree.parse(file) root = tree.getroot() valid_tags = [&#39;sg1&#39;, &#39;sg2&#39;, &#39;sg3Masc&#39;, &#39;sg3Fem&#39;, &#39;pl1&#39;, &#39;pl2&#39;, &#39;pl3&#39;] attribs = {} forms = [] if root.tag != &#39;preposition&#39;: raise BuNaMoWrongDocument(&#39;preposition&#39;, root.tag) attribs[&#39;default&#39;] = root.get(&#39;default&#39;) for child in root: if child.tag not in valid_tags: raise Exception(&#39;Unexpected tag &#39; + child.tag) attribs[child.tag] = child.get(&#39;default&#39;) return attribs . import glob import json adjectives = {} for x in glob.glob(&#39;../input/bunamo-bunachar-naisiunta-moirfeolaiochta/adjective/*.xml&#39;): fname = x.split(&#39;/&#39;)[-1].replace(&#39;.xml&#39;, &#39;&#39;) attribs, forms = read_adjective(x) tmp = {} tmp[&#39;attributes&#39;] = attribs tmp[&#39;forms&#39;] = forms adjectives[fname] = tmp word = attribs[&#39;default&#39;] with open(&#39;adjectives.json&#39;, &#39;w&#39;) as outfile: json.dump(adjectives, outfile) . nouns = {} for x in glob.glob(&#39;../input/bunamo-bunachar-naisiunta-moirfeolaiochta/noun/*.xml&#39;): fname = x.split(&#39;/&#39;)[-1].replace(&#39;.xml&#39;, &#39;&#39;) attribs, forms = read_noun(x) tmp = {} tmp[&#39;attributes&#39;] = attribs tmp[&#39;forms&#39;] = forms nouns[fname] = tmp word = attribs[&#39;default&#39;] with open(&#39;nouns.json&#39;, &#39;w&#39;) as outfile: json.dump(nouns, outfile) . nounphrases = {} for x in glob.glob(&#39;../input/bunamo-bunachar-naisiunta-moirfeolaiochta/nounPhrase/*.xml&#39;): fname = x.split(&#39;/&#39;)[-1].replace(&#39;.xml&#39;, &#39;&#39;) attribs, forms = read_nounphrase(x) tmp = {} tmp[&#39;attributes&#39;] = attribs tmp[&#39;forms&#39;] = forms nounphrases[fname] = tmp word = attribs[&#39;default&#39;] with open(&#39;nounphrases.json&#39;, &#39;w&#39;) as outfile: json.dump(nounphrases, outfile) . verbs = {} for x in glob.glob(&#39;../input/bunamo-bunachar-naisiunta-moirfeolaiochta/verb/*.xml&#39;): fname = x.split(&#39;/&#39;)[-1].replace(&#39;.xml&#39;, &#39;&#39;) attribs, forms = read_verb(x) tmp = {} tmp[&#39;attributes&#39;] = attribs tmp[&#39;forms&#39;] = forms verbs[fname] = tmp word = attribs[&#39;default&#39;] with open(&#39;verbs.json&#39;, &#39;w&#39;) as outfile: json.dump(verbs, outfile) . preposition = {} for x in glob.glob(&#39;../input/bunamo-bunachar-naisiunta-moirfeolaiochta/preposition/*.xml&#39;): fname = x.split(&#39;/&#39;)[-1].replace(&#39;.xml&#39;, &#39;&#39;) attribs = read_preposition(x) tmp = {} tmp[&#39;attributes&#39;] = attribs preposition[fname] = tmp with open(&#39;prepositions.json&#39;, &#39;w&#39;) as outfile: json.dump(preposition, outfile) . possessive = {} for x in glob.glob(&#39;../input/bunamo-bunachar-naisiunta-moirfeolaiochta/possessive/*.xml&#39;): fname = x.split(&#39;/&#39;)[-1].replace(&#39;.xml&#39;, &#39;&#39;) attribs = read_possessive(x) tmp = {} tmp[&#39;attributes&#39;] = attribs possessive[fname] = tmp with open(&#39;possessives.json&#39;, &#39;w&#39;) as outfile: json.dump(possessive, outfile) . possessive . {&#39;Ã¡r_poss&#39;: {&#39;attributes&#39;: {&#39;default&#39;: &#39;Ã¡r&#39;, &#39;disambig&#39;: &#39;&#39;, &#39;mutation&#39;: &#39;ecl1&#39;}}, &#39;a_poss_masc&#39;: {&#39;attributes&#39;: {&#39;default&#39;: &#39;a&#39;, &#39;disambig&#39;: &#39;masc&#39;, &#39;mutation&#39;: &#39;len1&#39;}}, &#39;a_poss_fem&#39;: {&#39;attributes&#39;: {&#39;default&#39;: &#39;a&#39;, &#39;disambig&#39;: &#39;fem&#39;, &#39;mutation&#39;: &#39;prefH&#39;}}, &#39;do_poss&#39;: {&#39;attributes&#39;: {&#39;default&#39;: &#39;do&#39;, &#39;disambig&#39;: &#39;&#39;, &#39;mutation&#39;: &#39;len1&#39;, &#39;apos&#39;: &#34;d&#39;&#34;}}, &#39;a_poss_pl&#39;: {&#39;attributes&#39;: {&#39;default&#39;: &#39;a&#39;, &#39;disambig&#39;: &#39;pl&#39;, &#39;mutation&#39;: &#39;ecl1&#39;}}, &#39;mo_poss&#39;: {&#39;attributes&#39;: {&#39;default&#39;: &#39;mo&#39;, &#39;disambig&#39;: &#39;&#39;, &#39;mutation&#39;: &#39;len1&#39;, &#39;apos&#39;: &#34;m&#39;&#34;}}, &#39;bhur_poss&#39;: {&#39;attributes&#39;: {&#39;default&#39;: &#39;bhur&#39;, &#39;disambig&#39;: &#39;&#39;, &#39;mutation&#39;: &#39;ecl1&#39;}}} .",
            "url": "https://jimregan.github.io/notes/irish/bunamo/kaggle/2021/04/24/bunamo-raw-json.html",
            "relUrl": "/irish/bunamo/kaggle/2021/04/24/bunamo-raw-json.html",
            "date": " â€¢ Apr 24, 2021"
        }
        
    
  
    
        ,"post192": {
            "title": "Kashubian PDF corpus 1",
            "content": "!wget $(lynx -dump http://skarbnicakaszubska.pl/najo-uczba/|grep pdf|awk &#39;{print $NF}&#39;) . For the most part, the text extracted from the pdfs is fine as is; one of the files has multiple articles, several with translations, making it potentially useful as a parallel corpus. . The text (seems to) come out fine with pdftotext, so I haven&#39;t bothered doing anything else. . !pdftotext -nopgbrk -f 9 -l 10 ZKP_biuletynRJK_2015_internet.pdf - | grep -v &#39;BIUÂ­L EÂ­T IN RADZÃ‹ZNÃ‹ KASZÃ‹BSCZÃ‰GÃ’ JÃƒZÃ‹KA 2015&#39;|grep -v &#39;^10&#39;|grep -v &#39;^$&#39; &gt; ZKP_biuletynRJK_2015_internet_1.csb.txt . !pdftotext -nopgbrk -f 11 -l 12 ZKP_biuletynRJK_2015_internet.pdf - | grep -v &#39;BIUÂ­L EÂ­T YN RADY JÄ˜ZYKA KASZUBSKIEGO 2015&#39;|grep -v &#39;^12&#39;|grep -v &#39;^$&#39; &gt; ZKP_biuletynRJK_2015_internet_1.pl.txt . !pdftotext -nopgbrk -f 14 -l 20 ZKP_biuletynRJK_2015_internet.pdf - | grep -v &#39;BIUÂ­L EÂ­T IN RADZÃ‹ZNÃ‹ KASZÃ‹BSCZÃ‰GÃ’ JÃƒZÃ‹KA 2015&#39;|grep -v &#39;^PÃ²stanowienia RadzÃ«znÃ« KaszÃ«bsczÃ©gÃ² JÃ£zÃ«ka&#39;|grep -v &#39;^$&#39;|grep -v &#39;^1[5-9]$&#39;|grep -v &#39;^20$&#39; &gt; ZKP_biuletynRJK_2015_internet_wl1.txt . !pdftotext -nopgbrk -f 21 -l 23 ZKP_biuletynRJK_2015_internet.pdf - | grep -v &#39;BIUÂ­L EÂ­T IN RADZÃ‹ZNÃ‹ KASZÃ‹BSCZÃ‰GÃ’ JÃƒZÃ‹KA 2015&#39;|grep -v &#39;^PÃ²stanowienia RadzÃ«znÃ« KaszÃ«bsczÃ©gÃ² JÃ£zÃ«ka&#39;|grep -v &#39;^$&#39;|grep -v &#39;^2[1-9]$&#39; &gt; ZKP_biuletynRJK_2015_internet_wl2.txt . !pdftotext -nopgbrk -f 24 -l 29 ZKP_biuletynRJK_2015_internet.pdf - | grep -v &#39;BIUÂ­L EÂ­T IN RADZÃ‹ZNÃ‹ KASZÃ‹BSCZÃ‰GÃ’ JÃƒZÃ‹KA 2015&#39;|grep -v &#39;^PÃ²stanowienia RadzÃ«znÃ« KaszÃ«bsczÃ©gÃ² JÃ£zÃ«ka&#39;|grep -v &#39;^$&#39;|grep -v &#39;^2[1-9]$&#39; &gt; ZKP_biuletynRJK_2015_internet_wl3.txt . !pdftotext -nopgbrk -f 30 -l 48 ZKP_biuletynRJK_2015_internet.pdf - | grep -v &#39;BIUÂ­L EÂ­T IN RADZÃ‹ZNÃ‹ KASZÃ‹BSCZÃ‰GÃ’ JÃƒZÃ‹KA 2015&#39;|grep -v &#39;^PÃ²stanowienia RadzÃ«znÃ« KaszÃ«bsczÃ©gÃ² JÃ£zÃ«ka&#39;|grep -v &#39;^$&#39;|grep -v &#39;^[34][0-9]$&#39; &gt; ZKP_biuletynRJK_2015_internet_wl4.txt . !pdftotext -nopgbrk -f 49 -l 49 ZKP_biuletynRJK_2015_internet.pdf - | grep -v &#39;BIUÂ­L EÂ­T IN RADZÃ‹ZNÃ‹ KASZÃ‹BSCZÃ‰GÃ’ JÃƒZÃ‹KA 2015&#39;|grep -v &#39;^PÃ²stanowienia RadzÃ«znÃ« KaszÃ«bsczÃ©gÃ² JÃ£zÃ«ka&#39;|grep -v &#39;^$&#39;|grep -v &#39;^[34][0-9]$&#39; &gt; ZKP_biuletynRJK_2015_internet_wl5.txt . !pdftotext -nopgbrk -f 50 -l 65 ZKP_biuletynRJK_2015_internet.pdf - | grep -v &#39;BIUÂ­L EÂ­T IN RADZÃ‹ZNÃ‹ KASZÃ‹BSCZÃ‰GÃ’ JÃƒZÃ‹KA 2015&#39;|grep -v &#39;^PÃ²stanowienia RadzÃ«znÃ« KaszÃ«bsczÃ©gÃ² JÃ£zÃ«ka&#39;|grep -v &#39;^$&#39;|grep -v &#39;^[56][0-9]$&#39; &gt; ZKP_biuletynRJK_2015_internet_wl6.txt . def runner(file, start, end, suffix): base = file.replace(&#39;.pdf&#39;, &#39;&#39;) outfile = f&quot;{base}_{suffix}.txt&quot; !pdftotext -nopgbrk -f {start} -l {end} {file} - | grep -v &#39;BIUÂ­L EÂ­T IN RADZÃ‹ZNÃ‹ KASZÃ‹BSCZÃ‰GÃ’ JÃƒZÃ‹KA 2015&#39;|grep -v &#39;BIUÂ­L EÂ­T YN RADY JÄ˜ZYKA KASZUBSKIEGO 2015&#39;|grep -v &#39;^PÃ²stanowienia RadzÃ«znÃ« KaszÃ«bsczÃ©gÃ² JÃ£zÃ«ka&#39;|grep -v &#39;^$&#39;|grep -v &#39;^[0-9][0-9]$&#39;|grep -v &#39;^[1-4][0-9][0-9]$&#39; &gt; {outfile} . runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 68, 74, &#39;wl7&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 75, 77, &#39;wl8&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 78, 83, &#39;wl9&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 84, 102, &#39;wl10&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 103, 103, &#39;wl11&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 104, 119, &#39;wl12&#39;) . runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 122, 128, &#39;csb2&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 129, 132, &#39;csb3&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 133, 144, &#39;csb4&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 145, 151, &#39;csb5&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 153, 161, &#39;csb6&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 162, 166, &#39;csb7&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 168, 178, &#39;csb8&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 179, 185, &#39;csb9&#39;) # it took me this long to remember that there&#39;s a table of contents! runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 186, 197, &#39;csb10&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 198, 204, &#39;csb11&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 205, 211, &#39;csb12&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 212, 220, &#39;csb13&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 222, 228, &#39;pl2&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 229, 237, &#39;plx1&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 238, 241, &#39;pl3&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 242, 248, &#39;plx2&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 249, 254, &#39;plx3&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 255, 266, &#39;pl4&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 267, 274, &#39;pl5&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 275, 283, &#39;pl6&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 284, 289, &#39;pl7&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 290, 300, &#39;plx4&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 301, 313, &#39;pl8&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 314, 320, &#39;pl9&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 5, 8, &#39;toc&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 321, 333, &#39;pl10&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 334, 359, &#39;plx5&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 360, 367, &#39;pl11&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 368, 374, &#39;pl12&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 375, 390, &#39;plx6&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 391, 396, &#39;plx7&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 397, 404, &#39;pl13&#39;) . Now, the rest . !for i in [0-9N]*.pdf;do pdftotext $i;done . uname=!uname -a if not &#39;LAPTOP-6PFTN7M9&#39; in uname: !rm *.pdf .",
            "url": "https://jimregan.github.io/notes/kashubian/lazyscrape/2021/04/23/najo-uczba-pdfs.html",
            "relUrl": "/kashubian/lazyscrape/2021/04/23/najo-uczba-pdfs.html",
            "date": " â€¢ Apr 23, 2021"
        }
        
    
  
    
        ,"post193": {
            "title": "Checking a Kashubian adjective-like declension",
            "content": "def _list_to_check(pos): num = [&#39;sg&#39;, &#39;pl&#39;] gen = [&#39;mp&#39;, &#39;ma&#39;, &#39;mi&#39;, &#39;f&#39;, &#39;nt&#39;] cas = [&#39;nom&#39;, &#39;gen&#39;, &#39;dat&#39;, &#39;acc&#39;, &#39;ins&#39;, &#39;loc&#39;, &#39;voc&#39;] out = [] for n in num: for g in gen: for c in cas: out.append(f&quot;{pos}.{g}.{n}.{c}&quot;) return out . len(_list_to_check(&#39;num.ord&#39;)) . 70 . dredzi = &quot;&quot;&quot; drÃ«dÅ¼i drÃ«dÅ¼i num.ord.mp|ma|mi.sg.nom|voc drÃ«gÃ´ drÃ«dÅ¼i num.ord.f.sg.nom|voc drÃ«dÅ¼Ã© drÃ«dÅ¼i num.ord.nt.sg.nom|acc|voc drÃ«gÄ… drÃ«dÅ¼i num.ord.f.sg.acc|ins drÃ«dÅ¼i drÃ«dÅ¼i num.ord.f.sg.gen|dat|loc drÃ«dÅ¼im drÃ«dÅ¼i num.ord.mp|ma|mi|nt.sg.loc|ins drÃ«dÅ¼Ã© drÃ«dÅ¼i num.ord.nt|f|mi|ma.pl.nom|acc|voc drÃ«dÅ¼ich drÃ«dÅ¼i num.ord.nt|f|mi|ma|mp.pl.gen|loc drÃ«dÅ¼ima drÃ«dÅ¼i num.ord.nt|f|mi|ma.pl.ins drÃ«dÅ¼Ã©gÃ² drÃ«dÅ¼i num.ord.nt|mi|ma|mp.sg.gen drÃ«dÅ¼Ã©gÃ² drÃ«dÅ¼i num.ord.ma|mp.sg.acc drÃ«dÅ¼Ã©mÃ¹ drÃ«dÅ¼i num.ord.nt|mi|ma|mp.sg.dat drÃ«dÅ¼i drÃ«dÅ¼i num.ord.mp.pl.nom|voc drÃ«dÅ¼ich drÃ«dÅ¼i num.ord.mp.pl.acc drÃ«dÅ¼im drÃ«dÅ¼i num.ord.nt|f|mi|ma|mp.pl.dat &quot;&quot;&quot; . def _do_expand(stack, todo): onward = [] if not &#39;.&#39; in todo: return [f&#39;{a}.{b}&#39; for a in stack for b in todo.split(&#39;|&#39;)] cur, rest = todo.split(&#39;.&#39;, 1) if stack == []: onward = cur.split(&#39;|&#39;) return _do_expand(onward, rest) else: onward = [f&#39;{a}.{b}&#39; for a in stack for b in cur.split(&#39;|&#39;)] return _do_expand(onward, rest) def expand_compressed(lines): output = [] for i in lines: form, lemma, postag = i.split(&#39; t&#39;) newtags = _do_expand([], postag) output.extend([f&quot;{form} t{lemma} t{itag}&quot; for itag in newtags]) return output . expand_compressed([l for l in dredzi.split(&#39; n&#39;) if l != &#39;&#39;]) . vals = expand_compressed([l for l in dredzi.split(&#39; n&#39;) if l != &#39;&#39;]) . tags = [a.split(&#39; t&#39;)[-1] for a in vals] . for tc in _list_to_check(&#39;num.ord&#39;): if not tc in tags: print(tc) . num.ord.mi.sg.acc num.ord.mp.pl.ins . dredzi = &quot;&quot;&quot; drÃ«dÅ¼i drÃ«dÅ¼i num.ord.mp|ma|mi.sg.nom|voc drÃ«dÅ¼i drÃ«dÅ¼i num.ord.mi.sg.acc drÃ«gÃ´ drÃ«dÅ¼i num.ord.f.sg.nom|voc drÃ«dÅ¼Ã© drÃ«dÅ¼i num.ord.nt.sg.nom|acc|voc drÃ«gÄ… drÃ«dÅ¼i num.ord.f.sg.acc|ins drÃ«dÅ¼i drÃ«dÅ¼i num.ord.f.sg.gen|dat|loc drÃ«dÅ¼im drÃ«dÅ¼i num.ord.mp|ma|mi|nt.sg.loc|ins drÃ«dÅ¼Ã© drÃ«dÅ¼i num.ord.nt|f|mi|ma.pl.nom|acc|voc drÃ«dÅ¼ich drÃ«dÅ¼i num.ord.nt|f|mi|ma|mp.pl.gen|loc drÃ«dÅ¼ima drÃ«dÅ¼i num.ord.nt|f|mi|ma|mp.pl.ins drÃ«dÅ¼Ã©gÃ² drÃ«dÅ¼i num.ord.nt|mi|ma|mp.sg.gen drÃ«dÅ¼Ã©gÃ² drÃ«dÅ¼i num.ord.ma|mp.sg.acc drÃ«dÅ¼Ã©mÃ¹ drÃ«dÅ¼i num.ord.nt|mi|ma|mp.sg.dat drÃ«dÅ¼i drÃ«dÅ¼i num.ord.mp.pl.nom|voc drÃ«dÅ¼ich drÃ«dÅ¼i num.ord.mp.pl.acc drÃ«dÅ¼im drÃ«dÅ¼i num.ord.nt|f|mi|ma|mp.pl.dat &quot;&quot;&quot; .",
            "url": "https://jimregan.github.io/notes/kashubian/declension/2021/04/23/check-kashubian-adjlike.html",
            "relUrl": "/kashubian/declension/2021/04/23/check-kashubian-adjlike.html",
            "date": " â€¢ Apr 23, 2021"
        }
        
    
  
    
        ,"post194": {
            "title": "Title",
            "content": "&gt; &quot;Train a model for MFA on Irish data on Kaggle&quot; - toc: false - branch: master - hidden: true - categories: [kaggle, irish, mfa] . Original on [Kaggle](https://www.kaggle.com/jimregan/train-irish-mfa-model) . %%capture import os os.chdir(&#39;/tmp&#39;) !wget https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/releases/download/v1.0.1/montreal-forced-aligner_linux.tar.gz !tar zxvf montreal-forced-aligner_linux.tar.gz !ln -s /tmp/montreal-forced-aligner/lib/libpython3.6m.so.1.0 /tmp/montreal-forced-aligner/lib/libpython3.6m.so . os.chdir(&#39;/kaggle/working&#39;) os.environ[&#39;LD_LIBRARY_PATH&#39;] = f&#39;{os.environ[&quot;LD_LIBRARY_PATH&quot;]}:/tmp/montreal-forced-aligner/lib/&#39; os.environ[&#39;PATH&#39;] = f&#39;{os.environ[&quot;PATH&quot;]}:/tmp/montreal-forced-aligner/bin/&#39; . %%capture !yes|apt install libgfortran3 . !mkdir /tmp/mfa-temp . import json datapath = &#39;../input/living-audio-irish-speech-corpus/living-audio.json&#39; with open(datapath) as jsonf: data = json.load(jsonf) . !mkdir /tmp/living-audio . lexicon_words = set() with open(&#39;../input/living-audio-irish-speech-corpus/lexicon.txt&#39;) as lexicon_file: for line in lexicon_file.readlines(): words = line.split(&#39; &#39;) lexicon_words.add(words[0]) . import shutil missing_words = set() for utt in data: shutil.copyfile(utt[&#39;path&#39;], f&quot;/tmp/living-audio/{utt[&#39;id&#39;]}.wav&quot;) with open(f&quot;/tmp/living-audio/{utt[&#39;id&#39;]}.txt&quot;, &#39;w&#39;) as text: sentence = utt[&#39;sentence&#39;] sentence = sentence.replace(&#39;(&#39;, &#39;&#39;).replace(&#39;)&#39;, &#39;&#39;) words = [] for word in sentence.split(&#39; &#39;): if not word in lexicon_words: missing_words.add(word) if &#39;-&#39; in word: if word.startswith(&#39;n-&#39;) or word.startswith(&#39;t-&#39;): workword = word[2:] workword.replace(&#39;-&#39;, &#39; &#39;) word = word[0:2] + workword else: word = word.replace(&#39;-&#39;, &#39; &#39;) words.append(word) text.write(&#39; &#39;.join(words)) . !mfa_train_and_align -t /tmp/mfa-temp -o ./irish-model /tmp/living-audio ../input/living-audio-irish-speech-corpus/lexicon.txt ./textgrid . Setting up corpus information... Creating dictionary information... Setting up training data... Calculating MFCCs... Calculating CMVN... Number of speakers in corpus: 1, average number of utterances per speaker: 1121.0 b&#39;number of phones 215 nnumber of pdfs 165 nnumber of transition-ids 1470 nnumber of transition-states 675 nfeature dimension 39 nnumber of gaussians 165 n&#39; None b&#39;number of phones 215 nnumber of pdfs 165 nnumber of transition-ids 1470 nnumber of transition-states 675 nfeature dimension 39 nnumber of gaussians 165 n&#39; None Beginning monophone training... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 39/39 [25:35&lt;00:00, 21.13s/it] Initializing triphone training... Beginning triphone training... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [19:09&lt;00:00, 16.35s/it] Initializing speaker-adapted triphone training... Beginning speaker-adapted triphone training... 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 34/34 [08:55&lt;00:00, 8.33s/it] Saved model to ./irish-model .",
            "url": "https://jimregan.github.io/notes/2021/04/22/train-irish-mfa-model.html",
            "relUrl": "/2021/04/22/train-irish-mfa-model.html",
            "date": " â€¢ Apr 22, 2021"
        }
        
    
  
    
        ,"post195": {
            "title": "Kashubian - extract text from tlog",
            "content": "import json with open(&quot;/tmp/csb/kashubian-data.json&quot;, &quot;r&quot;) as read_file: data = json.load(read_file) . for datum in data: file = datum[&#39;audio&#39;].split(&#39;/&#39;)[-1].replace(&#39;.ogg&#39;, &#39;.txt&#39;) with open(f&#39;/tmp/csb/{file}&#39;, &#39;w&#39;) as f: text = &#39; n&#39;.join([a.strip() for a in datum[&#39;text&#39;].split(&#39; n&#39;) if a.strip() != &#39;&#39;]) f.write(text) . import glob for file in glob.glob(&#39;/tmp/csb/*.ogg.wav.tlog&#39;): outfile = file.replace(&#39;.ogg.wav.tlog&#39;, &#39;.rec.txt&#39;) with open(file, &quot;r&quot;) as tlog: data = json.load(tlog) with open(outfile, &quot;w&quot;) as rectxt: for datum in data: rectxt.write(f&quot;{datum[&#39;transcript&#39;]} n&quot;) .",
            "url": "https://jimregan.github.io/notes/asr/kashubian/2021/04/22/kashubian-extract-text-from-tlog.html",
            "relUrl": "/asr/kashubian/2021/04/22/kashubian-extract-text-from-tlog.html",
            "date": " â€¢ Apr 22, 2021"
        }
        
    
  
    
        ,"post196": {
            "title": "Training MFA G2P on fuaimeanna.ie",
            "content": "Original on Kaggle . %%capture import os os.chdir(&#39;/tmp&#39;) !wget https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/releases/download/v1.0.1/montreal-forced-aligner_linux.tar.gz !tar zxvf montreal-forced-aligner_linux.tar.gz !ln -s /tmp/montreal-forced-aligner/lib/libpython3.6m.so.1.0 /tmp/montreal-forced-aligner/lib/libpython3.6m.so . os.chdir(&#39;/kaggle/working&#39;) os.environ[&#39;LD_LIBRARY_PATH&#39;] = f&#39;{os.environ[&quot;LD_LIBRARY_PATH&quot;]}:/tmp/montreal-forced-aligner/lib/&#39; . os.environ[&#39;PATH&#39;] = f&#39;{os.environ[&quot;PATH&quot;]}:/tmp/montreal-forced-aligner/bin/&#39; . !mkdir /tmp/mfa-temp . !mfa_train_g2p -t /tmp/mfa-temp ../input/living-audio-irish-speech-corpus/lexicon.txt ./g2p-model . GitRevision: kaldi-6-g64719c Loading input file: /tmp/mfa-temp/g2p-model/input.txt Starting EM... Finished first iter... Iteration: 1 Change: 3.18428 Iteration: 2 Change: 0.068243 Iteration: 3 Change: 0.0359888 Iteration: 4 Change: 0.00983238 Iteration: 5 Change: 0.00348759 Iteration: 6 Change: 0.00150681 Iteration: 7 Change: 0.00084877 Iteration: 8 Change: 0.000713348 Iteration: 9 Change: 0.000318527 Iteration: 10 Change: 0.000238419 Iteration: 11 Change: 0.000259399 Last iteration: GitRevision: kaldi-6-g64719c Initializing... Converting... Saved model to ./g2p-model .",
            "url": "https://jimregan.github.io/notes/kaggle/mfa/fuaimeanna/2021/04/21/train-irish-g2p-model-with-mfa.html",
            "relUrl": "/kaggle/mfa/fuaimeanna/2021/04/21/train-irish-g2p-model-with-mfa.html",
            "date": " â€¢ Apr 21, 2021"
        }
        
    
  
    
        ,"post197": {
            "title": "Installing montreal-forced-aligner on kaggle",
            "content": "%%capture !wget https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/releases/download/v1.0.1/montreal-forced-aligner_linux.tar.gz . %%capture !tar zxvf montreal-forced-aligner_linux.tar.gz !rm montreal-forced-aligner_linux.tar.gz . !mv montreal-forced-aligner/bin montreal-forced-aligner/bb . !ln -s montreal-forced-aligner/lib/libpython3.6m.so.1.0 montreal-forced-aligner/lib/libpython3.6m.so .",
            "url": "https://jimregan.github.io/notes/kaggle/itworks/2021/04/20/mfa-on-kaggle.html",
            "relUrl": "/kaggle/itworks/2021/04/20/mfa-on-kaggle.html",
            "date": " â€¢ Apr 20, 2021"
        }
        
    
  
    
        ,"post198": {
            "title": "Title",
            "content": "&gt; &quot;[Incomplete]&quot; - toc: false - branch: master - hidden: true - categories: [irish, g2p, icu, incomplete] . import icu . def transliterator_from_rules(name, rules): fromrules = icu.Transliterator.createFromRules(name, rules) icu.Transliterator.registerInstance(fromrules) return icu.Transliterator.createInstance(name) . irishlc_rules = &quot;&quot;&quot; :: NFD; $uvowel=[AEIOU]; $wb=[^[:L:][:M:]]; $wb { ([nt]) } $uvowel â†’ $1 &#39;-&#39;; :: lower; :: NFC; &quot;&quot;&quot; . irishlc = transliterator_from_rules(&#39;irishlc&#39;, irishlc_rules) . ulster_stress_rules = &quot;&quot;&quot; $wb=[^[:L:][:M:]]; $cons = [bcdfghjklmnpqrstvwxyz]; $vowel = [aeiouÃ¡Ã©Ã­Ã³Ãº]; $bvowel = [aouÃ¡Ã³Ãº{ae}]; $svowel = [eiÃ©Ã­]; :: irishlc; $wb { anois } $wb â†’ an&#39;Ëˆ&#39;ois; $wb { arÃ­s } $wb â†’ air&#39;Ëˆ&#39;Ã­s; $wb { isteach } $wb â†’ ist&#39;Ëˆ&#39;each; $wb { istigh } $wb â†’ ist&#39;Ëˆ&#39;igh; $wb { amach } $wb â†’ am&#39;Ëˆ&#39;ach; $wb $cons* { ($vowel) â†’ &#39;Ëˆ&#39;$1; &quot;&quot;&quot; . stress = transliterator_from_rules(&#39;ulster_stress&#39;, ulster_stress_rules) . stress.transliterate(&quot;amach&quot;) . &#39;amËˆach&#39; . ulster_g2p_rules = &quot;&quot;&quot; $wb=[^[:L:][:M:]]; $cons = [bcdfghjklmnpqrstvwxyz]; # when we transliterate past the first consonant, # we need to use the transliteration as context $scons = [{bÊ²}cÃ§{dÊ²}{fÊ²}ÉŸ{mÊ²}{É´Ê²}Êƒ{tÊ²}{vÊ²}{GJ}{DJ}{BJ}{MJ}]; $bcons = [{bË }{kË }x{dË }{fË }{gË }{mË }{É´Ë }{sË }{tË }w{GH}{DH}{BH}{MH}]; $vowel = [aeiouÃ¡Ã©Ã­Ã³Ãº]; $bvowel = [aouÃ¡Ã³Ãº{ae}]; $svowel = [eiÃ©Ã­]; $apos = [â€™ &#39;]; $bfce = [{Ã¡}{adh}{aidh}{aidÃ­s}{aimid}{aimis}{ainn}{as}]; $sfce = [{eÃ¡}{eadh}{idh}{idÃ­s}{imid}{imis}{inn}]; $ps = &#39;Ëˆ&#39;; :: irishlc; :: ulster_stress; $wb { mb $apos? } $cons* Ëˆ? $bvowel â†’ mË ; $wb { mb $apos? } $cons* Ëˆ? $svowel â†’ mÊ²; #$bvowel $bcons* { bh â†’ w; #bh } $cons* Ëˆ? $bvowel â†’ w; #$svowel $scons* { bh â†’ vÊ²; #bh } $cons* Ëˆ? $svowel â†’ vÊ²; $bvowel $bcons* { bh â†’ BH; bh } $cons* Ëˆ? $bvowel â†’ BH; $svowel $scons* { bh â†’ BJ; bh } $cons* Ëˆ? $svowel â†’ BJ; bf } $bfce $wb â†’ pË ; bf } $sfce $wb â†’ pÊ²; $bvowel $bcons* { b â†’ bË ; b } $cons* Ëˆ? $bvowel â†’ bË ; $svowel $scons* { b â†’ bÊ²; b } $cons* Ëˆ? $svowel â†’ bÊ²; # gKim/Khim are things that happen too $wb { gc } $cons* Ëˆ? $bvowel â†’ gË ; $wb { gc } $cons* Ëˆ? $svowel â†’ ÉŸ; $bvowel $bcons* { ch â†’ x; ch } $cons* Ëˆ? $bvowel â†’ x; $svowel $scons* { ch â†’ Ã§; ch } $cons* Ëˆ? $svowel â†’ Ã§; $bvowel $bcons* { [ck] â†’ kË ; [ck] } $cons* Ëˆ? $bvowel â†’ kË ; $svowel $scons* { [ck] â†’ c; [ck] } $cons* Ëˆ? $svowel â†’ c; $wb { nd } $cons* Ëˆ? $bvowel â†’ É´Ë ; $wb { nd } $cons* Ëˆ? $svowel â†’ É´Ê²; $wb { dh $apos? } $cons* Ëˆ? $bvowel â†’ É£; $wb { dh $apos? } $cons* Ëˆ? $svowel â†’ j; # can&#39;t do this here, because the next pass does diphthongs #$bvowel $bcons* { dh â†’ É£; #dh } $cons* Ëˆ? $bvowel â†’ É£; #$svowel $scons* { dh â†’ j; #dh } $cons* Ëˆ? $svowel â†’ j; $bvowel $bcons* { dh â†’ DH; dh } $cons* Ëˆ? $bvowel â†’ DH; $svowel $scons* { dh â†’ DJ; dh } $cons* Ëˆ? $svowel â†’ DJ; $wb { d $apos? } $cons* Ëˆ? $bvowel â†’ dË ; $wb { d $apos? } $cons* Ëˆ? $svowel â†’ dÊ²; $bvowel $bcons* { d â†’ dË ; d } $cons* Ëˆ? $bvowel â†’ dË ; $svowel $scons* { d â†’ dÊ²; d } $cons* Ëˆ? $svowel â†’ dÊ²; j â†’ dÊ² ; $wb { bhf } $cons* Ëˆ? $bvowel â†’ w; $wb { bhf } $cons* Ëˆ? $svowel â†’ vÊ²; fh â†’ ; $bvowel $bcons* { f â†’ fË ; f } $cons* Ëˆ? $bvowel â†’ fË ; $svowel $scons* { f â†’ fÊ²; f } $cons* Ëˆ? $svowel â†’ fÊ²; # can&#39;t do this here, because the next pass does diphthongs #$bvowel $bcons* { gh â†’ É£; #gh } $cons* Ëˆ? $bvowel â†’ É£; #$svowel $scons* { gh â†’ j; #gh } $cons* Ëˆ? $svowel â†’ j; $bvowel $bcons* { gh â†’ GH; gh } $cons* Ëˆ? $bvowel â†’ GH; $svowel $scons* { gh â†’ GJ; gh } $cons* Ëˆ? $svowel â†’ GJ; $bvowel $bcons* { g â†’ gË ; g } $cons* Ëˆ? $bvowel â†’ gË ; $svowel $scons* { g â†’ ÉŸ; g } $cons* Ëˆ? $svowel â†’ ÉŸ; $wb { l } Ëˆ? $svowel â†’ ÊŸÊ²; $bvowel $bcons* { ll â†’ ÊŸË ; ll } $cons* Ëˆ? $bvowel â†’ ÊŸË ; $svowel $scons* { ll â†’ ÊŸÊ²; ll } $cons* Ëˆ? $svowel â†’ ÊŸÊ²; $bvowel $bcons* { l â†’ ÊŸË ; l } $cons* Ëˆ? $bvowel â†’ ÊŸË ; $svowel $scons* { l â†’ lÊ²; l } $cons* Ëˆ? $svowel â†’ lÊ²; #$bvowel $bcons* { mh â†’ w; #mh } $cons* Ëˆ? $bvowel â†’ w; #$svowel $scons* { mh â†’ vÊ²; #mh } $cons* Ëˆ? $svowel â†’ vÊ²; $bvowel $bcons* { mh â†’ MH; mh } $cons* Ëˆ? $bvowel â†’ MH; $svowel $scons* { mh â†’ MJ; mh } $cons* Ëˆ? $svowel â†’ MJ; $wb { m $apos? } $cons* Ëˆ? $bvowel â†’ mË ; $wb { m $apos? } $cons* Ëˆ? $svowel â†’ mÊ²; $bvowel $bcons* { m â†’ mË ; m } $cons* Ëˆ? $bvowel â†’ mË ; $svowel $scons* { m â†’ mÊ²; m } $cons* Ëˆ? $svowel â†’ mÊ²; $wb { bp } $cons* Ëˆ? $bvowel â†’ bË ; $wb { bp } $cons* Ëˆ? $svowel â†’ bÊ²; $bvowel $bcons* { ph â†’ fË ; ph } $cons* Ëˆ? $bvowel â†’ fË ; $svowel $scons* { ph â†’ fÊ²; ph } $cons* Ëˆ? $svowel â†’ fÊ²; $bvowel $bcons* { p â†’ pË ; p } $cons* Ëˆ? $bvowel â†’ pË ; $svowel $scons* { p â†’ pÊ²; p } $cons* Ëˆ? $svowel â†’ pÊ²; $wb { r â†’ É¾Ë ; [st]hr } Ëˆ? $bvowel â†’ rÌªË  ; [st]hr } Ëˆ? $svowel â†’ rÌªÊ² ; $bvowel $cons* { [st]hr â†’ rÌªË ; [st]hr } Ëˆ? $bvowel â†’ rÌªË  ; $svowel $cons* { [st]hr â†’ rÌªÊ²; [st]hr } Ëˆ? $svowel â†’ rÌªÊ² ; $wb { sh } Ëˆ? [{eÃ¡}{eÃ¡i}{eoi}{eo}{iÃºi}{iÃº}] â†’ Ã§ ; [st]h â†’ h ; h â†’ h ; $bvowel $cons* { s â†’ sË ; s } $cons* Ëˆ? $bvowel â†’ sË ; $svowel $cons* { s â†’ Êƒ; s } $cons* Ëˆ? $svowel â†’ Êƒ; $bvowel $bcons* { t â†’ tË ; t } $cons* Ëˆ? $bvowel â†’ tË ; $svowel $scons* { t â†’ tÊ²; t } $cons* Ëˆ? $svowel â†’ tÊ²; # &#39;oi&#39; can represent either: # * &#39;o&#39; before a slender consonant # * &#39;i&#39; after a broad consonant # &#39;goitse&#39; can be either, I think, but abair says /i/ ([Éª]) (I&#39;ve only ever heard /o/ ([ÊŒ])) $wb g $ps { oi } tse $wb â†’ i ; $wb an $ps { oi } s $wb â†’ i ; :: null; e?a DH ai? â†’ eË; $ps { e?a DH â†’ eË; e?a DH â†’ uË; $ps { oi [DG]J â†’ ai; $ps { [ae]i DJ â†’ eË; $ps { a?i GJ â†’ ai; oi [DG]J â†’ É™; ai [DG]J â†’ iË; ei DJ â†’ É™; i DJ â†’ iË; i GJ â†’ É™; o MH } $wb â†’ uË; o MH â†’ oË; $ps { o BH ai? â†’ au; $ps { o [DG]H a? â†’ au; o GH a? â†’ É™; o BH a i? â†’ É™; o DH a â†’ É™; o DH â†’ uË; $ps { ea [MB]H ai â†’ au ; $ps { ea [MB]H a â†’ au ; $ps { ea [MB]H â†’ au ; $ps { a [MB]H ai â†’ au ; $ps { a [MB]H a â†’ au ; $ps { a [MB]H â†’ au ; ea [MB]H ai â†’ É™ ; ea [MB]H a â†’ É™ ; ea [MB]H â†’ uË ; a [MB]H ai â†’ É™ ; a [MB]H a â†’ É™ ; a [MB]H â†’ É™ ; $ps { ei GH ea â†’ eË; # it seems like abair ought to have this rule, but doesn&#39;t #a GH ai â†’ eË; # instead this happens (agha + i separately) a GH ai â†’ eËÉ™; a GH a â†’ eË; $ps { a GH â†’ eË; ei GH ea â†’ É™; a GH â†’ É™; $ps { eÃ¡i â†’ aË; $ps { eÃ¡ â†’ aË; $ps { Ã¡i â†’ aË; $ps { Ã¡ â†’ aË; $ps { aei â†’ eË; $ps { ae â†’ eË; $ps { Ã©i â†’ eË; $ps { Ã© â†’ eË; $ps { uÃ­o â†’ iË; $ps { aÃ­o â†’ iË; $ps { aÃ­ â†’ iË; $ps { uÃ­ â†’ iË; $ps { oÃ­ â†’ iË; $ps { Ã­o â†’ iË; $ps { aoi â†’ iË; $ps { ao â†’ iË; $ps { Ã­ â†’ iË; $ps { eoi â†’ oË; $ps { eÃ³ â†’ oË; $ps { eo â†’ oË; $ps { iÃ³ â†’ oË; $ps { Ã³i â†’ oË; $ps { Ã³ â†’ oË; eÃ¡i â†’ a; eÃ¡ â†’ a; Ã¡i â†’ a; Ã¡ â†’ a; aei â†’ e; ae â†’ e; Ã©i â†’ e; Ã© â†’ e; uÃ­o â†’ iÉ™; aÃ­o â†’ iÉ™; aÃ­ â†’ i; uÃ­ â†’ i; oÃ­ â†’ i; Ã­o â†’ iÉ™; aoi â†’ i; ao â†’ i; Ã­ â†’ i; eoi â†’ É”; eÃ³ â†’ É”; eo â†’ É”; iÃ³ â†’ É”; Ã³i â†’ É”; Ã³ â†’ É”; $ps { iÃºi â†’ uË; $ps { Ãºai â†’ uË; $ps { iÃº â†’ uË; iÃº } $wb â†’ uË; $ps { Ãºi â†’ uË; $ps { Ãº â†’ uË; Ãº } $wb â†’ uË; iÃºi â†’ u; Ãºai â†’ u; iÃº â†’ u; Ãºi â†’ u; Ãº â†’ u; $ps { eai â†’ a ; $ps { ea â†’ a ; $ps { ai â†’ a ; $ps { a â†’ a ; $ps { ei â†’ e ; $ps { ue â†’ e ; $ps { e â†’ e ; eai â†’ É™ ; ea â†’ É™ ; ai â†’ É™ ; a â†’ É™ ; ei â†’ É™ ; ue â†’ É™ ; e â†’ É™ ; $ps { oi â†’ o ; $ps { ui â†’ i ; $ps { iu â†’ u ; $ps { u â†’ u ; $ps { io â†’ i ; $ps { i â†’ i ; $wb $ps? { o } [r{É¾Ë }] â†’ oË ; $ps { o â†’ o ; oi â†’ É™ ; ui â†’ É™ ; iu â†’ É™ ; io â†’ É™ ; u â†’ É™ ; i â†’ É™ ; o â†’ É™ ; DH â†’ É£; DJ â†’ j; GH â†’ É£; GJ â†’ j; BH â†’ w; BJ â†’ v; MH â†’ w; MJ â†’ v; $ps â†’ $ps; &quot;&quot;&quot; . ulster_g2p = transliterator_from_rules(&#39;ulster_g2p&#39;, ulster_g2p_rules) . ulster_g2p.transliterate(&quot;scuaibfeÃ¡&quot;) . &#39;sË kË ËˆuÉ™pÊ²a&#39; .",
            "url": "https://jimregan.github.io/notes/2021/04/19/ulster_g2p.html",
            "relUrl": "/2021/04/19/ulster_g2p.html",
            "date": " â€¢ Apr 19, 2021"
        }
        
    
  
    
        ,"post199": {
            "title": "Irish lowercase with ICU",
            "content": "import icu . def transliterator_from_rules(name, rules): fromrules = icu.Transliterator.createFromRules(name, rules) icu.Transliterator.registerInstance(fromrules) return icu.Transliterator.createInstance(name) . irishlc_rules = &quot;&quot;&quot; :: NFD; $uvowel=[AEIOU]; $wb=[^[:L:][:M:]]; $wb { ([nt]) } $uvowel â†’ $1 &#39;-&#39;; :: lower; :: NFC; &quot;&quot;&quot; . irishlc = transliterator_from_rules(&#39;irishlc&#39;, irishlc_rules) . irishlc.transliterate(&quot;tÃ¡ an tUachtarÃ¡n tar Ã©is a lÃ¡mh a chur leis&quot;) . &#39;tÃ¡ an t-uachtarÃ¡n tar Ã©is a lÃ¡mh a chur leis&#39; .",
            "url": "https://jimregan.github.io/notes/icu/2021/04/18/irish-lower-with-icu.html",
            "relUrl": "/icu/2021/04/18/irish-lower-with-icu.html",
            "date": " â€¢ Apr 18, 2021"
        }
        
    
  
    
        ,"post200": {
            "title": "Clarin-Studio dataset",
            "content": "The datasets are on the hub: jimregan/clarinpl_studio and jimregan/clarinpl_sejmsenat . !wget http://mowa.clarin-pl.eu/korpusy/audio.tar.gz . !tar zxvf audio.tar.gz . !cat /content/audio/SES0001/spk.txt . SPK0001 . !cat /content/audio/SES0001/sent030.txt . gdy maluch juÅ¼ siÄ™ wypluska wytrzyjcie go dokÅ‚adnie rÄ™cznikiem posmarujcie jeszcze raz kremem przeciwsÅ‚onecznym i ubierzcie w suche u branie . !head /content/SejmSenat/test/wav.scp.orig . !head /content/SejmSenat/test/spk2utt . !head /content/SejmSenat/train/text . !huggingface-cli login . !huggingface-cli repo create clarinpl_studio --type dataset . !rm -rf clarinpl_studio !git clone https://huggingface.co/datasets/jimregan/clarinpl_studio . Cloning into &#39;clarinpl_studio&#39;... remote: Enumerating objects: 6, done. remote: Counting objects: 100% (6/6), done. remote: Compressing objects: 100% (5/5), done. remote: Total 6 (delta 0), reused 0 (delta 0) Unpacking objects: 100% (6/6), done. . !datasets-cli test clarinpl_studio --save_infos --all_configs . Testing builder &#39;clean&#39; (1/1) Downloading and preparing dataset clarin_pl_studio/clean (download: 4.59 GiB, generated: 4.50 MiB, post-processed: Unknown size, total: 4.60 GiB) to /root/.cache/huggingface/datasets/clarin_pl_studio/clean/2.1.0/733df40ff099ad45628c8c755782c0abb5554817218890a3d232ed359122252c... 0 examples [00:00, ? examples/s]2021-04-15 10:43:00.739700: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0 Dataset clarin_pl_studio downloaded and prepared to /root/.cache/huggingface/datasets/clarin_pl_studio/clean/2.1.0/733df40ff099ad45628c8c755782c0abb5554817218890a3d232ed359122252c. Subsequent calls will reuse this data. 100% 3/3 [00:00&lt;00:00, 176.78it/s] Dataset Infos file saved at clarinpl_studio/dataset_infos.json Test successful. . # coding=utf-8 # Copyright 2021 The TensorFlow Datasets Authors and the HuggingFace Datasets Authors. # Copyright 2021 Jim O&#39;Regan # # Licensed under the Apache License, Version 2.0 (the &quot;License&quot;); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an &quot;AS IS&quot; BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # Lint as: python3 &quot;&quot;&quot;ClarinPL Studio automatic speech recognition dataset.&quot;&quot;&quot; import os import datasets _CITATION = &quot;&quot;&quot; @article{korvzinek2017polish, title={Polish read speech corpus for speech tools and services}, author={Kor{ v{z}}inek, Danijel and Marasek, Krzysztof and Brocki, { L}ukasz and Wo{ l}k, Krzysztof}, journal={arXiv preprint arXiv:1706.00245}, year={2017} } &quot;&quot;&quot; _DESCRIPTION = &quot;&quot;&quot; The corpus consists of 317 speakers recorded in 554 sessions, where each session consists of 20 read sentences and 10 phonetically rich words. The size of the audio portion of the corpus amounts to around 56 hours, with transcriptions containing 356674 words from a vocabulary of size 46361. Note that in order to limit the required storage for preparing this dataset, the audio is stored in the .wav format and is not converted to a float32 array. To convert the audio file to a float32 array, please make use of the `.map()` function as follows: python import soundfile as sf def map_to_array(batch): speech_array, _ = sf.read(batch[&quot;file&quot;]) batch[&quot;speech&quot;] = speech_array return batch dataset = dataset.map(map_to_array, remove_columns=[&quot;file&quot;]) &quot;&quot;&quot; _URL = &quot;https://mowa.clarin-pl.eu/&quot; _DS_URL = &quot;http://mowa.clarin-pl.eu/korpusy/audio.tar.gz&quot; _TRAIN_URL = &quot;https://raw.githubusercontent.com/danijel3/ClarinStudioKaldi/master/local_clarin/train.sessions&quot; _TEST_URL = &quot;https://raw.githubusercontent.com/danijel3/ClarinStudioKaldi/master/local_clarin/test.sessions&quot; _VALID_URL = &quot;https://raw.githubusercontent.com/danijel3/ClarinStudioKaldi/master/local_clarin/dev.sessions&quot; class ClarinPLStudioASRConfig(datasets.BuilderConfig): &quot;&quot;&quot;BuilderConfig for ClarinPLStudioASR.&quot;&quot;&quot; def __init__(self, **kwargs): &quot;&quot;&quot; Args: data_dir: `string`, the path to the folder containing the files in the downloaded .tar citation: `string`, citation for the data set url: `string`, url for information about the data set **kwargs: keyword arguments forwarded to super. &quot;&quot;&quot; super(ClarinPLStudioASRConfig, self).__init__(version=datasets.Version(&quot;2.1.0&quot;, &quot;&quot;), **kwargs) class ClarinPLStudio(datasets.GeneratorBasedBuilder): &quot;&quot;&quot;ClarinPL Studio dataset.&quot;&quot;&quot; BUILDER_CONFIGS = [ ClarinPLStudioASRConfig(name=&quot;clean&quot;, description=&quot;&#39;Clean&#39; speech.&quot;), ] def _info(self): return datasets.DatasetInfo( description=_DESCRIPTION, features=datasets.Features( { &quot;file&quot;: datasets.Value(&quot;string&quot;), &quot;text&quot;: datasets.Value(&quot;string&quot;), &quot;speaker_id&quot;: datasets.Value(&quot;string&quot;), &quot;id&quot;: datasets.Value(&quot;string&quot;), } ), supervised_keys=(&quot;file&quot;, &quot;text&quot;), homepage=_URL, citation=_CITATION, ) def _split_generators(self, dl_manager): def get_sessions(path): sessions = [] with open(path, &#39;r&#39;) as f: for line in f: sessions.append(line.strip()) return sessions archive_path = dl_manager.download_and_extract(_DS_URL) train_sessions_path = dl_manager.download(_TRAIN_URL) test_sessions_path = dl_manager.download(_TEST_URL) valid_sessions_path = dl_manager.download(_VALID_URL) train_sessions = get_sessions(train_sessions_path) test_sessions = get_sessions(test_sessions_path) valid_sessions = get_sessions(valid_sessions_path) archive_path = os.path.join(archive_path, &quot;audio&quot;) return [ datasets.SplitGenerator(name=&quot;train&quot;, gen_kwargs={ &quot;archive_path&quot;: archive_path, &quot;sessions&quot;: train_sessions }), datasets.SplitGenerator(name=&quot;test&quot;, gen_kwargs={ &quot;archive_path&quot;: archive_path, &quot;sessions&quot;: test_sessions }), datasets.SplitGenerator(name=&quot;valid&quot;, gen_kwargs={ &quot;archive_path&quot;: archive_path, &quot;sessions&quot;: valid_sessions }), ] def _generate_examples(self, archive_path, sessions): &quot;&quot;&quot;Generate examples from a ClarinPL Studio archive_path.&quot;&quot;&quot; def get_single_line(path): lines = [] with open(path, &#39;r&#39;, encoding=&quot;utf-8&quot;) as f: for line in f: line = line.strip() lines.append(line) assert(len(lines) == 1) return lines[0] for session in sessions: session_path = os.path.join(archive_path, session) speaker = get_single_line(os.path.join(session_path, &quot;spk.txt&quot;)) text_glob = os.path.join(session_path, &quot;*.txt&quot;) for text_file in sorted(glob.glob(text_glob)): if text_file.endswith(&quot;spk.txt&quot;): continue basename = os.path.basename(text_file) basename = basename.replace(&#39;.txt&#39;, &#39;&#39;) key = f&#39;{session}_{basename}&#39; text = get_single_line(text_file) audio = text_file.replace(&#39;.txt&#39;, &#39;.wav&#39;) example = { &quot;id&quot;: key, &quot;speaker_id&quot;: speaker, &quot;file&quot;: audio, &quot;text&quot;: text, } yield key, example . !pip install datasets . from datasets import load_dataset dataset = load_dataset(&#39;clarinpl_studio.py&#39;) . Downloading and preparing dataset clarin_pl_studio/clean (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/clarin_pl_studio/clean/2.1.0/733df40ff099ad45628c8c755782c0abb5554817218890a3d232ed359122252c... Dataset clarin_pl_studio downloaded and prepared to /root/.cache/huggingface/datasets/clarin_pl_studio/clean/2.1.0/733df40ff099ad45628c8c755782c0abb5554817218890a3d232ed359122252c. Subsequent calls will reuse this data. . dataset . DatasetDict({ train: Dataset({ features: [&#39;file&#39;, &#39;text&#39;, &#39;speaker_id&#39;, &#39;id&#39;], num_rows: 11222 }) test: Dataset({ features: [&#39;file&#39;, &#39;text&#39;, &#39;speaker_id&#39;, &#39;id&#39;], num_rows: 1362 }) valid: Dataset({ features: [&#39;file&#39;, &#39;text&#39;, &#39;speaker_id&#39;, &#39;id&#39;], num_rows: 1229 }) }) . import IPython IPython.display.Audio(dataset[&#39;train&#39;][&#39;file&#39;][2184]) . dataset . DatasetDict({ train: Dataset({ features: [&#39;file&#39;, &#39;text&#39;, &#39;speaker_id&#39;, &#39;id&#39;], num_rows: 6622 }) test: Dataset({ features: [&#39;file&#39;, &#39;text&#39;, &#39;speaker_id&#39;, &#39;id&#39;], num_rows: 130 }) }) . dataset[&#39;train&#39;][0] . {&#39;file&#39;: &#39;/root/.cache/huggingface/datasets/downloads/extracted/333ddc746f2df1e1d19b44986992d4cbe28710fde81d533a220e755ee6c5c519/audio/SES0001/rich001.wav&#39;, &#39;id&#39;: &#39;SES0001_rich001&#39;, &#39;speaker_id&#39;: &#39;SPK0001&#39;, &#39;text&#39;: &#39;droÅ¼dÅ¼e dÅ¼ip gwoÅ¼dÅ¼enie ozimina wÄ™dzarz rdzeÅ„ wÄ™dzonka ingerowaÄ‡ kÅ‚adzenie jutrzenka&#39;} . !wc -l /root/.cache/huggingface/datasets/downloads/extracted/4143b1d75559b10028c1c7e8800c9ccc05934ca5a8ea15f8f9a92770576a1ee3/SejmSenat/*/text . 130 /root/.cache/huggingface/datasets/downloads/extracted/4143b1d75559b10028c1c7e8800c9ccc05934ca5a8ea15f8f9a92770576a1ee3/SejmSenat/test/text 6622 /root/.cache/huggingface/datasets/downloads/extracted/4143b1d75559b10028c1c7e8800c9ccc05934ca5a8ea15f8f9a92770576a1ee3/SejmSenat/train/text 6752 total . !find /root/.cache/huggingface/datasets/downloads/extracted/4143b1d75559b10028c1c7e8800c9ccc05934ca5a8ea15f8f9a92770576a1ee3/SejmSenat/audio/ -type f|wc . 6752 6752 1159384 . !rm -rf SejmSenat/ .",
            "url": "https://jimregan.github.io/notes/clarinpl/huggingface/2021/04/14/clarin-studio-dataset.html",
            "relUrl": "/clarinpl/huggingface/2021/04/14/clarin-studio-dataset.html",
            "date": " â€¢ Apr 14, 2021"
        }
        
    
  
    
        ,"post201": {
            "title": "CC-Aligned Irish contains rubbish",
            "content": "See here. This is probably why M2M100 sucks at Irish. . !wget http://www.statmt.org/cc-aligned/en_XX-ga_IE.tsv.xz . --2021-06-05 17:38:16-- http://www.statmt.org/cc-aligned/en_XX-ga_IE.tsv.xz Resolving www.statmt.org (www.statmt.org)... 129.215.197.184 Connecting to www.statmt.org (www.statmt.org)|129.215.197.184|:80... connected. HTTP request sent, awaiting response... 200 OK Length: 150347648 (143M) [application/x-xz] Saving to: â€˜en_XX-ga_IE.tsv.xzâ€™ en_XX-ga_IE.tsv.xz 100%[===================&gt;] 143.38M 139KB/s in 20m 26s 2021-06-05 17:58:43 (120 KB/s) - â€˜en_XX-ga_IE.tsv.xzâ€™ saved [150347648/150347648] . !unxz en_XX-ga_IE.tsv.xz . !grep &#39; .ca&#39; en_XX-ga_IE.tsv| cut -c -120 . boutiquestepup.ca https://boutiquestepup.ca/collections/figure-skating-tights Figure skating tights â€“ Boutique Step Up boutiquestepup.ca https://boutiquestepup.ca/collections/crystalized-dress-and-catsuit Figure Skating Dress with Crystals boutiquestepup.ca https://boutiquestepup.ca/collections/mens-skatewear BOYS &amp; MENS FIGURE SKATING WEAR â€“ Boutique Step boutiquestepup.ca https://boutiquestepup.ca/collections/black-figure-skating-dresses Black Figure Skating Dresses, Catsu boutiquestepup.ca https://boutiquestepup.ca/products/new-jerrys-figure-skating-dress-catsuit-unitard-black-lace-made-on- boutiquestepup.ca https://boutiquestepup.ca/ Boutique Step Up|All Departments|GIFT CARDS|AQUATICS &amp; SWIMMING|WOMENS /GIR boutiquestepup.ca https://boutiquestepup.ca/products/new-skating-dress-catsuit-unitard-290-high-neck-made-on-order-youth boutiquestepup.ca https://boutiquestepup.ca/collections/training-racing-swimsuit Training &amp; Racing Swimsuit â€“ Boutique boutiquestepup.ca https://boutiquestepup.ca/collections/skating-catsuit-unitard SKATING CATSUIT- UNITARD â€“ Boutique St boutiquestepup.ca https://boutiquestepup.ca/collections/figure-skates-skating-boots-and-skating-blades Figure Skates, Sk boutiquestepup.ca https://boutiquestepup.ca/collections/dance-shoes Dance Shoes â€“ Boutique Step Up|â…|â†|â…|â†|â… boutiquestepup.ca https://boutiquestepup.ca/collections/dance-costumes Dance Costumes â€“ Boutique Step Up|All Departmen mp3gain-pro.com http://mp3gain-pro.com/mp3/keywords Keywords Â« Mp3 Gain PRO official site Mp3 Normalizer|Home|Tags|Keyw boutiquestepup.ca https://boutiquestepup.ca/collections/skating-shorts Skating Shorts â€“ Boutique Step Up|All Departmen boutiquestepup.ca https://boutiquestepup.ca/products/new-jerrys-competition-skating-dress-142-mirror-red-made-on-order N boutiquestepup.ca https://boutiquestepup.ca/collections/jammers Men&#39;s &amp; Boys Swimwear â€“ Boutique Step Up|All Departmen boutiquestepup.ca https://boutiquestepup.ca/products/new-rockerz-figure-skating-guards-skate-guards-mix-match-colors Fig boutiquestepup.ca https://boutiquestepup.ca/collections/practice-gymnastics-leotard-competition-gymnastics-leotard-team- boutiquestepup.ca https://boutiquestepup.ca/collections/figure-skating-skirt FIGURE SKATING SKIRT â€“ Boutique Step Up|A boutiquestepup.ca https://boutiquestepup.ca/collections/aqua-fitness-chlorine-resistant-swimsuit Aqua Fitness Swimsuits boutiquestepup.ca https://boutiquestepup.ca/collections/dance-accessories-tights DANCE ACCESSORIES &amp; TIGHTS â€“ Boutique cantonfair.net https://www.cantonfair.net/category/49-health-industry Trade Shows from Health Industry China|Search|Sear lrmsafety.com https://en.lrmsafety.com/products/3m-11525 3M à¸£à¸¸à¹ˆà¸™ 11525 â€“ à¸šà¸£à¸´à¸©à¸±à¸— à¹€à¸«à¸¥à¸·à¸­à¸‡ Binary file en_XX-ga_IE.tsv matches .",
            "url": "https://jimregan.github.io/notes/badmt/irish/2021/04/14/cc-aligned-irish.html",
            "relUrl": "/badmt/irish/2021/04/14/cc-aligned-irish.html",
            "date": " â€¢ Apr 14, 2021"
        }
        
    
  
    
        ,"post202": {
            "title": "M2M100 sucks at Irish",
            "content": "Huggingface Transformers added the M2M 100 model, I tried it out and tweeted screenshots of the appalling output, so I thought I&#39;d recreate the translations to show they were very real. . !pip install sentencepiece transformers . from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer model = M2M100ForConditionalGeneration.from_pretrained(&quot;facebook/m2m100_418M&quot;) tokenizer = M2M100Tokenizer.from_pretrained(&quot;facebook/m2m100_418M&quot;) . def translate(text, src_lang=&quot;pl&quot;, trg_lang=&quot;ga&quot;): tokenizer.src_lang = src_lang encoded = tokenizer(text, return_tensors=&quot;pt&quot;) generated_tokens = model.generate(**encoded, forced_bos_token_id=tokenizer.get_lang_id(trg_lang)) print(tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)) . So, do massively multilingual MT models trained on massively crawled datasets lead to great output?No pic.twitter.com/SckNGTq09B . &mdash; Jim O&#39;Regan (@jimregan) April 12, 2021 . â€œOne must love one&#39;s wifeâ€ . translate(&quot;Trzeba kochaÄ‡ swojÄ… Å¼onÄ™&quot;) . [&#39;Brazzers fÃ­seÃ¡n catagÃ³ir Inexperienced, DÃ©agÃ³ir Inexperienced&#39;] . pic.twitter.com/4b6DgbbhtE . &mdash; Jim O&#39;Regan (@jimregan) April 12, 2021 . â€œWhat are you on about?â€ or â€œWhat are you getting at?â€ . translate(&quot;O co Ci chodzi?&quot;) . [&#39;Brazzers fÃ­seÃ¡n catagÃ³ir Inexperienced, DÃ©agÃ³ir Inexperienced&#39;] . It&#39;s almost poetic pic.twitter.com/IbJi1zvlrX . &mdash; Jim O&#39;Regan (@jimregan) April 12, 2021 . Let&#39;s try English: . translate(&quot;Hello, how are you?&quot;, src_lang=&#39;en&#39;) . [&#39;Brazzers fÃ­seÃ¡n catagÃ³ir Inexperienced, DÃ©agÃ³ir Inexperienced, DÃ©agÃ³ir Inexperienced&#39;] . pic.twitter.com/GH4KtctnTI . &mdash; Jim O&#39;Regan (@jimregan) April 12, 2021 . How poetic. How about some actual poetry? (Pan Tadeusz) . translate(&quot;Litwo, Ojczyzno moja! ty jesteÅ› jak zdrowie; Ile ciÄ™ trzeba ceniÄ‡, ten tylko siÄ™ dowie, Kto ciÄ™ straciÅ‚.&quot;) . [&#39;Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers&#39;] . Switching to English output, it at least gives a decent-looking sentence. (It only looks decent, it&#39;s wrong) pic.twitter.com/4HyBQvTAux . &mdash; Jim O&#39;Regan (@jimregan) April 12, 2021 . â€œIt seems to me that you are not soberâ€ . translate(&quot;Mi siÄ™ wydaje, Å¼e nie jesteÅ› trzeÅºwy&quot;, trg_lang=&#39;en&#39;) . [&#39;I donâ€™t think youâ€™re trembling.&#39;] .",
            "url": "https://jimregan.github.io/notes/m2m100/badmt/2021/04/13/m2m100-sucks-at-irish.html",
            "relUrl": "/m2m100/badmt/2021/04/13/m2m100-sucks-at-irish.html",
            "date": " â€¢ Apr 13, 2021"
        }
        
    
  
    
        ,"post203": {
            "title": "Living Audio Irish",
            "content": "%%capture !wget https://ia800700.us.archive.org/6/items/ga.ie.cll.48000.tar/ga.ie.cll.48000.tar.gz . %%capture !wget https://raw.githubusercontent.com/Idlak/Living-Audio-Dataset/master/ga/text.xml . %%capture !tar zxvf ga.ie.cll.48000.tar.gz !rm ga.ie.cll.48000.tar.gz . %%capture !pip install bs4 . from bs4 import BeautifulSoup import unicodedata soup = BeautifulSoup(open(&#39;text.xml&#39;).read(), &#39;lxml&#39;) dataset = list() for entry in soup.find_all(&#39;fileid&#39;): current = dict() current[&#39;id&#39;] = entry[&#39;id&#39;] current[&#39;text&#39;] = unicodedata.normalize(&#39;NFC&#39;, entry.text.strip()) dataset.append(current) . !rm text.xml . def is_upper_vowel(letter): if letter in [&#39;A&#39;, &#39;E&#39;, &#39;I&#39;, &#39;O&#39;, &#39;U&#39;, &#39;Ã&#39;, &#39;Ã‰&#39;, &#39;Ã&#39;, &#39;Ã“&#39;, &#39;Ãš&#39;]: return True else: return False def irish_lower(word): if len(word) &gt; 1 and word[0] in [&#39;n&#39;, &#39;t&#39;] and is_upper_vowel(word[1]): return word[0] + &#39;-&#39; + word[1:].lower() else: return word.lower() def irish_lower_sentence(sentence): return &quot; &quot;.join([irish_lower(w) for w in sentence.split(&quot; &quot;)]) . import re hyphens = &#39;cll_z0001_713 cll_z0001_804 cll_z0002_069 cll_z0002_296 cll_z0002_448 cll_z0002_481 cll_z0002_484 cll_z0002_495&#39;.split(&#39; &#39;) for entry in dataset: tmp = entry[&#39;text&#39;] tmp = re.sub(&#39; - &#39;, &#39; &#39;, tmp) tmp = re.sub(&#39; â€“ &#39;, &#39; &#39;, tmp) tmp = re.sub(&#39;[â€˜â€œâ€ &quot; . ?!,â€“â€”;:]&#39;, &#39;&#39;, tmp) if entry[&#39;id&#39;] in hyphens: tmp = re.sub(&#39; &#39;&#39;, &#39;&#39;, tmp) entry[&#39;sentence&#39;] = irish_lower_sentence(tmp) . for entry in dataset: entry[&#39;speaker&#39;] = &#39;cll&#39; entry[&#39;accent&#39;] = &#39;dublin&#39; entry[&#39;gender&#39;] = &#39;male&#39; entry[&#39;path&#39;] = &#39;../input/living-audio-irish-speech-corpus/48000_orig/{}.wav&#39;.format(entry[&#39;id&#39;]) . import json datasetjson = json.dumps(dataset) jsonf = open(&quot;living-audio.json&quot;, &quot;w&quot;) jsonf.write(datasetjson) jsonf.close() . !wget https://raw.githubusercontent.com/Idlak/idlak/master/idlak-data/ga/ie/lexicon-default.xml . --2021-04-20 21:54:40-- https://raw.githubusercontent.com/Idlak/idlak/master/idlak-data/ga/ie/lexicon-default.xml Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ... Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 405337 (396K) [text/plain] Saving to: â€˜lexicon-default.xmlâ€™ lexicon-default.xml 100%[===================&gt;] 395.84K --.-KB/s in 0.03s 2021-04-20 21:54:40 (14.8 MB/s) - â€˜lexicon-default.xmlâ€™ saved [405337/405337] . from bs4 import BeautifulSoup import unicodedata soup = BeautifulSoup(open(&#39;lexicon-default.xml&#39;).read(), &#39;lxml&#39;) lexicon = [] for entry in soup.find_all(&#39;lex&#39;): current = {} current[&#39;pron&#39;] = entry[&#39;pron&#39;] current[&#39;text&#39;] = unicodedata.normalize(&#39;NFC&#39;, entry.text.strip()) lexicon.append(current) . lexiconjson = json.dumps(lexicon) jsonf = open(&quot;ga-lexicon.json&quot;, &quot;w&quot;) jsonf.write(lexiconjson) jsonf.close() . !rm lexicon-default.xml . with open(&#39;lexicon.txt&#39;, &#39;w&#39;) as lextxt: for lex in lexicon: text = lex[&#39;text&#39;] cleaned = lex[&#39;pron&#39;].replace(&#39;0&#39;, &#39;&#39;).replace(&#39;1&#39;, &#39;&#39;).replace(&#39;2&#39;, &#39;&#39;) lextxt.write(f&#39;{text} {cleaned} n&#39;) .",
            "url": "https://jimregan.github.io/notes/speech/dataset/2021/04/06/living-audio-irish.html",
            "relUrl": "/speech/dataset/2021/04/06/living-audio-irish.html",
            "date": " â€¢ Apr 6, 2021"
        }
        
    
  
    
        ,"post204": {
            "title": "Install pynini on Colab",
            "content": "!pip install -q condacolab import condacolab condacolab.install() . âœ¨ðŸ°âœ¨ Everything looks OK! . !conda install -c conda-forge pynini . import pynini .",
            "url": "https://jimregan.github.io/notes/colab/pynini/2021/04/06/install-pynini-on-colab.html",
            "relUrl": "/colab/pynini/2021/04/06/install-pynini-on-colab.html",
            "date": " â€¢ Apr 6, 2021"
        }
        
    
  
    
        ,"post205": {
            "title": "Running wav2vec2 for Polish on Kashubian",
            "content": "%%capture import requests from bs4 import BeautifulSoup . URL=&#39;http://www.miesiecznikpomerania.pl/audio&#39; . req = requests.get(URL) soup = BeautifulSoup(req.content, &#39;html.parser&#39;) . contents = list() for part in soup.find_all(&#39;div&#39;, class_=&#39;sp-accordion-inner&#39;): out = {} audtag = part.find(&#39;audio&#39;) source = audtag.find(&#39;source&#39;) out[&#39;audio&#39;] = &#39;http://www.miesiecznikpomerania.pl{}&#39;.format(source[&#39;src&#39;]) audtag.decompose() out[&#39;text&#39;] = part.text.strip() contents.append(out) . for c in contents: !echo {c[&#39;audio&#39;]} &gt;&gt; input . %%capture !cat input|sort|uniq &gt; input.sorted !wget -i input.sorted . !cat input.sorted|grep -v uczba_5_Miedzy_niebem_a_ziemia_-_Najo_uczba|awk &#39;{print &quot;http://web.archive.org/web/&quot; $0}&#39; &gt; input.wayback . %%capture !wget -i input.wayback . import json with open(&#39;data.json&#39;, &#39;w&#39;) as outfile: json.dump(contents, outfile) . %%capture !for i in *.ogg;do ffmpeg -y -i &quot;$i&quot; -acodec pcm_s16le -ac 1 -ar 16000 &quot;$i.wav&quot;;done . %%capture !pip install librosa webrtcvad . # VAD wrapper is taken from PyTorch Speaker Verification: # https://github.com/HarryVolek/PyTorch_Speaker_Verification # Copyright (c) 2019, HarryVolek # License: BSD-3-Clause # based on https://github.com/wiseman/py-webrtcvad/blob/master/example.py # Copyright (c) 2016 John Wiseman # License: MIT import collections import contextlib import numpy as np import sys import librosa import wave import webrtcvad #from hparam import hparam as hp sr = 16000 def read_wave(path, sr): &quot;&quot;&quot;Reads a .wav file. Takes the path, and returns (PCM audio data, sample rate). Assumes sample width == 2 &quot;&quot;&quot; with contextlib.closing(wave.open(path, &#39;rb&#39;)) as wf: num_channels = wf.getnchannels() assert num_channels == 1 sample_width = wf.getsampwidth() assert sample_width == 2 sample_rate = wf.getframerate() assert sample_rate in (8000, 16000, 32000, 48000) pcm_data = wf.readframes(wf.getnframes()) data, _ = librosa.load(path, sr) assert len(data.shape) == 1 assert sr in (8000, 16000, 32000, 48000) return data, pcm_data class Frame(object): &quot;&quot;&quot;Represents a &quot;frame&quot; of audio data.&quot;&quot;&quot; def __init__(self, bytes, timestamp, duration): self.bytes = bytes self.timestamp = timestamp self.duration = duration def frame_generator(frame_duration_ms, audio, sample_rate): &quot;&quot;&quot;Generates audio frames from PCM audio data. Takes the desired frame duration in milliseconds, the PCM data, and the sample rate. Yields Frames of the requested duration. &quot;&quot;&quot; n = int(sample_rate * (frame_duration_ms / 1000.0) * 2) offset = 0 timestamp = 0.0 duration = (float(n) / sample_rate) / 2.0 while offset + n &lt; len(audio): yield Frame(audio[offset:offset + n], timestamp, duration) timestamp += duration offset += n def vad_collector(sample_rate, frame_duration_ms, padding_duration_ms, vad, frames): &quot;&quot;&quot;Filters out non-voiced audio frames. Given a webrtcvad.Vad and a source of audio frames, yields only the voiced audio. Uses a padded, sliding window algorithm over the audio frames. When more than 90% of the frames in the window are voiced (as reported by the VAD), the collector triggers and begins yielding audio frames. Then the collector waits until 90% of the frames in the window are unvoiced to detrigger. The window is padded at the front and back to provide a small amount of silence or the beginnings/endings of speech around the voiced frames. Arguments: sample_rate - The audio sample rate, in Hz. frame_duration_ms - The frame duration in milliseconds. padding_duration_ms - The amount to pad the window, in milliseconds. vad - An instance of webrtcvad.Vad. frames - a source of audio frames (sequence or generator). Returns: A generator that yields PCM audio data. &quot;&quot;&quot; num_padding_frames = int(padding_duration_ms / frame_duration_ms) # We use a deque for our sliding window/ring buffer. ring_buffer = collections.deque(maxlen=num_padding_frames) # We have two states: TRIGGERED and NOTTRIGGERED. We start in the # NOTTRIGGERED state. triggered = False voiced_frames = [] for frame in frames: is_speech = vad.is_speech(frame.bytes, sample_rate) if not triggered: ring_buffer.append((frame, is_speech)) num_voiced = len([f for f, speech in ring_buffer if speech]) # If we&#39;re NOTTRIGGERED and more than 90% of the frames in # the ring buffer are voiced frames, then enter the # TRIGGERED state. if num_voiced &gt; 0.9 * ring_buffer.maxlen: triggered = True start = ring_buffer[0][0].timestamp # We want to yield all the audio we see from now until # we are NOTTRIGGERED, but we have to start with the # audio that&#39;s already in the ring buffer. for f, s in ring_buffer: voiced_frames.append(f) ring_buffer.clear() else: # We&#39;re in the TRIGGERED state, so collect the audio data # and add it to the ring buffer. voiced_frames.append(frame) ring_buffer.append((frame, is_speech)) num_unvoiced = len([f for f, speech in ring_buffer if not speech]) # If more than 90% of the frames in the ring buffer are # unvoiced, then enter NOTTRIGGERED and yield whatever # audio we&#39;ve collected. if num_unvoiced &gt; 0.9 * ring_buffer.maxlen: triggered = False yield (start, frame.timestamp + frame.duration) ring_buffer.clear() voiced_frames = [] # If we have any leftover voiced audio when we run out of input, # yield it. if voiced_frames: yield (start, frame.timestamp + frame.duration) def VAD_chunk(aggressiveness, path): audio, byte_audio = read_wave(path, sr) vad = webrtcvad.Vad(int(aggressiveness)) frames = frame_generator(20, byte_audio, sr) frames = list(frames) times = vad_collector(sr, 20, 200, vad, frames) speech_times = [] speech_segs = [] for i, time in enumerate(times): start = np.round(time[0],decimals=2) end = np.round(time[1],decimals=2) j = start while j + .4 &lt; end: end_j = np.round(j+.4,decimals=2) speech_times.append((j, end_j)) speech_segs.append(audio[int(j*sr):int(end_j*sr)]) j = end_j else: speech_times.append((j, end)) speech_segs.append(audio[int(j*sr):int(end*sr)]) return speech_times, speech_segs . . # Based on code from PyTorch Speaker Verification: # https://github.com/HarryVolek/PyTorch_Speaker_Verification # Copyright (c) 2019, HarryVolek # Additions Copyright (c) 2021, Jim O&#39;Regan # License: MIT import numpy as np # wav2vec2&#39;s max duration is 40 seconds, using 39 by default # to be a little safer def vad_concat(times, segs, max_duration=39.0): &quot;&quot;&quot; Concatenate continuous times and their segments, where the end time of a segment is the same as the start time of the next Parameters: times: list of tuple (start, end) segs: list of segments (audio frames) max_duration: maximum duration of the resulting concatenated segments; the kernel size of wav2vec2 is 40 seconds, so the default max_duration is 39, to ensure the resulting list of segments will fit Returns: concat_times: list of tuple (start, end) concat_segs: list of segments (audio frames) &quot;&quot;&quot; absolute_maximum=40.0 if max_duration &gt; absolute_maximum: raise Exception(&#39;`max_duration` {:.2f} larger than kernel size (40 seconds)&#39;.format(max_duration)) # we take 0.0 to mean &quot;don&#39;t concatenate&quot; do_concat = (max_duration != 0.0) concat_seg = [] concat_times = [] seg_concat = segs[0] time_concat = times[0] for i in range(0, len(times)-1): can_concat = (times[i+1][1] - time_concat[0]) &lt; max_duration if time_concat[1] == times[i+1][0] and do_concat and can_concat: seg_concat = np.concatenate((seg_concat, segs[i+1])) time_concat = (time_concat[0], times[i+1][1]) else: concat_seg.append(seg_concat) seg_concat = segs[i+1] concat_times.append(time_concat) time_concat = times[i+1] else: concat_seg.append(seg_concat) concat_times.append(time_concat) return concat_times, concat_seg . . def make_dataset(concat_times, concat_segs): starts = [s[0] for s in concat_times] ends = [s[1] for s in concat_times] return {&#39;start&#39;: starts, &#39;end&#39;: ends, &#39;speech&#39;: concat_segs} . %%capture !pip install datasets . from datasets import Dataset def vad_to_dataset(path, max_duration): t,s = VAD_chunk(3, path) if max_duration &gt; 0.0: ct, cs = vad_concat(t, s, max_duration) dset = make_dataset(ct, cs) else: dset = make_dataset(t, s) return Dataset.from_dict(dset) . %%capture !pip install -q transformers . %%capture from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC # load model and tokenizer processor = Wav2Vec2Processor.from_pretrained(&quot;mbien/wav2vec2-large-xlsr-polish&quot;) model = Wav2Vec2ForCTC.from_pretrained(&quot;mbien/wav2vec2-large-xlsr-polish&quot;) model.to(&quot;cuda&quot;) . def speech_file_to_array_fn(batch): import torchaudio speech_array, sampling_rate = torchaudio.load(batch[&quot;path&quot;]) batch[&quot;speech&quot;] = speech_array[0].numpy() batch[&quot;sampling_rate&quot;] = sampling_rate batch[&quot;target_text&quot;] = batch[&quot;sentence&quot;] return batch def evaluate(batch): import torch inputs = processor(batch[&quot;speech&quot;], sampling_rate=16_000, return_tensors=&quot;pt&quot;, padding=True) with torch.no_grad(): logits = model(inputs.input_values.to(&quot;cuda&quot;), attention_mask=inputs.attention_mask.to(&quot;cuda&quot;)).logits pred_ids = torch.argmax(logits, dim=-1) batch[&quot;pred_strings&quot;] = processor.batch_decode(pred_ids) return batch . import json def process_wave(filename, duration): import json dataset = vad_to_dataset(filename, duration) result = dataset.map(evaluate, batched=True, batch_size=16) speechless = result.remove_columns([&#39;speech&#39;]) d=speechless.to_dict() tlog = list() for i in range(0, len(d[&#39;end&#39;]) - 1): out = dict() out[&#39;start&#39;] = d[&#39;start&#39;][i] out[&#39;end&#39;] = d[&#39;end&#39;][i] out[&#39;transcript&#39;] = d[&#39;pred_strings&#39;][i] tlog.append(out) with open(&#39;{}.tlog&#39;.format(filename), &#39;w&#39;) as outfile: json.dump(tlog, outfile) . import glob for f in glob.glob(&#39;./*.wav&#39;): print(f) process_wave(f, 10.0) . !ls *tlog|zip tlogs-csb.zip -@ .",
            "url": "https://jimregan.github.io/notes/wav2vec2/kashubian/2021/03/28/wav2vec2-polish-with-kashubian.html",
            "relUrl": "/wav2vec2/kashubian/2021/03/28/wav2vec2-polish-with-kashubian.html",
            "date": " â€¢ Mar 28, 2021"
        }
        
    
  
    
        ,"post206": {
            "title": "Using a wav2vec2 model with DSAlign",
            "content": "%%capture !pip install librosa webrtcvad . . The VAD wrapper is taken from PyTorch Speaker Verification, which is in turn is based on py-webrtcvad. . # VAD wrapper is taken from PyTorch Speaker Verification: # https://github.com/HarryVolek/PyTorch_Speaker_Verification # Copyright (c) 2019, HarryVolek # License: BSD-3-Clause # based on https://github.com/wiseman/py-webrtcvad/blob/master/example.py # Copyright (c) 2016 John Wiseman # License: MIT import collections import contextlib import numpy as np import sys import librosa import wave import webrtcvad #from hparam import hparam as hp sr = 16000 def read_wave(path, sr): &quot;&quot;&quot;Reads a .wav file. Takes the path, and returns (PCM audio data, sample rate). Assumes sample width == 2 &quot;&quot;&quot; with contextlib.closing(wave.open(path, &#39;rb&#39;)) as wf: num_channels = wf.getnchannels() assert num_channels == 1 sample_width = wf.getsampwidth() assert sample_width == 2 sample_rate = wf.getframerate() assert sample_rate in (8000, 16000, 32000, 48000) pcm_data = wf.readframes(wf.getnframes()) data, _ = librosa.load(path, sr) assert len(data.shape) == 1 assert sr in (8000, 16000, 32000, 48000) return data, pcm_data class Frame(object): &quot;&quot;&quot;Represents a &quot;frame&quot; of audio data.&quot;&quot;&quot; def __init__(self, bytes, timestamp, duration): self.bytes = bytes self.timestamp = timestamp self.duration = duration def frame_generator(frame_duration_ms, audio, sample_rate): &quot;&quot;&quot;Generates audio frames from PCM audio data. Takes the desired frame duration in milliseconds, the PCM data, and the sample rate. Yields Frames of the requested duration. &quot;&quot;&quot; n = int(sample_rate * (frame_duration_ms / 1000.0) * 2) offset = 0 timestamp = 0.0 duration = (float(n) / sample_rate) / 2.0 while offset + n &lt; len(audio): yield Frame(audio[offset:offset + n], timestamp, duration) timestamp += duration offset += n def vad_collector(sample_rate, frame_duration_ms, padding_duration_ms, vad, frames): &quot;&quot;&quot;Filters out non-voiced audio frames. Given a webrtcvad.Vad and a source of audio frames, yields only the voiced audio. Uses a padded, sliding window algorithm over the audio frames. When more than 90% of the frames in the window are voiced (as reported by the VAD), the collector triggers and begins yielding audio frames. Then the collector waits until 90% of the frames in the window are unvoiced to detrigger. The window is padded at the front and back to provide a small amount of silence or the beginnings/endings of speech around the voiced frames. Arguments: sample_rate - The audio sample rate, in Hz. frame_duration_ms - The frame duration in milliseconds. padding_duration_ms - The amount to pad the window, in milliseconds. vad - An instance of webrtcvad.Vad. frames - a source of audio frames (sequence or generator). Returns: A generator that yields PCM audio data. &quot;&quot;&quot; num_padding_frames = int(padding_duration_ms / frame_duration_ms) # We use a deque for our sliding window/ring buffer. ring_buffer = collections.deque(maxlen=num_padding_frames) # We have two states: TRIGGERED and NOTTRIGGERED. We start in the # NOTTRIGGERED state. triggered = False voiced_frames = [] for frame in frames: is_speech = vad.is_speech(frame.bytes, sample_rate) if not triggered: ring_buffer.append((frame, is_speech)) num_voiced = len([f for f, speech in ring_buffer if speech]) # If we&#39;re NOTTRIGGERED and more than 90% of the frames in # the ring buffer are voiced frames, then enter the # TRIGGERED state. if num_voiced &gt; 0.9 * ring_buffer.maxlen: triggered = True start = ring_buffer[0][0].timestamp # We want to yield all the audio we see from now until # we are NOTTRIGGERED, but we have to start with the # audio that&#39;s already in the ring buffer. for f, s in ring_buffer: voiced_frames.append(f) ring_buffer.clear() else: # We&#39;re in the TRIGGERED state, so collect the audio data # and add it to the ring buffer. voiced_frames.append(frame) ring_buffer.append((frame, is_speech)) num_unvoiced = len([f for f, speech in ring_buffer if not speech]) # If more than 90% of the frames in the ring buffer are # unvoiced, then enter NOTTRIGGERED and yield whatever # audio we&#39;ve collected. if num_unvoiced &gt; 0.9 * ring_buffer.maxlen: triggered = False yield (start, frame.timestamp + frame.duration) ring_buffer.clear() voiced_frames = [] # If we have any leftover voiced audio when we run out of input, # yield it. if voiced_frames: yield (start, frame.timestamp + frame.duration) def VAD_chunk(aggressiveness, path): audio, byte_audio = read_wave(path, sr) vad = webrtcvad.Vad(int(aggressiveness)) frames = frame_generator(20, byte_audio, sr) frames = list(frames) times = vad_collector(sr, 20, 200, vad, frames) speech_times = [] speech_segs = [] for i, time in enumerate(times): start = np.round(time[0],decimals=2) end = np.round(time[1],decimals=2) j = start while j + .4 &lt; end: end_j = np.round(j+.4,decimals=2) speech_times.append((j, end_j)) speech_segs.append(audio[int(j*sr):int(end_j*sr)]) j = end_j else: speech_times.append((j, end)) speech_segs.append(audio[int(j*sr):int(end*sr)]) return speech_times, speech_segs . . Running . I&#39;m going to use a video from YouTube as my input, so first I need to install youtube-dl . %%capture !pip install youtube-dl . I&#39;ve selected this video because it&#39;s a speech by the President of Ireland (and so copyright-free as a matter of public record), it has subtitles (in Irish, though listed as English), and the subtitles are quite faithful to what was spoken. . %%capture !youtube-dl --all-subs -o &#39;%(id)s&#39; VRg-a0qSGa8 . The audio needs to be a 16k wav, so I&#39;m converting it with ffmpeg. . %%capture !ffmpeg -i VRg-a0qSGa8.mkv -acodec pcm_s16le -ac 1 -ar 16000 VRg-a0qSGa8.wav . Next, I&#39;m using the VAD_chunk() function to get the start and end times, and audio segements of each part of the video with speech. . times, segs = VAD_chunk(3, &#39;VRg-a0qSGa8.wav&#39;) . The wav2vec2 models generally perform badly on short input, so vad_concat() concatenates the segments, as well as the times (for DSAlign). . # Based on code from PyTorch Speaker Verification: # https://github.com/HarryVolek/PyTorch_Speaker_Verification # Copyright (c) 2019, HarryVolek # Additions Copyright (c) 2021, Jim O&#39;Regan # License: MIT import numpy as np # wav2vec2&#39;s max duration is 40 seconds, using 39 by default # to be a little safer def vad_concat(times, segs, max_duration=39.0): &quot;&quot;&quot; Concatenate continuous times and their segments, where the end time of a segment is the same as the start time of the next Parameters: times: list of tuple (start, end) segs: list of segments (audio frames) max_duration: maximum duration of the resulting concatenated segments; the kernel size of wav2vec2 is 40 seconds, so the default max_duration is 39, to ensure the resulting list of segments will fit Returns: concat_times: list of tuple (start, end) concat_segs: list of segments (audio frames) &quot;&quot;&quot; absolute_maximum=40.0 if max_duration &gt; absolute_maximum: raise Exception(&#39;`max_duration` {:.2f} larger than kernel size (40 seconds)&#39;.format(max_duration)) # we take 0.0 to mean &quot;don&#39;t concatenate&quot; do_concat = (max_duration != 0.0) concat_seg = [] concat_times = [] seg_concat = segs[0] time_concat = times[0] for i in range(0, len(times)-1): can_concat = (times[i+1][1] - time_concat[0]) &lt; max_duration if time_concat[1] == times[i+1][0] and do_concat and can_concat: seg_concat = np.concatenate((seg_concat, segs[i+1])) time_concat = (time_concat[0], times[i+1][1]) else: concat_seg.append(seg_concat) seg_concat = segs[i+1] concat_times.append(time_concat) time_concat = times[i+1] else: concat_seg.append(seg_concat) concat_times.append(time_concat) return concat_times, concat_seg . . ntimes, nsegs = vad_concat(times, segs) . Next, I&#39;m putting the data into a dict that Huggingface datasets can read: . starts = [s[0] for s in ntimes] ends = [s[1] for s in ntimes] . dset = {&#39;start&#39;: starts, &#39;end&#39;: ends, &#39;speech&#39;: nsegs} . %%capture !pip install datasets . from datasets import Dataset dataset = Dataset.from_dict(dset) . dataset . Dataset({ features: [&#39;start&#39;, &#39;end&#39;, &#39;speech&#39;], num_rows: 137 }) . Now, the data is ready to plug into my wav2vec2 model. . %%capture !pip install -q transformers . %%capture from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC # load model and tokenizer processor = Wav2Vec2Processor.from_pretrained(&quot;jimregan/wav2vec2-large-xlsr-irish-basic&quot;) model = Wav2Vec2ForCTC.from_pretrained(&quot;jimregan/wav2vec2-large-xlsr-irish-basic&quot;) model.to(&quot;cuda&quot;) . Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained. . def speech_file_to_array_fn(batch): import torchaudio speech_array, sampling_rate = torchaudio.load(batch[&quot;path&quot;]) batch[&quot;speech&quot;] = speech_array[0].numpy() batch[&quot;sampling_rate&quot;] = sampling_rate batch[&quot;target_text&quot;] = batch[&quot;sentence&quot;] return batch def evaluate(batch): import torch inputs = processor(batch[&quot;speech&quot;], sampling_rate=16_000, return_tensors=&quot;pt&quot;, padding=True) with torch.no_grad(): logits = model(inputs.input_values.to(&quot;cuda&quot;), attention_mask=inputs.attention_mask.to(&quot;cuda&quot;)).logits pred_ids = torch.argmax(logits, dim=-1) batch[&quot;pred_strings&quot;] = processor.batch_decode(pred_ids) return batch . . result = dataset.map(evaluate, batched=True, batch_size=8) . . speechless = result.remove_columns([&#39;speech&#39;]) . d=speechless.to_dict() . tlog = list() for i in range(0, len(d[&#39;end&#39;]) - 1): out = dict() out[&#39;start&#39;] = d[&#39;start&#39;][i] out[&#39;end&#39;] = d[&#39;end&#39;][i] out[&#39;transcript&#39;] = d[&#39;pred_strings&#39;][i] tlog.append(out) . import json with open(&#39;/content/VRg-a0qSGa8.tlog&#39;, &#39;w&#39;) as outfile: json.dump(tlog, outfile) . Next, I&#39;m extracting the text content from the vtt file . !pip install webvtt-py . Requirement already satisfied: webvtt-py in /usr/local/lib/python3.7/dist-packages (0.4.6) Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from webvtt-py) (0.6.2) . def get_vtt_text(filename): import webvtt out = list() for sub in webvtt.read(filename): out.append(sub.text) return &#39; &#39;.join(out) . text = get_vtt_text(&#39;/content/VRg-a0qSGa8.en.vtt&#39;) . I can do some normalisation now: . text = text.replace(&#39;1901&#39;, &#39;naoi dÃ©ag is a haon&#39;) text = text.replace(&#39;2021&#39;, &#39;fiche is fiche is a haon&#39;) text = text.replace(&#39;Covid-19&#39;, &#39;covid a naoi dÃ©ag&#39;) text = text.replace(&#39;fiche fiche haon&#39;, &#39;fiche is fiche is a haon&#39;) . I want sentences, so I&#39;m going to use mosestokenizer to split the text (there aren&#39;t any specific abbreviations in this video, so the English splitter works fine. YMMV.) . %%capture !pip install mosestokenizer . The actual moses tokeniser has sentence splitting support for Irish, but the Python version was forked before that; we don&#39;t actually need any specific support for Irish here, so we can just use English. . from mosestokenizer import MosesSentenceSplitter with MosesSentenceSplitter(&#39;en&#39;) as splitsents: sents = splitsents([text]) . with open(&#39;/content/VRg-a0qSGa8.txt&#39;, &#39;w&#39;) as outfile: outfile.writelines([&#39; n&#39;.join(sents)]) . DSAlign requires an alphabet (1 character per line), so create that first . alpha=&quot;aÃ¡bcdeÃ©fghiÃ­jklmnoÃ³pqrstuÃºvwxyz&#39;-&quot; alpha_chars = [char for char in alpha] . with open(&#39;/content/ga.alphabet&#39;, &#39;w&#39;) as outfile: outfile.writelines([&#39; n&#39;.join(alpha_chars)]) . Now, to install DSAlign and its dependencies: . %%capture !git clone https://github.com/mozilla/DSAlign . %%capture !apt-get install sox . %%capture import os os.chdir(&#39;DSAlign&#39;) !pip install -r requirements.txt . Now, I&#39;m ready to align: . !bin/align.sh --force --tlog /content/VRg-a0qSGa8.tlog --script /content/VRg-a0qSGa8.txt --aligned /content/VRg-a0qSGa8.aligned --text-meaningful-newlines --alphabet /content/ga.alphabet . bin/align.sh: line 3: /content/DSAlign/venv/bin/activate: No such file or directory INFO:root:Aligning 1 of 1 : 100.00% (elapsed: 00:00:04, speed: 0.25 it/s, ETA: 00:00:00) INFO:root:Aligned 24 fragments INFO:root:Dropped 112 fragments 466.67%: . 24 out of 136 fragments isn&#39;t great, but it&#39;s quite good considering the WER of the model (43.7%); the next step would be to add the aligned data to the training set, retrain, and repeat. .",
            "url": "https://jimregan.github.io/notes/wav2vec2/dsalign/2021/03/27/using-a-wav2vec2-model-with-dsalign.html",
            "relUrl": "/wav2vec2/dsalign/2021/03/27/using-a-wav2vec2-model-with-dsalign.html",
            "date": " â€¢ Mar 27, 2021"
        }
        
    
  
    
        ,"post207": {
            "title": "Seanchas Rann na Feirste scraper pieces",
            "content": "import requests from bs4 import BeautifulSoup BASE=&#39;http://www.rannnafeirste.com&#39; . class Page: def __init__(self, id, title): self.id = id self.title = title self.url = &#39;{}/{}&#39;.format(BASE, id) # TODO: stop trying to make fetch happen def _fetch_text(self): req = requests.get(self.url) if req.status_code != 200: raise Exception(&#39;Error fetching page &#39; + self.url) self.content = req.content def _soupynorman(self): self.soup = BeautifulSoup(self.content, &#39;html.parser&#39;) def _fetch_audio(self): audio_div = self.soup.find(&quot;div&quot;, class_=&#39;sqs-audio-embed&#39;) self.audio = audio_div[&quot;data-url&quot;] def _fetch_fragments(self): for i in self.soup.find_all(&quot;div&quot;, class_=&#39;sqs-block-content&#39;): children = list(i.children) if children[0].name == &quot;h1&quot;: self.fragments = children ## don&#39;t actually need this, because the title comes from the landing page def _fetch_title(self): if self.fragments[0].name == &quot;h1&quot;: self.title = fragments[0].text else: raise Exception(&#39;Error reading title: &#39; + self.url) def _fetch_author(self): if len(self.fragments) &gt; 2 and self.fragments[1].name == &quot;h2&quot;: self.author = self.fragments[1].text else: raise Exception(&#39;Error reading author: &#39; + self.url) def _fetch_paragraphs(self): raw_paras = [n for n in self.fragments if n.name == &quot;p&quot;] for frag in raw_paras: for br in frag.find_all(&quot;br&quot;): br.insert(0, &#39; n&#39;) br.unwrap() first = list(raw_paras[0].children) if len(first) == 1 and first[0].name == &#39;em&#39;: self.em_para = raw_paras[0].text.strip() del raw_paras[0] extent = len(raw_paras) counter = 0 for i in raw_paras: if i.text.strip().startswith(&#39;NÃ³ta&#39;) or i.text.strip().startswith(&#39;NÃ“TA&#39;) and extent &gt; counter: extent = counter counter += 1 filt = raw_paras[0:extent] self.paragraphs = [p.text for p in filt] def get_initials(self): fada = { &#39;Ã&#39;: &#39;A&#39;, &#39;Ã‰&#39;: &#39;E&#39;, &#39;Ã&#39;: &#39;I&#39;, &#39;Ã“&#39;: &#39;O&#39;, &#39;Ãš&#39;: &#39;U&#39; } def initial(s): if s == None or len(s) &lt; 1: return &#39;&#39; else: return fada.get(s.upper()[0]) or s.upper()[0] try: return &quot;&quot;.join([initial(i) for i in self.author.split(&#39; &#39;)]) except: print(&#39;Author missing: did you run scrape()?&#39;) def _specifics(self): title = [&#39;mo-bhaile-dchais&#39;, &#39;taiscidh-ghleann-domhain&#39;, &#39;banron-an-uaignis&#39;, &#39;non-an-r-agus-an-frog&#39;, &#39;seanchaithe-agus-fil-rann-na-feirste&#39;, &#39;an-ghaeltacht-bheo&#39;] titlele = [&#39;liontar-duinn-an-cruiscin&#39;, &#39;oireachtas-na-ndise&#39;, &#39;fidilir-ghleann-fhinne&#39;] if self.id in title: self.paragraphs.insert(0, self.title) if self.id in titlele: second = self.em_para.replace(&#39; a chum&#39;, &#39;&#39;) self.paragraphs.insert(0, &#39;{} le {}&#39;.format(self.title, second)) def scrape(self): self._fetch_text() self._soupynorman() self._fetch_audio() self._fetch_fragments() self._fetch_author() self._fetch_paragraphs() self._specifics() . foo = Page(&#39;deorai-an-oileain&#39;, &#39;Mo Bhaile&#39;) foo.scrape() foo.paragraphs . para = foo.fragments[4] . #one = para.contents[0] for br in para.find_all(&quot;br&quot;): br.insert(0, &#39; n&#39;) br.unwrap() para.contents . raw_paras = [n for n in foo.fragments if n.name == &quot;p&quot;] #raw_paras first = list(raw_paras[0].children) if len(first) == 1 and first[0].name == &#39;em&#39;: del raw_paras[0] extent = len(raw_paras) counter = 0 for i in raw_paras: print(i.text) if i.text.strip().startswith(&#39;NÃ³ta&#39;) or i.text.strip().startswith(&#39;NÃ“TA&#39;) and extent &gt; counter: extent = counter counter += 1 raw_paras[0:extent] #counter .",
            "url": "https://jimregan.github.io/notes/irish/asr/text/2021/03/25/rann_na_feirste_scraper.html",
            "relUrl": "/irish/asr/text/2021/03/25/rann_na_feirste_scraper.html",
            "date": " â€¢ Mar 25, 2021"
        }
        
    
  
    
        ,"post208": {
            "title": "Irish Texts from South West Donegal. An mhÃ³in.",
            "content": "The table below compares the transcription of Text 2: â€œAn mhÃ³inâ€ from Oâ€™Neillâ€™s1 â€œIrish Texts from South West Donegalâ€, comparing it with Abairâ€™s transcription. . Texts 1â€”4 were contributed by Seamus Ã“ Beirn (Jim Phat James), aged c. 70 years, cobbler, from the townland of MÃ­n na Gaoithe, Teelin. . A special feature of his speech is the clearness and strength of the affricates tâ€²Êƒ and dâ€²Ê’ due to the deliberate manner in which each word is enunciated. . The phonetic rules were mostly to help with automatic comparison, though the places where verb froms were pronounced differently before a pronoun was interesting enough to note. . Original Transcript Abair G2P Abair source Adjusted word (standardised) Adjusted Abair Rule . An | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . dtiocfadh | dâ€²{Ê’}oÌ¤ku | ËˆdÊ²okË uË | L | Â  | Â  | Â  | . leat | Lâ€²at | ËˆlÊ²atË  | L | Â  | Â  | Â  | . innse | iÌˆÎâ€²ÊƒÉ™ | ËˆiËˆÉ´Ê²Êƒe | Â  | insint | ËŒinÊ²ËˆÊƒinÊ²tÊ² | Â  | . domh | du | ËˆdË uË | L | Â  | Â  | Â  | . caidÃ© | gÉ™Ëˆdâ€²{Ê’}e: | kË É™ËˆdÊ²eË | L | Â  | Â  | Â  | . n | n | nË  | L | Â  | Â  | Â  | . dÃ³igh | ËˆdÉ”:i | ËˆdË oËj | L | Â  | Â  | Â  | . a | É™ | É™ | L | Â  | Â  | Â  | . ndÃ©antar | Nâ€²a:NtÉ‘r | ËˆnÊ²eËÉ´Ë tË É™É¾Ë  | L | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . mhÃ³in | Ëˆwo:áµŠnâ€² | ËˆwoËnÊ² | L+M | Â  | Â  | Â  | . Nuair | NuÉ™râ€² | ËˆÉ´Ë uËÉ¾Ê² | L | Â  | Â  | Â  | . a | É™ | É™ | L | Â  | Â  | Â  | . thig | hÉªgâ€² | ËˆhjiÉŸ | L | Â  | Â  | Â  | . mÃ­ | Ëˆmâ€²i: | ËˆmÊ²iË | L | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . MhÃ¡rta | ËˆwÉ‘:rtÉ™ | ËˆwaËÉ¾Ë tË É™ | L+M | Â  | Â  | Â  | . agus | É”gÉ™s | ËˆagË É™sË  | L | Â  | Â  | Â  | . go | gÉ” | ËˆgË É™ | L | Â  | Â  | Â  | . h-Ã¡irid | Ëˆha:ridâ€²á¶¾ | ËˆhaËÉ¾Ê²É™dÊ² | Â  | hÃ¡irithe | ËˆhaËÉ¾Ê²ihjÉ™ | Â  | . nuair | NuÉ™râ€² | ËˆÉ´Ë uËÉ¾Ê² | L | Â  | Â  | Â  | . a | É™ | É™ | L | Â  | Â  | Â  | . thÃ©igheann | Ëˆhe:áµŠN | ËˆheËjÉ™É´Ë  | Â  | thÃ©ann | ËˆheËÉ´Ë  | Â  | . LÃ¡ | LÉ‘: | ËˆÊŸË aË | L | Â  | Â  | Â  | . FhÃ©il | lâ€² | ËˆeËlÊ² | L | Â  | Â  | Â  | . PÃ¡draig | ËˆpÉ‘:drikâ€² | ËˆpË aËdË É¾Ë É™ÉŸ | L | Â  | Â  | Â  | . thart | hÉ‘rt | ËˆhaÉ¾Ë tË  | L | Â  | Â  | Â  | . tÃ¡ | tÉ‘: | ËˆtË aË | L | Â  | Â  | Â  | . an | n | ËˆÉ™É´Ë  | L | Â  | Â  | É™ â†’ âˆ… / V # _ | . t-am | ËˆtÉ‘:m | ËˆtË aËmË  | L | Â  | Â  | Â  | . ann | oÌ¤N | ËˆaÉ´Ë  | L | Â  | Â  | Â  | . fÃ¡ | fÉ‘ | ËˆfË aË | L | Â  | Â  | Â  | . dhÃ©in | Ëˆje:nâ€² | ËˆjeËnÊ² | L+M | Â  | Â  | Â  | . a | É™ | É™ | L | Â  | Â  | Â  | . ghabhÃ¡il | ËˆÉ£É”lâ€² | ËˆÉ£olÊ² | L | Â  | Â  | Â  | . na | nÉ™ | ËˆÉ´Ë É™ | L | Â  | Â  | Â  | . phortaigh. | ËˆfÉ”rti | ËˆfË aÉ¾Ë tË iË | L | Â  | Â  | Â  | . BhÃ©arfaidh | verhÉ™ | ËˆvÊ²eËÉ¾Ë hiË | L | Â  | Â  | Â  | . tÃº | tu | ËˆtË uË | L | Â  | Â  | Â  | . leat | Lâ€²at | ËˆlÊ²atË  | L | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . spÃ¡d | ËˆsbÊ·É‘:d | ËˆsË pË aËdË  | L | Â  | Â  | Â  | . sÃ­ | Êƒi: | ËˆÊƒiË | L | Â  | Â  | Â  | . an | nÌ¥ | ËˆÉ™É´Ë  | L | Â  | Â  | É™ â†’ âˆ… / V # _ | . chÃ©ad | Ëˆxâ€²e:d | ËˆÃ§eËdË  | L | Â  | Â  | Â  | . armaÃ­ | ËˆÉ‘rmÊ·i | ËˆaÉ¾Ë É™mË iË | Â  | Â  | Â  | Â  | . a | Ã¨ | É™ | L | Â  | Â  | Â  | . bhÃ©arfaidh | vÉ›rhÉ™ | ËˆvÊ²eËÉ¾Ë hiË | L | Â  | Â  | Â  | . tÃº | tu | ËˆtË uË | L | Â  | Â  | Â  | . leat | ËˆLâ€²at | ËˆlÊ²atË  | L | Â  | Â  | Â  | . na | nÉ™ | ËˆÉ´Ë É™ | L | Â  | Â  | Â  | . phortaigh | ËˆfÉ”rti | ËˆfË aÉ¾Ë tË iË | L | Â  | Â  | Â  | . Agus | É”gÉ™s | ËˆagË É™sË  | L | Â  | Â  | Â  | . rachaidh | ËˆrÉ‘hÉ™ | ËˆÉ¾Ë aËhij | L | Â  | Â  | Â  | . tÃº | tu | ËˆtË uË | L | Â  | Â  | Â  | . fhad | ad | ËˆadË  | L | Â  | Â  | Â  | . leis | Lâ€²eÊƒ | ËˆlÊ²iÊƒ | L | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . bhachta | ËˆwÉ‘xdÉ™ | ËˆwaÉ¾Ë tË É™ | L+M | Â  | Â  | Â  | . agus | É”gÉ™s | ËˆagË É™sË  | L | Â  | Â  | Â  | . caithfidh | ËˆkaihÉª | ËˆkË ahjiË | L | Â  | Â  | Â  | . tÃº | tu | ËˆtË uË | L | Â  | Â  | Â  | . an | nÌ¥ | ËˆÉ™É´Ë  | L | Â  | Â  | É™ â†’ âˆ… / V # _ | . bachtadh | ËˆbÉ‘xdu | ËˆbË aÉ¾Ë tË uË | Â  | bachta | Â  | Â  | . a | É™ | É™ | L | Â  | Â  | Â  | . lomadh | ËˆLoÌ¤mu | ËˆÊŸË omË uË | L | Â  | Â  | Â  | . leis | Lâ€²eÊƒ | ËˆlÊ²iÊƒ | L | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . spÃ¡d | ËˆsbÉ‘:d | ËˆsË pË aËdË  | L | Â  | Â  | Â  | . Agus | É”gÉ™s | ËˆagË É™sË  | L | Â  | Â  | Â  | . sÃ© | ÊƒÎµ | ËˆÊƒeË | L | Â  | Â  | Â  | . an | nÌ¥ | ËˆÉ™É´Ë  | L | Â  | Â  | É™ â†’ âˆ… / V # _ | . chiall | Ëˆxâ€²i:É™L | ËˆÃ§iaÊŸË  | L | Â  | Â  | Â  | . atÃ¡ | É™tÉ‘: | É™ËˆtË aË | L | Â  | Â  | Â  | . leis | lâ€²É› | ËˆlÊ²iÊƒ | L | Â  | Â  | Êƒ â†’ âˆ… / Êƒ # _ | . sin | ËˆÊƒÉªnâ€² | ËˆÊƒinÊ² | L | Â  | Â  | Â  | . an | nÌ¥ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . croiceann | ËˆkrÉ›kâ€²É™N | ËˆkË É¾Ë ocÉ™É´Ë  | Â  | craiceann | ËˆkË É¾Ë acÉ™É´Ë  | Â  | . a | É™ | É™ | L | Â  | Â  | Â  | . bhaint | wÃ¯â€²Nt | ËˆwanÊ²tÊ² | L | Â  | Â  | Â  | . deâ€™n | É”n | ËˆdË enË  | L | Â  | Â  | d â†’ âˆ… / t # _ | . talamh | ËˆtÉ‘lu | ËˆtË oÊŸË uË | L | Â  | Â  | Â  | . go | go | ËˆgË É™ | L | Â  | Â  | Â  | . dtÃ©ighidh | Ëˆdâ€²á¶¾e:áµŠ | ËˆdÊ²eËjiË | Â  | dtÃ© | ËˆdÊ²eË | Â  | . tÃº | tu | ËˆtË uË | L | Â  | Â  | Â  | . sÃ­os | ËˆÊƒi:s | ËˆÊƒiËsË  | L | Â  | Â  | Â  | . fhad | É‘d | ËˆadË  | L | Â  | Â  | Â  | . leis | Lâ€²eÊƒ | ËˆlÊ²iÊƒ | L | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . mhÃ³in. | Ëˆwo:nâ€² | ËˆwoËnÊ² | L+M | Â  | Â  | Â  | . TÃ¡ | tÉ‘: | ËˆtË aË | L | Â  | Â  | Â  | . an | nÌ¥ | ËˆÉ™É´Ë  | L | Â  | Â  | É™ â†’ âˆ… / V # _ | . t-uachtar | ËˆtuÉ™xdÉ™r | ËˆtË uaxtË É™É¾Ë  | L+M | Â  | Â  | Â  | . marbh | Ëˆmaru | ËˆmË aÉ¾Ë É™w | L | Â  | Â  | Â  | . ag | Éªgâ€² | ËˆeÉŸ | L | Â  | Â  | Â  | . sioc | ËˆÊƒoÌ¤k | ËˆÊƒikË  | L | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . Gheimhridh | ËˆjÉ›vrâ€²i | ËˆjivÊ²É¾Ê²i | L | Â  | Â  | Â  | . agus | É”gÉ™s | ËˆagË É™sË  | L | Â  | Â  | Â  | . caithfidh | ËˆkÉ‘ihÉª | ËˆkË ahjiË | L | Â  | Â  | Â  | . tÃº | tu | ËˆtË uË | L | Â  | Â  | Â  | . ghabhÃ¡il | É£É”lâ€² | ËˆÉ£olÊ² | L | Â  | Â  | Â  | . sÃ­os | ËˆÊƒiáµŠs | ËˆÊƒiËsË  | L | Â  | Â  | Â  | . go | gÉ” | ËˆgË É™ | L | Â  | Â  | Â  | . dtÃ­ | Ëˆdâ€²Ê’i: | ËˆdÊ²iË | L | Â  | Â  | Â  | . go | gÉ” | ËˆgË É™ | L | Â  | Â  | Â  | . bhfaghaidh | ËˆwÉ‘: | ËˆweËiË | Â  | bhfaighidh | ËˆwiË | Â  | . tÃº | tu | ËˆtË uË | L | Â  | Â  | Â  | . an | nÌ¥ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . mhÃ³in | Ëˆwo:áµŠnâ€² | ËˆwoËnÊ² | L+M | Â  | Â  | Â  | . Leagfaidh | ËˆLâ€²oÌ¤khÉ™ | ËˆÊŸÊ²agË iË | Â  | Â  | Â  | Â  | . tÃº | tu | ËˆtË uË | L | Â  | Â  | Â  | . an | nÌ¥ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . dorga | ËˆdÉ”rÉ™gÉ™ | ËˆdË oËˆÉ¾Ë gË a | Â  | dorÃº | ËˆdË oÉ¾Ë uË | Â  | . ar | É›r | ËˆeÉ¾Ê² | L | Â  | Â  | Â  | . Ã©adan | Ëˆe:áµŠdÉ‘n | ËˆeËdË É™É´Ë  | L | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . bhachta | ËˆwÉ‘xdÉ™ | ËˆwaÉ¾Ë tË É™ | L+M | Â  | Â  | Â  | . agus | É”gÉ™s | ËˆagË É™sË  | L | Â  | Â  | Â  | . bhÃ©arfaidh | vÃ¨rhÉ™ | ËˆvÊ²eËÉ¾Ë hiË | L | Â  | Â  | Â  | . tÃº | tu | ËˆtË uË | L | Â  | Â  | Â  | . slat | ËˆslÉ‘t | ËˆsË ÊŸË atË  | L | Â  | Â  | Â  | . ar | É›r | ËˆeÉ¾Ê² | L | Â  | Â  | Â  | . leithead | ËˆLâ€²É›hÉ™d | ËˆÊŸÊ²aihjÉ™dË  | L | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . bhachtadh | ËˆwÉ‘xdu | ËˆwaÉ¾Ë tË uË | Â  | Â  | Â  | Â  | . Ã³ | É‘ | ËˆoË | L | Â  | Â  | Â  | . bhun | ËˆwoÌ¤n | ËˆwuÉ´Ë  | L | Â  | Â  | Â  | . go | gÉ” | ËˆgË É™ | L | Â  | Â  | Â  | . bÃ¡rr | ËˆbÉ‘:R | ËˆbË aËÉ¾Ë  | Â  | barr | ËˆbË aËÉ¾Ë  | Â  | . Nuair | NuÉ™râ€² | ËˆÉ´Ë uËÉ¾Ê² | L | Â  | Â  | Â  | . atÃ¡ | É™tÉ‘: | É™ËˆtË aË | L | Â  | Â  | Â  | . an | nÌ¥ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . bachtadh | ËˆbÉ‘xdu | ËˆbË aÉ¾Ë tË uË | Â  | Â  | Â  | Â  | . lomta | ËˆLoÌ¤mt | ËˆÊŸË omË tË É™ | Â  | Â  | Â  | Â  | . agat | Ã¨it | ËˆÉ™gË É™tË  | L | Â  | Â  | Â  | . annsin | nÌ¥ËˆÊƒÉªnâ€² | ËˆaËˆÉ´Ê²ÊƒinÊ² | Â  | ansin | É™É´Ë ÊƒinÊ² | Â  | . bhÃ©arfaidh | vÉ›:rhÉ™ | ËˆvÊ²eËÉ¾Ë hiË | L | Â  | Â  | Â  | . tÃº | tu | ËˆtË uË | L | Â  | Â  | Â  | . leat | Lâ€²at | ËˆlÊ²atË  | L | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . spÃ¡d | ËˆsbÊ·É‘:d | ËˆsË pË aËdË  | L | Â  | Â  | Â  | . araist | É™ËˆraÊƒdâ€² | ËˆaÉ¾Ë É™ÊƒtÊ² | Â  | ar ais | Â  | Â  | . agus | ogÉ™s | ËˆagË É™sË  | L | Â  | Â  | Â  | . gÃ©arrfaidh | Ëˆgâ€²É‘:RhÉ™ | ËˆÉŸeËËˆÉ¾Ë eË | Â  | gearrfaidh | ËˆÉŸaÉ¾Ë iË | Â  | . tÃº | tu | ËˆtË uË | L | Â  | Â  | Â  | . le | lâ€²É› | ËˆlÊ²e | L | Â  | Â  | Â  | . Ã©adan | ËˆÉ›:dÉ‘n | ËˆeËdË É™É´Ë  | L | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . bhachtadh | ËˆwÉ‘xdu | ËˆwaÉ¾Ë tË uË | Â  | Â  | Â  | Â  | . ar | É›r | ËˆeÉ¾Ê² | L | Â  | Â  | Â  | . fhad | ËˆÉ‘d | ËˆadË  | L | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . bhachtadh | ËˆwÉ‘xdu | ËˆwaÉ¾Ë tË uË | Â  | Â  | Â  | Â  | . leis | Lâ€²eÊƒ | ËˆlÊ²iÊƒ | L | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . spÃ¡d | ËˆsbÉ‘:d | ËˆsË pË aËdË  | L | Â  | Â  | Â  | . TÃ¡ | tÉ‘: | ËˆtË aË | L | Â  | Â  | Â  | . tÃº | tu | ËˆtË uË | L | Â  | Â  | Â  | . ag | É™ | ËˆeÉŸ | L | Â  | Â  | Â  | . gabhÃ¡il | gÉ”lâ€² | ËˆgË olÊ² | L | Â  | Â  | Â  | . a | É™ | É™ | L | Â  | Â  | Â  | . gheÃ¡rradh | ËˆjÉ‘:Ru | ËˆjaËÉ¾Ë uË | Â  | ghearradh | Â  | Â  | . le | lâ€²É› | ËˆlÊ²e | L | Â  | Â  | Â  | . sleaghÃ¡n | ËˆÊƒLâ€²a:n | ËˆÊƒlÊ²aÉ£aËÉ´Ë  | Â  | sleÃ¡n | ËˆÊƒlÊ²aËÉ´Ë  | Â  | . mÃ¡ | mÉ‘ | ËˆmË a | L | Â  | Â  | Â  | . tÃ¡ | tÉ‘: | ËˆtË aË | L | Â  | Â  | Â  | . tÃº | tu | ËˆtË uË | L | Â  | Â  | Â  | . deasach | Ëˆdâ€²á¶¾asÉ‘x | ËˆdÊ²asË ah | L | Â  | Â  | Â  | . agus | É”gÉ™s | ËˆagË É™sË  | L | Â  | Â  | Â  | . ag | É™ | ËˆeÉŸ | L | Â  | Â  | Â  | . gabhÃ¡il | ËˆgÉ”lâ€² | ËˆgË olÊ² | L | Â  | Â  | Â  | . a | É™ | É™ | L | Â  | Â  | Â  | . chur | xoÌ¤r | ËˆxuÉ¾Ë  | L | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . mhÃ³in | Ëˆwo:nâ€² | ËˆwoËnÊ² | L+M | Â  | Â  | Â  | . ar | É›r | ËˆeÉ¾Ê² | L | Â  | Â  | Â  | . bruach | ËˆbryÉ™x | ËˆbË É¾Ë uah | L | Â  | Â  | Â  | . Caithfidh | ËˆkÉ‘ihi | ËˆkË ahjiË | L | Â  | Â  | Â  | . tÃº | tu | ËˆtË uË | L | Â  | Â  | Â  | . geÃ¡rradh | Ëˆgâ€²É‘:Ru | ËˆÉŸaËÉ¾Ë uË | Â  | gearradh | ËˆÉŸaÉ¾Ë uË | Â  | . leis | Lâ€²eÊƒ | ËˆlÊ²iÊƒ | L | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . spÃ¡d | ËˆsbÉ‘:d | ËˆsË pË aËdË  | L | Â  | Â  | Â  | . le | lâ€²Îµ | ËˆlÊ²e | L | Â  | Â  | Â  | . Ã©adan | Ëˆe:áµŠdÉ‘n | ËˆeËdË É™É´Ë  | L | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . bhachtadh | ËˆwÉ‘xdu | ËˆwaÉ¾Ë tË uË | Â  | Â  | Â  | Â  | . mar | moÌ¤r | ËˆmË aÉ¾Ë  | L | Â  | Â  | Â  | . go | gÉ” | ËˆgË É™ | L | Â  | Â  | Â  | . bhfuil | wÉªlâ€² | ËˆwilÊ² | L | Â  | Â  | Â  | . binn | Ëˆbâ€²Ã¯Nâ€² | ËˆbÊ²iÉ´Ê² | L | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . tsleaghÃ¡in | â€²tâ€²ÊƒLâ€²a:nâ€² | ËˆtÊ²lÊ²aÉ£aËnÊ² | Â  | tsleÃ¡in | ËˆtÊ²lÊ²aËnÊ² | Â  | . i | Â  | Ëˆi | L | Â  | Â  | Â  | . dtÃ³lamh | ËˆdÉ”:luw | ËˆdË oËÊŸË uË | L+M | Â  | Â  | Â  | . ag | É™ | ËˆeÉŸ | L | Â  | Â  | Â  | . fÃ¡gÃ¡il | ËˆfÉ‘:gÉ‘lâ€² | ËˆfË aËgË alÊ² | L | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . bhachtadh | ËˆwÉ‘xdu | ËˆwaÉ¾Ë tË uË | Â  | Â  | Â  | Â  | . nuair | NuÉ™râ€² | ËˆÉ´Ë uËÉ¾Ê² | L | Â  | Â  | Â  | . atÃ¡ | É™tÉ‘: | É™ËˆtË aË | L | Â  | Â  | Â  | . tusa | ËˆtÃ¶sÉ™ | ËˆtË usË É™ | L | Â  | Â  | Â  | . ag | É™ | ËˆeÉŸ | L | Â  | Â  | Â  | . cur | koÌ¤r | ËˆkË uÉ¾Ë  | L | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . mhÃ³in | Ëˆwo:nâ€² | ËˆwoËnÊ² | L+M | Â  | Â  | Â  | . ar | Îµr | ËˆeÉ¾Ê² | L | Â  | Â  | Â  | . bruach | Ëˆbri:x | ËˆbË É¾Ë uah | L | Â  | Â  | Â  | . Ach | É‘x | Ëˆah | L | Â  | Â  | Â  | . tÃ¡ | tÉ‘: | ËˆtË aË | L | Â  | Â  | Â  | . Ã¡iteacha | Ëˆa:Nâ€²tâ€²axÉ™ | ËˆaËtÊ²É™hÉ™ | Â  | Ã¡iteanna | ËˆaËtÊ²É™É´Ë É™ | Â  | . agus | É”gÉ™s | ËˆagË É™sË  | L | Â  | Â  | Â  | . nÃ­ | Nâ€²i: | ËˆÉ´Ê²iË | L | Â  | Â  | Â  | . h-Ã© | hÃ¨ | ËˆheË | L+M | Â  | Â  | Â  | . sin | ËˆÊƒÉªnâ€² | ËˆÊƒinÊ² | L | Â  | Â  | Â  | . marâ€™s | moÌ¤Å™Å¡ | Ëˆm_ea_er_ez_e | L | Â  | Â  | Â  | . geÃ¡rraidh | Ëˆgâ€²É‘:Ri | ËˆÉŸaËÉ¾Ë iË | Â  | gearra | ËˆÉŸaÉ¾Ë É™ | Â  | . siad | ÊƒÉ™d | ËˆÊƒiËdË  | L | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . mhÃ³in | Ëˆwo:nâ€² | ËˆwoËnÊ² | L+M | Â  | Â  | Â  | . ar | É™ | ËˆeÉ¾Ê² | L | Â  | Â  | Â  | . chor | xÉ”r | ËˆxaÉ¾Ë  | L | Â  | Â  | Â  | . ar | É™ | ËˆeÉ¾Ê² | L | Â  | Â  | Â  | . bith | Ëˆbâ€²i | ËˆbÊ²iË | L | Â  | Â  | Â  | . sÃ­os | Êƒi:s | ËˆÊƒiËsË  | L | Â  | Â  | Â  | . i | Â  | Ëˆi | L | Â  | Â  | Â  | . gConnadae | ËˆgoÌ¤Ndei | ËˆgË oÉ´Ë É™dË eË | Â  | gContae | ËˆgË É™É´Ë ËˆtË e | Â  | . na | NÉ™ | ËˆÉ´Ë É™ | L | Â  | Â  | Â  | . Midhe | Ëˆmâ€²i:É™ | ËˆmÊ²iËÉ™ | Â  | MÃ­ | ËˆmÊ²iË | Â  | . agus | É”gÉ™s | ËˆagË É™sË  | L | Â  | Â  | Â  | . na | NÉ™ | ËˆÉ´Ë É™ | L | Â  | Â  | Â  | . h-Ã¡iteacha | Ëˆha:Nâ€²tâ€²ahÉ™ | ËˆhaËtÊ²É™hÉ™ | h-Ã¡iteacha | Â  | Â  | Â  | . sin | ËˆÊƒÉªnâ€² | ËˆÊƒinÊ² | L | Â  | Â  | Â  | . Ach | É‘x | Ëˆah | L | Â  | Â  | Â  | . seo | ÊƒÉ” | ËˆÊƒo | L | Â  | Â  | Â  | . marâ€™s | moÌ¤Å™Å¡ | Ëˆm_ea_er_ez_e | L | Â  | Â  | Â  | . geÃ¡rraidh | Ëˆgâ€²É‘:Ri | ËˆÉŸaËÉ¾Ë iË | Â  | gearra | ËˆÉŸaÉ¾Ë É™ | Â  | . siad | ÊƒÉ™d | ËˆÊƒiËdË  | L | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . mhÃ³in | Ëˆwo:nâ€² | ËˆwoËnÊ² | L+M | Â  | Â  | Â  | . insa | nÌ¥sÉ™ | ËˆinÊ²ËˆsË É™ | Â  | sa | ËˆsË É™ | Â  | . tÃ­r | Ëˆtâ€²á¶´i:râ€² | ËˆtÊ²iËÉ¾Ê² | L | Â  | Â  | Â  | . seo | ÊƒÉ” | ËˆÊƒo | L | Â  | Â  | Â  | . Tosochaidh | ËˆtÉ”sahÉ™ | ËˆtË osË É™hiË | Â  | TosÃ³idh | ËˆtË osË É”j | Â  | . tÃº | tu | ËˆtË uË | L | Â  | Â  | Â  | . a | Â  | É™ | L | Â  | Â  | Â  | . gheÃ¡rradh | ËˆjÉ‘:Ru | ËˆjaËÉ¾Ë uË | Â  | ghearradh | ËˆjaÉ¾Ë uË | Â  | . agus | É”gÉ™s | ËˆagË É™sË  | L | Â  | Â  | Â  | . nÃ­l | ËˆNâ€²i:lâ€² | ËˆÉ´Ê²iËlÊ² | L | Â  | Â  | Â  | . tÃº | tu | ËˆtË uË | L | Â  | Â  | Â  | . ag | É™ | ËˆeÉŸ | L | Â  | Â  | Â  | . cailleadh | ËˆkaLâ€²Lâ€²u | ËˆkË aÊŸÊ²uË | L | Â  | Â  | Â  | . aon | e:ËˆN | ËˆeËÉ´Ë  | L | Â  | Â  | Â  | . fhÃ³d | o:d | ËˆoËdË  | L+M | Â  | Â  | Â  | . tÃ¡ | tÉ‘: | ËˆtË aË | L | Â  | Â  | Â  | . tÃº | tu | ËˆtË uË | L | Â  | Â  | Â  | . ag | É™ | ËˆeÉŸ | L | Â  | Â  | Â  | . cur | koÌ¤r | ËˆkË uÉ¾Ë  | L | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . uile | ËˆNÉªlâ€²É™ | ËˆilÊ²É™ | L | Â  | Â  | Â  | . cheann | Ëˆxâ€²oÌ¤N | ËˆÃ§iÉ´Ë  | L | Â  | Â  | Â  | . isteach | É™â€²Êƒdâ€²ax | iÊƒËˆtÊ²ah | L | Â  | Â  | Â  | . ar | É›r | ËˆeÉ¾Ê² | L | Â  | Â  | Â  | . bruach | Ëˆbri:x | ËˆbË É¾Ë uah | L | Â  | Â  | Â  | . Agus | É”gÉ™s | ËˆagË É™sË  | L | Â  | Â  | Â  | . nuair | NuÉ™râ€² | ËˆÉ´Ë uËÉ¾Ê² | L | Â  | Â  | Â  | . atÃ¡ | É™tÉ‘: | É™ËˆtË aË | L | Â  | Â  | Â  | . an | n | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . fÃ³d | Ëˆfo:d | ËˆfË oËdË  | L | Â  | Â  | Â  | . sin | ÊƒÉªnâ€² | ËˆÊƒinÊ² | L | Â  | Â  | Â  | . geÃ¡rrtha | Ëˆgâ€²É‘:Rh | ËˆÉŸaËÉ¾Ë hÉ™ | Â  | gearrtha | ËˆÉŸaËÉ¾Ë Ëˆha | Â  | . agat | É›it | ËˆÉ™gË É™tË  | L | Â  | Â  | Â  | . geÃ¡rrfaidh | Ëˆgâ€²É‘:RhÉ™ | ËˆÉŸaËÉ¾Ë iË | Â  | gearrfaidh | ËˆÉŸaÉ¾Ë iË | Â  | . tÃº | tu | ËˆtË uË | L | Â  | Â  | Â  | . an | nÌ¥ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . dara | ËˆdÉ‘rÉ™ | ËˆdË aÉ¾Ë É™ | L | Â  | Â  | Â  | . fÃ³d | Ëˆfo:d | ËˆfË oËdË  | L | Â  | Â  | Â  | . ar | É›r | ËˆeÉ¾Ê² | L | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . dÃ³igh | dÉ”:i | ËˆdË oËj | L | Â  | Â  | Â  | . chiadhna | Ëˆxâ€²iÉ™NÉ™ | ËˆÃ§iÉ™É£É´Ë É™ | Â  | chÃ©anna | ËˆÃ§eËÉ¾Ë É´Ë É™ | Â  | . Well | wÉ›Lâ€² | ËˆweÊŸÊ² | Â  | Â  | Â  | Â  | . mÃ¡ | mÉ‘ | ËˆmË a | L | Â  | Â  | Â  | . tÃ¡ | tÉ‘: | ËˆtË aË | L | Â  | Â  | Â  | . bachtadh | ËˆbÉ‘xdu | ËˆbË aÉ¾Ë tË uË | Â  | bachta | ËˆbË aÉ¾Ë tË É™ | Â  | . mÃ³r | Ëˆmo:r | ËˆmË oËÉ¾Ë  | L | Â  | Â  | Â  | . agat | Ã¨it | ËˆÉ™gË É™tË  | L | Â  | Â  | Â  | . fÃ¡ | fÉ‘ | ËˆfË aË | L | Â  | Â  | Â  | . dhÃ©in | Ëˆje:nâ€² | ËˆjeËnÊ² | L+M | Â  | Â  | Â  | . a | Â  | É™ | L | Â  | Â  | Â  | . dtig | Ëˆdâ€²á¶¾Éªgâ€² | ËˆdÊ²iÉŸ | L | Â  | Â  | Â  | . leat | ËˆLâ€²at | ËˆlÊ²atË  | L | Â  | Â  | Â  | . mÃ³in | mo:nâ€² | ËˆmË oËnÊ² | L | Â  | Â  | Â  | . a | É™ | É™ | L | Â  | Â  | Â  | . rannadh | ËˆrÉ‘Nhu | ËˆÉ¾Ë aÉ´Ë uË | Â  | roinnt | ËˆÉ¾Ë oÉ´Ê²tÊ² | Â  | . air | Ã¨râ€² | ËˆeÉ¾Ê² | L | Â  | Â  | Â  | . Anois | NÉªÊƒ | É™ËˆÉ´Ë iÊƒ | L | Â  | Â  | Â  | . tionntochaidh | Ëˆtâ€²á¶´oÌ¤NtahÉ™ | ËˆtÊ²iÉ´Ë tË É™hiË | Â  | tiontÃ³idh | ËˆtÊ²iÉ´Ë tË É”j | Â  | . tÃº | tu | ËˆtË uË | L | Â  | Â  | Â  | . ar | É›r | ËˆeÉ¾Ê² | L | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . bhachtadh | ËˆwÉ‘xdu | ËˆwaÉ¾Ë tË uË | Â  | bhachta | Â  | Â  | . agus | É”gÉ™s | ËˆagË É™sË  | L | Â  | Â  | Â  | . bhÃ©arfaidh | vÉ›rhÉ™ | ËˆvÊ²eËÉ¾Ë hiË | L | Â  | Â  | Â  | . tÃº | tu | ËˆtË uË | L | Â  | Â  | Â  | . an | nÌ¥ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . bhinn | ËˆÎ½Ã¯Îâ€² | ËˆvÊ²iÉ´Ê² | L | Â  | Â  | Â  | . le | lâ€²Îµ | ËˆlÊ²e | L | Â  | Â  | Â  | . Ã©adan | ËˆÉ›:áµŠdÉ‘n | ËˆeËdË É™É´Ë  | L | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . bhachtadh | ËˆwÉ‘xdu | ËˆwaÉ¾Ë tË uË | Â  | bhachta | Â  | Â  | . Agus | É”gÉ™s | ËˆagË É™sË  | L | Â  | Â  | Â  | . rachaidh | rÉ‘hÉ™ | ËˆÉ¾Ë aËhij | L | Â  | Â  | Â  | . tÃº | tu | ËˆtË uË | L | Â  | Â  | Â  | . a | É™ | É™ | L | Â  | Â  | Â  | . chaitheamh | ËˆxÉ‘hu | ËˆxahjuË | L | Â  | Â  | Â  | . amach | É™ËˆmÉ‘h | É™ËˆmË ah | L | Â  | Â  | Â  | . as | Ã¯s | ËˆasË  | L | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . bhachtadh | ËˆwÉ‘xdu | ËˆwaÉ¾Ë tË uË | Â  | bhachta | Â  | Â  | . nÃ¡ | nÉ‘: | ËˆÉ´Ë aË | L | Â  | Â  | Â  | . go | gÉ” | ËˆgË É™ | L | Â  | Â  | Â  | . rabh | ro | ËˆÉ¾Ë au | Â  | raibh | ËˆÉ¾Ë oËw | Â  | . an | nÌ¥ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . bachtadh | ËˆbÉ‘xdu | ËˆbË aÉ¾Ë tË uË | Â  | bachta | ËˆbË aÉ¾Ë tË É™ | Â  | . geÃ¡rrtha | Ëˆgâ€²É‘:RhÉ™ | ËˆÉŸaËÉ¾Ë hÉ™ | Â  | gearrtha | ËˆÉŸaËÉ¾Ë Ëˆha | Â  | . Nuair | NuÉ™râ€² | ËˆÉ´Ë uËÉ¾Ê² | L | Â  | Â  | Â  | . atÃ¡ | É™tÉ‘: | É™ËˆtË aË | L | Â  | Â  | Â  | . an | nÌ¥ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . bachtadh | ËˆbÉ‘xdu | ËˆbË aÉ¾Ë tË uË | Â  | bachta | ËˆbË aÉ¾Ë tË É™ | Â  | . geÃ¡rrtha | Ëˆgâ€²É‘:RhÉ™ | ËˆÉŸaËÉ¾Ë hÉ™ | Â  | gearrtha | ËˆÉŸaËÉ¾Ë Ëˆha | Â  | . annsin | nÌ¥ËˆÊƒÉªnâ€² | ËˆaËˆÉ´Ê²ÊƒinÊ² | Â  | ansin | Â  | Â  | . agat | Ã¨it | ËˆÉ™gË É™tË  | L | Â  | Â  | Â  | . bhÃ©arfaidh | vÉ›rhÉ™ | ËˆvÊ²eËÉ¾Ë hiË | L | Â  | Â  | Â  | . tÃº | tu | ËˆtË uË | L | Â  | Â  | Â  | . leat | Lâ€²at | ËˆlÊ²atË  | L | Â  | Â  | Â  | . bascÃ³id | ËˆbÉ‘sgÉ”dâ€²á¶¾ | ËˆbË asË kË É”dÊ² | Â  | bascaed | ËˆbË asË kË edË  | Â  | . nÃ¡ | nÉ‘: | ËˆÉ´Ë aË | L | Â  | Â  | Â  | . tÃ¡ | tÉ‘: | ËˆtË aË | L | Â  | Â  | Â  | . rud | roÌ¤D | ËˆÉ¾Ë udË  | L | Â  | Â  | Â  | . againn | ËˆÎµiÎâ€² | ËˆÉ™gË É™É´Ê² | L | Â  | Â  | Â  | . sa | sÉ™ | ËˆsË É™ | L | Â  | Â  | Â  | . tÃ­r | Ëˆtâ€²á¶´i:râ€² | ËˆtÊ²iËÉ¾Ê² | L | Â  | Â  | Â  | . seo | ÊƒÉ” | ËˆÊƒo | L | Â  | Â  | Â  | . a | É™ | É™ | L | Â  | Â  | Â  | . bhfuil | wÉªlâ€² | ËˆwilÊ² | L | Â  | Â  | Â  | . rotha | ËˆrÉ”h | ËˆÉ¾Ë ohÉ™ | Â  | Â  | Â  | Â  | . air | erâ€²Ê” | ËˆeÉ¾Ê² | L | Â  | Â  | Â  | . agus | É”gÉ™s | ËˆagË É™sË  | L | Â  | Â  | Â  | . dhÃ¡ | ËˆÉ£É‘: | ËˆÉ£aË | L | Â  | Â  | Â  | . lÃ¡mh | ËˆLÉ‘:w | ËˆÊŸË aËw | L | Â  | Â  | Â  | . amach | É™ËˆmÉ‘h | É™ËˆmË ah | L | Â  | Â  | Â  | . as | Ã¯s | ËˆasË  | L | Â  | Â  | Â  | . agus | É”gÉ™s | ËˆagË É™sË  | L | Â  | Â  | Â  | . bocsa | ËˆboÌ¤ks | ËˆbË okË sË É™ | Â  | bosca | ËˆbË okË sË É™ | Â  | . air | É›râ€² | ËˆeÉ¾Ê² | L | Â  | Â  | Â  | . a | É™ | É™ | L | Â  | Â  | Â  | . chuireas | ËˆxoÌ¤râ€²É™s | ËˆxuÉ¾Ê²É™sË  | L | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . mhÃ³in | Ëˆwo:nâ€² | ËˆwoËnÊ² | L+M | Â  | Â  | Â  | . amach | É™ËˆmÉ‘x | É™ËˆmË ah | L | Â  | Â  | Â  | . Sin | ÊƒÉªnâ€² | ËˆÊƒinÊ² | L | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . dÃ³igh | ËˆdÉ”:i | ËˆdË oËj | L | Â  | Â  | Â  | . a | áµŠ | É™ | L | Â  | Â  | Â  | . ndÃ©antar | ËˆNâ€²a:NtÉ™r | ËˆnÊ²eËÉ´Ë tË É™É¾Ë  | L | Â  | Â  | Â  | . TÃ¡ | tÉ‘ | ËˆtË aË | L | Â  | Â  | Â  | . an | nÌ¥ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . bruach | Ëˆbri:x | ËˆbË É¾Ë uah | L | Â  | Â  | Â  | . mÃ³nadh | mo:nu | ËˆmË oËÉ´Ë uË | L | Â  | Â  | Â  | . sin | ËˆÊƒÉªnâ€² | ËˆÊƒinÊ² | L | Â  | Â  | Â  | . agat | É›it | ËˆÉ™gË É™tË  | L | Â  | Â  | Â  | . le | lâ€²Îµ | ËˆlÊ²e | L | Â  | Â  | Â  | . cur | ËˆkoÌ¤r | ËˆkË uÉ¾Ë  | L | Â  | Â  | Â  | . amach | É™Ëˆmax | É™ËˆmË ah | L | Â  | Â  | Â  | . agus | É”gÉ™s | ËˆagË É™sË  | L | Â  | Â  | Â  | . anois | É™ËˆnÉªÊƒ | É™ËˆÉ´Ë iÊƒ | L | Â  | Â  | Â  | . fÃ¡gfaidh | ËˆfÉ‘:khÉ™ | ËˆfË aËgË hÉ™ | L | Â  | Â  | Â  | . tÃº | tu | ËˆtË uË | L | Â  | Â  | Â  | . annsin | nÌ¥ËˆÊƒinâ€² | ËˆaËˆÉ´Ê²ÊƒinÊ² | Â  | ansin | É™É´Ë ËˆÊƒinÊ² | Â  | . Ã­ | i: | ËˆiË | L | Â  | Â  | Â  | . mar | moÌ¤r | ËˆmË aÉ¾Ë  | L | Â  | Â  | Â  | . atÃ¡ | ËˆtÉ‘: | É™ËˆtË aË | L | Â  | Â  | Â  | . sÃ­ | Êƒi: | ËˆÊƒiË | L | Â  | Â  | Â  | . nÃ³ | nÉ‘: | ËˆÉ´Ë oË | L | Â  | Â  | Â  | . go | gÉ” | ËˆgË É™ | L | Â  | Â  | Â  | . dtÃ­ | ËˆdÊ’â€²i: | ËˆdÊ²iË | L | Â  | Â  | Â  | . go | gÉ” | ËˆgË É™ | L | Â  | Â  | Â  | . dtig | Ëˆdâ€²Éªgâ€² | ËˆdÊ²iÉŸ | L | Â  | Â  | Â  | . grian | Ëˆgâ€²râ€²iÉ™n | ËˆÉŸÉ¾Ê²iaÉ´Ë  | L | Â  | Â  | Â  | . orthaÃ­ | É”rhi | ËˆoËÉ¾Ë hiË | Â  | uirthi | ËˆaÉ¾Ë hjiË | Â  | . i | É™ | Ëˆi | L | Â  | Â  | Â  | . mÃ­ | mâ€²i: | ËˆmÊ²iË | L | Â  | Â  | Â  | . na | NÉ™ | ËˆÉ´Ë É™ | L | Â  | Â  | Â  | . Bealtaine | Ëˆbâ€²a:LtÉªnâ€²É™ | ËˆbÊ²oÊŸË tË É™nÊ²É™ | L | Â  | Â  | Â  | . Agus | É”gÉ™s | ËˆagË É™sË  | L | Â  | Â  | Â  | . tÃ¡ | tÉ‘: | ËˆtË aË | L | Â  | Â  | Â  | . sÃ­ | Êƒi | ËˆÊƒiË | L | Â  | Â  | Â  | . caithte | ËˆkoÌ¤tâ€²á¶´É™ | ËˆkË ahtÊ²É™ | Â  | caite | ËˆkË atÊ²É™ | Â  | . ina | NÉ™ | ËˆiÉ´Ë É™ | L | Â  | Â  | Â  | . crapannaÃ­ | ËˆkrÉ‘pÉ™Ni | ËˆkË É¾Ë apË É™É´Ë iË | Â  | Â  | Â  | Â  | . agat | É›it | ËˆÉ™gË É™tË  | L | Â  | Â  | Â  | . go | gÉ” | ËˆgË É™ | L | Â  | Â  | Â  | . dtÃ­ | Ëˆdâ€²Ê’i: | ËˆdÊ²iË | L | Â  | Â  | Â  | . go | go | ËˆgË É™ | L | Â  | Â  | Â  | . bhfosclaidh | ËˆwÉ”sgli | ËˆwoËˆsË kË ÊŸË eË | Â  | bhfosclaÃ­ | ËˆwoËˆsË kË ÊŸË iË | Â  | . an | nÌ¥ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . ghrian | ËˆjáµŠrâ€²iÉ™n | ËˆÉ£É¾Ê²iaÉ´Ë  | L | Â  | Â  | Â  | . rud | roÌ¤D | ËˆÉ¾Ë udË  | L | Â  | Â  | Â  | . beag | Ëˆbâ€²Ã¸G | ËˆbÊ²ogË  | L | Â  | Â  | Â  | . agus | É”gÉ™s | ËˆagË É™sË  | L | Â  | Â  | Â  | . sprÃ©idhfidh | Ëˆsbâ€²râ€²e:fâ€²É™ | ËˆsË pÊ²É¾Ê²eËjiË | Â  | sprÃ©ifidh | ËˆsË pÊ²É¾Ê²eËiË | Â  | . tÃº | tu | ËˆtË uË | L | Â  | Â  | Â  | . le | lâ€²Îµ | ËˆlÊ²e | L | Â  | Â  | Â  | . do | dÉ” | ËˆdË É™ | L | Â  | Â  | Â  | . lÃ¡mha | ËˆLÉ‘:wÉ™ | ËˆÊŸË aËwÉ™ | L | Â  | Â  | Â  | . annsin | nÌ¥ËˆÊƒÉªnâ€² | ËˆaËˆÉ´Ê²ÊƒinÊ² | Â  | ansin | É™É´Ë ËˆÊƒinÊ² | Â  | . Ã­ | i: | ËˆiË | L | Â  | Â  | Â  | . FÃ¡gfaidh | ËˆfÉ‘:kÉ™ | ËˆfË aËgË hÉ™ | L | Â  | Â  | Â  | . tÃº | tuáµŠ | ËˆtË uË | L | Â  | Â  | Â  | . anois | ËˆnÉªÊƒ | É™ËˆÉ´Ë iÊƒ | L | Â  | Â  | Â  | . tamallt | tÉ‘mÉ™Lt | ËˆtË amË É™ÊŸË tË  | Â  | tamall | ËˆtË amË É™ÊŸË  | Â  | . eile | ËˆÉ›lâ€²i: | ËˆelÊ²É™ | L | Â  | Â  | Â  | . Ã­ | Â  | ËˆiË | L | Â  | Â  | Â  | . agus | É”gas | ËˆagË É™sË  | L | Â  | Â  | Â  | . nuair | NuÉ™râ€² | ËˆÉ´Ë uËÉ¾Ê² | L | Â  | Â  | Â  | . a | É™ | É™ | L | Â  | Â  | Â  | . thriomuigheann | Ëˆxâ€²râ€²oÌ¤mÊ·iÉ™N | ËˆrÌªÊ²imË É™jÉ™É´Ë  | Â  | thriomaÃ­onn | ËˆrÌªÊ²imË iÉ™É´Ë  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . uair | ËˆNuÉ™râ€² | ËˆuaÉ¾Ê² | L | Â  | Â  | Â  | . suas | ÊƒuÉ™s | ËˆsË uasË  | L | Â  | Â  | Â  | . faoi | fÊ·i | ËˆfË iË | L | Â  | Â  | Â  | . chionn | xâ€²oÌ¤N | ËˆÃ§iÉ´Ë  | L+M | Â  | Â  | Â  | . seachtmhaine | ËˆÊƒaxdÉªnâ€²É™ | ËˆÊƒaÉ¾Ë tË wÉ™nÊ²É™ | Â  | seachtaine | ËˆÊƒaÉ¾Ë tË É™nÊ²É™ | Â  | . nÃ¡ | nÉ‘: | ËˆÉ´Ë aË | L | Â  | Â  | Â  | . mar | moÌ¤r | ËˆmË aÉ¾Ë  | L | Â  | Â  | Â  | . sin | ËˆÊƒÉªnâ€² | ËˆÊƒinÊ² | L | Â  | Â  | Â  | . rachaidh | rÉ‘hÉ™ | ËˆÉ¾Ë aËhij | L | Â  | Â  | Â  | . tÃº | tu | ËˆtË uË | L | Â  | Â  | Â  | . fhad | É‘d | ËˆadË  | L | Â  | Â  | Â  | . lÃ©ithe | Lâ€²É›:hÉ™ | ËˆlÊ²eËhjÉ™ | L | Â  | Â  | Â  | . arais | É™ËˆraÊƒ | ËˆaÉ¾Ë É™Êƒ | Â  | ar ais | ËˆeÉ¾Ê² ËˆaÊƒ | Â  | . agus | É”gÉ™s | ËˆagË É™sË  | L | Â  | Â  | Â  | . crÃ³igfidh | ËˆkrÉ”:áµŠkâ€²É™ | ËˆkË É¾Ë oËÉŸiË | Â  | grÃ³igfidh | ËˆgË É¾Ë oËÉŸiË | Â  | . tÃº | tu | ËˆtË uË | L | Â  | Â  | Â  | . Ã­ | i: | ËˆiË | L | Â  | Â  | Â  | . FÃ¡gfaidh | ËˆfÉ‘:kÉ™ | ËˆfË aËgË hÉ™ | L | Â  | Â  | Â  | . tÃº | tu | ËˆtË uË | L | Â  | Â  | Â  | . ins | nÌ¥s | ËˆinÊ²Êƒ | Â  | sa | ËˆsË É™ | Â  | . na | NÉ™ | ËˆÉ´Ë É™ | L | Â  | Â  | Â  | . crÃ³igeÃ¡in | ËˆkrÉ”:áµŠgâ€²É™nâ€² | ËˆkË É¾Ë oËÉŸaËnÊ² | Â  | grÃ³igeÃ¡in | ËˆgË É¾Ë oËÉŸaËnÊ² | Â  | . anois | É™ËˆnÉªÊƒ | É™ËˆÉ´Ë iÊƒ | L | Â  | Â  | Â  | . Ã­ | i: | ËˆiË | L | Â  | Â  | Â  | . tamallt | tÉ‘mÉ™Lt | ËˆtË amË É™ÊŸË tË  | Â  | tamall | ËˆtË amË É™ÊŸË  | Â  | . eile | Îµlâ€²É™ | ËˆelÊ²É™ | L | Â  | Â  | Â  | . agus | É”gÉ™s | ËˆagË É™sË  | L | Â  | Â  | Â  | . dhÃ©anfaidh | ja:nhÉ™ | ËˆÉ£eËÉ´Ë hiË | L | Â  | Â  | Â  | . tÃº | tu | ËˆtË uË | L | Â  | Â  | Â  | . anois | É™ËˆnÉªÊƒ | É™ËˆÉ´Ë iÊƒ | L | Â  | Â  | Â  | . clampaÃ­ | ËˆklÉ‘mbi | ËˆkË ÊŸË amË pË iË | Â  | Â  | Â  | Â  | . daoithe | dihÉ™ | ËˆdË iËhÉ™ | Â  | di | ËˆdË i | Â  | . Nuair | NuÉ™râ€² | ËˆÉ´Ë uËÉ¾Ê² | L | Â  | Â  | Â  | . atÃ¡ | É™ | É™ËˆtË aË | L | Â  | Â  | Â  | . sÃ­ | tÉ‘:Êƒi: | ËˆÊƒiË | L | Â  | Â  | Â  | . ins | nÌ¥s | ËˆinÊ²Êƒ | Â  | sa | ËˆsË É™ | Â  | . na | NÉ™ | ËˆÉ´Ë É™ | L | Â  | Â  | Â  | . clampaÃ­ | ËˆklÉ‘mbi | ËˆkË ÊŸË amË pË iË | Â  | Â  | Â  | Â  | . tamallt | tÉ‘mÉ™Lt | ËˆtË amË É™ÊŸË tË  | Â  | tamall | ËˆtË amË É™ÊŸË  | Â  | . agat | Ã¨it | ËˆÉ™gË É™tË  | L | Â  | Â  | Â  | . Ã¡ | a | aË | L | Â  | Â  | Â  | . rÃ©ir | Ëˆrâ€²e: | ËˆÉ¾Ë eËÉ¾Ê² | L | Â  | Â  | Â  | . sin | ÊƒÉªnâ€² | ËˆÊƒinÊ² | L | Â  | Â  | Â  | . marâ€™s | mÉ™s | ËˆmË aÉ¾Ë sË  | L | Â  | Â  | Â  | . tÃ¡ | tÉ‘: | ËˆtË aË | L | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . uair | ËˆNuÉ™râ€² | ËˆuaÉ¾Ê² | L | Â  | Â  | Â  | . briste | Ëˆbâ€²râ€²Ã¯Êƒdâ€²É™ | ËˆbÊ²É¾Ê²iÊƒtÊ²É™ | L | Â  | Â  | Â  | . caithfidh | kaihÉª | ËˆkË ahjiË | L | Â  | Â  | Â  | . tÃº | tu | ËˆtË uË | L | Â  | Â  | Â  | . riclÃ­nÃ­ | ËˆrÃ¯kâ€²lâ€²i:nâ€²i | ËˆÉ¾Ë iclÊ²iËnÊ²iË | Â  | Â  | Â  | Â  | . a | É™ | É™ | L | Â  | Â  | Â  | . dhÃ©anamh | Ëˆja:nu | ËˆjeËÉ´Ë uË | L | Â  | Â  | Â  | . daoithe | di:Ê°É™ | ËˆdË iËhÉ™ | Â  | di | ËˆdË i | Â  | . Ach | É‘x | Ëˆah | L | Â  | Â  | Â  | . mÃ¡ | mÉ‘ | ËˆmË a | L | Â  | Â  | Â  | . tÃ¡ | tÉ‘: | ËˆtË aË | L | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . uair | NuÉ™râ€² | ËˆuaÉ¾Ê² | L | Â  | Â  | Â  | . maith | ËˆmÉ‘i | ËˆmË ahj | L | Â  | Â  | Â  | . triomochaidh | Ëˆtâ€²á¶´râ€²Ã¯mÉ‘hÉ™ | ËˆtÊ²É¾Ê²imË É™hiË | Â  | triomÃ³idh | ËˆtÊ²É¾Ê²imË É”j | Â  | . sÃ­ | Êƒi: | ËˆÊƒiË | L | Â  | Â  | Â  | . ins | nÌ¥s | ËˆinÊ²Êƒ | Â  | sa | ËˆsË É™ | Â  | . na | NÉ™ | ËˆÉ´Ë É™ | L | Â  | Â  | Â  | . clampaÃ­ | ËˆklÉ‘mbi | ËˆkË ÊŸË amË pË iË | Â  | Â  | Â  | Â  | . go | gÉ™ | ËˆgË É™ | L | Â  | Â  | Â  | . gcruachaidh | ËˆgruÉ™xÉ™ | ËˆgË É¾Ë uÉ™ËˆxeË | Â  | gcruacha | ËˆgË É¾Ë uÉ™Ëˆxa | Â  | . tÃº | tu | ËˆtË uË | L | Â  | Â  | Â  | . Ã­ | i: | ËˆiË | L | Â  | Â  | Â  | . Nuair | NuÉ™râ€² | ËˆÉ´Ë uËÉ¾Ê² | L | Â  | Â  | Â  | . atÃ¡ | É™tÉ‘: | É™ËˆtË aË | L | Â  | Â  | Â  | . sÃ­ | Êƒi: | ËˆÊƒiË | L | Â  | Â  | Â  | . cruachta | ËˆkruÉ™xdÉ™ | ËˆkË É¾Ë uÉ™ËˆÉ¾Ë tË a | Â  | Â  | Â  | Â  | . annsin | nÌ¥ËˆÊƒÉªnâ€² | ËˆaËˆÉ´Ê²ÊƒinÊ² | Â  | Â  | Â  | Â  | . agat | É›jÉ™d | ËˆÉ™gË É™tË  | L | Â  | Â  | Â  | . fÃ¡gfaidh | ËˆfÉ‘:kÉ™ | ËˆfË aËgË hÉ™ | L | Â  | Â  | Â  | . tÃº | tu | ËˆtË uË | L | Â  | Â  | Â  | . ins | nÌ¥s | ËˆinÊ²Êƒ | Â  | Â  | Â  | Â  | . na | NÉ™ | ËˆÉ´Ë É™ | L | Â  | Â  | Â  | . cruacha | ËˆkruÉ™x | ËˆkË É¾Ë uÉ™Ëˆxa | Â  | Â  | Â  | Â  | . Ã­ | i: | ËˆiË | L | Â  | Â  | Â  | . go | gÉ” | ËˆgË É™ | L | Â  | Â  | Â  | . stÃ¡luighidh | ËˆsdÉ‘:li | ËˆsË tË aËÊŸË É™jiË | Â  | stÃ¡laÃ­ | ËˆsË tË aËÊŸË iË | Â  | . sÃ­ | Êƒi: | ËˆÊƒiË | L | Â  | Â  | Â  | . Agus | É”gÉ™s | ËˆagË É™sË  | L | Â  | Â  | Â  | . tÃ¡ | ËˆtÉ‘: | ËˆtË aË | L | Â  | Â  | Â  | . sÃ­ | Êƒi: | ËˆÊƒiË | L | Â  | Â  | Â  | . agat | Ã¨it | ËˆÉ™gË É™tË  | L | Â  | Â  | Â  | . sÃ¡bhÃ¡ilte | ËˆsÉ‘:wÉ‘Lâ€²tâ€²á¶´É™ | ËˆsË aËwaÊŸÊ²tÊ²É™ | L | Â  | Â  | Â  | . annsin | nÌ¥ËˆÊƒÉªnâ€² | ËˆaËˆÉ´Ê²ÊƒinÊ² | Â  | Â  | Â  | Â  | . Oâ€™Neill, John E. â€œIrish Texts from South West Donegal.â€ Zeitschrift FÃ¼r Celtische Philologie, vol. 33, 1974, doi:10.1515/zcph.1974.33.1.285.Â &#8617; . |",
            "url": "https://jimregan.github.io/notes/irish/donegal/2021/01/25/irish-texts-from-south-west-donegal-text-2-an-mhoin.html",
            "relUrl": "/irish/donegal/2021/01/25/irish-texts-from-south-west-donegal-text-2-an-mhoin.html",
            "date": " â€¢ Jan 25, 2021"
        }
        
    
  
    
        ,"post209": {
            "title": "Irish Texts from South West Donegal. PoitÃ­n.",
            "content": "The table below compares the transcription of Text 1: â€œPoitÃ­nâ€ from Oâ€™Neillâ€™s1 â€œIrish Texts from South West Donegalâ€, comparing it with Abairâ€™s transcription. . Texts 1â€”4 were contributed by Seamus Ã“ Beirn (Jim Phat James), aged c. 70 years, cobbler, from the townland of MÃ­n na Gaoithe, Teelin. . A special feature of his speech is the clearness and strength of the affricates tâ€²Êƒ and dâ€²Ê’ due to the deliberate manner in which each word is enunciated. . The phonetic rules were mostly to help with automatic comparison, though the places where verb froms were pronounced differently before a pronoun was interesting enough to note. . Original Transcript Abair G2P Abair source Adjusted word (standardised) Adjusted Abair Rule . An | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . dtiocfadh | dâ€²á¶¾oÌ¤ku | ËˆdÊ²okË uË | L | Â  | Â  | Â  | . leat | Lâ€²at | ËˆlÊ²atË  | L | Â  | Â  | Â  | . innse | iÌˆÎâ€²ÊƒÉ™ | ËˆiËˆÉ´Ê²Êƒe | Â  | insint | ËŒinÊ²ËˆÊƒinÊ²tÊ² | Â  | . domh | du | ËˆdË uË | L | Â  | Â  | Â  | . goidÃ© | gÉ™Ëˆdâ€²á¶¾e: | ËˆgË É™dÊ²eË | L | Â  | Â  | Â  | . n | nÌ¥ | nË  | L | Â  | Â  | Â  | . dÃ³igh | dÉ”:i | ËˆdË oËj | L | Â  | Â  | Â  | . a | É™ | É™ | L | Â  | Â  | Â  | . ndÃ©antar | Nâ€²a:NtÉ‘r | ËˆnÊ²eËÉ´Ë tË É™É¾Ë  | L | Â  | Â  | Â  | . poitÃ­n | ËˆpÉ”tâ€²inâ€² | ËˆpË otÊ²inÊ² | L | Â  | Â  | Â  | . Well | wÉ›Lâ€² | ËˆweÊŸÊ² | Â  | Â  | Â  | Â  | . sÃ© | ÊƒÎµ | ËˆÊƒeË | L | Â  | Â  | Â  | . a | Â  | É™ | L | Â  | Â  | É™ â†’ âˆ… / V # _ | . bhfuil | Ëˆwilâ€² | ËˆwilÊ² | L | Â  | Â  | Â  | . fhios | iÌˆs | ËˆisË  | L | Â  | Â  | Â  | . agamsa | Ã¨imsÉ™ | ËˆÉ™gË É™mË sË É™ | L | Â  | Â  | Â  | . fÃ¡ | fÉ‘ | ËˆfË aË | L | Â  | Â  | Â  | . dtaobh | du: | ËˆdÊ²iËw | L | Â  | Â  | Â  | . den | dÉ”n | ËˆdË enË  | L | Â  | Â  | Â  | . phoitÃ­n | Ëˆfotâ€²inâ€² | ËˆfË otÊ²inÊ² | L+M | Â  | Â  | Â  | . fad | fÉ‘d | ËˆfË adË  | L | Â  | Â  | Â  | . Ã³ | É” | ËˆoË | L | Â  | Â  | Â  | . shoin | xÉªnâ€² | ËˆhoËˆinÊ² | Â  | shin | ËˆhinÊ² | Â  | . nuair | NuÉ™râ€² | ËˆÉ´Ë uËÉ¾Ê² | L | Â  | Â  | Â  | . a | É™ | É™ | L | Â  | Â  | Â  | . nÃ­odh | ËˆNâ€²i:wÉ™dâ€² | ËˆnÊ²iËuË | L | Â  | Â  | &lt;odh&gt; â†’ É™dÊ² / _ # PRONOUN | . siad | ÊƒÉ™d | ËˆÊƒiËdË  | L | Â  | Â  | Â  | . as | iÌˆs | ËˆasË  | L | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . eÃ³rna | ËˆNâ€²É”:rN | ËˆoËÉ¾Ë É´Ë É™ | Â  | eorna | ËˆoËÉ¾Ë É´Ë É™ | É™ â†’ âˆ… / _ # V | . Ã­ | i: | ËˆiË | L | Â  | Â  | Â  | . Nuair | NuÉ™râ€² | ËˆÉ´Ë uËÉ¾Ê² | L | Â  | Â  | Â  | . a | É™ | É™ | L | Â  | Â  | Â  | . bhÃ©adh | vÉ›uw | ËˆvÊ²eËÉ£ | Â  | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . eÃ³rna | ËˆNâ€²É”:rNÉ™ | ËˆoËÉ¾Ë É´Ë É™ | Â  | Â  | Â  | Â  | . sÃ¡bhÃ¡ilte | ËˆsÉ‘:wÉ‘Lâ€²tâ€² | ËˆsË aËwaÊŸÊ²tÊ²É™ | L | Â  | Â  | Â  | . acÃº | É”ku | ËˆakË uË | Â  | Â  | Â  | Â  | . cÃ¡ithte | Ëˆka:tâ€²ÊƒÉ™ | ËˆkË aËhtÊ²É™ | Â  | cÃ¡ite | kË aËtÊ²É™ | Â  | . astoigh | É™ËˆsdihÊ” | ËˆasË tË É™ | Â  | istigh | isË ËˆtË ij | Â  | . ina | É™ÎÉ™ | ËˆiÉ´Ë É™ | L | Â  | Â  | Â  | . mÃ¡la | ËˆmÉ‘:lÉ™ | ËˆmË aËÊŸË É™ | L | Â  | Â  | Â  | . bheireadh | vÉ›râ€²É™dâ€² | ËˆvÊ²eÉ¾Ê²uË | L | Â  | Â  | &lt;eadh&gt; â†’ É™dÊ² / _ # PRONOUN | . siad | ÊƒÉ™d | ËˆÊƒiËdË  | L | Â  | Â  | Â  | . leÃ³fa | Lâ€²É”:fÉ™ | ËˆÊŸÊ²oËfË É™ | Â  | leo | ËˆlÊ²o | Â  | . tuairim | tuÉ™râ€²Éªmâ€² | ËˆtË uaÉ¾Ê²imÊ² | L | Â  | Â  | Â  | . ar | É™r | ËˆeÉ¾Ê² | L | Â  | Â  | Â  | . ocht | É”xd | ËˆaxtË  | L | Â  | Â  | Â  | . gclocha | gloÌ¤hÉ™ | ËˆgË ÊŸË ahÉ™ | L+M | Â  | Â  | Â  | . den | dÉ” | ËˆdË enË  | L | Â  | Â  | Â  | . eÃ³rna | ËˆNâ€²É”:rNÉ™ | ËˆoËÉ¾Ë É´Ë É™ | Â  | eorna | ËˆoËÉ¾Ë É´Ë É™ | Â  | . sin | ÊƒÉªnâ€² | ËˆÊƒinÊ² | L | Â  | Â  | Â  | . agus | É”gÉ™s | ËˆagË É™sË  | L | Â  | Â  | Â  | . chuireadh | xoÌ¤râ€²É™dâ€² | ËˆxuÉ¾Ê²uË | L | Â  | Â  | &lt;eadh&gt; â†’ É™dÊ² / _ # PRONOUN | . siad | ÊƒÉ™d | ËˆÊƒiËdË  | L | Â  | Â  | Â  | . isteach | É™ËˆÊƒdâ€²ax | iÊƒËˆtÊ²ah | L | Â  | Â  | Â  | . ina | É™ÎÉ™ | ËˆiÉ´Ë É™ | L | Â  | Â  | Â  | . ndam | ËˆNÉ‘MÊ· | ËˆÉ´Ë amË  | Â  | ndamba | ËˆÉ´Ë amË bË É™ | Â  | . Ã­ | i: | ËˆiË | L | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . rud | roÌ¤D | ËˆÉ¾Ë udË  | L | Â  | Â  | Â  | . a | É™ | É™ | L | Â  | Â  | Â  | . dtugadh | doÌ¤gÉ™dâ€² | ËˆdË ugË uË | L+M | Â  | Â  | &lt;adh&gt; â†’ É™dÊ² / _ # PRONOUN | . siad | ÊƒÉ™d | ËˆÊƒiËdË  | L | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . bachtadh | ËˆbÉ‘xdu | ËˆbË aÉ¾Ë tË uË | Â  | bachta | ËˆbË aÉ¾Ë tË É™ | Â  | . air | É›râ€² | ËˆeÉ¾Ê² | L | Â  | Â  | Â  | . Nuair | NuÉ™râ€² | ËˆÉ´Ë uËÉ¾Ê² | L | Â  | Â  | Â  | . a | É™ | É™ | L | Â  | Â  | Â  | . bhÃ­odh | vi:dâ€² | ËˆvÊ²iËuË | L | Â  | Â  | &lt;odh&gt; â†’ É™dÊ² / _ # PRONOUN | . sÃ­ | Êƒi: | ËˆÊƒiË | L | Â  | Â  | Â  | . naoi | ËˆNi: | ËˆÉ´Ë iË | L | Â  | Â  | Â  | . lÃ¡ | ËˆLÉ‘: | ËˆÊŸË aË | L | Â  | Â  | Â  | . annsin | nÌ¥ËˆÊƒÉªnâ€² | ËˆaËˆÉ´Ê²ÊƒinÊ² | Â  | Â  | Â  | Â  | . dâ€™fhÃ¡sfadh | dÉ‘:shÉ™dâ€² | ËˆdË aËsË uË | Â  | Â  | Â  | &lt;adh&gt; â†’ É™dÊ² / _ # PRONOUN | . sÃ­ | Êƒi: | ËˆÊƒiË | L | Â  | Â  | Â  | . gÃ©ar | Ëˆgâ€²É›:áµŠr | ËˆÉŸeËÉ¾Ë  | L | Â  | Â  | Â  | . agus | É”gÉ™s | ËˆagË É™sË  | L | Â  | Â  | Â  | . rachadh | rÉ‘hÉ™dâ€² | ËˆÉ¾Ë ahuË | L | Â  | Â  | &lt;adh&gt; â†’ É™dÊ² / _ # PRONOUN | . sÃ­ | Êƒi: | ËˆÊƒiË | L | Â  | Â  | Â  | . a | Â  | É™ | L | Â  | Â  | É™ â†’ âˆ… / V # _ | . dhâ€™fhÃ¡s | ËˆÉ£É‘:s | ËˆÉ£aËsË  | Â  | dâ€™fhÃ¡s | ËˆdË aËsË  | Â  | . agus | É”gÉ™s | ËˆagË É™sË  | L | Â  | Â  | Â  | . ba Ã© | byje: | ËˆbË É™ ËˆeË | Â  | Â  | Â  | Â  | . sin | ÊƒÉªnâ€² | ËˆÊƒinÊ² | L | Â  | Â  | Â  | . an | É™Ëˆ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . t-am | tÉ‘M | ËˆtË aËmË  | L | Â  | Â  | Â  | . acÃº | É”ku | ËˆakË uË | Â  | Â  | Â  | Â  | . lena | lâ€²É›nÉ™ | ËˆlÊ²eÉ´Ë É™ | L | Â  | Â  | Â  | . tarraingt | tÉ‘RÉ™Nâ€²tâ€² | ËˆtË aÉ¾Ë inÊ²tÊ² | L | Â  | Â  | Â  | . amach | É™ËˆmÉ‘x | É™ËˆmË ah | L | Â  | Â  | Â  | . Agus | É”gÉ™s | ËˆagË É™sË  | L | Â  | Â  | Â  | . ins an | nÌ¥sÉ™ | ËˆinÊ²Êƒ ËˆÉ™É´Ë  | Â  | Â  | Â  | Â  | . am | ËˆNÉ‘M | ËˆamË  | L | Â  | Â  | Â  | . sin | ÊƒÉªnâ€² | ËˆÊƒinÊ² | L | Â  | Â  | Â  | . bhÃ­ | vi: | ËˆvÊ²iË | L | Â  | Â  | Â  | . na | NÉ™ | ËˆÉ´Ë É™ | L | Â  | Â  | Â  | . toithe | tihÉ™ | ËˆtË ohÉ™ | Â  | tithe | ËˆtÊ²ihjiË | Â  | . bracha | ËˆbrÉ‘xÉ™ | ËˆbË É¾Ë ahÉ™ | Â  | braiche | ËˆbË É¾Ë aÃ§É™ | Â  | . faoin | fÊ·i:n | ËˆfË inÊ² | L | Â  | Â  | Â  | . talamh | ËˆtÉ‘lu | ËˆtË oÊŸË uË | L | Â  | Â  | Â  | . ar | É›r | ËˆeÉ¾Ê² | L | Â  | Â  | Â  | . eagla | Ã¸GlÉ™ | ËˆogË ÊŸË É™ | L | Â  | Â  | Â  | . go | gÉ” | ËˆgË É™ | L | Â  | Â  | Â  | . bhfeiceadh | ËˆvÉ›kâ€²u | ËˆvÊ²ecuË | Â  | Â  | Â  | Â  | . duine | ËˆdÉªnâ€² | ËˆdË inÊ²É™ | L | Â  | Â  | É™ â†’ âˆ… / _ # V | . ar | É›r | ËˆeÉ¾Ê² | L | Â  | Â  | Â  | . bith | bâ€²i | ËˆbÊ²iË | L | Â  | Â  | Â  | . iad | iÉ™d | ËˆiadË  | L | Â  | Â  | Â  | . Agus | É”gÉ™s | ËˆagË É™sË  | L | Â  | Â  | Â  | . ins | nÌ¥s | ËˆinÊ²Êƒ | Â  | Â  | Â  | Â  | . na | NÉ™ | ËˆÉ´Ë É™ | L | Â  | Â  | Â  | . toithe | ËˆtihÉ™ | ËˆtË ohÉ™ | Â  | tithe | ËˆtÊ²ihjiË | Â  | . bracha | ËˆbrÉ‘xÉ™ | ËˆbË É¾Ë ahÉ™ | Â  | braiche | ËˆbË É¾Ë aÃ§É™ | Â  | . thriomuigheadh | Ëˆxâ€²râ€²iÌˆmÊ·iedâ€² | ËˆrÌªÊ²imË É™juË | Â  | thriomaÃ­odh | ËˆrÌªÊ²imË iÉ™É£ | Â  | . siad | ÊƒÉ™d | ËˆÊƒiËdË  | L | Â  | Â  | Â  | . araist | É™ËˆraÊƒdâ€² | ËˆaÉ¾Ë É™ÊƒtÊ² | Â  | Â  | Â  | Â  | . Ã­ | i: | ËˆiË | L | Â  | Â  | Â  | . Annsin | nÌ¥ËˆÊƒÉªnâ€² | ËˆaËˆÉ´Ê²ÊƒinÊ² | Â  | Â  | Â  | É™ â†’ âˆ… / V # _ | . mheileadh | vÉ™lâ€²hÉ™dâ€² | ËˆvÊ²elÊ²uË | Â  | Â  | Â  | &lt;eadh&gt; â†’ É™dÊ² / _ # PRONOUN | . siad | ÊƒÉ™d | ËˆÊƒiËdË  | L | Â  | Â  | Â  | . Ã­ | i: | ËˆiË | L | Â  | Â  | Â  | . le | lâ€²É› | ËˆlÊ²e | L | Â  | Â  | Â  | . brÃ³inte | ËˆbrÉ”:Nâ€²tâ€²É™ | ËˆbË É¾Ë oËnÊ²tÊ²É™ | Â  | brÃ³nna | bË É¾Ë oËÉ´Ë É™ | Â  | . lÃ¡imhe | ËˆLÉ‘:vÉ™ | ËˆÊŸË aËvÊ²É™ | L | Â  | Â  | Â  | . BhÃ­ | vi: | ËˆvÊ²iË | L | Â  | Â  | Â  | . na | NÉ™ | ËˆÉ´Ë É™ | L | Â  | Â  | Â  | . barraillÃ­ | ËˆbÉ‘RÉ™Lâ€²i | ËˆbË aËËˆÉ¾Ë aÊŸÊ²iË | Â  | bairillÃ­ | ËˆbË aÉ¾Ê²É™ÊŸÊ²iË | Â  | . acÃº | É”ku | ËˆakË uË | Â  | acu | akË u | Â  | . annsin | nÌ¥ËˆÊƒÉªnâ€² | ËˆaËˆÉ´Ê²ÊƒinÊ² | Â  | ansin | É™É´Ë ÊƒinÊ² | É™ â†’ âˆ… / V # _ | . agus | É”ges | ËˆagË É™sË  | L | Â  | Â  | Â  | . lÃ­onadh | ËˆLâ€²i:nÉ™dâ€² | ËˆÊŸÊ²iËÉ´Ë uË | L | Â  | Â  | Â  | . siad | ÊƒÉ™d | ËˆÊƒiËdË  | L | Â  | Â  | Â  | . lÃ¡n | LÉ‘:n | ËˆÊŸË aËÉ´Ë  | L | Â  | Â  | Â  | . uisce | ÉªÊƒgâ€²É™ | ËˆiÊƒcÉ™ | L | Â  | Â  | Â  | . an | nÌ¥ | ËˆÉ™É´Ë  | L | Â  | Â  | É™ â†’ âˆ… / V # _ | . barraille | ËˆbÉ‘RÉ™Lâ€²É™ | ËˆbË aËËˆÉ¾Ë aÊŸÊ²É™ | Â  | bairille | ËˆbË aÉ¾Ê²ÊŸÊ²É™ | Â  | . Chuireadh | xoÌ¤râ€²É™dâ€² | ËˆxuÉ¾Ê²uË | L | Â  | Â  | &lt;eadh&gt; â†’ É™dÊ² / _ # PRONOUN | . siad | ÊƒÉ™d | ËˆÊƒiËdË  | L | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . bhraich | ËˆvreihÊ” | ËˆwÉ¾Ë aÃ§ | L+M | Â  | Â  | Â  | . isteach | É™ËˆÊƒdâ€²ax | iÊƒËˆtÊ²ah | L | Â  | Â  | Â  | . insa | nÌ¥sÉ™ | ËˆinÊ²ËˆsË É™ | Â  | sa | ËˆsË É™ | Â  | . bharraille | ËˆwÉ‘RÉ™Lâ€²É™ | ËˆwaËËˆÉ¾Ë aÊŸÊ²É™ | Â  | bhairille | ËˆwaÉ¾Ê²ÊŸÊ²É™ | Â  | . agus | É”gÉ™s | ËˆagË É™sË  | L | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . ghabhÃ¡il | ËˆÉ£É”:lâ€² | ËˆÉ£olÊ² | L | Â  | Â  | Â  | . annsin | nÌ¥ËˆÊƒÉªnâ€² | ËˆaÉ´Ê²ÊƒinÊ² | Â  | ansin | É™É´Ë ÊƒinÊ² | Â  | . Chuireadh | xoÌ¤râ€²É™dâ€² | ËˆxuÉ¾Ê²uË | L | Â  | Â  | &lt;eadh&gt; â†’ É™dÊ² / _ # PRONOUN | . siad | ÊƒÉ™d | ËˆÊƒiËdË  | L | Â  | Â  | Â  | . cumhdach | Ëˆku:dÉ‘x | ËˆkË uËdË ah | L | Â  | Â  | Â  | . ar | É›r | ËˆeÉ¾Ê² | L | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . bharraille | ËˆwÉ‘RÉ™Lâ€²É™ | ËˆwaËËˆÉ¾Ë aÊŸÊ²É™ | Â  | bhairille | ËˆwaÉ¾Ê²ÊŸÊ²É™ | Â  | . agus | É”gÉ™s | ËˆagË É™sË  | L | Â  | Â  | Â  | . ba | boÌ¤ | ËˆbË É™ | L | Â  | Â  | Â  | . ghoirid | ËˆÉ£oÌ¤râ€²idâ€²á¶¾ | ËˆÉ£oÉ¾Ê²É™dÊ² | Â  | Â  | Â  | Â  | . i | É™ | Ëˆi | L | Â  | Â  | Â  | . gcionn | gâ€²oÌ¤N | ËˆÉŸoÉ´Ë  | L | Â  | Â  | Â  | . cheithre | Ëˆxâ€²É›râ€²É™ | ËˆxeÉ¾Ê²É™ | L | Â  | Â  | Â  | . huaire | ËˆhuÉ™râ€²É™ | ËˆhuaÉ¾Ê²É™ | L | Â  | Â  | Â  | . fichead | Ëˆfâ€²ihÉ™d | ËˆfÊ²ihjÉ™dË  | L | Â  | Â  | Â  | . thiocfadh | hoÌ¤ku | ËˆhjokË uË | L | Â  | Â  | Â  | . an | nÌ¥ | ËˆÉ™É´Ë  | L | Â  | Â  | É™ â†’ âˆ… / V # _ | . cubhar | Ëˆku:r | ËˆkË uwÉ™É¾Ë  | Â  | cÃºr | ËˆkË uËÉ¾Ë  | Â  | . a | É™ | É™ | L | Â  | Â  | Â  | . theacht | haxd | ËˆhjaxtË  | L | Â  | Â  | Â  | . ar | É›r | ËˆeÉ¾Ê² | L | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . bharraille | ËˆwÉ‘RÉ™Lâ€²É™ | ËˆwaËËˆÉ¾Ë aÊŸÊ²É™ | Â  | bhairille | ËˆwaÉ¾Ê²ÊŸÊ²É™ | Â  | . agus | É”gÉ™s | ËˆagË É™sË  | L | Â  | Â  | Â  | . bhÃ­ | vi: | ËˆvÊ²iË | L | Â  | Â  | Â  | . an | n | ËˆÉ™É´Ë  | L | Â  | Â  | É™ â†’ âˆ… / V # _ | . ceol | Ëˆkâ€²Ê²É”:l | ËˆcoËÊŸË  | L | Â  | Â  | Â  | . aige | É›gâ€²É™ | ËˆeÉŸÉ™ | L | Â  | Â  | Â  | . mar | moÌ¤r | ËˆmË aÉ¾Ë  | L | Â  | Â  | Â  | . ceÃ³l | Ëˆkâ€²Ê²É”:l | ËˆcoËÊŸË  | Â  | ceol | ËˆcoËÊŸË  | Â  | . beachÃ³g | Ëˆbâ€²ahÉ”g | ËˆbÊ²ahÉ”gË  | Â  | Â  | Â  | Â  | . Nuair | NuÉ™râ€² | ËˆÉ´Ë uËÉ¾Ê² | L | Â  | Â  | Â  | . a | É™ | É™ | L | Â  | Â  | Â  | . bhÃ­odh | vi:dâ€² | ËˆvÊ²iËuË | L | Â  | Â  | &lt;odh&gt; â†’ É™dÊ² / _ # PRONOUN | . sÃ© | ÊƒÉ› | ËˆÊƒeË | L | Â  | Â  | Â  | . naoi | ËˆNi: | ËˆÉ´Ë iË | L | Â  | Â  | Â  | . lÃ¡ | ËˆLÉ‘: | ËˆÊŸË aË | L | Â  | Â  | Â  | . shÃ­olthuigheadh | ËˆhiÉ™lhiuw | ËˆhiËÊŸË hÉ™juË | Â  | shÃ­othlaÃ­odh | ËˆhiËhÊŸË iÉ™É£ | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . t-iomlÃ¡n | Ëˆtâ€²á¶´oÌ¤mlan | ËˆtÊ²uËmË ÊŸË aÉ´Ë  | Â  | Â  | Â  | Â  | . sÃ­os | Êƒi:s | ËˆÊƒiËsË  | L | Â  | Â  | Â  | . ins | nÌ¥s | ËˆinÊ²Êƒ | Â  | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . bharraille | ËˆwÉ‘RÉ™Lâ€²É™ | ËˆwaËËˆÉ¾Ë aÊŸÊ²É™ | Â  | Â  | Â  | Â  | . araist | É™ËˆraÊƒdâ€² | ËˆaÉ¾Ë É™ÊƒtÊ² | Â  | Â  | Â  | Â  | . agus | É”gÉ™s | ËˆagË É™sË  | L | Â  | Â  | Â  | . ba Ã© | byje: | ËˆbË É™ ËˆeË | L | Â  | Â  | Â  | . sin | ÊƒÉªnâ€² | ËˆÊƒinÊ² | L | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . t-am | ËˆtÉ‘M | ËˆtË aËmË  | L | Â  | Â  | Â  | . acÃº | É”ku | ËˆakË uË | Â  | Â  | Â  | Â  | . lena | lâ€²É›nÉ™ | ËˆlÊ²eÉ´Ë É™ | L | Â  | Â  | Â  | . chur | ËˆxoÌ¤r | ËˆxuÉ¾Ë  | L | Â  | Â  | Â  | . sa | sÉ™ | ËˆsË É™ | L | Â  | Â  | Â  | . still | ËˆsdÃ¯l | ËˆÊƒtÊ²iÊŸÊ² | Â  | Â  | Â  | Â  | . BhÃ­ | vi: | ËˆvÊ²iË | L | Â  | Â  | Â  | . sÃ­ | Êƒi: | ËˆÊƒiË | L | Â  | Â  | Â  | . rÃ©idh | Ëˆre:i | ËˆÉ¾Ë eËj | L | Â  | Â  | Â  | . fÃ¡ | fÉ‘ | ËˆfË aË | L | Â  | Â  | Â  | . dhÃ©in | Ëˆje:nâ€² | ËˆjeËnÊ² | L+M | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . still | ËˆsdÃ¯l | ËˆÊƒtÊ²iÊŸÊ² | Â  | Â  | Â  | Â  | . Chuireadh | xoÌ¤râ€²É™dâ€² | ËˆxuÉ¾Ê²uË | L | Â  | Â  | &lt;eadh&gt; â†’ É™dÊ² / _ # PRONOUN | . siad | ÊƒÉ™d | ËˆÊƒiËdË  | L | Â  | Â  | Â  | . isteach | É™ËˆÊƒdâ€²ah | iÊƒËˆtÊ²ah | L | Â  | Â  | Â  | . insa | nÌ¥sÉ™ | ËˆinÊ²ËˆsË É™ | Â  | Â  | Â  | Â  | . still | ËˆsdÃ¯l | ËˆÊƒtÊ²iÊŸÊ² | Â  | Â  | Â  | Â  | . Ã­ | i: | ËˆiË | L | Â  | Â  | Â  | . agus | É”gÉ™s | ËˆagË É™sË  | L | Â  | Â  | Â  | . bhÃ­ | vi: | ËˆvÊ²iË | L | Â  | Â  | Â  | . dabhach | ËˆdÉ”uÊ·É‘x | ËˆdË auh | L | Â  | Â  | Â  | . acÃº | É”ku | ËˆakË uË | Â  | Â  | Â  | Â  | . agus | É”gÉ™s | ËˆagË É™sË  | L | Â  | Â  | Â  | . rud | ËˆroÌ¤D | ËˆÉ¾Ë udË  | L | Â  | Â  | Â  | . a | É™ | É™ | L | Â  | Â  | Â  | . dtugadh | doÌ¤gÉ™dâ€² | ËˆdË ugË uË | L+M | Â  | Â  | &lt;adh&gt; â†’ É™dÊ² / _ # PRONOUN | . siad | ÊƒÉ™d | ËˆÊƒiËdË  | L | Â  | Â  | Â  | . worm | ËˆwÃ¯râ€²É™m | ËˆwoËÉ¾Ë É™mË  | Â  | Â  | Â  | Â  | . air | É›râ€² | ËˆeÉ¾Ê² | L | Â  | Â  | Â  | . a | É™ | É™ | L | Â  | Â  | Â  | . rabh | roËˆ | ËˆÉ¾Ë au | Â  | raibh | ËˆÉ¾Ë oËw | Â  | . trÃ­ | tâ€²Êƒrâ€²i: | ËˆtÊ²É¾Ê²iË | L | Â  | Â  | Â  | . chor | ËˆxÉ”r | ËˆxaÉ¾Ë  | L | Â  | Â  | Â  | . inntÃ­ | ËˆÉªNâ€²tâ€²i | ËˆiËˆÉ´Ê²tÊ²iË | Â  | inti | iÉ´Ê²tÊ²i | Â  | . Agus | É”gÉ™s | ËˆagË É™sË  | L | Â  | Â  | Â  | . bhÃ­ | vi: | ËˆvÊ²iË | L | Â  | Â  | Â  | . an | nÌ¥ | ËˆÉ™É´Ë  | L | Â  | Â  | É™ â†’ âˆ… / V # _ | . worm | ËˆwÃ¯râ€²É™m | ËˆwoËÉ¾Ë É™mË  | Â  | Â  | Â  | Â  | . astoigh | É™ËˆÊƒdihÊ” | ËˆasË tË É™ | Â  | istigh | isË ËˆtË ij | Â  | . sa | sÉ™ | ËˆsË É™ | L | Â  | Â  | Â  | . dabhach | ËˆdÉ”uÊ·É‘x | ËˆdË auh | L | Â  | Â  | Â  | . agus | É”gÉ™s | ËˆagË É™sË  | L | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . t-uisce | tÉªÊƒgâ€²É™ | ËˆtË iÊƒcÉ™ | L | Â  | Â  | Â  | . fuar | ËˆfyÉ™r | ËˆfË iaÉ¾Ë  | L | Â  | Â  | Â  | . ag | É™ | ËˆeÉŸ | L | Â  | Â  | ÉŸ â†’ âˆ… / _ # [+stop] | . dÃ³rtadh | ËˆdÉ”:rtu | ËˆdË oËËˆÉ¾Ë tË eË | Â  | doirteadh | ËˆdË oÉ¾Ë tÊ²uË | Â  | . orthaÃ­ | É”rhi | ËˆoËÉ¾Ë hiË | Â  | uirthi | ËˆaÉ¾Ë hjiË | Â  | . Agus | É”gÉ™s | ËˆagË É™sË  | L | Â  | Â  | Â  | . ar | É›r | ËˆeÉ¾Ê² | L | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . taobh | ti:w | ËˆtË iËw | L | Â  | Â  | Â  | . eile | Îµlâ€²É™ | ËˆelÊ²É™ | L | Â  | Â  | Â  | . den | dÉ”n | ËˆdË enË  | L | Â  | Â  | Â  | . worm | ËˆwÃ¯râ€²É™m | ËˆwoËÉ¾Ë É™mË  | Â  | Â  | Â  | Â  | . bhÃ­ | vi: | ËˆvÊ²iË | L | Â  | Â  | Â  | . an | nÌ¥ | ËˆÉ™É´Ë  | L | Â  | Â  | É™ â†’ âˆ… / V # _ | . ceig | Ëˆkâ€²Ã¨Gâ€² | ËˆceÉŸ | Â  | Â  | Â  | Â  | . agus | É”gÉ™s | ËˆagË É™sË  | L | Â  | Â  | Â  | . ar | É™r | ËˆeÉ¾Ê² | L | Â  | Â  | Â  | . tuairim | tuÉ™râ€²Éªmâ€² | ËˆtË uaÉ¾Ê²imÊ² | L | Â  | Â  | Â  | . ar | É›r | ËˆeÉ¾Ê² | L | Â  | Â  | Â  | . thoirt | ËˆhoÌ¤Rtâ€² | ËˆhaÉ¾Ë tÊ² | L+M | Â  | Â  | Â  | . fiog | Ëˆfâ€²Ã¸G | ËˆfÊ²igË  | Â  | Â  | Â  | Â  | . ghlas | ËˆÉ£lÉ‘s | ËˆÉ£ÊŸË asË  | L | Â  | Â  | Â  | . rachadh | rÉ‘hu | ËˆÉ¾Ë ahuË | L | Â  | Â  | Â  | . an | nÌ¥ | ËˆÉ™É´Ë  | L | Â  | Â  | É™ â†’ âˆ… / V # _ | . poitÃ­n | ËˆpÉ”tâ€²inâ€² | ËˆpË otÊ²inÊ² | L | Â  | Â  | Â  | . isteach | É™ËˆÊƒdâ€²ah | iÊƒËˆtÊ²ah | L | Â  | Â  | Â  | . insa | nÌ¥sÉ™ | ËˆinÊ²ËˆsË É™ | Â  | Â  | Â  | Â  | . cheig | Ëˆxâ€²É›Gâ€² | ËˆÃ§eÉŸ | Â  | Â  | Â  | Â  | . amach | É™ËˆmÉ‘h | É™ËˆmË ah | L | Â  | Â  | Â  | . as | Ã¯s | ËˆasË  | L | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . worm | ËˆwÃ¯râ€²É™m | ËˆwoËÉ¾Ë É™mË  | Â  | Â  | Â  | Â  | . Annsin | nÌ¥ËˆÊƒÉªnâ€² | ËˆaËˆÉ´Ê²ÊƒinÊ² | Â  | Â  | Â  | Â  | . nuair | NuÉ™râ€² | ËˆÉ´Ë uËÉ¾Ê² | L | Â  | Â  | Â  | . a | É™ | É™ | L | Â  | Â  | Â  | . bhÃ­odh | viuw | ËˆvÊ²iËuË | L | Â  | Â  | Â  | . an | nÌ¥ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . chÃ©ad | Ëˆxâ€²ed | ËˆÃ§eËdË  | L | Â  | Â  | Â  | . rathaidh | ËˆrÉ‘hi | ËˆÉ¾Ë ahiË | Â  | ratha | ËˆÉ¾Ë ahÉ™ | Â  | . raithte | Ëˆratâ€²Êƒ | ËˆÉ¾Ë ahtÊ²É™ | Â  | rÃ¡ite | ËˆÉ¾Ë aËtÊ²É™ | É™ â†’ âˆ… / _ # V | . acÃº | É”ku | ËˆakË uË | Â  | Â  | Â  | Â  | . chuireadh | xoÌ¤râ€²É™dâ€² | ËˆxuÉ¾Ê²uË | L | Â  | Â  | &lt;eadh&gt; â†’ É™dÊ² / _ # PRONOUN | . siad | ÊƒÉ™d | ËˆÊƒiËdË  | L | Â  | Â  | Â  | . isteach | É™ËˆÊƒdâ€²ah | iÊƒËˆtÊ²ah | L | Â  | Â  | Â  | . araist | É™ËˆraÊƒdâ€² | ËˆaÉ¾Ë É™ÊƒtÊ² | Â  | Â  | Â  | Â  | . Ã­ | i: | ËˆiË | L | Â  | Â  | Â  | . ins | nÌ¥s | ËˆinÊ²Êƒ | Â  | Â  | Â  | É™ â†’ âˆ… / V # _ | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . still | ËˆsdÃ¯l | ËˆÊƒtÊ²iÊŸÊ² | Â  | Â  | Â  | Â  | . agus | É”gÉ™s | ËˆagË É™sË  | L | Â  | Â  | Â  | . nÃ­odh | ËˆNâ€²i:wÉ™dâ€² | ËˆnÊ²iËuË | L | Â  | Â  | &lt;odh&gt; â†’ É™dÊ² / _ # PRONOUN | . siad | ÊƒÉ™d | ËˆÊƒiËdË  | L | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . dara | ËˆdÉ‘rÉ™ | ËˆdË aÉ¾Ë É™ | L | Â  | Â  | Â  | . rathaidh | nÌ¥Ëˆrahi | ËˆÉ¾Ë ahiË | Â  | Â  | Â  | Â  | . annsin | ËˆÊƒÉªnâ€² | ËˆaËˆÉ´Ê²ÊƒinÊ² | Â  | Â  | Â  | Â  | . BhÃ­odh | viuw | ËˆvÊ²iËuË | L | Â  | Â  | Â  | . gloine | ËˆglÃ¶nâ€²É™ | ËˆgË ÊŸË inÊ²É™ | L | Â  | Â  | Â  | . acÃº | É”ku | ËˆakË uË | Â  | Â  | Â  | Â  | . a | É™ | É™ | L | Â  | Â  | Â  | . dtugadh | doÌ¤gÉ™dâ€² | ËˆdË ugË uË | L+M | Â  | Â  | &lt;adh&gt; â†’ É™dÊ² / _ # PRONOUN | . siad | ÊƒÉ™d | ËˆÊƒiËdË  | L | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . adharc | ËˆNe:rk | ËˆeËÉ¾Ë kË  | L | Â  | Â  | Â  | . air | É›râ€² | ËˆeÉ¾Ê² | L | Â  | Â  | Â  | . agus | É”gÉ™s | ËˆagË É™sË  | L | Â  | Â  | Â  | . Ã¡ | a | aË | L | Â  | Â  | Â  | . rÃ©ir | Ëˆre: | ËˆÉ¾Ë eËÉ¾Ê² | L | Â  | Â  | Â  | . sinâ€™s | ÊƒÉªnâ€²s | ËˆÊƒinÊ²Êƒ | Â  | Â  | Â  | Â  | . bhÃ­odh | vi:dâ€² | ËˆvÊ²iËuË | L | Â  | Â  | Â  | . siad | ÊƒÉ™d | ËˆÊƒiËdË  | L | Â  | Â  | Â  | . ag | É™ | ËˆeÉŸ | L | Â  | Â  | Â  | . rathaidh | ËˆrÉ‘hi | ËˆÉ¾Ë ahiË | Â  | Â  | Â  | Â  | . an | nÌ¥ | ËˆÉ™É´Ë  | L | Â  | Â  | É™ â†’ âˆ… / V # _ | . phoitÃ­n | ËˆfÉ”tâ€²inâ€² | ËˆfË otÊ²inÊ² | L+M | Â  | Â  | Â  | . chuireadh | xoÌ¤râ€²É™dâ€² | ËˆxuÉ¾Ê²uË | L | Â  | Â  | &lt;eadh&gt; â†’ É™dÊ² / _ # PRONOUN | . siad | ÊƒÉ™d | ËˆÊƒiËdË  | L | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . adharc | ËˆNe:rk | ËˆeËÉ¾Ë kË  | L | Â  | Â  | Â  | . isteach | É™ËˆÊƒdâ€²ax | iÊƒËˆtÊ²ah | L | Â  | Â  | Â  | . faoin | fÊ·i:n | ËˆfË inÊ² | L | Â  | Â  | Â  | . phoitÃ­n | ËˆfÉ”tâ€²inâ€² | ËˆfË otÊ²inÊ² | L+M | Â  | Â  | Â  | . agus | É”gÉ™s | ËˆagË É™sË  | L | Â  | Â  | Â  | . chaith | ËˆxÉ‘ih | Ëˆxahj | L | Â  | Â  | Â  | . iad | É™d | ËˆiadË  | L | Â  | Â  | Â  | . insa | nÌ¥sÉ™ | ËˆinÊ²ËˆsË É™ | Â  | Â  | Â  | Â  | . teinidh | Ëˆtâ€²ÊƒÉªnâ€²i | ËˆtÊ²enÊ²iË | Â  | Â  | Â  | Â  | . Ã­ | i: | ËˆiË | L | Â  | Â  | Â  | . Agus | É”gÉ™s | ËˆagË É™sË  | L | Â  | Â  | Â  | . nuair | NuÉ™râ€² | ËˆÉ´Ë uËÉ¾Ê² | L | Â  | Â  | Â  | . a | É™ | É™ | L | Â  | Â  | Â  | . thiocfadh | hoÌ¤ku | ËˆhjokË uË | L | Â  | Â  | Â  | . an | nÌ¥ | ËˆÉ™É´Ë  | L | Â  | Â  | É™ â†’ âˆ… / V # _ | . bladhaire | Ëˆblá´‡irâ€²É™ | ËˆbË ÊŸË eËÉ¾Ê²É™ | L | Â  | Â  | Â  | . bhÃ­ | vi: | ËˆvÊ²iË | L | Â  | Â  | Â  | . sÃ© | ÊƒÉ› | ËˆÊƒeË | L | Â  | Â  | Â  | . i | Â  | Ëˆi | L | Â  | Â  | Â  | . dtÃ³lamh | ËˆdÉ”:lÉ™fâ€² | ËˆdË oËÊŸË uË | L+M | Â  | Â  | Â  | . ar | É›r | ËˆeÉ¾Ê² | L | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . phoitÃ­n | ËˆfÉ”tâ€²inâ€² | ËˆfË otÊ²inÊ² | L+M | Â  | Â  | Â  | . Agus | É”gÉ™s | ËˆagË É™sË  | L | Â  | Â  | Â  | . nuair | NuÉ™râ€² | ËˆÉ´Ë uËÉ¾Ê² | L | Â  | Â  | Â  | . a | É™ | É™ | L | Â  | Â  | Â  | . thÃ©igheadh | Ëˆhe:wÉ™dâ€² | ËˆheËjuË | Â  | thÃ©adh | ËˆhjeËh | &lt;eadh&gt; â†’ É™dÊ² / _ # PRONOUN | . sÃ­ | Êƒi: | ËˆÊƒiË | L | Â  | Â  | Â  | . a | Â  | É™ | L | Â  | Â  | É™ â†’ âˆ… / V # _ | . chur | xoÌ¤r | ËˆxuÉ¾Ë  | L | Â  | Â  | Â  | . an | É™ | ËˆÉ™É´Ë  | L | Â  | Â  | Â  | . teinidh | Ëˆtâ€²ÊƒÉªnâ€²i | ËˆtÊ²enÊ²iË | Â  | tine | Â  | Â  | . as | Ã¯s | ËˆasË  | L | Â  | Â  | Â  | . bhÃ­ | vi: | ËˆvÊ²iË | L | Â  | Â  | Â  | . an | nÌ¥ | ËˆÉ™É´Ë  | L | Â  | Â  | É™ â†’ âˆ… / V # _ | . poitÃ­n | ËˆpÉ”tâ€²inâ€² | ËˆpË otÊ²inÊ² | L | Â  | Â  | Â  | . acÃº | É”ku | ËˆakË uË | Â  | Â  | Â  | Â  | . Oâ€™Neill, John E. â€œIrish Texts from South West Donegal.â€ Zeitschrift FÃ¼r Celtische Philologie, vol. 33, 1974, doi:10.1515/zcph.1974.33.1.285.Â &#8617; . |",
            "url": "https://jimregan.github.io/notes/irish/donegal/2021/01/24/irish-texts-from-south-west-donegal-text-1-poitin.html",
            "relUrl": "/irish/donegal/2021/01/24/irish-texts-from-south-west-donegal-text-1-poitin.html",
            "date": " â€¢ Jan 24, 2021"
        }
        
    
  
    
        ,"post210": {
            "title": "InÃ­on an cheannaÃ­",
            "content": "TÃ¡ tamall fad anois a bhÃ­ fear ina chÃ³naÃ­ i mbaile mÃ³r ChorcaÃ­. Fear saibhir agus ceannaÃ­ farraige ab ea Ã©. Do bhÃ­odh loingeas ag teacht thar lÃ¡r chÃºige. Do bhÃ­ aon inÃ­on amhÃ¡in aige gurb Ã© an ainm a bhÃ­ uirthi MÃ¡ire BhÃ¡n. Do shÃ­l sÃ­ an ainm sin mar nÃ­ raibh sÃ­ sa bhaile mhÃ³r aon chailÃ­n comh deas comh maorga lÃ©i. NÃ­ raibh Ã©inne clainne aige ina muintir ach Ã­ agus do mhÃ©adaigh sin urraim agus grÃ¡ na ndaoine don inÃ­on Ã³g so. . Ba ghnÃ¡thach lÃ©i captaen Ã³g loinge teacht ar cuairt go tigh an cheannaÃ­ go minic agus bhÃ­odh sÃ© an-cheanÃºil ar MhÃ¡ire bhÃ¡n. BhÃ­ MÃ¡ire ag titim i ngrÃ¡ leis i gan fhios di fÃ©in. Nuair a imÃ­odh sÃ© Ã³n gcuan bhÃ­odh uaigneas agus dÃ­omÃ¡ an domhain uirthi ach nÃ­ bhÃ­odh fhios aici cad Ã© an fÃ¡th. NÃ­ raibh aon fhear Ã³g uasal timpeall nÃ¡ go raibh Ã© tnÃºth le MÃ¡ire BhÃ¡n i dhÃ¡il le pÃ³sadh ach nÃ­ raibh aon mhaith dena bheith Ã¡ lorg. NÃ­ phÃ³sadh sÃ­ aon fhear ach a captaen Ã³g. NÃ­or mhaith lena muintir Ã­ (a) thabhairt le pÃ³sadh dÃ³san. Do bâ€™fhearr leo Ã­ a bheith ina gcÃ³ngar fÃ©in. Dâ€™fhan MÃ¡ire blianta gan pÃ³sadh. Deireadh sÃ­ ina haigne fÃ©in â€œdÃ¡ bheadh mâ€™athair bÃ¡s bheadh sÃ© ar mo chumas mo reogha fear a phÃ³sadh.â€ .",
            "url": "https://jimregan.github.io/notes/irish/2021/01/16/in%C3%ADon-an-cheanna%C3%AD.html",
            "relUrl": "/irish/2021/01/16/in%C3%ADon-an-cheanna%C3%AD.html",
            "date": " â€¢ Jan 16, 2021"
        }
        
    
  
    
        ,"post211": {
            "title": "Dinneen, p. 34",
            "content": "ainmheas, -a and -ta, m., disrespect. . ainmheasartha, indec. a., unmeasured, immoderate, intemperate. . ainmheasarthacht, -a, f., immoderateness, excess, intemperance. . ainmheisneach, -nigh and -nighe, m. and f., rashness, hesitancy, weakness, state of discouragement (m. in M.). . ainmheon, a., busy (Clare). . ainmhian, -mhÃ©ine, pl. -a, and -ta, dpl. ainmhianaibh (Kea.), f., lust, concupiscence, passion; ainmhianta na colna, the concupiscence of the flesh. . ainmhianach, -aighe, a., passionate, lustful, sensual. . ainmhidhe, g. id., pl. ainmhinte and ainmhidhthe, m., a brute, an animal. . ainmhidheach, -dhighe, a., brutish, beastly. . ainmhidheacht, -a, f., brutality. . ainmhÃ­n, -e, a., rough, passionate. . ainmhÃ­ne, g. id., f., roughness, coarseness, passionateness. . ainmneach, -nighe, a., famous, illustrious. . ainmneamhail, -mhla, a., famous. . ainmnighim, -iughadh, v. tr., I name, assign. . ainmnighthe, p. a., named, specified; go ha., namely. . ainmniughadh, -ighthe, m., act of naming, denomination, dedication. . ainnir (ainnear), -nire, pl. id., f., a maiden; is Ã­ &#39;na hainnir bhig, while she was a young maiden. . ainreacht (ainriocht), -a, pl. id., m., evil plight. . ainriachtanach, -aighe, a., necessitous, poor, miserable. . ainriachtanas, -ais, m., extreme danger, great misery or necessity. . ainriochtach, -aighe, a., pitiable. See riocht. . ainscian, -cine, pl. -ceanna, f., a large knife; fury, extravagance; a furious or wild person. . ainscianach, -aighe, a., furious, extravagant. . ainscianta, indecl. a., furious, extravagant. . ainshearc, g. -eirce and -earca, f., hatred. . ainshearc, m. and f., excessive love. . ainshearcach, -aighe, a., unloving, merciless, cruel. . ainsheascair, -e, a., troublous, uneasy, uncomfortable. . ainspioraid, -e, -idhe, f., an evil spirit; the devil. . ainshrianta, a., unbridled, debauched. . ainshriantacht, -a., f., libertinism, debauchery, unbridled passion. . ainteann, -einne, a., very violent, oppressive, severe; braced up, very stiff, very stout. . ainteas, -a, m., great heat, inflammation, wrath. . ainteasach, -aighe, a., hot, feverish. . ainteasaidhe, indec. a., sultry, warm (of weather). . ainteastach, -aigh, pl. id., m., a false witness; â€œainteastach brÃ©ag,â€ a base asserter of lies (Kea.); â€œinnisin scÃ©al ainteastach do bhÃ­ fuathmhar dÃ³â€ (id.). . ainteastach, -aighe, a., falsely testified. . aintighearna, g. id., pl., -idhe, m., a tyrant, an oppressor. . aintighearnacht, -a, f., tyranny, oppression. . aipche, g. id., f., maturity (from abaidh, ripe). . aipidh, see abaid. . air, prep., on, upon, etc.; more generally written ar, which see. . air, prep, pr., m., upon him or it. See ar, prep. . airc, -e, f., greed, voracity; gÃ©ar-airc (O&#39;Ra.) want, hardship (Don.). . airc, in phr. gheall sÃ© na huirc is na hairc dam, he promised me the world and all. . airc, -e, -eacha, f., a chest, a coffer; an ark. . airc, in various meanings, as a lizard, etc. See earc and arc. .",
            "url": "https://jimregan.github.io/notes/irish/dinneen/2021/01/09/dinneen-p-34.html",
            "relUrl": "/irish/dinneen/2021/01/09/dinneen-p-34.html",
            "date": " â€¢ Jan 9, 2021"
        }
        
    
  
    
        ,"post212": {
            "title": "Teanglann pronunciations",
            "content": "Link Ulster Connacht Munster Ulster (Abair IPA) Connacht (Abair IPA) Munster (Abair IPA) Speaker Ulster Speaker Connacht Speaker Munster . Ã¡dhÃºil | ËˆauÉ™lÊ² | ËˆÉ‘ËuËlÊ² | É‘ËËˆuËlÊ² | ËˆaËuËlÊ² | ËˆÉ‘ËÉ£uËlÊ² | É‘ËËˆÉ£uËl | Â  | Â  | Â  | . adhmad | ËˆÉ‘mË É™dË  | ËˆÉ‘mË É™dË  | Â  | ËˆeËmË É™dË  | ËˆaimË É™dË  | ËˆaimË É™dË  | =ocht | Â  | Â  | . adhmad | ËˆeËmË É™dË  | ËˆÉ‘mË É™dË  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | . ocht | ËˆokË tË  | Â  | Â  | ËˆaxtË  | ËˆoxtË  | ËˆoxtË  | Â  | Â  | Â  | . seachtain | ËˆÊƒÉ‘xtË É™nÊ² | ËˆÊƒÉ‘xtË É™nÊ² | ËˆÊƒÉ‘xtË É™nÊ² | ËˆÊƒaÉ¾Ë tË É™nÊ² | ËˆÊƒaxtË É™nÊ² | ËˆÊƒaxtË É™nÊ² | =ocht | Â  | Â  | . Seachtain | ËˆÊƒÉ‘kË tË É™nÊ² | ËˆÊƒÉ‘xtË É™nÊ² | ËˆÊƒÉ‘xtË É™nÊ² | Â  | Â  | Â  | Â  | Â  | =seachtÃ³dÃº | . seacht | ËˆÊƒÉ‘tË  1 | ËˆÊƒÉ‘xtË  | ËˆÊƒÉ‘xtË  | ËˆÊƒaxtË  | ËˆÊƒaxtË  | ËˆÊƒaxtË  | Â  | Â  | Â  | . seachtÃ³ | ËˆÊƒÉ‘hbË É™ | ËˆÊƒÉ‘xtË oË | ËˆÊƒÉ‘xtË oË | ËˆÊƒaÉ¾Ë tË oË | ËˆÊƒaxtË uË | ÊƒaxËˆtË oË | Â  | =seachtain | =seachtain | . seachtÃ³dÃº | ËˆÊƒÉ‘xtË odË uË | ËˆÊƒÉ‘xtË uËdË uË | ËˆÊƒÉ‘xtË oËdË uË | ËˆÊƒaÉ¾Ë tË odË uË | ËˆÊƒaxtË oËdË uË | ÊƒaxËˆtË oËdË uË | Â  | Â  | Â  | . ochtÃ³ | ËˆoxtË wa | ËˆoxtË oË | ËˆoxtË oË | ËˆaxtË oË | ËˆoxtË uË | oxËˆtË oË | Â  | Â  | Â  | . srÃ³nach | Â  | Â  | ËˆÊƒÉ¾Ë oËnË É™x | ËˆsË É¾Ë oËÉ´Ë ah | ËˆsË É¾Ë oËÉ´Ë É™x | ËˆsË É¾Ë oËnË É™x | Â  | Â  | Â  | . teorainn | ËˆtÊ²oËËˆÉ¾Ë aÉ´Ê² | ËˆtÊ²oËÉ¾Ë É™É´Ê² | ËˆtÊ²oËÉ¾Ë É™ 2 | ËˆtÊ²oËÉ¾Ë É™É´Ê² | ËˆtÊ²oËËˆÉ¾Ë aÉ´Ê² | ËˆtÊ²oËÉ¾Ë É™nÊ² | Â  | Â  | Â  | . sram | ËˆsË É¾Ë É‘mË  | ËˆsË É¾Ë É‘mË  | ËˆsË É¾Ë É‘mË  | ËˆsË É¾Ë amË  | ËˆsË É¾Ë amË  | ËˆsË É¾Ë amË  | Â  | Â  | Â  | . seachtar | ËˆÊƒÉ‘tË É™É¾Ë  | Â  | Â  | ËˆÊƒaÉ¾Ë tË É™É¾Ë  | ËˆÊƒaxtË É™É¾Ë  | ËˆÊƒaxtË É™É¾Ë  | =seacht | Â  | Â  | . seachtar | ËˆÊƒÉ‘tË É™ | Â  | Â  | Â  | Â  | Â  | =seacht | Â  | Â  | . cathlÃ¡n | ËˆkË aÊŸÌ¥Ë aÉ´Ë  | ËˆkË aÊŸË É‘ËÉ´Ë  | kË É‘ËˆlÌ¥Ë É‘ËnË  | ËˆkË ahÊŸË aÉ´Ë  | ËˆkË ahÊŸË É‘ËÉ´Ë  | kË aËˆhlË É‘ËnË  | Â  | Â  | Â  | . Or ËˆÊƒÉ‘htË  ?Â &#8617; . | teoraÂ &#8617; . |",
            "url": "https://jimregan.github.io/notes/irish/teanglann/2020/11/25/teanglann-pronunciations.html",
            "relUrl": "/irish/teanglann/2020/11/25/teanglann-pronunciations.html",
            "date": " â€¢ Nov 25, 2020"
        }
        
    
  
    
        ,"post213": {
            "title": "Teanglann compound pronunciations",
            "content": "Word Compound Ulster Connacht Munster Ulster (Abair IPA) Connacht (Abair IPA) Munster (Abair IPA) Speaker Ulster Speaker Connacht Speaker Munster . tuathghrÃ­osÃ³ir | tuath+ghrÃ­osÃ³ir | ËˆtË uahÉ™ËˆÉ¾Ê²iËsË É™É¾Ê² | ËˆtË uËˆÊiËsË oËÉ¾Ê² | ËˆtË uÉ™ÊÉ¾Ê²iËËˆsË oËÉ¾Ê² | ËˆtË uajÉ¾Ê²isË oÉ¾Ê² | ËˆtË uÉ™ËˆjÉ¾Ê²iËsË oËÉ¾Ê² | ËˆtË uÉ™jÉ¾Ê²iËËˆsË oËÉ¾Ê² | Â  | Â  | Â  | . leathrÃ©al | leath+rÃ©al | ËˆÊŸÊ²aÉ¾Ì¥Ë eËÊŸË  | Â  | Â  | ËˆÊŸÊ²aËˆÉ¾Ë eËÊŸË  | ËˆÊŸÊ²aËˆÉ¾Ë eËÊŸË  | ËˆlÊ²aËˆÉ¾Ë eËlË  | Â  | Â  | Â  | . leathnÃ³ta | leath+nÃ³ta | ËˆÊŸÊ²aËŒÉ´Ì¥Ë oËtË É™ | Â  | Â  | ËˆÊŸÊ²aËˆÉ´Ë oËtË É™ | ËˆÊŸÊ²aËˆÉ´Ë oËtË É™ | ËˆlÊ²aËˆnË oËtË É™ | Â  | Â  | Â  | . leathghealach | leath+ghealach | ËˆÊŸÊ²aËˆÃ§É‘ÊŸË É™x | Â  | ËˆlÊ²aÊaËˆlË É‘x | ËˆÊŸÊ²aËˆjaÊŸË É™h | ËˆÊŸÊ²aËˆjaÊŸË É™x | ËˆlÊ²ajÉ™ËˆlË ax | Â  | Â  | Â  | . leathchiorcal | leath+chiorcal | ËˆÊŸÊ²aËˆÃ§oÉ¾Ë kË É™ÊŸË  | ËˆÊŸÊ²aËˆÃ§oÉ¾Ë kË É™ÊŸË  | Â  | ËˆÊŸÊ²aËˆÃ§iÉ¾Ë kË É™ÊŸË  | ËˆÊŸÊ²aËˆÃ§iÉ¾Ë kË É™ÊŸË  | ËˆlÊ²aËˆÃ§iÉ¾Ë kË É™ÊŸË  | Â  | Â  | Â  | . iathghlas | iath+ghlas | iÉ™xÊŸË asË  | ËˆiÉ™É£ÊŸË asË  | iÉ™ËˆÉ£lË É‘sË  | ËˆiÉ™hÉ£ÊŸË É™sË  | ËˆiÉ™hÉ£ÊŸË É™sË  | ËˆiÉ™hÉ£lË É™sË  | Â  | Â  | Â  | . leathard | leath+ard | ËˆÊŸÊ²ehaÉ¾Ë d | ËˆÊŸÊ²aËˆÉ‘ËÉ¾Ë dË  | ËˆlÊ²aËˆhÉ‘ËÉ¾Ë dË  | ËˆÊŸÊ²aËˆaÉ¾Ë dË  | ËˆÊŸÊ²aËˆÉ‘ËÉ¾Ë dË  | ËˆlÊ²aËˆÉ‘ËÉ¾Ë dË  | Â  | Â  | Â  | . leathardaithe | leath+ardaithe | ËˆÊŸÊ²aËˆaÉ¾Ë dË iËhÉ™ | ËˆÊŸÊ²aËˆÉ‘ËÉ¾Ë dË iË | ËˆlÊ²aËˆÉ‘ËÉ¾Ë dË É™hÉ™ | ËˆÊŸÊ²aËˆaÉ¾Ë dË É™hÉ™ | ËˆÊŸÊ²aËˆaÉ¾Ë dË É™hÉ™ | ËˆlÊ²aËˆaÉ¾Ë dË É™hÉ™ | =leathard | =leathard | =leathard | . leathfhocal | leath+fhocal | Â  | Â  | Â  | ËˆÊŸÊ²aËˆhokË É™ÊŸË  | ËˆÊŸÊ²aËˆokË É™ÊŸË  | ËˆlÊ²aËˆokË É™lË  | Â  | Â  | Â  | . leathshlÃ­ | leath+shlÃ­ | ËˆÊŸÊ²aËˆlÌ¥Ê²iË | ÊŸÊ²aËˆlÌ¥Ê²iË | ËˆlÊ²aËˆlÌ¥Ê²iË | ËˆÊŸÊ²aËˆhlÊ²i | ËˆÊŸÊ²aËˆlÌªÊ²iË | ËˆlÊ²aËˆÊƒlÊ²iË | Â  | Â  | Â  | . dlÃºthdhiosca | dlÃºth+dhiosca | Â  | Â  | Â  | ËˆdË ÊŸË uËËˆjisË kË É™ | ËˆdË ÊŸË uËjisË kË É™ | ËˆdË lË uËËˆjisË kË É™ | Â  | Â  | Â  | . dlÃºthshaothair | dlÃºth+shaothair | ËˆdË ÊŸË uËhiËhÉ™É¾Ê² | ËˆdË ÊŸË uËhiËhÉ™É¾Ê² | Â  | ËˆdË ÊŸË uËËˆhiËhÉ™É¾Ê² | ËˆdË ÊŸË uËËˆhiËhÉ™É¾Ê² | ËˆdË lË uËËˆheËhÉ™É¾ | Â  | Â  | Â  | . dlÃºthfhostaÃ­ochta | dlÃºth+fhostaÃ­ochta | ËˆdË ÊŸË uËËˆosË tË iÉ™ktË É™ | Â  | Â  | ËˆdË ÊŸË uËËˆoËˆsË tË iËÉ¾Ë tË É™ | ËˆdË ÊŸË uËËˆoËˆsË tË iËxtË É™ | ËˆdË lË uËosË ËˆtË iÉ™xtË É™ | =ocht | Â  | Â  | . scÃ¡thlÃ­nigh | scÃ¡th+lÃ­nigh | ËˆsË kË aËlÌ¥Ê²iËnÊ²iË | ËˆsË kË É‘ËlÊ²iËnÊ²É™ | sË kË É‘ËËˆlÊ²iËnÊ²iÉŸ | ËˆsË kË aËhlÊ²iËnÊ²É™ | ËˆsË kË É‘ËhlÊ²iËnÊ²É™ | sË kË É‘ËËˆhlÊ²iËnÊ²iÉŸ | Â  | Â  | Â  | . liathghorm | liath+ghorm | Â  | Â  | Â  | ËˆÊŸÊ²iÉ™ËˆÉ£oÉ¾Ë É™mË  | ËˆÊŸÊ²iÉ™ËˆÉ£oÉ¾Ë É™mË  | lÊ²iÉ™É£oÉ¾Ë É™mË  | Â  | Â  | Â  | . atheisiÃºint | ath+eisiÃºint | Â  | Â  | Â  | ËˆaËˆeÊƒuÉ´Ê²tÊ² | ËˆaËˆeÊƒuËnÊ²tÊ² | ËˆaeËˆÊƒuËnÊ²tÊ² | Â  | Â  | Â  | . atheisigh | ath+eisigh | ËˆaËˆheÊƒiË | Â  | Â  | ËˆaËˆeÊƒiË | ËˆaËˆeÊƒÉ™ | ËˆaËˆeÊƒiÉŸ | Â  | Â  | Â  | . atheagrÃº | ath+eagrÃº | ËˆaËˆhagË É¾Ë uË | Â  | aËŒhagË ËˆÉ¾Ë uË | ËˆaËˆagË É¾Ë uË | ËˆaËˆagË É¾Ë uË | ËˆaËŒagË É™ËˆÉ¾Ë uË | Â  | Â  | Â  | . athdhrÃ©acht | ath+dhrÃ©acht | ËˆaËˆÉ¾Ì¥Ê²eËxtË  | ËˆaËˆÉ¾Ê²eËxtË  | É‘ËˆÊÉ¾Ê²eËxtË  | ËˆaËˆjÉ¾Ê²eËxtË  | ËˆaËˆjÉ¾Ê²eËxtË  | ËˆaËˆjÉ¾Ê²eËxtË  | Â  | Â  | Â  | . athdhreas | ath+dhreas | ËˆaËˆhjÉ¾Ê²asË  | ËˆaÉ¾Ê²asË  | É‘ËˆÉ¾Ì¥Ê²asË  | ËˆaËˆjÉ¾Ê²asË  | ËˆaËˆjÉ¾Ê²asË  | ËˆaËˆjÉ¾Ê²asË  | Â  | Â  | Â  | . athdhreasaigh | ath+dhreasaigh | ËˆaiËˆÉ¾Ê²asË iË | ËˆaËˆvÊ²asË É™ | aËˆhjasË iÉŸ 1 | ËˆaËˆjÉ¾Ê²asË iË | ËˆaËˆjÉ¾Ê²asË É™ | ËˆaËˆjÉ¾Ê²asË iÉŸ | Â  | Â  | =atheagraigh | . atheagraigh | ath+eagraigh | ËˆaËˆhagË É¾Ë iË | ËˆaËˆhagË É¾Ë É™ | ËˆaËˆhagË É¾Ë iÉŸ | ËˆaËˆagË É¾Ë iË | ËˆaËˆagË É¾Ë É™ | ËˆaËˆagË É™É¾Ë iÉŸ | Â  | Â  | Â  | . athfheistigh | ath+fheistigh | Â  | Â  | Â  | ËˆaËˆeÊƒtÊ²iË | ËˆaËˆeÊƒtÊ²É™ | ËˆaËˆeÊƒtÊ²iÉŸ | Â  | Â  | Â  | . athdheisigh | ath+dheisigh | ËˆahËˆjeÊƒiË | Â  | É‘ËˆjeÊƒiÉŸ | ËˆaËˆjeÊƒÉ™ | ËˆaËˆjeÊƒÉ™ | ËˆaËˆjeÊƒiÉŸ | Â  | Â  | Â  | . athdhÃ­ol | ath+dhÃ­ol | ËˆahËˆjiËÊŸË  | ËˆajiËÊŸË  | aËˆjiÉ™lË  | ËˆaËˆjiËÊŸË  | ËˆaËˆjiËÊŸË  | ËˆaËˆjiÉ™lË  | Â  | Â  | Â  | . athdhÃ­righ | ath+dhÃ­righ | ËˆahjiËÉ¾Ê²iË | Â  | aËˆiËÉ¾Ê²iÉŸ | ËˆaËˆjiËÉ¾Ê²iË | ËˆaËˆjiËÉ¾Ê²É™ | ËˆaËˆjiËÉ¾Ê²iÉŸ | Â  | Â  | Â  | . athimir | ath+imir | Â  | Â  | aËˆhimÊ²É™É¾Ê² | ËˆaËˆimÊ²É™É¾Ê² | ËˆaËˆimÊ²É™É¾Ê² | ËˆaËˆimÊ²É™É¾Ê² | Â  | Â  | Â  | . athlÃ¡imhe | ath+lÃ¡imhe | Â  | Â  | aËˆlË É‘ËvÊ²É™ 2 | ËˆaËˆÊŸË aËvÊ²É™ | ËˆaËŒÊŸË É‘ËvÊ²É™ | ËˆaËˆlË É‘ËvÊ²É™ | Â  | Â  | =athdhÃ­ol | . athleabaigh | ath+leabaigh | ËˆaËˆÊŸÌ¥Ê²abË iË | Â  | É‘ËˆlÊ²É‘bË iÉŸ | ËˆaËˆÊŸÊ²abË iË | ËˆaËˆÊŸÊ²abË É™ | ËˆaËˆlÊ²abË iÉŸ | Â  | Â  | Â  | . athmhaoinigh | ath+mhaoinigh | ËˆaËˆhwiËnÊ²iË | Â  | aËˆvË iËnÊ²iÉŸ | ËˆaËˆwiËnÊ²iË | ËˆaËˆwiËnÊ²É™ | ËˆaËˆwiËnÊ²iÉŸ | Â  | Â  | Â  | . athghin | ath+ghin | ËˆaÃ§inÊ² | ËˆajinÊ² | É‘ËˆÃ§jinÊ² | ËˆaËˆjinÊ² | ËˆaËˆjinÊ²É™dÊ²É™x | ËˆaËˆjinÊ² | Â  | Â  | Â  | . saincheaptha | sain+cheaptha | ËˆsË anÊ²ËˆÃ§apË É™ | ËˆsË anÊ²ËˆÃ§apË iË | ËˆsË anÊ²ËˆÃ§apÉ™Ë hÉ™ | ËˆsË anÊ²ËˆÃ§apË hÉ™ | ËˆsË anÊ²ËˆÃ§apË É™ | ËˆsË anÊ²ËˆÃ§apË hÉ™ | Â  | Â  | Â  | . uathoibreÃ¡n | uath+oibreÃ¡n | u:ËˆibÊ²É¾Ê²aÉ´Ë  | ËˆuËˆÉ™ibÊ²É¾Ê²É‘ËÉ´Ë  | ËˆuËiËˆbÊ²É¾Ê²É‘ËnË  | ËˆuahËˆobÊ²É¾Ê²aÉ´Ë  | ËˆuÉ™ËˆobÊ²É¾Ê²É‘ËÉ´Ë  | ËˆuÉ™oËˆbÊ²É¾Ê²É‘ËnË  | Â  | Â  | Â  | . uathfheidhmeach | uath+fheidhmeach | Ëˆu:ËˆaimÊ²ah | Â  | u:ËˆaimÊ²É™x | ËˆuahËˆaimÊ²ah | ËˆuÉ™ËˆaimÊ²É™x | ËˆuÉ™ËˆaimÊ²É™x | =uathoibreÃ¡n | =uathoibreÃ¡n | =uathoibreÃ¡n | . uasghrÃ¡dÃº | uas+ghrÃ¡dÃº | Â  | Â  | uÉ™sË ËˆÉ¾Ë É‘ËdË u | ËˆuÉ™sË ËˆÉ£É¾Ë aËdË uË | ËˆuÉ™sË ËˆÉ£É¾Ë É‘ËdË uË | ËˆuÉ™sË É£É¾Ë É‘ËËˆdË u | Â  | Â  | Â  | . sraithadhmad | sraith+adhmad | ËˆsË É¾Ë aËˆhjemË É™dË  | ËˆsË É¾Ë É‘ËˆÉ‘:mË É™dË  | sË É¾Ë É‘ËˆaimË É™dË  | ËˆsË É¾Ë aiËˆhjeËmË É™dË  | ËˆsË É¾Ë ahÉ™mË É™dË  | ËˆsË É¾Ë ahÉ™mË É™dË  | Â  | Â  | Â  | . sraithchomÃ³rtas | sraith+chomÃ³rtas | ËˆsË É¾Ë aiËˆhomË oÉ¾Ë tË É™sË  | ËˆsË É¾Ë É‘ËŒxomË oËÉ¾Ë tË É™sË  | ËˆsË É¾Ë axÉ™ËˆmË oËÉ¾Ë tË É™sË  | ËˆsË É¾Ë aËˆhomË oÉ¾Ë tË É™sË  | ËˆsË É¾Ë aËŒxomË oËÉ¾Ë tË É™sË  | ËŒsË É¾Ë ahxÉ™ËˆmË oËÉ¾Ë tË É™sË  | Â  | Â  | Â  | . sramshÃºileach | sram+shÃºileach | ËˆsË É¾Ë É‘mË ËˆhuËlÊ²É™ | ËˆsË É¾Ë É‘mË ËˆhuËlÊ²É™x | ËˆsË É¾Ë É‘mË ËˆhuËlÊ²É™x | ËˆsË É¾Ë amË huËlÊ²É™h | ËˆsË É¾Ë amË huËlÊ²É™x | sË É¾Ë amË ËˆhuËlÊ²É™x | Â  | Â  | ! | . Same speaker as â€˜atheagraighâ€™; no accent on â€˜athâ€™ here, but there is there (Ã“ SÃ©, pt 830)Â &#8617; . | Ã“ SÃ©, pt. 830 (p. 471): â€œBionn suiomh na bÃ©ime de rÃ©ir riail bhÃ©ime an chomhfhocail nuair atÃ¡ guta fada i dtÃºs an fhocailâ€Â &#8617; . |",
            "url": "https://jimregan.github.io/notes/irish/teanglann/2020/11/25/teanglann-compound-pronunciations.html",
            "relUrl": "/irish/teanglann/2020/11/25/teanglann-compound-pronunciations.html",
            "date": " â€¢ Nov 25, 2020"
        }
        
    
  
    
        ,"post214": {
            "title": "Evernote web clips, 16/10/2020",
            "content": "High or low? Comparing high and low-variability phonetic training in adult and child second language learners . Introducing LexTALE: A quick and valid Lexical Test for Advanced Learners of English . A Tutorial on Extracting Formants in Praat . A Dive Into GhostNet with PyTorch and TensorFlow .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/praat/2020/10/16/evernote-links.html",
            "relUrl": "/evernote/web%20clip/praat/2020/10/16/evernote-links.html",
            "date": " â€¢ Oct 16, 2020"
        }
        
    
  
    
        ,"post215": {
            "title": "Evernote web clips, 5/10/2020",
            "content": "How to use multiple keywords in Pocketsphinx continuous mode . Richer Sentence Embeddings using Sentence-BERT â€” Part I . Examples of synthesizing sounds with Praat VocalTract area functions . Recommendations for Real-Time Speech MRI .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2020/10/05/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2020/10/05/evernote-links.html",
            "date": " â€¢ Oct 5, 2020"
        }
        
    
  
    
        ,"post216": {
            "title": "Evernote web clips, 29/9/2020",
            "content": "Poor Manâ€™s BERT - Exploring layer pruning . Computing MFCCs voice recognition features on ARM systems . Beginnerâ€™s guide to Speech Analysis . Yes you should understand backprop . Long Form Question Answering with ELI5 and Wikipedia . A Framework For Contrastive Self-Supervised Learning And Designing A New Approach . DeepSpeech-Polyglot-PL - Google Drive . Speech Recognition â€” ASR Model Training .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2020/09/29/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2020/09/29/evernote-links.html",
            "date": " â€¢ Sep 29, 2020"
        }
        
    
  
    
        ,"post217": {
            "title": "Training spaCy on IDT",
            "content": "!git clone https://github.com/UniversalDependencies/UD_Irish-IDT . Cloning into &#39;UD_Irish-IDT&#39;... remote: Enumerating objects: 32, done. remote: Counting objects: 100% (32/32), done. remote: Compressing objects: 100% (23/23), done. remote: Total 328 (delta 14), reused 25 (delta 9), pack-reused 296 Receiving objects: 100% (328/328), 3.63 MiB | 12.73 MiB/s, done. Resolving deltas: 100% (182/182), done. . !mkdir idt-json . !python -m spacy convert /content/UD_Irish-IDT/ga_idt-ud-train.conllu /content/idt-json . âœ” Generated output file (2019 documents): /content/idt-json/ga_idt-ud-train.json . !python -m spacy convert /content/UD_Irish-IDT/ga_idt-ud-dev.conllu /content/idt-json . âœ” Generated output file (451 documents): /content/idt-json/ga_idt-ud-dev.json . !wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ga.300.vec.gz !python -m spacy init-model ga /content/ga_vectors_cc --vectors-loc cc.ga.300.vec.gz . --2020-09-14 17:16:11-- https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ga.300.vec.gz Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.75.142, 104.22.74.142, ... Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 184422000 (176M) [binary/octet-stream] Saving to: â€˜cc.ga.300.vec.gzâ€™ cc.ga.300.vec.gz 100%[===================&gt;] 175.88M 44.2MB/s in 4.0s 2020-09-14 17:16:16 (43.8 MB/s) - â€˜cc.ga.300.vec.gzâ€™ saved [184422000/184422000] âœ” Successfully created model 316836it [00:27, 11398.56it/s] âœ” Loaded vectors from cc.ga.300.vec.gz âœ” Sucessfully compiled vocab 317041 entries, 316836 vectors . WikiANN is currently only available through Google Drive . from google.colab import drive drive.mount(&#39;/gdrive&#39;) . Mounted at /gdrive . !cp /gdrive/My Drive/ga.tar.gz . . !tar zxvf ga.tar.gz . README.txt wikiann-ga.bio . !wget http://downloads.dbpedia.org/links/resources/wikidatadump/2017-07-07/enwiki/20170701/enwiki-20170701-interlanguage-links_wikidataorg.ttl . --2020-09-14 17:15:11-- http://downloads.dbpedia.org/links/resources/wikidatadump/2017-07-07/enwiki/20170701/enwiki-20170701-interlanguage-links_wikidataorg.ttl Resolving downloads.dbpedia.org (downloads.dbpedia.org)... 139.18.16.66 Connecting to downloads.dbpedia.org (downloads.dbpedia.org)|139.18.16.66|:80... connected. HTTP request sent, awaiting response... 200 OK Length: 1020894244 (974M) [text/turtle] Saving to: â€˜enwiki-20170701-interlanguage-links_wikidataorg.ttlâ€™ enwiki-20170701-int 100%[===================&gt;] 973.60M 18.7MB/s in 54s 2020-09-14 17:16:05 (18.1 MB/s) - â€˜enwiki-20170701-interlanguage-links_wikidataorg.ttlâ€™ saved [1020894244/1020894244] . !cat wikiann-ga.bio | awk &#39;(NF == 7){print $6}&#39;|sort|uniq|while read i;do grep &quot;/$i&gt;&quot; enwiki-20170701-interlanguage-links_wikidataorg.ttl &gt;&gt; filtered;done . !pip install danlp . Collecting danlp Downloading https://files.pythonhosted.org/packages/3c/79/96d0d3f3634ce75787d408383fa81cdd854552e27e4e279a985b511a6d88/danlp-0.0.9-py3-none-any.whl Collecting pyconll Downloading https://files.pythonhosted.org/packages/2c/6e/c325d0db05ac1b8d45645de903e4ba691d419e861c915c3d4ebfcaf8ac25/pyconll-2.2.1-py3-none-any.whl Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from danlp) (4.41.1) Requirement already satisfied: tweepy in /usr/local/lib/python3.6/dist-packages (from danlp) (3.6.0) Requirement already satisfied: requests&gt;=2.21 in /usr/local/lib/python3.6/dist-packages (from pyconll-&gt;danlp) (2.23.0) Requirement already satisfied: six&gt;=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy-&gt;danlp) (1.15.0) Requirement already satisfied: PySocks&gt;=1.5.7 in /usr/local/lib/python3.6/dist-packages (from tweepy-&gt;danlp) (1.7.1) Requirement already satisfied: requests-oauthlib&gt;=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy-&gt;danlp) (1.3.0) Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests&gt;=2.21-&gt;pyconll-&gt;danlp) (2020.6.20) Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.6/dist-packages (from requests&gt;=2.21-&gt;pyconll-&gt;danlp) (2.10) Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests&gt;=2.21-&gt;pyconll-&gt;danlp) (1.24.3) Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests&gt;=2.21-&gt;pyconll-&gt;danlp) (3.0.4) Requirement already satisfied: oauthlib&gt;=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib&gt;=0.7.0-&gt;tweepy-&gt;danlp) (3.1.0) Installing collected packages: pyconll, danlp Successfully installed danlp-0.0.9 pyconll-2.2.1 . import danlp.datasets.wiki_ann wa = danlp.datasets.wiki_ann._convert_wikiann_to_iob(&#39;wikiann-ga.bio&#39;, &#39;wikiann-ga.ner&#39;) . !head out . Colm _ _ B-PER Ã“ _ _ I-PER Ruairc _ _ I-PER Seosamh _ _ B-PER Ã“ _ _ I-PER CainÃ­n _ _ I-PER DÃ³nal _ _ B-PER Ã“ _ _ I-PER . !python -m spacy convert -n 10 wikiann-ga.ner /content/idt-json/ . â„¹ Auto-detected token-per-line NER format â„¹ Grouping every 10 sentences into a document. âœ” Generated output file (757 documents): /content/idt-json/wikiann-ga.json . !rm -rf models !mkdir models !python -m spacy train -v /content/ga_vectors_cc -p &#39;tagger,parser,ner&#39; ga models idt-json/ga_idt-ud-train.json idt-json/ga_idt-ud-dev.json . Training pipeline: [&#39;tagger&#39;, &#39;parser&#39;] Starting with blank model &#39;ga&#39; Loading vector from model &#39;/content/ga_vectors_cc&#39; Counting training words (limit=0) /usr/lib/python3.6/runpy.py:193: UserWarning: [W022] Training a new part-of-speech tagger using a model with no lemmatization rules or data. This means that the trained model may not be able to lemmatize correctly. If this is intentional or the language you&#39;re using doesn&#39;t have lemmatization data, you can ignore this warning by setting SPACY_WARNING_IGNORE=W022. If this is surprising, make sure you have the spacy-lookups-data package installed. &#34;__main__&#34;, mod_spec) Itn Tag Loss Tag % Dep Loss UAS LAS Token % CPU WPS -- - - 1 14058.829 90.650 43482.222 74.804 56.787 100.000 11293 2 6188.294 92.810 34097.493 79.836 66.009 100.000 11461 3 4475.949 93.400 30061.441 81.314 69.572 100.000 11930 4 3549.242 93.530 27752.841 82.784 71.759 100.000 11719 5 2916.639 93.570 25861.771 83.066 72.401 100.000 11616 6 2438.355 93.550 24533.545 83.133 72.726 100.000 12227 7 2084.913 93.500 22901.218 83.281 73.043 100.000 11842 8 1845.607 93.610 21836.129 83.516 73.346 100.000 12094 9 1698.212 93.630 20626.109 83.555 73.507 100.000 11907 10 1406.626 93.570 19251.761 83.712 73.978 100.000 11926 11 1366.677 93.620 18882.570 83.896 74.128 100.000 12023 12 1209.500 93.610 17836.598 83.968 74.177 100.000 11924 13 1140.886 93.640 17341.624 84.098 74.375 100.000 11522 14 1043.542 93.670 16748.375 83.992 74.292 100.000 11766 15 926.876 93.700 15727.938 84.183 74.572 100.000 11931 16 848.805 93.680 15002.112 84.059 74.427 100.000 11750 17 857.415 93.760 14686.168 84.075 74.465 100.000 11724 18 775.277 93.750 14028.872 84.091 74.603 100.000 11890 19 651.078 93.680 13698.526 84.215 74.794 100.000 11932 20 672.552 93.670 13036.999 84.356 74.879 100.000 11724 21 590.244 93.670 12162.862 84.468 75.048 100.000 11851 22 593.722 93.680 12494.905 84.441 75.122 100.000 11910 23 582.541 93.660 12110.757 84.351 75.032 100.000 11544 24 514.448 93.690 11635.750 84.232 74.879 100.000 11984 25 491.457 93.640 10942.966 84.226 74.816 100.000 12106 26 521.324 93.660 10958.952 84.232 74.779 100.000 12112 27 507.717 93.650 10907.860 84.255 74.790 100.000 11754 28 485.186 93.660 10149.477 84.143 74.666 100.000 11411 29 507.038 93.720 10331.116 84.165 74.644 100.000 11740 30 477.966 93.700 9649.121 84.300 74.891 100.000 11300 âœ” Saved model to output directory models/model-final âœ” Created best model models/model-best . !mkdir modelout !python -m spacy package --meta meta.json /content/models/model-best modelout . âœ” Loaded meta.json from file meta.json âœ” Successfully created package &#39;ga_idt_lg-1.0.0&#39; modelout/ga_idt_lg-1.0.0 To build the package, run `python setup.py sdist` in this directory. . import os os.chdir(&#39;/content/modelout/ga_idt_lg-1.0.0&#39;) !python setup.py sdist . running sdist running egg_info creating ga_idt_lg.egg-info writing ga_idt_lg.egg-info/PKG-INFO writing dependency_links to ga_idt_lg.egg-info/dependency_links.txt writing requirements to ga_idt_lg.egg-info/requires.txt writing top-level names to ga_idt_lg.egg-info/top_level.txt writing manifest file &#39;ga_idt_lg.egg-info/SOURCES.txt&#39; reading manifest file &#39;ga_idt_lg.egg-info/SOURCES.txt&#39; reading manifest template &#39;MANIFEST.in&#39; writing manifest file &#39;ga_idt_lg.egg-info/SOURCES.txt&#39; warning: sdist: standard file not found: should have one of README, README.rst, README.txt, README.md running check creating ga_idt_lg-1.0.0 creating ga_idt_lg-1.0.0/ga_idt_lg creating ga_idt_lg-1.0.0/ga_idt_lg.egg-info creating ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0 creating ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/parser creating ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/tagger creating ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/vocab copying files to ga_idt_lg-1.0.0... copying MANIFEST.in -&gt; ga_idt_lg-1.0.0 copying meta.json -&gt; ga_idt_lg-1.0.0 copying setup.py -&gt; ga_idt_lg-1.0.0 copying ga_idt_lg/__init__.py -&gt; ga_idt_lg-1.0.0/ga_idt_lg copying ga_idt_lg/meta.json -&gt; ga_idt_lg-1.0.0/ga_idt_lg copying ga_idt_lg.egg-info/PKG-INFO -&gt; ga_idt_lg-1.0.0/ga_idt_lg.egg-info copying ga_idt_lg.egg-info/SOURCES.txt -&gt; ga_idt_lg-1.0.0/ga_idt_lg.egg-info copying ga_idt_lg.egg-info/dependency_links.txt -&gt; ga_idt_lg-1.0.0/ga_idt_lg.egg-info copying ga_idt_lg.egg-info/not-zip-safe -&gt; ga_idt_lg-1.0.0/ga_idt_lg.egg-info copying ga_idt_lg.egg-info/requires.txt -&gt; ga_idt_lg-1.0.0/ga_idt_lg.egg-info copying ga_idt_lg.egg-info/top_level.txt -&gt; ga_idt_lg-1.0.0/ga_idt_lg.egg-info copying ga_idt_lg/ga_idt_lg-1.0.0/meta.json -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0 copying ga_idt_lg/ga_idt_lg-1.0.0/tokenizer -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0 copying ga_idt_lg/ga_idt_lg-1.0.0/parser/cfg -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/parser copying ga_idt_lg/ga_idt_lg-1.0.0/parser/model -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/parser copying ga_idt_lg/ga_idt_lg-1.0.0/parser/moves -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/parser copying ga_idt_lg/ga_idt_lg-1.0.0/tagger/cfg -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/tagger copying ga_idt_lg/ga_idt_lg-1.0.0/tagger/model -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/tagger copying ga_idt_lg/ga_idt_lg-1.0.0/tagger/tag_map -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/tagger copying ga_idt_lg/ga_idt_lg-1.0.0/vocab/key2row -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/vocab copying ga_idt_lg/ga_idt_lg-1.0.0/vocab/lexemes.bin -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/vocab copying ga_idt_lg/ga_idt_lg-1.0.0/vocab/strings.json -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/vocab copying ga_idt_lg/ga_idt_lg-1.0.0/vocab/vectors -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/vocab Writing ga_idt_lg-1.0.0/setup.cfg creating dist Creating tar archive removing &#39;ga_idt_lg-1.0.0&#39; (and everything under it) . !cat /content/models/model-best/meta.json . { &#34;lang&#34;:&#34;ga&#34;, &#34;name&#34;:&#34;model&#34;, &#34;version&#34;:&#34;0.0.0&#34;, &#34;spacy_version&#34;:&#34;&gt;=2.2.4&#34;, &#34;description&#34;:&#34;&#34;, &#34;author&#34;:&#34;&#34;, &#34;email&#34;:&#34;&#34;, &#34;url&#34;:&#34;&#34;, &#34;license&#34;:&#34;&#34;, &#34;vectors&#34;:{ &#34;width&#34;:300, &#34;vectors&#34;:316836, &#34;keys&#34;:316836, &#34;name&#34;:&#34;ga_model.vectors&#34; }, &#34;pipeline&#34;:[ &#34;tagger&#34;, &#34;parser&#34; ], &#34;factories&#34;:{ &#34;tagger&#34;:&#34;tagger&#34;, &#34;parser&#34;:&#34;parser&#34; }, &#34;labels&#34;:{ &#34;tagger&#34;:[ &#34;!&#34;, &#34;.&#34;, &#34;...&#34;, &#34;?&#34;, &#34;Abr&#34;, &#34;Ad&#34;, &#34;Adj&#34;, &#34;Art&#34;, &#34;CM&#34;, &#34;CU&#34;, &#34;Cmp&#34;, &#34;Cmpd&#34;, &#34;CmpdNoGen&#34;, &#34;Comp&#34;, &#34;Cond&#34;, &#34;Coord&#34;, &#34;Cop&#34;, &#34;Cp&#34;, &#34;Deg&#34;, &#34;Dem&#34;, &#34;Det&#34;, &#34;Dir&#34;, &#34;Foreign&#34;, &#34;FutInd&#34;, &#34;Gn&#34;, &#34;Idf&#34;, &#34;Imper&#34;, &#34;Inf&#34;, &#34;Item&#34;, &#34;Itj&#34;, &#34;Its&#34;, &#34;Loc&#34;, &#34;Nm&#34;, &#34;Noun&#34;, &#34;Num&#34;, &#34;PastImp&#34;, &#34;PastInd&#34;, &#34;Pat&#34;, &#34;Pers&#34;, &#34;Poss&#34;, &#34;Prep&#34;, &#34;PresImp&#34;, &#34;PresInd&#34;, &#34;PresSubj&#34;, &#34;Pron&#34;, &#34;Punct&#34;, &#34;Q&#34;, &#34;Ref&#34;, &#34;Rel&#34;, &#34;Simp&#34;, &#34;Subord&#34;, &#34;Subst&#34;, &#34;Sup&#34;, &#34;Temp&#34;, &#34;Unknown&#34;, &#34;VD&#34;, &#34;VI&#34;, &#34;VT&#34;, &#34;VTI&#34;, &#34;Vb&#34;, &#34;Voc&#34;, &#34;Web&#34;, &#34;_SP&#34;, &#34;cionn&#34; ], &#34;parser&#34;:[ &#34;ROOT&#34;, &#34;acl:relcl&#34;, &#34;advcl&#34;, &#34;advmod&#34;, &#34;amod&#34;, &#34;appos&#34;, &#34;case&#34;, &#34;cc&#34;, &#34;ccomp&#34;, &#34;compound&#34;, &#34;conj&#34;, &#34;cop&#34;, &#34;csubj:cleft&#34;, &#34;csubj:cop&#34;, &#34;dep&#34;, &#34;det&#34;, &#34;fixed&#34;, &#34;flat&#34;, &#34;flat:name&#34;, &#34;mark&#34;, &#34;mark:prt&#34;, &#34;nmod&#34;, &#34;nmod:poss&#34;, &#34;nsubj&#34;, &#34;nummod&#34;, &#34;obj&#34;, &#34;obl&#34;, &#34;obl:prep&#34;, &#34;obl:tmod&#34;, &#34;parataxis&#34;, &#34;punct&#34;, &#34;xcomp&#34;, &#34;xcomp:pred&#34; ] }, &#34;accuracy&#34;:{ &#34;tags_acc&#34;:92.23, &#34;token_acc&#34;:100.0, &#34;las&#34;:68.3640850205, &#34;uas&#34;:80.5899837362, &#34;las_per_type&#34;:{ &#34;nummod&#34;:{ &#34;p&#34;:70.0, &#34;r&#34;:61.5384615385, &#34;f&#34;:65.4970760234 }, &#34;root&#34;:{ &#34;p&#34;:88.0266075388, &#34;r&#34;:88.0266075388, &#34;f&#34;:88.0266075388 }, &#34;case&#34;:{ &#34;p&#34;:88.8535031847, &#34;r&#34;:91.7763157895, &#34;f&#34;:90.2912621359 }, &#34;obl&#34;:{ &#34;p&#34;:47.0031545741, &#34;r&#34;:54.9815498155, &#34;f&#34;:50.6802721088 }, &#34;mark:prt&#34;:{ &#34;p&#34;:71.1538461538, &#34;r&#34;:81.9620253165, &#34;f&#34;:76.1764705882 }, &#34;ccomp&#34;:{ &#34;p&#34;:40.2777777778, &#34;r&#34;:47.5409836066, &#34;f&#34;:43.6090225564 }, &#34;nsubj&#34;:{ &#34;p&#34;:75.1824817518, &#34;r&#34;:79.7213622291, &#34;f&#34;:77.3854244929 }, &#34;obj&#34;:{ &#34;p&#34;:55.5555555556, &#34;r&#34;:49.2957746479, &#34;f&#34;:52.2388059701 }, &#34;nmod&#34;:{ &#34;p&#34;:52.912142152, &#34;r&#34;:54.8618219038, &#34;f&#34;:53.8693467337 }, &#34;mark&#34;:{ &#34;p&#34;:82.7715355805, &#34;r&#34;:72.6973684211, &#34;f&#34;:77.408056042 }, &#34;xcomp&#34;:{ &#34;p&#34;:60.4743083004, &#34;r&#34;:65.3846153846, &#34;f&#34;:62.8336755647 }, &#34;acl:relcl&#34;:{ &#34;p&#34;:47.2602739726, &#34;r&#34;:53.488372093, &#34;f&#34;:50.1818181818 }, &#34;xcomp:pred&#34;:{ &#34;p&#34;:44.0476190476, &#34;r&#34;:59.6774193548, &#34;f&#34;:50.6849315068 }, &#34;amod&#34;:{ &#34;p&#34;:57.5438596491, &#34;r&#34;:54.3046357616, &#34;f&#34;:55.8773424191 }, &#34;det&#34;:{ &#34;p&#34;:92.8480204342, &#34;r&#34;:94.0491591203, &#34;f&#34;:93.4447300771 }, &#34;csubj:cleft&#34;:{ &#34;p&#34;:47.2222222222, &#34;r&#34;:27.4193548387, &#34;f&#34;:34.693877551 }, &#34;obl:prep&#34;:{ &#34;p&#34;:77.6041666667, &#34;r&#34;:65.6387665198, &#34;f&#34;:71.1217183771 }, &#34;advcl&#34;:{ &#34;p&#34;:54.4, &#34;r&#34;:49.2753623188, &#34;f&#34;:51.711026616 }, &#34;parataxis&#34;:{ &#34;p&#34;:42.4242424242, &#34;r&#34;:27.4509803922, &#34;f&#34;:33.3333333333 }, &#34;nmod:poss&#34;:{ &#34;p&#34;:73.4939759036, &#34;r&#34;:75.3086419753, &#34;f&#34;:74.3902439024 }, &#34;cc&#34;:{ &#34;p&#34;:78.9473684211, &#34;r&#34;:79.5454545455, &#34;f&#34;:79.2452830189 }, &#34;conj&#34;:{ &#34;p&#34;:42.7609427609, &#34;r&#34;:42.0529801325, &#34;f&#34;:42.4040066778 }, &#34;dep&#34;:{ &#34;p&#34;:0.0, &#34;r&#34;:0.0, &#34;f&#34;:0.0 }, &#34;compound&#34;:{ &#34;p&#34;:75.0, &#34;r&#34;:26.0869565217, &#34;f&#34;:38.7096774194 }, &#34;flat&#34;:{ &#34;p&#34;:64.1025641026, &#34;r&#34;:64.9350649351, &#34;f&#34;:64.5161290323 }, &#34;cop&#34;:{ &#34;p&#34;:69.3251533742, &#34;r&#34;:70.625, &#34;f&#34;:69.9690402477 }, &#34;flat:name&#34;:{ &#34;p&#34;:63.4782608696, &#34;r&#34;:51.4084507042, &#34;f&#34;:56.8093385214 }, &#34;obl:tmod&#34;:{ &#34;p&#34;:66.6666666667, &#34;r&#34;:2.7397260274, &#34;f&#34;:5.2631578947 }, &#34;advmod&#34;:{ &#34;p&#34;:66.2745098039, &#34;r&#34;:65.0, &#34;f&#34;:65.6310679612 }, &#34;appos&#34;:{ &#34;p&#34;:21.9512195122, &#34;r&#34;:20.9302325581, &#34;f&#34;:21.4285714286 }, &#34;flat:foreign&#34;:{ &#34;p&#34;:0.0, &#34;r&#34;:0.0, &#34;f&#34;:0.0 }, &#34;fixed&#34;:{ &#34;p&#34;:74.7663551402, &#34;r&#34;:61.0687022901, &#34;f&#34;:67.2268907563 }, &#34;csubj:cop&#34;:{ &#34;p&#34;:62.5, &#34;r&#34;:55.5555555556, &#34;f&#34;:58.8235294118 }, &#34;discourse&#34;:{ &#34;p&#34;:0.0, &#34;r&#34;:0.0, &#34;f&#34;:0.0 }, &#34;case:voc&#34;:{ &#34;p&#34;:0.0, &#34;r&#34;:0.0, &#34;f&#34;:0.0 }, &#34;vocative&#34;:{ &#34;p&#34;:0.0, &#34;r&#34;:0.0, &#34;f&#34;:0.0 } } }, &#34;speed&#34;:{ &#34;cpu&#34;:13038.7132631094, &#34;gpu&#34;:null, &#34;nwords&#34;:10000 } } . import os os.chdir(&#39;/content&#39;) !rm -rf modelout !mkdir modelout !rm meta.json . !cat meta.json . { &#34;name&#34;: &#34;ga_idt_sm&#34;, &#34;lang&#34;: &#34;ga&#34;, &#34;version&#34;: &#34;1.0.0&#34;, &#34;spacy_version&#34;: &#34;&gt;=2.0.0,&lt;3.0.0&#34;, &#34;description&#34;: &#34;Irish model for spaCy trained on IDT&#34;, &#34;author&#34;: &#34;Jim O&#39;Regan&#34;, &#34;email&#34;: &#34;jaoregan@tcd.ie&#34;, &#34;license&#34;: &#34;CC BY-SA 3.0&#34;, &#34;pipeline&#34;: [&#34;tagger&#34;, &#34;parser&#34;, &#34;ner&#34;] } .",
            "url": "https://jimregan.github.io/notes/spacy/idt/2020/09/14/train-spacy-idt.html",
            "relUrl": "/spacy/idt/2020/09/14/train-spacy-idt.html",
            "date": " â€¢ Sep 14, 2020"
        }
        
    
  
    
        ,"post218": {
            "title": "Evernote web clips, 30/8/2020",
            "content": "Language-Agnostic BERT Sentence Embedding . End-to-End Automatic Pronunciation Error Detection Based on Improved Hybrid CTC/Attention Architecture . Festival Speech Synthesis System - 13 Lexicons . awslabs/mlm-scoring .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2020/08/30/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2020/08/30/evernote-links.html",
            "date": " â€¢ Aug 30, 2020"
        }
        
    
  
    
        ,"post219": {
            "title": "Javascript hoops",
            "content": "!git clone https://github.com/jimregan/coco-ssd-ga . Cloning into &#39;coco-ssd-ga&#39;... remote: Enumerating objects: 55, done. remote: Counting objects: 100% (55/55), done. remote: Compressing objects: 100% (38/38), done. remote: Total 55 (delta 17), reused 48 (delta 14), pack-reused 0 Unpacking objects: 100% (55/55), done. . import os os.chdir(&#39;coco-ssd-ga&#39;) . !npm install -g yarn rimraf browserify typescript ts-node @tensorflow/tfjs-core @tensorflow/tfjs-converter . &gt; yarn@1.22.10 preinstall /tools/node/lib/node_modules/yarn &gt; :; (node ./preinstall.js &gt; /dev/null 2&gt;&amp;1 || true) /tools/node/bin/browserify -&gt; /tools/node/lib/node_modules/browserify/bin/cmd.js /tools/node/bin/rimraf -&gt; /tools/node/lib/node_modules/rimraf/bin.js /tools/node/bin/ts-node -&gt; /tools/node/lib/node_modules/ts-node/dist/bin.js /tools/node/bin/ts-script -&gt; /tools/node/lib/node_modules/ts-node/dist/bin-script-deprecated.js /tools/node/bin/ts-node-script -&gt; /tools/node/lib/node_modules/ts-node/dist/bin-script.js /tools/node/bin/ts-node-transpile-only -&gt; /tools/node/lib/node_modules/ts-node/dist/bin-transpile.js /tools/node/bin/tsc -&gt; /tools/node/lib/node_modules/typescript/bin/tsc /tools/node/bin/tsserver -&gt; /tools/node/lib/node_modules/typescript/bin/tsserver /tools/node/bin/yarn -&gt; /tools/node/lib/node_modules/yarn/bin/yarn.js /tools/node/bin/yarnpkg -&gt; /tools/node/lib/node_modules/yarn/bin/yarn.js + rimraf@3.0.2 + yarn@1.22.10 + browserify@17.0.0 + ts-node@9.1.1 + @tensorflow/tfjs-converter@3.5.0 + @tensorflow/tfjs-core@3.5.0 + typescript@4.2.4 added 203 packages from 137 contributors in 12.754s . !npm install . npm WARN deprecated fsevents@2.1.3: &#34;Please update to latest v2.3 or v2.2&#34; npm WARN deprecated core-js@2.6.12: core-js@&lt;3 is no longer maintained and not recommended for usage due to the number of issues. Please, upgrade your dependencies to the actual version of core-js@3. &gt; core-js@2.6.12 postinstall /content/coco-ssd-ga/node_modules/core-js &gt; node -e &#34;try{require(&#39;./postinstall&#39;)}catch(e){}&#34; Thank you for using core-js ( https://github.com/zloirock/core-js ) for polyfilling JavaScript standard library! The project needs your help! Please consider supporting of core-js on Open Collective or Patreon: &gt; https://opencollective.com/core-js &gt; https://www.patreon.com/zloirock Also, the author of core-js ( https://github.com/zloirock ) is looking for a good job -) npm notice created a lockfile as package-lock.json. You should commit this file. npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@~2.1.2 (node_modules/rollup/node_modules/fsevents): npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@2.1.3: wanted {&#34;os&#34;:&#34;darwin&#34;,&#34;arch&#34;:&#34;any&#34;} (current: {&#34;os&#34;:&#34;linux&#34;,&#34;arch&#34;:&#34;x64&#34;}) npm WARN @rollup/plugin-typescript@3.1.1 requires a peer of rollup@^1.20.0 but none is installed. You must install peer dependencies yourself. added 196 packages from 157 contributors and audited 197 packages in 10.534s 10 packages are looking for funding run `npm fund` for details found 0 vulnerabilities â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•® â”‚ â”‚ â”‚ New major version of npm available! 6.14.8 â†’ 7.11.1 â”‚ â”‚ Changelog: https://github.com/npm/cli/releases/tag/v7.11.1 â”‚ â”‚ Run npm install -g npm to update! â”‚ â”‚ â”‚ â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯ . !yarn build . yarn run v1.22.10 $ rimraf dist &amp;&amp; tsc Done in 6.76s. . !npm install yalc . npm WARN @rollup/plugin-typescript@3.1.1 requires a peer of rollup@^1.20.0 but none is installed. You must install peer dependencies yourself. npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@2.1.3 (node_modules/fsevents): npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@2.1.3: wanted {&#34;os&#34;:&#34;darwin&#34;,&#34;arch&#34;:&#34;any&#34;} (current: {&#34;os&#34;:&#34;linux&#34;,&#34;arch&#34;:&#34;x64&#34;}) + yalc@1.0.0-pre.51 updated 1 package and audited 197 packages in 2.25s 8 packages are looking for funding run `npm fund` for details found 0 vulnerabilities . !npm install -g cross-env . /tools/node/bin/cross-env -&gt; /tools/node/lib/node_modules/cross-env/src/bin/cross-env.js /tools/node/bin/cross-env-shell -&gt; /tools/node/lib/node_modules/cross-env/src/bin/cross-env-shell.js + cross-env@7.0.3 added 7 packages from 5 contributors in 0.789s . !npm install -g @tensorflow/tfjs-core @tensorflow/tfjs-converter rollup yalc !npm install --save install !yarn run publish-local . . /tools/node/bin/rollup -&gt; /tools/node/lib/node_modules/rollup/dist/bin/rollup /tools/node/bin/yalc -&gt; /tools/node/lib/node_modules/yalc/src/yalc.js npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@~2.3.1 (node_modules/rollup/node_modules/fsevents): npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@2.3.2: wanted {&#34;os&#34;:&#34;darwin&#34;,&#34;arch&#34;:&#34;any&#34;} (current: {&#34;os&#34;:&#34;linux&#34;,&#34;arch&#34;:&#34;x64&#34;}) + rollup@2.45.2 + yalc@1.0.0-pre.51 + @tensorflow/tfjs-core@3.5.0 + @tensorflow/tfjs-converter@3.5.0 updated 4 packages in 3.883s npm WARN @rollup/plugin-typescript@3.1.1 requires a peer of rollup@^1.20.0 but none is installed. You must install peer dependencies yourself. npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@2.1.3 (node_modules/fsevents): npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@2.1.3: wanted {&#34;os&#34;:&#34;darwin&#34;,&#34;arch&#34;:&#34;any&#34;} (current: {&#34;os&#34;:&#34;linux&#34;,&#34;arch&#34;:&#34;x64&#34;}) + install@0.13.0 added 1 package from 1 contributor and audited 198 packages in 1.647s 10 packages are looking for funding run `npm fund` for details found 0 vulnerabilities yarn run v1.22.10 $ yarn build &amp;&amp; rollup -c &amp;&amp; yalc push . $ rimraf dist &amp;&amp; tsc src/index.ts â†’ dist/coco-ssd.node.js... created dist/coco-ssd.node.js in 8.9s coco-ssd-ga@2.1.0 published in store. Done in 16.51s. . !npm install -g browserify . /tools/node/bin/browserify -&gt; /tools/node/lib/node_modules/browserify/bin/cmd.js + browserify@17.0.0 updated 1 package in 4.871s . !npm i minify -g . /tools/node/bin/minify -&gt; /tools/node/lib/node_modules/minify/bin/minify.js + minify@7.0.1 added 26 packages from 52 contributors in 1.951s . !browserify /content/coco-ssd-ga/dist/coco-ssd.node.js --s cocoGa -o /content/coco-ssd-ga/dist/coco-ssd.browser.js . !minify /content/coco-ssd-ga/dist/coco-ssd.browser.js &gt; /content/coco-ssd-ga/dist/coco-ssd.min.js .",
            "url": "https://jimregan.github.io/notes/web/coco-ssd/2020/08/12/coco-ssd-ga.html",
            "relUrl": "/web/coco-ssd/2020/08/12/coco-ssd-ga.html",
            "date": " â€¢ Aug 12, 2020"
        }
        
    
  
    
        ,"post220": {
            "title": "Evernote web clips, 9/8/2020",
            "content": "LM Rescoring . any example on lattice rescoring for large language model . Lattice re-scoring during manual editing for automatic error correction of ASR transcripts . Neural Network Language Modeling with Letter-Based Features and Importance Sampling . Tutorial - RiveScript.com . An Overview of Multi-Task Learning in Speech Recognition . aalto-speech/subword-kaldi Properly handle position-dependent phones in a subword lexicon FST . wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2020/08/09/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2020/08/09/evernote-links.html",
            "date": " â€¢ Aug 9, 2020"
        }
        
    
  
    
        ,"post221": {
            "title": "Evernote web clips, 8/7/2020",
            "content": "Muskerry pronunciation . Dive into Deep Learning . One LEGO at a Time - Explaining the Math of how Neural Networks Learn with Implementation from Scratch . MULTI-LINGUAL AUTOMATIC PHONEME CLUSTERING . Closleabhair: 13 Irish language audiobooks you can listen to for free online . Measuring Unsupervised Acoustic Clustering through Phoneme Pair Merge-and-Split Tests . The General Ideas of Word Embeddings .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2020/07/08/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2020/07/08/evernote-links.html",
            "date": " â€¢ Jul 8, 2020"
        }
        
    
  
    
        ,"post222": {
            "title": "Boat parts",
            "content": "en pron. pl . mast | Â  | maszt | . jib | Â  | fok | . mainsail | Â  | grot | . forestay | Â  | forsztag | . foremast | Â  | fokmaszt | . shroud | Â  | wanta | . tack | Â  | hals | . clew | Â  | rÃ³g szotowy | . stern | Â  | rufa | . bow | Â  | dziÃ³b | . hull | Â  | kadÅ‚ub | . tiller | Â  | rumpel | . boom | Â  | bom | . gunwale | (/ËˆÉ¡ÊŒnÉ™l/ - ganl) | reling | . board | Â  | pokÅ‚ad | . rudder | Â  | ster | . halyard | Â  | faÅ‚ (halliard) | . head | Â  | lik gÃ³rny | . leech | Â  | lik wolny | . luff | Â  | lik przedni | . foot | Â  | lik dolny | . boatswain | /ËˆbÉ™ÊŠsnÌ©/ (bosn) | bosman | . coxswain | Â  | sternik | .",
            "url": "https://jimregan.github.io/notes/english%20teaching/pruszk%C3%B3w/2020/06/10/boat-parts.html",
            "relUrl": "/english%20teaching/pruszk%C3%B3w/2020/06/10/boat-parts.html",
            "date": " â€¢ Jun 10, 2020"
        }
        
    
  
    
        ,"post223": {
            "title": "Interesting links, 16/3/2020",
            "content": "Pocketsphinx.js - Speech Recognition in JavaScript and WebAssembly . RiveScript - Artificial Intelligence Scripting Language . andi611/Mockingjay-Speech-Representation Official Implementation of Mockingjay in Pytorch . grtzsohalf/Audio-Phonetic-and-Semantic-Embedding . Phonetic-and-Semantic Embedding of Spoken Words with Applications in Spoken Content Retrieval . Tesseract.js â€“ pure Javascript port of the popular Tesseract OCR engine. . microsoft/Recognizers-Text Microsoft.Recognizers.Text provides recognition and resolution of numbers, units, and date/time expressed in multiple languages .",
            "url": "https://jimregan.github.io/notes/links/2020/03/16/misc-links.html",
            "relUrl": "/links/2020/03/16/misc-links.html",
            "date": " â€¢ Mar 16, 2020"
        }
        
    
  
    
        ,"post224": {
            "title": "Evernote web clips, 15/3/2020",
            "content": "Open Challenge for Correcting Errors of Speech Recognition Systems . Understanding RNNs . Unsupervised Pre-training for Speech Recognition wav2vec . PodchraoltaÃ­ Gaeilge . Universal Phone Recognition with a Multilingual Allophone System . Re-Scoring Word Lattices from Automatic Speech Recognition System Based on Manual Error Corrections . ASR Context-Sensitive Error Correction Based on Microsoft N-Gram Dataset . Results of the IMPACT project .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2020/03/15/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2020/03/15/evernote-links.html",
            "date": " â€¢ Mar 15, 2020"
        }
        
    
  
    
        ,"post225": {
            "title": "ClarinPL SpeechTools links",
            "content": "ForcedAlign/run.sh . ./steps/make_mfcc.sh --nj 1 data ./steps/compute_cmvn_stats.sh data ./local_utils/prepare_dict.sh data dict ./utils/prepare_lang.sh dict &quot;&lt;unk&gt;&quot; tmp lang ./steps/align_fmllr.sh --nj 1 --beam ${beam} --retry-beam ${retry_beam} data lang tri3b_mmi ali ./steps/get_train_ctm.sh data lang ali ./local_utils/get_phoneme_ctm.sh data lang ali awk &#39;$0=&quot;@&quot;$0&#39; ali/phonectm | cat ali/ctm - | sort -r -k3n &gt; $out . ForcedAlign/run_eaf.sh . if $phones ; then ./local_utils/get_phoneme_ctm.sh --use-segments false data lang ali python3 local_utils/ctm2eaf.py --phones-ctm ali/phonectm ali/ctm data/seg2tier ${eaf_in} ${eaf_out} else python3 local_utils/ctm2eaf.py ali/ctm data/seg2tier ${eaf_in} ${eaf_out} fi . ForcedAlign/run_segments.sh . SegmentAlign/run.sh . misc/transcribe_word_list.sh . misc/train_g2p.sh . SpeechActivityDetection/run.sh .",
            "url": "https://jimregan.github.io/notes/kaldi/2020/03/07/kaldi-pl-scripts.html",
            "relUrl": "/kaldi/2020/03/07/kaldi-pl-scripts.html",
            "date": " â€¢ Mar 7, 2020"
        }
        
    
  
    
        ,"post226": {
            "title": "SÃ©adna, Caibidil a hAon",
            "content": "SÃ‰ADNA. . CAIBIDIL A hAON. . Cois na tine. Peig, NÃ³ra, Gobnait, SÃ­le bheag, agus CÃ¡it NÃ­ Bhuachalla. . NÃ³ra.â€”A Pheig, inis scÃ©al dÃºinn. . Peig.â€”Bâ€™ait liom san! Inis fÃ©in scÃ©al. . Gobnait.â€”NÃ­l aon mhaith inti, a Pheig. Bâ€™fhearr linn do scÃ©alsa. . SÃ­le.â€”Dein, a Pheig, agus beimid an-shocair. . Peig.â€”Nach maith nÃ¡r fhanais socair arÃ©ir, nuair a bhÃ­ â€œMadra na nOcht gCosâ€ agam dÃ¡ insint! . SÃ­le.â€”Mar sin nÃ­ stadfadh CÃ¡it NÃ­ Bhuachalla ach am priocadh. . CÃ¡it.â€”Thugais dâ€™Ã©itheach! NÃ­ rabhas-sa ad phriocadh, a chaillichÃ­n! . Gobnait.â€”NÃ¡ bac Ã­ fÃ©in, a ChÃ¡it. NÃ­ raibh Ã©inne Ã¡ priocadh ach Ã­ Ã¡ ligeant uirthi. . SÃ­le.â€”Do bhÃ­, is dÃ³in; agus mura mbeadh go raibh, nÃ­ liÃºfainn. . NÃ³ra.â€”Abair le Peig nÃ¡ liÃºfair anois, a ShÃ­le, agus â€˜neosaidh sÃ­ scÃ©al dÃºinn. . SÃ­le.â€”NÃ­ liÃºfad, a Pheig, pÃ© rud a imeoidh orm. . Peig.â€”MÃ¡s ea, suigh anso i mâ€™aice, i dtreo nÃ¡ fÃ©adfaidh Ã©inne thÃº phriocadh a gan fhios dom. . CÃ¡it.â€”BÃ­odh geall go bpriocfaidh an cat Ã­. A thoice bhig, bheadh scÃ©al breÃ¡ againn mura mbeadh tÃº fÃ©in agus do chuid liÃºirÃ­. . Gobnait.â€”Ã‰ist, a ChÃ¡it, nÃ³ cuirfir ag gol Ã­, agus beimid gan scÃ©al. MÃ¡ curtar fearg ar Pheig nÃ­ â€˜neosaidh sÃ­ aon scÃ©al anocht. Sea anois, a Pheig, tÃ¡ gach Ã©inne ciÃºin ag brath ar scÃ©al uait. . Peig.â€”BhÃ­ fear ann fadÃ³ agus is Ã© ainm a bhÃ­ air nÃ¡ SÃ©adna. GrÃ©asaÃ­ ab ea Ã©. BhÃ­ tigh beag deas cluthar aige ag bun cnoic, ar thaobh na fothana. BhÃ­ cathaoir shÃºgÃ¡in aige do dhein sÃ© fÃ©in dÃ³ fÃ©in, agus ba ghnÃ¡th leis suÃ­ inti um thrÃ¡thnÃ³na, nuair a bhÃ­odh obair an lae crÃ­ochnaithe, agus nuair a shuÃ­odh sÃ© inti bhÃ­odh sÃ© ar a shÃ¡stacht. BhÃ­ mealbhÃ³g mine aige ar crochadh in aice na tine, agus anois agus arÃ­s chuireadh sÃ© a lÃ¡mh inti agus thÃ³gadh sÃ© lÃ¡n a dhoirn den mhin, agus bhÃ­odh sÃ© Ã¡ cogaint ar a shuaimhneas. BhÃ­ crann Ãºll ag fÃ¡s ar an dtaobh amuigh de dhoras aige, agus nuair a bhÃ­odh tart air Ã³ bheith ag cogaint na mine, chuireadh sÃ© lÃ¡mh sa chrann san agus thÃ³gadh sÃ© ceann desna hÃºllaibh, agus dâ€™itheadh sÃ© Ã©. . SÃ­le.â€”Ã“, a thiarcais, a Pheig, nÃ¡r dheas Ã©! . Peig.â€”CÃ© acu an chathaoir nÃ³ an mhin nÃ³ an tâ€‘Ãºll ba dheas? . SÃ­le.â€”An tâ€‘Ãºll, gan amhras! . CÃ¡it.â€”Bâ€™fhearr liomsa an mhin. NÃ­ bhainfeadh an tâ€‘Ãºll an tâ€‘ocras de dhuine. . Gobnait.â€”Bâ€™fhearr liomsa an chathaoir, agus chuirfinn Peig ina suÃ­ inti, ag insint na scÃ©al. . Peig.â€”Is maith chun plÃ¡mÃ¡is thÃº, a Ghobnait. . Gobnait.â€”Is fearr chun na scÃ©al tusa, a Pheig. Conas dâ€™imigh le SÃ©adna? . Peig.â€”LÃ¡ dÃ¡ raibh sÃ© ag dÃ©anamh brÃ³g, thug sÃ© fÃ© ndeara nÃ¡ raibh a thuilleadh leathair aige, nÃ¡ a thuilleadh snÃ¡ithe, nÃ¡ a thuilleadh cÃ©arach. BhÃ­ an taoibhÃ­n dÃ©anach suas agus an greim dÃ©anach curtha, agus nÃ­orbh fholÃ¡ir dÃ³ dul agus Ã¡bhar do sholÃ¡thar sula bhfÃ©adfadh sÃ© a thuilleadh brÃ³g a dhÃ©anamh. Do ghluais sÃ© ar maidin, agus bhÃ­ trÃ­ scillinge ina phÃ³ca, agus nÃ­ raibh sÃ© ach mÃ­le Ã³n dtigh nuair a bhuail duine bocht uime, a dâ€™iaraidh dÃ©irce. . â€œTabhair dhom dÃ©irc ar son an tSlÃ¡naitheora agus le hâ€‘anaman na marbh, agus tar cheann do shlÃ¡inte,â€ arsan duine bocht. . Thug SÃ©adna scilling dÃ³, agus ansan nÃ­ raibh aige ach dhÃ¡ scilling. DÃºirt sÃ© leis fÃ©in go mbâ€™fhÃ©idir go ndÃ©anfadh an dÃ¡ scilling a ghnÃ³. NÃ­ raibh sÃ© ach mÃ­le eile Ã³ bhaile nuair a bhuail bean bhocht uime agus Ã­ cos-nochtaithe. . â€œTabhair dhom cÃºnamh Ã©igin,â€ ar sise, â€œar son an tSlÃ¡naitheora, agus le hanaman do mharbh, agus tar cheann do shlÃ¡inte.â€ . Do ghlac trua dhÃ­ Ã©, agus thug sÃ© scilling di, agus dâ€™imigh sÃ­. Do bhÃ­ aon scilling amhÃ¡in ansan aige, ach do chomÃ¡in sÃ© leis, ag brath air go mbuailfeadh seans Ã©igin uime a chuirfeadh ar a chumas a ghnÃ³ a dhÃ©anamh. NÃ­orbh fhada gur casadh air leanbh agus Ã© ag gol le fuacht agus le hocras. â€œAr son an tSlÃ¡naitheora,â€ arsan leanbh, â€œtabhair dhom rud Ã©igin le nâ€‘ithe.â€ . BhÃ­ tigh Ã³sta i ngar dÃ³ibh, agus do chuaigh SÃ©adna isteach ann, agus cheannaigh sÃ© brÃ­c arÃ¡in agus thug sÃ© chun an linbh Ã©. Nuair a fuair an leanbh an tâ€‘arÃ¡n dâ€™athraigh a dhealbh. Dâ€™fhÃ¡s sÃ© suas inâ€‘airde, agus do las solas iontach ina shÃºilibh agus ina cheannachaibh, i dtreo go dtÃ¡inig scanradh ar ShÃ©anna. . SÃ­le.â€”Dia linn! a Pheig, is dÃ³cha gur thit SÃ©adna bocht i laige. . Peig.â€”NÃ­or thit; ach mÃ¡s ea, ba dhÃ­cheall dÃ³. Chomh luath agus dâ€™fhÃ©ad sÃ© labhairt, dÃºirt sÃ©:â€“ . â€œCad Ã© an saghas duine thusa?â€ Agus is Ã© freagra a fuair sÃ©:â€” . â€œA ShÃ©anna, tÃ¡ Dia buÃ­och dÃ­ot. Aingeal is ea mise. Is mÃ© an trÃ­Ãº hâ€‘aingeal gur thugais dÃ©irc dÃ³ inniu ar son an tSlÃ¡naitheora. Agus anois tÃ¡ trÃ­ ghuÃ­ agat le fÃ¡il Ã³ Dhia na glÃ³ire. Iar ar Dhia aon trÃ­ ghuÃ­ is toil leat, agus gheobhair iad. Ach tÃ¡ aon chomhairle amhÃ¡in agamsa le tabhairt duit.â€”NÃ¡ dearÃºd an TrÃ³caire.â€ . â€œAgus an ndeirir liom go bhfaighead mo ghuÃ­?â€ arsa SÃ©adna. . â€œDeirim, gan amhras,â€ arsan tâ€‘aingeal. . â€œTÃ¡ go maith,â€ arsa SÃ©adna. â€œTÃ¡ cathaoir bheag dheas sÃºgÃ¡in agam sa bhaile, agus an uile dhailtÃ­n a thagann isteach, nÃ­ folÃ¡ir leis suÃ­ inti. An chÃ©ad duine eile a shuÃ­fidh inti, ach mÃ© fÃ©in, go gceanglaÃ­ sÃ© inti!â€ . â€œFaire, faire, a ShÃ©anna,â€ arsan tâ€‘aingeal; â€œsin guÃ­ breÃ¡ imithe gan tairbhe. TÃ¡ dhÃ¡ cheann eile agat, agus nÃ¡ dearÃºd an TrÃ³caire.â€ . â€œTÃ¡,â€ arsa SÃ©adna, â€œmealbhÃ³igÃ­n mine agam sa bhaile, agus an uile dhailtÃ­n a thagann isteach, nÃ­ folÃ¡ir leis a dhorn a shÃ¡ inti. An chÃ©ad duine eile a chuirfidh lÃ¡mh sa mhealbhÃ³ig sin, ach mÃ© fÃ©in, go gceanglaÃ­ sÃ© inti, fÃ©ach!â€ . â€œÃ“, a ShÃ©anna, a ShÃ©anna, nÃ­l fasc agat,â€ arsan tâ€‘aingeal. â€œNÃ­l agat anois ach aon ghuÃ­ amhÃ¡in eile. Iar TrÃ³caire DÃ© do dâ€™anam.â€ . â€œÃ“, is fÃ­or dhuit,â€ arsa SÃ©adna, â€œba dhÃ³bair dom Ã© dhearÃºd. TÃ¡ crann beag Ãºll agam i leataoibh mo dhorais, agus an uile dhailtÃ­n a thagann an treo, nÃ­ folÃ¡ir leis a lÃ¡mh do chur in airde agus Ãºll do stathadh agus do bhreith leis. An chÃ©ad duine eile, ach mÃ© fÃ©in, a chuirfidh lÃ¡mh sa chrann san, go gceanglaÃ­ sÃ© ann!â€”Ã“! a dhaoine!â€ ar seisean, ag scairteadh ar ghÃ¡irÃ­, â€œnach agam a bheidh an spÃ³rt orthu!â€ . Nuair a thÃ¡inig sÃ© as na trithÃ­bh, dâ€™fhÃ©ach sÃ© suas agus bhÃ­ an tâ€‘aingeal imithe. Dhein sÃ© a mhachnamh air fÃ©in ar feadh tamaill mhaith. FÃ© dheireadh thiar thall, dÃºirt sÃ© leis fÃ©in: â€œFÃ©ach anois, nÃ­l aon amadÃ¡n in Ã‰irinn is mÃ³ nÃ¡ mÃ©! DÃ¡ mbeadh triÃºr ceangailte agam um an dtaca so, duine sa chathaoir, duine sa mhealbhÃ³ig, agus duine sa chrann, cad Ã© an mhaith a dhÃ©anfadh san domsa agus mÃ© i bhfad Ã³ bhaile, gan bia, gan deoch, gan airgead?â€ . NÃ­ tÃºisce a bhÃ­ an mÃ©id sin cainte rÃ¡ite aige nÃ¡ a thug sÃ© fÃ© ndeara os a chomhair amach, sa nâ€‘Ã¡it ina raibh an tâ€‘aingeal, fear fada caol dubh, agus Ã© ag glinniÃºint air, agus tine chreasa ag teacht as a dhÃ¡ shÃºil ina sprÃ©achaibh nimhe. BhÃ­ dhÃ¡ adhairc air mar bheadh ar phocÃ¡n gabhair; agus meigeall fada liathghorm garbh air, eireaball mar a bheadh ar mhadra rua, agus crÃºb ar chois leis mar chrÃºb thairbh. Do leath a bhÃ©al agus a dhÃ¡ shÃºil ar ShÃ©anna, agus do stad a chaint. I gceann tamaill do labhair an Fear Dubh. . â€œA ShÃ©anna,â€ ar seisean, â€œnÃ­ gÃ¡ dhuit aon eagla do bheith ort romhamsa. NÃ­lim ar tÃ­ do dhÃ­obhÃ¡la. Ba mhian liom tairbhe Ã©igin a dhÃ©anamh duit, dÃ¡ nglacfÃ¡ mo chomhairle. Do chloiseas thÃº, anois beag, Ã¡ rÃ¡ go rabhais gan bia, gan deoch, gan airgead. Thabharfainnse airgead do dhÃ³thain duit ar aon choinnÃ­oll bheag amhÃ¡in.â€ . â€œAgus greadadh trÃ© lÃ¡r do scairt!â€ arsa SÃ©adna, agus thÃ¡inig a chaint dÃ³; â€œnÃ¡ fÃ©adfÃ¡ an mÃ©id sin do rÃ¡ gan duine do mhilleadh ledâ€™ chuid glinniÃºna, pÃ© hÃ© thÃº fÃ©in?â€ . â€œIs cuma dhuit cÃ© hÃ© mÃ©, ach bhÃ©arfad an oiread airgid duit anois agus cheannÃ³idh an oiread leathair agus choimeÃ¡dfaidh ag obair thÃº go ceann trÃ­ mbliain ndÃ©ag, ar an gcoinnÃ­oll seoâ€”go dtiocfair liom an uair sin.â€ . â€œAgus mÃ¡ rÃ©idhtighim leat, cÃ¡ raghmaoÃ­d an uair sin?â€ . â€œCÃ¡ beag duit an cheist sin do chur nuair a bheidh an leathar Ã­dithe agus bheimid ag gluaiseacht?â€ . â€œTÃ¡ir gÃ©archÃºiseach. BÃ­odh agat. Feiceam an tâ€‘airgead.â€ . â€œTÃ¡irse gÃ©archÃºiseach. FÃ©ach!â€â€”do chuir an Fear Dubh a lÃ¡mh ina phÃ³ca agus tharraing sÃ© amach sparÃ¡n mÃ³r, agus as an sparÃ¡n do lig sÃ© amach ar a bhais carn beag dâ€™Ã³r bhreÃ¡ bhuÃ­. . â€œFÃ©ach!â€ ar seisean, agus shÃ­n sÃ© a lÃ¡mh agus chuir sÃ© an carn de phÃ­osaÃ­bh gleoite glÃ©ineacha suas fÃ© shÃºilibh ShÃ©anna bhoicht. Do shÃ­n SÃ©adna a dhÃ¡ lÃ¡imh, agus do leathadar a dhÃ¡ ladhar chun an Ã³ir. . â€œGo rÃ©idh!â€ arsan Fear Dubh, ag tarrang an Ã³ir chuige isteach. â€œNÃ­l an margadh dÃ©anta fÃ³s.â€ . â€œBÃ­odh ina mhargadh,â€ arsa SÃ©adna. . â€œGan teip?â€ arsan Fear Dubh. . â€œGan teip,â€ arsa SÃ©adna. . â€œDar bhrÃ­ na mionn?â€ arsan Fear Dubh. . â€œDar bhrÃ­ na mionn,â€ arsa SÃ©adna. .",
            "url": "https://jimregan.github.io/notes/irish/seadna/2020/02/15/seadna-caibidil-a-haon.html",
            "relUrl": "/irish/seadna/2020/02/15/seadna-caibidil-a-haon.html",
            "date": " â€¢ Feb 15, 2020"
        }
        
    
  
    
        ,"post227": {
            "title": "Evernote web clips, 10/1/2020",
            "content": "PDF - www.ilrweb.ie . Kaldi Tutorial . How to get timestamps of an audio file using pre-trained model with Kaldi . kaldi/create_segments_from_ctm.pl . kaldi/run_unk_model.sh . Create shared versions of get_ctm_conf.sh, add get_ctm_confâ€¦ . Added a new lexicon learning (adaptation) recipe for tedlium . Output-Gate Projected Gated Recurrent Unit for Speech Recognition . Improvements to multi_en tdnn-opgru/lstm recipes #2824 . Fix a typo in steps/dict/learn_lexicon_bayesian.sh #3288 . simple-g2p/run_simpleG2P.sh . Backstitch: Counteracting Finite-Sample Bias via Negative Steps . Acoustic data-driven lexicon learning based on a greedy pronunciation selection framework . Evaluating Natural Language Understanding Services for Conversational Question Answering Systems . [ASR Independent Hybrid Recurrent Neural Network Based Error Correction for Dialog System Applications | Request PDF](https://www.researchgate.net/publication/302498352_ASR_Independent_Hybrid_Recurrent_Neural_Network_Based_Error_Correction_for_Dialog_System_Applications) | . Improving Performance of End-to-End ASR on Numeric Sequences . REFORMER: THE EFFICIENT TRANSFORMER . Reformer: The Efficient Transformer - Pastebin.com . Fix issue in copy_lat_dir.sh affecting combine_lat_dirs.sh . kaldi/compute-gop.cc at b0f6bcb76824fc7ce0dbf8ecaba3467273bba1c7 . Make compute-gop work with missing alignments . Add layer for attention with bypass by danpovey . Incremental determinization . Handwriting recognition and language modeling with MXNet Gluon .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2020/01/10/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2020/01/10/evernote-links.html",
            "date": " â€¢ Jan 10, 2020"
        }
        
    
  
    
        ,"post228": {
            "title": "Evernote web clips, 9/1/2020",
            "content": "Luik 1 - Gospel of Luke in Ulster-Scots . Acoustic data-driven lexicon learning based on a greedy pronunciation selection framework . The Illustrated BERT, ELMo, and co. . A Visual Guide to Using BERT for the First Time . Zwroty angielskie przydatne u fryzjera .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2020/01/09/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2020/01/09/evernote-links.html",
            "date": " â€¢ Jan 9, 2020"
        }
        
    
  
    
        ,"post229": {
            "title": "Evernote web clips, 30/12/2019",
            "content": "Lesson 1: Deep Learning 2019 - Image classification . Arrayfire Getting Started . flashlight/examples . gulp21/languagetool-neural-network . Neural Network Rules - Development - LanguageTool Forum . Java Regex - Java Regular Expressions . PDF - www.speech.cs.cmu.edu . gf5353/deploytools . Books Â· LÃ©amh â€“ Learn Early Modern Irish . Deep Lip Reading . Add Chime 6 baseline system #3755 . Minority language resources: a guide - How to get fluent, with Dr Popkins . facebookresearch/detectron2 . PyTorch 1.3 adds mobile, privacy, quantization, and named tensors . Learning from Past Mistakes: Improving Automatic Speech Recognition Output via Noisy-Clean Phrase Context Modeling . Statistical Error Correction Methods for Domain-Specific ASR Systems . A simple module consistently outperforms self-attention and Transformer model on main NMT datasets with SoTA performance . Googleâ€™s Explainable AI service sheds light on how machine learning models make decisions . EdgeSpeechNets: Highly Efficient Deep Neural Networks for Speech Recognition on the Edge . Google AI technique reduces speech recognition errors by 29% . ASR Context-Sensitive Error Correction Based on Microsoft N-Gram Dataset . Automatic Speech Recognition Errors Detection and Correction: A Review . Creating and using ground truth OCR sample data for Finnish historical newspapers and journals . NBoost: Boost Elasticsearch Search Relevance by 80% with BERT : MachineLearning . CMU Sphinx Use Needleman-Wunsch algorithm to get results. . openslr.org Crowdsourced high-quality Basque speech data set . Added tri3b and chain training for Aurora4 #3638 . A Visual Guide to Using BERT for the First Time . Mathematics for Machine Learning . The Illustrated Word2vec . The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning) . Is mÃºinteoir Gaeilge mÃ©â€¦ . Gramadach - Blag Gaeilge SMPPS . Goodness of Pronunciation (GOP) #3703 . Talking Head Anime from a Single Image : MachineLearning . GELU better than RELU? : MachineLearning . [How to write vectorized code | ArrayFire](http://arrayfire.com/how-to-write-vectorized-code/) | . Post-Editing Error Correction Algorithm For Speech Recognition using Bing Spelling Suggestion . A spelling correction model for end-to-end speech recognition . Novelist Cormac McCarthyâ€™s tips on how to write a great science paper . How to do Unsupervised Clustering with Keras . Contrastive Predictive Coding Based Feature for Automatic Speaker Verification . Representation Learning with Contrastive Predictive Coding . Maven â€“ Maven on Windows .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2019/12/30/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2019/12/30/evernote-links.html",
            "date": " â€¢ Dec 30, 2019"
        }
        
    
  
    
        ,"post230": {
            "title": "Evernote web clips, 22/12/2019",
            "content": "KPWr . Marian :: MTM2017 Tutorial - Part 2 . Training and Adapting Multilingual NMT for Less-resourced and Morphologically Rich Languages . An Exploration of Neural Sequence-to-Sequence Architectures for Automatic Post-Editing .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2019/12/22/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2019/12/22/evernote-links.html",
            "date": " â€¢ Dec 22, 2019"
        }
        
    
  
    
        ,"post231": {
            "title": "Evernote web clips, 15/12/2019",
            "content": "Controlling Text Generation with Plug and Play Language Models . How To Code Modern Neural Networks Using Python and NumPy . Distilling knowledge from Neural Networks to build smaller and faster models .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2019/12/15/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2019/12/15/evernote-links.html",
            "date": " â€¢ Dec 15, 2019"
        }
        
    
  
    
        ,"post232": {
            "title": "Trick or Treat",
            "content": "Trick or treat is an American custom, but it has its origins in earlier customs: â€œguisingâ€, which was practiced in Scotland and Ireland; and â€œsoulingâ€, which was practiced in Britain and Ireland, but is more usually associated with England. . In â€œguisingâ€, children wore costumes (or â€œguisesâ€), and went from door to door, much like with trick or treat. The main difference was that children who went guising had to perform something - a joke, a song, or a poem - to receive a treat. . â€œSoulingâ€ involved people going in groups, offering to pray for the souls of family members of the people they visited: for this, they would receive a â€œsoul cakeâ€. . â€œTrick or treatâ€ is usually just something that people say - these days, people donâ€™t usually expect to have to play a trick - but in the 1990s, egging (throwing raw eggs) and TP-ing (throwing an opened roll of toilet paper, to â€œdecorateâ€ the house) were common â€œtricksâ€. .",
            "url": "https://jimregan.github.io/notes/english%20teaching/pruszk%C3%B3w/2019/10/31/trick-or-treat.html",
            "relUrl": "/english%20teaching/pruszk%C3%B3w/2019/10/31/trick-or-treat.html",
            "date": " â€¢ Oct 31, 2019"
        }
        
    
  
    
        ,"post233": {
            "title": "Harry Potter quiz",
            "content": "1. What is Harryâ€™s full address? . (The Cupboard under the stairs, 2 Privet Drive) . 2. What did Harry get for Christmas? . (The invisibility cloak) . 3. What did Harry get at the end of the movie? . (A photo album) . 4. What was the number of Harryâ€™s vault at Gringottâ€™s . 687 . 5. What was spelled on Harryâ€™s birthday cake? . Happee birthdae Harry . 6. Who taught Defence Against the Dark Arts? . Quirrell . 7. How many times did McGonagall appear as a cat? . Twice . 8. What is the name of the wizardâ€™s bank? . Gringottâ€™s . 9. What was the number of the vault Hagrid went to at Gringottâ€™s? . 713 . 10. What did Neville receive in the mail? . A rememberall . 11. What is the name of Harryâ€™s aunt? . Petunia . 12. What is the name of the ball that wins a game of quidditch? . The Golden Snitch . 13. What is the name of Hagridâ€™s dog . Fang/KieÅ‚ . 14. What is the name of the dog guarding the trap door? . Fluffy . 15. What was the name of Hagridâ€™s dragon? . Norbert . 16. How many points did Neville receive at the end of the movie? . 10 . 17. What was the name of the centaur? . Firenze . 18. Where was the snake at the start of the movie from? . Burma . 19. Where is Ronâ€™s brother studying dragons? . Romania . 20. What kind of dragon did Hagrid have? . A Norwegian Ridgeback . 21. How old was Harry when he found out he is a wizard? . 11 . 22. What flavour of Every Flavour Beans did Dumbledore eat in the hospital? . Ear wax . 23. Who was the wizard on the Chocolate Frog card that Harry opened on the train? . Dumbledore . 24. What is at the core of Harryâ€™s wand? . Phoenix feather .",
            "url": "https://jimregan.github.io/notes/english%20teaching/siemczyno/2019/07/28/hp-quiz.html",
            "relUrl": "/english%20teaching/siemczyno/2019/07/28/hp-quiz.html",
            "date": " â€¢ Jul 28, 2019"
        }
        
    
  
    
        ,"post234": {
            "title": "Treasure Island, Chapter 1 vocab",
            "content": "year of grace: year in the Christian era; year A.D. . Cove: an inlet, usually with high cliffs that can protect ships from the wind . Capstan: machine for putting force on ropes, usually on a ship . Grog: rum and water . â€œsittyatedâ€ - situated . â€œmoughtâ€ - might . berth - bunk for sleeping (usually on a ship); also, room for movement: to give someone a wide berth means to avoid them . keep a weather eye open - be alert (a weather eye was a tool for predicting the weather) . assizes - court hearing . be quit of - be rid of in modern English . rheumatics - rheumatism .",
            "url": "https://jimregan.github.io/notes/english%20teaching/pruszk%C3%B3w/2019/06/03/treasure-island-chapter-1.html",
            "relUrl": "/english%20teaching/pruszk%C3%B3w/2019/06/03/treasure-island-chapter-1.html",
            "date": " â€¢ Jun 3, 2019"
        }
        
    
  
    
        ,"post235": {
            "title": "Snatch vocabulary",
            "content": "Bust a cap in his ass: African-American slang. â€œBust a capâ€ means to shoot (a cap can be a small explosive used to set off a larger explosive, especially in mining, so in slang, itâ€™s a bullet); oneâ€™s ass can be used as an emphatic replacement for a pronoun: â€œmy ass is tiredâ€, â€œhe has to drag his ass to workâ€. Possibly from work oneâ€™s ass off (to work to the point of fatigue). . Yardie: a Jamaican (â€œyardâ€ in Jamaican Creole means â€œhomeâ€); more specifically, a member of a Jamaican gang . Goody gumdrops (or goody goody gumdrops): childish expression of happiness, usually sarcastic when used by adults. . Pisshead: person who regularly gets drunk. â€œPissâ€ can be used to mean alcohol (â€œWeâ€™re going on the pissâ€ = â€œweâ€™re going drinkingâ€); -head can be used to form a noun (usually derogatory) for a person whoâ€™s dedicated to something: a pothead likes to smoke marijuana (â€œpotâ€), a metalhead listens to heavy metal; it can also be added to other insults to imply stupidity (blockhead, shithead). . Look like curry to a pisshead: curry is an extremely popular post-pub food in Britain, so this is irresistible food. . Porky pies: rhyming slang for lies. Usually shortened to porkies. .",
            "url": "https://jimregan.github.io/notes/english%20teaching/pruszk%C3%B3w/2019/06/03/snatch-vocab.html",
            "relUrl": "/english%20teaching/pruszk%C3%B3w/2019/06/03/snatch-vocab.html",
            "date": " â€¢ Jun 3, 2019"
        }
        
    
  
    
        ,"post236": {
            "title": "Title",
            "content": "https://dumps.wikimedia.org/enwiktionary/ . !wget https://dumps.wikimedia.org/enwiktionary/20190501/enwiktionary-20190501-pages-articles-multistream.xml.bz2 . %%writefile extract-enwiktionary-ipa.pl #!/usr/bin/perl use warnings; use strict; use utf8; binmode(STDIN, &quot;:utf8&quot;); binmode(STDOUT, &quot;:utf8&quot;); binmode(STDERR, &quot;:utf8&quot;); my $title = &#39;&#39;; my $polish_seen = 0; while(&lt;&gt;) { if(/&lt;title&gt;([^&lt;]*)&lt; /title&gt;/) { $title = trim($1); $polish_seen = 0; } elsif(/== *Polish *==/) { $polish_seen = 1; } elsif(/== *([^=]*)==/) { if($1 !~ /polish/i) { $polish_seen = 0; } } elsif(/ { {IPA |([^}]*) } }/) { my $inner = $1; if($inner =~ / |/) { my @parts = split/ |/, $inner; if($#parts != 1) { if($inner =~ /lang=pl$|lang=pl |/) { for my $part (@parts) { next if($part =~ /^lang=pl$/); print &quot;$title t$part n&quot;; } } else { next; } } else { my $pron = ($parts[0] =~ /lang=/) ? $parts[1] : $parts[0]; my $lang = ($parts[0] =~ /lang=/) ? $parts[0] : $parts[1]; if($lang =~ /=pl$/) { print &quot;$title t$pron n&quot;; } else { next; } } } elsif($polish_seen) { print &quot;CHECK: t$title $inner n&quot;; } else { next; } $polish_seen = 0; } else { next; } } sub trim { my $var = shift; $var =~ s/^ *//; $var =~ s/ *$//; $var; } . !bzcat enwiktionary-20190501-pages-articles-multistream.xml.bz2|perl extract-enwiktionary-ipa.pl &gt; wikt-ipa.txt .",
            "url": "https://jimregan.github.io/notes/2019/05/19/get-polish-ipa-from-enwiktionary.html",
            "relUrl": "/2019/05/19/get-polish-ipa-from-enwiktionary.html",
            "date": " â€¢ May 19, 2019"
        }
        
    
  
    
        ,"post237": {
            "title": "Evernote web clips, 29/3/2019",
            "content": "Multilingual Speech Recognition With A Single End-To-End Model . Memory, attention, sequences . natsuhh / SWC . Building Kaldi on Windows: Part 1 . Yes you should understand backprop . The M-AILABS Speech Dataset â€“ caito .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2019/03/29/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2019/03/29/evernote-links.html",
            "date": " â€¢ Mar 29, 2019"
        }
        
    
  
    
        ,"post238": {
            "title": "Interesting links, 29/1/2019",
            "content": "FstContrib . OpenGrm Libraries . OpenGrm Thrax Grammar Compiler . OpenGrm Thrax tools . mjansche/tts-tutorial . google/sparrowhawk . google/language-resources . Free Linguistic Environment â€“ a grammar engineering platform for LFG. git . dcavar/treebankparsersa â€“ This is a tool that reads treebank files and generates a probabilistic grammar for use in FLE. . Practical Instructions for Working with LFG . Grammar Development with LFG and XLE . S --&gt; NP: (^ SUBJ)=! (! CASE)=NOM; VP: ^=!. &quot;indicate comments&quot; VP --&gt; V: ^=!; &quot;head&quot; (NP: (^ OBJ)=! &quot;() = optionality&quot; (! CASE)=ACC) PP*: ! $ (^ ADJUNCT). &quot;$ = set, * = Kleene star&quot; . astorfi/TensorFlow-World â€“ Simple and ready-to-use tutorials for TensorFlow .",
            "url": "https://jimregan.github.io/notes/links/2019/01/29/misc-links.html",
            "relUrl": "/links/2019/01/29/misc-links.html",
            "date": " â€¢ Jan 29, 2019"
        }
        
    
  
    
        ,"post239": {
            "title": "Last Christmas notes",
            "content": "For Christmas, the school insisted that we get the students to sing a song, and record it for their parents. So, with older students, we generally let them pick the song themselves. . I had two all-girl groups, and both chose â€œLast Christmasâ€ - fine by me, one set of notes. It also ended up being the song chosen by a group of mainly boys, because their other teacher foolishly mentioned that, having spent a Christmas working in retail in England, she really hated that song. Which I mentioned to them. Next lesson, she walked in to a serenade of â€œLast Christmasâ€, and immediately came across to the office to ask if I might know why that had happened. . . Very . We most often see â€œveryâ€ as an adverb which intensifies an adjective: very dark, very wet, etc., but it can also be used as an adjective meaning â€œthe sameâ€ or â€œidenticalâ€: he left that very night. . Once bitten, twice shy . This is a proverb that means that if youâ€™ve been hurt by something once, youâ€™ll be more careful the next time. . Itâ€™s an example of elliptical causation: if once bitten, then twice shy: that is, the causation (ifâ€¦ thenâ€¦) is omitted: this kind of omission is known as an ellipsis, which is also the name given to the triple dots (â€¦) used to show a piece of a quotation has been omitted. . Other examples of elliptical causation include â€œno pain, no gainâ€, â€œwaste not, want notâ€, â€œnothing ventured, nothing gainedâ€. . Gave: not that, unlike the standard pronunciation (gejw), George Michael pronounces it as gew throughout. This is typical of a number of accents in England. (He pronounces â€œsaveâ€ in a similar manner.) . To catch s.b.â€™s eye: to capture someoneâ€™s attention. . A shoulder to cry on: a person who is prepared to listen to someone elseâ€™s problems . Undercover: in secret; spying. . With a fire in oneâ€™s heart: to be very passionate about something .",
            "url": "https://jimregan.github.io/notes/english%20teaching/pruszk%C3%B3w/2018/11/27/last-christmas.html",
            "relUrl": "/english%20teaching/pruszk%C3%B3w/2018/11/27/last-christmas.html",
            "date": " â€¢ Nov 27, 2018"
        }
        
    
  
    
        ,"post240": {
            "title": "Evernote web clips, 11/4/2018",
            "content": "The Annotated Transformer . General Information . explosion/sense2vec .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2018/04/11/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2018/04/11/evernote-links.html",
            "date": " â€¢ Apr 11, 2018"
        }
        
    
  
    
        ,"post241": {
            "title": "Evernote web clips, 23/3/2018",
            "content": "Gangsterâ€™s paradise: how organised crime took over Russia . WIP: Segmenting long erroneous recordings by vimalmanohar . vimalmanohar/kaldi . vimalmanohar/kaldi . vimalmanohar/kaldi . vimalmanohar/kaldi . vimalmanohar/kaldi . vimalmanohar/kaldi . vimalmanohar/kaldi . vimalmanohar/kaldi . Modeling Relational Data with Graph Convolutional Networks . RodenLuo/Smith-Waterman-in-Perl . Untitled note . Plucene-Plugin-Analyzer-MetaphoneAnalyzer-1.02 - Metaphone analyzer - metacpan.org . Find What You Want with Plucene . Machine Learning 10-701/15-781: Lectures . Top Machine Learning MOOCs and Online Lectures: A Comprehensive Survey . tcsai/data-mining . Add the diphone alignment system by akreal . Add diphones acoustic model and dictionary by akreal . akreal/diphones . Add modernized vystadial_cz recipe . Pretrained models . GSByeon/multi-speaker-tacotron-tensorflow . How to build a three-layer neural network from scratch . Prerequisites and Prework . voicy-ai/DialogStateTracking . RasaHQ/rasa_nlu . Question answering with TensorFlow . English gold standard recipe â€” Ossian 1.3 documentation . Implementation of Gradient Descent in TensorFlow using tf.gradients . tensorflow/tensor2tensor . AI::FANN - search.cpan.org . [Machine learning in Perl | Sergey Kolychev [blogs.perl.org]](http://blogs.perl.org/users/sergey_kolychev/2017/02/machine-learning-in-perl.html) | . AN TRIAIL le MÃ¡irÃ©ad NÃ­ GhrÃ¡da . Anna Heussaff ag lÃ©amh as SÃRÃš . deepmipt/DeepPavlov . CMU-Perceptual-Computing-Lab/openpose . dlib C++ Library - train_shape_predictor_ex.cpp . Real-Time Face Pose Estimation . astorfi/lip-reading-deeplearning . facebookresearch/TensorComprehensions . facebookresearch/StarSpace . facebookresearch/MUSE . facebookresearch/InferSent . facebookresearch/tdfbanks . facebookresearch/loop . fastai/numerical-linear-algebra . zackchase/mxnet-slides . zackchase/mxnet-the-straight-dope . zackchase/mxnet-the-straight-dope . aalto-speech/finnish-parliament-scripts . tudarmstadt-lt/kaldi-tuda-de . cltk/lapos . Speech::Recognizer::SPX - search.cpan.org . opencv/opencv_contrib . Dynamic word embeddings for evolving semantic discovery . Machine Learning Top 10 Open Source Projects (v.Mar 2018) . Bliain an Ãir (Year of Slaughter) â€“ Irish Famine of 1740-1741 . Phn2vec Embeddings . syhw/speech_embeddings . Pointer Networks . ikostrikov/TensorFlow-Pointer-Networks . atom/flight-manual.atom.io . tsee/p5-ML-TensorFlow . How To Write Your Own Tensorflow in C++ . MycroftAI/padatious . Pocketsphinx.js - Speech Recognition in JavaScript and WebAssembly . MycroftAI/padatious . Conv Nets: A Modular Perspective . Attention and Augmented Recurrent Neural Networks . Understanding LSTM Networks . UFLDL Recommended Readings . tiny-dnn/tiny-dnn . zotroneneis/machine_learning_basics . mozilla/TTS . uclmr/inferbeddings . Rayhane-mamah/Tacotron-2 . sdkcarlos/artyom.js . kan-bayashi/PytorchWaveNetVocoder . Rayhane-mamah/Tacotron-2 . Kyubyong/cross_vc . k2kobayashi/sprocket . timothycrosley/jiphy . pyjs/pyjs . uwgraphics/Leap . A-Jacobson/tacotron2 . The Books and the Pilgrimage of the Polish Nation . Adversarial Sets for Regularising Neural Link Predictors . Compiling Deep Learning Models to WebGL with TVM . NNVM Compiler: Open Compiler for AI Frameworks . Tool for segmenting long audio files with erroneous transcripts Â· Issue #869 Â· kaldi-asr/kaldi . resonance-audio/resonance-audio . Implementation - Rust By Example . Starting to Corrode . KeyMe Releases Two Machine Learning Models - KeyMe Blog . PDF - arxiv.org . Community Interaction and Conflict on the Web . Transfer Your Font Style with GANs . PolEval 2017 :: Tasks . Introduction to Gaussian Processes . Bad Speech Synthesis Made Simple . Are the hyper-realistic results of Tacotron-2 and Wavenet not reproducible? â€¢ r/MachineLearning . KPWr . PDF - static.googleusercontent.com . a-nagrani/VGGVox . Visual Geometry Group: VoxCeleb dataset . Transfer learning wsj-rm by pegahgh Â· Pull Request #1633 Â· kaldi-asr/kaldi . Semi-supervised training on Fisher English by vimalmanohar Â· Pull Request #2140 Â· kaldi-asr/kaldi . DNN-based speaker embedding - Google Groups . End-to-end speech recognition - Google Groups . [Machine learning in Perl | Sergey Kolychev [blogs.perl.org]](http://blogs.perl.org/users/sergey_kolychev/2017/02/machine-learning-in-perl.html) | . salesforce/nonauto-nmt . salesforce/awd-lstm-lm . An Analysis of Neural Language Modeling at Multiple Scales . facebookresearch/tdfbanks . tensorflow/tensorflow . fomorians/highway-cnn . Highway Networks with TensorFlow â€“ Jim Fleming â€“ Medium . deltamachine/naive-automatic-postediting . Added lexnet_nc model. Â· tensorflow/models@1f37153 . [Understanding Deep Learning through Neuron Deletion | DeepMind](https://deepmind.com/blog/understanding-deep-learning-through-neuron-deletion/) | . kaldi-asr/kaldi . facebookresearch/tdfbanks . PDF - arxiv.org . Corpus building for data-driven TTS systems . apohllo/pjn . Time alignments off by a factor of 3 when using nnet3-align-compiled - Google Groups . One best hypothesis Lattice to CTM - Google Groups . zackchase/ddc . ethanfetaya/NRI . C++ gradients: Fractional*Pool, Soft{Plus,Sign} by kbsriram Â· Pull Request #17331 Â· tensorflow/tensorflow .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2018/03/23/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2018/03/23/evernote-links.html",
            "date": " â€¢ Mar 23, 2018"
        }
        
    
  
    
        ,"post242": {
            "title": "Evernote web clips, 22/3/2018",
            "content": "Language Transfer of Audio Word2Vec: Learning Audio Segment Representations without Target Language Data . Peering into Neural Networksâ€”How Sequence Models View State of the Union Speeches from Three U.S. Presidents . Annotation Artifacts in Natural Language Inference Data . CMU Sphinx Frequently Asked Questions . How to use an Existing DNN Recognizer for Decoding in Kaldi . Exploring the Boost Graph Library . How to build a deep learning model in 15 minutes . Requests for Research . Gradient Descent in a Nutshell .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2018/03/22/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2018/03/22/evernote-links.html",
            "date": " â€¢ Mar 22, 2018"
        }
        
    
  
    
        ,"post243": {
            "title": "Evernote web clips, 14/2/2018",
            "content": "Create a working compiler with the LLVM framework, Part 1 . Create a working compiler with the LLVM framework, Part 2 .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/llvm/2018/02/14/evernote-links.html",
            "relUrl": "/evernote/web%20clip/llvm/2018/02/14/evernote-links.html",
            "date": " â€¢ Feb 14, 2018"
        }
        
    
  
    
        ,"post244": {
            "title": "Evernote web clips, 16/1/2018",
            "content": "Fast Inference for Neural Vocoders . The 10 Deep Learning Methods AI Practitioners Need to Apply . Adapting the default acoustic model . What most people donâ€™t understand about AI and the the state of machine learning . Recent Advances in Recurrent Neural Networks . Deep Learning: A Critical Appraisal . mozilla/DeepSpeech document-init-from-frozen-model . Building Speech Applications Using CMU Sphinx and Related Resources .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2018/01/16/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2018/01/16/evernote-links.html",
            "date": " â€¢ Jan 16, 2018"
        }
        
    
  
    
        ,"post245": {
            "title": "Evernote web clips, 5/12/2016",
            "content": "[Readings | ÃšFAL](https://ufal.mff.cuni.cz/milan-straka/readings) | .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2016/12/05/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2016/12/05/evernote-links.html",
            "date": " â€¢ Dec 5, 2016"
        }
        
    
  
    
        ,"post246": {
            "title": "Evernote web clips, 11/7/2016",
            "content": "User:Krvoje/Foma script for testing finite-state disambiguation - Apertium . Facebook will soon introduce a new Multilingual composer that automatically translates posts .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2016/07/11/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2016/07/11/evernote-links.html",
            "date": " â€¢ Jul 11, 2016"
        }
        
    
  
    
        ,"post247": {
            "title": "Evernote web clips, 4/4/2016",
            "content": "Formant-controlled HMM-based Speech Synthesis .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/tts/2016/04/04/evernote-links.html",
            "relUrl": "/evernote/web%20clip/tts/2016/04/04/evernote-links.html",
            "date": " â€¢ Apr 4, 2016"
        }
        
    
  
    
        ,"post248": {
            "title": "Evernote web clips, 25/3/2016",
            "content": "SpeCT - The Speech Corpus Toolkit for Praat .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/praat/2016/03/25/evernote-links.html",
            "relUrl": "/evernote/web%20clip/praat/2016/03/25/evernote-links.html",
            "date": " â€¢ Mar 25, 2016"
        }
        
    
  
    
        ,"post249": {
            "title": "Evernote web clips, 19/3/2016",
            "content": "Train your own image classifier with Inception in TensorFlow .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2016/03/19/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2016/03/19/evernote-links.html",
            "date": " â€¢ Mar 19, 2016"
        }
        
    
  
    
        ,"post250": {
            "title": "Evernote web clips, 17/3/2016",
            "content": "Train your own image classifier with Inception in TensorFlow . TensorFlow for Poets .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2016/03/17/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2016/03/17/evernote-links.html",
            "date": " â€¢ Mar 17, 2016"
        }
        
    
  
    
        ,"post251": {
            "title": "signal processing definitions",
            "content": "periodic - traces same path . aperiodic - doesnâ€™t . cycle - shape that repeats . period - time cycle takes to repeat . Hertz - cycles per second .",
            "url": "https://jimregan.github.io/notes/evernote/2016/01/31/signal-processing-defn.html",
            "relUrl": "/evernote/2016/01/31/signal-processing-defn.html",
            "date": " â€¢ Jan 31, 2016"
        }
        
    
  
    
        ,"post252": {
            "title": "node",
            "content": "Node . class Node { Â Â Â Â  char ch = START; Â Â Â Â  List&lt;Node&gt; = List.newArrayList(); Â Â Â Â  void add (String str) { Â Â Â Â Â Â Â Â Â  if (str.length() == 0) Â Â Â Â Â Â Â Â Â Â Â Â Â Â  return; Â Â Â Â Â Â Â Â Â  char chNew = str.charAt(0); Â Â Â Â Â Â Â Â Â  for (Node n : nodes) { Â Â Â Â Â Â Â Â Â Â Â Â Â Â  if (n.ch == chNew) { Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  n.add (str.substring(1)); Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  return; Â Â Â Â Â Â Â Â Â Â Â Â Â Â  } Â Â Â Â Â Â Â Â Â  Node newNode = new Node(); Â Â Â Â Â Â Â Â Â  newNode.ch = chNew; Â Â Â Â Â Â Â Â Â  new Node.add(str.substring(1)); Â Â Â Â Â Â Â Â Â  nodes.add(newNode); Â Â Â Â  } Â Â Â Â  String toRegexp() { Â Â Â Â Â Â Â Â Â  StringBuilder .",
            "url": "https://jimregan.github.io/notes/evernote/incomplete/2016/01/31/node.html",
            "relUrl": "/evernote/incomplete/2016/01/31/node.html",
            "date": " â€¢ Jan 31, 2016"
        }
        
    
  
    
        ,"post253": {
            "title": "neuron",
            "content": "double activation = 0.0; for (int i = 0; i &lt; n; i++) { Â  Â  Â activation += x[i] + n[i]; } . e = 2.7183 (approx) . a = activation . p = shape of curve . sigmoid . output = $1/1 + e^{-a/p}$ . class Neuron { Â  Â  Â int num_inputs; Â  Â  Â vector&lt;double&gt; weights; Â  Â  Â Neuron (int num); } Neuron::Neuron (int num) : num.inputs(num + 1) { Â  Â  Â for (int i = 0; i &lt;= num; i++) { Â  Â  Â  Â  Â  weights.push_back(random()); Â  Â  Â } } .",
            "url": "https://jimregan.github.io/notes/evernote/2016/01/31/neuron.html",
            "relUrl": "/evernote/2016/01/31/neuron.html",
            "date": " â€¢ Jan 31, 2016"
        }
        
    
  
    
        ,"post254": {
            "title": "Influence",
            "content": "Influence . Festinger - cognitive dissonance | experiment - 20 dollars vs 1 to lie | &gt; $1 changed beliefs | Americans in Korea, captured by China | rice for propaganda, most became Communist | . â€˜We have to take our country backâ€™ . No details Listener fills in details | . | donâ€™t sell past the close | . Points: . Loss response &gt; gain response . | When you laugh, you look at the person youâ€™re most comfortable with | Feet pointing towards you -&gt; at ease | People remember first &amp; last moments most clearly | Concert or amusement park for first dates - excitement | Silence encourages the other to talk more | A mirror behind customer service - people like to check themselves/others in line | Sitting next to someone discourages badmouthing | Sincere excitement when seeing someone elicits the same reaction from them next time | Ask for small favours - encourages people to like you | Confidence boost in meeting - pretend interviewer is your best friend | Mirror body language to build trust | Cold hands - wear gloves -&gt; warm handshake | Laughter causes happiness | Teaching is the best way to learn | Use names in conversation | .",
            "url": "https://jimregan.github.io/notes/evernote/2016/01/31/influence.html",
            "relUrl": "/evernote/2016/01/31/influence.html",
            "date": " â€¢ Jan 31, 2016"
        }
        
    
  
    
        ,"post255": {
            "title": "FST",
            "content": "FST (openfst? morfologik?) . for (StateIterator&lt; FST&lt;A&gt;&gt; siter(fst); Â  Â  Â !siter.Done(); Â Â Â Â Â siter.Next() { Â  Â  Â StateId s = siter.Value(); Â  Â  Â if (fst.Final(s) != Weight::Zero()) { Â  Â  Â  Â  Â  //do stuff Â  Â  Â } } . Weight::Zero() applies with unweighted FSTs .",
            "url": "https://jimregan.github.io/notes/evernote/2016/01/31/fst.html",
            "relUrl": "/evernote/2016/01/31/fst.html",
            "date": " â€¢ Jan 31, 2016"
        }
        
    
  
    
        ,"post256": {
            "title": "LuaJ / Scribunto",
            "content": "LuaJ / Scribunto . LuaJ Field Access / function calls . LuaValue globals = JsePlatform.standardGlobals(); LuaValue sqrt = globals.get(&quot;math&quot;).get(&quot;sqrt&quot;); LuaValue print = globals.get(&quot;print&quot;); LuaValue d = sqrt.call(a); print.call(LuaValue.valueOf(&quot;sqrt(5):&quot;), a); . varargs / multiple returns . use invoke(Varargs) or invokemethod(LuaValue, Varargs) . LuaValue modf = globals.get(&quot;math&quot;).get(&quot;modf&quot;); Varargs r = modf.invoke(d); print.call(r.arg(1), r.arg(2)); . To load / run script: LoadState . LoadState.load(new FileInputStream(&quot;main.lua&quot;), &quot;main.lua&quot;, globals).call(); . or require . globals.get(&quot;require&quot;).call(LuaValue.valueOf(&quot;main&quot;)) . preinit tables: . listOf(LuaValue[]) - for unnamed elements | tableOf (LuaValue[]) - for named | tableOf(LuaValue[], LuaValue[], Varargs) - mixture | . LuaJ - date not implemented . if (format[0] == &#39;!&#39;) { Â Â Â Â  calendar = Calendar.getInstance(TimeZone.getTimeZone(&quot;GMT&quot;); } else { Â Â Â Â  calendar = Cak,getInst(TimeZone.getDefault()); } . also adjust format . DST: TimeZone tz = TimeZone.getDefault(); Â Â Â Â  bool.isdst = tz.useDaylightTime(); function setTTL ($ttl) { Â Â Â Â  $args = func_get_args(); Â Â Â Â  $this-&gt;checkNumber(&#39;setTTL&#39;, $args, 0); Â Â Â Â  $frame = $this-&gt;getFrameById(&#39;current&#39;); Â Â Â Â  if (is_callable(array($frame, &#39;setTTL&#39;))) { Â Â Â Â Â Â Â Â Â  $frame-&gt;setTTL($ttl); // ?? Â Â Â Â  } } . Scribunto . Module: Bananas . local p = {} function p.hello(frame) Â Â Â Â  return &quot;Hello world&quot; end return p . other page: . {{#invoke:Bananas|hello}} .",
            "url": "https://jimregan.github.io/notes/evernote/2016/01/30/luaj-scribunto.html",
            "relUrl": "/evernote/2016/01/30/luaj-scribunto.html",
            "date": " â€¢ Jan 30, 2016"
        }
        
    
  
    
        ,"post257": {
            "title": "lisa-groundhog layers",
            "content": "lisa-groundhog layers . Layer | MultiLayer | SoftmaxLayer | HierarchicalSoftmaxLayer | LSTMLayer | RecurrentLayer | RecursiveConvolutionLayer | UnaryOp | Shift | LastState | DropOp | Concatenate | .",
            "url": "https://jimregan.github.io/notes/evernote/2016/01/30/lisa-groundhog-layers.html",
            "relUrl": "/evernote/2016/01/30/lisa-groundhog-layers.html",
            "date": " â€¢ Jan 30, 2016"
        }
        
    
  
    
        ,"post258": {
            "title": "Evernote web clips, 27/1/2016",
            "content": "A cross-language vowel normalisation procedure . An Aspectual Classification of Polish Verbs .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2016/01/27/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2016/01/27/evernote-links.html",
            "date": " â€¢ Jan 27, 2016"
        }
        
    
  
    
        ,"post259": {
            "title": "Evernote web clips, 16/1/2016",
            "content": "generate-bidix-templates.py . Hiberno-English Vowel System: Drogheda English . Tonal Alignment in Three Varieties of Hiberno-English . Hiberno-English Question Intonation: the Case of Drogheda English .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2016/01/16/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2016/01/16/evernote-links.html",
            "date": " â€¢ Jan 16, 2016"
        }
        
    
  
    
        ,"post260": {
            "title": "Evernote web clips, 1/12/2015",
            "content": "Unsupervised estimation of the human vocal tract length over sentence level utterances .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/12/01/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/12/01/evernote-links.html",
            "date": " â€¢ Dec 1, 2015"
        }
        
    
  
    
        ,"post261": {
            "title": "Evernote web clips, 29/11/2015",
            "content": "The invisible minority: revisiting the debate on foreign-accented speakers and upward mobility in the workplace. . Accents in the workplace: their effects during a job interview. . PLURILINGUALISM â€“ PRIORITY IN PROMOTING EQUALITY OF CHANCES. . Challenges of multilingualism in the EU. . Piecing together the workplace multilingualism jigsaw puzzle .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/11/29/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/11/29/evernote-links.html",
            "date": " â€¢ Nov 29, 2015"
        }
        
    
  
    
        ,"post262": {
            "title": "Evernote web clips, 17/11/2015",
            "content": "[Swesaurus | SprÃ¥kbanken](http://spraakbanken.gu.se/eng/resource/swesaurus) | . [SALDOâ€™s morphology | SprÃ¥kbanken](http://spraakbanken.gu.se/eng/resource/saldom) | . [LWT | SprÃ¥kbanken](http://spraakbanken.gu.se/eng/resource/lwt) | . [LWT-PWN | SprÃ¥kbanken](http://spraakbanken.gu.se/eng/resource/lwt-pwn) | . An Engineerâ€™s Guide to GEMM .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/11/17/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/11/17/evernote-links.html",
            "date": " â€¢ Nov 17, 2015"
        }
        
    
  
    
        ,"post263": {
            "title": "Evernote web clips, 28/10/2015",
            "content": "Guidelines for developing NIF-based NLP services . The Stanford NLP (Natural Language Processing) Group . Guidelines for Linked Data corpus creation using NIF . [Torch | The power of Spatial Transformer Networks](http://torch.ch/blog/2015/09/07/spatial_transformers.html) | .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/10/28/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/10/28/evernote-links.html",
            "date": " â€¢ Oct 28, 2015"
        }
        
    
  
    
        ,"post264": {
            "title": "Dependency analysis",
            "content": "Irish stuff . Â  Â  Â  . dâ€™ | do | do+Part+Vb+@&gt;V | . Ã³l | Ã³l | Ã³l+Verb+VTI+Vow+PastInd+Len+@FMV | . mÃ© | mÃ© | mÃ©+Pron+Pers+1P+Sg+@SUBJ | .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/10/26/irish-dependency.html",
            "relUrl": "/evernote/web%20clip/2015/10/26/irish-dependency.html",
            "date": " â€¢ Oct 26, 2015"
        }
        
    
  
    
        ,"post265": {
            "title": "Evernote web clips, 6/9/2015",
            "content": "Phoneme Recognition . btrask/stronglink .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/09/06/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/09/06/evernote-links.html",
            "date": " â€¢ Sep 6, 2015"
        }
        
    
  
    
        ,"post266": {
            "title": "Evernote web clips, 3/9/2015",
            "content": "Wikidata/Wikidata-Toolkit . NASARI . [Transition-Based Dependency Parsing with Stack Long Short-Term Memory | GitXiv](http://gitxiv.com/posts/qEQvDP8eidkAsGcPQ/transition-based-dependency-parsing-with-stack-long-short) | .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/09/03/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/09/03/evernote-links.html",
            "date": " â€¢ Sep 3, 2015"
        }
        
    
  
    
        ,"post267": {
            "title": "Evernote web clips, 12/8/2015",
            "content": "Parsing S-Expressions in Scala . Function Memoization in Scala . Clang Plugins â€” Clang 3.8 documentation .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/08/12/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/08/12/evernote-links.html",
            "date": " â€¢ Aug 12, 2015"
        }
        
    
  
    
        ,"post268": {
            "title": "Evernote web clips, 12/6/2015",
            "content": "I have now converged on a stable recipe for deep neural net training Kaldi.â€¦ . Start of parser . Untitled note . karpathy/gist:7bae8033dcf5ca2630ba . Use of exp in the Reparametrization Â· Issue #3 Â· y0ast/VAE-Torch . chrisnatale / IHTAI / wiki / Home â€” Bitbucket . littleowen/Conceptor . duguyue100/conceptors .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/06/12/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/06/12/evernote-links.html",
            "date": " â€¢ Jun 12, 2015"
        }
        
    
  
    
        ,"post269": {
            "title": "Evernote web clips, 4/6/2015",
            "content": "ÄŒetnost jmen a pÅ™Ã­jmenÃ­ - Ministerstvo vnitra ÄŒeskÃ© republiky . NomesLex-PT 01 in English - DMIR Group at INESC-ID . [Sansa Stark | Reaction Images](http://knowyourmeme.com/photos/588075-reaction-images) | . OpenCL alternatives for CUDA Linear Algebra Libraries . What are important points about deep learning applied to speech recognition, for a business audience? - Quora . Deep Learning, NLP, and Representations . From Machine Learning to Machine Reasoning . Learning Continuous Phrase Representations for Translation Modeling . Hintonâ€™s Dark Knowledge . High-Performance OCR for Printed English and Fraktur using LSTM Networks . C3D: Generic Features for Video Analysis . dlwh/epic . Senna . Natural Language Processing (almost) from Scratch . Conv Nets: A Modular Perspective . Understanding Convolutions . Visualizing Representations: Deep Learning and Human Beings .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/06/04/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/06/04/evernote-links.html",
            "date": " â€¢ Jun 4, 2015"
        }
        
    
  
    
        ,"post270": {
            "title": "Evernote web clips, 2015-06-03",
            "content": "cubicdaiya/dtl . facebook/Stack-RNN . An Introduction to Conditional Random Fields . Using word2vec for different NLP tasks â€¢ /r/MachineLearning . gensim: topic modelling for humans . erickrf/nlpnet . SENNA . Natural Language Processing (almost) from Scratch . The Agency . Demystifying LSTM Neural Networks . A good source to learn Recurrent Neural Nets and Long Short Term Memory Nets? â€¢ /r/MachineLearning . An illustrated introduction to the t-SNE algorithm - O&#39;Reilly Media . Feeding an image to a RNN or dealing with images of different dimensions? â€¢ /r/MachineLearning .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/06/03/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/06/03/evernote-links.html",
            "date": " â€¢ Jun 3, 2015"
        }
        
    
  
    
        ,"post271": {
            "title": "Evernote web clips, 31/5/2015",
            "content": "pyklatt - An advanced Python implementation of a Klatt synthesizer . Untitled note . Formant Estimation with LPC Coefficients . proteusvacuum/KlattSynth .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/05/31/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/05/31/evernote-links.html",
            "date": " â€¢ May 31, 2015"
        }
        
    
  
    
        ,"post272": {
            "title": "Evernote notes, TTS",
            "content": "Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups . Multi-distribution deep beliefÂ network for speech synthesis . Modeling spectral envelopes using restricted Boltzmann machines for statistical parametric speech synthesis . Speech recognition with deep recurrent neural networks . Hybrid speech recognition with Deep Bidirectional LSTM . Connectionist temporal classification: labelling un-segmented sequence data with recurrent neural networks . mohammadpz/CTC-Connectionist-Temporal-Classification . Feature engineering in context-dependent deep neural networks for conversational speech transcription . A Novel Approach to On-Line Handwriting Recognition Based on Bidirectional Long Short-Term Memory Networks .",
            "url": "https://jimregan.github.io/notes/evernote/tts/asr/2015/05/30/tts-evernote.html",
            "relUrl": "/evernote/tts/asr/2015/05/30/tts-evernote.html",
            "date": " â€¢ May 30, 2015"
        }
        
    
  
    
        ,"post273": {
            "title": "Evernote web clips, 30/5/2015",
            "content": "Modeling spectral envelopes using restricted Boltzmann machines for statistical parametric speech synthesis . Multi-distribution deep belief network for speech synthesis . Deep Neural Networks for Acoustic Modeling in Speech Recognition . Grapheme-based Synthesizer . glecorve/rnnlm2wfst . Statistical Parametric Speech Synthesis Using Deep Neural Networks . NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE . Combining a vector space representation of linguistic context with a deep neural network for text-to-speech synthesis . TTS Synthesis with Bidirectional LSTM based Recurrent Neural Networks . Implementation of Neural Turing Machines â€¢ /r/MachineLearning . Sequence to Sequence Learning with Neural Networks . Discriminative models, not discriminative training . kastnerkyle/test_ctc.py . glecorve/rnnlm2wfst . DEEP NEURAL NETWORK (DNN) FOR TTS SYNTHESIS - Microsoft Research .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/05/30/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/05/30/evernote-links.html",
            "date": " â€¢ May 30, 2015"
        }
        
    
  
    
        ,"post274": {
            "title": "Evernote web clips, 29/5/2015",
            "content": "aalto-speech/AaltoASR . nouiz/lisa_emotiw . dpkingma/nips14-ssl . stanfordnlp/treelstm . CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers . mattpap/IScala . brian473/neural_rl . dcodeIO/ByteBuffer.js .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/05/29/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/05/29/evernote-links.html",
            "date": " â€¢ May 29, 2015"
        }
        
    
  
    
        ,"post275": {
            "title": "Simple lttoolbox transducer",
            "content": "hexdump /tmp/test2.bin 0000000 1a 40 61 40 62 40 63 40 64 40 65 40 66 40 67 40 0000010 68 40 69 40 6a 40 6b 40 6c 40 6d 40 6e 40 6f 40 0000020 70 40 71 40 72 40 73 40 74 40 75 40 76 40 77 40 0000030 78 40 79 40 7a 01 01 40 6e 08 01 01 01 40 74 01 0000040 00 40 67 40 67 40 70 40 70 40 63 40 63 40 62 40 0000050 62 40 73 40 73 02 12 40 69 40 6e 40 63 40 6f 40 0000060 40 40 69 40 6e 40 63 40 6f 40 6e 40 64 40 69 40 0000070 74 40 69 40 6f 40 6e 40 61 40 6c 00 01 05 06 01 0000080 05 01 01 06 01 01 07 01 01 01 01 01 02 01 00 0d 0000090 40 6d 40 61 40 69 40 6e 40 40 40 73 40 74 40 61 00000a0 40 6e 40 64 40 61 40 72 40 64 00 01 05 06 01 03 00000b0 01 01 04 01 01 04 01 01 01 01 01 02 01 00Â Â Â Â Â  00000be . ^Z@a@b@c@d@e@f@g@h@i@j@k@l@m@n@o@p@q@r@s@t@u@v@w@x@y@z ^A^A@^A^A^A@t^A^@@g@g@p@p@c@c@b@b@s@s^B^R@i@n@c@o@@@i @n@c@o@n@d@i@t@i@o@n@a@l^@^A^E^F^A^E^A^A^F^A^A^G^A^A ^A^A^A^B^A^@^M@m@a@i@n@@@s@t@a@n@d@a@r@d^@^A^E^F^A^C ^A^A^D^A^A^D^A^A^A^A^A^B^A^@ . $ lt-print /tmp/test2.bin 0Â Â Â Â  1Â Â Â Â  bÂ Â Â Â  bÂ Â Â Â  1Â Â Â Â  2Â Â Â Â  aÂ Â Â Â  aÂ Â Â Â  2Â Â Â Â  3Â Â Â Â  rÂ Â Â Â  rÂ Â Â Â  3Â Â Â Â  4Â Â Â Â  ÎµÂ Â Â Â  sÂ Â Â Â  4Â Â Â Â  5Â Â Â Â  ÎµÂ Â Â Â  &lt;n&gt;Â Â Â Â  5 -- 0Â Â Â Â  1Â Â Â Â  fÂ Â Â Â  fÂ Â Â Â  1Â Â Â Â  2Â Â Â Â  oÂ Â Â Â  oÂ Â Â Â  2Â Â Â Â  3Â Â Â Â  oÂ Â Â Â  oÂ Â Â Â  3Â Â Â Â  4Â Â Â Â  ÎµÂ Â Â Â  sÂ Â Â Â  4Â Â Â Â  5Â Â Â Â  ÎµÂ Â Â Â  &lt;n&gt;Â Â Â Â  5 . ^@ ^A^E^F^A^E^A^A^F^A^A^G^A^A^A^A^A^B^A ^@ ^M . $ cat /tmp/test.dix . &lt;dictionary&gt; Â  &lt;alphabet&gt;abcdefghijklmnopqrstuvwxyz&lt;/alphabet&gt; Â  &lt;sdefs&gt; Â Â Â  &lt;sdef n=&quot;n&quot;/&gt; Â  &lt;/sdefs&gt; Â  &lt;pardefs&gt; Â Â Â  &lt;pardef n=&quot;one&quot;&gt; Â Â Â Â Â  &lt;e&gt;&lt;p&gt;&lt;l&gt;&lt;/l&gt;&lt;r&gt;s&lt;s n=&quot;n&quot;/&gt;&lt;/r&gt;&lt;/p&gt;&lt;/e&gt; Â Â Â  &lt;/pardef&gt; Â  &lt;/pardefs&gt; Â  &lt;section id=&quot;main&quot; type=&quot;standard&quot;&gt; Â Â Â  &lt;e&gt;&lt;i&gt;foo&lt;/i&gt;&lt;par n=&quot;one&quot;/&gt;&lt;/e&gt; Â  &lt;/section&gt; Â  &lt;section id=&quot;inco&quot; type=&quot;inconditional&quot;&gt; Â Â Â  &lt;e&gt;&lt;i&gt;bar&lt;/i&gt;&lt;par n=&quot;one&quot;/&gt;&lt;/e&gt; Â  &lt;/section&gt; &lt;/dictionary&gt; .",
            "url": "https://jimregan.github.io/notes/evernote/2015/05/28/simple-lttoolbox-transducer.html",
            "relUrl": "/evernote/2015/05/28/simple-lttoolbox-transducer.html",
            "date": " â€¢ May 28, 2015"
        }
        
    
  
    
        ,"post276": {
            "title": "neural notes",
            "content": "Weakly Supervised Memory Networks . Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks . wojzaremba/lstm . Reinforcement Learning Neural Turing Machines . kaishengtai/torch-ntm . stanfordnlp/treelstm . Neural Machine Translation by Jointly Learning to Align and Translate . lisa-groundhog/GroundHog . rsennrich/nplm . shawntan/neural-turing-machines, implementation of neural turing machines, gcgibson/NTM . Learning to Execute . Sequence to Sequence Learning with Neural Networks .",
            "url": "https://jimregan.github.io/notes/evernote/2015/05/28/neural-notes-evernote-links.html",
            "relUrl": "/evernote/2015/05/28/neural-notes-evernote-links.html",
            "date": " â€¢ May 28, 2015"
        }
        
    
  
    
        ,"post277": {
            "title": "Evernote web clips, 27/5/2015",
            "content": "The Unreasonable Effectiveness of Recurrent Neural Networks . fchollet/keras . Implementation of Neural Turing Machines â€¢ /r/MachineLearning . [Keras: Theano-Based Deep Learning Library | Hacker News](https://news.ycombinator.com/item?id=9283105) | . INL/BlackLab . INL/BlackLab . INL/BlackLab . Circular_buffer example - 1.58.0 . Neural Machine Translation by Jointly Learning to Align and Translate .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/05/27/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/05/27/evernote-links.html",
            "date": " â€¢ May 27, 2015"
        }
        
    
  
    
        ,"post278": {
            "title": "Evernote web clips, 1/3/2015",
            "content": "SAMPA for Polish . Which GPU(s) to Get for Deep Learning: My Experience and Advice for Using GPUs in Deep Learning .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/03/01/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/03/01/evernote-links.html",
            "date": " â€¢ Mar 1, 2015"
        }
        
    
  
    
        ,"post279": {
            "title": "Evernote web clips, 19/5/2015",
            "content": "TrainingTesseract3 . CÃ©dric Verstraeten . Introduction to Artificial Neural Networks Part 2 - Learning . Pauls Online Notes : Calculus III - Partial Derivatives . Medieval Unicode Font Initiative - Wikipedia, the free encyclopedia .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/02/19/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/02/19/evernote-links.html",
            "date": " â€¢ Feb 19, 2015"
        }
        
    
  
    
        ,"post280": {
            "title": "Evernote web clips, 15/2/2015",
            "content": "Finger Trees - Andrew Gibiansky . Machine Learning: Neural Networks - Andrew Gibiansky . Machine Learning: the Basics - Andrew Gibiansky . Creating Language Kernels for IPython - Andrew Gibiansky . Convolutional Neural Networks - Andrew Gibiansky . K Nearest Neighbors: Simplest Machine Learning - Andrew Gibiansky . Hessian Free Optimization - Andrew Gibiansky . Fully Connected Neural Network Algorithms - Andrew Gibiansky . Convolutional Neural Networks - Andrew Gibiansky . Homophony Groups in Haskell - Andrew Gibiansky . Gradient Descent Typeclasses in Haskell - Andrew Gibiansky . Cool Linear Algebra: Singular Value Decomposition - Andrew Gibiansky . Recurrent Neural Networks - Andrew Gibiansky . Speech Recognition with Neural Networks - Andrew Gibiansky . Sequence Transduction with Recurrent Neural Networks . Speech Recognition with Neural Networks - Andrew Gibiansky .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/02/15/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/02/15/evernote-links.html",
            "date": " â€¢ Feb 15, 2015"
        }
        
    
  
    
        ,"post281": {
            "title": "Evernote web clips, 8/2/2015",
            "content": "SuDoKu Grabber with OpenCV: Recognizing digits - AI Shack . SuDoKu Grabber with OpenCV: Extracting digits - AI Shack . SuDoKu Grabber with OpenCV: Extracting the grid - AI Shack . SuDoKu Grabber with OpenCV: The Plot - AI Shack . Caffe: Add TRec unit . Caffe: Load weights from multiple caffemodels . On Academiaâ€¦ Â« muellis blog . Running the code with Ocelot - Udacity .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/02/08/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/02/08/evernote-links.html",
            "date": " â€¢ Feb 8, 2015"
        }
        
    
  
    
        ,"post282": {
            "title": "Evernote web clips, 6/2/2015",
            "content": "Android: Simple Shape Recognition using OpenCV, JavaCV . SuDoKu Grabber with OpenCV: Grid detection - AI Shack . [The D2RQ Mapping Language | The D2RQ Platform](http://d2rq.org/d2rq-language#example-join) | . d2rp example . Metacademy - Deep learning from the bottom up . How to detect simple geometric shapes using OpenCV . [Note to self: Compiling C++ programs using libraries installed with homebrew | The NonConditional Beast](http://nonconditional.com/2013/10/note-to-self-compiling-programs-using-boost-installed-with-homebrew/) | . Deep Learning via Semi-Supervised Embedding . Representation Learning: A Review and New Perspectives . Recursive Autoencoder with Theano - Google Groups .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/02/06/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/02/06/evernote-links.html",
            "date": " â€¢ Feb 6, 2015"
        }
        
    
  
    
        ,"post283": {
            "title": "Evernote web clips, 15/1/2015",
            "content": "[School of Shred: Paul Gilbert on the Art and Science of Playing Lead Guitar - Page 3 | Guitar World](http://www.guitarworld.com/school-shred-paul-gilbert-teaches-isightful-lesson-art-and-science-lead-guitar-playing?page=0,2) | . [School of Shred: Paul Gilbert on the Art and Science of Playing Lead Guitar - Page 2 | Guitar World](http://www.guitarworld.com/school-shred-paul-gilbert-teaches-isightful-lesson-art-and-science-lead-guitar-playing?page=0,1) | . [School of Shred: Paul Gilbert on the Art and Science of Playing Lead Guitar | Guitar World](http://www.guitarworld.com/school-shred-paul-gilbert-teaches-isightful-lesson-art-and-science-lead-guitar-playing) | . Drop 2 Chords &amp; Voicings For Guitar . Guitar Chalk Sessions: A Clean Guide to Understanding Seventh Chords . . Dlaczego sÅ‚ownik nie stoi na straÅ¼y czystoÅ›ci jÄ™zyka? - Wielki sÅ‚ownik od kuchni . GDSSecurity/Docker-Secure-Deployment-Guidelines . Creating and publishing a node.js module - Quick Left . Felixâ€™s Node.js Beginners Guide .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/01/15/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/01/15/evernote-links.html",
            "date": " â€¢ Jan 15, 2015"
        }
        
    
  
    
        ,"post284": {
            "title": "Evernote web clips, 14/1/2015",
            "content": "Constructing Deterministic Finite-State Automata in Recurrent Neural Networks . Finite-state computation in analog neural networks: steps towards biologically plausible models? . Comparing two acquisition systems for automatically building an Englishâ€“Croatian parallel corpus from multilingual websites . Quality Estimation for Synthetic Parallel Data Generation . Abu-MaTran at WMT 2014 Translation Task: Two-step Data Selection and RBMT-Style Synthetic Rules . [Custom Runners | Cloud9 User Documentation](https://docs.c9.io/custom_runners.html) | . [Jazz Guitar Corner: Jazz Guitar Chord Exercises â€” with Tab and Audio | Guitar World](http://www.guitarworld.com/jazz-guitar-corner-jazz-guitar-chord-exercises-tab-and-audio) | . To Fall in Love With Anyone, Do This - NYTimes.com . Here Are the 36 Questions That Will Allegedly Make You Fall in Love . No. 37: Big Wedding or Small? - NYTimes.com . How to Get Read on Medium â€” Medium . The Grumpy Programmer: October 2014 . Scripting Languages You May Not Know - Dice News .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/01/14/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/01/14/evernote-links.html",
            "date": " â€¢ Jan 14, 2015"
        }
        
    
  
    
        ,"post285": {
            "title": "Evernote web clips, 12/1/2015",
            "content": "Text in Russian: Saint Petersburg . Text in Russian: The coldest town on Earth . Text in Russian: Banya / Russian Sauna . Text in Russian: Russian bear .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/russian/2015/01/12/evernote-links.html",
            "relUrl": "/evernote/web%20clip/russian/2015/01/12/evernote-links.html",
            "date": " â€¢ Jan 12, 2015"
        }
        
    
  
    
        ,"post286": {
            "title": "Evernote web clips, 8/1/2015",
            "content": "Wikimedia Blog Â» Blog Archive Â» Scaling Wikidata: success means making the pie bigger . [The 88 movies weâ€™re most excited about in 2015 | Film | The Guardian](http://www.theguardian.com/film/2015/jan/06/2015-key-movies-films-year-ahead) | . azakai: HOWTO: Port a C/C++ Library to JavaScript (xml.js) . Getting Started With Emscripten Â· jallwine/emscripten_test Wiki . wiki.dbpedia.org : meetingsÂ /Â DublinÂ 2015 . [What reviewers write, and what they (really) mean | Peter Simons - Academia.edu](https://www.academia.edu/9468277/What_reviewers_write_and_what_they_really_mean) | .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/01/08/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/01/08/evernote-links.html",
            "date": " â€¢ Jan 8, 2015"
        }
        
    
  
    
        ,"post287": {
            "title": "Evernote web clips, 1/1/2015",
            "content": "[Word Embeddings For Fashion | Technology on Heels with Lyst Engineering](https://making.lyst.com/2014/11/11/word-embeddings-for-fashion/) | . Neat Algorithms - Paxos - Will You Harry Me . Radim Å˜ehÅ¯Å™ek : Word2vec Tutorial . Life Lessons From Highly Successful People - Business Insider .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/01/01/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/01/01/evernote-links.html",
            "date": " â€¢ Jan 1, 2015"
        }
        
    
  
    
        ,"post288": {
            "title": "Evernote web clips, 29/12/2014",
            "content": "A Faster Scrabble Move Generation Algorithm . [Gaddag Data Structure â€“ A Way To Quickly Find Scrabble Words | NullWords Blog](http://nullwords.wordpress.com/2013/02/27/gaddag-data-structure/) | . [Jacky Tian | Blog](http://blog.xjtian.com/post/50516439182/a-smarter-scrabble-ai-part-1-lexical) | . GADDAG.java .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/gaddag/scrabble/2014/12/29/evernote-links.html",
            "relUrl": "/evernote/web%20clip/gaddag/scrabble/2014/12/29/evernote-links.html",
            "date": " â€¢ Dec 29, 2014"
        }
        
    
  
    
        ,"post289": {
            "title": "Evernote web clips, 28/12/2014",
            "content": "Distilling the Knowledge in a Neural Network . Implementation of Lucas-Kanade tracker in cpp . lk_track.py . SLAM for Dummies . Nikita Zhiltsov / ÐÐ¸ÐºÐ¸Ñ‚Ð° Ð–Ð¸Ð»ÑŒÑ†Ð¾Ð²: My Visiting Project at Emory University: Entity Search over Linked Data . ChapterÂ 10.Â Code case study: parsing a binary data format .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/12/28/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/12/28/evernote-links.html",
            "date": " â€¢ Dec 28, 2014"
        }
        
    
  
    
        ,"post290": {
            "title": "Evernote, 21/12/2014",
            "content": "phash.cc . #include &lt;iostream&gt; #include &lt;string&gt; #include &lt;pHash.h&gt; #define PROPS_URL &quot;&lt;http://...&gt;&quot; int main (int argc, char** argv) { Â Â Â Â  ulong64 hash = 0; Â Â Â Â  string name; Â Â Â Â  while(std::getline(std::cin, name)) Â Â Â Â  { Â Â Â Â Â Â Â Â Â  ph_dct_imagehash(name.c_str(), hash); Â Â Â Â Â Â Â Â Â  std::cout &lt;&lt; &quot;&lt;http://&quot; &lt;&lt; name &lt;&lt; &quot;&gt; &quot;; Â Â Â Â Â Â Â Â Â  std::cout &lt;&lt; PROPS_URL; Â Â Â Â Â Â Â Â Â  std::cout &lt;&lt; &quot; &quot;&quot; &lt;&lt; hash &lt;&lt; &quot; &quot; .&quot; &lt;&lt; endl; Â Â Â Â Â Â Â Â Â  hash = 0; Â Â Â Â  } Â Â Â Â  return 0; } .",
            "url": "https://jimregan.github.io/notes/evernote/phash/2014/12/21/phash.html",
            "relUrl": "/evernote/phash/2014/12/21/phash.html",
            "date": " â€¢ Dec 21, 2014"
        }
        
    
  
    
        ,"post291": {
            "title": "Evernote web clips, 18/12/2014",
            "content": "Fun mosaic effect with Go . Cultural Studies and Modern Languages: an Introduction â€” University of Bristol â€” FutureLearn . Introduction to Dutch â€” University of Groningen â€” FutureLearn .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/12/18/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/12/18/evernote-links.html",
            "date": " â€¢ Dec 18, 2014"
        }
        
    
  
    
        ,"post292": {
            "title": "Evernote web clips, 13/12/2014",
            "content": "Rich feature hierarchies for accurate object detection and semantic segmentation . AUDFPRINT - Audio fingerprint database creation + query . [Using Docker to Encapsulate Complicated Program is Successful | Internet Archive Blogs](http://blog.archive.org/2014/11/14/docker-to-encapsulate-complicated-program-successful/) | .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/12/13/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/12/13/evernote-links.html",
            "date": " â€¢ Dec 13, 2014"
        }
        
    
  
    
        ,"post293": {
            "title": "Evernote web clips, 12/12/2014",
            "content": "Addressing the Rare Word Problem in Neural Machine Translation . presslabs/gitfs . gitfs/Vagrantfile at master Â· PressLabs/gitfs . [From word2vec to doc2vec: an approach driven by Chinese restaurant process | Kifi Engineering Blog](https://web.archive.org/web/20160309231845/http://eng.kifi.com/from-word2vec-to-doc2vec-an-approach-driven-by-chinese-restaurant-process/) | . word2vec Explained: deriving Mikolov et al.â€™s negative-sampling word-embedding method . gensim: models.word2vec â€“ Deep learning with word2vec . Sequence to Sequence Learning with Neural Networks . Distributed Representations of Sentences and Documents . Writing and transliterating Swahili in Arabic script with Andika! . [Fast Randomized SVD | Blog | Research at Facebook](https://research.facebook.com/blog/294071574113354/fast-randomized-svd/) | . [Question Answering with Subgraph Embeddings | Publications | Research at Facebook](https://research.facebook.com/publications/1473550739586509/question-answering-with-subgraph-embeddings/) | . [C3D: Generic Features for Video Analysis | Blog | Research at Facebook](https://research.facebook.com/blog/736987489723834/c3d-generic-features-for-video-analysis/) | . Machine Learning: The High-Interest Credit Card of Technical Debt . The Psychology of Color in Marketing and Branding . GloVe: Global Vectors for Word Representation . Distributing the Singular Value Decomposition with Spark â€“ Databricks . Spark/mllib SVD example . How do I turn off the unlimited whitespace in IntelliJ editor? - Stack Overflow .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/12/12/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/12/12/evernote-links.html",
            "date": " â€¢ Dec 12, 2014"
        }
        
    
  
    
        ,"post294": {
            "title": "Evernote web clips, 6/11/2014",
            "content": "KALDI: Decision tree internals . Recurrent Neural Network Language Models . Deeplearning4j - Open-source, distributed deep learning for the JVM . Hac - A Java class library for hierarchical agglomerative clustering . Tangle: API Reference . Blazing fast AST generation using boost::spirit . Deep Learning, NLP, and Representations . Parse::RecDescent - search.cpan.org . An Introduction to the Boost Spirit Parser framework - CodeProject .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/11/06/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/11/06/evernote-links.html",
            "date": " â€¢ Nov 6, 2014"
        }
        
    
  
    
        ,"post295": {
            "title": "Evernote web clips, 2/11/2014",
            "content": "www.boddie.org.uk/david - Impression Documents and Tools . Spectrum +3 CP/M Plus manual . Reverse engineering the Quark Xpress file format .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/11/02/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/11/02/evernote-links.html",
            "date": " â€¢ Nov 2, 2014"
        }
        
    
  
    
        ,"post296": {
            "title": "Evernote web clips, 30/10/2014",
            "content": "Training Acoustic Model For CMUSphinx - CMUSphinx Wiki . [Russian Audiobook Morphology-Based Model | CMU Sphinx - Speech Recognition Toolkit](https://cmusphinx.github.io/2011/09/russian-audiobook-morphology-based-model/) | .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/10/30/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/10/30/evernote-links.html",
            "date": " â€¢ Oct 30, 2014"
        }
        
    
  
    
        ,"post297": {
            "title": "Evernote web clips, 28/10/2014",
            "content": "Pagestream . Impression Document Description Format .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/10/28/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/10/28/evernote-links.html",
            "date": " â€¢ Oct 28, 2014"
        }
        
    
  
    
        ,"post298": {
            "title": "Evernote web clips, 27/10/2014",
            "content": "LibriVox . OpenGRM.org . Lecture 6: OpenFST . OpenFst: src/include/fst/concat.h Source File . Tutorial for OpenFST and PyFST . OpenFST: Part II. Library Use and Design . The Problem With Positive Thinking - NYTimes.com . ConcatDoc &lt; FST &lt; TWiki . espeak ttsengine.cpp . /sources/flite/sapi/FliteTTSEngineObj/FliteTTSEngineObj.cpp . TTS Engine Vendor Porting Guide (SAPI 5.3) . XML TTS Tutorial (SAPI 5.3) . Overview of SAPI Grammar: Solitaire Example (SAPI 5.3) . Helper SpConvertStreamFormatEnum (SAPI 5.3) .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/10/27/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/10/27/evernote-links.html",
            "date": " â€¢ Oct 27, 2014"
        }
        
    
  
    
        ,"post299": {
            "title": "Evernote web clips, 17/10/2014",
            "content": "Changing Bits: Luceneâ€™s TokenStreams are actually graphs! . Appendix:Lower Sorbian nouns - Wiktionary . [How to Write a Spelling Corrector | Felipe Farinon](http://scarvenger.wordpress.com/2007/12/11/how-to-write-a-spelling-corrector/) | .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/10/17/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/10/17/evernote-links.html",
            "date": " â€¢ Oct 17, 2014"
        }
        
    
  
    
        ,"post300": {
            "title": "Evernote web clips, 7/9/2014",
            "content": "command center: The byte order fallacy . nnFileFormat - tesseract-ocr-extradocs - Extra documentation about Tesseract OCR - Google Project Hosting . Distributed systems theory for the distributed systems engineer : Paper Trail .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/09/07/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/09/07/evernote-links.html",
            "date": " â€¢ Sep 7, 2014"
        }
        
    
  
    
        ,"post301": {
            "title": "Evernote web clips, 1/9/2014",
            "content": "HfstTwolC &lt; KitWiki &lt; TWiki . koskenni/pytwolc . CA : Two-Level Rule Compiler - Xerox XRCE .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/09/01/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/09/01/evernote-links.html",
            "date": " â€¢ Sep 1, 2014"
        }
        
    
  
    
        ,"post302": {
            "title": "Evernote web clips, 8/8/2014",
            "content": "vptree.hs . Convert Between std::string and std::wstring, UTF-8 and UTF-16 - CodeProject . Google Fonts Uncial Antiqua . Appendix:Scots irregular verbs .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/08/08/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/08/08/evernote-links.html",
            "date": " â€¢ Aug 8, 2014"
        }
        
    
  
    
        ,"post303": {
            "title": "Evernote web clips, 2/8/2014",
            "content": "LLVM Tutorial . robovm/robovm . BlueRiverInteractive/robovm-ios-bindings . parslet -Get Started . A Gentle Introduction to IO Streams in C++ . Implementing a JIT Compiler with Haskell and LLVM . . As Yet Untitled â€” Git: Grafting repositories . hivex - Windows Registry &quot;hive&quot; extraction library .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/08/02/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/08/02/evernote-links.html",
            "date": " â€¢ Aug 2, 2014"
        }
        
    
  
    
        ,"post304": {
            "title": "Lolita vocabulary",
            "content": "etiolate make pale . coeval of the same age, from the same time . palliative serving to mitigate . fascinum ivory phallus . somatic relating to the body of an organism . tiddle fondle . axillary of or pertaining to the axilla or armpit . russet reddish-brown . voluptas pleasure . frÃ©tillement wriggling . tant pis too bad, never mind . Il Ã©tait malin, celui qui a inventÃ© ce truc-lÃ  He was clever, whoever invented this thing . grue prostitute .",
            "url": "https://jimregan.github.io/notes/evernote/2014/07/23/lolita-vocab-evernote-links.html",
            "relUrl": "/evernote/2014/07/23/lolita-vocab-evernote-links.html",
            "date": " â€¢ Jul 23, 2014"
        }
        
    
  
    
        ,"post305": {
            "title": "Evernote web clips, 23/7/2014",
            "content": "PL101: Create your own programming language . PL101: Create your own programming language . PL101: Create your own programming language . PL101: Create your own programming language . PL101: Create your own programming language . PL101: Create your own programming language . PL101: Create your own programming language . PL101: Create your own programming language . Parsoid - MediaWiki . Parsoid/MediaWiki DOM spec - MediaWiki .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/07/23/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/07/23/evernote-links.html",
            "date": " â€¢ Jul 23, 2014"
        }
        
    
  
    
        ,"post306": {
            "title": "Evernote web clips, 22/7/2014",
            "content": "The End of the Russian Fairy Tale . Rosja idzie w zaparte: faÅ‚szywi eksperci i informacje w rzÄ…dowych mediach . Koniec rosyjskiej bajki. WkrÃ³tce wszystko stanie siÄ™ jasne . SeparatyÅ›ci wpuÅ›cili ekspertÃ³w na miejsce katastrofy. Na UkrainÄ™ lecÄ… policjanci z Australii . Ukraina . . Basic Binding using RoboVM and libGDXSeven Armed Squid . [Caffe | MNIST Tutorial](http://caffe.berkeleyvision.org/gathered/examples/mnist.html) | . [article | Perl 5 to Perl 6](http://perlgeek.de/en/article/5-to-6) | . Reading: It&#39;s All Good: Lolita . gocircuit/escher . simple_example.cc .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/07/22/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/07/22/evernote-links.html",
            "date": " â€¢ Jul 22, 2014"
        }
        
    
  
    
        ,"post307": {
            "title": "Evernote web clips, 16/7/2014",
            "content": "Public API Specification - NIF 2.0 . PDFBox text extraction . PDFBox create . Getting Started with Xtext . latex_equations.md .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/07/16/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/07/16/evernote-links.html",
            "date": " â€¢ Jul 16, 2014"
        }
        
    
  
    
        ,"post308": {
            "title": "Evernote web clips, 13/7/2014",
            "content": "[5 Essential Jazz Guitar Soloing Patterns | The Jazz Guitar Blog](http://www.jazzguitar.be/blog/5-essential-jazz-guitar-soloing-patterns/) | . Jazz Guitar Chord Theory Part 1 . [Guitar Scales | The Altered Scale For Guitar](https://www.jazzguitar.be/blog/altered-scale-for-guitar/) | . [17 Essential Jazz Guitar Chords For Beginners | Chord Chart](http://www.jazzguitar.be/blog/17-essential-jazz-guitar-chords-beginners/) | . [Gypsy Jazz Guitar | Django Reinhardt Arpeggios, Tricks &amp; Licks](https://www.jazzguitar.be/blog/django-reinhardt/) | . Exotic Guitar Scales .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/07/13/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/07/13/evernote-links.html",
            "date": " â€¢ Jul 13, 2014"
        }
        
    
  
    
        ,"post309": {
            "title": "Evernote web clips, 10/7/2014",
            "content": "Folder2IndexApp.java . APIExample . sven efftingeâ€™s blog: 5 simple steps to Fowlerâ€™s DSL with Xtext 2.0 . Elastic Bunch Graph Matching - Scholarpedia . Polish Â» I4D - IVONA 4 Developers . Enclosing the public domain: The restriction of public domain books in a digital environment .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/07/10/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/07/10/evernote-links.html",
            "date": " â€¢ Jul 10, 2014"
        }
        
    
  
    
        ,"post310": {
            "title": "Evernote web clips, 28/4/2014",
            "content": "Ania DÄ…browska - Jej zapach . Ania DÄ…browska - Przy sÄ…siednim stoliku .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/04/28/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/04/28/evernote-links.html",
            "date": " â€¢ Apr 28, 2014"
        }
        
    
  
    
        ,"post311": {
            "title": "Evernote web clips, 26/4/2014",
            "content": "LuaJ add lua function in Java - Stack Overflow . lua - Force an integer type in luajava - Stack Overflow . nltk.probability.FreqDist . [public:gaussian_mixture_models_em_algorithm_-demo](https://web.archive.org/web/20160911013157/http://juergenwiki.de/work/wiki/doku.php?id=public:gaussian_mixture_models_em_algorithm-_demo) . c++ - OpenCV: color extraction based on Gaussian mixture model - Stack Overflow . ~sepisoad/vala-totrials/ValaTutorials : contents of io/gio_based/simple_text_file_reading/main.vala at revision 22 .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/04/26/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/04/26/evernote-links.html",
            "date": " â€¢ Apr 26, 2014"
        }
        
    
  
    
        ,"post312": {
            "title": "Evernote web clips, 25/4/2014",
            "content": "Image Recoloring using Gaussian Mixture Model and Expectation Maximization . _gpc.py . _gpr.py . 1.7 Gaussian Processes â€” scikit-learn 0.14 documentation .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/04/25/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/04/25/evernote-links.html",
            "date": " â€¢ Apr 25, 2014"
        }
        
    
  
    
        ,"post313": {
            "title": "Evernote web clips, 24/4/2014",
            "content": "Neural networks and deep learning . java - How can I pass objects to an exposed luaj function? - Stack Overflow .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/04/24/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/04/24/evernote-links.html",
            "date": " â€¢ Apr 24, 2014"
        }
        
    
  
    
        ,"post314": {
            "title": "Evernote web clips, 23/4/2014",
            "content": "The Science of Scientific Writing Â» American Scientist . File Exchange - MATLAB Central . A Gentle Introduction to Infrared Photography - Part 1 â€” Twelve-Tone Infrared Photography . Infrared basics for digital photographers . FLIR Tools Software for Use with FLIR Infrared Cameras and Thermal Imagers . Open Source Thermal Imaging . IRINFO - Understanding Proprietary Infrared Image Files .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/04/23/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/04/23/evernote-links.html",
            "date": " â€¢ Apr 23, 2014"
        }
        
    
  
    
        ,"post315": {
            "title": "jsoup Evernote web clips, 21/4/2014",
            "content": "Use selector-syntax to find elements: jsoup Java HTML parser . Use DOM methods to navigate a document: jsoup Java HTML parser . jsoup Java HTML Parser, with best of DOM, CSS, and jquery . Working with URLs: jsoup Java HTML parser . Extract attributes, text, and HTML from elements . Example program: list links: jsoup Java HTML parser . Set attribute values: jsoup Java HTML parser . Jsoup.clean without adding html entities - Stack Overflow . jsoup: Java HTML Parser . Whitelist (jsoup 1.7.4-SNAPSHOT API) . How To Parse HTML in JAVA -JSOUP Examples .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/jsoup/2014/04/21/jsoup-evernote-links.html",
            "relUrl": "/evernote/web%20clip/jsoup/2014/04/21/jsoup-evernote-links.html",
            "date": " â€¢ Apr 21, 2014"
        }
        
    
  
    
        ,"post316": {
            "title": "Evernote web clips, 21/4/2014",
            "content": "LOCOCONZ-PAS.txt . hypercard.org - Open Source HyperCard-related stuff . q_c.txt . dkpro-jwpl . TemplateNameExtractor.java . MicroDesign 3 page (.MDP) and area (.MDA) file specifications . LocoScript 1 file format .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/04/21/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/04/21/evernote-links.html",
            "date": " â€¢ Apr 21, 2014"
        }
        
    
  
    
        ,"post317": {
            "title": "lttoolbox oneOrMore",
            "content": "oneOrMore . This is code from lttoolbox, licence GPL 2 . void Transducer::oneOrMore(int const epsilon_tag) { Â  joinFinals(epsilon_tag); Â  int state = newState(); Â  linkStates(state, initial, epsilon_tag); Â  initial = state; Â  state = newState(); Â  linkStates(*finals.begin(), state, epsilon_tag); Â  finals.clear(); Â  finals.insert(state); Â  linkStates(state, initial, epsilon_tag); } void Transducer::joinFinals(int const epsilon_tag) { Â  if(finals.size() &gt; 1) Â  { Â Â Â  int state = newState(); Â Â Â  for(set&lt;int&gt;::iterator it = finals.begin(), limit = finals.end(); Â Â Â Â Â Â Â  it != limit; it++) Â Â Â  { Â Â Â Â Â  linkStates(*it, state, epsilon_tag); Â Â Â  } Â Â Â  finals.clear(); Â Â Â  finals.insert(state); Â  } Â  else if(finals.size() == 0) Â  { Â Â Â  wcerr &lt;&lt; L&quot;Error: empty set of final states&quot; &lt;&lt;endl; Â Â Â  exit(EXIT_FAILURE); Â  } } void Transducer::linkStates(int const source, int const destino, Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  int const etiqueta) { Â  if(transitions.find(source) != transitions.end() &amp;&amp; Â Â Â Â  transitions.find(destino) != transitions.end()) Â  { Â Â Â  // new code Â Â Â  pair&lt;multimap&lt;int, int&gt;::iterator, multimap&lt;int, int&gt;::iterator&gt; range; Â Â Â  range = transitions[source].equal_range(etiqueta); Â Â Â  for(;range.first != range.second; range.first++) Â Â Â  { Â Â Â Â Â  if(range.first-&gt;first == etiqueta &amp;&amp; range.first-&gt;second == destino) Â Â Â Â Â  { Â Â Â Â Â Â Â  return; Â Â Â Â Â  } Â Â Â  } Â Â Â  // end of new code Â Â Â  transitions[source].insert(pair&lt;int, int&gt;(etiqueta, destino)); Â  } Â  else Â  { Â Â Â  wcerr &lt;&lt; L&quot;Error: Trying to link nonexistent states (&quot; &lt;&lt; source; Â Â Â  wcerr &lt;&lt; L&quot;, &quot; &lt;&lt; destino &lt;&lt; L&quot;, &quot; &lt;&lt; etiqueta &lt;&lt; L&quot;)&quot; &lt;&lt; endl; Â Â Â  exit(EXIT_FAILURE); Â  } } .",
            "url": "https://jimregan.github.io/notes/evernote/lttoolbox/2014/03/23/one-or-more.html",
            "relUrl": "/evernote/lttoolbox/2014/03/23/one-or-more.html",
            "date": " â€¢ Mar 23, 2014"
        }
        
    
  
    
        ,"post318": {
            "title": "Evernote web clips, 22/6/2013",
            "content": "Quick notes on how to use RapidXML . rapid xml example . Archive of Formal Proofs .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2013/06/22/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2013/06/22/evernote-links.html",
            "date": " â€¢ Jun 22, 2013"
        }
        
    
  
    
        ,"post319": {
            "title": "Evernote web clips, 12/2/2013",
            "content": "IBM Model 1 . IBM Model 1 defines the probability of a sentence $s_1^J$, with length $J$, being translated to a sentence $t_1^I$, with length $I$, with the alignment $a_1^J$ as: . $Pr(t,a|s) = frac{ epsilon}{(J+1)^{I}} prod_{j=1}^{J}{tr(t_j|s_{a(j)})}$ . ASM/AAM . LeungMalikFilterBank .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2013/02/12/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2013/02/12/evernote-links.html",
            "date": " â€¢ Feb 12, 2013"
        }
        
    
  
    
        ,"post320": {
            "title": "Evernote web clips, 28/1/2013",
            "content": "mysql&gt; SELECT COUNT(DISTINCT p.product_id) AS total FROM oc_product p LEFT JOIN oc_product_description pd ON (p.product_id = pd.product_id) LEFT JOIN oc_product_to_store p2s ON (p.product_id = p2s.product_id) LEFT JOIN oc_product_to_category p2c ON (p.product_id = p2c.product_id) WHERE pd.language_id = &#39;1&#39; AND p.status = &#39;1&#39; AND p.date_available &lt;= NOW() AND p2s.store_id = &#39;0&#39; AND (p2c.category_id = &#39;2101&#39;); +-+ | total | +-+ |Â Â Â  19 | +-+ 1 row in set (15.58 sec) . Keynote DTD . keynote-apxl.html .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2013/01/28/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2013/01/28/evernote-links.html",
            "date": " â€¢ Jan 28, 2013"
        }
        
    
  
    
        ,"post321": {
            "title": "Evernote web clips, 2012-09-17",
            "content": "[How to clear font caches in Leopard | Macworld](http://www.macworld.com/article/1139383/fontcacheclear.html) | . If you want to remove the font cache for all users, use this command, and provide your admin password when asked: sudo atsutil databases -remove . Once youâ€™ve cleared the caches, you should stop and restart the ATS server with these commands: . $ atsutil server -shutdown . $ atsutil server -ping . OpenIMAJ DoubleKMeans .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2012/09/17/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2012/09/17/evernote-links.html",
            "date": " â€¢ Sep 17, 2012"
        }
        
    
  
    
        ,"post322": {
            "title": "Evernote web clips, 16/9/2012",
            "content": "[Home | Natural Language Processing Laboratory](http://web.archive.org/web/20110907050907/http://nlp.sbu.ac.ir/site) | . [Multilingual Central Repository | adimen.si.ehu.es](http://adimen.si.ehu.es/web/MCR) | . MultiWordNet - Related works . MLSN: Download . Japanese Wordnet . FinnWordNet: Download files - Department of General Linguistics . Estonian Wordnet . Thai WordNet license . Sanskrit WordNet . SlovenskÃ¡ terminologickÃ¡ databÃ¡za .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/wordnet/2012/09/16/evernote-links.html",
            "relUrl": "/evernote/web%20clip/wordnet/2012/09/16/evernote-links.html",
            "date": " â€¢ Sep 16, 2012"
        }
        
    
  
    
        ,"post323": {
            "title": "SUMO relations",
            "content": "SUMO relations . Â  Â  . equivalenceRelationÂ  | = | . subsumingRelationÂ  | + | . instanceRelation | @ | . antiSubsumingRelation | [ | . antiEquivalenceRelation | : | .",
            "url": "https://jimregan.github.io/notes/evernote/sumo/2012/09/10/sumo-relations.html",
            "relUrl": "/evernote/sumo/2012/09/10/sumo-relations.html",
            "date": " â€¢ Sep 10, 2012"
        }
        
    
  
    
        ,"post324": {
            "title": "Linking lexical resources and ontologies on the semantic web with lemon",
            "content": "@inproceedings{McCrae:2011:LLR:2008892.2008914, author = {McCrae, John and Spohr, Dennis and Cimiano, Philipp}, title = {Linking lexical resources and ontologies on the semantic web with lemon}, booktitle = {Proceedings of the 8th extended semantic web conference on The semantic web: research and applications - Volume Part I}, series = {ESWC&#39;11}, year = {2011}, isbn = {978-3-642-21033-4}, location = {Heraklion, Crete, Greece}, pages = {245--259}, numpages = {15}, url = {http://dl.acm.org/citation.cfm?id=2008892.2008914}, acmid = {2008914}, publisher = {Springer-Verlag}, address = {Berlin, Heidelberg}, } .",
            "url": "https://jimregan.github.io/notes/evernote/2012/08/17/lemon-citation.html",
            "relUrl": "/evernote/2012/08/17/lemon-citation.html",
            "date": " â€¢ Aug 17, 2012"
        }
        
    
  
    
        ,"post325": {
            "title": "ImageTerrier command",
            "content": "ImageTerrier command . /usr/bin/java -Xshare:off -Xmx6G -Djava.awt.headless=true -XX:-UseGCOverheadLimit -Dbundle.size=1000 -Dmemory.reserved=400000000 -cp /Users/jim/Downloads/ImageTerrierTools-3.0.1-jar-with-dependencies.jar org.imageterrier.basictools.BasicIndexer -o idx -qt RANDOM -p BYTE -k 100000 -t POSITION -pm SPATIAL_SCALE_ORI -nb 8,8,8,8 -mins 0.0,0.0,0.0,-3.14157 -maxs 1000.0,1000.0,150.0,3.14157 . .",
            "url": "https://jimregan.github.io/notes/evernote/imageterrier/2012/06/12/imageterrier-command-evernote-links.html",
            "relUrl": "/evernote/imageterrier/2012/06/12/imageterrier-command-evernote-links.html",
            "date": " â€¢ Jun 12, 2012"
        }
        
    
  
    
        ,"post326": {
            "title": "Evernote web clips, 12/6/2012",
            "content": "Tesseract iterator . tess.SetImage(...); tess.Recognize(0); tesseract::ResultIterator* ri = tess.GetIterator(); tesseract::ChoiceIterator* ci; if(ri != 0) { do { const char* symbol = ri-&gt;GetUTF8Text(tesseract::RIL_SYMBOL); if(symbol != 0) { float conf = ri-&gt;Confidence(tesseract::RIL_SYMBOL); std::cout &lt;&lt; &quot; tnext symbol: &quot; &lt;&lt; symbol &lt;&lt; &quot; tconf: &quot; &lt;&lt; conf &lt;&lt; &quot; n&quot;; const tesseract::ResultIterator itr = *ri; ci = new tesseract::ChoiceIterator(itr); do { const char* choice = ci-&gt;GetUTF8Text(); std::cout &lt;&lt; &quot; t t&quot; &lt;&lt; choice &lt;&lt; &quot; conf: &quot; &lt;&lt; ci-&gt;Confidence() &lt;&lt; &quot; n&quot;; } while(ci-&gt;Next()); delete ci; } delete[] symbol; } while((ri-&gt;Next(tesseract::RIL_SYMBOL))); } . System/36-Compatible RPG II Userâ€™s Guide and Reference .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/rpg/tesseract/2012/06/12/evernote-links.html",
            "relUrl": "/evernote/web%20clip/rpg/tesseract/2012/06/12/evernote-links.html",
            "date": " â€¢ Jun 12, 2012"
        }
        
    
  
    
        ,"post327": {
            "title": "Evernote web clips, 21/5/2012",
            "content": "How to write a Paper or Presentation . 10 Scala One Liners to Impress Your Friends . VP_tree.py .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2012/05/21/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2012/05/21/evernote-links.html",
            "date": " â€¢ May 21, 2012"
        }
        
    
  
    
        ,"post328": {
            "title": "Evernote web clips, 19/5/2012",
            "content": "10 CoffeeScript One Liners to Impress Your Friends . Processing real world HTML as if it were XML in scala . SSTable and Log Structured Storage: LevelDB . User:Rednaxela/kD-Tree - RoboWiki . bytefish/libfacerec .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2012/05/19/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2012/05/19/evernote-links.html",
            "date": " â€¢ May 19, 2012"
        }
        
    
  
    
        ,"post329": {
            "title": "Evernote web clips, 18/5/2012",
            "content": "CMU Sphinx: Long audio aligner for foreign languages . A Tour of Scala: Sequence Comprehensions . ScalaNLP . VP trees: A data structure for finding stuff fast . Reading XML using Groovyâ€™s XmlSlurper wayback . R2R Framework â€“ Translating RDF dataÂ from the Web to a target vocabulary . eldur/jwbf . TOPIC MODELING FOR WIKIPEDIA LINK DISAMBIGUATION .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2012/05/18/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2012/05/18/evernote-links.html",
            "date": " â€¢ May 18, 2012"
        }
        
    
  
    
        ,"post330": {
            "title": "Pascal, Software",
            "content": "Software . Two types - Operating Systems, Applications . O.S. â€“ Set of instructions which control the computer â€” MS DOS, OS/2 . App. â€“ Set of instructions to make computer perform specific tasks . Algorithm â€“ set of instructions which lead to a solution . Program â€“ algorithm expressed in a language thaat a computer can understand . Programs are all about data manipulation . must be able to store data &amp; instructions . | data and instructions stored in memory . | . Computer memory is a 2 state device â€“ think of one state as 1, other as 0 â€“ binary . Data and instructions are converted to binary using a coding scheme . Schemes â€“ ASCII, EBCDIC . Programs are at levels, which depend on levels (how far away from the machine) . lowest â€“ machine code . | next â€“ assembler . | next â€“ higher level language . | . Binary programming is difficult. Solutions to problems (programs) are usually written in English like structures called high level languages, which are converted to machine code using a compiler. . Source program (Pascal Statement) . | Compiler . | Object Program (Machine Language) . |",
            "url": "https://jimregan.github.io/notes/college%20notes/1997/09/18/pascal-software.html",
            "relUrl": "/college%20notes/1997/09/18/pascal-software.html",
            "date": " â€¢ Sep 18, 1997"
        }
        
    
  
    
        ,"post331": {
            "title": "Pascal, Introduction to programming",
            "content": "Introduction to Programming . Computer â€“ programmable electronic device that can store information, process it and display results . Hardware â€“ Any physical component . Software â€“ set of instruction which enables computer to perform functions . History . Newgrange, abacus â€“ 2000 years . | Logarithms â€“ 1500 years . | Pascalâ€™s adder, Leibnitz calculator â€“ 1600s . | Jacquardâ€™s Loom â€“ 1801 . | Difference machine, Analytical engine â€“ 1820s . | Hollerith equipment â€“ 1900 . | Mark 1 â€“ 1944 . | Atanasoff Berry Computer â€“ 1942 . | . Input Â Â Â --&gt; CPU --&gt; Secondary &lt;-- Memory (CU, ALU, Main Memory) Output &lt;-- . CPU â€“ all calculations and manipulations carried out . CU takes instructions in given sequence . controls movement of data inside computer | . | ALU performs mathematical functions &amp; logical decisions . | Main memory allows data to be stored for processing &amp; holds results . | .",
            "url": "https://jimregan.github.io/notes/college%20notes/1997/09/18/pascal-intro.html",
            "relUrl": "/college%20notes/1997/09/18/pascal-intro.html",
            "date": " â€¢ Sep 18, 1997"
        }
        
    
  
    
        ,"post332": {
            "title": "Pascal Books",
            "content": "Turbo Pascal - Programming &amp; Problem Solving . (Library) Introduction to Pascal, Welsh Elder 3rd ed. 1988 Prentice Hall 0-13-491549-6 . (library) Simple Pascal McGregor Watt 1989 Pitman 0-273-01704-7 .",
            "url": "https://jimregan.github.io/notes/college%20notes/1997/09/18/pascal-books.html",
            "relUrl": "/college%20notes/1997/09/18/pascal-books.html",
            "date": " â€¢ Sep 18, 1997"
        }
        
    
  
    
        ,"post333": {
            "title": "Music",
            "content": "The Sundays - Summertime . The Pastels - The Hits Hurt . The Marbles - Car Crash . The Devlins - Waiting .",
            "url": "https://jimregan.github.io/notes/college%20notes/1997/09/18/music.html",
            "relUrl": "/college%20notes/1997/09/18/music.html",
            "date": " â€¢ Sep 18, 1997"
        }
        
    
  
    
        ,"post334": {
            "title": "Maths course outline",
            "content": "Foundation Systems (Numeration Systems) . | Logic . | Sets and Relations . | Vectors and Matrix Algebra . | Calculus . | Statistics . | Integers, Semi Groups and Groups . | (If available) Essential Computer Mathematics Seymour Lipschutz Schaun Outline Series . Discrete Mathematics for Computing Peter Grossman ISBN 0 333 646 94 0 Macmillan Press Ltd . Mathematics for Computing McKeon Smith . Any book on discrete mathematics . 20% X-Mas . 5% 2 Midterms (Nov, Mar) .",
            "url": "https://jimregan.github.io/notes/college%20notes/1997/09/18/maths-course-outline.html",
            "relUrl": "/college%20notes/1997/09/18/maths-course-outline.html",
            "date": " â€¢ Sep 18, 1997"
        }
        
    
  
    
        ,"post335": {
            "title": "Business systems, course outline",
            "content": "CP102 . Business Systems . Course Outline . Topic 1 Â - Business Organisations . Business functions (work areas) | . Topic 2 Â - Nature of Management . Topic 3 Â - Business and its external environment . Topic 4 Â - Corporate strategy and planning . Topic 5 Â - Organising . Topic 6 Â - Directing . Topic 7 Â - Controlling . Topic 8 Â - Marketing and sales management . Topic 9 Â - Production and operations management . Topic 10 Â - Human Resource Management . Topic 11 Â - Administration Management . Topic 12 Â - Role of the Systems Analyst . Topic 13 Â - Organisations and information . Topic 14 Â - Project feasibility and management . Topic 15 Â - Data collection and sampling . Topic 16 Â - Methods of Communication . Topic 17 Â - Interviews . Topic 18 Â - Questionnaires . Topic 19 Â - Prototyping . Topic 20 Â - Presentations . Topic 21 Â - The systems life cycle . Topic 22 Â - Systems analysis and design tools . Topic 23 - File management . Assessment . Continuous Assessment Excercises (30%) . Final Written Examination (70%) - 2 hours . Course Texts . Modern Business Administration Robert C Appelby (6th Edition) Pitman Publishing 1994 ISBN 0-273-60282-9 . Systems Analysis And Design K.E. Kendall &amp; J.E. Kendall (Third Edition) Prentice-Hall, 1995 .",
            "url": "https://jimregan.github.io/notes/college%20notes/1997/09/18/bus-sys-course-outline.html",
            "relUrl": "/college%20notes/1997/09/18/bus-sys-course-outline.html",
            "date": " â€¢ Sep 18, 1997"
        }
        
    
  
    
        ,"post336": {
            "title": "Tortured teenage scribblings",
            "content": "Jimmy had been camping at Richardâ€™s house after the Trax, and the next day Eccentric were auditioning singers (they fired PJ - crap). He said they taught him a thousand riffs he forgot, and that theyâ€™re sound &amp; said we can use their equipment any time we want. Jimmy tried out as their singer, but they donâ€™t play â€œhis musicâ€. One guy came in, they played Die Laughing, he hadnâ€™t a clue so he started doing a death metal growl: â€œEhâ€¦ itâ€™s Therapy?â€ â€œOhâ€¦ I thought it sounded punkyâ€. . Sat. we were here, &amp; Paul C came over. Chatted. Heâ€™s going to the Gaeltacht by himself today. Willie &amp; Liam Dunne are going in a few weeks. Heâ€™s going to Feothanach. (Joe went there). .",
            "url": "https://jimregan.github.io/notes/old%20diary/1996/07/01/tortured-teenage-scribblings.html",
            "relUrl": "/old%20diary/1996/07/01/tortured-teenage-scribblings.html",
            "date": " â€¢ Jul 1, 1996"
        }
        
    
  
    
        ,"post337": {
            "title": "The Easter Holidays",
            "content": "The first few days of the Easter Holidays were quite uneventful. I sat around all day watching TV. Then on Holy Thursday I had to pack messages at Crazy Prices. This was quite boring too. I had to do it again on Easter Saturday. At lunch time we were eating at the Apollo. I had finished. One of the lads asked my patrol leader to pass the vinegar. As he was doing this he knocked the leaderâ€™s coffee on top of me. That evening, after I found out we had no scouts, I went into Romcos and played my first ever game of Street Fighter 2. The next day we went on a parade to mass. . The next Sunday we went climbing Galteemore. I almost died of tiredness on the way up and from the idiots from other units on the way down. But when we got to the bottom we stopped for a rest and we played on a heather-covered hill. Then we went to our buses. . When I got home I found that I had missed both episodes of â€œThe Simpsonsâ€ and after a while I watched Mr Bean. . Then, after a couple of hours I went to sleep, dreading school the next day. .",
            "url": "https://jimregan.github.io/notes/old%20diary/1993/04/18/tortured-teenage-scribblings.html",
            "relUrl": "/old%20diary/1993/04/18/tortured-teenage-scribblings.html",
            "date": " â€¢ Apr 18, 1993"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats.Â &#8617; . |",
          "url": "https://jimregan.github.io/notes/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  

  

  

  

  
  

  
      ,"page14": {
          "title": "",
          "content": "Sitemap: {{ â€œsitemap.xmlâ€ | absolute_url }} | .",
          "url": "https://jimregan.github.io/notes/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}