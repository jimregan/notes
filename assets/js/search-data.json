{
  
    
        "post0": {
            "title": "wav2vec-u notes",
            "content": "The skippable blah . wav2vec unsupervised has caught a bit of attention. . There has been a mixed bag of expectations: there was a blog post, they even had a video: . Facebook AI‚Äôs new open source speech recognition model, wav2vec Unsupervised, uses no transcribed data at all. We‚Äôve tested it on many languages, such as Swahili, that have proven challenging for other systems. Learn more in our blog post here: https://t.co/b6ic50AsM6 pic.twitter.com/x3Tx9nxq5i . &mdash; Facebook AI (@facebookai) June 1, 2021 So, a few people have had the expectation that it would be quite a bit easier than it turned out to. . I‚Äôve been beating my head against multiple walls for over a decade, with various pieces of research software for various purposes, so my expectations were a little different. Just looking at the directory, the third subdirectory is kaldi_self_train, which is the first red flag: this will not be easy. Scrolling down, among the first instructions are zsh scripts. zsh is a great shell, and using it as a shell was a sign of sophistication in the late 90s, but it isn‚Äôt the most universal shell, so if your scripts are zsh scripts, that‚Äôs a pretty good sign you‚Äôve never tried to run them on a second computer. That said, trying to use any kind of software on Linux in the late 90s involved some sort of beating of heads against walls, so that contributes too. . I like Kaggle. A lot. I like the workflow, and being able to use the output of one notebook as the input to another. I like being able to run something, and not have to babysit it in case it disconnects, like with Colab. So I‚Äôve tried to do as much of this as possible on Kaggle. . But the GPU images on Kaggle are seriously broken. It could be by design: the handful of things I‚Äôve tried that are run purely as a notebook seem to work well. Maybe conda is deliberately cobbled, maybe it‚Äôs unintentional, but it fails more often than not. So anything that involves using a GPU: switch to Colab. . Caveat . These are my notes for my own use, because once I‚Äôve done a full trial run, I have some data I want to try out. I‚Äôm deliberately not adding additional text, mostly because I want the trial run to go as quickly as possible; that‚Äôs failing for other reasons, but such is life. . What I‚Äôve done was based on my understanding, or best guess. I can guarantee that I was not smoking any illegal substances, but considering where I live, I can‚Äôt guarantee that there was no second-hand smoke. . There is an issue on fairseq‚Äôs github where Alexei Baevski has said that better instructions are coming in a week or so, so maybe bide your time; he also offered to answer questions on that thread, so if you have questions, your best bet is to ask there. . Step 0: Data . In an ideal world, Kaggle‚Äôs dataset uploader would Do The Right Thing when given a link to a zip file, or, rather, one of two Right Things: just download it, or download and unzip. Instead, it creates a directory for every file in the zip. . ü§¶ . Cool, I‚Äôll just do that in a notebook. . wav2vec-u (and just about everything else in the world of ASR, ever) needs audio sampled at 16 kHz, and uses soundfile, so MP3s are not welcome, so I‚Äôll do that in another notebook. . Step 0.1: ltr/wrd/phn files . Preparing these files is mentioned in passing, as though they‚Äôre self-explanatory. Which they are, if you happen to have played with phoneme-based ASR as well as wav2letter. So, not really. . What I ended up doing is this; I should have changed the tab separation in the dict.* files to a space, because that‚Äôs what‚Äôs usually given to Kaldi, but IIRC, it handles tab. So change: . paste /tmp/$i.wl /tmp/$i.wl.phn &gt; dict.$i . to: . paste /tmp/$i.wl /tmp/$i.wl.phn | tr &#39; t&#39; &#39; &#39; &gt; dict.$i . or equivalent. . Caveat: I can‚Äôt say for sure if these are actually correct outputs, and I‚Äôm not even sure they‚Äôre actually used by default, aside from the prepare_audio.sh script dying if they‚Äôre missing. . There are some notes in that notebook where I tracked down and corrected for espeak‚Äôs language switching; feel free to ignore that if you‚Äôre not borderline OCD. . Step 0.2: Preparing TSVs . Another thing that‚Äôs glossed over a bit is the TSV files, which are more pseudo-TSV. . ‚ÄúSimilar to wav2vec 2.0‚Äù is more-or-less true, in that you can figure it out if you look at this script; basically, the format is: . /path/to/my/audio/ file1.wav [number of frames] file2.wav [number of frames] ... (etc.) . I used this notebook to convert Common Voice TSV to these pseudo-TSVs, but the number of frames aren‚Äôt read by anything, so you can get away with a file list, as long as the first line is the path. . Step 1: VAD/Silence trimming . There‚Äôs a passing mention of rVAD, like it‚Äôs a common piece of software that you should just be able to install. It‚Äôs not: it‚Äôs here. Or, you know, save yourself the trouble and copy the relevant steps from the notebook . This went fairly smoothly; I wrestled with Kaggle a bit, but I think any problems here were of my own creation. . Step 2: prepare_audio.sh . My notebook for prepare_audio.sh is quite short; basically, you need the dict.*, *.wrd, *.ltr, and *.phn files from Step 0.1, and: . pip install npy-append-array faiss-gpu . (also, possibly, apt install zsh) . Also: wow! This used GPU on Kaggle, and actually worked. . Step 3: prepare_text.sh . This needs Kaldi to compile FSTs. On Kaggle, I used this notebook to extract a pre-built version from the official docker images. DNN parts won‚Äôt run, because they‚Äôre compiled for an earlier version of CUDA, but they‚Äôre not necessary for this step. . If you‚Äôre using Colab, this question on Stack Overflow is for you: . !pip install kora -q import kora.install.kaldi . The version of Kaldi there is also from the official docker image (that‚Äôs where I got the idea), but it also downloads and unpacks it for you. Which is nice. . My notebook for running prepare_text.sh has more notes than usual: check it out . Step 4: GAN training . This doesn‚Äôt work on Kaggle, because GPU. It does, however, run on CPU‚Äîalbeit 8-9 times slower‚Äîso I‚Äôve been chaining together calls, starting with this, leading up to (at the time of writing) this. . The good news is, it runs fine on Colab: notebook here. . (By ‚Äúfine‚Äù, I mean ‚Äúwith this patch added, running from this branch where everything has been moved around.‚Äù Close enough.) . Fin . I‚Äôm still waiting for GAN training to finish, so I can‚Äôt comment on anything else. .",
            "url": "https://jimregan.github.io/notes/wav2vec-u/2021/06/05/wav2vec-u-notes.html",
            "relUrl": "/wav2vec-u/2021/06/05/wav2vec-u-notes.html",
            "date": " ‚Ä¢ Jun 5, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "wav2vec-u Common Voice Swedish - GAN training, CPU8",
            "content": "Original here . Preparation . !cp ../input/w2vu-cvsv-checkpoints-cpu7/checkpoint_best.pt . !cp ../input/w2vu-cvsv-checkpoints-cpu7/checkpoint_last.pt . . %%capture !conda install -c pykaldi pykaldi -y . %cd /tmp . !git clone https://github.com/jimregan/fairseq/ --branch issue3581 . !git clone https://github.com/kpu/kenlm . %%capture !apt-get -y install libeigen3-dev liblzma-dev zlib1g-dev libbz2-dev . %%capture %cd /tmp/kenlm !python setup.py install %cd /tmp . import os os.environ[&#39;PATH&#39;] = f&quot;{os.environ[&#39;PATH&#39;]}:/tmp/kenlm/build/bin/&quot; os.environ[&#39;FAIRSEQ_ROOT&#39;] = &#39;/tmp/fairseq&#39; . %cd /tmp/fairseq/ . %%capture !python setup.py install . %cd /tmp/fairseq/ . os.environ[&#39;HYDRA_FULL_ERROR&#39;] = &#39;1&#39; . %%capture !pip install editdistance . GAN . %%writefile rungan.sh PREFIX=w2v_unsup_gan_xp TASK_DATA=/kaggle/input/wav2vec-u-cv-swedish-audio/precompute_pca512_cls128_mean_pooled/ TEXT_DATA=/kaggle/input/wav2vec-u-cv-swedish-text-prep/preppedtext/phones/ KENLM_PATH=/kaggle/input/wav2vec-u-cv-swedish-text-prep/preppedtext/phones/lm.phones.filtered.04.bin PREFIX=$PREFIX fairseq-hydra-train -m --config-dir fairseq/config/model/wav2vecu/gan --config-name w2vu task.data=${TASK_DATA} task.text_data=${TEXT_DATA} task.kenlm_path=${KENLM_PATH} checkpoint.no_epoch_checkpoints=false checkpoint.keep_last_epochs=5 checkpoint.save_dir=/kaggle/working &#39;common.seed=range(0,5)&#39; . !bash rungan.sh .",
            "url": "https://jimregan.github.io/notes/kaggle/wav2vec-u/2021/06/05/wav2vec-u-cv-swedish-gan-cpu8.html",
            "relUrl": "/kaggle/wav2vec-u/2021/06/05/wav2vec-u-cv-swedish-gan-cpu8.html",
            "date": " ‚Ä¢ Jun 5, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "wav2vec-u Common Voice Swedish - GAN training, CPU1",
            "content": "Original here . Preparation . %%capture !conda install -c pykaldi pykaldi -y . %cd /tmp . /tmp . !git clone https://github.com/jimregan/fairseq/ --branch issue3581 . !git clone https://github.com/kpu/kenlm . %%capture !apt-get -y install libeigen3-dev liblzma-dev zlib1g-dev libbz2-dev . %%capture %cd /tmp/kenlm !python setup.py install %cd /tmp . import os os.environ[&#39;PATH&#39;] = f&quot;{os.environ[&#39;PATH&#39;]}:/tmp/kenlm/build/bin/&quot; os.environ[&#39;FAIRSEQ_ROOT&#39;] = &#39;/tmp/fairseq&#39; . %cd /tmp/fairseq/ . /tmp/fairseq . %%capture !python setup.py install . %cd /tmp/fairseq/ . /tmp/fairseq . os.environ[&#39;HYDRA_FULL_ERROR&#39;] = &#39;1&#39; . %%capture !pip install editdistance . GAN . %%writefile rungan.sh PREFIX=w2v_unsup_gan_xp TASK_DATA=/kaggle/input/wav2vec-u-cv-swedish-audio/precompute_pca512_cls128_mean_pooled/ TEXT_DATA=/kaggle/input/wav2vec-u-cv-swedish-text-prep/preppedtext/phones/ KENLM_PATH=/kaggle/input/wav2vec-u-cv-swedish-text-prep/preppedtext/phones/lm.phones.filtered.04.bin PREFIX=$PREFIX fairseq-hydra-train -m --config-dir fairseq/config/model/wav2vecu/gan --config-name w2vu task.data=${TASK_DATA} task.text_data=${TEXT_DATA} task.kenlm_path=${KENLM_PATH} checkpoint.no_epoch_checkpoints=false checkpoint.keep_last_epochs=20 checkpoint.save_dir=/kaggle/working &#39;common.seed=range(0,5)&#39; . Writing rungan.sh . !bash rungan.sh .",
            "url": "https://jimregan.github.io/notes/kaggle/wav2vec-u/2021/06/01/wav2vec-u-cv-swedish-gan-cpu1.html",
            "relUrl": "/kaggle/wav2vec-u/2021/06/01/wav2vec-u-cv-swedish-gan-cpu1.html",
            "date": " ‚Ä¢ Jun 1, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "wav2vec-u CV-sv - GAN",
            "content": "The original attempt on Kaggle won&#39;t run because of an issue with CuDNN, but this notebook runs fine on Colab. . Preparation . !pip install condacolab . Collecting condacolab Downloading https://files.pythonhosted.org/packages/ee/47/6f9fe13087c31aba889c4b09f9beaa558bf216bf9108c9ccef44e6c9dcfe/condacolab-0.1.2-py3-none-any.whl Installing collected packages: condacolab Successfully installed condacolab-0.1.2 . import condacolab condacolab.install() . ‚è¨ Downloading https://github.com/jaimergp/miniforge/releases/latest/download/Mambaforge-colab-Linux-x86_64.sh... üì¶ Installing... üìå Adjusting configuration... ü©π Patching environment... ‚è≤ Done in 0:00:36 üîÅ Restarting kernel... . %%capture !conda install -c pykaldi pykaldi -y . !git clone https://github.com/jimregan/fairseq/ --branch issue3581 . Cloning into &#39;fairseq&#39;... remote: Enumerating objects: 28296, done. remote: Total 28296 (delta 0), reused 0 (delta 0), pack-reused 28296 Receiving objects: 100% (28296/28296), 11.77 MiB | 24.69 MiB/s, done. Resolving deltas: 100% (21286/21286), done. . !git clone https://github.com/kpu/kenlm . Cloning into &#39;kenlm&#39;... remote: Enumerating objects: 13824, done. remote: Counting objects: 100% (137/137), done. remote: Compressing objects: 100% (79/79), done. remote: Total 13824 (delta 76), reused 92 (delta 45), pack-reused 13687 Receiving objects: 100% (13824/13824), 5.49 MiB | 20.76 MiB/s, done. Resolving deltas: 100% (7956/7956), done. . %%capture !apt-get -y install libeigen3-dev liblzma-dev zlib1g-dev libbz2-dev . %%capture %cd /content/kenlm !python setup.py install %cd /tmp . import os os.environ[&#39;PATH&#39;] = f&quot;{os.environ[&#39;PATH&#39;]}:/content/kenlm/build/bin/&quot; os.environ[&#39;FAIRSEQ_ROOT&#39;] = &#39;/content/fairseq&#39; . %cd /content/fairseq/ . /content/fairseq . %%capture !python setup.py install . os.environ[&#39;HYDRA_FULL_ERROR&#39;] = &#39;1&#39; . %%capture !pip install editdistance . https://colab.research.google.com/github/corrieann/kaggle/blob/master/kaggle_api_in_colab.ipynb . %%capture !pip install kaggle . from google.colab import files uploaded = files.upload() for fn in uploaded.keys(): print(&#39;User uploaded file &quot;{name}&quot; with length {length} bytes&#39;.format( name=fn, length=len(uploaded[fn]))) # Then move kaggle.json into the folder where the API expects to find it. !mkdir -p ~/.kaggle/ &amp;&amp; mv kaggle.json ~/.kaggle/ &amp;&amp; chmod 600 ~/.kaggle/kaggle.json . Upload widget is only available when the cell has been executed in the current browser session. Please rerun this cell to enable. Saving kaggle.json to kaggle.json User uploaded file &#34;kaggle.json&#34; with length 64 bytes . %cd /content . /content . !kaggle datasets download &quot;jimregan/w2vu-cvsv-prepared-text&quot; . Downloading w2vu-cvsv-prepared-text.zip to /content 75% 13.0M/17.4M [00:00&lt;00:00, 55.1MB/s] 100% 17.4M/17.4M [00:00&lt;00:00, 64.5MB/s] . %%capture !unzip /content/w2vu-cvsv-prepared-text.zip . !kaggle datasets download -d jimregan/w2vu-cvsv-precompute-pca512-cls128-mean-pooled . Downloading w2vu-cvsv-precompute-pca512-cls128-mean-pooled.zip to /content 98% 386M/394M [00:04&lt;00:00, 90.1MB/s] 100% 394M/394M [00:04&lt;00:00, 102MB/s] . %%capture !unzip w2vu-cvsv-precompute-pca512-cls128-mean-pooled.zip . !rm *.zip . GAN . import torch torch.version.cuda . &#39;10.1&#39; . torch.backends.cudnn.version() . 7603 . %cd /content/fairseq . /content/fairseq . from google.colab import drive drive.mount(&#39;/content/drive&#39;) . %%writefile rungan.sh PREFIX=w2v_unsup_gan_xp TASK_DATA=/content/precompute_pca512_cls128_mean_pooled TEXT_DATA=/content/preppedtext/phones/ KENLM_PATH=/content/preppedtext/phones/lm.phones.filtered.04.bin PREFIX=$PREFIX CUDA_LAUNCH_BLOCKING=1 fairseq-hydra-train -m --config-dir fairseq/config/model/wav2vecu/gan --config-name w2vu task.data=${TASK_DATA} task.text_data=${TEXT_DATA} task.kenlm_path=${KENLM_PATH} checkpoint.no_epoch_checkpoints=false checkpoint.keep_last_epochs=5 checkpoint.save_dir=/content/drive/MyDrive/w2vu &#39;common.seed=range(0,5)&#39; . Writing rungan.sh . !bash rungan.sh . [2021-06-04 00:06:14,189][fairseq.tasks.unpaired_audio_text][INFO] - REF: …õ n f ≈ì  Ç …ô n a d …µ  Ç …ô k t f √∏Àê r d eÀê t s …î m h …õ n d …ô p oÀê …ï ≈ì r k …î n s …õ t …ô n [2021-06-04 00:06:14,192][fairseq.tasks.unpaired_audio_text][INFO] - HYP: oÀê b iÀê  É ≈ì m …ï m ≈ì …ï …™ …µ …ï …µ m …µ s …µ uÀê …µ s …µ …õ  Ç a tÀê sx [2021-06-04 00:06:14,198][fairseq.tasks.unpaired_audio_text][INFO] - LM [REF]: -53.44462585449219, 0.05339602260269112 [2021-06-04 00:06:14,198][fairseq.tasks.unpaired_audio_text][INFO] - LM [HYP]: -61.104984283447266, 0.006571721232914821 [2021-06-04 00:06:14,844][valid][INFO] - {&#34;epoch&#34;: 8, &#34;valid_loss&#34;: &#34;0.93&#34;, &#34;valid_ntokens&#34;: &#34;3039.79&#34;, &#34;valid_nsentences&#34;: &#34;144.214&#34;, &#34;valid_lm_score_sum&#34;: &#34;-71760.8&#34;, &#34;valid_num_pred_chars&#34;: &#34;28972&#34;, &#34;valid_vocab_seen_pct&#34;: &#34;0.949477&#34;, &#34;valid_uer&#34;: &#34;92.9812&#34;, &#34;valid_weighted_lm_ppl&#34;: &#34;229.386&#34;, &#34;valid_lm_ppl&#34;: &#34;206.793&#34;, &#34;valid_wps&#34;: &#34;15426&#34;, &#34;valid_wpb&#34;: &#34;3039.8&#34;, &#34;valid_bsz&#34;: &#34;144.2&#34;, &#34;valid_num_updates&#34;: &#34;128&#34;, &#34;valid_best_weighted_lm_ppl&#34;: &#34;189.002&#34;} [2021-06-04 00:06:14,846][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 8 @ 128 updates [2021-06-04 00:06:14,847][fairseq.trainer][INFO] - Saving checkpoint to /content/drive/MyDrive/w2vu/checkpoint8.pt [2021-06-04 00:06:14,911][fairseq.trainer][INFO] - Finished saving checkpoint to /content/drive/MyDrive/w2vu/checkpoint8.pt [2021-06-04 00:06:14,974][fairseq.checkpoint_utils][INFO] - Saved checkpoint /content/drive/MyDrive/w2vu/checkpoint8.pt (epoch 8 @ 128 updates, score 229.38563413598007) (writing took 0.12713056299980963 seconds) .",
            "url": "https://jimregan.github.io/notes/kaggle/colab/wav2vec-u/2021/05/30/wav2vec-u-cv-swedish-gan.html",
            "relUrl": "/kaggle/colab/wav2vec-u/2021/05/30/wav2vec-u-cv-swedish-gan.html",
            "date": " ‚Ä¢ May 30, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Common Voice Swedish - prepare audio",
            "content": "Original here . %cd /tmp . /tmp . %%capture !pip install git+https://github.com/pytorch/fairseq/ . %%capture !git clone https://github.com/pytorch/fairseq/ . %cd fairseq/examples/wav2vec/unsupervised/scripts . /tmp/fairseq/examples/wav2vec/unsupervised/scripts . !mkdir tsv !for i in train test valid; do echo /kaggle/input/wav2vec-u-cv-swedish-vads/wav/$i/common-voice-swedish-16bit-wav/ &gt; tsv/$i.tsv; cat /kaggle/input/fork-of-wav2vec-u-cv-swedish-tsv/$i.tsv|sed &#39;1d&#39; &gt;&gt; tsv/$i.tsv;done !cp /kaggle/input/wav2vec-u-cv-swedish-prep-ltr-phn-wrd/dic* tsv/ !cp /kaggle/input/wav2vec-u-cv-swedish-prep-ltr-phn-wrd/*.wrd tsv/ !cp /kaggle/input/wav2vec-u-cv-swedish-prep-ltr-phn-wrd/*.ltr tsv/ !cp /kaggle/input/wav2vec-u-cv-swedish-prep-ltr-phn-wrd/*.phn tsv/ . %%capture !pip install npy-append-array . !pip install faiss-gpu . %%capture !apt-get -y install zsh . !zsh prepare_audio.sh tsv /kaggle/working /kaggle/input/download-xlsr-53-wav2vec2-model/xlsr_53_56k.pt . using 512 dim for PCA 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2331/2331 [01:21&lt;00:00, 28.76it/s] 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2019/2019 [01:07&lt;00:00, 29.98it/s] 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2027/2027 [01:08&lt;00:00, 29.41it/s] Faiss Specs: [faiss_spec(pca=0, norm=False, n_clus=128, sphere=False, spec_str=&#39;CLUS128&#39;)] 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2331/2331 [01:10&lt;00:00, 33.09it/s] (223140, 1024) Processing spec faiss_spec(pca=0, norm=False, n_clus=128, sphere=False, spec_str=&#39;CLUS128&#39;) Computing kmeans Clustering 223140 points in 1024D to 128 clusters, redo 3 times, 50 iterations Preprocessing in 0.17 s Outer iteration 0 / 3 Objective improved: keep new clusters Outer iteration 1 / 3 Objective improved: keep new clusters Outer iteration 2 / 3 Objective improved: keep new clusters Faiss Spec: faiss_spec(pca=0, norm=False, n_clus=128, sphere=False, spec_str=&#39;CLUS128&#39;) Loaded centroids (128, 1024) 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2331/2331 [00:58&lt;00:00, 40.05it/s] Faiss Spec: faiss_spec(pca=0, norm=False, n_clus=128, sphere=False, spec_str=&#39;CLUS128&#39;) Loaded centroids (128, 1024) 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2019/2019 [00:57&lt;00:00, 35.24it/s] Faiss Spec: faiss_spec(pca=0, norm=False, n_clus=128, sphere=False, spec_str=&#39;CLUS128&#39;) Loaded centroids (128, 1024) 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2027/2027 [00:51&lt;00:00, 39.40it/s] Reading features Computing PCA data path: /kaggle/working/train 0%| | 0/1 [00:00&lt;?, ?it/s]apply_pca.py:66: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1603729047590/work/torch/csrc/utils/tensor_numpy.cpp:141.) x = torch.from_numpy(features[start:end]).cuda() 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01&lt;00:00, 1.53s/it] data path: /kaggle/working/precompute_pca512/train 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2331/2331 [00:05&lt;00:00, 402.56it/s] data path: /kaggle/working/precompute_pca512_cls128_mean/train 0%| | 0/2331 [00:00&lt;?, ?it/s]mean_pool.py:69: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1603729047590/work/torch/csrc/utils/tensor_numpy.cpp:141.) x = torch.from_numpy(feats).cuda() 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2331/2331 [00:03&lt;00:00, 692.56it/s] data path: /kaggle/working/valid 0%| | 0/1 [00:00&lt;?, ?it/s]apply_pca.py:66: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1603729047590/work/torch/csrc/utils/tensor_numpy.cpp:141.) x = torch.from_numpy(features[start:end]).cuda() 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01&lt;00:00, 1.60s/it] data path: /kaggle/working/precompute_pca512/valid 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2019/2019 [00:04&lt;00:00, 447.45it/s] data path: /kaggle/working/precompute_pca512_cls128_mean/valid 0%| | 0/2019 [00:00&lt;?, ?it/s]mean_pool.py:69: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1603729047590/work/torch/csrc/utils/tensor_numpy.cpp:141.) x = torch.from_numpy(feats).cuda() 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2019/2019 [00:03&lt;00:00, 592.35it/s] data path: /kaggle/working/test 0%| | 0/1 [00:00&lt;?, ?it/s]apply_pca.py:66: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1603729047590/work/torch/csrc/utils/tensor_numpy.cpp:141.) x = torch.from_numpy(features[start:end]).cuda() 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:01&lt;00:00, 1.22s/it] data path: /kaggle/working/precompute_pca512/test 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2027/2027 [00:05&lt;00:00, 379.47it/s] data path: /kaggle/working/precompute_pca512_cls128_mean/test 0%| | 0/2027 [00:00&lt;?, ?it/s]mean_pool.py:69: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1603729047590/work/torch/csrc/utils/tensor_numpy.cpp:141.) x = torch.from_numpy(feats).cuda() 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2027/2027 [00:03&lt;00:00, 569.65it/s] .",
            "url": "https://jimregan.github.io/notes/kaggle/wav2vec-u/2021/05/27/wav2vec-u-cv-swedish-audio.html",
            "relUrl": "/kaggle/wav2vec-u/2021/05/27/wav2vec-u-cv-swedish-audio.html",
            "date": " ‚Ä¢ May 27, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "wav2vec-u CV-sv - prepare text",
            "content": "Original here . %cd /opt . /opt . %%capture !tar xvf /kaggle/input/extract-prebuilt-kaldi-from-docker/kaldi.tar . %cd /tmp . /tmp . !git clone https://github.com/pytorch/fairseq/ . %%capture !pip install phonemizer . %%capture !pip install git+https://github.com/pytorch/fairseq/ . %%capture !apt-get -y install espeak . !git clone https://github.com/kpu/kenlm . %%capture !apt-get -y install libeigen3-dev liblzma-dev zlib1g-dev libbz2-dev . %%capture %cd kenlm !mkdir build %cd build !cmake .. !make -j 4 %cd /tmp . import os os.environ[&#39;PATH&#39;] = f&quot;{os.environ[&#39;PATH&#39;]}:/tmp/kenlm/build/bin/&quot; os.environ[&#39;FAIRSEQ_ROOT&#39;] = &#39;/tmp/fairseq&#39; . !cat /kaggle/input/wav2vec-u-cv-swedish-audio/*.wrd | grep -v &#39;^$&#39; | sort| uniq &gt; /kaggle/working/sentences.txt . %cd fairseq/examples/wav2vec/unsupervised . /tmp/fairseq/examples/wav2vec/unsupervised . %%capture !apt-get -y install zsh . !mkdir /kaggle/working/preppedtext . %cd scripts . /tmp/fairseq/examples/wav2vec/unsupervised/scripts . The next part requires a FastText language id model; I don&#39;t know where the 187 language model comes from, but there is a model for 176 languages here . !wget https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin . !cat normalize_and_filter_text.py|sed -e &#39;s/187/176/&#39; &gt; tmp !mv tmp normalize_and_filter_text.py . os.environ[&#39;HYDRA_FULL_ERROR&#39;] = &#39;1&#39; . import os os.environ[&#39;LD_LIBRARY_PATH&#39;] = &#39;/opt/conda/lib:/opt/kaldi/tools/openfst-1.6.7/lib:/opt/kaldi/src/lib&#39; . There are two lines with missing variables in prepare_text.sh - pull request - so replace the file. . While I&#39;m replacing the file: most of the first part of the script is unneeded, as I already have a phonetic dictionary, so I&#39;m use that instead. . With the calls of the preprocess.py script, make sure to check the threshold: there&#39;s a divide by zero if the threshold is set too high. . Config options for kaldi_initializer.py . in_labels: a naming component, for the Kaldi lexicons/fsts (required) | wav2letter_lexicon: path to wav2letter lexicon | out_labels: a naming component, for the Kaldi lexicons/fsts: set to in_label if missing | kaldi_root: path to Kaldi: /opt/kaldi for my kaggle image | fst_dir: path where generated fsts will be saved | data_dir: path to phones data | lm_arpa: path to the lm in ARPA format | blank_symbol: CTC blank symbol (&lt;s&gt; here) | silence_symbol: Kaldi symbol for silence (&lt;SIL&gt; is set for two of the scripts) | . A config file needs to exist for this, even though the options set in it seem to be ignored. . !mkdir /tmp/fairseq/examples/speech_recognition/kaldi/config/ . %%writefile /tmp/fairseq/examples/speech_recognition/kaldi/config/config.yaml kaldi_root: &quot;/opt/kaldi&quot; . Writing /tmp/fairseq/examples/speech_recognition/kaldi/config/config.yaml . %%writefile prepare_text.sh #!/usr/bin/env zsh # Copyright (c) Facebook, Inc. and its affiliates. # # This source code is licensed under the MIT license found in the # LICENSE file in the root directory of this source tree. lg=$1 text_path=$2 target_dir=$3 #ph_lg=${lg:l} #if test &quot;$lg&quot; = &#39;fr&#39;; then # ph_lg=&#39;fr-fr&#39; #elif test &quot;$lg&quot; = &#39;en&#39;; then # ph_lg=&#39;en-us&#39; #elif test &quot;$lg&quot; = &#39;pt&#39;; then # ph_lg=&#39;pt-br&#39; #fi ph_lg=&quot;sv&quot; echo $lg echo $ph_lg echo $text_path echo $target_dir mkdir -p $target_dir #python normalize_and_filter_text.py --lang $lg &lt; $text_path | grep -v &#39; - - -&#39; &gt;! $target_dir/lm.upper.lid.txt #python $FAIRSEQ_ROOT/fairseq_cli/preprocess.py --dataset-impl mmap --trainpref $target_dir/lm.upper.lid.txt --only-source --destdir $target_dir --thresholdsrc 2 --padding-factor 1 --dict-only #cut -f1 -d&#39; &#39; $target_dir/dict.txt | grep -v -x &#39;[[:punct:]]*&#39; | grep -Pv &#39; d d d d d+&#39; &gt;! $target_dir/words.txt cp /kaggle/input/wav2vec-u-cv-swedish-audio/train.wrd $target_dir/lm.upper.lid.txt cut -f1 -d&#39; &#39; /kaggle/input/wav2vec-u-cv-swedish-audio/dict.train &gt;! $target_dir/words.txt #one=$(echo &quot;1&quot; | PHONEMIZER_ESPEAK_PATH=$(which espeak) phonemize -p &#39; &#39; -w &#39;&#39; -l $ph_lg --language-switch remove-flags) #sed &#39;s/$/ 1/&#39; $target_dir/words.txt | PHONEMIZER_ESPEAK_PATH=$(which espeak) phonemize -o $target_dir/phones.txt -p &#39; &#39; -w &#39;&#39; -l $ph_lg -j 70 --language-switch remove-flags cut -f2- -d&#39; &#39; /kaggle/input/wav2vec-u-cv-swedish-audio/dict.train &gt;! $target_dir/phones.txt #echo &quot;one is ${one}&quot; #sed -i &quot;s/${one}$//&quot; $target_dir/phones.txt #paste $target_dir/words.txt $target_dir/phones.txt &gt;! $target_dir/lexicon.lst cp /kaggle/input/wav2vec-u-cv-swedish-audio/dict.train $target_dir/lexicon.lst #python $FAIRSEQ_ROOT/fairseq_cli/preprocess.py --dataset-impl mmap --trainpref $target_dir/phones.txt --only-source --destdir $target_dir/phones --thresholdsrc 1000 --padding-factor 1 --dict-only python $FAIRSEQ_ROOT/fairseq_cli/preprocess.py --dataset-impl mmap --trainpref $target_dir/phones.txt --only-source --destdir $target_dir/phones --thresholdsrc 2 --padding-factor 1 --dict-only python filter_lexicon.py -d $target_dir/phones/dict.txt &lt; $target_dir/lexicon.lst &gt;! $target_dir/lexicon_filtered.lst python phonemize_with_sil.py -s 0.25 --surround --lexicon $target_dir/lexicon_filtered.lst &lt; $target_dir/lm.upper.lid.txt &gt;! $target_dir/phones/lm.phones.filtered.txt cp $target_dir/phones/dict.txt $target_dir/phones/dict.phn.txt echo &quot;&lt;SIL&gt; 0&quot; &gt;&gt; $target_dir/phones/dict.phn.txt python $FAIRSEQ_ROOT/fairseq_cli/preprocess.py --dataset-impl mmap --trainpref $target_dir/phones/lm.phones.filtered.txt --workers 70 --only-source --destdir $target_dir/phones --srcdict $target_dir/phones/dict.phn.txt lmplz -o 4 &lt; $target_dir/lm.upper.lid.txt --discount_fallback --prune 0 0 0 3 &gt;! $target_dir/kenlm.wrd.o40003.arpa build_binary $target_dir/kenlm.wrd.o40003.arpa $target_dir/kenlm.wrd.o40003.bin lg=$lg python $FAIRSEQ_ROOT/examples/speech_recognition/kaldi/kaldi_initializer.py fst_dir=$target_dir/fst/phn_to_words_sil lm_arpa=$target_dir/kenlm.wrd.o40003.arpa wav2letter_lexicon=$target_dir/lexicon_filtered.lst data_dir=$target_dir/phones &quot;blank_symbol=&#39;&lt;SIL&gt;&#39;&quot; &quot;in_labels=&#39;phn&#39;&quot; &quot;kaldi_root=&#39;/opt/kaldi&#39;&quot; lg=$lg python $FAIRSEQ_ROOT/examples/speech_recognition/kaldi/kaldi_initializer.py fst_dir=$target_dir/fst/phn_to_words lm_arpa=$target_dir/kenlm.wrd.o40003.arpa wav2letter_lexicon=$target_dir/lexicon_filtered.lst data_dir=$target_dir/phones &quot;in_labels=&#39;phn&#39;&quot; &quot;kaldi_root=&#39;/opt/kaldi&#39;&quot; lmplz -o 4 &lt; $target_dir/phones/lm.phones.filtered.txt --discount_fallback &gt;! $target_dir/phones/lm.phones.filtered.04.arpa build_binary -s $target_dir/phones/lm.phones.filtered.04.arpa $target_dir/phones/lm.phones.filtered.04.bin lmplz -o 6 &lt; $target_dir/phones/lm.phones.filtered.txt --discount_fallback &gt;! $target_dir/phones/lm.phones.filtered.06.arpa build_binary -s $target_dir/phones/lm.phones.filtered.06.arpa $target_dir/phones/lm.phones.filtered.06.bin lg=$lg python $FAIRSEQ_ROOT/examples/speech_recognition/kaldi/kaldi_initializer.py fst_dir=$target_dir/fst/phn_to_phn_sil lm_arpa=$target_dir/phones/lm.phones.filtered.06.arpa data_dir=$target_dir/phones &quot;blank_symbol=&#39;&lt;SIL&gt;&#39;&quot; &quot;in_labels=&#39;phn&#39;&quot; &quot;kaldi_root=&#39;/opt/kaldi&#39;&quot; . Overwriting prepare_text.sh . add-self-loop-simple.cc attempts to use std::endl with KALDI_LOG, which doesn&#39;t work, so rewrite that (I&#39;m not sure if this actually prevents anything from working, but it is really distracting). . %%writefile /tmp/fairseq/examples/speech_recognition/kaldi/add-self-loop-simple.cc /* * Copyright (c) Facebook, Inc. and its affiliates. * * This source code is licensed under the MIT license found in the * LICENSE file in the root directory of this source tree. */ #include &lt;iostream&gt; #include &quot;fstext/fstext-lib.h&quot; // @manual #include &quot;util/common-utils.h&quot; // @manual /* * This program is to modify a FST without self-loop by: * for each incoming arc with non-eps input symbol, add a self-loop arc * with that non-eps symbol as input and eps as output. * * This is to make sure the resultant FST can do deduplication for repeated * symbols, which is very common in acoustic model * */ namespace { int32 AddSelfLoopsSimple(fst::StdVectorFst* fst) { typedef fst::MutableArcIterator&lt;fst::StdVectorFst&gt; IterType; int32 num_states_before = fst-&gt;NumStates(); fst::MakePrecedingInputSymbolsSame(false, fst); int32 num_states_after = fst-&gt;NumStates(); KALDI_LOG &lt;&lt; &quot;There are &quot; &lt;&lt; num_states_before &lt;&lt; &quot; states in the original FST; &quot; &lt;&lt; &quot; after MakePrecedingInputSymbolsSame, there are &quot; &lt;&lt; num_states_after &lt;&lt; &quot; states &quot;; auto weight_one = fst::StdArc::Weight::One(); int32 num_arc_added = 0; fst::StdArc self_loop_arc; self_loop_arc.weight = weight_one; int32 num_states = fst-&gt;NumStates(); std::vector&lt;std::set&lt;int32&gt;&gt; incoming_non_eps_label_per_state(num_states); for (int32 state = 0; state &lt; num_states; state++) { for (IterType aiter(fst, state); !aiter.Done(); aiter.Next()) { fst::StdArc arc(aiter.Value()); if (arc.ilabel != 0) { incoming_non_eps_label_per_state[arc.nextstate].insert(arc.ilabel); } } } for (int32 state = 0; state &lt; num_states; state++) { if (!incoming_non_eps_label_per_state[state].empty()) { auto&amp; ilabel_set = incoming_non_eps_label_per_state[state]; for (auto it = ilabel_set.begin(); it != ilabel_set.end(); it++) { self_loop_arc.ilabel = *it; self_loop_arc.olabel = 0; self_loop_arc.nextstate = state; fst-&gt;AddArc(state, self_loop_arc); num_arc_added++; } } } return num_arc_added; } void print_usage() { std::cout &lt;&lt; &quot;add-self-loop-simple usage: n&quot; &quot; tadd-self-loop-simple &lt;in-fst&gt; &lt;out-fst&gt; n&quot;; } } // namespace int main(int argc, char** argv) { if (argc != 3) { print_usage(); exit(1); } auto input = argv[1]; auto output = argv[2]; auto fst = fst::ReadFstKaldi(input); auto num_states = fst-&gt;NumStates(); KALDI_LOG &lt;&lt; &quot;Loading FST from &quot; &lt;&lt; input &lt;&lt; &quot; with &quot; &lt;&lt; num_states &lt;&lt; &quot; states.&quot;; int32 num_arc_added = AddSelfLoopsSimple(fst); KALDI_LOG &lt;&lt; &quot;Adding &quot; &lt;&lt; num_arc_added &lt;&lt; &quot; self-loop arcs &quot;; fst::WriteFstKaldi(*fst, std::string(output)); KALDI_LOG &lt;&lt; &quot;Writing FST to &quot; &lt;&lt; output; delete fst; } . Overwriting /tmp/fairseq/examples/speech_recognition/kaldi/add-self-loop-simple.cc . !zsh prepare_text.sh sv /kaggle/working/sentences.txt /kaggle/working/preppedtext . sv sv /kaggle/working/sentences.txt /kaggle/working/preppedtext === 1/5 Counting and sorting n-grams === Reading /kaggle/working/preppedtext/lm.upper.lid.txt -5101520253035404550556065707580859095--100 **************************************************************************************************** Unigram tokens 14359 types 3160 === 2/5 Calculating and sorting adjusted counts === Chain sizes: 1:37920 2:2571431424 3:4821433856 4:7714294272 Statistics: 1 3160 D1=0.722623 D2=1.14413 D3+=1.45956 2 10285 D1=0.848104 D2=1.2466 D3+=1.46191 3 12632 D1=0.943362 D2=1.24166 D3+=1.32723 4 19/11699 D1=0.970399 D2=1.4843 D3+=2.12351 Memory estimate for binary LM: type kB probing 617 assuming -p 1.5 probing 764 assuming -r models -p 1.5 trie 309 without quantization trie 182 assuming -q 8 -b 8 quantization trie 293 assuming -a 22 array pointer compression trie 166 assuming -a 22 -q 8 -b 8 array pointer compression and quantization === 3/5 Calculating and sorting initial probabilities === Chain sizes: 1:37920 2:164560 3:252640 4:456 -5101520253035404550556065707580859095--100 #################################################################################################### === 4/5 Calculating and writing order-interpolated probabilities === Chain sizes: 1:37920 2:164560 3:252640 4:456 -5101520253035404550556065707580859095--100 #################################################################################################### === 5/5 Writing ARPA model === -5101520253035404550556065707580859095--100 **************************************************************************************************** Name:lmplz VmPeak:14925024 kB VmRSS:6488 kB RSSMax:2975268 kB user:0.194576 sys:0.839708 CPU:1.03431 real:1.03864 Reading /kaggle/working/preppedtext/kenlm.wrd.o40003.arpa -5101520253035404550556065707580859095--100 **************************************************************************************************** SUCCESS [2021-05-30 15:50:13,771][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words_sil/kaldi_dict.phn.txt [2021-05-30 15:50:13,771][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words_sil/G_kenlm.wrd.o40003.fst /opt/kaldi/src/lmbin/arpa2fst --disambig-symbol=#0 --write-symbol-table=/kaggle/working/preppedtext/fst/phn_to_words_sil/kaldi_dict.kenlm.wrd.o40003.txt /kaggle/working/preppedtext/kenlm.wrd.o40003.arpa /kaggle/working/preppedtext/fst/phn_to_words_sil/G_kenlm.wrd.o40003.fst LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:94) Reading data section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 1-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 2-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 3-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 4-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:RemoveRedundantStates():arpa-lm-compiler.cc:359) Reduced num-states from 22665 to 12144 [2021-05-30 15:50:13,918][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words_sil/kaldi_lexicon.phn.kenlm.wrd.o40003.txt (in units file: /kaggle/working/preppedtext/fst/phn_to_words_sil/kaldi_dict.phn.txt) [2021-05-30 15:50:14,005][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words_sil/H.phn.fst [2021-05-30 15:50:14,045][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words_sil/L.phn.kenlm.wrd.o40003.fst (in units: /kaggle/working/preppedtext/fst/phn_to_words_sil/kaldi_dict.phn_disambig.txt) [2021-05-30 15:50:14,244][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words_sil/LG.phn.kenlm.wrd.o40003.fst [2021-05-30 15:50:15,269][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words_sil/HLGa.phn.kenlm.wrd.o40003.fst [2021-05-30 15:50:17,600][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words_sil/HLG.phn.kenlm.wrd.o40003.fst [2021-05-30 15:50:26,782][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words/kaldi_dict.phn.txt [2021-05-30 15:50:26,783][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words/G_kenlm.wrd.o40003.fst /opt/kaldi/src/lmbin/arpa2fst --disambig-symbol=#0 --write-symbol-table=/kaggle/working/preppedtext/fst/phn_to_words/kaldi_dict.kenlm.wrd.o40003.txt /kaggle/working/preppedtext/kenlm.wrd.o40003.arpa /kaggle/working/preppedtext/fst/phn_to_words/G_kenlm.wrd.o40003.fst LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:94) Reading data section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 1-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 2-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 3-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 4-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:RemoveRedundantStates():arpa-lm-compiler.cc:359) Reduced num-states from 22665 to 12144 [2021-05-30 15:50:26,992][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words/kaldi_lexicon.phn.kenlm.wrd.o40003.txt (in units file: /kaggle/working/preppedtext/fst/phn_to_words/kaldi_dict.phn.txt) [2021-05-30 15:50:27,047][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words/H.phn.fst [2021-05-30 15:50:27,088][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words/L.phn.kenlm.wrd.o40003.fst (in units: /kaggle/working/preppedtext/fst/phn_to_words/kaldi_dict.phn_disambig.txt) [2021-05-30 15:50:27,281][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words/LG.phn.kenlm.wrd.o40003.fst [2021-05-30 15:50:28,293][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words/HLGa.phn.kenlm.wrd.o40003.fst [2021-05-30 15:50:31,245][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words/HLG.phn.kenlm.wrd.o40003.fst === 1/5 Counting and sorting n-grams === Reading /kaggle/working/preppedtext/phones/lm.phones.filtered.txt -5101520253035404550556065707580859095--100 **************************************************************************************************** Unigram tokens 63676 types 44 === 2/5 Calculating and sorting adjusted counts === Chain sizes: 1:528 2:2571437824 3:4821446144 4:7714313728 Substituting fallback discounts for order 0: D1=0.5 D2=1 D3+=1.5 Statistics: 1 44 D1=0.5 D2=1 D3+=1.5 2 1053 D1=0.421189 D2=1.06361 D3+=1.49793 3 8534 D1=0.558099 D2=1.17765 D3+=1.45173 4 23058 D1=0.643934 D2=1.15876 D3+=1.53884 Memory estimate for binary LM: type kB probing 631 assuming -p 1.5 probing 687 assuming -r models -p 1.5 trie 203 without quantization trie 88 assuming -q 8 -b 8 quantization trie 196 assuming -a 22 array pointer compression trie 81 assuming -a 22 -q 8 -b 8 array pointer compression and quantization === 3/5 Calculating and sorting initial probabilities === Chain sizes: 1:528 2:16848 3:170680 4:553392 -5101520253035404550556065707580859095--100 #################################################################################################### === 4/5 Calculating and writing order-interpolated probabilities === Chain sizes: 1:528 2:16848 3:170680 4:553392 -5101520253035404550556065707580859095--100 #################################################################################################### === 5/5 Writing ARPA model === -5101520253035404550556065707580859095--100 **************************************************************************************************** Name:lmplz VmPeak:14916784 kB VmRSS:7056 kB RSSMax:2973864 kB user:0.209899 sys:0.716931 CPU:0.926881 real:0.936705 Reading /kaggle/working/preppedtext/phones/lm.phones.filtered.04.arpa -5101520253035404550556065707580859095--100 **************************************************************************************************** SUCCESS === 1/5 Counting and sorting n-grams === Reading /kaggle/working/preppedtext/phones/lm.phones.filtered.txt -5101520253035404550556065707580859095--100 **************************************************************************************************** Unigram tokens 63676 types 44 === 2/5 Calculating and sorting adjusted counts === Chain sizes: 1:528 2:929673728 3:1743138176 4:2789021184 5:4067322624 6:5578042368 Substituting fallback discounts for order 0: D1=0.5 D2=1 D3+=1.5 Statistics: 1 44 D1=0.5 D2=1 D3+=1.5 2 1053 D1=0.421189 D2=1.06361 D3+=1.49793 3 8534 D1=0.558099 D2=1.17765 D3+=1.45173 4 23058 D1=0.704256 D2=1.25425 D3+=1.63465 5 35879 D1=0.821218 D2=1.34714 D3+=1.61281 6 43593 D1=0.834579 D2=1.24241 D3+=1.56972 Memory estimate for binary LM: type kB probing 2373 assuming -p 1.5 probing 2775 assuming -r models -p 1.5 trie 907 without quantization trie 401 assuming -q 8 -b 8 quantization trie 838 assuming -a 22 array pointer compression trie 331 assuming -a 22 -q 8 -b 8 array pointer compression and quantization === 3/5 Calculating and sorting initial probabilities === Chain sizes: 1:528 2:16848 3:170680 4:553392 5:1004612 6:1394976 -5101520253035404550556065707580859095--100 #################################################################################################### === 4/5 Calculating and writing order-interpolated probabilities === Chain sizes: 1:528 2:16848 3:170680 4:553392 5:1004612 6:1394976 -5101520253035404550556065707580859095--100 #################################################################################################### === 5/5 Writing ARPA model === -5101520253035404550556065707580859095--100 **************************************************************************************************** Name:lmplz VmPeak:14949572 kB VmRSS:6500 kB RSSMax:2354520 kB user:0.256512 sys:0.588288 CPU:0.84484 real:0.81585 Reading /kaggle/working/preppedtext/phones/lm.phones.filtered.06.arpa -5101520253035404550556065707580859095--100 **************************************************************************************************** SUCCESS [2021-05-30 15:50:35,812][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_phn_sil/kaldi_dict.phn.txt [2021-05-30 15:50:35,812][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_phn_sil/G_lm.phones.filtered.06.fst /opt/kaldi/src/lmbin/arpa2fst --disambig-symbol=#0 --write-symbol-table=/kaggle/working/preppedtext/fst/phn_to_phn_sil/kaldi_dict.lm.phones.filtered.06.txt /kaggle/working/preppedtext/phones/lm.phones.filtered.06.arpa /kaggle/working/preppedtext/fst/phn_to_phn_sil/G_lm.phones.filtered.06.fst LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:94) Reading data section. LOG (arpa2fst[5.5.0~1-2b62]:HeaderAvailable():arpa-lm-compiler.cc:300) Reverting to slower state tracking because model is large: 6-gram with symbols up to 47 LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 1-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 2-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 3-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 4-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 5-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 6-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:RemoveRedundantStates():arpa-lm-compiler.cc:359) Reduced num-states from 67529 to 67528 [2021-05-30 15:50:36,696][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_phn_sil/kaldi_lexicon.phn.lm.phones.filtered.06.txt (in units file: /kaggle/working/preppedtext/fst/phn_to_phn_sil/kaldi_dict.phn.txt) [2021-05-30 15:50:36,713][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_phn_sil/H.phn.fst [2021-05-30 15:50:36,754][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_phn_sil/L.phn.lm.phones.filtered.06.fst (in units: /kaggle/working/preppedtext/fst/phn_to_phn_sil/kaldi_dict.phn_disambig.txt) [2021-05-30 15:50:36,802][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_phn_sil/LG.phn.lm.phones.filtered.06.fst [2021-05-30 15:50:37,700][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_phn_sil/HLGa.phn.lm.phones.filtered.06.fst [2021-05-30 15:50:40,759][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_phn_sil/HLG.phn.lm.phones.filtered.06.fst .",
            "url": "https://jimregan.github.io/notes/kaggle/wav2vec-u/2021/05/26/wav2vec-u-cv-swedish-text-prep.html",
            "relUrl": "/kaggle/wav2vec-u/2021/05/26/wav2vec-u-cv-swedish-text-prep.html",
            "date": " ‚Ä¢ May 26, 2021"
        }
        
    
  
    
        ,"post6": {
            "title": "wav2vec-u Common Voice Swedish - prepare ltr/phn/wrd",
            "content": "Original here . In the section Preparation of speech and text data of the readme, it says: . Similar to wav2vec 2.0, data folders contain {train,valid,test}.{tsv,wrd,phn} files, where audio paths are stored in tsv files, and word, letter or phoneme transcriptions are stored in .{wrd,ltr,phn}. The .wrd and .ltr files are outputs of libri_labels.py . %%capture !pip install phonemizer . %%capture !apt-get -y install espeak . %%capture !apt-get -y install zsh . This is just my best guess at what the .wrd files contain - it seems to match up with what libri_labels.py does: given input like . 1272-128104-0000 MISTER QUILTER IS THE APOSTLE OF THE MIDDLE CLASSES AND WE ARE GLAD TO WELCOME HIS GOSPEL . it does &quot; &quot;.join(items[1:]), which is basically the same . !cat /kaggle/input/download-common-voice-swedish/cv-corpus-6.1-2020-12-11/sv-SE/test.tsv | awk -F&#39; t&#39; &#39;{print $3}&#39;|grep -v &#39;^sentence$&#39; | perl -C7 -ane &#39;chomp;$_=lc($_);s/[^ p{L} p{N} p{M}&#39;&quot; &#39;&quot;&#39; -]/ /g;s/ +/ /g;s/ $//;s/^ //;print &quot;$_ n&quot;;&#39; &gt; test.wrd !cat /kaggle/input/download-common-voice-swedish/cv-corpus-6.1-2020-12-11/sv-SE/dev.tsv | awk -F&#39; t&#39; &#39;{print $3}&#39;|grep -v &#39;^sentence$&#39; | perl -C7 -ane &#39;chomp;$_=lc($_);s/[^ p{L} p{N} p{M}&#39;&quot; &#39;&quot;&#39; -]/ /g;s/ +/ /g;s/ $//;s/^ //;print &quot;$_ n&quot;;&#39; &gt; valid.wrd !cat /kaggle/input/download-common-voice-swedish/cv-corpus-6.1-2020-12-11/sv-SE/train.tsv | awk -F&#39; t&#39; &#39;{print $3}&#39;|grep -v &#39;^sentence$&#39; | perl -C7 -ane &#39;chomp;$_=lc($_);s/[^ p{L} p{N} p{M}&#39;&quot; &#39;&quot;&#39; -]/ /g;s/ +/ /g;s/ $//;s/^ //;print &quot;$_ n&quot;;&#39; &gt; train.wrd . for i in [&#39;train&#39;, &#39;test&#39;, &#39;valid&#39;]: with open(f&#39;/kaggle/working/{i}.wrd&#39;, &#39;r&#39;) as inf, open(f&#39;/kaggle/working/{i}.ltr&#39;, &#39;w&#39;) as out: for line in inf.readlines(): print(&quot; &quot;.join(list(line.strip().replace(&quot; &quot;, &quot;|&quot;))) + &quot; |&quot;, file=out) . !head train.ltr . v a d | √§ r | d e t | i | e u r o | d u | s k a | v e t a | a t t | d e t | √§ r | d u | s o m | h a r | f e l | g √• | n e r | p √• | k n √§ | f √∂ r s t | m √• s t e | j a g | s l √• | s √∂ n d e r | d e n | d √§ r | s t o r a | s k r o t h √∂ g e n | d e t | b l i r | s v √• r t | v a d | f √∂ r | j √§ v l a | f r √• g a | √§ r | d e t | j a g | √• t e r v √§ n d e r | i n t e | t i l l | s k i t h √• l e t | t i t t a | p √• | s √∂ m m a r n a | f e s | d u | p r e c i s | a k t r i s e r | h a r | e t t | b √§ s t | f √∂ r e d a t u m | . There are some warnings about switching, so echo the filename first to known where the errors are . !for i in train test valid; do echo $i.wrd; cat $i.wrd | PHONEMIZER_ESPEAK_PATH=$(which espeak) phonemize -o $i.phn -p &#39; &#39; -w &#39;&#39; -l sv -j 70 --language-switch remove-flags ;done . train.wrd [WARNING] 2 utterances containing language switches on lines 254, 1457 [WARNING] extra phones may appear in the &#34;sv&#34; phoneset [WARNING] language switch flags have been removed (applying &#34;remove-flags&#34; policy) test.wrd [WARNING] 1 utterances containing language switches on lines 81 [WARNING] extra phones may appear in the &#34;sv&#34; phoneset [WARNING] language switch flags have been removed (applying &#34;remove-flags&#34; policy) valid.wrd [WARNING] 1 utterances containing language switches on lines 1831 [WARNING] extra phones may appear in the &#34;sv&#34; phoneset [WARNING] language switch flags have been removed (applying &#34;remove-flags&#34; policy) . !cat test.wrd|awk &#39;BEGIN{ln=1}{if(ln==81){print $0};ln++}&#39; !cat train.wrd|awk &#39;BEGIN{ln=1}{if(ln==254||ln==1457){print $0};ln++}&#39; !cat valid.wrd|awk &#39;BEGIN{ln=1}{if(ln==1831){print $0};ln++}&#39; . det √§r taskigt och s√• unik design internet slutade fungera det finns inget internet . !cat test.phn|awk &#39;BEGIN{ln=1}{if(ln==81){print $0};ln++}&#39; !cat train.phn|awk &#39;BEGIN{ln=1}{if(ln==254||ln==1457){print $0};ln++}&#39; !cat valid.phn|awk &#39;BEGIN{ln=1}{if(ln==1831){print $0};ln++}&#39; . d eÀê t …õÀê r t a s k …™ …° t …î k s oÀê …µ n iÀê k d …™ z a…™ n …™ n t …ô n …õ t s l  â t a d …ô f …µ n …° eÀê r a d eÀê t f …™ n s …™ ≈ã …ô t …™ n t …ô n …õ t . &quot;design&quot; and &quot;internet&quot; are clearly the English words that are causing the switch in their respective sentences, but I&#39;m not sure what the problem in test.wrd is: &quot;taskigt&quot;? . design /d…õÀàsajn/ | internet /Àà…™nt…õrn…õt/, /…™nt…õrÀàn…õt/ | . !echo taskigt|espeak -v sv --ipa 2&gt; /dev/null . (en)tÀàask…™…°t(sv) . !cat test.phn|sed -e &#39;s/^ //;s/t a s k …™ …° t/t a s k …™ t/&#39; &gt; tmp !mv tmp test.phn !cat train.phn|sed -e &#39;s/^ //;s/d …™ z a…™ n/d …õ s a j n/;s/…™ n t …ô n …õ t/…™ n t …õ r n …õ t/&#39; &gt; tmp !mv tmp train.phn !cat valid.phn|sed -e &#39;s/^ //;s/…™ n t …ô n …õ t/…™ n t …õ r n …õ t/&#39; &gt; tmp !mv tmp valid.phn . !for i in train test valid; do cat $i.wrd|tr &#39; &#39; &#39; n&#39;|sort|uniq |grep -v &#39;^internet$&#39;|grep -v &#39;^design$&#39;|grep -v &#39;^taskigt$&#39; &gt; /tmp/$i.wl; cat /tmp/$i.wl | PHONEMIZER_ESPEAK_PATH=$(which espeak) phonemize -o /tmp/$i.wl.phn -p &#39; &#39; -w &#39;&#39; -l sv -j 70 --language-switch remove-flags;paste /tmp/$i.wl /tmp/$i.wl.phn &gt; dict.$i; done !printf &quot;taskigt tt a s k …™ t n&quot; &gt;&gt; dict.test !printf &quot;design td …õ s a j n n&quot; &gt;&gt; dict.train !printf &quot;internet t…™ n t …õ r n …õ t n&quot; &gt;&gt; dict.train !printf &quot;internet t…™ n t …õ r n …õ t n&quot; &gt;&gt; dict.valid . !for i in dic*;do cat $i |sort &gt; tmp;mv tmp $i;done . cat: valid: No such file or directory .",
            "url": "https://jimregan.github.io/notes/kaggle/wav2vec-u/2021/05/26/wav2vec-u-cv-swedish-prep-ltr-phn-wrd.html",
            "relUrl": "/kaggle/wav2vec-u/2021/05/26/wav2vec-u-cv-swedish-prep-ltr-phn-wrd.html",
            "date": " ‚Ä¢ May 26, 2021"
        }
        
    
  
    
        ,"post7": {
            "title": "wav2vec-u Common Voice Swedish - vad",
            "content": "Original here . %cd /tmp . /tmp . !git clone https://github.com/pytorch/fairseq/ . %cd fairseq/examples/wav2vec/unsupervised . /tmp/fairseq/examples/wav2vec/unsupervised . !git clone https://github.com/zhenghuatan/rVADfast . !cat scripts/vads.py|sed -e &#39;s!/path/to/rVADfast_py_2.0!/tmp/fairseq/examples/wav2vec/unsupervised/rVADfast!&#39; &gt; tmp !mv tmp scripts/vads.py . !for i in train valid test;do cat /kaggle/input/fork-of-wav2vec-u-cv-swedish-tsv/$i.tsv|python scripts/vads.py &gt; /kaggle/working/$i.vads;done . 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2331/2331 [1:01:46&lt;00:00, 1.59s/it] 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2019/2019 [53:39&lt;00:00, 1.59s/it] 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2027/2027 [57:26&lt;00:00, 1.70s/it] . !mkdir /kaggle/working/wav !mkdir /kaggle/working/wav/train !mkdir /kaggle/working/wav/test !mkdir /kaggle/working/wav/valid . !for i in train test valid; do python scripts/remove_silence.py --tsv /kaggle/input/fork-of-wav2vec-u-cv-swedish-tsv/$i.tsv --vads /kaggle/working/$i.vads --out /kaggle/working/wav/$i;done .",
            "url": "https://jimregan.github.io/notes/kaggle/wav2vec-u/2021/05/25/wav2vec-u-cv-swedish-vads.html",
            "relUrl": "/kaggle/wav2vec-u/2021/05/25/wav2vec-u-cv-swedish-vads.html",
            "date": " ‚Ä¢ May 25, 2021"
        }
        
    
  
    
        ,"post8": {
            "title": "wav2vec-u Common Voice Swedish - prepare tsv",
            "content": "Original here . import soundfile input = { &#39;train&#39;: &#39;/kaggle/input/download-common-voice-swedish/cv-corpus-6.1-2020-12-11/sv-SE/train.tsv&#39;, &#39;test&#39;: &#39;/kaggle/input/download-common-voice-swedish/cv-corpus-6.1-2020-12-11/sv-SE/test.tsv&#39;, &#39;valid&#39;: &#39;/kaggle/input/download-common-voice-swedish/cv-corpus-6.1-2020-12-11/sv-SE/dev.tsv&#39; } for split in input.keys(): with open(input[split], &#39;r&#39;) as tsv: with open(f&#39;/kaggle/working/{split}.tsv&#39;, &#39;w&#39;) as out: print(&#39;/kaggle/input/common-voice-swedish-16bit-wav/&#39;, file=out) for line in tsv.readlines(): data = line.split(&#39; t&#39;) if data[1] == &#39;path&#39;: continue file = data[1] file = file.replace(&#39;.mp3&#39;, &#39;.wav&#39;) path = f&#39;/kaggle/input/common-voice-swedish-16bit-wav/{file}&#39; frames = soundfile.info(path).frames print(&quot;{} t{}&quot;.format(file, frames), file=out) .",
            "url": "https://jimregan.github.io/notes/kaggle/wav2vec-u/2021/05/25/wav2vec-u-cv-swedish-tsv.html",
            "relUrl": "/kaggle/wav2vec-u/2021/05/25/wav2vec-u-cv-swedish-tsv.html",
            "date": " ‚Ä¢ May 25, 2021"
        }
        
    
  
    
        ,"post9": {
            "title": "Download Common Voice Swedish",
            "content": "Original notebook here . This link won&#39;t work any more, so you&#39;ll need a fresh link from Common Voice Datasets . !wget &#39;https://mozilla-common-voice-datasets.s3.dualstack.us-west-2.amazonaws.com/cv-corpus-6.1-2020-12-11/sv-SE.tar.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=ASIAQ3GQRTO3KA6TWRBY%2F20210525%2Fus-west-2%2Fs3%2Faws4_request&amp;X-Amz-Date=20210525T103604Z&amp;X-Amz-Expires=43200&amp;X-Amz-Security-Token=FwoGZXIvYXdzEHwaDAOxZbXj8dSCv%2B%2B1%2FyKSBFuQ4WGxxfHEd51rf4QvMe6fipqbY4nXKUe7Hi%2FCoUFR%2BgXEgXjMjzgKih3fiiBllsdJ1w%2BO4dQ6mKmIYdYWwfXWezdctGJ13gGNYRX2RO8EpTEHOcG48Jvc8pF97Wrv4vZ3Kmlo0jf3Y6rKLZ3HHiKbkQBQgCT40vylI0wPZg5pFXZm6o%2B8zXun1NncwAzRtbmsDSuYT0tJ4zLXpzTZhJ0Ln%2F5gZVxPnZv5WleN0sFcYBMsqTnt9hNyaCQFbnQuCv1BfE6m6KBCG8cSc23YN%2FALgcd4EzxvPaIRM%2F0vFjPTHQFuipe3du7u6TW5gJemh0xaJnLczIx7FbmkrWuZ6HXQH77U7S4YQEX3BSLrBhkcIS7QeTv9oZ5D7yfCbRAXc2V2qzVANcAoipgYxP2By0iA0C90t3ggu5YvTwSAnrHxtSDMalsXU6%2BVcEo87VDb2DkOZ9OtpApZdpstX7QXHmC5QdR7Gg7M4aiW9jbZMyAH%2FQAowc2pZHqh%2BrJqySYOLYMWEApqDZ94VaCkuguuXODS25l%2F07IqAaCzT5LO%2FjPyuFBs7nXlDZXZo64295Iu6VDprtvutUvHbxQy6qkiMYT%2Fkt297E%2FsorK9YjNhj17PjtGPx6EW4WZIHLikvpkQ3aEiVN5%2ByLu9sbj8lwdzWnf9mSGp3T5oedv27ARY1SvmWn9uQH1FB6Tet%2ByaM5u1KIBKKJGbs4UGMipKgz7uHdY53WDR2h1mkBlucbyh484Wj%2BldCrqic%2FgIKjqhay57WHKZe2w%3D&amp;X-Amz-Signature=549006bf559d20bba1fbc6523f7b7b02ef8b2b7a68f229b1875bd02336e3c3b6&amp;X-Amz-SignedHeaders=host&#39; -O sv-SE.tar.gz . !tar zxvf sv-SE.tar.gz !rm sv-SE.tar.gz .",
            "url": "https://jimregan.github.io/notes/kaggle/wav2vec-u/2021/05/25/download-common-voice-swedish.html",
            "relUrl": "/kaggle/wav2vec-u/2021/05/25/download-common-voice-swedish.html",
            "date": " ‚Ä¢ May 25, 2021"
        }
        
    
  
    
        ,"post10": {
            "title": "Convert Common Voice Swedish to 16bit wav",
            "content": "Original here . !for i in ../input/download-common-voice-swedish/cv-corpus-6.1-2020-12-11/sv-SE/clips/*.mp3;do o=$(basename $i &#39;.mp3&#39;); ffmpeg -i &quot;$i&quot; -acodec pcm_s16le -ac 1 -ar 16000 $o.wav;done .",
            "url": "https://jimregan.github.io/notes/kaggle/wav2vec-u/2021/05/25/common-voice-swedish-16bit-wav.html",
            "relUrl": "/kaggle/wav2vec-u/2021/05/25/common-voice-swedish-16bit-wav.html",
            "date": " ‚Ä¢ May 25, 2021"
        }
        
    
  
    
        ,"post11": {
            "title": "Running rbg2p on Colab",
            "content": "!pip install -q condacolab import condacolab condacolab.install() . ‚è¨ Downloading https://github.com/jaimergp/miniforge/releases/latest/download/Mambaforge-colab-Linux-x86_64.sh... üì¶ Installing... üìå Adjusting configuration... ü©π Patching environment... ‚è≤ Done in 0:00:30 üîÅ Restarting kernel... . %%capture !conda install -c conda-forge go go-cgo -y . %%capture !pip install --upgrade setuptools wheel . !go get github.com/sergi/go-diff !go get github.com/stts-se/rbg2p . go: downloading github.com/sergi/go-diff v1.2.0 . !git clone https://github.com/stts-se/rbg2p . Cloning into &#39;rbg2p&#39;... remote: Enumerating objects: 3918, done. remote: Counting objects: 100% (123/123), done. remote: Compressing objects: 100% (85/85), done. remote: Total 3918 (delta 59), reused 77 (delta 29), pack-reused 3795 Receiving objects: 100% (3918/3918), 678.17 KiB | 2.32 MiB/s, done. Resolving deltas: 100% (1233/1233), done. . import os os.environ[&quot;PATH&quot;]=f&#39;{os.environ[&quot;PATH&quot;]}:/root/go/bin&#39; . %cd rbg2p . /content/rbg2p . %%writefile maori.g2p CHARACTER_SET &quot;aeghikmnoprtuwƒÅƒìƒ´≈ç≈´&quot; DEFAULT_PHONEME &quot;_&quot; PHONEME_DELIMITER &quot; &quot; wh -&gt; f h -&gt; h k -&gt; k m -&gt; m ng -&gt; ≈ã n -&gt; n p -&gt; p r -&gt; …æ t -&gt; t w -&gt; w au -&gt; au ƒÅ -&gt; aÀê a -&gt; a ƒì -&gt; …õÀê e -&gt; …õ ƒ´ -&gt; iÀê i -&gt; i ≈ç -&gt; …îÀê o -&gt; …î ≈´ -&gt;  âÀê u -&gt;  â g -&gt; ‚àÖ . Writing maori.g2p . !echo kaumƒÅtua | go run cmd/g2p/g2p.go ../maori.g2p . 0 ERROR(S) FOR ../maori.g2p 0 WARNING(S) FOR ../maori.g2p ALL 0 TESTS PASSED FOR ../maori.g2p Reading input from stdin... kaumƒÅtua k au m aÀê t  â a TOTAL INPUT : 1 ERRORS : 0 TRANSCRIBED : 1 .",
            "url": "https://jimregan.github.io/notes/rbg2p/colab/2021/05/20/running-rbg2p.html",
            "relUrl": "/rbg2p/colab/2021/05/20/running-rbg2p.html",
            "date": " ‚Ä¢ May 20, 2021"
        }
        
    
  
    
        ,"post12": {
            "title": "Kilkenny vs. Waterford",
            "content": "Comparing Kilkenny Irish with Waterford Irish. . The Kilkenny Irish comes from these tweets: (Google Books says √âigse, vol. 26, p. 35) . C√∫pla sampla sp√©isi√∫il breise: pic.twitter.com/tYckKMrPM7 . &mdash; Cormac de Briot√∫n (@erisceres) May 17, 2021 I‚Äôve marked the clear differences in bold face; differences in transcription (s‚Ä≤/ É, …ëÀê/aÀê) are not marked, nor are expected differences (‚ü®ao‚ü© ‚Üí [ai] in Waterford Irish; /r‚Ä≤/ ‚Üí [ í] in Kilkenny Irish). . The Waterford side of the comparison is from Breatnach 1; references as in the index. I chose the first (that matched), except with some common words, where I used the first place I came across them. . ansoin and ansan are clearly different, but Breatnach (t. 20) gives √≥ shoin (/oÀê xin‚Ä≤/). . raibh /re/ is a bit of a stretch; Breatnach says this is only before pronouns, and considers it a back-formation from the unstressed form /r…ô/ (/rev‚Ä≤/ stressed). . /duÀêr‚Ä≤t‚Ä≤/ for d√∫irt in Waterford is a little unexpected: the usual rule is r‚Ä≤ ‚Üí [r] / _ [+dental]. . K. Word K. Phonetic W. Phonetic Breatnach W. Word . a | …ô | …ô | t. 349 | ¬† | . acu | …ôku | …ôÀàku | 163 | aca | . ag | eg‚Ä≤ | eg‚Ä≤ | p. 146 n. 4 | ¬† | . ag | …ô | …ô | 317 | ¬† | . ag | g‚Ä≤ | g‚Ä≤ | 42 | ¬† | . agus | …ëg…ôs | ag…ô(s) | 303 | ¬† | . √°it | …ëÀêt‚Ä≤ | aÀêt‚Ä≤ | 53 | ¬† | . an | …ôn | …ôn | 250 | ¬† | . an | …ô | …ô | t. 339 | ¬† | . an | (…ô)n | n | 496 | ¬† | . ag an | g‚Ä≤en | g‚Ä≤en | t. 78 | aige ‚Äôn | . anall | …ôn…ôul | (…ô)Àànaul | 111 | ¬† | . anchuid | an…ôÀàxid‚Ä≤ | an…ô + xid‚Ä≤ | 171 + t. 253 | ana- + chuid | . ann | uÀên | aun | 110 | ¬† | . anonn | …ônuÀên | (…ô)Àànaun | 111 | ¬† | . ansoin | …ônsin‚Ä≤ | …ônson | 320 | annsan | . ar | e í | er‚Ä≤ | 42 | ¬† | . bean | b‚Ä≤an | b‚Ä≤an | 44 | ¬† | . bhean | v‚Ä≤an | v‚Ä≤an | 483 | ¬† | . bhfuil | bil‚Ä≤ | bil‚Ä≤ | 399 | ¬† | . bh√≠ | v‚Ä≤iÀê | v‚Ä≤iÀê | 21 | ¬† | . broim | br…ôim‚Ä≤ | br…ôim‚Ä≤ | 545 | ¬† | . cad√© | d‚Ä≤eÀê | d‚Ä≤eÀê | 302 | d√© | . chuir | xi í | xir‚Ä≤ | 28 | ¬† | . chun | xuÀên | xuÀên | 308 | ch√∫n | . c√© | k‚Ä≤eÀê | k‚Ä≤eÀê | t. 56 | cia | . conas | kun…ôs | kun…ôs | 66 | cionnus | . cuir | kir | kir‚Ä≤ | 260 | ¬† | . d√©in | t‚Ä≤eÀên‚Ä≤ | d‚Ä≤eÀên‚Ä≤ | 34 | ¬† | . deir | d‚Ä≤er | d‚Ä≤er‚Ä≤ | 303 | ¬† | . duine | din‚Ä≤…ô | din‚Ä≤…ô | 77 | ¬† | . d√∫irt | duÀêrt‚Ä≤ | duÀêr‚Ä≤t‚Ä≤ | 72 | adubhairt | . √©inne | eÀê≈ã‚Ä≤…ô | ai≈ã‚Ä≤…ô | 106 | aonduine | . fad√≥ | f…ôdoÀê | f…ôÀàdoÀê | 62 | fad‚Äô √≥ | . fear | f‚Ä≤ar | f‚Ä≤ar | 44 | ¬† | . feicim | hek‚Ä≤…ôm‚Ä≤ | f‚Ä≤ek‚Ä≤…ôm‚Ä≤ | 553 | faicim | . fhios | (…ô)s | …ô ≈ãan…ôs | 231 | i ngan-fhios | . lig | l‚Ä≤ig‚Ä≤ | l‚Ä≤ig‚Ä≤ | 426 | l√©ig | . l√°mh | l…ëÀê | laÀê l‚Ä≤…ô, laÀêv‚Ä≤ | p. 134 n. 2 | l√°imh l√©, l√°imh | . leis | l‚Ä≤es‚Ä≤ | l‚Ä≤e É | 39 | ¬† | . mn√° | mn…ëÀê | m…ôÀànaÀê | 227 | ¬† | . n√≠ | n‚Ä≤iÀê | n‚Ä≤iÀê | p. 67 n. 2 | ¬† | . orthu | orh…ô | orh…ô | 57 | ortha | . raibh | re | re | p. 119 n. 6 | ¬† | . r√©idh | reÀê | reÀêg‚Ä≤ | 36 | ¬† | . siar | s‚Ä≤i…ôr |  Éi…ôr | 180 | ¬† | . su√≠ | siÀê | siÀê | 24 | suidhe | . s√© | s‚Ä≤e |  Ée | t. 305 | ¬† | . scian | s‚Ä≤g‚Ä≤i…ôn |  Ég‚Ä≤i…ôn | 87 | ¬† | . t-ainm | tan‚Ä≤…ôm‚Ä≤ | an‚Ä≤…ôm‚Ä≤ | 44 | ainm | . thine | hin‚Ä≤…ô | t‚Ä≤in‚Ä≤…ô | 26 + 210 | teine | . th√° | h…ëÀê | haÀê | t. 323 | at√° | . tr√≠ | t‚Ä≤ íiÀê | t‚Ä≤siÀê | 219 | ¬† | . t√∫ | tu | tuÀê, t…ô | 134, 80 | ¬† | . Breatnach, R. B., (1947). The Irish of Ring, Co. Waterford: A Phonetic Study. Dublin Institute for Advanced Studies.¬†&#8617; . |",
            "url": "https://jimregan.github.io/notes/irish/kilkenny/waterford/2021/05/19/kilkenny-vs-waterford.html",
            "relUrl": "/irish/kilkenny/waterford/2021/05/19/kilkenny-vs-waterford.html",
            "date": " ‚Ä¢ May 19, 2021"
        }
        
    
  
    
        ,"post13": {
            "title": "Converting √ì Raghallaigh (2010)",
            "content": "This notebook contains a re-implementation of the &quot;global&quot; phonetiser from Brian √ì Raghallaigh&#39;s Ph.D. thesis using rbg2p, along with the &quot;local&quot; phonetiser for Kerry. . The global phonetiser here is essentially the same as the earlier one, except the output phonemes are lowercase, and there are no spaces between output phonemes, to work around some slight limitations of rbg2p. . Brian √ì Raghallaigh (2010). Multi-dialect phonetisation for Irish text-to-speech synthesis: a modular approach. (Doctoral thesis, Trinity College, Dublin), Appendix B.1 . %%writefile oraghallaigh.g2p CHARACTER_SET &quot;a√°bcde√©fghi√≠jklmno√≥pqrstu√∫vwxyz&#39;-‚Äô&quot; DEFAULT_PHONEME &quot;_&quot; PHONEME_DELIMITER &quot;&quot; VAR CONS [bcdfghjklmnpqrstvwxyz] VAR CONSS [bcdfghjklmnpqrstvwxyz]* VAR CONSP [bcdfghjklmnpqrstvwxyz]+ VAR NONSYLLABIC [√°bcdfghjklmn√≥pqrst√∫vwxyz] // broad future/conditional endings VAR BFCE (√°|adh|aidh|aid√≠s|aimid|aimis|ainn|as) // slender future/conditional endings VAR SFCE (e√°|eadh|idh|id√≠s|imid|imis|inn) VAR FMP [fmp] VAR LNRP [lnr]+ VAR DNLST [dnlst] VAR RDNLR (rd|rn|rl|rr) VAR VOWEL [a√°e√©i√≠o√≥u√∫] VAR VOWELS [a√°e√©i√≠o√≥u√∫]* VAR VOWELP [a√°e√©i√≠o√≥u√∫]+ // left context short broad vowel VAR LCSBV (ea|io|iu|a|o|u) // left context short slender vowel VAR LCSSV (ai|eai|ei|e|iui|i|oi|ui) // left context broad vowel VAR LCBV (adh|ae|ao|a√°|ea|e√°|eo|√©a|io|iu|i√∫|√≠o|o√≥|u√≠o|ua|u|√∫) // left context slender vowel VAR LCSV (aei|aidh|ai|a√≠|aoi|√°i|eai|e√°i|ei|eoi|e|√©i|√©|iai|iui|i√∫i|i|√≠|oi|√≥i|uai|ui|u√≠|√∫i) VAR LCSVS (aei|aidh|ai|a√≠|aoi|√°i|eai|e√°i|ei|eoi|e|√©i|√©|iai|iui|i√∫i|i|√≠|oi|√≥i|uai|ui|u√≠|√∫i)* // right context slender vowel VAR RCSV (eai|ea|e√°i|e√°|ei|eoi|eo|e|√©a|√©i|√©|iai|ia|io|iui|iu|i√∫i|i√∫|i|√≠o|√≠) // left context long vowel VAR LCLV (aei|ae|aoi|ao|√°i|√°|e√°i|e√°|eoi|e√≥|eo|√©i|√©|i√∫i|i√∫|√≠o|√≠|√≥i|√≥|u√≠o|u√≠|√∫i|√∫) // left context slender long vowel VAR LCSLV (aei|aidh|aoi|√°i|e√°i|eoi|√©i|√©|i√∫i|√≠|√≥i|uai|u√≠|√∫i) √°dh -&gt; aa √°i -&gt; aa √° -&gt; aa abh -&gt; abh adh -&gt; adh / _ # adh -&gt; ai agh -&gt; ai aei -&gt; ee ae -&gt; ee a√≠odh -&gt; √≠odh / _ # a√≠o -&gt; a√≠o a√≠ -&gt; ii aidh -&gt; idh / _ # aidh -&gt; ai aigh -&gt; igh / _ # aigh -&gt; ai aithe -&gt; ithe / _ # ai -&gt; ‚àÖ / # CONSS VOWELS (abh|adh|agh|amh|√≥dh|ogh|omh|umh) _ CONSP ai -&gt; ‚àÖ / # CONSS (obh|odh) _ CONSP ai -&gt; aa / # CONSS _ RDNLR ai -&gt; a / # CONSS _ ai -&gt; @@ / VOWELP CONSP _ ai -&gt; a amh -&gt; amh / _ # amh -&gt; au aoi -&gt; ao ao -&gt; ao a -&gt; ‚àÖ / # CONSS VOWELS (abh|adh|agh|amh|√≥dh|ogh|omh|umh) _ CONSP a -&gt; ‚àÖ / # CONSS (obh|odh) _ CONSP # addition a -&gt; ‚àÖ / # CONSS VOWELS ogh _ # omh -&gt; OO / (gc|ch|c) _ (ai|a) r a -&gt; aa / # CONSS _ RDNLR a -&gt; a / # CONSS _ a -&gt; @@ / VOWELP CONSP _ a -&gt; a √©a -&gt; ee √©i -&gt; ee √© -&gt; ee e√°i -&gt; aa e√° -&gt; aa eabh -&gt; abh eadh -&gt; adh / _ # eadh -&gt; au eagh -&gt; ai eai -&gt; a eamh -&gt; amh / _ # eamh -&gt; au / # CONSS _ # VOWEL, or VOWELS ?? ea -&gt; ‚àÖ / # CONSS VOWEL igh _ CONSP ea -&gt; aa / # CONSS _ RDNLR ea -&gt; a / # CONSS _ ea -&gt; @@ / VOWELP CONSP _ ea -&gt; a eidh -&gt; eidh eigh -&gt; eigh ei -&gt; ee / # CONSS _ RDNLR # ei -&gt; ee / # CONSS _ RDNLR NONSYLLABIC ei -&gt; e / # CONSS _ ei -&gt; e e√≥dh -&gt; oo eoi -&gt; oo e√≥ -&gt; oo eo -&gt; oo e -&gt; e / # CONSS _ e -&gt; @@ / VOWELP CONSP _ e -&gt; e √≠odh -&gt; √≠odh / _ # √≠o -&gt; ii √≠ -&gt; ii iadh -&gt; i@ iath -&gt; i@ iai -&gt; i@ ia -&gt; i@ idh -&gt; idh igh -&gt; igh io -&gt; io ithe -&gt; ithe / _ # i√∫i -&gt; uu i√∫ -&gt; uu iubh -&gt; ubh iumh -&gt; uu iui -&gt; uu iu -&gt; u i -&gt; ‚àÖ / # CONSS VOWEL idh _ CONSP # i -&gt; ‚àÖ / # CONSS VOWEL igh _ CONSP i -&gt; @@ / VOWELP CONSP _ i -&gt; I √≥dh -&gt; √≥dh / _ # √≥i -&gt; oo √≥ -&gt; oo obh -&gt; obh odh -&gt; odh ogh -&gt; ogh o√≠ -&gt; ii oidh -&gt; oidh oigh -&gt; oigh oi -&gt; oo / # CONSS _ RDNLR oi -&gt; @@ / # VOWELP CONSP _ oi -&gt; oi omh -&gt; omh o -&gt; oo / # CONSS _ RDNLR # o -&gt; oo / # CONSS _ RDNLR NONSYLLABIC o -&gt; o / # VOWELP CONSP _ o -&gt; o √∫i -&gt; uu √∫ -&gt; uu uath -&gt; u@ uai -&gt; u@ ua -&gt; u@ ubh -&gt; ubh ue -&gt; e ui -&gt; uu / # CONSS _ RDNLR # ui -&gt; uu / # CONSS _ RDNLR NONSYLLABIC ui -&gt; i / # CONSS _ ui -&gt; @@ / VOWELP CONSP _ ui -&gt; ui u√≠o -&gt; ii u√≠ -&gt; ii umh -&gt; uu u -&gt; uu / # CONSS _ RDNLR u -&gt; u / # CONSS _ u -&gt; @@ / VOWELP CONSP _ u -&gt; u bf -&gt; p / _ BFCE # bf -&gt; pj / _ SFCE # bhf -&gt; vj / # _ CONSS RCSV # bhf -&gt; vj / # _ CONSS RCSV NONSYLLABIC bhf -&gt; v / # _ bhf -&gt; f / _ BFCE # bhf -&gt; fj / _ SFCE # bh -&gt; @@ v / # LCSBV LNRP _ bh -&gt; @@ v / NONSYLLABIC LCSBV LNRP _ bh -&gt; @@ vj / # LCSSV LNRP _ bh -&gt; @@ vj / NONSYLLABIC LCSSV LNRP _ bh -&gt; vj / # _ CONSS RCSV # bh -&gt; vj / # _ CONSS RCSV NONSYLLABIC bh -&gt; v / # _ bh -&gt; vj / _ CONSS RCSV # bh -&gt; vj / _ CONSS RCSV NONSYLLABIC bh -&gt; vj / # LCSV CONSP _ bh -&gt; vj / NONSYLLABIC LCSV CONSP _ bh -&gt; vj / # LCSV _ bh -&gt; vj / NONSYLLABIC LCSV _ bh -&gt; v bp -&gt; bj / # _ CONSS RCSV # bp -&gt; bj / # _ CONSS RCSV NONSYLLABIC bp -&gt; b / # _ bth -&gt; p / LCBV CONSS _ bth -&gt; pj / LCSV CONSS _ b -&gt; @@ b / # LCSBV LNRP _ b -&gt; @@ b / NONSYLLABIC LCSBV LNRP _ b -&gt; @@ bj / # LCSSV LNRP _ b -&gt; @@ bj / NONSYLLABIC LCSSV LNRP _ b -&gt; bj / _ CONSS RCSV # b -&gt; bj / _ CONSS RCSV NONSYLLABIC b -&gt; bj / # LCSV CONSP _ b -&gt; bj / NONSYLLABIC LCSV CONSP _ b -&gt; bj / # LCSV _ b -&gt; bj / NONSYLLABIC LCSV _ b -&gt; b cf -&gt; k / _ BFCE # cf -&gt; kj / _ SFCE # chf -&gt; x / _ BFCE # chf -&gt; xj / _ SFCE # ch -&gt; @@ x / # LCSBV LNRP _ ch -&gt; @@ x / NONSYLLABIC LCSBV LNRP _ ch -&gt; @@ xj / # LCSSV LNRP _ ch -&gt; @@ xj / NONSYLLABIC LCSSV LNRP _ ch -&gt; xj / # _ CONSS RCSV # ch -&gt; xj / # _ CONSS RCSV NONSYLLABIC ch -&gt; x / # _ ch -&gt; xj / _ CONSS RCSV # ch -&gt; xj / _ CONSS RCSV NONSYLLABIC ch -&gt; xj / # LCSV CONSP _ ch -&gt; xj / NONSYLLABIC LCSV CONSP _ ch -&gt; xj / # LCSV _ ch -&gt; xj / NONSYLLABIC LCSV _ ch -&gt; x cth -&gt; k / LCBV CONSS _ cth -&gt; kj / LCSV CONSS _ c -&gt; kj / _ CONSS RCSV # c -&gt; kj / _ CONSS RCSV NONSYLLABIC c -&gt; kj / # LCSV CONSP _ c -&gt; kj / NONSYLLABIC LCSV CONSP _ c -&gt; kj / # LCSV _ c -&gt; kj / NONSYLLABIC LCSV _ c -&gt; k df -&gt; t / _ BFCE # df -&gt; tj / _ SFCE # dha -&gt; ‚àÖ / # LCLV _ dha -&gt; ‚àÖ / NONSYLLABIC LCLV _ dh -&gt; gfj / # LCSLV _ dh -&gt; gfj / NONSYLLABIC LCSLV _ dh -&gt; gfj / # CONSS LCSVS _ # dh -&gt; ‚àÖ / # LCLV _ dh -&gt; ‚àÖ / NONSYLLABIC LCLV _ dh -&gt; gfj / # _ CONSS RCSV # dh -&gt; gfj / # _ CONSS RCSV NONSYLLABIC dh -&gt; gf / # _ dh -&gt; gfj / _ CONSS RCSV # dh -&gt; gfj / _ CONSS RCSV NONSYLLABIC dh -&gt; gfj / # LCSV CONSP _ dh -&gt; gfj / NONSYLLABIC LCSV CONSP _ dh -&gt; gfj / # LCSV _ dh -&gt; gfj / NONSYLLABIC LCSV _ dh -&gt; gf dt -&gt; dj / # _ CONSS RCSV # dt -&gt; dj / # _ CONSS RCSV NONSYLLABIC dt -&gt; d / # _ dt -&gt; t / LCBV CONSS _ dt -&gt; tj / LCSV CONSS _ d -&gt; dj / _ CONSS RCSV # d -&gt; dj / _ CONSS RCSV NONSYLLABIC d -&gt; dj / # LCSV CONSP _ d -&gt; dj / NONSYLLABIC LCSV CONSP _ d -&gt; dj / # LCSV _ d -&gt; dj / NONSYLLABIC LCSV _ d -&gt; d fh -&gt; ‚àÖ f -&gt; h / VOWEL _ BFCE # f -&gt; hj / VOWEL _ SFCE # f -&gt; @@ f / # LCSBV LNRP _ f -&gt; @@ f / NONSYLLABIC LCSBV LNRP _ f -&gt; @@ fj / # LCSSV LNRP _ f -&gt; @@ fj / NONSYLLABIC LCSSV LNRP _ f -&gt; fj / _ CONSS RCSV # f -&gt; fj / _ CONSS RCSV NONSYLLABIC f -&gt; fj / # LCSV CONSP _ f -&gt; fj / NONSYLLABIC LCSV CONSP _ f -&gt; fj / # LCSV _ f -&gt; fj / NONSYLLABIC LCSV _ f -&gt; f gc -&gt; gj / # _ CONSS RCSV # gc -&gt; gj / # _ CONSS RCSV NONSYLLABIC gc -&gt; g / # _ gf -&gt; k / _ BFCE # gf -&gt; kj / _ SFCE # gh -&gt; gfj / # _ CONSS RCSV # gh -&gt; gfj / # _ CONSS RCSV NONSYLLABIC gh -&gt; gf / # _ gh -&gt; gfj / # LCSLV _ gh -&gt; gfj / NONSYLLABIC LCSLV _ gh -&gt; gfj / # CONSS LCSVS _ # gh -&gt; ‚àÖ / # LCLV _ gh -&gt; ‚àÖ / NONSYLLABIC LCLV _ gh -&gt; gfj / _ CONSS RCSV # gh -&gt; gfj / _ CONSS RCSV NONSYLLABIC gh -&gt; gfj / # LCSV CONSP _ gh -&gt; gfj / NONSYLLABIC LCSV CONSP _ gh -&gt; gfj / # LCSV _ gh -&gt; gfj / NONSYLLABIC LCSV _ gh -&gt; gf gth -&gt; k / LCBV CONSS _ gth -&gt; kj / LCSV CONSS _ g -&gt; @@ g / # LCSBV LNRP _ g -&gt; @@ g / NONSYLLABIC LCSBV LNRP _ g -&gt; @@ gj / # LCSSV LNRP _ g -&gt; @@ gj / NONSYLLABIC LCSSV LNRP _ g -&gt; gj / _ CONSS RCSV # g -&gt; gj / _ CONSS RCSV NONSYLLABIC g -&gt; gj / # LCSV CONSP _ g -&gt; gj / NONSYLLABIC LCSV CONSP _ g -&gt; gj / # LCSV _ g -&gt; gj / NONSYLLABIC LCSV _ g -&gt; g h -&gt; hj / _ CONSS RCSV # h -&gt; hj / _ CONSS RCSV NONSYLLABIC h -&gt; hj / # LCSV CONSP _ h -&gt; hj / NONSYLLABIC LCSV CONSP _ h -&gt; hj / # LCSV _ h -&gt; hj / NONSYLLABIC LCSV _ h -&gt; h j -&gt; djzj k -&gt; kj / _ CONSS RCSV # k -&gt; kj / _ CONSS RCSV NONSYLLABIC k -&gt; kj / # LCSV CONSP _ k -&gt; kj / NONSYLLABIC LCSV CONSP _ k -&gt; kj / # LCSV _ k -&gt; kj / NONSYLLABIC LCSV _ k -&gt; k llf -&gt; ll_d / _ BFCE # llf -&gt; llj_d / _ SFCE # llth -&gt; ll_d / LCBV CONSS _ llth -&gt; llj_d / LCSV CONSS _ ll -&gt; llj / _ CONSS RCSV # ll -&gt; llj / _ CONSS RCSV NONSYLLABIC ll -&gt; llj / # LCSV CONSP _ ll -&gt; llj / NONSYLLABIC LCSV CONSP _ ll -&gt; llj / # LCSV _ ll -&gt; llj / NONSYLLABIC LCSV _ ll -&gt; ll lf -&gt; ll_d / _ BFCE # lf -&gt; lj_d / _ SFCE # lth -&gt; ll_d / LCBV CONSS _ lth -&gt; lj_d / LCSV CONSS _ l -&gt; lj / _ CONSS RCSV # l -&gt; lj / _ CONSS RCSV NONSYLLABIC l -&gt; lj / # LCSV CONSP _ l -&gt; lj / NONSYLLABIC LCSV CONSP _ l -&gt; lj / # LCSV _ l -&gt; lj / NONSYLLABIC LCSV _ l -&gt; ll mb -&gt; mj / # _ CONSS RCSV # mb -&gt; mj / # _ CONSS RCSV NONSYLLABIC mb -&gt; m / # _ mf -&gt; m_d / _ BFCE # mf -&gt; mj_d / _ SFCE # mhf -&gt; f / _ BFCE # mhf -&gt; fj / _ SFCE # mh -&gt; vj / # _ CONSS RCSV # mh -&gt; vj / # _ CONSS RCSV NONSYLLABIC mh -&gt; v / # _ mh -&gt; @@ v / # LCSBV LNRP _ mh -&gt; @@ v / NONSYLLABIC LCSBV LNRP _ mh -&gt; @@ vj / # LCSSV LNRP _ mh -&gt; @@ vj / NONSYLLABIC LCSSV LNRP _ mh -&gt; vj / _ CONSS RCSV # mh -&gt; vj / _ CONSS RCSV NONSYLLABIC mh -&gt; vj / # LCSV CONSP _ mh -&gt; vj / NONSYLLABIC LCSV CONSP _ mh -&gt; vj / # LCSV _ mh -&gt; vj / NONSYLLABIC LCSV _ mh -&gt; v mth -&gt; m_d / LCBV CONSS _ mth -&gt; mj_d / LCSV CONSS _ m -&gt; @@ m / # LCSBV LNRP _ m -&gt; @@ m / NONSYLLABIC LCSBV LNRP _ m -&gt; @@ mj / # LCSSV LNRP _ m -&gt; @@ mj / NONSYLLABIC LCSSV LNRP _ m -&gt; mj / _ CONSS RCSV # m -&gt; mj / _ CONSS RCSV NONSYLLABIC m -&gt; mj / # LCSV CONSP _ m -&gt; mj / NONSYLLABIC LCSV CONSP _ m -&gt; mj / # LCSV _ m -&gt; mj / NONSYLLABIC LCSV _ m -&gt; m nnf -&gt; nn_d / _ BFCE # nnf -&gt; nnj_d / _ SFCE # nnth -&gt; nn_d / LCBV CONSS _ nnth -&gt; nnj_d / LCSV CONSS _ nn -&gt; nnj / _ CONSS RCSV # nn -&gt; nnj / _ CONSS RCSV NONSYLLABIC nn -&gt; nnj / # LCSV CONSP _ nn -&gt; nnj / NONSYLLABIC LCSV CONSP _ nn -&gt; nnj / # LCSV _ nn -&gt; nnj / NONSYLLABIC LCSV _ nn -&gt; nn n- -&gt; nj / # _ RCSV # n- -&gt; nj / # _ RCSV NONSYLLABIC n- -&gt; nn / # _ nd -&gt; nnj / # _ CONSS RCSV # nd -&gt; nnj / # _ CONSS RCSV NONSYLLABIC nd -&gt; nn / # _ nf -&gt; nn_d / _ BFCE # nf -&gt; nj_d / _ SFCE # ngf -&gt; ng_d / _ BFCE # ngf -&gt; ngj_d / _ SFCE # ngth -&gt; ng_d / LCBV CONSS _ ngth -&gt; ngj_d / LCSV CONSS _ ng -&gt; ngj / # _ CONSS RCSV # ng -&gt; ngj / # _ CONSS RCSV NONSYLLABIC ng -&gt; ng / # _ ng -&gt; nj / # LCSV _ t # ng -&gt; nj / NONSYLLABIC LCSV _ t # ng -&gt; ngj / _ CONSS RCSV # ng -&gt; ngj / _ CONSS RCSV NONSYLLABIC ng -&gt; ngj / # LCSV CONSP _ ng -&gt; ngj / NONSYLLABIC LCSV CONSP _ ng -&gt; ngj / # LCSV _ ng -&gt; ngj / NONSYLLABIC LCSV _ ng -&gt; ng nth -&gt; nn_d / LCBV CONSS _ nth -&gt; nj_d / LCSV CONSS _ n -&gt; ngj / # LCSV _ c n -&gt; ngj / NONSYLLABIC LCSV _ c n -&gt; ng / _ c n -&gt; nj / _ CONSS RCSV # n -&gt; nj / _ CONSS RCSV NONSYLLABIC n -&gt; nj / # LCSV CONSP _ n -&gt; nj / NONSYLLABIC LCSV CONSP _ n -&gt; nj / # LCSV _ n -&gt; nj / NONSYLLABIC LCSV _ n -&gt; nn pf -&gt; p / _ BFCE # pf -&gt; pj / _ SFCE # ph -&gt; fj / # _ CONSS RCSV # ph -&gt; fj / # _ CONSS RCSV NONSYLLABIC ph -&gt; f / # _ ph -&gt; fj / _ CONSS RCSV # ph -&gt; fj / _ CONSS RCSV NONSYLLABIC ph -&gt; fj / # LCSV CONSP _ ph -&gt; fj / NONSYLLABIC LCSV CONSP _ ph -&gt; fj / # LCSV _ ph -&gt; fj / NONSYLLABIC LCSV _ ph -&gt; f pth -&gt; p / LCBV CONSS _ pth -&gt; pj / LCSV CONSS _ p -&gt; pj / _ CONSS RCSV # p -&gt; pj / _ CONSS RCSV NONSYLLABIC p -&gt; pj / # LCSV CONSP _ p -&gt; pj / NONSYLLABIC LCSV CONSP _ p -&gt; pj / # LCSV _ p -&gt; pj / NONSYLLABIC LCSV _ p -&gt; p # really? there&#39;s a &#39;W&#39; in the phoneset q -&gt; k v rrf -&gt; rr_d / _ BFCE # rrf -&gt; rrj_d / _ SFCE # rrth -&gt; rr_d / LCBV CONSS _ rrth -&gt; rrj_d / LCSV CONSS _ rr -&gt; rrj / _ CONSS RCSV # rr -&gt; rrj / _ CONSS RCSV NONSYLLABIC rr -&gt; rrj / # LCSV CONSP _ rr -&gt; rrj / NONSYLLABIC LCSV CONSP _ rr -&gt; rrj / # LCSV _ rr -&gt; rrj / NONSYLLABIC LCSV _ rr -&gt; rr rf -&gt; r_d / _ BFCE # rf -&gt; rj_d / _ SFCE # rth -&gt; r_d / LCBV CONSS _ rth -&gt; rj_d / LCSV CONSS _ r -&gt; r / # s _ r -&gt; r / # _ r -&gt; r / _ DNLST r -&gt; rj / _ CONSS RCSV # r -&gt; rj / _ CONSS RCSV NONSYLLABIC r -&gt; rj / # LCSV CONSP _ r -&gt; rj / NONSYLLABIC LCSV CONSP _ r -&gt; rj / # LCSV _ r -&gt; rj / NONSYLLABIC LCSV _ r -&gt; r sf -&gt; s / _ BFCE # sf -&gt; sj / _ SFCE # shl -&gt; lj_d / _ CONSS RCSV # shl -&gt; lj_d / _ CONSS RCSV NONSYLLABIC shl -&gt; ll_d shm -&gt; mj_d / _ CONSS RCSV # shm -&gt; mj_d / _ CONSS RCSV NONSYLLABIC shm -&gt; m_d shn -&gt; nj_d / _ CONSS RCSV # shn -&gt; nj_d / _ CONSS RCSV NONSYLLABIC shn -&gt; nn_d shr -&gt; rj_d / _ CONSS RCSV # shr -&gt; rj_d / _ CONSS RCSV NONSYLLABIC shr -&gt; r_d sh -&gt; xj / # _ CONSS RCSV # sh -&gt; xj / # _ CONSS RCSV NONSYLLABIC sh -&gt; h / # _ sh -&gt; xj / _ CONSS RCSV # sh -&gt; xj / _ CONSS RCSV NONSYLLABIC sh -&gt; xj / # LCSV CONSP _ sh -&gt; xj / NONSYLLABIC LCSV CONSP _ sh -&gt; xj / # LCSV _ sh -&gt; xj / NONSYLLABIC LCSV _ sh -&gt; h s -&gt; s / # _ r s -&gt; s / # _ FMP CONSS RCSV # s -&gt; s / # _ FMP CONSS RCSV NONSYLLABIC s -&gt; sj / _ CONSS RCSV # s -&gt; sj / _ CONSS RCSV NONSYLLABIC s -&gt; sj / # LCSV CONSP _ s -&gt; sj / NONSYLLABIC LCSV CONSP _ s -&gt; sj / # LCSV _ s -&gt; sj / NONSYLLABIC LCSV _ s -&gt; s t- -&gt; tj / # _ RCSV # t- -&gt; tj / # _ RCSV NONSYLLABIC t- -&gt; t / # _ tf -&gt; t / _ BFCE # tf -&gt; tj / _ SFCE # // &quot;hack for compound boundaries&quot; th -&gt; ‚àÖ / _ CONS h thb -&gt; pj / _ CONSS RCSV # thb -&gt; pj / _ CONSS RCSV NONSYLLABIC thb -&gt; p thc -&gt; kj / _ CONSS RCSV # thc -&gt; kj / _ CONSS RCSV NONSYLLABIC thc -&gt; k thd -&gt; tj / _ CONSS RCSV # thd -&gt; tj / _ CONSS RCSV NONSYLLABIC thd -&gt; t thf -&gt; h / _ BFCE # thf -&gt; xj / _ SFCE # thl -&gt; lj_d / _ CONSS RCSV # thl -&gt; lj_d / _ CONSS RCSV NONSYLLABIC thl -&gt; ll_d thm -&gt; mj_d / _ CONSS RCSV # thm -&gt; mj_d / _ CONSS RCSV NONSYLLABIC thm -&gt; m_d thn -&gt; nj_d / _ CONSS RCSV # thn -&gt; nj_d / _ CONSS RCSV NONSYLLABIC thn -&gt; nn_d thp -&gt; pj / _ CONSS RCSV # thp -&gt; pj / _ CONSS RCSV NONSYLLABIC thp -&gt; p thr -&gt; rj_d / _ CONSS RCSV # thr -&gt; rj_d / _ CONSS RCSV NONSYLLABIC thr -&gt; r_d ths -&gt; sj / _ CONSS RCSV # ths -&gt; sj / _ CONSS RCSV NONSYLLABIC ths -&gt; s tht -&gt; tj / _ CONSS RCSV # tht -&gt; tj / _ CONSS RCSV NONSYLLABIC tht -&gt; t th -&gt; hj / # _ CONSS RCSV # th -&gt; hj / # _ CONSS RCSV NONSYLLABIC th -&gt; h / # _ th -&gt; hj / _ CONSS RCSV # th -&gt; hj / _ CONSS RCSV NONSYLLABIC th -&gt; hj / # LCSV CONSP _ th -&gt; hj / NONSYLLABIC LCSV CONSP _ th -&gt; hj / # LCSV _ th -&gt; hj / NONSYLLABIC LCSV _ th -&gt; h ts -&gt; tj / # _ CONSS RCSV # ts -&gt; tj / # _ CONSS RCSV NONSYLLABIC ts -&gt; t / # _ t -&gt; tj / _ CONSS RCSV # t -&gt; tj / _ CONSS RCSV NONSYLLABIC t -&gt; tj / # LCSV CONSP _ t -&gt; tj / NONSYLLABIC LCSV CONSP _ t -&gt; tj / # LCSV _ t -&gt; tj / NONSYLLABIC LCSV _ t -&gt; t v -&gt; vj / _ CONSS RCSV # v -&gt; vj / _ CONSS RCSV NONSYLLABIC v -&gt; vj / # LCSV CONSP _ v -&gt; vj / NONSYLLABIC LCSV CONSP _ v -&gt; vj / # LCSV _ v -&gt; vj / NONSYLLABIC LCSV _ v -&gt; v w -&gt; v x- -&gt; e kj s x -&gt; zj y -&gt; gfj z -&gt; zj / _ CONSS RCSV # z -&gt; zj / _ CONSS RCSV NONSYLLABIC z -&gt; zj / # LCSV CONSP _ z -&gt; zj / NONSYLLABIC LCSV CONSP _ z -&gt; zj / # LCSV _ z -&gt; zj / NONSYLLABIC LCSV _ z -&gt; z &#39; -&gt; ‚àÖ ‚Äô -&gt; ‚àÖ - -&gt; ‚àÖ TEST √°dh -&gt; aa TEST √°iseanna -&gt; aa sj @@ nn @@ TEST √°thas -&gt; aa h @@ s TEST abhainn -&gt; abh nnj TEST bualadh -&gt; b u@ ll adh TEST sadhbh -&gt; s ai v TEST saghas -&gt; s ai s TEST gaeilge -&gt; g ee lj gj @@ TEST saola√≠odh -&gt; s ao ll √≠odh TEST garda√≠ -&gt; g aa r d ii TEST d√∫nfaidh -&gt; d uu nn_d idh TEST aidhm -&gt; ai mj TEST cheadaigh -&gt; xj a d igh TEST aighneas -&gt; ai nj @@ s TEST di√∫ltaithe -&gt; dj uu ll t ithe TEST seabhaic -&gt; sj abh kj TEST feadhain -&gt; fj au nj TEST teaghais -&gt; tj ai sj TEST eamhain -&gt; au nj TEST lobhair -&gt; ll obh rj TEST le√≥dhais -&gt; lj oo sj TEST bodhair -&gt; b odh rj TEST eoghain -&gt; oo nj TEST broghais -&gt; b r ogh sj TEST comhair -&gt; k oo rj TEST ciumhais -&gt; kj uu sj TEST airde -&gt; aa r dj @@ TEST cait -&gt; k a tj TEST sodair -&gt; s o d @@ rj TEST ait -&gt; a tj TEST d√©anamh -&gt; dj ee nn amh TEST amharc -&gt; au r k TEST gaoil -&gt; g ao lj TEST gaol -&gt; g ao ll TEST seabhac -&gt; sj abh k TEST ceadharlach -&gt; kj au r ll @@ x TEST teaghas√°n -&gt; tj ai s aa nn TEST lobhar -&gt; ll obh r TEST le√≥dhas -&gt; lj oo s TEST bodhar -&gt; b odh r TEST eoghan -&gt; oo nn TEST bogha -&gt; b ogh TEST comhar -&gt; k oo r TEST dumhach -&gt; d uu x TEST ard -&gt; aa r d TEST cat -&gt; k a t TEST sodar -&gt; s o d @@ r TEST at -&gt; a t TEST √©an -&gt; ee nn TEST √©in√≠n√≠ -&gt; ee nj ii nj ii TEST √© -&gt; ee TEST she√°in -&gt; xj aa nj TEST se√°n -&gt; sj aa nn TEST seabhac -&gt; sj abh k TEST seinneadh -&gt; sj e nnj adh TEST ceadharlach -&gt; kj au r ll @@ x TEST teaghlach -&gt; tj ai ll @@ x TEST beairic -&gt; bj a rj @@ kj TEST √°ireamh -&gt; aa rj amh TEST sleamhn√°n -&gt; sj lj au nn aa nn TEST oighear -&gt; oigh r TEST ceard -&gt; kj aa r d TEST cead -&gt; kj a d TEST √°ireamh√°n -&gt; aa rj @@ v aa nn TEST eas -&gt; a s TEST feidhm -&gt; fj eidh mj TEST leigheas -&gt; lj eigh s TEST ceird -&gt; kj ee r dj TEST deis -&gt; dj e sj TEST eitpheil -&gt; e tj fj e lj TEST ceoil -&gt; kj oo lj TEST bainse√≥ -&gt; b a nj sj oo TEST ceol -&gt; kj oo ll TEST uile -&gt; i lj @@ TEST ceanna√≠odh -&gt; kj a nn √≠odh TEST s√≠os -&gt; sj ii s TEST s√≠ -&gt; sj ii TEST siadhail -&gt; sj i@ lj TEST sciath -&gt; sj kj i@ TEST riail -&gt; r i@ lj TEST siad -&gt; sj i@ d TEST seinnfidh -&gt; sj e nnj_d idh TEST cheannaigh -&gt; xj a nn igh TEST fios -&gt; fj io s TEST imithe -&gt; i mj ithe TEST si√∫il -&gt; sj uu lj TEST si√∫l -&gt; sj uu ll TEST tiubh -&gt; tj ubh TEST ciumhais -&gt; kj uu sj TEST giuirl√©id -&gt; gj uu r lj ee dj TEST fiuch -&gt; fj u x TEST leighis -&gt; lj eigh sj TEST foighid -&gt; f oigh dj TEST aithris -&gt; a rj_d @@ sj TEST sin -&gt; sj i nj TEST cheann√≥dh -&gt; xj a nn √≥dh TEST √≥il -&gt; oo lj TEST √≥l -&gt; oo ll TEST lobhadh -&gt; ll obh adh TEST todhcha√≠ -&gt; t odh x ii TEST toghadh -&gt; t ogh adh TEST o√≠che -&gt; ii xj @@ TEST oidhe -&gt; oidh @@ TEST oighear -&gt; oigh r TEST boird -&gt; b oo r dj TEST soir -&gt; s oi rj TEST comhar -&gt; k oo r TEST bord -&gt; b oo r d TEST bos -&gt; b o s TEST s√∫il -&gt; s uu lj TEST s√∫l -&gt; s uu ll TEST uath√∫il -&gt; u@ uu lj TEST uaine -&gt; u@ nj @@ TEST uan -&gt; u@ nn TEST subh -&gt; s ubh TEST bhuel -&gt; v e ll TEST guird -&gt; g uu r dj TEST cuid -&gt; k i dj TEST uile -&gt; i lj @@ TEST bru√≠on -&gt; b r ii nn TEST bru√≠ne -&gt; b r ii nj @@ TEST cumhacht -&gt; k uu x t TEST burd√∫n -&gt; b uu r d uu nn TEST cur -&gt; k u r TEST bus -&gt; b u s TEST scuabfaidh -&gt; s k u@ p idh TEST clibfidh -&gt; kj lj i pj idh TEST scuabfadh -&gt; s k u@ p adh TEST clibfeadh -&gt; kj lj i pj adh TEST bhf√°inne -&gt; v aa nnj @@ TEST bhfianaise -&gt; vj i@ nn @@ sj @@ TEST scr√≠obhfaidh -&gt; sj kj rj ii f idh TEST d√≠bhfidh -&gt; dj ii fj idh TEST scr√≠obhfadh -&gt; sj kj rj ii f adh TEST d√≠bhfeadh -&gt; dj ii fj adh TEST searbh -&gt; sj a r @@ v TEST seirbh√≠s -&gt; sj e rj @@ vj ii sj TEST bhrostaigh -&gt; v r o s t igh TEST bhris -&gt; vj rj i sj TEST coibh√≠n -&gt; k oi vj ii nj TEST bp√°ist√≠ -&gt; b aa sj tj ii TEST bp√©isteanna -&gt; bj ee sj tj @@ nn @@ TEST scuabtha -&gt; s k u@ p @@ TEST clibthe -&gt; kj lj i pj @@ TEST borb -&gt; b o r @@ b TEST seirbiach -&gt; sj e rj @@ bj i@ x TEST br√≥na -&gt; b r oo nn @@ TEST brian -&gt; bj rj i@ nn TEST le√≥dhas -&gt; lj oo s TEST t-uisce -&gt; t ui sj kj @@ TEST t-√©abhl√≥id√≠ -&gt; tj ee v ll oo dj ii TEST atfaidh -&gt; a t idh TEST titfidh -&gt; tj i tj idh TEST athdh√©anamh -&gt; a gfj ee nn amh TEST meathfadh -&gt; mj a h adh TEST rithfeadh -&gt; r i xj adh TEST bl√°thra -&gt; b ll aa r_d @@ TEST tharla -&gt; h aa r ll @@ TEST thit -&gt; hj i tj TEST tseachtain -&gt; tj a x t @@ nj TEST tsagairt -&gt; t a g @@ r tj TEST teann -&gt; tj a nn TEST tit -&gt; tj i tj TEST togra -&gt; t o g r @@ TEST sadhbh -&gt; s ai v TEST bh√©al -&gt; vj ee ll TEST bh√©il -&gt; vj ee lj . %%writefile oraghallaigh-cd.g2p CHARACTER_SET &quot;abcdefghi√≠jklmno√≥prstuvwxz@.012-_&quot; DEFAULT_PHONEME &quot;_&quot; PHONEME_DELIMITER &quot; &quot; VAR BC (p|b|f|v|m_d|m|t_|t|d_|d|ll_d|ll|l_d|l|nn_d|nn|n_d|n|rr_d|r_d|rr|r|s|z|k|g|x|gf|ng_d|ng|h) VAR LLJ (llj|nnj|rrj|mj) VAR LL (ll|nn|rr|m) aa -&gt; aa abh -&gt; au adh -&gt; @ x agh -&gt; ai a√≠o -&gt; i@ amh -&gt; @ v ai -&gt; ai ao -&gt; ee au -&gt; au a -&gt; ai / _ LLJ a -&gt; au / _ LL a -&gt; a ee -&gt; i@ / _ BC ee -&gt; ee eidh -&gt; e gj / _ # eidh -&gt; ai eigh -&gt; ai e -&gt; e idh -&gt; @ gj igh -&gt; @ gj √≠odh -&gt; i@ x ithe -&gt; @ . 0 h @ i@ -&gt; i@ ii -&gt; ii io -&gt; i i -&gt; ii / _ LLJ # i -&gt; i obh -&gt; au √≥dh -&gt; oo x odh -&gt; au ogh -&gt; au oidh -&gt; ai oigh -&gt; ai oi -&gt; ii / _ LLJ # oi -&gt; i omh -&gt; au oo -&gt; oo o -&gt; au / _ LL # o -&gt; o ubh -&gt; u v / _ # ubh -&gt; @ v u@ -&gt; u@ ui -&gt; ii / _ LLJ ui -&gt; i uu -&gt; uu u -&gt; u @@ -&gt; @ pj -&gt; pj p -&gt; p bj -&gt; bj b -&gt; b fj -&gt; fj f -&gt; f vj -&gt; vj v -&gt; v w -&gt; w mj_d -&gt; mj_d m_d -&gt; m_d mj -&gt; mj m -&gt; m tjsj -&gt; tjsj djzj -&gt; djzj t_- -&gt; t_- tj -&gt; tj t -&gt; t d_- -&gt; d_- dj -&gt; dj d -&gt; d llj_d -&gt; lj_d ll_d -&gt; l_d llj -&gt; lj ll -&gt; l lj_d -&gt; lj_d l_d -&gt; l_d lj -&gt; lj l -&gt; l nnj_d -&gt; nj_d nn_d -&gt; n_d nnj -&gt; nj nn -&gt; n nj_d -&gt; nj_d n_d -&gt; n_d rrj_d -&gt; rj_d rj_d -&gt; rj_d rr_d -&gt; r_d r_d -&gt; r_d rrj -&gt; rj rj -&gt; rj rr -&gt; r r -&gt; r sj -&gt; sj s -&gt; s zj -&gt; zj z -&gt; z kj -&gt; kj k -&gt; k gj -&gt; gj g -&gt; g xj -&gt; xj x -&gt; x gfj -&gt; ‚àÖ / _ # gfj -&gt; gfj ngj_d -&gt; ngj h ng_d -&gt; ng h ngj -&gt; nj / _ # ngj -&gt; ngj ng -&gt; ng nj -&gt; nj n -&gt; n hj -&gt; h h -&gt; h 0 -&gt; 0 1 -&gt; 1 2 -&gt; 2 . -&gt; . - -&gt; ‚àÖ @ -&gt; ‚àÖ c -&gt; ‚àÖ j -&gt; ‚àÖ √≠ -&gt; ‚àÖ √≥ -&gt; ‚àÖ _ -&gt; ‚àÖ TEST faas -&gt; f aa s TEST abhnnj -&gt; au nj TEST saghd -&gt; s ai d TEST sa√≠oxt -&gt; s i@ x t TEST djeennamh -&gt; dj ee n @ v TEST taig -&gt; t ai g TEST saoll -&gt; s ee l TEST saulj -&gt; s au lj TEST kallj -&gt; k ai lj TEST krann -&gt; k r au n TEST kad -&gt; k a d TEST eenn -&gt; i@ n TEST sjee -&gt; sj ee TEST beidh -&gt; b e gj TEST fjeidhmj -&gt; fj ai mj TEST ljeighs -&gt; lj ai s TEST djesj -&gt; dj e sj TEST bjrjisjidh -&gt; bj rj i sj @ gj TEST xjannigh -&gt; xj a n @ gj TEST kjann√≠odh -&gt; kj a n i@ x TEST kjannithe -&gt; kj a n @ h @ TEST i@rr -&gt; i@ r TEST sjiinj -&gt; sj ii nj TEST fjios -&gt; fj i s TEST imj -&gt; ii mj TEST sjinj -&gt; sj i nj TEST llobhr -&gt; l au r TEST kjann√≥dh -&gt; kj a n oo x TEST bodhr -&gt; b au r TEST toghxaann -&gt; t au x aa n TEST oidhrjaxt -&gt; ai rj a x t TEST oighr -&gt; ai r TEST koillj -&gt; k ii lj TEST koillj@@ -&gt; k i lj @ TEST domhnn -&gt; d au n TEST moor -&gt; m oo r TEST poll -&gt; p au l TEST polladh -&gt; p o l @ x TEST ubh@@gaann -&gt; @ v @ g aa n TEST bu@ -&gt; b u@ TEST suimj -&gt; s ii mj TEST kuidj -&gt; k i dj TEST kuur -&gt; k uu r TEST kur -&gt; k u r TEST farjsj@@ngj -&gt; f a rj sj @ nj .",
            "url": "https://jimregan.github.io/notes/irish/g2p/kerry/2021/05/17/o-raghallaigh-thesis-attempt-2-cd.html",
            "relUrl": "/irish/g2p/kerry/2021/05/17/o-raghallaigh-thesis-attempt-2-cd.html",
            "date": " ‚Ä¢ May 17, 2021"
        }
        
    
  
    
        ,"post14": {
            "title": "Kilkenny Irish example",
            "content": "Sc√©al beag√°n i nGaeilig Osra√≠ (Contae Chill Choinnigh). pic.twitter.com/KhG3fd7fkE . &mdash; Cormac de Briot√∫n (@erisceres) May 17, 2021 The picture is nice; transcriptions are better: . v‚Ä≤iÀê toÀêr…ô uÀên f…ôdoÀê …ëg…ôs v‚Ä≤i an…ôÀàxid‚Ä≤ mn…ëÀê eg‚Ä≤…ôn toÀêr…ô, …ëg…ôs v‚Ä≤iÀê s‚Ä≤i…ôd …ô siÀê e í …ô loxd…ô, …ôn …ëÀêt‚Ä≤ …ô re n toÀêr…ô. wel‚Ä≤, l‚Ä≤ig‚Ä≤ din‚Ä≤…ô br…ôim‚Ä≤ …ëg…ôs n‚Ä≤iÀê res eg‚Ä≤ eÀê≈ã‚Ä≤…ô k‚Ä≤eÀê l‚Ä≤ig‚Ä≤ …ôn br…ôim‚Ä≤ duÀêrt‚Ä≤ f‚Ä≤ar …ô v‚Ä≤iÀê g‚Ä≤en toÀêr…ô ‚Äòwel‚Ä≤‚Äô, …ô d‚Ä≤er s‚Ä≤e, ‚Äò…ôn b‚Ä≤an …ô l‚Ä≤ig‚Ä≤ …ô br…ôim‚Ä≤ h…ëÀê k…ôip‚Ä≤ t‚Ä≤ íiÀê hin‚Ä≤…ô‚Äô …ônsin‚Ä≤ xi í …ôn v‚Ä≤an «ù l…ëÀê s‚Ä≤i…ôr xuÀên …ô k…ôip‚Ä≤, …ëg«ùs v‚Ä≤iÀês …ôku el‚Ä≤…ô (…ô)nsin‚Ä≤ …ôn b‚Ä≤an …ô l‚Ä≤ig‚Ä≤ …ôn br…ôim‚Ä≤. . Bh√≠ t√≥rramh ann fad√≥ agus bh√≠ anchuid mn√° ag an t√≥rramh, agus bh√≠ siad ag su√≠ ar an lochta, an √°it a raibh an t√≥rramh. Well, lig duine broim agus n√≠ raibh a fhios ag √©inne c√© lig an broim. D√∫irt fear a bh√≠ ag an t√≥rramh ‚ÄòWell‚Äô, a deir s√©, ‚Äòan bean (sic) a lig an broim, th√° a caidhp tr√≠ thine.‚Äô Ansoin chuir an bhean a l√°mh siar chun a caidhp, agus bh√≠ a fhios acu uile ansoin an bean a lig an broim. .",
            "url": "https://jimregan.github.io/notes/irish/twitter/kilkenny/2021/05/17/kilkenny-irish.html",
            "relUrl": "/irish/twitter/kilkenny/2021/05/17/kilkenny-irish.html",
            "date": " ‚Ä¢ May 17, 2021"
        }
        
    
  
    
        ,"post15": {
            "title": "Converting √ì Raghallaigh (2010)",
            "content": "This notebook contains a re-implementation of the &quot;global&quot; phonetiser from Brian √ì Raghallaigh&#39;s Ph.D. thesis using rbg2p. . Brian √ì Raghallaigh (2010). Multi-dialect phonetisation for Irish text-to-speech synthesis: a modular approach. (Doctoral thesis, Trinity College, Dublin), Appendix B.1 . @phdthesis{oraghallaigh2010multidialect, author = {Brian √ì~Raghallaigh}, title = {Multi-dialect phonetisation for {I}rish text-to-speech synthesis: a modular approach}, school = {Trinity College, Dublin}, year = 2010, address = {Dublin, Ireland}, month = 9, } . The initial run (after small conversion errors were corrected) gave the following set of errors: . FAILED TEST: for &#39;comhair&#39;, expected /K OO RJ/, got /K OMH RJ/ FAILED TEST: for &#39;airde&#39;, expected /AA RJ DJ @@/, got /AA R DJ @@/ FAILED TEST: for &#39;bogha&#39;, expected /B OGH/, got /B OGH @@/ FAILED TEST: for &#39;comhar&#39;, expected /K OO R/, got /K OMH R/ FAILED TEST: for &#39;ceird&#39;, expected /KJ EE RJ DJ/, got /KJ EE R DJ/ FAILED TEST: for &#39;riail&#39;, expected /RJ I@ LJ/, got /R I@ LJ/ FAILED TEST: for &#39;giuirl√©id&#39;, expected /GJ UU RJ LJ EE DJ/, got /GJ UU R LJ EE DJ/ FAILED TEST: for &#39;boird&#39;, expected /B OO RJ DJ/, got /B OO R DJ/ FAILED TEST: for &#39;bantaboic&#39;, expected /B A NN T @@ B @@ KJ/, got /B A NN T @@ B OI KJ/ FAILED TEST: for &#39;comhar&#39;, expected /K OO R/, got /K OMH R/ FAILED TEST: for &#39;bantaboc&#39;, expected /B A NN T @@ B @@ K/, got /B A NN T @@ B O K/ FAILED TEST: for &#39;guird&#39;, expected /G UU RJ DJ/, got /G UU R DJ/ FAILED TEST: for &#39;bhfianaise&#39;, expected /VJ I@ NN @@ SJ @@/, got /V I@ NN @@ SJ @@/ FAILED TEST: for &#39;leathbhosca&#39;, expected /LJ A V @@ S K @@/, got /LJ A V O S K @@/ FAILED TEST: for &#39;rithfeadh&#39;, expected /RJ I XJ ADH/, got /R I XJ ADH/ FAILED TEST: for &#39;tsagairt&#39;, expected /T A G @@ RJ TJ/, got /T A G @@ R TJ/ 16 OF 168 TESTS FAILED FOR briain.g2p exit status 1 . The most consistent source of errors is slender &#39;r&#39; in environments (word initially, before &#39;d&#39;, etc.) where the rule is that they should be left broad; I corrected the tests (which were intended only as tests of the vowels). . Of the remainder, bogha represents a missing rule, while comhar/comhair does not fit with the given rule, so I added a somewhat lexicalised rule to handle it (and its mutated forms) specifically. . This leaves these words: . FAILED TEST: for &#39;bantaboic&#39;, expected /B A NN T @@ B @@ KJ/, got /B A NN T @@ B OI KJ/ FAILED TEST: for &#39;bantaboc&#39;, expected /B A NN T @@ B @@ K/, got /B A NN T @@ B O K/ FAILED TEST: for &#39;leathbhosca&#39;, expected /LJ A V @@ S K @@/, got /LJ A V O S K @@/ . leathbhosca is a compound, and keeping bhosca as V O S K @@ is correct; otherwise, the rule which for other short vowels converts to schwa is specifically converted to O, so I disabled these rules. . %%writefile oraghallaigh.g2p CHARACTER_SET &quot;a√°bcde√©fghi√≠jklmno√≥pqrstu√∫vwxyz&#39;-‚Äô&quot; DEFAULT_PHONEME &quot;_&quot; PHONEME_DELIMITER &quot; &quot; #VAR ALPHA [abcdefghijklmnopqrstuvwxyz] VAR CONS [bcdfghjklmnpqrstvwxyz] VAR CONSS [bcdfghjklmnpqrstvwxyz]* VAR CONSP [bcdfghjklmnpqrstvwxyz]+ # including &#39;#&#39; doesn&#39;t work, so those rules were duplicated #VAR NONSYLLABIC (√°|b|c|d|f|g|h|j|k|l|m|n|√≥|p|q|r|s|t|√∫|v|w|x|y|z|#) VAR NONSYLLABIC [√°bcdfghjklmn√≥pqrst√∫vwxyz] // broad future/conditional endings VAR BFCE (√°|adh|aidh|aid√≠s|aimid|aimis|ainn|as) // slender future/conditional endings VAR SFCE (e√°|eadh|idh|id√≠s|imid|imis|inn) #VAR L (ll|l) #VAR MN [mn] VAR FMP [fmp] #VAR LNR [lnr] VAR LNRP [lnr]+ #VAR LRST [lrst] VAR DNLST [dnlst] #VAR DNST [dnst] VAR RDNLR (rd|rn|rl|rr) VAR VOWEL [a√°e√©i√≠o√≥u√∫] VAR VOWELS [a√°e√©i√≠o√≥u√∫]* VAR VOWELP [a√°e√©i√≠o√≥u√∫]+ // left context short broad vowel VAR LCSBV (ea|io|iu|a|o|u) // left context short slender vowel VAR LCSSV (ai|eai|ei|e|iui|i|oi|ui) // left context broad vowel VAR LCBV (adh|ae|ao|a√°|ea|e√°|eo|√©a|io|iu|i√∫|√≠o|o√≥|u√≠o|ua|u|√∫) // right context broad vowel #VAR RCBV (aei|ae|ai|aoi|ao|a|√°i|√°|oi|o|√≥i|√≥|ui|u√≠o|u√≠|u|√∫i|√∫) // left context slender vowel VAR LCSV (aei|aidh|ai|a√≠|aoi|√°i|eai|e√°i|ei|eoi|e|√©i|√©|iai|iui|i√∫i|i|√≠|oi|√≥i|uai|ui|u√≠|√∫i) VAR LCSVS (aei|aidh|ai|a√≠|aoi|√°i|eai|e√°i|ei|eoi|e|√©i|√©|iai|iui|i√∫i|i|√≠|oi|√≥i|uai|ui|u√≠|√∫i)* // right context slender vowel VAR RCSV (eai|ea|e√°i|e√°|ei|eoi|eo|e|√©a|√©i|√©|iai|ia|io|iui|iu|i√∫i|i√∫|i|√≠o|√≠) // left context long vowel VAR LCLV (aei|ae|aoi|ao|√°i|√°|e√°i|e√°|eoi|e√≥|eo|√©i|√©|i√∫i|i√∫|√≠o|√≠|√≥i|√≥|u√≠o|u√≠|√∫i|√∫) // left context slender long vowel VAR LCSLV (aei|aidh|aoi|√°i|e√°i|eoi|√©i|√©|i√∫i|√≠|√≥i|uai|u√≠|√∫i) √°dh -&gt; AA √°i -&gt; AA √° -&gt; AA abh -&gt; ABH adh -&gt; ADH / _ # adh -&gt; AI agh -&gt; AI aei -&gt; EE ae -&gt; EE a√≠odh -&gt; √çODH / _ # a√≠o -&gt; A√çO a√≠ -&gt; II aidh -&gt; IDH / _ # aidh -&gt; AI aigh -&gt; IGH / _ # aigh -&gt; AI aithe -&gt; ITHE / _ # ai -&gt; ‚àÖ / # CONSS VOWELS abh _ CONSP ai -&gt; ‚àÖ / # CONSS VOWELS adh _ CONSP ai -&gt; ‚àÖ / # CONSS VOWELS agh _ CONSP ai -&gt; ‚àÖ / # CONSS VOWELS amh _ CONSP ai -&gt; ‚àÖ / # CONSS obh _ CONSP ai -&gt; ‚àÖ / # CONSS VOWELS √≥dh _ CONSP ai -&gt; ‚àÖ / # CONSS odh _ CONSP ai -&gt; ‚àÖ / # CONSS VOWELS ogh _ CONSP ai -&gt; ‚àÖ / # CONSS VOWELS omh _ CONSP ai -&gt; ‚àÖ / # CONSS VOWELS umh _ CONSP ai -&gt; AA / # CONSS _ RDNLR ai -&gt; A / # CONSS _ ai -&gt; @@ / VOWELP CONSP _ ai -&gt; A amh -&gt; AMH / _ # amh -&gt; AU aoi -&gt; AO ao -&gt; AO a -&gt; ‚àÖ / # CONSS VOWELS abh _ CONSP a -&gt; ‚àÖ / # CONSS VOWELS adh _ CONSP a -&gt; ‚àÖ / # CONSS VOWELS agh _ CONSP a -&gt; ‚àÖ / # CONSS VOWELS amh _ CONSP a -&gt; ‚àÖ / # CONSS obh _ CONSP a -&gt; ‚àÖ / # CONSS VOWELS √≥dh _ CONSP a -&gt; ‚àÖ / # CONSS odh _ CONSP a -&gt; ‚àÖ / # CONSS VOWELS ogh _ CONSP a -&gt; ‚àÖ / # CONSS VOWELS omh _ CONSP a -&gt; ‚àÖ / # CONSS VOWELS umh _ CONSP # addition a -&gt; ‚àÖ / # CONSS VOWELS ogh _ # omh -&gt; OO / (gc|ch|c) _ (ai|a) r a -&gt; AA / # CONSS _ RDNLR a -&gt; A / # CONSS _ a -&gt; @@ / VOWELP CONSP _ a -&gt; A √©a -&gt; EE √©i -&gt; EE √© -&gt; EE e√°i -&gt; AA e√° -&gt; AA eabh -&gt; ABH eadh -&gt; ADH / _ # eadh -&gt; AU eagh -&gt; AI eai -&gt; A eamh -&gt; AMH / _ # eamh -&gt; AU / # CONSS _ # VOWEL, or VOWELS ?? ea -&gt; ‚àÖ / # CONSS VOWEL igh _ CONSP ea -&gt; AA / # CONSS _ RDNLR ea -&gt; A / # CONSS _ ea -&gt; @@ / VOWELP CONSP _ ea -&gt; A eidh -&gt; EIDH eigh -&gt; EIGH ei -&gt; EE / # CONSS _ RDNLR # ei -&gt; EE / # CONSS _ RDNLR NONSYLLABIC ei -&gt; E / # CONSS _ ei -&gt; E e√≥dh -&gt; OO eoi -&gt; OO e√≥ -&gt; OO eo -&gt; OO e -&gt; E / # CONSS _ e -&gt; @@ / VOWELP CONSP _ e -&gt; E √≠odh -&gt; √çODH / _ # √≠o -&gt; II √≠ -&gt; II iadh -&gt; I@ iath -&gt; I@ iai -&gt; I@ ia -&gt; I@ idh -&gt; IDH igh -&gt; IGH io -&gt; IO ithe -&gt; ITHE / _ # i√∫i -&gt; UU i√∫ -&gt; UU iubh -&gt; UBH iumh -&gt; UU iui -&gt; UU iu -&gt; U i -&gt; ‚àÖ / # CONSS VOWEL idh _ CONSP # i -&gt; ‚àÖ / # CONSS VOWEL igh _ CONSP i -&gt; @@ / VOWELP CONSP _ i -&gt; I √≥dh -&gt; √ìDH / _ # √≥i -&gt; OO √≥ -&gt; OO obh -&gt; OBH odh -&gt; ODH ogh -&gt; OGH o√≠ -&gt; II oidh -&gt; OIDH oigh -&gt; OIGH oi -&gt; OO / # CONSS _ RDNLR oi -&gt; @@ / # VOWELP CONSP _ oi -&gt; OI omh -&gt; OMH o -&gt; OO / # CONSS _ RDNLR # o -&gt; OO / # CONSS _ RDNLR NONSYLLABIC o -&gt; O / # VOWELP CONSP _ o -&gt; O √∫i -&gt; UU √∫ -&gt; UU uath -&gt; U@ uai -&gt; U@ ua -&gt; U@ ubh -&gt; UBH ue -&gt; E ui -&gt; UU / # CONSS _ RDNLR # ui -&gt; UU / # CONSS _ RDNLR NONSYLLABIC ui -&gt; I / # CONSS _ ui -&gt; @@ / VOWELP CONSP _ ui -&gt; UI u√≠o -&gt; II u√≠ -&gt; II umh -&gt; UU u -&gt; UU / # CONSS _ RDNLR u -&gt; U / # CONSS _ u -&gt; @@ / VOWELP CONSP _ u -&gt; U bf -&gt; P / _ BFCE # bf -&gt; PJ / _ SFCE # bhf -&gt; VJ / # _ CONSS RCSV # bhf -&gt; VJ / # _ CONSS RCSV NONSYLLABIC bhf -&gt; V / # _ bhf -&gt; F / _ BFCE # bhf -&gt; FJ / _ SFCE # bh -&gt; @@ V / # LCSBV LNRP _ bh -&gt; @@ V / NONSYLLABIC LCSBV LNRP _ bh -&gt; @@ VJ / # LCSSV LNRP _ bh -&gt; @@ VJ / NONSYLLABIC LCSSV LNRP _ bh -&gt; VJ / # _ CONSS RCSV # bh -&gt; VJ / # _ CONSS RCSV NONSYLLABIC bh -&gt; V / # _ bh -&gt; VJ / _ CONSS RCSV # bh -&gt; VJ / _ CONSS RCSV NONSYLLABIC bh -&gt; VJ / # LCSV CONSP _ bh -&gt; VJ / NONSYLLABIC LCSV CONSP _ bh -&gt; VJ / # LCSV _ bh -&gt; VJ / NONSYLLABIC LCSV _ bh -&gt; V bp -&gt; BJ / # _ CONSS RCSV # bp -&gt; BJ / # _ CONSS RCSV NONSYLLABIC bp -&gt; B / # _ bth -&gt; P / LCBV CONSS _ bth -&gt; PJ / LCSV CONSS _ b -&gt; @@ B / # LCSBV LNRP _ b -&gt; @@ B / NONSYLLABIC LCSBV LNRP _ b -&gt; @@ BJ / # LCSSV LNRP _ b -&gt; @@ BJ / NONSYLLABIC LCSSV LNRP _ b -&gt; BJ / _ CONSS RCSV # b -&gt; BJ / _ CONSS RCSV NONSYLLABIC b -&gt; BJ / # LCSV CONSP _ b -&gt; BJ / NONSYLLABIC LCSV CONSP _ b -&gt; BJ / # LCSV _ b -&gt; BJ / NONSYLLABIC LCSV _ b -&gt; B cf -&gt; K / _ BFCE # cf -&gt; KJ / _ SFCE # chf -&gt; X / _ BFCE # chf -&gt; XJ / _ SFCE # ch -&gt; @@ X / # LCSBV LNRP _ ch -&gt; @@ X / NONSYLLABIC LCSBV LNRP _ ch -&gt; @@ XJ / # LCSSV LNRP _ ch -&gt; @@ XJ / NONSYLLABIC LCSSV LNRP _ ch -&gt; XJ / # _ CONSS RCSV # ch -&gt; XJ / # _ CONSS RCSV NONSYLLABIC ch -&gt; X / # _ ch -&gt; XJ / _ CONSS RCSV # ch -&gt; XJ / _ CONSS RCSV NONSYLLABIC ch -&gt; XJ / # LCSV CONSP _ ch -&gt; XJ / NONSYLLABIC LCSV CONSP _ ch -&gt; XJ / # LCSV _ ch -&gt; XJ / NONSYLLABIC LCSV _ ch -&gt; X cth -&gt; K / LCBV CONSS _ cth -&gt; KJ / LCSV CONSS _ c -&gt; KJ / _ CONSS RCSV # c -&gt; KJ / _ CONSS RCSV NONSYLLABIC c -&gt; KJ / # LCSV CONSP _ c -&gt; KJ / NONSYLLABIC LCSV CONSP _ c -&gt; KJ / # LCSV _ c -&gt; KJ / NONSYLLABIC LCSV _ c -&gt; K df -&gt; T / _ BFCE # df -&gt; TJ / _ SFCE # dha -&gt; ‚àÖ / # LCLV _ dha -&gt; ‚àÖ / NONSYLLABIC LCLV _ dh -&gt; GFJ / # LCSLV _ dh -&gt; GFJ / NONSYLLABIC LCSLV _ dh -&gt; GFJ / # CONSS LCSVS _ # dh -&gt; ‚àÖ / # LCLV _ dh -&gt; ‚àÖ / NONSYLLABIC LCLV _ dh -&gt; GFJ / # _ CONSS RCSV # dh -&gt; GFJ / # _ CONSS RCSV NONSYLLABIC dh -&gt; GF / # _ dh -&gt; GFJ / _ CONSS RCSV # dh -&gt; GFJ / _ CONSS RCSV NONSYLLABIC dh -&gt; GFJ / # LCSV CONSP _ dh -&gt; GFJ / NONSYLLABIC LCSV CONSP _ dh -&gt; GFJ / # LCSV _ dh -&gt; GFJ / NONSYLLABIC LCSV _ dh -&gt; GF dt -&gt; DJ / # _ CONSS RCSV # dt -&gt; DJ / # _ CONSS RCSV NONSYLLABIC dt -&gt; D / # _ dt -&gt; T / LCBV CONSS _ dt -&gt; TJ / LCSV CONSS _ d -&gt; DJ / _ CONSS RCSV # d -&gt; DJ / _ CONSS RCSV NONSYLLABIC d -&gt; DJ / # LCSV CONSP _ d -&gt; DJ / NONSYLLABIC LCSV CONSP _ d -&gt; DJ / # LCSV _ d -&gt; DJ / NONSYLLABIC LCSV _ d -&gt; D fh -&gt; ‚àÖ f -&gt; H / VOWEL _ BFCE # f -&gt; HJ / VOWEL _ SFCE # f -&gt; @@ F / # LCSBV LNRP _ f -&gt; @@ F / NONSYLLABIC LCSBV LNRP _ f -&gt; @@ FJ / # LCSSV LNRP _ f -&gt; @@ FJ / NONSYLLABIC LCSSV LNRP _ f -&gt; FJ / _ CONSS RCSV # f -&gt; FJ / _ CONSS RCSV NONSYLLABIC f -&gt; FJ / # LCSV CONSP _ f -&gt; FJ / NONSYLLABIC LCSV CONSP _ f -&gt; FJ / # LCSV _ f -&gt; FJ / NONSYLLABIC LCSV _ f -&gt; F gc -&gt; GJ / # _ CONSS RCSV # gc -&gt; GJ / # _ CONSS RCSV NONSYLLABIC gc -&gt; G / # _ gf -&gt; K / _ BFCE # gf -&gt; KJ / _ SFCE # gh -&gt; GFJ / # _ CONSS RCSV # gh -&gt; GFJ / # _ CONSS RCSV NONSYLLABIC gh -&gt; GF / # _ gh -&gt; GFJ / # LCSLV _ gh -&gt; GFJ / NONSYLLABIC LCSLV _ gh -&gt; GFJ / # CONSS LCSVS _ # gh -&gt; ‚àÖ / # LCLV _ gh -&gt; ‚àÖ / NONSYLLABIC LCLV _ gh -&gt; GFJ / _ CONSS RCSV # gh -&gt; GFJ / _ CONSS RCSV NONSYLLABIC gh -&gt; GFJ / # LCSV CONSP _ gh -&gt; GFJ / NONSYLLABIC LCSV CONSP _ gh -&gt; GFJ / # LCSV _ gh -&gt; GFJ / NONSYLLABIC LCSV _ gh -&gt; GF gth -&gt; K / LCBV CONSS _ gth -&gt; KJ / LCSV CONSS _ g -&gt; @@ G / # LCSBV LNRP _ g -&gt; @@ G / NONSYLLABIC LCSBV LNRP _ g -&gt; @@ GJ / # LCSSV LNRP _ g -&gt; @@ GJ / NONSYLLABIC LCSSV LNRP _ g -&gt; GJ / _ CONSS RCSV # g -&gt; GJ / _ CONSS RCSV NONSYLLABIC g -&gt; GJ / # LCSV CONSP _ g -&gt; GJ / NONSYLLABIC LCSV CONSP _ g -&gt; GJ / # LCSV _ g -&gt; GJ / NONSYLLABIC LCSV _ g -&gt; G h -&gt; HJ / _ CONSS RCSV # h -&gt; HJ / _ CONSS RCSV NONSYLLABIC h -&gt; HJ / # LCSV CONSP _ h -&gt; HJ / NONSYLLABIC LCSV CONSP _ h -&gt; HJ / # LCSV _ h -&gt; HJ / NONSYLLABIC LCSV _ h -&gt; H j -&gt; DJZJ k -&gt; KJ / _ CONSS RCSV # k -&gt; KJ / _ CONSS RCSV NONSYLLABIC k -&gt; KJ / # LCSV CONSP _ k -&gt; KJ / NONSYLLABIC LCSV CONSP _ k -&gt; KJ / # LCSV _ k -&gt; KJ / NONSYLLABIC LCSV _ k -&gt; K llf -&gt; LL_D / _ BFCE # llf -&gt; LLJ_D / _ SFCE # llth -&gt; LL_D / LCBV CONSS _ llth -&gt; LLJ_D / LCSV CONSS _ ll -&gt; LLJ / _ CONSS RCSV # ll -&gt; LLJ / _ CONSS RCSV NONSYLLABIC ll -&gt; LLJ / # LCSV CONSP _ ll -&gt; LLJ / NONSYLLABIC LCSV CONSP _ ll -&gt; LLJ / # LCSV _ ll -&gt; LLJ / NONSYLLABIC LCSV _ ll -&gt; LL lf -&gt; LL_D / _ BFCE # lf -&gt; LJ_D / _ SFCE # lth -&gt; LL_D / LCBV CONSS _ lth -&gt; LJ_D / LCSV CONSS _ l -&gt; LJ / _ CONSS RCSV # l -&gt; LJ / _ CONSS RCSV NONSYLLABIC l -&gt; LJ / # LCSV CONSP _ l -&gt; LJ / NONSYLLABIC LCSV CONSP _ l -&gt; LJ / # LCSV _ l -&gt; LJ / NONSYLLABIC LCSV _ l -&gt; LL mb -&gt; MJ / # _ CONSS RCSV # mb -&gt; MJ / # _ CONSS RCSV NONSYLLABIC mb -&gt; M / # _ mf -&gt; M_D / _ BFCE # mf -&gt; MJ_D / _ SFCE # mhf -&gt; F / _ BFCE # mhf -&gt; FJ / _ SFCE # mh -&gt; VJ / # _ CONSS RCSV # mh -&gt; VJ / # _ CONSS RCSV NONSYLLABIC mh -&gt; V / # _ mh -&gt; @@ V / # LCSBV LNRP _ mh -&gt; @@ V / NONSYLLABIC LCSBV LNRP _ mh -&gt; @@ VJ / # LCSSV LNRP _ mh -&gt; @@ VJ / NONSYLLABIC LCSSV LNRP _ mh -&gt; VJ / _ CONSS RCSV # mh -&gt; VJ / _ CONSS RCSV NONSYLLABIC mh -&gt; VJ / # LCSV CONSP _ mh -&gt; VJ / NONSYLLABIC LCSV CONSP _ mh -&gt; VJ / # LCSV _ mh -&gt; VJ / NONSYLLABIC LCSV _ mh -&gt; V mth -&gt; M_D / LCBV CONSS _ mth -&gt; MJ_D / LCSV CONSS _ m -&gt; @@ M / # LCSBV LNRP _ m -&gt; @@ M / NONSYLLABIC LCSBV LNRP _ m -&gt; @@ MJ / # LCSSV LNRP _ m -&gt; @@ MJ / NONSYLLABIC LCSSV LNRP _ m -&gt; MJ / _ CONSS RCSV # m -&gt; MJ / _ CONSS RCSV NONSYLLABIC m -&gt; MJ / # LCSV CONSP _ m -&gt; MJ / NONSYLLABIC LCSV CONSP _ m -&gt; MJ / # LCSV _ m -&gt; MJ / NONSYLLABIC LCSV _ m -&gt; M nnf -&gt; NN_D / _ BFCE # nnf -&gt; NNJ_D / _ SFCE # nnth -&gt; NN_D / LCBV CONSS _ nnth -&gt; NNJ_D / LCSV CONSS _ nn -&gt; NNJ / _ CONSS RCSV # nn -&gt; NNJ / _ CONSS RCSV NONSYLLABIC nn -&gt; NNJ / # LCSV CONSP _ nn -&gt; NNJ / NONSYLLABIC LCSV CONSP _ nn -&gt; NNJ / # LCSV _ nn -&gt; NNJ / NONSYLLABIC LCSV _ nn -&gt; NN n- -&gt; NJ / # _ RCSV # n- -&gt; NJ / # _ RCSV NONSYLLABIC n- -&gt; NN / # _ nd -&gt; NNJ / # _ CONSS RCSV # nd -&gt; NNJ / # _ CONSS RCSV NONSYLLABIC nd -&gt; NN / # _ nf -&gt; NN_D / _ BFCE # nf -&gt; NJ_D / _ SFCE # ngf -&gt; NG_D / _ BFCE # ngf -&gt; NGJ_D / _ SFCE # ngth -&gt; NG_D / LCBV CONSS _ ngth -&gt; NGJ_D / LCSV CONSS _ ng -&gt; NGJ / # _ CONSS RCSV # ng -&gt; NGJ / # _ CONSS RCSV NONSYLLABIC ng -&gt; NG / # _ ng -&gt; NJ / # LCSV _ t # ng -&gt; NJ / NONSYLLABIC LCSV _ t # ng -&gt; NGJ / _ CONSS RCSV # ng -&gt; NGJ / _ CONSS RCSV NONSYLLABIC ng -&gt; NGJ / # LCSV CONSP _ ng -&gt; NGJ / NONSYLLABIC LCSV CONSP _ ng -&gt; NGJ / # LCSV _ ng -&gt; NGJ / NONSYLLABIC LCSV _ ng -&gt; NG nth -&gt; NN_D / LCBV CONSS _ nth -&gt; NJ_D / LCSV CONSS _ n -&gt; NGJ / # LCSV _ c n -&gt; NGJ / NONSYLLABIC LCSV _ c n -&gt; NG / _ c n -&gt; NJ / _ CONSS RCSV # n -&gt; NJ / _ CONSS RCSV NONSYLLABIC n -&gt; NJ / # LCSV CONSP _ n -&gt; NJ / NONSYLLABIC LCSV CONSP _ n -&gt; NJ / # LCSV _ n -&gt; NJ / NONSYLLABIC LCSV _ n -&gt; NN pf -&gt; P / _ BFCE # pf -&gt; PJ / _ SFCE # ph -&gt; FJ / # _ CONSS RCSV # ph -&gt; FJ / # _ CONSS RCSV NONSYLLABIC ph -&gt; F / # _ ph -&gt; FJ / _ CONSS RCSV # ph -&gt; FJ / _ CONSS RCSV NONSYLLABIC ph -&gt; FJ / # LCSV CONSP _ ph -&gt; FJ / NONSYLLABIC LCSV CONSP _ ph -&gt; FJ / # LCSV _ ph -&gt; FJ / NONSYLLABIC LCSV _ ph -&gt; F pth -&gt; P / LCBV CONSS _ pth -&gt; PJ / LCSV CONSS _ p -&gt; PJ / _ CONSS RCSV # p -&gt; PJ / _ CONSS RCSV NONSYLLABIC p -&gt; PJ / # LCSV CONSP _ p -&gt; PJ / NONSYLLABIC LCSV CONSP _ p -&gt; PJ / # LCSV _ p -&gt; PJ / NONSYLLABIC LCSV _ p -&gt; P # really? there&#39;s a &#39;W&#39; in the phoneset q -&gt; K V rrf -&gt; RR_D / _ BFCE # rrf -&gt; RRJ_D / _ SFCE # rrth -&gt; RR_D / LCBV CONSS _ rrth -&gt; RRJ_D / LCSV CONSS _ rr -&gt; RRJ / _ CONSS RCSV # rr -&gt; RRJ / _ CONSS RCSV NONSYLLABIC rr -&gt; RRJ / # LCSV CONSP _ rr -&gt; RRJ / NONSYLLABIC LCSV CONSP _ rr -&gt; RRJ / # LCSV _ rr -&gt; RRJ / NONSYLLABIC LCSV _ rr -&gt; RR rf -&gt; R_D / _ BFCE # rf -&gt; RJ_D / _ SFCE # rth -&gt; R_D / LCBV CONSS _ rth -&gt; RJ_D / LCSV CONSS _ r -&gt; R / # s _ r -&gt; R / # _ // This rule blocks tests for airde and ceird r -&gt; R / _ DNLST r -&gt; RJ / _ CONSS RCSV # r -&gt; RJ / _ CONSS RCSV NONSYLLABIC r -&gt; RJ / # LCSV CONSP _ r -&gt; RJ / NONSYLLABIC LCSV CONSP _ r -&gt; RJ / # LCSV _ r -&gt; RJ / NONSYLLABIC LCSV _ r -&gt; R sf -&gt; S / _ BFCE # sf -&gt; SJ / _ SFCE # shl -&gt; LJ_D / _ CONSS RCSV # shl -&gt; LJ_D / _ CONSS RCSV NONSYLLABIC shl -&gt; LL_D shm -&gt; MJ_D / _ CONSS RCSV # shm -&gt; MJ_D / _ CONSS RCSV NONSYLLABIC shm -&gt; M_D shn -&gt; NJ_D / _ CONSS RCSV # shn -&gt; NJ_D / _ CONSS RCSV NONSYLLABIC shn -&gt; NN_D shr -&gt; RJ_D / _ CONSS RCSV # shr -&gt; RJ_D / _ CONSS RCSV NONSYLLABIC shr -&gt; R_D sh -&gt; XJ / # _ CONSS RCSV # sh -&gt; XJ / # _ CONSS RCSV NONSYLLABIC sh -&gt; H / # _ sh -&gt; XJ / _ CONSS RCSV # sh -&gt; XJ / _ CONSS RCSV NONSYLLABIC sh -&gt; XJ / # LCSV CONSP _ sh -&gt; XJ / NONSYLLABIC LCSV CONSP _ sh -&gt; XJ / # LCSV _ sh -&gt; XJ / NONSYLLABIC LCSV _ sh -&gt; H s -&gt; S / # _ r s -&gt; S / # _ FMP CONSS RCSV # s -&gt; S / # _ FMP CONSS RCSV NONSYLLABIC s -&gt; SJ / _ CONSS RCSV # s -&gt; SJ / _ CONSS RCSV NONSYLLABIC s -&gt; SJ / # LCSV CONSP _ s -&gt; SJ / NONSYLLABIC LCSV CONSP _ s -&gt; SJ / # LCSV _ s -&gt; SJ / NONSYLLABIC LCSV _ s -&gt; S t- -&gt; TJ / # _ RCSV # t- -&gt; TJ / # _ RCSV NONSYLLABIC t- -&gt; T / # _ tf -&gt; T / _ BFCE # tf -&gt; TJ / _ SFCE # // &quot;hack for compound boundaries&quot; th -&gt; ‚àÖ / _ CONS h thb -&gt; PJ / _ CONSS RCSV # thb -&gt; PJ / _ CONSS RCSV NONSYLLABIC thb -&gt; P thc -&gt; KJ / _ CONSS RCSV # thc -&gt; KJ / _ CONSS RCSV NONSYLLABIC thc -&gt; K thd -&gt; TJ / _ CONSS RCSV # thd -&gt; TJ / _ CONSS RCSV NONSYLLABIC thd -&gt; T thf -&gt; H / _ BFCE # thf -&gt; XJ / _ SFCE # thl -&gt; LJ_D / _ CONSS RCSV # thl -&gt; LJ_D / _ CONSS RCSV NONSYLLABIC thl -&gt; LL_D thm -&gt; MJ_D / _ CONSS RCSV # thm -&gt; MJ_D / _ CONSS RCSV NONSYLLABIC thm -&gt; M_D thn -&gt; NJ_D / _ CONSS RCSV # thn -&gt; NJ_D / _ CONSS RCSV NONSYLLABIC thn -&gt; NN_D thp -&gt; PJ / _ CONSS RCSV # thp -&gt; PJ / _ CONSS RCSV NONSYLLABIC thp -&gt; P thr -&gt; RJ_D / _ CONSS RCSV # thr -&gt; RJ_D / _ CONSS RCSV NONSYLLABIC thr -&gt; R_D ths -&gt; SJ / _ CONSS RCSV # ths -&gt; SJ / _ CONSS RCSV NONSYLLABIC ths -&gt; S tht -&gt; TJ / _ CONSS RCSV # tht -&gt; TJ / _ CONSS RCSV NONSYLLABIC tht -&gt; T th -&gt; HJ / # _ CONSS RCSV # th -&gt; HJ / # _ CONSS RCSV NONSYLLABIC th -&gt; H / # _ th -&gt; HJ / _ CONSS RCSV # th -&gt; HJ / _ CONSS RCSV NONSYLLABIC th -&gt; HJ / # LCSV CONSP _ th -&gt; HJ / NONSYLLABIC LCSV CONSP _ th -&gt; HJ / # LCSV _ th -&gt; HJ / NONSYLLABIC LCSV _ th -&gt; H ts -&gt; TJ / # _ CONSS RCSV # ts -&gt; TJ / # _ CONSS RCSV NONSYLLABIC ts -&gt; T / # _ t -&gt; TJ / _ CONSS RCSV # t -&gt; TJ / _ CONSS RCSV NONSYLLABIC t -&gt; TJ / # LCSV CONSP _ t -&gt; TJ / NONSYLLABIC LCSV CONSP _ t -&gt; TJ / # LCSV _ t -&gt; TJ / NONSYLLABIC LCSV _ t -&gt; T v -&gt; VJ / _ CONSS RCSV # v -&gt; VJ / _ CONSS RCSV NONSYLLABIC v -&gt; VJ / # LCSV CONSP _ v -&gt; VJ / NONSYLLABIC LCSV CONSP _ v -&gt; VJ / # LCSV _ v -&gt; VJ / NONSYLLABIC LCSV _ v -&gt; V w -&gt; V x- -&gt; E KJ S x -&gt; ZJ y -&gt; GFJ z -&gt; ZJ / _ CONSS RCSV # z -&gt; ZJ / _ CONSS RCSV NONSYLLABIC z -&gt; ZJ / # LCSV CONSP _ z -&gt; ZJ / NONSYLLABIC LCSV CONSP _ z -&gt; ZJ / # LCSV _ z -&gt; ZJ / NONSYLLABIC LCSV _ z -&gt; Z &#39; -&gt; ‚àÖ ‚Äô -&gt; ‚àÖ - -&gt; ‚àÖ TEST √°dh -&gt; AA TEST √°iseanna -&gt; AA SJ @@ NN @@ TEST √°thas -&gt; AA H @@ S TEST abhainn -&gt; ABH NNJ TEST bualadh -&gt; B U@ LL ADH TEST sadhbh -&gt; S AI V TEST saghas -&gt; S AI S TEST gaeilge -&gt; G EE LJ GJ @@ TEST saola√≠odh -&gt; S AO LL √çODH TEST garda√≠ -&gt; G AA R D II TEST d√∫nfaidh -&gt; D UU NN_D IDH TEST aidhm -&gt; AI MJ TEST cheadaigh -&gt; XJ A D IGH TEST aighneas -&gt; AI NJ @@ S TEST di√∫ltaithe -&gt; DJ UU LL T ITHE TEST seabhaic -&gt; SJ ABH KJ TEST feadhain -&gt; FJ AU NJ TEST teaghais -&gt; TJ AI SJ TEST eamhain -&gt; AU NJ TEST lobhair -&gt; LL OBH RJ TEST le√≥dhais -&gt; LJ OO SJ TEST bodhair -&gt; B ODH RJ TEST eoghain -&gt; OO NJ TEST broghais -&gt; B R OGH SJ TEST comhair -&gt; K OO RJ TEST ciumhais -&gt; KJ UU SJ # wiktionary has: Àà…ëÀê…æÀ†d ≤…ô ÀàiÀê…æÀ†d ≤…ô Àà…ëÀê…æÀ†d ≤…ô Ààai…æ ≤d ≤…ô Àà√¶Àê…æÀ†d ≤…ô Àà å…æÀ†d ≤…ô, so rule seems right #TEST airde -&gt; AA RJ DJ @@ TEST airde -&gt; AA R DJ @@ TEST cait -&gt; K A TJ TEST sodair -&gt; S O D @@ RJ TEST ait -&gt; A TJ TEST d√©anamh -&gt; DJ EE NN AMH TEST amharc -&gt; AU R K TEST gaoil -&gt; G AO LJ TEST gaol -&gt; G AO LL TEST seabhac -&gt; SJ ABH K TEST ceadharlach -&gt; KJ AU R LL @@ X TEST teaghas√°n -&gt; TJ AI S AA NN TEST lobhar -&gt; LL OBH R TEST le√≥dhas -&gt; LJ OO S TEST bodhar -&gt; B ODH R TEST eoghan -&gt; OO NN TEST bogha -&gt; B OGH TEST comhar -&gt; K OO R TEST dumhach -&gt; D UU X TEST ard -&gt; AA R D TEST cat -&gt; K A T TEST sodar -&gt; S O D @@ R TEST at -&gt; A T TEST √©an -&gt; EE NN TEST √©in√≠n√≠ -&gt; EE NJ II NJ II TEST √© -&gt; EE TEST she√°in -&gt; XJ AA NJ TEST se√°n -&gt; SJ AA NN TEST seabhac -&gt; SJ ABH K TEST seinneadh -&gt; SJ E NNJ ADH TEST ceadharlach -&gt; KJ AU R LL @@ X TEST teaghlach -&gt; TJ AI LL @@ X TEST beairic -&gt; BJ A RJ @@ KJ TEST √°ireamh -&gt; AA RJ AMH TEST sleamhn√°n -&gt; SJ LJ AU NN AA NN TEST oighear -&gt; OIGH R TEST ceard -&gt; KJ AA R D TEST cead -&gt; KJ A D TEST √°ireamh√°n -&gt; AA RJ @@ V AA NN TEST eas -&gt; A S TEST feidhm -&gt; FJ EIDH MJ TEST leigheas -&gt; LJ EIGH S # wiktionary gives c…ôi…æÀ†d ≤ and c…™…æÀ†d ≤; the rule seems right #TEST ceird -&gt; KJ EE RJ DJ TEST ceird -&gt; KJ EE R DJ TEST deis -&gt; DJ E SJ TEST eitpheil -&gt; E TJ FJ E LJ TEST ceoil -&gt; KJ OO LJ TEST bainse√≥ -&gt; B A NJ SJ OO TEST ceol -&gt; KJ OO LL TEST uile -&gt; I LJ @@ TEST ceanna√≠odh -&gt; KJ A NN √çODH TEST s√≠os -&gt; SJ II S TEST s√≠ -&gt; SJ II TEST siadhail -&gt; SJ I@ LJ TEST sciath -&gt; SJ KJ I@ #TEST riail -&gt; RJ I@ LJ TEST riail -&gt; R I@ LJ TEST siad -&gt; SJ I@ D TEST seinnfidh -&gt; SJ E NNJ_D IDH TEST cheannaigh -&gt; XJ A NN IGH TEST fios -&gt; FJ IO S TEST imithe -&gt; I MJ ITHE TEST si√∫il -&gt; SJ UU LJ TEST si√∫l -&gt; SJ UU LL TEST tiubh -&gt; TJ UBH TEST ciumhais -&gt; KJ UU SJ #TEST giuirl√©id -&gt; GJ UU RJ LJ EE DJ TEST giuirl√©id -&gt; GJ UU R LJ EE DJ TEST fiuch -&gt; FJ U X TEST leighis -&gt; LJ EIGH SJ TEST foighid -&gt; F OIGH DJ TEST aithris -&gt; A RJ_D @@ SJ TEST sin -&gt; SJ I NJ TEST cheann√≥dh -&gt; XJ A NN √ìDH TEST √≥il -&gt; OO LJ TEST √≥l -&gt; OO LL TEST lobhadh -&gt; LL OBH ADH TEST todhcha√≠ -&gt; T ODH X II TEST toghadh -&gt; T OGH ADH TEST o√≠che -&gt; II XJ @@ TEST oidhe -&gt; OIDH @@ TEST oighear -&gt; OIGH R #TEST boird -&gt; B OO RJ DJ TEST boird -&gt; B OO R DJ TEST soir -&gt; S OI RJ TEST comhar -&gt; K OO R TEST bord -&gt; B OO R D TEST bos -&gt; B O S TEST s√∫il -&gt; S UU LJ TEST s√∫l -&gt; S UU LL TEST uath√∫il -&gt; U@ UU LJ TEST uaine -&gt; U@ NJ @@ TEST uan -&gt; U@ NN TEST subh -&gt; S UBH // not LJ ? TEST bhuel -&gt; V E LL #TEST guird -&gt; G UU RJ DJ TEST guird -&gt; G UU R DJ TEST cuid -&gt; K I DJ TEST uile -&gt; I LJ @@ TEST bru√≠on -&gt; B R II NN TEST bru√≠ne -&gt; B R II NJ @@ TEST cumhacht -&gt; K UU X T TEST burd√∫n -&gt; B UU R D UU NN TEST cur -&gt; K U R TEST bus -&gt; B U S TEST scuabfaidh -&gt; S K U@ P IDH TEST clibfidh -&gt; KJ LJ I PJ IDH TEST scuabfadh -&gt; S K U@ P ADH TEST clibfeadh -&gt; KJ LJ I PJ ADH TEST bhf√°inne -&gt; V AA NNJ @@ TEST bhfianaise -&gt; VJ I@ NN @@ SJ @@ TEST scr√≠obhfaidh -&gt; SJ KJ RJ II F IDH TEST d√≠bhfidh -&gt; DJ II FJ IDH TEST scr√≠obhfadh -&gt; SJ KJ RJ II F ADH TEST d√≠bhfeadh -&gt; DJ II FJ ADH TEST searbh -&gt; SJ A R @@ V TEST seirbh√≠s -&gt; SJ E RJ @@ VJ II SJ TEST bhrostaigh -&gt; V R O S T IGH TEST bhris -&gt; VJ RJ I SJ TEST coibh√≠n -&gt; K OI VJ II NJ TEST bp√°ist√≠ -&gt; B AA SJ TJ II TEST bp√©isteanna -&gt; BJ EE SJ TJ @@ NN @@ TEST scuabtha -&gt; S K U@ P @@ TEST clibthe -&gt; KJ LJ I PJ @@ TEST borb -&gt; B O R @@ B TEST seirbiach -&gt; SJ E RJ @@ BJ I@ X TEST br√≥na -&gt; B R OO NN @@ TEST brian -&gt; BJ RJ I@ NN TEST le√≥dhas -&gt; LJ OO S TEST t-uisce -&gt; T UI SJ KJ @@ TEST t-√©abhl√≥id√≠ -&gt; TJ EE V LL OO DJ II TEST atfaidh -&gt; A T IDH TEST titfidh -&gt; TJ I TJ IDH TEST athdh√©anamh -&gt; A GFJ EE NN AMH TEST meathfadh -&gt; MJ A H ADH #TEST rithfeadh -&gt; RJ I XJ ADH TEST rithfeadh -&gt; R I XJ ADH TEST bl√°thra -&gt; B LL AA R_D @@ TEST tharla -&gt; H AA R LL @@ TEST thit -&gt; HJ I TJ TEST tseachtain -&gt; TJ A X T @@ NJ #TEST tsagairt -&gt; T A G @@ RJ TJ # wiktionary (sagairt): ÀàsÀ†a…°…ô…æÀ†t ≤ ÀàsÀ†√¶…°…ô…æÀ†t ≤ TEST tsagairt -&gt; T A G @@ R TJ TEST teann -&gt; TJ A NN TEST tit -&gt; TJ I TJ TEST togra -&gt; T O G R @@ TEST sadhbh -&gt; S AI V # disabled; the rule for &#39;o&#39; in an unaccented syllable # does not produce schwa; also, &#39;leathbhosca&#39; is a compound; # the &#39;o&#39; should not be reduced #TEST leathbhosca -&gt; LJ A V @@ S K @@ #TEST bantaboic -&gt; B A NN T @@ B @@ KJ #TEST bantaboc -&gt; B A NN T @@ B @@ K TEST bh√©al -&gt; VJ EE LL TEST bh√©il -&gt; VJ EE LJ .",
            "url": "https://jimregan.github.io/notes/irish/g2p/2021/05/16/o-raghallaigh-thesis-attempt-1.html",
            "relUrl": "/irish/g2p/2021/05/16/o-raghallaigh-thesis-attempt-1.html",
            "date": " ‚Ä¢ May 16, 2021"
        }
        
    
  
    
        ,"post16": {
            "title": "Extract pre-built Kaldi on Kaggle",
            "content": "Original here . %cd /tmp . /tmp . !git clone https://github.com/jjlin/docker-image-extract/ . !docker-image-extract/docker-image-extract kaldiasr/kaldi:gpu-latest . Getting API token... Getting image manifest for kaldiasr/kaldi:gpu-latest... Fetching and extracting layer 976a760c94fcdd7d105269ae621e8269e7bb25a58c52ae667b4029a6bc7e33cb... Fetching and extracting layer c58992f3c37bb64aeba18910408cda9a7a63e212fe27e95065a8d54130ca5926... Fetching and extracting layer 0ca0e5e7f12e6eb512246aea5579fcb771fe7203bc60944384d5cd7962f87ddb... Fetching and extracting layer f2a274cc00ca5f671b1740c43672dbc96504760cee585e7604029a3fe56854a8... Fetching and extracting layer 708a53113e13a385afdeddfe409f4b7b71e65b1e5cff48ba33906c8803e19808... Fetching and extracting layer 465b2edc87fbc8c5fb06541c382eefd1edbfcac71521273855dbe0841a5aaf4a... Fetching and extracting layer 4189f57a58ef61e7e283534fb6d0dd4b2b818a037d82c0e1a2994cea35b01883... Fetching and extracting layer 35de2d1091bb82248c486931c94f18336d55dfee05d32d549305626c2e54ca82... Fetching and extracting layer 719d77537fdce03bba6ed02fcbc2e4b84d58906af53a95102326d7aa290549bf... Fetching and extracting layer 3745e7bcc1b3b7ef8b9afe38e20019cdd052d2ed5fa6b32f063e693620179f90... Fetching and extracting layer d990bd9da1ddb55d091b2fcc12a80dc7d3b04e1ba14c2e79f6e0ec9f487773fe... Fetching and extracting layer 15f2cb6c17ae91014b292d6db2438f202e2fb2f9527cb6730f5a38f639526641... Fetching and extracting layer d3305c2a9a9794962ae8183ae36e93f656f290fcec1216407bf4f417e09e512b... Image contents extracted into ./output. . %cd output/opt/ . /tmp/output/opt . import os os.environ[&#39;LD_LIBRARY_PATH&#39;] = &#39;/opt/conda/lib:/opt/kaldi/tools/openfst-1.6.7/lib:/opt/kaldi/src/lib&#39; . %pushd kaldi/tools !bash extras/install_phonetisaurus.sh %popd . !tar cvf /kaggle/working/kaldi.tar kaldi/ .",
            "url": "https://jimregan.github.io/notes/kaggle/kaldi/wav2vec-u/2021/05/15/extract-prebuilt-kaldi-from-docker.html",
            "relUrl": "/kaggle/kaldi/wav2vec-u/2021/05/15/extract-prebuilt-kaldi-from-docker.html",
            "date": " ‚Ä¢ May 15, 2021"
        }
        
    
  
    
        ,"post17": {
            "title": "Azure ASR's JSONL output to JSON",
            "content": "import glob import json for i in glob.glob(&#39;../input/mo-sgeal-fein-wikisource-azure-asr-output/*.jsonl&#39;): outf = i.replace(&#39;jsonl&#39;, &#39;json&#39;).split(&#39;/&#39;)[-1] with open(i) as f: curfile = [] for line in f.readlines(): cur = {} json_data = json.loads(line) cur[&#39;start&#39;] = json_data[&#39;Offset&#39;] cur[&#39;duration&#39;] = json_data[&#39;Duration&#39;] cur[&#39;text&#39;] = json_data[&#39;NBest&#39;][0][&#39;Lexical&#39;] curfile.append(cur) with open(outf, &#39;w&#39;) as of: json.dump(curfile, of) .",
            "url": "https://jimregan.github.io/notes/azure/irish/asr/2021/05/04/msf-azure-jsonl-to-json.html",
            "relUrl": "/azure/irish/asr/2021/05/04/msf-azure-jsonl-to-json.html",
            "date": " ‚Ä¢ May 4, 2021"
        }
        
    
  
    
        ,"post18": {
            "title": "Azure speech recognition for Irish",
            "content": "%%capture !pip install azure-cognitiveservices-speech . %%capture !pip install youtube-dl . %%capture !youtube-dl https://www.youtube.com/watch?v=cfjdfaqWY3Y . %%capture !ffmpeg -i C√∫la4 Ar Scoil _ √Åbhar - Mata _ T√©ama - Bia-cfjdfaqWY3Y.mkv -acodec pcm_s16le -ac 1 -ar 16000 cfjdfaqWY3Y.wav . import IPython IPython.display.Audio(&#39;/content/cfjdfaqWY3Y.wav&#39;) . import azure.cognitiveservices.speech as speechsdk . Use either Key1 or Key2 (on Azure Portal, in &quot;Keys and Endpoints&quot; from the menu on the left hand side of the screen). . _SUBS=&#39;&#39; . _LOC=&#39;westeurope&#39; . speech_config = speechsdk.SpeechConfig(region=_LOC, subscription=_SUBS) . audio_input=speechsdk.audio.AudioConfig(filename=&#39;cfjdfaqWY3Y.wav&#39;) . speech_config.speech_recognition_language = &#39;ga-IE&#39; speech_config.request_word_level_timestamps() speech_config.output_format = speechsdk.OutputFormat(1) speech_config.endpoint_id=&#39;https://westeurope.api.cognitive.microsoft.com/sts/v1.0/issuetoken&#39; . speech_config.set_property(speechsdk.PropertyId.Speech_LogFilename, &quot;azure.log&quot;) . # Copyright (c) Microsoft. All rights reserved. # Licensed under the MIT license. See LICENSE.md file in the project root for full license information. import time def speech_recognize_continuous_from_file(speech_config, audio_config): &quot;&quot;&quot;performs continuous speech recognition with input from an audio file&quot;&quot;&quot; speech_config = speech_config audio_config = audio_config speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, language=&#39;ga-IE&#39;, audio_config=audio_config) done = False def stop_cb(evt): &quot;&quot;&quot;callback that signals to stop continuous recognition upon receiving an event `evt`&quot;&quot;&quot; print(&#39;CLOSING on {}&#39;.format(evt)) nonlocal done done = True def cancelled(evt): result = evt.result cancellation_details = result.cancellation_details print(&quot;Speech Recognition canceled: {}&quot;.format(cancellation_details.reason)) if cancellation_details.reason == speechsdk.CancellationReason.Error: print(&quot;Error details: {}&quot;.format(cancellation_details.error_details)) # Connect callbacks to the events fired by the speech recognizer speech_recognizer.recognizing.connect(lambda evt: print(&#39;RECOGNIZING: {}&#39;.format(evt))) speech_recognizer.recognized.connect(lambda evt: print(&#39;RECOGNIZED: {}&#39;.format(evt))) speech_recognizer.session_started.connect(lambda evt: print(&#39;SESSION STARTED: {}&#39;.format(evt))) speech_recognizer.session_stopped.connect(lambda evt: print(&#39;SESSION STOPPED {}&#39;.format(evt))) speech_recognizer.canceled.connect(cancelled) # stop continuous recognition on either session stopped or canceled events speech_recognizer.session_stopped.connect(stop_cb) speech_recognizer.canceled.connect(stop_cb) # Start continuous speech recognition speech_recognizer.start_continuous_recognition() while not done: time.sleep(.5) speech_recognizer.stop_continuous_recognition() . speech_recognize_continuous_from_file(speech_config, audio_input) . Debugging with curl . !curl -v -X POST &quot;https://{_LOC}.api.cognitive.microsoft.com/sts/v1.0/issueToken&quot; -H &quot;Ocp-Apim-Subscription-Key: {_SUBS}&quot; -H &quot;Content-type: application/x-www-form-urlencoded&quot; -H &quot;Content-Length: 0&quot; . _TOK=&#39;&#39; . !curl -v -X POST &quot;https://{_LOC}.stt.speech.microsoft.com/speech/recognition/interactive/cognitiveservices/v1?language=ga-IE&quot; -H &quot;Authorization: Bearer {_TOK}&quot; -H &quot;Transfer-Encoding: chunked&quot; -H &quot;Content-type: audio/wav; codec=audio/pcm; samplerate=16000&quot; --data-binary @cfjdfaqWY3Y.wav . Next step, get at the innards (TODO) . transcript_display_list = [] transcript_ITN_list = [] confidence_list = [] words = [] def parse_azure_result(evt): import json response = json.loads(evt.result.json) transcript_display_list.append(response[&#39;DisplayText&#39;]) confidence_list_temp = [item.get(&#39;Confidence&#39;) for item in response[&#39;NBest&#39;]] max_confidence_index = confidence_list_temp.index(max(confidence_list_temp)) confidence_list.append(response[&#39;NBest&#39;][max_confidence_index][&#39;Confidence&#39;]) transcript_ITN_list.append(response[&#39;NBest&#39;][max_confidence_index][&#39;ITN&#39;]) words.extend(response[&#39;NBest&#39;][max_confidence_index][&#39;Words&#39;]) logger.debug(evt) .",
            "url": "https://jimregan.github.io/notes/azure/irish/asr/2021/05/04/azure-asr-with-irish.html",
            "relUrl": "/azure/irish/asr/2021/05/04/azure-asr-with-irish.html",
            "date": " ‚Ä¢ May 4, 2021"
        }
        
    
  
    
        ,"post19": {
            "title": "Azure speech recognition for Irish, part 2",
            "content": "%%capture !pip install azure-cognitiveservices-speech !pip install youtube-dl . %%capture !youtube-dl https://www.youtube.com/watch?v=cfjdfaqWY3Y . import azure.cognitiveservices.speech as speechsdk . Use either Key1 or Key2 (on Azure Portal, in &quot;Keys and Endpoints&quot; from the menu on the left hand side of the screen). . _SUBS=input(&#39;put your subscription key here: &#39;) . _LOC=&#39;westeurope&#39; . speech_config = speechsdk.SpeechConfig(region=_LOC, subscription=_SUBS) . !wget https://upload.wikimedia.org/wikipedia/commons/6/60/MSF_chapter_3.ogg https://upload.wikimedia.org/wikipedia/commons/e/ee/MSF_chapter_4.ogg https://upload.wikimedia.org/wikipedia/commons/b/b3/MSF_chapter_5.ogg https://upload.wikimedia.org/wikipedia/commons/2/21/MSF_chapter_6.ogg https://upload.wikimedia.org/wikipedia/commons/7/71/MSF_chapter_7.ogg https://upload.wikimedia.org/wikipedia/commons/d/d5/MSF_chapter_8.ogg . !ffmpeg -i MSF_chapter_5.ogg -acodec pcm_s16le -ac 1 -ar 16000 MSF_chapter_5.wav . speech_config.speech_recognition_language = &#39;ga-IE&#39; speech_config.request_word_level_timestamps() speech_config.output_format = speechsdk.OutputFormat(1) speech_config.endpoint_id=f&#39;https://{_LOC}.api.cognitive.microsoft.com/sts/v1.0/issuetoken&#39; . # Copyright (c) Microsoft. All rights reserved. # Licensed under the MIT license. See LICENSE.md file in the project root for full license information. import time import json def speech_recognize_continuous_from_file(speech_config, filename): &quot;&quot;&quot;performs continuous speech recognition with input from an audio file&quot;&quot;&quot; speech_config = speech_config audio_config = speechsdk.audio.AudioConfig(filename=filename) outfilename = filename.replace(&#39;.wav&#39;, &#39;.json&#39;) outfile = open(outfilename, &#39;a&#39;) speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, language=&#39;ga-IE&#39;, audio_config=audio_config) done = False def stop_cb(evt): &quot;&quot;&quot;callback that signals to stop continuous recognition upon receiving an event `evt`&quot;&quot;&quot; print(&#39;CLOSING on {}&#39;.format(evt)) nonlocal done done = True def cancelled(evt): result = evt.result cancellation_details = result.cancellation_details print(&quot;Speech Recognition canceled: {}&quot;.format(cancellation_details.reason)) if cancellation_details.reason == speechsdk.CancellationReason.Error: print(&quot;Error details: {}&quot;.format(cancellation_details.error_details)) def recognised(evt): response = json.loads(evt.result.json) outfile.write(&#39;{} n&#39;.format(evt.result.json)) # Connect callbacks to the events fired by the speech recognizer speech_recognizer.recognizing.connect(lambda evt: print(&#39;RECOGNIZING: {}&#39;.format(evt))) speech_recognizer.recognized.connect(recognised) speech_recognizer.session_started.connect(lambda evt: print(&#39;SESSION STARTED: {}&#39;.format(evt))) speech_recognizer.session_stopped.connect(lambda evt: print(&#39;SESSION STOPPED {}&#39;.format(evt))) speech_recognizer.canceled.connect(cancelled) # stop continuous recognition on either session stopped or canceled events speech_recognizer.session_stopped.connect(stop_cb) speech_recognizer.canceled.connect(stop_cb) # Start continuous speech recognition speech_recognizer.start_continuous_recognition() while not done: time.sleep(.5) speech_recognizer.stop_continuous_recognition() outfile.close() . for i in &quot;345678&quot;: speech_recognize_continuous_from_file(speech_config, f&#39;MSF_chapter_{i}.wav&#39;) .",
            "url": "https://jimregan.github.io/notes/azure/irish/asr/2021/05/04/azure-asr-with-irish-part2.html",
            "relUrl": "/azure/irish/asr/2021/05/04/azure-asr-with-irish-part2.html",
            "date": " ‚Ä¢ May 4, 2021"
        }
        
    
  
    
        ,"post20": {
            "title": "Playing with auditok",
            "content": "%%capture !pip install auditok . %%capture !yes|apt install python3-pyaudio . %%capture !pip install youtube-dl . !youtube-dl https://www.youtube.com/watch?v=D44-x6PTd_Q . [youtube] D44-x6PTd_Q: Downloading webpage [youtube] D44-x6PTd_Q: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 22 [download] Destination: Sraith Picti√∫r - An Ghaeilge Seoid luachmhar-D44-x6PTd_Q.f247.webm [download] 22.7% of ~12.60MiB at 5.49MiB/s ETA 00:13[download] Got server HTTP error: HTTP Error 404: Not Found. Retrying fragment 6 (attempt 1 of 10)... [download] 100% of 15.12MiB in 00:18 [download] Destination: Sraith Picti√∫r - An Ghaeilge Seoid luachmhar-D44-x6PTd_Q.f140.m4a [download] 100% of 1.73MiB in 00:00 [ffmpeg] Merging formats into &#34;Sraith Picti√∫r - An Ghaeilge Seoid luachmhar-D44-x6PTd_Q.mkv&#34; Deleting original file Sraith Picti√∫r - An Ghaeilge Seoid luachmhar-D44-x6PTd_Q.f247.webm (pass -k to keep) Deleting original file Sraith Picti√∫r - An Ghaeilge Seoid luachmhar-D44-x6PTd_Q.f140.m4a (pass -k to keep) . import auditok input = &#39;Sraith Picti√∫r - An Ghaeilge Seoid luachmhar-D44-x6PTd_Q.mkv&#39; audio_regions = auditok.split( input, min_dur=1, max_dur=10, max_silence=0.9, energy_threshold=20 ) for i, r in enumerate(audio_regions): print(&quot;Region {i}: {r.meta.start:.3f}s -- {r.meta.end:.3f}s&quot;.format(i=i, r=r)) . Region 0: 0.300s -- 6.550s Region 1: 7.450s -- 12.950s Region 2: 13.150s -- 15.700s Region 3: 15.900s -- 19.200s Region 4: 19.350s -- 29.350s Region 5: 29.700s -- 34.200s Region 6: 34.300s -- 38.600s Region 7: 39.000s -- 43.650s Region 8: 43.700s -- 46.550s Region 9: 46.750s -- 49.500s Region 10: 49.550s -- 52.950s Region 11: 53.000s -- 56.050s Region 12: 56.250s -- 59.500s Region 13: 59.700s -- 62.550s Region 14: 63.150s -- 69.600s Region 15: 69.650s -- 73.100s Region 16: 73.400s -- 77.450s Region 17: 77.800s -- 81.150s Region 18: 81.350s -- 89.100s Region 19: 89.500s -- 92.750s Region 20: 92.950s -- 96.250s Region 21: 96.500s -- 99.600s Region 22: 99.850s -- 104.350s Region 23: 104.500s -- 108.050s . regs = auditok.load(input) regs.split_and_plot( min_dur=1, max_dur=10, max_silence=0.9, energy_threshold=20, dpi=600 ) . [AudioRegion(duration=6.250, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=5.500, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=2.550, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.300, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=10.000, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=4.500, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=4.300, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=4.650, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=2.850, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=2.750, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.400, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.050, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.250, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=2.850, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=6.450, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.450, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=4.050, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.350, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=7.750, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.250, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.300, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.100, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=4.500, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.550, sampling_rate=44100, sample_width=2, channels=2)] .",
            "url": "https://jimregan.github.io/notes/auditok/2021/05/03/playing-with-auditok.html",
            "relUrl": "/auditok/2021/05/03/playing-with-auditok.html",
            "date": " ‚Ä¢ May 3, 2021"
        }
        
    
  
    
        ,"post21": {
            "title": "rclone and Sharepoint",
            "content": "%%capture !curl https://rclone.org/install.sh |bash . curl_out=!curl --cookie -i -L &#39;https://uniwersytetlodzki-my.sharepoint.com/:f:/g/personal/pelcra_uni_lodz_pl/EpPehikqGqZJltrAKlVp3k0BOeyzEgBBO_ZwmFC9WaLbWw&#39;|grep &#39;var _spPageContextInfo=&#39; . import json for s in curl_out: if &#39;var _spPageContextInfo=&#39; in s: start = s[s.index(&#39;access_token=&#39;)+len(&#39;access_token=&#39;):] access_token = start[:start.index(&#39;&quot;&#39;)] . _URL=&#39;https://uniwersytetlodzki-my.sharepoint.com/personal/pelcra_uni_lodz_pl/Documents&#39; . _COOKIE=&#39;FedAuth=77u/PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0idXRmLTgiPz48U1A+VjksMGguZnxtZW1iZXJzaGlwfHVybiUzYXNwbyUzYWFub24jNTZiNDAwY2Y5OWYxMjQwYTkyYjRhNWU3ZTkwYjJlNWVlY2Q3MzYyMGJlNmNiMjI4OTllNjhiMWU4Zjc2Nzk4ZCwwIy5mfG1lbWJlcnNoaXB8dXJuJTNhc3BvJTNhYW5vbiM1NmI0MDBjZjk5ZjEyNDBhOTJiNGE1ZTdlOTBiMmU1ZWVjZDczNjIwYmU2Y2IyMjg5OWU2OGIxZThmNzY3OThkLDEzMjY0NDY0NTU3MDAwMDAwMCwwLDEzMjY0NTUwNjU4MDQxOTgzNCwwLjAuMC4wLDI1OCxkZGIyZmM4NS0xYzE4LTRjMmItOTkyYS1lODQxMWJmZmMwZTcsLCw0ODEyYzQ5Zi02MGY0LTIwMDAtZTE0Mi02YzYwM2MyZGE3YzQsNDgxMmM0OWYtNjBmNC0yMDAwLWUxNDItNmM2MDNjMmRhN2M0LDVrVml3YU9rSGtxaWZjbzVzKytYSlEsMCwwLDAsLCwsMjY1MDQ2Nzc0Mzk5OTk5OTk5OSwwLCwsLCwsc0JtSkR4RTZJd3I5VmsraGJHclFSUDhSNzJIUXh2UWlqNDZ6WnFPdXArUVZnVWhkNkVmQWljNUZ1YUYwMEdGUjRFRnhMRUJsRlNTZ3lnNElkTUdSSnpwbGZUT0JGSkw0Tyt4cjRHS01WdjZ1YnhJWTFzMkFWYWpySVgzbXRGWm9zOHkrYjk0SnhPZElibVVxaUJWZzVaZHVTcWxSMnlFdzc0Y3BueERjVHdQU3FVYTk3VG5qOTRWM0s4YkdkUnA1QVVGSGtacjg2Q0YvZVY5R2Y1OGlTd1ZKUWx2VEc5OVByaU9JWE94Umc4N2FZc2ZFTWZzcG9JL05tYlU0cm9sQ1ZnVzVVNUl3NXJlY29PNzkxUXZZbDBlUlZNcXBVSHI0UEdBOVhLaEJVb3I5YTJpMFpQZEhZRE9SQnlVcWtHRDQvb0NXY21JamdGQVhNM2RtTFgwWGJBPT08L1NQPg==; path=/; SameSite=None; secure; HttpOnly&#39; . !rclone config create pelcra webdav url {_URL} webdav-vendor other access_token {access_token} #cookie &quot;{_COOKIE}&quot; . Remote config -- [pelcra] type = webdav url = https://uniwersytetlodzki-my.sharepoint.com/personal/pelcra_uni_lodz_pl/Documents webdav-vendor = other access_token = eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJhdWQiOiIwMDAwMDAwMy0wMDAwLTBmZjEtY2UwMC0wMDAwMDAwMDAwMDAvdW5pd2Vyc3l0ZXRsb2R6a2ktbXkuc2hhcmVwb2ludC5jb21ANjM0NDFhZWYtZGEwZS00Mzk3LWJiN2UtZjlkNDcwNWU5NjNiIiwiaXNzIjoiMDAwMDAwMDMtMDAwMC0wZmYxLWNlMDAtMDAwMDAwMDAwMDAwIiwibmJmIjoxNjIwMjU0MjMwLCJleHAiOjE2MjAyNzU4MzAsImlzbG9vcGJhY2siOiJUcnVlIiwibmFtZWlkIjoiMCMuZnxtZW1iZXJzaGlwfHVybiUzYXNwbyUzYWFub24jNTZiNDAwY2Y5OWYxMjQwYTkyYjRhNWU3ZTkwYjJlNWVlY2Q3MzYyMGJlNmNiMjI4OTllNjhiMWU4Zjc2Nzk4ZCIsIm5paSI6Im1pY3Jvc29mdC5zaGFyZXBvaW50IiwiaXN1c2VyIjoidHJ1ZSIsImNhY2hla2V5IjoiMGguZnxtZW1iZXJzaGlwfHVybiUzYXNwbyUzYWFub24jNTZiNDAwY2Y5OWYxMjQwYTkyYjRhNWU3ZTkwYjJlNWVlY2Q3MzYyMGJlNmNiMjI4OTllNjhiMWU4Zjc2Nzk4ZCIsInR0IjoiMCIsInVzZVBlcnNpc3RlbnRDb29raWUiOiIyIn0.A50UZ17CCLwueDg9UAJx4NY4FM-3p_vRN59OrxDxFz4u0026prooftoken=eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsIng1dCI6IkcydDJKYzlkMVZ6RkdjdzZUZy02YUhZVXk2VSJ9.eyJhdWQiOiIwMDAwMDAwMy0wMDAwLTBmZjEtY2UwMC0wMDAwMDAwMDAwMDBAKiIsImlzcyI6IjAwMDAwMDAzLTAwMDAtMGZmMS1jZTAwLTAwMDAwMDAwMDAwMEAqIiwibmJmIjoiMTYyMDI0NjgzMCIsImV4cCI6IjE2MjA4NTE2MzAiLCJwcmYiOiJLMUs2Z21oMFNpZDBaL2E0SjJReXpDSVJLMXBTWGlyOXAzcitoM1UwTjZRNWo2UEc2REZPaG5OU2dPU3FwZDRXK1ZpenppSTlCcWc2d2kvSE83Zk9scGhmaE9pU3NLN1p6clFGMUxlOFk3dnJJejdNb1RLQ3Njbjh5cUhvSklVbjFmVFlIcGltb1E0NnJQdVlJV0pJK3UwOXVHTVBpSS9ZcWlCYzhHd0VBTit0bnoyZ2tIcXM3OGhXbGo2Y3dBNzNTckJwTHBTdG53QzZaRXRoUVV1N3l6eGhuRVlXdkNhNUFPdVlWaXRiMndTZWpib0g5QlBCc0puemVEL1ZMUDFqZXh2Qk9DRVpYN25XRjU4SC9Sck1tdWdZb2ZxMGQzZnhlTG56d0RJbDFEYjdqcFc3L20vaURJV1FQRUZScmFmUW1pbFJmYjRSTFUxVFFGWWptVHJmU1E9PSIsImlzdXNlciI6InRydWUifQ.o1x0-K2UNkorQjKyT5o0HXJiOJxHP3vlYscEzjKN2KQHzp95ja3ml5yzqPtSXdCwYxjCdJjWgtAvS5YlQzLBX2Eac8odydBxDa8EHyuVxIa6T-n7dD4R1WHVebyXt62shIP61s_TeiJkwiD0Sl_nPIzqY9zkrKEg_cSe0isEi0mCv6ynYXCWetYpaMdv4ifaGAl5aK7v6zxNKzwVoxBUfEIcJLV8MjdeV1i1Puuinpj69GUispryx7ruDs0g5CLVjOeAk0wwaoTeRzL4y04EKTKdt4UsdeAAXzE1Rby4na3xqDkeewPUCYxZHQL89tGOUcmiwjJKeB7Fos39XIhrRg -- . !rclone ls --use-cookies -vv &#39;pelcra:SHARE/CLARIN/SPOKES/PELCRA_EMO&#39; --dump bodies . 2021/05/05 22:54:48 DEBUG : Using config file from &#34;/root/.config/rclone/rclone.conf&#34; 2021/05/05 22:54:48 DEBUG : rclone: Version &#34;v1.55.1&#34; starting with parameters [&#34;rclone&#34; &#34;ls&#34; &#34;--use-cookies&#34; &#34;-vv&#34; &#34;pelcra:SHARE/CLARIN/SPOKES/PELCRA_EMO&#34; &#34;--dump&#34; &#34;bodies&#34;] 2021/05/05 22:54:48 DEBUG : Creating backend with remote &#34;pelcra:SHARE/CLARIN/SPOKES/PELCRA_EMO&#34; 2021/05/05 22:54:48 DEBUG : You have specified to dump information. Please be noted that the Accept-Encoding as shown may not be correct in the request and the response may not show Content-Encoding if the go standard libraries auto gzip encoding was in effect. In this case the body of the request will be gunzipped before showing it. 2021/05/05 22:54:48 DEBUG : &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 2021/05/05 22:54:48 DEBUG : HTTP REQUEST (req 0xc000596a00) 2021/05/05 22:54:48 DEBUG : PROPFIND /personal/pelcra_uni_lodz_pl/Documents/SHARE/CLARIN/SPOKES/PELCRA_EMO HTTP/1.1 Host: uniwersytetlodzki-my.sharepoint.com User-Agent: rclone/v1.55.1 Depth: 1 Referer: https://uniwersytetlodzki-my.sharepoint.com/personal/pelcra_uni_lodz_pl/Documents/ Accept-Encoding: gzip 2021/05/05 22:54:48 DEBUG : &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 2021/05/05 22:54:49 DEBUG : &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; 2021/05/05 22:54:49 DEBUG : HTTP RESPONSE (req 0xc000596a00) 2021/05/05 22:54:49 DEBUG : HTTP/2.0 403 Forbidden Content-Length: 13 Content-Type: text/plain; charset=utf-8 Date: Wed, 05 May 2021 22:54:48 GMT Microsoftsharepointteamservices: 16.0.0.21221 Ms-Cv: n8UOqHwAACDhQmsT9SmG6Q.0 P3p: CP=&#34;ALL IND DSP COR ADM CONo CUR CUSo IVAo IVDo PSA PSD TAI TELo OUR SAMo CNT COM INT NAV ONL PHY PRE PUR UNI&#34; Request-Id: a80ec59f-007c-2000-e142-6b13f52986e9 Sprequestguid: a80ec59f-007c-2000-e142-6b13f52986e9 X-Content-Type-Options: nosniff X-Forms_based_auth_required: https://uniwersytetlodzki-my.sharepoint.com/_forms/default.aspx?ReturnUrl=/_layouts/15/error.aspx&amp;Source=%2fpersonal%2fpelcra_uni_lodz_pl%2fDocuments%2fSHARE%2fCLARIN%2fSPOKES%2fPELCRA_EMO X-Forms_based_auth_return_url: https://uniwersytetlodzki-my.sharepoint.com/_layouts/15/error.aspx X-Idcrl_auth_params_v1: IDCRL Type=&#34;BPOSIDCRL&#34;, EndPoint=&#34;/personal/pelcra_uni_lodz_pl/_vti_bin/idcrl.svc/&#34;, RootDomain=&#34;sharepoint.com&#34;, Policy=&#34;MBI&#34; X-Ms-Invokeapp: 1; RequireReadOnly X-Msdavext_error: 917656; Access+denied.+Before+opening+files+in+this+location%2c+you+must+first+browse+to+the+web+site+and+select+the+option+to+login+automatically. X-Msedge-Ref: Ref A: 8A3CC80AA56A42C4A2112F4377B61AA6 Ref B: HK2EDGE0921 Ref C: 2021-05-05T22:54:49Z X-Powered-By: ASP.NET X-Sharepointhealthscore: 3 403 FORBIDDEN 2021/05/05 22:54:49 DEBUG : &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; 2021/05/05 22:54:49 Failed to create file system for &#34;pelcra:SHARE/CLARIN/SPOKES/PELCRA_EMO&#34;: read metadata failed: 403 FORBIDDEN: 403 Forbidden . !rclone ls :http: --http-url &#39;https://uniwersytetlodzki-my.sharepoint.com/:f:/g/personal/pelcra_uni_lodz_pl/EpPehikqGqZJltrAKlVp3k0BOeyzEgBBO_ZwmFC9WaLbWw&#39; --use-cookies -vv . !rclone config dump .",
            "url": "https://jimregan.github.io/notes/rclone/sharepoint/2021/05/02/rclone-and-sharepoint.html",
            "relUrl": "/rclone/sharepoint/2021/05/02/rclone-and-sharepoint.html",
            "date": " ‚Ä¢ May 2, 2021"
        }
        
    
  
    
        ,"post22": {
            "title": "Two speechbrain speech enhancement models",
            "content": "The Colab notebook (with outputs) is here; the models are on the Huggingface hub: mtl-mimic-voicebank and speechbrain/metricgan-plus-voicebank . The first twenty seconds of mtl-mimic-voicebank aren&#39;t great (but they are quieter in the recording); the rest is fantastic. The output from metricgan-plus-voicebank is bad from start to finish. . %%capture !pip install torchaudio speechbrain . !wget http://assets.doegen.ie/sound/MP3_versions/aud_Ul1-LA_1202d1u1.mp3 . import IPython IPython.display.Audio(&#39;aud_Ul1-LA_1202d1u1.mp3&#39;) . import torchaudio from speechbrain.pretrained import SpectralMaskEnhancement enhance_model = SpectralMaskEnhancement.from_hparams( source=&quot;speechbrain/mtl-mimic-voicebank&quot;, savedir=&quot;pretrained_models/mtl-mimic-voicebank&quot;, ) enhanced = enhance_model.enhance_file(&quot;aud_Ul1-LA_1202d1u1.mp3&quot;) # Saving enhanced signal on disk torchaudio.save(&#39;enhanced.wav&#39;, enhanced.unsqueeze(0), 16000) . IPython.display.Audio(&#39;enhanced.wav&#39;) . import torch enhance_model = SpectralMaskEnhancement.from_hparams( source=&quot;speechbrain/metricgan-plus-voicebank&quot;, savedir=&quot;pretrained_models/metricgan-plus-voicebank&quot;, ) noisy = enhance_model.load_audio(&quot;aud_Ul1-LA_1202d1u1.mp3&quot;).unsqueeze(0) # Add relative length tensor enhanced = enhance_model.enhance_batch(noisy, lengths=torch.tensor([1.])) # Saving enhanced signal on disk torchaudio.save(&#39;enhanced2.wav&#39;, enhanced, 16000) . IPython.display.Audio(&#39;enhanced2.wav&#39;) .",
            "url": "https://jimregan.github.io/notes/speechbrain/speech%20enhancement/2021/04/30/speechbrain_speech_enhancements.html",
            "relUrl": "/speechbrain/speech%20enhancement/2021/04/30/speechbrain_speech_enhancements.html",
            "date": " ‚Ä¢ Apr 30, 2021"
        }
        
    
  
    
        ,"post23": {
            "title": "Doegen recordings scraper",
            "content": "import requests from bs4 import BeautifulSoup import json . _BASE = &#39;https://doegen.ie/counties&#39; def do_get(url): r = requests.get(url, headers = {&#39;User-agent&#39;: &#39;Mozilla/5.0&#39;}) if r.status_code != 200: raise Exception(&quot;Failed to open landing page&quot;) return r.content . soup = BeautifulSoup(do_get(_BASE), &#39;html.parser&#39;) . counties = soup.find(&#39;ul&#39;, {&#39;class&#39;: &#39;vocabindex&#39;}).find_all(&#39;li&#39;) . pages = [] for county in counties: item = {} anchor = county.find(&#39;a&#39;) href = anchor[&#39;href&#39;] item[&#39;link&#39;] = f&#39;https://doegen.ie{href}&#39; if anchor.find(&#39;span&#39;).text.strip() != &#39;(0)&#39;: item[&#39;county&#39;] = anchor.text.split()[1] pages.append(item) . def proc_page(url): result = {} html = do_get(url) soup = BeautifulSoup(html, &#39;html.parser&#39;) main = soup.find(&#39;div&#39;, {&#39;id&#39;: &#39;main&#39;}) content = main.find(&#39;div&#39;, {&#39;class&#39;: &#39;content&#39;}) source = content.find(&#39;source&#39;) if source == None: return {} result[&#39;mp3&#39;] = source[&#39;src&#39;] result[&#39;transcript&#39;] = content.find(&#39;div&#39;, id=&#39;transcript&#39;).text if content.find(&#39;div&#39;, id=&#39;translation&#39;) != None: result[&#39;translation&#39;] = content.find(&#39;div&#39;, id=&#39;translation&#39;).text if content.find(&#39;div&#39;, id=&#39;footnote&#39;) != None: result[&#39;footnote&#39;] = content.find(&#39;div&#39;, id=&#39;footnote&#39;).text result[&#39;recording_metadata&#39;] = content.find(&#39;div&#39;, id=&#39;recording_metadata&#39;).text return result . def proc_county(item): content = do_get(item[&#39;link&#39;]) soup = BeautifulSoup(content, &#39;html.parser&#39;) main = soup.find(&#39;div&#39;, id=&#39;main&#39;) nodes = main.find_all(&#39;div&#39;, {&#39;class&#39;: &#39;node&#39;}) stories = [] for node in nodes: story = {} anchor = node.find(&#39;a&#39;) story[&#39;link&#39;] = f&quot;https://doegen.ie{anchor[&#39;href&#39;]}&quot; story[&#39;content&#39;] = proc_page(story[&#39;link&#39;]) if story[&#39;content&#39;] == {}: continue tags = node.find(&#39;div&#39;, {&#39;class&#39;: &#39;terms&#39;}).find_all(&#39;a&#39;, rel=&#39;tag&#39;) text = anchor.text if &#39; - &#39; in text: tmp = text.split(&#39; - &#39;) if len(tmp) == 2: story[&#39;title&#39;] = tmp[0] story[&#39;speaker_name&#39;] = tmp[1] name_parts = tmp[1].split(&#39; &#39;) first = name_parts[0] for tag in tags: if first in tag.text: story[&#39;speaker_url&#39;] = f&quot;https://doegen.ie{tag[&#39;href&#39;]}&quot; else: story[&#39;raw&#39;] = text else: story[&#39;raw&#39;] = text stories.append(story) item[&#39;stories&#39;] = stories . for page in pages: proc_county(page) . with open(&#39;doegen.json&#39;, &#39;w&#39;) as f: json.dump(pages, f) .",
            "url": "https://jimregan.github.io/notes/irish/scraper/2021/04/29/doegen-scraper.html",
            "relUrl": "/irish/scraper/2021/04/29/doegen-scraper.html",
            "date": " ‚Ä¢ Apr 29, 2021"
        }
        
    
  
    
        ,"post24": {
            "title": "Praat via parselmouth",
            "content": "import numpy as np import matplotlib.pyplot as plt import seaborn as sns import requests import parselmouth import tempfile . sns.set() # Use seaborn&#39;s default style to make attractive graphs plt.rcParams[&#39;figure.dpi&#39;] = 300 # Show nicely large images in this notebook . def load_from_teanglann(word, dialect): valid_dialects = [&#39;C&#39;, &#39;M&#39;, &#39;U&#39;] if dialect not in valid_dialects and dialect.upper()[0] not in valid_dialects: raise Exception(f&#39;Dialect must be one of &quot;C&quot;, &quot;M&quot; or &quot;U&quot;; got &quot;{dialect}&quot;&#39;) url = f&#39;https://www.teanglann.ie/Can{dialect}/{word}.mp3&#39; r = requests.get(url) if r.status_code != 200: raise Exception(f&#39;Failed to fetch {url}&#39;) file = tempfile.NamedTemporaryFile(mode=&#39;w+b&#39;) file.write(r.content) return file . def draw_spectrogram(spectrogram, dynamic_range=70): X, Y = spectrogram.x_grid(), spectrogram.y_grid() sg_db = 10 * np.log10(spectrogram.values) plt.pcolormesh(X, Y, sg_db, vmin=sg_db.max() - dynamic_range, cmap=&#39;afmhot&#39;) plt.ylim([spectrogram.ymin, spectrogram.ymax]) plt.xlabel(&quot;time [s]&quot;) plt.ylabel(&quot;frequency [Hz]&quot;) def draw_intensity(intensity): plt.plot(intensity.xs(), intensity.values.T, linewidth=3, color=&#39;w&#39;) plt.plot(intensity.xs(), intensity.values.T, linewidth=1) plt.grid(False) plt.ylim(0) plt.ylabel(&quot;intensity [dB]&quot;) . file=load_from_teanglann(&#39;athdhreas&#39;, &#39;U&#39;) snd = parselmouth.Sound(file_path=file.name) intensity = snd.to_intensity() spectrogram = snd.to_spectrogram() plt.figure() draw_spectrogram(spectrogram) plt.twinx() #draw_intensity(intensity) plt.xlim([snd.xmin, snd.xmax]) plt.show() . def draw_pitch(pitch): # Extract selected pitch contour, and # replace unvoiced samples by NaN to not plot pitch_values = pitch.selected_array[&#39;frequency&#39;] pitch_values[pitch_values==0] = np.nan plt.plot(pitch.xs(), pitch_values, &#39;o&#39;, markersize=5, color=&#39;w&#39;) plt.plot(pitch.xs(), pitch_values, &#39;o&#39;, markersize=2) plt.grid(False) plt.ylim(0, pitch.ceiling) plt.ylabel(&quot;fundamental frequency [Hz]&quot;) pitch = snd.to_pitch() # If desired, pre-emphasize the sound fragment before calculating the spectrogram pre_emphasized_snd = snd.copy() pre_emphasized_snd.pre_emphasize() spectrogram = pre_emphasized_snd.to_spectrogram(window_length=0.03, maximum_frequency=8000) plt.figure() draw_spectrogram(spectrogram) plt.twinx() #draw_pitch(pitch) plt.xlim([snd.xmin, snd.xmax]) plt.show() .",
            "url": "https://jimregan.github.io/notes/praat/parselmouth/2021/04/24/parselmouth.html",
            "relUrl": "/praat/parselmouth/2021/04/24/parselmouth.html",
            "date": " ‚Ä¢ Apr 24, 2021"
        }
        
    
  
    
        ,"post25": {
            "title": "BuNaMo to json",
            "content": "from lxml import etree . class BuNaMoWrongDocument(Exception): &quot;&quot;&quot;Exception raised for wrong document type&quot;&quot;&quot; def __init__(self, expected, got): self.expected = expected self.got = got self.message = f&quot;Expected root element &lt;{self.expected}&gt; but got &lt;{self.got}&gt;&quot; super().__init__(self.message) . Various functions to read one of the types of XML file. The open parts of speech (noun, adjective, verb) can have multiple forms, so those functions return attributes (a dictionary) and forms (a list of dictionaries) separately. . Close parts of speech (possessives and prepositions) are simpler, and most of the attributes are needless, so they return a simple dictionary containing the forms. . def read_adjective(file): tree = etree.parse(file) root = tree.getroot() valid_tags = [&#39;sgNom&#39;, &#39;sgGenMasc&#39;, &#39;sgGenFem&#39;, &#39;plNom&#39;, &#39;graded&#39;, &#39;abstractNoun&#39;, &#39;sgVocMasc&#39;, &#39;sgVocFem&#39;] attribs = {} forms = [] if root.tag != &#39;adjective&#39;: raise BuNaMoWrongDocument(&#39;adjective&#39;, root.tag) attribs[&#39;default&#39;] = root.get(&#39;default&#39;) attribs[&#39;declension&#39;] = root.get(&#39;declension&#39;) attribs[&#39;disambig&#39;] = root.get(&#39;disambig&#39;) attribs[&#39;isPre&#39;] = root.get(&#39;isPre&#39;) for child in root: if child.tag not in valid_tags: raise Exception(&#39;Unexpected tag &#39; + child.tag) tmp = {} tmp[&#39;props&#39;] = child.tag tmp[&#39;form&#39;] = child.get(&#39;default&#39;) forms.append(tmp) return attribs, forms def read_noun(file): tree = etree.parse(file) root = tree.getroot() valid_tags = [&#39;sgNom&#39;, &#39;sgGen&#39;, &#39;plNom&#39;, &#39;plGen&#39;, &#39;count&#39;, &#39;sgDat&#39;] attribs = {} forms = [] if root.tag != &#39;noun&#39;: raise BuNaMoWrongDocument(&#39;noun&#39;, root.tag) attribs[&#39;default&#39;] = root.get(&#39;default&#39;) attribs[&#39;declension&#39;] = root.get(&#39;declension&#39;) attribs[&#39;disambig&#39;] = root.get(&#39;disambig&#39;) attribs[&#39;isProper&#39;] = root.get(&#39;isProper&#39;) attribs[&#39;isDefinite&#39;] = root.get(&#39;isDefinite&#39;) attribs[&#39;allowArticledGenitive&#39;] = root.get(&#39;allowArticledGenitive&#39;) for child in root: if child.tag not in valid_tags: raise Exception(&#39;Unexpected tag &#39; + child.tag) tmp = {} tmp[&#39;props&#39;] = child.tag tmp[&#39;form&#39;] = child.get(&#39;default&#39;) tmp[&#39;gender&#39;] = child.get(&#39;gender&#39;) tmp[&#39;strength&#39;] = child.get(&#39;strength&#39;) forms.append(tmp) return attribs, forms def read_verb(file): tree = etree.parse(file) root = tree.getroot() valid_tags = [&#39;verbalNoun&#39;, &#39;verbalAdjective&#39;, &#39;tenseForm&#39;, &#39;moodForm&#39;] attribs = {} forms = [] if root.tag != &#39;verb&#39;: raise BuNaMoWrongDocument(&#39;verb&#39;, root.tag) attribs[&#39;default&#39;] = root.get(&#39;default&#39;) attribs[&#39;disambig&#39;] = root.get(&#39;disambig&#39;) for child in root: if child.tag not in valid_tags: raise Exception(&#39;Unexpected tag &#39; + child.tag) tmp = {} tmp[&#39;props&#39;] = child.tag tmp[&#39;form&#39;] = child.get(&#39;default&#39;) tmp[&#39;tense&#39;] = child.get(&#39;tense&#39;) tmp[&#39;mood&#39;] = child.get(&#39;mood&#39;) tmp[&#39;dependency&#39;] = child.get(&#39;dependency&#39;) tmp[&#39;person&#39;] = child.get(&#39;person&#39;) forms.append(tmp) return attribs, forms def read_nounphrase(file): tree = etree.parse(file) root = tree.getroot() valid_tags = [&#39;sgNom&#39;, &#39;sgGen&#39;, &#39;plNom&#39;, &#39;plGen&#39;, &#39;sgNomArt&#39;, &#39;sgGenArt&#39;, &#39;plNomArt&#39;, &#39;plGenArt&#39;] attribs = {} forms = [] if root.tag != &#39;nounPhrase&#39;: raise BuNaMoWrongDocument(&#39;nounPhrase&#39;, root.tag) attribs[&#39;default&#39;] = root.get(&#39;default&#39;) attribs[&#39;declension&#39;] = root.get(&#39;declension&#39;) attribs[&#39;disambig&#39;] = root.get(&#39;disambig&#39;) attribs[&#39;isProper&#39;] = root.get(&#39;isProper&#39;) attribs[&#39;isDefinite&#39;] = root.get(&#39;isDefinite&#39;) attribs[&#39;allowArticledGenitive&#39;] = root.get(&#39;allowArticledGenitive&#39;) attribs[&#39;forceNominative&#39;] = root.get(&#39;forceNominative&#39;) for child in root: if child.tag not in valid_tags: raise Exception(&#39;Unexpected tag &#39; + child.tag) tmp = {} tmp[&#39;props&#39;] = child.tag tmp[&#39;form&#39;] = child.get(&#39;default&#39;) tmp[&#39;gender&#39;] = child.get(&#39;gender&#39;) tmp[&#39;strength&#39;] = child.get(&#39;strength&#39;) forms.append(tmp) return attribs, forms def read_possessive(file): tree = etree.parse(file) root = tree.getroot() valid_tags = [&#39;full&#39;, &#39;apos&#39;] attribs = {} forms = [] if root.tag != &#39;possessive&#39;: raise BuNaMoWrongDocument(&#39;possessive&#39;, root.tag) attribs[&#39;default&#39;] = root.get(&#39;default&#39;) attribs[&#39;disambig&#39;] = root.get(&#39;disambig&#39;) attribs[&#39;mutation&#39;] = root.get(&#39;mutation&#39;) for child in root: if child.tag not in valid_tags: raise Exception(&#39;Unexpected tag &#39; + child.tag) if child.tag == &#39;apos&#39;: attribs[&#39;apos&#39;] = child.get(&#39;default&#39;) return attribs def read_preposition(file): tree = etree.parse(file) root = tree.getroot() valid_tags = [&#39;sg1&#39;, &#39;sg2&#39;, &#39;sg3Masc&#39;, &#39;sg3Fem&#39;, &#39;pl1&#39;, &#39;pl2&#39;, &#39;pl3&#39;] attribs = {} forms = [] if root.tag != &#39;preposition&#39;: raise BuNaMoWrongDocument(&#39;preposition&#39;, root.tag) attribs[&#39;default&#39;] = root.get(&#39;default&#39;) for child in root: if child.tag not in valid_tags: raise Exception(&#39;Unexpected tag &#39; + child.tag) attribs[child.tag] = child.get(&#39;default&#39;) return attribs . import glob import json adjectives = {} for x in glob.glob(&#39;../input/bunamo-bunachar-naisiunta-moirfeolaiochta/adjective/*.xml&#39;): fname = x.split(&#39;/&#39;)[-1].replace(&#39;.xml&#39;, &#39;&#39;) attribs, forms = read_adjective(x) tmp = {} tmp[&#39;attributes&#39;] = attribs tmp[&#39;forms&#39;] = forms adjectives[fname] = tmp word = attribs[&#39;default&#39;] with open(&#39;adjectives.json&#39;, &#39;w&#39;) as outfile: json.dump(adjectives, outfile) . nouns = {} for x in glob.glob(&#39;../input/bunamo-bunachar-naisiunta-moirfeolaiochta/noun/*.xml&#39;): fname = x.split(&#39;/&#39;)[-1].replace(&#39;.xml&#39;, &#39;&#39;) attribs, forms = read_noun(x) tmp = {} tmp[&#39;attributes&#39;] = attribs tmp[&#39;forms&#39;] = forms nouns[fname] = tmp word = attribs[&#39;default&#39;] with open(&#39;nouns.json&#39;, &#39;w&#39;) as outfile: json.dump(nouns, outfile) . nounphrases = {} for x in glob.glob(&#39;../input/bunamo-bunachar-naisiunta-moirfeolaiochta/nounPhrase/*.xml&#39;): fname = x.split(&#39;/&#39;)[-1].replace(&#39;.xml&#39;, &#39;&#39;) attribs, forms = read_nounphrase(x) tmp = {} tmp[&#39;attributes&#39;] = attribs tmp[&#39;forms&#39;] = forms nounphrases[fname] = tmp word = attribs[&#39;default&#39;] with open(&#39;nounphrases.json&#39;, &#39;w&#39;) as outfile: json.dump(nounphrases, outfile) . verbs = {} for x in glob.glob(&#39;../input/bunamo-bunachar-naisiunta-moirfeolaiochta/verb/*.xml&#39;): fname = x.split(&#39;/&#39;)[-1].replace(&#39;.xml&#39;, &#39;&#39;) attribs, forms = read_verb(x) tmp = {} tmp[&#39;attributes&#39;] = attribs tmp[&#39;forms&#39;] = forms verbs[fname] = tmp word = attribs[&#39;default&#39;] with open(&#39;verbs.json&#39;, &#39;w&#39;) as outfile: json.dump(verbs, outfile) . preposition = {} for x in glob.glob(&#39;../input/bunamo-bunachar-naisiunta-moirfeolaiochta/preposition/*.xml&#39;): fname = x.split(&#39;/&#39;)[-1].replace(&#39;.xml&#39;, &#39;&#39;) attribs = read_preposition(x) tmp = {} tmp[&#39;attributes&#39;] = attribs preposition[fname] = tmp with open(&#39;prepositions.json&#39;, &#39;w&#39;) as outfile: json.dump(preposition, outfile) . possessive = {} for x in glob.glob(&#39;../input/bunamo-bunachar-naisiunta-moirfeolaiochta/possessive/*.xml&#39;): fname = x.split(&#39;/&#39;)[-1].replace(&#39;.xml&#39;, &#39;&#39;) attribs = read_possessive(x) tmp = {} tmp[&#39;attributes&#39;] = attribs possessive[fname] = tmp with open(&#39;possessives.json&#39;, &#39;w&#39;) as outfile: json.dump(possessive, outfile) . possessive . {&#39;√°r_poss&#39;: {&#39;attributes&#39;: {&#39;default&#39;: &#39;√°r&#39;, &#39;disambig&#39;: &#39;&#39;, &#39;mutation&#39;: &#39;ecl1&#39;}}, &#39;a_poss_masc&#39;: {&#39;attributes&#39;: {&#39;default&#39;: &#39;a&#39;, &#39;disambig&#39;: &#39;masc&#39;, &#39;mutation&#39;: &#39;len1&#39;}}, &#39;a_poss_fem&#39;: {&#39;attributes&#39;: {&#39;default&#39;: &#39;a&#39;, &#39;disambig&#39;: &#39;fem&#39;, &#39;mutation&#39;: &#39;prefH&#39;}}, &#39;do_poss&#39;: {&#39;attributes&#39;: {&#39;default&#39;: &#39;do&#39;, &#39;disambig&#39;: &#39;&#39;, &#39;mutation&#39;: &#39;len1&#39;, &#39;apos&#39;: &#34;d&#39;&#34;}}, &#39;a_poss_pl&#39;: {&#39;attributes&#39;: {&#39;default&#39;: &#39;a&#39;, &#39;disambig&#39;: &#39;pl&#39;, &#39;mutation&#39;: &#39;ecl1&#39;}}, &#39;mo_poss&#39;: {&#39;attributes&#39;: {&#39;default&#39;: &#39;mo&#39;, &#39;disambig&#39;: &#39;&#39;, &#39;mutation&#39;: &#39;len1&#39;, &#39;apos&#39;: &#34;m&#39;&#34;}}, &#39;bhur_poss&#39;: {&#39;attributes&#39;: {&#39;default&#39;: &#39;bhur&#39;, &#39;disambig&#39;: &#39;&#39;, &#39;mutation&#39;: &#39;ecl1&#39;}}} .",
            "url": "https://jimregan.github.io/notes/irish/bunamo/kaggle/2021/04/24/bunamo-raw-json.html",
            "relUrl": "/irish/bunamo/kaggle/2021/04/24/bunamo-raw-json.html",
            "date": " ‚Ä¢ Apr 24, 2021"
        }
        
    
  
    
        ,"post26": {
            "title": "Kashubian PDF corpus 1",
            "content": "!wget $(lynx -dump http://skarbnicakaszubska.pl/najo-uczba/|grep pdf|awk &#39;{print $NF}&#39;) . For the most part, the text extracted from the pdfs is fine as is; one of the files has multiple articles, several with translations, making it potentially useful as a parallel corpus. . The text (seems to) come out fine with pdftotext, so I haven&#39;t bothered doing anything else. . !pdftotext -nopgbrk -f 9 -l 10 ZKP_biuletynRJK_2015_internet.pdf - | grep -v &#39;BIU¬≠L E¬≠T IN RADZ√ãZN√ã KASZ√ãBSCZ√âG√í J√ÉZ√ãKA 2015&#39;|grep -v &#39;^10&#39;|grep -v &#39;^$&#39; &gt; ZKP_biuletynRJK_2015_internet_1.csb.txt . !pdftotext -nopgbrk -f 11 -l 12 ZKP_biuletynRJK_2015_internet.pdf - | grep -v &#39;BIU¬≠L E¬≠T YN RADY JƒòZYKA KASZUBSKIEGO 2015&#39;|grep -v &#39;^12&#39;|grep -v &#39;^$&#39; &gt; ZKP_biuletynRJK_2015_internet_1.pl.txt . !pdftotext -nopgbrk -f 14 -l 20 ZKP_biuletynRJK_2015_internet.pdf - | grep -v &#39;BIU¬≠L E¬≠T IN RADZ√ãZN√ã KASZ√ãBSCZ√âG√í J√ÉZ√ãKA 2015&#39;|grep -v &#39;^P√≤stanowienia Radz√´zn√´ Kasz√´bscz√©g√≤ J√£z√´ka&#39;|grep -v &#39;^$&#39;|grep -v &#39;^1[5-9]$&#39;|grep -v &#39;^20$&#39; &gt; ZKP_biuletynRJK_2015_internet_wl1.txt . !pdftotext -nopgbrk -f 21 -l 23 ZKP_biuletynRJK_2015_internet.pdf - | grep -v &#39;BIU¬≠L E¬≠T IN RADZ√ãZN√ã KASZ√ãBSCZ√âG√í J√ÉZ√ãKA 2015&#39;|grep -v &#39;^P√≤stanowienia Radz√´zn√´ Kasz√´bscz√©g√≤ J√£z√´ka&#39;|grep -v &#39;^$&#39;|grep -v &#39;^2[1-9]$&#39; &gt; ZKP_biuletynRJK_2015_internet_wl2.txt . !pdftotext -nopgbrk -f 24 -l 29 ZKP_biuletynRJK_2015_internet.pdf - | grep -v &#39;BIU¬≠L E¬≠T IN RADZ√ãZN√ã KASZ√ãBSCZ√âG√í J√ÉZ√ãKA 2015&#39;|grep -v &#39;^P√≤stanowienia Radz√´zn√´ Kasz√´bscz√©g√≤ J√£z√´ka&#39;|grep -v &#39;^$&#39;|grep -v &#39;^2[1-9]$&#39; &gt; ZKP_biuletynRJK_2015_internet_wl3.txt . !pdftotext -nopgbrk -f 30 -l 48 ZKP_biuletynRJK_2015_internet.pdf - | grep -v &#39;BIU¬≠L E¬≠T IN RADZ√ãZN√ã KASZ√ãBSCZ√âG√í J√ÉZ√ãKA 2015&#39;|grep -v &#39;^P√≤stanowienia Radz√´zn√´ Kasz√´bscz√©g√≤ J√£z√´ka&#39;|grep -v &#39;^$&#39;|grep -v &#39;^[34][0-9]$&#39; &gt; ZKP_biuletynRJK_2015_internet_wl4.txt . !pdftotext -nopgbrk -f 49 -l 49 ZKP_biuletynRJK_2015_internet.pdf - | grep -v &#39;BIU¬≠L E¬≠T IN RADZ√ãZN√ã KASZ√ãBSCZ√âG√í J√ÉZ√ãKA 2015&#39;|grep -v &#39;^P√≤stanowienia Radz√´zn√´ Kasz√´bscz√©g√≤ J√£z√´ka&#39;|grep -v &#39;^$&#39;|grep -v &#39;^[34][0-9]$&#39; &gt; ZKP_biuletynRJK_2015_internet_wl5.txt . !pdftotext -nopgbrk -f 50 -l 65 ZKP_biuletynRJK_2015_internet.pdf - | grep -v &#39;BIU¬≠L E¬≠T IN RADZ√ãZN√ã KASZ√ãBSCZ√âG√í J√ÉZ√ãKA 2015&#39;|grep -v &#39;^P√≤stanowienia Radz√´zn√´ Kasz√´bscz√©g√≤ J√£z√´ka&#39;|grep -v &#39;^$&#39;|grep -v &#39;^[56][0-9]$&#39; &gt; ZKP_biuletynRJK_2015_internet_wl6.txt . def runner(file, start, end, suffix): base = file.replace(&#39;.pdf&#39;, &#39;&#39;) outfile = f&quot;{base}_{suffix}.txt&quot; !pdftotext -nopgbrk -f {start} -l {end} {file} - | grep -v &#39;BIU¬≠L E¬≠T IN RADZ√ãZN√ã KASZ√ãBSCZ√âG√í J√ÉZ√ãKA 2015&#39;|grep -v &#39;BIU¬≠L E¬≠T YN RADY JƒòZYKA KASZUBSKIEGO 2015&#39;|grep -v &#39;^P√≤stanowienia Radz√´zn√´ Kasz√´bscz√©g√≤ J√£z√´ka&#39;|grep -v &#39;^$&#39;|grep -v &#39;^[0-9][0-9]$&#39;|grep -v &#39;^[1-4][0-9][0-9]$&#39; &gt; {outfile} . runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 68, 74, &#39;wl7&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 75, 77, &#39;wl8&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 78, 83, &#39;wl9&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 84, 102, &#39;wl10&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 103, 103, &#39;wl11&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 104, 119, &#39;wl12&#39;) . runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 122, 128, &#39;csb2&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 129, 132, &#39;csb3&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 133, 144, &#39;csb4&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 145, 151, &#39;csb5&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 153, 161, &#39;csb6&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 162, 166, &#39;csb7&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 168, 178, &#39;csb8&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 179, 185, &#39;csb9&#39;) # it took me this long to remember that there&#39;s a table of contents! runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 186, 197, &#39;csb10&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 198, 204, &#39;csb11&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 205, 211, &#39;csb12&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 212, 220, &#39;csb13&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 222, 228, &#39;pl2&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 229, 237, &#39;plx1&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 238, 241, &#39;pl3&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 242, 248, &#39;plx2&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 249, 254, &#39;plx3&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 255, 266, &#39;pl4&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 267, 274, &#39;pl5&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 275, 283, &#39;pl6&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 284, 289, &#39;pl7&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 290, 300, &#39;plx4&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 301, 313, &#39;pl8&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 314, 320, &#39;pl9&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 5, 8, &#39;toc&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 321, 333, &#39;pl10&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 334, 359, &#39;plx5&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 360, 367, &#39;pl11&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 368, 374, &#39;pl12&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 375, 390, &#39;plx6&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 391, 396, &#39;plx7&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 397, 404, &#39;pl13&#39;) . Now, the rest . !for i in [0-9N]*.pdf;do pdftotext $i;done . uname=!uname -a if not &#39;LAPTOP-6PFTN7M9&#39; in uname: !rm *.pdf .",
            "url": "https://jimregan.github.io/notes/kashubian/lazyscrape/2021/04/23/najo-uczba-pdfs.html",
            "relUrl": "/kashubian/lazyscrape/2021/04/23/najo-uczba-pdfs.html",
            "date": " ‚Ä¢ Apr 23, 2021"
        }
        
    
  
    
        ,"post27": {
            "title": "Checking a Kashubian adjective-like declension",
            "content": "def _list_to_check(pos): num = [&#39;sg&#39;, &#39;pl&#39;] gen = [&#39;mp&#39;, &#39;ma&#39;, &#39;mi&#39;, &#39;f&#39;, &#39;nt&#39;] cas = [&#39;nom&#39;, &#39;gen&#39;, &#39;dat&#39;, &#39;acc&#39;, &#39;ins&#39;, &#39;loc&#39;, &#39;voc&#39;] out = [] for n in num: for g in gen: for c in cas: out.append(f&quot;{pos}.{g}.{n}.{c}&quot;) return out . len(_list_to_check(&#39;num.ord&#39;)) . 70 . dredzi = &quot;&quot;&quot; dr√´d≈ºi dr√´d≈ºi num.ord.mp|ma|mi.sg.nom|voc dr√´g√¥ dr√´d≈ºi num.ord.f.sg.nom|voc dr√´d≈º√© dr√´d≈ºi num.ord.nt.sg.nom|acc|voc dr√´gƒÖ dr√´d≈ºi num.ord.f.sg.acc|ins dr√´d≈ºi dr√´d≈ºi num.ord.f.sg.gen|dat|loc dr√´d≈ºim dr√´d≈ºi num.ord.mp|ma|mi|nt.sg.loc|ins dr√´d≈º√© dr√´d≈ºi num.ord.nt|f|mi|ma.pl.nom|acc|voc dr√´d≈ºich dr√´d≈ºi num.ord.nt|f|mi|ma|mp.pl.gen|loc dr√´d≈ºima dr√´d≈ºi num.ord.nt|f|mi|ma.pl.ins dr√´d≈º√©g√≤ dr√´d≈ºi num.ord.nt|mi|ma|mp.sg.gen dr√´d≈º√©g√≤ dr√´d≈ºi num.ord.ma|mp.sg.acc dr√´d≈º√©m√π dr√´d≈ºi num.ord.nt|mi|ma|mp.sg.dat dr√´d≈ºi dr√´d≈ºi num.ord.mp.pl.nom|voc dr√´d≈ºich dr√´d≈ºi num.ord.mp.pl.acc dr√´d≈ºim dr√´d≈ºi num.ord.nt|f|mi|ma|mp.pl.dat &quot;&quot;&quot; . def _do_expand(stack, todo): onward = [] if not &#39;.&#39; in todo: return [f&#39;{a}.{b}&#39; for a in stack for b in todo.split(&#39;|&#39;)] cur, rest = todo.split(&#39;.&#39;, 1) if stack == []: onward = cur.split(&#39;|&#39;) return _do_expand(onward, rest) else: onward = [f&#39;{a}.{b}&#39; for a in stack for b in cur.split(&#39;|&#39;)] return _do_expand(onward, rest) def expand_compressed(lines): output = [] for i in lines: form, lemma, postag = i.split(&#39; t&#39;) newtags = _do_expand([], postag) output.extend([f&quot;{form} t{lemma} t{itag}&quot; for itag in newtags]) return output . expand_compressed([l for l in dredzi.split(&#39; n&#39;) if l != &#39;&#39;]) . vals = expand_compressed([l for l in dredzi.split(&#39; n&#39;) if l != &#39;&#39;]) . tags = [a.split(&#39; t&#39;)[-1] for a in vals] . for tc in _list_to_check(&#39;num.ord&#39;): if not tc in tags: print(tc) . num.ord.mi.sg.acc num.ord.mp.pl.ins . dredzi = &quot;&quot;&quot; dr√´d≈ºi dr√´d≈ºi num.ord.mp|ma|mi.sg.nom|voc dr√´d≈ºi dr√´d≈ºi num.ord.mi.sg.acc dr√´g√¥ dr√´d≈ºi num.ord.f.sg.nom|voc dr√´d≈º√© dr√´d≈ºi num.ord.nt.sg.nom|acc|voc dr√´gƒÖ dr√´d≈ºi num.ord.f.sg.acc|ins dr√´d≈ºi dr√´d≈ºi num.ord.f.sg.gen|dat|loc dr√´d≈ºim dr√´d≈ºi num.ord.mp|ma|mi|nt.sg.loc|ins dr√´d≈º√© dr√´d≈ºi num.ord.nt|f|mi|ma.pl.nom|acc|voc dr√´d≈ºich dr√´d≈ºi num.ord.nt|f|mi|ma|mp.pl.gen|loc dr√´d≈ºima dr√´d≈ºi num.ord.nt|f|mi|ma|mp.pl.ins dr√´d≈º√©g√≤ dr√´d≈ºi num.ord.nt|mi|ma|mp.sg.gen dr√´d≈º√©g√≤ dr√´d≈ºi num.ord.ma|mp.sg.acc dr√´d≈º√©m√π dr√´d≈ºi num.ord.nt|mi|ma|mp.sg.dat dr√´d≈ºi dr√´d≈ºi num.ord.mp.pl.nom|voc dr√´d≈ºich dr√´d≈ºi num.ord.mp.pl.acc dr√´d≈ºim dr√´d≈ºi num.ord.nt|f|mi|ma|mp.pl.dat &quot;&quot;&quot; .",
            "url": "https://jimregan.github.io/notes/kashubian/declension/2021/04/23/check-kashubian-adjlike.html",
            "relUrl": "/kashubian/declension/2021/04/23/check-kashubian-adjlike.html",
            "date": " ‚Ä¢ Apr 23, 2021"
        }
        
    
  
    
        ,"post28": {
            "title": "Installing montreal-forced-aligner on kaggle",
            "content": "%%capture !wget https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/releases/download/v1.0.1/montreal-forced-aligner_linux.tar.gz . %%capture !tar zxvf montreal-forced-aligner_linux.tar.gz !rm montreal-forced-aligner_linux.tar.gz . !mv montreal-forced-aligner/bin montreal-forced-aligner/bb . !ln -s montreal-forced-aligner/lib/libpython3.6m.so.1.0 montreal-forced-aligner/lib/libpython3.6m.so .",
            "url": "https://jimregan.github.io/notes/kaggle/itworks/2021/04/20/mfa-on-kaggle.html",
            "relUrl": "/kaggle/itworks/2021/04/20/mfa-on-kaggle.html",
            "date": " ‚Ä¢ Apr 20, 2021"
        }
        
    
  
    
        ,"post29": {
            "title": "Irish lowercase with ICU",
            "content": "import icu . def transliterator_from_rules(name, rules): fromrules = icu.Transliterator.createFromRules(name, rules) icu.Transliterator.registerInstance(fromrules) return icu.Transliterator.createInstance(name) . irishlc_rules = &quot;&quot;&quot; :: NFD; $uvowel=[AEIOU]; $wb=[^[:L:][:M:]]; $wb { ([nt]) } $uvowel ‚Üí $1 &#39;-&#39;; :: lower; :: NFC; &quot;&quot;&quot; . irishlc = transliterator_from_rules(&#39;irishlc&#39;, irishlc_rules) . irishlc.transliterate(&quot;t√° an tUachtar√°n tar √©is a l√°mh a chur leis&quot;) . &#39;t√° an t-uachtar√°n tar √©is a l√°mh a chur leis&#39; .",
            "url": "https://jimregan.github.io/notes/icu/2021/04/18/irish-lower-with-icu.html",
            "relUrl": "/icu/2021/04/18/irish-lower-with-icu.html",
            "date": " ‚Ä¢ Apr 18, 2021"
        }
        
    
  
    
        ,"post30": {
            "title": "M2M100 sucks at Irish",
            "content": "Huggingface Transformers added the M2M 100 model, I tried it out and tweeted screenshots of the appalling output, so I thought I&#39;d recreate the translations to show they were very real. . !pip install sentencepiece transformers . from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer model = M2M100ForConditionalGeneration.from_pretrained(&quot;facebook/m2m100_418M&quot;) tokenizer = M2M100Tokenizer.from_pretrained(&quot;facebook/m2m100_418M&quot;) . def translate(text, src_lang=&quot;pl&quot;, trg_lang=&quot;ga&quot;): tokenizer.src_lang = src_lang encoded = tokenizer(text, return_tensors=&quot;pt&quot;) generated_tokens = model.generate(**encoded, forced_bos_token_id=tokenizer.get_lang_id(trg_lang)) print(tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)) . So, do massively multilingual MT models trained on massively crawled datasets lead to great output?No pic.twitter.com/SckNGTq09B . &mdash; Jim O&#39;Regan (@jimregan) April 12, 2021 . ‚ÄúOne must love one&#39;s wife‚Äù . translate(&quot;Trzeba kochaƒá swojƒÖ ≈ºonƒô&quot;) . [&#39;Brazzers f√≠se√°n catag√≥ir Inexperienced, D√©ag√≥ir Inexperienced&#39;] . pic.twitter.com/4b6DgbbhtE . &mdash; Jim O&#39;Regan (@jimregan) April 12, 2021 . ‚ÄúWhat are you on about?‚Äù or ‚ÄúWhat are you getting at?‚Äù . translate(&quot;O co Ci chodzi?&quot;) . [&#39;Brazzers f√≠se√°n catag√≥ir Inexperienced, D√©ag√≥ir Inexperienced&#39;] . It&#39;s almost poetic pic.twitter.com/IbJi1zvlrX . &mdash; Jim O&#39;Regan (@jimregan) April 12, 2021 . Let&#39;s try English: . translate(&quot;Hello, how are you?&quot;, src_lang=&#39;en&#39;) . [&#39;Brazzers f√≠se√°n catag√≥ir Inexperienced, D√©ag√≥ir Inexperienced, D√©ag√≥ir Inexperienced&#39;] . pic.twitter.com/GH4KtctnTI . &mdash; Jim O&#39;Regan (@jimregan) April 12, 2021 . How poetic. How about some actual poetry? (Pan Tadeusz) . translate(&quot;Litwo, Ojczyzno moja! ty jeste≈õ jak zdrowie; Ile ciƒô trzeba ceniƒá, ten tylko siƒô dowie, Kto ciƒô straci≈Ç.&quot;) . [&#39;Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers&#39;] . Switching to English output, it at least gives a decent-looking sentence. (It only looks decent, it&#39;s wrong) pic.twitter.com/4HyBQvTAux . &mdash; Jim O&#39;Regan (@jimregan) April 12, 2021 . ‚ÄúIt seems to me that you are not sober‚Äù . translate(&quot;Mi siƒô wydaje, ≈ºe nie jeste≈õ trze≈∫wy&quot;, trg_lang=&#39;en&#39;) . [&#39;I don‚Äôt think you‚Äôre trembling.&#39;] .",
            "url": "https://jimregan.github.io/notes/m2m100/badmt/2021/04/13/m2m100-sucks-at-irish.html",
            "relUrl": "/m2m100/badmt/2021/04/13/m2m100-sucks-at-irish.html",
            "date": " ‚Ä¢ Apr 13, 2021"
        }
        
    
  
    
        ,"post31": {
            "title": "Living Audio Irish",
            "content": "%%capture !wget https://ia800700.us.archive.org/6/items/ga.ie.cll.48000.tar/ga.ie.cll.48000.tar.gz . %%capture !wget https://raw.githubusercontent.com/Idlak/Living-Audio-Dataset/master/ga/text.xml . %%capture !tar zxvf ga.ie.cll.48000.tar.gz !rm ga.ie.cll.48000.tar.gz . %%capture !pip install bs4 . from bs4 import BeautifulSoup import unicodedata soup = BeautifulSoup(open(&#39;text.xml&#39;).read(), &#39;lxml&#39;) dataset = list() for entry in soup.find_all(&#39;fileid&#39;): current = dict() current[&#39;id&#39;] = entry[&#39;id&#39;] current[&#39;text&#39;] = unicodedata.normalize(&#39;NFC&#39;, entry.text.strip()) dataset.append(current) . !rm text.xml . def is_upper_vowel(letter): if letter in [&#39;A&#39;, &#39;E&#39;, &#39;I&#39;, &#39;O&#39;, &#39;U&#39;, &#39;√Å&#39;, &#39;√â&#39;, &#39;√ç&#39;, &#39;√ì&#39;, &#39;√ö&#39;]: return True else: return False def irish_lower(word): if len(word) &gt; 1 and word[0] in [&#39;n&#39;, &#39;t&#39;] and is_upper_vowel(word[1]): return word[0] + &#39;-&#39; + word[1:].lower() else: return word.lower() def irish_lower_sentence(sentence): return &quot; &quot;.join([irish_lower(w) for w in sentence.split(&quot; &quot;)]) . import re hyphens = &#39;cll_z0001_713 cll_z0001_804 cll_z0002_069 cll_z0002_296 cll_z0002_448 cll_z0002_481 cll_z0002_484 cll_z0002_495&#39;.split(&#39; &#39;) for entry in dataset: tmp = entry[&#39;text&#39;] tmp = re.sub(&#39; - &#39;, &#39; &#39;, tmp) tmp = re.sub(&#39; ‚Äì &#39;, &#39; &#39;, tmp) tmp = re.sub(&#39;[‚Äò‚Äú‚Äù &quot; . ?!,‚Äì‚Äî;:]&#39;, &#39;&#39;, tmp) if entry[&#39;id&#39;] in hyphens: tmp = re.sub(&#39; &#39;&#39;, &#39;&#39;, tmp) entry[&#39;sentence&#39;] = irish_lower_sentence(tmp) . for entry in dataset: entry[&#39;speaker&#39;] = &#39;cll&#39; entry[&#39;accent&#39;] = &#39;dublin&#39; entry[&#39;gender&#39;] = &#39;male&#39; entry[&#39;path&#39;] = &#39;../input/living-audio-irish-speech-corpus/48000_orig/{}.wav&#39;.format(entry[&#39;id&#39;]) . import json datasetjson = json.dumps(dataset) jsonf = open(&quot;living-audio.json&quot;, &quot;w&quot;) jsonf.write(datasetjson) jsonf.close() . !wget https://raw.githubusercontent.com/Idlak/idlak/master/idlak-data/ga/ie/lexicon-default.xml . --2021-04-20 21:54:40-- https://raw.githubusercontent.com/Idlak/idlak/master/idlak-data/ga/ie/lexicon-default.xml Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ... Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 405337 (396K) [text/plain] Saving to: ‚Äòlexicon-default.xml‚Äô lexicon-default.xml 100%[===================&gt;] 395.84K --.-KB/s in 0.03s 2021-04-20 21:54:40 (14.8 MB/s) - ‚Äòlexicon-default.xml‚Äô saved [405337/405337] . from bs4 import BeautifulSoup import unicodedata soup = BeautifulSoup(open(&#39;lexicon-default.xml&#39;).read(), &#39;lxml&#39;) lexicon = [] for entry in soup.find_all(&#39;lex&#39;): current = {} current[&#39;pron&#39;] = entry[&#39;pron&#39;] current[&#39;text&#39;] = unicodedata.normalize(&#39;NFC&#39;, entry.text.strip()) lexicon.append(current) . lexiconjson = json.dumps(lexicon) jsonf = open(&quot;ga-lexicon.json&quot;, &quot;w&quot;) jsonf.write(lexiconjson) jsonf.close() . !rm lexicon-default.xml . with open(&#39;lexicon.txt&#39;, &#39;w&#39;) as lextxt: for lex in lexicon: text = lex[&#39;text&#39;] cleaned = lex[&#39;pron&#39;].replace(&#39;0&#39;, &#39;&#39;).replace(&#39;1&#39;, &#39;&#39;).replace(&#39;2&#39;, &#39;&#39;) lextxt.write(f&#39;{text} {cleaned} n&#39;) .",
            "url": "https://jimregan.github.io/notes/speech/dataset/2021/04/06/living-audio-irish.html",
            "relUrl": "/speech/dataset/2021/04/06/living-audio-irish.html",
            "date": " ‚Ä¢ Apr 6, 2021"
        }
        
    
  
    
        ,"post32": {
            "title": "Install pynini on Colab",
            "content": "!pip install -q condacolab import condacolab condacolab.install() . ‚ú®üç∞‚ú® Everything looks OK! . !conda install -c conda-forge pynini . import pynini .",
            "url": "https://jimregan.github.io/notes/colab/pynini/2021/04/06/install-pynini-on-colab.html",
            "relUrl": "/colab/pynini/2021/04/06/install-pynini-on-colab.html",
            "date": " ‚Ä¢ Apr 6, 2021"
        }
        
    
  
    
        ,"post33": {
            "title": "Running wav2vec2 for Polish on Kashubian",
            "content": "%%capture import requests from bs4 import BeautifulSoup . URL=&#39;http://www.miesiecznikpomerania.pl/audio&#39; . req = requests.get(URL) soup = BeautifulSoup(req.content, &#39;html.parser&#39;) . contents = list() for part in soup.find_all(&#39;div&#39;, class_=&#39;sp-accordion-inner&#39;): out = {} audtag = part.find(&#39;audio&#39;) source = audtag.find(&#39;source&#39;) out[&#39;audio&#39;] = &#39;http://www.miesiecznikpomerania.pl{}&#39;.format(source[&#39;src&#39;]) audtag.decompose() out[&#39;text&#39;] = part.text.strip() contents.append(out) . for c in contents: !echo {c[&#39;audio&#39;]} &gt;&gt; input . %%capture !cat input|sort|uniq &gt; input.sorted !wget -i input.sorted . !cat input.sorted|grep -v uczba_5_Miedzy_niebem_a_ziemia_-_Najo_uczba|awk &#39;{print &quot;http://web.archive.org/web/&quot; $0}&#39; &gt; input.wayback . %%capture !wget -i input.wayback . import json with open(&#39;data.json&#39;, &#39;w&#39;) as outfile: json.dump(contents, outfile) . %%capture !for i in *.ogg;do ffmpeg -y -i &quot;$i&quot; -acodec pcm_s16le -ac 1 -ar 16000 &quot;$i.wav&quot;;done . %%capture !pip install librosa webrtcvad . # VAD wrapper is taken from PyTorch Speaker Verification: # https://github.com/HarryVolek/PyTorch_Speaker_Verification # Copyright (c) 2019, HarryVolek # License: BSD-3-Clause # based on https://github.com/wiseman/py-webrtcvad/blob/master/example.py # Copyright (c) 2016 John Wiseman # License: MIT import collections import contextlib import numpy as np import sys import librosa import wave import webrtcvad #from hparam import hparam as hp sr = 16000 def read_wave(path, sr): &quot;&quot;&quot;Reads a .wav file. Takes the path, and returns (PCM audio data, sample rate). Assumes sample width == 2 &quot;&quot;&quot; with contextlib.closing(wave.open(path, &#39;rb&#39;)) as wf: num_channels = wf.getnchannels() assert num_channels == 1 sample_width = wf.getsampwidth() assert sample_width == 2 sample_rate = wf.getframerate() assert sample_rate in (8000, 16000, 32000, 48000) pcm_data = wf.readframes(wf.getnframes()) data, _ = librosa.load(path, sr) assert len(data.shape) == 1 assert sr in (8000, 16000, 32000, 48000) return data, pcm_data class Frame(object): &quot;&quot;&quot;Represents a &quot;frame&quot; of audio data.&quot;&quot;&quot; def __init__(self, bytes, timestamp, duration): self.bytes = bytes self.timestamp = timestamp self.duration = duration def frame_generator(frame_duration_ms, audio, sample_rate): &quot;&quot;&quot;Generates audio frames from PCM audio data. Takes the desired frame duration in milliseconds, the PCM data, and the sample rate. Yields Frames of the requested duration. &quot;&quot;&quot; n = int(sample_rate * (frame_duration_ms / 1000.0) * 2) offset = 0 timestamp = 0.0 duration = (float(n) / sample_rate) / 2.0 while offset + n &lt; len(audio): yield Frame(audio[offset:offset + n], timestamp, duration) timestamp += duration offset += n def vad_collector(sample_rate, frame_duration_ms, padding_duration_ms, vad, frames): &quot;&quot;&quot;Filters out non-voiced audio frames. Given a webrtcvad.Vad and a source of audio frames, yields only the voiced audio. Uses a padded, sliding window algorithm over the audio frames. When more than 90% of the frames in the window are voiced (as reported by the VAD), the collector triggers and begins yielding audio frames. Then the collector waits until 90% of the frames in the window are unvoiced to detrigger. The window is padded at the front and back to provide a small amount of silence or the beginnings/endings of speech around the voiced frames. Arguments: sample_rate - The audio sample rate, in Hz. frame_duration_ms - The frame duration in milliseconds. padding_duration_ms - The amount to pad the window, in milliseconds. vad - An instance of webrtcvad.Vad. frames - a source of audio frames (sequence or generator). Returns: A generator that yields PCM audio data. &quot;&quot;&quot; num_padding_frames = int(padding_duration_ms / frame_duration_ms) # We use a deque for our sliding window/ring buffer. ring_buffer = collections.deque(maxlen=num_padding_frames) # We have two states: TRIGGERED and NOTTRIGGERED. We start in the # NOTTRIGGERED state. triggered = False voiced_frames = [] for frame in frames: is_speech = vad.is_speech(frame.bytes, sample_rate) if not triggered: ring_buffer.append((frame, is_speech)) num_voiced = len([f for f, speech in ring_buffer if speech]) # If we&#39;re NOTTRIGGERED and more than 90% of the frames in # the ring buffer are voiced frames, then enter the # TRIGGERED state. if num_voiced &gt; 0.9 * ring_buffer.maxlen: triggered = True start = ring_buffer[0][0].timestamp # We want to yield all the audio we see from now until # we are NOTTRIGGERED, but we have to start with the # audio that&#39;s already in the ring buffer. for f, s in ring_buffer: voiced_frames.append(f) ring_buffer.clear() else: # We&#39;re in the TRIGGERED state, so collect the audio data # and add it to the ring buffer. voiced_frames.append(frame) ring_buffer.append((frame, is_speech)) num_unvoiced = len([f for f, speech in ring_buffer if not speech]) # If more than 90% of the frames in the ring buffer are # unvoiced, then enter NOTTRIGGERED and yield whatever # audio we&#39;ve collected. if num_unvoiced &gt; 0.9 * ring_buffer.maxlen: triggered = False yield (start, frame.timestamp + frame.duration) ring_buffer.clear() voiced_frames = [] # If we have any leftover voiced audio when we run out of input, # yield it. if voiced_frames: yield (start, frame.timestamp + frame.duration) def VAD_chunk(aggressiveness, path): audio, byte_audio = read_wave(path, sr) vad = webrtcvad.Vad(int(aggressiveness)) frames = frame_generator(20, byte_audio, sr) frames = list(frames) times = vad_collector(sr, 20, 200, vad, frames) speech_times = [] speech_segs = [] for i, time in enumerate(times): start = np.round(time[0],decimals=2) end = np.round(time[1],decimals=2) j = start while j + .4 &lt; end: end_j = np.round(j+.4,decimals=2) speech_times.append((j, end_j)) speech_segs.append(audio[int(j*sr):int(end_j*sr)]) j = end_j else: speech_times.append((j, end)) speech_segs.append(audio[int(j*sr):int(end*sr)]) return speech_times, speech_segs . . # Based on code from PyTorch Speaker Verification: # https://github.com/HarryVolek/PyTorch_Speaker_Verification # Copyright (c) 2019, HarryVolek # Additions Copyright (c) 2021, Jim O&#39;Regan # License: MIT import numpy as np # wav2vec2&#39;s max duration is 40 seconds, using 39 by default # to be a little safer def vad_concat(times, segs, max_duration=39.0): &quot;&quot;&quot; Concatenate continuous times and their segments, where the end time of a segment is the same as the start time of the next Parameters: times: list of tuple (start, end) segs: list of segments (audio frames) max_duration: maximum duration of the resulting concatenated segments; the kernel size of wav2vec2 is 40 seconds, so the default max_duration is 39, to ensure the resulting list of segments will fit Returns: concat_times: list of tuple (start, end) concat_segs: list of segments (audio frames) &quot;&quot;&quot; absolute_maximum=40.0 if max_duration &gt; absolute_maximum: raise Exception(&#39;`max_duration` {:.2f} larger than kernel size (40 seconds)&#39;.format(max_duration)) # we take 0.0 to mean &quot;don&#39;t concatenate&quot; do_concat = (max_duration != 0.0) concat_seg = [] concat_times = [] seg_concat = segs[0] time_concat = times[0] for i in range(0, len(times)-1): can_concat = (times[i+1][1] - time_concat[0]) &lt; max_duration if time_concat[1] == times[i+1][0] and do_concat and can_concat: seg_concat = np.concatenate((seg_concat, segs[i+1])) time_concat = (time_concat[0], times[i+1][1]) else: concat_seg.append(seg_concat) seg_concat = segs[i+1] concat_times.append(time_concat) time_concat = times[i+1] else: concat_seg.append(seg_concat) concat_times.append(time_concat) return concat_times, concat_seg . . def make_dataset(concat_times, concat_segs): starts = [s[0] for s in concat_times] ends = [s[1] for s in concat_times] return {&#39;start&#39;: starts, &#39;end&#39;: ends, &#39;speech&#39;: concat_segs} . %%capture !pip install datasets . from datasets import Dataset def vad_to_dataset(path, max_duration): t,s = VAD_chunk(3, path) if max_duration &gt; 0.0: ct, cs = vad_concat(t, s, max_duration) dset = make_dataset(ct, cs) else: dset = make_dataset(t, s) return Dataset.from_dict(dset) . %%capture !pip install -q transformers . %%capture from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC # load model and tokenizer processor = Wav2Vec2Processor.from_pretrained(&quot;mbien/wav2vec2-large-xlsr-polish&quot;) model = Wav2Vec2ForCTC.from_pretrained(&quot;mbien/wav2vec2-large-xlsr-polish&quot;) model.to(&quot;cuda&quot;) . def speech_file_to_array_fn(batch): import torchaudio speech_array, sampling_rate = torchaudio.load(batch[&quot;path&quot;]) batch[&quot;speech&quot;] = speech_array[0].numpy() batch[&quot;sampling_rate&quot;] = sampling_rate batch[&quot;target_text&quot;] = batch[&quot;sentence&quot;] return batch def evaluate(batch): import torch inputs = processor(batch[&quot;speech&quot;], sampling_rate=16_000, return_tensors=&quot;pt&quot;, padding=True) with torch.no_grad(): logits = model(inputs.input_values.to(&quot;cuda&quot;), attention_mask=inputs.attention_mask.to(&quot;cuda&quot;)).logits pred_ids = torch.argmax(logits, dim=-1) batch[&quot;pred_strings&quot;] = processor.batch_decode(pred_ids) return batch . import json def process_wave(filename, duration): import json dataset = vad_to_dataset(filename, duration) result = dataset.map(evaluate, batched=True, batch_size=16) speechless = result.remove_columns([&#39;speech&#39;]) d=speechless.to_dict() tlog = list() for i in range(0, len(d[&#39;end&#39;]) - 1): out = dict() out[&#39;start&#39;] = d[&#39;start&#39;][i] out[&#39;end&#39;] = d[&#39;end&#39;][i] out[&#39;transcript&#39;] = d[&#39;pred_strings&#39;][i] tlog.append(out) with open(&#39;{}.tlog&#39;.format(filename), &#39;w&#39;) as outfile: json.dump(tlog, outfile) . import glob for f in glob.glob(&#39;./*.wav&#39;): print(f) process_wave(f, 10.0) . !ls *tlog|zip tlogs-csb.zip -@ .",
            "url": "https://jimregan.github.io/notes/wav2vec2/kashubian/2021/03/28/wav2vec2-polish-with-kashubian.html",
            "relUrl": "/wav2vec2/kashubian/2021/03/28/wav2vec2-polish-with-kashubian.html",
            "date": " ‚Ä¢ Mar 28, 2021"
        }
        
    
  
    
        ,"post34": {
            "title": "Using a wav2vec2 model with DSAlign",
            "content": "%%capture !pip install librosa webrtcvad . . The VAD wrapper is taken from PyTorch Speaker Verification, which is in turn is based on py-webrtcvad. . # VAD wrapper is taken from PyTorch Speaker Verification: # https://github.com/HarryVolek/PyTorch_Speaker_Verification # Copyright (c) 2019, HarryVolek # License: BSD-3-Clause # based on https://github.com/wiseman/py-webrtcvad/blob/master/example.py # Copyright (c) 2016 John Wiseman # License: MIT import collections import contextlib import numpy as np import sys import librosa import wave import webrtcvad #from hparam import hparam as hp sr = 16000 def read_wave(path, sr): &quot;&quot;&quot;Reads a .wav file. Takes the path, and returns (PCM audio data, sample rate). Assumes sample width == 2 &quot;&quot;&quot; with contextlib.closing(wave.open(path, &#39;rb&#39;)) as wf: num_channels = wf.getnchannels() assert num_channels == 1 sample_width = wf.getsampwidth() assert sample_width == 2 sample_rate = wf.getframerate() assert sample_rate in (8000, 16000, 32000, 48000) pcm_data = wf.readframes(wf.getnframes()) data, _ = librosa.load(path, sr) assert len(data.shape) == 1 assert sr in (8000, 16000, 32000, 48000) return data, pcm_data class Frame(object): &quot;&quot;&quot;Represents a &quot;frame&quot; of audio data.&quot;&quot;&quot; def __init__(self, bytes, timestamp, duration): self.bytes = bytes self.timestamp = timestamp self.duration = duration def frame_generator(frame_duration_ms, audio, sample_rate): &quot;&quot;&quot;Generates audio frames from PCM audio data. Takes the desired frame duration in milliseconds, the PCM data, and the sample rate. Yields Frames of the requested duration. &quot;&quot;&quot; n = int(sample_rate * (frame_duration_ms / 1000.0) * 2) offset = 0 timestamp = 0.0 duration = (float(n) / sample_rate) / 2.0 while offset + n &lt; len(audio): yield Frame(audio[offset:offset + n], timestamp, duration) timestamp += duration offset += n def vad_collector(sample_rate, frame_duration_ms, padding_duration_ms, vad, frames): &quot;&quot;&quot;Filters out non-voiced audio frames. Given a webrtcvad.Vad and a source of audio frames, yields only the voiced audio. Uses a padded, sliding window algorithm over the audio frames. When more than 90% of the frames in the window are voiced (as reported by the VAD), the collector triggers and begins yielding audio frames. Then the collector waits until 90% of the frames in the window are unvoiced to detrigger. The window is padded at the front and back to provide a small amount of silence or the beginnings/endings of speech around the voiced frames. Arguments: sample_rate - The audio sample rate, in Hz. frame_duration_ms - The frame duration in milliseconds. padding_duration_ms - The amount to pad the window, in milliseconds. vad - An instance of webrtcvad.Vad. frames - a source of audio frames (sequence or generator). Returns: A generator that yields PCM audio data. &quot;&quot;&quot; num_padding_frames = int(padding_duration_ms / frame_duration_ms) # We use a deque for our sliding window/ring buffer. ring_buffer = collections.deque(maxlen=num_padding_frames) # We have two states: TRIGGERED and NOTTRIGGERED. We start in the # NOTTRIGGERED state. triggered = False voiced_frames = [] for frame in frames: is_speech = vad.is_speech(frame.bytes, sample_rate) if not triggered: ring_buffer.append((frame, is_speech)) num_voiced = len([f for f, speech in ring_buffer if speech]) # If we&#39;re NOTTRIGGERED and more than 90% of the frames in # the ring buffer are voiced frames, then enter the # TRIGGERED state. if num_voiced &gt; 0.9 * ring_buffer.maxlen: triggered = True start = ring_buffer[0][0].timestamp # We want to yield all the audio we see from now until # we are NOTTRIGGERED, but we have to start with the # audio that&#39;s already in the ring buffer. for f, s in ring_buffer: voiced_frames.append(f) ring_buffer.clear() else: # We&#39;re in the TRIGGERED state, so collect the audio data # and add it to the ring buffer. voiced_frames.append(frame) ring_buffer.append((frame, is_speech)) num_unvoiced = len([f for f, speech in ring_buffer if not speech]) # If more than 90% of the frames in the ring buffer are # unvoiced, then enter NOTTRIGGERED and yield whatever # audio we&#39;ve collected. if num_unvoiced &gt; 0.9 * ring_buffer.maxlen: triggered = False yield (start, frame.timestamp + frame.duration) ring_buffer.clear() voiced_frames = [] # If we have any leftover voiced audio when we run out of input, # yield it. if voiced_frames: yield (start, frame.timestamp + frame.duration) def VAD_chunk(aggressiveness, path): audio, byte_audio = read_wave(path, sr) vad = webrtcvad.Vad(int(aggressiveness)) frames = frame_generator(20, byte_audio, sr) frames = list(frames) times = vad_collector(sr, 20, 200, vad, frames) speech_times = [] speech_segs = [] for i, time in enumerate(times): start = np.round(time[0],decimals=2) end = np.round(time[1],decimals=2) j = start while j + .4 &lt; end: end_j = np.round(j+.4,decimals=2) speech_times.append((j, end_j)) speech_segs.append(audio[int(j*sr):int(end_j*sr)]) j = end_j else: speech_times.append((j, end)) speech_segs.append(audio[int(j*sr):int(end*sr)]) return speech_times, speech_segs . . Running . I&#39;m going to use a video from YouTube as my input, so first I need to install youtube-dl . %%capture !pip install youtube-dl . I&#39;ve selected this video because it&#39;s a speech by the President of Ireland (and so copyright-free as a matter of public record), it has subtitles (in Irish, though listed as English), and the subtitles are quite faithful to what was spoken. . %%capture !youtube-dl --all-subs -o &#39;%(id)s&#39; VRg-a0qSGa8 . The audio needs to be a 16k wav, so I&#39;m converting it with ffmpeg. . %%capture !ffmpeg -i VRg-a0qSGa8.mkv -acodec pcm_s16le -ac 1 -ar 16000 VRg-a0qSGa8.wav . Next, I&#39;m using the VAD_chunk() function to get the start and end times, and audio segements of each part of the video with speech. . times, segs = VAD_chunk(3, &#39;VRg-a0qSGa8.wav&#39;) . The wav2vec2 models generally perform badly on short input, so vad_concat() concatenates the segments, as well as the times (for DSAlign). . # Based on code from PyTorch Speaker Verification: # https://github.com/HarryVolek/PyTorch_Speaker_Verification # Copyright (c) 2019, HarryVolek # Additions Copyright (c) 2021, Jim O&#39;Regan # License: MIT import numpy as np # wav2vec2&#39;s max duration is 40 seconds, using 39 by default # to be a little safer def vad_concat(times, segs, max_duration=39.0): &quot;&quot;&quot; Concatenate continuous times and their segments, where the end time of a segment is the same as the start time of the next Parameters: times: list of tuple (start, end) segs: list of segments (audio frames) max_duration: maximum duration of the resulting concatenated segments; the kernel size of wav2vec2 is 40 seconds, so the default max_duration is 39, to ensure the resulting list of segments will fit Returns: concat_times: list of tuple (start, end) concat_segs: list of segments (audio frames) &quot;&quot;&quot; absolute_maximum=40.0 if max_duration &gt; absolute_maximum: raise Exception(&#39;`max_duration` {:.2f} larger than kernel size (40 seconds)&#39;.format(max_duration)) # we take 0.0 to mean &quot;don&#39;t concatenate&quot; do_concat = (max_duration != 0.0) concat_seg = [] concat_times = [] seg_concat = segs[0] time_concat = times[0] for i in range(0, len(times)-1): can_concat = (times[i+1][1] - time_concat[0]) &lt; max_duration if time_concat[1] == times[i+1][0] and do_concat and can_concat: seg_concat = np.concatenate((seg_concat, segs[i+1])) time_concat = (time_concat[0], times[i+1][1]) else: concat_seg.append(seg_concat) seg_concat = segs[i+1] concat_times.append(time_concat) time_concat = times[i+1] else: concat_seg.append(seg_concat) concat_times.append(time_concat) return concat_times, concat_seg . . ntimes, nsegs = vad_concat(times, segs) . Next, I&#39;m putting the data into a dict that Huggingface datasets can read: . starts = [s[0] for s in ntimes] ends = [s[1] for s in ntimes] . dset = {&#39;start&#39;: starts, &#39;end&#39;: ends, &#39;speech&#39;: nsegs} . %%capture !pip install datasets . from datasets import Dataset dataset = Dataset.from_dict(dset) . dataset . Dataset({ features: [&#39;start&#39;, &#39;end&#39;, &#39;speech&#39;], num_rows: 137 }) . Now, the data is ready to plug into my wav2vec2 model. . %%capture !pip install -q transformers . %%capture from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC # load model and tokenizer processor = Wav2Vec2Processor.from_pretrained(&quot;jimregan/wav2vec2-large-xlsr-irish-basic&quot;) model = Wav2Vec2ForCTC.from_pretrained(&quot;jimregan/wav2vec2-large-xlsr-irish-basic&quot;) model.to(&quot;cuda&quot;) . Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained. . def speech_file_to_array_fn(batch): import torchaudio speech_array, sampling_rate = torchaudio.load(batch[&quot;path&quot;]) batch[&quot;speech&quot;] = speech_array[0].numpy() batch[&quot;sampling_rate&quot;] = sampling_rate batch[&quot;target_text&quot;] = batch[&quot;sentence&quot;] return batch def evaluate(batch): import torch inputs = processor(batch[&quot;speech&quot;], sampling_rate=16_000, return_tensors=&quot;pt&quot;, padding=True) with torch.no_grad(): logits = model(inputs.input_values.to(&quot;cuda&quot;), attention_mask=inputs.attention_mask.to(&quot;cuda&quot;)).logits pred_ids = torch.argmax(logits, dim=-1) batch[&quot;pred_strings&quot;] = processor.batch_decode(pred_ids) return batch . . result = dataset.map(evaluate, batched=True, batch_size=8) . . speechless = result.remove_columns([&#39;speech&#39;]) . d=speechless.to_dict() . tlog = list() for i in range(0, len(d[&#39;end&#39;]) - 1): out = dict() out[&#39;start&#39;] = d[&#39;start&#39;][i] out[&#39;end&#39;] = d[&#39;end&#39;][i] out[&#39;transcript&#39;] = d[&#39;pred_strings&#39;][i] tlog.append(out) . import json with open(&#39;/content/VRg-a0qSGa8.tlog&#39;, &#39;w&#39;) as outfile: json.dump(tlog, outfile) . Next, I&#39;m extracting the text content from the vtt file . !pip install webvtt-py . Requirement already satisfied: webvtt-py in /usr/local/lib/python3.7/dist-packages (0.4.6) Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from webvtt-py) (0.6.2) . def get_vtt_text(filename): import webvtt out = list() for sub in webvtt.read(filename): out.append(sub.text) return &#39; &#39;.join(out) . text = get_vtt_text(&#39;/content/VRg-a0qSGa8.en.vtt&#39;) . I can do some normalisation now: . text = text.replace(&#39;1901&#39;, &#39;naoi d√©ag is a haon&#39;) text = text.replace(&#39;2021&#39;, &#39;fiche is fiche is a haon&#39;) text = text.replace(&#39;Covid-19&#39;, &#39;covid a naoi d√©ag&#39;) text = text.replace(&#39;fiche fiche haon&#39;, &#39;fiche is fiche is a haon&#39;) . I want sentences, so I&#39;m going to use mosestokenizer to split the text (there aren&#39;t any specific abbreviations in this video, so the English splitter works fine. YMMV.) . %%capture !pip install mosestokenizer . The actual moses tokeniser has sentence splitting support for Irish, but the Python version was forked before that; we don&#39;t actually need any specific support for Irish here, so we can just use English. . from mosestokenizer import MosesSentenceSplitter with MosesSentenceSplitter(&#39;en&#39;) as splitsents: sents = splitsents([text]) . with open(&#39;/content/VRg-a0qSGa8.txt&#39;, &#39;w&#39;) as outfile: outfile.writelines([&#39; n&#39;.join(sents)]) . DSAlign requires an alphabet (1 character per line), so create that first . alpha=&quot;a√°bcde√©fghi√≠jklmno√≥pqrstu√∫vwxyz&#39;-&quot; alpha_chars = [char for char in alpha] . with open(&#39;/content/ga.alphabet&#39;, &#39;w&#39;) as outfile: outfile.writelines([&#39; n&#39;.join(alpha_chars)]) . Now, to install DSAlign and its dependencies: . %%capture !git clone https://github.com/mozilla/DSAlign . %%capture !apt-get install sox . %%capture import os os.chdir(&#39;DSAlign&#39;) !pip install -r requirements.txt . Now, I&#39;m ready to align: . !bin/align.sh --force --tlog /content/VRg-a0qSGa8.tlog --script /content/VRg-a0qSGa8.txt --aligned /content/VRg-a0qSGa8.aligned --text-meaningful-newlines --alphabet /content/ga.alphabet . bin/align.sh: line 3: /content/DSAlign/venv/bin/activate: No such file or directory INFO:root:Aligning 1 of 1 : 100.00% (elapsed: 00:00:04, speed: 0.25 it/s, ETA: 00:00:00) INFO:root:Aligned 24 fragments INFO:root:Dropped 112 fragments 466.67%: . 24 out of 136 fragments isn&#39;t great, but it&#39;s quite good considering the WER of the model (43.7%); the next step would be to add the aligned data to the training set, retrain, and repeat. .",
            "url": "https://jimregan.github.io/notes/wav2vec2/dsalign/2021/03/27/using-a-wav2vec2-model-with-dsalign.html",
            "relUrl": "/wav2vec2/dsalign/2021/03/27/using-a-wav2vec2-model-with-dsalign.html",
            "date": " ‚Ä¢ Mar 27, 2021"
        }
        
    
  
    
        ,"post35": {
            "title": "Training spaCy on IDT",
            "content": "!git clone https://github.com/UniversalDependencies/UD_Irish-IDT . Cloning into &#39;UD_Irish-IDT&#39;... remote: Enumerating objects: 32, done. remote: Counting objects: 100% (32/32), done. remote: Compressing objects: 100% (23/23), done. remote: Total 328 (delta 14), reused 25 (delta 9), pack-reused 296 Receiving objects: 100% (328/328), 3.63 MiB | 12.73 MiB/s, done. Resolving deltas: 100% (182/182), done. . !mkdir idt-json . !python -m spacy convert /content/UD_Irish-IDT/ga_idt-ud-train.conllu /content/idt-json . ‚úî Generated output file (2019 documents): /content/idt-json/ga_idt-ud-train.json . !python -m spacy convert /content/UD_Irish-IDT/ga_idt-ud-dev.conllu /content/idt-json . ‚úî Generated output file (451 documents): /content/idt-json/ga_idt-ud-dev.json . !wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ga.300.vec.gz !python -m spacy init-model ga /content/ga_vectors_cc --vectors-loc cc.ga.300.vec.gz . --2020-09-14 17:16:11-- https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ga.300.vec.gz Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.75.142, 104.22.74.142, ... Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 184422000 (176M) [binary/octet-stream] Saving to: ‚Äòcc.ga.300.vec.gz‚Äô cc.ga.300.vec.gz 100%[===================&gt;] 175.88M 44.2MB/s in 4.0s 2020-09-14 17:16:16 (43.8 MB/s) - ‚Äòcc.ga.300.vec.gz‚Äô saved [184422000/184422000] ‚úî Successfully created model 316836it [00:27, 11398.56it/s] ‚úî Loaded vectors from cc.ga.300.vec.gz ‚úî Sucessfully compiled vocab 317041 entries, 316836 vectors . WikiANN is currently only available through Google Drive . from google.colab import drive drive.mount(&#39;/gdrive&#39;) . Mounted at /gdrive . !cp /gdrive/My Drive/ga.tar.gz . . !tar zxvf ga.tar.gz . README.txt wikiann-ga.bio . !wget http://downloads.dbpedia.org/links/resources/wikidatadump/2017-07-07/enwiki/20170701/enwiki-20170701-interlanguage-links_wikidataorg.ttl . --2020-09-14 17:15:11-- http://downloads.dbpedia.org/links/resources/wikidatadump/2017-07-07/enwiki/20170701/enwiki-20170701-interlanguage-links_wikidataorg.ttl Resolving downloads.dbpedia.org (downloads.dbpedia.org)... 139.18.16.66 Connecting to downloads.dbpedia.org (downloads.dbpedia.org)|139.18.16.66|:80... connected. HTTP request sent, awaiting response... 200 OK Length: 1020894244 (974M) [text/turtle] Saving to: ‚Äòenwiki-20170701-interlanguage-links_wikidataorg.ttl‚Äô enwiki-20170701-int 100%[===================&gt;] 973.60M 18.7MB/s in 54s 2020-09-14 17:16:05 (18.1 MB/s) - ‚Äòenwiki-20170701-interlanguage-links_wikidataorg.ttl‚Äô saved [1020894244/1020894244] . !cat wikiann-ga.bio | awk &#39;(NF == 7){print $6}&#39;|sort|uniq|while read i;do grep &quot;/$i&gt;&quot; enwiki-20170701-interlanguage-links_wikidataorg.ttl &gt;&gt; filtered;done . !pip install danlp . Collecting danlp Downloading https://files.pythonhosted.org/packages/3c/79/96d0d3f3634ce75787d408383fa81cdd854552e27e4e279a985b511a6d88/danlp-0.0.9-py3-none-any.whl Collecting pyconll Downloading https://files.pythonhosted.org/packages/2c/6e/c325d0db05ac1b8d45645de903e4ba691d419e861c915c3d4ebfcaf8ac25/pyconll-2.2.1-py3-none-any.whl Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from danlp) (4.41.1) Requirement already satisfied: tweepy in /usr/local/lib/python3.6/dist-packages (from danlp) (3.6.0) Requirement already satisfied: requests&gt;=2.21 in /usr/local/lib/python3.6/dist-packages (from pyconll-&gt;danlp) (2.23.0) Requirement already satisfied: six&gt;=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy-&gt;danlp) (1.15.0) Requirement already satisfied: PySocks&gt;=1.5.7 in /usr/local/lib/python3.6/dist-packages (from tweepy-&gt;danlp) (1.7.1) Requirement already satisfied: requests-oauthlib&gt;=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy-&gt;danlp) (1.3.0) Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests&gt;=2.21-&gt;pyconll-&gt;danlp) (2020.6.20) Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.6/dist-packages (from requests&gt;=2.21-&gt;pyconll-&gt;danlp) (2.10) Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests&gt;=2.21-&gt;pyconll-&gt;danlp) (1.24.3) Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests&gt;=2.21-&gt;pyconll-&gt;danlp) (3.0.4) Requirement already satisfied: oauthlib&gt;=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib&gt;=0.7.0-&gt;tweepy-&gt;danlp) (3.1.0) Installing collected packages: pyconll, danlp Successfully installed danlp-0.0.9 pyconll-2.2.1 . import danlp.datasets.wiki_ann wa = danlp.datasets.wiki_ann._convert_wikiann_to_iob(&#39;wikiann-ga.bio&#39;, &#39;wikiann-ga.ner&#39;) . !head out . Colm _ _ B-PER √ì _ _ I-PER Ruairc _ _ I-PER Seosamh _ _ B-PER √ì _ _ I-PER Cain√≠n _ _ I-PER D√≥nal _ _ B-PER √ì _ _ I-PER . !python -m spacy convert -n 10 wikiann-ga.ner /content/idt-json/ . ‚Ñπ Auto-detected token-per-line NER format ‚Ñπ Grouping every 10 sentences into a document. ‚úî Generated output file (757 documents): /content/idt-json/wikiann-ga.json . !rm -rf models !mkdir models !python -m spacy train -v /content/ga_vectors_cc -p &#39;tagger,parser,ner&#39; ga models idt-json/ga_idt-ud-train.json idt-json/ga_idt-ud-dev.json . Training pipeline: [&#39;tagger&#39;, &#39;parser&#39;] Starting with blank model &#39;ga&#39; Loading vector from model &#39;/content/ga_vectors_cc&#39; Counting training words (limit=0) /usr/lib/python3.6/runpy.py:193: UserWarning: [W022] Training a new part-of-speech tagger using a model with no lemmatization rules or data. This means that the trained model may not be able to lemmatize correctly. If this is intentional or the language you&#39;re using doesn&#39;t have lemmatization data, you can ignore this warning by setting SPACY_WARNING_IGNORE=W022. If this is surprising, make sure you have the spacy-lookups-data package installed. &#34;__main__&#34;, mod_spec) Itn Tag Loss Tag % Dep Loss UAS LAS Token % CPU WPS -- - - 1 14058.829 90.650 43482.222 74.804 56.787 100.000 11293 2 6188.294 92.810 34097.493 79.836 66.009 100.000 11461 3 4475.949 93.400 30061.441 81.314 69.572 100.000 11930 4 3549.242 93.530 27752.841 82.784 71.759 100.000 11719 5 2916.639 93.570 25861.771 83.066 72.401 100.000 11616 6 2438.355 93.550 24533.545 83.133 72.726 100.000 12227 7 2084.913 93.500 22901.218 83.281 73.043 100.000 11842 8 1845.607 93.610 21836.129 83.516 73.346 100.000 12094 9 1698.212 93.630 20626.109 83.555 73.507 100.000 11907 10 1406.626 93.570 19251.761 83.712 73.978 100.000 11926 11 1366.677 93.620 18882.570 83.896 74.128 100.000 12023 12 1209.500 93.610 17836.598 83.968 74.177 100.000 11924 13 1140.886 93.640 17341.624 84.098 74.375 100.000 11522 14 1043.542 93.670 16748.375 83.992 74.292 100.000 11766 15 926.876 93.700 15727.938 84.183 74.572 100.000 11931 16 848.805 93.680 15002.112 84.059 74.427 100.000 11750 17 857.415 93.760 14686.168 84.075 74.465 100.000 11724 18 775.277 93.750 14028.872 84.091 74.603 100.000 11890 19 651.078 93.680 13698.526 84.215 74.794 100.000 11932 20 672.552 93.670 13036.999 84.356 74.879 100.000 11724 21 590.244 93.670 12162.862 84.468 75.048 100.000 11851 22 593.722 93.680 12494.905 84.441 75.122 100.000 11910 23 582.541 93.660 12110.757 84.351 75.032 100.000 11544 24 514.448 93.690 11635.750 84.232 74.879 100.000 11984 25 491.457 93.640 10942.966 84.226 74.816 100.000 12106 26 521.324 93.660 10958.952 84.232 74.779 100.000 12112 27 507.717 93.650 10907.860 84.255 74.790 100.000 11754 28 485.186 93.660 10149.477 84.143 74.666 100.000 11411 29 507.038 93.720 10331.116 84.165 74.644 100.000 11740 30 477.966 93.700 9649.121 84.300 74.891 100.000 11300 ‚úî Saved model to output directory models/model-final ‚úî Created best model models/model-best . !mkdir modelout !python -m spacy package --meta meta.json /content/models/model-best modelout . ‚úî Loaded meta.json from file meta.json ‚úî Successfully created package &#39;ga_idt_lg-1.0.0&#39; modelout/ga_idt_lg-1.0.0 To build the package, run `python setup.py sdist` in this directory. . import os os.chdir(&#39;/content/modelout/ga_idt_lg-1.0.0&#39;) !python setup.py sdist . running sdist running egg_info creating ga_idt_lg.egg-info writing ga_idt_lg.egg-info/PKG-INFO writing dependency_links to ga_idt_lg.egg-info/dependency_links.txt writing requirements to ga_idt_lg.egg-info/requires.txt writing top-level names to ga_idt_lg.egg-info/top_level.txt writing manifest file &#39;ga_idt_lg.egg-info/SOURCES.txt&#39; reading manifest file &#39;ga_idt_lg.egg-info/SOURCES.txt&#39; reading manifest template &#39;MANIFEST.in&#39; writing manifest file &#39;ga_idt_lg.egg-info/SOURCES.txt&#39; warning: sdist: standard file not found: should have one of README, README.rst, README.txt, README.md running check creating ga_idt_lg-1.0.0 creating ga_idt_lg-1.0.0/ga_idt_lg creating ga_idt_lg-1.0.0/ga_idt_lg.egg-info creating ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0 creating ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/parser creating ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/tagger creating ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/vocab copying files to ga_idt_lg-1.0.0... copying MANIFEST.in -&gt; ga_idt_lg-1.0.0 copying meta.json -&gt; ga_idt_lg-1.0.0 copying setup.py -&gt; ga_idt_lg-1.0.0 copying ga_idt_lg/__init__.py -&gt; ga_idt_lg-1.0.0/ga_idt_lg copying ga_idt_lg/meta.json -&gt; ga_idt_lg-1.0.0/ga_idt_lg copying ga_idt_lg.egg-info/PKG-INFO -&gt; ga_idt_lg-1.0.0/ga_idt_lg.egg-info copying ga_idt_lg.egg-info/SOURCES.txt -&gt; ga_idt_lg-1.0.0/ga_idt_lg.egg-info copying ga_idt_lg.egg-info/dependency_links.txt -&gt; ga_idt_lg-1.0.0/ga_idt_lg.egg-info copying ga_idt_lg.egg-info/not-zip-safe -&gt; ga_idt_lg-1.0.0/ga_idt_lg.egg-info copying ga_idt_lg.egg-info/requires.txt -&gt; ga_idt_lg-1.0.0/ga_idt_lg.egg-info copying ga_idt_lg.egg-info/top_level.txt -&gt; ga_idt_lg-1.0.0/ga_idt_lg.egg-info copying ga_idt_lg/ga_idt_lg-1.0.0/meta.json -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0 copying ga_idt_lg/ga_idt_lg-1.0.0/tokenizer -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0 copying ga_idt_lg/ga_idt_lg-1.0.0/parser/cfg -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/parser copying ga_idt_lg/ga_idt_lg-1.0.0/parser/model -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/parser copying ga_idt_lg/ga_idt_lg-1.0.0/parser/moves -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/parser copying ga_idt_lg/ga_idt_lg-1.0.0/tagger/cfg -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/tagger copying ga_idt_lg/ga_idt_lg-1.0.0/tagger/model -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/tagger copying ga_idt_lg/ga_idt_lg-1.0.0/tagger/tag_map -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/tagger copying ga_idt_lg/ga_idt_lg-1.0.0/vocab/key2row -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/vocab copying ga_idt_lg/ga_idt_lg-1.0.0/vocab/lexemes.bin -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/vocab copying ga_idt_lg/ga_idt_lg-1.0.0/vocab/strings.json -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/vocab copying ga_idt_lg/ga_idt_lg-1.0.0/vocab/vectors -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/vocab Writing ga_idt_lg-1.0.0/setup.cfg creating dist Creating tar archive removing &#39;ga_idt_lg-1.0.0&#39; (and everything under it) . !cat /content/models/model-best/meta.json . { &#34;lang&#34;:&#34;ga&#34;, &#34;name&#34;:&#34;model&#34;, &#34;version&#34;:&#34;0.0.0&#34;, &#34;spacy_version&#34;:&#34;&gt;=2.2.4&#34;, &#34;description&#34;:&#34;&#34;, &#34;author&#34;:&#34;&#34;, &#34;email&#34;:&#34;&#34;, &#34;url&#34;:&#34;&#34;, &#34;license&#34;:&#34;&#34;, &#34;vectors&#34;:{ &#34;width&#34;:300, &#34;vectors&#34;:316836, &#34;keys&#34;:316836, &#34;name&#34;:&#34;ga_model.vectors&#34; }, &#34;pipeline&#34;:[ &#34;tagger&#34;, &#34;parser&#34; ], &#34;factories&#34;:{ &#34;tagger&#34;:&#34;tagger&#34;, &#34;parser&#34;:&#34;parser&#34; }, &#34;labels&#34;:{ &#34;tagger&#34;:[ &#34;!&#34;, &#34;.&#34;, &#34;...&#34;, &#34;?&#34;, &#34;Abr&#34;, &#34;Ad&#34;, &#34;Adj&#34;, &#34;Art&#34;, &#34;CM&#34;, &#34;CU&#34;, &#34;Cmp&#34;, &#34;Cmpd&#34;, &#34;CmpdNoGen&#34;, &#34;Comp&#34;, &#34;Cond&#34;, &#34;Coord&#34;, &#34;Cop&#34;, &#34;Cp&#34;, &#34;Deg&#34;, &#34;Dem&#34;, &#34;Det&#34;, &#34;Dir&#34;, &#34;Foreign&#34;, &#34;FutInd&#34;, &#34;Gn&#34;, &#34;Idf&#34;, &#34;Imper&#34;, &#34;Inf&#34;, &#34;Item&#34;, &#34;Itj&#34;, &#34;Its&#34;, &#34;Loc&#34;, &#34;Nm&#34;, &#34;Noun&#34;, &#34;Num&#34;, &#34;PastImp&#34;, &#34;PastInd&#34;, &#34;Pat&#34;, &#34;Pers&#34;, &#34;Poss&#34;, &#34;Prep&#34;, &#34;PresImp&#34;, &#34;PresInd&#34;, &#34;PresSubj&#34;, &#34;Pron&#34;, &#34;Punct&#34;, &#34;Q&#34;, &#34;Ref&#34;, &#34;Rel&#34;, &#34;Simp&#34;, &#34;Subord&#34;, &#34;Subst&#34;, &#34;Sup&#34;, &#34;Temp&#34;, &#34;Unknown&#34;, &#34;VD&#34;, &#34;VI&#34;, &#34;VT&#34;, &#34;VTI&#34;, &#34;Vb&#34;, &#34;Voc&#34;, &#34;Web&#34;, &#34;_SP&#34;, &#34;cionn&#34; ], &#34;parser&#34;:[ &#34;ROOT&#34;, &#34;acl:relcl&#34;, &#34;advcl&#34;, &#34;advmod&#34;, &#34;amod&#34;, &#34;appos&#34;, &#34;case&#34;, &#34;cc&#34;, &#34;ccomp&#34;, &#34;compound&#34;, &#34;conj&#34;, &#34;cop&#34;, &#34;csubj:cleft&#34;, &#34;csubj:cop&#34;, &#34;dep&#34;, &#34;det&#34;, &#34;fixed&#34;, &#34;flat&#34;, &#34;flat:name&#34;, &#34;mark&#34;, &#34;mark:prt&#34;, &#34;nmod&#34;, &#34;nmod:poss&#34;, &#34;nsubj&#34;, &#34;nummod&#34;, &#34;obj&#34;, &#34;obl&#34;, &#34;obl:prep&#34;, &#34;obl:tmod&#34;, &#34;parataxis&#34;, &#34;punct&#34;, &#34;xcomp&#34;, &#34;xcomp:pred&#34; ] }, &#34;accuracy&#34;:{ &#34;tags_acc&#34;:92.23, &#34;token_acc&#34;:100.0, &#34;las&#34;:68.3640850205, &#34;uas&#34;:80.5899837362, &#34;las_per_type&#34;:{ &#34;nummod&#34;:{ &#34;p&#34;:70.0, &#34;r&#34;:61.5384615385, &#34;f&#34;:65.4970760234 }, &#34;root&#34;:{ &#34;p&#34;:88.0266075388, &#34;r&#34;:88.0266075388, &#34;f&#34;:88.0266075388 }, &#34;case&#34;:{ &#34;p&#34;:88.8535031847, &#34;r&#34;:91.7763157895, &#34;f&#34;:90.2912621359 }, &#34;obl&#34;:{ &#34;p&#34;:47.0031545741, &#34;r&#34;:54.9815498155, &#34;f&#34;:50.6802721088 }, &#34;mark:prt&#34;:{ &#34;p&#34;:71.1538461538, &#34;r&#34;:81.9620253165, &#34;f&#34;:76.1764705882 }, &#34;ccomp&#34;:{ &#34;p&#34;:40.2777777778, &#34;r&#34;:47.5409836066, &#34;f&#34;:43.6090225564 }, &#34;nsubj&#34;:{ &#34;p&#34;:75.1824817518, &#34;r&#34;:79.7213622291, &#34;f&#34;:77.3854244929 }, &#34;obj&#34;:{ &#34;p&#34;:55.5555555556, &#34;r&#34;:49.2957746479, &#34;f&#34;:52.2388059701 }, &#34;nmod&#34;:{ &#34;p&#34;:52.912142152, &#34;r&#34;:54.8618219038, &#34;f&#34;:53.8693467337 }, &#34;mark&#34;:{ &#34;p&#34;:82.7715355805, &#34;r&#34;:72.6973684211, &#34;f&#34;:77.408056042 }, &#34;xcomp&#34;:{ &#34;p&#34;:60.4743083004, &#34;r&#34;:65.3846153846, &#34;f&#34;:62.8336755647 }, &#34;acl:relcl&#34;:{ &#34;p&#34;:47.2602739726, &#34;r&#34;:53.488372093, &#34;f&#34;:50.1818181818 }, &#34;xcomp:pred&#34;:{ &#34;p&#34;:44.0476190476, &#34;r&#34;:59.6774193548, &#34;f&#34;:50.6849315068 }, &#34;amod&#34;:{ &#34;p&#34;:57.5438596491, &#34;r&#34;:54.3046357616, &#34;f&#34;:55.8773424191 }, &#34;det&#34;:{ &#34;p&#34;:92.8480204342, &#34;r&#34;:94.0491591203, &#34;f&#34;:93.4447300771 }, &#34;csubj:cleft&#34;:{ &#34;p&#34;:47.2222222222, &#34;r&#34;:27.4193548387, &#34;f&#34;:34.693877551 }, &#34;obl:prep&#34;:{ &#34;p&#34;:77.6041666667, &#34;r&#34;:65.6387665198, &#34;f&#34;:71.1217183771 }, &#34;advcl&#34;:{ &#34;p&#34;:54.4, &#34;r&#34;:49.2753623188, &#34;f&#34;:51.711026616 }, &#34;parataxis&#34;:{ &#34;p&#34;:42.4242424242, &#34;r&#34;:27.4509803922, &#34;f&#34;:33.3333333333 }, &#34;nmod:poss&#34;:{ &#34;p&#34;:73.4939759036, &#34;r&#34;:75.3086419753, &#34;f&#34;:74.3902439024 }, &#34;cc&#34;:{ &#34;p&#34;:78.9473684211, &#34;r&#34;:79.5454545455, &#34;f&#34;:79.2452830189 }, &#34;conj&#34;:{ &#34;p&#34;:42.7609427609, &#34;r&#34;:42.0529801325, &#34;f&#34;:42.4040066778 }, &#34;dep&#34;:{ &#34;p&#34;:0.0, &#34;r&#34;:0.0, &#34;f&#34;:0.0 }, &#34;compound&#34;:{ &#34;p&#34;:75.0, &#34;r&#34;:26.0869565217, &#34;f&#34;:38.7096774194 }, &#34;flat&#34;:{ &#34;p&#34;:64.1025641026, &#34;r&#34;:64.9350649351, &#34;f&#34;:64.5161290323 }, &#34;cop&#34;:{ &#34;p&#34;:69.3251533742, &#34;r&#34;:70.625, &#34;f&#34;:69.9690402477 }, &#34;flat:name&#34;:{ &#34;p&#34;:63.4782608696, &#34;r&#34;:51.4084507042, &#34;f&#34;:56.8093385214 }, &#34;obl:tmod&#34;:{ &#34;p&#34;:66.6666666667, &#34;r&#34;:2.7397260274, &#34;f&#34;:5.2631578947 }, &#34;advmod&#34;:{ &#34;p&#34;:66.2745098039, &#34;r&#34;:65.0, &#34;f&#34;:65.6310679612 }, &#34;appos&#34;:{ &#34;p&#34;:21.9512195122, &#34;r&#34;:20.9302325581, &#34;f&#34;:21.4285714286 }, &#34;flat:foreign&#34;:{ &#34;p&#34;:0.0, &#34;r&#34;:0.0, &#34;f&#34;:0.0 }, &#34;fixed&#34;:{ &#34;p&#34;:74.7663551402, &#34;r&#34;:61.0687022901, &#34;f&#34;:67.2268907563 }, &#34;csubj:cop&#34;:{ &#34;p&#34;:62.5, &#34;r&#34;:55.5555555556, &#34;f&#34;:58.8235294118 }, &#34;discourse&#34;:{ &#34;p&#34;:0.0, &#34;r&#34;:0.0, &#34;f&#34;:0.0 }, &#34;case:voc&#34;:{ &#34;p&#34;:0.0, &#34;r&#34;:0.0, &#34;f&#34;:0.0 }, &#34;vocative&#34;:{ &#34;p&#34;:0.0, &#34;r&#34;:0.0, &#34;f&#34;:0.0 } } }, &#34;speed&#34;:{ &#34;cpu&#34;:13038.7132631094, &#34;gpu&#34;:null, &#34;nwords&#34;:10000 } } . import os os.chdir(&#39;/content&#39;) !rm -rf modelout !mkdir modelout !rm meta.json . !cat meta.json . { &#34;name&#34;: &#34;ga_idt_sm&#34;, &#34;lang&#34;: &#34;ga&#34;, &#34;version&#34;: &#34;1.0.0&#34;, &#34;spacy_version&#34;: &#34;&gt;=2.0.0,&lt;3.0.0&#34;, &#34;description&#34;: &#34;Irish model for spaCy trained on IDT&#34;, &#34;author&#34;: &#34;Jim O&#39;Regan&#34;, &#34;email&#34;: &#34;jaoregan@tcd.ie&#34;, &#34;license&#34;: &#34;CC BY-SA 3.0&#34;, &#34;pipeline&#34;: [&#34;tagger&#34;, &#34;parser&#34;, &#34;ner&#34;] } .",
            "url": "https://jimregan.github.io/notes/spacy/idt/2020/09/14/train-spacy-idt.html",
            "relUrl": "/spacy/idt/2020/09/14/train-spacy-idt.html",
            "date": " ‚Ä¢ Sep 14, 2020"
        }
        
    
  
    
        ,"post36": {
            "title": "Javascript hoops",
            "content": "!git clone https://github.com/jimregan/coco-ssd-ga . Cloning into &#39;coco-ssd-ga&#39;... remote: Enumerating objects: 55, done. remote: Counting objects: 100% (55/55), done. remote: Compressing objects: 100% (38/38), done. remote: Total 55 (delta 17), reused 48 (delta 14), pack-reused 0 Unpacking objects: 100% (55/55), done. . import os os.chdir(&#39;coco-ssd-ga&#39;) . !npm install -g yarn rimraf browserify typescript ts-node @tensorflow/tfjs-core @tensorflow/tfjs-converter . &gt; yarn@1.22.10 preinstall /tools/node/lib/node_modules/yarn &gt; :; (node ./preinstall.js &gt; /dev/null 2&gt;&amp;1 || true) /tools/node/bin/browserify -&gt; /tools/node/lib/node_modules/browserify/bin/cmd.js /tools/node/bin/rimraf -&gt; /tools/node/lib/node_modules/rimraf/bin.js /tools/node/bin/ts-node -&gt; /tools/node/lib/node_modules/ts-node/dist/bin.js /tools/node/bin/ts-script -&gt; /tools/node/lib/node_modules/ts-node/dist/bin-script-deprecated.js /tools/node/bin/ts-node-script -&gt; /tools/node/lib/node_modules/ts-node/dist/bin-script.js /tools/node/bin/ts-node-transpile-only -&gt; /tools/node/lib/node_modules/ts-node/dist/bin-transpile.js /tools/node/bin/tsc -&gt; /tools/node/lib/node_modules/typescript/bin/tsc /tools/node/bin/tsserver -&gt; /tools/node/lib/node_modules/typescript/bin/tsserver /tools/node/bin/yarn -&gt; /tools/node/lib/node_modules/yarn/bin/yarn.js /tools/node/bin/yarnpkg -&gt; /tools/node/lib/node_modules/yarn/bin/yarn.js + rimraf@3.0.2 + yarn@1.22.10 + browserify@17.0.0 + ts-node@9.1.1 + @tensorflow/tfjs-converter@3.5.0 + @tensorflow/tfjs-core@3.5.0 + typescript@4.2.4 added 203 packages from 137 contributors in 12.754s . !npm install . npm WARN deprecated fsevents@2.1.3: &#34;Please update to latest v2.3 or v2.2&#34; npm WARN deprecated core-js@2.6.12: core-js@&lt;3 is no longer maintained and not recommended for usage due to the number of issues. Please, upgrade your dependencies to the actual version of core-js@3. &gt; core-js@2.6.12 postinstall /content/coco-ssd-ga/node_modules/core-js &gt; node -e &#34;try{require(&#39;./postinstall&#39;)}catch(e){}&#34; Thank you for using core-js ( https://github.com/zloirock/core-js ) for polyfilling JavaScript standard library! The project needs your help! Please consider supporting of core-js on Open Collective or Patreon: &gt; https://opencollective.com/core-js &gt; https://www.patreon.com/zloirock Also, the author of core-js ( https://github.com/zloirock ) is looking for a good job -) npm notice created a lockfile as package-lock.json. You should commit this file. npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@~2.1.2 (node_modules/rollup/node_modules/fsevents): npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@2.1.3: wanted {&#34;os&#34;:&#34;darwin&#34;,&#34;arch&#34;:&#34;any&#34;} (current: {&#34;os&#34;:&#34;linux&#34;,&#34;arch&#34;:&#34;x64&#34;}) npm WARN @rollup/plugin-typescript@3.1.1 requires a peer of rollup@^1.20.0 but none is installed. You must install peer dependencies yourself. added 196 packages from 157 contributors and audited 197 packages in 10.534s 10 packages are looking for funding run `npm fund` for details found 0 vulnerabilities ‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ ‚îÇ ‚îÇ ‚îÇ New major version of npm available! 6.14.8 ‚Üí 7.11.1 ‚îÇ ‚îÇ Changelog: https://github.com/npm/cli/releases/tag/v7.11.1 ‚îÇ ‚îÇ Run npm install -g npm to update! ‚îÇ ‚îÇ ‚îÇ ‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ . !yarn build . yarn run v1.22.10 $ rimraf dist &amp;&amp; tsc Done in 6.76s. . !npm install yalc . npm WARN @rollup/plugin-typescript@3.1.1 requires a peer of rollup@^1.20.0 but none is installed. You must install peer dependencies yourself. npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@2.1.3 (node_modules/fsevents): npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@2.1.3: wanted {&#34;os&#34;:&#34;darwin&#34;,&#34;arch&#34;:&#34;any&#34;} (current: {&#34;os&#34;:&#34;linux&#34;,&#34;arch&#34;:&#34;x64&#34;}) + yalc@1.0.0-pre.51 updated 1 package and audited 197 packages in 2.25s 8 packages are looking for funding run `npm fund` for details found 0 vulnerabilities . !npm install -g cross-env . /tools/node/bin/cross-env -&gt; /tools/node/lib/node_modules/cross-env/src/bin/cross-env.js /tools/node/bin/cross-env-shell -&gt; /tools/node/lib/node_modules/cross-env/src/bin/cross-env-shell.js + cross-env@7.0.3 added 7 packages from 5 contributors in 0.789s . !npm install -g @tensorflow/tfjs-core @tensorflow/tfjs-converter rollup yalc !npm install --save install !yarn run publish-local . . /tools/node/bin/rollup -&gt; /tools/node/lib/node_modules/rollup/dist/bin/rollup /tools/node/bin/yalc -&gt; /tools/node/lib/node_modules/yalc/src/yalc.js npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@~2.3.1 (node_modules/rollup/node_modules/fsevents): npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@2.3.2: wanted {&#34;os&#34;:&#34;darwin&#34;,&#34;arch&#34;:&#34;any&#34;} (current: {&#34;os&#34;:&#34;linux&#34;,&#34;arch&#34;:&#34;x64&#34;}) + rollup@2.45.2 + yalc@1.0.0-pre.51 + @tensorflow/tfjs-core@3.5.0 + @tensorflow/tfjs-converter@3.5.0 updated 4 packages in 3.883s npm WARN @rollup/plugin-typescript@3.1.1 requires a peer of rollup@^1.20.0 but none is installed. You must install peer dependencies yourself. npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@2.1.3 (node_modules/fsevents): npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@2.1.3: wanted {&#34;os&#34;:&#34;darwin&#34;,&#34;arch&#34;:&#34;any&#34;} (current: {&#34;os&#34;:&#34;linux&#34;,&#34;arch&#34;:&#34;x64&#34;}) + install@0.13.0 added 1 package from 1 contributor and audited 198 packages in 1.647s 10 packages are looking for funding run `npm fund` for details found 0 vulnerabilities yarn run v1.22.10 $ yarn build &amp;&amp; rollup -c &amp;&amp; yalc push . $ rimraf dist &amp;&amp; tsc src/index.ts ‚Üí dist/coco-ssd.node.js... created dist/coco-ssd.node.js in 8.9s coco-ssd-ga@2.1.0 published in store. Done in 16.51s. . !npm install -g browserify . /tools/node/bin/browserify -&gt; /tools/node/lib/node_modules/browserify/bin/cmd.js + browserify@17.0.0 updated 1 package in 4.871s . !npm i minify -g . /tools/node/bin/minify -&gt; /tools/node/lib/node_modules/minify/bin/minify.js + minify@7.0.1 added 26 packages from 52 contributors in 1.951s . !browserify /content/coco-ssd-ga/dist/coco-ssd.node.js --s cocoGa -o /content/coco-ssd-ga/dist/coco-ssd.browser.js . !minify /content/coco-ssd-ga/dist/coco-ssd.browser.js &gt; /content/coco-ssd-ga/dist/coco-ssd.min.js .",
            "url": "https://jimregan.github.io/notes/web/coco-ssd/2020/08/12/coco-ssd-ga.html",
            "relUrl": "/web/coco-ssd/2020/08/12/coco-ssd-ga.html",
            "date": " ‚Ä¢ Aug 12, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats.¬†&#8617; . |",
          "url": "https://jimregan.github.io/notes/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  

  

  
  

  
      ,"page12": {
          "title": "",
          "content": "Sitemap: {{ ‚Äúsitemap.xml‚Äù | absolute_url }} | .",
          "url": "https://jimregan.github.io/notes/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}