{
  
    
        "post0": {
            "title": "Converting Ó Raghallaigh (2010)",
            "content": "This notebook contains a re-implementation of the &quot;global&quot; phonetiser from Brian Ó Raghallaigh&#39;s Ph.D. thesis using rbg2p. . Brian Ó Raghallaigh (2010). Multi-dialect phonetisation for Irish text-to-speech synthesis: a modular approach. (Doctoral thesis, Trinity College, Dublin), Appendix B.1 . @phdthesis{oraghallaigh2010multidialect, author = {Brian Ó~Raghallaigh}, title = {Multi-dialect phonetisation for {I}rish text-to-speech synthesis: a modular approach}, school = {Trinity College, Dublin}, year = 2010, address = {Dublin, Ireland}, month = 9, } . The initial run (after small conversion errors were corrected) gave the following set of errors: . FAILED TEST: for &#39;comhair&#39;, expected /K OO RJ/, got /K OMH RJ/ FAILED TEST: for &#39;airde&#39;, expected /AA RJ DJ @@/, got /AA R DJ @@/ FAILED TEST: for &#39;bogha&#39;, expected /B OGH/, got /B OGH @@/ FAILED TEST: for &#39;comhar&#39;, expected /K OO R/, got /K OMH R/ FAILED TEST: for &#39;ceird&#39;, expected /KJ EE RJ DJ/, got /KJ EE R DJ/ FAILED TEST: for &#39;riail&#39;, expected /RJ I@ LJ/, got /R I@ LJ/ FAILED TEST: for &#39;giuirléid&#39;, expected /GJ UU RJ LJ EE DJ/, got /GJ UU R LJ EE DJ/ FAILED TEST: for &#39;boird&#39;, expected /B OO RJ DJ/, got /B OO R DJ/ FAILED TEST: for &#39;bantaboic&#39;, expected /B A NN T @@ B @@ KJ/, got /B A NN T @@ B OI KJ/ FAILED TEST: for &#39;comhar&#39;, expected /K OO R/, got /K OMH R/ FAILED TEST: for &#39;bantaboc&#39;, expected /B A NN T @@ B @@ K/, got /B A NN T @@ B O K/ FAILED TEST: for &#39;guird&#39;, expected /G UU RJ DJ/, got /G UU R DJ/ FAILED TEST: for &#39;bhfianaise&#39;, expected /VJ I@ NN @@ SJ @@/, got /V I@ NN @@ SJ @@/ FAILED TEST: for &#39;leathbhosca&#39;, expected /LJ A V @@ S K @@/, got /LJ A V O S K @@/ FAILED TEST: for &#39;rithfeadh&#39;, expected /RJ I XJ ADH/, got /R I XJ ADH/ FAILED TEST: for &#39;tsagairt&#39;, expected /T A G @@ RJ TJ/, got /T A G @@ R TJ/ 16 OF 168 TESTS FAILED FOR briain.g2p exit status 1 . The most consistent source of errors is slender &#39;r&#39; in environments (word initially, before &#39;d&#39;, etc.) where the rule is that they should be left broad; I corrected the tests (which were intended only as tests of the vowels). . Of the remainder, bogha represents a missing rule, while comhar/comhair does not fit with the given rule, so I added a somewhat lexicalised rule to handle it (and its mutated forms) specifically. . This leaves these words: . FAILED TEST: for &#39;bantaboic&#39;, expected /B A NN T @@ B @@ KJ/, got /B A NN T @@ B OI KJ/ FAILED TEST: for &#39;bantaboc&#39;, expected /B A NN T @@ B @@ K/, got /B A NN T @@ B O K/ FAILED TEST: for &#39;leathbhosca&#39;, expected /LJ A V @@ S K @@/, got /LJ A V O S K @@/ . leathbhosca is a compound, and keeping bhosca as V O S K @@ is correct; otherwise, the rule which for other short vowels converts to schwa is specifically converted to O, so I disabled these rules. . %%writefile oraghallaigh.g2p CHARACTER_SET &quot;aábcdeéfghiíjklmnoópqrstuúvwxyz&#39;-’&quot; DEFAULT_PHONEME &quot;_&quot; PHONEME_DELIMITER &quot; &quot; #VAR ALPHA [abcdefghijklmnopqrstuvwxyz] VAR CONS [bcdfghjklmnpqrstvwxyz] VAR CONSS [bcdfghjklmnpqrstvwxyz]* VAR CONSP [bcdfghjklmnpqrstvwxyz]+ # including &#39;#&#39; doesn&#39;t work, so those rules were duplicated #VAR NONSYLLABIC (á|b|c|d|f|g|h|j|k|l|m|n|ó|p|q|r|s|t|ú|v|w|x|y|z|#) VAR NONSYLLABIC [ábcdfghjklmnópqrstúvwxyz] // broad future/conditional endings VAR BFCE (á|adh|aidh|aidís|aimid|aimis|ainn|as) // slender future/conditional endings VAR SFCE (eá|eadh|idh|idís|imid|imis|inn) #VAR L (ll|l) #VAR MN [mn] VAR FMP [fmp] #VAR LNR [lnr] VAR LNRP [lnr]+ #VAR LRST [lrst] VAR DNLST [dnlst] #VAR DNST [dnst] VAR RDNLR (rd|rn|rl|rr) VAR VOWEL [aáeéiíoóuú] VAR VOWELS [aáeéiíoóuú]* VAR VOWELP [aáeéiíoóuú]+ // left context short broad vowel VAR LCSBV (ea|io|iu|a|o|u) // left context short slender vowel VAR LCSSV (ai|eai|ei|e|iui|i|oi|ui) // left context broad vowel VAR LCBV (adh|ae|ao|aá|ea|eá|eo|éa|io|iu|iú|ío|oó|uío|ua|u|ú) // right context broad vowel #VAR RCBV (aei|ae|ai|aoi|ao|a|ái|á|oi|o|ói|ó|ui|uío|uí|u|úi|ú) // left context slender vowel VAR LCSV (aei|aidh|ai|aí|aoi|ái|eai|eái|ei|eoi|e|éi|é|iai|iui|iúi|i|í|oi|ói|uai|ui|uí|úi) VAR LCSVS (aei|aidh|ai|aí|aoi|ái|eai|eái|ei|eoi|e|éi|é|iai|iui|iúi|i|í|oi|ói|uai|ui|uí|úi)* // right context slender vowel VAR RCSV (eai|ea|eái|eá|ei|eoi|eo|e|éa|éi|é|iai|ia|io|iui|iu|iúi|iú|i|ío|í) // left context long vowel VAR LCLV (aei|ae|aoi|ao|ái|á|eái|eá|eoi|eó|eo|éi|é|iúi|iú|ío|í|ói|ó|uío|uí|úi|ú) // left context slender long vowel VAR LCSLV (aei|aidh|aoi|ái|eái|eoi|éi|é|iúi|í|ói|uai|uí|úi) ádh -&gt; AA ái -&gt; AA á -&gt; AA abh -&gt; ABH adh -&gt; ADH / _ # adh -&gt; AI agh -&gt; AI aei -&gt; EE ae -&gt; EE aíodh -&gt; ÍODH / _ # aío -&gt; AÍO aí -&gt; II aidh -&gt; IDH / _ # aidh -&gt; AI aigh -&gt; IGH / _ # aigh -&gt; AI aithe -&gt; ITHE / _ # ai -&gt; ∅ / # CONSS VOWELS abh _ CONSP ai -&gt; ∅ / # CONSS VOWELS adh _ CONSP ai -&gt; ∅ / # CONSS VOWELS agh _ CONSP ai -&gt; ∅ / # CONSS VOWELS amh _ CONSP ai -&gt; ∅ / # CONSS obh _ CONSP ai -&gt; ∅ / # CONSS VOWELS ódh _ CONSP ai -&gt; ∅ / # CONSS odh _ CONSP ai -&gt; ∅ / # CONSS VOWELS ogh _ CONSP ai -&gt; ∅ / # CONSS VOWELS omh _ CONSP ai -&gt; ∅ / # CONSS VOWELS umh _ CONSP ai -&gt; AA / # CONSS _ RDNLR ai -&gt; A / # CONSS _ ai -&gt; @@ / VOWELP CONSP _ ai -&gt; A amh -&gt; AMH / _ # amh -&gt; AU aoi -&gt; AO ao -&gt; AO a -&gt; ∅ / # CONSS VOWELS abh _ CONSP a -&gt; ∅ / # CONSS VOWELS adh _ CONSP a -&gt; ∅ / # CONSS VOWELS agh _ CONSP a -&gt; ∅ / # CONSS VOWELS amh _ CONSP a -&gt; ∅ / # CONSS obh _ CONSP a -&gt; ∅ / # CONSS VOWELS ódh _ CONSP a -&gt; ∅ / # CONSS odh _ CONSP a -&gt; ∅ / # CONSS VOWELS ogh _ CONSP a -&gt; ∅ / # CONSS VOWELS omh _ CONSP a -&gt; ∅ / # CONSS VOWELS umh _ CONSP # addition a -&gt; ∅ / # CONSS VOWELS ogh _ # omh -&gt; OO / (gc|ch|c) _ (ai|a) r a -&gt; AA / # CONSS _ RDNLR a -&gt; A / # CONSS _ a -&gt; @@ / VOWELP CONSP _ a -&gt; A éa -&gt; EE éi -&gt; EE é -&gt; EE eái -&gt; AA eá -&gt; AA eabh -&gt; ABH eadh -&gt; ADH / _ # eadh -&gt; AU eagh -&gt; AI eai -&gt; A eamh -&gt; AMH / _ # eamh -&gt; AU / # CONSS _ # VOWEL, or VOWELS ?? ea -&gt; ∅ / # CONSS VOWEL igh _ CONSP ea -&gt; AA / # CONSS _ RDNLR ea -&gt; A / # CONSS _ ea -&gt; @@ / VOWELP CONSP _ ea -&gt; A eidh -&gt; EIDH eigh -&gt; EIGH ei -&gt; EE / # CONSS _ RDNLR # ei -&gt; EE / # CONSS _ RDNLR NONSYLLABIC ei -&gt; E / # CONSS _ ei -&gt; E eódh -&gt; OO eoi -&gt; OO eó -&gt; OO eo -&gt; OO e -&gt; E / # CONSS _ e -&gt; @@ / VOWELP CONSP _ e -&gt; E íodh -&gt; ÍODH / _ # ío -&gt; II í -&gt; II iadh -&gt; I@ iath -&gt; I@ iai -&gt; I@ ia -&gt; I@ idh -&gt; IDH igh -&gt; IGH io -&gt; IO ithe -&gt; ITHE / _ # iúi -&gt; UU iú -&gt; UU iubh -&gt; UBH iumh -&gt; UU iui -&gt; UU iu -&gt; U i -&gt; ∅ / # CONSS VOWEL idh _ CONSP # i -&gt; ∅ / # CONSS VOWEL igh _ CONSP i -&gt; @@ / VOWELP CONSP _ i -&gt; I ódh -&gt; ÓDH / _ # ói -&gt; OO ó -&gt; OO obh -&gt; OBH odh -&gt; ODH ogh -&gt; OGH oí -&gt; II oidh -&gt; OIDH oigh -&gt; OIGH oi -&gt; OO / # CONSS _ RDNLR oi -&gt; @@ / # VOWELP CONSP _ oi -&gt; OI omh -&gt; OMH o -&gt; OO / # CONSS _ RDNLR # o -&gt; OO / # CONSS _ RDNLR NONSYLLABIC o -&gt; O / # VOWELP CONSP _ o -&gt; O úi -&gt; UU ú -&gt; UU uath -&gt; U@ uai -&gt; U@ ua -&gt; U@ ubh -&gt; UBH ue -&gt; E ui -&gt; UU / # CONSS _ RDNLR # ui -&gt; UU / # CONSS _ RDNLR NONSYLLABIC ui -&gt; I / # CONSS _ ui -&gt; @@ / VOWELP CONSP _ ui -&gt; UI uío -&gt; II uí -&gt; II umh -&gt; UU u -&gt; UU / # CONSS _ RDNLR u -&gt; U / # CONSS _ u -&gt; @@ / VOWELP CONSP _ u -&gt; U bf -&gt; P / _ BFCE # bf -&gt; PJ / _ SFCE # bhf -&gt; VJ / # _ CONSS RCSV # bhf -&gt; VJ / # _ CONSS RCSV NONSYLLABIC bhf -&gt; V / # _ bhf -&gt; F / _ BFCE # bhf -&gt; FJ / _ SFCE # bh -&gt; @@ V / # LCSBV LNRP _ bh -&gt; @@ V / NONSYLLABIC LCSBV LNRP _ bh -&gt; @@ VJ / # LCSSV LNRP _ bh -&gt; @@ VJ / NONSYLLABIC LCSSV LNRP _ bh -&gt; VJ / # _ CONSS RCSV # bh -&gt; VJ / # _ CONSS RCSV NONSYLLABIC bh -&gt; V / # _ bh -&gt; VJ / _ CONSS RCSV # bh -&gt; VJ / _ CONSS RCSV NONSYLLABIC bh -&gt; VJ / # LCSV CONSP _ bh -&gt; VJ / NONSYLLABIC LCSV CONSP _ bh -&gt; VJ / # LCSV _ bh -&gt; VJ / NONSYLLABIC LCSV _ bh -&gt; V bp -&gt; BJ / # _ CONSS RCSV # bp -&gt; BJ / # _ CONSS RCSV NONSYLLABIC bp -&gt; B / # _ bth -&gt; P / LCBV CONSS _ bth -&gt; PJ / LCSV CONSS _ b -&gt; @@ B / # LCSBV LNRP _ b -&gt; @@ B / NONSYLLABIC LCSBV LNRP _ b -&gt; @@ BJ / # LCSSV LNRP _ b -&gt; @@ BJ / NONSYLLABIC LCSSV LNRP _ b -&gt; BJ / _ CONSS RCSV # b -&gt; BJ / _ CONSS RCSV NONSYLLABIC b -&gt; BJ / # LCSV CONSP _ b -&gt; BJ / NONSYLLABIC LCSV CONSP _ b -&gt; BJ / # LCSV _ b -&gt; BJ / NONSYLLABIC LCSV _ b -&gt; B cf -&gt; K / _ BFCE # cf -&gt; KJ / _ SFCE # chf -&gt; X / _ BFCE # chf -&gt; XJ / _ SFCE # ch -&gt; @@ X / # LCSBV LNRP _ ch -&gt; @@ X / NONSYLLABIC LCSBV LNRP _ ch -&gt; @@ XJ / # LCSSV LNRP _ ch -&gt; @@ XJ / NONSYLLABIC LCSSV LNRP _ ch -&gt; XJ / # _ CONSS RCSV # ch -&gt; XJ / # _ CONSS RCSV NONSYLLABIC ch -&gt; X / # _ ch -&gt; XJ / _ CONSS RCSV # ch -&gt; XJ / _ CONSS RCSV NONSYLLABIC ch -&gt; XJ / # LCSV CONSP _ ch -&gt; XJ / NONSYLLABIC LCSV CONSP _ ch -&gt; XJ / # LCSV _ ch -&gt; XJ / NONSYLLABIC LCSV _ ch -&gt; X cth -&gt; K / LCBV CONSS _ cth -&gt; KJ / LCSV CONSS _ c -&gt; KJ / _ CONSS RCSV # c -&gt; KJ / _ CONSS RCSV NONSYLLABIC c -&gt; KJ / # LCSV CONSP _ c -&gt; KJ / NONSYLLABIC LCSV CONSP _ c -&gt; KJ / # LCSV _ c -&gt; KJ / NONSYLLABIC LCSV _ c -&gt; K df -&gt; T / _ BFCE # df -&gt; TJ / _ SFCE # dha -&gt; ∅ / # LCLV _ dha -&gt; ∅ / NONSYLLABIC LCLV _ dh -&gt; GFJ / # LCSLV _ dh -&gt; GFJ / NONSYLLABIC LCSLV _ dh -&gt; GFJ / # CONSS LCSVS _ # dh -&gt; ∅ / # LCLV _ dh -&gt; ∅ / NONSYLLABIC LCLV _ dh -&gt; GFJ / # _ CONSS RCSV # dh -&gt; GFJ / # _ CONSS RCSV NONSYLLABIC dh -&gt; GF / # _ dh -&gt; GFJ / _ CONSS RCSV # dh -&gt; GFJ / _ CONSS RCSV NONSYLLABIC dh -&gt; GFJ / # LCSV CONSP _ dh -&gt; GFJ / NONSYLLABIC LCSV CONSP _ dh -&gt; GFJ / # LCSV _ dh -&gt; GFJ / NONSYLLABIC LCSV _ dh -&gt; GF dt -&gt; DJ / # _ CONSS RCSV # dt -&gt; DJ / # _ CONSS RCSV NONSYLLABIC dt -&gt; D / # _ dt -&gt; T / LCBV CONSS _ dt -&gt; TJ / LCSV CONSS _ d -&gt; DJ / _ CONSS RCSV # d -&gt; DJ / _ CONSS RCSV NONSYLLABIC d -&gt; DJ / # LCSV CONSP _ d -&gt; DJ / NONSYLLABIC LCSV CONSP _ d -&gt; DJ / # LCSV _ d -&gt; DJ / NONSYLLABIC LCSV _ d -&gt; D fh -&gt; ∅ f -&gt; H / VOWEL _ BFCE # f -&gt; HJ / VOWEL _ SFCE # f -&gt; @@ F / # LCSBV LNRP _ f -&gt; @@ F / NONSYLLABIC LCSBV LNRP _ f -&gt; @@ FJ / # LCSSV LNRP _ f -&gt; @@ FJ / NONSYLLABIC LCSSV LNRP _ f -&gt; FJ / _ CONSS RCSV # f -&gt; FJ / _ CONSS RCSV NONSYLLABIC f -&gt; FJ / # LCSV CONSP _ f -&gt; FJ / NONSYLLABIC LCSV CONSP _ f -&gt; FJ / # LCSV _ f -&gt; FJ / NONSYLLABIC LCSV _ f -&gt; F gc -&gt; GJ / # _ CONSS RCSV # gc -&gt; GJ / # _ CONSS RCSV NONSYLLABIC gc -&gt; G / # _ gf -&gt; K / _ BFCE # gf -&gt; KJ / _ SFCE # gh -&gt; GFJ / # _ CONSS RCSV # gh -&gt; GFJ / # _ CONSS RCSV NONSYLLABIC gh -&gt; GF / # _ gh -&gt; GFJ / # LCSLV _ gh -&gt; GFJ / NONSYLLABIC LCSLV _ gh -&gt; GFJ / # CONSS LCSVS _ # gh -&gt; ∅ / # LCLV _ gh -&gt; ∅ / NONSYLLABIC LCLV _ gh -&gt; GFJ / _ CONSS RCSV # gh -&gt; GFJ / _ CONSS RCSV NONSYLLABIC gh -&gt; GFJ / # LCSV CONSP _ gh -&gt; GFJ / NONSYLLABIC LCSV CONSP _ gh -&gt; GFJ / # LCSV _ gh -&gt; GFJ / NONSYLLABIC LCSV _ gh -&gt; GF gth -&gt; K / LCBV CONSS _ gth -&gt; KJ / LCSV CONSS _ g -&gt; @@ G / # LCSBV LNRP _ g -&gt; @@ G / NONSYLLABIC LCSBV LNRP _ g -&gt; @@ GJ / # LCSSV LNRP _ g -&gt; @@ GJ / NONSYLLABIC LCSSV LNRP _ g -&gt; GJ / _ CONSS RCSV # g -&gt; GJ / _ CONSS RCSV NONSYLLABIC g -&gt; GJ / # LCSV CONSP _ g -&gt; GJ / NONSYLLABIC LCSV CONSP _ g -&gt; GJ / # LCSV _ g -&gt; GJ / NONSYLLABIC LCSV _ g -&gt; G h -&gt; HJ / _ CONSS RCSV # h -&gt; HJ / _ CONSS RCSV NONSYLLABIC h -&gt; HJ / # LCSV CONSP _ h -&gt; HJ / NONSYLLABIC LCSV CONSP _ h -&gt; HJ / # LCSV _ h -&gt; HJ / NONSYLLABIC LCSV _ h -&gt; H j -&gt; DJZJ k -&gt; KJ / _ CONSS RCSV # k -&gt; KJ / _ CONSS RCSV NONSYLLABIC k -&gt; KJ / # LCSV CONSP _ k -&gt; KJ / NONSYLLABIC LCSV CONSP _ k -&gt; KJ / # LCSV _ k -&gt; KJ / NONSYLLABIC LCSV _ k -&gt; K llf -&gt; LL_D / _ BFCE # llf -&gt; LLJ_D / _ SFCE # llth -&gt; LL_D / LCBV CONSS _ llth -&gt; LLJ_D / LCSV CONSS _ ll -&gt; LLJ / _ CONSS RCSV # ll -&gt; LLJ / _ CONSS RCSV NONSYLLABIC ll -&gt; LLJ / # LCSV CONSP _ ll -&gt; LLJ / NONSYLLABIC LCSV CONSP _ ll -&gt; LLJ / # LCSV _ ll -&gt; LLJ / NONSYLLABIC LCSV _ ll -&gt; LL lf -&gt; LL_D / _ BFCE # lf -&gt; LJ_D / _ SFCE # lth -&gt; LL_D / LCBV CONSS _ lth -&gt; LJ_D / LCSV CONSS _ l -&gt; LJ / _ CONSS RCSV # l -&gt; LJ / _ CONSS RCSV NONSYLLABIC l -&gt; LJ / # LCSV CONSP _ l -&gt; LJ / NONSYLLABIC LCSV CONSP _ l -&gt; LJ / # LCSV _ l -&gt; LJ / NONSYLLABIC LCSV _ l -&gt; LL mb -&gt; MJ / # _ CONSS RCSV # mb -&gt; MJ / # _ CONSS RCSV NONSYLLABIC mb -&gt; M / # _ mf -&gt; M_D / _ BFCE # mf -&gt; MJ_D / _ SFCE # mhf -&gt; F / _ BFCE # mhf -&gt; FJ / _ SFCE # mh -&gt; VJ / # _ CONSS RCSV # mh -&gt; VJ / # _ CONSS RCSV NONSYLLABIC mh -&gt; V / # _ mh -&gt; @@ V / # LCSBV LNRP _ mh -&gt; @@ V / NONSYLLABIC LCSBV LNRP _ mh -&gt; @@ VJ / # LCSSV LNRP _ mh -&gt; @@ VJ / NONSYLLABIC LCSSV LNRP _ mh -&gt; VJ / _ CONSS RCSV # mh -&gt; VJ / _ CONSS RCSV NONSYLLABIC mh -&gt; VJ / # LCSV CONSP _ mh -&gt; VJ / NONSYLLABIC LCSV CONSP _ mh -&gt; VJ / # LCSV _ mh -&gt; VJ / NONSYLLABIC LCSV _ mh -&gt; V mth -&gt; M_D / LCBV CONSS _ mth -&gt; MJ_D / LCSV CONSS _ m -&gt; @@ M / # LCSBV LNRP _ m -&gt; @@ M / NONSYLLABIC LCSBV LNRP _ m -&gt; @@ MJ / # LCSSV LNRP _ m -&gt; @@ MJ / NONSYLLABIC LCSSV LNRP _ m -&gt; MJ / _ CONSS RCSV # m -&gt; MJ / _ CONSS RCSV NONSYLLABIC m -&gt; MJ / # LCSV CONSP _ m -&gt; MJ / NONSYLLABIC LCSV CONSP _ m -&gt; MJ / # LCSV _ m -&gt; MJ / NONSYLLABIC LCSV _ m -&gt; M nnf -&gt; NN_D / _ BFCE # nnf -&gt; NNJ_D / _ SFCE # nnth -&gt; NN_D / LCBV CONSS _ nnth -&gt; NNJ_D / LCSV CONSS _ nn -&gt; NNJ / _ CONSS RCSV # nn -&gt; NNJ / _ CONSS RCSV NONSYLLABIC nn -&gt; NNJ / # LCSV CONSP _ nn -&gt; NNJ / NONSYLLABIC LCSV CONSP _ nn -&gt; NNJ / # LCSV _ nn -&gt; NNJ / NONSYLLABIC LCSV _ nn -&gt; NN n- -&gt; NJ / # _ RCSV # n- -&gt; NJ / # _ RCSV NONSYLLABIC n- -&gt; NN / # _ nd -&gt; NNJ / # _ CONSS RCSV # nd -&gt; NNJ / # _ CONSS RCSV NONSYLLABIC nd -&gt; NN / # _ nf -&gt; NN_D / _ BFCE # nf -&gt; NJ_D / _ SFCE # ngf -&gt; NG_D / _ BFCE # ngf -&gt; NGJ_D / _ SFCE # ngth -&gt; NG_D / LCBV CONSS _ ngth -&gt; NGJ_D / LCSV CONSS _ ng -&gt; NGJ / # _ CONSS RCSV # ng -&gt; NGJ / # _ CONSS RCSV NONSYLLABIC ng -&gt; NG / # _ ng -&gt; NJ / # LCSV _ t # ng -&gt; NJ / NONSYLLABIC LCSV _ t # ng -&gt; NGJ / _ CONSS RCSV # ng -&gt; NGJ / _ CONSS RCSV NONSYLLABIC ng -&gt; NGJ / # LCSV CONSP _ ng -&gt; NGJ / NONSYLLABIC LCSV CONSP _ ng -&gt; NGJ / # LCSV _ ng -&gt; NGJ / NONSYLLABIC LCSV _ ng -&gt; NG nth -&gt; NN_D / LCBV CONSS _ nth -&gt; NJ_D / LCSV CONSS _ n -&gt; NGJ / # LCSV _ c n -&gt; NGJ / NONSYLLABIC LCSV _ c n -&gt; NG / _ c n -&gt; NJ / _ CONSS RCSV # n -&gt; NJ / _ CONSS RCSV NONSYLLABIC n -&gt; NJ / # LCSV CONSP _ n -&gt; NJ / NONSYLLABIC LCSV CONSP _ n -&gt; NJ / # LCSV _ n -&gt; NJ / NONSYLLABIC LCSV _ n -&gt; NN pf -&gt; P / _ BFCE # pf -&gt; PJ / _ SFCE # ph -&gt; FJ / # _ CONSS RCSV # ph -&gt; FJ / # _ CONSS RCSV NONSYLLABIC ph -&gt; F / # _ ph -&gt; FJ / _ CONSS RCSV # ph -&gt; FJ / _ CONSS RCSV NONSYLLABIC ph -&gt; FJ / # LCSV CONSP _ ph -&gt; FJ / NONSYLLABIC LCSV CONSP _ ph -&gt; FJ / # LCSV _ ph -&gt; FJ / NONSYLLABIC LCSV _ ph -&gt; F pth -&gt; P / LCBV CONSS _ pth -&gt; PJ / LCSV CONSS _ p -&gt; PJ / _ CONSS RCSV # p -&gt; PJ / _ CONSS RCSV NONSYLLABIC p -&gt; PJ / # LCSV CONSP _ p -&gt; PJ / NONSYLLABIC LCSV CONSP _ p -&gt; PJ / # LCSV _ p -&gt; PJ / NONSYLLABIC LCSV _ p -&gt; P # really? there&#39;s a &#39;W&#39; in the phoneset q -&gt; K V rrf -&gt; RR_D / _ BFCE # rrf -&gt; RRJ_D / _ SFCE # rrth -&gt; RR_D / LCBV CONSS _ rrth -&gt; RRJ_D / LCSV CONSS _ rr -&gt; RRJ / _ CONSS RCSV # rr -&gt; RRJ / _ CONSS RCSV NONSYLLABIC rr -&gt; RRJ / # LCSV CONSP _ rr -&gt; RRJ / NONSYLLABIC LCSV CONSP _ rr -&gt; RRJ / # LCSV _ rr -&gt; RRJ / NONSYLLABIC LCSV _ rr -&gt; RR rf -&gt; R_D / _ BFCE # rf -&gt; RJ_D / _ SFCE # rth -&gt; R_D / LCBV CONSS _ rth -&gt; RJ_D / LCSV CONSS _ r -&gt; R / # s _ r -&gt; R / # _ // This rule blocks tests for airde and ceird r -&gt; R / _ DNLST r -&gt; RJ / _ CONSS RCSV # r -&gt; RJ / _ CONSS RCSV NONSYLLABIC r -&gt; RJ / # LCSV CONSP _ r -&gt; RJ / NONSYLLABIC LCSV CONSP _ r -&gt; RJ / # LCSV _ r -&gt; RJ / NONSYLLABIC LCSV _ r -&gt; R sf -&gt; S / _ BFCE # sf -&gt; SJ / _ SFCE # shl -&gt; LJ_D / _ CONSS RCSV # shl -&gt; LJ_D / _ CONSS RCSV NONSYLLABIC shl -&gt; LL_D shm -&gt; MJ_D / _ CONSS RCSV # shm -&gt; MJ_D / _ CONSS RCSV NONSYLLABIC shm -&gt; M_D shn -&gt; NJ_D / _ CONSS RCSV # shn -&gt; NJ_D / _ CONSS RCSV NONSYLLABIC shn -&gt; NN_D shr -&gt; RJ_D / _ CONSS RCSV # shr -&gt; RJ_D / _ CONSS RCSV NONSYLLABIC shr -&gt; R_D sh -&gt; XJ / # _ CONSS RCSV # sh -&gt; XJ / # _ CONSS RCSV NONSYLLABIC sh -&gt; H / # _ sh -&gt; XJ / _ CONSS RCSV # sh -&gt; XJ / _ CONSS RCSV NONSYLLABIC sh -&gt; XJ / # LCSV CONSP _ sh -&gt; XJ / NONSYLLABIC LCSV CONSP _ sh -&gt; XJ / # LCSV _ sh -&gt; XJ / NONSYLLABIC LCSV _ sh -&gt; H s -&gt; S / # _ r s -&gt; S / # _ FMP CONSS RCSV # s -&gt; S / # _ FMP CONSS RCSV NONSYLLABIC s -&gt; SJ / _ CONSS RCSV # s -&gt; SJ / _ CONSS RCSV NONSYLLABIC s -&gt; SJ / # LCSV CONSP _ s -&gt; SJ / NONSYLLABIC LCSV CONSP _ s -&gt; SJ / # LCSV _ s -&gt; SJ / NONSYLLABIC LCSV _ s -&gt; S t- -&gt; TJ / # _ RCSV # t- -&gt; TJ / # _ RCSV NONSYLLABIC t- -&gt; T / # _ tf -&gt; T / _ BFCE # tf -&gt; TJ / _ SFCE # // &quot;hack for compound boundaries&quot; th -&gt; ∅ / _ CONS h thb -&gt; PJ / _ CONSS RCSV # thb -&gt; PJ / _ CONSS RCSV NONSYLLABIC thb -&gt; P thc -&gt; KJ / _ CONSS RCSV # thc -&gt; KJ / _ CONSS RCSV NONSYLLABIC thc -&gt; K thd -&gt; TJ / _ CONSS RCSV # thd -&gt; TJ / _ CONSS RCSV NONSYLLABIC thd -&gt; T thf -&gt; H / _ BFCE # thf -&gt; XJ / _ SFCE # thl -&gt; LJ_D / _ CONSS RCSV # thl -&gt; LJ_D / _ CONSS RCSV NONSYLLABIC thl -&gt; LL_D thm -&gt; MJ_D / _ CONSS RCSV # thm -&gt; MJ_D / _ CONSS RCSV NONSYLLABIC thm -&gt; M_D thn -&gt; NJ_D / _ CONSS RCSV # thn -&gt; NJ_D / _ CONSS RCSV NONSYLLABIC thn -&gt; NN_D thp -&gt; PJ / _ CONSS RCSV # thp -&gt; PJ / _ CONSS RCSV NONSYLLABIC thp -&gt; P thr -&gt; RJ_D / _ CONSS RCSV # thr -&gt; RJ_D / _ CONSS RCSV NONSYLLABIC thr -&gt; R_D ths -&gt; SJ / _ CONSS RCSV # ths -&gt; SJ / _ CONSS RCSV NONSYLLABIC ths -&gt; S tht -&gt; TJ / _ CONSS RCSV # tht -&gt; TJ / _ CONSS RCSV NONSYLLABIC tht -&gt; T th -&gt; HJ / # _ CONSS RCSV # th -&gt; HJ / # _ CONSS RCSV NONSYLLABIC th -&gt; H / # _ th -&gt; HJ / _ CONSS RCSV # th -&gt; HJ / _ CONSS RCSV NONSYLLABIC th -&gt; HJ / # LCSV CONSP _ th -&gt; HJ / NONSYLLABIC LCSV CONSP _ th -&gt; HJ / # LCSV _ th -&gt; HJ / NONSYLLABIC LCSV _ th -&gt; H ts -&gt; TJ / # _ CONSS RCSV # ts -&gt; TJ / # _ CONSS RCSV NONSYLLABIC ts -&gt; T / # _ t -&gt; TJ / _ CONSS RCSV # t -&gt; TJ / _ CONSS RCSV NONSYLLABIC t -&gt; TJ / # LCSV CONSP _ t -&gt; TJ / NONSYLLABIC LCSV CONSP _ t -&gt; TJ / # LCSV _ t -&gt; TJ / NONSYLLABIC LCSV _ t -&gt; T v -&gt; VJ / _ CONSS RCSV # v -&gt; VJ / _ CONSS RCSV NONSYLLABIC v -&gt; VJ / # LCSV CONSP _ v -&gt; VJ / NONSYLLABIC LCSV CONSP _ v -&gt; VJ / # LCSV _ v -&gt; VJ / NONSYLLABIC LCSV _ v -&gt; V w -&gt; V x- -&gt; E KJ S x -&gt; ZJ y -&gt; GFJ z -&gt; ZJ / _ CONSS RCSV # z -&gt; ZJ / _ CONSS RCSV NONSYLLABIC z -&gt; ZJ / # LCSV CONSP _ z -&gt; ZJ / NONSYLLABIC LCSV CONSP _ z -&gt; ZJ / # LCSV _ z -&gt; ZJ / NONSYLLABIC LCSV _ z -&gt; Z &#39; -&gt; ∅ ’ -&gt; ∅ - -&gt; ∅ TEST ádh -&gt; AA TEST áiseanna -&gt; AA SJ @@ NN @@ TEST áthas -&gt; AA H @@ S TEST abhainn -&gt; ABH NNJ TEST bualadh -&gt; B U@ LL ADH TEST sadhbh -&gt; S AI V TEST saghas -&gt; S AI S TEST gaeilge -&gt; G EE LJ GJ @@ TEST saolaíodh -&gt; S AO LL ÍODH TEST gardaí -&gt; G AA R D II TEST dúnfaidh -&gt; D UU NN_D IDH TEST aidhm -&gt; AI MJ TEST cheadaigh -&gt; XJ A D IGH TEST aighneas -&gt; AI NJ @@ S TEST diúltaithe -&gt; DJ UU LL T ITHE TEST seabhaic -&gt; SJ ABH KJ TEST feadhain -&gt; FJ AU NJ TEST teaghais -&gt; TJ AI SJ TEST eamhain -&gt; AU NJ TEST lobhair -&gt; LL OBH RJ TEST leódhais -&gt; LJ OO SJ TEST bodhair -&gt; B ODH RJ TEST eoghain -&gt; OO NJ TEST broghais -&gt; B R OGH SJ TEST comhair -&gt; K OO RJ TEST ciumhais -&gt; KJ UU SJ # wiktionary has: ˈɑːɾˠdʲə ˈiːɾˠdʲə ˈɑːɾˠdʲə ˈaiɾʲdʲə ˈæːɾˠdʲə ˈʌɾˠdʲə, so rule seems right #TEST airde -&gt; AA RJ DJ @@ TEST airde -&gt; AA R DJ @@ TEST cait -&gt; K A TJ TEST sodair -&gt; S O D @@ RJ TEST ait -&gt; A TJ TEST déanamh -&gt; DJ EE NN AMH TEST amharc -&gt; AU R K TEST gaoil -&gt; G AO LJ TEST gaol -&gt; G AO LL TEST seabhac -&gt; SJ ABH K TEST ceadharlach -&gt; KJ AU R LL @@ X TEST teaghasán -&gt; TJ AI S AA NN TEST lobhar -&gt; LL OBH R TEST leódhas -&gt; LJ OO S TEST bodhar -&gt; B ODH R TEST eoghan -&gt; OO NN TEST bogha -&gt; B OGH TEST comhar -&gt; K OO R TEST dumhach -&gt; D UU X TEST ard -&gt; AA R D TEST cat -&gt; K A T TEST sodar -&gt; S O D @@ R TEST at -&gt; A T TEST éan -&gt; EE NN TEST éiníní -&gt; EE NJ II NJ II TEST é -&gt; EE TEST sheáin -&gt; XJ AA NJ TEST seán -&gt; SJ AA NN TEST seabhac -&gt; SJ ABH K TEST seinneadh -&gt; SJ E NNJ ADH TEST ceadharlach -&gt; KJ AU R LL @@ X TEST teaghlach -&gt; TJ AI LL @@ X TEST beairic -&gt; BJ A RJ @@ KJ TEST áireamh -&gt; AA RJ AMH TEST sleamhnán -&gt; SJ LJ AU NN AA NN TEST oighear -&gt; OIGH R TEST ceard -&gt; KJ AA R D TEST cead -&gt; KJ A D TEST áireamhán -&gt; AA RJ @@ V AA NN TEST eas -&gt; A S TEST feidhm -&gt; FJ EIDH MJ TEST leigheas -&gt; LJ EIGH S # wiktionary gives cəiɾˠdʲ and cɪɾˠdʲ; the rule seems right #TEST ceird -&gt; KJ EE RJ DJ TEST ceird -&gt; KJ EE R DJ TEST deis -&gt; DJ E SJ TEST eitpheil -&gt; E TJ FJ E LJ TEST ceoil -&gt; KJ OO LJ TEST bainseó -&gt; B A NJ SJ OO TEST ceol -&gt; KJ OO LL TEST uile -&gt; I LJ @@ TEST ceannaíodh -&gt; KJ A NN ÍODH TEST síos -&gt; SJ II S TEST sí -&gt; SJ II TEST siadhail -&gt; SJ I@ LJ TEST sciath -&gt; SJ KJ I@ #TEST riail -&gt; RJ I@ LJ TEST riail -&gt; R I@ LJ TEST siad -&gt; SJ I@ D TEST seinnfidh -&gt; SJ E NNJ_D IDH TEST cheannaigh -&gt; XJ A NN IGH TEST fios -&gt; FJ IO S TEST imithe -&gt; I MJ ITHE TEST siúil -&gt; SJ UU LJ TEST siúl -&gt; SJ UU LL TEST tiubh -&gt; TJ UBH TEST ciumhais -&gt; KJ UU SJ #TEST giuirléid -&gt; GJ UU RJ LJ EE DJ TEST giuirléid -&gt; GJ UU R LJ EE DJ TEST fiuch -&gt; FJ U X TEST leighis -&gt; LJ EIGH SJ TEST foighid -&gt; F OIGH DJ TEST aithris -&gt; A RJ_D @@ SJ TEST sin -&gt; SJ I NJ TEST cheannódh -&gt; XJ A NN ÓDH TEST óil -&gt; OO LJ TEST ól -&gt; OO LL TEST lobhadh -&gt; LL OBH ADH TEST todhchaí -&gt; T ODH X II TEST toghadh -&gt; T OGH ADH TEST oíche -&gt; II XJ @@ TEST oidhe -&gt; OIDH @@ TEST oighear -&gt; OIGH R #TEST boird -&gt; B OO RJ DJ TEST boird -&gt; B OO R DJ TEST soir -&gt; S OI RJ TEST comhar -&gt; K OO R TEST bord -&gt; B OO R D TEST bos -&gt; B O S TEST súil -&gt; S UU LJ TEST súl -&gt; S UU LL TEST uathúil -&gt; U@ UU LJ TEST uaine -&gt; U@ NJ @@ TEST uan -&gt; U@ NN TEST subh -&gt; S UBH // not LJ ? TEST bhuel -&gt; V E LL #TEST guird -&gt; G UU RJ DJ TEST guird -&gt; G UU R DJ TEST cuid -&gt; K I DJ TEST uile -&gt; I LJ @@ TEST bruíon -&gt; B R II NN TEST bruíne -&gt; B R II NJ @@ TEST cumhacht -&gt; K UU X T TEST burdún -&gt; B UU R D UU NN TEST cur -&gt; K U R TEST bus -&gt; B U S TEST scuabfaidh -&gt; S K U@ P IDH TEST clibfidh -&gt; KJ LJ I PJ IDH TEST scuabfadh -&gt; S K U@ P ADH TEST clibfeadh -&gt; KJ LJ I PJ ADH TEST bhfáinne -&gt; V AA NNJ @@ TEST bhfianaise -&gt; VJ I@ NN @@ SJ @@ TEST scríobhfaidh -&gt; SJ KJ RJ II F IDH TEST díbhfidh -&gt; DJ II FJ IDH TEST scríobhfadh -&gt; SJ KJ RJ II F ADH TEST díbhfeadh -&gt; DJ II FJ ADH TEST searbh -&gt; SJ A R @@ V TEST seirbhís -&gt; SJ E RJ @@ VJ II SJ TEST bhrostaigh -&gt; V R O S T IGH TEST bhris -&gt; VJ RJ I SJ TEST coibhín -&gt; K OI VJ II NJ TEST bpáistí -&gt; B AA SJ TJ II TEST bpéisteanna -&gt; BJ EE SJ TJ @@ NN @@ TEST scuabtha -&gt; S K U@ P @@ TEST clibthe -&gt; KJ LJ I PJ @@ TEST borb -&gt; B O R @@ B TEST seirbiach -&gt; SJ E RJ @@ BJ I@ X TEST bróna -&gt; B R OO NN @@ TEST brian -&gt; BJ RJ I@ NN TEST leódhas -&gt; LJ OO S TEST t-uisce -&gt; T UI SJ KJ @@ TEST t-éabhlóidí -&gt; TJ EE V LL OO DJ II TEST atfaidh -&gt; A T IDH TEST titfidh -&gt; TJ I TJ IDH TEST athdhéanamh -&gt; A GFJ EE NN AMH TEST meathfadh -&gt; MJ A H ADH #TEST rithfeadh -&gt; RJ I XJ ADH TEST rithfeadh -&gt; R I XJ ADH TEST bláthra -&gt; B LL AA R_D @@ TEST tharla -&gt; H AA R LL @@ TEST thit -&gt; HJ I TJ TEST tseachtain -&gt; TJ A X T @@ NJ #TEST tsagairt -&gt; T A G @@ RJ TJ # wiktionary (sagairt): ˈsˠaɡəɾˠtʲ ˈsˠæɡəɾˠtʲ TEST tsagairt -&gt; T A G @@ R TJ TEST teann -&gt; TJ A NN TEST tit -&gt; TJ I TJ TEST togra -&gt; T O G R @@ TEST sadhbh -&gt; S AI V # disabled; the rule for &#39;o&#39; in an unaccented syllable # does not produce schwa; also, &#39;leathbhosca&#39; is a compound; # the &#39;o&#39; should not be reduced #TEST leathbhosca -&gt; LJ A V @@ S K @@ #TEST bantaboic -&gt; B A NN T @@ B @@ KJ #TEST bantaboc -&gt; B A NN T @@ B @@ K TEST bhéal -&gt; VJ EE LL TEST bhéil -&gt; VJ EE LJ .",
            "url": "https://jimregan.github.io/notes/irish/g2p/2021/05/16/o-raghallaigh-thesis-attempt-1.html",
            "relUrl": "/irish/g2p/2021/05/16/o-raghallaigh-thesis-attempt-1.html",
            "date": " • May 16, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Azure speech recognition for Irish",
            "content": "%%capture !pip install azure-cognitiveservices-speech . %%capture !pip install youtube-dl . %%capture !youtube-dl https://www.youtube.com/watch?v=cfjdfaqWY3Y . %%capture !ffmpeg -i Cúla4 Ar Scoil _ Ábhar - Mata _ Téama - Bia-cfjdfaqWY3Y.mkv -acodec pcm_s16le -ac 1 -ar 16000 cfjdfaqWY3Y.wav . import IPython IPython.display.Audio(&#39;/content/cfjdfaqWY3Y.wav&#39;) . import azure.cognitiveservices.speech as speechsdk . Use either Key1 or Key2 (on Azure Portal, in &quot;Keys and Endpoints&quot; from the menu on the left hand side of the screen). . _SUBS=&#39;&#39; . _LOC=&#39;westeurope&#39; . speech_config = speechsdk.SpeechConfig(region=_LOC, subscription=_SUBS) . audio_input=speechsdk.audio.AudioConfig(filename=&#39;cfjdfaqWY3Y.wav&#39;) . speech_config.speech_recognition_language = &#39;ga-IE&#39; speech_config.request_word_level_timestamps() speech_config.output_format = speechsdk.OutputFormat(1) speech_config.endpoint_id=&#39;https://westeurope.api.cognitive.microsoft.com/sts/v1.0/issuetoken&#39; . speech_config.set_property(speechsdk.PropertyId.Speech_LogFilename, &quot;azure.log&quot;) . # Copyright (c) Microsoft. All rights reserved. # Licensed under the MIT license. See LICENSE.md file in the project root for full license information. import time def speech_recognize_continuous_from_file(speech_config, audio_config): &quot;&quot;&quot;performs continuous speech recognition with input from an audio file&quot;&quot;&quot; speech_config = speech_config audio_config = audio_config speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, language=&#39;ga-IE&#39;, audio_config=audio_config) done = False def stop_cb(evt): &quot;&quot;&quot;callback that signals to stop continuous recognition upon receiving an event `evt`&quot;&quot;&quot; print(&#39;CLOSING on {}&#39;.format(evt)) nonlocal done done = True def cancelled(evt): result = evt.result cancellation_details = result.cancellation_details print(&quot;Speech Recognition canceled: {}&quot;.format(cancellation_details.reason)) if cancellation_details.reason == speechsdk.CancellationReason.Error: print(&quot;Error details: {}&quot;.format(cancellation_details.error_details)) # Connect callbacks to the events fired by the speech recognizer speech_recognizer.recognizing.connect(lambda evt: print(&#39;RECOGNIZING: {}&#39;.format(evt))) speech_recognizer.recognized.connect(lambda evt: print(&#39;RECOGNIZED: {}&#39;.format(evt))) speech_recognizer.session_started.connect(lambda evt: print(&#39;SESSION STARTED: {}&#39;.format(evt))) speech_recognizer.session_stopped.connect(lambda evt: print(&#39;SESSION STOPPED {}&#39;.format(evt))) speech_recognizer.canceled.connect(cancelled) # stop continuous recognition on either session stopped or canceled events speech_recognizer.session_stopped.connect(stop_cb) speech_recognizer.canceled.connect(stop_cb) # Start continuous speech recognition speech_recognizer.start_continuous_recognition() while not done: time.sleep(.5) speech_recognizer.stop_continuous_recognition() . speech_recognize_continuous_from_file(speech_config, audio_input) . Debugging with curl . !curl -v -X POST &quot;https://{_LOC}.api.cognitive.microsoft.com/sts/v1.0/issueToken&quot; -H &quot;Ocp-Apim-Subscription-Key: {_SUBS}&quot; -H &quot;Content-type: application/x-www-form-urlencoded&quot; -H &quot;Content-Length: 0&quot; . _TOK=&#39;&#39; . !curl -v -X POST &quot;https://{_LOC}.stt.speech.microsoft.com/speech/recognition/interactive/cognitiveservices/v1?language=ga-IE&quot; -H &quot;Authorization: Bearer {_TOK}&quot; -H &quot;Transfer-Encoding: chunked&quot; -H &quot;Content-type: audio/wav; codec=audio/pcm; samplerate=16000&quot; --data-binary @cfjdfaqWY3Y.wav . Next step, get at the innards (TODO) . transcript_display_list = [] transcript_ITN_list = [] confidence_list = [] words = [] def parse_azure_result(evt): import json response = json.loads(evt.result.json) transcript_display_list.append(response[&#39;DisplayText&#39;]) confidence_list_temp = [item.get(&#39;Confidence&#39;) for item in response[&#39;NBest&#39;]] max_confidence_index = confidence_list_temp.index(max(confidence_list_temp)) confidence_list.append(response[&#39;NBest&#39;][max_confidence_index][&#39;Confidence&#39;]) transcript_ITN_list.append(response[&#39;NBest&#39;][max_confidence_index][&#39;ITN&#39;]) words.extend(response[&#39;NBest&#39;][max_confidence_index][&#39;Words&#39;]) logger.debug(evt) .",
            "url": "https://jimregan.github.io/notes/azure/irish/asr/2021/05/04/azure-asr-with-irish.html",
            "relUrl": "/azure/irish/asr/2021/05/04/azure-asr-with-irish.html",
            "date": " • May 4, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Azure speech recognition for Irish, part 2",
            "content": "%%capture !pip install azure-cognitiveservices-speech !pip install youtube-dl . %%capture !youtube-dl https://www.youtube.com/watch?v=cfjdfaqWY3Y . import azure.cognitiveservices.speech as speechsdk . Use either Key1 or Key2 (on Azure Portal, in &quot;Keys and Endpoints&quot; from the menu on the left hand side of the screen). . _SUBS=input(&#39;put your subscription key here: &#39;) . _LOC=&#39;westeurope&#39; . speech_config = speechsdk.SpeechConfig(region=_LOC, subscription=_SUBS) . !wget https://upload.wikimedia.org/wikipedia/commons/6/60/MSF_chapter_3.ogg https://upload.wikimedia.org/wikipedia/commons/e/ee/MSF_chapter_4.ogg https://upload.wikimedia.org/wikipedia/commons/b/b3/MSF_chapter_5.ogg https://upload.wikimedia.org/wikipedia/commons/2/21/MSF_chapter_6.ogg https://upload.wikimedia.org/wikipedia/commons/7/71/MSF_chapter_7.ogg https://upload.wikimedia.org/wikipedia/commons/d/d5/MSF_chapter_8.ogg . !ffmpeg -i MSF_chapter_5.ogg -acodec pcm_s16le -ac 1 -ar 16000 MSF_chapter_5.wav . speech_config.speech_recognition_language = &#39;ga-IE&#39; speech_config.request_word_level_timestamps() speech_config.output_format = speechsdk.OutputFormat(1) speech_config.endpoint_id=f&#39;https://{_LOC}.api.cognitive.microsoft.com/sts/v1.0/issuetoken&#39; . # Copyright (c) Microsoft. All rights reserved. # Licensed under the MIT license. See LICENSE.md file in the project root for full license information. import time import json def speech_recognize_continuous_from_file(speech_config, filename): &quot;&quot;&quot;performs continuous speech recognition with input from an audio file&quot;&quot;&quot; speech_config = speech_config audio_config = speechsdk.audio.AudioConfig(filename=filename) outfilename = filename.replace(&#39;.wav&#39;, &#39;.json&#39;) outfile = open(outfilename, &#39;a&#39;) speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, language=&#39;ga-IE&#39;, audio_config=audio_config) done = False def stop_cb(evt): &quot;&quot;&quot;callback that signals to stop continuous recognition upon receiving an event `evt`&quot;&quot;&quot; print(&#39;CLOSING on {}&#39;.format(evt)) nonlocal done done = True def cancelled(evt): result = evt.result cancellation_details = result.cancellation_details print(&quot;Speech Recognition canceled: {}&quot;.format(cancellation_details.reason)) if cancellation_details.reason == speechsdk.CancellationReason.Error: print(&quot;Error details: {}&quot;.format(cancellation_details.error_details)) def recognised(evt): response = json.loads(evt.result.json) outfile.write(&#39;{} n&#39;.format(evt.result.json)) # Connect callbacks to the events fired by the speech recognizer speech_recognizer.recognizing.connect(lambda evt: print(&#39;RECOGNIZING: {}&#39;.format(evt))) speech_recognizer.recognized.connect(recognised) speech_recognizer.session_started.connect(lambda evt: print(&#39;SESSION STARTED: {}&#39;.format(evt))) speech_recognizer.session_stopped.connect(lambda evt: print(&#39;SESSION STOPPED {}&#39;.format(evt))) speech_recognizer.canceled.connect(cancelled) # stop continuous recognition on either session stopped or canceled events speech_recognizer.session_stopped.connect(stop_cb) speech_recognizer.canceled.connect(stop_cb) # Start continuous speech recognition speech_recognizer.start_continuous_recognition() while not done: time.sleep(.5) speech_recognizer.stop_continuous_recognition() outfile.close() . for i in &quot;345678&quot;: speech_recognize_continuous_from_file(speech_config, f&#39;MSF_chapter_{i}.wav&#39;) .",
            "url": "https://jimregan.github.io/notes/azure/irish/asr/2021/05/04/azure-asr-with-irish-part2.html",
            "relUrl": "/azure/irish/asr/2021/05/04/azure-asr-with-irish-part2.html",
            "date": " • May 4, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Playing with auditok",
            "content": "%%capture !pip install auditok . %%capture !yes|apt install python3-pyaudio . %%capture !pip install youtube-dl . !youtube-dl https://www.youtube.com/watch?v=D44-x6PTd_Q . [youtube] D44-x6PTd_Q: Downloading webpage [youtube] D44-x6PTd_Q: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 22 [download] Destination: Sraith Pictiúr - An Ghaeilge Seoid luachmhar-D44-x6PTd_Q.f247.webm [download] 22.7% of ~12.60MiB at 5.49MiB/s ETA 00:13[download] Got server HTTP error: HTTP Error 404: Not Found. Retrying fragment 6 (attempt 1 of 10)... [download] 100% of 15.12MiB in 00:18 [download] Destination: Sraith Pictiúr - An Ghaeilge Seoid luachmhar-D44-x6PTd_Q.f140.m4a [download] 100% of 1.73MiB in 00:00 [ffmpeg] Merging formats into &#34;Sraith Pictiúr - An Ghaeilge Seoid luachmhar-D44-x6PTd_Q.mkv&#34; Deleting original file Sraith Pictiúr - An Ghaeilge Seoid luachmhar-D44-x6PTd_Q.f247.webm (pass -k to keep) Deleting original file Sraith Pictiúr - An Ghaeilge Seoid luachmhar-D44-x6PTd_Q.f140.m4a (pass -k to keep) . import auditok input = &#39;Sraith Pictiúr - An Ghaeilge Seoid luachmhar-D44-x6PTd_Q.mkv&#39; audio_regions = auditok.split( input, min_dur=1, max_dur=10, max_silence=0.9, energy_threshold=20 ) for i, r in enumerate(audio_regions): print(&quot;Region {i}: {r.meta.start:.3f}s -- {r.meta.end:.3f}s&quot;.format(i=i, r=r)) . Region 0: 0.300s -- 6.550s Region 1: 7.450s -- 12.950s Region 2: 13.150s -- 15.700s Region 3: 15.900s -- 19.200s Region 4: 19.350s -- 29.350s Region 5: 29.700s -- 34.200s Region 6: 34.300s -- 38.600s Region 7: 39.000s -- 43.650s Region 8: 43.700s -- 46.550s Region 9: 46.750s -- 49.500s Region 10: 49.550s -- 52.950s Region 11: 53.000s -- 56.050s Region 12: 56.250s -- 59.500s Region 13: 59.700s -- 62.550s Region 14: 63.150s -- 69.600s Region 15: 69.650s -- 73.100s Region 16: 73.400s -- 77.450s Region 17: 77.800s -- 81.150s Region 18: 81.350s -- 89.100s Region 19: 89.500s -- 92.750s Region 20: 92.950s -- 96.250s Region 21: 96.500s -- 99.600s Region 22: 99.850s -- 104.350s Region 23: 104.500s -- 108.050s . regs = auditok.load(input) regs.split_and_plot( min_dur=1, max_dur=10, max_silence=0.9, energy_threshold=20, dpi=600 ) . [AudioRegion(duration=6.250, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=5.500, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=2.550, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.300, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=10.000, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=4.500, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=4.300, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=4.650, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=2.850, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=2.750, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.400, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.050, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.250, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=2.850, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=6.450, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.450, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=4.050, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.350, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=7.750, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.250, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.300, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.100, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=4.500, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.550, sampling_rate=44100, sample_width=2, channels=2)] .",
            "url": "https://jimregan.github.io/notes/auditok/2021/05/03/playing-with-auditok.html",
            "relUrl": "/auditok/2021/05/03/playing-with-auditok.html",
            "date": " • May 3, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "rclone and Sharepoint",
            "content": "%%capture !curl https://rclone.org/install.sh |bash . curl_out=!curl --cookie -i -L &#39;https://uniwersytetlodzki-my.sharepoint.com/:f:/g/personal/pelcra_uni_lodz_pl/EpPehikqGqZJltrAKlVp3k0BOeyzEgBBO_ZwmFC9WaLbWw&#39;|grep &#39;var _spPageContextInfo=&#39; . import json for s in curl_out: if &#39;var _spPageContextInfo=&#39; in s: start = s[s.index(&#39;access_token=&#39;)+len(&#39;access_token=&#39;):] access_token = start[:start.index(&#39;&quot;&#39;)] . _URL=&#39;https://uniwersytetlodzki-my.sharepoint.com/personal/pelcra_uni_lodz_pl/Documents&#39; . _COOKIE=&#39;FedAuth=77u/PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0idXRmLTgiPz48U1A+VjksMGguZnxtZW1iZXJzaGlwfHVybiUzYXNwbyUzYWFub24jNTZiNDAwY2Y5OWYxMjQwYTkyYjRhNWU3ZTkwYjJlNWVlY2Q3MzYyMGJlNmNiMjI4OTllNjhiMWU4Zjc2Nzk4ZCwwIy5mfG1lbWJlcnNoaXB8dXJuJTNhc3BvJTNhYW5vbiM1NmI0MDBjZjk5ZjEyNDBhOTJiNGE1ZTdlOTBiMmU1ZWVjZDczNjIwYmU2Y2IyMjg5OWU2OGIxZThmNzY3OThkLDEzMjY0NDY0NTU3MDAwMDAwMCwwLDEzMjY0NTUwNjU4MDQxOTgzNCwwLjAuMC4wLDI1OCxkZGIyZmM4NS0xYzE4LTRjMmItOTkyYS1lODQxMWJmZmMwZTcsLCw0ODEyYzQ5Zi02MGY0LTIwMDAtZTE0Mi02YzYwM2MyZGE3YzQsNDgxMmM0OWYtNjBmNC0yMDAwLWUxNDItNmM2MDNjMmRhN2M0LDVrVml3YU9rSGtxaWZjbzVzKytYSlEsMCwwLDAsLCwsMjY1MDQ2Nzc0Mzk5OTk5OTk5OSwwLCwsLCwsc0JtSkR4RTZJd3I5VmsraGJHclFSUDhSNzJIUXh2UWlqNDZ6WnFPdXArUVZnVWhkNkVmQWljNUZ1YUYwMEdGUjRFRnhMRUJsRlNTZ3lnNElkTUdSSnpwbGZUT0JGSkw0Tyt4cjRHS01WdjZ1YnhJWTFzMkFWYWpySVgzbXRGWm9zOHkrYjk0SnhPZElibVVxaUJWZzVaZHVTcWxSMnlFdzc0Y3BueERjVHdQU3FVYTk3VG5qOTRWM0s4YkdkUnA1QVVGSGtacjg2Q0YvZVY5R2Y1OGlTd1ZKUWx2VEc5OVByaU9JWE94Umc4N2FZc2ZFTWZzcG9JL05tYlU0cm9sQ1ZnVzVVNUl3NXJlY29PNzkxUXZZbDBlUlZNcXBVSHI0UEdBOVhLaEJVb3I5YTJpMFpQZEhZRE9SQnlVcWtHRDQvb0NXY21JamdGQVhNM2RtTFgwWGJBPT08L1NQPg==; path=/; SameSite=None; secure; HttpOnly&#39; . !rclone config create pelcra webdav url {_URL} webdav-vendor other access_token {access_token} #cookie &quot;{_COOKIE}&quot; . Remote config -- [pelcra] type = webdav url = https://uniwersytetlodzki-my.sharepoint.com/personal/pelcra_uni_lodz_pl/Documents webdav-vendor = other access_token = eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJhdWQiOiIwMDAwMDAwMy0wMDAwLTBmZjEtY2UwMC0wMDAwMDAwMDAwMDAvdW5pd2Vyc3l0ZXRsb2R6a2ktbXkuc2hhcmVwb2ludC5jb21ANjM0NDFhZWYtZGEwZS00Mzk3LWJiN2UtZjlkNDcwNWU5NjNiIiwiaXNzIjoiMDAwMDAwMDMtMDAwMC0wZmYxLWNlMDAtMDAwMDAwMDAwMDAwIiwibmJmIjoxNjIwMjU0MjMwLCJleHAiOjE2MjAyNzU4MzAsImlzbG9vcGJhY2siOiJUcnVlIiwibmFtZWlkIjoiMCMuZnxtZW1iZXJzaGlwfHVybiUzYXNwbyUzYWFub24jNTZiNDAwY2Y5OWYxMjQwYTkyYjRhNWU3ZTkwYjJlNWVlY2Q3MzYyMGJlNmNiMjI4OTllNjhiMWU4Zjc2Nzk4ZCIsIm5paSI6Im1pY3Jvc29mdC5zaGFyZXBvaW50IiwiaXN1c2VyIjoidHJ1ZSIsImNhY2hla2V5IjoiMGguZnxtZW1iZXJzaGlwfHVybiUzYXNwbyUzYWFub24jNTZiNDAwY2Y5OWYxMjQwYTkyYjRhNWU3ZTkwYjJlNWVlY2Q3MzYyMGJlNmNiMjI4OTllNjhiMWU4Zjc2Nzk4ZCIsInR0IjoiMCIsInVzZVBlcnNpc3RlbnRDb29raWUiOiIyIn0.A50UZ17CCLwueDg9UAJx4NY4FM-3p_vRN59OrxDxFz4u0026prooftoken=eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsIng1dCI6IkcydDJKYzlkMVZ6RkdjdzZUZy02YUhZVXk2VSJ9.eyJhdWQiOiIwMDAwMDAwMy0wMDAwLTBmZjEtY2UwMC0wMDAwMDAwMDAwMDBAKiIsImlzcyI6IjAwMDAwMDAzLTAwMDAtMGZmMS1jZTAwLTAwMDAwMDAwMDAwMEAqIiwibmJmIjoiMTYyMDI0NjgzMCIsImV4cCI6IjE2MjA4NTE2MzAiLCJwcmYiOiJLMUs2Z21oMFNpZDBaL2E0SjJReXpDSVJLMXBTWGlyOXAzcitoM1UwTjZRNWo2UEc2REZPaG5OU2dPU3FwZDRXK1ZpenppSTlCcWc2d2kvSE83Zk9scGhmaE9pU3NLN1p6clFGMUxlOFk3dnJJejdNb1RLQ3Njbjh5cUhvSklVbjFmVFlIcGltb1E0NnJQdVlJV0pJK3UwOXVHTVBpSS9ZcWlCYzhHd0VBTit0bnoyZ2tIcXM3OGhXbGo2Y3dBNzNTckJwTHBTdG53QzZaRXRoUVV1N3l6eGhuRVlXdkNhNUFPdVlWaXRiMndTZWpib0g5QlBCc0puemVEL1ZMUDFqZXh2Qk9DRVpYN25XRjU4SC9Sck1tdWdZb2ZxMGQzZnhlTG56d0RJbDFEYjdqcFc3L20vaURJV1FQRUZScmFmUW1pbFJmYjRSTFUxVFFGWWptVHJmU1E9PSIsImlzdXNlciI6InRydWUifQ.o1x0-K2UNkorQjKyT5o0HXJiOJxHP3vlYscEzjKN2KQHzp95ja3ml5yzqPtSXdCwYxjCdJjWgtAvS5YlQzLBX2Eac8odydBxDa8EHyuVxIa6T-n7dD4R1WHVebyXt62shIP61s_TeiJkwiD0Sl_nPIzqY9zkrKEg_cSe0isEi0mCv6ynYXCWetYpaMdv4ifaGAl5aK7v6zxNKzwVoxBUfEIcJLV8MjdeV1i1Puuinpj69GUispryx7ruDs0g5CLVjOeAk0wwaoTeRzL4y04EKTKdt4UsdeAAXzE1Rby4na3xqDkeewPUCYxZHQL89tGOUcmiwjJKeB7Fos39XIhrRg -- . !rclone ls --use-cookies -vv &#39;pelcra:SHARE/CLARIN/SPOKES/PELCRA_EMO&#39; --dump bodies . 2021/05/05 22:54:48 DEBUG : Using config file from &#34;/root/.config/rclone/rclone.conf&#34; 2021/05/05 22:54:48 DEBUG : rclone: Version &#34;v1.55.1&#34; starting with parameters [&#34;rclone&#34; &#34;ls&#34; &#34;--use-cookies&#34; &#34;-vv&#34; &#34;pelcra:SHARE/CLARIN/SPOKES/PELCRA_EMO&#34; &#34;--dump&#34; &#34;bodies&#34;] 2021/05/05 22:54:48 DEBUG : Creating backend with remote &#34;pelcra:SHARE/CLARIN/SPOKES/PELCRA_EMO&#34; 2021/05/05 22:54:48 DEBUG : You have specified to dump information. Please be noted that the Accept-Encoding as shown may not be correct in the request and the response may not show Content-Encoding if the go standard libraries auto gzip encoding was in effect. In this case the body of the request will be gunzipped before showing it. 2021/05/05 22:54:48 DEBUG : &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 2021/05/05 22:54:48 DEBUG : HTTP REQUEST (req 0xc000596a00) 2021/05/05 22:54:48 DEBUG : PROPFIND /personal/pelcra_uni_lodz_pl/Documents/SHARE/CLARIN/SPOKES/PELCRA_EMO HTTP/1.1 Host: uniwersytetlodzki-my.sharepoint.com User-Agent: rclone/v1.55.1 Depth: 1 Referer: https://uniwersytetlodzki-my.sharepoint.com/personal/pelcra_uni_lodz_pl/Documents/ Accept-Encoding: gzip 2021/05/05 22:54:48 DEBUG : &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 2021/05/05 22:54:49 DEBUG : &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; 2021/05/05 22:54:49 DEBUG : HTTP RESPONSE (req 0xc000596a00) 2021/05/05 22:54:49 DEBUG : HTTP/2.0 403 Forbidden Content-Length: 13 Content-Type: text/plain; charset=utf-8 Date: Wed, 05 May 2021 22:54:48 GMT Microsoftsharepointteamservices: 16.0.0.21221 Ms-Cv: n8UOqHwAACDhQmsT9SmG6Q.0 P3p: CP=&#34;ALL IND DSP COR ADM CONo CUR CUSo IVAo IVDo PSA PSD TAI TELo OUR SAMo CNT COM INT NAV ONL PHY PRE PUR UNI&#34; Request-Id: a80ec59f-007c-2000-e142-6b13f52986e9 Sprequestguid: a80ec59f-007c-2000-e142-6b13f52986e9 X-Content-Type-Options: nosniff X-Forms_based_auth_required: https://uniwersytetlodzki-my.sharepoint.com/_forms/default.aspx?ReturnUrl=/_layouts/15/error.aspx&amp;Source=%2fpersonal%2fpelcra_uni_lodz_pl%2fDocuments%2fSHARE%2fCLARIN%2fSPOKES%2fPELCRA_EMO X-Forms_based_auth_return_url: https://uniwersytetlodzki-my.sharepoint.com/_layouts/15/error.aspx X-Idcrl_auth_params_v1: IDCRL Type=&#34;BPOSIDCRL&#34;, EndPoint=&#34;/personal/pelcra_uni_lodz_pl/_vti_bin/idcrl.svc/&#34;, RootDomain=&#34;sharepoint.com&#34;, Policy=&#34;MBI&#34; X-Ms-Invokeapp: 1; RequireReadOnly X-Msdavext_error: 917656; Access+denied.+Before+opening+files+in+this+location%2c+you+must+first+browse+to+the+web+site+and+select+the+option+to+login+automatically. X-Msedge-Ref: Ref A: 8A3CC80AA56A42C4A2112F4377B61AA6 Ref B: HK2EDGE0921 Ref C: 2021-05-05T22:54:49Z X-Powered-By: ASP.NET X-Sharepointhealthscore: 3 403 FORBIDDEN 2021/05/05 22:54:49 DEBUG : &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; 2021/05/05 22:54:49 Failed to create file system for &#34;pelcra:SHARE/CLARIN/SPOKES/PELCRA_EMO&#34;: read metadata failed: 403 FORBIDDEN: 403 Forbidden . !rclone ls :http: --http-url &#39;https://uniwersytetlodzki-my.sharepoint.com/:f:/g/personal/pelcra_uni_lodz_pl/EpPehikqGqZJltrAKlVp3k0BOeyzEgBBO_ZwmFC9WaLbWw&#39; --use-cookies -vv . !rclone config dump .",
            "url": "https://jimregan.github.io/notes/rclone/sharepoint/2021/05/02/rclone-and-sharepoint.html",
            "relUrl": "/rclone/sharepoint/2021/05/02/rclone-and-sharepoint.html",
            "date": " • May 2, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "Two speechbrain speech enhancement models",
            "content": "The Colab notebook (with outputs) is here; the models are on the Huggingface hub: mtl-mimic-voicebank and speechbrain/metricgan-plus-voicebank . The first twenty seconds of mtl-mimic-voicebank aren&#39;t great (but they are quieter in the recording); the rest is fantastic. The output from metricgan-plus-voicebank is bad from start to finish. . %%capture !pip install torchaudio speechbrain . !wget http://assets.doegen.ie/sound/MP3_versions/aud_Ul1-LA_1202d1u1.mp3 . import IPython IPython.display.Audio(&#39;aud_Ul1-LA_1202d1u1.mp3&#39;) . import torchaudio from speechbrain.pretrained import SpectralMaskEnhancement enhance_model = SpectralMaskEnhancement.from_hparams( source=&quot;speechbrain/mtl-mimic-voicebank&quot;, savedir=&quot;pretrained_models/mtl-mimic-voicebank&quot;, ) enhanced = enhance_model.enhance_file(&quot;aud_Ul1-LA_1202d1u1.mp3&quot;) # Saving enhanced signal on disk torchaudio.save(&#39;enhanced.wav&#39;, enhanced.unsqueeze(0), 16000) . IPython.display.Audio(&#39;enhanced.wav&#39;) . import torch enhance_model = SpectralMaskEnhancement.from_hparams( source=&quot;speechbrain/metricgan-plus-voicebank&quot;, savedir=&quot;pretrained_models/metricgan-plus-voicebank&quot;, ) noisy = enhance_model.load_audio(&quot;aud_Ul1-LA_1202d1u1.mp3&quot;).unsqueeze(0) # Add relative length tensor enhanced = enhance_model.enhance_batch(noisy, lengths=torch.tensor([1.])) # Saving enhanced signal on disk torchaudio.save(&#39;enhanced2.wav&#39;, enhanced, 16000) . IPython.display.Audio(&#39;enhanced2.wav&#39;) .",
            "url": "https://jimregan.github.io/notes/speechbrain/speech%20enhancement/2021/04/30/speechbrain_speech_enhancements.html",
            "relUrl": "/speechbrain/speech%20enhancement/2021/04/30/speechbrain_speech_enhancements.html",
            "date": " • Apr 30, 2021"
        }
        
    
  
    
        ,"post6": {
            "title": "Doegen recordings scraper",
            "content": "import requests from bs4 import BeautifulSoup import json . _BASE = &#39;https://doegen.ie/counties&#39; def do_get(url): r = requests.get(url, headers = {&#39;User-agent&#39;: &#39;Mozilla/5.0&#39;}) if r.status_code != 200: raise Exception(&quot;Failed to open landing page&quot;) return r.content . soup = BeautifulSoup(do_get(_BASE), &#39;html.parser&#39;) . counties = soup.find(&#39;ul&#39;, {&#39;class&#39;: &#39;vocabindex&#39;}).find_all(&#39;li&#39;) . pages = [] for county in counties: item = {} anchor = county.find(&#39;a&#39;) href = anchor[&#39;href&#39;] item[&#39;link&#39;] = f&#39;https://doegen.ie{href}&#39; if anchor.find(&#39;span&#39;).text.strip() != &#39;(0)&#39;: item[&#39;county&#39;] = anchor.text.split()[1] pages.append(item) . def proc_page(url): result = {} html = do_get(url) soup = BeautifulSoup(html, &#39;html.parser&#39;) main = soup.find(&#39;div&#39;, {&#39;id&#39;: &#39;main&#39;}) content = main.find(&#39;div&#39;, {&#39;class&#39;: &#39;content&#39;}) source = content.find(&#39;source&#39;) if source == None: return {} result[&#39;mp3&#39;] = source[&#39;src&#39;] result[&#39;transcript&#39;] = content.find(&#39;div&#39;, id=&#39;transcript&#39;).text if content.find(&#39;div&#39;, id=&#39;translation&#39;) != None: result[&#39;translation&#39;] = content.find(&#39;div&#39;, id=&#39;translation&#39;).text if content.find(&#39;div&#39;, id=&#39;footnote&#39;) != None: result[&#39;footnote&#39;] = content.find(&#39;div&#39;, id=&#39;footnote&#39;).text result[&#39;recording_metadata&#39;] = content.find(&#39;div&#39;, id=&#39;recording_metadata&#39;).text return result . def proc_county(item): content = do_get(item[&#39;link&#39;]) soup = BeautifulSoup(content, &#39;html.parser&#39;) main = soup.find(&#39;div&#39;, id=&#39;main&#39;) nodes = main.find_all(&#39;div&#39;, {&#39;class&#39;: &#39;node&#39;}) stories = [] for node in nodes: story = {} anchor = node.find(&#39;a&#39;) story[&#39;link&#39;] = f&quot;https://doegen.ie{anchor[&#39;href&#39;]}&quot; story[&#39;content&#39;] = proc_page(story[&#39;link&#39;]) if story[&#39;content&#39;] == {}: continue tags = node.find(&#39;div&#39;, {&#39;class&#39;: &#39;terms&#39;}).find_all(&#39;a&#39;, rel=&#39;tag&#39;) text = anchor.text if &#39; - &#39; in text: tmp = text.split(&#39; - &#39;) if len(tmp) == 2: story[&#39;title&#39;] = tmp[0] story[&#39;speaker_name&#39;] = tmp[1] name_parts = tmp[1].split(&#39; &#39;) first = name_parts[0] for tag in tags: if first in tag.text: story[&#39;speaker_url&#39;] = f&quot;https://doegen.ie{tag[&#39;href&#39;]}&quot; else: story[&#39;raw&#39;] = text else: story[&#39;raw&#39;] = text stories.append(story) item[&#39;stories&#39;] = stories . for page in pages: proc_county(page) . with open(&#39;doegen.json&#39;, &#39;w&#39;) as f: json.dump(pages, f) .",
            "url": "https://jimregan.github.io/notes/irish/scraper/2021/04/29/doegen-scraper.html",
            "relUrl": "/irish/scraper/2021/04/29/doegen-scraper.html",
            "date": " • Apr 29, 2021"
        }
        
    
  
    
        ,"post7": {
            "title": "Praat via parselmouth",
            "content": "import numpy as np import matplotlib.pyplot as plt import seaborn as sns import requests import parselmouth import tempfile . sns.set() # Use seaborn&#39;s default style to make attractive graphs plt.rcParams[&#39;figure.dpi&#39;] = 300 # Show nicely large images in this notebook . def load_from_teanglann(word, dialect): valid_dialects = [&#39;C&#39;, &#39;M&#39;, &#39;U&#39;] if dialect not in valid_dialects and dialect.upper()[0] not in valid_dialects: raise Exception(f&#39;Dialect must be one of &quot;C&quot;, &quot;M&quot; or &quot;U&quot;; got &quot;{dialect}&quot;&#39;) url = f&#39;https://www.teanglann.ie/Can{dialect}/{word}.mp3&#39; r = requests.get(url) if r.status_code != 200: raise Exception(f&#39;Failed to fetch {url}&#39;) file = tempfile.NamedTemporaryFile(mode=&#39;w+b&#39;) file.write(r.content) return file . def draw_spectrogram(spectrogram, dynamic_range=70): X, Y = spectrogram.x_grid(), spectrogram.y_grid() sg_db = 10 * np.log10(spectrogram.values) plt.pcolormesh(X, Y, sg_db, vmin=sg_db.max() - dynamic_range, cmap=&#39;afmhot&#39;) plt.ylim([spectrogram.ymin, spectrogram.ymax]) plt.xlabel(&quot;time [s]&quot;) plt.ylabel(&quot;frequency [Hz]&quot;) def draw_intensity(intensity): plt.plot(intensity.xs(), intensity.values.T, linewidth=3, color=&#39;w&#39;) plt.plot(intensity.xs(), intensity.values.T, linewidth=1) plt.grid(False) plt.ylim(0) plt.ylabel(&quot;intensity [dB]&quot;) . file=load_from_teanglann(&#39;athdhreas&#39;, &#39;U&#39;) snd = parselmouth.Sound(file_path=file.name) intensity = snd.to_intensity() spectrogram = snd.to_spectrogram() plt.figure() draw_spectrogram(spectrogram) plt.twinx() #draw_intensity(intensity) plt.xlim([snd.xmin, snd.xmax]) plt.show() . def draw_pitch(pitch): # Extract selected pitch contour, and # replace unvoiced samples by NaN to not plot pitch_values = pitch.selected_array[&#39;frequency&#39;] pitch_values[pitch_values==0] = np.nan plt.plot(pitch.xs(), pitch_values, &#39;o&#39;, markersize=5, color=&#39;w&#39;) plt.plot(pitch.xs(), pitch_values, &#39;o&#39;, markersize=2) plt.grid(False) plt.ylim(0, pitch.ceiling) plt.ylabel(&quot;fundamental frequency [Hz]&quot;) pitch = snd.to_pitch() # If desired, pre-emphasize the sound fragment before calculating the spectrogram pre_emphasized_snd = snd.copy() pre_emphasized_snd.pre_emphasize() spectrogram = pre_emphasized_snd.to_spectrogram(window_length=0.03, maximum_frequency=8000) plt.figure() draw_spectrogram(spectrogram) plt.twinx() #draw_pitch(pitch) plt.xlim([snd.xmin, snd.xmax]) plt.show() .",
            "url": "https://jimregan.github.io/notes/praat/parselmouth/2021/04/24/parselmouth.html",
            "relUrl": "/praat/parselmouth/2021/04/24/parselmouth.html",
            "date": " • Apr 24, 2021"
        }
        
    
  
    
        ,"post8": {
            "title": "BuNaMo to json",
            "content": "from lxml import etree . class BuNaMoWrongDocument(Exception): &quot;&quot;&quot;Exception raised for wrong document type&quot;&quot;&quot; def __init__(self, expected, got): self.expected = expected self.got = got self.message = f&quot;Expected root element &lt;{self.expected}&gt; but got &lt;{self.got}&gt;&quot; super().__init__(self.message) . Various functions to read one of the types of XML file. The open parts of speech (noun, adjective, verb) can have multiple forms, so those functions return attributes (a dictionary) and forms (a list of dictionaries) separately. . Close parts of speech (possessives and prepositions) are simpler, and most of the attributes are needless, so they return a simple dictionary containing the forms. . def read_adjective(file): tree = etree.parse(file) root = tree.getroot() valid_tags = [&#39;sgNom&#39;, &#39;sgGenMasc&#39;, &#39;sgGenFem&#39;, &#39;plNom&#39;, &#39;graded&#39;, &#39;abstractNoun&#39;, &#39;sgVocMasc&#39;, &#39;sgVocFem&#39;] attribs = {} forms = [] if root.tag != &#39;adjective&#39;: raise BuNaMoWrongDocument(&#39;adjective&#39;, root.tag) attribs[&#39;default&#39;] = root.get(&#39;default&#39;) attribs[&#39;declension&#39;] = root.get(&#39;declension&#39;) attribs[&#39;disambig&#39;] = root.get(&#39;disambig&#39;) attribs[&#39;isPre&#39;] = root.get(&#39;isPre&#39;) for child in root: if child.tag not in valid_tags: raise Exception(&#39;Unexpected tag &#39; + child.tag) tmp = {} tmp[&#39;props&#39;] = child.tag tmp[&#39;form&#39;] = child.get(&#39;default&#39;) forms.append(tmp) return attribs, forms def read_noun(file): tree = etree.parse(file) root = tree.getroot() valid_tags = [&#39;sgNom&#39;, &#39;sgGen&#39;, &#39;plNom&#39;, &#39;plGen&#39;, &#39;count&#39;, &#39;sgDat&#39;] attribs = {} forms = [] if root.tag != &#39;noun&#39;: raise BuNaMoWrongDocument(&#39;noun&#39;, root.tag) attribs[&#39;default&#39;] = root.get(&#39;default&#39;) attribs[&#39;declension&#39;] = root.get(&#39;declension&#39;) attribs[&#39;disambig&#39;] = root.get(&#39;disambig&#39;) attribs[&#39;isProper&#39;] = root.get(&#39;isProper&#39;) attribs[&#39;isDefinite&#39;] = root.get(&#39;isDefinite&#39;) attribs[&#39;allowArticledGenitive&#39;] = root.get(&#39;allowArticledGenitive&#39;) for child in root: if child.tag not in valid_tags: raise Exception(&#39;Unexpected tag &#39; + child.tag) tmp = {} tmp[&#39;props&#39;] = child.tag tmp[&#39;form&#39;] = child.get(&#39;default&#39;) tmp[&#39;gender&#39;] = child.get(&#39;gender&#39;) tmp[&#39;strength&#39;] = child.get(&#39;strength&#39;) forms.append(tmp) return attribs, forms def read_verb(file): tree = etree.parse(file) root = tree.getroot() valid_tags = [&#39;verbalNoun&#39;, &#39;verbalAdjective&#39;, &#39;tenseForm&#39;, &#39;moodForm&#39;] attribs = {} forms = [] if root.tag != &#39;verb&#39;: raise BuNaMoWrongDocument(&#39;verb&#39;, root.tag) attribs[&#39;default&#39;] = root.get(&#39;default&#39;) attribs[&#39;disambig&#39;] = root.get(&#39;disambig&#39;) for child in root: if child.tag not in valid_tags: raise Exception(&#39;Unexpected tag &#39; + child.tag) tmp = {} tmp[&#39;props&#39;] = child.tag tmp[&#39;form&#39;] = child.get(&#39;default&#39;) tmp[&#39;tense&#39;] = child.get(&#39;tense&#39;) tmp[&#39;mood&#39;] = child.get(&#39;mood&#39;) tmp[&#39;dependency&#39;] = child.get(&#39;dependency&#39;) tmp[&#39;person&#39;] = child.get(&#39;person&#39;) forms.append(tmp) return attribs, forms def read_nounphrase(file): tree = etree.parse(file) root = tree.getroot() valid_tags = [&#39;sgNom&#39;, &#39;sgGen&#39;, &#39;plNom&#39;, &#39;plGen&#39;, &#39;sgNomArt&#39;, &#39;sgGenArt&#39;, &#39;plNomArt&#39;, &#39;plGenArt&#39;] attribs = {} forms = [] if root.tag != &#39;nounPhrase&#39;: raise BuNaMoWrongDocument(&#39;nounPhrase&#39;, root.tag) attribs[&#39;default&#39;] = root.get(&#39;default&#39;) attribs[&#39;declension&#39;] = root.get(&#39;declension&#39;) attribs[&#39;disambig&#39;] = root.get(&#39;disambig&#39;) attribs[&#39;isProper&#39;] = root.get(&#39;isProper&#39;) attribs[&#39;isDefinite&#39;] = root.get(&#39;isDefinite&#39;) attribs[&#39;allowArticledGenitive&#39;] = root.get(&#39;allowArticledGenitive&#39;) attribs[&#39;forceNominative&#39;] = root.get(&#39;forceNominative&#39;) for child in root: if child.tag not in valid_tags: raise Exception(&#39;Unexpected tag &#39; + child.tag) tmp = {} tmp[&#39;props&#39;] = child.tag tmp[&#39;form&#39;] = child.get(&#39;default&#39;) tmp[&#39;gender&#39;] = child.get(&#39;gender&#39;) tmp[&#39;strength&#39;] = child.get(&#39;strength&#39;) forms.append(tmp) return attribs, forms def read_possessive(file): tree = etree.parse(file) root = tree.getroot() valid_tags = [&#39;full&#39;, &#39;apos&#39;] attribs = {} forms = [] if root.tag != &#39;possessive&#39;: raise BuNaMoWrongDocument(&#39;possessive&#39;, root.tag) attribs[&#39;default&#39;] = root.get(&#39;default&#39;) attribs[&#39;disambig&#39;] = root.get(&#39;disambig&#39;) attribs[&#39;mutation&#39;] = root.get(&#39;mutation&#39;) for child in root: if child.tag not in valid_tags: raise Exception(&#39;Unexpected tag &#39; + child.tag) if child.tag == &#39;apos&#39;: attribs[&#39;apos&#39;] = child.get(&#39;default&#39;) return attribs def read_preposition(file): tree = etree.parse(file) root = tree.getroot() valid_tags = [&#39;sg1&#39;, &#39;sg2&#39;, &#39;sg3Masc&#39;, &#39;sg3Fem&#39;, &#39;pl1&#39;, &#39;pl2&#39;, &#39;pl3&#39;] attribs = {} forms = [] if root.tag != &#39;preposition&#39;: raise BuNaMoWrongDocument(&#39;preposition&#39;, root.tag) attribs[&#39;default&#39;] = root.get(&#39;default&#39;) for child in root: if child.tag not in valid_tags: raise Exception(&#39;Unexpected tag &#39; + child.tag) attribs[child.tag] = child.get(&#39;default&#39;) return attribs . import glob import json adjectives = {} for x in glob.glob(&#39;../input/bunamo-bunachar-naisiunta-moirfeolaiochta/adjective/*.xml&#39;): fname = x.split(&#39;/&#39;)[-1].replace(&#39;.xml&#39;, &#39;&#39;) attribs, forms = read_adjective(x) tmp = {} tmp[&#39;attributes&#39;] = attribs tmp[&#39;forms&#39;] = forms adjectives[fname] = tmp word = attribs[&#39;default&#39;] with open(&#39;adjectives.json&#39;, &#39;w&#39;) as outfile: json.dump(adjectives, outfile) . nouns = {} for x in glob.glob(&#39;../input/bunamo-bunachar-naisiunta-moirfeolaiochta/noun/*.xml&#39;): fname = x.split(&#39;/&#39;)[-1].replace(&#39;.xml&#39;, &#39;&#39;) attribs, forms = read_noun(x) tmp = {} tmp[&#39;attributes&#39;] = attribs tmp[&#39;forms&#39;] = forms nouns[fname] = tmp word = attribs[&#39;default&#39;] with open(&#39;nouns.json&#39;, &#39;w&#39;) as outfile: json.dump(nouns, outfile) . nounphrases = {} for x in glob.glob(&#39;../input/bunamo-bunachar-naisiunta-moirfeolaiochta/nounPhrase/*.xml&#39;): fname = x.split(&#39;/&#39;)[-1].replace(&#39;.xml&#39;, &#39;&#39;) attribs, forms = read_nounphrase(x) tmp = {} tmp[&#39;attributes&#39;] = attribs tmp[&#39;forms&#39;] = forms nounphrases[fname] = tmp word = attribs[&#39;default&#39;] with open(&#39;nounphrases.json&#39;, &#39;w&#39;) as outfile: json.dump(nounphrases, outfile) . verbs = {} for x in glob.glob(&#39;../input/bunamo-bunachar-naisiunta-moirfeolaiochta/verb/*.xml&#39;): fname = x.split(&#39;/&#39;)[-1].replace(&#39;.xml&#39;, &#39;&#39;) attribs, forms = read_verb(x) tmp = {} tmp[&#39;attributes&#39;] = attribs tmp[&#39;forms&#39;] = forms verbs[fname] = tmp word = attribs[&#39;default&#39;] with open(&#39;verbs.json&#39;, &#39;w&#39;) as outfile: json.dump(verbs, outfile) . preposition = {} for x in glob.glob(&#39;../input/bunamo-bunachar-naisiunta-moirfeolaiochta/preposition/*.xml&#39;): fname = x.split(&#39;/&#39;)[-1].replace(&#39;.xml&#39;, &#39;&#39;) attribs = read_preposition(x) tmp = {} tmp[&#39;attributes&#39;] = attribs preposition[fname] = tmp with open(&#39;prepositions.json&#39;, &#39;w&#39;) as outfile: json.dump(preposition, outfile) . possessive = {} for x in glob.glob(&#39;../input/bunamo-bunachar-naisiunta-moirfeolaiochta/possessive/*.xml&#39;): fname = x.split(&#39;/&#39;)[-1].replace(&#39;.xml&#39;, &#39;&#39;) attribs = read_possessive(x) tmp = {} tmp[&#39;attributes&#39;] = attribs possessive[fname] = tmp with open(&#39;possessives.json&#39;, &#39;w&#39;) as outfile: json.dump(possessive, outfile) . possessive . {&#39;ár_poss&#39;: {&#39;attributes&#39;: {&#39;default&#39;: &#39;ár&#39;, &#39;disambig&#39;: &#39;&#39;, &#39;mutation&#39;: &#39;ecl1&#39;}}, &#39;a_poss_masc&#39;: {&#39;attributes&#39;: {&#39;default&#39;: &#39;a&#39;, &#39;disambig&#39;: &#39;masc&#39;, &#39;mutation&#39;: &#39;len1&#39;}}, &#39;a_poss_fem&#39;: {&#39;attributes&#39;: {&#39;default&#39;: &#39;a&#39;, &#39;disambig&#39;: &#39;fem&#39;, &#39;mutation&#39;: &#39;prefH&#39;}}, &#39;do_poss&#39;: {&#39;attributes&#39;: {&#39;default&#39;: &#39;do&#39;, &#39;disambig&#39;: &#39;&#39;, &#39;mutation&#39;: &#39;len1&#39;, &#39;apos&#39;: &#34;d&#39;&#34;}}, &#39;a_poss_pl&#39;: {&#39;attributes&#39;: {&#39;default&#39;: &#39;a&#39;, &#39;disambig&#39;: &#39;pl&#39;, &#39;mutation&#39;: &#39;ecl1&#39;}}, &#39;mo_poss&#39;: {&#39;attributes&#39;: {&#39;default&#39;: &#39;mo&#39;, &#39;disambig&#39;: &#39;&#39;, &#39;mutation&#39;: &#39;len1&#39;, &#39;apos&#39;: &#34;m&#39;&#34;}}, &#39;bhur_poss&#39;: {&#39;attributes&#39;: {&#39;default&#39;: &#39;bhur&#39;, &#39;disambig&#39;: &#39;&#39;, &#39;mutation&#39;: &#39;ecl1&#39;}}} .",
            "url": "https://jimregan.github.io/notes/irish/bunamo/kaggle/2021/04/24/bunamo-raw-json.html",
            "relUrl": "/irish/bunamo/kaggle/2021/04/24/bunamo-raw-json.html",
            "date": " • Apr 24, 2021"
        }
        
    
  
    
        ,"post9": {
            "title": "Kashubian PDF corpus 1",
            "content": "!wget $(lynx -dump http://skarbnicakaszubska.pl/najo-uczba/|grep pdf|awk &#39;{print $NF}&#39;) . For the most part, the text extracted from the pdfs is fine as is; one of the files has multiple articles, several with translations, making it potentially useful as a parallel corpus. . The text (seems to) come out fine with pdftotext, so I haven&#39;t bothered doing anything else. . !pdftotext -nopgbrk -f 9 -l 10 ZKP_biuletynRJK_2015_internet.pdf - | grep -v &#39;BIU­L E­T IN RADZËZNË KASZËBSCZÉGÒ JÃZËKA 2015&#39;|grep -v &#39;^10&#39;|grep -v &#39;^$&#39; &gt; ZKP_biuletynRJK_2015_internet_1.csb.txt . !pdftotext -nopgbrk -f 11 -l 12 ZKP_biuletynRJK_2015_internet.pdf - | grep -v &#39;BIU­L E­T YN RADY JĘZYKA KASZUBSKIEGO 2015&#39;|grep -v &#39;^12&#39;|grep -v &#39;^$&#39; &gt; ZKP_biuletynRJK_2015_internet_1.pl.txt . !pdftotext -nopgbrk -f 14 -l 20 ZKP_biuletynRJK_2015_internet.pdf - | grep -v &#39;BIU­L E­T IN RADZËZNË KASZËBSCZÉGÒ JÃZËKA 2015&#39;|grep -v &#39;^Pòstanowienia Radzëznë Kaszëbsczégò Jãzëka&#39;|grep -v &#39;^$&#39;|grep -v &#39;^1[5-9]$&#39;|grep -v &#39;^20$&#39; &gt; ZKP_biuletynRJK_2015_internet_wl1.txt . !pdftotext -nopgbrk -f 21 -l 23 ZKP_biuletynRJK_2015_internet.pdf - | grep -v &#39;BIU­L E­T IN RADZËZNË KASZËBSCZÉGÒ JÃZËKA 2015&#39;|grep -v &#39;^Pòstanowienia Radzëznë Kaszëbsczégò Jãzëka&#39;|grep -v &#39;^$&#39;|grep -v &#39;^2[1-9]$&#39; &gt; ZKP_biuletynRJK_2015_internet_wl2.txt . !pdftotext -nopgbrk -f 24 -l 29 ZKP_biuletynRJK_2015_internet.pdf - | grep -v &#39;BIU­L E­T IN RADZËZNË KASZËBSCZÉGÒ JÃZËKA 2015&#39;|grep -v &#39;^Pòstanowienia Radzëznë Kaszëbsczégò Jãzëka&#39;|grep -v &#39;^$&#39;|grep -v &#39;^2[1-9]$&#39; &gt; ZKP_biuletynRJK_2015_internet_wl3.txt . !pdftotext -nopgbrk -f 30 -l 48 ZKP_biuletynRJK_2015_internet.pdf - | grep -v &#39;BIU­L E­T IN RADZËZNË KASZËBSCZÉGÒ JÃZËKA 2015&#39;|grep -v &#39;^Pòstanowienia Radzëznë Kaszëbsczégò Jãzëka&#39;|grep -v &#39;^$&#39;|grep -v &#39;^[34][0-9]$&#39; &gt; ZKP_biuletynRJK_2015_internet_wl4.txt . !pdftotext -nopgbrk -f 49 -l 49 ZKP_biuletynRJK_2015_internet.pdf - | grep -v &#39;BIU­L E­T IN RADZËZNË KASZËBSCZÉGÒ JÃZËKA 2015&#39;|grep -v &#39;^Pòstanowienia Radzëznë Kaszëbsczégò Jãzëka&#39;|grep -v &#39;^$&#39;|grep -v &#39;^[34][0-9]$&#39; &gt; ZKP_biuletynRJK_2015_internet_wl5.txt . !pdftotext -nopgbrk -f 50 -l 65 ZKP_biuletynRJK_2015_internet.pdf - | grep -v &#39;BIU­L E­T IN RADZËZNË KASZËBSCZÉGÒ JÃZËKA 2015&#39;|grep -v &#39;^Pòstanowienia Radzëznë Kaszëbsczégò Jãzëka&#39;|grep -v &#39;^$&#39;|grep -v &#39;^[56][0-9]$&#39; &gt; ZKP_biuletynRJK_2015_internet_wl6.txt . def runner(file, start, end, suffix): base = file.replace(&#39;.pdf&#39;, &#39;&#39;) outfile = f&quot;{base}_{suffix}.txt&quot; !pdftotext -nopgbrk -f {start} -l {end} {file} - | grep -v &#39;BIU­L E­T IN RADZËZNË KASZËBSCZÉGÒ JÃZËKA 2015&#39;|grep -v &#39;BIU­L E­T YN RADY JĘZYKA KASZUBSKIEGO 2015&#39;|grep -v &#39;^Pòstanowienia Radzëznë Kaszëbsczégò Jãzëka&#39;|grep -v &#39;^$&#39;|grep -v &#39;^[0-9][0-9]$&#39;|grep -v &#39;^[1-4][0-9][0-9]$&#39; &gt; {outfile} . runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 68, 74, &#39;wl7&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 75, 77, &#39;wl8&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 78, 83, &#39;wl9&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 84, 102, &#39;wl10&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 103, 103, &#39;wl11&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 104, 119, &#39;wl12&#39;) . runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 122, 128, &#39;csb2&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 129, 132, &#39;csb3&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 133, 144, &#39;csb4&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 145, 151, &#39;csb5&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 153, 161, &#39;csb6&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 162, 166, &#39;csb7&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 168, 178, &#39;csb8&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 179, 185, &#39;csb9&#39;) # it took me this long to remember that there&#39;s a table of contents! runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 186, 197, &#39;csb10&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 198, 204, &#39;csb11&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 205, 211, &#39;csb12&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 212, 220, &#39;csb13&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 222, 228, &#39;pl2&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 229, 237, &#39;plx1&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 238, 241, &#39;pl3&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 242, 248, &#39;plx2&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 249, 254, &#39;plx3&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 255, 266, &#39;pl4&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 267, 274, &#39;pl5&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 275, 283, &#39;pl6&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 284, 289, &#39;pl7&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 290, 300, &#39;plx4&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 301, 313, &#39;pl8&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 314, 320, &#39;pl9&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 5, 8, &#39;toc&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 321, 333, &#39;pl10&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 334, 359, &#39;plx5&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 360, 367, &#39;pl11&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 368, 374, &#39;pl12&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 375, 390, &#39;plx6&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 391, 396, &#39;plx7&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 397, 404, &#39;pl13&#39;) . Now, the rest . !for i in [0-9N]*.pdf;do pdftotext $i;done . uname=!uname -a if not &#39;LAPTOP-6PFTN7M9&#39; in uname: !rm *.pdf .",
            "url": "https://jimregan.github.io/notes/kashubian/lazyscrape/2021/04/23/najo-uczba-pdfs.html",
            "relUrl": "/kashubian/lazyscrape/2021/04/23/najo-uczba-pdfs.html",
            "date": " • Apr 23, 2021"
        }
        
    
  
    
        ,"post10": {
            "title": "Checking a Kashubian adjective-like declension",
            "content": "def _list_to_check(pos): num = [&#39;sg&#39;, &#39;pl&#39;] gen = [&#39;mp&#39;, &#39;ma&#39;, &#39;mi&#39;, &#39;f&#39;, &#39;nt&#39;] cas = [&#39;nom&#39;, &#39;gen&#39;, &#39;dat&#39;, &#39;acc&#39;, &#39;ins&#39;, &#39;loc&#39;, &#39;voc&#39;] out = [] for n in num: for g in gen: for c in cas: out.append(f&quot;{pos}.{g}.{n}.{c}&quot;) return out . len(_list_to_check(&#39;num.ord&#39;)) . 70 . dredzi = &quot;&quot;&quot; drëdżi drëdżi num.ord.mp|ma|mi.sg.nom|voc drëgô drëdżi num.ord.f.sg.nom|voc drëdżé drëdżi num.ord.nt.sg.nom|acc|voc drëgą drëdżi num.ord.f.sg.acc|ins drëdżi drëdżi num.ord.f.sg.gen|dat|loc drëdżim drëdżi num.ord.mp|ma|mi|nt.sg.loc|ins drëdżé drëdżi num.ord.nt|f|mi|ma.pl.nom|acc|voc drëdżich drëdżi num.ord.nt|f|mi|ma|mp.pl.gen|loc drëdżima drëdżi num.ord.nt|f|mi|ma.pl.ins drëdżégò drëdżi num.ord.nt|mi|ma|mp.sg.gen drëdżégò drëdżi num.ord.ma|mp.sg.acc drëdżémù drëdżi num.ord.nt|mi|ma|mp.sg.dat drëdżi drëdżi num.ord.mp.pl.nom|voc drëdżich drëdżi num.ord.mp.pl.acc drëdżim drëdżi num.ord.nt|f|mi|ma|mp.pl.dat &quot;&quot;&quot; . def _do_expand(stack, todo): onward = [] if not &#39;.&#39; in todo: return [f&#39;{a}.{b}&#39; for a in stack for b in todo.split(&#39;|&#39;)] cur, rest = todo.split(&#39;.&#39;, 1) if stack == []: onward = cur.split(&#39;|&#39;) return _do_expand(onward, rest) else: onward = [f&#39;{a}.{b}&#39; for a in stack for b in cur.split(&#39;|&#39;)] return _do_expand(onward, rest) def expand_compressed(lines): output = [] for i in lines: form, lemma, postag = i.split(&#39; t&#39;) newtags = _do_expand([], postag) output.extend([f&quot;{form} t{lemma} t{itag}&quot; for itag in newtags]) return output . expand_compressed([l for l in dredzi.split(&#39; n&#39;) if l != &#39;&#39;]) . vals = expand_compressed([l for l in dredzi.split(&#39; n&#39;) if l != &#39;&#39;]) . tags = [a.split(&#39; t&#39;)[-1] for a in vals] . for tc in _list_to_check(&#39;num.ord&#39;): if not tc in tags: print(tc) . num.ord.mi.sg.acc num.ord.mp.pl.ins . dredzi = &quot;&quot;&quot; drëdżi drëdżi num.ord.mp|ma|mi.sg.nom|voc drëdżi drëdżi num.ord.mi.sg.acc drëgô drëdżi num.ord.f.sg.nom|voc drëdżé drëdżi num.ord.nt.sg.nom|acc|voc drëgą drëdżi num.ord.f.sg.acc|ins drëdżi drëdżi num.ord.f.sg.gen|dat|loc drëdżim drëdżi num.ord.mp|ma|mi|nt.sg.loc|ins drëdżé drëdżi num.ord.nt|f|mi|ma.pl.nom|acc|voc drëdżich drëdżi num.ord.nt|f|mi|ma|mp.pl.gen|loc drëdżima drëdżi num.ord.nt|f|mi|ma|mp.pl.ins drëdżégò drëdżi num.ord.nt|mi|ma|mp.sg.gen drëdżégò drëdżi num.ord.ma|mp.sg.acc drëdżémù drëdżi num.ord.nt|mi|ma|mp.sg.dat drëdżi drëdżi num.ord.mp.pl.nom|voc drëdżich drëdżi num.ord.mp.pl.acc drëdżim drëdżi num.ord.nt|f|mi|ma|mp.pl.dat &quot;&quot;&quot; .",
            "url": "https://jimregan.github.io/notes/kashubian/declension/2021/04/23/check-kashubian-adjlike.html",
            "relUrl": "/kashubian/declension/2021/04/23/check-kashubian-adjlike.html",
            "date": " • Apr 23, 2021"
        }
        
    
  
    
        ,"post11": {
            "title": "Installing montreal-forced-aligner on kaggle",
            "content": "%%capture !wget https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/releases/download/v1.0.1/montreal-forced-aligner_linux.tar.gz . %%capture !tar zxvf montreal-forced-aligner_linux.tar.gz !rm montreal-forced-aligner_linux.tar.gz . !mv montreal-forced-aligner/bin montreal-forced-aligner/bb . !ln -s montreal-forced-aligner/lib/libpython3.6m.so.1.0 montreal-forced-aligner/lib/libpython3.6m.so .",
            "url": "https://jimregan.github.io/notes/kaggle/itworks/2021/04/20/mfa-on-kaggle.html",
            "relUrl": "/kaggle/itworks/2021/04/20/mfa-on-kaggle.html",
            "date": " • Apr 20, 2021"
        }
        
    
  
    
        ,"post12": {
            "title": "Irish lowercase with ICU",
            "content": "import icu . def transliterator_from_rules(name, rules): fromrules = icu.Transliterator.createFromRules(name, rules) icu.Transliterator.registerInstance(fromrules) return icu.Transliterator.createInstance(name) . irishlc_rules = &quot;&quot;&quot; :: NFD; $uvowel=[AEIOU]; $wb=[^[:L:][:M:]]; $wb { ([nt]) } $uvowel → $1 &#39;-&#39;; :: lower; :: NFC; &quot;&quot;&quot; . irishlc = transliterator_from_rules(&#39;irishlc&#39;, irishlc_rules) . irishlc.transliterate(&quot;tá an tUachtarán tar éis a lámh a chur leis&quot;) . &#39;tá an t-uachtarán tar éis a lámh a chur leis&#39; .",
            "url": "https://jimregan.github.io/notes/icu/2021/04/18/irish-lower-with-icu.html",
            "relUrl": "/icu/2021/04/18/irish-lower-with-icu.html",
            "date": " • Apr 18, 2021"
        }
        
    
  
    
        ,"post13": {
            "title": "M2M100 sucks at Irish",
            "content": "Huggingface Transformers added the M2M 100 model, I tried it out and tweeted screenshots of the appalling output, so I thought I&#39;d recreate the translations to show they were very real. . !pip install sentencepiece transformers . from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer model = M2M100ForConditionalGeneration.from_pretrained(&quot;facebook/m2m100_418M&quot;) tokenizer = M2M100Tokenizer.from_pretrained(&quot;facebook/m2m100_418M&quot;) . def translate(text, src_lang=&quot;pl&quot;, trg_lang=&quot;ga&quot;): tokenizer.src_lang = src_lang encoded = tokenizer(text, return_tensors=&quot;pt&quot;) generated_tokens = model.generate(**encoded, forced_bos_token_id=tokenizer.get_lang_id(trg_lang)) print(tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)) . So, do massively multilingual MT models trained on massively crawled datasets lead to great output?No pic.twitter.com/SckNGTq09B . &mdash; Jim O&#39;Regan (@jimregan) April 12, 2021 . “One must love one&#39;s wife” . translate(&quot;Trzeba kochać swoją żonę&quot;) . [&#39;Brazzers físeán catagóir Inexperienced, Déagóir Inexperienced&#39;] . pic.twitter.com/4b6DgbbhtE . &mdash; Jim O&#39;Regan (@jimregan) April 12, 2021 . “What are you on about?” or “What are you getting at?” . translate(&quot;O co Ci chodzi?&quot;) . [&#39;Brazzers físeán catagóir Inexperienced, Déagóir Inexperienced&#39;] . It&#39;s almost poetic pic.twitter.com/IbJi1zvlrX . &mdash; Jim O&#39;Regan (@jimregan) April 12, 2021 . Let&#39;s try English: . translate(&quot;Hello, how are you?&quot;, src_lang=&#39;en&#39;) . [&#39;Brazzers físeán catagóir Inexperienced, Déagóir Inexperienced, Déagóir Inexperienced&#39;] . pic.twitter.com/GH4KtctnTI . &mdash; Jim O&#39;Regan (@jimregan) April 12, 2021 . How poetic. How about some actual poetry? (Pan Tadeusz) . translate(&quot;Litwo, Ojczyzno moja! ty jesteś jak zdrowie; Ile cię trzeba cenić, ten tylko się dowie, Kto cię stracił.&quot;) . [&#39;Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers&#39;] . Switching to English output, it at least gives a decent-looking sentence. (It only looks decent, it&#39;s wrong) pic.twitter.com/4HyBQvTAux . &mdash; Jim O&#39;Regan (@jimregan) April 12, 2021 . “It seems to me that you are not sober” . translate(&quot;Mi się wydaje, że nie jesteś trzeźwy&quot;, trg_lang=&#39;en&#39;) . [&#39;I don’t think you’re trembling.&#39;] .",
            "url": "https://jimregan.github.io/notes/m2m100/badmt/2021/04/13/m2m100-sucks-at-irish.html",
            "relUrl": "/m2m100/badmt/2021/04/13/m2m100-sucks-at-irish.html",
            "date": " • Apr 13, 2021"
        }
        
    
  
    
        ,"post14": {
            "title": "Living Audio Irish",
            "content": "%%capture !wget https://ia800700.us.archive.org/6/items/ga.ie.cll.48000.tar/ga.ie.cll.48000.tar.gz . %%capture !wget https://raw.githubusercontent.com/Idlak/Living-Audio-Dataset/master/ga/text.xml . %%capture !tar zxvf ga.ie.cll.48000.tar.gz !rm ga.ie.cll.48000.tar.gz . %%capture !pip install bs4 . from bs4 import BeautifulSoup import unicodedata soup = BeautifulSoup(open(&#39;text.xml&#39;).read(), &#39;lxml&#39;) dataset = list() for entry in soup.find_all(&#39;fileid&#39;): current = dict() current[&#39;id&#39;] = entry[&#39;id&#39;] current[&#39;text&#39;] = unicodedata.normalize(&#39;NFC&#39;, entry.text.strip()) dataset.append(current) . !rm text.xml . def is_upper_vowel(letter): if letter in [&#39;A&#39;, &#39;E&#39;, &#39;I&#39;, &#39;O&#39;, &#39;U&#39;, &#39;Á&#39;, &#39;É&#39;, &#39;Í&#39;, &#39;Ó&#39;, &#39;Ú&#39;]: return True else: return False def irish_lower(word): if len(word) &gt; 1 and word[0] in [&#39;n&#39;, &#39;t&#39;] and is_upper_vowel(word[1]): return word[0] + &#39;-&#39; + word[1:].lower() else: return word.lower() def irish_lower_sentence(sentence): return &quot; &quot;.join([irish_lower(w) for w in sentence.split(&quot; &quot;)]) . import re hyphens = &#39;cll_z0001_713 cll_z0001_804 cll_z0002_069 cll_z0002_296 cll_z0002_448 cll_z0002_481 cll_z0002_484 cll_z0002_495&#39;.split(&#39; &#39;) for entry in dataset: tmp = entry[&#39;text&#39;] tmp = re.sub(&#39; - &#39;, &#39; &#39;, tmp) tmp = re.sub(&#39; – &#39;, &#39; &#39;, tmp) tmp = re.sub(&#39;[‘“” &quot; . ?!,–—;:]&#39;, &#39;&#39;, tmp) if entry[&#39;id&#39;] in hyphens: tmp = re.sub(&#39; &#39;&#39;, &#39;&#39;, tmp) entry[&#39;sentence&#39;] = irish_lower_sentence(tmp) . for entry in dataset: entry[&#39;speaker&#39;] = &#39;cll&#39; entry[&#39;accent&#39;] = &#39;dublin&#39; entry[&#39;gender&#39;] = &#39;male&#39; entry[&#39;path&#39;] = &#39;../input/living-audio-irish-speech-corpus/48000_orig/{}.wav&#39;.format(entry[&#39;id&#39;]) . import json datasetjson = json.dumps(dataset) jsonf = open(&quot;living-audio.json&quot;, &quot;w&quot;) jsonf.write(datasetjson) jsonf.close() . !wget https://raw.githubusercontent.com/Idlak/idlak/master/idlak-data/ga/ie/lexicon-default.xml . --2021-04-20 21:54:40-- https://raw.githubusercontent.com/Idlak/idlak/master/idlak-data/ga/ie/lexicon-default.xml Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ... Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 405337 (396K) [text/plain] Saving to: ‘lexicon-default.xml’ lexicon-default.xml 100%[===================&gt;] 395.84K --.-KB/s in 0.03s 2021-04-20 21:54:40 (14.8 MB/s) - ‘lexicon-default.xml’ saved [405337/405337] . from bs4 import BeautifulSoup import unicodedata soup = BeautifulSoup(open(&#39;lexicon-default.xml&#39;).read(), &#39;lxml&#39;) lexicon = [] for entry in soup.find_all(&#39;lex&#39;): current = {} current[&#39;pron&#39;] = entry[&#39;pron&#39;] current[&#39;text&#39;] = unicodedata.normalize(&#39;NFC&#39;, entry.text.strip()) lexicon.append(current) . lexiconjson = json.dumps(lexicon) jsonf = open(&quot;ga-lexicon.json&quot;, &quot;w&quot;) jsonf.write(lexiconjson) jsonf.close() . !rm lexicon-default.xml . with open(&#39;lexicon.txt&#39;, &#39;w&#39;) as lextxt: for lex in lexicon: text = lex[&#39;text&#39;] cleaned = lex[&#39;pron&#39;].replace(&#39;0&#39;, &#39;&#39;).replace(&#39;1&#39;, &#39;&#39;).replace(&#39;2&#39;, &#39;&#39;) lextxt.write(f&#39;{text} {cleaned} n&#39;) .",
            "url": "https://jimregan.github.io/notes/speech/dataset/2021/04/06/living-audio-irish.html",
            "relUrl": "/speech/dataset/2021/04/06/living-audio-irish.html",
            "date": " • Apr 6, 2021"
        }
        
    
  
    
        ,"post15": {
            "title": "Install pynini on Colab",
            "content": "!pip install -q condacolab import condacolab condacolab.install() . ✨🍰✨ Everything looks OK! . !conda install -c conda-forge pynini . import pynini .",
            "url": "https://jimregan.github.io/notes/colab/pynini/2021/04/06/install-pynini-on-colab.html",
            "relUrl": "/colab/pynini/2021/04/06/install-pynini-on-colab.html",
            "date": " • Apr 6, 2021"
        }
        
    
  
    
        ,"post16": {
            "title": "Running wav2vec2 for Polish on Kashubian",
            "content": "%%capture import requests from bs4 import BeautifulSoup . URL=&#39;http://www.miesiecznikpomerania.pl/audio&#39; . req = requests.get(URL) soup = BeautifulSoup(req.content, &#39;html.parser&#39;) . contents = list() for part in soup.find_all(&#39;div&#39;, class_=&#39;sp-accordion-inner&#39;): out = {} audtag = part.find(&#39;audio&#39;) source = audtag.find(&#39;source&#39;) out[&#39;audio&#39;] = &#39;http://www.miesiecznikpomerania.pl{}&#39;.format(source[&#39;src&#39;]) audtag.decompose() out[&#39;text&#39;] = part.text.strip() contents.append(out) . for c in contents: !echo {c[&#39;audio&#39;]} &gt;&gt; input . %%capture !cat input|sort|uniq &gt; input.sorted !wget -i input.sorted . !cat input.sorted|grep -v uczba_5_Miedzy_niebem_a_ziemia_-_Najo_uczba|awk &#39;{print &quot;http://web.archive.org/web/&quot; $0}&#39; &gt; input.wayback . %%capture !wget -i input.wayback . import json with open(&#39;data.json&#39;, &#39;w&#39;) as outfile: json.dump(contents, outfile) . %%capture !for i in *.ogg;do ffmpeg -y -i &quot;$i&quot; -acodec pcm_s16le -ac 1 -ar 16000 &quot;$i.wav&quot;;done . %%capture !pip install librosa webrtcvad . # VAD wrapper is taken from PyTorch Speaker Verification: # https://github.com/HarryVolek/PyTorch_Speaker_Verification # Copyright (c) 2019, HarryVolek # License: BSD-3-Clause # based on https://github.com/wiseman/py-webrtcvad/blob/master/example.py # Copyright (c) 2016 John Wiseman # License: MIT import collections import contextlib import numpy as np import sys import librosa import wave import webrtcvad #from hparam import hparam as hp sr = 16000 def read_wave(path, sr): &quot;&quot;&quot;Reads a .wav file. Takes the path, and returns (PCM audio data, sample rate). Assumes sample width == 2 &quot;&quot;&quot; with contextlib.closing(wave.open(path, &#39;rb&#39;)) as wf: num_channels = wf.getnchannels() assert num_channels == 1 sample_width = wf.getsampwidth() assert sample_width == 2 sample_rate = wf.getframerate() assert sample_rate in (8000, 16000, 32000, 48000) pcm_data = wf.readframes(wf.getnframes()) data, _ = librosa.load(path, sr) assert len(data.shape) == 1 assert sr in (8000, 16000, 32000, 48000) return data, pcm_data class Frame(object): &quot;&quot;&quot;Represents a &quot;frame&quot; of audio data.&quot;&quot;&quot; def __init__(self, bytes, timestamp, duration): self.bytes = bytes self.timestamp = timestamp self.duration = duration def frame_generator(frame_duration_ms, audio, sample_rate): &quot;&quot;&quot;Generates audio frames from PCM audio data. Takes the desired frame duration in milliseconds, the PCM data, and the sample rate. Yields Frames of the requested duration. &quot;&quot;&quot; n = int(sample_rate * (frame_duration_ms / 1000.0) * 2) offset = 0 timestamp = 0.0 duration = (float(n) / sample_rate) / 2.0 while offset + n &lt; len(audio): yield Frame(audio[offset:offset + n], timestamp, duration) timestamp += duration offset += n def vad_collector(sample_rate, frame_duration_ms, padding_duration_ms, vad, frames): &quot;&quot;&quot;Filters out non-voiced audio frames. Given a webrtcvad.Vad and a source of audio frames, yields only the voiced audio. Uses a padded, sliding window algorithm over the audio frames. When more than 90% of the frames in the window are voiced (as reported by the VAD), the collector triggers and begins yielding audio frames. Then the collector waits until 90% of the frames in the window are unvoiced to detrigger. The window is padded at the front and back to provide a small amount of silence or the beginnings/endings of speech around the voiced frames. Arguments: sample_rate - The audio sample rate, in Hz. frame_duration_ms - The frame duration in milliseconds. padding_duration_ms - The amount to pad the window, in milliseconds. vad - An instance of webrtcvad.Vad. frames - a source of audio frames (sequence or generator). Returns: A generator that yields PCM audio data. &quot;&quot;&quot; num_padding_frames = int(padding_duration_ms / frame_duration_ms) # We use a deque for our sliding window/ring buffer. ring_buffer = collections.deque(maxlen=num_padding_frames) # We have two states: TRIGGERED and NOTTRIGGERED. We start in the # NOTTRIGGERED state. triggered = False voiced_frames = [] for frame in frames: is_speech = vad.is_speech(frame.bytes, sample_rate) if not triggered: ring_buffer.append((frame, is_speech)) num_voiced = len([f for f, speech in ring_buffer if speech]) # If we&#39;re NOTTRIGGERED and more than 90% of the frames in # the ring buffer are voiced frames, then enter the # TRIGGERED state. if num_voiced &gt; 0.9 * ring_buffer.maxlen: triggered = True start = ring_buffer[0][0].timestamp # We want to yield all the audio we see from now until # we are NOTTRIGGERED, but we have to start with the # audio that&#39;s already in the ring buffer. for f, s in ring_buffer: voiced_frames.append(f) ring_buffer.clear() else: # We&#39;re in the TRIGGERED state, so collect the audio data # and add it to the ring buffer. voiced_frames.append(frame) ring_buffer.append((frame, is_speech)) num_unvoiced = len([f for f, speech in ring_buffer if not speech]) # If more than 90% of the frames in the ring buffer are # unvoiced, then enter NOTTRIGGERED and yield whatever # audio we&#39;ve collected. if num_unvoiced &gt; 0.9 * ring_buffer.maxlen: triggered = False yield (start, frame.timestamp + frame.duration) ring_buffer.clear() voiced_frames = [] # If we have any leftover voiced audio when we run out of input, # yield it. if voiced_frames: yield (start, frame.timestamp + frame.duration) def VAD_chunk(aggressiveness, path): audio, byte_audio = read_wave(path, sr) vad = webrtcvad.Vad(int(aggressiveness)) frames = frame_generator(20, byte_audio, sr) frames = list(frames) times = vad_collector(sr, 20, 200, vad, frames) speech_times = [] speech_segs = [] for i, time in enumerate(times): start = np.round(time[0],decimals=2) end = np.round(time[1],decimals=2) j = start while j + .4 &lt; end: end_j = np.round(j+.4,decimals=2) speech_times.append((j, end_j)) speech_segs.append(audio[int(j*sr):int(end_j*sr)]) j = end_j else: speech_times.append((j, end)) speech_segs.append(audio[int(j*sr):int(end*sr)]) return speech_times, speech_segs . . # Based on code from PyTorch Speaker Verification: # https://github.com/HarryVolek/PyTorch_Speaker_Verification # Copyright (c) 2019, HarryVolek # Additions Copyright (c) 2021, Jim O&#39;Regan # License: MIT import numpy as np # wav2vec2&#39;s max duration is 40 seconds, using 39 by default # to be a little safer def vad_concat(times, segs, max_duration=39.0): &quot;&quot;&quot; Concatenate continuous times and their segments, where the end time of a segment is the same as the start time of the next Parameters: times: list of tuple (start, end) segs: list of segments (audio frames) max_duration: maximum duration of the resulting concatenated segments; the kernel size of wav2vec2 is 40 seconds, so the default max_duration is 39, to ensure the resulting list of segments will fit Returns: concat_times: list of tuple (start, end) concat_segs: list of segments (audio frames) &quot;&quot;&quot; absolute_maximum=40.0 if max_duration &gt; absolute_maximum: raise Exception(&#39;`max_duration` {:.2f} larger than kernel size (40 seconds)&#39;.format(max_duration)) # we take 0.0 to mean &quot;don&#39;t concatenate&quot; do_concat = (max_duration != 0.0) concat_seg = [] concat_times = [] seg_concat = segs[0] time_concat = times[0] for i in range(0, len(times)-1): can_concat = (times[i+1][1] - time_concat[0]) &lt; max_duration if time_concat[1] == times[i+1][0] and do_concat and can_concat: seg_concat = np.concatenate((seg_concat, segs[i+1])) time_concat = (time_concat[0], times[i+1][1]) else: concat_seg.append(seg_concat) seg_concat = segs[i+1] concat_times.append(time_concat) time_concat = times[i+1] else: concat_seg.append(seg_concat) concat_times.append(time_concat) return concat_times, concat_seg . . def make_dataset(concat_times, concat_segs): starts = [s[0] for s in concat_times] ends = [s[1] for s in concat_times] return {&#39;start&#39;: starts, &#39;end&#39;: ends, &#39;speech&#39;: concat_segs} . %%capture !pip install datasets . from datasets import Dataset def vad_to_dataset(path, max_duration): t,s = VAD_chunk(3, path) if max_duration &gt; 0.0: ct, cs = vad_concat(t, s, max_duration) dset = make_dataset(ct, cs) else: dset = make_dataset(t, s) return Dataset.from_dict(dset) . %%capture !pip install -q transformers . %%capture from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC # load model and tokenizer processor = Wav2Vec2Processor.from_pretrained(&quot;mbien/wav2vec2-large-xlsr-polish&quot;) model = Wav2Vec2ForCTC.from_pretrained(&quot;mbien/wav2vec2-large-xlsr-polish&quot;) model.to(&quot;cuda&quot;) . def speech_file_to_array_fn(batch): import torchaudio speech_array, sampling_rate = torchaudio.load(batch[&quot;path&quot;]) batch[&quot;speech&quot;] = speech_array[0].numpy() batch[&quot;sampling_rate&quot;] = sampling_rate batch[&quot;target_text&quot;] = batch[&quot;sentence&quot;] return batch def evaluate(batch): import torch inputs = processor(batch[&quot;speech&quot;], sampling_rate=16_000, return_tensors=&quot;pt&quot;, padding=True) with torch.no_grad(): logits = model(inputs.input_values.to(&quot;cuda&quot;), attention_mask=inputs.attention_mask.to(&quot;cuda&quot;)).logits pred_ids = torch.argmax(logits, dim=-1) batch[&quot;pred_strings&quot;] = processor.batch_decode(pred_ids) return batch . import json def process_wave(filename, duration): import json dataset = vad_to_dataset(filename, duration) result = dataset.map(evaluate, batched=True, batch_size=16) speechless = result.remove_columns([&#39;speech&#39;]) d=speechless.to_dict() tlog = list() for i in range(0, len(d[&#39;end&#39;]) - 1): out = dict() out[&#39;start&#39;] = d[&#39;start&#39;][i] out[&#39;end&#39;] = d[&#39;end&#39;][i] out[&#39;transcript&#39;] = d[&#39;pred_strings&#39;][i] tlog.append(out) with open(&#39;{}.tlog&#39;.format(filename), &#39;w&#39;) as outfile: json.dump(tlog, outfile) . import glob for f in glob.glob(&#39;./*.wav&#39;): print(f) process_wave(f, 10.0) . !ls *tlog|zip tlogs-csb.zip -@ .",
            "url": "https://jimregan.github.io/notes/wav2vec2/kashubian/2021/03/28/wav2vec2-polish-with-kashubian.html",
            "relUrl": "/wav2vec2/kashubian/2021/03/28/wav2vec2-polish-with-kashubian.html",
            "date": " • Mar 28, 2021"
        }
        
    
  
    
        ,"post17": {
            "title": "Using a wav2vec2 model with DSAlign",
            "content": "%%capture !pip install librosa webrtcvad . . The VAD wrapper is taken from PyTorch Speaker Verification, which is in turn is based on py-webrtcvad. . # VAD wrapper is taken from PyTorch Speaker Verification: # https://github.com/HarryVolek/PyTorch_Speaker_Verification # Copyright (c) 2019, HarryVolek # License: BSD-3-Clause # based on https://github.com/wiseman/py-webrtcvad/blob/master/example.py # Copyright (c) 2016 John Wiseman # License: MIT import collections import contextlib import numpy as np import sys import librosa import wave import webrtcvad #from hparam import hparam as hp sr = 16000 def read_wave(path, sr): &quot;&quot;&quot;Reads a .wav file. Takes the path, and returns (PCM audio data, sample rate). Assumes sample width == 2 &quot;&quot;&quot; with contextlib.closing(wave.open(path, &#39;rb&#39;)) as wf: num_channels = wf.getnchannels() assert num_channels == 1 sample_width = wf.getsampwidth() assert sample_width == 2 sample_rate = wf.getframerate() assert sample_rate in (8000, 16000, 32000, 48000) pcm_data = wf.readframes(wf.getnframes()) data, _ = librosa.load(path, sr) assert len(data.shape) == 1 assert sr in (8000, 16000, 32000, 48000) return data, pcm_data class Frame(object): &quot;&quot;&quot;Represents a &quot;frame&quot; of audio data.&quot;&quot;&quot; def __init__(self, bytes, timestamp, duration): self.bytes = bytes self.timestamp = timestamp self.duration = duration def frame_generator(frame_duration_ms, audio, sample_rate): &quot;&quot;&quot;Generates audio frames from PCM audio data. Takes the desired frame duration in milliseconds, the PCM data, and the sample rate. Yields Frames of the requested duration. &quot;&quot;&quot; n = int(sample_rate * (frame_duration_ms / 1000.0) * 2) offset = 0 timestamp = 0.0 duration = (float(n) / sample_rate) / 2.0 while offset + n &lt; len(audio): yield Frame(audio[offset:offset + n], timestamp, duration) timestamp += duration offset += n def vad_collector(sample_rate, frame_duration_ms, padding_duration_ms, vad, frames): &quot;&quot;&quot;Filters out non-voiced audio frames. Given a webrtcvad.Vad and a source of audio frames, yields only the voiced audio. Uses a padded, sliding window algorithm over the audio frames. When more than 90% of the frames in the window are voiced (as reported by the VAD), the collector triggers and begins yielding audio frames. Then the collector waits until 90% of the frames in the window are unvoiced to detrigger. The window is padded at the front and back to provide a small amount of silence or the beginnings/endings of speech around the voiced frames. Arguments: sample_rate - The audio sample rate, in Hz. frame_duration_ms - The frame duration in milliseconds. padding_duration_ms - The amount to pad the window, in milliseconds. vad - An instance of webrtcvad.Vad. frames - a source of audio frames (sequence or generator). Returns: A generator that yields PCM audio data. &quot;&quot;&quot; num_padding_frames = int(padding_duration_ms / frame_duration_ms) # We use a deque for our sliding window/ring buffer. ring_buffer = collections.deque(maxlen=num_padding_frames) # We have two states: TRIGGERED and NOTTRIGGERED. We start in the # NOTTRIGGERED state. triggered = False voiced_frames = [] for frame in frames: is_speech = vad.is_speech(frame.bytes, sample_rate) if not triggered: ring_buffer.append((frame, is_speech)) num_voiced = len([f for f, speech in ring_buffer if speech]) # If we&#39;re NOTTRIGGERED and more than 90% of the frames in # the ring buffer are voiced frames, then enter the # TRIGGERED state. if num_voiced &gt; 0.9 * ring_buffer.maxlen: triggered = True start = ring_buffer[0][0].timestamp # We want to yield all the audio we see from now until # we are NOTTRIGGERED, but we have to start with the # audio that&#39;s already in the ring buffer. for f, s in ring_buffer: voiced_frames.append(f) ring_buffer.clear() else: # We&#39;re in the TRIGGERED state, so collect the audio data # and add it to the ring buffer. voiced_frames.append(frame) ring_buffer.append((frame, is_speech)) num_unvoiced = len([f for f, speech in ring_buffer if not speech]) # If more than 90% of the frames in the ring buffer are # unvoiced, then enter NOTTRIGGERED and yield whatever # audio we&#39;ve collected. if num_unvoiced &gt; 0.9 * ring_buffer.maxlen: triggered = False yield (start, frame.timestamp + frame.duration) ring_buffer.clear() voiced_frames = [] # If we have any leftover voiced audio when we run out of input, # yield it. if voiced_frames: yield (start, frame.timestamp + frame.duration) def VAD_chunk(aggressiveness, path): audio, byte_audio = read_wave(path, sr) vad = webrtcvad.Vad(int(aggressiveness)) frames = frame_generator(20, byte_audio, sr) frames = list(frames) times = vad_collector(sr, 20, 200, vad, frames) speech_times = [] speech_segs = [] for i, time in enumerate(times): start = np.round(time[0],decimals=2) end = np.round(time[1],decimals=2) j = start while j + .4 &lt; end: end_j = np.round(j+.4,decimals=2) speech_times.append((j, end_j)) speech_segs.append(audio[int(j*sr):int(end_j*sr)]) j = end_j else: speech_times.append((j, end)) speech_segs.append(audio[int(j*sr):int(end*sr)]) return speech_times, speech_segs . . Running . I&#39;m going to use a video from YouTube as my input, so first I need to install youtube-dl . %%capture !pip install youtube-dl . I&#39;ve selected this video because it&#39;s a speech by the President of Ireland (and so copyright-free as a matter of public record), it has subtitles (in Irish, though listed as English), and the subtitles are quite faithful to what was spoken. . %%capture !youtube-dl --all-subs -o &#39;%(id)s&#39; VRg-a0qSGa8 . The audio needs to be a 16k wav, so I&#39;m converting it with ffmpeg. . %%capture !ffmpeg -i VRg-a0qSGa8.mkv -acodec pcm_s16le -ac 1 -ar 16000 VRg-a0qSGa8.wav . Next, I&#39;m using the VAD_chunk() function to get the start and end times, and audio segements of each part of the video with speech. . times, segs = VAD_chunk(3, &#39;VRg-a0qSGa8.wav&#39;) . The wav2vec2 models generally perform badly on short input, so vad_concat() concatenates the segments, as well as the times (for DSAlign). . # Based on code from PyTorch Speaker Verification: # https://github.com/HarryVolek/PyTorch_Speaker_Verification # Copyright (c) 2019, HarryVolek # Additions Copyright (c) 2021, Jim O&#39;Regan # License: MIT import numpy as np # wav2vec2&#39;s max duration is 40 seconds, using 39 by default # to be a little safer def vad_concat(times, segs, max_duration=39.0): &quot;&quot;&quot; Concatenate continuous times and their segments, where the end time of a segment is the same as the start time of the next Parameters: times: list of tuple (start, end) segs: list of segments (audio frames) max_duration: maximum duration of the resulting concatenated segments; the kernel size of wav2vec2 is 40 seconds, so the default max_duration is 39, to ensure the resulting list of segments will fit Returns: concat_times: list of tuple (start, end) concat_segs: list of segments (audio frames) &quot;&quot;&quot; absolute_maximum=40.0 if max_duration &gt; absolute_maximum: raise Exception(&#39;`max_duration` {:.2f} larger than kernel size (40 seconds)&#39;.format(max_duration)) # we take 0.0 to mean &quot;don&#39;t concatenate&quot; do_concat = (max_duration != 0.0) concat_seg = [] concat_times = [] seg_concat = segs[0] time_concat = times[0] for i in range(0, len(times)-1): can_concat = (times[i+1][1] - time_concat[0]) &lt; max_duration if time_concat[1] == times[i+1][0] and do_concat and can_concat: seg_concat = np.concatenate((seg_concat, segs[i+1])) time_concat = (time_concat[0], times[i+1][1]) else: concat_seg.append(seg_concat) seg_concat = segs[i+1] concat_times.append(time_concat) time_concat = times[i+1] else: concat_seg.append(seg_concat) concat_times.append(time_concat) return concat_times, concat_seg . . ntimes, nsegs = vad_concat(times, segs) . Next, I&#39;m putting the data into a dict that Huggingface datasets can read: . starts = [s[0] for s in ntimes] ends = [s[1] for s in ntimes] . dset = {&#39;start&#39;: starts, &#39;end&#39;: ends, &#39;speech&#39;: nsegs} . %%capture !pip install datasets . from datasets import Dataset dataset = Dataset.from_dict(dset) . dataset . Dataset({ features: [&#39;start&#39;, &#39;end&#39;, &#39;speech&#39;], num_rows: 137 }) . Now, the data is ready to plug into my wav2vec2 model. . %%capture !pip install -q transformers . %%capture from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC # load model and tokenizer processor = Wav2Vec2Processor.from_pretrained(&quot;jimregan/wav2vec2-large-xlsr-irish-basic&quot;) model = Wav2Vec2ForCTC.from_pretrained(&quot;jimregan/wav2vec2-large-xlsr-irish-basic&quot;) model.to(&quot;cuda&quot;) . Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained. . def speech_file_to_array_fn(batch): import torchaudio speech_array, sampling_rate = torchaudio.load(batch[&quot;path&quot;]) batch[&quot;speech&quot;] = speech_array[0].numpy() batch[&quot;sampling_rate&quot;] = sampling_rate batch[&quot;target_text&quot;] = batch[&quot;sentence&quot;] return batch def evaluate(batch): import torch inputs = processor(batch[&quot;speech&quot;], sampling_rate=16_000, return_tensors=&quot;pt&quot;, padding=True) with torch.no_grad(): logits = model(inputs.input_values.to(&quot;cuda&quot;), attention_mask=inputs.attention_mask.to(&quot;cuda&quot;)).logits pred_ids = torch.argmax(logits, dim=-1) batch[&quot;pred_strings&quot;] = processor.batch_decode(pred_ids) return batch . . result = dataset.map(evaluate, batched=True, batch_size=8) . . speechless = result.remove_columns([&#39;speech&#39;]) . d=speechless.to_dict() . tlog = list() for i in range(0, len(d[&#39;end&#39;]) - 1): out = dict() out[&#39;start&#39;] = d[&#39;start&#39;][i] out[&#39;end&#39;] = d[&#39;end&#39;][i] out[&#39;transcript&#39;] = d[&#39;pred_strings&#39;][i] tlog.append(out) . import json with open(&#39;/content/VRg-a0qSGa8.tlog&#39;, &#39;w&#39;) as outfile: json.dump(tlog, outfile) . Next, I&#39;m extracting the text content from the vtt file . !pip install webvtt-py . Requirement already satisfied: webvtt-py in /usr/local/lib/python3.7/dist-packages (0.4.6) Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from webvtt-py) (0.6.2) . def get_vtt_text(filename): import webvtt out = list() for sub in webvtt.read(filename): out.append(sub.text) return &#39; &#39;.join(out) . text = get_vtt_text(&#39;/content/VRg-a0qSGa8.en.vtt&#39;) . I can do some normalisation now: . text = text.replace(&#39;1901&#39;, &#39;naoi déag is a haon&#39;) text = text.replace(&#39;2021&#39;, &#39;fiche is fiche is a haon&#39;) text = text.replace(&#39;Covid-19&#39;, &#39;covid a naoi déag&#39;) text = text.replace(&#39;fiche fiche haon&#39;, &#39;fiche is fiche is a haon&#39;) . I want sentences, so I&#39;m going to use mosestokenizer to split the text (there aren&#39;t any specific abbreviations in this video, so the English splitter works fine. YMMV.) . %%capture !pip install mosestokenizer . The actual moses tokeniser has sentence splitting support for Irish, but the Python version was forked before that; we don&#39;t actually need any specific support for Irish here, so we can just use English. . from mosestokenizer import MosesSentenceSplitter with MosesSentenceSplitter(&#39;en&#39;) as splitsents: sents = splitsents([text]) . with open(&#39;/content/VRg-a0qSGa8.txt&#39;, &#39;w&#39;) as outfile: outfile.writelines([&#39; n&#39;.join(sents)]) . DSAlign requires an alphabet (1 character per line), so create that first . alpha=&quot;aábcdeéfghiíjklmnoópqrstuúvwxyz&#39;-&quot; alpha_chars = [char for char in alpha] . with open(&#39;/content/ga.alphabet&#39;, &#39;w&#39;) as outfile: outfile.writelines([&#39; n&#39;.join(alpha_chars)]) . Now, to install DSAlign and its dependencies: . %%capture !git clone https://github.com/mozilla/DSAlign . %%capture !apt-get install sox . %%capture import os os.chdir(&#39;DSAlign&#39;) !pip install -r requirements.txt . Now, I&#39;m ready to align: . !bin/align.sh --force --tlog /content/VRg-a0qSGa8.tlog --script /content/VRg-a0qSGa8.txt --aligned /content/VRg-a0qSGa8.aligned --text-meaningful-newlines --alphabet /content/ga.alphabet . bin/align.sh: line 3: /content/DSAlign/venv/bin/activate: No such file or directory INFO:root:Aligning 1 of 1 : 100.00% (elapsed: 00:00:04, speed: 0.25 it/s, ETA: 00:00:00) INFO:root:Aligned 24 fragments INFO:root:Dropped 112 fragments 466.67%: . 24 out of 136 fragments isn&#39;t great, but it&#39;s quite good considering the WER of the model (43.7%); the next step would be to add the aligned data to the training set, retrain, and repeat. .",
            "url": "https://jimregan.github.io/notes/wav2vec2/dsalign/2021/03/27/using-a-wav2vec2-model-with-dsalign.html",
            "relUrl": "/wav2vec2/dsalign/2021/03/27/using-a-wav2vec2-model-with-dsalign.html",
            "date": " • Mar 27, 2021"
        }
        
    
  
    
        ,"post18": {
            "title": "Training spaCy on IDT",
            "content": "!git clone https://github.com/UniversalDependencies/UD_Irish-IDT . Cloning into &#39;UD_Irish-IDT&#39;... remote: Enumerating objects: 32, done. remote: Counting objects: 100% (32/32), done. remote: Compressing objects: 100% (23/23), done. remote: Total 328 (delta 14), reused 25 (delta 9), pack-reused 296 Receiving objects: 100% (328/328), 3.63 MiB | 12.73 MiB/s, done. Resolving deltas: 100% (182/182), done. . !mkdir idt-json . !python -m spacy convert /content/UD_Irish-IDT/ga_idt-ud-train.conllu /content/idt-json . ✔ Generated output file (2019 documents): /content/idt-json/ga_idt-ud-train.json . !python -m spacy convert /content/UD_Irish-IDT/ga_idt-ud-dev.conllu /content/idt-json . ✔ Generated output file (451 documents): /content/idt-json/ga_idt-ud-dev.json . !wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ga.300.vec.gz !python -m spacy init-model ga /content/ga_vectors_cc --vectors-loc cc.ga.300.vec.gz . --2020-09-14 17:16:11-- https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ga.300.vec.gz Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.75.142, 104.22.74.142, ... Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 184422000 (176M) [binary/octet-stream] Saving to: ‘cc.ga.300.vec.gz’ cc.ga.300.vec.gz 100%[===================&gt;] 175.88M 44.2MB/s in 4.0s 2020-09-14 17:16:16 (43.8 MB/s) - ‘cc.ga.300.vec.gz’ saved [184422000/184422000] ✔ Successfully created model 316836it [00:27, 11398.56it/s] ✔ Loaded vectors from cc.ga.300.vec.gz ✔ Sucessfully compiled vocab 317041 entries, 316836 vectors . WikiANN is currently only available through Google Drive . from google.colab import drive drive.mount(&#39;/gdrive&#39;) . Mounted at /gdrive . !cp /gdrive/My Drive/ga.tar.gz . . !tar zxvf ga.tar.gz . README.txt wikiann-ga.bio . !wget http://downloads.dbpedia.org/links/resources/wikidatadump/2017-07-07/enwiki/20170701/enwiki-20170701-interlanguage-links_wikidataorg.ttl . --2020-09-14 17:15:11-- http://downloads.dbpedia.org/links/resources/wikidatadump/2017-07-07/enwiki/20170701/enwiki-20170701-interlanguage-links_wikidataorg.ttl Resolving downloads.dbpedia.org (downloads.dbpedia.org)... 139.18.16.66 Connecting to downloads.dbpedia.org (downloads.dbpedia.org)|139.18.16.66|:80... connected. HTTP request sent, awaiting response... 200 OK Length: 1020894244 (974M) [text/turtle] Saving to: ‘enwiki-20170701-interlanguage-links_wikidataorg.ttl’ enwiki-20170701-int 100%[===================&gt;] 973.60M 18.7MB/s in 54s 2020-09-14 17:16:05 (18.1 MB/s) - ‘enwiki-20170701-interlanguage-links_wikidataorg.ttl’ saved [1020894244/1020894244] . !cat wikiann-ga.bio | awk &#39;(NF == 7){print $6}&#39;|sort|uniq|while read i;do grep &quot;/$i&gt;&quot; enwiki-20170701-interlanguage-links_wikidataorg.ttl &gt;&gt; filtered;done . !pip install danlp . Collecting danlp Downloading https://files.pythonhosted.org/packages/3c/79/96d0d3f3634ce75787d408383fa81cdd854552e27e4e279a985b511a6d88/danlp-0.0.9-py3-none-any.whl Collecting pyconll Downloading https://files.pythonhosted.org/packages/2c/6e/c325d0db05ac1b8d45645de903e4ba691d419e861c915c3d4ebfcaf8ac25/pyconll-2.2.1-py3-none-any.whl Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from danlp) (4.41.1) Requirement already satisfied: tweepy in /usr/local/lib/python3.6/dist-packages (from danlp) (3.6.0) Requirement already satisfied: requests&gt;=2.21 in /usr/local/lib/python3.6/dist-packages (from pyconll-&gt;danlp) (2.23.0) Requirement already satisfied: six&gt;=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy-&gt;danlp) (1.15.0) Requirement already satisfied: PySocks&gt;=1.5.7 in /usr/local/lib/python3.6/dist-packages (from tweepy-&gt;danlp) (1.7.1) Requirement already satisfied: requests-oauthlib&gt;=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy-&gt;danlp) (1.3.0) Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests&gt;=2.21-&gt;pyconll-&gt;danlp) (2020.6.20) Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.6/dist-packages (from requests&gt;=2.21-&gt;pyconll-&gt;danlp) (2.10) Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests&gt;=2.21-&gt;pyconll-&gt;danlp) (1.24.3) Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests&gt;=2.21-&gt;pyconll-&gt;danlp) (3.0.4) Requirement already satisfied: oauthlib&gt;=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib&gt;=0.7.0-&gt;tweepy-&gt;danlp) (3.1.0) Installing collected packages: pyconll, danlp Successfully installed danlp-0.0.9 pyconll-2.2.1 . import danlp.datasets.wiki_ann wa = danlp.datasets.wiki_ann._convert_wikiann_to_iob(&#39;wikiann-ga.bio&#39;, &#39;wikiann-ga.ner&#39;) . !head out . Colm _ _ B-PER Ó _ _ I-PER Ruairc _ _ I-PER Seosamh _ _ B-PER Ó _ _ I-PER Cainín _ _ I-PER Dónal _ _ B-PER Ó _ _ I-PER . !python -m spacy convert -n 10 wikiann-ga.ner /content/idt-json/ . ℹ Auto-detected token-per-line NER format ℹ Grouping every 10 sentences into a document. ✔ Generated output file (757 documents): /content/idt-json/wikiann-ga.json . !rm -rf models !mkdir models !python -m spacy train -v /content/ga_vectors_cc -p &#39;tagger,parser,ner&#39; ga models idt-json/ga_idt-ud-train.json idt-json/ga_idt-ud-dev.json . Training pipeline: [&#39;tagger&#39;, &#39;parser&#39;] Starting with blank model &#39;ga&#39; Loading vector from model &#39;/content/ga_vectors_cc&#39; Counting training words (limit=0) /usr/lib/python3.6/runpy.py:193: UserWarning: [W022] Training a new part-of-speech tagger using a model with no lemmatization rules or data. This means that the trained model may not be able to lemmatize correctly. If this is intentional or the language you&#39;re using doesn&#39;t have lemmatization data, you can ignore this warning by setting SPACY_WARNING_IGNORE=W022. If this is surprising, make sure you have the spacy-lookups-data package installed. &#34;__main__&#34;, mod_spec) Itn Tag Loss Tag % Dep Loss UAS LAS Token % CPU WPS -- - - 1 14058.829 90.650 43482.222 74.804 56.787 100.000 11293 2 6188.294 92.810 34097.493 79.836 66.009 100.000 11461 3 4475.949 93.400 30061.441 81.314 69.572 100.000 11930 4 3549.242 93.530 27752.841 82.784 71.759 100.000 11719 5 2916.639 93.570 25861.771 83.066 72.401 100.000 11616 6 2438.355 93.550 24533.545 83.133 72.726 100.000 12227 7 2084.913 93.500 22901.218 83.281 73.043 100.000 11842 8 1845.607 93.610 21836.129 83.516 73.346 100.000 12094 9 1698.212 93.630 20626.109 83.555 73.507 100.000 11907 10 1406.626 93.570 19251.761 83.712 73.978 100.000 11926 11 1366.677 93.620 18882.570 83.896 74.128 100.000 12023 12 1209.500 93.610 17836.598 83.968 74.177 100.000 11924 13 1140.886 93.640 17341.624 84.098 74.375 100.000 11522 14 1043.542 93.670 16748.375 83.992 74.292 100.000 11766 15 926.876 93.700 15727.938 84.183 74.572 100.000 11931 16 848.805 93.680 15002.112 84.059 74.427 100.000 11750 17 857.415 93.760 14686.168 84.075 74.465 100.000 11724 18 775.277 93.750 14028.872 84.091 74.603 100.000 11890 19 651.078 93.680 13698.526 84.215 74.794 100.000 11932 20 672.552 93.670 13036.999 84.356 74.879 100.000 11724 21 590.244 93.670 12162.862 84.468 75.048 100.000 11851 22 593.722 93.680 12494.905 84.441 75.122 100.000 11910 23 582.541 93.660 12110.757 84.351 75.032 100.000 11544 24 514.448 93.690 11635.750 84.232 74.879 100.000 11984 25 491.457 93.640 10942.966 84.226 74.816 100.000 12106 26 521.324 93.660 10958.952 84.232 74.779 100.000 12112 27 507.717 93.650 10907.860 84.255 74.790 100.000 11754 28 485.186 93.660 10149.477 84.143 74.666 100.000 11411 29 507.038 93.720 10331.116 84.165 74.644 100.000 11740 30 477.966 93.700 9649.121 84.300 74.891 100.000 11300 ✔ Saved model to output directory models/model-final ✔ Created best model models/model-best . !mkdir modelout !python -m spacy package --meta meta.json /content/models/model-best modelout . ✔ Loaded meta.json from file meta.json ✔ Successfully created package &#39;ga_idt_lg-1.0.0&#39; modelout/ga_idt_lg-1.0.0 To build the package, run `python setup.py sdist` in this directory. . import os os.chdir(&#39;/content/modelout/ga_idt_lg-1.0.0&#39;) !python setup.py sdist . running sdist running egg_info creating ga_idt_lg.egg-info writing ga_idt_lg.egg-info/PKG-INFO writing dependency_links to ga_idt_lg.egg-info/dependency_links.txt writing requirements to ga_idt_lg.egg-info/requires.txt writing top-level names to ga_idt_lg.egg-info/top_level.txt writing manifest file &#39;ga_idt_lg.egg-info/SOURCES.txt&#39; reading manifest file &#39;ga_idt_lg.egg-info/SOURCES.txt&#39; reading manifest template &#39;MANIFEST.in&#39; writing manifest file &#39;ga_idt_lg.egg-info/SOURCES.txt&#39; warning: sdist: standard file not found: should have one of README, README.rst, README.txt, README.md running check creating ga_idt_lg-1.0.0 creating ga_idt_lg-1.0.0/ga_idt_lg creating ga_idt_lg-1.0.0/ga_idt_lg.egg-info creating ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0 creating ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/parser creating ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/tagger creating ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/vocab copying files to ga_idt_lg-1.0.0... copying MANIFEST.in -&gt; ga_idt_lg-1.0.0 copying meta.json -&gt; ga_idt_lg-1.0.0 copying setup.py -&gt; ga_idt_lg-1.0.0 copying ga_idt_lg/__init__.py -&gt; ga_idt_lg-1.0.0/ga_idt_lg copying ga_idt_lg/meta.json -&gt; ga_idt_lg-1.0.0/ga_idt_lg copying ga_idt_lg.egg-info/PKG-INFO -&gt; ga_idt_lg-1.0.0/ga_idt_lg.egg-info copying ga_idt_lg.egg-info/SOURCES.txt -&gt; ga_idt_lg-1.0.0/ga_idt_lg.egg-info copying ga_idt_lg.egg-info/dependency_links.txt -&gt; ga_idt_lg-1.0.0/ga_idt_lg.egg-info copying ga_idt_lg.egg-info/not-zip-safe -&gt; ga_idt_lg-1.0.0/ga_idt_lg.egg-info copying ga_idt_lg.egg-info/requires.txt -&gt; ga_idt_lg-1.0.0/ga_idt_lg.egg-info copying ga_idt_lg.egg-info/top_level.txt -&gt; ga_idt_lg-1.0.0/ga_idt_lg.egg-info copying ga_idt_lg/ga_idt_lg-1.0.0/meta.json -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0 copying ga_idt_lg/ga_idt_lg-1.0.0/tokenizer -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0 copying ga_idt_lg/ga_idt_lg-1.0.0/parser/cfg -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/parser copying ga_idt_lg/ga_idt_lg-1.0.0/parser/model -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/parser copying ga_idt_lg/ga_idt_lg-1.0.0/parser/moves -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/parser copying ga_idt_lg/ga_idt_lg-1.0.0/tagger/cfg -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/tagger copying ga_idt_lg/ga_idt_lg-1.0.0/tagger/model -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/tagger copying ga_idt_lg/ga_idt_lg-1.0.0/tagger/tag_map -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/tagger copying ga_idt_lg/ga_idt_lg-1.0.0/vocab/key2row -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/vocab copying ga_idt_lg/ga_idt_lg-1.0.0/vocab/lexemes.bin -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/vocab copying ga_idt_lg/ga_idt_lg-1.0.0/vocab/strings.json -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/vocab copying ga_idt_lg/ga_idt_lg-1.0.0/vocab/vectors -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/vocab Writing ga_idt_lg-1.0.0/setup.cfg creating dist Creating tar archive removing &#39;ga_idt_lg-1.0.0&#39; (and everything under it) . !cat /content/models/model-best/meta.json . { &#34;lang&#34;:&#34;ga&#34;, &#34;name&#34;:&#34;model&#34;, &#34;version&#34;:&#34;0.0.0&#34;, &#34;spacy_version&#34;:&#34;&gt;=2.2.4&#34;, &#34;description&#34;:&#34;&#34;, &#34;author&#34;:&#34;&#34;, &#34;email&#34;:&#34;&#34;, &#34;url&#34;:&#34;&#34;, &#34;license&#34;:&#34;&#34;, &#34;vectors&#34;:{ &#34;width&#34;:300, &#34;vectors&#34;:316836, &#34;keys&#34;:316836, &#34;name&#34;:&#34;ga_model.vectors&#34; }, &#34;pipeline&#34;:[ &#34;tagger&#34;, &#34;parser&#34; ], &#34;factories&#34;:{ &#34;tagger&#34;:&#34;tagger&#34;, &#34;parser&#34;:&#34;parser&#34; }, &#34;labels&#34;:{ &#34;tagger&#34;:[ &#34;!&#34;, &#34;.&#34;, &#34;...&#34;, &#34;?&#34;, &#34;Abr&#34;, &#34;Ad&#34;, &#34;Adj&#34;, &#34;Art&#34;, &#34;CM&#34;, &#34;CU&#34;, &#34;Cmp&#34;, &#34;Cmpd&#34;, &#34;CmpdNoGen&#34;, &#34;Comp&#34;, &#34;Cond&#34;, &#34;Coord&#34;, &#34;Cop&#34;, &#34;Cp&#34;, &#34;Deg&#34;, &#34;Dem&#34;, &#34;Det&#34;, &#34;Dir&#34;, &#34;Foreign&#34;, &#34;FutInd&#34;, &#34;Gn&#34;, &#34;Idf&#34;, &#34;Imper&#34;, &#34;Inf&#34;, &#34;Item&#34;, &#34;Itj&#34;, &#34;Its&#34;, &#34;Loc&#34;, &#34;Nm&#34;, &#34;Noun&#34;, &#34;Num&#34;, &#34;PastImp&#34;, &#34;PastInd&#34;, &#34;Pat&#34;, &#34;Pers&#34;, &#34;Poss&#34;, &#34;Prep&#34;, &#34;PresImp&#34;, &#34;PresInd&#34;, &#34;PresSubj&#34;, &#34;Pron&#34;, &#34;Punct&#34;, &#34;Q&#34;, &#34;Ref&#34;, &#34;Rel&#34;, &#34;Simp&#34;, &#34;Subord&#34;, &#34;Subst&#34;, &#34;Sup&#34;, &#34;Temp&#34;, &#34;Unknown&#34;, &#34;VD&#34;, &#34;VI&#34;, &#34;VT&#34;, &#34;VTI&#34;, &#34;Vb&#34;, &#34;Voc&#34;, &#34;Web&#34;, &#34;_SP&#34;, &#34;cionn&#34; ], &#34;parser&#34;:[ &#34;ROOT&#34;, &#34;acl:relcl&#34;, &#34;advcl&#34;, &#34;advmod&#34;, &#34;amod&#34;, &#34;appos&#34;, &#34;case&#34;, &#34;cc&#34;, &#34;ccomp&#34;, &#34;compound&#34;, &#34;conj&#34;, &#34;cop&#34;, &#34;csubj:cleft&#34;, &#34;csubj:cop&#34;, &#34;dep&#34;, &#34;det&#34;, &#34;fixed&#34;, &#34;flat&#34;, &#34;flat:name&#34;, &#34;mark&#34;, &#34;mark:prt&#34;, &#34;nmod&#34;, &#34;nmod:poss&#34;, &#34;nsubj&#34;, &#34;nummod&#34;, &#34;obj&#34;, &#34;obl&#34;, &#34;obl:prep&#34;, &#34;obl:tmod&#34;, &#34;parataxis&#34;, &#34;punct&#34;, &#34;xcomp&#34;, &#34;xcomp:pred&#34; ] }, &#34;accuracy&#34;:{ &#34;tags_acc&#34;:92.23, &#34;token_acc&#34;:100.0, &#34;las&#34;:68.3640850205, &#34;uas&#34;:80.5899837362, &#34;las_per_type&#34;:{ &#34;nummod&#34;:{ &#34;p&#34;:70.0, &#34;r&#34;:61.5384615385, &#34;f&#34;:65.4970760234 }, &#34;root&#34;:{ &#34;p&#34;:88.0266075388, &#34;r&#34;:88.0266075388, &#34;f&#34;:88.0266075388 }, &#34;case&#34;:{ &#34;p&#34;:88.8535031847, &#34;r&#34;:91.7763157895, &#34;f&#34;:90.2912621359 }, &#34;obl&#34;:{ &#34;p&#34;:47.0031545741, &#34;r&#34;:54.9815498155, &#34;f&#34;:50.6802721088 }, &#34;mark:prt&#34;:{ &#34;p&#34;:71.1538461538, &#34;r&#34;:81.9620253165, &#34;f&#34;:76.1764705882 }, &#34;ccomp&#34;:{ &#34;p&#34;:40.2777777778, &#34;r&#34;:47.5409836066, &#34;f&#34;:43.6090225564 }, &#34;nsubj&#34;:{ &#34;p&#34;:75.1824817518, &#34;r&#34;:79.7213622291, &#34;f&#34;:77.3854244929 }, &#34;obj&#34;:{ &#34;p&#34;:55.5555555556, &#34;r&#34;:49.2957746479, &#34;f&#34;:52.2388059701 }, &#34;nmod&#34;:{ &#34;p&#34;:52.912142152, &#34;r&#34;:54.8618219038, &#34;f&#34;:53.8693467337 }, &#34;mark&#34;:{ &#34;p&#34;:82.7715355805, &#34;r&#34;:72.6973684211, &#34;f&#34;:77.408056042 }, &#34;xcomp&#34;:{ &#34;p&#34;:60.4743083004, &#34;r&#34;:65.3846153846, &#34;f&#34;:62.8336755647 }, &#34;acl:relcl&#34;:{ &#34;p&#34;:47.2602739726, &#34;r&#34;:53.488372093, &#34;f&#34;:50.1818181818 }, &#34;xcomp:pred&#34;:{ &#34;p&#34;:44.0476190476, &#34;r&#34;:59.6774193548, &#34;f&#34;:50.6849315068 }, &#34;amod&#34;:{ &#34;p&#34;:57.5438596491, &#34;r&#34;:54.3046357616, &#34;f&#34;:55.8773424191 }, &#34;det&#34;:{ &#34;p&#34;:92.8480204342, &#34;r&#34;:94.0491591203, &#34;f&#34;:93.4447300771 }, &#34;csubj:cleft&#34;:{ &#34;p&#34;:47.2222222222, &#34;r&#34;:27.4193548387, &#34;f&#34;:34.693877551 }, &#34;obl:prep&#34;:{ &#34;p&#34;:77.6041666667, &#34;r&#34;:65.6387665198, &#34;f&#34;:71.1217183771 }, &#34;advcl&#34;:{ &#34;p&#34;:54.4, &#34;r&#34;:49.2753623188, &#34;f&#34;:51.711026616 }, &#34;parataxis&#34;:{ &#34;p&#34;:42.4242424242, &#34;r&#34;:27.4509803922, &#34;f&#34;:33.3333333333 }, &#34;nmod:poss&#34;:{ &#34;p&#34;:73.4939759036, &#34;r&#34;:75.3086419753, &#34;f&#34;:74.3902439024 }, &#34;cc&#34;:{ &#34;p&#34;:78.9473684211, &#34;r&#34;:79.5454545455, &#34;f&#34;:79.2452830189 }, &#34;conj&#34;:{ &#34;p&#34;:42.7609427609, &#34;r&#34;:42.0529801325, &#34;f&#34;:42.4040066778 }, &#34;dep&#34;:{ &#34;p&#34;:0.0, &#34;r&#34;:0.0, &#34;f&#34;:0.0 }, &#34;compound&#34;:{ &#34;p&#34;:75.0, &#34;r&#34;:26.0869565217, &#34;f&#34;:38.7096774194 }, &#34;flat&#34;:{ &#34;p&#34;:64.1025641026, &#34;r&#34;:64.9350649351, &#34;f&#34;:64.5161290323 }, &#34;cop&#34;:{ &#34;p&#34;:69.3251533742, &#34;r&#34;:70.625, &#34;f&#34;:69.9690402477 }, &#34;flat:name&#34;:{ &#34;p&#34;:63.4782608696, &#34;r&#34;:51.4084507042, &#34;f&#34;:56.8093385214 }, &#34;obl:tmod&#34;:{ &#34;p&#34;:66.6666666667, &#34;r&#34;:2.7397260274, &#34;f&#34;:5.2631578947 }, &#34;advmod&#34;:{ &#34;p&#34;:66.2745098039, &#34;r&#34;:65.0, &#34;f&#34;:65.6310679612 }, &#34;appos&#34;:{ &#34;p&#34;:21.9512195122, &#34;r&#34;:20.9302325581, &#34;f&#34;:21.4285714286 }, &#34;flat:foreign&#34;:{ &#34;p&#34;:0.0, &#34;r&#34;:0.0, &#34;f&#34;:0.0 }, &#34;fixed&#34;:{ &#34;p&#34;:74.7663551402, &#34;r&#34;:61.0687022901, &#34;f&#34;:67.2268907563 }, &#34;csubj:cop&#34;:{ &#34;p&#34;:62.5, &#34;r&#34;:55.5555555556, &#34;f&#34;:58.8235294118 }, &#34;discourse&#34;:{ &#34;p&#34;:0.0, &#34;r&#34;:0.0, &#34;f&#34;:0.0 }, &#34;case:voc&#34;:{ &#34;p&#34;:0.0, &#34;r&#34;:0.0, &#34;f&#34;:0.0 }, &#34;vocative&#34;:{ &#34;p&#34;:0.0, &#34;r&#34;:0.0, &#34;f&#34;:0.0 } } }, &#34;speed&#34;:{ &#34;cpu&#34;:13038.7132631094, &#34;gpu&#34;:null, &#34;nwords&#34;:10000 } } . import os os.chdir(&#39;/content&#39;) !rm -rf modelout !mkdir modelout !rm meta.json . !cat meta.json . { &#34;name&#34;: &#34;ga_idt_sm&#34;, &#34;lang&#34;: &#34;ga&#34;, &#34;version&#34;: &#34;1.0.0&#34;, &#34;spacy_version&#34;: &#34;&gt;=2.0.0,&lt;3.0.0&#34;, &#34;description&#34;: &#34;Irish model for spaCy trained on IDT&#34;, &#34;author&#34;: &#34;Jim O&#39;Regan&#34;, &#34;email&#34;: &#34;jaoregan@tcd.ie&#34;, &#34;license&#34;: &#34;CC BY-SA 3.0&#34;, &#34;pipeline&#34;: [&#34;tagger&#34;, &#34;parser&#34;, &#34;ner&#34;] } .",
            "url": "https://jimregan.github.io/notes/spacy/idt/2020/09/14/train-spacy-idt.html",
            "relUrl": "/spacy/idt/2020/09/14/train-spacy-idt.html",
            "date": " • Sep 14, 2020"
        }
        
    
  
    
        ,"post19": {
            "title": "Javascript hoops",
            "content": "!git clone https://github.com/jimregan/coco-ssd-ga . Cloning into &#39;coco-ssd-ga&#39;... remote: Enumerating objects: 55, done. remote: Counting objects: 100% (55/55), done. remote: Compressing objects: 100% (38/38), done. remote: Total 55 (delta 17), reused 48 (delta 14), pack-reused 0 Unpacking objects: 100% (55/55), done. . import os os.chdir(&#39;coco-ssd-ga&#39;) . !npm install -g yarn rimraf browserify typescript ts-node @tensorflow/tfjs-core @tensorflow/tfjs-converter . &gt; yarn@1.22.10 preinstall /tools/node/lib/node_modules/yarn &gt; :; (node ./preinstall.js &gt; /dev/null 2&gt;&amp;1 || true) /tools/node/bin/browserify -&gt; /tools/node/lib/node_modules/browserify/bin/cmd.js /tools/node/bin/rimraf -&gt; /tools/node/lib/node_modules/rimraf/bin.js /tools/node/bin/ts-node -&gt; /tools/node/lib/node_modules/ts-node/dist/bin.js /tools/node/bin/ts-script -&gt; /tools/node/lib/node_modules/ts-node/dist/bin-script-deprecated.js /tools/node/bin/ts-node-script -&gt; /tools/node/lib/node_modules/ts-node/dist/bin-script.js /tools/node/bin/ts-node-transpile-only -&gt; /tools/node/lib/node_modules/ts-node/dist/bin-transpile.js /tools/node/bin/tsc -&gt; /tools/node/lib/node_modules/typescript/bin/tsc /tools/node/bin/tsserver -&gt; /tools/node/lib/node_modules/typescript/bin/tsserver /tools/node/bin/yarn -&gt; /tools/node/lib/node_modules/yarn/bin/yarn.js /tools/node/bin/yarnpkg -&gt; /tools/node/lib/node_modules/yarn/bin/yarn.js + rimraf@3.0.2 + yarn@1.22.10 + browserify@17.0.0 + ts-node@9.1.1 + @tensorflow/tfjs-converter@3.5.0 + @tensorflow/tfjs-core@3.5.0 + typescript@4.2.4 added 203 packages from 137 contributors in 12.754s . !npm install . npm WARN deprecated fsevents@2.1.3: &#34;Please update to latest v2.3 or v2.2&#34; npm WARN deprecated core-js@2.6.12: core-js@&lt;3 is no longer maintained and not recommended for usage due to the number of issues. Please, upgrade your dependencies to the actual version of core-js@3. &gt; core-js@2.6.12 postinstall /content/coco-ssd-ga/node_modules/core-js &gt; node -e &#34;try{require(&#39;./postinstall&#39;)}catch(e){}&#34; Thank you for using core-js ( https://github.com/zloirock/core-js ) for polyfilling JavaScript standard library! The project needs your help! Please consider supporting of core-js on Open Collective or Patreon: &gt; https://opencollective.com/core-js &gt; https://www.patreon.com/zloirock Also, the author of core-js ( https://github.com/zloirock ) is looking for a good job -) npm notice created a lockfile as package-lock.json. You should commit this file. npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@~2.1.2 (node_modules/rollup/node_modules/fsevents): npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@2.1.3: wanted {&#34;os&#34;:&#34;darwin&#34;,&#34;arch&#34;:&#34;any&#34;} (current: {&#34;os&#34;:&#34;linux&#34;,&#34;arch&#34;:&#34;x64&#34;}) npm WARN @rollup/plugin-typescript@3.1.1 requires a peer of rollup@^1.20.0 but none is installed. You must install peer dependencies yourself. added 196 packages from 157 contributors and audited 197 packages in 10.534s 10 packages are looking for funding run `npm fund` for details found 0 vulnerabilities ╭────────────────────────────────────────────────────────────────╮ │ │ │ New major version of npm available! 6.14.8 → 7.11.1 │ │ Changelog: https://github.com/npm/cli/releases/tag/v7.11.1 │ │ Run npm install -g npm to update! │ │ │ ╰────────────────────────────────────────────────────────────────╯ . !yarn build . yarn run v1.22.10 $ rimraf dist &amp;&amp; tsc Done in 6.76s. . !npm install yalc . npm WARN @rollup/plugin-typescript@3.1.1 requires a peer of rollup@^1.20.0 but none is installed. You must install peer dependencies yourself. npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@2.1.3 (node_modules/fsevents): npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@2.1.3: wanted {&#34;os&#34;:&#34;darwin&#34;,&#34;arch&#34;:&#34;any&#34;} (current: {&#34;os&#34;:&#34;linux&#34;,&#34;arch&#34;:&#34;x64&#34;}) + yalc@1.0.0-pre.51 updated 1 package and audited 197 packages in 2.25s 8 packages are looking for funding run `npm fund` for details found 0 vulnerabilities . !npm install -g cross-env . /tools/node/bin/cross-env -&gt; /tools/node/lib/node_modules/cross-env/src/bin/cross-env.js /tools/node/bin/cross-env-shell -&gt; /tools/node/lib/node_modules/cross-env/src/bin/cross-env-shell.js + cross-env@7.0.3 added 7 packages from 5 contributors in 0.789s . !npm install -g @tensorflow/tfjs-core @tensorflow/tfjs-converter rollup yalc !npm install --save install !yarn run publish-local . . /tools/node/bin/rollup -&gt; /tools/node/lib/node_modules/rollup/dist/bin/rollup /tools/node/bin/yalc -&gt; /tools/node/lib/node_modules/yalc/src/yalc.js npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@~2.3.1 (node_modules/rollup/node_modules/fsevents): npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@2.3.2: wanted {&#34;os&#34;:&#34;darwin&#34;,&#34;arch&#34;:&#34;any&#34;} (current: {&#34;os&#34;:&#34;linux&#34;,&#34;arch&#34;:&#34;x64&#34;}) + rollup@2.45.2 + yalc@1.0.0-pre.51 + @tensorflow/tfjs-core@3.5.0 + @tensorflow/tfjs-converter@3.5.0 updated 4 packages in 3.883s npm WARN @rollup/plugin-typescript@3.1.1 requires a peer of rollup@^1.20.0 but none is installed. You must install peer dependencies yourself. npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@2.1.3 (node_modules/fsevents): npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@2.1.3: wanted {&#34;os&#34;:&#34;darwin&#34;,&#34;arch&#34;:&#34;any&#34;} (current: {&#34;os&#34;:&#34;linux&#34;,&#34;arch&#34;:&#34;x64&#34;}) + install@0.13.0 added 1 package from 1 contributor and audited 198 packages in 1.647s 10 packages are looking for funding run `npm fund` for details found 0 vulnerabilities yarn run v1.22.10 $ yarn build &amp;&amp; rollup -c &amp;&amp; yalc push . $ rimraf dist &amp;&amp; tsc src/index.ts → dist/coco-ssd.node.js... created dist/coco-ssd.node.js in 8.9s coco-ssd-ga@2.1.0 published in store. Done in 16.51s. . !npm install -g browserify . /tools/node/bin/browserify -&gt; /tools/node/lib/node_modules/browserify/bin/cmd.js + browserify@17.0.0 updated 1 package in 4.871s . !npm i minify -g . /tools/node/bin/minify -&gt; /tools/node/lib/node_modules/minify/bin/minify.js + minify@7.0.1 added 26 packages from 52 contributors in 1.951s . !browserify /content/coco-ssd-ga/dist/coco-ssd.node.js --s cocoGa -o /content/coco-ssd-ga/dist/coco-ssd.browser.js . !minify /content/coco-ssd-ga/dist/coco-ssd.browser.js &gt; /content/coco-ssd-ga/dist/coco-ssd.min.js .",
            "url": "https://jimregan.github.io/notes/web/coco-ssd/2020/08/12/coco-ssd-ga.html",
            "relUrl": "/web/coco-ssd/2020/08/12/coco-ssd-ga.html",
            "date": " • Aug 12, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://jimregan.github.io/notes/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  

  
  

  
      ,"page11": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://jimregan.github.io/notes/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}