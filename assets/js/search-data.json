{
  
    
        "post0": {
            "title": "First attempts at alignment (take 2)",
            "content": "TEST_A = &quot;/Users/joregan/Playing/rd_ctm_edit/H5C120171011va&quot; . lines = [] with open(TEST_A) as f: for line in f.readlines(): lines.append(line.strip()) . def accept_all(lines): outlines = [] for line in lines: parts = line.split(&quot; &quot;) if parts[-1] == &quot;cor&quot;: outlines.append(line) elif parts[-1] == &quot;sub&quot;: parts[4] = parts[6] parts[-1] = &quot;cor&quot; outlines.append(&quot; &quot;.join(parts)) return outlines . accept_all(lines) . [&#39;2442205210012872721 1 27.86 0.06 Herr 1.0 Herr cor&#39;, &#39;2442205210012872721 1 28.0 0.48 talman! 1.0 talman! cor&#39;, &#39;2442205210012872721 1 28.72 0.96 Riksdagsledamöter! 1.0 Riksdagsledamöter! cor&#39;, &#39;2442205210012872721 1 30.16 0.82 Allianspartierna 1.0 Allianspartierna cor&#39;, &#39;2442205210012872721 1 31.08 0.56 Moderaterna, 1.0 Moderaterna, cor&#39;, &#39;2442205210012872721 1 32.08 0.74 Centerpartiet, 1.0 Centerpartiet, cor&#39;, &#39;2442205210012872721 1 33.02 0.579 Liberalerna 1.0 Liberalerna cor&#39;, &#39;2442205210012872721 1 33.74 0.079 och 1.0 och cor&#39;, &#39;2442205210012872721 1 33.88 0.759 Kristdemokraterna 1.0 Kristdemokraterna cor&#39;, &#39;2442205210012872721 1 34.76 0.399 föreslår 1.0 föreslår cor&#39;, &#39;2442205210012872721 1 35.22 0.079 som 1.0 som cor&#39;, &#39;2442205210012872721 1 35.36 0.579 riksdagens 1.0 riksdagens cor&#39;, &#39;2442205210012872721 1 36.02 0.239 förste 1.0 förste cor&#39;, &#39;2442205210012872721 1 36.32 0.179 vice 1.0 vice cor&#39;, &#39;2442205210012872721 1 36.58 0.34 talman 1.0 talman cor&#39;, &#39;2442205210012872721 1 37.32 0.14 Ewa 1.0 Ewa cor&#39;, &#39;2442205210012872721 1 37.56 0.28 Thalén 1.0 Thalén cor&#39;, &#39;2442205210012872721 1 38.14 0.32 Finné. 1.0 Finné. cor&#39;] . def ctm_to_timed(lines): output = [] for line in lines: parts = line.split(&quot; &quot;) start = float(parts[2]) dur = float(parts[3]) output.append({ &quot;start&quot;: start, &quot;end&quot;: start + dur, &quot;text&quot;: parts[6] }) return output . side_a = ctm_to_timed(accept_all(lines)) . phonfile = &quot;/Users/joregan/Playing/rd_phonetic/2442205210012872721_480p.json&quot; . import json with open(phonfile) as f: pieces = json.load(f) . def hf_json_to_timed(data): output = [] for chunk in data[&quot;chunks&quot;]: output.append({ &quot;start&quot;: chunk[&quot;timestamp&quot;][0], &quot;end&quot;: chunk[&quot;timestamp&quot;][1], &quot;text&quot;: chunk[&quot;text&quot;] }) return output . side_b = hf_json_to_timed(pieces) . def prune_to_other(left, right, fudge=0.5): safe = left working = right # if right[0][&quot;start&quot;] &gt; (left[0][&quot;start&quot;] - fudge) and right[-1][&quot;end&quot;] &lt; (left[-1][&quot;end&quot;] + fudge): # safe = right # working = left output = [] for item in working: if item[&quot;start&quot;] &lt; safe[0][&quot;start&quot;] - fudge: continue elif item[&quot;end&quot;] &gt; safe[-1][&quot;end&quot;] + fudge: continue else: output.append(item) return safe, output . new_a, new_b = prune_to_other(side_a, side_b) . new_b[0] . {&#39;start&#39;: 27.86, &#39;end&#39;: 27.9, &#39;text&#39;: &#39;ɑː&#39;} . new_a[0] . {&#39;start&#39;: 27.86, &#39;end&#39;: 27.919999999999998, &#39;text&#39;: &#39;Herr&#39;} . def cost(a, b): starts = abs(a[&quot;start&quot;] - b[&quot;start&quot;]) ends = abs(a[&quot;end&quot;] - b[&quot;end&quot;]) return starts + ends . def in_start_range(a, b, range=0.2): return abs(a[&quot;start&quot;] - b[&quot;start&quot;]) &lt;= range def in_end_range(a, b, range=0.2): return abs(a[&quot;end&quot;] - b[&quot;end&quot;]) &lt;= range def in_range(a, b, range=0.2): r_start = in_start_range(a, b, range) r_end = in_end_range(a, b, range) return r_start or r_end . in_range(new_a[0], new_b[-1]) . False . in_range(new_a[0], new_b[0]) . True . import numpy as np . dist_matrix = np.zeros((len(new_a) + 1, len(new_b) + 1)) . for i in range(1, len(new_a) + 1): for j in range(1, len(new_b) + 1): if not in_range(new_a[i-1], new_b[j-1]): continue pair_cost = cost(new_a[i-1], new_b[j-1]) dist_matrix[i, j] = pair_cost print(new_a[i-1], new_b[j-1], pair_cost) . {&#39;start&#39;: 27.86, &#39;end&#39;: 27.919999999999998, &#39;text&#39;: &#39;Herr&#39;} {&#39;start&#39;: 27.86, &#39;end&#39;: 27.9, &#39;text&#39;: &#39;ɑː&#39;} 0.019999999999999574 {&#39;start&#39;: 27.86, &#39;end&#39;: 27.919999999999998, &#39;text&#39;: &#39;Herr&#39;} {&#39;start&#39;: 28.0, &#39;end&#39;: 28.6, &#39;text&#39;: &#39;tɑːlman&#39;} 0.8200000000000038 {&#39;start&#39;: 28.0, &#39;end&#39;: 28.48, &#39;text&#39;: &#39;talman!&#39;} {&#39;start&#39;: 27.86, &#39;end&#39;: 27.9, &#39;text&#39;: &#39;ɑː&#39;} 0.7200000000000024 {&#39;start&#39;: 28.0, &#39;end&#39;: 28.48, &#39;text&#39;: &#39;talman!&#39;} {&#39;start&#39;: 28.0, &#39;end&#39;: 28.6, &#39;text&#39;: &#39;tɑːlman&#39;} 0.120000000000001 {&#39;start&#39;: 28.72, &#39;end&#39;: 29.68, &#39;text&#39;: &#39;Riksdagsledamöter!&#39;} {&#39;start&#39;: 28.7, &#39;end&#39;: 29.18, &#39;text&#39;: &#39;rɪksasleːda&#39;} 0.5199999999999996 {&#39;start&#39;: 28.72, &#39;end&#39;: 29.68, &#39;text&#39;: &#39;Riksdagsledamöter!&#39;} {&#39;start&#39;: 29.24, &#39;end&#39;: 29.58, &#39;text&#39;: &#39;møːtœ̞&#39;} 0.620000000000001 {&#39;start&#39;: 30.16, &#39;end&#39;: 30.98, &#39;text&#39;: &#39;Allianspartierna&#39;} {&#39;start&#39;: 30.0, &#39;end&#39;: 30.04, &#39;text&#39;: &#39;&lt;pa&gt;&#39;} 1.1000000000000014 {&#39;start&#39;: 30.16, &#39;end&#39;: 30.98, &#39;text&#39;: &#39;Allianspartierna&#39;} {&#39;start&#39;: 30.16, &#39;end&#39;: 30.26, &#39;text&#39;: &#39;al&#39;} 0.7199999999999989 {&#39;start&#39;: 30.16, &#39;end&#39;: 30.98, &#39;text&#39;: &#39;Allianspartierna&#39;} {&#39;start&#39;: 30.32, &#39;end&#39;: 30.98, &#39;text&#39;: &#39;aspatiːæɳa&#39;} 0.16000000000000014 {&#39;start&#39;: 31.08, &#39;end&#39;: 31.639999999999997, &#39;text&#39;: &#39;Moderaterna,&#39;} {&#39;start&#39;: 31.06, &#39;end&#39;: 31.64, &#39;text&#39;: &#39;mʊdɑːtœ̞ɔɳa&#39;} 0.020000000000003126 {&#39;start&#39;: 31.08, &#39;end&#39;: 31.639999999999997, &#39;text&#39;: &#39;Moderaterna,&#39;} {&#39;start&#39;: 31.78, &#39;end&#39;: 31.82, &#39;text&#39;: &#39;&lt;pa&gt;&#39;} 0.8800000000000061 {&#39;start&#39;: 32.08, &#39;end&#39;: 32.82, &#39;text&#39;: &#39;Centerpartiet,&#39;} {&#39;start&#39;: 32.06, &#39;end&#39;: 32.3, &#39;text&#39;: &#39;sentə&#39;} 0.5399999999999991 {&#39;start&#39;: 32.08, &#39;end&#39;: 32.82, &#39;text&#39;: &#39;Centerpartiet,&#39;} {&#39;start&#39;: 32.36, &#39;end&#39;: 32.86, &#39;text&#39;: &#39;patiːət&#39;} 0.3200000000000003 {&#39;start&#39;: 33.02, &#39;end&#39;: 33.599000000000004, &#39;text&#39;: &#39;Liberalerna&#39;} {&#39;start&#39;: 33.02, &#39;end&#39;: 33.62, &#39;text&#39;: &#39;lɪbɑːlɔɳa&#39;} 0.02099999999999369 {&#39;start&#39;: 33.02, &#39;end&#39;: 33.599000000000004, &#39;text&#39;: &#39;Liberalerna&#39;} {&#39;start&#39;: 33.74, &#39;end&#39;: 33.78, &#39;text&#39;: &#39;oː&#39;} 0.9009999999999962 {&#39;start&#39;: 33.74, &#39;end&#39;: 33.819, &#39;text&#39;: &#39;och&#39;} {&#39;start&#39;: 33.02, &#39;end&#39;: 33.62, &#39;text&#39;: &#39;lɪbɑːlɔɳa&#39;} 0.919000000000004 {&#39;start&#39;: 33.74, &#39;end&#39;: 33.819, &#39;text&#39;: &#39;och&#39;} {&#39;start&#39;: 33.74, &#39;end&#39;: 33.78, &#39;text&#39;: &#39;oː&#39;} 0.03900000000000148 {&#39;start&#39;: 33.74, &#39;end&#39;: 33.819, &#39;text&#39;: &#39;och&#39;} {&#39;start&#39;: 33.84, &#39;end&#39;: 34.04, &#39;text&#39;: &#39;kɪs&#39;} 0.32099999999999795 {&#39;start&#39;: 33.88, &#39;end&#39;: 34.639, &#39;text&#39;: &#39;Kristdemokraterna&#39;} {&#39;start&#39;: 33.74, &#39;end&#39;: 33.78, &#39;text&#39;: &#39;oː&#39;} 0.9990000000000023 {&#39;start&#39;: 33.88, &#39;end&#39;: 34.639, &#39;text&#39;: &#39;Kristdemokraterna&#39;} {&#39;start&#39;: 33.84, &#39;end&#39;: 34.04, &#39;text&#39;: &#39;kɪs&#39;} 0.6390000000000029 {&#39;start&#39;: 33.88, &#39;end&#39;: 34.639, &#39;text&#39;: &#39;Kristdemokraterna&#39;} {&#39;start&#39;: 34.08, &#39;end&#39;: 34.64, &#39;text&#39;: &#39;demɔkɑːtɔɳa&#39;} 0.2009999999999934 {&#39;start&#39;: 34.76, &#39;end&#39;: 35.159, &#39;text&#39;: &#39;föreslår&#39;} {&#39;start&#39;: 34.76, &#39;end&#39;: 35.1, &#39;text&#39;: &#39;fœ̞ːesoː&#39;} 0.0589999999999975 {&#39;start&#39;: 34.76, &#39;end&#39;: 35.159, &#39;text&#39;: &#39;föreslår&#39;} {&#39;start&#39;: 35.2, &#39;end&#39;: 35.32, &#39;text&#39;: &#39;sɔm&#39;} 0.6010000000000062 {&#39;start&#39;: 35.22, &#39;end&#39;: 35.299, &#39;text&#39;: &#39;som&#39;} {&#39;start&#39;: 34.76, &#39;end&#39;: 35.1, &#39;text&#39;: &#39;fœ̞ːesoː&#39;} 0.6589999999999989 {&#39;start&#39;: 35.22, &#39;end&#39;: 35.299, &#39;text&#39;: &#39;som&#39;} {&#39;start&#39;: 35.2, &#39;end&#39;: 35.32, &#39;text&#39;: &#39;sɔm&#39;} 0.04099999999999682 {&#39;start&#39;: 35.22, &#39;end&#39;: 35.299, &#39;text&#39;: &#39;som&#39;} {&#39;start&#39;: 35.36, &#39;end&#39;: 35.94, &#39;text&#39;: &#39;rɪksdɑːɡəns&#39;} 0.7809999999999988 {&#39;start&#39;: 35.36, &#39;end&#39;: 35.939, &#39;text&#39;: &#39;riksdagens&#39;} {&#39;start&#39;: 35.2, &#39;end&#39;: 35.32, &#39;text&#39;: &#39;sɔm&#39;} 0.7789999999999964 {&#39;start&#39;: 35.36, &#39;end&#39;: 35.939, &#39;text&#39;: &#39;riksdagens&#39;} {&#39;start&#39;: 35.36, &#39;end&#39;: 35.94, &#39;text&#39;: &#39;rɪksdɑːɡəns&#39;} 0.0009999999999976694 {&#39;start&#39;: 36.02, &#39;end&#39;: 36.259, &#39;text&#39;: &#39;förste&#39;} {&#39;start&#39;: 36.02, &#39;end&#39;: 36.24, &#39;text&#39;: &#39;fœ̞st&#39;} 0.01899999999999835 {&#39;start&#39;: 36.32, &#39;end&#39;: 36.499, &#39;text&#39;: &#39;vice&#39;} {&#39;start&#39;: 36.3, &#39;end&#39;: 36.5, &#39;text&#39;: &#39;viːsə&#39;} 0.021000000000000796 {&#39;start&#39;: 36.58, &#39;end&#39;: 36.92, &#39;text&#39;: &#39;talman&#39;} {&#39;start&#39;: 36.58, &#39;end&#39;: 36.96, &#39;text&#39;: &#39;tɑːlman&#39;} 0.03999999999999915 {&#39;start&#39;: 36.58, &#39;end&#39;: 36.92, &#39;text&#39;: &#39;talman&#39;} {&#39;start&#39;: 37.08, &#39;end&#39;: 37.12, &#39;text&#39;: &#39;&lt;pa&gt;&#39;} 0.6999999999999957 {&#39;start&#39;: 37.32, &#39;end&#39;: 37.46, &#39;text&#39;: &#39;Ewa&#39;} {&#39;start&#39;: 37.3, &#39;end&#39;: 37.46, &#39;text&#39;: &#39;eva&#39;} 0.020000000000003126 {&#39;start&#39;: 37.56, &#39;end&#39;: 37.84, &#39;text&#39;: &#39;Thalén&#39;} {&#39;start&#39;: 37.56, &#39;end&#39;: 37.86, &#39;text&#39;: &#39;tareːn&#39;} 0.01999999999999602 {&#39;start&#39;: 38.14, &#39;end&#39;: 38.46, &#39;text&#39;: &#39;Finné.&#39;} {&#39;start&#39;: 38.14, &#39;end&#39;: 38.32, &#39;text&#39;: &#39;fɪne&#39;} 0.14000000000000057 . s1 = len(new_a) + 1 s2 = len(new_b) + 1 for i in range(s1): dist_matrix[i, 0] = float(i) for j in range(s2): dist_matrix[0, j] = float(j) for i in range(1, s1): for j in range(1, s2): if not in_range(new_a[i-1], new_b[j-1]): continue pair_cost = cost(new_a[i-1], new_b[j-1]) dist_matrix[i, j] = min( dist_matrix[i - 1][j] + pair_cost, dist_matrix[i][j - 1] + pair_cost, dist_matrix[i - 1][j - 1] + pair_cost ) . import pandas as pd df = pd.DataFrame(data=dist_matrix,index=[&quot;&quot;] + [x[&quot;text&quot;] for x in new_a], columns=[&quot;&quot;] + [x[&quot;text&quot;] for x in new_b]) . def falls_between(a1, a2, b): if b[&quot;end&quot;] &lt;= a2[&quot;start&quot;] and b[&quot;start&quot;] &gt;= a1[&quot;end&quot;]: return True return False . df . ɑː tɑːlman rɪksasleːda møːtœ̞ &lt;pa&gt; al aspatiːæɳa mʊdɑːtœ̞ɔɳa &lt;pa&gt; ... fœ̞ːesoː sɔm rɪksdɑːɡəns fœ̞st viːsə tɑːlman &lt;pa&gt; eva tareːn fɪne . 0.0 | 1.00 | 2.00 | 3.00 | 4.00 | 5.0 | 6.00 | 7.00 | 8.00 | 9.00 | ... | 16.000 | 17.000 | 18.000 | 19.000 | 20.000 | 21.00 | 22.0 | 23.00 | 24.00 | 25.00 | . Herr 1.0 | 0.02 | 0.84 | 0.00 | 0.00 | 0.0 | 0.00 | 0.00 | 0.00 | 0.00 | ... | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | 0.00 | 0.0 | 0.00 | 0.00 | 0.00 | . talman! 2.0 | 0.74 | 0.14 | 0.00 | 0.00 | 0.0 | 0.00 | 0.00 | 0.00 | 0.00 | ... | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | 0.00 | 0.0 | 0.00 | 0.00 | 0.00 | . Riksdagsledamöter! 3.0 | 0.00 | 0.00 | 0.52 | 0.62 | 0.0 | 0.00 | 0.00 | 0.00 | 0.00 | ... | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | 0.00 | 0.0 | 0.00 | 0.00 | 0.00 | . Allianspartierna 4.0 | 0.00 | 0.00 | 0.00 | 0.00 | 1.1 | 0.72 | 0.16 | 0.00 | 0.00 | ... | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | 0.00 | 0.0 | 0.00 | 0.00 | 0.00 | . Moderaterna, 5.0 | 0.00 | 0.00 | 0.00 | 0.00 | 0.0 | 0.00 | 0.00 | 0.02 | 0.88 | ... | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | 0.00 | 0.0 | 0.00 | 0.00 | 0.00 | . Centerpartiet, 6.0 | 0.00 | 0.00 | 0.00 | 0.00 | 0.0 | 0.00 | 0.00 | 0.00 | 0.00 | ... | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | 0.00 | 0.0 | 0.00 | 0.00 | 0.00 | . Liberalerna 7.0 | 0.00 | 0.00 | 0.00 | 0.00 | 0.0 | 0.00 | 0.00 | 0.00 | 0.00 | ... | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | 0.00 | 0.0 | 0.00 | 0.00 | 0.00 | . och 8.0 | 0.00 | 0.00 | 0.00 | 0.00 | 0.0 | 0.00 | 0.00 | 0.00 | 0.00 | ... | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | 0.00 | 0.0 | 0.00 | 0.00 | 0.00 | . Kristdemokraterna 9.0 | 0.00 | 0.00 | 0.00 | 0.00 | 0.0 | 0.00 | 0.00 | 0.00 | 0.00 | ... | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | 0.00 | 0.0 | 0.00 | 0.00 | 0.00 | . föreslår 10.0 | 0.00 | 0.00 | 0.00 | 0.00 | 0.0 | 0.00 | 0.00 | 0.00 | 0.00 | ... | 0.059 | 0.601 | 0.000 | 0.000 | 0.000 | 0.00 | 0.0 | 0.00 | 0.00 | 0.00 | . som 11.0 | 0.00 | 0.00 | 0.00 | 0.00 | 0.0 | 0.00 | 0.00 | 0.00 | 0.00 | ... | 0.659 | 0.100 | 0.781 | 0.000 | 0.000 | 0.00 | 0.0 | 0.00 | 0.00 | 0.00 | . riksdagens 12.0 | 0.00 | 0.00 | 0.00 | 0.00 | 0.0 | 0.00 | 0.00 | 0.00 | 0.00 | ... | 0.000 | 0.779 | 0.101 | 0.000 | 0.000 | 0.00 | 0.0 | 0.00 | 0.00 | 0.00 | . förste 13.0 | 0.00 | 0.00 | 0.00 | 0.00 | 0.0 | 0.00 | 0.00 | 0.00 | 0.00 | ... | 0.000 | 0.000 | 0.000 | 0.019 | 0.000 | 0.00 | 0.0 | 0.00 | 0.00 | 0.00 | . vice 14.0 | 0.00 | 0.00 | 0.00 | 0.00 | 0.0 | 0.00 | 0.00 | 0.00 | 0.00 | ... | 0.000 | 0.000 | 0.000 | 0.000 | 0.021 | 0.00 | 0.0 | 0.00 | 0.00 | 0.00 | . talman 15.0 | 0.00 | 0.00 | 0.00 | 0.00 | 0.0 | 0.00 | 0.00 | 0.00 | 0.00 | ... | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | 0.04 | 0.7 | 0.00 | 0.00 | 0.00 | . Ewa 16.0 | 0.00 | 0.00 | 0.00 | 0.00 | 0.0 | 0.00 | 0.00 | 0.00 | 0.00 | ... | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | 0.00 | 0.0 | 0.02 | 0.00 | 0.00 | . Thalén 17.0 | 0.00 | 0.00 | 0.00 | 0.00 | 0.0 | 0.00 | 0.00 | 0.00 | 0.00 | ... | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | 0.00 | 0.0 | 0.00 | 0.02 | 0.00 | . Finné. 18.0 | 0.00 | 0.00 | 0.00 | 0.00 | 0.0 | 0.00 | 0.00 | 0.00 | 0.00 | ... | 0.000 | 0.000 | 0.000 | 0.000 | 0.000 | 0.00 | 0.0 | 0.00 | 0.00 | 0.14 | . 19 rows × 26 columns .",
            "url": "https://jimregan.github.io/notes/riksdag/wav2vec/alignment/2024/03/09/alignment-stabs.html",
            "relUrl": "/riksdag/wav2vec/alignment/2024/03/09/alignment-stabs.html",
            "date": " • Mar 9, 2024"
        }
        
    
  
    
        ,"post1": {
            "title": "Interesting links, 05/03/2024",
            "content": "Current . OlaWod/FreeVC . RaPID-5 . Harvard sentences . Metavoice demo colab . ffmpeg - concatenate: . printf &quot;file &#39;%s&#39; n&quot; *.wav &gt; mylist.txt ffmpeg -f concat -i mylist.txt -c copy output.mkv . FAVE-extract . The TORGO Database: Acoustic and articulatory speech from speakers with dysarthria . TTS Arena . Interspeech 2024 CfP . PolyAI-LDN/pheme . Dysartria Classification . SIKOR North Saami corpus, DOI . SIKOR North Saami free corpus . GiellaLT Translation Memories . Code LoRA from Scratch . kyegomez/AudioFlamingo — Implementation of the model “AudioFlamingo” from the paper: “Audio Flamingo: A Novel Audio Language Model with Few-Shot Learning and Dialogue Abilities” . Map of Swedish counties . Map of Swedish dialects . . Peppa Malac - A Nagy Beteg . Peppa Malac - Az álruha, Peppa Pig - Dressing Up . A besúgó - 1. rész . DubDB - Hungarian . . lucidrains/RETRO-pytorch — Implementation of RETRO, Deepmind’s Retrieval based Attention net, in Pytorch . The Illustrated Retrieval Transformer . IDEFICS perceiver . SpiRit-LM: Interleaved Spoken and Written Language Model . NeMo - rnnt . espnet - Support external dataset library . DeAL: Decoding-time Alignment for Large Language Models . Welcome Aya-101 🚀&gt; Follows instructions in 101 languages!&gt; 12.9 B parameters&gt; Outperforms mT0 &amp; Bloomz&gt; Released under Apache 2.0 &gt; Training + Evaluation data released too!&gt; mt5-xxl architecture!GG @CohereForAI ♥️Model ckpt: https://t.co/FSK4E89YbV pic.twitter.com/1ykAHWOP8A . &mdash; Vaibhav (VB) Srivastav (@reach_vb) February 13, 2024 Textually Pretrained Speech Language Models, code, project . Master 6 French Tenses In Just 10 Minutes . MINISTRY - New Religion . Can’t stop watching this😂 pic.twitter.com/jlALwxpPPH . &mdash; Historic Vids (@historyinmemes) March 1, 2024 RTE 2FM Classic Irish Track Uncovered - Sally by Kerbdog with Cormac Battle . CNChTu/FCPE — Fast Context-based Pitch Estimation . TSP Speech Database . Scalable Diffusion Models with Transformers Meta, github: facebookresearch/DiT, not open source. . Diffusion Models for Audio Restoration . LibriSpeech Alignments . NST N-gram – Swedish .",
            "url": "https://jimregan.github.io/notes/links/2024/03/05/misc-links.html",
            "relUrl": "/links/2024/03/05/misc-links.html",
            "date": " • Mar 5, 2024"
        }
        
    
  
    
        ,"post2": {
            "title": "Processing Harvard sentences with metavoice",
            "content": "curl https://www.cs.columbia.edu/~hgs/audio/harvard.html|grep &#39;^&lt;li&gt;&#39;|awk -F&#39;[&lt;&gt;]&#39; &#39;{print $3}&#39; &gt; harvard.txt . &gt; &gt;&gt; with open(&quot;als3_mult.txt&quot;, &quot;w&quot;) as outf:... for id in range(2, 11): ... for line in harvard: ... wav_file = tts.synthesise(text=line, spk_ref_path=&quot;als3.mp3&quot;) ... outf.write(f&quot;{id} t{wav_file} n&quot;) . from fam.llm.fast_inference import TTS tts = TTS() . with open(&quot;harvard.txt&quot;) as harv: for line in harv.readlines(): harvard.append(line.strip()) . with open(&quot;park6_mult.txt&quot;, &quot;w&quot;) as outf: for id in range(1, 11): for line in harvard: wav_file = tts.synthesise(text=line, spk_ref_path=&quot;park6.mp3&quot;) outf.write(f&quot;{id} t{wav_file} n&quot;) . with open(&quot;aut1_mult.txt&quot;, &quot;w&quot;) as outf: for id in range(1, 11): for line in harvard: wav_file = tts.synthesise(text=line, spk_ref_path=&quot;aut1.mp3&quot;) outf.write(f&quot;{id} t{wav_file} n&quot;) . with open(&quot;park6_mult.txt&quot;, &quot;w&quot;) as outf: for id in range(1, 11): for line in harvard: wav_file = tts.synthesise(text=line, spk_ref_path=&quot;park6.mp3&quot;) outf.write(f&quot;{id} t{wav_file} n&quot;) . #!/bin/bash cat &quot;$1&quot; |while read i do id=$(echo &quot;$i&quot;|awk -F&#39; t&#39; &#39;{print $1}&#39;) dirname=$(printf &quot;batch_%02d&quot; $id) file=$(echo &quot;$i&quot;|awk -F&#39; t&#39; &#39;{print $NF}&#39;) echo &quot;$id : $dirname : $file&quot; if [ ! -d &quot;$2&quot;/&quot;$dirname&quot; ]; then echo &quot;$2&quot;/&quot;$dirname&quot; mkdir -p &quot;$2&quot;/&quot;$dirname&quot; fi cp &quot;$file&quot; &quot;$2&quot;/&quot;$dirname&quot;/ done .",
            "url": "https://jimregan.github.io/notes/metavoice/harvard/tts/2024/03/05/metavoice.html",
            "relUrl": "/metavoice/harvard/tts/2024/03/05/metavoice.html",
            "date": " • Mar 5, 2024"
        }
        
    
  
    
        ,"post3": {
            "title": "sayitinsaami.yle.fi scraper",
            "content": "JSON = &quot;http://sayitinsaami.yle.fi/js/fraasit.js?2019-02-15&quot; . import requests . rawdata = requests.get(JSON) . to_clean = rawdata.text to_clean = to_clean.replace(&quot; f:&quot;, &#39; &quot;f&quot;:&#39;).replace(&quot; fi:&quot;, &#39; &quot;fi&quot;:&#39;).replace(&quot; sv:&quot;, &#39; &quot;sv&quot;:&#39;).replace(&quot; en:&quot;, &#39; &quot;en&quot;:&#39;).replace(&quot; sme:&quot;, &#39; &quot;sme&quot;:&#39;).replace(&quot; smn:&quot;, &#39; &quot;smn&quot;:&#39;).replace(&quot; sms:&quot;, &#39; &quot;sms&quot;:&#39;).replace(&quot; cats:&quot;, &#39; &quot;cats&quot;:&#39;) . if to_clean.startswith(&quot;FRAASIT = &quot;): to_clean = to_clean[10:] to_clean = to_clean.strip() if to_clean.endswith(&quot;}, n]&quot;): to_clean = to_clean.replace(&quot;}, n]&quot;, &quot;}]&quot;) . import json data = json.loads(to_clean) . with open(&quot;sayitinsaami_output.tsv&quot;, &quot;w&quot;) as outf: for item in data: outf.write(f&#39;{item[&quot;sme&quot;]} thttp://sanosesaameksi.katrikoivula.com/audio/sme/{item[&quot;f&quot;]}.m4a n&#39;) . !cat output.tsv|awk -F&#39; t&#39; &#39;{print $2}&#39;|while read i;do f=$(echo $i|awk -F/ &#39;{print $NF}&#39;); if [ ! -e $f ];then wget -c $i;fi;done . with open(&quot;sayitinsaami.json&quot;, &quot;w&quot;) as cleaned: json.dump(data, cleaned) . !ls *.m4a|zip sayitinsaami_audio.zip -@ . !for f in *.m4a;do ffmpeg -i $f -acodec pcm_s16le -ac 1 -ar 16000 $(basename $f .m4a).wav;done . !ls -al *.wav . text = [] audio = [] for item in data: text.append(item[&quot;sme&quot;]) audio.append(f&#39;{item[&quot;f&quot;]}.wav&#39;) . %%capture !pip install datasets . %%capture !pip install torchaudio librosa . from datasets import Dataset, Audio . /home/joregan/miniconda3/envs/hf_new/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html from .autonotebook import tqdm as notebook_tqdm . text = [] audio = [] with open(&quot;/home/joregan/sayitinsaami/sayitinsaami_output.tsv&quot;) as tsvf: for line in tsvf.readlines(): parts = line.split(&quot; t&quot;) text.append(parts[0]) urlparts = parts[1].split(&quot;/&quot;) audio_path = &quot;/home/joregan/sayitinsaami/&quot; + urlparts[-1].replace(&quot;m4a&quot;, &quot;wav&quot;).strip() audio.append(audio_path) . audio_ds = Dataset.from_dict({&quot;text&quot;: text, &quot;audio&quot;: audio}).cast_column(&quot;audio&quot;, Audio()) . audio_ds[1] . {&#39;text&#39;: &#39;Buorre beaivi!&#39;, &#39;audio&#39;: {&#39;path&#39;: &#39;/home/joregan/sayitinsaami/102.wav&#39;, &#39;array&#39;: array([-3.05175781e-05, -6.10351562e-05, -6.10351562e-05, ..., 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]), &#39;sampling_rate&#39;: 16000}} . %%capture !pip install --upgrade evaluate jiwer . def clean_text(batch): if &quot;(duaali)&quot; in batch[&quot;text&quot;]: batch[&quot;text&quot;] = batch[&quot;text&quot;].replace(&quot;(duaali)&quot;, &quot;&quot;).strip() if &quot;...&quot; in batch[&quot;text&quot;]: batch[&quot;text&quot;] = batch[&quot;text&quot;].replace(&quot;...&quot;, &quot;&quot;).strip() if batch[&quot;text&quot;][-1] in &quot;?!.&quot;: batch[&quot;text&quot;] = batch[&quot;text&quot;][:-1] return batch . audio_ds = audio_ds.map(clean_text) . Map: 0%| | 0/888 [00:00&lt;?, ? examples/s]Map: 100%|██████████| 888/888 [00:00&lt;00:00, 11158.84 examples/s] . from transformers import pipeline import torch MODEL = &quot;NbAiLab/whisper-large-sme&quot; LANG = &quot;fi&quot; pipe = pipeline(task=&quot;automatic-speech-recognition&quot;, model=MODEL, chunk_length_s=30, device=0) pipe.model.config.forced_decoder_ids = pipe.tokenizer.get_decoder_prompt_ids(language=LANG, task=&quot;transcribe&quot;) . import evaluate metric = evaluate.load(&quot;wer&quot;) . Downloading builder script: 100%|██████████| 4.49k/4.49k [00:00&lt;00:00, 2.94MB/s] . from transformers.pipelines.pt_utils import KeyDataset . from tqdm.auto import tqdm preds = [] for out in tqdm(pipe(KeyDataset(audio_ds, &quot;audio&quot;))): preds.append(out[&quot;text&quot;]) . 100%|██████████| 888/888 [11:46&lt;00:00, 1.26it/s] . from evaluate import load wer_metric = load(&quot;wer&quot;) wer_ortho = 100 * wer_metric.compute( references=audio_ds[&quot;text&quot;], predictions=preds ) wer_ortho . 69.94623655913979 . def clean_for_wer(text): if text[-1] in &quot;?!.&quot;: text = text[:-1] return text.lower().strip() . preds = [clean_for_wer(x) for x in preds] refs = [clean_for_wer(x) for x in audio_ds[&quot;text&quot;]] . wer_ortho = 100 * wer_metric.compute( references=refs, predictions=preds ) wer_ortho . 51.45161290322581 .",
            "url": "https://jimregan.github.io/notes/sami/scraper/dt2112/2024/03/03/sayitinsaami-scraper.html",
            "relUrl": "/sami/scraper/dt2112/2024/03/03/sayitinsaami-scraper.html",
            "date": " • Mar 3, 2024"
        }
        
    
  
    
        ,"post4": {
            "title": "Example of converting and using a Huggingface Whisper model with whisper.cpp",
            "content": "!git clone https://github.com/ggerganov/whisper.cpp.git . Cloning into &#39;whisper.cpp&#39;... remote: Enumerating objects: 7336, done. remote: Total 7336 (delta 0), reused 0 (delta 0), pack-reused 7336 Receiving objects: 100% (7336/7336), 10.87 MiB | 20.88 MiB/s, done. Resolving deltas: 100% (4753/4753), done. . %cd whisper.cpp !make -j 8 . /content/whisper.cpp I whisper.cpp build info: I UNAME_S: Linux I UNAME_P: x86_64 I UNAME_M: x86_64 I CFLAGS: -I. -O3 -DNDEBUG -std=c11 -fPIC -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -pthread -mavx -mavx2 -mfma -mf16c -msse3 -mssse3 I CXXFLAGS: -I. -I./examples -O3 -DNDEBUG -std=c++11 -fPIC -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -pthread -mavx -mavx2 -mfma -mf16c -msse3 -mssse3 I LDFLAGS: I CC: cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 I CXX: g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 cc -I. -O3 -DNDEBUG -std=c11 -fPIC -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -pthread -mavx -mavx2 -mfma -mf16c -msse3 -mssse3 -c ggml.c -o ggml.o cc -I. -O3 -DNDEBUG -std=c11 -fPIC -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -pthread -mavx -mavx2 -mfma -mf16c -msse3 -mssse3 -c ggml-alloc.c -o ggml-alloc.o cc -I. -O3 -DNDEBUG -std=c11 -fPIC -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -pthread -mavx -mavx2 -mfma -mf16c -msse3 -mssse3 -c ggml-backend.c -o ggml-backend.o cc -I. -O3 -DNDEBUG -std=c11 -fPIC -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -pthread -mavx -mavx2 -mfma -mf16c -msse3 -mssse3 -c ggml-quants.c -o ggml-quants.o g++ -I. -I./examples -O3 -DNDEBUG -std=c++11 -fPIC -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -pthread -mavx -mavx2 -mfma -mf16c -msse3 -mssse3 -c whisper.cpp -o whisper.o g++ -I. -I./examples -O3 -DNDEBUG -std=c++11 -fPIC -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -pthread -mavx -mavx2 -mfma -mf16c -msse3 -mssse3 examples/main/main.cpp examples/common.cpp examples/common-ggml.cpp ggml.o ggml-alloc.o ggml-backend.o ggml-quants.o whisper.o -o main g++ -I. -I./examples -O3 -DNDEBUG -std=c++11 -fPIC -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -pthread -mavx -mavx2 -mfma -mf16c -msse3 -mssse3 examples/bench/bench.cpp ggml.o ggml-alloc.o ggml-backend.o ggml-quants.o whisper.o -o bench g++ -I. -I./examples -O3 -DNDEBUG -std=c++11 -fPIC -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -pthread -mavx -mavx2 -mfma -mf16c -msse3 -mssse3 examples/quantize/quantize.cpp examples/common.cpp examples/common-ggml.cpp ggml.o ggml-alloc.o ggml-backend.o ggml-quants.o whisper.o -o quantize g++ -I. -I./examples -O3 -DNDEBUG -std=c++11 -fPIC -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -pthread -mavx -mavx2 -mfma -mf16c -msse3 -mssse3 examples/server/server.cpp examples/common.cpp examples/common-ggml.cpp ggml.o ggml-alloc.o ggml-backend.o ggml-quants.o whisper.o -o server ./main -h usage: ./main [options] file0.wav file1.wav ... options: -h, --help [default] show this help message and exit -t N, --threads N [2 ] number of threads to use during computation -p N, --processors N [1 ] number of processors to use during computation -ot N, --offset-t N [0 ] time offset in milliseconds -on N, --offset-n N [0 ] segment index offset -d N, --duration N [0 ] duration of audio to process in milliseconds -mc N, --max-context N [-1 ] maximum number of text context tokens to store -ml N, --max-len N [0 ] maximum segment length in characters -sow, --split-on-word [false ] split on word rather than on token -bo N, --best-of N [5 ] number of best candidates to keep -bs N, --beam-size N [5 ] beam size for beam search -ac N, --audio-ctx N [0 ] audio context size (0 - all) -wt N, --word-thold N [0.01 ] word timestamp probability threshold -et N, --entropy-thold N [2.40 ] entropy threshold for decoder fail -lpt N, --logprob-thold N [-1.00 ] log probability threshold for decoder fail -debug, --debug-mode [false ] enable debug mode (eg. dump log_mel) -tr, --translate [false ] translate from source language to english -di, --diarize [false ] stereo audio diarization -tdrz, --tinydiarize [false ] enable tinydiarize (requires a tdrz model) -nf, --no-fallback [false ] do not use temperature fallback while decoding -otxt, --output-txt [false ] output result in a text file -ovtt, --output-vtt [false ] output result in a vtt file -osrt, --output-srt [false ] output result in a srt file -olrc, --output-lrc [false ] output result in a lrc file -owts, --output-words [false ] output script for generating karaoke video -fp, --font-path [/System/Library/Fonts/Supplemental/Courier New Bold.ttf] path to a monospace font for karaoke video -ocsv, --output-csv [false ] output result in a CSV file -oj, --output-json [false ] output result in a JSON file -ojf, --output-json-full [false ] include more information in the JSON file -of FNAME, --output-file FNAME [ ] output file path (without file extension) -np, --no-prints [false ] do not print anything other than the results -ps, --print-special [false ] print special tokens -pc, --print-colors [false ] print colors -pp, --print-progress [false ] print progress -nt, --no-timestamps [false ] do not print timestamps -l LANG, --language LANG [en ] spoken language (&#39;auto&#39; for auto-detect) -dl, --detect-language [false ] exit after automatically detecting language --prompt PROMPT [ ] initial prompt -m FNAME, --model FNAME [models/ggml-base.en.bin] model path -f FNAME, --file FNAME [ ] input WAV file path -oved D, --ov-e-device DNAME [CPU ] the OpenVINO device used for encode inference -ls, --log-score [false ] log best decoder scores of tokens -ng, --no-gpu [false ] disable GPU . !git lfs install . Updated git hooks. Git LFS initialized. . %cd /content !git clone https://huggingface.co/NbAiLab/whisper-large-sme . /content Cloning into &#39;whisper-large-sme&#39;... remote: Enumerating objects: 444, done. remote: Total 444 (delta 0), reused 0 (delta 0), pack-reused 444 Receiving objects: 100% (444/444), 642.41 KiB | 9.73 MiB/s, done. Resolving deltas: 100% (146/146), done. . %cd /content !git clone https://github.com/openai/whisper . /content Cloning into &#39;whisper&#39;... remote: Enumerating objects: 712, done. remote: Counting objects: 100% (10/10), done. remote: Compressing objects: 100% (10/10), done. remote: Total 712 (delta 1), reused 3 (delta 0), pack-reused 702 Receiving objects: 100% (712/712), 12.43 MiB | 20.53 MiB/s, done. Resolving deltas: 100% (419/419), done. . !mkdir whisper-ggml-sme !python whisper.cpp/models/convert-h5-to-ggml.py ./whisper-large-sme/ ./whisper ./whisper-ggml-sme/ . mkdir: cannot create directory ‘whisper-ggml-sme’: File exists /usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly. To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage() return self.fget.__get__(instance, owner)() model.encoder.conv1.weight -&gt; encoder.conv1.weight encoder.conv1.weight 3 (1280, 80, 3) model.encoder.conv1.bias -&gt; encoder.conv1.bias Reshaped variable: encoder.conv1.bias to shape: (1280, 1) encoder.conv1.bias 2 (1280, 1) Converting to float32 model.encoder.conv2.weight -&gt; encoder.conv2.weight encoder.conv2.weight 3 (1280, 1280, 3) model.encoder.conv2.bias -&gt; encoder.conv2.bias Reshaped variable: encoder.conv2.bias to shape: (1280, 1) encoder.conv2.bias 2 (1280, 1) Converting to float32 model.encoder.embed_positions.weight -&gt; encoder.positional_embedding encoder.positional_embedding 2 (1500, 1280) Converting to float32 model.encoder.layers.0.self_attn.k_proj.weight -&gt; encoder.blocks.0.attn.key.weight encoder.blocks.0.attn.key.weight 2 (1280, 1280) model.encoder.layers.0.self_attn.v_proj.weight -&gt; encoder.blocks.0.attn.value.weight encoder.blocks.0.attn.value.weight 2 (1280, 1280) model.encoder.layers.0.self_attn.v_proj.bias -&gt; encoder.blocks.0.attn.value.bias encoder.blocks.0.attn.value.bias 1 (1280,) Converting to float32 model.encoder.layers.0.self_attn.q_proj.weight -&gt; encoder.blocks.0.attn.query.weight encoder.blocks.0.attn.query.weight 2 (1280, 1280) model.encoder.layers.0.self_attn.q_proj.bias -&gt; encoder.blocks.0.attn.query.bias encoder.blocks.0.attn.query.bias 1 (1280,) Converting to float32 model.encoder.layers.0.self_attn.out_proj.weight -&gt; encoder.blocks.0.attn.out.weight encoder.blocks.0.attn.out.weight 2 (1280, 1280) model.encoder.layers.0.self_attn.out_proj.bias -&gt; encoder.blocks.0.attn.out.bias encoder.blocks.0.attn.out.bias 1 (1280,) Converting to float32 model.encoder.layers.0.self_attn_layer_norm.weight -&gt; encoder.blocks.0.attn_ln.weight encoder.blocks.0.attn_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.0.self_attn_layer_norm.bias -&gt; encoder.blocks.0.attn_ln.bias encoder.blocks.0.attn_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.0.fc1.weight -&gt; encoder.blocks.0.mlp.0.weight encoder.blocks.0.mlp.0.weight 2 (5120, 1280) model.encoder.layers.0.fc1.bias -&gt; encoder.blocks.0.mlp.0.bias encoder.blocks.0.mlp.0.bias 1 (5120,) Converting to float32 model.encoder.layers.0.fc2.weight -&gt; encoder.blocks.0.mlp.2.weight encoder.blocks.0.mlp.2.weight 2 (1280, 5120) model.encoder.layers.0.fc2.bias -&gt; encoder.blocks.0.mlp.2.bias encoder.blocks.0.mlp.2.bias 1 (1280,) Converting to float32 model.encoder.layers.0.final_layer_norm.weight -&gt; encoder.blocks.0.mlp_ln.weight encoder.blocks.0.mlp_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.0.final_layer_norm.bias -&gt; encoder.blocks.0.mlp_ln.bias encoder.blocks.0.mlp_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.1.self_attn.k_proj.weight -&gt; encoder.blocks.1.attn.key.weight encoder.blocks.1.attn.key.weight 2 (1280, 1280) model.encoder.layers.1.self_attn.v_proj.weight -&gt; encoder.blocks.1.attn.value.weight encoder.blocks.1.attn.value.weight 2 (1280, 1280) model.encoder.layers.1.self_attn.v_proj.bias -&gt; encoder.blocks.1.attn.value.bias encoder.blocks.1.attn.value.bias 1 (1280,) Converting to float32 model.encoder.layers.1.self_attn.q_proj.weight -&gt; encoder.blocks.1.attn.query.weight encoder.blocks.1.attn.query.weight 2 (1280, 1280) model.encoder.layers.1.self_attn.q_proj.bias -&gt; encoder.blocks.1.attn.query.bias encoder.blocks.1.attn.query.bias 1 (1280,) Converting to float32 model.encoder.layers.1.self_attn.out_proj.weight -&gt; encoder.blocks.1.attn.out.weight encoder.blocks.1.attn.out.weight 2 (1280, 1280) model.encoder.layers.1.self_attn.out_proj.bias -&gt; encoder.blocks.1.attn.out.bias encoder.blocks.1.attn.out.bias 1 (1280,) Converting to float32 model.encoder.layers.1.self_attn_layer_norm.weight -&gt; encoder.blocks.1.attn_ln.weight encoder.blocks.1.attn_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.1.self_attn_layer_norm.bias -&gt; encoder.blocks.1.attn_ln.bias encoder.blocks.1.attn_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.1.fc1.weight -&gt; encoder.blocks.1.mlp.0.weight encoder.blocks.1.mlp.0.weight 2 (5120, 1280) model.encoder.layers.1.fc1.bias -&gt; encoder.blocks.1.mlp.0.bias encoder.blocks.1.mlp.0.bias 1 (5120,) Converting to float32 model.encoder.layers.1.fc2.weight -&gt; encoder.blocks.1.mlp.2.weight encoder.blocks.1.mlp.2.weight 2 (1280, 5120) model.encoder.layers.1.fc2.bias -&gt; encoder.blocks.1.mlp.2.bias encoder.blocks.1.mlp.2.bias 1 (1280,) Converting to float32 model.encoder.layers.1.final_layer_norm.weight -&gt; encoder.blocks.1.mlp_ln.weight encoder.blocks.1.mlp_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.1.final_layer_norm.bias -&gt; encoder.blocks.1.mlp_ln.bias encoder.blocks.1.mlp_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.2.self_attn.k_proj.weight -&gt; encoder.blocks.2.attn.key.weight encoder.blocks.2.attn.key.weight 2 (1280, 1280) model.encoder.layers.2.self_attn.v_proj.weight -&gt; encoder.blocks.2.attn.value.weight encoder.blocks.2.attn.value.weight 2 (1280, 1280) model.encoder.layers.2.self_attn.v_proj.bias -&gt; encoder.blocks.2.attn.value.bias encoder.blocks.2.attn.value.bias 1 (1280,) Converting to float32 model.encoder.layers.2.self_attn.q_proj.weight -&gt; encoder.blocks.2.attn.query.weight encoder.blocks.2.attn.query.weight 2 (1280, 1280) model.encoder.layers.2.self_attn.q_proj.bias -&gt; encoder.blocks.2.attn.query.bias encoder.blocks.2.attn.query.bias 1 (1280,) Converting to float32 model.encoder.layers.2.self_attn.out_proj.weight -&gt; encoder.blocks.2.attn.out.weight encoder.blocks.2.attn.out.weight 2 (1280, 1280) model.encoder.layers.2.self_attn.out_proj.bias -&gt; encoder.blocks.2.attn.out.bias encoder.blocks.2.attn.out.bias 1 (1280,) Converting to float32 model.encoder.layers.2.self_attn_layer_norm.weight -&gt; encoder.blocks.2.attn_ln.weight encoder.blocks.2.attn_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.2.self_attn_layer_norm.bias -&gt; encoder.blocks.2.attn_ln.bias encoder.blocks.2.attn_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.2.fc1.weight -&gt; encoder.blocks.2.mlp.0.weight encoder.blocks.2.mlp.0.weight 2 (5120, 1280) model.encoder.layers.2.fc1.bias -&gt; encoder.blocks.2.mlp.0.bias encoder.blocks.2.mlp.0.bias 1 (5120,) Converting to float32 model.encoder.layers.2.fc2.weight -&gt; encoder.blocks.2.mlp.2.weight encoder.blocks.2.mlp.2.weight 2 (1280, 5120) model.encoder.layers.2.fc2.bias -&gt; encoder.blocks.2.mlp.2.bias encoder.blocks.2.mlp.2.bias 1 (1280,) Converting to float32 model.encoder.layers.2.final_layer_norm.weight -&gt; encoder.blocks.2.mlp_ln.weight encoder.blocks.2.mlp_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.2.final_layer_norm.bias -&gt; encoder.blocks.2.mlp_ln.bias encoder.blocks.2.mlp_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.3.self_attn.k_proj.weight -&gt; encoder.blocks.3.attn.key.weight encoder.blocks.3.attn.key.weight 2 (1280, 1280) model.encoder.layers.3.self_attn.v_proj.weight -&gt; encoder.blocks.3.attn.value.weight encoder.blocks.3.attn.value.weight 2 (1280, 1280) model.encoder.layers.3.self_attn.v_proj.bias -&gt; encoder.blocks.3.attn.value.bias encoder.blocks.3.attn.value.bias 1 (1280,) Converting to float32 model.encoder.layers.3.self_attn.q_proj.weight -&gt; encoder.blocks.3.attn.query.weight encoder.blocks.3.attn.query.weight 2 (1280, 1280) model.encoder.layers.3.self_attn.q_proj.bias -&gt; encoder.blocks.3.attn.query.bias encoder.blocks.3.attn.query.bias 1 (1280,) Converting to float32 model.encoder.layers.3.self_attn.out_proj.weight -&gt; encoder.blocks.3.attn.out.weight encoder.blocks.3.attn.out.weight 2 (1280, 1280) model.encoder.layers.3.self_attn.out_proj.bias -&gt; encoder.blocks.3.attn.out.bias encoder.blocks.3.attn.out.bias 1 (1280,) Converting to float32 model.encoder.layers.3.self_attn_layer_norm.weight -&gt; encoder.blocks.3.attn_ln.weight encoder.blocks.3.attn_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.3.self_attn_layer_norm.bias -&gt; encoder.blocks.3.attn_ln.bias encoder.blocks.3.attn_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.3.fc1.weight -&gt; encoder.blocks.3.mlp.0.weight encoder.blocks.3.mlp.0.weight 2 (5120, 1280) model.encoder.layers.3.fc1.bias -&gt; encoder.blocks.3.mlp.0.bias encoder.blocks.3.mlp.0.bias 1 (5120,) Converting to float32 model.encoder.layers.3.fc2.weight -&gt; encoder.blocks.3.mlp.2.weight encoder.blocks.3.mlp.2.weight 2 (1280, 5120) model.encoder.layers.3.fc2.bias -&gt; encoder.blocks.3.mlp.2.bias encoder.blocks.3.mlp.2.bias 1 (1280,) Converting to float32 model.encoder.layers.3.final_layer_norm.weight -&gt; encoder.blocks.3.mlp_ln.weight encoder.blocks.3.mlp_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.3.final_layer_norm.bias -&gt; encoder.blocks.3.mlp_ln.bias encoder.blocks.3.mlp_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.4.self_attn.k_proj.weight -&gt; encoder.blocks.4.attn.key.weight encoder.blocks.4.attn.key.weight 2 (1280, 1280) model.encoder.layers.4.self_attn.v_proj.weight -&gt; encoder.blocks.4.attn.value.weight encoder.blocks.4.attn.value.weight 2 (1280, 1280) model.encoder.layers.4.self_attn.v_proj.bias -&gt; encoder.blocks.4.attn.value.bias encoder.blocks.4.attn.value.bias 1 (1280,) Converting to float32 model.encoder.layers.4.self_attn.q_proj.weight -&gt; encoder.blocks.4.attn.query.weight encoder.blocks.4.attn.query.weight 2 (1280, 1280) model.encoder.layers.4.self_attn.q_proj.bias -&gt; encoder.blocks.4.attn.query.bias encoder.blocks.4.attn.query.bias 1 (1280,) Converting to float32 model.encoder.layers.4.self_attn.out_proj.weight -&gt; encoder.blocks.4.attn.out.weight encoder.blocks.4.attn.out.weight 2 (1280, 1280) model.encoder.layers.4.self_attn.out_proj.bias -&gt; encoder.blocks.4.attn.out.bias encoder.blocks.4.attn.out.bias 1 (1280,) Converting to float32 model.encoder.layers.4.self_attn_layer_norm.weight -&gt; encoder.blocks.4.attn_ln.weight encoder.blocks.4.attn_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.4.self_attn_layer_norm.bias -&gt; encoder.blocks.4.attn_ln.bias encoder.blocks.4.attn_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.4.fc1.weight -&gt; encoder.blocks.4.mlp.0.weight encoder.blocks.4.mlp.0.weight 2 (5120, 1280) model.encoder.layers.4.fc1.bias -&gt; encoder.blocks.4.mlp.0.bias encoder.blocks.4.mlp.0.bias 1 (5120,) Converting to float32 model.encoder.layers.4.fc2.weight -&gt; encoder.blocks.4.mlp.2.weight encoder.blocks.4.mlp.2.weight 2 (1280, 5120) model.encoder.layers.4.fc2.bias -&gt; encoder.blocks.4.mlp.2.bias encoder.blocks.4.mlp.2.bias 1 (1280,) Converting to float32 model.encoder.layers.4.final_layer_norm.weight -&gt; encoder.blocks.4.mlp_ln.weight encoder.blocks.4.mlp_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.4.final_layer_norm.bias -&gt; encoder.blocks.4.mlp_ln.bias encoder.blocks.4.mlp_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.5.self_attn.k_proj.weight -&gt; encoder.blocks.5.attn.key.weight encoder.blocks.5.attn.key.weight 2 (1280, 1280) model.encoder.layers.5.self_attn.v_proj.weight -&gt; encoder.blocks.5.attn.value.weight encoder.blocks.5.attn.value.weight 2 (1280, 1280) model.encoder.layers.5.self_attn.v_proj.bias -&gt; encoder.blocks.5.attn.value.bias encoder.blocks.5.attn.value.bias 1 (1280,) Converting to float32 model.encoder.layers.5.self_attn.q_proj.weight -&gt; encoder.blocks.5.attn.query.weight encoder.blocks.5.attn.query.weight 2 (1280, 1280) model.encoder.layers.5.self_attn.q_proj.bias -&gt; encoder.blocks.5.attn.query.bias encoder.blocks.5.attn.query.bias 1 (1280,) Converting to float32 model.encoder.layers.5.self_attn.out_proj.weight -&gt; encoder.blocks.5.attn.out.weight encoder.blocks.5.attn.out.weight 2 (1280, 1280) model.encoder.layers.5.self_attn.out_proj.bias -&gt; encoder.blocks.5.attn.out.bias encoder.blocks.5.attn.out.bias 1 (1280,) Converting to float32 model.encoder.layers.5.self_attn_layer_norm.weight -&gt; encoder.blocks.5.attn_ln.weight encoder.blocks.5.attn_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.5.self_attn_layer_norm.bias -&gt; encoder.blocks.5.attn_ln.bias encoder.blocks.5.attn_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.5.fc1.weight -&gt; encoder.blocks.5.mlp.0.weight encoder.blocks.5.mlp.0.weight 2 (5120, 1280) model.encoder.layers.5.fc1.bias -&gt; encoder.blocks.5.mlp.0.bias encoder.blocks.5.mlp.0.bias 1 (5120,) Converting to float32 model.encoder.layers.5.fc2.weight -&gt; encoder.blocks.5.mlp.2.weight encoder.blocks.5.mlp.2.weight 2 (1280, 5120) model.encoder.layers.5.fc2.bias -&gt; encoder.blocks.5.mlp.2.bias encoder.blocks.5.mlp.2.bias 1 (1280,) Converting to float32 model.encoder.layers.5.final_layer_norm.weight -&gt; encoder.blocks.5.mlp_ln.weight encoder.blocks.5.mlp_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.5.final_layer_norm.bias -&gt; encoder.blocks.5.mlp_ln.bias encoder.blocks.5.mlp_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.6.self_attn.k_proj.weight -&gt; encoder.blocks.6.attn.key.weight encoder.blocks.6.attn.key.weight 2 (1280, 1280) model.encoder.layers.6.self_attn.v_proj.weight -&gt; encoder.blocks.6.attn.value.weight encoder.blocks.6.attn.value.weight 2 (1280, 1280) model.encoder.layers.6.self_attn.v_proj.bias -&gt; encoder.blocks.6.attn.value.bias encoder.blocks.6.attn.value.bias 1 (1280,) Converting to float32 model.encoder.layers.6.self_attn.q_proj.weight -&gt; encoder.blocks.6.attn.query.weight encoder.blocks.6.attn.query.weight 2 (1280, 1280) model.encoder.layers.6.self_attn.q_proj.bias -&gt; encoder.blocks.6.attn.query.bias encoder.blocks.6.attn.query.bias 1 (1280,) Converting to float32 model.encoder.layers.6.self_attn.out_proj.weight -&gt; encoder.blocks.6.attn.out.weight encoder.blocks.6.attn.out.weight 2 (1280, 1280) model.encoder.layers.6.self_attn.out_proj.bias -&gt; encoder.blocks.6.attn.out.bias encoder.blocks.6.attn.out.bias 1 (1280,) Converting to float32 model.encoder.layers.6.self_attn_layer_norm.weight -&gt; encoder.blocks.6.attn_ln.weight encoder.blocks.6.attn_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.6.self_attn_layer_norm.bias -&gt; encoder.blocks.6.attn_ln.bias encoder.blocks.6.attn_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.6.fc1.weight -&gt; encoder.blocks.6.mlp.0.weight encoder.blocks.6.mlp.0.weight 2 (5120, 1280) model.encoder.layers.6.fc1.bias -&gt; encoder.blocks.6.mlp.0.bias encoder.blocks.6.mlp.0.bias 1 (5120,) Converting to float32 model.encoder.layers.6.fc2.weight -&gt; encoder.blocks.6.mlp.2.weight encoder.blocks.6.mlp.2.weight 2 (1280, 5120) model.encoder.layers.6.fc2.bias -&gt; encoder.blocks.6.mlp.2.bias encoder.blocks.6.mlp.2.bias 1 (1280,) Converting to float32 model.encoder.layers.6.final_layer_norm.weight -&gt; encoder.blocks.6.mlp_ln.weight encoder.blocks.6.mlp_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.6.final_layer_norm.bias -&gt; encoder.blocks.6.mlp_ln.bias encoder.blocks.6.mlp_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.7.self_attn.k_proj.weight -&gt; encoder.blocks.7.attn.key.weight encoder.blocks.7.attn.key.weight 2 (1280, 1280) model.encoder.layers.7.self_attn.v_proj.weight -&gt; encoder.blocks.7.attn.value.weight encoder.blocks.7.attn.value.weight 2 (1280, 1280) model.encoder.layers.7.self_attn.v_proj.bias -&gt; encoder.blocks.7.attn.value.bias encoder.blocks.7.attn.value.bias 1 (1280,) Converting to float32 model.encoder.layers.7.self_attn.q_proj.weight -&gt; encoder.blocks.7.attn.query.weight encoder.blocks.7.attn.query.weight 2 (1280, 1280) model.encoder.layers.7.self_attn.q_proj.bias -&gt; encoder.blocks.7.attn.query.bias encoder.blocks.7.attn.query.bias 1 (1280,) Converting to float32 model.encoder.layers.7.self_attn.out_proj.weight -&gt; encoder.blocks.7.attn.out.weight encoder.blocks.7.attn.out.weight 2 (1280, 1280) model.encoder.layers.7.self_attn.out_proj.bias -&gt; encoder.blocks.7.attn.out.bias encoder.blocks.7.attn.out.bias 1 (1280,) Converting to float32 model.encoder.layers.7.self_attn_layer_norm.weight -&gt; encoder.blocks.7.attn_ln.weight encoder.blocks.7.attn_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.7.self_attn_layer_norm.bias -&gt; encoder.blocks.7.attn_ln.bias encoder.blocks.7.attn_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.7.fc1.weight -&gt; encoder.blocks.7.mlp.0.weight encoder.blocks.7.mlp.0.weight 2 (5120, 1280) model.encoder.layers.7.fc1.bias -&gt; encoder.blocks.7.mlp.0.bias encoder.blocks.7.mlp.0.bias 1 (5120,) Converting to float32 model.encoder.layers.7.fc2.weight -&gt; encoder.blocks.7.mlp.2.weight encoder.blocks.7.mlp.2.weight 2 (1280, 5120) model.encoder.layers.7.fc2.bias -&gt; encoder.blocks.7.mlp.2.bias encoder.blocks.7.mlp.2.bias 1 (1280,) Converting to float32 model.encoder.layers.7.final_layer_norm.weight -&gt; encoder.blocks.7.mlp_ln.weight encoder.blocks.7.mlp_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.7.final_layer_norm.bias -&gt; encoder.blocks.7.mlp_ln.bias encoder.blocks.7.mlp_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.8.self_attn.k_proj.weight -&gt; encoder.blocks.8.attn.key.weight encoder.blocks.8.attn.key.weight 2 (1280, 1280) model.encoder.layers.8.self_attn.v_proj.weight -&gt; encoder.blocks.8.attn.value.weight encoder.blocks.8.attn.value.weight 2 (1280, 1280) model.encoder.layers.8.self_attn.v_proj.bias -&gt; encoder.blocks.8.attn.value.bias encoder.blocks.8.attn.value.bias 1 (1280,) Converting to float32 model.encoder.layers.8.self_attn.q_proj.weight -&gt; encoder.blocks.8.attn.query.weight encoder.blocks.8.attn.query.weight 2 (1280, 1280) model.encoder.layers.8.self_attn.q_proj.bias -&gt; encoder.blocks.8.attn.query.bias encoder.blocks.8.attn.query.bias 1 (1280,) Converting to float32 model.encoder.layers.8.self_attn.out_proj.weight -&gt; encoder.blocks.8.attn.out.weight encoder.blocks.8.attn.out.weight 2 (1280, 1280) model.encoder.layers.8.self_attn.out_proj.bias -&gt; encoder.blocks.8.attn.out.bias encoder.blocks.8.attn.out.bias 1 (1280,) Converting to float32 model.encoder.layers.8.self_attn_layer_norm.weight -&gt; encoder.blocks.8.attn_ln.weight encoder.blocks.8.attn_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.8.self_attn_layer_norm.bias -&gt; encoder.blocks.8.attn_ln.bias encoder.blocks.8.attn_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.8.fc1.weight -&gt; encoder.blocks.8.mlp.0.weight encoder.blocks.8.mlp.0.weight 2 (5120, 1280) model.encoder.layers.8.fc1.bias -&gt; encoder.blocks.8.mlp.0.bias encoder.blocks.8.mlp.0.bias 1 (5120,) Converting to float32 model.encoder.layers.8.fc2.weight -&gt; encoder.blocks.8.mlp.2.weight encoder.blocks.8.mlp.2.weight 2 (1280, 5120) model.encoder.layers.8.fc2.bias -&gt; encoder.blocks.8.mlp.2.bias encoder.blocks.8.mlp.2.bias 1 (1280,) Converting to float32 model.encoder.layers.8.final_layer_norm.weight -&gt; encoder.blocks.8.mlp_ln.weight encoder.blocks.8.mlp_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.8.final_layer_norm.bias -&gt; encoder.blocks.8.mlp_ln.bias encoder.blocks.8.mlp_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.9.self_attn.k_proj.weight -&gt; encoder.blocks.9.attn.key.weight encoder.blocks.9.attn.key.weight 2 (1280, 1280) model.encoder.layers.9.self_attn.v_proj.weight -&gt; encoder.blocks.9.attn.value.weight encoder.blocks.9.attn.value.weight 2 (1280, 1280) model.encoder.layers.9.self_attn.v_proj.bias -&gt; encoder.blocks.9.attn.value.bias encoder.blocks.9.attn.value.bias 1 (1280,) Converting to float32 model.encoder.layers.9.self_attn.q_proj.weight -&gt; encoder.blocks.9.attn.query.weight encoder.blocks.9.attn.query.weight 2 (1280, 1280) model.encoder.layers.9.self_attn.q_proj.bias -&gt; encoder.blocks.9.attn.query.bias encoder.blocks.9.attn.query.bias 1 (1280,) Converting to float32 model.encoder.layers.9.self_attn.out_proj.weight -&gt; encoder.blocks.9.attn.out.weight encoder.blocks.9.attn.out.weight 2 (1280, 1280) model.encoder.layers.9.self_attn.out_proj.bias -&gt; encoder.blocks.9.attn.out.bias encoder.blocks.9.attn.out.bias 1 (1280,) Converting to float32 model.encoder.layers.9.self_attn_layer_norm.weight -&gt; encoder.blocks.9.attn_ln.weight encoder.blocks.9.attn_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.9.self_attn_layer_norm.bias -&gt; encoder.blocks.9.attn_ln.bias encoder.blocks.9.attn_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.9.fc1.weight -&gt; encoder.blocks.9.mlp.0.weight encoder.blocks.9.mlp.0.weight 2 (5120, 1280) model.encoder.layers.9.fc1.bias -&gt; encoder.blocks.9.mlp.0.bias encoder.blocks.9.mlp.0.bias 1 (5120,) Converting to float32 model.encoder.layers.9.fc2.weight -&gt; encoder.blocks.9.mlp.2.weight encoder.blocks.9.mlp.2.weight 2 (1280, 5120) model.encoder.layers.9.fc2.bias -&gt; encoder.blocks.9.mlp.2.bias encoder.blocks.9.mlp.2.bias 1 (1280,) Converting to float32 model.encoder.layers.9.final_layer_norm.weight -&gt; encoder.blocks.9.mlp_ln.weight encoder.blocks.9.mlp_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.9.final_layer_norm.bias -&gt; encoder.blocks.9.mlp_ln.bias encoder.blocks.9.mlp_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.10.self_attn.k_proj.weight -&gt; encoder.blocks.10.attn.key.weight encoder.blocks.10.attn.key.weight 2 (1280, 1280) model.encoder.layers.10.self_attn.v_proj.weight -&gt; encoder.blocks.10.attn.value.weight encoder.blocks.10.attn.value.weight 2 (1280, 1280) model.encoder.layers.10.self_attn.v_proj.bias -&gt; encoder.blocks.10.attn.value.bias encoder.blocks.10.attn.value.bias 1 (1280,) Converting to float32 model.encoder.layers.10.self_attn.q_proj.weight -&gt; encoder.blocks.10.attn.query.weight encoder.blocks.10.attn.query.weight 2 (1280, 1280) model.encoder.layers.10.self_attn.q_proj.bias -&gt; encoder.blocks.10.attn.query.bias encoder.blocks.10.attn.query.bias 1 (1280,) Converting to float32 model.encoder.layers.10.self_attn.out_proj.weight -&gt; encoder.blocks.10.attn.out.weight encoder.blocks.10.attn.out.weight 2 (1280, 1280) model.encoder.layers.10.self_attn.out_proj.bias -&gt; encoder.blocks.10.attn.out.bias encoder.blocks.10.attn.out.bias 1 (1280,) Converting to float32 model.encoder.layers.10.self_attn_layer_norm.weight -&gt; encoder.blocks.10.attn_ln.weight encoder.blocks.10.attn_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.10.self_attn_layer_norm.bias -&gt; encoder.blocks.10.attn_ln.bias encoder.blocks.10.attn_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.10.fc1.weight -&gt; encoder.blocks.10.mlp.0.weight encoder.blocks.10.mlp.0.weight 2 (5120, 1280) model.encoder.layers.10.fc1.bias -&gt; encoder.blocks.10.mlp.0.bias encoder.blocks.10.mlp.0.bias 1 (5120,) Converting to float32 model.encoder.layers.10.fc2.weight -&gt; encoder.blocks.10.mlp.2.weight encoder.blocks.10.mlp.2.weight 2 (1280, 5120) model.encoder.layers.10.fc2.bias -&gt; encoder.blocks.10.mlp.2.bias encoder.blocks.10.mlp.2.bias 1 (1280,) Converting to float32 model.encoder.layers.10.final_layer_norm.weight -&gt; encoder.blocks.10.mlp_ln.weight encoder.blocks.10.mlp_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.10.final_layer_norm.bias -&gt; encoder.blocks.10.mlp_ln.bias encoder.blocks.10.mlp_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.11.self_attn.k_proj.weight -&gt; encoder.blocks.11.attn.key.weight encoder.blocks.11.attn.key.weight 2 (1280, 1280) model.encoder.layers.11.self_attn.v_proj.weight -&gt; encoder.blocks.11.attn.value.weight encoder.blocks.11.attn.value.weight 2 (1280, 1280) model.encoder.layers.11.self_attn.v_proj.bias -&gt; encoder.blocks.11.attn.value.bias encoder.blocks.11.attn.value.bias 1 (1280,) Converting to float32 model.encoder.layers.11.self_attn.q_proj.weight -&gt; encoder.blocks.11.attn.query.weight encoder.blocks.11.attn.query.weight 2 (1280, 1280) model.encoder.layers.11.self_attn.q_proj.bias -&gt; encoder.blocks.11.attn.query.bias encoder.blocks.11.attn.query.bias 1 (1280,) Converting to float32 model.encoder.layers.11.self_attn.out_proj.weight -&gt; encoder.blocks.11.attn.out.weight encoder.blocks.11.attn.out.weight 2 (1280, 1280) model.encoder.layers.11.self_attn.out_proj.bias -&gt; encoder.blocks.11.attn.out.bias encoder.blocks.11.attn.out.bias 1 (1280,) Converting to float32 model.encoder.layers.11.self_attn_layer_norm.weight -&gt; encoder.blocks.11.attn_ln.weight encoder.blocks.11.attn_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.11.self_attn_layer_norm.bias -&gt; encoder.blocks.11.attn_ln.bias encoder.blocks.11.attn_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.11.fc1.weight -&gt; encoder.blocks.11.mlp.0.weight encoder.blocks.11.mlp.0.weight 2 (5120, 1280) model.encoder.layers.11.fc1.bias -&gt; encoder.blocks.11.mlp.0.bias encoder.blocks.11.mlp.0.bias 1 (5120,) Converting to float32 model.encoder.layers.11.fc2.weight -&gt; encoder.blocks.11.mlp.2.weight encoder.blocks.11.mlp.2.weight 2 (1280, 5120) model.encoder.layers.11.fc2.bias -&gt; encoder.blocks.11.mlp.2.bias encoder.blocks.11.mlp.2.bias 1 (1280,) Converting to float32 model.encoder.layers.11.final_layer_norm.weight -&gt; encoder.blocks.11.mlp_ln.weight encoder.blocks.11.mlp_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.11.final_layer_norm.bias -&gt; encoder.blocks.11.mlp_ln.bias encoder.blocks.11.mlp_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.12.self_attn.k_proj.weight -&gt; encoder.blocks.12.attn.key.weight encoder.blocks.12.attn.key.weight 2 (1280, 1280) model.encoder.layers.12.self_attn.v_proj.weight -&gt; encoder.blocks.12.attn.value.weight encoder.blocks.12.attn.value.weight 2 (1280, 1280) model.encoder.layers.12.self_attn.v_proj.bias -&gt; encoder.blocks.12.attn.value.bias encoder.blocks.12.attn.value.bias 1 (1280,) Converting to float32 model.encoder.layers.12.self_attn.q_proj.weight -&gt; encoder.blocks.12.attn.query.weight encoder.blocks.12.attn.query.weight 2 (1280, 1280) model.encoder.layers.12.self_attn.q_proj.bias -&gt; encoder.blocks.12.attn.query.bias encoder.blocks.12.attn.query.bias 1 (1280,) Converting to float32 model.encoder.layers.12.self_attn.out_proj.weight -&gt; encoder.blocks.12.attn.out.weight encoder.blocks.12.attn.out.weight 2 (1280, 1280) model.encoder.layers.12.self_attn.out_proj.bias -&gt; encoder.blocks.12.attn.out.bias encoder.blocks.12.attn.out.bias 1 (1280,) Converting to float32 model.encoder.layers.12.self_attn_layer_norm.weight -&gt; encoder.blocks.12.attn_ln.weight encoder.blocks.12.attn_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.12.self_attn_layer_norm.bias -&gt; encoder.blocks.12.attn_ln.bias encoder.blocks.12.attn_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.12.fc1.weight -&gt; encoder.blocks.12.mlp.0.weight encoder.blocks.12.mlp.0.weight 2 (5120, 1280) model.encoder.layers.12.fc1.bias -&gt; encoder.blocks.12.mlp.0.bias encoder.blocks.12.mlp.0.bias 1 (5120,) Converting to float32 model.encoder.layers.12.fc2.weight -&gt; encoder.blocks.12.mlp.2.weight encoder.blocks.12.mlp.2.weight 2 (1280, 5120) model.encoder.layers.12.fc2.bias -&gt; encoder.blocks.12.mlp.2.bias encoder.blocks.12.mlp.2.bias 1 (1280,) Converting to float32 model.encoder.layers.12.final_layer_norm.weight -&gt; encoder.blocks.12.mlp_ln.weight encoder.blocks.12.mlp_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.12.final_layer_norm.bias -&gt; encoder.blocks.12.mlp_ln.bias encoder.blocks.12.mlp_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.13.self_attn.k_proj.weight -&gt; encoder.blocks.13.attn.key.weight encoder.blocks.13.attn.key.weight 2 (1280, 1280) model.encoder.layers.13.self_attn.v_proj.weight -&gt; encoder.blocks.13.attn.value.weight encoder.blocks.13.attn.value.weight 2 (1280, 1280) model.encoder.layers.13.self_attn.v_proj.bias -&gt; encoder.blocks.13.attn.value.bias encoder.blocks.13.attn.value.bias 1 (1280,) Converting to float32 model.encoder.layers.13.self_attn.q_proj.weight -&gt; encoder.blocks.13.attn.query.weight encoder.blocks.13.attn.query.weight 2 (1280, 1280) model.encoder.layers.13.self_attn.q_proj.bias -&gt; encoder.blocks.13.attn.query.bias encoder.blocks.13.attn.query.bias 1 (1280,) Converting to float32 model.encoder.layers.13.self_attn.out_proj.weight -&gt; encoder.blocks.13.attn.out.weight encoder.blocks.13.attn.out.weight 2 (1280, 1280) model.encoder.layers.13.self_attn.out_proj.bias -&gt; encoder.blocks.13.attn.out.bias encoder.blocks.13.attn.out.bias 1 (1280,) Converting to float32 model.encoder.layers.13.self_attn_layer_norm.weight -&gt; encoder.blocks.13.attn_ln.weight encoder.blocks.13.attn_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.13.self_attn_layer_norm.bias -&gt; encoder.blocks.13.attn_ln.bias encoder.blocks.13.attn_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.13.fc1.weight -&gt; encoder.blocks.13.mlp.0.weight encoder.blocks.13.mlp.0.weight 2 (5120, 1280) model.encoder.layers.13.fc1.bias -&gt; encoder.blocks.13.mlp.0.bias encoder.blocks.13.mlp.0.bias 1 (5120,) Converting to float32 model.encoder.layers.13.fc2.weight -&gt; encoder.blocks.13.mlp.2.weight encoder.blocks.13.mlp.2.weight 2 (1280, 5120) model.encoder.layers.13.fc2.bias -&gt; encoder.blocks.13.mlp.2.bias encoder.blocks.13.mlp.2.bias 1 (1280,) Converting to float32 model.encoder.layers.13.final_layer_norm.weight -&gt; encoder.blocks.13.mlp_ln.weight encoder.blocks.13.mlp_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.13.final_layer_norm.bias -&gt; encoder.blocks.13.mlp_ln.bias encoder.blocks.13.mlp_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.14.self_attn.k_proj.weight -&gt; encoder.blocks.14.attn.key.weight encoder.blocks.14.attn.key.weight 2 (1280, 1280) model.encoder.layers.14.self_attn.v_proj.weight -&gt; encoder.blocks.14.attn.value.weight encoder.blocks.14.attn.value.weight 2 (1280, 1280) model.encoder.layers.14.self_attn.v_proj.bias -&gt; encoder.blocks.14.attn.value.bias encoder.blocks.14.attn.value.bias 1 (1280,) Converting to float32 model.encoder.layers.14.self_attn.q_proj.weight -&gt; encoder.blocks.14.attn.query.weight encoder.blocks.14.attn.query.weight 2 (1280, 1280) model.encoder.layers.14.self_attn.q_proj.bias -&gt; encoder.blocks.14.attn.query.bias encoder.blocks.14.attn.query.bias 1 (1280,) Converting to float32 model.encoder.layers.14.self_attn.out_proj.weight -&gt; encoder.blocks.14.attn.out.weight encoder.blocks.14.attn.out.weight 2 (1280, 1280) model.encoder.layers.14.self_attn.out_proj.bias -&gt; encoder.blocks.14.attn.out.bias encoder.blocks.14.attn.out.bias 1 (1280,) Converting to float32 model.encoder.layers.14.self_attn_layer_norm.weight -&gt; encoder.blocks.14.attn_ln.weight encoder.blocks.14.attn_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.14.self_attn_layer_norm.bias -&gt; encoder.blocks.14.attn_ln.bias encoder.blocks.14.attn_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.14.fc1.weight -&gt; encoder.blocks.14.mlp.0.weight encoder.blocks.14.mlp.0.weight 2 (5120, 1280) model.encoder.layers.14.fc1.bias -&gt; encoder.blocks.14.mlp.0.bias encoder.blocks.14.mlp.0.bias 1 (5120,) Converting to float32 model.encoder.layers.14.fc2.weight -&gt; encoder.blocks.14.mlp.2.weight encoder.blocks.14.mlp.2.weight 2 (1280, 5120) model.encoder.layers.14.fc2.bias -&gt; encoder.blocks.14.mlp.2.bias encoder.blocks.14.mlp.2.bias 1 (1280,) Converting to float32 model.encoder.layers.14.final_layer_norm.weight -&gt; encoder.blocks.14.mlp_ln.weight encoder.blocks.14.mlp_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.14.final_layer_norm.bias -&gt; encoder.blocks.14.mlp_ln.bias encoder.blocks.14.mlp_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.15.self_attn.k_proj.weight -&gt; encoder.blocks.15.attn.key.weight encoder.blocks.15.attn.key.weight 2 (1280, 1280) model.encoder.layers.15.self_attn.v_proj.weight -&gt; encoder.blocks.15.attn.value.weight encoder.blocks.15.attn.value.weight 2 (1280, 1280) model.encoder.layers.15.self_attn.v_proj.bias -&gt; encoder.blocks.15.attn.value.bias encoder.blocks.15.attn.value.bias 1 (1280,) Converting to float32 model.encoder.layers.15.self_attn.q_proj.weight -&gt; encoder.blocks.15.attn.query.weight encoder.blocks.15.attn.query.weight 2 (1280, 1280) model.encoder.layers.15.self_attn.q_proj.bias -&gt; encoder.blocks.15.attn.query.bias encoder.blocks.15.attn.query.bias 1 (1280,) Converting to float32 model.encoder.layers.15.self_attn.out_proj.weight -&gt; encoder.blocks.15.attn.out.weight encoder.blocks.15.attn.out.weight 2 (1280, 1280) model.encoder.layers.15.self_attn.out_proj.bias -&gt; encoder.blocks.15.attn.out.bias encoder.blocks.15.attn.out.bias 1 (1280,) Converting to float32 model.encoder.layers.15.self_attn_layer_norm.weight -&gt; encoder.blocks.15.attn_ln.weight encoder.blocks.15.attn_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.15.self_attn_layer_norm.bias -&gt; encoder.blocks.15.attn_ln.bias encoder.blocks.15.attn_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.15.fc1.weight -&gt; encoder.blocks.15.mlp.0.weight encoder.blocks.15.mlp.0.weight 2 (5120, 1280) model.encoder.layers.15.fc1.bias -&gt; encoder.blocks.15.mlp.0.bias encoder.blocks.15.mlp.0.bias 1 (5120,) Converting to float32 model.encoder.layers.15.fc2.weight -&gt; encoder.blocks.15.mlp.2.weight encoder.blocks.15.mlp.2.weight 2 (1280, 5120) model.encoder.layers.15.fc2.bias -&gt; encoder.blocks.15.mlp.2.bias encoder.blocks.15.mlp.2.bias 1 (1280,) Converting to float32 model.encoder.layers.15.final_layer_norm.weight -&gt; encoder.blocks.15.mlp_ln.weight encoder.blocks.15.mlp_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.15.final_layer_norm.bias -&gt; encoder.blocks.15.mlp_ln.bias encoder.blocks.15.mlp_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.16.self_attn.k_proj.weight -&gt; encoder.blocks.16.attn.key.weight encoder.blocks.16.attn.key.weight 2 (1280, 1280) model.encoder.layers.16.self_attn.v_proj.weight -&gt; encoder.blocks.16.attn.value.weight encoder.blocks.16.attn.value.weight 2 (1280, 1280) model.encoder.layers.16.self_attn.v_proj.bias -&gt; encoder.blocks.16.attn.value.bias encoder.blocks.16.attn.value.bias 1 (1280,) Converting to float32 model.encoder.layers.16.self_attn.q_proj.weight -&gt; encoder.blocks.16.attn.query.weight encoder.blocks.16.attn.query.weight 2 (1280, 1280) model.encoder.layers.16.self_attn.q_proj.bias -&gt; encoder.blocks.16.attn.query.bias encoder.blocks.16.attn.query.bias 1 (1280,) Converting to float32 model.encoder.layers.16.self_attn.out_proj.weight -&gt; encoder.blocks.16.attn.out.weight encoder.blocks.16.attn.out.weight 2 (1280, 1280) model.encoder.layers.16.self_attn.out_proj.bias -&gt; encoder.blocks.16.attn.out.bias encoder.blocks.16.attn.out.bias 1 (1280,) Converting to float32 model.encoder.layers.16.self_attn_layer_norm.weight -&gt; encoder.blocks.16.attn_ln.weight encoder.blocks.16.attn_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.16.self_attn_layer_norm.bias -&gt; encoder.blocks.16.attn_ln.bias encoder.blocks.16.attn_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.16.fc1.weight -&gt; encoder.blocks.16.mlp.0.weight encoder.blocks.16.mlp.0.weight 2 (5120, 1280) model.encoder.layers.16.fc1.bias -&gt; encoder.blocks.16.mlp.0.bias encoder.blocks.16.mlp.0.bias 1 (5120,) Converting to float32 model.encoder.layers.16.fc2.weight -&gt; encoder.blocks.16.mlp.2.weight encoder.blocks.16.mlp.2.weight 2 (1280, 5120) model.encoder.layers.16.fc2.bias -&gt; encoder.blocks.16.mlp.2.bias encoder.blocks.16.mlp.2.bias 1 (1280,) Converting to float32 model.encoder.layers.16.final_layer_norm.weight -&gt; encoder.blocks.16.mlp_ln.weight encoder.blocks.16.mlp_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.16.final_layer_norm.bias -&gt; encoder.blocks.16.mlp_ln.bias encoder.blocks.16.mlp_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.17.self_attn.k_proj.weight -&gt; encoder.blocks.17.attn.key.weight encoder.blocks.17.attn.key.weight 2 (1280, 1280) model.encoder.layers.17.self_attn.v_proj.weight -&gt; encoder.blocks.17.attn.value.weight encoder.blocks.17.attn.value.weight 2 (1280, 1280) model.encoder.layers.17.self_attn.v_proj.bias -&gt; encoder.blocks.17.attn.value.bias encoder.blocks.17.attn.value.bias 1 (1280,) Converting to float32 model.encoder.layers.17.self_attn.q_proj.weight -&gt; encoder.blocks.17.attn.query.weight encoder.blocks.17.attn.query.weight 2 (1280, 1280) model.encoder.layers.17.self_attn.q_proj.bias -&gt; encoder.blocks.17.attn.query.bias encoder.blocks.17.attn.query.bias 1 (1280,) Converting to float32 model.encoder.layers.17.self_attn.out_proj.weight -&gt; encoder.blocks.17.attn.out.weight encoder.blocks.17.attn.out.weight 2 (1280, 1280) model.encoder.layers.17.self_attn.out_proj.bias -&gt; encoder.blocks.17.attn.out.bias encoder.blocks.17.attn.out.bias 1 (1280,) Converting to float32 model.encoder.layers.17.self_attn_layer_norm.weight -&gt; encoder.blocks.17.attn_ln.weight encoder.blocks.17.attn_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.17.self_attn_layer_norm.bias -&gt; encoder.blocks.17.attn_ln.bias encoder.blocks.17.attn_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.17.fc1.weight -&gt; encoder.blocks.17.mlp.0.weight encoder.blocks.17.mlp.0.weight 2 (5120, 1280) model.encoder.layers.17.fc1.bias -&gt; encoder.blocks.17.mlp.0.bias encoder.blocks.17.mlp.0.bias 1 (5120,) Converting to float32 model.encoder.layers.17.fc2.weight -&gt; encoder.blocks.17.mlp.2.weight encoder.blocks.17.mlp.2.weight 2 (1280, 5120) model.encoder.layers.17.fc2.bias -&gt; encoder.blocks.17.mlp.2.bias encoder.blocks.17.mlp.2.bias 1 (1280,) Converting to float32 model.encoder.layers.17.final_layer_norm.weight -&gt; encoder.blocks.17.mlp_ln.weight encoder.blocks.17.mlp_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.17.final_layer_norm.bias -&gt; encoder.blocks.17.mlp_ln.bias encoder.blocks.17.mlp_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.18.self_attn.k_proj.weight -&gt; encoder.blocks.18.attn.key.weight encoder.blocks.18.attn.key.weight 2 (1280, 1280) model.encoder.layers.18.self_attn.v_proj.weight -&gt; encoder.blocks.18.attn.value.weight encoder.blocks.18.attn.value.weight 2 (1280, 1280) model.encoder.layers.18.self_attn.v_proj.bias -&gt; encoder.blocks.18.attn.value.bias encoder.blocks.18.attn.value.bias 1 (1280,) Converting to float32 model.encoder.layers.18.self_attn.q_proj.weight -&gt; encoder.blocks.18.attn.query.weight encoder.blocks.18.attn.query.weight 2 (1280, 1280) model.encoder.layers.18.self_attn.q_proj.bias -&gt; encoder.blocks.18.attn.query.bias encoder.blocks.18.attn.query.bias 1 (1280,) Converting to float32 model.encoder.layers.18.self_attn.out_proj.weight -&gt; encoder.blocks.18.attn.out.weight encoder.blocks.18.attn.out.weight 2 (1280, 1280) model.encoder.layers.18.self_attn.out_proj.bias -&gt; encoder.blocks.18.attn.out.bias encoder.blocks.18.attn.out.bias 1 (1280,) Converting to float32 model.encoder.layers.18.self_attn_layer_norm.weight -&gt; encoder.blocks.18.attn_ln.weight encoder.blocks.18.attn_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.18.self_attn_layer_norm.bias -&gt; encoder.blocks.18.attn_ln.bias encoder.blocks.18.attn_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.18.fc1.weight -&gt; encoder.blocks.18.mlp.0.weight encoder.blocks.18.mlp.0.weight 2 (5120, 1280) model.encoder.layers.18.fc1.bias -&gt; encoder.blocks.18.mlp.0.bias encoder.blocks.18.mlp.0.bias 1 (5120,) Converting to float32 model.encoder.layers.18.fc2.weight -&gt; encoder.blocks.18.mlp.2.weight encoder.blocks.18.mlp.2.weight 2 (1280, 5120) model.encoder.layers.18.fc2.bias -&gt; encoder.blocks.18.mlp.2.bias encoder.blocks.18.mlp.2.bias 1 (1280,) Converting to float32 model.encoder.layers.18.final_layer_norm.weight -&gt; encoder.blocks.18.mlp_ln.weight encoder.blocks.18.mlp_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.18.final_layer_norm.bias -&gt; encoder.blocks.18.mlp_ln.bias encoder.blocks.18.mlp_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.19.self_attn.k_proj.weight -&gt; encoder.blocks.19.attn.key.weight encoder.blocks.19.attn.key.weight 2 (1280, 1280) model.encoder.layers.19.self_attn.v_proj.weight -&gt; encoder.blocks.19.attn.value.weight encoder.blocks.19.attn.value.weight 2 (1280, 1280) model.encoder.layers.19.self_attn.v_proj.bias -&gt; encoder.blocks.19.attn.value.bias encoder.blocks.19.attn.value.bias 1 (1280,) Converting to float32 model.encoder.layers.19.self_attn.q_proj.weight -&gt; encoder.blocks.19.attn.query.weight encoder.blocks.19.attn.query.weight 2 (1280, 1280) model.encoder.layers.19.self_attn.q_proj.bias -&gt; encoder.blocks.19.attn.query.bias encoder.blocks.19.attn.query.bias 1 (1280,) Converting to float32 model.encoder.layers.19.self_attn.out_proj.weight -&gt; encoder.blocks.19.attn.out.weight encoder.blocks.19.attn.out.weight 2 (1280, 1280) model.encoder.layers.19.self_attn.out_proj.bias -&gt; encoder.blocks.19.attn.out.bias encoder.blocks.19.attn.out.bias 1 (1280,) Converting to float32 model.encoder.layers.19.self_attn_layer_norm.weight -&gt; encoder.blocks.19.attn_ln.weight encoder.blocks.19.attn_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.19.self_attn_layer_norm.bias -&gt; encoder.blocks.19.attn_ln.bias encoder.blocks.19.attn_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.19.fc1.weight -&gt; encoder.blocks.19.mlp.0.weight encoder.blocks.19.mlp.0.weight 2 (5120, 1280) model.encoder.layers.19.fc1.bias -&gt; encoder.blocks.19.mlp.0.bias encoder.blocks.19.mlp.0.bias 1 (5120,) Converting to float32 model.encoder.layers.19.fc2.weight -&gt; encoder.blocks.19.mlp.2.weight encoder.blocks.19.mlp.2.weight 2 (1280, 5120) model.encoder.layers.19.fc2.bias -&gt; encoder.blocks.19.mlp.2.bias encoder.blocks.19.mlp.2.bias 1 (1280,) Converting to float32 model.encoder.layers.19.final_layer_norm.weight -&gt; encoder.blocks.19.mlp_ln.weight encoder.blocks.19.mlp_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.19.final_layer_norm.bias -&gt; encoder.blocks.19.mlp_ln.bias encoder.blocks.19.mlp_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.20.self_attn.k_proj.weight -&gt; encoder.blocks.20.attn.key.weight encoder.blocks.20.attn.key.weight 2 (1280, 1280) model.encoder.layers.20.self_attn.v_proj.weight -&gt; encoder.blocks.20.attn.value.weight encoder.blocks.20.attn.value.weight 2 (1280, 1280) model.encoder.layers.20.self_attn.v_proj.bias -&gt; encoder.blocks.20.attn.value.bias encoder.blocks.20.attn.value.bias 1 (1280,) Converting to float32 model.encoder.layers.20.self_attn.q_proj.weight -&gt; encoder.blocks.20.attn.query.weight encoder.blocks.20.attn.query.weight 2 (1280, 1280) model.encoder.layers.20.self_attn.q_proj.bias -&gt; encoder.blocks.20.attn.query.bias encoder.blocks.20.attn.query.bias 1 (1280,) Converting to float32 model.encoder.layers.20.self_attn.out_proj.weight -&gt; encoder.blocks.20.attn.out.weight encoder.blocks.20.attn.out.weight 2 (1280, 1280) model.encoder.layers.20.self_attn.out_proj.bias -&gt; encoder.blocks.20.attn.out.bias encoder.blocks.20.attn.out.bias 1 (1280,) Converting to float32 model.encoder.layers.20.self_attn_layer_norm.weight -&gt; encoder.blocks.20.attn_ln.weight encoder.blocks.20.attn_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.20.self_attn_layer_norm.bias -&gt; encoder.blocks.20.attn_ln.bias encoder.blocks.20.attn_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.20.fc1.weight -&gt; encoder.blocks.20.mlp.0.weight encoder.blocks.20.mlp.0.weight 2 (5120, 1280) model.encoder.layers.20.fc1.bias -&gt; encoder.blocks.20.mlp.0.bias encoder.blocks.20.mlp.0.bias 1 (5120,) Converting to float32 model.encoder.layers.20.fc2.weight -&gt; encoder.blocks.20.mlp.2.weight encoder.blocks.20.mlp.2.weight 2 (1280, 5120) model.encoder.layers.20.fc2.bias -&gt; encoder.blocks.20.mlp.2.bias encoder.blocks.20.mlp.2.bias 1 (1280,) Converting to float32 model.encoder.layers.20.final_layer_norm.weight -&gt; encoder.blocks.20.mlp_ln.weight encoder.blocks.20.mlp_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.20.final_layer_norm.bias -&gt; encoder.blocks.20.mlp_ln.bias encoder.blocks.20.mlp_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.21.self_attn.k_proj.weight -&gt; encoder.blocks.21.attn.key.weight encoder.blocks.21.attn.key.weight 2 (1280, 1280) model.encoder.layers.21.self_attn.v_proj.weight -&gt; encoder.blocks.21.attn.value.weight encoder.blocks.21.attn.value.weight 2 (1280, 1280) model.encoder.layers.21.self_attn.v_proj.bias -&gt; encoder.blocks.21.attn.value.bias encoder.blocks.21.attn.value.bias 1 (1280,) Converting to float32 model.encoder.layers.21.self_attn.q_proj.weight -&gt; encoder.blocks.21.attn.query.weight encoder.blocks.21.attn.query.weight 2 (1280, 1280) model.encoder.layers.21.self_attn.q_proj.bias -&gt; encoder.blocks.21.attn.query.bias encoder.blocks.21.attn.query.bias 1 (1280,) Converting to float32 model.encoder.layers.21.self_attn.out_proj.weight -&gt; encoder.blocks.21.attn.out.weight encoder.blocks.21.attn.out.weight 2 (1280, 1280) model.encoder.layers.21.self_attn.out_proj.bias -&gt; encoder.blocks.21.attn.out.bias encoder.blocks.21.attn.out.bias 1 (1280,) Converting to float32 model.encoder.layers.21.self_attn_layer_norm.weight -&gt; encoder.blocks.21.attn_ln.weight encoder.blocks.21.attn_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.21.self_attn_layer_norm.bias -&gt; encoder.blocks.21.attn_ln.bias encoder.blocks.21.attn_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.21.fc1.weight -&gt; encoder.blocks.21.mlp.0.weight encoder.blocks.21.mlp.0.weight 2 (5120, 1280) model.encoder.layers.21.fc1.bias -&gt; encoder.blocks.21.mlp.0.bias encoder.blocks.21.mlp.0.bias 1 (5120,) Converting to float32 model.encoder.layers.21.fc2.weight -&gt; encoder.blocks.21.mlp.2.weight encoder.blocks.21.mlp.2.weight 2 (1280, 5120) model.encoder.layers.21.fc2.bias -&gt; encoder.blocks.21.mlp.2.bias encoder.blocks.21.mlp.2.bias 1 (1280,) Converting to float32 model.encoder.layers.21.final_layer_norm.weight -&gt; encoder.blocks.21.mlp_ln.weight encoder.blocks.21.mlp_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.21.final_layer_norm.bias -&gt; encoder.blocks.21.mlp_ln.bias encoder.blocks.21.mlp_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.22.self_attn.k_proj.weight -&gt; encoder.blocks.22.attn.key.weight encoder.blocks.22.attn.key.weight 2 (1280, 1280) model.encoder.layers.22.self_attn.v_proj.weight -&gt; encoder.blocks.22.attn.value.weight encoder.blocks.22.attn.value.weight 2 (1280, 1280) model.encoder.layers.22.self_attn.v_proj.bias -&gt; encoder.blocks.22.attn.value.bias encoder.blocks.22.attn.value.bias 1 (1280,) Converting to float32 model.encoder.layers.22.self_attn.q_proj.weight -&gt; encoder.blocks.22.attn.query.weight encoder.blocks.22.attn.query.weight 2 (1280, 1280) model.encoder.layers.22.self_attn.q_proj.bias -&gt; encoder.blocks.22.attn.query.bias encoder.blocks.22.attn.query.bias 1 (1280,) Converting to float32 model.encoder.layers.22.self_attn.out_proj.weight -&gt; encoder.blocks.22.attn.out.weight encoder.blocks.22.attn.out.weight 2 (1280, 1280) model.encoder.layers.22.self_attn.out_proj.bias -&gt; encoder.blocks.22.attn.out.bias encoder.blocks.22.attn.out.bias 1 (1280,) Converting to float32 model.encoder.layers.22.self_attn_layer_norm.weight -&gt; encoder.blocks.22.attn_ln.weight encoder.blocks.22.attn_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.22.self_attn_layer_norm.bias -&gt; encoder.blocks.22.attn_ln.bias encoder.blocks.22.attn_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.22.fc1.weight -&gt; encoder.blocks.22.mlp.0.weight encoder.blocks.22.mlp.0.weight 2 (5120, 1280) model.encoder.layers.22.fc1.bias -&gt; encoder.blocks.22.mlp.0.bias encoder.blocks.22.mlp.0.bias 1 (5120,) Converting to float32 model.encoder.layers.22.fc2.weight -&gt; encoder.blocks.22.mlp.2.weight encoder.blocks.22.mlp.2.weight 2 (1280, 5120) model.encoder.layers.22.fc2.bias -&gt; encoder.blocks.22.mlp.2.bias encoder.blocks.22.mlp.2.bias 1 (1280,) Converting to float32 model.encoder.layers.22.final_layer_norm.weight -&gt; encoder.blocks.22.mlp_ln.weight encoder.blocks.22.mlp_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.22.final_layer_norm.bias -&gt; encoder.blocks.22.mlp_ln.bias encoder.blocks.22.mlp_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.23.self_attn.k_proj.weight -&gt; encoder.blocks.23.attn.key.weight encoder.blocks.23.attn.key.weight 2 (1280, 1280) model.encoder.layers.23.self_attn.v_proj.weight -&gt; encoder.blocks.23.attn.value.weight encoder.blocks.23.attn.value.weight 2 (1280, 1280) model.encoder.layers.23.self_attn.v_proj.bias -&gt; encoder.blocks.23.attn.value.bias encoder.blocks.23.attn.value.bias 1 (1280,) Converting to float32 model.encoder.layers.23.self_attn.q_proj.weight -&gt; encoder.blocks.23.attn.query.weight encoder.blocks.23.attn.query.weight 2 (1280, 1280) model.encoder.layers.23.self_attn.q_proj.bias -&gt; encoder.blocks.23.attn.query.bias encoder.blocks.23.attn.query.bias 1 (1280,) Converting to float32 model.encoder.layers.23.self_attn.out_proj.weight -&gt; encoder.blocks.23.attn.out.weight encoder.blocks.23.attn.out.weight 2 (1280, 1280) model.encoder.layers.23.self_attn.out_proj.bias -&gt; encoder.blocks.23.attn.out.bias encoder.blocks.23.attn.out.bias 1 (1280,) Converting to float32 model.encoder.layers.23.self_attn_layer_norm.weight -&gt; encoder.blocks.23.attn_ln.weight encoder.blocks.23.attn_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.23.self_attn_layer_norm.bias -&gt; encoder.blocks.23.attn_ln.bias encoder.blocks.23.attn_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.23.fc1.weight -&gt; encoder.blocks.23.mlp.0.weight encoder.blocks.23.mlp.0.weight 2 (5120, 1280) model.encoder.layers.23.fc1.bias -&gt; encoder.blocks.23.mlp.0.bias encoder.blocks.23.mlp.0.bias 1 (5120,) Converting to float32 model.encoder.layers.23.fc2.weight -&gt; encoder.blocks.23.mlp.2.weight encoder.blocks.23.mlp.2.weight 2 (1280, 5120) model.encoder.layers.23.fc2.bias -&gt; encoder.blocks.23.mlp.2.bias encoder.blocks.23.mlp.2.bias 1 (1280,) Converting to float32 model.encoder.layers.23.final_layer_norm.weight -&gt; encoder.blocks.23.mlp_ln.weight encoder.blocks.23.mlp_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.23.final_layer_norm.bias -&gt; encoder.blocks.23.mlp_ln.bias encoder.blocks.23.mlp_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.24.self_attn.k_proj.weight -&gt; encoder.blocks.24.attn.key.weight encoder.blocks.24.attn.key.weight 2 (1280, 1280) model.encoder.layers.24.self_attn.v_proj.weight -&gt; encoder.blocks.24.attn.value.weight encoder.blocks.24.attn.value.weight 2 (1280, 1280) model.encoder.layers.24.self_attn.v_proj.bias -&gt; encoder.blocks.24.attn.value.bias encoder.blocks.24.attn.value.bias 1 (1280,) Converting to float32 model.encoder.layers.24.self_attn.q_proj.weight -&gt; encoder.blocks.24.attn.query.weight encoder.blocks.24.attn.query.weight 2 (1280, 1280) model.encoder.layers.24.self_attn.q_proj.bias -&gt; encoder.blocks.24.attn.query.bias encoder.blocks.24.attn.query.bias 1 (1280,) Converting to float32 model.encoder.layers.24.self_attn.out_proj.weight -&gt; encoder.blocks.24.attn.out.weight encoder.blocks.24.attn.out.weight 2 (1280, 1280) model.encoder.layers.24.self_attn.out_proj.bias -&gt; encoder.blocks.24.attn.out.bias encoder.blocks.24.attn.out.bias 1 (1280,) Converting to float32 model.encoder.layers.24.self_attn_layer_norm.weight -&gt; encoder.blocks.24.attn_ln.weight encoder.blocks.24.attn_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.24.self_attn_layer_norm.bias -&gt; encoder.blocks.24.attn_ln.bias encoder.blocks.24.attn_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.24.fc1.weight -&gt; encoder.blocks.24.mlp.0.weight encoder.blocks.24.mlp.0.weight 2 (5120, 1280) model.encoder.layers.24.fc1.bias -&gt; encoder.blocks.24.mlp.0.bias encoder.blocks.24.mlp.0.bias 1 (5120,) Converting to float32 model.encoder.layers.24.fc2.weight -&gt; encoder.blocks.24.mlp.2.weight encoder.blocks.24.mlp.2.weight 2 (1280, 5120) model.encoder.layers.24.fc2.bias -&gt; encoder.blocks.24.mlp.2.bias encoder.blocks.24.mlp.2.bias 1 (1280,) Converting to float32 model.encoder.layers.24.final_layer_norm.weight -&gt; encoder.blocks.24.mlp_ln.weight encoder.blocks.24.mlp_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.24.final_layer_norm.bias -&gt; encoder.blocks.24.mlp_ln.bias encoder.blocks.24.mlp_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.25.self_attn.k_proj.weight -&gt; encoder.blocks.25.attn.key.weight encoder.blocks.25.attn.key.weight 2 (1280, 1280) model.encoder.layers.25.self_attn.v_proj.weight -&gt; encoder.blocks.25.attn.value.weight encoder.blocks.25.attn.value.weight 2 (1280, 1280) model.encoder.layers.25.self_attn.v_proj.bias -&gt; encoder.blocks.25.attn.value.bias encoder.blocks.25.attn.value.bias 1 (1280,) Converting to float32 model.encoder.layers.25.self_attn.q_proj.weight -&gt; encoder.blocks.25.attn.query.weight encoder.blocks.25.attn.query.weight 2 (1280, 1280) model.encoder.layers.25.self_attn.q_proj.bias -&gt; encoder.blocks.25.attn.query.bias encoder.blocks.25.attn.query.bias 1 (1280,) Converting to float32 model.encoder.layers.25.self_attn.out_proj.weight -&gt; encoder.blocks.25.attn.out.weight encoder.blocks.25.attn.out.weight 2 (1280, 1280) model.encoder.layers.25.self_attn.out_proj.bias -&gt; encoder.blocks.25.attn.out.bias encoder.blocks.25.attn.out.bias 1 (1280,) Converting to float32 model.encoder.layers.25.self_attn_layer_norm.weight -&gt; encoder.blocks.25.attn_ln.weight encoder.blocks.25.attn_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.25.self_attn_layer_norm.bias -&gt; encoder.blocks.25.attn_ln.bias encoder.blocks.25.attn_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.25.fc1.weight -&gt; encoder.blocks.25.mlp.0.weight encoder.blocks.25.mlp.0.weight 2 (5120, 1280) model.encoder.layers.25.fc1.bias -&gt; encoder.blocks.25.mlp.0.bias encoder.blocks.25.mlp.0.bias 1 (5120,) Converting to float32 model.encoder.layers.25.fc2.weight -&gt; encoder.blocks.25.mlp.2.weight encoder.blocks.25.mlp.2.weight 2 (1280, 5120) model.encoder.layers.25.fc2.bias -&gt; encoder.blocks.25.mlp.2.bias encoder.blocks.25.mlp.2.bias 1 (1280,) Converting to float32 model.encoder.layers.25.final_layer_norm.weight -&gt; encoder.blocks.25.mlp_ln.weight encoder.blocks.25.mlp_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.25.final_layer_norm.bias -&gt; encoder.blocks.25.mlp_ln.bias encoder.blocks.25.mlp_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.26.self_attn.k_proj.weight -&gt; encoder.blocks.26.attn.key.weight encoder.blocks.26.attn.key.weight 2 (1280, 1280) model.encoder.layers.26.self_attn.v_proj.weight -&gt; encoder.blocks.26.attn.value.weight encoder.blocks.26.attn.value.weight 2 (1280, 1280) model.encoder.layers.26.self_attn.v_proj.bias -&gt; encoder.blocks.26.attn.value.bias encoder.blocks.26.attn.value.bias 1 (1280,) Converting to float32 model.encoder.layers.26.self_attn.q_proj.weight -&gt; encoder.blocks.26.attn.query.weight encoder.blocks.26.attn.query.weight 2 (1280, 1280) model.encoder.layers.26.self_attn.q_proj.bias -&gt; encoder.blocks.26.attn.query.bias encoder.blocks.26.attn.query.bias 1 (1280,) Converting to float32 model.encoder.layers.26.self_attn.out_proj.weight -&gt; encoder.blocks.26.attn.out.weight encoder.blocks.26.attn.out.weight 2 (1280, 1280) model.encoder.layers.26.self_attn.out_proj.bias -&gt; encoder.blocks.26.attn.out.bias encoder.blocks.26.attn.out.bias 1 (1280,) Converting to float32 model.encoder.layers.26.self_attn_layer_norm.weight -&gt; encoder.blocks.26.attn_ln.weight encoder.blocks.26.attn_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.26.self_attn_layer_norm.bias -&gt; encoder.blocks.26.attn_ln.bias encoder.blocks.26.attn_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.26.fc1.weight -&gt; encoder.blocks.26.mlp.0.weight encoder.blocks.26.mlp.0.weight 2 (5120, 1280) model.encoder.layers.26.fc1.bias -&gt; encoder.blocks.26.mlp.0.bias encoder.blocks.26.mlp.0.bias 1 (5120,) Converting to float32 model.encoder.layers.26.fc2.weight -&gt; encoder.blocks.26.mlp.2.weight encoder.blocks.26.mlp.2.weight 2 (1280, 5120) model.encoder.layers.26.fc2.bias -&gt; encoder.blocks.26.mlp.2.bias encoder.blocks.26.mlp.2.bias 1 (1280,) Converting to float32 model.encoder.layers.26.final_layer_norm.weight -&gt; encoder.blocks.26.mlp_ln.weight encoder.blocks.26.mlp_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.26.final_layer_norm.bias -&gt; encoder.blocks.26.mlp_ln.bias encoder.blocks.26.mlp_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.27.self_attn.k_proj.weight -&gt; encoder.blocks.27.attn.key.weight encoder.blocks.27.attn.key.weight 2 (1280, 1280) model.encoder.layers.27.self_attn.v_proj.weight -&gt; encoder.blocks.27.attn.value.weight encoder.blocks.27.attn.value.weight 2 (1280, 1280) model.encoder.layers.27.self_attn.v_proj.bias -&gt; encoder.blocks.27.attn.value.bias encoder.blocks.27.attn.value.bias 1 (1280,) Converting to float32 model.encoder.layers.27.self_attn.q_proj.weight -&gt; encoder.blocks.27.attn.query.weight encoder.blocks.27.attn.query.weight 2 (1280, 1280) model.encoder.layers.27.self_attn.q_proj.bias -&gt; encoder.blocks.27.attn.query.bias encoder.blocks.27.attn.query.bias 1 (1280,) Converting to float32 model.encoder.layers.27.self_attn.out_proj.weight -&gt; encoder.blocks.27.attn.out.weight encoder.blocks.27.attn.out.weight 2 (1280, 1280) model.encoder.layers.27.self_attn.out_proj.bias -&gt; encoder.blocks.27.attn.out.bias encoder.blocks.27.attn.out.bias 1 (1280,) Converting to float32 model.encoder.layers.27.self_attn_layer_norm.weight -&gt; encoder.blocks.27.attn_ln.weight encoder.blocks.27.attn_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.27.self_attn_layer_norm.bias -&gt; encoder.blocks.27.attn_ln.bias encoder.blocks.27.attn_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.27.fc1.weight -&gt; encoder.blocks.27.mlp.0.weight encoder.blocks.27.mlp.0.weight 2 (5120, 1280) model.encoder.layers.27.fc1.bias -&gt; encoder.blocks.27.mlp.0.bias encoder.blocks.27.mlp.0.bias 1 (5120,) Converting to float32 model.encoder.layers.27.fc2.weight -&gt; encoder.blocks.27.mlp.2.weight encoder.blocks.27.mlp.2.weight 2 (1280, 5120) model.encoder.layers.27.fc2.bias -&gt; encoder.blocks.27.mlp.2.bias encoder.blocks.27.mlp.2.bias 1 (1280,) Converting to float32 model.encoder.layers.27.final_layer_norm.weight -&gt; encoder.blocks.27.mlp_ln.weight encoder.blocks.27.mlp_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.27.final_layer_norm.bias -&gt; encoder.blocks.27.mlp_ln.bias encoder.blocks.27.mlp_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.28.self_attn.k_proj.weight -&gt; encoder.blocks.28.attn.key.weight encoder.blocks.28.attn.key.weight 2 (1280, 1280) model.encoder.layers.28.self_attn.v_proj.weight -&gt; encoder.blocks.28.attn.value.weight encoder.blocks.28.attn.value.weight 2 (1280, 1280) model.encoder.layers.28.self_attn.v_proj.bias -&gt; encoder.blocks.28.attn.value.bias encoder.blocks.28.attn.value.bias 1 (1280,) Converting to float32 model.encoder.layers.28.self_attn.q_proj.weight -&gt; encoder.blocks.28.attn.query.weight encoder.blocks.28.attn.query.weight 2 (1280, 1280) model.encoder.layers.28.self_attn.q_proj.bias -&gt; encoder.blocks.28.attn.query.bias encoder.blocks.28.attn.query.bias 1 (1280,) Converting to float32 model.encoder.layers.28.self_attn.out_proj.weight -&gt; encoder.blocks.28.attn.out.weight encoder.blocks.28.attn.out.weight 2 (1280, 1280) model.encoder.layers.28.self_attn.out_proj.bias -&gt; encoder.blocks.28.attn.out.bias encoder.blocks.28.attn.out.bias 1 (1280,) Converting to float32 model.encoder.layers.28.self_attn_layer_norm.weight -&gt; encoder.blocks.28.attn_ln.weight encoder.blocks.28.attn_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.28.self_attn_layer_norm.bias -&gt; encoder.blocks.28.attn_ln.bias encoder.blocks.28.attn_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.28.fc1.weight -&gt; encoder.blocks.28.mlp.0.weight encoder.blocks.28.mlp.0.weight 2 (5120, 1280) model.encoder.layers.28.fc1.bias -&gt; encoder.blocks.28.mlp.0.bias encoder.blocks.28.mlp.0.bias 1 (5120,) Converting to float32 model.encoder.layers.28.fc2.weight -&gt; encoder.blocks.28.mlp.2.weight encoder.blocks.28.mlp.2.weight 2 (1280, 5120) model.encoder.layers.28.fc2.bias -&gt; encoder.blocks.28.mlp.2.bias encoder.blocks.28.mlp.2.bias 1 (1280,) Converting to float32 model.encoder.layers.28.final_layer_norm.weight -&gt; encoder.blocks.28.mlp_ln.weight encoder.blocks.28.mlp_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.28.final_layer_norm.bias -&gt; encoder.blocks.28.mlp_ln.bias encoder.blocks.28.mlp_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.29.self_attn.k_proj.weight -&gt; encoder.blocks.29.attn.key.weight encoder.blocks.29.attn.key.weight 2 (1280, 1280) model.encoder.layers.29.self_attn.v_proj.weight -&gt; encoder.blocks.29.attn.value.weight encoder.blocks.29.attn.value.weight 2 (1280, 1280) model.encoder.layers.29.self_attn.v_proj.bias -&gt; encoder.blocks.29.attn.value.bias encoder.blocks.29.attn.value.bias 1 (1280,) Converting to float32 model.encoder.layers.29.self_attn.q_proj.weight -&gt; encoder.blocks.29.attn.query.weight encoder.blocks.29.attn.query.weight 2 (1280, 1280) model.encoder.layers.29.self_attn.q_proj.bias -&gt; encoder.blocks.29.attn.query.bias encoder.blocks.29.attn.query.bias 1 (1280,) Converting to float32 model.encoder.layers.29.self_attn.out_proj.weight -&gt; encoder.blocks.29.attn.out.weight encoder.blocks.29.attn.out.weight 2 (1280, 1280) model.encoder.layers.29.self_attn.out_proj.bias -&gt; encoder.blocks.29.attn.out.bias encoder.blocks.29.attn.out.bias 1 (1280,) Converting to float32 model.encoder.layers.29.self_attn_layer_norm.weight -&gt; encoder.blocks.29.attn_ln.weight encoder.blocks.29.attn_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.29.self_attn_layer_norm.bias -&gt; encoder.blocks.29.attn_ln.bias encoder.blocks.29.attn_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.29.fc1.weight -&gt; encoder.blocks.29.mlp.0.weight encoder.blocks.29.mlp.0.weight 2 (5120, 1280) model.encoder.layers.29.fc1.bias -&gt; encoder.blocks.29.mlp.0.bias encoder.blocks.29.mlp.0.bias 1 (5120,) Converting to float32 model.encoder.layers.29.fc2.weight -&gt; encoder.blocks.29.mlp.2.weight encoder.blocks.29.mlp.2.weight 2 (1280, 5120) model.encoder.layers.29.fc2.bias -&gt; encoder.blocks.29.mlp.2.bias encoder.blocks.29.mlp.2.bias 1 (1280,) Converting to float32 model.encoder.layers.29.final_layer_norm.weight -&gt; encoder.blocks.29.mlp_ln.weight encoder.blocks.29.mlp_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.29.final_layer_norm.bias -&gt; encoder.blocks.29.mlp_ln.bias encoder.blocks.29.mlp_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.30.self_attn.k_proj.weight -&gt; encoder.blocks.30.attn.key.weight encoder.blocks.30.attn.key.weight 2 (1280, 1280) model.encoder.layers.30.self_attn.v_proj.weight -&gt; encoder.blocks.30.attn.value.weight encoder.blocks.30.attn.value.weight 2 (1280, 1280) model.encoder.layers.30.self_attn.v_proj.bias -&gt; encoder.blocks.30.attn.value.bias encoder.blocks.30.attn.value.bias 1 (1280,) Converting to float32 model.encoder.layers.30.self_attn.q_proj.weight -&gt; encoder.blocks.30.attn.query.weight encoder.blocks.30.attn.query.weight 2 (1280, 1280) model.encoder.layers.30.self_attn.q_proj.bias -&gt; encoder.blocks.30.attn.query.bias encoder.blocks.30.attn.query.bias 1 (1280,) Converting to float32 model.encoder.layers.30.self_attn.out_proj.weight -&gt; encoder.blocks.30.attn.out.weight encoder.blocks.30.attn.out.weight 2 (1280, 1280) model.encoder.layers.30.self_attn.out_proj.bias -&gt; encoder.blocks.30.attn.out.bias encoder.blocks.30.attn.out.bias 1 (1280,) Converting to float32 model.encoder.layers.30.self_attn_layer_norm.weight -&gt; encoder.blocks.30.attn_ln.weight encoder.blocks.30.attn_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.30.self_attn_layer_norm.bias -&gt; encoder.blocks.30.attn_ln.bias encoder.blocks.30.attn_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.30.fc1.weight -&gt; encoder.blocks.30.mlp.0.weight encoder.blocks.30.mlp.0.weight 2 (5120, 1280) model.encoder.layers.30.fc1.bias -&gt; encoder.blocks.30.mlp.0.bias encoder.blocks.30.mlp.0.bias 1 (5120,) Converting to float32 model.encoder.layers.30.fc2.weight -&gt; encoder.blocks.30.mlp.2.weight encoder.blocks.30.mlp.2.weight 2 (1280, 5120) model.encoder.layers.30.fc2.bias -&gt; encoder.blocks.30.mlp.2.bias encoder.blocks.30.mlp.2.bias 1 (1280,) Converting to float32 model.encoder.layers.30.final_layer_norm.weight -&gt; encoder.blocks.30.mlp_ln.weight encoder.blocks.30.mlp_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.30.final_layer_norm.bias -&gt; encoder.blocks.30.mlp_ln.bias encoder.blocks.30.mlp_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.31.self_attn.k_proj.weight -&gt; encoder.blocks.31.attn.key.weight encoder.blocks.31.attn.key.weight 2 (1280, 1280) model.encoder.layers.31.self_attn.v_proj.weight -&gt; encoder.blocks.31.attn.value.weight encoder.blocks.31.attn.value.weight 2 (1280, 1280) model.encoder.layers.31.self_attn.v_proj.bias -&gt; encoder.blocks.31.attn.value.bias encoder.blocks.31.attn.value.bias 1 (1280,) Converting to float32 model.encoder.layers.31.self_attn.q_proj.weight -&gt; encoder.blocks.31.attn.query.weight encoder.blocks.31.attn.query.weight 2 (1280, 1280) model.encoder.layers.31.self_attn.q_proj.bias -&gt; encoder.blocks.31.attn.query.bias encoder.blocks.31.attn.query.bias 1 (1280,) Converting to float32 model.encoder.layers.31.self_attn.out_proj.weight -&gt; encoder.blocks.31.attn.out.weight encoder.blocks.31.attn.out.weight 2 (1280, 1280) model.encoder.layers.31.self_attn.out_proj.bias -&gt; encoder.blocks.31.attn.out.bias encoder.blocks.31.attn.out.bias 1 (1280,) Converting to float32 model.encoder.layers.31.self_attn_layer_norm.weight -&gt; encoder.blocks.31.attn_ln.weight encoder.blocks.31.attn_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.31.self_attn_layer_norm.bias -&gt; encoder.blocks.31.attn_ln.bias encoder.blocks.31.attn_ln.bias 1 (1280,) Converting to float32 model.encoder.layers.31.fc1.weight -&gt; encoder.blocks.31.mlp.0.weight encoder.blocks.31.mlp.0.weight 2 (5120, 1280) model.encoder.layers.31.fc1.bias -&gt; encoder.blocks.31.mlp.0.bias encoder.blocks.31.mlp.0.bias 1 (5120,) Converting to float32 model.encoder.layers.31.fc2.weight -&gt; encoder.blocks.31.mlp.2.weight encoder.blocks.31.mlp.2.weight 2 (1280, 5120) model.encoder.layers.31.fc2.bias -&gt; encoder.blocks.31.mlp.2.bias encoder.blocks.31.mlp.2.bias 1 (1280,) Converting to float32 model.encoder.layers.31.final_layer_norm.weight -&gt; encoder.blocks.31.mlp_ln.weight encoder.blocks.31.mlp_ln.weight 1 (1280,) Converting to float32 model.encoder.layers.31.final_layer_norm.bias -&gt; encoder.blocks.31.mlp_ln.bias encoder.blocks.31.mlp_ln.bias 1 (1280,) Converting to float32 model.encoder.layer_norm.weight -&gt; encoder.ln_post.weight encoder.ln_post.weight 1 (1280,) Converting to float32 model.encoder.layer_norm.bias -&gt; encoder.ln_post.bias encoder.ln_post.bias 1 (1280,) Converting to float32 model.decoder.embed_tokens.weight -&gt; decoder.token_embedding.weight decoder.token_embedding.weight 2 (51865, 1280) model.decoder.embed_positions.weight -&gt; decoder.positional_embedding decoder.positional_embedding 2 (448, 1280) Converting to float32 model.decoder.layers.0.self_attn.k_proj.weight -&gt; decoder.blocks.0.attn.key.weight decoder.blocks.0.attn.key.weight 2 (1280, 1280) model.decoder.layers.0.self_attn.v_proj.weight -&gt; decoder.blocks.0.attn.value.weight decoder.blocks.0.attn.value.weight 2 (1280, 1280) model.decoder.layers.0.self_attn.v_proj.bias -&gt; decoder.blocks.0.attn.value.bias decoder.blocks.0.attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.0.self_attn.q_proj.weight -&gt; decoder.blocks.0.attn.query.weight decoder.blocks.0.attn.query.weight 2 (1280, 1280) model.decoder.layers.0.self_attn.q_proj.bias -&gt; decoder.blocks.0.attn.query.bias decoder.blocks.0.attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.0.self_attn.out_proj.weight -&gt; decoder.blocks.0.attn.out.weight decoder.blocks.0.attn.out.weight 2 (1280, 1280) model.decoder.layers.0.self_attn.out_proj.bias -&gt; decoder.blocks.0.attn.out.bias decoder.blocks.0.attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.0.self_attn_layer_norm.weight -&gt; decoder.blocks.0.attn_ln.weight decoder.blocks.0.attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.0.self_attn_layer_norm.bias -&gt; decoder.blocks.0.attn_ln.bias decoder.blocks.0.attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.0.encoder_attn.k_proj.weight -&gt; decoder.blocks.0.cross_attn.key.weight decoder.blocks.0.cross_attn.key.weight 2 (1280, 1280) model.decoder.layers.0.encoder_attn.v_proj.weight -&gt; decoder.blocks.0.cross_attn.value.weight decoder.blocks.0.cross_attn.value.weight 2 (1280, 1280) model.decoder.layers.0.encoder_attn.v_proj.bias -&gt; decoder.blocks.0.cross_attn.value.bias decoder.blocks.0.cross_attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.0.encoder_attn.q_proj.weight -&gt; decoder.blocks.0.cross_attn.query.weight decoder.blocks.0.cross_attn.query.weight 2 (1280, 1280) model.decoder.layers.0.encoder_attn.q_proj.bias -&gt; decoder.blocks.0.cross_attn.query.bias decoder.blocks.0.cross_attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.0.encoder_attn.out_proj.weight -&gt; decoder.blocks.0.cross_attn.out.weight decoder.blocks.0.cross_attn.out.weight 2 (1280, 1280) model.decoder.layers.0.encoder_attn.out_proj.bias -&gt; decoder.blocks.0.cross_attn.out.bias decoder.blocks.0.cross_attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.0.encoder_attn_layer_norm.weight -&gt; decoder.blocks.0.cross_attn_ln.weight decoder.blocks.0.cross_attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.0.encoder_attn_layer_norm.bias -&gt; decoder.blocks.0.cross_attn_ln.bias decoder.blocks.0.cross_attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.0.fc1.weight -&gt; decoder.blocks.0.mlp.0.weight decoder.blocks.0.mlp.0.weight 2 (5120, 1280) model.decoder.layers.0.fc1.bias -&gt; decoder.blocks.0.mlp.0.bias decoder.blocks.0.mlp.0.bias 1 (5120,) Converting to float32 model.decoder.layers.0.fc2.weight -&gt; decoder.blocks.0.mlp.2.weight decoder.blocks.0.mlp.2.weight 2 (1280, 5120) model.decoder.layers.0.fc2.bias -&gt; decoder.blocks.0.mlp.2.bias decoder.blocks.0.mlp.2.bias 1 (1280,) Converting to float32 model.decoder.layers.0.final_layer_norm.weight -&gt; decoder.blocks.0.mlp_ln.weight decoder.blocks.0.mlp_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.0.final_layer_norm.bias -&gt; decoder.blocks.0.mlp_ln.bias decoder.blocks.0.mlp_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.1.self_attn.k_proj.weight -&gt; decoder.blocks.1.attn.key.weight decoder.blocks.1.attn.key.weight 2 (1280, 1280) model.decoder.layers.1.self_attn.v_proj.weight -&gt; decoder.blocks.1.attn.value.weight decoder.blocks.1.attn.value.weight 2 (1280, 1280) model.decoder.layers.1.self_attn.v_proj.bias -&gt; decoder.blocks.1.attn.value.bias decoder.blocks.1.attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.1.self_attn.q_proj.weight -&gt; decoder.blocks.1.attn.query.weight decoder.blocks.1.attn.query.weight 2 (1280, 1280) model.decoder.layers.1.self_attn.q_proj.bias -&gt; decoder.blocks.1.attn.query.bias decoder.blocks.1.attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.1.self_attn.out_proj.weight -&gt; decoder.blocks.1.attn.out.weight decoder.blocks.1.attn.out.weight 2 (1280, 1280) model.decoder.layers.1.self_attn.out_proj.bias -&gt; decoder.blocks.1.attn.out.bias decoder.blocks.1.attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.1.self_attn_layer_norm.weight -&gt; decoder.blocks.1.attn_ln.weight decoder.blocks.1.attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.1.self_attn_layer_norm.bias -&gt; decoder.blocks.1.attn_ln.bias decoder.blocks.1.attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.1.encoder_attn.k_proj.weight -&gt; decoder.blocks.1.cross_attn.key.weight decoder.blocks.1.cross_attn.key.weight 2 (1280, 1280) model.decoder.layers.1.encoder_attn.v_proj.weight -&gt; decoder.blocks.1.cross_attn.value.weight decoder.blocks.1.cross_attn.value.weight 2 (1280, 1280) model.decoder.layers.1.encoder_attn.v_proj.bias -&gt; decoder.blocks.1.cross_attn.value.bias decoder.blocks.1.cross_attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.1.encoder_attn.q_proj.weight -&gt; decoder.blocks.1.cross_attn.query.weight decoder.blocks.1.cross_attn.query.weight 2 (1280, 1280) model.decoder.layers.1.encoder_attn.q_proj.bias -&gt; decoder.blocks.1.cross_attn.query.bias decoder.blocks.1.cross_attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.1.encoder_attn.out_proj.weight -&gt; decoder.blocks.1.cross_attn.out.weight decoder.blocks.1.cross_attn.out.weight 2 (1280, 1280) model.decoder.layers.1.encoder_attn.out_proj.bias -&gt; decoder.blocks.1.cross_attn.out.bias decoder.blocks.1.cross_attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.1.encoder_attn_layer_norm.weight -&gt; decoder.blocks.1.cross_attn_ln.weight decoder.blocks.1.cross_attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.1.encoder_attn_layer_norm.bias -&gt; decoder.blocks.1.cross_attn_ln.bias decoder.blocks.1.cross_attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.1.fc1.weight -&gt; decoder.blocks.1.mlp.0.weight decoder.blocks.1.mlp.0.weight 2 (5120, 1280) model.decoder.layers.1.fc1.bias -&gt; decoder.blocks.1.mlp.0.bias decoder.blocks.1.mlp.0.bias 1 (5120,) Converting to float32 model.decoder.layers.1.fc2.weight -&gt; decoder.blocks.1.mlp.2.weight decoder.blocks.1.mlp.2.weight 2 (1280, 5120) model.decoder.layers.1.fc2.bias -&gt; decoder.blocks.1.mlp.2.bias decoder.blocks.1.mlp.2.bias 1 (1280,) Converting to float32 model.decoder.layers.1.final_layer_norm.weight -&gt; decoder.blocks.1.mlp_ln.weight decoder.blocks.1.mlp_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.1.final_layer_norm.bias -&gt; decoder.blocks.1.mlp_ln.bias decoder.blocks.1.mlp_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.2.self_attn.k_proj.weight -&gt; decoder.blocks.2.attn.key.weight decoder.blocks.2.attn.key.weight 2 (1280, 1280) model.decoder.layers.2.self_attn.v_proj.weight -&gt; decoder.blocks.2.attn.value.weight decoder.blocks.2.attn.value.weight 2 (1280, 1280) model.decoder.layers.2.self_attn.v_proj.bias -&gt; decoder.blocks.2.attn.value.bias decoder.blocks.2.attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.2.self_attn.q_proj.weight -&gt; decoder.blocks.2.attn.query.weight decoder.blocks.2.attn.query.weight 2 (1280, 1280) model.decoder.layers.2.self_attn.q_proj.bias -&gt; decoder.blocks.2.attn.query.bias decoder.blocks.2.attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.2.self_attn.out_proj.weight -&gt; decoder.blocks.2.attn.out.weight decoder.blocks.2.attn.out.weight 2 (1280, 1280) model.decoder.layers.2.self_attn.out_proj.bias -&gt; decoder.blocks.2.attn.out.bias decoder.blocks.2.attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.2.self_attn_layer_norm.weight -&gt; decoder.blocks.2.attn_ln.weight decoder.blocks.2.attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.2.self_attn_layer_norm.bias -&gt; decoder.blocks.2.attn_ln.bias decoder.blocks.2.attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.2.encoder_attn.k_proj.weight -&gt; decoder.blocks.2.cross_attn.key.weight decoder.blocks.2.cross_attn.key.weight 2 (1280, 1280) model.decoder.layers.2.encoder_attn.v_proj.weight -&gt; decoder.blocks.2.cross_attn.value.weight decoder.blocks.2.cross_attn.value.weight 2 (1280, 1280) model.decoder.layers.2.encoder_attn.v_proj.bias -&gt; decoder.blocks.2.cross_attn.value.bias decoder.blocks.2.cross_attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.2.encoder_attn.q_proj.weight -&gt; decoder.blocks.2.cross_attn.query.weight decoder.blocks.2.cross_attn.query.weight 2 (1280, 1280) model.decoder.layers.2.encoder_attn.q_proj.bias -&gt; decoder.blocks.2.cross_attn.query.bias decoder.blocks.2.cross_attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.2.encoder_attn.out_proj.weight -&gt; decoder.blocks.2.cross_attn.out.weight decoder.blocks.2.cross_attn.out.weight 2 (1280, 1280) model.decoder.layers.2.encoder_attn.out_proj.bias -&gt; decoder.blocks.2.cross_attn.out.bias decoder.blocks.2.cross_attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.2.encoder_attn_layer_norm.weight -&gt; decoder.blocks.2.cross_attn_ln.weight decoder.blocks.2.cross_attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.2.encoder_attn_layer_norm.bias -&gt; decoder.blocks.2.cross_attn_ln.bias decoder.blocks.2.cross_attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.2.fc1.weight -&gt; decoder.blocks.2.mlp.0.weight decoder.blocks.2.mlp.0.weight 2 (5120, 1280) model.decoder.layers.2.fc1.bias -&gt; decoder.blocks.2.mlp.0.bias decoder.blocks.2.mlp.0.bias 1 (5120,) Converting to float32 model.decoder.layers.2.fc2.weight -&gt; decoder.blocks.2.mlp.2.weight decoder.blocks.2.mlp.2.weight 2 (1280, 5120) model.decoder.layers.2.fc2.bias -&gt; decoder.blocks.2.mlp.2.bias decoder.blocks.2.mlp.2.bias 1 (1280,) Converting to float32 model.decoder.layers.2.final_layer_norm.weight -&gt; decoder.blocks.2.mlp_ln.weight decoder.blocks.2.mlp_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.2.final_layer_norm.bias -&gt; decoder.blocks.2.mlp_ln.bias decoder.blocks.2.mlp_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.3.self_attn.k_proj.weight -&gt; decoder.blocks.3.attn.key.weight decoder.blocks.3.attn.key.weight 2 (1280, 1280) model.decoder.layers.3.self_attn.v_proj.weight -&gt; decoder.blocks.3.attn.value.weight decoder.blocks.3.attn.value.weight 2 (1280, 1280) model.decoder.layers.3.self_attn.v_proj.bias -&gt; decoder.blocks.3.attn.value.bias decoder.blocks.3.attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.3.self_attn.q_proj.weight -&gt; decoder.blocks.3.attn.query.weight decoder.blocks.3.attn.query.weight 2 (1280, 1280) model.decoder.layers.3.self_attn.q_proj.bias -&gt; decoder.blocks.3.attn.query.bias decoder.blocks.3.attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.3.self_attn.out_proj.weight -&gt; decoder.blocks.3.attn.out.weight decoder.blocks.3.attn.out.weight 2 (1280, 1280) model.decoder.layers.3.self_attn.out_proj.bias -&gt; decoder.blocks.3.attn.out.bias decoder.blocks.3.attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.3.self_attn_layer_norm.weight -&gt; decoder.blocks.3.attn_ln.weight decoder.blocks.3.attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.3.self_attn_layer_norm.bias -&gt; decoder.blocks.3.attn_ln.bias decoder.blocks.3.attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.3.encoder_attn.k_proj.weight -&gt; decoder.blocks.3.cross_attn.key.weight decoder.blocks.3.cross_attn.key.weight 2 (1280, 1280) model.decoder.layers.3.encoder_attn.v_proj.weight -&gt; decoder.blocks.3.cross_attn.value.weight decoder.blocks.3.cross_attn.value.weight 2 (1280, 1280) model.decoder.layers.3.encoder_attn.v_proj.bias -&gt; decoder.blocks.3.cross_attn.value.bias decoder.blocks.3.cross_attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.3.encoder_attn.q_proj.weight -&gt; decoder.blocks.3.cross_attn.query.weight decoder.blocks.3.cross_attn.query.weight 2 (1280, 1280) model.decoder.layers.3.encoder_attn.q_proj.bias -&gt; decoder.blocks.3.cross_attn.query.bias decoder.blocks.3.cross_attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.3.encoder_attn.out_proj.weight -&gt; decoder.blocks.3.cross_attn.out.weight decoder.blocks.3.cross_attn.out.weight 2 (1280, 1280) model.decoder.layers.3.encoder_attn.out_proj.bias -&gt; decoder.blocks.3.cross_attn.out.bias decoder.blocks.3.cross_attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.3.encoder_attn_layer_norm.weight -&gt; decoder.blocks.3.cross_attn_ln.weight decoder.blocks.3.cross_attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.3.encoder_attn_layer_norm.bias -&gt; decoder.blocks.3.cross_attn_ln.bias decoder.blocks.3.cross_attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.3.fc1.weight -&gt; decoder.blocks.3.mlp.0.weight decoder.blocks.3.mlp.0.weight 2 (5120, 1280) model.decoder.layers.3.fc1.bias -&gt; decoder.blocks.3.mlp.0.bias decoder.blocks.3.mlp.0.bias 1 (5120,) Converting to float32 model.decoder.layers.3.fc2.weight -&gt; decoder.blocks.3.mlp.2.weight decoder.blocks.3.mlp.2.weight 2 (1280, 5120) model.decoder.layers.3.fc2.bias -&gt; decoder.blocks.3.mlp.2.bias decoder.blocks.3.mlp.2.bias 1 (1280,) Converting to float32 model.decoder.layers.3.final_layer_norm.weight -&gt; decoder.blocks.3.mlp_ln.weight decoder.blocks.3.mlp_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.3.final_layer_norm.bias -&gt; decoder.blocks.3.mlp_ln.bias decoder.blocks.3.mlp_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.4.self_attn.k_proj.weight -&gt; decoder.blocks.4.attn.key.weight decoder.blocks.4.attn.key.weight 2 (1280, 1280) model.decoder.layers.4.self_attn.v_proj.weight -&gt; decoder.blocks.4.attn.value.weight decoder.blocks.4.attn.value.weight 2 (1280, 1280) model.decoder.layers.4.self_attn.v_proj.bias -&gt; decoder.blocks.4.attn.value.bias decoder.blocks.4.attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.4.self_attn.q_proj.weight -&gt; decoder.blocks.4.attn.query.weight decoder.blocks.4.attn.query.weight 2 (1280, 1280) model.decoder.layers.4.self_attn.q_proj.bias -&gt; decoder.blocks.4.attn.query.bias decoder.blocks.4.attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.4.self_attn.out_proj.weight -&gt; decoder.blocks.4.attn.out.weight decoder.blocks.4.attn.out.weight 2 (1280, 1280) model.decoder.layers.4.self_attn.out_proj.bias -&gt; decoder.blocks.4.attn.out.bias decoder.blocks.4.attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.4.self_attn_layer_norm.weight -&gt; decoder.blocks.4.attn_ln.weight decoder.blocks.4.attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.4.self_attn_layer_norm.bias -&gt; decoder.blocks.4.attn_ln.bias decoder.blocks.4.attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.4.encoder_attn.k_proj.weight -&gt; decoder.blocks.4.cross_attn.key.weight decoder.blocks.4.cross_attn.key.weight 2 (1280, 1280) model.decoder.layers.4.encoder_attn.v_proj.weight -&gt; decoder.blocks.4.cross_attn.value.weight decoder.blocks.4.cross_attn.value.weight 2 (1280, 1280) model.decoder.layers.4.encoder_attn.v_proj.bias -&gt; decoder.blocks.4.cross_attn.value.bias decoder.blocks.4.cross_attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.4.encoder_attn.q_proj.weight -&gt; decoder.blocks.4.cross_attn.query.weight decoder.blocks.4.cross_attn.query.weight 2 (1280, 1280) model.decoder.layers.4.encoder_attn.q_proj.bias -&gt; decoder.blocks.4.cross_attn.query.bias decoder.blocks.4.cross_attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.4.encoder_attn.out_proj.weight -&gt; decoder.blocks.4.cross_attn.out.weight decoder.blocks.4.cross_attn.out.weight 2 (1280, 1280) model.decoder.layers.4.encoder_attn.out_proj.bias -&gt; decoder.blocks.4.cross_attn.out.bias decoder.blocks.4.cross_attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.4.encoder_attn_layer_norm.weight -&gt; decoder.blocks.4.cross_attn_ln.weight decoder.blocks.4.cross_attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.4.encoder_attn_layer_norm.bias -&gt; decoder.blocks.4.cross_attn_ln.bias decoder.blocks.4.cross_attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.4.fc1.weight -&gt; decoder.blocks.4.mlp.0.weight decoder.blocks.4.mlp.0.weight 2 (5120, 1280) model.decoder.layers.4.fc1.bias -&gt; decoder.blocks.4.mlp.0.bias decoder.blocks.4.mlp.0.bias 1 (5120,) Converting to float32 model.decoder.layers.4.fc2.weight -&gt; decoder.blocks.4.mlp.2.weight decoder.blocks.4.mlp.2.weight 2 (1280, 5120) model.decoder.layers.4.fc2.bias -&gt; decoder.blocks.4.mlp.2.bias decoder.blocks.4.mlp.2.bias 1 (1280,) Converting to float32 model.decoder.layers.4.final_layer_norm.weight -&gt; decoder.blocks.4.mlp_ln.weight decoder.blocks.4.mlp_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.4.final_layer_norm.bias -&gt; decoder.blocks.4.mlp_ln.bias decoder.blocks.4.mlp_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.5.self_attn.k_proj.weight -&gt; decoder.blocks.5.attn.key.weight decoder.blocks.5.attn.key.weight 2 (1280, 1280) model.decoder.layers.5.self_attn.v_proj.weight -&gt; decoder.blocks.5.attn.value.weight decoder.blocks.5.attn.value.weight 2 (1280, 1280) model.decoder.layers.5.self_attn.v_proj.bias -&gt; decoder.blocks.5.attn.value.bias decoder.blocks.5.attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.5.self_attn.q_proj.weight -&gt; decoder.blocks.5.attn.query.weight decoder.blocks.5.attn.query.weight 2 (1280, 1280) model.decoder.layers.5.self_attn.q_proj.bias -&gt; decoder.blocks.5.attn.query.bias decoder.blocks.5.attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.5.self_attn.out_proj.weight -&gt; decoder.blocks.5.attn.out.weight decoder.blocks.5.attn.out.weight 2 (1280, 1280) model.decoder.layers.5.self_attn.out_proj.bias -&gt; decoder.blocks.5.attn.out.bias decoder.blocks.5.attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.5.self_attn_layer_norm.weight -&gt; decoder.blocks.5.attn_ln.weight decoder.blocks.5.attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.5.self_attn_layer_norm.bias -&gt; decoder.blocks.5.attn_ln.bias decoder.blocks.5.attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.5.encoder_attn.k_proj.weight -&gt; decoder.blocks.5.cross_attn.key.weight decoder.blocks.5.cross_attn.key.weight 2 (1280, 1280) model.decoder.layers.5.encoder_attn.v_proj.weight -&gt; decoder.blocks.5.cross_attn.value.weight decoder.blocks.5.cross_attn.value.weight 2 (1280, 1280) model.decoder.layers.5.encoder_attn.v_proj.bias -&gt; decoder.blocks.5.cross_attn.value.bias decoder.blocks.5.cross_attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.5.encoder_attn.q_proj.weight -&gt; decoder.blocks.5.cross_attn.query.weight decoder.blocks.5.cross_attn.query.weight 2 (1280, 1280) model.decoder.layers.5.encoder_attn.q_proj.bias -&gt; decoder.blocks.5.cross_attn.query.bias decoder.blocks.5.cross_attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.5.encoder_attn.out_proj.weight -&gt; decoder.blocks.5.cross_attn.out.weight decoder.blocks.5.cross_attn.out.weight 2 (1280, 1280) model.decoder.layers.5.encoder_attn.out_proj.bias -&gt; decoder.blocks.5.cross_attn.out.bias decoder.blocks.5.cross_attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.5.encoder_attn_layer_norm.weight -&gt; decoder.blocks.5.cross_attn_ln.weight decoder.blocks.5.cross_attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.5.encoder_attn_layer_norm.bias -&gt; decoder.blocks.5.cross_attn_ln.bias decoder.blocks.5.cross_attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.5.fc1.weight -&gt; decoder.blocks.5.mlp.0.weight decoder.blocks.5.mlp.0.weight 2 (5120, 1280) model.decoder.layers.5.fc1.bias -&gt; decoder.blocks.5.mlp.0.bias decoder.blocks.5.mlp.0.bias 1 (5120,) Converting to float32 model.decoder.layers.5.fc2.weight -&gt; decoder.blocks.5.mlp.2.weight decoder.blocks.5.mlp.2.weight 2 (1280, 5120) model.decoder.layers.5.fc2.bias -&gt; decoder.blocks.5.mlp.2.bias decoder.blocks.5.mlp.2.bias 1 (1280,) Converting to float32 model.decoder.layers.5.final_layer_norm.weight -&gt; decoder.blocks.5.mlp_ln.weight decoder.blocks.5.mlp_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.5.final_layer_norm.bias -&gt; decoder.blocks.5.mlp_ln.bias decoder.blocks.5.mlp_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.6.self_attn.k_proj.weight -&gt; decoder.blocks.6.attn.key.weight decoder.blocks.6.attn.key.weight 2 (1280, 1280) model.decoder.layers.6.self_attn.v_proj.weight -&gt; decoder.blocks.6.attn.value.weight decoder.blocks.6.attn.value.weight 2 (1280, 1280) model.decoder.layers.6.self_attn.v_proj.bias -&gt; decoder.blocks.6.attn.value.bias decoder.blocks.6.attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.6.self_attn.q_proj.weight -&gt; decoder.blocks.6.attn.query.weight decoder.blocks.6.attn.query.weight 2 (1280, 1280) model.decoder.layers.6.self_attn.q_proj.bias -&gt; decoder.blocks.6.attn.query.bias decoder.blocks.6.attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.6.self_attn.out_proj.weight -&gt; decoder.blocks.6.attn.out.weight decoder.blocks.6.attn.out.weight 2 (1280, 1280) model.decoder.layers.6.self_attn.out_proj.bias -&gt; decoder.blocks.6.attn.out.bias decoder.blocks.6.attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.6.self_attn_layer_norm.weight -&gt; decoder.blocks.6.attn_ln.weight decoder.blocks.6.attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.6.self_attn_layer_norm.bias -&gt; decoder.blocks.6.attn_ln.bias decoder.blocks.6.attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.6.encoder_attn.k_proj.weight -&gt; decoder.blocks.6.cross_attn.key.weight decoder.blocks.6.cross_attn.key.weight 2 (1280, 1280) model.decoder.layers.6.encoder_attn.v_proj.weight -&gt; decoder.blocks.6.cross_attn.value.weight decoder.blocks.6.cross_attn.value.weight 2 (1280, 1280) model.decoder.layers.6.encoder_attn.v_proj.bias -&gt; decoder.blocks.6.cross_attn.value.bias decoder.blocks.6.cross_attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.6.encoder_attn.q_proj.weight -&gt; decoder.blocks.6.cross_attn.query.weight decoder.blocks.6.cross_attn.query.weight 2 (1280, 1280) model.decoder.layers.6.encoder_attn.q_proj.bias -&gt; decoder.blocks.6.cross_attn.query.bias decoder.blocks.6.cross_attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.6.encoder_attn.out_proj.weight -&gt; decoder.blocks.6.cross_attn.out.weight decoder.blocks.6.cross_attn.out.weight 2 (1280, 1280) model.decoder.layers.6.encoder_attn.out_proj.bias -&gt; decoder.blocks.6.cross_attn.out.bias decoder.blocks.6.cross_attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.6.encoder_attn_layer_norm.weight -&gt; decoder.blocks.6.cross_attn_ln.weight decoder.blocks.6.cross_attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.6.encoder_attn_layer_norm.bias -&gt; decoder.blocks.6.cross_attn_ln.bias decoder.blocks.6.cross_attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.6.fc1.weight -&gt; decoder.blocks.6.mlp.0.weight decoder.blocks.6.mlp.0.weight 2 (5120, 1280) model.decoder.layers.6.fc1.bias -&gt; decoder.blocks.6.mlp.0.bias decoder.blocks.6.mlp.0.bias 1 (5120,) Converting to float32 model.decoder.layers.6.fc2.weight -&gt; decoder.blocks.6.mlp.2.weight decoder.blocks.6.mlp.2.weight 2 (1280, 5120) model.decoder.layers.6.fc2.bias -&gt; decoder.blocks.6.mlp.2.bias decoder.blocks.6.mlp.2.bias 1 (1280,) Converting to float32 model.decoder.layers.6.final_layer_norm.weight -&gt; decoder.blocks.6.mlp_ln.weight decoder.blocks.6.mlp_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.6.final_layer_norm.bias -&gt; decoder.blocks.6.mlp_ln.bias decoder.blocks.6.mlp_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.7.self_attn.k_proj.weight -&gt; decoder.blocks.7.attn.key.weight decoder.blocks.7.attn.key.weight 2 (1280, 1280) model.decoder.layers.7.self_attn.v_proj.weight -&gt; decoder.blocks.7.attn.value.weight decoder.blocks.7.attn.value.weight 2 (1280, 1280) model.decoder.layers.7.self_attn.v_proj.bias -&gt; decoder.blocks.7.attn.value.bias decoder.blocks.7.attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.7.self_attn.q_proj.weight -&gt; decoder.blocks.7.attn.query.weight decoder.blocks.7.attn.query.weight 2 (1280, 1280) model.decoder.layers.7.self_attn.q_proj.bias -&gt; decoder.blocks.7.attn.query.bias decoder.blocks.7.attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.7.self_attn.out_proj.weight -&gt; decoder.blocks.7.attn.out.weight decoder.blocks.7.attn.out.weight 2 (1280, 1280) model.decoder.layers.7.self_attn.out_proj.bias -&gt; decoder.blocks.7.attn.out.bias decoder.blocks.7.attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.7.self_attn_layer_norm.weight -&gt; decoder.blocks.7.attn_ln.weight decoder.blocks.7.attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.7.self_attn_layer_norm.bias -&gt; decoder.blocks.7.attn_ln.bias decoder.blocks.7.attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.7.encoder_attn.k_proj.weight -&gt; decoder.blocks.7.cross_attn.key.weight decoder.blocks.7.cross_attn.key.weight 2 (1280, 1280) model.decoder.layers.7.encoder_attn.v_proj.weight -&gt; decoder.blocks.7.cross_attn.value.weight decoder.blocks.7.cross_attn.value.weight 2 (1280, 1280) model.decoder.layers.7.encoder_attn.v_proj.bias -&gt; decoder.blocks.7.cross_attn.value.bias decoder.blocks.7.cross_attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.7.encoder_attn.q_proj.weight -&gt; decoder.blocks.7.cross_attn.query.weight decoder.blocks.7.cross_attn.query.weight 2 (1280, 1280) model.decoder.layers.7.encoder_attn.q_proj.bias -&gt; decoder.blocks.7.cross_attn.query.bias decoder.blocks.7.cross_attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.7.encoder_attn.out_proj.weight -&gt; decoder.blocks.7.cross_attn.out.weight decoder.blocks.7.cross_attn.out.weight 2 (1280, 1280) model.decoder.layers.7.encoder_attn.out_proj.bias -&gt; decoder.blocks.7.cross_attn.out.bias decoder.blocks.7.cross_attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.7.encoder_attn_layer_norm.weight -&gt; decoder.blocks.7.cross_attn_ln.weight decoder.blocks.7.cross_attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.7.encoder_attn_layer_norm.bias -&gt; decoder.blocks.7.cross_attn_ln.bias decoder.blocks.7.cross_attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.7.fc1.weight -&gt; decoder.blocks.7.mlp.0.weight decoder.blocks.7.mlp.0.weight 2 (5120, 1280) model.decoder.layers.7.fc1.bias -&gt; decoder.blocks.7.mlp.0.bias decoder.blocks.7.mlp.0.bias 1 (5120,) Converting to float32 model.decoder.layers.7.fc2.weight -&gt; decoder.blocks.7.mlp.2.weight decoder.blocks.7.mlp.2.weight 2 (1280, 5120) model.decoder.layers.7.fc2.bias -&gt; decoder.blocks.7.mlp.2.bias decoder.blocks.7.mlp.2.bias 1 (1280,) Converting to float32 model.decoder.layers.7.final_layer_norm.weight -&gt; decoder.blocks.7.mlp_ln.weight decoder.blocks.7.mlp_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.7.final_layer_norm.bias -&gt; decoder.blocks.7.mlp_ln.bias decoder.blocks.7.mlp_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.8.self_attn.k_proj.weight -&gt; decoder.blocks.8.attn.key.weight decoder.blocks.8.attn.key.weight 2 (1280, 1280) model.decoder.layers.8.self_attn.v_proj.weight -&gt; decoder.blocks.8.attn.value.weight decoder.blocks.8.attn.value.weight 2 (1280, 1280) model.decoder.layers.8.self_attn.v_proj.bias -&gt; decoder.blocks.8.attn.value.bias decoder.blocks.8.attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.8.self_attn.q_proj.weight -&gt; decoder.blocks.8.attn.query.weight decoder.blocks.8.attn.query.weight 2 (1280, 1280) model.decoder.layers.8.self_attn.q_proj.bias -&gt; decoder.blocks.8.attn.query.bias decoder.blocks.8.attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.8.self_attn.out_proj.weight -&gt; decoder.blocks.8.attn.out.weight decoder.blocks.8.attn.out.weight 2 (1280, 1280) model.decoder.layers.8.self_attn.out_proj.bias -&gt; decoder.blocks.8.attn.out.bias decoder.blocks.8.attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.8.self_attn_layer_norm.weight -&gt; decoder.blocks.8.attn_ln.weight decoder.blocks.8.attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.8.self_attn_layer_norm.bias -&gt; decoder.blocks.8.attn_ln.bias decoder.blocks.8.attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.8.encoder_attn.k_proj.weight -&gt; decoder.blocks.8.cross_attn.key.weight decoder.blocks.8.cross_attn.key.weight 2 (1280, 1280) model.decoder.layers.8.encoder_attn.v_proj.weight -&gt; decoder.blocks.8.cross_attn.value.weight decoder.blocks.8.cross_attn.value.weight 2 (1280, 1280) model.decoder.layers.8.encoder_attn.v_proj.bias -&gt; decoder.blocks.8.cross_attn.value.bias decoder.blocks.8.cross_attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.8.encoder_attn.q_proj.weight -&gt; decoder.blocks.8.cross_attn.query.weight decoder.blocks.8.cross_attn.query.weight 2 (1280, 1280) model.decoder.layers.8.encoder_attn.q_proj.bias -&gt; decoder.blocks.8.cross_attn.query.bias decoder.blocks.8.cross_attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.8.encoder_attn.out_proj.weight -&gt; decoder.blocks.8.cross_attn.out.weight decoder.blocks.8.cross_attn.out.weight 2 (1280, 1280) model.decoder.layers.8.encoder_attn.out_proj.bias -&gt; decoder.blocks.8.cross_attn.out.bias decoder.blocks.8.cross_attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.8.encoder_attn_layer_norm.weight -&gt; decoder.blocks.8.cross_attn_ln.weight decoder.blocks.8.cross_attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.8.encoder_attn_layer_norm.bias -&gt; decoder.blocks.8.cross_attn_ln.bias decoder.blocks.8.cross_attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.8.fc1.weight -&gt; decoder.blocks.8.mlp.0.weight decoder.blocks.8.mlp.0.weight 2 (5120, 1280) model.decoder.layers.8.fc1.bias -&gt; decoder.blocks.8.mlp.0.bias decoder.blocks.8.mlp.0.bias 1 (5120,) Converting to float32 model.decoder.layers.8.fc2.weight -&gt; decoder.blocks.8.mlp.2.weight decoder.blocks.8.mlp.2.weight 2 (1280, 5120) model.decoder.layers.8.fc2.bias -&gt; decoder.blocks.8.mlp.2.bias decoder.blocks.8.mlp.2.bias 1 (1280,) Converting to float32 model.decoder.layers.8.final_layer_norm.weight -&gt; decoder.blocks.8.mlp_ln.weight decoder.blocks.8.mlp_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.8.final_layer_norm.bias -&gt; decoder.blocks.8.mlp_ln.bias decoder.blocks.8.mlp_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.9.self_attn.k_proj.weight -&gt; decoder.blocks.9.attn.key.weight decoder.blocks.9.attn.key.weight 2 (1280, 1280) model.decoder.layers.9.self_attn.v_proj.weight -&gt; decoder.blocks.9.attn.value.weight decoder.blocks.9.attn.value.weight 2 (1280, 1280) model.decoder.layers.9.self_attn.v_proj.bias -&gt; decoder.blocks.9.attn.value.bias decoder.blocks.9.attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.9.self_attn.q_proj.weight -&gt; decoder.blocks.9.attn.query.weight decoder.blocks.9.attn.query.weight 2 (1280, 1280) model.decoder.layers.9.self_attn.q_proj.bias -&gt; decoder.blocks.9.attn.query.bias decoder.blocks.9.attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.9.self_attn.out_proj.weight -&gt; decoder.blocks.9.attn.out.weight decoder.blocks.9.attn.out.weight 2 (1280, 1280) model.decoder.layers.9.self_attn.out_proj.bias -&gt; decoder.blocks.9.attn.out.bias decoder.blocks.9.attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.9.self_attn_layer_norm.weight -&gt; decoder.blocks.9.attn_ln.weight decoder.blocks.9.attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.9.self_attn_layer_norm.bias -&gt; decoder.blocks.9.attn_ln.bias decoder.blocks.9.attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.9.encoder_attn.k_proj.weight -&gt; decoder.blocks.9.cross_attn.key.weight decoder.blocks.9.cross_attn.key.weight 2 (1280, 1280) model.decoder.layers.9.encoder_attn.v_proj.weight -&gt; decoder.blocks.9.cross_attn.value.weight decoder.blocks.9.cross_attn.value.weight 2 (1280, 1280) model.decoder.layers.9.encoder_attn.v_proj.bias -&gt; decoder.blocks.9.cross_attn.value.bias decoder.blocks.9.cross_attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.9.encoder_attn.q_proj.weight -&gt; decoder.blocks.9.cross_attn.query.weight decoder.blocks.9.cross_attn.query.weight 2 (1280, 1280) model.decoder.layers.9.encoder_attn.q_proj.bias -&gt; decoder.blocks.9.cross_attn.query.bias decoder.blocks.9.cross_attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.9.encoder_attn.out_proj.weight -&gt; decoder.blocks.9.cross_attn.out.weight decoder.blocks.9.cross_attn.out.weight 2 (1280, 1280) model.decoder.layers.9.encoder_attn.out_proj.bias -&gt; decoder.blocks.9.cross_attn.out.bias decoder.blocks.9.cross_attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.9.encoder_attn_layer_norm.weight -&gt; decoder.blocks.9.cross_attn_ln.weight decoder.blocks.9.cross_attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.9.encoder_attn_layer_norm.bias -&gt; decoder.blocks.9.cross_attn_ln.bias decoder.blocks.9.cross_attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.9.fc1.weight -&gt; decoder.blocks.9.mlp.0.weight decoder.blocks.9.mlp.0.weight 2 (5120, 1280) model.decoder.layers.9.fc1.bias -&gt; decoder.blocks.9.mlp.0.bias decoder.blocks.9.mlp.0.bias 1 (5120,) Converting to float32 model.decoder.layers.9.fc2.weight -&gt; decoder.blocks.9.mlp.2.weight decoder.blocks.9.mlp.2.weight 2 (1280, 5120) model.decoder.layers.9.fc2.bias -&gt; decoder.blocks.9.mlp.2.bias decoder.blocks.9.mlp.2.bias 1 (1280,) Converting to float32 model.decoder.layers.9.final_layer_norm.weight -&gt; decoder.blocks.9.mlp_ln.weight decoder.blocks.9.mlp_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.9.final_layer_norm.bias -&gt; decoder.blocks.9.mlp_ln.bias decoder.blocks.9.mlp_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.10.self_attn.k_proj.weight -&gt; decoder.blocks.10.attn.key.weight decoder.blocks.10.attn.key.weight 2 (1280, 1280) model.decoder.layers.10.self_attn.v_proj.weight -&gt; decoder.blocks.10.attn.value.weight decoder.blocks.10.attn.value.weight 2 (1280, 1280) model.decoder.layers.10.self_attn.v_proj.bias -&gt; decoder.blocks.10.attn.value.bias decoder.blocks.10.attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.10.self_attn.q_proj.weight -&gt; decoder.blocks.10.attn.query.weight decoder.blocks.10.attn.query.weight 2 (1280, 1280) model.decoder.layers.10.self_attn.q_proj.bias -&gt; decoder.blocks.10.attn.query.bias decoder.blocks.10.attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.10.self_attn.out_proj.weight -&gt; decoder.blocks.10.attn.out.weight decoder.blocks.10.attn.out.weight 2 (1280, 1280) model.decoder.layers.10.self_attn.out_proj.bias -&gt; decoder.blocks.10.attn.out.bias decoder.blocks.10.attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.10.self_attn_layer_norm.weight -&gt; decoder.blocks.10.attn_ln.weight decoder.blocks.10.attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.10.self_attn_layer_norm.bias -&gt; decoder.blocks.10.attn_ln.bias decoder.blocks.10.attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.10.encoder_attn.k_proj.weight -&gt; decoder.blocks.10.cross_attn.key.weight decoder.blocks.10.cross_attn.key.weight 2 (1280, 1280) model.decoder.layers.10.encoder_attn.v_proj.weight -&gt; decoder.blocks.10.cross_attn.value.weight decoder.blocks.10.cross_attn.value.weight 2 (1280, 1280) model.decoder.layers.10.encoder_attn.v_proj.bias -&gt; decoder.blocks.10.cross_attn.value.bias decoder.blocks.10.cross_attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.10.encoder_attn.q_proj.weight -&gt; decoder.blocks.10.cross_attn.query.weight decoder.blocks.10.cross_attn.query.weight 2 (1280, 1280) model.decoder.layers.10.encoder_attn.q_proj.bias -&gt; decoder.blocks.10.cross_attn.query.bias decoder.blocks.10.cross_attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.10.encoder_attn.out_proj.weight -&gt; decoder.blocks.10.cross_attn.out.weight decoder.blocks.10.cross_attn.out.weight 2 (1280, 1280) model.decoder.layers.10.encoder_attn.out_proj.bias -&gt; decoder.blocks.10.cross_attn.out.bias decoder.blocks.10.cross_attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.10.encoder_attn_layer_norm.weight -&gt; decoder.blocks.10.cross_attn_ln.weight decoder.blocks.10.cross_attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.10.encoder_attn_layer_norm.bias -&gt; decoder.blocks.10.cross_attn_ln.bias decoder.blocks.10.cross_attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.10.fc1.weight -&gt; decoder.blocks.10.mlp.0.weight decoder.blocks.10.mlp.0.weight 2 (5120, 1280) model.decoder.layers.10.fc1.bias -&gt; decoder.blocks.10.mlp.0.bias decoder.blocks.10.mlp.0.bias 1 (5120,) Converting to float32 model.decoder.layers.10.fc2.weight -&gt; decoder.blocks.10.mlp.2.weight decoder.blocks.10.mlp.2.weight 2 (1280, 5120) model.decoder.layers.10.fc2.bias -&gt; decoder.blocks.10.mlp.2.bias decoder.blocks.10.mlp.2.bias 1 (1280,) Converting to float32 model.decoder.layers.10.final_layer_norm.weight -&gt; decoder.blocks.10.mlp_ln.weight decoder.blocks.10.mlp_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.10.final_layer_norm.bias -&gt; decoder.blocks.10.mlp_ln.bias decoder.blocks.10.mlp_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.11.self_attn.k_proj.weight -&gt; decoder.blocks.11.attn.key.weight decoder.blocks.11.attn.key.weight 2 (1280, 1280) model.decoder.layers.11.self_attn.v_proj.weight -&gt; decoder.blocks.11.attn.value.weight decoder.blocks.11.attn.value.weight 2 (1280, 1280) model.decoder.layers.11.self_attn.v_proj.bias -&gt; decoder.blocks.11.attn.value.bias decoder.blocks.11.attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.11.self_attn.q_proj.weight -&gt; decoder.blocks.11.attn.query.weight decoder.blocks.11.attn.query.weight 2 (1280, 1280) model.decoder.layers.11.self_attn.q_proj.bias -&gt; decoder.blocks.11.attn.query.bias decoder.blocks.11.attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.11.self_attn.out_proj.weight -&gt; decoder.blocks.11.attn.out.weight decoder.blocks.11.attn.out.weight 2 (1280, 1280) model.decoder.layers.11.self_attn.out_proj.bias -&gt; decoder.blocks.11.attn.out.bias decoder.blocks.11.attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.11.self_attn_layer_norm.weight -&gt; decoder.blocks.11.attn_ln.weight decoder.blocks.11.attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.11.self_attn_layer_norm.bias -&gt; decoder.blocks.11.attn_ln.bias decoder.blocks.11.attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.11.encoder_attn.k_proj.weight -&gt; decoder.blocks.11.cross_attn.key.weight decoder.blocks.11.cross_attn.key.weight 2 (1280, 1280) model.decoder.layers.11.encoder_attn.v_proj.weight -&gt; decoder.blocks.11.cross_attn.value.weight decoder.blocks.11.cross_attn.value.weight 2 (1280, 1280) model.decoder.layers.11.encoder_attn.v_proj.bias -&gt; decoder.blocks.11.cross_attn.value.bias decoder.blocks.11.cross_attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.11.encoder_attn.q_proj.weight -&gt; decoder.blocks.11.cross_attn.query.weight decoder.blocks.11.cross_attn.query.weight 2 (1280, 1280) model.decoder.layers.11.encoder_attn.q_proj.bias -&gt; decoder.blocks.11.cross_attn.query.bias decoder.blocks.11.cross_attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.11.encoder_attn.out_proj.weight -&gt; decoder.blocks.11.cross_attn.out.weight decoder.blocks.11.cross_attn.out.weight 2 (1280, 1280) model.decoder.layers.11.encoder_attn.out_proj.bias -&gt; decoder.blocks.11.cross_attn.out.bias decoder.blocks.11.cross_attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.11.encoder_attn_layer_norm.weight -&gt; decoder.blocks.11.cross_attn_ln.weight decoder.blocks.11.cross_attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.11.encoder_attn_layer_norm.bias -&gt; decoder.blocks.11.cross_attn_ln.bias decoder.blocks.11.cross_attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.11.fc1.weight -&gt; decoder.blocks.11.mlp.0.weight decoder.blocks.11.mlp.0.weight 2 (5120, 1280) model.decoder.layers.11.fc1.bias -&gt; decoder.blocks.11.mlp.0.bias decoder.blocks.11.mlp.0.bias 1 (5120,) Converting to float32 model.decoder.layers.11.fc2.weight -&gt; decoder.blocks.11.mlp.2.weight decoder.blocks.11.mlp.2.weight 2 (1280, 5120) model.decoder.layers.11.fc2.bias -&gt; decoder.blocks.11.mlp.2.bias decoder.blocks.11.mlp.2.bias 1 (1280,) Converting to float32 model.decoder.layers.11.final_layer_norm.weight -&gt; decoder.blocks.11.mlp_ln.weight decoder.blocks.11.mlp_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.11.final_layer_norm.bias -&gt; decoder.blocks.11.mlp_ln.bias decoder.blocks.11.mlp_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.12.self_attn.k_proj.weight -&gt; decoder.blocks.12.attn.key.weight decoder.blocks.12.attn.key.weight 2 (1280, 1280) model.decoder.layers.12.self_attn.v_proj.weight -&gt; decoder.blocks.12.attn.value.weight decoder.blocks.12.attn.value.weight 2 (1280, 1280) model.decoder.layers.12.self_attn.v_proj.bias -&gt; decoder.blocks.12.attn.value.bias decoder.blocks.12.attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.12.self_attn.q_proj.weight -&gt; decoder.blocks.12.attn.query.weight decoder.blocks.12.attn.query.weight 2 (1280, 1280) model.decoder.layers.12.self_attn.q_proj.bias -&gt; decoder.blocks.12.attn.query.bias decoder.blocks.12.attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.12.self_attn.out_proj.weight -&gt; decoder.blocks.12.attn.out.weight decoder.blocks.12.attn.out.weight 2 (1280, 1280) model.decoder.layers.12.self_attn.out_proj.bias -&gt; decoder.blocks.12.attn.out.bias decoder.blocks.12.attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.12.self_attn_layer_norm.weight -&gt; decoder.blocks.12.attn_ln.weight decoder.blocks.12.attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.12.self_attn_layer_norm.bias -&gt; decoder.blocks.12.attn_ln.bias decoder.blocks.12.attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.12.encoder_attn.k_proj.weight -&gt; decoder.blocks.12.cross_attn.key.weight decoder.blocks.12.cross_attn.key.weight 2 (1280, 1280) model.decoder.layers.12.encoder_attn.v_proj.weight -&gt; decoder.blocks.12.cross_attn.value.weight decoder.blocks.12.cross_attn.value.weight 2 (1280, 1280) model.decoder.layers.12.encoder_attn.v_proj.bias -&gt; decoder.blocks.12.cross_attn.value.bias decoder.blocks.12.cross_attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.12.encoder_attn.q_proj.weight -&gt; decoder.blocks.12.cross_attn.query.weight decoder.blocks.12.cross_attn.query.weight 2 (1280, 1280) model.decoder.layers.12.encoder_attn.q_proj.bias -&gt; decoder.blocks.12.cross_attn.query.bias decoder.blocks.12.cross_attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.12.encoder_attn.out_proj.weight -&gt; decoder.blocks.12.cross_attn.out.weight decoder.blocks.12.cross_attn.out.weight 2 (1280, 1280) model.decoder.layers.12.encoder_attn.out_proj.bias -&gt; decoder.blocks.12.cross_attn.out.bias decoder.blocks.12.cross_attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.12.encoder_attn_layer_norm.weight -&gt; decoder.blocks.12.cross_attn_ln.weight decoder.blocks.12.cross_attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.12.encoder_attn_layer_norm.bias -&gt; decoder.blocks.12.cross_attn_ln.bias decoder.blocks.12.cross_attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.12.fc1.weight -&gt; decoder.blocks.12.mlp.0.weight decoder.blocks.12.mlp.0.weight 2 (5120, 1280) model.decoder.layers.12.fc1.bias -&gt; decoder.blocks.12.mlp.0.bias decoder.blocks.12.mlp.0.bias 1 (5120,) Converting to float32 model.decoder.layers.12.fc2.weight -&gt; decoder.blocks.12.mlp.2.weight decoder.blocks.12.mlp.2.weight 2 (1280, 5120) model.decoder.layers.12.fc2.bias -&gt; decoder.blocks.12.mlp.2.bias decoder.blocks.12.mlp.2.bias 1 (1280,) Converting to float32 model.decoder.layers.12.final_layer_norm.weight -&gt; decoder.blocks.12.mlp_ln.weight decoder.blocks.12.mlp_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.12.final_layer_norm.bias -&gt; decoder.blocks.12.mlp_ln.bias decoder.blocks.12.mlp_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.13.self_attn.k_proj.weight -&gt; decoder.blocks.13.attn.key.weight decoder.blocks.13.attn.key.weight 2 (1280, 1280) model.decoder.layers.13.self_attn.v_proj.weight -&gt; decoder.blocks.13.attn.value.weight decoder.blocks.13.attn.value.weight 2 (1280, 1280) model.decoder.layers.13.self_attn.v_proj.bias -&gt; decoder.blocks.13.attn.value.bias decoder.blocks.13.attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.13.self_attn.q_proj.weight -&gt; decoder.blocks.13.attn.query.weight decoder.blocks.13.attn.query.weight 2 (1280, 1280) model.decoder.layers.13.self_attn.q_proj.bias -&gt; decoder.blocks.13.attn.query.bias decoder.blocks.13.attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.13.self_attn.out_proj.weight -&gt; decoder.blocks.13.attn.out.weight decoder.blocks.13.attn.out.weight 2 (1280, 1280) model.decoder.layers.13.self_attn.out_proj.bias -&gt; decoder.blocks.13.attn.out.bias decoder.blocks.13.attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.13.self_attn_layer_norm.weight -&gt; decoder.blocks.13.attn_ln.weight decoder.blocks.13.attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.13.self_attn_layer_norm.bias -&gt; decoder.blocks.13.attn_ln.bias decoder.blocks.13.attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.13.encoder_attn.k_proj.weight -&gt; decoder.blocks.13.cross_attn.key.weight decoder.blocks.13.cross_attn.key.weight 2 (1280, 1280) model.decoder.layers.13.encoder_attn.v_proj.weight -&gt; decoder.blocks.13.cross_attn.value.weight decoder.blocks.13.cross_attn.value.weight 2 (1280, 1280) model.decoder.layers.13.encoder_attn.v_proj.bias -&gt; decoder.blocks.13.cross_attn.value.bias decoder.blocks.13.cross_attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.13.encoder_attn.q_proj.weight -&gt; decoder.blocks.13.cross_attn.query.weight decoder.blocks.13.cross_attn.query.weight 2 (1280, 1280) model.decoder.layers.13.encoder_attn.q_proj.bias -&gt; decoder.blocks.13.cross_attn.query.bias decoder.blocks.13.cross_attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.13.encoder_attn.out_proj.weight -&gt; decoder.blocks.13.cross_attn.out.weight decoder.blocks.13.cross_attn.out.weight 2 (1280, 1280) model.decoder.layers.13.encoder_attn.out_proj.bias -&gt; decoder.blocks.13.cross_attn.out.bias decoder.blocks.13.cross_attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.13.encoder_attn_layer_norm.weight -&gt; decoder.blocks.13.cross_attn_ln.weight decoder.blocks.13.cross_attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.13.encoder_attn_layer_norm.bias -&gt; decoder.blocks.13.cross_attn_ln.bias decoder.blocks.13.cross_attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.13.fc1.weight -&gt; decoder.blocks.13.mlp.0.weight decoder.blocks.13.mlp.0.weight 2 (5120, 1280) model.decoder.layers.13.fc1.bias -&gt; decoder.blocks.13.mlp.0.bias decoder.blocks.13.mlp.0.bias 1 (5120,) Converting to float32 model.decoder.layers.13.fc2.weight -&gt; decoder.blocks.13.mlp.2.weight decoder.blocks.13.mlp.2.weight 2 (1280, 5120) model.decoder.layers.13.fc2.bias -&gt; decoder.blocks.13.mlp.2.bias decoder.blocks.13.mlp.2.bias 1 (1280,) Converting to float32 model.decoder.layers.13.final_layer_norm.weight -&gt; decoder.blocks.13.mlp_ln.weight decoder.blocks.13.mlp_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.13.final_layer_norm.bias -&gt; decoder.blocks.13.mlp_ln.bias decoder.blocks.13.mlp_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.14.self_attn.k_proj.weight -&gt; decoder.blocks.14.attn.key.weight decoder.blocks.14.attn.key.weight 2 (1280, 1280) model.decoder.layers.14.self_attn.v_proj.weight -&gt; decoder.blocks.14.attn.value.weight decoder.blocks.14.attn.value.weight 2 (1280, 1280) model.decoder.layers.14.self_attn.v_proj.bias -&gt; decoder.blocks.14.attn.value.bias decoder.blocks.14.attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.14.self_attn.q_proj.weight -&gt; decoder.blocks.14.attn.query.weight decoder.blocks.14.attn.query.weight 2 (1280, 1280) model.decoder.layers.14.self_attn.q_proj.bias -&gt; decoder.blocks.14.attn.query.bias decoder.blocks.14.attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.14.self_attn.out_proj.weight -&gt; decoder.blocks.14.attn.out.weight decoder.blocks.14.attn.out.weight 2 (1280, 1280) model.decoder.layers.14.self_attn.out_proj.bias -&gt; decoder.blocks.14.attn.out.bias decoder.blocks.14.attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.14.self_attn_layer_norm.weight -&gt; decoder.blocks.14.attn_ln.weight decoder.blocks.14.attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.14.self_attn_layer_norm.bias -&gt; decoder.blocks.14.attn_ln.bias decoder.blocks.14.attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.14.encoder_attn.k_proj.weight -&gt; decoder.blocks.14.cross_attn.key.weight decoder.blocks.14.cross_attn.key.weight 2 (1280, 1280) model.decoder.layers.14.encoder_attn.v_proj.weight -&gt; decoder.blocks.14.cross_attn.value.weight decoder.blocks.14.cross_attn.value.weight 2 (1280, 1280) model.decoder.layers.14.encoder_attn.v_proj.bias -&gt; decoder.blocks.14.cross_attn.value.bias decoder.blocks.14.cross_attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.14.encoder_attn.q_proj.weight -&gt; decoder.blocks.14.cross_attn.query.weight decoder.blocks.14.cross_attn.query.weight 2 (1280, 1280) model.decoder.layers.14.encoder_attn.q_proj.bias -&gt; decoder.blocks.14.cross_attn.query.bias decoder.blocks.14.cross_attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.14.encoder_attn.out_proj.weight -&gt; decoder.blocks.14.cross_attn.out.weight decoder.blocks.14.cross_attn.out.weight 2 (1280, 1280) model.decoder.layers.14.encoder_attn.out_proj.bias -&gt; decoder.blocks.14.cross_attn.out.bias decoder.blocks.14.cross_attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.14.encoder_attn_layer_norm.weight -&gt; decoder.blocks.14.cross_attn_ln.weight decoder.blocks.14.cross_attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.14.encoder_attn_layer_norm.bias -&gt; decoder.blocks.14.cross_attn_ln.bias decoder.blocks.14.cross_attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.14.fc1.weight -&gt; decoder.blocks.14.mlp.0.weight decoder.blocks.14.mlp.0.weight 2 (5120, 1280) model.decoder.layers.14.fc1.bias -&gt; decoder.blocks.14.mlp.0.bias decoder.blocks.14.mlp.0.bias 1 (5120,) Converting to float32 model.decoder.layers.14.fc2.weight -&gt; decoder.blocks.14.mlp.2.weight decoder.blocks.14.mlp.2.weight 2 (1280, 5120) model.decoder.layers.14.fc2.bias -&gt; decoder.blocks.14.mlp.2.bias decoder.blocks.14.mlp.2.bias 1 (1280,) Converting to float32 model.decoder.layers.14.final_layer_norm.weight -&gt; decoder.blocks.14.mlp_ln.weight decoder.blocks.14.mlp_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.14.final_layer_norm.bias -&gt; decoder.blocks.14.mlp_ln.bias decoder.blocks.14.mlp_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.15.self_attn.k_proj.weight -&gt; decoder.blocks.15.attn.key.weight decoder.blocks.15.attn.key.weight 2 (1280, 1280) model.decoder.layers.15.self_attn.v_proj.weight -&gt; decoder.blocks.15.attn.value.weight decoder.blocks.15.attn.value.weight 2 (1280, 1280) model.decoder.layers.15.self_attn.v_proj.bias -&gt; decoder.blocks.15.attn.value.bias decoder.blocks.15.attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.15.self_attn.q_proj.weight -&gt; decoder.blocks.15.attn.query.weight decoder.blocks.15.attn.query.weight 2 (1280, 1280) model.decoder.layers.15.self_attn.q_proj.bias -&gt; decoder.blocks.15.attn.query.bias decoder.blocks.15.attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.15.self_attn.out_proj.weight -&gt; decoder.blocks.15.attn.out.weight decoder.blocks.15.attn.out.weight 2 (1280, 1280) model.decoder.layers.15.self_attn.out_proj.bias -&gt; decoder.blocks.15.attn.out.bias decoder.blocks.15.attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.15.self_attn_layer_norm.weight -&gt; decoder.blocks.15.attn_ln.weight decoder.blocks.15.attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.15.self_attn_layer_norm.bias -&gt; decoder.blocks.15.attn_ln.bias decoder.blocks.15.attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.15.encoder_attn.k_proj.weight -&gt; decoder.blocks.15.cross_attn.key.weight decoder.blocks.15.cross_attn.key.weight 2 (1280, 1280) model.decoder.layers.15.encoder_attn.v_proj.weight -&gt; decoder.blocks.15.cross_attn.value.weight decoder.blocks.15.cross_attn.value.weight 2 (1280, 1280) model.decoder.layers.15.encoder_attn.v_proj.bias -&gt; decoder.blocks.15.cross_attn.value.bias decoder.blocks.15.cross_attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.15.encoder_attn.q_proj.weight -&gt; decoder.blocks.15.cross_attn.query.weight decoder.blocks.15.cross_attn.query.weight 2 (1280, 1280) model.decoder.layers.15.encoder_attn.q_proj.bias -&gt; decoder.blocks.15.cross_attn.query.bias decoder.blocks.15.cross_attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.15.encoder_attn.out_proj.weight -&gt; decoder.blocks.15.cross_attn.out.weight decoder.blocks.15.cross_attn.out.weight 2 (1280, 1280) model.decoder.layers.15.encoder_attn.out_proj.bias -&gt; decoder.blocks.15.cross_attn.out.bias decoder.blocks.15.cross_attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.15.encoder_attn_layer_norm.weight -&gt; decoder.blocks.15.cross_attn_ln.weight decoder.blocks.15.cross_attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.15.encoder_attn_layer_norm.bias -&gt; decoder.blocks.15.cross_attn_ln.bias decoder.blocks.15.cross_attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.15.fc1.weight -&gt; decoder.blocks.15.mlp.0.weight decoder.blocks.15.mlp.0.weight 2 (5120, 1280) model.decoder.layers.15.fc1.bias -&gt; decoder.blocks.15.mlp.0.bias decoder.blocks.15.mlp.0.bias 1 (5120,) Converting to float32 model.decoder.layers.15.fc2.weight -&gt; decoder.blocks.15.mlp.2.weight decoder.blocks.15.mlp.2.weight 2 (1280, 5120) model.decoder.layers.15.fc2.bias -&gt; decoder.blocks.15.mlp.2.bias decoder.blocks.15.mlp.2.bias 1 (1280,) Converting to float32 model.decoder.layers.15.final_layer_norm.weight -&gt; decoder.blocks.15.mlp_ln.weight decoder.blocks.15.mlp_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.15.final_layer_norm.bias -&gt; decoder.blocks.15.mlp_ln.bias decoder.blocks.15.mlp_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.16.self_attn.k_proj.weight -&gt; decoder.blocks.16.attn.key.weight decoder.blocks.16.attn.key.weight 2 (1280, 1280) model.decoder.layers.16.self_attn.v_proj.weight -&gt; decoder.blocks.16.attn.value.weight decoder.blocks.16.attn.value.weight 2 (1280, 1280) model.decoder.layers.16.self_attn.v_proj.bias -&gt; decoder.blocks.16.attn.value.bias decoder.blocks.16.attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.16.self_attn.q_proj.weight -&gt; decoder.blocks.16.attn.query.weight decoder.blocks.16.attn.query.weight 2 (1280, 1280) model.decoder.layers.16.self_attn.q_proj.bias -&gt; decoder.blocks.16.attn.query.bias decoder.blocks.16.attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.16.self_attn.out_proj.weight -&gt; decoder.blocks.16.attn.out.weight decoder.blocks.16.attn.out.weight 2 (1280, 1280) model.decoder.layers.16.self_attn.out_proj.bias -&gt; decoder.blocks.16.attn.out.bias decoder.blocks.16.attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.16.self_attn_layer_norm.weight -&gt; decoder.blocks.16.attn_ln.weight decoder.blocks.16.attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.16.self_attn_layer_norm.bias -&gt; decoder.blocks.16.attn_ln.bias decoder.blocks.16.attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.16.encoder_attn.k_proj.weight -&gt; decoder.blocks.16.cross_attn.key.weight decoder.blocks.16.cross_attn.key.weight 2 (1280, 1280) model.decoder.layers.16.encoder_attn.v_proj.weight -&gt; decoder.blocks.16.cross_attn.value.weight decoder.blocks.16.cross_attn.value.weight 2 (1280, 1280) model.decoder.layers.16.encoder_attn.v_proj.bias -&gt; decoder.blocks.16.cross_attn.value.bias decoder.blocks.16.cross_attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.16.encoder_attn.q_proj.weight -&gt; decoder.blocks.16.cross_attn.query.weight decoder.blocks.16.cross_attn.query.weight 2 (1280, 1280) model.decoder.layers.16.encoder_attn.q_proj.bias -&gt; decoder.blocks.16.cross_attn.query.bias decoder.blocks.16.cross_attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.16.encoder_attn.out_proj.weight -&gt; decoder.blocks.16.cross_attn.out.weight decoder.blocks.16.cross_attn.out.weight 2 (1280, 1280) model.decoder.layers.16.encoder_attn.out_proj.bias -&gt; decoder.blocks.16.cross_attn.out.bias decoder.blocks.16.cross_attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.16.encoder_attn_layer_norm.weight -&gt; decoder.blocks.16.cross_attn_ln.weight decoder.blocks.16.cross_attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.16.encoder_attn_layer_norm.bias -&gt; decoder.blocks.16.cross_attn_ln.bias decoder.blocks.16.cross_attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.16.fc1.weight -&gt; decoder.blocks.16.mlp.0.weight decoder.blocks.16.mlp.0.weight 2 (5120, 1280) model.decoder.layers.16.fc1.bias -&gt; decoder.blocks.16.mlp.0.bias decoder.blocks.16.mlp.0.bias 1 (5120,) Converting to float32 model.decoder.layers.16.fc2.weight -&gt; decoder.blocks.16.mlp.2.weight decoder.blocks.16.mlp.2.weight 2 (1280, 5120) model.decoder.layers.16.fc2.bias -&gt; decoder.blocks.16.mlp.2.bias decoder.blocks.16.mlp.2.bias 1 (1280,) Converting to float32 model.decoder.layers.16.final_layer_norm.weight -&gt; decoder.blocks.16.mlp_ln.weight decoder.blocks.16.mlp_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.16.final_layer_norm.bias -&gt; decoder.blocks.16.mlp_ln.bias decoder.blocks.16.mlp_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.17.self_attn.k_proj.weight -&gt; decoder.blocks.17.attn.key.weight decoder.blocks.17.attn.key.weight 2 (1280, 1280) model.decoder.layers.17.self_attn.v_proj.weight -&gt; decoder.blocks.17.attn.value.weight decoder.blocks.17.attn.value.weight 2 (1280, 1280) model.decoder.layers.17.self_attn.v_proj.bias -&gt; decoder.blocks.17.attn.value.bias decoder.blocks.17.attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.17.self_attn.q_proj.weight -&gt; decoder.blocks.17.attn.query.weight decoder.blocks.17.attn.query.weight 2 (1280, 1280) model.decoder.layers.17.self_attn.q_proj.bias -&gt; decoder.blocks.17.attn.query.bias decoder.blocks.17.attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.17.self_attn.out_proj.weight -&gt; decoder.blocks.17.attn.out.weight decoder.blocks.17.attn.out.weight 2 (1280, 1280) model.decoder.layers.17.self_attn.out_proj.bias -&gt; decoder.blocks.17.attn.out.bias decoder.blocks.17.attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.17.self_attn_layer_norm.weight -&gt; decoder.blocks.17.attn_ln.weight decoder.blocks.17.attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.17.self_attn_layer_norm.bias -&gt; decoder.blocks.17.attn_ln.bias decoder.blocks.17.attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.17.encoder_attn.k_proj.weight -&gt; decoder.blocks.17.cross_attn.key.weight decoder.blocks.17.cross_attn.key.weight 2 (1280, 1280) model.decoder.layers.17.encoder_attn.v_proj.weight -&gt; decoder.blocks.17.cross_attn.value.weight decoder.blocks.17.cross_attn.value.weight 2 (1280, 1280) model.decoder.layers.17.encoder_attn.v_proj.bias -&gt; decoder.blocks.17.cross_attn.value.bias decoder.blocks.17.cross_attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.17.encoder_attn.q_proj.weight -&gt; decoder.blocks.17.cross_attn.query.weight decoder.blocks.17.cross_attn.query.weight 2 (1280, 1280) model.decoder.layers.17.encoder_attn.q_proj.bias -&gt; decoder.blocks.17.cross_attn.query.bias decoder.blocks.17.cross_attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.17.encoder_attn.out_proj.weight -&gt; decoder.blocks.17.cross_attn.out.weight decoder.blocks.17.cross_attn.out.weight 2 (1280, 1280) model.decoder.layers.17.encoder_attn.out_proj.bias -&gt; decoder.blocks.17.cross_attn.out.bias decoder.blocks.17.cross_attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.17.encoder_attn_layer_norm.weight -&gt; decoder.blocks.17.cross_attn_ln.weight decoder.blocks.17.cross_attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.17.encoder_attn_layer_norm.bias -&gt; decoder.blocks.17.cross_attn_ln.bias decoder.blocks.17.cross_attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.17.fc1.weight -&gt; decoder.blocks.17.mlp.0.weight decoder.blocks.17.mlp.0.weight 2 (5120, 1280) model.decoder.layers.17.fc1.bias -&gt; decoder.blocks.17.mlp.0.bias decoder.blocks.17.mlp.0.bias 1 (5120,) Converting to float32 model.decoder.layers.17.fc2.weight -&gt; decoder.blocks.17.mlp.2.weight decoder.blocks.17.mlp.2.weight 2 (1280, 5120) model.decoder.layers.17.fc2.bias -&gt; decoder.blocks.17.mlp.2.bias decoder.blocks.17.mlp.2.bias 1 (1280,) Converting to float32 model.decoder.layers.17.final_layer_norm.weight -&gt; decoder.blocks.17.mlp_ln.weight decoder.blocks.17.mlp_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.17.final_layer_norm.bias -&gt; decoder.blocks.17.mlp_ln.bias decoder.blocks.17.mlp_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.18.self_attn.k_proj.weight -&gt; decoder.blocks.18.attn.key.weight decoder.blocks.18.attn.key.weight 2 (1280, 1280) model.decoder.layers.18.self_attn.v_proj.weight -&gt; decoder.blocks.18.attn.value.weight decoder.blocks.18.attn.value.weight 2 (1280, 1280) model.decoder.layers.18.self_attn.v_proj.bias -&gt; decoder.blocks.18.attn.value.bias decoder.blocks.18.attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.18.self_attn.q_proj.weight -&gt; decoder.blocks.18.attn.query.weight decoder.blocks.18.attn.query.weight 2 (1280, 1280) model.decoder.layers.18.self_attn.q_proj.bias -&gt; decoder.blocks.18.attn.query.bias decoder.blocks.18.attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.18.self_attn.out_proj.weight -&gt; decoder.blocks.18.attn.out.weight decoder.blocks.18.attn.out.weight 2 (1280, 1280) model.decoder.layers.18.self_attn.out_proj.bias -&gt; decoder.blocks.18.attn.out.bias decoder.blocks.18.attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.18.self_attn_layer_norm.weight -&gt; decoder.blocks.18.attn_ln.weight decoder.blocks.18.attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.18.self_attn_layer_norm.bias -&gt; decoder.blocks.18.attn_ln.bias decoder.blocks.18.attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.18.encoder_attn.k_proj.weight -&gt; decoder.blocks.18.cross_attn.key.weight decoder.blocks.18.cross_attn.key.weight 2 (1280, 1280) model.decoder.layers.18.encoder_attn.v_proj.weight -&gt; decoder.blocks.18.cross_attn.value.weight decoder.blocks.18.cross_attn.value.weight 2 (1280, 1280) model.decoder.layers.18.encoder_attn.v_proj.bias -&gt; decoder.blocks.18.cross_attn.value.bias decoder.blocks.18.cross_attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.18.encoder_attn.q_proj.weight -&gt; decoder.blocks.18.cross_attn.query.weight decoder.blocks.18.cross_attn.query.weight 2 (1280, 1280) model.decoder.layers.18.encoder_attn.q_proj.bias -&gt; decoder.blocks.18.cross_attn.query.bias decoder.blocks.18.cross_attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.18.encoder_attn.out_proj.weight -&gt; decoder.blocks.18.cross_attn.out.weight decoder.blocks.18.cross_attn.out.weight 2 (1280, 1280) model.decoder.layers.18.encoder_attn.out_proj.bias -&gt; decoder.blocks.18.cross_attn.out.bias decoder.blocks.18.cross_attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.18.encoder_attn_layer_norm.weight -&gt; decoder.blocks.18.cross_attn_ln.weight decoder.blocks.18.cross_attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.18.encoder_attn_layer_norm.bias -&gt; decoder.blocks.18.cross_attn_ln.bias decoder.blocks.18.cross_attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.18.fc1.weight -&gt; decoder.blocks.18.mlp.0.weight decoder.blocks.18.mlp.0.weight 2 (5120, 1280) model.decoder.layers.18.fc1.bias -&gt; decoder.blocks.18.mlp.0.bias decoder.blocks.18.mlp.0.bias 1 (5120,) Converting to float32 model.decoder.layers.18.fc2.weight -&gt; decoder.blocks.18.mlp.2.weight decoder.blocks.18.mlp.2.weight 2 (1280, 5120) model.decoder.layers.18.fc2.bias -&gt; decoder.blocks.18.mlp.2.bias decoder.blocks.18.mlp.2.bias 1 (1280,) Converting to float32 model.decoder.layers.18.final_layer_norm.weight -&gt; decoder.blocks.18.mlp_ln.weight decoder.blocks.18.mlp_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.18.final_layer_norm.bias -&gt; decoder.blocks.18.mlp_ln.bias decoder.blocks.18.mlp_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.19.self_attn.k_proj.weight -&gt; decoder.blocks.19.attn.key.weight decoder.blocks.19.attn.key.weight 2 (1280, 1280) model.decoder.layers.19.self_attn.v_proj.weight -&gt; decoder.blocks.19.attn.value.weight decoder.blocks.19.attn.value.weight 2 (1280, 1280) model.decoder.layers.19.self_attn.v_proj.bias -&gt; decoder.blocks.19.attn.value.bias decoder.blocks.19.attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.19.self_attn.q_proj.weight -&gt; decoder.blocks.19.attn.query.weight decoder.blocks.19.attn.query.weight 2 (1280, 1280) model.decoder.layers.19.self_attn.q_proj.bias -&gt; decoder.blocks.19.attn.query.bias decoder.blocks.19.attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.19.self_attn.out_proj.weight -&gt; decoder.blocks.19.attn.out.weight decoder.blocks.19.attn.out.weight 2 (1280, 1280) model.decoder.layers.19.self_attn.out_proj.bias -&gt; decoder.blocks.19.attn.out.bias decoder.blocks.19.attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.19.self_attn_layer_norm.weight -&gt; decoder.blocks.19.attn_ln.weight decoder.blocks.19.attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.19.self_attn_layer_norm.bias -&gt; decoder.blocks.19.attn_ln.bias decoder.blocks.19.attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.19.encoder_attn.k_proj.weight -&gt; decoder.blocks.19.cross_attn.key.weight decoder.blocks.19.cross_attn.key.weight 2 (1280, 1280) model.decoder.layers.19.encoder_attn.v_proj.weight -&gt; decoder.blocks.19.cross_attn.value.weight decoder.blocks.19.cross_attn.value.weight 2 (1280, 1280) model.decoder.layers.19.encoder_attn.v_proj.bias -&gt; decoder.blocks.19.cross_attn.value.bias decoder.blocks.19.cross_attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.19.encoder_attn.q_proj.weight -&gt; decoder.blocks.19.cross_attn.query.weight decoder.blocks.19.cross_attn.query.weight 2 (1280, 1280) model.decoder.layers.19.encoder_attn.q_proj.bias -&gt; decoder.blocks.19.cross_attn.query.bias decoder.blocks.19.cross_attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.19.encoder_attn.out_proj.weight -&gt; decoder.blocks.19.cross_attn.out.weight decoder.blocks.19.cross_attn.out.weight 2 (1280, 1280) model.decoder.layers.19.encoder_attn.out_proj.bias -&gt; decoder.blocks.19.cross_attn.out.bias decoder.blocks.19.cross_attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.19.encoder_attn_layer_norm.weight -&gt; decoder.blocks.19.cross_attn_ln.weight decoder.blocks.19.cross_attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.19.encoder_attn_layer_norm.bias -&gt; decoder.blocks.19.cross_attn_ln.bias decoder.blocks.19.cross_attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.19.fc1.weight -&gt; decoder.blocks.19.mlp.0.weight decoder.blocks.19.mlp.0.weight 2 (5120, 1280) model.decoder.layers.19.fc1.bias -&gt; decoder.blocks.19.mlp.0.bias decoder.blocks.19.mlp.0.bias 1 (5120,) Converting to float32 model.decoder.layers.19.fc2.weight -&gt; decoder.blocks.19.mlp.2.weight decoder.blocks.19.mlp.2.weight 2 (1280, 5120) model.decoder.layers.19.fc2.bias -&gt; decoder.blocks.19.mlp.2.bias decoder.blocks.19.mlp.2.bias 1 (1280,) Converting to float32 model.decoder.layers.19.final_layer_norm.weight -&gt; decoder.blocks.19.mlp_ln.weight decoder.blocks.19.mlp_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.19.final_layer_norm.bias -&gt; decoder.blocks.19.mlp_ln.bias decoder.blocks.19.mlp_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.20.self_attn.k_proj.weight -&gt; decoder.blocks.20.attn.key.weight decoder.blocks.20.attn.key.weight 2 (1280, 1280) model.decoder.layers.20.self_attn.v_proj.weight -&gt; decoder.blocks.20.attn.value.weight decoder.blocks.20.attn.value.weight 2 (1280, 1280) model.decoder.layers.20.self_attn.v_proj.bias -&gt; decoder.blocks.20.attn.value.bias decoder.blocks.20.attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.20.self_attn.q_proj.weight -&gt; decoder.blocks.20.attn.query.weight decoder.blocks.20.attn.query.weight 2 (1280, 1280) model.decoder.layers.20.self_attn.q_proj.bias -&gt; decoder.blocks.20.attn.query.bias decoder.blocks.20.attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.20.self_attn.out_proj.weight -&gt; decoder.blocks.20.attn.out.weight decoder.blocks.20.attn.out.weight 2 (1280, 1280) model.decoder.layers.20.self_attn.out_proj.bias -&gt; decoder.blocks.20.attn.out.bias decoder.blocks.20.attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.20.self_attn_layer_norm.weight -&gt; decoder.blocks.20.attn_ln.weight decoder.blocks.20.attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.20.self_attn_layer_norm.bias -&gt; decoder.blocks.20.attn_ln.bias decoder.blocks.20.attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.20.encoder_attn.k_proj.weight -&gt; decoder.blocks.20.cross_attn.key.weight decoder.blocks.20.cross_attn.key.weight 2 (1280, 1280) model.decoder.layers.20.encoder_attn.v_proj.weight -&gt; decoder.blocks.20.cross_attn.value.weight decoder.blocks.20.cross_attn.value.weight 2 (1280, 1280) model.decoder.layers.20.encoder_attn.v_proj.bias -&gt; decoder.blocks.20.cross_attn.value.bias decoder.blocks.20.cross_attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.20.encoder_attn.q_proj.weight -&gt; decoder.blocks.20.cross_attn.query.weight decoder.blocks.20.cross_attn.query.weight 2 (1280, 1280) model.decoder.layers.20.encoder_attn.q_proj.bias -&gt; decoder.blocks.20.cross_attn.query.bias decoder.blocks.20.cross_attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.20.encoder_attn.out_proj.weight -&gt; decoder.blocks.20.cross_attn.out.weight decoder.blocks.20.cross_attn.out.weight 2 (1280, 1280) model.decoder.layers.20.encoder_attn.out_proj.bias -&gt; decoder.blocks.20.cross_attn.out.bias decoder.blocks.20.cross_attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.20.encoder_attn_layer_norm.weight -&gt; decoder.blocks.20.cross_attn_ln.weight decoder.blocks.20.cross_attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.20.encoder_attn_layer_norm.bias -&gt; decoder.blocks.20.cross_attn_ln.bias decoder.blocks.20.cross_attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.20.fc1.weight -&gt; decoder.blocks.20.mlp.0.weight decoder.blocks.20.mlp.0.weight 2 (5120, 1280) model.decoder.layers.20.fc1.bias -&gt; decoder.blocks.20.mlp.0.bias decoder.blocks.20.mlp.0.bias 1 (5120,) Converting to float32 model.decoder.layers.20.fc2.weight -&gt; decoder.blocks.20.mlp.2.weight decoder.blocks.20.mlp.2.weight 2 (1280, 5120) model.decoder.layers.20.fc2.bias -&gt; decoder.blocks.20.mlp.2.bias decoder.blocks.20.mlp.2.bias 1 (1280,) Converting to float32 model.decoder.layers.20.final_layer_norm.weight -&gt; decoder.blocks.20.mlp_ln.weight decoder.blocks.20.mlp_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.20.final_layer_norm.bias -&gt; decoder.blocks.20.mlp_ln.bias decoder.blocks.20.mlp_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.21.self_attn.k_proj.weight -&gt; decoder.blocks.21.attn.key.weight decoder.blocks.21.attn.key.weight 2 (1280, 1280) model.decoder.layers.21.self_attn.v_proj.weight -&gt; decoder.blocks.21.attn.value.weight decoder.blocks.21.attn.value.weight 2 (1280, 1280) model.decoder.layers.21.self_attn.v_proj.bias -&gt; decoder.blocks.21.attn.value.bias decoder.blocks.21.attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.21.self_attn.q_proj.weight -&gt; decoder.blocks.21.attn.query.weight decoder.blocks.21.attn.query.weight 2 (1280, 1280) model.decoder.layers.21.self_attn.q_proj.bias -&gt; decoder.blocks.21.attn.query.bias decoder.blocks.21.attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.21.self_attn.out_proj.weight -&gt; decoder.blocks.21.attn.out.weight decoder.blocks.21.attn.out.weight 2 (1280, 1280) model.decoder.layers.21.self_attn.out_proj.bias -&gt; decoder.blocks.21.attn.out.bias decoder.blocks.21.attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.21.self_attn_layer_norm.weight -&gt; decoder.blocks.21.attn_ln.weight decoder.blocks.21.attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.21.self_attn_layer_norm.bias -&gt; decoder.blocks.21.attn_ln.bias decoder.blocks.21.attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.21.encoder_attn.k_proj.weight -&gt; decoder.blocks.21.cross_attn.key.weight decoder.blocks.21.cross_attn.key.weight 2 (1280, 1280) model.decoder.layers.21.encoder_attn.v_proj.weight -&gt; decoder.blocks.21.cross_attn.value.weight decoder.blocks.21.cross_attn.value.weight 2 (1280, 1280) model.decoder.layers.21.encoder_attn.v_proj.bias -&gt; decoder.blocks.21.cross_attn.value.bias decoder.blocks.21.cross_attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.21.encoder_attn.q_proj.weight -&gt; decoder.blocks.21.cross_attn.query.weight decoder.blocks.21.cross_attn.query.weight 2 (1280, 1280) model.decoder.layers.21.encoder_attn.q_proj.bias -&gt; decoder.blocks.21.cross_attn.query.bias decoder.blocks.21.cross_attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.21.encoder_attn.out_proj.weight -&gt; decoder.blocks.21.cross_attn.out.weight decoder.blocks.21.cross_attn.out.weight 2 (1280, 1280) model.decoder.layers.21.encoder_attn.out_proj.bias -&gt; decoder.blocks.21.cross_attn.out.bias decoder.blocks.21.cross_attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.21.encoder_attn_layer_norm.weight -&gt; decoder.blocks.21.cross_attn_ln.weight decoder.blocks.21.cross_attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.21.encoder_attn_layer_norm.bias -&gt; decoder.blocks.21.cross_attn_ln.bias decoder.blocks.21.cross_attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.21.fc1.weight -&gt; decoder.blocks.21.mlp.0.weight decoder.blocks.21.mlp.0.weight 2 (5120, 1280) model.decoder.layers.21.fc1.bias -&gt; decoder.blocks.21.mlp.0.bias decoder.blocks.21.mlp.0.bias 1 (5120,) Converting to float32 model.decoder.layers.21.fc2.weight -&gt; decoder.blocks.21.mlp.2.weight decoder.blocks.21.mlp.2.weight 2 (1280, 5120) model.decoder.layers.21.fc2.bias -&gt; decoder.blocks.21.mlp.2.bias decoder.blocks.21.mlp.2.bias 1 (1280,) Converting to float32 model.decoder.layers.21.final_layer_norm.weight -&gt; decoder.blocks.21.mlp_ln.weight decoder.blocks.21.mlp_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.21.final_layer_norm.bias -&gt; decoder.blocks.21.mlp_ln.bias decoder.blocks.21.mlp_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.22.self_attn.k_proj.weight -&gt; decoder.blocks.22.attn.key.weight decoder.blocks.22.attn.key.weight 2 (1280, 1280) model.decoder.layers.22.self_attn.v_proj.weight -&gt; decoder.blocks.22.attn.value.weight decoder.blocks.22.attn.value.weight 2 (1280, 1280) model.decoder.layers.22.self_attn.v_proj.bias -&gt; decoder.blocks.22.attn.value.bias decoder.blocks.22.attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.22.self_attn.q_proj.weight -&gt; decoder.blocks.22.attn.query.weight decoder.blocks.22.attn.query.weight 2 (1280, 1280) model.decoder.layers.22.self_attn.q_proj.bias -&gt; decoder.blocks.22.attn.query.bias decoder.blocks.22.attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.22.self_attn.out_proj.weight -&gt; decoder.blocks.22.attn.out.weight decoder.blocks.22.attn.out.weight 2 (1280, 1280) model.decoder.layers.22.self_attn.out_proj.bias -&gt; decoder.blocks.22.attn.out.bias decoder.blocks.22.attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.22.self_attn_layer_norm.weight -&gt; decoder.blocks.22.attn_ln.weight decoder.blocks.22.attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.22.self_attn_layer_norm.bias -&gt; decoder.blocks.22.attn_ln.bias decoder.blocks.22.attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.22.encoder_attn.k_proj.weight -&gt; decoder.blocks.22.cross_attn.key.weight decoder.blocks.22.cross_attn.key.weight 2 (1280, 1280) model.decoder.layers.22.encoder_attn.v_proj.weight -&gt; decoder.blocks.22.cross_attn.value.weight decoder.blocks.22.cross_attn.value.weight 2 (1280, 1280) model.decoder.layers.22.encoder_attn.v_proj.bias -&gt; decoder.blocks.22.cross_attn.value.bias decoder.blocks.22.cross_attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.22.encoder_attn.q_proj.weight -&gt; decoder.blocks.22.cross_attn.query.weight decoder.blocks.22.cross_attn.query.weight 2 (1280, 1280) model.decoder.layers.22.encoder_attn.q_proj.bias -&gt; decoder.blocks.22.cross_attn.query.bias decoder.blocks.22.cross_attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.22.encoder_attn.out_proj.weight -&gt; decoder.blocks.22.cross_attn.out.weight decoder.blocks.22.cross_attn.out.weight 2 (1280, 1280) model.decoder.layers.22.encoder_attn.out_proj.bias -&gt; decoder.blocks.22.cross_attn.out.bias decoder.blocks.22.cross_attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.22.encoder_attn_layer_norm.weight -&gt; decoder.blocks.22.cross_attn_ln.weight decoder.blocks.22.cross_attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.22.encoder_attn_layer_norm.bias -&gt; decoder.blocks.22.cross_attn_ln.bias decoder.blocks.22.cross_attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.22.fc1.weight -&gt; decoder.blocks.22.mlp.0.weight decoder.blocks.22.mlp.0.weight 2 (5120, 1280) model.decoder.layers.22.fc1.bias -&gt; decoder.blocks.22.mlp.0.bias decoder.blocks.22.mlp.0.bias 1 (5120,) Converting to float32 model.decoder.layers.22.fc2.weight -&gt; decoder.blocks.22.mlp.2.weight decoder.blocks.22.mlp.2.weight 2 (1280, 5120) model.decoder.layers.22.fc2.bias -&gt; decoder.blocks.22.mlp.2.bias decoder.blocks.22.mlp.2.bias 1 (1280,) Converting to float32 model.decoder.layers.22.final_layer_norm.weight -&gt; decoder.blocks.22.mlp_ln.weight decoder.blocks.22.mlp_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.22.final_layer_norm.bias -&gt; decoder.blocks.22.mlp_ln.bias decoder.blocks.22.mlp_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.23.self_attn.k_proj.weight -&gt; decoder.blocks.23.attn.key.weight decoder.blocks.23.attn.key.weight 2 (1280, 1280) model.decoder.layers.23.self_attn.v_proj.weight -&gt; decoder.blocks.23.attn.value.weight decoder.blocks.23.attn.value.weight 2 (1280, 1280) model.decoder.layers.23.self_attn.v_proj.bias -&gt; decoder.blocks.23.attn.value.bias decoder.blocks.23.attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.23.self_attn.q_proj.weight -&gt; decoder.blocks.23.attn.query.weight decoder.blocks.23.attn.query.weight 2 (1280, 1280) model.decoder.layers.23.self_attn.q_proj.bias -&gt; decoder.blocks.23.attn.query.bias decoder.blocks.23.attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.23.self_attn.out_proj.weight -&gt; decoder.blocks.23.attn.out.weight decoder.blocks.23.attn.out.weight 2 (1280, 1280) model.decoder.layers.23.self_attn.out_proj.bias -&gt; decoder.blocks.23.attn.out.bias decoder.blocks.23.attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.23.self_attn_layer_norm.weight -&gt; decoder.blocks.23.attn_ln.weight decoder.blocks.23.attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.23.self_attn_layer_norm.bias -&gt; decoder.blocks.23.attn_ln.bias decoder.blocks.23.attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.23.encoder_attn.k_proj.weight -&gt; decoder.blocks.23.cross_attn.key.weight decoder.blocks.23.cross_attn.key.weight 2 (1280, 1280) model.decoder.layers.23.encoder_attn.v_proj.weight -&gt; decoder.blocks.23.cross_attn.value.weight decoder.blocks.23.cross_attn.value.weight 2 (1280, 1280) model.decoder.layers.23.encoder_attn.v_proj.bias -&gt; decoder.blocks.23.cross_attn.value.bias decoder.blocks.23.cross_attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.23.encoder_attn.q_proj.weight -&gt; decoder.blocks.23.cross_attn.query.weight decoder.blocks.23.cross_attn.query.weight 2 (1280, 1280) model.decoder.layers.23.encoder_attn.q_proj.bias -&gt; decoder.blocks.23.cross_attn.query.bias decoder.blocks.23.cross_attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.23.encoder_attn.out_proj.weight -&gt; decoder.blocks.23.cross_attn.out.weight decoder.blocks.23.cross_attn.out.weight 2 (1280, 1280) model.decoder.layers.23.encoder_attn.out_proj.bias -&gt; decoder.blocks.23.cross_attn.out.bias decoder.blocks.23.cross_attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.23.encoder_attn_layer_norm.weight -&gt; decoder.blocks.23.cross_attn_ln.weight decoder.blocks.23.cross_attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.23.encoder_attn_layer_norm.bias -&gt; decoder.blocks.23.cross_attn_ln.bias decoder.blocks.23.cross_attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.23.fc1.weight -&gt; decoder.blocks.23.mlp.0.weight decoder.blocks.23.mlp.0.weight 2 (5120, 1280) model.decoder.layers.23.fc1.bias -&gt; decoder.blocks.23.mlp.0.bias decoder.blocks.23.mlp.0.bias 1 (5120,) Converting to float32 model.decoder.layers.23.fc2.weight -&gt; decoder.blocks.23.mlp.2.weight decoder.blocks.23.mlp.2.weight 2 (1280, 5120) model.decoder.layers.23.fc2.bias -&gt; decoder.blocks.23.mlp.2.bias decoder.blocks.23.mlp.2.bias 1 (1280,) Converting to float32 model.decoder.layers.23.final_layer_norm.weight -&gt; decoder.blocks.23.mlp_ln.weight decoder.blocks.23.mlp_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.23.final_layer_norm.bias -&gt; decoder.blocks.23.mlp_ln.bias decoder.blocks.23.mlp_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.24.self_attn.k_proj.weight -&gt; decoder.blocks.24.attn.key.weight decoder.blocks.24.attn.key.weight 2 (1280, 1280) model.decoder.layers.24.self_attn.v_proj.weight -&gt; decoder.blocks.24.attn.value.weight decoder.blocks.24.attn.value.weight 2 (1280, 1280) model.decoder.layers.24.self_attn.v_proj.bias -&gt; decoder.blocks.24.attn.value.bias decoder.blocks.24.attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.24.self_attn.q_proj.weight -&gt; decoder.blocks.24.attn.query.weight decoder.blocks.24.attn.query.weight 2 (1280, 1280) model.decoder.layers.24.self_attn.q_proj.bias -&gt; decoder.blocks.24.attn.query.bias decoder.blocks.24.attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.24.self_attn.out_proj.weight -&gt; decoder.blocks.24.attn.out.weight decoder.blocks.24.attn.out.weight 2 (1280, 1280) model.decoder.layers.24.self_attn.out_proj.bias -&gt; decoder.blocks.24.attn.out.bias decoder.blocks.24.attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.24.self_attn_layer_norm.weight -&gt; decoder.blocks.24.attn_ln.weight decoder.blocks.24.attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.24.self_attn_layer_norm.bias -&gt; decoder.blocks.24.attn_ln.bias decoder.blocks.24.attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.24.encoder_attn.k_proj.weight -&gt; decoder.blocks.24.cross_attn.key.weight decoder.blocks.24.cross_attn.key.weight 2 (1280, 1280) model.decoder.layers.24.encoder_attn.v_proj.weight -&gt; decoder.blocks.24.cross_attn.value.weight decoder.blocks.24.cross_attn.value.weight 2 (1280, 1280) model.decoder.layers.24.encoder_attn.v_proj.bias -&gt; decoder.blocks.24.cross_attn.value.bias decoder.blocks.24.cross_attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.24.encoder_attn.q_proj.weight -&gt; decoder.blocks.24.cross_attn.query.weight decoder.blocks.24.cross_attn.query.weight 2 (1280, 1280) model.decoder.layers.24.encoder_attn.q_proj.bias -&gt; decoder.blocks.24.cross_attn.query.bias decoder.blocks.24.cross_attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.24.encoder_attn.out_proj.weight -&gt; decoder.blocks.24.cross_attn.out.weight decoder.blocks.24.cross_attn.out.weight 2 (1280, 1280) model.decoder.layers.24.encoder_attn.out_proj.bias -&gt; decoder.blocks.24.cross_attn.out.bias decoder.blocks.24.cross_attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.24.encoder_attn_layer_norm.weight -&gt; decoder.blocks.24.cross_attn_ln.weight decoder.blocks.24.cross_attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.24.encoder_attn_layer_norm.bias -&gt; decoder.blocks.24.cross_attn_ln.bias decoder.blocks.24.cross_attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.24.fc1.weight -&gt; decoder.blocks.24.mlp.0.weight decoder.blocks.24.mlp.0.weight 2 (5120, 1280) model.decoder.layers.24.fc1.bias -&gt; decoder.blocks.24.mlp.0.bias decoder.blocks.24.mlp.0.bias 1 (5120,) Converting to float32 model.decoder.layers.24.fc2.weight -&gt; decoder.blocks.24.mlp.2.weight decoder.blocks.24.mlp.2.weight 2 (1280, 5120) model.decoder.layers.24.fc2.bias -&gt; decoder.blocks.24.mlp.2.bias decoder.blocks.24.mlp.2.bias 1 (1280,) Converting to float32 model.decoder.layers.24.final_layer_norm.weight -&gt; decoder.blocks.24.mlp_ln.weight decoder.blocks.24.mlp_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.24.final_layer_norm.bias -&gt; decoder.blocks.24.mlp_ln.bias decoder.blocks.24.mlp_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.25.self_attn.k_proj.weight -&gt; decoder.blocks.25.attn.key.weight decoder.blocks.25.attn.key.weight 2 (1280, 1280) model.decoder.layers.25.self_attn.v_proj.weight -&gt; decoder.blocks.25.attn.value.weight decoder.blocks.25.attn.value.weight 2 (1280, 1280) model.decoder.layers.25.self_attn.v_proj.bias -&gt; decoder.blocks.25.attn.value.bias decoder.blocks.25.attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.25.self_attn.q_proj.weight -&gt; decoder.blocks.25.attn.query.weight decoder.blocks.25.attn.query.weight 2 (1280, 1280) model.decoder.layers.25.self_attn.q_proj.bias -&gt; decoder.blocks.25.attn.query.bias decoder.blocks.25.attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.25.self_attn.out_proj.weight -&gt; decoder.blocks.25.attn.out.weight decoder.blocks.25.attn.out.weight 2 (1280, 1280) model.decoder.layers.25.self_attn.out_proj.bias -&gt; decoder.blocks.25.attn.out.bias decoder.blocks.25.attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.25.self_attn_layer_norm.weight -&gt; decoder.blocks.25.attn_ln.weight decoder.blocks.25.attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.25.self_attn_layer_norm.bias -&gt; decoder.blocks.25.attn_ln.bias decoder.blocks.25.attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.25.encoder_attn.k_proj.weight -&gt; decoder.blocks.25.cross_attn.key.weight decoder.blocks.25.cross_attn.key.weight 2 (1280, 1280) model.decoder.layers.25.encoder_attn.v_proj.weight -&gt; decoder.blocks.25.cross_attn.value.weight decoder.blocks.25.cross_attn.value.weight 2 (1280, 1280) model.decoder.layers.25.encoder_attn.v_proj.bias -&gt; decoder.blocks.25.cross_attn.value.bias decoder.blocks.25.cross_attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.25.encoder_attn.q_proj.weight -&gt; decoder.blocks.25.cross_attn.query.weight decoder.blocks.25.cross_attn.query.weight 2 (1280, 1280) model.decoder.layers.25.encoder_attn.q_proj.bias -&gt; decoder.blocks.25.cross_attn.query.bias decoder.blocks.25.cross_attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.25.encoder_attn.out_proj.weight -&gt; decoder.blocks.25.cross_attn.out.weight decoder.blocks.25.cross_attn.out.weight 2 (1280, 1280) model.decoder.layers.25.encoder_attn.out_proj.bias -&gt; decoder.blocks.25.cross_attn.out.bias decoder.blocks.25.cross_attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.25.encoder_attn_layer_norm.weight -&gt; decoder.blocks.25.cross_attn_ln.weight decoder.blocks.25.cross_attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.25.encoder_attn_layer_norm.bias -&gt; decoder.blocks.25.cross_attn_ln.bias decoder.blocks.25.cross_attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.25.fc1.weight -&gt; decoder.blocks.25.mlp.0.weight decoder.blocks.25.mlp.0.weight 2 (5120, 1280) model.decoder.layers.25.fc1.bias -&gt; decoder.blocks.25.mlp.0.bias decoder.blocks.25.mlp.0.bias 1 (5120,) Converting to float32 model.decoder.layers.25.fc2.weight -&gt; decoder.blocks.25.mlp.2.weight decoder.blocks.25.mlp.2.weight 2 (1280, 5120) model.decoder.layers.25.fc2.bias -&gt; decoder.blocks.25.mlp.2.bias decoder.blocks.25.mlp.2.bias 1 (1280,) Converting to float32 model.decoder.layers.25.final_layer_norm.weight -&gt; decoder.blocks.25.mlp_ln.weight decoder.blocks.25.mlp_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.25.final_layer_norm.bias -&gt; decoder.blocks.25.mlp_ln.bias decoder.blocks.25.mlp_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.26.self_attn.k_proj.weight -&gt; decoder.blocks.26.attn.key.weight decoder.blocks.26.attn.key.weight 2 (1280, 1280) model.decoder.layers.26.self_attn.v_proj.weight -&gt; decoder.blocks.26.attn.value.weight decoder.blocks.26.attn.value.weight 2 (1280, 1280) model.decoder.layers.26.self_attn.v_proj.bias -&gt; decoder.blocks.26.attn.value.bias decoder.blocks.26.attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.26.self_attn.q_proj.weight -&gt; decoder.blocks.26.attn.query.weight decoder.blocks.26.attn.query.weight 2 (1280, 1280) model.decoder.layers.26.self_attn.q_proj.bias -&gt; decoder.blocks.26.attn.query.bias decoder.blocks.26.attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.26.self_attn.out_proj.weight -&gt; decoder.blocks.26.attn.out.weight decoder.blocks.26.attn.out.weight 2 (1280, 1280) model.decoder.layers.26.self_attn.out_proj.bias -&gt; decoder.blocks.26.attn.out.bias decoder.blocks.26.attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.26.self_attn_layer_norm.weight -&gt; decoder.blocks.26.attn_ln.weight decoder.blocks.26.attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.26.self_attn_layer_norm.bias -&gt; decoder.blocks.26.attn_ln.bias decoder.blocks.26.attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.26.encoder_attn.k_proj.weight -&gt; decoder.blocks.26.cross_attn.key.weight decoder.blocks.26.cross_attn.key.weight 2 (1280, 1280) model.decoder.layers.26.encoder_attn.v_proj.weight -&gt; decoder.blocks.26.cross_attn.value.weight decoder.blocks.26.cross_attn.value.weight 2 (1280, 1280) model.decoder.layers.26.encoder_attn.v_proj.bias -&gt; decoder.blocks.26.cross_attn.value.bias decoder.blocks.26.cross_attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.26.encoder_attn.q_proj.weight -&gt; decoder.blocks.26.cross_attn.query.weight decoder.blocks.26.cross_attn.query.weight 2 (1280, 1280) model.decoder.layers.26.encoder_attn.q_proj.bias -&gt; decoder.blocks.26.cross_attn.query.bias decoder.blocks.26.cross_attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.26.encoder_attn.out_proj.weight -&gt; decoder.blocks.26.cross_attn.out.weight decoder.blocks.26.cross_attn.out.weight 2 (1280, 1280) model.decoder.layers.26.encoder_attn.out_proj.bias -&gt; decoder.blocks.26.cross_attn.out.bias decoder.blocks.26.cross_attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.26.encoder_attn_layer_norm.weight -&gt; decoder.blocks.26.cross_attn_ln.weight decoder.blocks.26.cross_attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.26.encoder_attn_layer_norm.bias -&gt; decoder.blocks.26.cross_attn_ln.bias decoder.blocks.26.cross_attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.26.fc1.weight -&gt; decoder.blocks.26.mlp.0.weight decoder.blocks.26.mlp.0.weight 2 (5120, 1280) model.decoder.layers.26.fc1.bias -&gt; decoder.blocks.26.mlp.0.bias decoder.blocks.26.mlp.0.bias 1 (5120,) Converting to float32 model.decoder.layers.26.fc2.weight -&gt; decoder.blocks.26.mlp.2.weight decoder.blocks.26.mlp.2.weight 2 (1280, 5120) model.decoder.layers.26.fc2.bias -&gt; decoder.blocks.26.mlp.2.bias decoder.blocks.26.mlp.2.bias 1 (1280,) Converting to float32 model.decoder.layers.26.final_layer_norm.weight -&gt; decoder.blocks.26.mlp_ln.weight decoder.blocks.26.mlp_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.26.final_layer_norm.bias -&gt; decoder.blocks.26.mlp_ln.bias decoder.blocks.26.mlp_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.27.self_attn.k_proj.weight -&gt; decoder.blocks.27.attn.key.weight decoder.blocks.27.attn.key.weight 2 (1280, 1280) model.decoder.layers.27.self_attn.v_proj.weight -&gt; decoder.blocks.27.attn.value.weight decoder.blocks.27.attn.value.weight 2 (1280, 1280) model.decoder.layers.27.self_attn.v_proj.bias -&gt; decoder.blocks.27.attn.value.bias decoder.blocks.27.attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.27.self_attn.q_proj.weight -&gt; decoder.blocks.27.attn.query.weight decoder.blocks.27.attn.query.weight 2 (1280, 1280) model.decoder.layers.27.self_attn.q_proj.bias -&gt; decoder.blocks.27.attn.query.bias decoder.blocks.27.attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.27.self_attn.out_proj.weight -&gt; decoder.blocks.27.attn.out.weight decoder.blocks.27.attn.out.weight 2 (1280, 1280) model.decoder.layers.27.self_attn.out_proj.bias -&gt; decoder.blocks.27.attn.out.bias decoder.blocks.27.attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.27.self_attn_layer_norm.weight -&gt; decoder.blocks.27.attn_ln.weight decoder.blocks.27.attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.27.self_attn_layer_norm.bias -&gt; decoder.blocks.27.attn_ln.bias decoder.blocks.27.attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.27.encoder_attn.k_proj.weight -&gt; decoder.blocks.27.cross_attn.key.weight decoder.blocks.27.cross_attn.key.weight 2 (1280, 1280) model.decoder.layers.27.encoder_attn.v_proj.weight -&gt; decoder.blocks.27.cross_attn.value.weight decoder.blocks.27.cross_attn.value.weight 2 (1280, 1280) model.decoder.layers.27.encoder_attn.v_proj.bias -&gt; decoder.blocks.27.cross_attn.value.bias decoder.blocks.27.cross_attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.27.encoder_attn.q_proj.weight -&gt; decoder.blocks.27.cross_attn.query.weight decoder.blocks.27.cross_attn.query.weight 2 (1280, 1280) model.decoder.layers.27.encoder_attn.q_proj.bias -&gt; decoder.blocks.27.cross_attn.query.bias decoder.blocks.27.cross_attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.27.encoder_attn.out_proj.weight -&gt; decoder.blocks.27.cross_attn.out.weight decoder.blocks.27.cross_attn.out.weight 2 (1280, 1280) model.decoder.layers.27.encoder_attn.out_proj.bias -&gt; decoder.blocks.27.cross_attn.out.bias decoder.blocks.27.cross_attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.27.encoder_attn_layer_norm.weight -&gt; decoder.blocks.27.cross_attn_ln.weight decoder.blocks.27.cross_attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.27.encoder_attn_layer_norm.bias -&gt; decoder.blocks.27.cross_attn_ln.bias decoder.blocks.27.cross_attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.27.fc1.weight -&gt; decoder.blocks.27.mlp.0.weight decoder.blocks.27.mlp.0.weight 2 (5120, 1280) model.decoder.layers.27.fc1.bias -&gt; decoder.blocks.27.mlp.0.bias decoder.blocks.27.mlp.0.bias 1 (5120,) Converting to float32 model.decoder.layers.27.fc2.weight -&gt; decoder.blocks.27.mlp.2.weight decoder.blocks.27.mlp.2.weight 2 (1280, 5120) model.decoder.layers.27.fc2.bias -&gt; decoder.blocks.27.mlp.2.bias decoder.blocks.27.mlp.2.bias 1 (1280,) Converting to float32 model.decoder.layers.27.final_layer_norm.weight -&gt; decoder.blocks.27.mlp_ln.weight decoder.blocks.27.mlp_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.27.final_layer_norm.bias -&gt; decoder.blocks.27.mlp_ln.bias decoder.blocks.27.mlp_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.28.self_attn.k_proj.weight -&gt; decoder.blocks.28.attn.key.weight decoder.blocks.28.attn.key.weight 2 (1280, 1280) model.decoder.layers.28.self_attn.v_proj.weight -&gt; decoder.blocks.28.attn.value.weight decoder.blocks.28.attn.value.weight 2 (1280, 1280) model.decoder.layers.28.self_attn.v_proj.bias -&gt; decoder.blocks.28.attn.value.bias decoder.blocks.28.attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.28.self_attn.q_proj.weight -&gt; decoder.blocks.28.attn.query.weight decoder.blocks.28.attn.query.weight 2 (1280, 1280) model.decoder.layers.28.self_attn.q_proj.bias -&gt; decoder.blocks.28.attn.query.bias decoder.blocks.28.attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.28.self_attn.out_proj.weight -&gt; decoder.blocks.28.attn.out.weight decoder.blocks.28.attn.out.weight 2 (1280, 1280) model.decoder.layers.28.self_attn.out_proj.bias -&gt; decoder.blocks.28.attn.out.bias decoder.blocks.28.attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.28.self_attn_layer_norm.weight -&gt; decoder.blocks.28.attn_ln.weight decoder.blocks.28.attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.28.self_attn_layer_norm.bias -&gt; decoder.blocks.28.attn_ln.bias decoder.blocks.28.attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.28.encoder_attn.k_proj.weight -&gt; decoder.blocks.28.cross_attn.key.weight decoder.blocks.28.cross_attn.key.weight 2 (1280, 1280) model.decoder.layers.28.encoder_attn.v_proj.weight -&gt; decoder.blocks.28.cross_attn.value.weight decoder.blocks.28.cross_attn.value.weight 2 (1280, 1280) model.decoder.layers.28.encoder_attn.v_proj.bias -&gt; decoder.blocks.28.cross_attn.value.bias decoder.blocks.28.cross_attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.28.encoder_attn.q_proj.weight -&gt; decoder.blocks.28.cross_attn.query.weight decoder.blocks.28.cross_attn.query.weight 2 (1280, 1280) model.decoder.layers.28.encoder_attn.q_proj.bias -&gt; decoder.blocks.28.cross_attn.query.bias decoder.blocks.28.cross_attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.28.encoder_attn.out_proj.weight -&gt; decoder.blocks.28.cross_attn.out.weight decoder.blocks.28.cross_attn.out.weight 2 (1280, 1280) model.decoder.layers.28.encoder_attn.out_proj.bias -&gt; decoder.blocks.28.cross_attn.out.bias decoder.blocks.28.cross_attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.28.encoder_attn_layer_norm.weight -&gt; decoder.blocks.28.cross_attn_ln.weight decoder.blocks.28.cross_attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.28.encoder_attn_layer_norm.bias -&gt; decoder.blocks.28.cross_attn_ln.bias decoder.blocks.28.cross_attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.28.fc1.weight -&gt; decoder.blocks.28.mlp.0.weight decoder.blocks.28.mlp.0.weight 2 (5120, 1280) model.decoder.layers.28.fc1.bias -&gt; decoder.blocks.28.mlp.0.bias decoder.blocks.28.mlp.0.bias 1 (5120,) Converting to float32 model.decoder.layers.28.fc2.weight -&gt; decoder.blocks.28.mlp.2.weight decoder.blocks.28.mlp.2.weight 2 (1280, 5120) model.decoder.layers.28.fc2.bias -&gt; decoder.blocks.28.mlp.2.bias decoder.blocks.28.mlp.2.bias 1 (1280,) Converting to float32 model.decoder.layers.28.final_layer_norm.weight -&gt; decoder.blocks.28.mlp_ln.weight decoder.blocks.28.mlp_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.28.final_layer_norm.bias -&gt; decoder.blocks.28.mlp_ln.bias decoder.blocks.28.mlp_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.29.self_attn.k_proj.weight -&gt; decoder.blocks.29.attn.key.weight decoder.blocks.29.attn.key.weight 2 (1280, 1280) model.decoder.layers.29.self_attn.v_proj.weight -&gt; decoder.blocks.29.attn.value.weight decoder.blocks.29.attn.value.weight 2 (1280, 1280) model.decoder.layers.29.self_attn.v_proj.bias -&gt; decoder.blocks.29.attn.value.bias decoder.blocks.29.attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.29.self_attn.q_proj.weight -&gt; decoder.blocks.29.attn.query.weight decoder.blocks.29.attn.query.weight 2 (1280, 1280) model.decoder.layers.29.self_attn.q_proj.bias -&gt; decoder.blocks.29.attn.query.bias decoder.blocks.29.attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.29.self_attn.out_proj.weight -&gt; decoder.blocks.29.attn.out.weight decoder.blocks.29.attn.out.weight 2 (1280, 1280) model.decoder.layers.29.self_attn.out_proj.bias -&gt; decoder.blocks.29.attn.out.bias decoder.blocks.29.attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.29.self_attn_layer_norm.weight -&gt; decoder.blocks.29.attn_ln.weight decoder.blocks.29.attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.29.self_attn_layer_norm.bias -&gt; decoder.blocks.29.attn_ln.bias decoder.blocks.29.attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.29.encoder_attn.k_proj.weight -&gt; decoder.blocks.29.cross_attn.key.weight decoder.blocks.29.cross_attn.key.weight 2 (1280, 1280) model.decoder.layers.29.encoder_attn.v_proj.weight -&gt; decoder.blocks.29.cross_attn.value.weight decoder.blocks.29.cross_attn.value.weight 2 (1280, 1280) model.decoder.layers.29.encoder_attn.v_proj.bias -&gt; decoder.blocks.29.cross_attn.value.bias decoder.blocks.29.cross_attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.29.encoder_attn.q_proj.weight -&gt; decoder.blocks.29.cross_attn.query.weight decoder.blocks.29.cross_attn.query.weight 2 (1280, 1280) model.decoder.layers.29.encoder_attn.q_proj.bias -&gt; decoder.blocks.29.cross_attn.query.bias decoder.blocks.29.cross_attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.29.encoder_attn.out_proj.weight -&gt; decoder.blocks.29.cross_attn.out.weight decoder.blocks.29.cross_attn.out.weight 2 (1280, 1280) model.decoder.layers.29.encoder_attn.out_proj.bias -&gt; decoder.blocks.29.cross_attn.out.bias decoder.blocks.29.cross_attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.29.encoder_attn_layer_norm.weight -&gt; decoder.blocks.29.cross_attn_ln.weight decoder.blocks.29.cross_attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.29.encoder_attn_layer_norm.bias -&gt; decoder.blocks.29.cross_attn_ln.bias decoder.blocks.29.cross_attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.29.fc1.weight -&gt; decoder.blocks.29.mlp.0.weight decoder.blocks.29.mlp.0.weight 2 (5120, 1280) model.decoder.layers.29.fc1.bias -&gt; decoder.blocks.29.mlp.0.bias decoder.blocks.29.mlp.0.bias 1 (5120,) Converting to float32 model.decoder.layers.29.fc2.weight -&gt; decoder.blocks.29.mlp.2.weight decoder.blocks.29.mlp.2.weight 2 (1280, 5120) model.decoder.layers.29.fc2.bias -&gt; decoder.blocks.29.mlp.2.bias decoder.blocks.29.mlp.2.bias 1 (1280,) Converting to float32 model.decoder.layers.29.final_layer_norm.weight -&gt; decoder.blocks.29.mlp_ln.weight decoder.blocks.29.mlp_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.29.final_layer_norm.bias -&gt; decoder.blocks.29.mlp_ln.bias decoder.blocks.29.mlp_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.30.self_attn.k_proj.weight -&gt; decoder.blocks.30.attn.key.weight decoder.blocks.30.attn.key.weight 2 (1280, 1280) model.decoder.layers.30.self_attn.v_proj.weight -&gt; decoder.blocks.30.attn.value.weight decoder.blocks.30.attn.value.weight 2 (1280, 1280) model.decoder.layers.30.self_attn.v_proj.bias -&gt; decoder.blocks.30.attn.value.bias decoder.blocks.30.attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.30.self_attn.q_proj.weight -&gt; decoder.blocks.30.attn.query.weight decoder.blocks.30.attn.query.weight 2 (1280, 1280) model.decoder.layers.30.self_attn.q_proj.bias -&gt; decoder.blocks.30.attn.query.bias decoder.blocks.30.attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.30.self_attn.out_proj.weight -&gt; decoder.blocks.30.attn.out.weight decoder.blocks.30.attn.out.weight 2 (1280, 1280) model.decoder.layers.30.self_attn.out_proj.bias -&gt; decoder.blocks.30.attn.out.bias decoder.blocks.30.attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.30.self_attn_layer_norm.weight -&gt; decoder.blocks.30.attn_ln.weight decoder.blocks.30.attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.30.self_attn_layer_norm.bias -&gt; decoder.blocks.30.attn_ln.bias decoder.blocks.30.attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.30.encoder_attn.k_proj.weight -&gt; decoder.blocks.30.cross_attn.key.weight decoder.blocks.30.cross_attn.key.weight 2 (1280, 1280) model.decoder.layers.30.encoder_attn.v_proj.weight -&gt; decoder.blocks.30.cross_attn.value.weight decoder.blocks.30.cross_attn.value.weight 2 (1280, 1280) model.decoder.layers.30.encoder_attn.v_proj.bias -&gt; decoder.blocks.30.cross_attn.value.bias decoder.blocks.30.cross_attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.30.encoder_attn.q_proj.weight -&gt; decoder.blocks.30.cross_attn.query.weight decoder.blocks.30.cross_attn.query.weight 2 (1280, 1280) model.decoder.layers.30.encoder_attn.q_proj.bias -&gt; decoder.blocks.30.cross_attn.query.bias decoder.blocks.30.cross_attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.30.encoder_attn.out_proj.weight -&gt; decoder.blocks.30.cross_attn.out.weight decoder.blocks.30.cross_attn.out.weight 2 (1280, 1280) model.decoder.layers.30.encoder_attn.out_proj.bias -&gt; decoder.blocks.30.cross_attn.out.bias decoder.blocks.30.cross_attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.30.encoder_attn_layer_norm.weight -&gt; decoder.blocks.30.cross_attn_ln.weight decoder.blocks.30.cross_attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.30.encoder_attn_layer_norm.bias -&gt; decoder.blocks.30.cross_attn_ln.bias decoder.blocks.30.cross_attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.30.fc1.weight -&gt; decoder.blocks.30.mlp.0.weight decoder.blocks.30.mlp.0.weight 2 (5120, 1280) model.decoder.layers.30.fc1.bias -&gt; decoder.blocks.30.mlp.0.bias decoder.blocks.30.mlp.0.bias 1 (5120,) Converting to float32 model.decoder.layers.30.fc2.weight -&gt; decoder.blocks.30.mlp.2.weight decoder.blocks.30.mlp.2.weight 2 (1280, 5120) model.decoder.layers.30.fc2.bias -&gt; decoder.blocks.30.mlp.2.bias decoder.blocks.30.mlp.2.bias 1 (1280,) Converting to float32 model.decoder.layers.30.final_layer_norm.weight -&gt; decoder.blocks.30.mlp_ln.weight decoder.blocks.30.mlp_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.30.final_layer_norm.bias -&gt; decoder.blocks.30.mlp_ln.bias decoder.blocks.30.mlp_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.31.self_attn.k_proj.weight -&gt; decoder.blocks.31.attn.key.weight decoder.blocks.31.attn.key.weight 2 (1280, 1280) model.decoder.layers.31.self_attn.v_proj.weight -&gt; decoder.blocks.31.attn.value.weight decoder.blocks.31.attn.value.weight 2 (1280, 1280) model.decoder.layers.31.self_attn.v_proj.bias -&gt; decoder.blocks.31.attn.value.bias decoder.blocks.31.attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.31.self_attn.q_proj.weight -&gt; decoder.blocks.31.attn.query.weight decoder.blocks.31.attn.query.weight 2 (1280, 1280) model.decoder.layers.31.self_attn.q_proj.bias -&gt; decoder.blocks.31.attn.query.bias decoder.blocks.31.attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.31.self_attn.out_proj.weight -&gt; decoder.blocks.31.attn.out.weight decoder.blocks.31.attn.out.weight 2 (1280, 1280) model.decoder.layers.31.self_attn.out_proj.bias -&gt; decoder.blocks.31.attn.out.bias decoder.blocks.31.attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.31.self_attn_layer_norm.weight -&gt; decoder.blocks.31.attn_ln.weight decoder.blocks.31.attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.31.self_attn_layer_norm.bias -&gt; decoder.blocks.31.attn_ln.bias decoder.blocks.31.attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.31.encoder_attn.k_proj.weight -&gt; decoder.blocks.31.cross_attn.key.weight decoder.blocks.31.cross_attn.key.weight 2 (1280, 1280) model.decoder.layers.31.encoder_attn.v_proj.weight -&gt; decoder.blocks.31.cross_attn.value.weight decoder.blocks.31.cross_attn.value.weight 2 (1280, 1280) model.decoder.layers.31.encoder_attn.v_proj.bias -&gt; decoder.blocks.31.cross_attn.value.bias decoder.blocks.31.cross_attn.value.bias 1 (1280,) Converting to float32 model.decoder.layers.31.encoder_attn.q_proj.weight -&gt; decoder.blocks.31.cross_attn.query.weight decoder.blocks.31.cross_attn.query.weight 2 (1280, 1280) model.decoder.layers.31.encoder_attn.q_proj.bias -&gt; decoder.blocks.31.cross_attn.query.bias decoder.blocks.31.cross_attn.query.bias 1 (1280,) Converting to float32 model.decoder.layers.31.encoder_attn.out_proj.weight -&gt; decoder.blocks.31.cross_attn.out.weight decoder.blocks.31.cross_attn.out.weight 2 (1280, 1280) model.decoder.layers.31.encoder_attn.out_proj.bias -&gt; decoder.blocks.31.cross_attn.out.bias decoder.blocks.31.cross_attn.out.bias 1 (1280,) Converting to float32 model.decoder.layers.31.encoder_attn_layer_norm.weight -&gt; decoder.blocks.31.cross_attn_ln.weight decoder.blocks.31.cross_attn_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.31.encoder_attn_layer_norm.bias -&gt; decoder.blocks.31.cross_attn_ln.bias decoder.blocks.31.cross_attn_ln.bias 1 (1280,) Converting to float32 model.decoder.layers.31.fc1.weight -&gt; decoder.blocks.31.mlp.0.weight decoder.blocks.31.mlp.0.weight 2 (5120, 1280) model.decoder.layers.31.fc1.bias -&gt; decoder.blocks.31.mlp.0.bias decoder.blocks.31.mlp.0.bias 1 (5120,) Converting to float32 model.decoder.layers.31.fc2.weight -&gt; decoder.blocks.31.mlp.2.weight decoder.blocks.31.mlp.2.weight 2 (1280, 5120) model.decoder.layers.31.fc2.bias -&gt; decoder.blocks.31.mlp.2.bias decoder.blocks.31.mlp.2.bias 1 (1280,) Converting to float32 model.decoder.layers.31.final_layer_norm.weight -&gt; decoder.blocks.31.mlp_ln.weight decoder.blocks.31.mlp_ln.weight 1 (1280,) Converting to float32 model.decoder.layers.31.final_layer_norm.bias -&gt; decoder.blocks.31.mlp_ln.bias decoder.blocks.31.mlp_ln.bias 1 (1280,) Converting to float32 model.decoder.layer_norm.weight -&gt; decoder.ln.weight decoder.ln.weight 1 (1280,) Converting to float32 model.decoder.layer_norm.bias -&gt; decoder.ln.bias decoder.ln.bias 1 (1280,) Converting to float32 Skipping proj_out.weight Done. Output file: whisper-ggml-sme/ggml-model.bin . !wget https://media.globalrecordings.net/GOKit_MP3s_named/Saami%20North%20-%20The%20Two%20Roads.mp3 -O sample.mp3 !ffmpeg -i sample.mp3 -acodec pcm_s16le -ac 1 -ar 16000 sample.wav . --2024-03-03 18:09:42-- https://media.globalrecordings.net/GOKit_MP3s_named/Saami%20North%20-%20The%20Two%20Roads.mp3 Resolving media.globalrecordings.net (media.globalrecordings.net)... 35.208.248.145 Connecting to media.globalrecordings.net (media.globalrecordings.net)|35.208.248.145|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 493511 (482K) [audio/mpeg] Saving to: ‘sample.mp3’ sample.mp3 100%[===================&gt;] 481.94K 3.00MB/s in 0.2s 2024-03-03 18:09:42 (3.00 MB/s) - ‘sample.mp3’ saved [493511/493511] ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers built with gcc 11 (Ubuntu 11.2.0-19ubuntu1) configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared libavutil 56. 70.100 / 56. 70.100 libavcodec 58.134.100 / 58.134.100 libavformat 58. 76.100 / 58. 76.100 libavdevice 58. 13.100 / 58. 13.100 libavfilter 7.110.100 / 7.110.100 libswscale 5. 9.100 / 5. 9.100 libswresample 3. 9.100 / 3. 9.100 libpostproc 55. 9.100 / 55. 9.100 Input #0, mp3, from &#39;sample.mp3&#39;: Metadata: title : Saami, North Picture 22: The Two Roads The Two Roads artist : GRN Language Samples album : Saami, North SME composer : Saami, North genre : GRN Language Sample encoder : Lavf58.76.100 track : 1 copyright : 2010 GRN comment : https://globalrecordings.net/en/language/3475 grnprog : A63258 grnlang : 3475 grnprepared : 20240113 date : 2010 Duration: 00:01:44.67, start: 0.050111, bitrate: 37 kb/s Stream #0:0: Audio: mp3, 22050 Hz, mono, fltp, 32 kb/s Stream #0:1: Video: mjpeg (Baseline), yuvj420p(pc, bt470bg/unknown/unknown), 300x300 [SAR 300:300 DAR 1:1], 90k tbr, 90k tbn, 90k tbc (attached pic) Metadata: title : gn-22 comment : Cover (front) Stream mapping: Stream #0:0 -&gt; #0:0 (mp3 (mp3float) -&gt; pcm_s16le (native)) Press [q] to stop, [?] for help Output #0, wav, to &#39;sample.wav&#39;: Metadata: INAM : Saami, North Picture 22: The Two Roads The Two Roads IART : GRN Language Samples IPRD : Saami, North SME composer : Saami, North IGNR : GRN Language Sample ICRD : 2010 IPRT : 1 ICOP : 2010 GRN ICMT : https://globalrecordings.net/en/language/3475 grnprog : A63258 grnlang : 3475 grnprepared : 20240113 ISFT : Lavf58.76.100 Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s Metadata: encoder : Lavc58.134.100 pcm_s16le size= 3269kB time=00:01:44.61 bitrate= 256.0kbits/s speed= 722x video:0kB audio:3269kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.009559% . !./whisper.cpp/main -m whisper-ggml-sme/ggml-model.bin -f sample.wav . whisper_init_from_file_with_params_no_state: loading model from &#39;whisper-ggml-sme/ggml-model.bin&#39; whisper_model_load: loading model whisper_model_load: n_vocab = 51865 whisper_model_load: n_audio_ctx = 1500 whisper_model_load: n_audio_state = 1280 whisper_model_load: n_audio_head = 20 whisper_model_load: n_audio_layer = 32 whisper_model_load: n_text_ctx = 448 whisper_model_load: n_text_state = 1280 whisper_model_load: n_text_head = 20 whisper_model_load: n_text_layer = 32 whisper_model_load: n_mels = 80 whisper_model_load: ftype = 1 whisper_model_load: qntvr = 0 whisper_model_load: type = 5 (large) whisper_model_load: adding 1608 extra tokens whisper_model_load: n_langs = 99 whisper_model_load: CPU total size = 3093.99 MB whisper_model_load: model size = 3093.99 MB whisper_init_state: kv self size = 220.20 MB whisper_init_state: kv cross size = 245.76 MB whisper_init_state: compute buffer (conv) = 34.82 MB whisper_init_state: compute buffer (encode) = 926.66 MB whisper_init_state: compute buffer (cross) = 9.38 MB whisper_init_state: compute buffer (decode) = 209.26 MB system_info: n_threads = 2 / 2 | AVX = 1 | AVX2 = 1 | AVX512 = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | METAL = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | CUDA = 0 | COREML = 0 | OPENVINO = 0 | main: processing &#39;sample.wav&#39; (1673814 samples, 104.6 sec), 2 threads, 1 processors, 5 beams + best of 5, lang = en, task = transcribe, timestamps = 1 ... .",
            "url": "https://jimregan.github.io/notes/whisper.cpp/whisper/dt2112/2024/03/03/example-of-converting-and-using-a-hf-whisper-model-with-whisper.cpp.html",
            "relUrl": "/whisper.cpp/whisper/dt2112/2024/03/03/example-of-converting-and-using-a-hf-whisper-model-with-whisper.cpp.html",
            "date": " • Mar 3, 2024"
        }
        
    
  
    
        ,"post5": {
            "title": "Recreating a phonetic dictionary with piper_phonemize",
            "content": "Matcha-TTS uses piper_phonemize as its phonemiser, so for best results, the pre-phonemised text that you feed it should match that type of input: one method is to use a phoneset mapping between the two, to create a new dictionary with which to train an MFA model. This is an alternative approach, where you take the headwords from an MFA dictionary, and generate the pronunciations using piper_phonemize: this guarantees that the input matches not only the phoneset, but other conventions (for one, providing accent marks in the expected way) without the potential mess that can happen in phoneset mapping: e.g., that mappings are not always 1:1. . As an additional bonus, you can be assured that some of the pronunciations it generates will be incorrect: for testing an interface where the user provides their own pronunciations, this is a good thing! . Watch in amazement at how easy it is to install piper_phonemize on Linux, compared to how incredibly difficult it is on Mac... . %pip install piper_phonemize . Collecting piper_phonemize Downloading piper_phonemize-1.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (25.0 MB) ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 25.0/25.0 MB 41.5 MB/s eta 0:00:00 Installing collected packages: piper_phonemize Successfully installed piper_phonemize-1.1.0 . This function copies what Matcha does. . import piper_phonemize def matcha_style_phonemizer(text): return piper_phonemize.phonemize_espeak(text=text, voice=&quot;en-US&quot;) . As input, I&#39;m using the MFA 3.0 US dictionary, available here . %%capture !wget https://github.com/MontrealCorpusTools/mfa-models/releases/download/dictionary-english_us_mfa-v3.0.0/english_us_mfa.dict . Let&#39;s take a quick look at the format: . !tail english_us_mfa.dict . zygon z aj ɡ ɑ n zygophyte z ɪ ɡ ow f aj t zygophyte z aj ɡ ow f aj t zygote 0.99 0.14 1.0 1.0 z aj ɡ ow t zyme z aj m zymophyte z aj m ow f aj t zythum z aj θ ə m zyzzyva 0.99 0.14 1.0 1.0 z ɪ z ɪ v ə zzyzx z aj z ɪ k s zzzs z i z . So, we can see two kinds of line: one probabilistic, the other more basic. In either case, we are only interested in the first field of the tab-delimited file. . with open(&quot;english_us_mfa.dict&quot;) as mfadict: words = set() for line in mfadict.readlines(): parts = line.split(&quot; t&quot;) words.add(parts[0]) . I&#39;m not doing all of this for you: MFA expects tab delimited output, with word separated phonemes: by default, stress and duration marks are separate &quot;phones&quot;. You get to check if this is correct input to Matcha. . with open(&quot;english_with_piper.dict&quot;, &quot;w&quot;) as piperdict: for word in words: piper = matcha_style_phonemizer(word) for piper_item in piper: phon = &quot; &quot;.join(piper_item) piperdict.write(f&quot;{word} t{phon} n&quot;) . !tail english_with_piper.dict . annihilating ɐ n ˈ a ɪ ə l ˌ e ɪ ɾ ɪ ŋ horatia h o ː ɹ ˈ e ɪ ʃ ə aliena ˌ e ɪ l i ˈ ɛ n ə disbanding d ɪ s b ˈ æ n d ɪ ŋ beginneth b ɪ ɡ ˈ ɪ n ə θ wordster w ˈ ɜ ː d s t ɚ sullying s ˈ ʌ l i ɪ ŋ offices ˈ ɑ ː f ɪ s ᵻ z toads t ˈ o ʊ d z projective p ɹ ə d ʒ ˈ ɛ k t ɪ v .",
            "url": "https://jimregan.github.io/notes/matcha/g2p/dt2112/2024/02/29/recreate-g2p-dictionary-for-matcha.html",
            "relUrl": "/matcha/g2p/dt2112/2024/02/29/recreate-g2p-dictionary-for-matcha.html",
            "date": " • Feb 29, 2024"
        }
        
    
  
    
        ,"post6": {
            "title": "Extract data for the ARS project, take 2",
            "content": "!grep -i &#39; (terror |teror )&#39; ~/rd_ctm_edit/* | awk -F&#39;:&#39; &#39;{print $1}&#39;|sort|uniq &gt; /tmp/terror_files . FILES=!cat /tmp/terror_files | shuf | head -n 5 . UPPER_BOUND = 60 * 7 LOWER_BOUND = 60 * 6 . import random random.randrange(LOWER_BOUND, UPPER_BOUND) . 379 . def slurp(filename): lines = [] with open(filename) as inputfile: for line in inputfile.readlines(): if line.strip() != &quot;&quot;: lines.append(line.strip()) return lines . from pathlib import Path BASEPATH = Path(&quot;/home/joregan/rd_ctm_edit&quot;) . testing = slurp(str(BASEPATH / &quot;H9C120210930fs&quot;)) . def get_terror_lines(lines): outlines = [] for line in lines: if &quot;terror&quot; in line.lower() or &quot;teror&quot; in line.lower(): outlines.append(line) return outlines . def file_upper_bound(lines): last = lines[-1] parts = last.split(&quot; &quot;) return float(parts[2]) + float(parts[3]) . def file_upper_bound_start(lines): last = lines[-1] parts = last.split(&quot; &quot;) return float(parts[2]) . def get_random_mention(lines): terror_lines = get_terror_lines(lines) if len(terror_lines) == 1: return terror_lines[0] randn = random.randrange(0, len(terror_lines) - 1) return terror_lines[randn] . def random_time(lines): random_line = get_random_mention(lines) parts = random_line.split(&quot; &quot;) start_time = float(parts[2]) return start_time, random_line def time_difference(line1, line2): parts1 = line1.split(&quot; &quot;) parts2 = line2.split(&quot; &quot;) start = float(parts1[2]) end = float(parts2[2]) + float(parts2[3]) return end - start def do_the_thing(lines): upper = file_upper_bound_start(lines) focal = upper line = &quot;&quot; while focal &gt;= upper: focal, line = random_time(lines) line_index = lines.index(line) idx_up = idx_down = line_index while idx_up &lt; len(lines) and idx_down &gt; 0: if time_difference(lines[idx_down], lines[idx_up]) &lt; UPPER_BOUND: if idx_up &lt; len(lines): idx_up += 1 if idx_down &gt; 0: idx_down -= 1 elif time_difference(lines[idx_down], lines[idx_up]) &gt; UPPER_BOUND: idx_up -= 1 idx_down += 1 break else: break return lines[idx_down:idx_up] . a = do_the_thing(testing) time_difference(a[0], a[-1]) . 418.8399999999997 . segments = [] with open(&quot;/tmp/run_ffmpeg1.sh&quot;, &quot;w&quot;) as runsh, open(&quot;/tmp/segments.ctm&quot;, &quot;w&quot;) as segctm: for filename in FILES: lines = slurp(filename) seg = do_the_thing(lines) segments.append(seg) # stem = Path(filename).stem parts = lines[0].split(&quot; &quot;) vidid = parts[0] runsh.write(f&quot;ffmpeg -i /sbtal/riksdag-video/{vidid}_480p.mp4 -acodec pcm_s16le -ac 1 -ar 16000 /tmp/{vidid}.wav n&quot;) for segline in seg: segctm.write(segline + &quot; n&quot;) segctm.write(&quot; n&quot;) . !bash /tmp/run_ffmpeg1.sh . from pydub import AudioSegment parameters=[&quot;-ac&quot;, &quot;1&quot;, &quot;-acodec&quot;, &quot;pcm_s16le&quot;, &quot;-ar&quot;, &quot;16000&quot;] for seg in segments: first = seg[0].split(&quot; &quot;) last = seg[-1].split(&quot; &quot;) vidid = first[0] start = int(float(first[2]) * 1000) end = int(float(last[2]) + float(last[3]) * 1000) wavaudio = AudioSegment.from_wav(f&quot;/tmp/{vidid}.wav&quot;) sect = wavaudio[start:end] sect.export(f&quot;/tmp/SEG_{vidid}.wav&quot;, format=&quot;wav&quot;, parameters=parameters) .",
            "url": "https://jimregan.github.io/notes/ars/riksdag/dt2112/2024/02/29/extract-ars2.html",
            "relUrl": "/ars/riksdag/dt2112/2024/02/29/extract-ars2.html",
            "date": " • Feb 29, 2024"
        }
        
    
  
    
        ,"post7": {
            "title": "Extract data for the ARS project",
            "content": "from pathlib import Path LINESFILE = Path(&quot;/home/joregan/third-shuffle&quot;) . from pydub import AudioSegment . VIDBASE = &quot;/sbtal/riksdag-video/&quot; VIDSFX = &quot;_480p.mp4&quot; . parameters=[&quot;-ac&quot;, &quot;1&quot;, &quot;-acodec&quot;, &quot;pcm_s16le&quot;, &quot;-ar&quot;, &quot;16000&quot;] . VIDBASEPATH = Path(VIDBASE) for tscr in LINESFILE.glob(&quot;TERROR_*&quot;): with open(tscr) as tscf: lines = [] for line in tscf.readlines(): line = line.strip() if line == &quot;&quot;: continue else: lines.append(line) parts_s = lines[0].split(&quot; &quot;) parts_e = lines[-1].split(&quot; &quot;) vidfile = VIDBASEPATH / f&quot;{vidid}{VIDSFX}&quot; if not vidfile.exists(): print(&quot;Error&quot;, vidfile) vidid = parts_s[0] fstart = float(parts_s[2]) fend = float(parts_e[2]) + float(parts_e[3]) print(fstart, fend) start = int(fstart * 1000) end = int(fend * 1000) # audio = AudioSegment.from_file(str(vidfile), &quot;mp4&quot;) # tmpwav = audio.export(f&quot;/tmp/{vidid}.wav&quot;, format=&quot;wav&quot;, parameters=parameters) wavaudio = AudioSegment.from_wav(f&quot;/tmp/{vidid}.wav&quot;) sect = wavaudio[start:end] outname = str(LINESFILE / f&quot;{vidid}.wav&quot;) sect.export(outname, format=&quot;wav&quot;, parameters=parameters) . 2303.74 2312.079 1517.42 1529.1599999999999 885.9 897.299 2107.76 2119.38 305.86 314.5 1415.62 1426.819 50.12 61.38 992.76 1000.13 766.86 771.799 3596.66 3601.7799999999997 .",
            "url": "https://jimregan.github.io/notes/ars/riksdag/dt2112/2024/02/29/extract-ars.html",
            "relUrl": "/ars/riksdag/dt2112/2024/02/29/extract-ars.html",
            "date": " • Feb 29, 2024"
        }
        
    
  
    
        ,"post8": {
            "title": "Phonetic rules, take 2",
            "content": "Earlier notebook is here . _ALPHABET = { &quot;A&quot;: [&quot;a&quot;], &quot;B&quot;: [&quot;be&quot;, &quot;bé&quot;], &quot;C&quot;: [&quot;ce&quot;, &quot;se&quot;, &quot;sé&quot;, &quot;cé&quot;, &quot;si&quot;, &quot;ci&quot;], &quot;D&quot;: [&quot;de&quot;, &quot;dé&quot;, &quot;di&quot;], &quot;E&quot;: [&quot;e&quot;, &quot;é&quot;], &quot;F&quot;: [&quot;eff&quot;, &quot;ef&quot;], &quot;G&quot;: [&quot;ge&quot;, &quot;gé&quot;, &quot;gi&quot;], &quot;H&quot;: [&quot;hå&quot;, &quot;ho&quot;], &quot;I&quot;: [&quot;i&quot;], &quot;J&quot;: [&quot;ji&quot;, &quot;gi&quot;], &quot;K&quot;: [&quot;kå&quot;, &quot;ko&quot;], &quot;L&quot;: [&quot;ell&quot;, &quot;el&quot;], &quot;M&quot;: [&quot;emm&quot;, &quot;em&quot;], &quot;N&quot;: [&quot;enn&quot;, &quot;en&quot;], &quot;O&quot;: [&quot;o&quot;], &quot;P&quot;: [&quot;pe&quot;, &quot;pé&quot;, &quot;pi&quot;], &quot;Q&quot;: [&quot;qu&quot;], &quot;R&quot;: [&quot;err&quot;, &quot;er&quot;, &quot;är&quot;, &quot;ärr&quot;], &quot;S&quot;: [&quot;ess&quot;, &quot;es&quot;], &quot;T&quot;: [&quot;te&quot;, &quot;té&quot;, &quot;ti&quot;], &quot;U&quot;: [&quot;u&quot;], &quot;V&quot;: [&quot;ve&quot;, &quot;vé&quot;, &quot;vi&quot;], &quot;W&quot;: [&quot;dubbelve&quot;], &quot;X&quot;: [&quot;ex&quot;, &quot;ecz&quot;, &quot;ecs&quot;, &quot;eks&quot;], &quot;Y&quot;: [&quot;y&quot;], &quot;Z&quot;: [&quot;zäta&quot;, &quot;säta&quot;, &quot;seta&quot;, &quot;zeta&quot;], &quot;Å&quot;: [&quot;å&quot;], &quot;Ä&quot;: [&quot;ä&quot;], &quot;Ö&quot;: [&quot;ö&quot;] } DIGITS = { &quot;1&quot;: [&quot;ett&quot;], &quot;2&quot;: [&quot;två&quot;], &quot;3&quot;: [&quot;tre&quot;], &quot;4&quot;: [&quot;fyra&quot;], &quot;5&quot;: [&quot;fem&quot;], &quot;6&quot;: [&quot;sex&quot;], &quot;7&quot;: [&quot;sju&quot;], &quot;8&quot;: [&quot;åtta&quot;], &quot;9&quot;: [&quot;nio&quot;, &quot;ni&quot;] } . ALPHABET = {k: sorted(v, key=len, reverse=True) for k,v in _ALPHABET.items()} . 2442206120015761721 1 487.78 0.32 essefu 1.0 &lt;eps&gt; ins 2442206120015761721 1 488.26 0.16 fem 1.0 SfU5 sub . 2442206120015761721 1 490.6 0.519 tjugohundrafjorton 1.0 &lt;eps&gt; ins 2442206120015761721 1 491.2 0.379 femton 1.0 &lt;eps&gt; ins 2442206120015761721 1 491.74 0.779 etthundratjugofyra 1.0 2014/15:124 sub . ALNUM = {**ALPHABET, **DIGITS} ALNUM_REGEX = {k: f&quot;({&#39;|&#39;.join(v)})&quot; for k,v in ALNUM.items()} . from difflib import SequenceMatcher ACCEPT = [ (&quot;e&quot;, &quot;ə&quot;) ] a = &quot;kamaren&quot; b = &quot;kamarən&quot; ok = False s = SequenceMatcher(None, a, b) for tag, i1, i2, j1, j2 in s.get_opcodes(): if tag == &quot;replace&quot;: if (a[i1:i2], b[j1:j2]) in ACCEPT: ok = True else: ok = False elif tag == &quot;equal&quot;: ok = True . from phonemizer import phonemize . phonemize(&quot;slut&quot;, language=&#39;sv&#39;) . &#39;slʉt &#39; . from sync_asr.utils.nst_lexicon import get_nst_lexicon . %cd /Users/joregan/Playing/sync_asr %pip install -e . . lexicon = get_nst_lexicon() . dictionary = {} for entry in lexicon: if &#39;garbage&#39; in entry and entry[&#39;garbage&#39;] == &#39;GARB&#39;: continue else: word = entry[&#39;orthography&#39;] word = word.replace(&quot;_&quot;, &quot; &quot;) if not word in dictionary: dictionary[word] = set() for translit in entry[&#39;transliterations&#39;]: dictionary[word].add(translit[&#39;ipa&#39;].replace(&quot;.&quot;, &quot;&quot;).replace(&quot;¤&quot;, &quot;&quot;).replace(&quot;_&quot;, &quot; &quot;).replace(&quot; u0361&quot;, &quot;&quot;)) . CONSONANTS = &quot;bdfhjklmnprstvŋɕɖɡɧɭɳʂʈ&quot; VOWELS = &quot;aeiouyøɪɑɔɛɵʉʊʏ&quot; ACCENTS = &quot;²ˌˈ&quot; . print(dictionary[&quot;inte&quot;]) print(phonemize(&quot;inte&quot;, language=&#39;sv&#39;)) . {&#39;²ɪnte&#39;} ɪntɛ . characters = set() for entry in dictionary: for pron in dictionary[entry]: for char in pron: characters.add(char) . cons = set() VS = VOWELS + ACCENTS + &quot;_&quot; for entry in dictionary: for pron in dictionary[entry]: for char in pron: if char not in VS: cons.add(char) . def shift_accent(ipa): accent = &quot;&quot; output = &quot;&quot; for character in ipa: if character in ACCENTS: accent = character elif character in CONSONANTS: output += character elif character in VOWELS: if accent != &quot;&quot;: output += accent accent = &quot;&quot; output += character else: output += character return output . shift_accent(&quot;²kratʊʂ&quot;) . &#39;kr²atʊʂ&#39; . import re import itertools class Rule(): def __init__(self, match, replacement, rulename, example, on_accented = False, before_accented = False): self.match = match self.replacement = replacement self.rulename = rulename self.example = example self.on_accented = on_accented self.before_accented = before_accented def apply(self, word): if self.on_accented: pattern = fr&quot;((?:[^²ˌˈ]){self.match}|^{self.match})&quot; elif self.before_accented: pattern = fr&quot;({self.match}(?:[^²ˌˈ]))&quot; else: word = re.sub(&quot;[²ˌˈ]&quot;, &quot;&quot;, word) pattern = self.match matches = [(m.start(), m.end()) for m in re.finditer(pattern, word)] if self.on_accented: tmp = [] for m in matches: if m[1] - m[0] &gt; len(self.match): tmp.append((m[1] - len(self.match), m[1])) else: tmp.append(m) matches = tmp pieces = [] prev_end = 0 for piece in matches: if piece[0] &gt; 0: pieces.append([word[prev_end:piece[0]]]) pieces.append([word[piece[0]:piece[1]], self.replacement]) prev_end = piece[1] pieces.append([word[prev_end:]]) output = [] for part in itertools.product(*pieces): output.append(&quot;&quot;.join(part)) return output . rule = Rule(&quot;nh&quot;, &quot;n&quot;, &quot;n → ∅ / _ h&quot;, &quot;Stenholm&quot;) . assert rule.apply(&quot;nhanhanha&quot;) == [&#39;nhanhanha&#39;, &#39;nhanhana&#39;, &#39;nhananha&#39;, &#39;nhanana&#39;, &#39;nanhanha&#39;, &#39;nanhana&#39;, &#39;nananha&#39;, &#39;nanana&#39;] . # is single words, but at some later processing stage we can validate class AssimilationRule(Rule): def __init__(self, match, replacement, rulename, example, on_accented = False, before_accented = False, pre_context = &quot;&quot;, post_context = &quot;&quot;): super.__init__(match, replacement, rulename, example, on_accented, before_accented) self.pre_context = pre_context self.post_context = post_context . GENERAL_STRESSED = [ Rule(&quot;e&quot;, &quot;ə&quot;, &quot;e → ə / [-stressed]&quot;, &quot;&quot;, True), Rule(&quot;ɛ&quot;, &quot;ə&quot;, &quot;e → ə / [-stressed]&quot;, &quot;&quot;, True) ] AssimilationRule(&quot;r$&quot;, &quot;&quot;, &quot;h → ∅ / r # _&quot;, &quot;har han&quot;, False, False, &quot;&quot;, &quot;h&quot;) AssimilationRule(&quot;n$&quot;, &quot;&quot;, &quot;h → ∅ / n # _&quot;, &quot;han har&quot;, False, False, &quot;&quot;, &quot;h&quot;) AssimilationRule(&quot;r$&quot;, &quot;&quot;, &quot;r → ∅ / _ # [+consonant]&quot;, &quot;där bilen&quot;, False, False, &quot;&quot;, f&quot;[{CONSONANTS}]&quot;) Rule(&quot;[œɶeə]r&quot;, &quot;r&quot;, &quot;e → ∅ / _ r [+stressed]&quot;, &quot;bero&quot;, False, True) # # Same phone twice (within word and across word boundaries (repeated below) # $s =~ s/(.) 1/$1/g; # RULE: @ → ∅ / _ @ etc. # $s =~ s/(.) ($wb 1)/$2/g; # RULE: @ → ∅ / _ # @ etc. Rule(&quot;ɪntə&quot;, &quot;ntə&quot;, &quot;ɪ → ∅ / [+vowel] # _ n t ə&quot;, &quot;ska inte&quot;, False, False) Rule(&quot;ɪnte&quot;, &quot;nte&quot;, &quot;ɪ → ∅ / [+vowel] # _ n t e&quot;, &quot;ska inte&quot;, False, False) Rule(&quot;nh&quot;, &quot;h&quot;, &quot;n → ∅ / _ h&quot;, &quot;Stenholm&quot;) # # r # $s =~ s/ @ r m/ @ m/g; # RULE: r → ∅ / @ _ m Schleiermacher # # rd/rl # $s =~ s/: rd (rn)/: $1/g; # RULE: rd → ∅ / : _ sn ordning # $s =~ s/rl/l/g; # RULE: rl → l / svårhanterliga .",
            "url": "https://jimregan.github.io/notes/swedish/nst/lexicon/phonetic/rules/2024/02/20/phonetic-rule-take-2.html",
            "relUrl": "/swedish/nst/lexicon/phonetic/rules/2024/02/20/phonetic-rule-take-2.html",
            "date": " • Feb 20, 2024"
        }
        
    
  
    
        ,"post9": {
            "title": "Interesting links, 20/02/2024",
            "content": "LAVE: LLM-Powered Agent Assistance and Language Augmentation for Video Editing . karpathy/minbpe — Minimal, clean, code for the Byte Pair Encoding (BPE) algorithm commonly used in LLM tokenization. . MAGVIT: Masked Generative Video Transformer, code . DiffiT: Diffusion Vision Transformers for Image Generation . A Novel Sampling Scheme for Text- and Image-Conditional Image Synthesis in Quantized Latent Spaces . How to Train Data-Efficient LLMs . Fine-tuning Large Language Models for Adaptive Machine Translation . Robust agents learn causal world models . Mamba: The Hard Way . open-mmlab/Amphion — Amphion (/æmˈfaɪən/) is a toolkit for Audio, Music, and Speech Generation. Its purpose is to support reproducible research and help junior researchers and engineers get started in the field of audio, music, and speech generation research and development. . The effects of automatic speech recognition quality on human transcription latency — “We present results from 2 studies which indicate that starting with the ASR output is worse unless it is sufficiently accurate (Word Error Rate of under 30%).” . Lexicographical data/Statistics/Counts of various things by language . OLMo - Open Language Model . OpenAccess-AI-Collective/axolotl — Go ahead and axolotl questions . Listen, Think, and Understand . Neural Network Diffusion . mistralai/cookbook . OWSM-CTC: An Open Encoder-Only Speech Foundation Model for Speech Recognition, Translation, and Language Identification . Encoding of multi-modal emotional information via personalized skin-integrated wireless facial interface . alterebro/IPA-Keyboard . BBA: Bi-Modal Behavioral Alignment for Reasoning with Large Vision-Language Models . Exploring Speech Recognition, Translation, and Understanding with Discrete Speech Units: A Comparative Study . microsoft/torchscale — Foundation Architecture for (M)LLMs . A Paradigm Shift in Machine Translation: Boosting Translation Performance of Large Language Models, code . lucidrains/flamingo-pytorch . lucidrains/RETRO-pytorch .",
            "url": "https://jimregan.github.io/notes/links/2024/02/20/misc-links.html",
            "relUrl": "/links/2024/02/20/misc-links.html",
            "date": " • Feb 20, 2024"
        }
        
    
  
    
        ,"post10": {
            "title": "Scrape NRK videos",
            "content": "PAGE = &quot;https://tv.nrk.no/serie/samenes-nasjonaldag/2024/SAPP63008024/avspiller&quot; . import requests import json def get_programme_data(page): if page.endswith(&quot;/avspiller&quot;): parts = page.split(&quot;/&quot;) programme_id = parts[-2] res = requests.get(f&quot;https://psapi.nrk.no/playback/manifest/program/{programme_id}?eea-portability=true&quot;) if res.status_code == 200: data = json.loads(res.text) return data return None . res = get_programme_data(PAGE) . res.keys() . dict_keys([&#39;_links&#39;, &#39;id&#39;, &#39;playability&#39;, &#39;streamingMode&#39;, &#39;availability&#39;, &#39;statistics&#39;, &#39;playable&#39;, &#39;nonPlayable&#39;, &#39;displayAspectRatio&#39;, &#39;sourceMedium&#39;]) . def get_urls_from_programme_data(data): output = {} if not &#39;playable&#39; in data: return [] if not &#39;assets&#39; in data[&#39;playable&#39;]: return [] for asset in data[&#39;playable&#39;][&#39;assets&#39;]: if &#39;url&#39; in asset: output[&#39;m3u&#39;] = asset[&#39;url&#39;] if &#39;subtitles&#39; in data[&#39;playable&#39;]: subtitles = [] for st in data[&#39;playable&#39;][&#39;subtitles&#39;]: subtitles.append(st[&#39;webVtt&#39;]) output[&#39;subtitles&#39;] = subtitles return output . get_urls_from_programme_data(res) . {&#39;m3u&#39;: &#39;https://nrkod46-cdn0-47115-odedge1.dna.contentdelivery.net/47115-odedge1/open/ps/sapp/sapp63008024/32342f4f-5.smil/index.m3u8?adap=small&amp;s=0&#39;, &#39;subtitles&#39;: [&#39;https://undertekst.nrk.no/SAPP63/00/SAPP63008024/NOR/SAPP63008024.vtt&#39;, &#39;https://undertekst.nrk.no/SAPP63/00/SAPP63008024/TTV/SAPP63008024.vtt&#39;]} .",
            "url": "https://jimregan.github.io/notes/nrk/scraper/dt2112/2024/02/19/scrape-nrk-video.html",
            "relUrl": "/nrk/scraper/dt2112/2024/02/19/scrape-nrk-video.html",
            "date": " • Feb 19, 2024"
        }
        
    
  
    
        ,"post11": {
            "title": "Load Sámi Whisper model",
            "content": "from transformers import pipeline import torch . MODEL = &quot;NbAiLab/whisper-large-sme&quot; LANG = &quot;fi&quot; . if torch.cuda.is_available(): device = 0 else: device = &quot;cpu&quot; . pipe = pipeline(task=&quot;automatic-speech-recognition&quot;, model=MODEL, chunk_length_s=30, device=device) . pipe.model.config.forced_decoder_ids = pipe.tokenizer.get_decoder_prompt_ids(language=lang, task=&quot;transcribe&quot;) . PAGE = &quot;https://sverigesradio.se/artikel/odda-skearru-bitonsami-ludiiguin&quot; AUDIOJSON = &quot;https://sverigesradio.se/playerajax/audio?id=8580562&amp;type=publication&amp;publicationid=8580562&amp;quality=medium&quot; . import requests import json def get_sverigesradio_audio(page): req = requests.get(page) if req.status_code != 200: return None data = json.loads(req.text) if &quot;audioUrl&quot; in data: return data[&quot;audioUrl&quot;] return None . !wget {get_sverigesradio_audio(AUDIOJSON)} . from bs4 import BeautifulSoup . def get_audio_id_from_page(page): req = requests.get(page) if req.status_code != 200: return None soup = BeautifulSoup(req.text, &#39;html.parser&#39;) for elem in soup.findAll(&quot;script&quot;, {&quot;id&quot;: &quot;gtm-metadata&quot;}): if &quot;pageId&quot; in elem.text: data = json.loads(elem.text) return data[&quot;pageId&quot;] return None . get_audio_id_from_page(PAGE) . &#39;8580562&#39; . def get_audio_from_page(page): pageid = get_audio_id_from_page(page) if pageid is None: return None return get_sverigesradio_audio(f&quot;https://sverigesradio.se/playerajax/audio?id={pageid}&amp;type=publication&amp;publicationid={pageid}&amp;quality=medium&quot;) . get_audio_from_page(PAGE) .",
            "url": "https://jimregan.github.io/notes/sami/whisper/sverigesradio/dt2112/2024/02/17/load-sami-whisper-basic-scrape-for-sr.html",
            "relUrl": "/sami/whisper/sverigesradio/dt2112/2024/02/17/load-sami-whisper-basic-scrape-for-sr.html",
            "date": " • Feb 17, 2024"
        }
        
    
  
    
        ,"post12": {
            "title": "Create n-gram LM from Dubliners",
            "content": "Version on Kaggle . %pip install mosestokenizer . !pwd . /kaggle/working . HTML = &quot;https://www.gutenberg.org/cache/epub/2814/pg2814-images.html&quot; . import requests from bs4 import BeautifulSoup . dubliners = requests.get(HTML) . assert dubliners.status_code == 200 . soup = BeautifulSoup(dubliners.text, &#39;html.parser&#39;) . body = soup.find(&quot;body&quot;) . text = [] for chapter in body.findAll(&quot;div&quot;, {&quot;class&quot;: &quot;chapter&quot;}): for element in chapter.findChildren(): if element.name == &quot;section&quot; and element.get(&quot;id&quot;) in [&quot;pg-header&quot;, &quot;pg-footer&quot;]: continue stripped = element.text.strip() if stripped != &quot;&quot;: text.append(stripped) . from mosestokenizer import MosesSentenceSplitter . sents = [] try: with MosesSentenceSplitter(&#39;en&#39;) as splitsents: for para in text: if para == &quot;&quot;: continue sents += splitsents([para.replace(&quot; r n&quot;, &quot; &quot;)]) except Exception as ex: print(ex, para) . import re def cleaner(text): text = text.replace(&quot;“&quot;, &quot;&quot;) text = text.replace(&quot;”&quot;, &quot;&quot;) text = text.replace(&quot;’ &quot;, &quot; &quot;) text = text.replace(&quot;’&quot;, &quot;&#39;&quot;) text = text.replace(&quot;‘&quot;, &quot; &quot;) text = text.replace(&quot; t&quot;, &quot; &quot;) text = text.replace(&quot;!...&quot;, &quot; &quot;) text = text.replace(&quot;....&quot;, &quot; &quot;) text = text.replace(&quot;...&quot;, &quot; &quot;) text = text.replace(&quot;:&quot;, &quot; &quot;) text = text.replace(&quot;;&quot;, &quot; &quot;) text = text.replace(&quot;!&quot;, &quot; &quot;) text = text.replace(&quot;,&quot;, &quot; &quot;) text = text.replace(&quot;?&quot;, &quot; &quot;) text = text.replace(&quot;(&quot;, &quot; &quot;) text = text.replace(&quot;)&quot;, &quot; &quot;) text = text.replace(&quot;—&quot;, &quot; &quot;) text = text.replace(&quot; r n&quot;, &quot; &quot;) text = text.replace(&quot; n&quot;, &quot; &quot;) text = text.replace(&quot; xa0&quot;, &quot; &quot;) text = text.replace(&quot;.&quot;, &quot; &quot;) text = text.replace(&quot;&amp;&quot;, &quot; and &quot;) text = text.replace(&quot; 57E &quot;, &quot; fifty seven e &quot;) text = text.replace(&quot; 1st &quot;, &quot; first &quot;) text = text.replace(&quot; 6th &quot;, &quot; sixth &quot;) text = text.replace(&quot; 1895 &quot;, &quot; eighteen ninety five &quot;) text = text.replace(&quot; 1891&quot;, &quot; eighteen ninety one&quot;) text = text.replace(&quot;1891&quot;, &quot; eighteen ninety one&quot;) text = text.replace(&quot;65 &quot;, &quot; sixty five &quot;) if text[-1] == &quot;.&quot;: text = text[:-1] text = re.sub(&quot; +&quot;, &quot; &quot;, text) return text.lower().strip() . clean = [cleaner(x) for x in sents] . with open(&quot;dubliners-clean.txt&quot;, &quot;w&quot;) as outf: for line in clean: outf.write(line + &quot; n&quot;) . !apt install -y build-essential libboost-all-dev cmake zlib1g-dev libbz2-dev liblzma-dev . %cd /tmp . /tmp . !git clone https://github.com/kpu/kenlm . %cd kenlm . /tmp/kenlm . !mkdir build %cd build !cmake .. !make -j 4 . %cd /kaggle/working . /kaggle/working . !/tmp/kenlm/build/bin/lmplz -o 5 &lt; dubliners-clean.txt &gt; dubliners.arpa .",
            "url": "https://jimregan.github.io/notes/lm/dubliners/dt2112/2024/02/16/dubliners-lm.html",
            "relUrl": "/lm/dubliners/dt2112/2024/02/16/dubliners-lm.html",
            "date": " • Feb 16, 2024"
        }
        
    
  
    
        ,"post13": {
            "title": "Dubliners - download audio and run ASR",
            "content": "Original version on Kaggle . %%capture !apt install -y lynx . !lynx -dump https://librivox.org/dubliners-by-james-joyce/|grep mp3|awk &#39;{print $NF}&#39;|grep 64kb|grep &#39;mp3$&#39; &gt; dubliners1.txt !lynx -dump https://librivox.org/dubliners-by-james-joyce-2/|grep mp3|awk &#39;{print $NF}&#39;|grep 64kb|grep &#39;mp3$&#39; &gt; dubliners2.txt !wget -i dubliners1.txt !wget -i dubliners2.txt . !for i in *.mp3.1;do mv $i $(basename $i .mp3.1)_2.mp3;done . Here starts the actual ASR stuff. . !pip install transformers . EN_MODEL = &quot;jonatasgrosman/wav2vec2-large-xlsr-53-english&quot; PHONE_MODEL = &quot;vitouphy/wav2vec2-xls-r-300m-timit-phoneme&quot; . from transformers import pipeline . pipe_en = pipeline(model=EN_MODEL, device=0) pipe_phone = pipeline(model=PHONE_MODEL, device=1) . from pathlib import Path import json cur = Path(&quot;.&quot;) for file in cur.glob(&quot;*.mp3&quot;): en_out = pipe_en(str(file), chunk_length_s=10, return_timestamps=&quot;word&quot;) phone_out = pipe_phone(str(file), chunk_length_s=10, return_timestamps=&quot;word&quot;) stem = file.stem with open(f&quot;{stem}_en.json&quot;, &quot;w&quot;) as enfile: json.dump(en_out, enfile) with open(f&quot;{stem}_phone.json&quot;, &quot;w&quot;) as phonefile: json.dump(phone_out, phonefile) .",
            "url": "https://jimregan.github.io/notes/kaggle/asr/dubliners/dt2112/2024/02/15/dubliners-download-and-asr.html",
            "relUrl": "/kaggle/asr/dubliners/dt2112/2024/02/15/dubliners-download-and-asr.html",
            "date": " • Feb 15, 2024"
        }
        
    
  
    
        ,"post14": {
            "title": "Interesting links, 01/02/2024",
            "content": "VHS-Decode has to be one of the most interesting software projects I&#39;ve stumbled upon recently. It replaces the decoding process of a VHS tape with a software stack, bypassing most of the original hardware. Using an FPGA device for RF capture like the MiSTer, it creates a… pic.twitter.com/9c2R2Xhkyf . &mdash; LaurieWired (@lauriewired) January 31, 2024 oyvindln/vhs-decode . How can we get LLM-based agents to understand the *visual structure* of a webpage? Announcing Llama2D🦙👀!We fine-tuned Llama on OCR&#39;d webpage screenshots but with 2D positional embeddings, enabling it to see the structure of a webpage rather than just a sequence of tokens. 🧵 pic.twitter.com/Rz2JocZyOq . &mdash; Rohan Pandey (e/acc) (@khoomeik) February 2, 2024 BlackMamba Mixture of ExpertsBlackMamba is an novel architecture which combines state-space models (SSMs) with mixture of experts (MoE). It uses Mamba as its SSM block and switch transformer as its MoE block base. BlackMamba is extremely low latency for generation and… pic.twitter.com/ojhmAKfsUK . &mdash; Carlos E. Perez (@IntuitMachine) February 3, 2024 MatFormer: Nested Transformer for Elastic Inference . What Do Self-Supervised Speech Models Know About Words? . What Do Self-Supervised Speech and Speaker Models Learn? New Findings From a Cross Model Layer-Wise Analysis . Progress on dense retrievers is saturating.The best retrievers in 2024 will apply new forms of late interaction, i.e. scalable attention-like scoring for multi-vector embeddings.A🧵on late interaction, how it works efficiently, and why/where it&#39;s been shown to improve quality pic.twitter.com/2XG33TtM9R . &mdash; Omar Khattab (@lateinteraction) December 18, 2023 Is it possible to teach LLMs a different language? 🤔 Can we transfer the capabilities of LLMs, like Llama, from English to non-English language?A group of researchers from Fudan University tried to answer those questions by running vast experiments on extending vocabulary… pic.twitter.com/fJLYFyQOqP . &mdash; Philipp Schmid (@_philschmid) January 4, 2024 RAIVNLab/MatFormer-OLMo — Code repository for the public reproduction of the language modelling experiments on “MatFormer: Nested Transformer for Elastic Inference” . arcee-ai/mergekit — Tools for merging pretrained large language models. . OWSM v3.1: Better and Faster Open Whisper-Style Speech Models based on E-Branchformer . E-Branchformer: Branchformer with Enhanced merging for speech recognition . PAM: Prompting Audio-Language Models for Audio Quality Assessment, no code yet . ChatQA: Building GPT-4 Level Conversational QA Models . 3 Advanced Document Retrieval Techniques To Improve RAG Systems . Efficiently Modeling Long Sequences with Structured State Spaces, code . Add S4 decoder in ESPnet2 . Alignment-Length Synchronous Decoding for RNN Transducer . init owsm v3.1 recipe . Lingit uttaleleksikon for nynorsk . NLB uttaleleksikon for bokmål . Tuva Taledatabase . NST uttaleleksikon for bokmål . NST uttaleleksikon for svensk . N-gram – svensk . LIA sápmi – LIA-korpuset for samiske dialekter . collabora/WhisperSpeech — An Open Source text-to-speech system built by inverting Whisper. Space . Fast Lexically Constrained Decoding with Dynamic Beam Allocation for Neural Machine Translation . SentenceTransformer: A Model For Computing Sentence Embedding . CLAP Learning Audio Concepts from Natural Language Supervision, code . MambaByte: Token-free Selective State Space Model . kyegomez/MambaByte — Implementation of MambaByte in “MambaByte: Token-free Selective State Space Model” in Pytorch and Zeta . Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model, code - no licence . Matryoshka Representation Learning, code . It’s year 2024, and n-gram LMs are making a comeback!!We develop infini-gram, an engine that efficiently processes n-gram queries with unbounded n and trillion-token corpora. It takes merely 20 milliseconds to count the frequency of an arbitrarily long n-gram in RedPajama (1.4T… pic.twitter.com/07O1o5pahv . &mdash; Jiacheng Liu (Gary) (@liujc1998) February 1, 2024 BlackMamba: Mixture of Experts for State-Space Models, code . V-IRL: Grounding Virtual Intelligence in Real Life . Layer-Wise Analysis of Self-Supervised Acoustic Word Embeddings: A Study on Speech Emotion Recognition . MM-LLMs: Recent Advances in MultiModal Large Language Models . Training-Free Consistent Text-to-Image Generation . RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval, no code yet . Open Language Model: OLMo . Magyar nyelvtan . Compressing Transformer-based self-supervised models for speech processing . AdANNS: A Framework for Adaptive Semantic Search, code . SGI&#39;s 3D File System Navigator (1993) was real pic.twitter.com/UWbx3PS3Kk . &mdash; Retro Tech Dreams (@RetroTechDreams) February 6, 2024 Enhancing the Stability of LLM-based Speech Generation Systems through Self-Supervised Representations . Listen, Chat, and Edit: Text-Guided Soundscape Modification for Enhanced Auditory Experience . Self-Discover: Large Language Models Self-Compose Reasoning Structures . RAG From Scratch: Video series focused on understanding the RAG landscapeRAG is central for LLM application development, connecting LLMs to external data sources.But, the pace of innovation and new approaches makes it challenging to keep up.We&#39;re launching a new video… pic.twitter.com/963lOnVLcP . &mdash; LangChain (@LangChainAI) February 6, 2024 We are releasing the Gen-2 weights. This is a limited edition. Collect all 6,834 books to acquire the complete model. pic.twitter.com/VVVdLPWYSO . &mdash; Cristóbal Valenzuela (@c_valenzuelab) February 6, 2024 REBORN: Reinforcement-Learned Boundary Segmentation with Iterative Training for Unsupervised ASR . Background Removal w/ 🤗 Transformers.js . Scaling Laws for Downstream Task Performance of Large Language Models . Can Mamba Learn How to Learn? A Comparative Study on In-Context Learning Tasks . Large-Scale Contrastive Language-Audio Pretraining with Feature Fusion and Keyword-to-Caption Augmentation . Led by @GoogleDeepMind, we present ALOHA 2 🤙: An Enhanced Low-Cost Hardware for Bimanual Teleoperation.ALOHA 2 🤙 significantly improves the durability of the original ALOHA 🏖️, enabling fleet-scale data collection on more complex tasks.As usual, everything is open-sourced! pic.twitter.com/5OEpO8EFrG . &mdash; Tony Z. Zhao (@tonyzzhao) February 7, 2024 tonyzhaozh/aloha . Fast Timing-Conditioned Latent Audio Diffusion, code . StreamVoice: Streamable Context-Aware Language Modeling for Real-time Zero-Shot Voice Conversion . LGM: Large Multi-View Gaussian Model for High-Resolution 3D Content Creation, code, weights, space . segmind/segmoe — Segmind Mixture of Diffusion Experts, blog . Unified Speech-Text Pretraining for Spoken Dialog Modeling . Memory Consolidation Enables Long-Context Video Understanding . AV2Wav: Diffusion-Based Re-synthesis from Continuous Self-supervised Features for Audio-Visual Speech Enhancement . &gt; two genius tech hippies just want to make their music software run faster&gt; develop an algorithm, publish a paper&gt; algorithm not patented, but used in every commercial sampling synthesizer immediately after&gt; tech hippies run out of grant money for their lab 😅Gossett: We… pic.twitter.com/LSz4INRKVy . &mdash; 👩‍💻 Paige Bailey (@DynamicWebPaige) February 9, 2024 CNChTu/FCPE — fast pitch estimator using Transformer . SpiRit-LM: Interleaved Spoken and Written Language Model . Multilingual E5 Text Embeddings: A Technical Report, code . Learning to Route Among Specialized Experts for Zero-Shot Generalization, code . Can &quot;small&quot; finetuned LLMs with less than 2B parameters outperform larger openly available LLMs (Mixtral, Llama 2 Chat) and proprietary LLMs (ChatGPT)? Here&#39;s a closer look at the Tiny Titans paper (https://t.co/WBFDJ9Q7th), where researchers tried to find the answer to this… pic.twitter.com/z6rDkBrLEj . &mdash; Sebastian Raschka (@rasbt) February 10, 2024 idT5: Indonesian Version of Multilingual T5 Transformer . mT6: Multilingual Pretrained Text-to-Text Transformer with Translation Pairs . Self-Discover: Large Language Models Self-Compose Reasoning Structures . Efficient Exploration for LLMs . Can Large Language Models Understand Context? . Long is more for alignmentTL;DR: LIMA&#39;s paper [1] claimed that if you just train on 1000 high quality samples you will get a great model.Well.. turns out it is even easier.Just use the 1000 longest responses in the dataset.You will get a surprisingly powerful model.… pic.twitter.com/0kaTByZ2ho . &mdash; Yam Peleg (@Yampeleg) February 10, 2024 Spectral State Space Models . K-Adapter: Infusing Knowledge into Pre-Trained Models with Adapters, code . CodeIt: Self-Improving Language Models with Prioritized Hindsight Replay . Hungarian - Geography . Texts - Easy Hungarian . Wordwall - Hungarian grammar . Resource List for Learning Hungarian, doc . Code LoRA from Scratch . Accelerating RNN Transducer Inference via Adaptive Expansion Search . CTC Segmentation for ESPnet 2 . Implement wav2gloss . gemelo-ai/vocos — Vocos: Closing the gap between time-domain and Fourier-based neural vocoders for high-quality audio synthesis . CPJKU/onset_detection — Python implementation of the most common spectral based onset detection algorithms. . Taskmaster wiki . A Hackers’ Guide to Language Models . veeresht/CommPy — Digital Communication with Python . RVC-Project/Retrieval-based-Voice-Conversion-WebUI . Diff-HierVC: Diffusion-based Hierarchical Voice Conversion with Robust Pitch Generation and Masked Prior for Zero-shot Speaker Adaptation, demo . Affective and Dynamic Beam Search for Story Generation . Automatic vocal tract landmark localization from midsagittal MRI data, code . lucidrains/phenaki-pytorch — Implementation of Phenaki Video, which uses Mask GIT to produce text guided videos of up to 2 minutes in length, in Pytorch . Describing Differences in Image Sets with Natural Language, code . google-research/multinerf — A Code Release for Mip-NeRF 360, Ref-NeRF, and RawNeRF . vasistalodagala/whisper-finetune — Fine-tune and evaluate Whisper models for Automatic Speech Recognition (ASR) on custom datasets or datasets from huggingface. . lucidrains/CALM-pytorch — Implementation of CALM from the paper “LLM Augmented LLMs: Expanding Capabilities through Composition”, out of Google Deepmind . lucidrains/llama-qrlhf — Implementation of the Llama architecture with RLHF + Q-learning . Robust Speech Recognition via Large-Scale Weak Supervision . ActiveVisionLab/Awesome-LLM-3D — Awesome-LLM-3D: a curated list of Multi-modal Large Language Model in 3D world Resources . Are Emergent Abilities of Large Language Models a Mirage? . facebookresearch/Pearl — A Production-ready Reinforcement Learning AI Agent Library brought by the Applied Reinforcement Learning team at Meta. . metavoiceio/metavoice-src — Foundational model for human-like, expressive TTS . lucidrains/retro-pytorch — Implementation of RETRO, Deepmind’s Retrieval based Attention net, in Pytorch . The Illustrated Retrieval Transformer . lifeiteng/vall-e — PyTorch implementation of VALL-E(Zero-Shot Text-To-Speech), Reproduced Demo . Aya Dataset: An Open-Access Collection for Multilingual Instruction Tuning . cisnlp/simalign — Obtain Word Alignments using Pretrained Language Models (e.g., mBERT) . Speech Recognition for Minority Languages Using HuBERT and Model Adaptation . Textually Pretrained Speech Language Models . An Embarrassingly Simple Approach for LLM with Strong ASR Capacity . Exploiting Nonlinear Recurrence and Fractal Scaling Properties for Voice Disorder Detection . Large-scale Contrastive Language-Audio Pretraining with Feature Fusion and Keyword-to-Caption Augmentation, code . Can a 2B LLM outperform Mistral 7B or Llama 13B? Creators of the popular Ultrafeedback dataset released MiniCPM, a 2.4B parameter model claiming performance close to Mistral 7B, Llama 2 13B, or Falcon 40B. 🤯🤔As part of the release, the researchers released a detailed… . &mdash; Philipp Schmid (@_philschmid) February 7, 2024 MiniCPM: Unveiling the Potential of End-side Large Language Models, code . There&#39;s a strain of anti-anti-monopolist that insists that they&#39;re not *pro*-monopoly - they&#39;re just *realists* who understand that global gigacorporations are too big to fail, too big to jail, and that governments can&#39;t hope to rein them in. 1/ pic.twitter.com/nx0lM4lKWu . &mdash; Cory Doctorow @pluralistic@mamot.fr (@doctorow) February 6, 2024 Review — Flamingo: A Visual Language Model for Few-Shot Learning . Multimodal Language Models Explained: Visual Instruction Tuning . 📢Mixtures of Experts unlock parameter scaling for deep RL!Adding MoEs, and in particular Soft MoEs, to value-based deep RL agents results in more parameter-scalable models.Performance keeps increasing as we increase number of experts (green line below)!1/9 https://t.co/SMFUrpdNXN pic.twitter.com/kb9mqfyg3m . &mdash; Pablo Samuel Castro (@pcastr) February 14, 2024 Mixtures of Experts Unlock Parameter Scaling for Deep RL . 🔥Half a year after its initial release we are upgrading self-expanding neural networks🔥* SENN based on full-connectivity + now with convolutions* layer &amp; width addition + now pruning any time during training* jax code: https://t.co/ndnnGjBu4Fhttps://t.co/QrYBkWyAV8🧵 ⬇️ https://t.co/XLWcj8xoC1 pic.twitter.com/MnhObyE81B . &mdash; Martin Mundt (@mundt_martin) February 12, 2024 Cohere for AI launches open source LLM for 101 languages . 100x less compute with GPT-level LLM performance: How a little known open source project could help solve the GPU power conundrum — RWKV looks promising but challenges remain . BAAI-DCAI/Bunny — A family of lightweight multimodal models. . theodorblackbird/lina-speech seems interesting, but it’s not open source, so I don’t care. . Large Language Models, GPT-2 — Language Models Are Unsupervised Multitask Learners . vosen/ZLUDA — CUDA on AMD GPUs .",
            "url": "https://jimregan.github.io/notes/links/2024/02/01/misc-links.html",
            "relUrl": "/links/2024/02/01/misc-links.html",
            "date": " • Feb 1, 2024"
        }
        
    
  
    
        ,"post15": {
            "title": "Interesting links, 29/01/2024",
            "content": "Gaussian Adaptive Attention is All You Need: Robust Contextual Representations Across Multiple Modalities, code . EAGLE: Speculative Sampling Requires Rethinking Feature Uncertainty, code . The 3 papers I summarized above: - Averaging Weights Leads to Wider Optima and Better Generalization, Izmailov et al. (2018), https://t.co/S4LsGICsnH)- Early Weight Averaging meets High Learning Rates for LLM Pre-training, @SunnySanyal9 et al. (2018),… . &mdash; Sebastian Raschka (@rasbt) January 24, 2024 The Brain Processes Speech in Parallel With Other Sounds . SonicVisionLM — no paper, no code . makeMoE: Implement a Sparse Mixture of Experts Language Model from Scratch . VALL-T: Decoder-Only Generative Transducer for Robust and Decoding-Controllable Text-to-Speech . resemble-ai/Resemblyzer . ml-explore/mlx . lucidrains/meshgpt-pytorch — Implementation of MeshGPT, SOTA Mesh generation using Attention, in Pytorch . Real-time speech MRI datasets with corresponding articulator ground-truth segmentations, code, data, weights . A multispeaker dataset of raw and reconstructed speech production real-time MRI video and 3D volumetric images, data .",
            "url": "https://jimregan.github.io/notes/links/2024/01/29/misc-links.html",
            "relUrl": "/links/2024/01/29/misc-links.html",
            "date": " • Jan 29, 2024"
        }
        
    
  
    
        ,"post16": {
            "title": "Interesting links, 22/01/2024",
            "content": "Disordered speech . Hybrid CNN-LSTM model with efficient hyperparameter tuning for prediction of Parkinson’s disease . A machine learning method to process voice samples for identification of Parkinson’s disease . Analysis of Parkinson’s Disease Using an Imbalanced-Speech Dataset by Employing Decision Tree Ensemble Methods . Improving Parkinson’s disease recognition through voice analysis using deep learning . Misc . Not long ago, @nickfloats introduced a #prompt structure for creating 360° images. Today, I&#39;ve decided to show you another equally effective structure. Follow this thread for a complete workflow! 🔥🔥 pic.twitter.com/etrr5izMuG . &mdash; Pierrick Chevallier | IA (@CharaspowerAI) January 24, 2024 Are you using models to study human speech processing? 🗣️🤖🧠👶Consider submitting your work to our special session &quot;Computational models of human language acquisition, perception, and production&quot; at @ISCAInterspeech 2024organized by @ojrasanen,@thomashueber, and myself! . &mdash; Marvin Lavechin (@LavechinMarvin) January 24, 2024 Averaging Weights Leads to Wider Optima and Better Generalization . DreaMoving: A Human Video Generation Framework based on Diffusion Models, no code yet . VCoder: Versatile Vision Encoders for Multimodal Large Language Models, code . m-bain/whisperX — WhisperX: Automatic Speech Recognition with Word-level Timestamps (&amp; Diarization) . roboflow/supervision . FaceStudio: Put Your Face Everywhere in Seconds, no code yet . 3D-GPT: Procedural 3D Modeling with Large Language Models, no code yet . Schrodinger Bridges Beat Diffusion Models on Text-to-Speech Synthesis, no code yet . GAIA: Zero-shot Talking Avatar Generation . Speaker and Language Change Detection using Wav2vec2 and Whisper . DmitryRyumin/INTERSPEECH-2023-Papers . wenet-e2e/wespeaker — Research and Production Oriented Speaker Recognition Toolkit . alibaba-damo-academy/3D-Speaker — A repository for single- and multi-modal speaker verification, speaker recognition and speaker diarization. . vjeronymo2/mColBERT . Fine-Tune W2V2-Bert for low-resource ASR with 🤗 Transformers . lucidrains/voicebox-pytorch — Implementation of Voicebox, new SOTA Text-to-speech network from MetaAI, in Pytorch .",
            "url": "https://jimregan.github.io/notes/links/2024/01/22/misc-links.html",
            "relUrl": "/links/2024/01/22/misc-links.html",
            "date": " • Jan 22, 2024"
        }
        
    
  
    
        ,"post17": {
            "title": "Interesting links, 04/01/2024",
            "content": "Dao-AILab/flash-attention — Fast and memory-efficient exact attention . facebookincubator/velox — A C++ vectorized database acceleration library aimed to optimizing query engines and data processing systems. . How 🤗 Accelerate runs very large models thanks to PyTorch . A comparative analysis of speech signal processing algorithms for Parkinson’s disease classification and the use of the tunable Q-factor wavelet transform . karkirowle/relative_phoneme_analysis — Repository for phoneme analysis on word-level Kaldi/ESPNet ASR transcripts . Irish Gaelic/seanchló print . prajdabre/yanmtt — Yet Another Neural Machine Translation Toolkit . google-research-datasets/TextNormalizationCoveringGrammars — Covering grammars for English and Russian text normalization . Language Model Inversion . WavJourney: Compositional Audio Creation with Large Language Models . Minimum Word Error Rate Training with Language Model Fusion for End-to-End Speech Recognition . It wasn&#39;t on my bingo card for 2024-W1, but MSFT dropped a decoder-only embedding model based on Mistral7B-instruct, trained on synthetic retrieval data (+ a bunch of train splits from datasets in BEIR &amp; co...), claiming SotA on MTEB.Here are a few things that caught my eye: https://t.co/ObRUkmDgwg . &mdash; dinos (@din0s_) January 2, 2024 VioLA: Unified Codec Language Models for Speech Recognition, Synthesis, and Translation . thuhcsi/VAENAR-TTS — The official implementation of VAENAR-TTS, a VAE based non-autoregressive TTS model. . Automatic Generation of Subtitles for Videos of the Government of La Rioja . The Properly Illustrated Transformer . The Illustrated Transformer . The Annotated Transformer . Efficient Sequence Transduction by Jointly Predicting Tokens and Durations . Instant3D: Instant Text-to-3D Generation . LRM: Large Reconstruction Model for Single Image to 3D . Can we model syntax from speech?Most models of syntax are text-based.Here we propose that basic syntax can be modeled from raw speech.GANs trained on individual words start to concatenate them into multiple-word outputs.Sometimes the model even concatenates three words: pic.twitter.com/rZXAhEulmN . &mdash; Gašper Beguš (@begusgasper) May 9, 2023 Basic syntax from speech: Spontaneous concatenation in unsupervised deep neural networks . ‘Dair’ (Live @ Urban Assault 2018) . Train T5 Model From Scratch . lingjzhu/CharsiuG2P — Multilingual G2P in 100 languages . kNN-CTC: Enhancing ASR via Retrieval of CTC Pseudo Labels, “code” . A🧵on beating the hardware lottery for retrieval: the internals of the late interaction stack.ColBERT introduced a quirky multi-vector retrieval architecture. It does wonders for quality.But how can it search 100M docs in 0.1 sec on CPU? Or store 1 billion embeddings in 20GB? pic.twitter.com/Nc3MDFxrj6 . &mdash; Omar Khattab (@lateinteraction) December 20, 2023 Speculative Decoding for 2x Faster Whisper Inference . SHI-Labs/VCoder — VCoder: Versatile Vision Encoders for Multimodal Large Language Models, arXiv 2023 . ConvNets Match Vision Transformers at Scale . SD-HuBERT: Self-Distillation Induces Syllabic Organization in HuBERT . An Introduction to Transformers . MobileASR: A resource-aware on-device learning framework for user voice personalization applications on mobile phones . Writing a good paper intro is difficult. I mostly recommend a 4-paragraph intro:1) Motivation: Task description / why is it important?2) Challenge: Why is problem so difficult?3) Trends: How does SotA approach it? What&#39;s missing?4) Method: How do you solve it? Contributions! . &mdash; Matthias Niessner (@MattNiessner) November 15, 2023 Improving Large-scale Deep Biasing with Phoneme Features and Text-only Data in Streaming Transducer . Training Distil-Whisper . Want high-quality Audio embeddings? CLAP! 👏We support the latest general, music and speech CLAP models in Transformers! Use it for Text-to-Speech/ Text-to-Music training and more.What is CLAP?CLAP (Contrastive Language-Audio Pretraining) is a neural network trained on… pic.twitter.com/iQNF6Um9yJ . &mdash; Vaibhav (VB) Srivastav (@reach_vb) November 20, 2023 Open Whisper-style Speech Model (OWSM) 🔉OWSM reproduces Whisper training using an open-source toolkit (ESPNet) and publicly available datasets. OWSM is much more efficient in training and is robust at multi-directional translations.Open source training, inference scripts and… pic.twitter.com/v9exxwevnO . &mdash; Vaibhav (VB) Srivastav (@reach_vb) November 21, 2023 What is Mixture-of-Experts (MoE)?MoE is a neural network architecture design that integrates layers of experts/models within the Transformer block. As data flows through the MoE layers, each input token is dynamically routed to a subset of the experts for computation. This… pic.twitter.com/AnYeITgHVi . &mdash; Sophia Yang, Ph.D. (@sophiamyang) December 9, 2023 wellecks/ntptutorial — Tutorial on neural theorem proving . Since Mixture of Expert (MoE) LLMs are all the rage as of this weekend, thanks to the Mixtral-8x-7B release, here&#39;s a quick explainer. The figure below shows the architecture behind the Switch Transformer (https://t.co/g3Awj99h24), a great intro to MoEs. The model depicted in… pic.twitter.com/2Wg5zjeFXU . &mdash; Sebastian Raschka (@rasbt) December 11, 2023 THE LITTLE BOOK OF DEEP LEARNING . Solar rises ☀️ @upstageai just released Solar a 10B an open LLM outperforming other LLMs up to 30B parameters, including Mistral 7B. 🤯 Solar achieves an MMLU score of 65.48, which is only 4 points lower than Meta Llama 2 while being 7x smaller.TL;DR;🦙 Llama 2 architecture… pic.twitter.com/tqgVExY8Yx . &mdash; Philipp Schmid (@_philschmid) December 13, 2023 fun idea I tested out this morning: Language model fine-tuning in embedding spacehere&#39;s the idea: learn a model of *embeddings* of a certain text distribution; then, to generate text, sample embedding and map back to text with vec2textthis lets us generate language without… pic.twitter.com/9PPI9q5KiM . &mdash; jack morris (@jxmnop) December 13, 2023 open-mmlab/Amphion — Amphion (/æmˈfaɪən/) is a toolkit for Audio, Music, and Speech Generation. Its purpose is to support reproducible research and help junior researchers and engineers get started in the field of audio, music, and speech generation research and development. . yangdongchao/AcademiCodec . SpeechAct: Towards Generating Whole-body Motion from Speech . Fine-tuning Whisper for Dutch Language: The Crucial Role of Size . Introduction to Speech Processing . LibriSpeech Alignments . OML-Team/open-metric-learning — Library for metric learning pipelines and models. . haotian-liu/LLaVA — [NeurIPS’23 Oral] Visual Instruction Tuning (LLaVA) built towards GPT-4V level capabilities and beyond. . Flip - Glass Animals . Simplifying Transformer Blocks . Advanced RAG Techniques: an Illustrated Overview . Nvidia presents Incremental FastPitchChunk-based High Quality Text to Speechpaper page: https://t.co/v1FxDzo7uMParallel text-to-speech models have been widely applied for real-time speech synthesis, and they offer more controllability and a much faster synthesis process… pic.twitter.com/pM4fnSdMAo . &mdash; AK (@_akhaliq) January 4, 2024 I created my YouTube series on Reinforcement Learning because I saw it applied profitably at Lyft. It was a counterexample to the stigma: &quot;RL is only good for scenarios where a perfect simulator can be accessed endlessly. It&#39;s general-but-slow trial-and-error.&quot;There&#39;s truth… pic.twitter.com/wowDxJaUWy . &mdash; DJ (@DuaneJRich) January 4, 2024 Parakeet RNNT &amp; CTC models top the Open ASR Leaderboard! 👑Brought to you by @NVIDIAAI and @suno_ai_, parakeet beats Whisper and regains its first place. The models are released under a commercially permissive license! 🥳The models inherit the same FastConformer… pic.twitter.com/jF96yecZ1t . &mdash; Vaibhav (VB) Srivastav (@reach_vb) January 2, 2024 nvidia/parakeet-rnnt-1.1b . The RAG wave is here to stay, but in practice, it&#39;s hard to retrieve the right docs w/ embdings, &amp; better IR models are hard to use!Let&#39;s fix that: Introducing 🪤RAGatouille, a lib to train&amp;use SotA retrieval model, ColBERT, in just a few lines of code!https://t.co/VRHiGQl0Xv pic.twitter.com/0EpOfV6UWn . &mdash; Benjamin Clavié (@bclavie) January 4, 2024 bclavie/RAGatouille . colbert-ir/colbertv2.0 . Progress on dense retrievers is saturating.The best retrievers in 2024 will apply new forms of late interaction, i.e. scalable attention-like scoring for multi-vector embeddings.A🧵on late interaction, how it works efficiently, and why/where it&#39;s been shown to improve quality pic.twitter.com/2XG33TtM9R . &mdash; Omar Khattab (@lateinteraction) December 18, 2023 Hallucinations in Neural Automatic Speech Recognition: Identifying Errors and Hallucinatory Models . LLM Augmented LLMs: Expanding Capabilities through Composition . Everyone building RAG uses dense embedding retrieval, but simply doing cosine distance doesn’t always capture fine-grained similarity.That’s why SOTA retrieval like ColBERT models are so important; these new architectures are fast but more powerful than pure dense retrieval.… pic.twitter.com/W2RPBBxml4 . &mdash; Jerry Liu (@jerryjliu0) January 5, 2024 Mathematical Introduction to Deep Learning: Methods, Implementations, and Theory . Is it possible to teach LLMs a different language? 🤔 Can we transfer the capabilities of LLMs, like Llama, from English to non-English language?A group of researchers from Fudan University tried to answer those questions by running vast experiments on extending vocabulary… pic.twitter.com/fJLYFyQOqP . &mdash; Philipp Schmid (@_philschmid) January 4, 2024 This AI Paper from Meta Introduces Hyper-VolTran: A Novel Neural Network for Transformative 3D Reconstruction and Rendering, paper . Phi-2: The surprising power of small language models . From Audio to Photoreal Embodiment: Synthesizing Humans in Conversations . MotionScript: Natural Language Descriptions for Expressive 3D Human Motions . pjyazdian/Gesture2Vec — This is an official PyTorch implementation of “Gesture2Vec: Clustering Gestures using Representation Learning Methods for Co-speech Gesture Generation” (IROS 2022). . neuromorphs/NIR — Neuromorphic Intermediate Representation reference implementation . Better Explained . PEFT for Speech: Unveiling Optimal Placement, Merging Strategies, and Ensemble Techniques . What You See is What You GAN: Rendering Every Pixel for High-Fidelity Geometry in 3D GANs . Love how RAGatouille makes it so easy to train new ColBERTs.ColBERT&#39;s real power is you can train it with as little as a few hundred queries. Other dense retrievers need tens of thousands!Maybe the test for @bclavie&#39;s library is whether we see an uptick in ColBERT downloads😆 https://t.co/TnTPT0smff pic.twitter.com/n4hnHQODqB . &mdash; Omar Khattab (@lateinteraction) January 4, 2024 100 tiny changes to transform your life: from the one-minute rule to pyjama yoga . This Paper from MIT and Microsoft Introduces ‘LASER’: A Novel Machine Learning Approach that can Simultaneously Enhance an LLM’s Task Performance and Reduce its Size with no Additional Training . The Truth is in There: Improving Reasoning in Language Models with Layer-Selective Rank Reduction . Decoder-only Architecture for Speech Recognition with CTC Prompts and Text Data Augmentation . LiteLlama: Reduced-Scale Llama — We present an open-source reproduction of Meta AI’s LLaMa 2. However, with significantly reduced model sizes, LiteLlama-460M-1T has 460M parameters trained with 1T tokens. . Token 1.3: What is Retrieval-Augmented Generation (RAG)? . VikParuchuri/surya — Accurate line-level text detection and recognition (OCR) in any language . gchrupala/neurospoken — Neural models of spoken language - LOT Winter school 2024 . I just found a great introduction to embedding. The book is comprehensive yet short. Historical encoding tools, neural nets, and production - all covered.Fantastic job by @vboykis. Thanks for making it free to read!Looking forward to diving in.https://t.co/uFwaSjaysn pic.twitter.com/SKl2ExOJaw . &mdash; Christoph Molnar (@ChristophMolnar) January 12, 2024 My AI Timelines Have Sped Up (Again) . NeMo - ASR with Transducers . Mixtral 8x7B is currently the best open-source LLM, surpassing GPT-3.5 . Foundations of Vector Retrieval . GARField: Group Anything with Radiance Fields . AlphaGeometry: An Olympiad-level AI system for geometry, code . Less horror. Probably full of typo.Source tex there:https://t.co/M1CPZs1kPl https://t.co/Spiy0JvC3f pic.twitter.com/9e4FdQol3b . &mdash; François Fleuret (@francoisfleuret) January 18, 2024 SceneVerse: Scaling 3D Vision-Language Learning for Grounded Scene Understanding . Tuning Language Models by Proxy .",
            "url": "https://jimregan.github.io/notes/links/2024/01/04/misc-links.html",
            "relUrl": "/links/2024/01/04/misc-links.html",
            "date": " • Jan 4, 2024"
        }
        
    
  
    
        ,"post18": {
            "title": "Interesting links, 27/12/2023",
            "content": "MycroftAI/lingua-franca . Attention is Not Only a Weight: Analyzing Transformers with Vector Norms . Salesforce/xgen-7b-8k-base . Learning Sparse Prototypes for Text Generation . Hungarian name days . siddk/voltron-robotics — Voltron: Language-Driven Representation Learning for Robotics . Mamba: Linear-Time Sequence Modeling with Selective State Spaces, state-spaces/mamba . What is Mamba? . johnma2006/mamba-minimal — Simple, minimal implementation of the Mamba SSM in one file of PyTorch. . airbnb/visx . nnnoiseless: porting audio code from C to rust, code . CSTR VCTK Corpus . ZDisket/TensorVox — Desktop application for neural speech synthesis written in C++ . avaneev/r8brain-free-src — High-quality pro audio resampler / sample rate converter C++ library. Very fast, for both audio resampling and time-series interpolation. . castorini/howl — Wake word detection modeling toolkit for Firefox Voice, supporting open datasets like Speech Commands and Common Voice. . stanford-oval/genie-toolkit — The Genie open source kit for voice assistant (formerly known as Almond) . stanford-oval/thingtalk — The Programming Language of Virtual Assistants . salesforce/morpheus — Code for ACL’20 paper “It’s Morphin’ Time! Combating Linguistic Discrimination with Inflectional Perturbations” . Instructions for estimating the location of beats in a soundfile . LSTMs Explained: A Complete, Technically Accurate, Conceptual Guide with Keras . Looking under the tinfoil hat: Clarifying the personological and psychopathological correlates of conspiracy beliefs . Different languages, similar encoding efficiency: Comparable information rates across the human communicative niche . OpenNMT-py BERT Tutorial . In his spare time, an engineer found flaws in the classic book “A Million Random Digits” . QData/TextAttack — About TextAttack 🐙 is a Python framework for adversarial attacks, data augmentation, and model training in NLP . Hear Slayer guitarist Jeff Hanneman’s ferocious unreleased demos for Reign In Blood . gtn-org/gtn — Automatic differentiation with weighted finite-state transducers. . Deformable DETR: Deformable Transformers for End-to-End Object Detection . Latent linguistic embedding for cross-lingual text-to-speech and voice conversion . Domain Adversarial Neural Networks for Dysarthric Speech Recognition . facebookincubator/CG-SQL — CG/SQL is a compiler that converts a SQL Stored Procedure like language into C for SQLite. SQLite has no stored procedures of its own. CG/CQL can also generate other useful artifacts for testing and schema maintenance. . Knowledge Transfer in Self Supervised Learning . Transformer Transducer: One Model Unifying Streaming and Non-streaming Speech Recognition . google/monster-mash — Sketch-Based Modeling and Animation Tool . DEEP LEARNING . Transformer-based Encoder-Decoder Models . RNNLogic: Learning Logic Rules for Reasoning on Knowledge Graphs . Overview: State-of-the-Art Machine Learning Algorithms per Discipline &amp; per Task . kmkurn/pytorch-crf . Composition-based on-the-fly rescoring for salient n-gram biasing . Spectrogram Inversion for Audio Source Separation via Consistency, Mixing, and Magnitude Constraints . Táin Bó Cúalnge . getkeops/keops — KErnel OPerationS, on CPUs and GPUs, with autodiff and without memory overflows . The Annotated S4, code . A Comprehensive Overview of Gaussian Splatting . stanfordnlp/dspy — Stanford DSPy: The framework for programming with foundation models . stanford-futuredata/ColBERT — ColBERT: state-of-the-art neural search (SIGIR’20, TACL’21, NeurIPS’21, NAACL’22, CIKM’22) . allenai/Holodeck — Language Guided Generation of 3D Embodied AI Environments. . dolphin-2.5-mixtral-8x7b . LLM360/Amber . Improving Whispered Speech Recognition Performance using Pseudo-whispered based Data Augmentation . More Hungarian, Kafka crow . MalcolmSlaney/python_auditory_toolbox . Protecting Voice-Controlled Devices against LASER Injection Attacks . Accelerating over 130,000 Hugging Face models with ONNX Runtime . The N Implementation Details of RLHF with PPO . 8 Hungarian Novels You Should Read Before You Die . apple/ml-ferret . Deploy Embedding Models with Hugging Face Inference Endpoints . Personal Copilot: Train Your Own Coding Assistant . Calculus Made Easy . Language Model Beats Diffusion – Tokenizer is Key to Visual Generation . Open X-Embodiment: Robotic Learning Datasets and RT-X Models, code . marella/ctransformers — Python bindings for the Transformer models implemented in C/C++ using GGML library. . chronhib-MU/Chronhib-Website — This is the ChronHib website repository. . Plachtaa/VALL-E-X — An open source implementation of Microsoft’s VALL-E X zero-shot TTS model. . suno-ai/bark — Text-Prompted Generative Audio Model . The Project Gutenberg Open Audiobook Collection, code . Ressources for End-to-End French Text-to-Speech Blizzard challenge . Using speech synthesis to explain automatic speaker recognition: a new application of synthetic speech . Speaker-independent Speech Inversion for Estimation of Nasalance, code . A System for Generating Voice Source Signals that Implements the Transformed LF-model Parameter Control . Implementing Contextual Biasing in GPU Decoder for Online ASR, idiap/contextual-biasing-on-gpus . Learning Cross-lingual Mappings for Data Augmentation to Improve Low-Resource Speech Recognition . BAT: Boundary aware transducer for memory-efficient and low-latency ASR . 4D ASR: Joint modeling of CTC, Attention, Transducer, and Mask-Predict decoders . idiap/bob — Bob is a free signal-processing and machine learning toolbox originally developed by the Biometrics group at Idiap Research Institute, in Switzerland. . A Neural TTS System with Parallel Prosody Transfer from Unseen Speakers . Vowel reduction by Greek-speaking children: The effect of stress and word length . Mapping Phonemes to Acoustic Symbols and Codes Using Synchrony in Speech Modulation Vectors Estimated by the Travellingwave Filter Bank . NeMo Forced Aligner and its application to word alignment for subtitle generation . A stimulus-organism-response model of willingness to buy from advertising speech using voice quality . MMSpeech: Multi-modal Multi-task Encoder-Decoder Pre-training for speech recognition . Competitive and Resource Efficient Factored Hybrid HMM Systems are Simpler Than You Think . Regarding Topology and Variant Frame Rates for Differentiable WFST-based End-to-End ASR . Cross-lingual Prosody Transfer for Expressive Machine Dubbing . An Analysis of Goodness of Pronunciation for Child Speech . Data augmentation for children ASR and child-adult speaker classification using voice conversion methods . Prefix Search Decoding for RNN Transducers . ddlBoJack/MT4SSL — Official implementation for MT4SSL: Boosting Self-Supervised Speech Representation Learning by Integrating Multiple Targets . amogh3892/Audio-classification-using-Bag-of-Frames-approach — Classification of different categories of audio clips, especially non speech sounds using Bag-of-Frames approach. . JournalismAI-2021-Quotes/quote-extraction — Quote extraction for modular journalism (JournalismAI collab 2021) . Nearest Neighbor Machine Translation . Atticus Open Contract Dataset . Clarifying exceptions and visualizing tensor operations in deep learning code . Translation Artifacts in Cross-lingual Transfer Learning . AI Explorables . Improving Target-side Lexical Transfer in Multilingual Neural Machine Translation . Leap-Of-Thought: Teaching Pre-Trained Models to Systematically Reason Over Implicit Knowledge . meyda/meyda — Audio feature extraction for JavaScript. . adrianbg/kaldi.js — This is a version of Kaldi tweaked to build to WebAssembly. . LSTMs Compose (and Learn) Bottom-Up . Modern Practical Natural Language Processing . Understanding Transformers, the Programming Way . Dual-mode ASR: Unify and Improve Streaming ASR with Full-context Modeling . Length-Adaptive Transformer: Train Once with Length Drop, Use Anytime with Search, code . Does my multimodal model learn cross-modal interactions? It’s harder to tell than you might think! . X-FACTR: Multilingual Factual Knowledge Retrieval from Pretrained Language Models . antonisa/unimorph_inflect — A python library for easily querying morphological inflection models trained on Unimorph . A Neural Network Playground . ConvnetJS demo . vivjay30/Cone-of-Silence — Speech Separation by Localization . ssnl/dataset-distillation . kermitt2/grobid — A machine learning software for extracting information from scholarly documents . microsoft/nni — An open source AutoML toolkit for automate machine learning lifecycle, including feature engineering, neural architecture search, model compression and hyper-parameter tuning. . microsoft/LabanotationSuite — Microsoft Applied Robotics Research Library: LabanotationSuite - open source software tools to give service robots the ability to perform human-like gestures . lucidrains/mixture-of-experts . TezRomacH/layer-to-layer-pytorch . Cross-lingual Retrieval for Iterative Self-Supervised Training . Pre-training via Paraphrasing . Augmenting Transformers with KNN-Based Composite Memory for Dialogue . REALM: Retrieval-Augmented Language Model Pre-Training, code . Rethinking Attention with Performers . CS231n: Convolutional Neural Networks for Visual Recognition . Over 200 of the Best Machine Learning, NLP, and Python Tutorials — 2018 Edition . KinWaiCheuk/nnAudio — Audio processing by using pytorch 1D convolution network . Bootstrapping Relation Extractors using Syntactic Search by Examples . OpenMonkeyStudio . The Fairy Tales of the Brothers Grimm . Winnie-the-Pooh . An Introduction to Hungarian Literature in 8 books . NLP-progress Dialogue . mermaid-js/mermaid — Generation of diagrams like flowcharts or sequence diagrams from text in a similar manner as markdown . The JavaScript library for bespoke data visualization . opal/opal — Opal is a Ruby to JavaScript source-to-source compiler. . linebender/druid — A data-first Rust-native UI design toolkit. . alphacep/vosk-api — Offline speech recognition API for Android, iOS, Raspberry Pi and servers with Python, Java, C# and Node . ossrs/srs — SRS is a simple, high-efficiency, real-time video server supporting RTMP, WebRTC, HLS, HTTP-FLV, SRT, MPEG-DASH, and GB28181. . Dobiasd/frugally-deep — Header-only library for using Keras (TensorFlow) models in C++. . HazyResearch/bootleg — Self-Supervision for Named Entity Disambiguation at the Tail . Composition-based on-the-fly rescoring for salient n-gram biasing . Spectrogram Inversion for Audio Source Separation via Consistency, Mixing, and Magnitude Constraints . google-research-datasets/RxR — Room-across-Room (RxR) is a large-scale, multilingual dataset for Vision-and-Language Navigation (VLN) in Matterport3D environments. It contains 126k navigation instructions in English, Hindi and Telugu, and 126k navigation following demonstrations. Both annotation types include dense spatiotemporal alignments between the text and the visual per… . Localized Narratives, code . automerge/automerge — A JSON-like data structure (a CRDT) that can be modified concurrently by different users, and merged again automatically. . cyrildiagne/ar-cutpaste . Embeddings from the Ground Up . Parrots learn to make video calls to chat with other parrots, then develop friendships, Northeastern University researchers say . alexa/visitron — VISITRON: A multi-modal Transformer-based model for Cooperative Vision-and-Dialog Navigation (CVDN) . Deep Transformers with Latent Depth . Project Euphonia . Recreating Historical Streetscapes Using Deep Learning and Crowdsourcing . Advanced libtorch . Deep Transformers with Latent Depth . alexa/ramen — A software for transferring pre-trained English models to foreign languages . alexa/Topical-Chat — A dataset containing human-human knowledge-grounded open-domain conversations. . Causal Reasoning in Probability Trees . cdk8s-team/cdk8s — Define Kubernetes native apps and abstractions using object-oriented programming . aware-ai/byt5-german-grammar . ali-vilab/videocomposer — Official repo for VideoComposer: Compositional Video Synthesis with Motion Controllability . microsoft/MS-SNSD — The Microsoft Scalable Noisy Speech Dataset (MS-SNSD) is a noisy speech dataset that can scale to arbitrary sizes depending on the number of speakers, noise types, and Speech to Noise Ratio (SNR) levels desired. . MarvinLvn/BabySLM — Behavioral probing of language acquisition models at the lexical and syntactic level . A Complete Logistic Regression Algorithm From Scratch in Python: Step by Step . convert_lm_to_fst.py . microsoft/hummingbird — Hummingbird compiles trained ML models into tensor computation for faster inference. . Noisy speech database for training speech enhancement algorithms and TTS models . From Senones to Chenones: Tied Context-Dependent Graphemes for Hybrid Speech Recognition . Converting Jupyter Notebooks into blog posts with Gatsby . YannickJadoul/Parselmouth . kkroening/ffmpeg-python . Interactive spreadsheets in Jupyter . Supervised Pretraining Can Learn In-Context Reinforcement Learning . robodhruv/visualnav-transformer — Official code and checkpoint release for “ViNT: A Foundation Model for Visual Navigation”. . mfaruqui/retrofitting — Retrofitting Word Vectors to Semantic Lexicons . jart/sectorlisp — Bootstrapping LISP in a Boot Sector . blink1073/oct2py — Run M Files from Python - GNU Octave to Python bridge . R language for programmers . scoder/lupa — Lua in Python . Lua for Python Programmers . deepinsight/insightface — State-of-the-art 2D and 3D Face Analysis Project . The importance of fillers for text representations of speech transcripts . Learning Robust and Multilingual Speech Representations . End-to-End Speech Recognition and Disfluency Removal . The role of context in neural pitch accent detection in English . Reconstructing the brain of fruit flies . Sharing Project Amber with the mental health community . mfaruqui/morph-trans — Code for morphological transformations . higgood/incremental-word2vec — Modify word2vec such that it’s possible to “condition” on existing embeddings for some words, and induce embeddings for new words. . Supervised Pretraining Can Learn In-Context Reinforcement Learning . The Power of Scale for Parameter-Efficient Prompt Tuning . shashikg/WhisperS2T — An Optimized Speech-to-Text Pipeline for the Whisper Model Supporting Multiple Inference Enginer . ‘Less Than One’-Shot Learning: Learning N Classes From M&lt;N Samples . Better Together: Dialogue Separation and Voice Activity Detection for Audio Personalization in TV . Speaker Embedding Extraction with Phonetic Information . On the Importance of Adaptive Data Collection for Extremely Imbalanced Pairwise Tasks . TensorSpeech/TensorflowTTS — 😝 TensorFlowTTS: Real-Time State-of-the-art Speech Synthesis for Tensorflow 2 (supported including English, French, Korean, Chinese, German and Easy to adapt for other languages) . Language Model is All You Need: Natural Language Understanding as Question Answering . Building RNNs is Fun with PyTorch and Google Colab . 20 free Irish language audiobooks for children . emijrp/internet-archive . drtoast/flickr-backup . Generalized End-to-End Loss for Speaker Verification . Layout-Parser/layout-parser — A Unified Toolkit for Deep Learning Based Document Image Analysis . OCR for Endangered Language Texts, code . Google Cardboard open sourced as active development on Google VR SDK stops . googlevr/cardboard . KomputeProject/kompute — General purpose GPU compute framework built on Vulkan to support 1000s of cross vendor graphics cards (AMD, Qualcomm, NVIDIA &amp; friends). Blazing fast, mobile-enabled, asynchronous and optimized for advanced GPU data processing usecases. Backed by the Linux Foundation. . m3hrdadfi/wiki-summary — A Bert2Bert model which able to summarize articles! . CAMeL-Lab/camel_tools — A suite of Arabic natural language processing tools developed by the CAMeL Lab at New York University Abu Dhabi. . Traditional Versus ASR-Based Pronunciation Instruction, An Empirical Study . ruffle-rs/ruffle — A Flash Player emulator written in Rust . Learning Sparse Prototypes for Text Generation . A Speech-To-Text Practitioner’s Criticisms of Industry and Academia . ml5js . BrainJS/brain.js . edobashira/fst.js . Deconstructing BERT . ANNOYingly Simple Sentence Clustering . Guitarix . How JavaScript Libraries Are Training Neural Networks on Web Browsers . andrenatal/phonetisaurus-emscripten . U2-Net: Going Deeper with Nested U-Structure for Salient Object Detection, code . A table detection, cell recognition and text extraction algorithm to convert tables in images to excel files . Finding Syntax with Structural Probes . adefossez/julius — Fast PyTorch based DSP for audio and 1D signals . M2KD: Multi-model and Multi-level Knowledge Distillation for Incremental Learning . evcxr/evcxr — An evaluation context for Rust. . Rust and WebScraping . Attention is Not Only a Weight: Analyzing Transformers with Vector Norms . Pronunciation Variation Modeling for Dutch Automatic Speech Recognition . Booting from a vinyl record . Score-Based Generative Modeling through Stochastic Differential Equations . MSP: Multi-Stage Prompting for Making Pre-trained Language Models Better Translators . Hero-Tales of Ireland by Jeremiah Curtin . MycroftAI/lingua-franca — Mycroft’s multilingual text parsing and formatting library . Acoustic event recognition using cochleagram image and convolutional neural networks . CBMM/cochleagram — Cochlear sound spectrum . Speaker-independent vowel recognition: spectrograms versus cochleagrams . A joint training framework for robust automatic speech recognition . Auditory features based on Gammatone filters for robust speech recognition . NN-512 — NN-512 is a compiler that generates C99 code for neural net inference . vakila/de-stress — Prototype German Computer-Assisted Pronunciation Training tool for lexical stress errors . guanpengchn/awesome-pronunciation . Automatic Prosodic Event Detection Using Acoustic, Lexical, and Syntactic Evidence . 10 Ways to Optimize Text for Machine Translation . Text2Image: A new way to NLP? . The Nand Game . Learning from Language Explanations . Talisman: a JavaScript archive of fuzzy matching, information retrieval and record linkage building blocks . Computing Receptive Fields of Convolutional Neural Networks . Sequence Modeling With CTC . xinjli/allosaurus — Allosaurus is a pretrained universal phone recognizer for more than 2000 languages . Feature Learning in Infinite-Width Neural Networks . Uncertainty Estimation in Autoregressive Structured Prediction . RNNs can generate bounded hierarchical languages with optimal memory . persephone-tools/persephone — A tool for automatic phoneme transcription . dmort27/allovera — A phoneme-allophone database for many languages . Deploying Part-of-Speech Patterns to Enhance Statistical Phrase-Based Machine Translation Resources . A Comparison of Techniques for Language Model Integration in Encoder-Decoder Speech Recognition . The Scientist and Engineer’s Guide to Digital Signal Processing . When regular is not easy: Cracking the code of Irish orthography . giakou4/pyfeats — Open source software for image feature extraction. . Affordances from Human Videos as a Versatile Representation for Robotics . ReadAlongs/Studio — Audiobook alignment for Indigenous languages . ReadAlongs/Web-Component — Suite of web packages for creating interactive ReadAlongs . roedoejet/convertextract — Extract and find/replace text based on arbitrary correspondences while preserving original file formatting. This library is a fork from the Textract library by Dean Malmgren. . Gⁱ-to-Pⁱ Studio . markovka17/dla — Deep learning for audio processing . What is a signal . facebookresearch/CPC_audio — An implementation of the Contrast Predictive Coding (CPC) method to train audio features in an unsupervised fashion. . ZuCo, a simultaneous EEG and eye-tracking resource for natural sentence reading . iamjanvijay/rnnt_decoder_cuda — An efficient implementation of RNN-T Prefix Beam Search in C++/CUDA. . awni/transducer — A Fast Sequence Transducer Implementation with PyTorch Bindings . iceychris/LibreASR — An On-Premises, Streaming Speech Recognition System . How to convert a pre-trained model for Kaldi to Vosk . MediaPipe Holistic — Simultaneous Face, Hand and Pose Prediction, on Device . English Dialects From the Eighth Century to the Present Day by Walter W. Skeat . Ireland, Historic and Picturesque by Charles Johnston . What’s the Matter with Ireland? by Ruth Russell . A Visit From Saint Nicholas by Clement Clarke Moore . The Most Ancient Lives of Saint Patrick by James O’Leary . Anglo-Saxon Literature by John Earle . The Reminiscences of an Irish Land Agent by Samuel Murray Hussey . Digital ink recognition . Building Custom Deep Learning Based Optical Character Recognition (OCR) models . emedvedev/attention-ocr — A Tensorflow model for text recognition (CNN + seq2seq with visual attention) available as a Python package and compatible with Google Cloud ML Engine. . Retentive Network: A Successor to Transformer for Large Language Models . courao/ocr.pytorch — A pure pytorch implemented ocr project including text detection and recognition . Xilinx/pytorch-ocr — Quantized LSTMs for OCR . DTolm/VkFFT — Vulkan/CUDA/HIP/OpenCL/Level Zero/Metal Fast Fourier Transform library . DTolm/VkResample — Vulkan real-time FFT upscaling . Historical Copyright Records and Transparency . Speech-Lab-IITM/English_ASR_Challenge — English ASR Challenge organized by Speech Lab, IIT Madras . Unsupervised Cross-lingual Representation Learning for Speech Recognition . Example for Clustered Transformers . Speech Recognition with Python . TAPAS base model fine-tuned on WikiTable Questions . What is Similarity Between Sentences? . catalyst-team/dl-course — Deep Learning with Catalyst . facebookresearch/ClassyVision — An end-to-end PyTorch framework for image and video classification . Mel Frequency Cepstral Coefficient (MFCC) tutorial . Claare Ny Gael . Description d’un parler irlandais de Kerry/Texte . Audio samples of Ulster-Scots speakers . Ulster-Scots Education Resources . Lowland Scots . An focal don ainmhí seo → 🐶 i nGaeilge . Character Recognition and Segmentation For Custom Data Using Detectron2 . da03/Attention-OCR — Visual Attention based OCR . Comhar . How to train Tesseract 4 . Recent Advances in Google Translate . Narrative framing of consumer sentiment in online restaurant reviews . VFsync . TinyEMU . Model Zoo . Training optical character recognition technology Tesseract on a new character font on MacOS . Fine-tuning Tesseract OCR for German Invoices . Training Tesseract on your custom dataset using Qt Box Editor . Simple OCR with Tesseract . Add four additional special unicode characters to tesseract . zdenop/qt-box-editor — QT4 editor of tesseract-ocr box files . IfcOpenShell — The open source IFC toolkit and geometry engine . IFCjs/web-ifc-viewer — Graphics engine and toolkit for client applications. . SketchUp-STL . Self-training and pre-training, understanding the wav2vec series . clovaai/deep-text-recognition-benchmark — Text recognition (optical character recognition) with deep learning methods. . apple/ml-equivariant-neural-rendering — This repo contains code to reproduce all experiments in Equivariant Neural Rendering by E. Dupont, M. A. Bautista, A. Colburn, A. Sankar, C. Guestrin, J. Susskind, Q. Shan, ICML 2020. . PrefectHQ/prefect — Prefect is a workflow orchestration tool empowering developers to build, observe, and react to data pipelines . kaituoxu/Conv-TasNet — A PyTorch implementation of Conv-TasNet described in “TasNet: Surpassing Ideal Time-Frequency Masking for Speech Separation” with Permutation Invariant Training (PIT). . Månadens profil: Jim O´Regan - Språkbanken . The historical short vowel phonology of Gaelic . Lexicon of Old Irish . The Structure of the Consonant System of the Gaelic of Torr, Co. Donegal . Collins gem Irish dictionary : English-Irish, Irish-English . Visual Speech Enhancement Without A Real Visual Stream, code . joonson/syncnet_python — Out of time: automated lip sync in the wild . High-Fidelity Audio Generation and Representation Learning With Guided Adversarial Autoencoder . The Grammar of English Grammars . karthiTox/deepnet.js — Auto-differentiation library for javascript . Familiar feud in Poland after game show calls regional language a dialect . Intrinsic Dimensionality Explains the Effectiveness of Language Model Fine-Tuning . Google’s REALM — A Knowledge-base Augmented Language Model . apple/ml-mkqa — We introduce MKQA, an open-domain question answering evaluation set comprising 10k question-answer pairs aligned across 26 typologically diverse languages (260k question-answer pairs in total). The goal of this dataset is to provide a challenging benchmark for question answering quality across a wide set of languages. Please refer to our paper f… . Spoken Wikipedia - Swedish . From Historical Sources to Datasets: A Preview of DataScribe, code . Understanding the effects of word-level linguistic annotations in under-resourced neural machine translation . Reading and Writing RDF in Apache Jena . kba/jsonld-rapper — Create RDF from JSON-LD with rapper . JSON-LD Syntax 1.0 . Cad iad na focail Ghaeilge is mó a mbíonn deacracht ag daoine atá líofa sa teanga iad a litriú? . &mdash; Eoin P. Ó Murchú (@murchadhmor) January 6, 2021 Study: Folklore structure reveals how conspiracy theories emerge, fall apart . Word-level text generation with Keras in &lt;50 lines of code . TruthfulQA: Measuring How Models Mimic Human Falsehoods . Continuous Active Learning Using Pretrained Transformers . Cainteoirí Dúchais a éisteacht . stanfordnlp/string2string — String-to-String Algorithms for Natural Language Processing . REVIEW OF 1984 By Isaac Asimov . MLCommons People’s Speech Dataset . Wasmer, code . COBE: Contextualized Object Embeddings from Narrated Instructional Video . Russian Text Normalization for STT and TTS . k-Nearest Neighbor Language Models . PyTorch internals . MiniTorch . thu-spmi/CAT — A CRF-based ASR Toolkit . Linformer: Self-Attention with Linear Complexity . Joint Speech Recognition and Speaker Diarization via Sequence Transduction . galv/galvASR . awslabs/sockeye — Sequence-to-sequence framework with a focus on Neural Machine Translation based on PyTorch . Cross-lingual Retrieval for Iterative Self-Supervised Training . How to publish a txt corpora with NIF as Linked Data . RDF Mapping Language . ImageDescriptionRdfExamples . openai/CLIP — CLIP (Contrastive Language-Image Pretraining), Predict the most relevant text snippet given an image . Recognizing Pose Similarity in Images and Videos . opensheetmusicdisplay/opensheetmusicdisplay — OpenSheetMusicDisplay renders sheet music in MusicXML format in your web browser based on VexFlow. OSMD is brought to you by PhonicScore.com. . katspaugh/wavesurfer.js . Spectrograms and speech processing . Why You Should Do NLP Beyond English . Leabhair do Pháistí . DingXiaoH/RepVGG — RepVGG: Making VGG-style ConvNets Great Again . adamjankaczmarek/poleval2020 . kwrobel-nlp/kftt — Polish morphosyntactic tagger. . First Steps in Irish . Foghraidheacht Ghaedhilge an Tuaiscirt . Guide to Irish Pronunciation . An Ghaeilge . AOIDHMÍN MAC GRÉAGÓIR . izuzak/noam — JavaScript library for working with automata and grammars for regular and context-free languages . google/refr — A framework for building reranking models. . usc-sail/barista — Barista is an open-source framework for concurrent speech processing. . Pronouns and Definite vs Indefinite Conjugation . labmlai/annotated_deep_learning_paper_implementations . k-Nearest Neighbor Language Models . Evaluate k-nearest neighbor language model . Weight Standardization . Nucleus Sampling . Denoising Diffusion Probabilistic Models (DDPM) . A Course in Machine Learning . CS224N: Natural Language Processing with Deep Learning . OpenNLPLab/cosFormer — [ICLR 2022] Official implementation of cosformer-attention in cosFormer: Rethinking Softmax in Attention . MarianMT Know, Train &amp; Infer . web-arena-x/webarena — Code repo for “WebArena: A Realistic Web Environment for Building Autonomous Agents” . POSSESSIVE AFFIXES . nltk.tag.brill module . LoraHub: Efficient Cross-Task Generalization via Dynamic LoRA Composition, code . Guidance: a cheat code for diffusion models . Diffusion language models . Perspectives on diffusion . Anki decks Hungarian . How to adapt a multilingual T5 model for a single language . salesforce/LAVIS — LAVIS - A One-stop Library for Language-Vision Intelligence . kscanne/gbb — Sonraí traenála/tástála NLP . Transformer Taxonomy . ML Olympiad - Multilingual Spell Correction . Fine-tuning the multilingual T5 model from Huggingface with Keras . How to adapt a multilingual T5 model for a single language . Irish Language Sayings . Zjh-819/LLMDataHub — A quick guide (especially) for trending instruction finetuning datasets . Exploring Transfer Learning with T5: the Text-To-Text Transfer Transformer, code . T5 Fine Tuning Tutorial . Learning Cross-Lingual Sentence Representations via a Multi-task Dual-Encoder Model . Hannibal046/Awesome-LLM — Awesome-LLM: a curated list of Large Language Model . Miipher: A Robust Speech Restoration Model Integrating Self-Supervised Speech and Text Representations . cvg/LightGlue — LightGlue: Local Feature Matching at Light Speed (ICCV 2023) . kenjihiranabe/The-Art-of-Linear-Algebra — Graphic notes on Gilbert Strang’s “Linear Algebra for Everyone” . Forced Alignment with Wav2Vec2 . click . Prompting Large Language Models for Zero-Shot Domain Adaptation in Speech Recognition . UD Swedish Talbanken . google-research/tensor2robot — Distributed machine learning infrastructure for large-scale robotics research . google-research/pix2seq — Pix2Seq codebase: multi-tasks with generative modeling (autoregressive and diffusion) . google-research/language-table — Suite of human-collected datasets and a multi-task continuous control benchmark for open vocabulary visuolinguomotor learning. . google-research/jax3d . Doktor Bubó . Unit 3. Transformer architectures for audio . HomeRobot: Open Vocabulary Mobile Manipulation, code . SURT 2.0: Advances in Transducer-based Multi-talker Speech Recognition . google-deepmind/dm_robotics — Libraries, tools and tasks created and used at DeepMind Robotics. . facebookresearch/LaViLa — Code release for “Learning Video Representations from Large Language Models” . facebookresearch/paco — This repo contains documentation and code needed to use PACO dataset: data loaders and training and evaluation scripts for objects, parts, and attributes prediction models, query evaluation scripts, and visualization notebooks. . Introduction to Haliax . lyuchenyang/Macaw-LLM — Macaw-LLM: Multi-Modal Language Modeling with Image, Video, Audio, and Text Integration . YuanGongND/cav-mae — Code and Pretrained Models for ICLR 2023 Paper “Contrastive Audio-Visual Masked Autoencoder”. . Tracking Everything Everywhere All at Once, code . facebookresearch/audiocraft — Audiocraft is a library for audio processing and generation with deep learning. It features the state-of-the-art EnCodec audio compressor / tokenizer, along with MusicGen, a simple and controllable music generation LM with textual and melodic conditioning. . Whar city every country is most ashamed of in europe . mkuchnik/relm — ReLM is a Regular Expression engine for Language Models . A Fast Algorithm for Computing Prefix Probabilities . Implementation of the Branchformer . Transducer Beam Search . HyperMixer: An MLP-based Low Cost Alternative to Transformers . CTC Beam Search . FlexFormer . HyperConformer . SpeechX: Neural Codec Language Model as a Versatile Speech Transformer . Brainformers: Trading Simplicity for Efficiency . ggerganov/whisper.cpp . unilight/seq2seq-vc — A sequence-to-sequence voice conversion toolkit. . shivangi-aneja/COSMOS — [AAAI 2023] COSMOS: Catching Out-of-Context Misinformation using Self Supervised Learning . DeepFilterNet: Perceptually Motivated Real-Time Speech Enhancement . There was a &#39;Not Found&#39; error fetching URL: &#39;https://twitter.com/i/web/status/1661714548594823174&#39; . Announcing AI2 OLMo, an Open Language Model Made by Scientists, for Scientists . Byte Pair Encoding is Suboptimal for Language Model Pretraining . The PhotoBook Dataset: Building Common Ground through Visually-Grounded Dialogue . MuJoCo, code — Multi-Joint dynamics with Contact. A general purpose physics simulator. . google-research/robopianist — [CoRL ‘23] Dexterous piano playing with deep reinforcement learning. . Perlence/PyGuitarPro — Read, write and manipulate GP3, GP4 and GP5 files. . Towards Healthy AI: Large Language Models Need Therapists Too . https://openuni.ai/, code . psst-challenge/psstbaseline — Baseline models for the Post-Stroke Speech Transcription (PSST) challengt . OIG Dataset . togethercomputer/OpenChatKit . viktor-enzell/wav2vec2-large-voxrex-swedish-4gram . Flamingo: a Visual Language Model for Few-Shot Learning . UL2 20B: An Open Source Unified Language Learner, code . Kaldi ASR: Extending the ASpIRE model . openai/CLIP — CLIP (Contrastive Language-Image Pretraining), Predict the most relevant text snippet given an image . Multimodal Chain-of-Thought Reasoning in Language Models, code . lllyasviel/ControlNet — Let us control diffusion models! . HotpotQA, huggingface . GPT in 60 Lines of NumPy . FelixOpolka/Single-Player-MCTS — Python implementation of single-player Monte-Carlo Tree Search. . google-deepmind/mctx — Monte Carlo tree search in JAX . Speech Synthesis, Recognition, and More With SpeechT5 . Teaching OPT to Paraphrase through Soft Prompt Tuning . Use transfer learning for ASR in ESPnet2 . AudioLDM: Text-to-Audio Generation with Latent Diffusion Models . v-iashin/SpecVQGAN — Source code for “Taming Visually Guided Sound Generation” (Oral at the BMVC 2021) . Bayes risk CTC: Controllable CTC alignment in Sequence-to-Sequence tasks . Compiling . OverFlow: Putting flows on top of neural transducers for better TTS . Introducing anywidget . dair-ai/Mathematics-for-ML — A collection of resources to learn mathematics for machine learning . dair-ai/ML-Notebooks — Machine Learning Notebooks . SentenceBERT — Semantically meaningful sentence embeddings the right way . krrish94/nerf-pytorch — A PyTorch re-implementation of Neural Radiance Fields . nv-tlabs/nglod — Neural Geometric Level of Detail: Real-time Rendering with Implicit 3D Shapes (CVPR 2021 Oral) . NVIDIAGameWorks/PhysX — NVIDIA PhysX SDK . NVIDIA-Omniverse/IsaacGymEnvs — Isaac Gym Reinforcement Learning Environments . NVIDIAGameWorks/kaolin — A PyTorch Library for Accelerating 3D Deep Learning Research . Learning to Predict 3D Objects with an Interpolation-based Differentiable Renderer, code . Denys88/rl_games — RL implementations . sail-sg/envpool — C++-based high-performance parallel environment execution engine (vectorized env) for general RL environments. . Evidence of a predictive coding hierarchy in the human brain listening to speech . Hungarian pronouns . Hungarian Core 100 Word List . A Distributed Systems Reading List . facebookresearch/LASER . RDF Mapping Language . ImageDescriptionRdfExamples . Lexicon Model for Ontologies: Community Report, 10 May 2016 . Leabhair do Pháistí . ‘Tá an aisling seo agam’ . Dive into Deep Learning . Working with sequences . Wapiti - A simple and fast discriminative sequence labelling toolkit, code . Towards Augmenting Lexical Resources for Slang and African American English . jupyter-xeus/xeus-cling . Notebook to run Ruby on Google Colaboratory . Finding the Words to Say: Hidden State Visualizations for Language Models . MixConv: Mixed Depthwise Convolutional Kernels . Extracting Features from an Intermediate Layer of a Pretrained ResNet Model in PyTorch . Basics of Self-Attention . PatchBERT: Just-in-Time, Out-of-Vocabulary Patching . Fine-tuning Mozilla DeepSpeech for the Indian Accent . Indian Accent Speech Recognition . wilpert/RusPhonetizer . trainc — TrainC builds compact context dependency transducers for WFST-based speech recognition from acoustic training data. . VoxPopuli: A Large-Scale Multilingual Speech Corpus for Representation Learning, Semi-Supervised Learning and Interpretation . A curated list of speech and natural language processing resources . benob/openlat — Toolkit for manipulating word lattices built on top of openfst . usc-sail/barista — Barista is an open-source framework for concurrent speech processing. . amir-zeldes/gum — Repository for the Georgetown University Multilayer Corpus (GUM) . nassosoassos/sail_align — SailAlign is an open-source software toolkit for robust long speech-text alignment implementing an adaptive, iterative speech recognition and text alignment scheme that allows for the processing of very long (and possibly noisy) audio and is robust to transcription errors. . Darby O’Gill and the Good People . The Sleeping beauty of the wood . LEAF: A Learnable Frontend for Audio Classification . Spectrogram &amp; Oscillator, code . lucidrains/axial-positional-embedding — Axial Positional Embedding for Pytorch . CPJKU/madmom — Python audio and music signal processing library . matthew-brett/transforms3d — 3 dimensional spatial transformations . Moof-A-Day: Early Macintosh Software . arogozhnikov/einops — Flexible and powerful tensor operations for readable and reliable code (for pytorch, jax, TF and others) . Introducing Lamini, the LLM Platform for Rapidly Customizing Models . The Illustrated Stable Diffusion . Leaḃar ar áireaṁ . Auraicept na n-éces . Naoi ngábhadh an Ghiolla Dhuibh. . Naoi Ghabh an Ghiolla Dubh . lucidrains/PaLM-rlhf-pytorch — Implementation of RLHF (Reinforcement Learning with Human Feedback) on top of the PaLM architecture. Basically ChatGPT but with PaLM . How Virtual Reality Can Help Those With Autism . Giskard is coming to your notebook: Python meets Java via gRPC tunnel . Illustrating Reinforcement Learning from Human Feedback . Point-E: A System for Generating 3D Point Clouds from Complex Prompts . microsoft/BlingFire — A lightning fast Finite State machine and REgular expression manipulation library. . rom1504/cc2dataset — Easily convert common crawl to a dataset of caption and document. Image/text Audio/text Video/text, . facebookresearch/barlowtwins — PyTorch implementation of Barlow Twins. . facebookresearch/vicreg — VICReg official code base . sileod/tasknet — Easy multi-task learning with HuggingFace Datasets and Trainer . Irish English Resource Centre . Reward is not Necessary: How to Create a Modular &amp; Compositional Self-Preserving Agent for Life-Long Learning . The Standardization of Irish . Reviewed Work: Linguistic Atlas and Survey of Irish Dialects. Vol. IV, the Dialects of Ulster and the Isle of Man. Specimens of Scottish Gaelic Dialects. Phonetic Texts of East Ulster Irish by Heinrich Wagner, Colm Ó Baoill . Vol. 16, 1952, Contributions in Memory of Osborn Bergin . Vol. 13, 1942 Ériu . Why libtorch? . orktes/go-torch — LibTorch (PyTorch) bindings for Golang . The Gaelic dialect of Urris, Inishowen, Co. Donegal . karpathy/deep-vector-quantization — VQVAEs, GumbelSoftmaxes and friends . Animating Stereograms with Optical Flow Morphing . Transformers in Pytorch from scratch for NLP Beginners . PyTorch for TensorFlow Users - A Minimal Diff . Brain, Time, CTC blank states and streaming . Testing Facebook MMS and SeamlessMT4 Word Error Rate . N-gram language model toolkits in 2020 . jermp/tongrams — A C++ library providing fast language model queries in compressed space. . On latency of speech recognition . Wav2vec 2.0: Learning the structure of speech from raw audio . Generate distance matrix from features . Calamari-OCR/calamari — Line based ATR Engine based on OCRopy . kraken, mittagessen/kraken — OCR engine for all the languages . GT4HistOCR: Ground Truth for training OCR engines on historical documents in German Fraktur and Early Modern Latin . not-implemented/hocr-proofreader — Web based JavaScript GUI library for proofreading/editing hOCR . GeReV/hocr-editor-ts — A visual hOCR file editor . What the BookCorpus? . Introduction to Simple Neural Networks . PaperPort . OmniPage . Python Concurrency: The Tricky Bits . hocr-tools, CUSAT/hocr-tools — Tools for manipulating and evaluating the hOCR format for representing multi-lingual OCR results by embedding them into HTML. . mbartoli/tAlign — Text alignment for OCR using FFTs . DDMAL/text_alignment — Aligns correct transcripts to text images using a “messy” OCR and Needleman-Wunsch sequence alignment . Early-Modern-OCR/RETAS — Part of eMOP: the Recursive Text Alignment Tool compares OCR text results to groundtruth by character and computes a score. . cisocrgroup/ocrd_cis — OCR-D python tools . ofirpress/shortformer — Code for the Shortformer model, from the ACL 2021 paper by Ofir Press, Noah A. Smith and Mike Lewis. . PAQ: 65 Million Probably-Asked Questions and What You Can Do With Them . Irish Script on Screen . Gaeilge Laighean by Colm Ó Broin . XLSR.ipynb . TomHarte/dsk2woz — A command-line tool to convert Apple II DSK images to WOZ format. . bzotto/picturedsk — Imprint an “image” in the magnetic flux of an Apple 5.25” floppy disk . Learn About Transformers: A Recipe . ILF… audio recordings . Beaṫa Aoḋa Ruaiḋ Ui Doṁnaill . Fiche bliadhain ag fás . Training an Ocropus OCR model . Finding blocks of text in an image using Python, OpenCV and numpy . ocropus-archive/DUP-ocropy — Python-based tools for document analysis and OCR . Joint ASR and language identification using RNN-T: An efficent approach to dynamic language switching . NVIDIA/speechsquad — Conversational AI Benchmark. . Urlabhraidheacht agus graimear na gaedhilge, cuid I. . Illustrating the Reformer . digiah/oldOCR — Optical Character Recognition of old and noisy print sources . Neural Inverse Text Normalization . JFLAP — JFLAP is software for experimenting with formal languages topics including nondeterministic finite automata, nondeterministic pushdown automata, multi-tape Turing machines, several types of grammars, parsing, and L-systems. . tokenwiser . Chris Lattner: Revolutionizing the C++ World . Irish folklore archive inscribed into UNESCO register . GraphiteEditor/Graphite — 2D raster &amp; vector editor that melds traditional layers &amp; tools with a modern node-based, fully non-destructive procedural workflow. . apple/turicreate — Turi Create simplifies the development of custom machine learning models. . Comparing signals in the time domain . google-research/sofima — Scalable Optical Flow-based Image Montaging and Alignment . google-research/noise2music . google-research/lingvo-lab — Demos, samples, and experimental code for Lingvo. . google-research/last — A JAX library for building lattice-based speech transducer models . ZipIt! Merging Models from Different Tasks without Training . hyunwoongko/kochat — Opensource Korean chatbot framework . Asteroid getting started . Irish UPSID 342 . Lyra: A New Very Low-Bitrate Codec for Speech Compression . neulab/nn4nlp-concepts — A repository of concepts related to neural networks for NLP . neubig/nn4nlp-code — Code Samples from Neural Networks for NLP . Modern Irish grammar . seungwonpark/melgan — MelGAN vocoder (compatible with NVIDIA/tacotron2) . ‘Déanaim iarracht ‘rothar’ a rá in áit ‘badhsacal’ – tuairim chonspóideach do Chois Fhairrgeach…’ . Interface Between Phonology and Phonetics . Unsupervised Question Answering . Extending a Parser to Distant Domains Using a Few Dozen Partially Annotated Examples . NLTK Sample usage for parse . allenai/allennlp — An open-source NLP research library, built on PyTorch. . allenai/allennlp-semparse — A framework for building semantic parsers (including neural module networks) with AllenNLP, built by the authors of AllenNLP . DaCy: New Fast and Efficient State-of-the-Art in Danish NLP! . triantac/punkbuddy . Nuclear accents in four Irish (Gaelic) dialects . Development of an automatic attitude recognition system: a multimodal analysis of video blogs . The phonetics and phonology of the intonation of Irish dialects . Controlling the voice quality dimension of prosody in synthetic speech using an acoustic glottal model . MASSIVE translations . google-research/nisaba — Finite-state script normalization and processing utilities . OSM: Townlands . Using alignments from Montreal Forced Aligner to train . alberto-poncelas/tesseract_postprocess . Tonal alignment in three varieties of Hiberno-English . Modelling intonation in three Irish dialects . Peak timing in two dialects of Connaught Irish . Dialect alignment signatures . A Linguistically Motivated Computational Framework for Irish Sign Language . Maidir le Croidhe Cainnte Chiarraighe . SingFónaic . Helsinki-NLP/Tatoeba-Challenge . Fisher Information Matrix . zhao-shuyang/childrenize — Signal processing method to convert adult speech into child-like . Learnable latent embeddings for joint behavioural and neural analysis . Teic na nGael . ABAIR-CabairE . in progress list for Project Gutenberg . Facebook &amp; Google’s LazyTensor Enables Expressive Domain-Specific Compilers . The Dialects of Co. Clare, Part 1 . facebookresearch/vissl — VISSL is FAIR’s library of extensible, modular and scalable components for SOTA Self-Supervised Learning with images. . google-research/simclr — SimCLRv2 - Big Self-Supervised Models are Strong Semi-Supervised Learners . Leveraging the Exact Likelihood of Deep Latent Variable Models . Transformers Explained Visually part 2 . salesforce/WikiSQL — A large annotated semantic parsing corpus for developing natural language interfaces. . bentrevett/pytorch-seq2seq — Tutorials on implementing a few sequence-to-sequence (seq2seq) models with PyTorch and TorchText. . Essential sources for Irish dialect study II: Doegen . The Irish Language in Rathlin Island . Ráidhteachas an Fheadha . salesforce/apollo — An experimental multi-tenant distributed system platform . salesforce/TransmogrifAI — TransmogrifAI (pronounced trăns-mŏgˈrə-fī) is an AutoML library for building modular, reusable, strongly typed machine learning workflows on Apache Spark with minimal hand-tuning . salesforce/decaNLP — The Natural Language Decathlon: A Multitask Challenge for NLP . salesforce/TabularSemanticParsing — Translating natural language questions to a structured query language . salesforce/ai-economist — Foundation is a flexible, modular, and composable framework to model socio-economic behaviors and dynamics with both agents and governments. This framework can be used in conjunction with reinforcement learning to learn optimal economic policies, as done by the AI Economist (https://www.einstein.ai/the-ai-economist). . Books in Seanchló / Cló Gaelach . Cnuasach Focal as Oirialla . aistear — Suíomh áiseanna d’aistritheoirí, d’eagarthóirí agus do gach duine a bhíonn ag scríobh i nGaeilge. . Ba mhaith liom ‘a thuiscint’ cén fáth a bhfuil an ghramadach chomh deacair sin . D2Go brings Detectron2 to mobile, facebookresearch/d2go — D2Go is a toolkit for efficient deep learning . Ropucha: fadedpage, Wikiźródła . Spanish . . Apes, psychos, alcos: How British cartoonists depict the Irish . Keating’s general history of Ireland . Irish Language, 1700-1999 — Selection of books and manuscripts written in Irish. . Irish prose and poetry . Dánta aṁráin, is caointe Ṡeaṫrúin Céitinn . Imtheachta Æniasa. . Cuchulain of Muirthemne sacred texts . Parliamentary Papers, Proceedings and Departmental Papers : UK: Ireland . Calendar of documents, relating to Ireland, preserved in Her Majesty’s Public Record Office, London, 1171-1307 . Bealoideasbeo.com . . syegulalp/Akilang — A compiler for a simple language, built with Python and LLVM . lark-parser/lark — Lark is a parsing toolkit for Python, built with a focus on ergonomics, performance and modularity. . numba/llvmlite — A lightweight LLVM python binding for writing JIT compilers . libcpu/libcpu — “libcpu” is an open source library that emulates several CPU architectures . apple/ml-qrecc — Open-Domain Question Answering Goes Conversational via Question Rewriting . bbc/bbcrd-brirs — An impulse response dataset for dynamic data-based auralisation of advanced sound systems . sofacoustics/SOFAtoolbox — SOFA Toolbox (API for Matlab, Octave) . aligner 0.1.6 — Automatically corrects subtitle timings given a second correct subtitle, github . Cochleagram Representation of Sound . SpeechColab/GigaSpeech — Large, modern dataset for speech recognition . iver56/audiomentations — A Python library for audio data augmentation. Inspired by albumentations. Useful for machine learning. . SpeechBrain Tutorials . The Learning Rate Finder Technique: How Reliable Is It? . Faster than training from scratch — Fine-tuning the English GPT-2 in any language with Hugging Face and fastai v2 . Fastai with 🤗 Transformers . Unsupervised pretraining transfers well across languages . Podchraoltaí Gaeilge . A full statement of the trial and acquittal of Aaron Burr, esq . The Irish landed gentry when Cromwell came to Ireland . Litriú na Gaeilge . Jimín Ṁáire Ṫaiḋg . An foclóir beag . Jócleabhar beag bídeach na Gaeilge . Ceannóga agus Coinlíní . Fuaimeanna na Gaeilge . teddykoker/torchsort . Countering the claims about Australia’s Aboriginal number systems . Gryf : pismo dla spraw kaszubskich . AIdeaLab/wav2vec2_docker — pretraining wav2vec docker for sagemaker. . Compressing Wav2vec 2.0 . cpierse/wav2vec2-large-xlsr-53-irish . eval.py . ashubham/CPT — Compact prediction trees for fast sequence prediction using Machine Learning . Residual Energy-Based Models for End-to-End Speech Recognition . julien-c/DPRNNTasNet-ks16_WHAM_sepclean . Fine-tuning a model on a translation task . Leveraging Pre-trained Language Model Checkpoints for Encoder-Decoder Models . Fine-tune a pretrained model . OCR with Keras, TensorFlow, and Deep Learning . snapthat/TF-T5-text-to-text — This repository demonstrate training T5 transformers using tensorflow 2 . PiotrDabkowski/Js2Py — JavaScript to Python Translator &amp; JavaScript interpreter written in 100% pure Python . Wav2Vec2-T5 v2.ipynb . Core concepts in k2 . Efficiently Fusing Pretrained Acoustic and Linguistic Encoders for Low-resource Speech Recognition, code . Distilling Zero Shot Classification.ipynb . amzn/xfer — Transfer Learning library for Deep Neural Networks. . asteroid-team/asteroid — The PyTorch-based audio source separation toolkit for researchers . astanin/python-tabulate — Pretty-print tabular data in Python, a library and a command-line utility. Repository migrated from bitbucket.org/astanin/python-tabulate. . Trankit, nlp-uoregon/trankit — Trankit is a Light-Weight Transformer-based Python Toolkit for Multilingual Natural Language Processing . coqui-ai/STT — STT - The deep learning toolkit for Speech-to-Text. Training and deploying STT models has never been so easy. . Double Decoder Consistency . kan-bayashi/ParallelWaveGAN . NVIDIA/mellotron — Mellotron: a multispeaker voice synthesis model based on Tacotron 2 GST that can make a voice emote and sing without emotive or singing training data . MycroftAI/mimic2 — Text to Speech engine based on the Tacotron architecture, initially implemented by Keith Ito. . MycroftAI/lingua-franca — Mycroft’s multilingual text parsing and formatting library . MycroftAI/skill-date-time — Mycroft AI official Date and Time Skill, providing the current time, date and day of week for cities around the world. . Jaco-Assistant/Scribosermo Train fast Speech-to-Text networks in different languages . grammarly/ua-gec — UA-GEC: Grammatical Error Correction and Fluency Corpus for the Ukrainian Language . grammarly/gector — Official implementation of the papers “GECToR – Grammatical Error Correction: Tag, Not Rewrite” (BEA-20) and “Text Simplification by Tagging” (BEA-21) . Timers and Such: A Practical Benchmark for Spoken Language Understanding with Numbers . LT-LM: a novel non-autoregressive language model for single-shot lattice rescoring . Digital-Umuganda/Deepspeech-Kinyarwanda — The kinyarwanda model for deepspeech . End-to-End Speaker-Attributed ASR with Transformer . Differentiable Weighted Finite-State Transducers . facebookresearch/mmf — A modular framework for vision &amp; language multimodal research from Facebook AI Research (FAIR) . kaegi/alass — “Automatic Language-Agnostic Subtitle Synchronization” . pums974/srtsync — Automatic synchronizer of subtitles based on voice activity in the video . oseiskar/autosubsync — Automatically synchronize subtitles with audio using machine learning . tympanix/subsync — Synchronize your subtitles using machine learning . CCExtractor/Subtitle-Resync — A tool to automatically generate in-sync subtitles of different versions of the same base media (such as with edits) . sc0ty/subsync — Subtitle Speech Synchronizer . GEM Benchmark Tasks . Getting Started With Embeddings . This past week I spent some time learning about SentenceTransformers (https://t.co/5ZAV7lJq7u), and I&#39;m pretty blown away by what sentence embeddings can be used for.If you&#39;re curious to see what researchers have been getting up to with it, here&#39;s a 🧵 with some highlights: . &mdash; Nima Boscarino (@NimaBoscarino) June 10, 2022 Spectrum and Prosody Conversion for Cross-lingual Voice Conversion with CycleGAN . A Modern Self-Referential Weight Matrix That Learns to Modify Itself . High-Quality, Robust and Responsible Direct Speech-to-Speech Translation . Introducing CVSS: A Massively Multilingual Speech-to-Speech Translation Corpus . milvus-io/milvus — A cloud-native vector database, storage for next generation AI applications . Siri can’t speak Irish: Tackling the digital gaps for the Irish language . lucidrains/reformer-pytorch — Reformer, the efficient Transformer, in Pytorch . BBC reporter Phil McCann triggers ‘fill my can’ memes as he covers fuel shortage in UK . NodLabs/mlir-examples — a simple end to end example of taking a ML graph (TF2 / PyTorch) and running it on a device [cpu, gpu] . Machine Learning Simplified: A gentle introduction to supervised learning . XTREME-S benchmark examples . De vandrande djäknarne, De vandrande djäknarne / 3 . Beyond Graph Neural Networks with PyNeuraLogic . AMI Corpus Overview . TorchStudio/torchstudio — IDE for PyTorch and its ecosystem . TorchStudio . OFA: Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework, code . clam004/intro_continual_learning — This is a tutorial to connect the fundamental mathematics to a practical implementation addressing the continual learning problem of artificial intelligence . gustavo-beck/wavebender-gan . Accent-VITS:accent transfer for end-to-end TTS . Why Are Rich People So Mean? . Structured Log Linear Models for Noise Robust Speech Recognition . Let the Script Find Out the ML Model that Outperforms Yours . Neural music instrument cloning from very few samples . microsoft/Swin-Transformer — This is an official implementation for “Swin Transformer: Hierarchical Vision Transformer using Shifted Windows”. . facebookresearch/xcit — Official code Cross-Covariance Image Transformer (XCiT) . Patches Are All You Need?, locuslab/convmixer — Implementation of ConvMixer for “Patches Are All You Need?” . Direct multimodal few-shot learning of speech and images . yoav-lavi/melody — Melody is a language that compiles to regular expressions and aims to be more readable and maintainable . Boosting Wav2Vec2 with n-grams in 🤗 Transformers . En Nyckfull kvinna del 1 . Weakly Supervised Construction of ASR Systems with Massive Video Data . Data Augmentation library for text . Wav2vec could be more efficient, so we created our own pre-trained ASR Model for better Conversational AI. . SEW-D . Efficiently Fusing Pretrained Acoustic and Linguistic Encoders for Low-resource Speech Recognition . JAX Vs TensorFlow Vs PyTorch: A Comparative Analysis . FAST-RIR: FAST NEURAL DIFFUSE ROOM IMPULSE RESPONSE GENERATOR . google-deepmind/dm-haiku — JAX-based neural network library . Getting started with JAX . W2v-BERT: Combining Contrastive Learning and Masked Language Modeling for Self-Supervised Speech Pre-Training . SLAM: A Unified Encoder for Speech and Language Modeling via Speech-Text Joint Pre-Training . Joint Speech Recognition and Audio Captioning, code . Turning a Google Colab Notebook into a Web App . Training Acoustic Models . Forced Alignment . Common Mistakes in Hyper-Parameters Tuning . A Large-Scale Study on Regularization and Normalization in GANs . Psychophysical and behavioral peripheral and central auditory tests . shivammehta007/Neural-HMM . Data2vec: A General Framework for Self-supervised Learning in Speech, Vision and Language . One model for the learning of language . unfs3/unfs3 — UNFS3 is a user-space implementation of the NFSv3 server specification. . Sinkformers: Transformers with Doubly Stochastic Attention . descriptinc/lyrebird-wav2clip — Official implementation of the paper WAV2CLIP: LEARNING ROBUST AUDIO REPRESENTATIONS FROM CLIP . Understanding Q,K,V In Transformer . Billion-scale vector search with Vespa - part one . Scaling Vision with Sparse Mixture of Experts, google-research/vmoe . Improving Prosody Modelling with Cross-Utterance BERT Embeddings for End-to-end Speech Synthesis . Logainmneacha Mhagh Loirg agus Uachtar Thíre, Contae Ros Comáin: Anailís ar ainmneacha bhailte fearainn na seandúichí sin . Neural edit-tree lemmatization for spaCy . KristiyanVachev/Leaf-Question-Generation — Easy to use and understand multiple-choice question generation algorithm using T5 Transformers. . On visualizing phonetic data from repeated measures experiments with multiple random effects . Sohcahtoa: Sine, Cosine, Tangent . Áiseanna bunscoile ar líne . Strange and forgotten consoles . Lookup-Table Recurrent Language Models for Long Tail Speech Recognition . Explicit Alignment Objectives for Multilingual Bidirectional Encoders . UniversalDependencies/UD_Irish-IDT . bbc/peaks.js — JavaScript UI component for interacting with audio waveforms . bbc/waveform-data.js — Audio Waveform Data Manipulation API – resample, offset and segment waveform data in JavaScript. . frictionlessdata/frictionless-py — Data management framework for Python that provides functionality to describe, extract, validate, and transform tabular data . smacke/ffsubsync — Automagically synchronize subtitles with video. . bbc/morty-docs — Generate a static website from markdown files . BorisChumichev/everpolate — Numerical interpolation and extrapolation lib . 19 entities for 104 languages: A new era of NER with the DeepPavlov multilingual BERT . EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks . LEAF: A Learnable Frontend for Audio Classification . “Chain-linking” NLP tasks With Wav2Vec2 &amp; Transformers . guanlongzhao/kaldi-gop — Computes the Goodness of Pronunciation (GOP). Bases on Kaldi. . L2-ARCTIC . An Asynchronous WFST-Based Decoder For Automatic Speech Recognition . Speech and Language Processing . AdapterHub: A Framework for Adapting Transformers . Neighbours across the sea: A brief history of Anglo-Irish relations . make_lexicon_fst.py . Named Entity Recognition . NN-SVG — Publication-ready NN-architecture schematics . HarisIqbal88/PlotNeuralNet — Latex code for making neural networks diagrams . lutzroeder/netron — Visualizer for neural network, deep learning and machine learning models . pettarin/forced-alignment-tools — A collection of links and notes on forced alignment tools . chrisbaume/overtyper — Experiment in automatic insertion of timed transcript corrections using fuzzy phonetic matching . bbc/dialogger — Text-based media editing interface . chrisbaume/webaligner — A client-side forced aligner for speech . bbc/stt-align-node — node version of stt-align https://github.com/bbc/stt-align by Chris Baume - R&amp;D. . bbc/react-transcript-editor — A React component to make correcting automated transcriptions of audio and video easier and faster. By BBC News Labs. - Work in progress . bbc/vc2hqencode — Optimised VC-2 HQ Profile Encoder Library . bbc/vc2_conformance — Software tools for checking the conformance of SMPTE ST 2042-1 (VC-2) professional video codec implementations. . bbc/vc2-reference — A reference encoder and decoder for SMPTE ST 2042-1 “VC-2 Video Compression” . bbc/dash.js — A reference client implementation for the playback of MPEG DASH via Javascript and compliant browsers. . bbc/storyplayer — BBC Research &amp; Development’s Object Based Media Player . bbc/digital-paper-edit-api — Work in progress - BBC News Labs digital paper edit project - Express server API . mozilla/DSAlign — DeepSpeech based forced alignment tool . Trials and Tribulations: Using Keras on Colab and TPU . Hugging Face on PyTorch / XLA TPUs: Faster and cheaper training . Some Kaldi Notes . TensorSpeech/TensorFlowASR . Open Science in phonetics and phonology . hf_wav2vec2_deepspeed.ipynb . Part 2 - Extracting Audio Features . Yoda Speech Corpus . youtube8m . CNNDigitReco-speakerindependent . Spanish Automatic Speech Recognition pytorch . Mr Donald Trump Speeches . Joe Biden 2020 DNC Speech . Grid Search to find best tuning parameters . asahi417/tner — Language model fine-tuning on NER with an easy interface and cross-domain evaluation. “T-NER: An All-Round Python Library for Transformer-based Named Entity Recognition, EACL 2021” . Train BERT from scratch . Classification on FSDD using Spectograms . JaidedAI/EasyOCR — Ready-to-use OCR with 80+ supported languages and all popular writing scripts including Latin, Chinese, Arabic, Devanagari, Cyrillic and etc. . Polish Christmas Carols . An Saol ó Dheas . Nuacht1.com . FÍSEÁN: ‘Níl na comharthaí iontach maith’ – amhras léirithe ag stiúrthóir an Oireachtais faoi fhéile na bliana seo . make_kn_lm.py . A Speech-To-Text Practitioner’s Criticisms of Industry and Academia . eric-mitchell/direct-preference-optimization — Reference implementation for DPO (Direct Preference Optimization) . tiangolo/fastapi — FastAPI framework, high performance, easy to learn, fast to code, ready for production . explosion/wasabi — A lightweight console printing and formatting toolkit . lucidrains/DALLE-pytorch — Implementation / replication of DALL-E, OpenAI’s Text to Image Transformer, in Pytorch . facebookresearch/pytorchvideo — A deep learning library for video understanding research. . microg/GmsCore — Free implementation of Play Services . mortennobel/cpp-cheatsheet — Modern C++ Cheatsheet . micknoise/Maximilian — C++ Audio and Music DSP Library . taywee/args — A simple header-only C++ argument parser library. Supposed to be flexible and powerful, and attempts to be compatible with the functionality of the Python standard argparse library (though not necessarily the API). . antirez/linenoise — A small self-contained alternative to readline and libedit . p-ranav/tabulate — Table Maker for Modern C++ . photonstorm/phaser — Phaser is a fun, free and fast 2D game framework for making HTML5 games for desktop and mobile web browsers, supporting Canvas and WebGL rendering. . Suyash458/WiktionaryParser — A Python Wiktionary Parser . llvmpy/llvmpy . ucb-bar/riscv-sodor — educational microarchitectures for risc-v isa . boriel/zxbasic — The Sinclair ZX Spectrum BASIC compiler! . erikrose/blessings — A thin, practical wrapper around terminal capabilities in Python . tartley/colorama — Simple cross-platform colored terminal text in Python . jzhang38/TinyLlama — The TinyLlama project is an open endeavor to pretrain a 1.1B Llama model on 3 trillion tokens. . PrefectHQ/marvin — Build AI interfaces that spark joy . alibaba/animate-anything — Fine-Grained Open Domain Image Animation with Motion Guidance . Kanaries/pygwalker — PyGWalker: Turn your pandas dataframe into an interactive UI for visual analysis . commaai/openpilot — openpilot is an open source driver assistance system. openpilot performs the functions of Automated Lane Centering and Adaptive Cruise Control for 250+ supported car makes and models. . dvmazur/mixtral-offloading — Run Mixtral-8x7B models in Colab or consumer desktops . Textualize/rich — Rich is a Python library for rich text and beautiful formatting in the terminal. . DLYuanGod/TinyGPT-V — TinyGPT-V: Efficient Multimodal Large Language Model via Small Backbones . PaddlePaddle/PaddleGAN — PaddlePaddle GAN library, including lots of interesting applications like First-Order motion transfer, Wav2Lip, picture repair, image editing, photo2cartoon, image style transfer, GPEN, and so on. . koaning/drawdata — Draw datasets from within Jupyter. . jindrapetrik/jpexs-decompiler — JPEXS Free Flash Decompiler . SerenityOS/serenity . topjohnwu/Magisk — The Magic Mask for Android . gzc/CLRS — olutions to Introduction to Algorithms . libcpr/cpr — C++ Requests: Curl for People, a spiritual port of Python Requests. . fffaraz/awesome-cpp — A curated list of awesome C++ (or C) frameworks, libraries, resources, and shiny things. Inspired by awesome-… stuff. . martinmoene/ring-span-lite — ring-span lite - A C++yy-like ring_span type for C++98, C++11 and later in a single-file header-only library . davisking/dlib . autodiff/autodiff — automatic differentiation made easier for C++ . linebender/druid — A data-first Rust-native UI design toolkit. . linebender/runebender — A font editor written in Rust. . pemistahl/grex — A command-line tool and Rust library with Python bindings for generating regular expressions from user-provided test cases . emilk/egui — egui: an easy-to-use immediate mode GUI in Rust that runs on both web and native . actix/actix-web — Actix Web is a powerful, pragmatic, and extremely fast web framework for Rust. . RDFLib/rdflib . chipsalliance/chisel — Chisel: A Modern Hardware Design Language . ucb-bar/dsptools — A Library of Chisel3 Tools for Digital Signal Processing . When Being Unseen from mBERT is just the Beginning: Handling New Languages With Multilingual Language Models, code . Streamlit vs. Dash vs. Shiny vs. Voila vs. Flask vs. Jupyter . First Align, then Predict: Understanding the Cross-Lingual Ability of Multilingual BERT . Mallard BASIC: Introduction and Reference . Joyce Computer Club Public Domain - BASIC . Mallard BASIC to CPC BASIC . m-wiesner/nnet_pytorch — Kaldi style neural network training in pytorch for use in place of nnet3 in Kaldi. . PCWsBAS.WS4 . 32-bit Apps in a 64-bit Docker Container . marytts/gradle-marytts-voicebuilding-plugin . pyparsing/pyparsing — Python library for creating PEG parsers . IS2AI/Kazakh_TTS — An expanded version of the previously released Kazakh text-to-speech (KazakhTTS) synthesis corpus. In KazakhTTS2, the overall size has increased from 93 hours to 271 hours, the number of speakers has risen from two to five (three females and two males), and the topic coverage has been diversified. . coady/lupyne — Pythonic search engine based on PyLucene. . apache/pdfbox . Nine Polish books you must read before you die . pytorch/audio . ml-tooling/opyrator — Turns your machine learning code into microservices with web API, interactive GUI, and more. . tomstitt/lupyter — A Lua Kernel for Jupyter built on ipykernel. . Automated Guitar Transcription with Deep Learning . GuitarsAI/ADSP_Tutorials — Advanced Signal Processing Notebooks and Tutorials . GuitarML/GuitarLSTM — Deep learning models for guitar amp/pedal emulation using LSTM with Keras. . GuitarML/SmartAmpPro — Guitar plugin using neural networks to capture real amps and pedals . voila-dashboards/voila — Voilà turns Jupyter notebooks into standalone web applications . jupyter-xeus/xeus-cling — Jupyter kernel for the C++ programming language . PyO3/pyo3 — Rust bindings for the Python interpreter . Interactive Rust in a REPL and Jupyter Notebook with EVCXR . AK391/spleeter — Deezer source separation library including pretrained models. . CoderLine/alphaTab — alphaTab is a cross platform music notation and guitar tablature rendering library. . dpilger26/NumCpp — C++ implementation of the Python Numpy library . faridrashidi/kaggle-solutions — Collection of Kaggle Solutions and Ideas . Introduction to Sound Event Detection . Radio Kaszëbë . Podòdzél jistników na deklinacje. I deklinacjô . Najô Ùczba . Open-Speech-EkStep/vakyansh-wav2vec2-experimentation . Machine Learning - Google for Developers . 10 Jupyter Notebook Extensions Making My Lyfe Easier . org-arl/jupyter-ieee-paper — Jupyter notebook to generate fully formatted IEEE papers . jupyterlab/jupyterlab-latex — JupyterLab extension for live editing of LaTeX documents . Fission, fission/fission — Fast and Simple Serverless Functions for Kubernetes . Typography.js . jik876/hifi-gan — HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis . andabi/deep-voice-conversion — Deep neural networks for voice conversion (voice style transfer) in Tensorflow . chriskiehl/Gooey — Turn (almost) any Python command line program into a full GUI application with one line . googlecreativelab/quickdraw-dataset — Documentation on how to access and use the Quick, Draw! Dataset. . ARBML/klaam — Arabic speech recognition, classification and text-to-speech. . Semi-supervised Learning and Frame Rate . Using nbconvert as a library . amperser/proselint — A linter for prose. . openstack/swift — OpenStack Storage (Swift). Mirror of code maintained at opendev.org. . Setup docker for Kaggle . Semi-Supervised Training of Deep Neural Networks for Speech Recognition . Zero-Resource Neural Machine Translation with Monolingual Pivot Data . google/python-fire — Python Fire is a library for automatically generating command line interfaces (CLIs) from absolutely any Python object. . ceph/ceph — Ceph is a distributed object, block, and file storage platform . rook/rook — Storage Orchestration for Kubernetes . TigerBot: An Open Multilingual Multitask LLM . RLIF: Interactive Imitation Learning as Reinforcement Learning . Training tiny specialized language models . TinyStories: How Small Can Language Models Be and Still Speak Coherent English? . lucidrains/MEGABYTE-pytorch — Implementation of MEGABYTE: Predicting Million-byte Sequences with Multiscale Transformers, in Pytorch . 1SPU: 1-step Speech Processing Unit . Self-Supervised Learning from Images with a Joint-Embedding Predictive Architecture, code . sscardapane/reprodl2021 — Host repository for the “Reproducible Deep Learning” PhD course . Aligning Ground Truth Text with OCR Degraded Text . Are you GPU poor? . openaudible/openaudible — Audiobook Manager for Audible Users . A complete guide to transfer learning from English to other Languages using Sentence Embeddings BERT Models . Ki6an/fastT5 — boost inference speed of T5 models by 5x &amp; reduce the model size by 3x. . FieldDB/Praat-Scripts . FieldDB/AndroidLanguageLessons . Deep Implicit Attention: A Mean-Field Theory Perspective on Attention Mechanisms . Bootstrap your own latent: A new approach to self-supervised Learning . SBert quickstart . jmccrae/irish_saffron — Code related to adapting Saffron to Irish . A new open data set for multilingual speech research, OpenSLR . tugstugi/dl-colab-notebooks — Try out deep learning models online on Google Colab . FELIX: Flexible Text Editing Through Tagging and Insertion, code . openmainframeproject/cobol-programming-course — Training materials and labs for a “Getting Started” level course on COBOL . IBM/cobol-is-fun . Martinfx/Cobol . RiveScript . mohaEs/Train-Predict-Landmarks-by-dlib . ELITR/automin-2021 . Involution: Inverting the Inherence of Convolution for Visual Recognition, code, involution_pytorch . open-mmlab/mmocr — OpenMMLab Text Detection, Recognition and Understanding Toolbox . Nuacht Mhall . jakevdp/PythonDataScienceHandbook — Python Data Science Handbook: full text in Jupyter Notebooks . An ultrasound study of Connemara Irish palatalization and velarization . An Ultrasound Investigation of Irish Palatalization . wmcnally/evopose2d — EvoPose2D is a two-stage human pose estimation model that was designed using neuroevolution. It achieves state-of-the-art accuracy on COCO. . cdpierse/transformers-interpret — Model explainability that works seamlessly with 🤗 transformers. Explain your transformers model in just 2 lines of code. . A dictionary of the Manks language . Adapting BERT for Word Sense Disambiguation with Gloss Selection Objective and Example Sentences, code . ikekonglp/PAD — The PAD parser produces phrases-after-dependencies. Give it the output of a dependency parser and it will produce the optimal constrained phrase-structure parse. . Prompting the Hidden Talent of Web-Scale Speech Models for Zero-Shot Task Generalization . Neural HMMs are all you need (for high-quality attention-free TTS) . Measuring Massive Multitask Language Understanding, code . qdrant/qdrant — Qdrant - High-performance, massive-scale Vector Database for the next generation of AI. Also available in the cloud https://cloud.qdrant.io/ . Learning rule-based morpho-phonology, code . AakashKumarNain/annotated_research_papers . TextOCR . argilla-io/argilla — Argilla: the open-source feedback platform for LLMs . Beyond Offline Mapping: Learning Cross Lingual Word Embeddings through Context Anchoring . Feasta - Bealtaine 2013 . CCExtractor/ccextractor — CCExtractor is a tool used to produce subtitles for TV recordings from almost anywhere in the world. We intend to keep up with all sources and formats. . JabRef/jabref — Graphical Java application for managing BibTeX and biblatex (.bib) databases . rizinorg/rizin — UNIX-like reverse engineering framework and command-line toolset. . Synfig, code — Synfig Studio is a free and open-source 2D animation software, designed as powerful industrial-strength solution for creating film-quality animation using a vector and bitmap artwork . hamelsmu/Seq2Seq_Tutorial — Code For Medium Article “How To Create Data Products That Are Magical Using Sequence-to-Sequence Models” . hamelsmu/Docker_Tutorial — Code and helper scripts for article on Medium “How Docker Can Help You Become A More Effective Data Scientist” . How to write academic papers in Markdown . Writing academic papers in plain text with Markdown and Jupyter notebook . RasaHQ/paraphraser — Tool to generate paraphrases of sentences in many languages. . Diffusion Models Beat GANs on Image Synthesis . JoFrhwld/FAVE — A repository for maintaing the fave-align and fave-extract toolkits . Klatt . creating a vowel diagram . Vowels . vowel – Draw vowel charts for phonetic research . The vowel space . Cad a dhéanfaidh mé le mo fhleiscín-se? Comhairle ghramadaí… . From Notebook to Kubeflow Pipelines with MiniKF and Kale . pachyderm/pachyderm — Data-Centric Pipelines and Data Versioning . GeoPandas, code . KELM: Integrating Knowledge Graphs with Language Model Pre-training Corpora . sberdevices/golos . Neargye/magic_enum — Static reflection for enums (to string, from string, iteration) for modern C++, work with any enum type without any macro or boilerplate code . FNet: Mixing Tokens with Fourier Transforms, tensorflow, pytorch . Distributed Training of a Bengali ALBERT model . jgraph/drawio — draw.io is a JavaScript, client-side editor for general diagramming. . Barlow-Twins-TF . evolus/pencil — The Pencil Project’s unique mission is to build a free and opensource tool for making diagrams and GUI prototyping that everyone can use. . linkedin/greykite — A flexible, intuitive and fast forecasting library . staltz/matrixmultiplication.xyz — An interactive matrix multiplication calculator for educational purposes . A Journey Through Fastbook . trekhleb/homemade-machine-learning — Python examples of popular machine learning algorithms with interactive Jupyter demos and math being explained . launchbadge/sqlx — The Rust SQL Toolkit. An async, pure Rust SQL crate featuring compile-time checked queries without a DSL. Supports PostgreSQL, MySQL, SQLite, and MSSQL. . gfx-rs/wgpu — Cross-platform, safe, pure-rust graphics api. . seanmonstar/warp — A super-easy, composable, web server framework for warp speeds. . Nukesor/pueue — Manage your shell commands. . pytorch/captum — Model interpretability and understanding for PyTorch . Emotion Recognition in Greek Speech Using Wav2Vec 2.0 . synesthesiam/mycroft-precise-trainer — Text to speech wake word training scripts for Mycroft Precise . rhasspy/rhasspy-asr — Shared Python classes for speech to text . synesthesiam/voice2json — Command-line tools for speech and intent recognition on Linux . LARP: Language-Agent Role Play for Open-World Games . Continvvm/continuum — A clean and simple data loading library for Continual Learning . CC-100: Monolingual Datasets from Web Crawl Data . deepset-ai/haystack — LLM orchestration framework to build customizable, production-ready LLM applications. Connect components (models, vector DBs, file converters) to pipelines or agents that can interact with your data. With advanced retrieval methods, it’s best suited for building RAG, question answering, semantic search or conversational agent chatbots . janusgraph/janusgraph — JanusGraph: an open-source, distributed graph database . Streamlit Tutorial: A Beginner’s Guide to Building Machine Learning-Based Web Applications in Python . textext/textext — Re-editable LaTeX/ typst graphics for Inkscape . Searching, fast and slow, through product catalogs . How to Easily Draw Neural Network Architecture Diagrams . mlflow/mlflow — Open source platform for the machine learning lifecycle . Why use Docker containers for machine learning development? . Nine Tools I Wish I Mastered before My PhD in Machine Learning . Entering raw mode . Common Rust Lifetime Misconceptions . rhasspy/gruut — A tokenizer, text cleaner, and phonemizer for many human languages. . rhasspy/ipa2kaldi — Tool for creating Kaldi nnet3 recipes using the International Phonetic Alphabet (IPA) . rhasspy/wiktionary2dict — Tool for extracting IPA pronunciations from Wiktionary XML dump . Babel, code . How to use SVGs in React . nodejs/nan — Native Abstractions for Node.js . Hubert: How Much Can a Bad Teacher Benefit ASR Pre-Training? . hubert simple_kmeans . mamedev . The Gumbel trick . Modifying Custom Matmul CUDA Kernels . DeMoriarty/TorchPQ — Approximate nearest neighbor search with product quantization on GPU in pytorch and cuda . Alexander-H-Liu/NPC — Non-Autoregressive Predictive Coding . s3prl/s3prl . facebookresearch/CPC_audio — An implementation of the Contrast Predictive Coding (CPC) method to train audio features in an unsupervised fashion. . as-ideas/TransformerTTS — Transformer TTS: Implementation of a non-autoregressive Transformer based neural network for text to speech. . 8-Core Training on Colab TPUs . DistilBertTPUTraining.ipynb . T5 on TPU . dfm/extending-jax — Extending JAX with custom C++ and CUDA code . mmi_mbr_graph.py . SE and ASR joint training #3226 . . google/REAPER . voicesauce/opensauce-python — Voice analysis software (Python port of VoiceSauce) . . rish-16/aft-pytorch — Unofficial PyTorch implementation of Attention Free Transformer (AFT) layers by Apple Inc. . yoshitomo-matsubara/torchdistill — A coding-free framework built on PyTorch for reproducible deep learning studies. 🏆20 knowledge distillation methods presented at CVPR, ICLR, ECCV, NeurIPS, ICCV, etc are implemented so far. 🎁 Trained models, training logs and configurations are available for ensuring the reproducibiliy and benchmark. . Declassified Cold War code-breaking manual has lessons for solving ‘impossible’ puzzles . epfml/sent2vec . epfml/Bi-sent2vec — Robust Cross-lingual Embeddings from Parallel Sentences . MERLOT: Multimodal Neural Script Knowledge Models . Inference with Wav2vec 2.0 . AnthonyCalandra/modern-cpp-features — A cheatsheet of modern C++ language and library features. . MayaPosch/NymphCast — Audio and video casting system with support for custom applications. . How Fighter Jets Lock On (and How the Targets Know) . ‘Operation Legacy’: Britain’s Destruction and Concealment of Colonial Records Worldwide . gopherdata/gophernotes — The Go kernel for Jupyter notebooks and nteract. . Python and Go : Part II - Extending Python With Go . LANDrop, code — Drop any files to any devices on your LAN. . jpalardy/vim-slime — A vim plugin to give you some slime. (Emacs) . jlevy/the-art-of-command-line — Master the command line, in one page . EbookFoundation/free-programming-books . Neural Machine Translation Using Sequence to Sequence Model . Generative Spoken Language Modeling from Raw Audio . Bunfrasaí Ghaeilge Reachlann . . Standard Lexical Sets . Online Units . . Quechua Collection of Patricia Dreidemie . . mvcisback/lstar — Python implementation of lstar automata learning algorithm. . gbossert/pylstar — An implementation of the LSTAR Grammatical Inference Algorithm . Symbolic Automata . lorisdanto/symbolicautomata — Library for symbolic automata and symbolic visibly pushdown automata . awni/transducer — A Fast Sequence Transducer Implementation with PyTorch Bindings . Sequence Transduction with Recurrent Neural Networks . Sequence-to-sequence learning with Transducers . linear_crf.ipynb . tech-srl/RNN_to_PRS_CFG — Implementation of TACAS 2021 paper, “Extrapolating CFGs from RNNs” . . ByT5: Towards a token-free future with pre-trained byte-to-byte models, code . facebookresearch/AugLy — A data augmentations library for audio, image, text, and video. . PrithivirajDamodaran/Styleformer — A Neural Language Style Transfer framework to transfer natural language text smoothly between fine-grained language styles like formal/casual, active/passive, and many more. Created by Prithiviraj Damodaran. Open to pull requests and other forms of collaboration. . Contrastive Semi-supervised Learning for ASR . Contrastive Learning of General-Purpose Audio Representations, code . FRILL: On-Device Speech Representations using TensorFlow-Lite . parlance/ctcdecode — PyTorch CTC Decoder bindings . kensho-technologies/pyctcdecode — A fast and lightweight python-based CTC beam search decoder for speech recognition. . pariajm/awesome-disfluency-detection — A curated list of awesome disfluency detection publications along with the released code and bibliographical information . How to use the pre-trained Librispeech model in Kaldi . yandex-research/DeDLOC — Official code for “Distributed Deep Learning in Open Collaborations” (NeurIPS 2021) . Distributed Deep Learning in Open Collaborations . cross-language-cpp/djinni-generator — Command-line tool that generates gluecode from a djinni-IDL file . Calling Go Functions from Other Languages . Introduction To Golang For Python developers . Go by Example . jwieting/paraphrastic-representations-at-scale . python-trio/trio — Trio – a friendly Python library for async concurrency and I/O . Making Web Crawlers Using Scrapy for Python . scrapy/scrapy . google-research/deeplab2 — DeepLab2 is a TensorFlow library for deep labeling, aiming to provide a unified and state-of-the-art TensorFlow codebase for dense pixel labeling tasks. . hugapi/hug — Embrace the APIs of the future. Hug aims to make developing APIs as simple as possible, but no simpler. . Cutting Down on Prompts and Parameters: Simple Few-Shot Learning with Language Models . Statistics of diphones and triphones presence on the word boundaries in the Polish language. Applications to ASR . Using Syllables as Acoustic Units for Spontaneous Speech Recognition . akreal/diphones — PocketSphinx diphone alignment . Diphone-based speech recognition using neural networks . Speech recognition method and system using triphones, diphones, and phonemes . Face recognition with OpenCV, Python, and deep learning . Alignments in Kaldi . Improving Generalization of Transformer for Speech Recognition with Parallel Schedule Sampling and Relative Positional Embedding . Keras: Few-Shot learning with Reptile, Image similarity estimation using a Siamese Network with a triplet loss, Self-supervised contrastive learning with SimSiam, Automatic Speech Recognition with Transformer, Code examples . tuplex/tuplex — Tuplex is a parallel big data processing framework that runs data science pipelines written in Python at the speed of compiled code. Tuplex has similar Python APIs to Apache Spark or Dask, but rather than invoking the Python interpreter, Tuplex generates optimized LLVM bytecode for the given pipeline and input data set. . Semi-Supervised Speech Recognition via Graph-based Temporal Classification . How Kurt Cobain’s Favorite Novel Made Its Way Onto Nirvana’s Final Album . DIOM3DES . aws/graph-notebook — Library extending Jupyter notebooks to integrate with Apache TinkerPop, openCypher, and RDF SPARQL. . o3de/o3de — Open 3D Engine (O3DE) is an Apache 2.0-licensed multi-platform 3D engine that enables developers and content creators to build AAA games, cinema-quality 3D worlds, and high-fidelity simulations without any fees or commercial obligations. . GigaSpeech: An Evolving, Multi-domain ASR Corpus with 10,000 Hours of Transcribed Audio, SpeechColab/GigaSpeech — Large, modern dataset for speech recognition . LLM Training: RLHF and Its Alternatives . Sean-Chainnt na gCruach, Co. Dhún na nGall . Can Fully Connected Layers be Replaced by Convolutional Layers? . tencent-ailab/pika — a lightweight speech processing toolkit based on Pytorch and (Py)Kaldi . athena-team/athena — an open-source implementation of sequence-to-sequence based speech processing engine . Causal Language modeling . Unitnet Speech Demos: Unit Selection TTS strikes back . Automated Audio Captioning . chapter09_part01_image-segmentation.ipynb . Google DeepMind’s new AI tool helped create more than 700 new materials . UI researchers working to make speech-recognition technology more accessible . feast-dev/feast — Feature Store for Machine Learning . eugeneyan/applied-ml — Papers &amp; tech blogs by companies sharing their work on data science &amp; machine learning in production. . ucam-smt/ucam-smt — Cambridge SMT System . Welcome to the Zero to Mastery TensorFlow for Deep Learning Book . Neural Networks and Deep Learning . a2-4am/a2rchery — A multi-purpose tool for manipulating .a2r disk images . Neural Waveshaping Synthesis . microsoft/flow2dts — Flow declarations to TypeScript declarations transpiler . shivammehta25/Matcha-TTS — [ICASSP 2024] 🍵 Matcha-TTS: A fast TTS architecture with conditional flow matching . Using C++ and WSL in VS Code . microsoft/terminal — The new Windows Terminal and the original Windows console host, all in the same place! . microsoft/STL . uwol/proleap-vb6-parser — ProLeap ANTLR4-based parser for Visual Basic 6.0 . Barlow Twins: Self-Supervised Learning via Redundancy Reduction . Multistream TDNN and new Vosk model . Duanaire na Miḋe . tunib-ai/parallelformers — Parallelformers: An Efficient Model Parallelization Toolkit for Deployment . CPrAN — The plugin manager for Praat . ‘Our sound man had Kurt Cobain against the wall’: iconic Leeds gig pub ‘reopens’ . UniSpeech at scale: An Empirical Study of Pre-training Method on Large-Scale Speech Recognition Dataset . viatsko/awesome-vscode . Deep Learning over the Internet: Training Language Models Collaboratively . liuliu/ccv — C-based/Cached/Core Computer Vision Library, A Modern Computer Vision Library . Official Secrets Act reform could target journalists exposing state failings in Troubles’ killings . SUPERB: Speech processing Universal PERformance Benchmark . CS224S, Assignment 3: Deep Learning for End-to-End Speech Recognition . Scary Phonetics? Learning Cardinal Vowels, Part 1 . PhonEd: Phonetics Education . How to combine multiple criterions to a loss function? - PyTorch Forums . An Adapter Based Pre-Training for Efficient and Scalable Self-Supervised Speech Representation Learning . Biblia Tysiąclecia . yl4579/StarGANv2-VC — StarGANv2-VC: A Diverse, Unsupervised, Non-parallel Framework for Natural-Sounding Voice Conversion . Active learning in speech recognition . facebookresearch/fairo — A modular embodied agent architecture and platform for building embodied agents . apache/tvm — Open deep learning compiler stack for cpu, gpu and specialized accelerators . hora-search/hora — efficient approximate nearest neighbor search algorithm collections library written in Rust . An Introduction to Weighted Automata in Machine Learning . facebookresearch/SlowFast — PySlowFast: video understanding codebase from FAIR for reproducing state-of-the-art video models. . sarulab-speech/jtubespeech — JTubeSpeech: Corpus of Japanese speech collected from YouTube . anishathalye/neural-hash-collider — Preimage attack against NeuralHash 💣 . AsuharietYgvar/AppleNeuralHash2ONNX — Convert Apple NeuralHash model for CSAM Detection to ONNX. . KhaosT/nhcalc — Compute NeuralHash for the given image . The Formula For An Episode Of Murder, She Wrote . artyom-beilis/dlprimitives — Deep Learning Primitives and Mini-Framework for OpenCL . labmlai/annotated_deep_learning_paper_implementations . Enhancing audio quality for expressive Neural Text-to-Speech . One TTS Alignment to Rule Them All . turtle — Turtle graphics . respeecher/librispeech-cutter — Scripts for generating librispeech cuts from the original mp3 archive without 16kHz restrictions . stanford-crfm/mistral — Mistral: A strong, northwesterly wind: Framework for transparent and accessible large-scale language model training, built with Hugging Face 🤗 Transformers. . Language model training examples . A flexible, open-source platform for democratised access to digital resources . Tencent/TNN — deep learning inference framework for mobile、desktop and server. . Zero Redundancy Optimizer . rawpython/remi — Python REMote Interface library. Platform independent. In about 100 Kbytes, perfect for your diet. . microsoft/Focal-Transformer — [NeurIPS 2021 Spotlight] Official code for “Focal Self-attention for Local-Global Interactions in Vision Transformers” . microsoft/Swin-Transformer — This is an official implementation for “Swin Transformer: Hierarchical Vision Transformer using Shifted Windows”. . Cartlann na gCanúintí . ahrm/sioyek — Sioyek is a PDF viewer with a focus on textbooks and research papers . How lies about Irish ‘barbarism’ in 1641 paved way for Cromwell’s atrocities . microsoft/UniSpeech — UniSpeech - Large Scale Self-Supervised Learning for Speech . UniSpeech: Unified Speech Representation Learning with Labeled and Unlabeled Data . Generative Spoken Language Modeling from Raw Audio . NVIDIA/radtts — Provides training, inference and voice conversion recipes for RADTTS and RADTTS++: Flow-based TTS models with Robust Alignment Learning, Diverse Synthesis, and Generative Modeling and Fine-Grained Control over of Low Dimensional (F0 and Energy) Speech Attributes. . AI Choreographer. Music Conditioned 3D Dance Generation with AIST++, paper, dataset, api, model . BigSSL: Exploring the Frontier of Large-Scale Semi-Supervised Learning for Automatic Speech Recognition . Appen/UHV-OTS-Speech — A data annotation pipeline to generate high-quality, large-scale speech datasets with machine pre-labeling and fully manual auditing. . EgorLakomkin/KTSpeechCrawler — Automatically constructing corpus for automatic speech recognition from YouTube videos . gong-io/gecko — Gecko - A Tool for Effective Annotation of Human Conversations . A Recipe For Arbitrary Text Style Transfer with Large Language Models . DOLG: Single-Stage Image Retrieval with Deep Orthogonal Fusion of Local and Global Features . All Top Python Libraries for Data Science Explained . I trained Noam Chomsky TTS . FedJAX: Federated Learning Simulation with JAX . Appen/UHV-OTS-Speech — A data annotation pipeline to generate high-quality, large-scale speech datasets with machine pre-labeling and fully manual auditing. . striveiccv2021/STRIVE-ICCV2021/ — STRIVE: Scene Text Replacement In Videos . doxas/twigl — twigl.app is an online editor for One tweet shader, with gif generator and sound shader, and broadcast live coding. . giannisdaras/multilingual_robustness — [NeurIPS 2022] Multitasking Models are Robust to Structural Failure: A Neural Model for Bilingual Cognitive Reserve . The Annotated Transformer . DistilHuBERT: Speech Representation Learning by Layer-wise Distillation of Hidden-unit BERT . s3prl/LibriMix — An open source dataset for source separation . awslabs/speech-representations — Code for DeCoAR (ICASSP 2020) and BERTphone (Odyssey 2020) . BERTphone: Phonetically-aware Encoder Representations for Utterance-level Speaker and Language Recognition . FlowVocoder: A small Footprint Neural Vocoder based Normalizing flow for Speech Synthesis . The Turing Way . RLIF: Interactive Imitation Learning as Reinforcement Learning, paper, code . snorkel-team/snorkel — A system for quickly generating training data with weak supervision . Visualizing and Understanding Convolutional Networks . kedro-org/kedro — Kedro is a toolbox for production-ready data science. It uses software engineering best practices to help you create data engineering and data science pipelines that are reproducible, maintainable, and modular. . How to Train Bert For Q&amp;A in Any Language . Unsupervised Speech Segmentation and Variable Rate Representation Learning using Segmental Contrastive Predictive Coding . Gentle Dive into Math Behind Convolutional Neural Networks . t-ubukata/cudnnxx — cuDNN C++ wrapper. . To RAII or Not to RAII? . Smart developers use smart pointers (1/7) – Smart pointers basics . CTC Variations Through New WFST Topologies . Machine Learning Formulas Explained! 👨‍🏫This is the formula for the Binary Cross Entropy Loss. This loss function is commonly used for binary classification problems.It may look super confusing, but I promise you that it is actually quite simple!Let&#39;s go step by step 👇 pic.twitter.com/LcQofbUJnl . &mdash; haltakov.eth 🧱🔨 (@haltakov) October 13, 2021 BaguaSys/bagua — Bagua Speeds up PyTorch . visenger/awesome-mlops — A curated list of references for MLOps . Towards Robust Waveform-Based Acoustic Models . A Variational Bayesian Approach to Learning Latent Variables for Acoustic Knowledge Transfer . Simple and Effective Zero-shot Cross-lingual Phoneme Recognition . NormFormer: Improved Transformer Pretraining with Extra Normalization . WenetSpeech: A 10000+ Hours Multi-domain Mandarin Corpus for Speech Recognition . Have best of both worlds: two-pass hybrid and E2E cascading framework for speech recognition . Fine-tuning for Audio Classification with 🤗 Transformers . Control Strategies for Physically Simulated Characters Performing Two-player Competitive Sports . 47: Neural Body . Phrase Retrieval and Beyond . Hierarchical Skills for Efficient Exploration, code, paper . facebookresearch/ppuda — Code for Parameter Prediction for Unseen Deep Architectures (NeurIPS 2021) . hankcs/HanLP — Natural Language Processing for the next decade. Tokenization, Part-of-Speech Tagging, Named Entity Recognition, Syntactic &amp; Semantic Dependency Parsing, Document Classification . BinderHub, code . jupyterhub/repo2docker . How to write a DSL (in Python with Lark) . rpgleparser/rpgleparser — ANTLR parser for RPGLE . smeup/jariko — a JAva virtual machine Rpg Interpreter written in KOtlin . sallbach/arpgtool — IBM i RPG developer tools (AS/400 iSeries) . worksofliam/5250ttt — Tic-Tac-Toe for 5250 (2 player) . lppedd/RPG — IBM RPG projects . martinezga/ibm-rpg-programs — IBM RPG programs exercises. . How to write a transpiler, code . Strumenta/FormatsDSL — A DSL to describe formats and generate loaders . CLIPScore: A Reference-free Evaluation Metric for Image Captioning, code . This Word Does Not Exist, turtlesoupy/this-word-does-not-exist . Aim 3.0.0 — The foundations for open-source &amp; open-metadata ML platform . Large Language Models: A New Moore’s Law? . babelfish-for-postgresql/babelfish_extensions — Babelfish for PostgreSQL provides the capability for PostgreSQL to work with applications written for Microsoft SQL Server. . When Attention Meets Fast Recurrence: Training Language Models with Reduced Compute . uclnlp/torch-imle — Implicit MLE: Backpropagating Through Discrete Exponential Family Distributions . Stochastic Attention Head Removal: A simple and effective method for improving Transformer Based ASR Models . Hierarchical Transformers Are More Efficient Language Models . Language Modelling via Learning to Rank . Teaching robots to perceive, understand, and interact through touch, tacto, PyTouch . Speculative execution for LLMs is an excellent inference-time optimization.It hinges on the following unintuitive observation: forwarding an LLM on a single input token takes about as much time as forwarding an LLM on K input tokens in a batch (for larger K than you might… https://t.co/FiwTwqsfho . &mdash; Andrej Karpathy (@karpathy) August 31, 2023 jzhang38/TinyLlama — The TinyLlama project is an open endeavor to pretrain a 1.1B Llama model on 3 trillion tokens. . TinyLlama/TinyLlama-1.1B-Chat-v0.4 . TS-SEP: Joint Diarization and Separation Conditioned on Estimated Speaker Embeddings . w2v-SELD: A Sound Event Localization and Detection Framework for Self-Supervised Spatial Audio Pre-Training, code . Recent Advances in End-to-End Automatic Speech Recognition . bhky/opennsfw2 — Keras implementation of the Yahoo Open-NSFW model . The Rise of Self-Supervised Learning . TF_JAX_Tutorials - Part 9 (Autodiff in JAX) . Irisleabhar na Gaedhilge . Conformer-based Hybrid ASR System for Switchboard Dataset . Hacktoberfest 21’ - Unlocking 40 open-source audio datasets for ML . Full scan of a booklet on Leinster Irish (32 pages): “Dialect in East and Mid-Leinster”, Donn Piatt, 1933. . facebookresearch/demucs — Code for the paper Hybrid Spectrogram and Waveform Source Separation . Scaling ASR Improves Zero and Few Shot Learning . SpeechT5: Unified-Modal Encoder-Decoder Pre-Training for Spoken Language Processing . UniSpeech: Unified Speech Representation Learning with Labeled and Unlabeled Data . InfoXLM . CZWin32768/XLM-Align — Improving Pretrained Cross-Lingual Language Models via Self-Labeled Word Alignment . LiT: Zero-Shot Transfer with Locked-image text Tuning . Wormhole (1994 Session part 2) . XLS-R: Self-supervised Cross-lingual Speech Representation Learning at Scale . Joint Unsupervised and Supervised Training for Multilingual ASR . Cousin chart . Towards Measuring Fairness in Speech Recognition: Casual Conversations Dataset Transcriptions . British and American English Pronunciation Differences . Studying the History of English . The sounds of English . LucidDreamer: Domain-free Generation of 3D Gaussian Splatting Scenes . Directly Fine-Tuning Diffusion Models on Differentiable Rewards . Introducing IDEFICS: An Open Reproduction of State-of-the-Art Visual Language Model . thu-spmi/CAT — A CRF-based ASR Toolkit . CLARIN: Spoken Corpora . Historic Language Models . Mask-Predict: Parallel Decoding of Conditional Masked Language Models . Span Pointer Networks for Non-Autoregressive Task-Oriented Semantic Parsing . Non-Autoregressive Semantic Parsing for Compositional Task-Oriented Dialog, code . Sources for Connemara Irish . Performance-Efficiency Trade-offs in Unsupervised Pre-training for Speech Recognition, asappresearch/sew . Towards Learning Universal Audio Representations . Transformer-S2A: Robust and Efficient Speech-to-Animation . Multimodal and Multilingual Embeddings for Large-Scale Speech Mining . Hash Layers For Large Sparse Models . FST: the FAIR Speech Translation System for the IWSLT21 Multilingual Shared Task, code . g2p_encode.py, fairseq_simul_st_agent.py . facebook/wmt21-dense-24-wide-x-en — WMT 21 X-En is a 4.7B multilingual encoder-decoder (seq-to-seq) model trained for one-to-many multilingual translation. It was introduced in this paper and first released in this repository. . facebook/wav2vec2-large-robust-ft-swbd-300h . facebook/s2t-small-mustc-en-nl-st . facebook/wav2vec2-lv-60-espeak-cv-ft . Simultaneous Speech Translation (SimulST) on MuST-C . MuST-C: a Multilingual Speech Translation Corpus . Simplified Grammar of the Hungarian Language . A Green Approach for an Irish App (Refactor, reuse and keeping it real) . HuBERT: How to Apply BERT to Speech, Visually Explained . Automatic Speech Recognition for Supporting Endangered Language Documentation . “Attention is all you need” implementation from scratch in PyTorch. A Twitter thread . googleforgames/open-match-docs . LUKE: Deep Contextualized Entity Representations with Entity-aware Self-attention . CANINE: Pre-training an Efficient Tokenization-Free Encoder for Language Representation . mlcommons/peoples-speech — The People’s Speech Dataset . “Demokratifabriken” även som ljudbok? . srush/GPU-Puzzles — Solve puzzles. Learn CUDA. . Conformer: Convolution-augmented Transformer for Speech Recognition . i&#39;ll never get over how the cochlea is an analog fourier transform organ pic.twitter.com/VSlu0oqQXH . &mdash; murat 🍥 (@mayfer) January 3, 2024 Room impulse response reconstruction with physics-informed deep learning . GPT using Numpy! 🔥Here is Generative Pretrained Transformer(GPT) implemented from scratch using Numpy in just 60 lines of code: pic.twitter.com/80dTaDkePe . &mdash; Clarifai (@clarifai) January 2, 2024 DocLLM: A layout-aware generative language model for multimodal document understanding . godotengine/godot — Godot Engine – Multi-platform 2D and 3D game engine . The 3 Deep Learning Frameworks For End-to-End Speech Recognition That Power Your Devices . Perceiver IO: a scalable, fully-attentional model that works on any modality . Introduction to Facebook AI Similarity Search (Faiss), Facebook AI and the Index Factory . RichiH/vcsh — vcsh - Version Control System for $HOME - multiple Git repositories in $HOME . Few-shot Learning with Multilingual Language Models . UniSpeech: Unified Speech Representation Learning with Labeled and Unlabeled Data . Multi-turn RNN-T for streaming recognition of multi-party speech . 1ytic/warp-rna — Recurrent Neural Aligner . theblackcat102/edgedict — Working online speech recognition based on RNN Transducer. ( Trained model release available in release ) . 1ytic/warp-rnnt — CUDA-Warp RNN-Transducer . awni/automata_ml — An Introduction to Weighted Automata in Machine Learning . awni/speech — A PyTorch Implementation of End-to-End Models for Speech-to-Text . sooftware/kospeech — Open-Source Toolkit for End-to-End Korean Automatic Speech Recognition leveraging PyTorch and Hydra. . sooftware/RNN-Transducer — PyTorch implementation of RNN-Transducer(RNN-T). . EdinburghNLP/nematus — Open-Source Neural Machine Translation in Tensorflow . bbc/rd-apmm-python-lib-mediatimestamp — A simple timestamp implementation used by various other libraries . . bbc/lrud — Left, Right, Up, Down. A spatial navigation library for devices with input via directional controls. . bbc/grid — BBC’s implementation of The Guardian’s image management system . bbc/digital-paper-edit-client — Work in progress - BBC News Labs digital paper edit project - React Client . bbc/webMUSHRA — a MUSHRA compliant web audio API based experiment software . bbc/programmes-pages-service — A library for accessing ProgrammesDB . bbc/codext — VS Code’s editor shipped as a browser extension. . bbc/clever-thumbnailer — Audio thumbnail generator . bbc/digital-paper-edit-storybook — Work in progress - BBC News Labs digital paper edit project - React storybook . . Once a Week (magazine)/Series 1/Volume 11/From Canada to Liverpool, with “skedaddlers” from the Northern army . Rhymes of a Rolling Stone/The Cow-Juice Cure . Rhymes of a Red-Cross Man/Missis Moriarty’s Boy . The Shebeeners . . Neural Data Augmentation via Example Extrapolation . Train GPT-2 in your own language . Archivist Quill Guide . Fit More and Train Faster With ZeRO via DeepSpeed and FairScale . Sample teaching materials, teg.ie . POSH: A Data-Aware Shell for Faster Distributed Text Processing . Físeáin - Mar a Déarfá! . Retrieval Augmented Generation with Huggingface Transformers and Ray . Retrieval Augmented Generation: Streamlining the creation of intelligent natural language processing models . PanLex . This Non-Profit is Building the World’s Largest Lexical Translation Database . Text Classification Using DeepPavlov Library With PyTorch And Transformers . Spoken Corpus Linguistics in Romance: thoughts, design and results . Named Tensor Notation . namedtensor/notation . kakaobrain/pororo — PORORO: Platform Of neuRal mOdels for natuRal language prOcessing . modernmt/modernmt — Neural Adaptive Machine Translation that adapts to context and learns from corrections. . quic/sense — Enhance your application with the ability to see and interact with humans using any RGB camera. . wenet-e2e/wenet — Production First and Production Ready End-to-End Speech Recognition Toolkit . mlpen/Nystromformer . ray-project/ray — Ray is a unified framework for scaling AI and Python applications. Ray consists of a core distributed runtime and a set of AI Libraries for accelerating ML workloads. . Natooz/MidiTok — MIDI / symbolic music tokenizers for Deep Learning models 🎶 . Books in Irish - Royal Irish Academy . Bibliography of Irish philology and of printed Irish literature, scan 2 . IG01-15, IG01-16, IG01-19, IG01-25, IG02-10049, IG02-60, IG02-11771, IG02-66 . Irish Language Forum - Study Group: Séadna . Exemplar VAE: Linking Generative Models, Nearest Neighbor Retrieval, and Data Augmentation . Diverse Beam Search: Decoding Diverse Solutions from Neural Sequence Models . The Irish of Iorras Aithneach, County Galway . Multilingual BERT has an accent: Evaluating English influences on fluency in multilingual models . My Man Jeeves . nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation . Siamese networks with Keras, TensorFlow, and Deep Learning . Comparing images for similarity using siamese networks, Keras, and TensorFlow . Dense Passage Retrieval for Open-Domain Question Answering . messiaen/full-lattice-search — Full Text Search Over Probabilistic Lattices with Elasticsearch! . steveash/jopenfst — Partial Java port of the C++ OpenFST library . OlliSaarikivi/Automata — Automata and transducer library for .NET . . Recreating Historical Streetscapes Using Deep Learning and Crowdsourcing . Ordnance Survey Index to the Map of the Town of Thurles . Thurles maps . Thurles map, 2 . Thurles Town Square 1957 . Old Photos of Thurles Co Tipperary Ireland . . Praat on the Web: An Upgrade of Praat for Semi-Automatic Speech Annotation . monikaUPF/PraatontheWeb — Web implementation of Praat. Source code, running demo scripts on web, samples and documentation . ys10/Grapheme-PhonemeAlignment — This project aims to implement a algorithm to do a grapheme-phoneme alignment task. . kfirgoldberg/FUN — Official implementation of the FUN models . jailuthra/asr — Kaldi ASR wrapper scripts . CLDF for dummies . My ELAN workflow for segmenting and transcription . Sylli - The SSP Syllabifier . Sequitur G2P . lennes/spect — SpeCT - Speech Corpus Toolkit for Praat. Documentation . praaline/Praaline — Praaline is an open-source system to manage, annotate, visualise and analyse spoken language corpora . CoEDL/elpis — 🙊 software for creating speech recognition models. . This is Hogwild! . Deep Speech : Train Native Languages with Transfer Learning Part #0b01 . Prosogram . cohere-ai/natural-instructions — Expanding natural instructions . Bat banter is surprisingly nuanced . Yes you should understand backprop . The Unreasonable Effectiveness of Recurrent Neural Networks . Chrome Extension Programming: Illustrating a Basic Survival Skill with a Twitter Case Study . Feature Learning Escapades . A Survival Guide to a PhD . A Recipe for Training Neural Networks . Language Through a Prism: A Spectral Approach for Multiscale Language Representations . Sentence Embedding . How to Use Image Embeddings for Object Localization . Learning deep features to recognise speech emotion using merged deep CNN . How to Break GPU Memory Boundaries Even with Large Batch Sizes . zh217/torch-dct — DCT (discrete cosine transform) functions for pytorch . inejc/paragraph-vectors — :page_facing_up: A PyTorch implementation of Paragraph Vectors (doc2vec). . pperle/gaze-tracking — state-of-the-art gaze tracking model . tjysdsg/capt-public — Public version of my Computer-Aided Pronunciation Training (CAPT) system (server) . JawadAr/Pronunciation-verification-using-anomaly-detection-Thesis — This repository contains all the codes used in a thesis at Information Technology University (ITU). The topic of the thesis is pronunciation verification using anomaly detection. . googlefonts/gftools — Misc tools for working with the Google Fonts library . fonttools/fonttools — A library to manipulate font files from Python. . openjournals/joss — The Journal of Open Source Software . LaurentMazare/tch-rs — Rust bindings for the C++ api of PyTorch. . vesis84/kaldi-io-for-python — Python functions for reading kaldi data formats. Useful for rapid prototyping with python. . Peer Review: Implementing a “publish, then review” model of publishing . The Entropy of Words—Learnability and Expressivity across More than 1000 Languages, preprint . Exploiting Weak Ties in Incomplete Network Datasets Using Simplified Graph Convolutional Neural Networks . Why scientists are turning to Rust . Cookin’ with Rust . The Rust Programming Language . Phone set selection for HMM-based dialect speech synthesis . The On-Device Machine Learning Behind Recorder . Navigating Recorder Transcripts Easily, with Smart Scrolling . How to objectively measure phonetic distance? . CoEDL/elpis — 🙊 software for creating speech recognition models. . Neural circuit policies enabling auditable autonomy . The Challenges of using Transformers in ASR . Segment Anything Meets Point Tracking . SysCV/sam-pt — SAM-PT: Extending SAM to zero-shot video segmentation with point-based tracking. . SHAP-EDITOR: Instruction-guided Latent 3D Editing in Seconds . bbc/subtitles-generator — A node module to generate subtitles by segmenting a list of time-coded text - BBC News Labs . ebu/libbw64 — Broadcast Wave 64 (ITU-R BS.2088) library . bbc/aes31-adl-composer — Work in progress - A node module to convert a json sequence into an AES31 ADL (audio decision list) compatible with SADiE audio editing software. For BBC News Labs digital paper edit project . bbc/audiowaveform — C++ program to generate waveform data and render waveform images from audio files . enochkan/torch-metrics — Metrics for model evaluation in pytorch . formiel/speech-translation — Multilingual speech translation . synesthesiam/sv_kaldi-montreal — Swedish voice2json profile based on Kaldi . mycrazycracy/speaker-embedding-with-phonetic-information — The code for the Interspeech paper “Speaker Embedding Extraction with Phonetic Information” . openXBOW/openXBOW — openXBOW - the Passau Open-Source Crossmodal Bag-of-Words Toolkit . fastai/numerical-linear-algebra — Free online textbook of Jupyter notebooks for fast.ai Computational Linear Algebra course . . Irish . The Journey of Viscount Ramon de Perellós to Saint Patrick’s Purgatory . Mion-ċaint : an easy Irish phrase book . The Book of Kells . Researches in the South of Ireland . A little bit of Culture… Poetry from soc.culture.irish . Caoineadh Airt UÍ Laoghaire . An Caoineadh Airt Uí Laoghaire . . Adaptation Algorithms for Neural Network-Based Speech Recognition: An Overview . Train LLMs using QLoRA on Amazon SageMaker . apple/swift-algorithms — Commonly used sequence and collection algorithms for Swift . apple/sourcekit-lsp — Language Server Protocol implementation for Swift and C-based languages . apple/darwin-libplatform — Legacy mirror of Darwin Platform Library. Replaced by https://github.com/apple-oss-distributions/libplatform . apple/foundationdb — FoundationDB - the open source, distributed, transactional key-value store . marian-nmt/marian-examples — Examples, tutorials and use cases for Marian, including our WMT-2017/18 baselines. . pswietojanski/ojsp_adaptation_review_2020 — Auxiliary data and scripts for our OJSP review on speaker adaptation for speech recognition . Zeitschrift für celtische Philologie . Review: Oral Literature from Dunquin, County Kerry . A Gentle Introduction to the Huggingface Pipeline . Training with Marian . MarianNMT Examples . Séamus Ó Duilearga’s Co. Antrim notebooks . . Hungarian Speecon database . BUSZI-2 guided conversations - downloadable transcripts . Nordic Dialect Corpus . The Swedish subproject of ScanDiaSyn . Skolt Saami Documentation Corpus . Gothenburg Dialogue Corpus . Hungarian BABEL . Hungarian Broadcast News Database . Hungarian National Corpus . Hungarian Kindergarten Language Corpus . Hungarian MRBA . Hungarian Medical Speech Database . . Tunable Q-factor Wavelet Transform . PyWavelets/pywt — PyWavelets - Wavelet Transforms in Python . jollyjonson/tqwt_tools — Tunable-Q Wavelet Transform and Resonance-based Signal Decomposition Toolkit .",
            "url": "https://jimregan.github.io/notes/links/2023/12/27/misc-links.html",
            "relUrl": "/links/2023/12/27/misc-links.html",
            "date": " • Dec 27, 2023"
        }
        
    
  
    
        ,"post19": {
            "title": "Waxholm lexicon processing",
            "content": "import json with open(&quot;/tmp/waxholm_raw_lexicon.json&quot;) as lexjson: data = json.load(lexjson) . def simplify_stops(text): text = text.replace(&quot;Kk&quot;, &quot;K&quot;) text = text.replace(&quot;Gg&quot;, &quot;G&quot;) text = text.replace(&quot;Dd&quot;, &quot;D&quot;) text = text.replace(&quot;Tt&quot;, &quot;T&quot;) text = text.replace(&quot;Bb&quot;, &quot;B&quot;) text = text.replace(&quot;Pp&quot;, &quot;P&quot;) text = text.replace(&quot;k&quot;, &quot;K&quot;) text = text.replace(&quot;Kl&quot;, &quot;kl&quot;) text = text.replace(&quot;g&quot;, &quot;G&quot;) text = text.replace(&quot;d&quot;, &quot;D&quot;) text = text.replace(&quot;t&quot;, &quot;T&quot;) text = text.replace(&quot;b&quot;, &quot;B&quot;) text = text.replace(&quot;p&quot;, &quot;P&quot;) text = text.replace(&quot;Pa&quot;, &quot;pa&quot;) text = text.replace(&quot;P:&quot;, &quot;p:&quot;) return text . def simplify_phoneme(text): text = text.replace(&quot;+&quot;, &quot;&quot;) text = text.replace(&quot;hy&quot;, &quot;#&quot;) return text . def segment_label(label, skip_pause=True): phones = [] i = 0 while i &lt; len(label): start_i = i end_i = i if label[i:i+2] in [&quot;NG&quot;, &quot;E0&quot;, &quot;SJ&quot;, &quot;TJ&quot;, &quot;kl&quot;, &quot;sm&quot;, &quot;pa&quot;, &quot;ha&quot;, &quot;öh&quot;, &quot;Pa&quot;, &quot;p:_pa&quot;, &quot;pa_p:&quot;]: phones.append(label[i:i+2]) i += 2 elif label[i:i+2] == &quot;p:&quot;: if not skip_pause: phones.append(&quot;p:&quot;) i += 2 elif label[i:i+1] in [&quot;#&quot;, &quot;~&quot;]: i += 1 else: if label[i:i+1] in [&quot;&#39;&quot;, &quot;`&quot;, &quot; &quot;&quot;, &quot;,&quot;, &quot;2&quot;]: i += 1 end_i += 1 if label[i+1:i+2] in [&quot;:&quot;, &quot;3&quot;, &quot;4&quot;]: end_i += 1 phones.append(label[start_i:end_i+1]) i = end_i + 1 return phones . def lclem(lower): if lower[0] == lower[-1] == &quot;X&quot;: return lower else: return lower.lower() . data[0] . {&#39;stem&#39;: &#39;fp2024.1.03&#39;, &#39;smp&#39;: &#39;fp2024/fp2024.1.03.smp&#39;, &#39;text&#39;: &#39;tack det är bra&#39;, &#39;phoneme&#39;: &#34;T&#39;AK D&#39;E:T+ &#39;Ä3R+ BR&#39;A:&#34;, &#39;labels&#39;: &#34;Tt&#39;AKk Dd&#39;E: BbR&#39;A:&#34;, &#39;labels_original&#39;: &#34;Tt&#39;AKk Dd&#39;E: BbR&#39;A:&#34;} . X_TAGS = { &quot;XtvekX&quot;: &quot;öh&quot;, &quot;XinandX&quot;: &quot;pa&quot;, &quot;XsmackX&quot;: &quot;sm&quot;, &quot;XutandX&quot;: &quot;pa&quot;, &quot;XharklingX&quot;: &quot;ha&quot;, &quot;XklickX&quot;: &quot;kl&quot;, &quot;XavbrordX&quot;: &quot;&quot;, &quot;XskrattX&quot;: &quot;ha&quot;, &quot;XsuckX&quot;: &quot;pa&quot; } def check_x_tag(word, phoneme): if word == &quot;XavbrordX&quot;: return True if word in X_TAGS: return phoneme == X_TAGS[word] def modify_phonemes_inner(word, phonemes, idx): if not word in X_TAGS: return phonemes elif word == &quot;XavbrordX&quot;: return phonemes if not check_x_tag(word, phonemes[idx]): if idx == -1: return phonemes + [X_TAGS[word]] else: return phonemes[0:idx] + [X_TAGS[word]] + phonemes[idx:] . wds = &quot;XinandX lördag&quot;.split(&quot; &quot;) phn = &quot;L&#39;Ö32DA&quot;.split(&quot; &quot;) assert modify_phonemes_inner(wds[0], phn, 0) == [&#39;pa&#39;, &quot;L&#39;Ö32DA&quot;] wds = &quot;lördag XinandX&quot;.split(&quot; &quot;) phn = &quot;L&#39;Ö32DA&quot;.split(&quot; &quot;) assert modify_phonemes_inner(wds[1], phn, -1) == [&quot;L&#39;Ö32DA&quot;, &#39;pa&#39;] . def modify_phonemes(words, phonemes): i = 0 if phonemes is None or phonemes == [] or len(phonemes) == 0: print(&quot;Error with phonemes&quot;, phonemes) return [] my_phonemes = phonemes assert isinstance(my_phonemes, list) assert my_phonemes is not None while i &lt; len(words): if my_phonemes is None: print(words, phonemes, my_phonemes, type(my_phonemes)) if i &gt;= len(my_phonemes): p_i = -1 else: p_i = i my_phonemes = modify_phonemes_inner(words[i], my_phonemes, p_i) i += 1 return my_phonemes . for entry in data: if not &quot;phoneme&quot; in entry: continue if entry[&quot;phoneme&quot;] == &quot;&quot;: continue phonemes = entry[&quot;phoneme&quot;].strip().split(&quot; &quot;) phonemes_orig = &quot; &quot;.join(phonemes) words = entry[&quot;text&quot;].strip().split(&quot; &quot;) labels = entry[&quot;labels&quot;].strip().split(&quot; &quot;) if phonemes == None or phonemes == []: continue if len(words) != len(phonemes): mod = modify_phonemes(words, phonemes) if &quot; &quot;.join(mod) != phonemes_orig: entry[&quot;phoneme_orginal&quot;] = entry[&quot;phoneme&quot;] entry[&quot;phoneme&quot;] = &quot; &quot;.join(mod) with open(&quot;/tmp/waxholm_autoedit.json&quot;, &quot;w&quot;) as autoedit: json.dump(data, autoedit) . entries = {} rest = [] for item in data: if not &quot;phoneme&quot; in item: continue if item[&quot;labels&quot;].startswith(&quot;sm&quot;) and not item[&quot;text&quot;].startswith(&quot;XsmackX&quot;): item[&quot;text&quot;] = f&#39;XsmackX {item[&quot;text&quot;]}&#39; elif item[&quot;labels&quot;].startswith(&quot;öh&quot;) and not item[&quot;text&quot;].startswith(&quot;XtvekX&quot;): item[&quot;text&quot;] = f&#39;XtvekX {item[&quot;text&quot;]}&#39; # elif item[&quot;labels&quot;].startswith(&quot;pa&quot;) and not item[&quot;text&quot;].startswith(&quot;XutandX&quot;): # item[&quot;text&quot;] = f&#39;XutandX {item[&quot;text&quot;]}&#39; phonemes = simplify_phoneme(item[&quot;phoneme&quot;]).split(&quot; &quot;) labels = simplify_stops(item[&quot;labels&quot;]).split(&quot; &quot;) words = [lclem(x) for x in item[&quot;text&quot;].split(&quot; &quot;)] if len(phonemes) == len(labels) == len(words): curword = {} for x in zip(words, phonemes, labels): if not x[0] in entries: entries[x[0]] = {} if not x[1] in entries[x[0]]: entries[x[0]][x[1]] = {} if not x[2] in entries[x[0]][x[1]]: entries[x[0]][x[1]][x[2]] = set() entries[x[0]][x[1]][x[2]].add(item[&quot;stem&quot;]) else: rest.append(item) . for a in entries: for b in entries[a]: for c in entries[a][b]: for d in entries[a][b][c]: entries[a][b][c] = list(entries[a][b][c]) . with open(&quot;/tmp/simple-aligned-entries.json&quot;, &quot;w&quot;) as simplef: json.dump(entries, simplef) . len(rest) . 429 . smacks = [] uh = [] for item in rest: if item[&quot;labels&quot;].startswith(&quot;sm&quot;) and not item[&quot;text&quot;].startswith(&quot;XsmackX&quot;): smacks.append(item) elif item[&quot;labels&quot;].startswith(&quot;öh&quot;) and not item[&quot;text&quot;].startswith(&quot;XtvekX&quot;): uh.append(item) .",
            "url": "https://jimregan.github.io/notes/swedish/waxholm/lexicon/2023/12/15/waxholm-lexicon.html",
            "relUrl": "/swedish/waxholm/lexicon/2023/12/15/waxholm-lexicon.html",
            "date": " • Dec 15, 2023"
        }
        
    
  
    
        ,"post20": {
            "title": "Interesting links, 15/12/2023",
            "content": "A Cookbook of Self-Supervised Learning . Automatic Quality Estimation for ASR System Combination . Choose Your Weapon: Survival Strategies for Depressed AI Academics . ggerganov/whisper.cpp . Attention as a guide for Simultaneous Speech Translation . accent in CUBE — Current British English . Morse wavelet transform-based features for voice liveness detection . Towards inclusive automatic speech recognition . colmap/colmap — COLMAP - Structure-from-Motion and Multi-View Stereo . SuLvXiangXin/zipnerf-pytorch — Unofficial implementation of ZipNeRF . Tanks and Temples . Introduction to 3D Gaussian Splatting . LLM Visualization . How 🤗 Accelerate runs very large models thanks to PyTorch . Cló Gaelach agus Transkribus . google-deepmind/graphcast — GraphCast: Learning skillful medium-range global weather forecasting . vLLM: Easy, Fast, and Cheap LLM Serving with PagedAttention . FasterDecoding/REST — Retrieval-Based Speculative Decoding . HyenaDNA Models . HazyResearch/hyena-dna — Official implementation for HyenaDNA, a long-range genomic foundation model built with Hyena . On the Effectiveness of ASR Representations in Real-world Noisy Speech Emotion Recognition . Vaibhavs10/insanely-fast-whisper . Instruction Tuning Vol. 1 . Italian Parkinson’s voice and speech . neonbjb/tortoise-tts . NVIDIA/TensorRT-LLM . facebookincubator/AITemplate — AITemplate is a Python framework which renders neural network into high performance CUDA/HIP C++ code. Specialized for FP16 TensorCore (NVIDIA GPU) and MatrixCore (AMD GPU) inference. . SpeechMatrix: A Large-Scale Mined Corpus of Multilingual Speech-to-Speech Translations Horrible licence. . rasbt/LLMs-from-scratch . USM-Lite: Quantization and Sparsity Aware Fine-tuning for Speech Recognition with Universal Speech Models . BrainGPT - A step towards the future of human-AI merger BrainGPT is capable of thought-to-text translation and connects a multitask EEG encoder with LMS to decode coherent and readable sentences from EEG signals. This means that thoughts, measured by wearing a cap with… pic.twitter.com/2Vp58Uev3L . &mdash; Bindu Reddy (@bindureddy) December 17, 2023 dylanebert/gsplat.js . migtissera/Tess-Coder-v1.0 . google-research/robotics_transformer . huggingface/trl . UniversalDependencies/UD_Swedish_Sign_Language-SSLC . Numbers from 100-1 Million . Uimhreacha . Acoustic-to-Articulatory Mapping With Joint Optimization of Deep Speech Enhancement and Articulatory Inversion Models . This is a baby GPT with two tokens 0/1 and context length of 3, viewing it as a finite state markov chain. It was trained on the sequence &quot;111101111011110&quot; for 50 iterations. The parameters and the architecture of the Transformer modifies the probabilities on the arrows.E.g. we… pic.twitter.com/vj10nZEXlH . &mdash; Andrej Karpathy (@karpathy) April 9, 2023 Zip-NeRF: Anti-Aliased Grid-Based Neural Radiance Fields . OpenNMT/CTranslate2 . Nile Making Things That Gods Detest Documentary . GestureDiffuCLIP demo . FLAP: Fast Language-Audio Pre-training . Add Bayes Risk CTC . pnnl/HyperNetX — Python package for hypergraph analysis and visualization. . Finite state transducers and Pynini . cobcom/wlalign — An implementation of the WL-align algorithm, a graph-alignment routine based on the generalization of the Weisfeiler-Lehman algorithm. . eth-sri/astarix — AStarix: Fast and Optimal Sequence-to-Graph Aligner . OpenScene: 3D Scene Understanding with Open Vocabularies, demo, code . I’ve resigned from my role leading the Audio team at Stability AI, because I don’t agree with the company’s opinion that training generative AI models on copyrighted works is ‘fair use’.First off, I want to say that there are lots of people at Stability who are deeply… . &mdash; Ed Newton-Rex (@ednewtonrex) November 15, 2023 Mixtral of Experts . ReMoDiffuse: Retrieval-Augmented Motion Diffusion Model . MahmoudAshraf97/whisper-diarization . drlukeparry/pyslm — PySLM: A Python Library for 3D Printing and Additive Manufacturing . 3D Printing for Vocal-Tract Models . open-mmlab/mmpose . ochen1/insanely-fast-whisper-cli — The fastest Whisper optimization for automatic speech recognition as a command-line interface . geekodour/wscribe — ez audio transcription tool with flexible processing and post-processing options . SYSTRAN/fuzzy-match — Library and command line utility to do approximate string matching of a source against a bitext index and get matched source and target. . SYSTRAN/similarity — Bilingual sentence similarity classifier using Tensorflow .",
            "url": "https://jimregan.github.io/notes/links/2023/12/15/misc-links.html",
            "relUrl": "/links/2023/12/15/misc-links.html",
            "date": " • Dec 15, 2023"
        }
        
    
  
    
        ,"post21": {
            "title": "Check users",
            "content": "REPO = &quot;/Users/joregan/Playing/gpu-admin&quot; . from pathlib import Path from datetime import datetime . import json with open(Path(REPO) / &quot;users.json&quot;) as userfile: users = json.load(userfile) . today = datetime(2023, 12, 7) . exusers = [] for user in users: if &quot;expires&quot; in users[user]: expiration = datetime.strptime(users[user][&quot;expires&quot;], &quot;%Y-%m-%d&quot;) if expiration &lt; today: exusers.append(user) for user in exusers: del users[user] .",
            "url": "https://jimregan.github.io/notes/tmh/gpu-admin/2023/12/07/check-users.html",
            "relUrl": "/tmh/gpu-admin/2023/12/07/check-users.html",
            "date": " • Dec 7, 2023"
        }
        
    
  
    
        ,"post22": {
            "title": "Converting fuaimeanna.ie data for fairseq",
            "content": "Using data from an earlier scraper . from pathlib import Path BASEPATH = Path(&quot;/Users/joregan/Playing/irish-gists/scrape-fuaimeanna-private/&quot;) OUTPATH = Path(&quot;/tmp/fuaimeanna-fairseq&quot;) . if not OUTPATH.is_dir(): OUTPATH.mkdir() . EMPTY_AUDIO = &quot;&quot;&quot; gob_i3_s3.mp3 iioctha_i3_s3.mp3 mo_shuiiochaan_i3_s3.mp3 riail_i3_s3.mp3 &quot;&quot;&quot;.strip().split(&quot; n&quot;) . PHONES_NO_AUDIO = &quot;&quot;&quot; d&#39;fhaag_i1_s1.phones d&#39;fhaag_i2_s2.phones d&#39;fhaag_i3_s3.phones &quot;&quot;&quot;.strip().split(&quot; n&quot;) . parameters=[&quot;-ac&quot;, &quot;1&quot;, &quot;-acodec&quot;, &quot;pcm_s16le&quot;, &quot;-ar&quot;, &quot;16000&quot;] . from pydub import AudioSegment . def drop_accents(pron): parts = pron.split(&quot; &quot;) return &quot; &quot;.join([x for x in parts if x not in [&quot;.&quot;, &quot;ˈ&quot;, &quot;ˌ&quot;]]) . prons_gd = {} prons_cr = {} prons_cd = {} with open(str(BASEPATH / &quot;all-fuaimeanna-data.tsv&quot;)) as tsvf: for line in tsvf.readlines(): if line.startswith(&quot;Orth&quot;): continue parts = line.split(&quot; t&quot;) fname = parts[1] fname = fname.replace(&quot;.mp3&quot;, &quot;&quot;).split(&quot;/&quot;)[2] prons_gd[fname] = drop_accents(parts[2].strip()) fname = parts[3] fname = fname.replace(&quot;.mp3&quot;, &quot;&quot;).split(&quot;/&quot;)[2] prons_cr[fname] = drop_accents(parts[4].strip()) fname = parts[5] fname = fname.replace(&quot;.mp3&quot;, &quot;&quot;).split(&quot;/&quot;)[2] prons_cd[fname] = drop_accents(parts[6].strip()) . prons_all = {**prons_cd, **prons_cr, **prons_gd} . validkeys = list(prons_cd.keys())[:int(len(prons_cd) * .05)] validkeys += list(prons_cr.keys())[:int(len(prons_cr) * .05)] validkeys += list(prons_gd.keys())[:int(len(prons_gd) * .05)] . alldata = [] for audio_file in (BASEPATH / &quot;mp3&quot;).glob(&quot;*.mp3&quot;): if audio_file.name in EMPTY_AUDIO: continue stem = audio_file.stem if f&quot;{stem}.phones&quot; in PHONES_NO_AUDIO: continue data = {} data[&quot;name&quot;] = stem spoken = AudioSegment.from_mp3(str(audio_file)) outfile = OUTPATH / f&quot;{stem}.wav&quot; spoken.export(str(outfile), format=&quot;wav&quot;, parameters=parameters) data[&quot;labels&quot;] = prons_all[stem].replace(&quot;#&quot;, &quot;|&quot;) data[&quot;frames&quot;] = spoken.frame_count() alldata.append(data) . with open(str(OUTPATH / &quot;train.ltr&quot;), &quot;w&quot;) as train_ltr, open(str(OUTPATH / &quot;train.tsv&quot;), &quot;w&quot;) as train_tsv, open(str(OUTPATH / &quot;valid.ltr&quot;), &quot;w&quot;) as valid_ltr, open(str(OUTPATH / &quot;valid.tsv&quot;), &quot;w&quot;) as valid_tsv: for datum in alldata: if datum[&quot;name&quot;] in validkeys: out_ltr = valid_ltr out_tsv = valid_tsv else: out_ltr = train_ltr out_tsv = train_tsv out_ltr.write(f&#39;{datum[&quot;labels&quot;]} | n&#39;) out_tsv.write(f&#39;{datum[&quot;name&quot;]}.wav t{int(datum[&quot;frames&quot;])} n&#39;) .",
            "url": "https://jimregan.github.io/notes/irish/asr/phonetic/2023/11/10/fuaimeanna-to-fairseq.html",
            "relUrl": "/irish/asr/phonetic/2023/11/10/fuaimeanna-to-fairseq.html",
            "date": " • Nov 10, 2023"
        }
        
    
  
    
        ,"post23": {
            "title": "Waxholm kludge",
            "content": "WAXHOLM_DIR = &quot;/Users/joregan/Playing/waxholm/scenes_formatted/&quot; . $find ~/Playing/waxholm/scenes_formatted/ -name &#39;*.mix&#39;|while read i;do cat $i |grep -v &#39;^$&#39;|grep -v &#39;^FR&#39;|grep -v &#39;^CT&#39;|grep -v &#39;^WIZARD&#39;| grep -v &#39;^AUTOLAB&#39;|grep -v &#39;CORRECTED:&#39;|grep -v &#39;DATA BANK MATERIAL&#39;|grep -v &#39;^SPEAKER&#39;; done . #!/usr/bin/perl use warnings; use strict; use utf8; binmode(STDIN, &quot;:utf8&quot;); binmode(STDOUT, &quot;:utf8&quot;); binmode(STDERR, &quot;:utf8&quot;); my $smp = &#39;&#39;; my $last = &#39;&#39;; my $text = &#39;&#39;; my $phone = &#39;&#39;; my $label = &#39;&#39;; sub clean_up { my $text = shift; $text =~ s/ s+/ /g; $text =~ s/ {/ä/g; $text =~ s/ }/å/g; $text =~ s/ |/ö/g; $text =~ s/ /Ö/g; return $text; } while(&lt;&gt;) { chomp; if(m!Waxholm dialog. /u/wax/data/scenes/[^/]*/(.*)!) { my $newsmp = $1; $last = &#39;smp&#39;; $text = clean_up($text); $phone = clean_up($phone); $label = clean_up($label); if ($smp ne &#39;&#39;) { print &quot;$smp t$text t$phone t$label n&quot;; } $smp = $newsmp; $text = &#39;&#39;; $phone = &#39;&#39;; $label = &#39;&#39;; } elsif (m!^PHONEME:!) { s/^PHONEME: s+//; $phone = $_; $last = &#39;phone&#39;; } elsif (m!^Labels:!) { s/^Labels: s+//; $label = $_; $last = &#39;label&#39;; } elsif (m!^TEXT:!) { s/^TEXT: s*//; $text = $_; $last = &#39;text&#39;; } elsif (m!^S{g f|ljande mening:!) { print STDERR &quot;$smp:$_ n&quot;; } else { if($last eq &#39;text&#39;) { $text = &quot;$text $_&quot;; } elsif($last eq &#39;label&#39;) { $label = &quot;$label $_&quot;; } elsif($last eq &#39;phone&#39;) { $phone = &quot;$phone $_&quot;; } else { print &quot;DAFUQ: $_&quot;; } } } . from pathlib import Path import re WAXHOLM_PATH = Path(WAXHOLM_DIR) def skippable(text): if text.startswith(&quot;CT&quot;): return True elif text.startswith(&quot;CORRECTED:&quot;): return True elif text.startswith(&quot;AUTOLABEL:&quot;): return True elif text.startswith(&quot;DATA BANK MATERIAL:&quot;): return True elif text.startswith(&quot;WIZARD:&quot;): return True elif text.startswith(&quot;SPEAKER&quot;): return True elif text.startswith(&quot;Digital recording&quot;): return True elif text.startswith(&quot;S{g f|ljande mening:&quot;): return True elif text.startswith(&quot;Correction&quot;): return True elif text.strip().startswith(&quot;Corrected&quot;): return True elif text.strip() == &quot;&quot;: return True return False def fix_text(text: str) -&gt; str: if text == &quot;&quot;: return &quot;&quot; text = text.strip() replacements = text.maketrans(&quot;{}| []&quot;, &quot;äåöÖÄÅ&quot;) tr = text.translate(replacements) spaced = re.sub(&quot; s+&quot;, &quot; &quot;, tr) if spaced[-1] == &quot;.&quot;: spaced = spaced[:-1] return spaced.strip() def line_kludge(smp, line): LINES = { &quot;fp2015/fp2015.1.03.smp&quot;: &quot;J&#39;A:+&quot;, &quot;fp2015/fp2015.1.00.smp&quot;: &quot;H&#39;EJ&quot;, &#39;fp2015/fp2015.1.01.smp&#39;: &quot;J&#39;A:&quot;, &#39;fp2015/fp2015.1.04.smp&#39;: &#39;V&quot;ILK &#39;A&#39;, &#39;fp2015/fp2015.1.05.smp&#39;: &quot;G&#39;]:R&quot;, &#39;fp2015/fp2015.1.06.smp&#39;: &quot;&#39;]:+&quot;, &#39;fp2014/fp2014.1.02.smp&#39;: &quot;M&#39;]NDA&quot;, &#39;fp2014/fp2014.6.00.smp&#39;: &#39;V&quot;ILK &#39;A&#39;, &#39;fp2014/fp2014.8.05.smp&#39;: &quot;T&#39;AK&quot;, &#39;fp2014/fp2014.8.04.smp&#39;: &quot;F&#39;INS&quot;, &#39;fp2014/fp2014.6.01.smp&#39;: &#39;V&quot;ILK &#39;A&#39;, &#39;fp2014/fp2014.1.03.smp&#39;: &quot;K&#39;AN+&quot;, &#39;fp2014/fp2014.1.01.smp&#39;: &quot;FR&#39;]:N+&quot;, &#39;fp2014/fp2014.1.00.smp&#39;: &quot;G&#39;]:R&quot;, &#39;fp2014/fp2014.6.02.smp&#39;: &quot;T&#39;AK&quot;, &#39;fp2014/fp2014.8.02.smp&#39;: &quot;T&#39;AK&quot;, &#39;fp2014/fp2014.1.05.smp&#39;: &quot;D&#39;E+&quot;, &#39;fp2014/fp2014.1.04.smp&#39;: &quot;G&#39;]:R&quot;, &#39;fp2014/fp2014.8.03.smp&#39;: &quot;K&#39;AN+&quot;, &#39;fp2014/fp2014.8.01.smp&#39;: &#39;V&quot;ILK &#39;A&#39;, &#39;fp2014/fp2014.8.00.smp&#39;: &quot;K&#39;AN+&quot;, &#39;fp2007/fp2007.6.01.smp&#39;: &quot;V&#39;A:R+&quot;, &#39;fp2007/fp2007.8.04.smp&#39;: &quot;&#39;EN+&quot;, &#39;fp2007/fp2007.1.03.smp&#39;: &quot;J&#39;A:&quot;, &#39;fp2007/fp2007.1.13.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2007/fp2007.1.12.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2007/fp2007.1.02.smp&#39;: &quot;&#39;I:+&quot;, &#39;fp2007/fp2007.8.05.smp&#39;: &quot;&#39;EN+&quot;, &#39;fp2007/fp2007.6.00.smp&#39;: &quot;V&#39;A:R+&quot;, &#39;fp2007/fp2007.1.00.smp&#39;: &quot;N&#39;[3R+&quot;, &#39;fp2007/fp2007.1.09.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2007/fp2007.8.07.smp&#39;: &quot;SL&#39;U:T&quot;, &#39;fp2007/fp2007.6.02.smp&#39;: &quot;SL&#39;U:T&quot;, &#39;fp2007/fp2007.1.08.smp&#39;: &#39;V&quot;AKShyH &#39;]LM&#39;, &#39;fp2007/fp2007.8.06.smp&#39;: &quot;V&#39;A:R+&quot;, &#39;fp2007/fp2007.1.11.smp&#39;: &quot;FR&#39;E:DA&quot;, &#39;fp2007/fp2007.1.04.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2007/fp2007.1.14.smp&#39;: &quot;P&#39;]:+&quot;, &#39;fp2007/fp2007.8.03.smp&#39;: &quot;V&#39;A:R+&quot;, &#39;fp2007/fp2007.8.02.smp&#39;: &#39;V&quot;ILK &#39;A&#39;, &#39;fp2007/fp2007.1.15.smp&#39;: &quot;SL&#39;U:T&quot;, &#39;fp2007/fp2007.1.05.smp&#39;: &quot;V&#39;A:R+&quot;, &#39;fp2007/fp2007.8.00.smp&#39;: &quot;F&#39;INS&quot;, &#39;fp2007/fp2007.1.06.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2007/fp2007.8.01.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2009/fp2009.5.02.smp&#39;: &quot;T&#39;I:SDA&quot;, &#39;fp2009/fp2009.1.05.smp&#39;: &quot;&#39;EFTER+&quot;, &#39;fp2009/fp2009.2.00.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2009/fp2009.2.01.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2009/fp2009.5.03.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2009/fp2009.1.04.smp&#39;: &quot;&#39;EFTER+&quot;, &#39;fp2009/fp2009.2.03.smp&#39;: &quot;V&#39;A:+&quot;, &#39;fp2007/fp2007.1.10.smp&#39;: &quot;FR&#39;]:N+&quot;, &#39;fp2009/fp2009.5.01.smp&#39;: &quot;IFR&#39;]:N&quot;, &#39;fp2009/fp2009.1.06.smp&#39;: &quot;F&#39;INS&quot;, &#39;fp2009/fp2009.5.00.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2009/fp2009.1.07.smp&#39;: &quot;N&#39;[3R+&quot;, &#39;fp2009/fp2009.2.07.smp&#39;: &#39;&quot;ING &#39;ET+&#39;, &#39;fp2009/fp2009.1.02.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2009/fp2009.1.03.smp&#39;: &quot;N&#39;[3R+&quot;, &#39;fp2009/fp2009.5.04.smp&#39;: &#39;&quot;ING &#39;ET+&#39;, &#39;fp2009/fp2009.2.06.smp&#39;: &quot;V&#39;A:+&quot;, &#39;fp2009/fp2009.1.01.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2009/fp2009.1.08.smp&#39;: &quot;P&#39;]:+&quot;, &#39;fp2009/fp2009.2.04.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2009/fp2009.1.09.smp&#39;: &quot;&#39;EFTER+&quot;, &#39;fp2009/fp2009.2.05.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2009/fp2009.1.00.smp&#39;: &quot;N&#39;[3R+&quot;, &#39;fp2009/fp2009.1.10.smp&#39;: &#39;SL&quot;U:T &#39;A&#39;, &#39;fp2009/fp2009.2.02.smp&#39;: &quot;FR&#39;]:N+&quot;, &#39;fp2001/fp2001.1.02.smp&#39;: &#39;STR&quot; MK &#39;AJEN&#39;, &#39;fp2001/fp2001.6.00.smp&#39;: &#39;V&quot;I:S &#39;A&#39;, &#39;fp2001/fp2001.2.17.smp&#39;: &quot;N&#39;[3R+&quot;, &#39;fp2001/fp2001.2.07.smp&#39;: &quot;D&#39;E+&quot;, &#39;fp2001/fp2001.6.01.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2001/fp2001.2.06.smp&#39;: &quot;FR&#39;]:N+&quot;, &#39;fp2001/fp2001.2.16.smp&#39;: &quot;,H&#39;U:R+&quot;, &#39;fp2001/fp2001.1.03.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2001/fp2001.6.03.smp&#39;: &quot;V&#39;A:R+&quot;, &#39;fp2001/fp2001.2.14.smp&#39;: &#39;V&quot;ILK &#39;A&#39;, &#39;fp2001/fp2001.2.04.smp&#39;: &quot;V&#39;A:R+&quot;, &#39;fp2001/fp2001.1.01.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2001/fp2001.1.00.smp&#39;: &#39;V&quot;ILK &#39;A&#39;, &#39;fp2001/fp2001.6.02.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2001/fp2001.2.15.smp&#39;: &#39;V&quot;ILK &#39;A&#39;, &#39;fp2001/fp2001.2.10.smp&#39;: &#39;V&quot;ILK &#39;A&#39;, &#39;fp2001/fp2001.2.00.smp&#39;: &quot;K&#39;AN+&quot;, &#39;fp2001/fp2001.2.09.smp&#39;: &quot;G&#39;]:R&quot;, &#39;fp2001/fp2001.2.19.smp&#39;: &quot;D&#39;E+&quot;, &#39;fp2001/fp2001.1.05.smp&#39;: &#39;V&quot;ILK &#39;A&#39;, &#39;fp2001/fp2001.2.18.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2001/fp2001.2.08.smp&#39;: &quot;P&#39;]:+&quot;, &#39;fp2001/fp2001.1.04.smp&#39;: &quot;G&#39;]:R&quot;, &#39;fp2001/fp2001.2.01.smp&#39;: &quot;V&#39;A:R+&quot;, &#39;fp2001/fp2001.2.11.smp&#39;: &quot;V&#39;A:R+&quot;, &#39;fp2001/fp2001.6.06.smp&#39;: &quot;D&#39;]:+&quot;, &#39;fp2001/fp2001.2.13.smp&#39;: &#39;V&quot;ILK &#39;A&#39;, &#39;fp2001/fp2001.2.03.smp&#39;: &#39;V&quot;ILK &#39;A&#39;, &#39;fp2001/fp2001.6.04.smp&#39;: &#39;V&quot;ILK &#39;A&#39;, &#39;fp2001/fp2001.2.02.smp&#39;: &quot;JA:H&#39;A:,&#39;]:+&quot;, &#39;fp2001/fp2001.2.12.smp&#39;: &quot;V&#39;A:R+&quot;, &#39;fp2001/fp2001.6.05.smp&#39;: &quot;V&#39;A:R+&quot;, &#39;fp2006/fp2006.5.05.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2006/fp2006.1.02.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2006/fp2006.6.00.smp&#39;: &#39;V&quot;ILK &#39;A&#39;, &#39;fp2006/fp2006.6.01.smp&#39;: &#39;V&quot;ILK &#39;A&#39;, &#39;fp2006/fp2006.5.04.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2006/fp2006.1.03.smp&#39;: &quot;SL&#39;U:T&quot;, &#39;fp2006/fp2006.6.03.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2006/fp2006.5.06.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2006/fp2006.1.01.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2006/fp2006.5.07.smp&#39;: &#39;V&quot;ILK &#39;A&#39;, &#39;fp2006/fp2006.1.00.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2006/fp2006.6.02.smp&#39;: &quot;V&#39;A:R+&quot;, &#39;fp2006/fp2006.6.07.smp&#39;: &quot;SL&#39;U:T&quot;, &#39;fp2006/fp2006.5.02.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2006/fp2006.5.03.smp&#39;: &quot;P&#39;]:+&quot;, &#39;fp2006/fp2006.6.06.smp&#39;: &quot;V&#39;A:R+&quot;, &#39;fp2006/fp2006.5.01.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2006/fp2006.6.04.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2006/fp2006.5.08.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2006/fp2006.6.05.smp&#39;: &quot;V&#39;A:R+&quot;, &#39;fp2006/fp2006.5.09.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2006/fp2006.5.00.smp&#39;: &#39;V&quot;ILK &#39;A&#39;, &#39;fp2006/fp2006.5.10.smp&#39;: &quot;SL&#39;U:T&quot;, &#39;fp2011/fp2011.3.04.smp&#39;: &quot;&#39;EN+&quot;, &#39;fp2011/fp2011.1.07.smp&#39;: &quot;D&#39;]:+&quot;, &#39;fp2011/fp2011.1.06.smp&#39;: &quot;F&#39;INS&quot;, &#39;fp2011/fp2011.3.05.smp&#39;: &quot;F&#39;INS&quot;, &#39;fp2011/fp2011.1.04.smp&#39;: &quot;N&#39;[3R+&quot;, &#39;fp2011/fp2011.3.07.smp&#39;: &#39;ST&quot;]KhyH &#39;]LM&#39;, &#39;fp2011/fp2011.1.05.smp&#39;: &quot;VARIFR&#39;]:N&quot;, &#39;fp2011/fp2011.1.00.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2011/fp2011.1.09.smp&#39;: &quot;T&#39;AK&quot;, &#39;fp2011/fp2011.3.03.smp&#39;: &quot;K&#39;AN+&quot;, &#39;fp2011/fp2011.1.08.smp&#39;: &quot;T&#39;AK&quot;, &#39;fp2011/fp2011.3.02.smp&#39;: &quot;K&#39;AN+&quot;, &#39;fp2011/fp2011.1.01.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2011/fp2011.3.00.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2011/fp2011.3.10.smp&#39;: &quot;D&#39;E+&quot;, &#39;fp2011/fp2011.1.03.smp&#39;: &quot;K&#39;AN+&quot;, &#39;fp2011/fp2011.3.09.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2011/fp2011.1.02.smp&#39;: &quot;FR&#39;]:N+&quot;, &#39;fp2011/fp2011.3.01.smp&#39;: &quot;V&#39;A:R+&quot;, &#39;fp2011/fp2011.6.00.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2010/fp2010.1.06.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2010/fp2010.8.08.smp&#39;: &#39;V&quot;ILK &#39;A&#39;, &#39;fp2010/fp2010.6.04.smp&#39;: &quot;H&#39;U:R+&quot;, &#39;fp2010/fp2010.8.01.smp&#39;: &#39;N&quot;]:G]NhyST &#39;ANS&#39;, &#39;fp2010/fp2010.8.11.smp&#39;: &quot;F&#39;INS&quot;, &#39;fp2010/fp2010.8.10.smp&#39;: &quot;F&#39;INS&quot;, &#39;fp2010/fp2010.6.05.smp&#39;: &quot;&#39;[3R+&quot;, &#39;fp2010/fp2010.1.07.smp&#39;: &quot;G&#39;]:R&quot;, &#39;fp2010/fp2010.8.09.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2010/fp2010.8.02.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2010/fp2010.8.12.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2010/fp2010.1.05.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2010/fp2010.1.04.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2010/fp2010.6.06.smp&#39;: &quot;SL&#39;U:T&quot;, &#39;fp2010/fp2010.8.13.smp&#39;: &quot;V&#39;A:+&quot;, &#39;fp2010/fp2010.8.03.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2010/fp2010.6.03.smp&#39;: &quot;,H&#39;U:R+&quot;, &#39;fp2010/fp2010.8.06.smp&#39;: &#39;V&quot;ILK &#39;A&#39;, &#39;fp2010/fp2010.8.16.smp&#39;: &quot;SL&#39;U:T&quot;, &#39;fp2010/fp2010.1.08.smp&#39;: &quot;F&#39;INS&quot;, &#39;fp2010/fp2010.1.11.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2010/fp2010.1.01.smp&#39;: &quot;J&#39;A:&quot;, &#39;fp2010/fp2010.1.00.smp&#39;: &quot;J&#39;O:&quot;, &#39;fp2010/fp2010.1.10.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2010/fp2010.8.07.smp&#39;: &quot;N&#39;[3R+&quot;, &#39;fp2010/fp2010.6.02.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2010/fp2010.1.09.smp&#39;: &quot;G&#39;]:R&quot;, &#39;fp2010/fp2010.1.12.smp&#39;: &quot;G&#39;]:R&quot;, &#39;fp2010/fp2010.1.02.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2010/fp2010.8.05.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2010/fp2010.8.15.smp&#39;: &quot;K&#39;AN+&quot;, &#39;fp2010/fp2010.6.01.smp&#39;: &#39;V&quot;ILK &#39;A&#39;, &#39;fp2010/fp2010.8.14.smp&#39;: &quot;V&#39;A:+&quot;, &#39;fp2010/fp2010.8.04.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2010/fp2010.1.03.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2010/fp2010.1.13.smp&#39;: &quot;SL&#39;U:T&quot;, &#39;fp2003/fp2003.8.00.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2003/fp2003.1.07.smp&#39;: &#39;&quot;ING &#39;ET+&#39;, &#39;fp2003/fp2003.1.06.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2003/fp2003.8.01.smp&#39;: &quot;F&#39;INS&quot;, &#39;fp2003/fp2003.1.04.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2003/fp2003.8.03.smp&#39;: &quot;V&#39;A:R+&quot;, &#39;fp2003/fp2003.1.05.smp&#39;: &quot;T&#39;IL+&quot;, &#39;fp2003/fp2003.1.00.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2003/fp2003.6.02.smp&#39;: &#39;T&quot;AK &#39;AR&#39;, &#39;fp2003/fp2003.1.08.smp&#39;: &quot;N&#39;U:&quot;, &#39;fp2003/fp2003.1.01.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2003/fp2003.8.04.smp&#39;: &quot;T&#39;AK&quot;, &#39;fp2003/fp2003.6.01.smp&#39;: &quot;V&#39;A:R+&quot;, &#39;fp2003/fp2003.1.03.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2003/fp2003.1.02.smp&#39;: &quot;T&#39;IL+&quot;, &#39;fp2003/fp2003.6.00.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2004/fp2004.6.05.smp&#39;: &quot;F&#39;INS&quot;, &#39;fp2004/fp2004.6.04.smp&#39;: &#39;V&quot;ILK &#39;A&#39;, &#39;fp2004/fp2004.7.00.smp&#39;: &quot;V&#39;A:R+&quot;, &#39;fp2004/fp2004.6.06.smp&#39;: &quot;V&#39;A:R+&quot;, &#39;fp2004/fp2004.7.01.smp&#39;: &quot;,H&#39;U:R+&quot;, &#39;fp2004/fp2004.6.07.smp&#39;: &quot;T&#39;AK&quot;, &#39;fp2004/fp2004.1.00.smp&#39;: &quot;,H&#39;U:R+&quot;, &#39;fp2004/fp2004.6.02.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2004/fp2004.6.03.smp&#39;: &quot;V&#39;A:+&quot;, &#39;fp2004/fp2004.6.01.smp&#39;: &quot;V&#39;A:R+&quot;, &#39;fp2004/fp2004.6.00.smp&#39;: &#39;H&quot;EJS &#39;AN&#39;, &#39;fp2005/fp2005.5.01.smp&#39;: &quot;T&#39;IL+&quot;, &#39;fp2005/fp2005.2.03.smp&#39;: &quot;FR&#39;]:N+&quot;, &#39;fp2005/fp2005.2.12.smp&#39;: &quot;SL&#39;U:T&quot;, &#39;fp2005/fp2005.2.02.smp&#39;: &#39;ST&quot;]KhyH &#39;]LM&#39;, &#39;fp2005/fp2005.5.00.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2005/fp2005.2.00.smp&#39;: &quot;V&#39;A:R+&quot;, &#39;fp2005/fp2005.2.10.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2005/fp2005.5.02.smp&#39;: &quot;P&#39;]:+&quot;, &#39;fp2005/fp2005.2.09.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2005/fp2005.5.03.smp&#39;: &quot;SL&#39;U:T&quot;, &#39;fp2005/fp2005.2.08.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2005/fp2005.1.04.smp&#39;: &quot;SL&#39;U:T&quot;, &#39;fp2005/fp2005.2.11.smp&#39;: &quot;T&#39;IL+&quot;, &#39;fp2005/fp2005.2.01.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2005/fp2005.2.04.smp&#39;: &quot;FR&#39;E:DA&quot;, &#39;fp2005/fp2005.1.01.smp&#39;: &quot;FR&#39;]:N+&quot;, &#39;fp2005/fp2005.1.00.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2005/fp2005.2.05.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2005/fp2005.1.02.smp&#39;: &quot;P&#39;]:+&quot;, &#39;fp2005/fp2005.2.07.smp&#39;: &quot;J&#39;A:+&quot;, &#39;fp2005/fp2005.2.06.smp&#39;: &quot;&#39;EFTER+&quot;, &#39;fp2005/fp2005.1.03.smp&#39;: &quot;P&#39;]:+&quot;, &#39;fp2024/fp2024.5.00.smp&#39;: &quot;FR&#39;]:N+&quot;, } if not smp in LINES: return False return line.startswith(LINES[smp]) mixfiles = [] for mixfile in WAXHOLM_PATH.glob(&quot;*/*.mix&quot;): current = {} current[&quot;stem&quot;] = mixfile.stem with open(mixfile) as infile: last = &#39;&#39; for line in infile.readlines(): if skippable(line): continue elif line.startswith(&quot;Waxholm dialog.&quot;): SCENES = &quot;/scenes/&quot; scene_start = line.find(SCENES) smp = line[scene_start+len(SCENES):].strip() current[&quot;smp&quot;] = smp elif line.startswith(&quot;PHONEME:&quot;): current[&quot;phoneme&quot;] = line[9:].strip() last = &quot;phoneme&quot; elif line.startswith(&quot;Labels:&quot;): current[&quot;labels&quot;] = line[7:].strip() last = &quot;labels&quot; elif line.startswith(&quot;TEXT:&quot;): current[&quot;text&quot;] = line[5:].strip() last = &quot;text&quot; elif line_kludge(current[&quot;smp&quot;], line): current[&quot;phoneme&quot;] = line.strip() last = &quot;phoneme&quot; elif line.startswith(&quot;FR &quot;): continue else: if last == &quot;&quot;: print(smp, line) current[last] = &quot; &quot;.join([current[last], line.strip()]).strip() for key in [&quot;text&quot;, &quot;phoneme&quot;, &quot;labels&quot;]: if not &quot;phoneme&quot; in current: current[&quot;phoneme&quot;] = &quot;&quot; else: current[key] = fix_text(current[key]) mixfiles.append(current) . import json with open(&quot;/tmp/waxholm_raw_lexicon.json&quot;, &quot;w&quot;) as outf: json.dump(mixfiles, outf) . maybes = {} for entry in mixfiles: if entry[&quot;phoneme&quot;] == &quot;&quot;: maybe_ph = entry[&quot;text&quot;].split(&quot;.&quot;) maybe_first = maybe_ph[1].strip().split(&quot; &quot;)[0] maybes[entry[&quot;smp&quot;]] = maybe_first . with open(&quot;/tmp/waxholm_raw_lexicon.json&quot;) as inf: data = json.load(inf) . for item in data: item[&quot;stem&quot;] = item[&quot;stem&quot;].replace(&quot;.smp&quot;, &quot;&quot;) if item[&quot;phoneme&quot;] == &quot;&quot;: del item[&quot;phoneme&quot;] item[&quot;labels_original&quot;] = item[&quot;labels&quot;] labels = item[&quot;labels&quot;].split(&quot; &quot;) new_labels = [lbl for lbl in labels if lbl != &quot;p:&quot;] item[&quot;labels&quot;] = &quot; &quot;.join(new_labels) . with open(&quot;/tmp/waxholm_raw_lexicon.json&quot;, &quot;w&quot;) as outf: json.dump(data, outf) .",
            "url": "https://jimregan.github.io/notes/swedish/waxholm/2023/10/17/waxholm-kludge.html",
            "relUrl": "/swedish/waxholm/2023/10/17/waxholm-kludge.html",
            "date": " • Oct 17, 2023"
        }
        
    
  
    
        ,"post24": {
            "title": "Interesting links, 17/10/2023",
            "content": "NabuCasa/voice-datasets . espnet/owsm_v3 — OSWM v3 model for ESPnet. . basiralab/IMANGraphNet — Non-isomorphic Inter-modality Graph Alignment and Synthesis for Holistic Brain Mapping . eth-sri/astarix — AStarix: Fast and Optimal Sequence-to-Graph Aligner . IDEA-Research/GroundingDINO — Official implementation of the paper “Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection” . YODAS - 420k hours of speech . neurodata/goat — A paper (in progress) on graph matching via optimal transport. On arxiv at https://arxiv.org/abs/2111.05366 . Quechua dialectal recordings . . (Znachor)[https://pl.wikisource.org/wiki/Znachor_(Do%C5%82%C4%99ga-Mostowicz,_1938)], Wolne Lektury . British phonetic transcriptions . Charles Joughin was the chief baker on the Titanic and one of its most unlikely survivors. He was interrogated by the British Titanic inquiry, which was tasked with finding out how the Titanic had sunk. Below is his interrogation by Mr. Cotter:&quot;What did you do with the children… pic.twitter.com/OUSOhFW8oh . &mdash; Historic Vids (@historyinmemes) November 12, 2023",
            "url": "https://jimregan.github.io/notes/links/2023/10/17/misc-links.html",
            "relUrl": "/links/2023/10/17/misc-links.html",
            "date": " • Oct 17, 2023"
        }
        
    
  
    
        ,"post25": {
            "title": "Swedish pronunciation comparison",
            "content": "from pathlib import Path BASE = Path(&quot;/Users/joregan/Playing&quot;) TSV_DIR = BASE / &quot;wikipron&quot;/ &quot;data&quot; / &quot;scrape&quot; / &quot;tsv&quot; BROAD = TSV_DIR / &quot;swe_latn_broad.tsv&quot; NARROW = TSV_DIR / &quot;swe_latn_narrow.tsv&quot; . def clean_pron(word): word = word.replace(&quot;²&quot;, &quot;&quot;) word = word.replace(&quot;¹&quot;, &quot;&quot;) word = word.replace(&quot;‿&quot;, &quot;&quot;) return word . def read_tsv(filename): wordlist = {} with open(filename) as infile: for line in infile.readlines(): line = line.strip() if &quot; t&quot; in line: word, pron = line.split(&quot; t&quot;) else: parts = line.split() word = line[0] pron = &quot; &quot;.join(line[1:]) if not word in wordlist: wordlist[word] = [] wordlist[word].append(clean_pron(pron.replace(&quot; &quot;, &quot;&quot;))) return wordlist . broad = read_tsv(str(BROAD)) narrow = read_tsv(str(NARROW)) . def check_exact(word, pron): isbroad = False isnarrow = False mbroad = &quot;&quot; mnarrow = &quot;&quot; if word in broad: for pp in broad[word]: if pron == pp: isbroad = True mbroad = pp if word in narrow: for pp in narrow[word]: if pron == pp: isnarrow = True mnarrow = pp outword = &quot;&quot; label = &quot;&quot; if isbroad and isnarrow: if mbroad == mnarrow: outword = mbroad label = &quot;broad&quot; else: outword = f&quot;/{mbroad}/ [{mnarrow}]&quot; label = &quot;both&quot; elif isbroad: outword = mbroad label = &quot;broad&quot; elif isnarrow: outword = mnarrow label = &quot;narrow&quot; return outword, label with open(&quot;/tmp/all-sort-uniq&quot;) as uniq: for line in uniq.readlines(): count, word, pron = line.strip().split() word = word.lower() pron, label = check_exact(word, pron) if pron != &quot;&quot;: print(f&quot;{count} t{word} t{pron} t{label}&quot;) . 2651 å oː broad 23 å ɔ broad 3 ä ɛ broad 69 ä ɛː broad 1 åda oːda broad 1 adhd ɑːdeːhoːdeː broad 54 advokat advʊkɑːt broad 360 affär afæːr narrow 1 affär afɛːr broad 14 afton aftɔn broad 887 äga ɛːɡa broad 2 agna aŋna broad 408 agneta aŋneːta broad 1 aktuell aktɵɛl broad 1016 akut akʉːt broad 170 ål oːl broad 95 al ɑːl broad 110 åland oːland broad 6 albert albæʈ broad 17 albin albɪn broad 3 alert alæʈ broad 4 alfabet alfabeːt broad 236 alkohol alkʊhoːl broad 78632 alla ala broad 49 allihop alɪhuːp broad 143 allihopa alɪhuːpa broad 19 alltmer altmeːr broad 1961 alltså altsɔ broad 2 allvarlig alvɑːrlɪɡ broad 6 älska ɛlska broad 7 älta ɛlta broad 1 aluminium alɵmiːnɪɵm broad 1 älv ɛlv broad 1 älva ɛlva broad 461 amanda amanda broad 40 amerika ameːrɪka broad 20 amma ama broad 118 ana ɑːna broad 5 and and broad 53 ända ɛnda broad 537 ändå ɛndoː broad 6 ändå ɛndɔ broad 4 andlig andlɪɡ broad 68478 andra andra broad 7 andré andreː broad 282 ange anjeː broad 6 anka aŋka broad 2276 anna ana broad 34 annons anɔns broad 9 ännu ɛnɵ broad 52 ännu ɛnʉː broad 10 anomali anʊmaliː broad 3 ansat ansat broad 50 ansatt ansat broad 351 anspråk ansproːk broad 265 ansvarig ansvɑːrɪɡ broad 1 antimon antɪmuːn broad 68 antyda antyːda broad 5 apa ɑːpa broad 414 apotek apʊteːk broad 6 april apriːl broad 1348 april aprɪl broad 160398 är æːr broad 5098 är eːr broad 44026 år oːr broad 549 är ɛːr broad 180 ära æːra broad 10 åra oːra broad 208 äran æːran narrow 24 arbetslös arbeːtsløːs broad 90 arg arj broad 6 argt arjt broad 73 arkiv arkiːv broad 3 ärlig æːɭɪɡ broad 1 årlig oːɭɪɡ broad 4 arrangemang aranɧemaŋ broad 12 arrangera aranɧeːra broad 33 arton ɑːrtɔn broad 249 arv arv broad 15 ås oːs broad 22 as ɑːs broad 817 åsikt oːsɪkt broad 1542 åstadkomma oːstakɔma broad 13848 åt oːt broad 12 ät ɛːt broad 565 äta ɛːta broad 1161018 att at broad 1338 att ɔ broad 160 attack atak broad 1783 åttio ɔtɪ broad 14 åttio ɔtɪʊ broad 221 attityd atɪtyːd broad 305332 av ɑːv broad 92 avbrott ɑːvbrɔt broad 166 avgå ɑːvɡoː broad 53 avgång ɑːvɡɔŋ broad 4 avgjord ɑːvjuːɖ narrow 1218 avgöra ɑːvjœ̞ːra narrow 1 avi aviː broad 43 avled ɑːvleːd broad 13 avsked ɑːvɧeːd broad 10 avsky ɑːvɧyː broad 2007 avsluta ɑːvslʉːta broad 1 axel aksɛl broad 36 ba bɑː broad 218 bad bɑːd broad 4008 båda boːda broad 49 bada bɑːda broad 29860 både boːde broad 3 bagage baɡɑːɧ broad 1 bajsa bajsa broad 122 bak bɑːk broad 3 bål boːl broad 214 bana bɑːna broad 6 banan banɑːn broad 282 banan bɑːnan broad 234 band band broad 7 bår boːr broad 137 bar bɑːr broad 8 bär bɛːr broad 54 bara ba broad 41290 bara bɑːra broad 19 barn bɑːrn broad 19152 barn bɑːɳ narrow 58 barnmorska bɑːɳmʊʂka narrow 66 bärs bæːʂ narrow 393 bas bɑːs broad 2 basta basta broad 2 bea beːa broad 78 bearbeta beːarbeːta broad 491 ben beːn broad 5 bert bæʈ broad 302 bi biː broad 1836 bil biːl broad 34 bilist bɪlɪst broad 40 bill bɪl broad 1 biologi bɪʊlʊɡiː broad 7 birgitta bɪrɡɪta broad 999 bit biːt broad 6 bit bɪt broad 2 bits biːts broad 4 bits bɪts broad 170 bjöd bjøːd broad 713 björn bjœ̞ːɳ narrow 428 bjuda bjʉːda broad 217 blå bloː broad 30 blad blɑːd broad 9 blåljus bloːjʉːs broad 21 blåst bloːst broad 1 blåst blɔst broad 5511 blev bleːv broad 24954 bli bliː broad 7 blida bliːda broad 104 block blɔk broad 91 blod bluːd broad 1 blodröd bluːdrøːd broad 18 blomma blʊma broad 76 bly blyː broad 5 blyg blyːɡ broad 2636 bo buː broad 31 bodil buːdɪl broad 2 bög bøːɡ broad 323 bok buːk broad 112 boka buːka broad 15 bokstav buːkstɑːv broad 4 bokstav bʊkstɑːv broad 15 bor boːr broad 4085 bor buːr broad 3 böra bœ̞ra broad 1132 bord buːɖ broad 2260 borde buːɖə broad 6 börs bɵʂ narrow 1 börs bœ̞ʂ narrow 2050 bostad buːstɑːd broad 171 bot buːt broad 6 bot bɔt broad 74 bota buːta broad 7 botar buːtar broad 4 bov buːv broad 45107 bra brɑː broad 119 brand brand broad 13 brasklapp brasklap broad 9 bre breː broad 735 brev breːv broad 57 bris briːs broad 111 bro bruː broad 43 bröd brøːd broad 89 bron bruːn broad 1 brons brɔns broad 44 bror bruːr broad 1 bros bruːs broad 3 broschyr brʊɧyːr broad 238 bröt brøːt broad 6 brun brʉːn broad 3 brus brʉːs broad 1 bryggd brʏɡd broad 81 brytning bryːtnɪŋ broad 14 bu bʉː broad 15 bur bʉːr broad 12 bus bʉːs broad 1 busig bʉːsɪɡ broad 299 buss bɵs broad 1 byrå byːrɔ broad 1 byrå bʏroː broad 1 c k broad 5 c s broad 353 c seː broad 20 carina kariːna broad 1 carl kɑːl narrow 1 carl kɑːrl broad 2 champagne ɧampanj broad 380 chans ɕans broad 1219 chans ɧans broad 266 chans ɕaŋs broad 88 chans ɧaŋs broad 1 charm ɧarm broad 225 chef ɧeːf broad 175 chef ɧɛːf broad 7 chips ɕɪps broad 6 choklad ɧʊklɑːd broad 152245 då doː broad 2243 dag dɑːɡ broad 1994 dags daks broad 11 dags dɑːɡs broad 294 dålig doːlɪɡ broad 35 dam dɑːm broad 175 damm dam broad 245 dan dɑːn broad 1611 danmark danmark broad 139 dansk dansk broad 667 danska danska broad 105 där dɛːr broad 96 dator dɑːtɔr broad 15 dator dɑːtʊr broad 51164 de deː broad 369 de diː broad 51 de dɪ broad 129938 de dɔm broad 1 deg deːɡ broad 1594 dela deːla broad 20902 dem dɔm broad 1 designa dɪsajna broad 5838 dessutom desʉːtɔm broad 582874 det deː broad 2897 det deːt broad 499 det də broad 3 det dət broad 91 det dɛː broad 7 dig dɛj broad 2965 diskussion dɪskɵɧuːn broad 424 djup jʉːp broad 1145 djupt jʉːpt broad 1836 djur jʉːr broad 389 dö døː broad 489 död døːd broad 512 döda døːda broad 177 dog duːɡ broad 58 doktor dɔktɔr broad 247 dölja dœlja broad 3 dom doːm broad 96 dom dʊm broad 61 dos duːs broad 3429 dra drɑː broad 4 dragspel drɑːɡspeːl broad 3 dras dras broad 642 dras drɑːs broad 4766 driva driːva broad 227 drivkraft driːvkraft broad 11 drog droːɡ broad 431 drog druːɡ broad 70 drogs druːɡs broad 3 drös drøːs broad 98 dryg dryːɡ broad 162 du dɵ broad 17544 du dʉː broad 2 duk dʉːk broad 1 dumbom dɵmbʊm broad 1 dun dʉːn broad 1 duscha dɵɧa broad 4 dussin dɵsɪn broad 325 dyr dyːr broad 1215 e eː broad 3 e ɛ broad 5 e ɛː broad 20 ed eːd broad 7 edvin eːdvɪn broad 1 efor efoːr broad 678 ek eːk broad 78 eko eːkʊ broad 2639 el eːl broad 34 elak eːlak broad 2 elak eːlɑːk broad 1 eldar ɛldar broad 205 elva ɛlva broad 1788 en eːn broad 12 enda ɛnda broad 2 enfaldig eːnfaldɪɡ broad 262 engagera aŋɡaɧeːra broad 26 engelska eŋelska broad 60 enhetlig eːnheːtlɪɡ broad 11 ensamhet eːnsamheːt broad 155 entré antreː broad 41 entré aŋtreː broad 1 entusiasm antɵsɪasm broad 5291 er eːr broad 1774 era eːra broad 40 erinra eːrɪnra broad 502 erkänna eːrɕɛna broad 83 erkänt eːrɕɛnt broad 2 ett ɛt broad 1069 eva eːva broad 77991 få foː broad 1 fä fɛː broad 1 fäbod fɛːbuːd broad 80 fabrik fabriːk broad 38 fågel foːɡəl broad 161 falsk falsk broad 34859 får foːr broad 607 far fɑːr broad 3 farlig fɑːrlɪɡ broad 1 farlig fɑːɭɪɡ narrow 1 fars fɑːrs broad 14 fars fɑːʂ narrow 2 farväl farvɛːl broad 5 farväl fɑːrvɛːl broad 1 fatabur fɑːtabʉːr broad 533 fåtal foːtɑːl broad 3 fåtölj fʊtœlj broad 52 fattig fatɪɡ broad 1 fena feːna broad 20 fet feːt broad 17 fia fiːa broad 21 figur fɪɡʉːr broad 6 fik fiːk broad 84 fika fiːka broad 2 fikarast fiːkarast broad 21 fiktiv fɪktiːv narrow 27 fil fiːl broad 10 filippa fɪlɪpa broad 1 filmjölk fiːlmjœlk broad 12 filosofisk fɪlʊsoːfɪsk broad 3 fimpa fɪmpa broad 275 fin fiːn broad 5 final fɪnɑːl broad 2096 finland fɪnland broad 926 finna fɪna broad 730 finska fɪnska broad 481 fisk fɪsk broad 1 fjärd fjæːɖ broad 26 fjol fjuːl broad 2 fjord fjoːɖ narrow 3479 fjorton fjuːʈɔn broad 198 fjorton fjʊʈɔn broad 5 flå floː broad 6 flår floːr broad 972 flickor flɪkʊr broad 10 flod fluːd broad 8 flodvåg fluːdvoːɡ broad 1 flörta flɵʈa narrow 5 flummig flɵmɪɡ broad 8 flygskam flyːɡskam broad 2 flyktig flʏktɪɡ broad 32 flyta flyːta broad 1 focka fɔka broad 175 föda føːda broad 5 folkmusik fɔlkmɵsiːk broad 4 folköl fɔlkøːl broad 7 för føːr broad 34 förlåt fœ̞ɭoːt narrow 142 förstå fœ̞ʂtoː narrow 3 fort fɔʈ broad 321 fort fʊʈ broad 15 förvärra fœ̞rværa broad 18 förvärras fœ̞rværas broad 2 fosfor fɔsfɔr broad 353 fot fuːt broad 47 fotboll fuːtbɔl broad 2 fotnot fuːtnuːt broad 40088 fråga froːɡa broad 16 frakt frakt broad 19990 fram fram broad 60991 från froːn broad 209 från frɔn broad 42 fransk fransk broad 223 franska franska broad 318 frånvaro froːnvɑːrʊ broad 2080 fred freːd broad 237 fredag freːda broad 5 fredag freːdɑːɡ broad 2761 fri friː broad 121 frid friːd broad 2740 frihet friːheːt broad 80 fritis friːtɪs broad 19 frö frøː broad 67 fröjd frœjd broad 20 frös frøːs broad 8036 fru frʉː broad 138 frukt frɵkt broad 7 frys fryːs broad 11 ful fʉːl broad 1698 full fɵl broad 4028 fungera fɵŋɡeːra broad 214 funka fɵŋka broad 495 funktion fɵŋkɧuːn broad 5 fur fʉːr broad 6 fusion fɵɧuːn broad 751 fusk fɵsk broad 8 fy fyː broad 20 fynd fʏnd broad 4 fyr fyːr broad 14348 fyra fyːra broad 1 fyrtio fœrtɪ broad 13 g j broad 9 g ɡ broad 51 g ɡeː broad 31175 gå ɡoː broad 60 gagn ɡaŋn narrow 10695 gång ɡɔŋ broad 8 gången ɡɔŋen broad 3 garage ɡarɑːɧ broad 15 gås ɡoːs broad 353 gas ɡɑːs broad 144 gata ɡɑːta broad 8393 gått ɡɔt broad 2 gatukök ɡɑːtɵɕøːk narrow 2529 gav ɡɑːv broad 19633 ge jeː broad 1 gem ɡeːm broad 19 gen jeːn broad 14 genom jeːnoːm broad 21163 genom jeːnɔm broad 9658 ger jeːr broad 1 gert jæʈ broad 9 get jeːt broad 5735 gick jɪk broad 2 gir jiːr broad 10 gitarr jɪtar broad 8 giva jiːva broad 16222 gjort jʊʈ broad 3 gjuta jʉːta broad 3918 glad ɡlɑːd broad 50 glas ɡlɑːs broad 20 glashus ɡlɑːshʉːs broad 21 glass ɡlas broad 44 god ɡuː broad 7068 god ɡuːd broad 120 golv ɡɔlv broad 6 göra jøːra broad 1 gött jœt broad 4312 gott ɡɔt broad 16 gött ɡœt broad 16 gran ɡrɑːn broad 9 gråsäl ɡroːsɛːl broad 2 gråt ɡroːt broad 19 grät ɡrɛːt broad 1 gråtrut ɡroːtrʉːt broad 61 grattis ɡratɪs broad 37 grav ɡrɑːv broad 1 gravitation ɡravɪtaɧuːn broad 21 grej ɡrɛj broad 266 grekland ɡreːkland broad 21 grep ɡreːp broad 1 grina ɡriːna broad 2 groda ɡruːda broad 1105 grön ɡrøːn broad 7 gröt ɡrøːt broad 661 grov ɡruːv broad 7960 grund ɡrɵnd broad 6 grym ɡrʏm broad 1 grymta ɡrʏmta broad 16 gryning ɡryːnɪŋ broad 4 gryta ɡryːta broad 82 gud ɡʉːd broad 28 gul ɡʉːl broad 132 gula ɡʉːla broad 138 guld ɡɵld broad 8 gym jʏm broad 2 gymma jʏma broad 69 ha ha broad 63938 ha hɑː broad 12787 haft haft broad 20 håg hoːɡ broad 35 haj haj broad 2 häl hɛːl broad 1 håla hoːla broad 23 hall hal broad 16 hallå haloː broad 1 hallon halɔn broad 1046 halv halv broad 7 halvlek halvleːk broad 8 håna hoːna broad 4993 hand hand broad 29 handikapp handɪkap broad 2257 hans hɑːns broad 192389 här hæːr broad 38 hår hoːr broad 178728 har hɑːr broad 5 hara hɑːra broad 505 hård hoːɖ narrow 4003 hårt hoːʈ broad 495 hat hɑːt broad 32 hata hɑːta broad 222 hatt hat broad 1 håv hoːv broad 608 hav hɑːv broad 4588 hel heːl broad 14 helig heːlɪɡ broad 8 hen heːn broad 128 het heːt broad 230 heta heːta broad 7088 hitta hɪta broad 16 hjälm jɛlm broad 2761 hjälp jɛlp broad 2 hjärna jɛːɳa broad 34 hjul jʉːl broad 12 hö høː broad 7579 hög høːɡ broad 5429 höga høːɡa broad 25 högljudd høːɡjɵd broad 58 högljutt høːɡjɵt broad 5 högtid høːɡtiːd broad 1 hök høːk broad 20 hon huːn broad 5873 hon hʊn broad 2 höna høːna broad 8 honung hoːnɵŋ broad 323 hoppa hɔpa broad 1 hor huːr broad 6 höra høːra broad 5475 höra hœ̞ːra narrow 8 hörsel hɵʂəl narrow 6 hörsel hœ̞ʂəl narrow 101 hos huːs broad 6183 hos hʊs broad 998 höst hœst broad 1260 höstas hœstas broad 3213 hot huːt broad 9 hov hoːv broad 1 hov huːv broad 14 hud hʉːd broad 108 hund hɵnd broad 6470 hundra hɵndra broad 5 hungrig hɵŋrɪɡ broad 42443 hur hʉːr broad 1251 hus hʉːs broad 47 husdjur hʉːsjʉːr broad 52 huvud hʉːvɵd broad 13 hygglig hʏɡlɪɡ broad 746256 i iː broad 8876 i ɪ broad 754 idrott iːdrɔt broad 5909 igenom ɪjeːnɔm broad 217 ihjäl ɪjɛːl broad 1282 ihop ɪhuːp broad 12 illusion ɪlɵɧuːn broad 25516 in ɪn broad 9100 inga ɪŋa broad 54 inger ɪnjeːr broad 26 inn ɪn broad 9031 innan ɪnan broad 17 insjukna ɪnɧʉːkna broad 119 instruktion ɪnstrɵkɧuːn broad 31 inte ɪntɛ broad 113 intyg ɪntyːɡ broad 122 irland ɪrland broad 2 irra ɪra broad 234 is iːs broad 1 israel ɪsraeːl broad 2 ivar iːvar broad 516 j j broad 13 j jiː broad 415 ja ja broad 51972 ja jɑː broad 22 jacka jaka broad 5921 jag jɑːɡ broad 486 jaga jɑːɡa broad 2 jak jɑːk broad 1 jam jɑːm broad 1246 jan jɑːn narrow 493 jansson jɑːnsɔn narrow 389 januari janɵɑːrɪ broad 1 japan japɑːn broad 249 japan jɑːpan broad 1 japansk japɑːnsk broad 18 japanska japɑːnska broad 22 järn jæːɳ narrow 9 järv jærv broad 1 jason jɑːsɔn broad 12 jävig jɛːvɪɡ broad 6 jenny jɛnʏ broad 1837 jo juː broad 655 johan jʊan broad 341 johanna jʊhana broad 1 joint jɔɪnt broad 949 jonas juːnas broad 202 jönköping jœnɕøːpɪŋ broad 1445 jonsson jʊnsɔn broad 306 jord juːɖ narrow 3 jota juːta broad 11 journal ɧʊɳɑːl broad 10199 ju jɵ broad 115040 ju jʉː broad 895 jul jʉːl broad 1367 juli jʉːlɪ broad 2061 juni jʉːnɪ broad 1 jury jɵrʏ broad 9 k k broad 65 k koː broad 38 kå koː broad 6 kadmium kadmɪɵm broad 48 kafé kafeː broad 2 kajak kajɑːk broad 8 käka ɕɛːka broad 21 kål koːl broad 3 kal kɑːl broad 15 kalk kalk broad 87 kall kal broad 250 källa ɕɛla broad 20 kam kam broad 111 känd ɕɛnd broad 12 känga ɕɛŋa broad 7 kanot kanuːt broad 4 kanske kanʂɛ narrow 542 känsla ɕɛnsla broad 362 känt ɕɛnt broad 38 kaos kaʊs broad 19 kaos kɑːʊs broad 16 kår koːr broad 17 kar kɑːr broad 41 kär ɕæːr narrow 625 karina kariːna broad 150 karl kɑːl narrow 4 karl kɑːr broad 1 kärlek ɕæːɭeːk narrow 254 karolina karʊliːna broad 1 karta kɑːrta broad 1 kåta koːta broad 673 katarina katariːna broad 11 katrina katriːna broad 103 kedja ɕeːdja broad 8 kedja ɕɛːdja broad 169 kerstin ɕæʂtɪn broad 8 kidnappa kiːdnapa broad 39 kika ɕiːka broad 24 kil ɕiːl broad 247 kilo ɕiːlʊ broad 2173 kina ɕiːna broad 5 kind ɕɪnd broad 2 kines ɕɪneːs broad 34 kinesisk ɕɪneːsɪsk broad 337 kinesiska ɕɪneːsɪska broad 8 kiosk ɕɔsk broad 8 kissa kɪsa broad 6 kista ɕɪsta broad 119 kjell ɕɛl broad 2 kjol ɕuːl broad 3 klå kloː broad 1 kladdkaka kladkɑːka broad 11 klandra klandra broad 5 klår kloːr broad 1214 klar klɑːr broad 235 klarhet klɑːrheːt broad 13 klinga klɪŋa broad 14 klon kluːn broad 1 klor kloːr broad 26 klor kluːr broad 90 knä knɛː broad 1 knåda knoːda broad 239 knapp knap broad 39 knark knark broad 2 knarka knarka broad 45 kniv kniːv broad 8 knubbsäl knɵbsɛːl broad 23 knut knʉːt broad 233 kö køː broad 43 ko kuː broad 9 köa køːa broad 8 kobolt koːbɔlt broad 1 kobolt kuːbɔlt broad 31 kod koːd broad 2 kofta kɔfta broad 83 kök ɕøːk broad 488 kol koːl broad 11 köl ɕøːl broad 435 kolla kɔla broad 5890 kom kɔm broad 33394 komma kɔma broad 66 kompis kɔmpɪs broad 124 kön køːn broad 7 kon kuːn broad 624 kön ɕøːn broad 6 kondition kɔndɪɧuːn broad 1429 konflikt kɔnflɪkt broad 3 konspiration kɔnspɪraɧuːn broad 96 konstruktion kɔnstrɵkɧuːn broad 474 konsumtion kɔnsɵmɧuːn broad 169 kontra kɔntra broad 370 köp ɕøːp broad 2947 köpa ɕøːpa broad 39 kopia kʊpiːa broad 103 kopp kɔp broad 43 koppar kɔpar broad 1184 koppling kɔplɪŋ broad 90 kor kuːr broad 1754 köra ɕœ̞ːra broad 14 korea kʊreːa broad 37 korg kɔrj broad 21 kort kɔrt broad 1 kort kʊrt broad 72 kost kɔst broad 340 kraftfull kraftfɵl broad 4 kran krɑːn broad 2 krans krans broad 1825 krig kriːɡ broad 6 kristianstad krɪɧansta broad 901 kristina krɪstiːna broad 9 krita kriːta broad 16 krog kruːɡ broad 3 kröka krøːka broad 48 krokben kruːkbeːn broad 11 krom kroːm broad 844 krona kruːna broad 2502 kronor kruːnʊr broad 1 kruka krʉːka broad 58 krut krʉːt broad 549 kuba kʉːba broad 302 kul kʉːl broad 12 kull kɵl broad 2 kulör kɵløːr broad 6469 kunde kɵndə broad 22 kung kɵŋ broad 2 kur kʉːr broad 1 kurr kɵr broad 14 kusin kɵsiːn broad 3 kut kʉːt broad 2 kuta kʉːta broad 225 kvalitet kvalɪteː broad 1 kvälja kvɛlja broad 8238 kvar kvɑːr broad 4 kvist kvɪst broad 35 kyckling ɕʏklɪŋ broad 41 kyrka ɕʏrka broad 2 kyskhet ɕʏskheːt broad 4 kyssa ɕʏsa broad 3 la la broad 384 la lɑː broad 18 läcka lɛka broad 4170 låg loːɡ broad 3349 lag lɑːɡ broad 9053 lägga lɛɡa broad 158 lagom lɑːɡɔm broad 4578 lagt lakt broad 370 lagts lakts broad 2 laja laja broad 2011 län lɛːn broad 2089 land lan broad 16491 land land broad 54 längs lɛŋs broad 112 långsam lɔŋsam broad 7782 långt lɔŋt broad 38 långvarig lɔŋvɑːrɪɡ broad 5 lär lɛːr broad 2598 lära læːra broad 4 larv larv broad 230 läs lɛːs broad 4799 läsa lɛːsa broad 5191 låt loːt broad 4290 låta loːta broad 161 lätt lɛt broad 3 lavskrika lɑːvskriːka broad 3 lax laks broad 30 le leː broad 1 leddjur leːdjʉːr broad 23 ledig leːdɪɡ broad 14 ledsna lɛsna broad 1 legitim lɛɡɪtiːm broad 10 leif lɛjf broad 12 lev leːv broad 6556 leva leːva broad 103 lik liːk broad 299 liksom liːksɔm broad 8412 liksom lɪksɔm broad 68 lima liːma broad 9 lin liːn broad 163 lina liːna broad 31 lindgren lɪŋɡreːn broad 8 lingon lɪŋɔn broad 7 linnéa lɪneːa broad 109 lisa liːsa broad 3 lisas liːsas broad 1535 lita liːta broad 1 liten liːtɛn broad 7247 liv liːv broad 106 ljud jʉːd broad 72 ljuga jʉːɡa broad 12 ljungby jɵŋbʏ broad 530 ljus jʉːs broad 34 lo luː broad 1 lob lɔb broad 35 lodjur luːjʉːr broad 1 loge loːɧ broad 59 lögn lœŋn broad 51 lök løːk broad 2263 lön løːn broad 165 london lɔndɔn broad 113 löpa løːpa broad 101 lös løːs broad 6877 lösa løːsa broad 742 lov loːv broad 95 lov luːv broad 23 lucia lɵsiːa broad 320 lugn lɵŋn broad 12 lunch lɵnɧ broad 590 lund lɵnd broad 226 lundgren lɵndɡreːn broad 5 lyckta lʏkta broad 1 lydnad lyːdnad broad 38 lykta lʏkta broad 2839 lyssna lʏsna broad 620 må moː broad 25 mack mak broad 12 macka maka broad 1648 magnus maŋnɵs broad 2063 maj maj broad 31 maka mɑːka broad 10 mäkla mɛːkla broad 9008 mål moːl broad 12 mal mɑːl broad 265 måla moːla broad 10 malaria malɑːrɪa broad 1 malen mɑːlən narrow 1 malin maliːn broad 46 mall mal broad 1670 malmö malmøː broad 3 mambo mambuː broad 1 mambo mambʊ broad 211505 man man broad 1 män mɛn broad 7 man mɑːn broad 2004 månad moːnad broad 201 måndag mɔnda broad 1 manen mɑːnən broad 1 manga maŋɡa broad 1 manick manɪk broad 273 margareta marɡareːta broad 2068 maria mariːa broad 6 marika mariːka broad 1583 mark mark broad 91 märklig mærklɪɡ broad 10 mars mars broad 2097 mars maʂ broad 1 masa mɑːsa broad 45 maskin maɧiːn broad 1 massage masɑːɧ broad 2029 mat mɑːt broad 829 mäta mɛːta broad 4 matcha matɕa broad 20 matt mat broad 451 mattias matiːas broad 29307 med meːd broad 1033 med mɛːd broad 536 men meːn broad 551 men mɛn broad 48 meningslös meːnɪŋsløːs broad 58 meningslösa meːnɪŋsløːsa broad 1 mens meːns broad 55873 mer meːr broad 1 mes meːs broad 77 middag mɪda broad 3 middag mɪdɑːɡ broad 15 midsommar miːdsɔmar broad 2 midsommar mɪdsɔmar broad 50 midsommar mɪsɔmar broad 94 mig maj broad 11 mig mɛj broad 825 mil miːl broad 234 mildra mɪldra broad 1806 miljard mɪljɑːɖ broad 5749 miljö mɪljøː broad 440 miljon mɪljuːn broad 742 min miːn broad 4832 mina miːna broad 7 mission mɪɧuːn broad 190 mjölk mjœlk broad 2 mö møː broad 138 mod muːd broad 228 möjlig mœjlɪɡ broad 27 moln moːln broad 10 moln mɔln broad 80 mor muːr broad 2 mord muːrd broad 510 mord muːɖ broad 55 mörda mœ̞ːɖa narrow 20 morgnarna moːɳaɳa broad 27 morgon mɔrɡɔn broad 4 mors muːʂ narrow 113 moskva mʊskvɑː broad 20695 mot muːt broad 902 motion mɔtɧuːn broad 12 motion mʊtɧuːn broad 1 muck mɵk broad 2 mula mʉːla broad 85 mun mɵn broad 32 mur mʉːr broad 6 mus mʉːs broad 228 museum mɵseːɵm broad 426 musik mɵsiːk narrow 12 muslim mɵsliːm broad 52 must mɵst broad 90 mynt mʏnt broad 2 mysa myːsa broad 1 mysig myːsɪɡ broad 6 mystisk mʏstɪsk broad 70 myt myːt broad 7569 nå noː broad 38 nä nɛː broad 130 nacka naka broad 1 nafs nafs broad 11352 någon noːɡɔn broad 14022 någon nɔn broad 14330 något noːɡɔt broad 11682 något nɔt broad 4757 några noːɡra broad 78 naiv naiːv broad 12 nål noːl broad 1063 namn namn broad 12 nasa nɑːsa broad 5 näsa nɛːsa broad 13 nåt noːt broad 157 nåt nɔt broad 280 nation natɧuːn broad 12 nationalist natɧʊnalɪst broad 5 nationell natɧʊnɛl broad 2211 nato nɑːtʊ broad 1033 nått nɔt broad 218 ned neːd broad 7 nedladdning neːdladnɪŋ broad 21 nej nɛj broad 9827 ner neːr broad 3 neutral neːɵtrɑːl broad 29275 ni niː broad 32 nigeria nɪɡeːrɪa broad 3372 nio niːʊ broad 17 nittio nɪtɪʊ broad 3474 nitton nɪtɔn broad 18 nja nja broad 22 nja njɑː broad 2 njöt njøːt broad 1 njut njʉːt broad 96 njuta njʉːta broad 142 nödvändig nøːdvɛndɪɡ broad 7 nödvändighet nøːdvɛndɪɡheːt broad 1687 noll nɔl broad 133 nord nuːɖ broad 1 nörd nœ̞ːɖ narrow 17 nordkorea nuːɖkʊreːa broad 655 norska nɔʂka broad 21 nöt nøːt broad 7 not nuːt broad 9 nött nœt broad 98597 nu nʉː broad 11686 ny nyː broad 30162 nya nyːa broad 23 nypa nyːpa broad 1136 nyss nʏs broad 1 nytänkande nyːtɛŋkande broad 12 nyttig nʏtɪɡ broad 1942 o oː broad 199 ö øː broad 194 o uː broad 191 o ɔ broad 62 o ʊ broad 8 ö œ broad 1 obskyr ɔbskyːr broad 16838 och ɔ broad 151 ock ɔk broad 1 offert ʊfæʈ broad 169 öga øːɡa broad 10 ogilla uːjɪla broad 87 oklar uːklɑːr broad 112 öl øːl broad 53 olaglig uːlɑːɡlɪɡ broad 175 olof uːlɔf broad 7 olof uːlɔv broad 37 olycklig uːlʏklɪɡ broad 291260 om ɔm broad 14 öm œm broad 12 ombudsman ɔmbʉːdsman broad 31 omfång ɔmfɔŋ broad 1 omständig ɔmstɛndɪɡ broad 1 omständlig ɔmstɛndlɪɡ broad 1 ömtålig œmtoːlɪɡ broad 100 ön øːn broad 87 onsdag ʊnsda broad 1 öra øːra broad 29 öra œ̞ːra narrow 8 ord uːrd broad 4948 ord uːɖ narrow 1 ordbok uːɖbuːk narrow 399 ordning oːɖnɪŋ narrow 343 orka ɔrka broad 2 orkan ʊrkɑːn broad 1 orm ʊrm broad 22 ös øːs broad 3 osa uːsa broad 1 oscar ɔskar broad 282 oskar ɔskar broad 215 oslo ʊslʊ broad 42914 oss ɔs broad 9 otålig uːtoːlɪɡ broad 50 ovan oːvan broad 13 ovan uːvɑːn broad 9 över øːvær broad 512887 på poː broad 6 paj paj broad 479 paket pakeːt broad 27 parentes paranteːs broad 1 parentes paraŋteːs broad 712 paris pariːs broad 51 päron pæːrɔn broad 438 part pɑːʈ broad 2 påskas pɔskas broad 5 passage pasɑːɧ broad 15 passage pasɑːʂ broad 1 patent patɛnt broad 62 paul poːl broad 1 pax paks broad 35 pedagog pedaɡoːɡ broad 562 pension panɧuːn broad 14 peter petər broad 1 picka pɪka broad 1 pin piːn broad 1 pin pɪn broad 13 pizza pɪtsa broad 13 pjäs pjɛːs broad 11 planta planta broad 929 plocka plɔka broad 29 plundring plɵndrɪŋ broad 4 podd pɔd broad 5 pojk pɔjk broad 490 pojkar pɔjkar broad 28 pojken pɔjkən narrow 1 pokal pʊkɑːl broad 1 pöl pøːl broad 21 pol puːl broad 13021 politik pʊlɪtiːk broad 94 polska poːlska broad 12 polska pɔlska broad 422 post pɔst broad 1 prao prɑːʊ broad 132 prat prɑːt broad 4756 prata prɑːta broad 44 present present broad 1518 princip prɪnsiːp broad 1135 pris priːs broad 11869 problem prʊbleːm broad 20 procent prʊsɛnt broad 2 process prʊsɛs broad 102 prognos prɔɡnoːs broad 6 prosa pruːsa broad 1117 pröva prøːva broad 2 pulka pɵlka broad 181 punkt pɵŋkt broad 9 punktlig pɵŋtlɪɡ broad 1 pussa pɵsa broad 38 rå roː broad 113 rabatt rabat broad 1 rabba raba broad 3277 råd roːd broad 3 räd rɛːd broad 37 radar rɑːdar broad 28 rådjur roːjʉːr broad 22 radon radoːn broad 11 råg roːɡ broad 544 ram rɑːm broad 203 rån roːn broad 5 rand rand broad 1 ränna rɛna broad 67 ras rɑːs broad 2 råtta rɔta broad 5 räv rɛːv broad 9 rävar rɛːvar broad 3 red reːd broad 1153 reform refɔrm broad 1 regn rɛŋn broad 4 regna reŋna broad 43 relation rɛlaɧuːn broad 1 religion rɛlɪjuːn broad 2293 rent reːnt broad 12 rep reːp broad 42 rev reːv broad 162 rik riːk broad 44 ris riːs broad 66 robert roːbæʈ broad 9 rock rɔk broad 220 röd røːd broad 36 rök røːk broad 19 rökfritt røːkfrɪt broad 195 rökning røːknɪŋ broad 10 rom roːm broad 3 rom rɔm broad 4 rom rʊm broad 30 ros ruːs broad 86 rosa roːsa broad 1 rösa røːsa broad 8 rosa ruːsa broad 1274 röst rœst broad 270 rot ruːt broad 1 rova ruːva broad 540 rum rɵm broad 2 russin rɵsɪn broad 56 rygg rʏɡ narrow 2 rysa ryːsa narrow 1339 ryska rʏska broad 373091 så soː broad 16028 sa sɑː broad 1 sabla sɑːbla broad 8 sabotage sabʊtɑːɧ broad 6 saft saft broad 3668 såg soːɡ broad 12106 sagt sakt broad 7548 sak sɑːk broad 184 sakna sɑːkna broad 134 säl sɛːl broad 5 sälarna sæːlaɳa broad 1 saldo saldʊ broad 1 säljare sɛljare broad 4 säll sɛl broad 78 salt salt broad 40 sam sam broad 16 sambo sambuː broad 73 sambo sambʊ broad 242 samling samlɪŋ broad 5443 samt samt broad 2915 samtal samtɑːl broad 42 sån soːn broad 161 säpo sɛːpʊ broad 121 sår soːr broad 839 särskild sæːɧɪld narrow 680 särskild sæːʂɪld narrow 1 särskild sɛːrɧɪld broad 8 sås soːs broad 6 satan sɑːtan broad 25 schack ɧak broad 1 schampo ɧampʊ broad 53 schema ɧeːma broad 47150 se seː broad 7624 sedan seːdan broad 678 sedan sɛn broad 11 seg seːɡ broad 5 segling seːɡlɪŋ broad 1 semla sɛmla broad 555 sen seːn broad 215 sen sɛn broad 1642 sent seːnt broad 42 separation separaɧuːn broad 6 seta sɛːta broad 1 sex sɛks broad 3 sextio sɛkstɪ broad 22 sexton sɛkstɔn broad 1 shopping ɧɔpɪŋ broad 1 show ɧɔv broad 9566 sida siːda broad 43 sig saj broad 797 sig sɛj broad 3312 sikt sɪkt broad 49 sill sɪl broad 84 simma sɪma broad 190 sin siːn broad 2384 sitta sɪta broad 4158 situation sɪtvaɧuːn broad 40 situation sɪtɵaɧuːn broad 2 sjal ɧɑːl broad 55 själ ɧɛːl broad 146 själv ɧɛlv broad 89 självklar ɧɛlvklɑːr broad 251 självklarhet ɧɛlvklɑːrheːt broad 128 sjö ɧøː broad 5 sjökvist ɧøːkvɪst broad 8 sjöman ɧøːman broad 82 sjön ɧœn broad 6364 sju ɧʉː broad 842 sjuk ɧʉːk broad 2030 sjuka ɧʉːka broad 233 sjukdom ɧʉːkdʊm broad 270 sjukhus ɧʉːkhʉːs broad 57 sjukt ɧʉːkt broad 61 sjunga ɧɵŋa broad 1843 sjuttio ɧɵtɪ broad 17 sjuttio ɧɵtɪʊ broad 2433 sjutton ɧɵtɔn broad 203041 ska skɑː broad 7 skåda skoːda broad 5278 skäl ɧɛːl broad 14 skälig ɧɛːlɪɡ broad 820 skall skal broad 23 skam skam broad 11100 skapa skɑːpa broad 364 skär ɧæːr broad 589 skära ɧæːra broad 46 skärpa ɧærpa broad 5729 ske ɧeː broad 10 sked ɧeːd broad 145 sken ɧeːn broad 2 sket ɧeːt broad 35 skev ɧeːv broad 1611 skicka ɧɪka broad 9 skildring ɧɪldrɪŋ broad 511 skilja ɧɪlja broad 3926 skillnad ɧɪlnad broad 1 skina ɧiːna broad 33 skit ɧiːt broad 5 skiva ɧiːva broad 2 skjorta ɧʊʈa narrow 1 skjul ɧʉːl broad 1041 skjuta ɧʉːta broad 22 sko skuː broad 1904 skog skuːɡ narrow 5572 skola skuːla broad 46 sköld ɧœld broad 8 skolka skɔlka broad 8 skolmat skuːlmɑːt broad 66 skön ɧøːn broad 106 sköt ɧøːt broad 298 sköts ɧøːts broad 21 skottland skɔtland broad 2 skraj skraj broad 119 skrämma skrɛma broad 1 skridsko skrɪskʊ broad 7 skrik skriːk broad 781 skriva skriːva broad 2 skrivmaskin skriːvmaɧiːn broad 124 skrivning skriːvnɪŋ broad 98 skrota skruːta broad 8 skruv skrʉːv broad 21 skur skʉːr broad 2 sky ɧyː broad 3254 skydd ɧʏd broad 3 skygg ɧʏɡ broad 37 skylt ɧʏlt broad 15 skymma ɧʏma broad 2 skymning ɧʏmnɪŋ broad 7 skytt ɧʏt broad 2861 slå sloː broad 13 slagsmål slaksmoːl broad 4 släkt slɛkt broad 2 slät slɛːt broad 1 slitvarg sliːtvarj broad 2 slö sløː broad 443 slog sluːɡ broad 16 slogs sluːks broad 88 slogs sluːɡs broad 3 slogs slʊks broad 9 slöjd slœjd broad 83 slösa sløːsa broad 40 slussa slɵsa broad 2288 slut slʉːt broad 5435 små smoː broad 1 smaska smaska broad 3 smed smeːd broad 4 smet smeːt broad 1 smittkurva smɪtkɵrva broad 1 smörgås smœrɡɔs broad 13 smyg smyːɡ broad 1113 snabb snab broad 5356 snabbt snapt broad 12 snål snoːl broad 1 snäppa snɛpa broad 2830 snart snɑːʈ broad 4 sne sneː broad 9 snickra snɪkra broad 111 snö snøː broad 8 sno snuː broad 5 snöa snøːa broad 13 snor snuːr broad 20 snudd snɵd broad 3 snut snʉːt broad 2 snutt snɵt broad 3 so suː broad 756 söder søːdər broad 337 sofia sʊfiːa broad 219 sol suːl broad 108 solna soːlna broad 12 solsken suːlɧeːn broad 537306 som sɔm broad 1 söm sœm broad 1 sommartid sɔmartiːd broad 23 sömn sœmn broad 521 somras sɔmras broad 146 son soːn broad 59 söndag sœnda broad 1 söndag sœndɑːɡ broad 27 soppa sɔpa broad 149 sorg sɔrj broad 1 sortering sʊrteːrɪŋ broad 10 söt søːt broad 16 sot suːt broad 6 sött sœt broad 24 sov soːv broad 142 sova soːva broad 7 spå spoː broad 88 spanska spanska broad 855 spår spoːr broad 924 spara spɑːra broad 1078 spel speːl broad 1441 spela speːla broad 1175 spelar speːlar broad 27 spik spiːk broad 13 spis spiːs broad 1 spjut spjʉːt broad 4 spö spøː broad 82 sport spɔʈ broad 902 språk sproːk broad 1027 sprida spriːda broad 60 sprit spriːt broad 21 spruta sprʉːta broad 1 spy spyː broad 7940 stå stoː broad 28 stab stɑːb broad 884 stad stɑːd broad 15 stadig stɑːdɪɡ broad 360 stål stoːl broad 14 stal stɑːl broad 1 stäpp stɛp broad 1036 stat stɑːt broad 39 station staɧuːn broad 321 statlig stɑːtlɪɡ broad 5 stav stɑːv broad 8 stava stɑːva broad 15 stel steːl broad 532 sten steːn broad 391 stig stiːɡ broad 9 stillhet stɪlheːt broad 7 stjäl ɧɛːl broad 20 stjäla ɧɛːla broad 7 stjälpa ɧɛlpa broad 21 stjärna ɧæːɳa narrow 388 stockholm stɔkhɔlm broad 16503 stöd støːd broad 230 stod stuːd broad 888 stod stuːɡ broad 2 stoft stɔft broad 92 stol stuːl broad 15377 stor stuːr broad 46 storm stɔrm broad 241 större stɵrə narrow 15181 större stœ̞rə narrow 119 störst stɵʂʈ narrow 785 störst stœ̞ʂʈ narrow 416 största stɵʂʈa narrow 6658 största stœ̞ʂʈa narrow 9 störta stœ̞ʈa narrow 22 ström strœm broad 25 strömming strœmɪŋ broad 157 stryka stryːka broad 5 stubb stɵb broad 4 studio stʉːdɪʊ broad 3 studsa stɵtsa broad 26 stulit stʉːlɪt broad 1 substantiv sɵbstantiːv broad 116 succé sɵkseː narrow 26 suck sɵk broad 340 sund sɵnd broad 6 supa sʉːpa broad 26 sur sʉːr broad 27 sura sʉːra broad 674 svag svɑːɡ broad 5 svala svɑːla broad 3 svan svɑːn broad 13 svans svans broad 1445 svår svoːr broad 11813 svar svɑːr broad 4970 svara svɑːra broad 7 svart svart broad 8454 svårt svoːʈ broad 2 svartis svaʈiːs narrow 61 sveg sveːɡ broad 250 svek sveːk broad 47 sven svɛn broad 32571 svenska svɛnska broad 125 svika sviːka broad 1 svit sviːt broad 4 svor svuːr broad 247 syd syːd broad 28 sydkorea syːdkʊreːa broad 5 sydsamiska syːdsɑːmɪska broad 1 sylt sʏlt broad 1 sylta sʏlta broad 1 sylvass syːlvas broad 1 symfoni sʏmfʊniː broad 5 syntes sʏnteːs broad 5 syra syːra broad 1 syrak syːrak broad 3 syssling sʏslɪŋ broad 80 t teː broad 63 tå toː broad 57880 ta tɑː broad 84192 tack tak broad 3 täckt tɛkt broad 1353 tåg toːɡ broad 2474 tag tɑːɡ broad 574 tak tɑːk broad 3695 tala tɑːla broad 70 talang talaŋ broad 19 tall tal broad 22 tand tand broad 23 tända tɛnda broad 4 tango taŋɡʊ broad 4 tant tant broad 19 tår toːr broad 1 tatuera tatɵeːra broad 82 te teː broad 4 teg teːɡ broad 1 telefon telefuːn broad 2 terapeutisk terapeftɪsk broad 7 teve teːveː broad 27493 tid tiːd broad 53 tiden tiːn broad 261 tidning tiːnɪŋ broad 1 tik tiːk broad 1 tikar tiːkar broad 196679 till tɪl broad 449 tillbaka tɪlbɑːka broad 136 tillhandahålla tɪlhandahɔla broad 532 tills tɪls broad 716 tills tɪs broad 184 tillsammans tɪlsamans broad 354 tina tiːna broad 9584 tio tiːʊ broad 71 tisdag tiːsda broad 2 tisdag tiːsdɑːɡ broad 1 tivoli tɪvʊliː broad 13 tjej ɕɛj broad 46 tjock ɕɔk broad 5 tjuga ɕʉːɡa broad 2 tjugo tɕʉːɡʊ broad 9 tjugo ɕɵ broad 3663 tjugo ɕʉːɡɪ broad 18353 tjugo ɕʉːɡʊ broad 12 tjugotredje ɕʉːɡʊtreːdje broad 1 tjur ɕʉːr broad 2 tjuta ɕʉːta broad 5 tjuv ɕʉːv broad 4 tö tøː broad 349 tobak tuːbak broad 5844 tog tuːɡ broad 92 tok tuːk broad 3337 tolv tɔlv broad 1 tom toːm broad 2 tomte tɔmte broad 153 ton tuːn broad 323 ton tɔn broad 158 tor tuːr broad 268 torg tɔrj broad 19 törs tœ̞ʂ narrow 1 törst tœ̞ʂʈ narrow 5 törsta tœ̞ʂʈa narrow 1 törstig tœ̞ʂʈɪɡ narrow 516 total tʊtɑːl broad 167 trä trɛː broad 139 tråd troːd broad 188 träd trɛːd broad 137 träna trɛːna broad 6 trast trast broad 19299 tre treː broad 1 tretal treːtɑːl broad 4 trettio trɛtɪ broad 1 triljon trɪljuːn broad 55 trivas triːvas broad 2804 tro truː broad 151 tron truːn broad 14257 tror truːr broad 8 trosa truːsa broad 2 trumpet trɵmpeːt broad 560 tuff tɵf broad 318 tung tɵŋ broad 1433 tunga tɵŋa broad 1 turban tɵrbɑːn broad 1 tusen tʉːsɛn broad 310 tv teːveː broad 27960 två tvoː broad 406 tvång tvɔŋ broad 1 tvångssvenska tvɔŋssvɛnska broad 2 tvärtom tvæːʈɔm narrow 88 tvivla tviːvla broad 10 ty tyː broad 2741 tycka tʏka broad 54 tyda tyːda broad 4 tyg tyːɡ broad 50 tyngst tʏŋst broad 130 tysk tʏsk broad 480 tyska tʏska broad 1131 tyskland tʏskland broad 44 u ɵ broad 1094 u ʉː broad 2 ugn ɵŋn broad 1070 ulla ɵla broad 342 ulrika ɵlriːka broad 3 ulv ɵlv broad 982 ung ɵŋ broad 2478 ungefär ɵnjefæːr broad 55482 upp ɵp broad 9 uppå ɵpoː broad 4 upprätthålla ɵprɛthɔla broad 1069 uppsala ɵpsɑːla broad 1 uppträdande ɵptrɛːdande broad 14 uppvisning ɵpviːsnɪŋ broad 4624 ur ʉːr broad 81 uran ɵrɑːn broad 1 usch ɵɧ broad 51462 ut ʉːt broad 38641 utan ʉːtan broad 62 utbrott ʉːtbrɔt broad 75 utgång ʉːtɡɔŋ broad 13 utge ʉːtjeː broad 2 utropa ʉːtruːpa broad 129 utslag ʉːtslɑːɡ broad 495 va va broad 2264 va vɑː broad 4 vabba vaba broad 718 vaccin vaksiːn broad 7 väcka vɛka broad 62415 vad vɑː broad 4760 vad vɑːd broad 227 våg voːɡ broad 8267 väg vɛːɡ broad 119 vägra vɛːɡra broad 8 vaj vaj broad 4 vaja vaja broad 174 vakna vɑːkna broad 27 vakta vakta broad 4405 val vɑːl broad 12086 väl vɛːl broad 1 vålnad voːlnad broad 1 vän vɛn broad 132 van vɑːn broad 3 vän vɛːn broad 1 vång vɔŋ broad 2 vänlig vɛnlɪɡ broad 12 vänlig vɛːnlɪɡ broad 288 vann van broad 61 väntan vɛntan broad 21460 vår voːr broad 20404 vara vɑː broad 46808 vara vɑːra broad 4830 varandra varandra broad 279 varann varan broad 625 våras voːras broad 5 värd væːrd narrow 327 värd væːɖ narrow 4979 vård voːɖ broad 10 värd vɛːɖ broad 345 värdera væɖeːra narrow 123 varför vɑːrfœ̞r narrow 554 varg varj broad 3 vargflock varjflɔk broad 1 vargjakt varjjakt broad 2 vargpar varjpɑːr broad 16 vargstam varjstam broad 2512 varit vaʈ broad 24052 varit vɑːrɪt broad 563 varit vɑːʈ broad 1 värld væːrd narrow 1513 värld væːɖ narrow 236 varm varm broad 586 varmt varmt broad 1 värnpliktig væːɳplɪktɪɡ narrow 9 vars vars broad 5 varsågod vaʂɔɡuːd narrow 11 varsågod vɑːʂɔɡuːd narrow 4 vart vart broad 4 vart vɑːrt broad 660 vart vɑːʈ narrow 121 varv varv broad 15 värva værva broad 2 vas vɑːs broad 16 vass vas broad 33 våt voːt broad 1 växthus vɛksthʉːs broad 922 ve veː broad 25 vecka vɛka broad 9 vek veːk broad 2 venus veːnɵs broad 277 verk værk broad 5940 veta veːta broad 507377 vi viː broad 6695 vid viːd broad 38 vikt viːkt broad 105571 vill vɪl broad 184 vin viːn broad 332 vind vɪnd broad 3 vindskydd vɪndɧʏd narrow 71 vintras vɪntras broad 1 vischan vɪɧan broad 404 vision vɪɧuːn broad 1 vismut vɪsmɵt broad 136 vit viːt broad 22 vitryska viːtrʏska broad 1 viv viːv broad 3 vodka vɔdka broad 198 volvo vɔlvʊ broad 11 vred vreːd broad 1 vy vyː broad 13 ystad yːsta broad 6 yvas yːvas broad 1 zink sɪnk broad 111 zon suːn broad .",
            "url": "https://jimregan.github.io/notes/swedish/phonemes/wiktionary/2023/10/10/swedish-comparison-wiktionary.html",
            "relUrl": "/swedish/phonemes/wiktionary/2023/10/10/swedish-comparison-wiktionary.html",
            "date": " • Oct 10, 2023"
        }
        
    
  
    
        ,"post26": {
            "title": "Phonetic rule processing, take 1",
            "content": "!wget https://www.openslr.org/resources/29/lexicon-sv.tgz . --2023-09-13 16:17:26-- https://www.openslr.org/resources/29/lexicon-sv.tgz Resolving www.openslr.org (www.openslr.org)... 46.101.158.64 Connecting to www.openslr.org (www.openslr.org)|46.101.158.64|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 5374148 (5,1M) [application/x-gzip] Saving to: ‘lexicon-sv.tgz’ lexicon-sv.tgz 100%[===================&gt;] 5,12M 9,79MB/s in 0,5s 2023-09-13 16:17:27 (9,79 MB/s) - ‘lexicon-sv.tgz’ saved [5374148/5374148] . !tar zxvf lexicon-sv.tgz . x lexicon.txt . lexicon = {} with open(&quot;lexicon.txt&quot;) as lexf: for line in lexf.readlines(): parts = line.strip().split() word = parts[0] phones = parts[1:] if word[0:1] in &quot;!&lt;&amp;-&quot;: continue if not word in lexicon: lexicon[word] = [] lexicon[word].append(phones) . VOWELS = &quot;2: 9 A: E E*U E: I O U Y a a*U e e: i: o: u0 u: y: }:&quot;.split(&quot; &quot;) CONS = &quot;N S b d d` f g h j k l l` m n n` p r s s&#39; s` t t` v&quot;.split(&quot; &quot;) . def move_stress(phones): outphones = [] stress = &#39;&#39; for phone in phones: if phone.startswith(&#39;%&quot;&#39;): stress = &#39;&quot;&#39; phone = phone[2:] if phone in VOWELS: outphones.append(stress + phone) stress = &#39;&#39; else: outphones.append(phone) elif phone[0:1] in &#39;%&quot;&#39;: stress = phone[0:1] phone = phone[1:] if phone in VOWELS: outphones.append(stress + phone) stress = &#39;&#39; else: outphones.append(phone) else: if stress != &#39;&#39; and phone in VOWELS: phone = stress + phone stress = &#39;&#39; outphones.append(phone) if stress != &#39;&#39;: print(&quot;Error: unplaced stress&quot;, phones) return outphones . test = &#39;%&quot;j Y t r a %s E j&#39;.split() . assert move_stress(test) == [&#39;j&#39;, &#39;&quot;Y&#39;, &#39;t&#39;, &#39;r&#39;, &#39;a&#39;, &#39;s&#39;, &#39;%E&#39;, &#39;j&#39;] . import itertools . class BaseRule(): def __init__(self, rule, phone, keep_stress=False): self.rule = rule self.phone = phone self.keep_stress = keep_stress def clean_phones(self, phones): if self.keep_stress: return [x.replace(&#39;&quot;&#39;, &#39;&#39;).replace(&#39;%&#39;, &#39;&#39;) for x in phones] else: return phones def applies(self, phones): pass def expand(self, phones, positions=[]): pass def __str__(self): return f&quot;[{self.rule}]&quot; . class PhonologicalRule(BaseRule): def __init__(self, rule, phone, transform=[], left_context=[], right_context=[], keep_stress=False): super().__init__(rule, phone, keep_stress) self.lctx = left_context self.rctx = right_context self.transform = transform def lctx_ok(self, phones, pos): if self.lctx == []: return True end = pos start = end - len(self.lctx) if phones[start:end] == self.lctx: return True return False def rctx_ok(self, phones, pos): if self.rctx == []: return True start = pos + 1 end = start + len(self.rctx) if phones[start:end] == self.rctx: return True return False def ctx_ok(self, phones, pos): return self.rctx_ok(phones, pos) and self.lctx_ok(phones, pos) def applies(self, phones): positions = [] phones = self.clean_phones(phones) if not self.phone in phones: return [] for i in range(0, len(phones)): if phones[i] == self.phone and self.ctx_ok(phones, i): positions.append(i) return positions def expand(self, phones, positions=[]): tmp = [] if positions == []: positions = self.applies(phones) for i in range(0, len(phones)): if i in positions: tmp.append([phones[i], &quot; &quot;.join(self.transform)]) else: tmp.append([phones[i]]) expanded = [x for x in itertools.product(*tmp)] tidied = set() for exp in expanded: tidied.add(tuple([c for c in exp if c != &#39;&#39;])) return [list(t) for t in tidied] . rule = PhonologicalRule(&quot;k → ∅ / _ t&quot;, &quot;k&quot;, [], [], [&quot;t&quot;]) . print(rule) . [k → ∅ / _ t] . rule.expand(&quot;v I k t I k t&quot;.split(&quot; &quot;)) . [[&#39;v&#39;, &#39;I&#39;, &#39;t&#39;, &#39;I&#39;, &#39;t&#39;], [&#39;v&#39;, &#39;I&#39;, &#39;t&#39;, &#39;I&#39;, &#39;k&#39;, &#39;t&#39;], [&#39;v&#39;, &#39;I&#39;, &#39;k&#39;, &#39;t&#39;, &#39;I&#39;, &#39;k&#39;, &#39;t&#39;], [&#39;v&#39;, &#39;I&#39;, &#39;k&#39;, &#39;t&#39;, &#39;I&#39;, &#39;t&#39;]] . 2D ɖ 2L ɭ 2N ɳ 2S ʂ 2T ʈ A a A: ɑː B b D d E e E0 ə E: eː F f G ɡ H h I ɪ I: iː J j K k L l M m N n NG ŋ O ʊ O: uː P p R r S s SJ ɧ T t TJ ɕ U ɵ U: ʉː V v Y ʏ Y: yː [ ɛ [3 æː [4 æ [: ɛː œ 3 œ̞ː 4 œ̞ : øː ] ɔ ]: oː gcl &lt;gcl&gt; ha &lt;ha&gt; hes &lt;hes&gt; kl &lt;kl&gt; pa &lt;pa&gt; sm &lt;sm&gt; v &lt;v&gt; ~H ~h ~L ~l ~N ~n . ADDITIONS = &quot;&quot;&quot; INTE tn t e tI -&gt; 0 / VOWEL # _ EN tE N tn -&gt; N / _ # [+velar] EN tE m tn -&gt; m / _ # [+labial] JA t&quot;A: JA t&quot;j a NEJ t&quot;n E &quot;&quot;&quot; .",
            "url": "https://jimregan.github.io/notes/swedish/nst/lexicon/phonetic/rules/2023/10/09/phonetic-rule-take-1.html",
            "relUrl": "/swedish/nst/lexicon/phonetic/rules/2023/10/09/phonetic-rule-take-1.html",
            "date": " • Oct 9, 2023"
        }
        
    
  
    
        ,"post27": {
            "title": "Interesting links, 7/10/2023",
            "content": "UniAudio: An Audio Foundation Model Toward Universal Audio Generation, code . @misc{yang2023uniaudio, title={UniAudio: An Audio Foundation Model Toward Universal Audio Generation}, author={Dongchao Yang and Jinchuan Tian and Xu Tan and Rongjie Huang and Songxiang Liu and Xuankai Chang and Jiatong Shi and Sheng Zhao and Jiang Bian and Xixin Wu and Zhou Zhao and Helen Meng}, year={2023}, eprint={2310.00704}, archivePrefix={arXiv}, primaryClass={cs.SD} } . If you&#39;d asked me a year ago, superposition would have been by far the reason I was most worried that mechanistic interpretability would hit a dead end.I&#39;m now very optimistic. I&#39;d go as far as saying it&#39;s now primarily an engineering problem -- hard, but less fundamental risk. https://t.co/bhhHObbAOK . &mdash; Chris Olah (@ch402) October 5, 2023 It’s MBR All the Way Down: Modern Generation Techniques Through the Lens of Minimum Bayes Risk . @misc{bertsch2023its, title={It&#39;s MBR All the Way Down: Modern Generation Techniques Through the Lens of Minimum Bayes Risk}, author={Amanda Bertsch and Alex Xie and Graham Neubig and Matthew R. Gormley}, year={2023}, eprint={2310.01387}, archivePrefix={arXiv}, primaryClass={cs.CL} } . Fast-HuBERT: An Efficient Training Framework for Self-Supervised Speech Representation Learning, code . @misc{yang2023fasthubert, title={Fast-HuBERT: An Efficient Training Framework for Self-Supervised Speech Representation Learning}, author={Guanrou Yang and Ziyang Ma and Zhisheng Zheng and Yakun Song and Zhikang Niu and Xie Chen}, year={2023}, eprint={2309.13860}, archivePrefix={arXiv}, primaryClass={cs.CL} } . SLM: Bridge the thin gap between speech and text foundation models . @misc{wang2023slm, title={SLM: Bridge the thin gap between speech and text foundation models}, author={Mingqiu Wang and Wei Han and Izhak Shafran and Zelin Wu and Chung-Cheng Chiu and Yuan Cao and Yongqiang Wang and Nanxin Chen and Yu Zhang and Hagen Soltau and Paul Rubenstein and Lukas Zilka and Dian Yu and Zhong Meng and Golan Pundak and Nikhil Siddhartha and Johan Schalkwyk and Yonghui Wu}, year={2023}, eprint={2310.00230}, archivePrefix={arXiv}, primaryClass={cs.CL} } . Joint Audio and Speech Understanding . @misc{gong2023joint, title={Joint Audio and Speech Understanding}, author={Yuan Gong and Alexander H. Liu and Hongyin Luo and Leonid Karlinsky and James Glass}, year={2023}, eprint={2309.14405}, archivePrefix={arXiv}, primaryClass={cs.SD} } . EFFUSE: Efficient Self-Supervised Feature Fusion for E2E ASR in Multilingual and Low Resource Scenarios . @misc{srivastava2023effuse, title={EFFUSE: Efficient Self-Supervised Feature Fusion for E2E ASR in Multilingual and Low Resource Scenarios}, author={Tejes Srivastava and Jiatong Shi and William Chen and Shinji Watanabe}, year={2023}, eprint={2310.03938}, archivePrefix={arXiv}, primaryClass={cs.SD} } . A Token-Wise Beam Search Algorithm for RNN-T . @misc{keren2023tokenwise, title={A Token-Wise Beam Search Algorithm for RNN-T}, author={Gil Keren}, year={2023}, eprint={2302.14357}, archivePrefix={arXiv}, primaryClass={cs.LG} } . Zero-shot Domain-sensitive Speech Recognition with Prompt-conditioning Fine-tuning, code . @misc{liao2023zeroshot, title={Zero-shot Domain-sensitive Speech Recognition with Prompt-conditioning Fine-tuning}, author={Feng-Ting Liao and Yung-Chieh Chan and Yi-Chang Chen and Chan-Jan Hsu and Da-shan Shiu}, year={2023}, eprint={2307.10274}, archivePrefix={arXiv}, primaryClass={eess.AS} } . . faramuci, Mi az a faramuci? . seggrepacsi .",
            "url": "https://jimregan.github.io/notes/links/2023/10/07/misc-links.html",
            "relUrl": "/links/2023/10/07/misc-links.html",
            "date": " • Oct 7, 2023"
        }
        
    
  
    
        ,"post28": {
            "title": "Aligning output from a Swedish ASR and phonetic recogniser",
            "content": "def approx_match(time_a, time_b, slippage=(0.01 * 6)): return abs(time_a - time_b) &lt;= slippage . SAMPLE = &quot;2442204240010034621&quot; . from pathlib import Path TEXT = Path(&quot;/Users/joregan/Playing/kbw2v&quot;) PHONES = Path(&quot;/Users/joregan/Playing/rd_phonetic&quot;) . class Chunk: def __init__(self, chunk): self.text = chunk[&#39;text&#39;] self.start = chunk[&#39;timestamp&#39;][0] self.end = chunk[&#39;timestamp&#39;][1] def __repr__(self) -&gt; str: return f&quot;[{self.text} ({self.start}, {self.end})]&quot; class SimpleMerge(Chunk): def __init__(self, left: Chunk, right: Chunk): self.text = left.text self.phone = right.text self.start = left.start self.end = left.end self.diff_start = left.start - right.start self.diff_end = left.end - right.end def exact_length(self): return self.diff_start == 0 and self.diff_end == 0 def __repr__(self) -&gt; str: return f&quot;[{self.text} :: {self.phone} ({self.start}, {self.end})]&quot; class ComplexMerge(Chunk): def __init__(self, left, right): if type(left) == list: self.left_chunks = left elif left == None: self.left_chunks == [] else: self.left_chunks = [left] if type(right) == list: self.right_chunks = right elif right == None: self.right_chunks == [] else: self.right_chunks = [right] self.start = self.get_start() self.end = self.get_end() self.text = &quot; &quot;.join([x.text for x in self.left_chunks]) self.phone = &quot; &quot;.join([x.text for x in self.right_chunks]) def get_start(self): if self.left_chunks == [] and self.right_chunks == []: return None if self.left_chunks == []: return self.right_chunks[0].start if self.right_chunks == []: return self.left_chunks[0].start if self.left_chunks[0].start &lt; self.right_chunks[0].start: return self.left_chunks[0].start else: return self.right_chunks[0].start def get_end(self): if self.left_chunks == [] and self.right_chunks == []: return None if self.left_chunks == []: return self.right_chunks[-1].end if self.right_chunks == []: return self.left_chunks[-1].end if self.left_chunks[-1].end &gt; self.right_chunks[-1].end: return self.left_chunks[-1].end else: return self.right_chunks[-1].end def __repr__(self) -&gt; str: return f&quot;[{self.text} :: {self.phone} ({self.start}, {self.end})]&quot; . class PhoneChunk(Chunk): def __init__(self, chunk): self.text = chunk.text self.start = chunk.start self.end = chunk.end class WordChunk(Chunk): def __init__(self, chunk): self.text = chunk.text self.start = chunk.start self.end = chunk.end . def create_merges(text_chunks, phone_chunks): merged = [] start = True pci = 0 tci = 0 iteration = 0 while pci &lt; len(phone_chunks) and tci &lt; len(text_chunks): iteration += 1 am_start = approx_match(text_chunks[tci].start, phone_chunks[pci].start) am_end = approx_match(text_chunks[tci].end, phone_chunks[pci].end) if am_start and am_end: merged.append(SimpleMerge(text_chunks[tci], phone_chunks[pci])) elif am_start: cur_text = [text_chunks[tci]] cur_phone = [phone_chunks[pci]] if phone_chunks[pci].end &lt; text_chunks[tci].end: while not approx_match(text_chunks[tci].end, phone_chunks[pci].end) and phone_chunks[pci].end &lt; text_chunks[tci].end: pci += 1 if pci &gt;= len(phone_chunks): break cur_phone.append(phone_chunks[pci]) merged.append(ComplexMerge(cur_text, cur_phone)) else: while not approx_match(text_chunks[tci].end, phone_chunks[pci].end) and text_chunks[tci].end &lt; phone_chunks[pci].end: tci += 1 if tci &gt;= len(text_chunks): break cur_text.append(text_chunks[tci]) merged.append(ComplexMerge(cur_text, cur_phone)) else: if phone_chunks[pci].end &lt; text_chunks[tci].start: while phone_chunks[pci].end &lt; text_chunks[tci].start: pci += 1 if pci &gt;= len(phone_chunks): break merged.append(PhoneChunk(phone_chunks[pci])) elif text_chunks[tci].end &lt; phone_chunks[pci].start: while text_chunks[tci].end &lt; phone_chunks[pci].start: tci += 1 if tci &gt;= len(text_chunks): break merged.append(WordChunk(text_chunks[tci])) else: print(&quot;else&quot;, text_chunks[tci], phone_chunks[pci]) tci += 1 pci += 1 return merged . def print_merges(filename, source, merged): with open(filename, &quot;w&quot;) as outfile: for merge in merged: if type(merge) == PhoneChunk: outfile.write(f&#39;{source} t&lt;UNALIGNED PHONE&gt; t{merge.text} t{merge.start} t{merge.end} n&#39;) elif type(merge) == WordChunk: outfile.write(f&#39;{source} t&lt;UNALIGNED WORD&gt; t{merge.text} t{merge.start} t{merge.end} n&#39;) else: outfile.write(f&#39;{source} t{merge.text} t{merge.phone} t{merge.start} t{merge.end} n&#39;) . import json for file in PHONES.glob(&quot;*.json&quot;): text_chunks = [] phone_chunks = [] with open(TEXT / f&quot;{file.name}&quot;) as text: text_json = json.load(text) for text_chunk in text_json[&#39;chunks&#39;]: text_chunks.append(Chunk(text_chunk)) with open(file) as phones: phone_json = json.load(phones) for phone_chunk in phone_json[&#39;chunks&#39;]: phone_chunks.append(Chunk(phone_chunk)) merged = create_merges(text_chunks, phone_chunks) print_merges(f&quot;/Users/joregan/Playing/rd_tpalign/{file.stem}.tsv&quot;, file.stem, merged) .",
            "url": "https://jimregan.github.io/notes/swedish/asr/phonetic/alignment/2023/10/04/swedish-asr-alignment.html",
            "relUrl": "/swedish/asr/phonetic/alignment/2023/10/04/swedish-asr-alignment.html",
            "date": " • Oct 4, 2023"
        }
        
    
  
    
        ,"post29": {
            "title": "Interesting links, 31/08/2023",
            "content": "IPA Reader . Fuaimeanna na Gaeilge – The Sounds of Irish . Crowdsourced high-quality UK and Ireland English Dialect speech data set. . Teangannan na Gàidhlig / Gaelic Tongues . The 44 Phonemes in English . Sound Comparisons, Celtic . Speech Accent Archive, Swedish . . eginhard/cae-utd-utils — Zero-resource speech utilities and documentation . jmccrae/lds-esslli23 — Slides and content for ESSLLI 2023 course on “Introduction to Linguistic Data Science” . . RoboTAP: Tracking Arbitrary Points for Few-Shot Visual Imitation .",
            "url": "https://jimregan.github.io/notes/links/2023/08/31/misc-links.html",
            "relUrl": "/links/2023/08/31/misc-links.html",
            "date": " • Aug 31, 2023"
        }
        
    
  
    
        ,"post30": {
            "title": "Interesting links, 16/08/2023",
            "content": "TranUSR: Phoneme-to-word Transcoder Based Unified Speech Representation Learning for Cross-lingual Speech Recognition . @misc{xue2023tranusr, title={TranUSR: Phoneme-to-word Transcoder Based Unified Speech Representation Learning for Cross-lingual Speech Recognition}, author={Hongfei Xue and Qijie Shao and Peikun Chen and Pengcheng Guo and Lei Xie and Jie Liu}, year={2023}, eprint={2305.13629}, } . On the Transferability of Whisper-based Representations for “In-the-Wild” Cross-Task Downstream Speech Applications . @misc{chemudupati2023transferability, title={On the Transferability of Whisper-based Representations for &quot;In-the-Wild&quot; Cross-Task Downstream Speech Applications}, author={Vamsikrishna Chemudupati and Marzieh Tahaei and Heitor Guimaraes and Arthur Pimentel and Anderson Avila and Mehdi Rezagholizadeh and Boxing Chen and Tiago Falk}, year={2023}, eprint={2305.14546}, } . CASA-ASR: Context-Aware Speaker-Attributed ASR . @misc{shi2023casaasr, title={CASA-ASR: Context-Aware Speaker-Attributed ASR}, author={Mohan Shi and Zhihao Du and Qian Chen and Fan Yu and Yangze Li and Shiliang Zhang and Jie Zhang and Li-Rong Dai}, year={2023}, eprint={2305.12459}, } . CLAPSpeech: Learning Prosody from Text Context with Contrastive Language-Audio Pre-training, samples . @misc{ye2023clapspeech, title={CLAPSpeech: Learning Prosody from Text Context with Contrastive Language-Audio Pre-training}, author={Zhenhui Ye and Rongjie Huang and Yi Ren and Ziyue Jiang and Jinglin Liu and Jinzheng He and Xiang Yin and Zhou Zhao}, year={2023}, eprint={2305.10763}, } . Fast Conformer with Linearly Scalable Attention for Efficient Speech Recognition . @misc{rekesh2023fast, title={Fast Conformer with Linearly Scalable Attention for Efficient Speech Recognition}, author={Dima Rekesh and Samuel Kriman and Somshubra Majumdar and Vahid Noroozi and He Huang and Oleksii Hrinchuk and Ankur Kumar and Boris Ginsburg}, year={2023}, eprint={2305.05084}, } . The HARPY Speech Recognition System . Multi-Task and Transfer Learning in Low-Resource Speech Recognition . PaLI: Scaling Language-Image Learning in 100+ Languages . google/mt5-small . google/matcha-base . google/matcha-chart2text-pew — This model is the MatCha model, fine-tuned on Chart2text-pew dataset. This fine-tuned checkpoint might be better suited for chart summarization task. . google/matcha-plotqa-v2 — This model is the MatCha model, fine-tuned on plotQA-v2 dataset. This fine-tuned checkpoint might be better suited for plots question answering tasks. . FLEURS Irish — all non-native, from what I’ve checked. . budzianowski/multiwoz — Source code for end-to-end dialogue model from the MultiWOZ paper . salesforce/DialogStudio — DialogStudio: Towards Richest and Most Diverse Unified Dataset Collection and Instruction-Aware Models for Conversational AI . Implementation of the Branchformer . facebookresearch/Ego4d — Ego4d dataset repository. Download the dataset, visualize, extract features &amp; example usage of the dataset. (Data has an awful licence). . ContextNet: Improving Convolutional Neural Networks for Automatic Speech Recognition with Global Context . @misc{han2020contextnet, title={ContextNet: Improving Convolutional Neural Networks for Automatic Speech Recognition with Global Context}, author={Wei Han and Zhengdong Zhang and Yu Zhang and Jiahui Yu and Chung-Cheng Chiu and James Qin and Anmol Gulati and Ruoming Pang and Yonghui Wu}, year={2020}, eprint={2005.03191}, } . JOIST: A Joint Speech and Text Streaming Model For ASR . @misc{sainath2022joist, title={JOIST: A Joint Speech and Text Streaming Model For ASR}, author={Tara N. Sainath and Rohit Prabhavalkar and Ankur Bapna and Yu Zhang and Zhouyuan Huo and Zhehuai Chen and Bo Li and Weiran Wang and Trevor Strohman}, year={2022}, eprint={2210.07353}, } . Improving Joint Speech-Text Representations Without Alignment . @misc{peyser2023improving, title={Improving Joint Speech-Text Representations Without Alignment}, author={Cal Peyser and Zhong Meng and Ke Hu and Rohit Prabhavalkar and Andrew Rosenberg and Tara N. Sainath and Michael Picheny and Kyunghyun Cho}, year={2023}, eprint={2308.06125}, } .",
            "url": "https://jimregan.github.io/notes/links/2023/08/16/misc-links.html",
            "relUrl": "/links/2023/08/16/misc-links.html",
            "date": " • Aug 16, 2023"
        }
        
    
  
    
        ,"post31": {
            "title": "Waxholm phoneme fairseq",
            "content": "import soundfile as sf import wave . def smp_headers(filename: str): with open(filename, &quot;rb&quot;) as f: f.seek(0) raw_headers = f.read(1024) raw_headers = raw_headers.rstrip(b&#39; x00&#39;) asc_headers = raw_headers.decode(&quot;ascii&quot;) asc_headers.rstrip(&#39; x00&#39;) tmp = [a for a in asc_headers.split(&quot; r n&quot;)] back = -1 while abs(back) &gt; len(tmp) + 1: if tmp[back] == &#39;=&#39;: break back -= 1 tmp = tmp[0:back-1] return dict(a.split(&quot;=&quot;) for a in tmp) def smp_read_sf(filename: str): headers = smp_headers(filename) if headers[&quot;msb&quot;] == &quot;last&quot;: ENDIAN = &quot;LITTLE&quot; else: ENDIAN = &quot;BIG&quot; data, sr = sf.read(filename, channels=int(headers[&quot;nchans&quot;]), samplerate=16000, endian=ENDIAN, start=512, dtype=&quot;int16&quot;, format=&quot;RAW&quot;, subtype=&quot;PCM_16&quot;) return (data, sr) def write_wav(filename, arr): with wave.open(filename, &quot;w&quot;) as f: f.setnchannels(1) f.setsampwidth(2) f.setframerate(16000) f.writeframes(arr) . from pathlib import Path . WAXHOLM = &quot;/Users/joregan/Playing/waxholm&quot; OUTPUT = &quot;/Users/joregan/Playing/waxholm_fairseq&quot; . SCENES_PATH = Path(WAXHOLM) / &quot;scenes_formatted&quot; OUTPUT_PATH = Path(OUTPUT) if not OUTPUT_PATH.is_dir(): OUTPUT_PATH.mkdir() . TRAIN_FILES = [] with open(Path(WAXHOLM) / &quot;alloktrainfiles&quot;) as trainf: for line in trainf.readlines(): TRAIN_FILES.append(line.strip()) TEST_FILES = [] with open(Path(WAXHOLM) / &quot;testfiles&quot;) as testf: for line in testf.readlines(): TEST_FILES.append(line.strip()) . print(len(TRAIN_FILES), len(TEST_FILES)) . 1835 327 . import re def get_labels(mixfile): labels = &quot;&quot; saw_label = False with open(mixfile) as infile: for line in infile.readlines(): if not saw_label: if line.lower().startswith(&quot;labels:&quot;): saw_label = True labels = line[7:].strip() else: if line.startswith(&quot;FR&quot;): break else: labels = &quot; &quot;.join([labels, line.strip()]) labels = re.sub(&quot; +&quot;, &quot; &quot;, labels) return labels . get_labels(&quot;/Users/joregan/Playing/waxholm/scenes_formatted/fp2043/fp2043.16.03.smp.mix&quot;) . &#39;A:H &#39;A: pa p: |h J &#39;A:Ggv V &#39;ILv pap: sm p:v S &#39;E: pa H &#39;U:R 2Dd &#39;EM Bb &#39;]:TtE0NG Gg &#39;]:R 2Tt &#39;I STt&#34;A:VE0#STtR` M p: &#39;]: p: &#39;]M J &#39;A: Kk &#39;AN F&#34;O#2S`[TtA Tt &#39;I F&#34;IN#H`AM .&#39; . def segment_label(label, skip_pause=True): phones = [] i = 0 while i &lt; len(label): start_i = i end_i = i if label[i:i+2] in [&quot;NG&quot;, &quot;E0&quot;, &quot;SJ&quot;, &quot;TJ&quot;, &quot;kl&quot;, &quot;sm&quot;, &quot;kl&quot;, &quot;pa&quot;]: phones.append(label[i:i+2]) i += 2 elif label[i:i+2] == &quot;p:&quot;: if not skip_pause: phones.append(&quot;p:&quot;) i += 2 elif label[i:i+1] == &quot;#&quot;: i += 1 else: if label[i:i+1] in [&quot;&#39;&quot;, &quot;`&quot;, &quot; &quot;&quot;, &quot;2&quot;, &quot;~&quot;]: i += 1 end_i += 1 if label[i+1:i+2] in [&quot;:&quot;, &quot;3&quot;, &quot;4&quot;]: end_i += 1 phones.append(label[start_i:end_i+1]) i = end_i + 1 return phones . assert segment_label(&quot;Bb &#39;]:TtE0NG&quot;) == [&#39;B&#39;, &#39;b&#39;, &quot;&#39;]:&quot;, &#39;T&#39;, &#39;t&#39;, &#39;E0&#39;, &#39;NG&#39;] assert segment_label(&quot;STt &quot;A:VE0#STtR` M&quot;) == [&#39;S&#39;, &#39;T&#39;, &#39;t&#39;, &#39;&quot;A:&#39;, &#39;V&#39;, &#39;E0&#39;, &#39;S&#39;, &#39;T&#39;, &#39;t&#39;, &#39;R&#39;, &#39;` &#39;, &#39;M&#39;] assert segment_label(&quot;p:v&quot;) == [&#39;v&#39;] . def proc_label(label, stress=False): def strip_stress(phone, stress): if stress: return phone if phone[0] in [&quot;&#39;&quot;, &quot;`&quot;, &quot; &quot;&quot;]: return phone[1:] else: return phone words = [] for word in label.split(&quot; &quot;): if word in [&quot;p:pa&quot;, &quot;pap:&quot;, &quot;p:pap:&quot;, &quot;pa&quot;]: words.append(&quot;pa&quot;) elif word == &quot;p:&quot; or word == &quot;.&quot;: continue elif word == &quot;|h&quot;: words.append(&quot;hes&quot;) elif word in [&quot;sm&quot;, &quot;ha&quot;, &quot;kl&quot;]: words.append(word) else: phones = [strip_stress(p, stress) for p in segment_label(word)] words.append(&quot; &quot;.join(phones)) return(&quot; | &quot;.join(words)) + &quot; |&quot; . lbl = get_labels(&quot;/Users/joregan/Playing/waxholm/scenes_formatted/fp2043/fp2043.16.03.smp.mix&quot;) plbl = proc_label(lbl) print(lbl) print(plbl) . A:H&#39;A: pa p: |h J&#39;A:Ggv V&#39;ILv pap: sm p:v S&#39;E: pa H&#39;U:R 2Dd&#39;EM Bb&#39;]:TtE0NG Gg&#39;]:R 2Tt&#39;I STt&#34;A:VE0#STtR` M p: &#39;]: p: &#39;]M J&#39;A: Kk&#39;AN F&#34;O#2S`[TtA Tt&#39;I F&#34;IN#H`AM . A: H A: | pa | hes | J A: G g v | V I L v | pa | sm | v | S E: | pa | H U: R | 2D d E M | B b ]: T t E0 NG | G g ]: R | 2T t I | S T t A: V E0 S T t R M | ]: | ] M | J A: | K k A N | F O 2S [ T t A | T t I | F I N H A M | . with open(OUTPUT_PATH / &quot;train.tsv&quot;, &quot;w&quot;) as train_tsv, open(OUTPUT_PATH / &quot;train.ltr&quot;, &quot;w&quot;) as train_ltr, open(OUTPUT_PATH / &quot;valid.tsv&quot;, &quot;w&quot;) as valid_tsv, open(OUTPUT_PATH / &quot;valid.ltr&quot;, &quot;w&quot;) as valid_ltr, open(OUTPUT_PATH / &quot;test.tsv&quot;, &quot;w&quot;) as test_tsv, open(OUTPUT_PATH / &quot;test.ltr&quot;, &quot;w&quot;) as test_ltr: train_tsv.write(str(OUTPUT_PATH) + &quot; n&quot;) test_tsv.write(str(OUTPUT_PATH) + &quot; n&quot;) valid_tsv.write(str(OUTPUT_PATH) + &quot; n&quot;) valid_amount = 195 for smpfile in SCENES_PATH.glob(&quot;fp*/*.smp&quot;): mixfile = f&quot;{smpfile}.mix&quot; if not Path(mixfile).exists(): continue stem = smpfile.stem if f&quot;{stem}.smp&quot; in TEST_FILES: out_tsv = test_tsv out_ltr = test_ltr elif valid_amount &gt; 0: out_tsv = valid_tsv out_ltr = valid_ltr valid_amount -= 1 else: out_tsv = train_tsv out_ltr = train_ltr outwav = f&quot;{stem}.wav&quot; arr, sr = smp_read_sf(str(smpfile)) out_tsv.write(f&quot;{outwav} t{len(arr)} n&quot;) write_wav(outwav, arr) label = get_labels(mixfile) ltrline = proc_label(label) out_ltr.write(ltrline + &quot; n&quot;) .",
            "url": "https://jimregan.github.io/notes/waxholm/asr/swedish/2023/08/10/waxholm-phoneme-fairseq.html",
            "relUrl": "/waxholm/asr/swedish/2023/08/10/waxholm-phoneme-fairseq.html",
            "date": " • Aug 10, 2023"
        }
        
    
  
    
        ,"post32": {
            "title": "Interesting links, 04/08/2023",
            "content": "facebookresearch/NeRF-Det — Code for NeRF-Det: Learning Geometry-Aware Volumetric Representation for Multi-View 3D Object Detection . @inproceedings{ xu2023nerfdet, title={NeRF-Det: Learning Geometry-Aware Volumetric Representation for Multi-View 3D Object Detection}, author={Xu, Chenfeng and Wu, Bichen and Hou, Ji and Tsai, Sam and Li, Ruilong and Wang, Jialiang and Zhan, Wei and He, Zijian and Vajda, Peter and Keutzer, Kurt and Tomizuka, Masayoshi}, booktitle={ICCV}, year={2023}, } @inproceedings{ park2023time, title={Time Will Tell: New Outlooks and A Baseline for Temporal Multi-View 3D Object Detection}, author={Jinhyung Park and Chenfeng Xu and Shijia Yang and Kurt Keutzer and Kris M. Kitani and Masayoshi Tomizuka and Wei Zhan}, booktitle={The Eleventh International Conference on Learning Representations }, year={2023}, url={https://openreview.net/forum?id=H3HcEJA2Um} } . facebookresearch/vissl — VISSL is FAIR’s library of extensible, modular and scalable components for SOTA Self-Supervised Learning with images. . facebookresearch/myosuite — MyoSuite is a collection of environments/tasks to be solved by musculoskeletal models simulated with the MuJoCo physics engine and wrapped in the OpenAI gym API. . facebookresearch/HairMSNN — This is the official implementation of our EGSR 2023 paper, Accelerating Hair Rendering by Learning High-Order Scattered Radiance. . facebookresearch/home-robot — Mobile manipulation research tools for roboticists . facebookresearch/habitat-sim — A flexible, high-performance 3D simulator for Embodied AI research. . google-research/language-table — Suite of human-collected datasets and a multi-task continuous control benchmark for open vocabulary visuolinguomotor learning. . lcompilers/lpython — Python compiler .",
            "url": "https://jimregan.github.io/notes/links/2023/08/04/misc-links.html",
            "relUrl": "/links/2023/08/04/misc-links.html",
            "date": " • Aug 4, 2023"
        }
        
    
  
    
        ,"post33": {
            "title": "Interesting links, 08/07/2023",
            "content": "Making More of Little Data: Improving Low-Resource Automatic Speech Recognition Using Data Augmentation, code . @misc{bartelds2023making, title={Making More of Little Data: Improving Low-Resource Automatic Speech Recognition Using Data Augmentation}, author={Martijn Bartelds and Nay San and Bradley McDonnell and Dan Jurafsky and Martijn Wieling}, year={2023}, eprint={2305.10951}, archivePrefix={arXiv}, primaryClass={cs.CL} } . FLamE: Few-shot Learning from Natural Language Explanations . Vintage Voice Effect in Audacity . GenSim: Generative Models for Supersizing Robotic Simulation Tasks . JoseLlarena/Britfone — British English pronunciation dictionary . XPhoneBERT: A Pre-trained Multilingual Model for Phoneme Representations for Text-to-Speech, code . @misc{nguyen2023xphonebert, title={XPhoneBERT: A Pre-trained Multilingual Model for Phoneme Representations for Text-to-Speech}, author={Linh The Nguyen and Thinh Pham and Dat Quoc Nguyen}, year={2023}, eprint={2305.19709}, archivePrefix={arXiv}, primaryClass={cs.CL} } . Wavelet Diffusion Models are fast and scalable Image Generators, code . @misc{phung2023wavelet, title={Wavelet Diffusion Models are fast and scalable Image Generators}, author={Hao Phung and Quan Dao and Anh Tran}, year={2023}, eprint={2211.16152}, archivePrefix={arXiv}, primaryClass={cs.CV} } .",
            "url": "https://jimregan.github.io/notes/links/2023/07/08/misc-links.html",
            "relUrl": "/links/2023/07/08/misc-links.html",
            "date": " • Jul 8, 2023"
        }
        
    
  
    
        ,"post34": {
            "title": "Interesting links, 03/07/2023",
            "content": "Affordances from Human Videos as a Versatile Representation for Robotics, project page . Speech-to-Text Adapter and Speech-to-Entity Retriever Augmented LLMs for Speech Understanding . @misc{wang2023speechtotext, title={Speech-to-Text Adapter and Speech-to-Entity Retriever Augmented LLMs for Speech Understanding}, author={Mingqiu Wang and Izhak Shafran and Hagen Soltau and Wei Han and Yuan Cao and Dian Yu and Laurent El Shafey}, year={2023}, eprint={2306.07944}, archivePrefix={arXiv}, primaryClass={eess.AS} } . leimao/DeepLab-V3 . 1adrianb/2D-and-3D-face-alignment . budzianowski/multiwoz . giakou4/pyfeats . Self-Supervised Accent Learning for Under-Resourced Accents Using Native Language Data . @INPROCEEDINGS{10096854, author={Kumar, Mehul and Kim, Jiyeon and Gowda, Dhananjaya and Garg, Abhinav and Kim, Chanwoo}, booktitle={ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, title={Self-Supervised Accent Learning for Under-Resourced Accents Using Native Language Data}, year={2023}, volume={}, number={}, pages={1-5}, doi={10.1109/ICASSP49357.2023.10096854} } . Miipher: A Robust Speech Restoration Model Integrating Self-Supervised Speech and Text Representations, project page . facebookresearch/encodec . Improving Textless Spoken Language Understanding with Discrete Units as Intermediate Target . McGill-NLP/length-generalization . xiph/LPCNet . google-research/mozolm . google-research/fast-soft-sort . google-research/swirl-lm . googlecolab/colab-widgets . christos-c/bible-corpus . jbeskow/tuben – Tube model of vocal tract - resonance frequency estimation . Magic123: One Image to High-Quality 3D Object Generation Using Both 2D and 3D Diffusion Priors, project page, code (currently empty) . Guy who bought $37k in stolen human organs literally put &quot;braiiiiins.&quot; in the memo line on PayPal. https://t.co/Lz6uE8VfST pic.twitter.com/llLTT70k6n . &mdash; Nick Bax.eth (@bax1337) June 14, 2023 facebookresearch/dino .",
            "url": "https://jimregan.github.io/notes/links/2023/07/03/misc-links.html",
            "relUrl": "/links/2023/07/03/misc-links.html",
            "date": " • Jul 3, 2023"
        }
        
    
  
    
        ,"post35": {
            "title": "Interesting links, 13/04/2023",
            "content": "Conjunctive/Imperative/Subjunctive mood in Hungarian . Splitting coverbs from verb root . A Hungarian Language Course . . linto-ai/whisper-timestamped — Multilingual Automatic Speech Recognition with word-level timestamps and confidence . lucidrains/medical-chatgpt — Implementation of ChatGPT, but tailored towards primary care medicine, with the reward being able to collect patient histories in a thorough and efficient manner and come up with a reasonable differential diagnosis . DIVA-DIA/Text-Line-Segmentation-Method-for-Medieval-Manuscripts . personwhofloat/Line-Segmentation-Model — LSM is short for Line Segmentation Model. It is a model for text line segmentation in document images. The model is robust to color, brightness, page warping. . Tensor Calculus 0: Introduction . Matplotlib Graphs in Research Papers . “The duck pond”: showcase of TikZ-drawn animals/ducks . neonbjb/ocotillo — Performant and accurate speech recognition built on Pytorch . Customer Case Study: Building an end-to-end Speech Recognition model in PyTorch with AssemblyAI . alibaba-damo-academy/FunASR . Paraformer: Fast and Accurate Parallel Transformer for Non-autoregressive End-to-End Speech Recognition . @inproceedings{gao22b_interspeech, author={Zhifu Gao and ShiLiang Zhang and Ian McLoughlin and Zhijie Yan}, title={Paraformer: Fast and Accurate Parallel Transformer for Non-autoregressive End-to-End Speech Recognition}, year=2022, booktitle={Proc. Interspeech 2022}, pages={2063--2067}, doi={10.21437/Interspeech.2022-9996} } . Segment Anything, code . facebookresearch/habitat-lab . facebookresearch/myosuite . chroma-core/chroma — the AI-native open-source embedding database . Winfredy/SadTalker — Learning Realistic 3D Motion Coefficients for Stylized Audio-Driven Single Image Talking Face Animation, demo . sdatkinson/neural-amp-modeler — Neural network emulator for guitar amplifiers. . facebookresearch/Aria_data_tools — Aria data tools provide the open-source toolkit in C++ and Python to interact with data from Project Aria . bootphon/articulatory_inversion — Inversion-articulatoire is a Python library for training/testing neural network models for the acoustic to articulatory reconstruction. . Acoustic-to-Articulatory Mapping With Joint Optimization of Deep Speech Enhancement and Articulatory Inversion Models . @ARTICLE{9640504, author={Shahrebabaki, Abdolreza Sabzi and Salvi, Giampiero and Svendsen, Torbjørn and Siniscalchi, Sabato Marco}, journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing}, title={Acoustic-to-Articulatory Mapping With Joint Optimization of Deep Speech Enhancement and Articulatory Inversion Models}, year={2022}, volume={30}, number={}, pages={135-147}, doi={10.1109/TASLP.2021.3133218} } . databricks/dolly-v2-12b . AI is becoming powerful in 2023.But most people feel left out with million things happening around AI.Here&#39;s a MEGA THREAD🧵 (with resources) to keep you up-to-date: . &mdash; Barsee 🐶 (@heyBarsee) February 25, 2023 SODA: Million-scale Dialogue Distillation with Social Commonsense Contextualization, code . @misc{kim2022soda, title={SODA: Million-scale Dialogue Distillation with Social Commonsense Contextualization}, author={Hyunwoo Kim and Jack Hessel and Liwei Jiang and Ximing Lu and Youngjae Yu and Pei Zhou and Ronan Le Bras and Malihe Alikhani and Gunhee Kim and Maarten Sap and Yejin Choi}, year={2022}, eprint={2212.10465}, primaryClass={cs.CL} } . This is a baby GPT with two tokens 0/1 and context length of 3, viewing it as a finite state markov chain. It was trained on the sequence &quot;111101111011110&quot; for 50 iterations. The parameters and the architecture of the Transformer modifies the probabilities on the arrows.E.g. we… pic.twitter.com/vj10nZEXlH . &mdash; Andrej Karpathy (@karpathy) April 9, 2023 Differentiable Finite State Machines . jerryjliu/llama_index — a project that provides a central interface to connect your LLM’s with external data . auspicious3000/SpeechSplit — Unsupervised Speech Decomposition Via Triple Information Bottleneck . bjelkenhed/whisper-large-sv, train . KBLab/rixvox Finding Speeches in the Riksdag’s Debates RixVox: A Swedish Speech Corpus with 5500 Hours of Speech from Parliamentary Debates, code . Ultra fast ControlNet with Diffusers . Jzuluaga/wav2vec2-xls-r-300m-en-atc-uwb-atcc-and-atcosim . USC-TIMIT: a database of multimodal speech production data . Haskins_IEEE_Rate_Comparison_DB . mgnu0 . mocha . IEMOCAP . lucidrains/lion-pytorch — Lion, new optimizer discovered by Google Brain using genetic algorithms that is purportedly better than Adam(w), in Pytorch . lucidrains/denoising-diffusion-pytorch — Implementation of Denoising Diffusion Probabilistic Model in Pytorch . lucidrains/audiolm-pytorch — Implementation of AudioLM, a SOTA Language Modeling Approach to Audio Generation out of Google Research, in Pytorch . lucidrains/robotic-transformer-pytorch — Implementation of RT1 (Robotic Transformer) in Pytorch . lucidrains/recurrent-interface-network-pytorch — Implementation of Recurrent Interface Network (RIN), for highly efficient generation of images and video without cascading networks, in Pytorch . lucidrains/memory-efficient-attention-pytorch — Implementation of a memory efficient multi-head attention as proposed in the paper, “Self-attention Does Not Need O(n²) Memory” . lucidrains/PaLM-rlhf-pytorch — Implementation of RLHF (Reinforcement Learning with Human Feedback) on top of the PaLM architecture. Basically ChatGPT but with PaLM . hazyResearch/flash-attention — Fast and memory-efficient exact attention . lucidrains/make-a-video-pytorch — Implementation of Make-A-Video, new SOTA text to video generator from Meta AI, in Pytorch . lucidrains/rvq-vae-gpt — My attempts at applying Soundstream design on learned tokenization of text and then applying hierarchical attention to text generation . lucidrains/imagen-pytorch — Implementation of Imagen, Google’s Text-to-Image Neural Network, in Pytorch . crowsonkb/v-diffusion-jax — v objective diffusion inference code for JAX. . Datasheet for the Pile . Cocktail HuBERT: Generalized Self-Supervised Pre-training for Mixture and Single-Source Speech . @misc{fazelzarandi2023cocktail, title={Cocktail HuBERT: Generalized Self-Supervised Pre-training for Mixture and Single-Source Speech}, author={Maryam Fazel-Zarandi and Wei-Ning Hsu}, year={2023}, eprint={2303.11131}, archivePrefix={arXiv}, primaryClass={cs.CL} } . BlinkDL/RWKV-LM — RWKV is an RNN with transformer-level LLM performance. It can be directly trained like a GPT (parallelizable). So it’s combining the best of RNN and transformer - great performance, fast inference, saves VRAM, fast training, “infinite” ctx_len, and free sentence embedding. . cohogain/whisper-large-v2-ga-IE, cohogain/whisper-medium-ga-IE-cv11-fleurs-livaud . HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace, code . Efficient Audio Captioning Transformer with Patchout and Text Guidance . @misc{kouzelis2023efficient, title={Efficient Audio Captioning Transformer with Patchout and Text Guidance}, author={Thodoris Kouzelis and Grigoris Bastas and Athanasios Katsamanis and Alexandros Potamianos}, year={2023}, eprint={2304.02916}, archivePrefix={arXiv}, primaryClass={cs.SD} } . Continuous Speech Separation with Conformer . @misc{chen2020continuous, title={Continuous Speech Separation with Conformer}, author={Sanyuan Chen and Yu Wu and Zhuo Chen and Jian Wu and Jinyu Li and Takuya Yoshioka and Chengyi Wang and Shujie Liu and Ming Zhou}, year={2020}, eprint={2008.05773}, archivePrefix={arXiv}, primaryClass={eess.AS} } . From Undercomplete to Sparse Overcomplete Autoencoders to Improve LF-MMI based Speech Recognition . @inproceedings{handekabil22_interspeech, author={Selen {Hande Kabil} and Herve Bourlard}, title={From Undercomplete to Sparse Overcomplete Autoencoders to Improve LF-MMI based Speech Recognition}, year=2022, booktitle={Proc. Interspeech 2022}, pages={1061--1065}, doi={10.21437/Interspeech.2022-11390} } . Dealing with Unknowns in Continual Learning for End-to-end Automatic Speech Recognition . @inproceedings{sustek22_interspeech, author={Martin Sustek and Samik Sadhu and Hynek Hermansky}, title={Dealing with Unknowns in Continual Learning for End-to-end Automatic Speech Recognition}, year=2022, booktitle={Proc. Interspeech 2022}, pages={1046--1050}, doi={10.21437/Interspeech.2022-11139} } . A Temporal Extension of Latent Dirichlet Allocation for Unsupervised Acoustic Unit Discovery . @inproceedings{vandermerwe22_interspeech, author={Werner {van der Merwe} and Herman Kamper and Johan {Adam du Preez}}, title={A Temporal Extension of Latent Dirichlet Allocation for Unsupervised Acoustic Unit Discovery}, year=2022, booktitle={Proc. Interspeech 2022}, pages={1426--1430}, doi={10.21437/Interspeech.2022-11369} } . DEFORMER: Coupling Deformed Localized Patterns with Global Context for Robust End-to-end Speech Recognition . @inproceedings{xie22b_interspeech, author={Jiamin Xie and John H.L. Hansen}, title={DEFORMER: Coupling Deformed Localized Patterns with Global Context for Robust End-to-end Speech Recognition}, year=2022, booktitle={Proc. Interspeech 2022}, pages={1392--1396}, doi={10.21437/Interspeech.2022-11172} } . Knowledge of accent differences can be used to predict speech recognition . @inproceedings{szalay22_interspeech, author={Tuende Szalay and Mostafa Shahin and Beena Ahmed and Kirrie Ballard}, title={Knowledge of accent differences can be used to predict speech recognition}, year=2022, booktitle={Proc. Interspeech 2022}, pages={1372--1376}, doi={10.21437/Interspeech.2022-10162} } . Improving Phonetic Transcriptions of Children’s Speech by Pronunciation Modelling with Constrained CTC-Decoding . @inproceedings{rumberg22b_interspeech, author={Lars Rumberg and Christopher Gebauer and Hanna Ehlert and Ulrike Lüdtke and Jörn Ostermann}, title={Improving Phonetic Transcriptions of Children’s Speech by Pronunciation Modelling with Constrained CTC-Decoding}, year=2022, booktitle={Proc. Interspeech 2022}, pages={1357--1361}, doi={10.21437/Interspeech.2022-332} } . Automatic Pronunciation Assessment using Self-Supervised Speech Representation Learning . @inproceedings{kim22k_interspeech, author={Eesung Kim and Jae-Jin Jeon and Hyeji Seo and Hoon Kim}, title={Automatic Pronunciation Assessment using Self-Supervised Speech Representation Learning}, year=2022, booktitle={Proc. Interspeech 2022}, pages={1411--1415}, doi={10.21437/Interspeech.2022-10245} } . Probing phoneme, language and speaker information in unsupervised speech representations . @inproceedings{deseyssel22_interspeech, author={Maureen {de Seyssel} and Marvin Lavechin and Yossi Adi and Emmanuel Dupoux and Guillaume Wisniewski}, title={Probing phoneme, language and speaker information in unsupervised speech representations}, year=2022, booktitle={Proc. Interspeech 2022}, pages={1402--1406}, doi={10.21437/Interspeech.2022-373} } . VQ-T: RNN Transducers using Vector-Quantized Prediction Network States . @inproceedings{shi22b_interspeech, author={Jiatong Shi and George Saon and David Haws and Shinji Watanabe and Brian Kingsbury}, title={VQ-T: RNN Transducers using Vector-Quantized Prediction Network States}, year=2022, booktitle={Proc. Interspeech 2022}, pages={1656--1660}, doi={10.21437/Interspeech.2022-414} } . Source-Filter HiFi-GAN: Fast and Pitch Controllable High-Fidelity Neural Vocoder, chomeyama/SiFiGAN . @misc{yoneyama2023sourcefilter, title={Source-Filter HiFi-GAN: Fast and Pitch Controllable High-Fidelity Neural Vocoder}, author={Reo Yoneyama and Yi-Chiao Wu and Tomoki Toda}, year={2023}, eprint={2210.15533}, archivePrefix={arXiv}, primaryClass={cs.SD} } . Textless Speech-to-Music Retrieval Using Emotion Similarity . UL2 20B: An Open Source Unified Language Learner, checkpoints . DeBERTa: Decoding-enhanced BERT with Disentangled Attention, code . @misc{he2021deberta, title={DeBERTa: Decoding-enhanced BERT with Disentangled Attention}, author={Pengcheng He and Xiaodong Liu and Jianfeng Gao and Weizhu Chen}, year={2021}, eprint={2006.03654}, archivePrefix={arXiv}, primaryClass={cs.CL} } . Flow Network based Generative Models for Non-Iterative Diverse Candidate Generation . @misc{bengio2021flow, title={Flow Network based Generative Models for Non-Iterative Diverse Candidate Generation}, author={Emmanuel Bengio and Moksh Jain and Maksym Korablyov and Doina Precup and Yoshua Bengio}, year={2021}, eprint={2106.04399}, archivePrefix={arXiv}, primaryClass={cs.LG} } . thammegowda/016-many-eng-v2 — Many-English v2 . Sequence Modeling With CTC, Example CTC Decoder in Python . Announcing OpenChatKit, togethercomputer/OpenChatKit, spaces . microsoft/computervision-recipes . asuni/wavelet_prosody_toolkit . . VIFAX . @presidentofireland - Youtube . An Caighdeán Oifigiúil . Gramadach na Gaeilge . Bedell, James 3 . An Ultrasound Investigation of Irish Palatalization . . lohku, Modèle:se-décl-pari, Modèle:se-décl-contract, Buddhisma, 1700-lohku, okr, Modèle:se-décl-impari-sans-alt, ceahkki, lihtter, hávvi, Fága 6a ja 6á, Conjugaison:same_du_Nord/háddjet, .",
            "url": "https://jimregan.github.io/notes/links/2023/04/13/misc-links.html",
            "relUrl": "/links/2023/04/13/misc-links.html",
            "date": " • Apr 13, 2023"
        }
        
    
  
    
        ,"post36": {
            "title": "Interesting links, 04/04/2023",
            "content": "Flow Network based Generative Models for Non-Iterative Diverse Candidate Generation . @misc{bengio2021flow, title={Flow Network based Generative Models for Non-Iterative Diverse Candidate Generation}, author={Emmanuel Bengio and Moksh Jain and Maksym Korablyov and Doina Precup and Yoshua Bengio}, year={2021}, eprint={2106.04399}, archivePrefix={arXiv}, primaryClass={cs.LG} } . Make-A-Video: Text-to-Video Generation without Text-Video Data . @misc{singer2022makeavideo, doi = {10.48550/ARXIV.2209.14792}, url = {https://arxiv.org/abs/2209.14792}, author = {Singer, Uriel and Polyak, Adam and Hayes, Thomas and Yin, Xi and An, Jie and Zhang, Songyang and Hu, Qiyuan and Yang, Harry and Ashual, Oron and Gafni, Oran and Parikh, Devi and Gupta, Sonal and Taigman, Yaniv}, title = {Make-A-Video: Text-to-Video Generation without Text-Video Data}, year = {2022}, } . A real-time filled pause detection system for spontaneous speech recognition . @inproceedings{goto99_eurospeech, author={Masataka Goto and Katunobu Itou and Satoru Hayamizu}, title={A real-time filled pause detection system for spontaneous speech recognition}, year=1999, booktitle={Proc. 6th European Conference on Speech Communication and Technology (Eurospeech 1999)}, pages={227--230}, doi={10.21437/Eurospeech.1999-60} } . TransFusion: Transcribing Speech with Multinomial Diffusion, code – not open source. . @misc{baas2022transfusion, title={TransFusion: Transcribing Speech with Multinomial Diffusion}, author={Matthew Baas and Kevin Eloff and Herman Kamper}, year={2022}, eprint={2210.07677}, archivePrefix={arXiv}, primaryClass={eess.AS} } . The Norwegian Parliamentary Speech Corpus . @inproceedings{solberg-ortiz-2022-norwegian, title = &quot;The {N}orwegian Parliamentary Speech Corpus&quot;, author = &quot;Solberg, Per Erik and Ortiz, Pablo&quot;, booktitle = &quot;Proceedings of the Thirteenth Language Resources and Evaluation Conference&quot;, month = jun, year = &quot;2022&quot;, address = &quot;Marseille, France&quot;, publisher = &quot;European Language Resources Association&quot;, pages = &quot;1003--1008&quot;, } . There is more to Hungarian than goulash! Grammar Course for Beginners . sp-nitech/diffsptk — A differential version of SPTK . soobinseo/Transformer-TTS — A Pytorch Implementation of “Neural Speech Synthesis with Transformer Network” . jxzhanggg/nonparaSeq2seqVC_code — Implementation code of non-parallel sequence-to-sequence VC . snakers4/silero-vad . Many-to-English: Data v2 and Statistics . Probably the best thing you&#39;ll see today.In 2017, a group of developers hilariously competed for who could create worst volume control interface in the world.The results 🧵1/22 . &mdash; 0xDesigner (@0xDesigner) April 2, 2023 neonbjb/tortoise-tts — A multi-voice TTS system trained with an emphasis on quality . urschrei/pyzotero — Pyzotero: a Python client for the Zotero API . NaturalSpeech: End-to-End Text to Speech Synthesis with Human-Level Quality . @misc{tan2022naturalspeech, title={NaturalSpeech: End-to-End Text to Speech Synthesis with Human-Level Quality}, author={Xu Tan and Jiawei Chen and Haohe Liu and Jian Cong and Chen Zhang and Yanqing Liu and Xi Wang and Yichong Leng and Yuanhao Yi and Lei He and Frank Soong and Tao Qin and Sheng Zhao and Tie-Yan Liu}, year={2022}, eprint={2205.04421}, archivePrefix={arXiv}, primaryClass={eess.AS} } . Uimhreacha . Self-Instruct: Aligning Language Model with Self Generated Instructions, code . @misc{wang2022selfinstruct, title={Self-Instruct: Aligning Language Model with Self Generated Instructions}, author={Yizhong Wang and Yeganeh Kordi and Swaroop Mishra and Alisa Liu and Noah A. Smith and Daniel Khashabi and Hannaneh Hajishirzi}, year={2022}, eprint={2212.10560}, archivePrefix={arXiv}, primaryClass={cs.CL} } . Introduction to Human Behavioral Biology .",
            "url": "https://jimregan.github.io/notes/links/2023/04/04/misc-links.html",
            "relUrl": "/links/2023/04/04/misc-links.html",
            "date": " • Apr 4, 2023"
        }
        
    
  
    
        ,"post37": {
            "title": "Interesting links, 07/03/2023",
            "content": "Google USM: Scaling Automatic Speech Recognition Beyond 100 Languages, website . @misc{zhang2023usm, doi = {10.48550/ARXIV.2303.01037}, author = {Zhang, Yu and Han, Wei and Qin, James and Wang, Yongqiang and Bapna, Ankur and Chen, Zhehuai and Chen, Nanxin and Li, Bo and Axelrod, Vera and Wang, Gary and Meng, Zhong and Hu, Ke and Rosenberg, Andrew and Prabhavalkar, Rohit and Park, Daniel S. and Haghani, Parisa and Riesa, Jason and Perng, Ginger and Soltau, Hagen and Strohman, Trevor and Ramabhadran, Bhuvana and Sainath, Tara and Moreno, Pedro and Chiu, Chung-Cheng and Schalkwyk, Johan and Beaufays, Françoise and Wu, Yonghui}, title = {Google USM: Scaling Automatic Speech Recognition Beyond 100 Languages}, year = {2023}, } . Flamingo: a Visual Language Model for Few-Shot Learning . @misc{alayrac2022flamingo, doi = {10.48550/ARXIV.2204.14198}, author = {Alayrac, Jean-Baptiste and Donahue, Jeff and Luc, Pauline and Miech, Antoine and Barr, Iain and Hasson, Yana and Lenc, Karel and Mensch, Arthur and Millican, Katie and Reynolds, Malcolm and Ring, Roman and Rutherford, Eliza and Cabi, Serkan and Han, Tengda and Gong, Zhitao and Samangooei, Sina and Monteiro, Marianne and Menick, Jacob and Borgeaud, Sebastian and Brock, Andrew and Nematzadeh, Aida and Sharifzadeh, Sahand and Binkowski, Mikolaj and Barreira, Ricardo and Vinyals, Oriol and Zisserman, Andrew and Simonyan, Karen}, title = {Flamingo: a Visual Language Model for Few-Shot Learning}, year = {2022}, } . A Comparison of Speech Data Augmentation Methods Using S3PRL Toolkit . @misc{huh2023augmentation, doi = {10.48550/ARXIV.2303.00510}, author = {Huh, Mina and Ray, Ruchira and Karnei, Corey}, title = {A Comparison of Speech Data Augmentation Methods Using S3PRL Toolkit}, year = {2023}, } . revdotcom/fstalign — An efficient OpenFST-based tool for calculating WER and aligning two transcript sequences. .",
            "url": "https://jimregan.github.io/notes/links/2023/03/07/misc-links.html",
            "relUrl": "/links/2023/03/07/misc-links.html",
            "date": " • Mar 7, 2023"
        }
        
    
  
    
        ,"post38": {
            "title": "Get WER with Whisper and Huggingface",
            "content": "%%capture !pip install transformers datasets !python -m pip install huggingface_hub . from huggingface_hub import notebook_login notebook_login() . !pip install evaluate . from datasets import load_dataset rd = load_dataset(&quot;jimregan/sbtal_riksdag_asr&quot;, split=&quot;test&quot;, use_auth_token=True) . Downloading and preparing dataset None/None to /root/.cache/huggingface/datasets/jimregan___parquet/jimregan--sbtal_riksdag_asr-8175b7a674e1b59a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec... Dataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/jimregan___parquet/jimregan--sbtal_riksdag_asr-8175b7a674e1b59a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data. . !pip install jiwer . Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/ Collecting jiwer Downloading jiwer-2.5.1-py3-none-any.whl (15 kB) Collecting levenshtein==0.20.2 Downloading Levenshtein-0.20.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB) ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 27.1 MB/s eta 0:00:00 Collecting rapidfuzz&lt;3.0.0,&gt;=2.3.0 Downloading rapidfuzz-2.13.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB) ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.2/2.2 MB 87.5 MB/s eta 0:00:00 Installing collected packages: rapidfuzz, levenshtein, jiwer Successfully installed jiwer-2.5.1 levenshtein-0.20.2 rapidfuzz-2.13.7 . from datasets import load_dataset from transformers import WhisperForConditionalGeneration, WhisperProcessor import torch from evaluate import load processor = WhisperProcessor.from_pretrained(&quot;jimregan/whisper-small-sv-riksdag&quot;) model = WhisperForConditionalGeneration.from_pretrained(&quot;jimregan/whisper-small-sv-riksdag&quot;).to(&quot;cuda&quot;) def map_to_pred(batch): audio = batch[&quot;audio&quot;] input_features = processor(audio[&quot;array&quot;], sampling_rate=audio[&quot;sampling_rate&quot;], return_tensors=&quot;pt&quot;).input_features batch[&quot;reference&quot;] = processor.tokenizer._normalize(batch[&#39;text&#39;]) with torch.no_grad(): predicted_ids = model.generate(input_features.to(&quot;cuda&quot;))[0] transcription = processor.decode(predicted_ids) batch[&quot;prediction&quot;] = processor.tokenizer._normalize(transcription) return batch result = rd.map(map_to_pred) wer = load(&quot;wer&quot;) print(100 * wer.compute(references=result[&quot;reference&quot;], predictions=result[&quot;prediction&quot;])) . /usr/local/lib/python3.8/dist-packages/transformers/generation/utils.py:1273: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 448 (`generation_config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation. warnings.warn( . 1253.3994007835906 . wer = load(&quot;wer&quot;) print(100 * wer.compute(references=result[&quot;reference&quot;], predictions=result[&quot;prediction&quot;])) . 1253.3994007835906 . result[&quot;prediction&quot;] . [&#39;i b&#39;, &#39;as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;och en ansvarsfull politik for investeringar for jobb och for hallbar tillvaxt&#39;, &#39;a&#39;, &#39;le&#39;, &#39;&#39;, &#39;and to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to&#39;, &#39;de har tre myndigheterna ar centrala i var stadsforvaltning&#39;, &#39;for&#39;, &#39;i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i&#39;, &#39;talman jag far borja med att yrka bifall till forslaget i betankande som handlar om anslaget till de har tre myndigheterna tullverket skatteverket och kronofogde myndigheterna&#39;, &#39;&#39;, &#39;motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion motion&#39;, &#39;as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as&#39;, &#39;regeringen foreslar i propositionen&#39;, &#39;att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att&#39;, &#39;statliga verksamhetsstod till idrottsens utbildningsverksamhet nu ska fa detta lagreglerat&#39;, &#39;and that&#39;, &#39;av sysselsverksamhet som bestar i fordelning av statsbidrag ska ompassa offentlighetsprincipen&#39;, &#39;&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;&#39;, &#39;h&#39;, &#39;le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i&#39;, &#39;och for att fa fram en lit kravs en stor bredd&#39;, &#39;rererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererererere&#39;, &#39;d&#39;, &#39;n&#39;, &#39;&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as&#39;, &#39;d&#39;, &#39;&#39;, &#39;k r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r r&#39;, &#39;d&#39;, &#39;aka en tydlig ambition och ett uttalad onskan om att idrotten ska na annu fler och bli annu bredare&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;den gamla oforutserbara finansieringsmodellen dar idrotten finansieras via svenska spel har ersatts&#39;, &#39;mil finansieringsmodell via skatten&#39;, &#39;och darmed har idrottsrorelsen en mer stabil ekonomi och vet vad man har att rora sig med&#39;, &#39;le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le&#39;, &#39;att vara medlemmar i en forening&#39;, &#39;is is is is is is is is is is is is is as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as&#39;, &#39;att idrottning i sverige i hogre utstrackning i de flesta andra landerna ar till for alla som bor har&#39;, &#39;ekonomiska muskler ar&#39;, &#39;underhall stodet&#39;, &#39;&#39;, &#39;det var det verkar en tamligen okontroversiell forandring men likval betydelsefull och jag vill franningens skull darfor fru talman borjar med att yrka bifall till forslaget&#39;, &#39;bostadsbidraget ar en viktig del av den disponibla inkomsten for ganska manga barnfamiljer i vart land&#39;, &#39;and&#39;, &#39;&#39;, &#39;stodja ekonomiskt svagare barnfamiljer&#39;, &#39;med nuvarande konstruktion av bostadsbidraget kan barnfamiljer fa ett&#39;, &#39;by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by&#39;, &#39;tack fru talman idag har vi upp ett forslag om att infora en ny del inom bostadsbidraget for barn som bor vaxelvis hos sina separerade foraldrar samtidigt som det vaxelvis har stodet inom&#39;, &#39;d&#39;, &#39;men det finns inget alternativ for att barnen faktiskt kan bo vaxelvis hos bada sina foraldrar&#39;, &#39;and&#39;, &#39;&#39;, &#39;d&#39;, &#39;&#39;, &#39;le&#39;, &#39;or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;for ett barn som i praktiken bor vaxelvis hos tva foraldrar&#39;, &#39;&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;0&#39;, &#39;men dagens system bygger som sagt pa ett antal gammal om att barnen&#39;, &#39;&#39;, &#39;eller for att man har barn som vistas dar tidvis som sa kallade umingsban&#39;, &#39;&#39;, &#39;&#39;, &#39;and it is&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;d&#39;, &#39;vagmasta roster nu ser till att vi far ett statligt huvudmannenskap och att det antligen blir en utredning som ska se till att detta ocksa sker pa basta satt&#39;, &#39;&#39;, &#39;le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le&#39;, &#39;so har det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det det&#39;, &#39;s&#39;, &#39;&#39;, &#39;&#39;, &#39;&#39;, &#39;att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att&#39;, &#39;&#39;, &#39;och det ar en fraga som svendemokraterna har drivit i manga ar och faktum ar att vi&#39;, &#39;att vilk&#39;, &#39;d&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or&#39;, &#39;som avled for drygt ett manad sedan&#39;, &#39;le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;y&#39;, &#39;d&#39;, &#39;but i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i&#39;, &#39;att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att&#39;, &#39;ar med oss i debatten&#39;, &#39;min kollega cecilia videgrin och jag halsade pa maggan bara nagra dagar innan honorable gick bort&#39;, &#39;i&#39;, &#39;et boande som lig i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i&#39;, &#39;pa en kulle med utsiktiga vare liten insko&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;for de som kan skota sig sjalva&#39;, &#39;&#39;, &#39;&#39;, &#39;fru talman&#39;, &#39;&#39;, &#39;&#39;, &#39;g&#39;, &#39;d&#39;, &#39;by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by&#39;, &#39;anser att det bor inforas en aldre boendegaranti&#39;, &#39;ar i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i&#39;, &#39;&#39;, &#39;and&#39;, &#39;i&#39;, &#39;d&#39;, &#39;&#39;, &#39;i i sverige over 65 ar&#39;, &#39;&#39;, &#39;&#39;, &#39;&#39;, &#39;0&#39;, &#39;so den&#39;, &#39;an&#39;, &#39;d&#39;, &#39;and&#39;, &#39;adde behover arbetas fram en lag&#39;, &#39;0&#39;, &#39;and&#39;, &#39;d&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;y&#39;, &#39;i&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;&#39;, &#39;galler den som i begransad omfattning saljer varor och tjanster mot kontantbetalning eller mot betalning med kontokot och det har vi hort har innan redovisas av fler&#39;, &#39;as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as&#39;, &#39;det inne ba r as a 000&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;me&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;so den&#39;, &#39;or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;d&#39;, &#39;&#39;, &#39;as&#39;, &#39;h&#39;, &#39;d&#39;, &#39;&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or&#39;, &#39;me&#39;, &#39;d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;d&#39;, &#39;med forsaljning som understiger detta vill upp&#39;, &#39;s&#39;, &#39;det var ett ganska omfattande och omfacerterat svar&#39;, &#39;om en kanske inte riktigt pa den fraga som jag hade stallt jag far forsoka aterkomma och specifiktera fragan lite langre fram&#39;, &#39;svenska industri som i mangt och mycket ar den ekonomiska basen i den svenska modellen och i det svenska velofardsbygget ar bland mycket annat en valdigt energimentensiv verksamhet for&#39;, &#39;y&#39;, &#39;d&#39;, &#39;ungefar i runda tal en tregedel av den svenska elforbrukningen&#39;, &#39;jag mjoljer&#39;, &#39;d&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;tack for det har talman och jag vill naturligtvis inleda med att tacka statsradet forsvaret pa&#39;, &#39;de vi pratar om det ar huvudsak den svenska skogsindustrin det stalindustrin det ar en stor del av grumaringen och det keminindustrin det finns nagra till ytterligare darutover men det har ar de stora&#39;, &#39;205 sa inforde alltsa da den davarande socialdemokratiska regeringen det sa kallade pfe programmet&#39;, &#39;and it is is is is is is is is is is is is is is is is is is is is is is as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as&#39;, &#39;for just de&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;precis som statsradet sjalv namnde&#39;, &#39;&#39;, &#39;da benamns som processrelaterad el&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;har talman programmet hade och har for dem som fortfarande omfattas programmet pagar i fortfarande&#39;, &#39;&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;&#39;, &#39;but for&#39;, &#39;&#39;, &#39;&#39;, &#39;riksrevisionen noterar att statens aktiviteter for att snabbt oka realens skyddarskog har intensifierats kraftigt under de senaste aren&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;riksrevisionen lamnar med anledning av detta rad kommentarer&#39;, &#39;de handlar mycket om att hitta mer kostnadseffektiva metoder samt till vagagangsatt som kan ge storre acceptans hos skogsagarna&#39;, &#39;&#39;, &#39;i&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;&#39;, &#39;och i att regeringen betonar att aven funktionell skotsel&#39;, &#39;&#39;, &#39;i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i&#39;, &#39;konsekvenserna av detta konstaterande tycker vi ar otrackligt analyserade i regeringens skrivelse&#39;, &#39;&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;&#39;, &#39;vi tycker inte det ar lampligt att toleransnivaerna far vara som kunde maximalt talas&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;att&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;&#39;, &#39;fru tar manna&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;for me&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;med den nationella lakemilista ar att den ska kunna koppla sig ihop med journalistsystemen&#39;, &#39;och pa sa satt bidra till att en okad patientsakerhet&#39;, &#39;&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;att in och&#39;, &#39;for&#39;, &#39;by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by&#39;, &#39;&#39;, &#39;och jag yrkar pa reservation fyra och tio&#39;, &#39;me&#39;, &#39;att&#39;, &#39;re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re re&#39;, &#39;&#39;, &#39;d&#39;, &#39;och debattera som sig bor flytta i ett vass som diskuteras mindre men som bor fa lika stort utrymme&#39;, &#39;ar&#39;, &#39;&#39;, &#39;kunnade valja&#39;, &#39;&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;l&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;a&#39;, &#39;by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by by&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;because you have not the right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right right&#39;, &#39;n&#39;, &#39;d&#39;, &#39;ar en ind&#39;, &#39;som patienten sjalv administrerar&#39;, &#39;le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le&#39;, &#39;d&#39;, &#39;and&#39;, &#39;att&#39;, &#39;nu befinner oss vid oss&#39;, &#39;ganska tvartom i ett lage dar&#39;, &#39;dar har blivit en av de riktigt centrala fragorna&#39;, &#39;&#39;, &#39;kan talman&#39;, &#39;&#39;, &#39;s&#39;, &#39;&#39;, &#39;a&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;och darmed ocksa en nybyggnadstakt som har laggat langt under jamforbara lander i&#39;, &#39;so dar det set ut&#39;, &#39;vi ar helt enkelt inte byggt eller lyckats forma och bygga de bostader som behovs&#39;, &#39;och det ar klart nar man tillater att vara det under sa lang tid jag da uppstar problem&#39;, &#39;&#39;, &#39;svart att fa igang en storre diskussion svart att fa det att riktigt lyfta i debatten&#39;, &#39;det fanns ju en tid nar det ar de som agnade sig at bostadspolitik kanske lite grann klagade over att det var&#39;, &#39;and it makes it that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that&#39;, &#39;&#39;, &#39;det ar manga vaxande kommuner runt om i sverige som har svart att bygga sa mycket som skulle behovas pa&#39;, &#39;&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;for okat bostadsbyggande och fler bostader precis som den har regeringen&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i i&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;&#39;, &#39;&#39;, &#39;&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;&#39;, &#39;den perso le integrititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititititit&#39;, &#39;i&#39;, &#39;varje manniska har ratt till sin personliga svar&#39;, &#39;&#39;, &#39;or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or or&#39;, &#39;of&#39;, &#39;i&#39;, &#39;&#39;, &#39;d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;me&#39;, &#39;men vill till dem som lyssnar pa debatten sarskilt framhalla det viktiga arbete som framover&#39;, &#39;&#39;, &#39;&#39;, &#39;her talman&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;i&#39;, &#39;&#39;, &#39;kan behova vidtas&#39;, &#39;d&#39;, &#39;&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;och manga andra&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as&#39;, &#39;pa var hemsida&#39;, &#39;d&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;y&#39;, &#39;an&#39;, &#39;vi menar alltsa att det finns stora fordelar att vinna pa att lata olika tillsynsfragor pa&#39;, &#39;kring integritet samlas hos enmyndighet&#39;, &#39;att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att att&#39;, &#39;och vil&#39;, &#39;d&#39;, &#39;och det har namnts tidigare har idag dar utover har tio tusentals drabbats av svard sjukdom och fatt kroniska besvar&#39;, &#39;fradtalman&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;&#39;, &#39;&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;&#39;, &#39;&#39;, &#39;&#39;, &#39;&#39;, &#39;and of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of&#39;, &#39;n&#39;, &#39;n&#39;, &#39;&#39;, &#39;vaccinerade att vi kommit sa langt&#39;, &#39;is&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;till forskning och utveckling av vaccin var det andra att varldens nationer tillsammans sag till att finansiera framtagandet av vaccin&#39;, &#39;klart allman&#39;, &#39;d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d d&#39;, &#39;&#39;, &#39;bara ett ar senare skulle vara mitt en massvaccination&#39;, &#39;d&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;sa mycket beraknas alkohallen kostar vart samhalle varje ar&#39;, &#39;en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en en&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as&#39;, &#39;n&#39;, &#39;or all of the that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that that&#39;, &#39;och de som dor i for tid pa grund av alkoholrelaterade sjukdomar och olyckor&#39;, &#39;and&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;miss handes fall i ssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssssss&#39;, &#39;r&#39;, &#39;&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;pa grund av bakfylla&#39;, &#39;625 tusen alkoholrelaterade sjukskrivningsdagar tas ut varje ar&#39;, &#39;&#39;, &#39;le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le&#39;, &#39;&#39;, &#39;a&#39;, &#39;sa fortal man att alkoholen kostar oss langt mycket mer an vad den ger oss det vi val medvetna om&#39;, &#39;and just that is why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why why&#39;, &#39;&#39;, &#39;framgangsrika alkoholpolitik&#39;, &#39;d&#39;, &#39;y&#39;, &#39;d&#39;, &#39;&#39;, &#39;&#39;, &#39;d&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;&#39;, &#39;det enklare svaret ar for att vi diskuterar fragan att vi i sveris riksdagen lyfter och diskuterar kemikalier och giftryg miljo har i kammaren&#39;, &#39;&#39;, &#39;&#39;, &#39;&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;betankande mjolj trattan pa vag med en giftfri vardag&#39;, &#39;&#39;, &#39;and all are&#39;, &#39;far talman&#39;, &#39;&#39;, &#39;d&#39;, &#39;&#39;, &#39;&#39;, &#39;and&#39;, &#39;&#39;, &#39;d&#39;, &#39;for far&#39;, &#39;&#39;, &#39;&#39;, &#39;&#39;, &#39;but but but but but but but but but but but but but but but but but but but but but but but but but but but but but but but but but but but but but but but but&#39;, &#39;as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as&#39;, &#39;as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as as&#39;, &#39;&#39;, &#39;&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;&#39;, &#39;&#39;, &#39;&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;vi alla beroende av kemikalier och det kemikindustrin producerar&#39;, &#39;det parlamentariska laget innebar en rad utmaningar for ansvarsfordelningar mellan riksdag och kring&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;and&#39;, &#39;&#39;, &#39;&#39;, &#39;for to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to&#39;, &#39;y&#39;, &#39;och det ar just vad detta arende till stor del handlar om&#39;, &#39;i regeringen skriver sig sju tio fem redogor regeringen for vilka atgarder den vidtagit med anledning av det till kannagivandena som riksdagen har beslutat om&#39;, &#39;och ena sidan vad galler riksdagens uppgift att stifta lagar besluta om skatter till staten och bestamma hur statens medel ska anvandas&#39;, &#39;and in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in&#39;, &#39;med vad regeringen gjort for att folja vara beslut har i kammaren&#39;, &#39;for&#39;, &#39;&#39;, &#39;namligen att vi konstaterar att regeringens redogorelse for behandlingen av riksdagens skrivelser sedan flera ar tillbaka ger en mer utfoljig redovisning av atgarder vidtagna av regeringen och kan anses ge en korrekt bild av riksdagens skrivelser till regeringen&#39;, &#39;behandlar vi hur riksdagen ser pa just regeringens hantering av arat i kannagivanden&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;nar det galler behandlingen av riksdagens skrivelser pa konstitutionsutskottets omrade redovisas sex till karnan givande den som slutbehandlade&#39;, &#39;vi i kou gor nar det galler dessa ingen annan bedomning an regeringen&#39;, &#39;trytt talman&#39;, &#39;y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y y&#39;, &#39;&#39;, &#39;&#39;, &#39;det gjorde ocksa att aktieagare och medlemmar i ekonomiska foreningar riskerar att inte kunna utova sina rattigheter i de bolag eller foreningar dar de var agare eller medlemmar&#39;, &#39;t&#39;, &#39;regeringen tog darfor snabbt fram temporara andringar i lagstiftningen for att mojliggora helt digitala stammer och arsmoten eller stammer och arsmoten med endast posterosning&#39;, &#39;i&#39;, &#39;and&#39;, &#39;precis de som de forlangningar vi nu har att besluta om ar nodvandiga eftersom pandemin ser ut och blir langvarig&#39;, &#39;men jag menar forutalman att fragan ar storre an att bara forlanga en tillfallig lagstiftning&#39;, &#39;till att borja med sa har den nuvarande tillfalliga lagstiftningen fatt viss kritik&#39;, &#39;det galler bland annat mojligheterna att genomfora stammer med endast posterosning&#39;, &#39;le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le le&#39;, &#39;en global pandemi drogs snabt fram over varlden och omojlig gjorde folksamlinger&#39;, &#39;men det finns ocksa ett bredare perspektiv i fragan som inte ska glommas bort&#39;, &#39;aven om det till viss del av kompensierat som ytterligare bestammelser om minoritetsskydd&#39;, &#39;namligen den att digitala stammor ocksa har manga fordelar och kan vara ett satt att starka agar eller medlemsdemokratin&#39;, &#39;&#39;, &#39;&#39;, &#39;jag har under de senaste manaderna varit i kontakt med foretradare fran en rad bolag och foreningar som genomfor digitala stammer och hors deras inspel&#39;, &#39;&#39;, &#39;och det ar i sig ett skal att gora mer i genomgripande utredning om lagstiftningen&#39;, &#39;and&#39;] .",
            "url": "https://jimregan.github.io/notes/huggingface/whisper/wer/2023/03/02/wer-with-whisper-and-huggingface.html",
            "relUrl": "/huggingface/whisper/wer/2023/03/02/wer-with-whisper-and-huggingface.html",
            "date": " • Mar 2, 2023"
        }
        
    
  
    
        ,"post39": {
            "title": "Process test/validation data",
            "content": "from pathlib import Path from pydub import AudioSegment . BASE = Path(&quot;/home/joregan&quot;) TSV_PATH = BASE / &quot;train-valid-deliverable/round1/C1A1&quot; AUDIO_PATH = BASE / &quot;train-valid-deliverable&quot; / &quot;C1_audio&quot; OUT_PATH = BASE / &quot;train-valid-deliverable&quot; / &quot;split&quot; . parameters=[&quot;-ac&quot;, &quot;1&quot;, &quot;-acodec&quot;, &quot;pcm_s16le&quot;, &quot;-ar&quot;, &quot;16000&quot;] . MARKERS = [ &quot;#BREATH&quot;, &quot;#COUGH&quot;, &quot;#EH&quot;, &quot;#INAUDIBLE&quot;, &quot;#LIPSMACK&quot;, &quot;#NOISE&quot;, &quot;#OTHER&quot;, &quot;#PAUSE&quot;, &quot;#TRUNC&quot;, &quot;#UNKNOWN&quot; ] . TEST_VALID_SPEAKERS = &quot;&quot;&quot; 01 Jörgen Hellman TEST_M 02 Agneta Gille VAL_F 03 Amir Adan TEST_M 04 Teresa Carvalho TEST_F 05 Kerstin Nilsson VAL_F 06 Niclas Malmberg VAL_M 07 Carina Ståhl Herrstedt TEST_F 08 Vasiliki Tsouplaki VAL_F 09 Cecilie Tenfjord Toftby VAL_F 10 Ann-Britt Åsebol TEST_F 11 Karin Nilsson TEST_F 12 Ingemar Nilsson TEST_M 13 Mats Nordberg TEST_M 14 Ulrika Jörgensen TEST_F 15 Aylin Fazelian VAL_F 16 Björn Wiechel VAL_M 17 Sedat Dogru VAL_M 18 Oskar Öholm TEST_M 19 Eva Lohman VAL_F 20 Karin Granbom Ellison TEST_F 21 Åsa Karlsson VAL_F 22 Yilmaz Kerimo VAL_M 23 Aphram Melki TEST_M 24 Yasmine Bladelius TEST_F 25 Désirée Liljevall VAL_F 26 Erik Slottner VAL_M 27 Gustav Nilsson VAL_M 28 Linda Wemmert TEST_F 29 Mats Sander VAL_M 30 Arin Karapet VAL_M 31 Daniel Andersson TEST_M 32 David Josefsson TEST_M &quot;&quot;&quot; TEST = [] VALID = [] for line in TEST_VALID_SPEAKERS.split(&quot; n&quot;): if not &quot; t&quot; in line: continue parts = line.split(&quot; t&quot;) if parts[2].startswith(&quot;TEST&quot;): TEST.append(parts[0]) else: VALID.append(parts[0]) . OUT_DIR = BASE / &quot;train-valid-deliverable&quot; / &quot;split&quot; valid_tsv = open(str(BASE / &quot;valid.tsv&quot;), &quot;w&quot;) test_tsv = open(str(BASE / &quot;test.tsv&quot;), &quot;w&quot;) valid_tsv.write(&quot;path tduration ttext n&quot;) test_tsv.write(&quot;path tduration ttext n&quot;) for tsvfile in TSV_PATH.glob(&quot;*.tsv&quot;): stem = tsvfile.stem in_wav = AUDIO_PATH / f&quot;{stem}.wav&quot; wav_as = AudioSegment.from_wav(str(in_wav)) counter = 1 stem_pieces = stem.split(&quot;-&quot;) speaker_id = stem_pieces[1] test_set = False if speaker_id in VALID: test_set = False else: test_set = True with open(str(tsvfile)) as tsv: for line in tsv.readlines(): parts = line.strip().split(&quot; t&quot;) if line.startswith(&quot;Start&quot;): continue if parts[2].strip() in MARKERS: continue start = int(parts[0]) end = int(parts[1]) dur = end - start text = parts[2].strip() current_wav = wav_as[start:end] outname = OUT_PATH / f&quot;{stem}_{start}_{end}.wav&quot; text_raw = text word_buf = [] for word in text.split(&quot; &quot;): if word.startswith(&quot;#&quot;) or word.endswith(&quot;*&quot;): continue word_buf.append(word) text = &quot; &quot;.join(word_buf) if text == &quot;&quot;: continue if test_set: test_tsv.write(f&quot;{str(outname)} t{dur} t{text} n&quot;) else: valid_tsv.write(f&quot;{str(outname)} t{dur} t{text} n&quot;) current_wav.export(str(outname), format=&quot;wav&quot;, parameters=parameters) .",
            "url": "https://jimregan.github.io/notes/riksdag/sbtal/2023/03/01/process-data.html",
            "relUrl": "/riksdag/sbtal/2023/03/01/process-data.html",
            "date": " • Mar 1, 2023"
        }
        
    
  
    
        ,"post40": {
            "title": "Interesting links, 24/02/2023",
            "content": "Probing phoneme, language and speaker information in unsupervised speech representations, pdf . @inproceedings{deseyssel22_interspeech, author={Maureen {de Seyssel} and Marvin Lavechin and Yossi Adi and Emmanuel Dupoux and Guillaume Wisniewski}, title={ {Probing phoneme, language and speaker information in unsupervised speech representations}}, year=2022, booktitle={Proc. Interspeech 2022}, pages={1402--1406}, doi={10.21437/Interspeech.2022-373} } . VQ-T: RNN Transducers using Vector-Quantized Prediction Network States, pdf . @inproceedings{shi22b_interspeech, author={Jiatong Shi and George Saon and David Haws and Shinji Watanabe and Brian Kingsbury}, title={ {VQ-T: RNN Transducers using Vector-Quantized Prediction Network States}}, year=2022, booktitle={Proc. Interspeech 2022}, pages={1656--1660}, doi={10.21437/Interspeech.2022-414} } . CTC Variations Through New WFST Topologies, pdf . @inproceedings{laptev22_interspeech, author={Aleksandr Laptev and Somshubra Majumdar and Boris Ginsburg}, title={ {CTC Variations Through New WFST Topologies}}, year=2022, booktitle={Proc. Interspeech 2022}, pages={1041--1045}, doi={10.21437/Interspeech.2022-10854} } . nvidia-riva/riva-asrlib-decoder – Standalone implementation of the CUDA-accelerated WFST Decoder available in Riva . Dealing with Unknowns in Continual Learning for End-to-end Automatic Speech Recognition, pdf . @inproceedings{sustek22_interspeech, author={Martin Sustek and Samik Sadhu and Hynek Hermansky}, title={ {Dealing with Unknowns in Continual Learning for End-to-end Automatic Speech Recognition}}, year=2022, booktitle={Proc. Interspeech 2022}, pages={1046--1050}, doi={10.21437/Interspeech.2022-11139} } . From Undercomplete to Sparse Overcomplete Autoencoders to Improve LF-MMI based Speech Recognition, pdf . @inproceedings{handekabil22_interspeech, author={Selen {Hande Kabil} and Herve Bourlard}, title={ {From Undercomplete to Sparse Overcomplete Autoencoders to Improve LF-MMI based Speech Recognition}}, year=2022, booktitle={Proc. Interspeech 2022}, pages={1061--1065}, doi={10.21437/Interspeech.2022-11390} } . A Temporal Extension of Latent Dirichlet Allocation for Unsupervised Acoustic Unit Discovery, pdf . @inproceedings{vandermerwe22_interspeech, author={Werner {van der Merwe} and Herman Kamper and Johan {Adam du Preez}}, title={ {A Temporal Extension of Latent Dirichlet Allocation for Unsupervised Acoustic Unit Discovery}}, year=2022, booktitle={Proc. Interspeech 2022}, pages={1426--1430}, doi={10.21437/Interspeech.2022-11369} } . DEFORMER: Coupling Deformed Localized Patterns with Global Context for Robust End-to-end Speech Recognition, pdf . @inproceedings{xie22b_interspeech, author={Jiamin Xie and John H.L. Hansen}, title={ {DEFORMER: Coupling Deformed Localized Patterns with Global Context for Robust End-to-end Speech Recognition}}, year=2022, booktitle={Proc. Interspeech 2022}, pages={1392--1396}, doi={10.21437/Interspeech.2022-11172} } . Automatic Pronunciation Assessment using Self-Supervised Speech Representation Learning, pdf . @inproceedings{kim22k_interspeech, author={Eesung Kim and Jae-Jin Jeon and Hyeji Seo and Hoon Kim}, title={ {Automatic Pronunciation Assessment using Self-Supervised Speech Representation Learning}}, year=2022, booktitle={Proc. Interspeech 2022}, pages={1411--1415}, doi={10.21437/Interspeech.2022-10245} } . Knowledge of accent differences can be used to predict speech recognition, pdf . @inproceedings{szalay22_interspeech, author={Tuende Szalay and Mostafa Shahin and Beena Ahmed and Kirrie Ballard}, title={ {Knowledge of accent differences can be used to predict speech recognition}}, year=2022, booktitle={Proc. Interspeech 2022}, pages={1372--1376}, doi={10.21437/Interspeech.2022-10162} } . Improving Phonetic Transcriptions of Children’s Speech by Pronunciation Modelling with Constrained CTC-Decoding, pdf . @inproceedings{rumberg22b_interspeech, author={Lars Rumberg and Christopher Gebauer and Hanna Ehlert and Ulrike Lüdtke and Jörn Ostermann}, title={ {Improving Phonetic Transcriptions of Children’s Speech by Pronunciation Modelling with Constrained CTC-Decoding}}, year=2022, booktitle={Proc. Interspeech 2022}, pages={1357--1361}, doi={10.21437/Interspeech.2022-332} } .",
            "url": "https://jimregan.github.io/notes/links/2023/02/24/misc-links.html",
            "relUrl": "/links/2023/02/24/misc-links.html",
            "date": " • Feb 24, 2023"
        }
        
    
  
    
        ,"post41": {
            "title": "Interesting links, 22/02/2023",
            "content": "20 Open-Source Single Speaker Speech Datasets . Absolute adjectives . ResGrad: Residual Denoising Diffusion Probabilistic Models for Text to Speech . @misc{chen2022resgrad doi = {10.48550/ARXIV.2212.14518}, author = {Chen, Zehua and Wu, Yihan and Leng, Yichong and Chen, Jiawei and Liu, Haohe and Tan, Xu and Cui, Yang and Wang, Ke and He, Lei and Zhao, Sheng and Bian, Jiang and Mandic, Danilo}, title = {ResGrad: Residual Denoising Diffusion Probabilistic Models for Text to Speech}, year = {2022}, } . Coqui TTS on CPU Real-Time Spanish Speech Synthesis . CVSS: A Massively Multilingual Speech-to-Speech Translation Corpus . @inproceedings{jia2022cvss, title={ {CVSS} Corpus and Massively Multilingual Speech-to-Speech Translation}, author={Jia, Ye and Tadmor Ramanovich, Michelle and Wang, Quan and Zen, Heiga}, booktitle={Proceedings of Language Resources and Evaluation Conference (LREC)}, pages={6691--6703}, year={2022} } . FonBund: A Library for Combining Cross-lingual Phonological Segment Data . @inproceedings{46930, title = {FonBund: A Library for Combining Cross-lingual Phonological Segment Data}, author = {Alexander Gutkin and Martin Jansche and Tatiana Merkulova}, year = {2018}, URL = {http://www.lrec-conf.org/proceedings/lrec2018/pdf/8889.pdf}, booktitle = {Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018)}, pages = {2236--2240}, address = {7-12 May 2018, Miyazaki, Japan} } . The Norwegian Parliamentary Speech Corpus . The Talk of Norway: a richly annotated corpus of the Norwegian parliament, 1998–2016 . @article{lapponi_talk_2018, title = {The {Talk} of {Norway}: a richly annotated corpus of the {Norwe gian} parliament, 1998–2016}, volume = {52}, issn = {1574-0218}, url = {https://doi.org/10.1007/s10579-018-9411-5}, doi = {10.1007/s10579-018-9411-5}, number = {3}, journal = {Language Resources and Evaluation}, author = {Lapponi, Emanuele and Søyland, Martin G. and Velldal, Erik and Oepen, Stephan}, month = sep, year = {2018}, pages = {873--893}, } . Counting in Northern Sami – French wiktionary seems to have good inflection information. . Egri Csillagok . Weighted finite-state transducers: the later years . Minimally Supervised Number Normalization . @article{gorman-sproat-2016-minimally, title = &quot;Minimally Supervised Number Normalization&quot;, author = &quot;Gorman, Kyle and Sproat, Richard&quot;, journal = &quot;Transactions of the Association for Computational Linguistics&quot;, volume = &quot;4&quot;, year = &quot;2016&quot;, address = &quot;Cambridge, MA&quot;, publisher = &quot;MIT Press&quot;, url = &quot;https://aclanthology.org/Q16-1036&quot;, doi = &quot;10.1162/tacl_a_00114&quot;, pages = &quot;507--519&quot;, } . Structured abbreviation expansion in context . @inproceedings{gorman-etal-2021-structured-abbreviation, title = &quot;Structured abbreviation expansion in context&quot;, author = &quot;Gorman, Kyle and Kirov, Christo and Roark, Brian and Sproat, Richard&quot;, booktitle = &quot;Findings of the Association for Computational Linguistics: EMNLP 2021&quot;, month = nov, year = &quot;2021&quot;, address = &quot;Punta Cana, Dominican Republic&quot;, publisher = &quot;Association for Computational Linguistics&quot;, url = &quot;https://aclanthology.org/2021.findings-emnlp.85&quot;, doi = &quot;10.18653/v1/2021.findings-emnlp.85&quot;, pages = &quot;995--1005&quot;, } . FT Speech: Danish Parliament Speech Corpus . @inproceedings{Kirkedal_2020, doi = {10.21437/interspeech.2020-3164}, year = 2020, month = {oct}, publisher = {ISCA}, author = {Andreas Kirkedal and Marija Stepanovi{ &#39;{c}} and Barbara Plank}, title = { {FT} Speech: Danish Parliament Speech Corpus}, booktitle = {Interspeech 2020} } . Committee-Based Active Learning for Speech Recognition . @article{2011, title={Committee-Based Active Learning for Speech Recognition}, author={Yuzo HAMANAKA and Koichi SHINODA and Takuya TSUTAOKA and Sadaoki FURUI and Tadashi EMORI and Takafumi KOSHINAKA}, journal={IEICE Transactions on Information and Systems}, volume={E94.D}, number={10}, pages={2015-2023}, year={2011}, doi={10.1587/transinf.E94.D.2015} } . Phoneme-Level BERT for Enhanced Prosody of Text-to-Speech with Grapheme Predictions . @misc{li2023phoneme_bert doi = {10.48550/ARXIV.2301.08810}, author = {Li, Yinghao Aaron and Han, Cong and Jiang, Xilin and Mesgarani, Nima}, title = {Phoneme-Level BERT for Enhanced Prosody of Text-to-Speech with Grapheme Predictions}, publisher = {arXiv}, year = {2023}, } . Multi-blank Transducers for Speech Recognition . @misc{xu2022multiblank, doi = {10.48550/ARXIV.2211.03541}, author = {Xu, Hainan and Jia, Fei and Majumdar, Somshubra and Watanabe, Shinji and Ginsburg, Boris}, title = {Multi-blank Transducers for Speech Recognition}, publisher = {arXiv}, year = {2022}, } . Alpa: Automated Model-Parallel Deep Learning . Hearing voices at the National Library – a speech corpus and acoustic model for the Swedish language . @misc{malmsten2022kblabb_w2v, url = {https://arxiv.org/abs/2205.03026}, author = {Malmsten, Martin and Haffenden, Chris and Börjeson, Love}, title = {Hearing voices at the National Library -- a speech corpus and acoustic model for the Swedish language}, publisher = {arXiv}, year = {2022}, } . Applications of Lexicographic Semirings to Problems in Speech and Language Processing, pdf . @article{10.1162/COLI_a_00198, author = {Sproat, Richard and Yarmohammadi, Mahsa and Shafran, Izhak and Roark, Brian}, title = &quot;{Applications of Lexicographic Semirings to Problems in Speech and Language Processing}&quot;, journal = {Computational Linguistics}, volume = {40}, number = {4}, pages = {733-761}, year = {2014}, month = {12}, issn = {0891-2017}, doi = {10.1162/COLI_a_00198}, url = {https://doi.org/10.1162/COLI _a _00198}, } . Shallow Fusion of Weighted Finite-State Transducer and Language Model for Text Normalization . @inproceedings{bakhturina22_interspeech, author={Evelina Bakhturina and Yang Zhang and Boris Ginsburg}, title={ {Shallow Fusion of Weighted Finite-State Transducer and Language Model for Text Normalization}}, year=2022, booktitle={Proc. Interspeech 2022}, pages={491--495}, doi={10.21437/Interspeech.2022-11074} } . There is more to Hungarian than goulash! . Noise2Music . Augmenting Librispeech with French Translations: A Multimodal Corpus for Direct Speech Translation Evaluation . @inproceedings{kocabiyikoglu-etal-2018-augmenting, title = &quot;Augmenting Librispeech with {F}rench Translations: A Multimodal Corpus for Direct Speech Translation Evaluation&quot;, author = &quot;Kocabiyikoglu, Ali Can and Besacier, Laurent and Kraif, Olivier&quot;, booktitle = &quot;Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018)&quot;, month = may, year = &quot;2018&quot;, address = &quot;Miyazaki, Japan&quot;, publisher = &quot;European Language Resources Association (ELRA)&quot;, url = &quot;https://aclanthology.org/L18-1001&quot;, } . End-to-End Automatic Speech Translation of Audiobooks, code . @misc{berard2018speechtranslation, doi = {10.48550/ARXIV.1802.04200}, url = {https://arxiv.org/abs/1802.04200}, author = {Bérard, Alexandre and Besacier, Laurent and Kocabiyikoglu, Ali Can and Pietquin, Olivier}, title = {End-to-End Automatic Speech Translation of Audiobooks}, publisher = {arXiv}, year = {2018}, } . Adding Conditional Control to Text-to-Image Diffusion Models, code . @misc{zhang2023controlnet, doi = {10.48550/ARXIV.2302.05543}, author = {Zhang, Lvmin and Agrawala, Maneesh}, title = {Adding Conditional Control to Text-to-Image Diffusion Models}, publisher = {arXiv}, year = {2023}, } . New Year Concert 2017 Wiener Philarmoniker Part 1 . LiroyvH/signal-export – PDF friendly; carderne/signal-export – HTML . erwincoumans/motion_imitation . MILVLG/openvqa . patilli/vqa_benchmarking . Fine-tune FLAN-T5 for chat &amp; dialogue summarization . BatchBALD: Efficient and Diverse Batch Acquisition for Deep Bayesian Active Learning, BlackHC/batchbald_redux . @misc{kirsch2019batchbald, doi = {10.48550/ARXIV.1906.08158}, author = {Kirsch, Andreas and van Amersfoort, Joost and Gal, Yarin}, title = {BatchBALD: Efficient and Diverse Batch Acquisition for Deep Bayesian Active Learning}, publisher = {arXiv}, year = {2019}, } . Dysarthric Speech Recognition From Raw Waveform with Parametric CNNs . @inproceedings{yue22_interspeech, author={Zhengjun Yue and Erfan Loweimi and Heidi Christensen and Jon Barker and Zoran Cvetkovic}, title={ {Dysarthric Speech Recognition From Raw Waveform with Parametric CNNs}}, year=2022, booktitle={Proc. Interspeech 2022}, pages={31--35}, doi={10.21437/Interspeech.2022-163} } . Regularizing Transformer-based Acoustic Models by Penalizing Attention Weights . @inproceedings{lee22b_interspeech, author={Munhak Lee and Joon-Hyuk Chang and Sang-Eon Lee and Ju-Seok Seong and Chanhee Park and Haeyoung Kwon}, title={ {Regularizing Transformer-based Acoustic Models by Penalizing Attention Weights}}, year=2022, booktitle={Proc. Interspeech 2022}, pages={56--60}, doi={10.21437/Interspeech.2022-362} } . Use of prosodic and lexical cues for disambiguating wh-words in Korean . @inproceedings{song22b_interspeech, author={Jieun Song and Hae-Sung Jeon and Jieun Kiaer}, title={ {Use of prosodic and lexical cues for disambiguating wh-words in Korean}}, year=2022, booktitle={Proc. Interspeech 2022}, pages={81--85}, doi={10.21437/Interspeech.2022-561} } . Generalized Keyword Spotting using ASR embeddings . @inproceedings{r22_interspeech, author={Kirandevraj R and Vinod Kumar Kurmi and Vinay Namboodiri and C V Jawahar}, title={ {Generalized Keyword Spotting using ASR embeddings}}, year=2022, booktitle={Proc. Interspeech 2022}, pages={126--130}, doi={10.21437/Interspeech.2022-10450} } . VoiceLab: Software for Fully Reproducible Automated Voice Analysis . @inproceedings{feinberg22_interspeech, author={David Feinberg}, title={ {VoiceLab: Software for Fully Reproducible Automated Voice Analysis}}, year=2022, booktitle={Proc. Interspeech 2022}, pages={351--355}, doi={10.21437/Interspeech.2022-113} } . Hungarian word order . Hangsúly a magyar nyelvben . A magyar nyelv könyve . neonbjb/tortoise-tts – A multi-voice TTS system trained with an emphasis on quality . TorToiSe - Spending Compute for High Quality TTS . Parsing Icelandic Alþingi Transcripts: Parliamentary Speeches as a Genre . @inproceedings{runarsson-sigurdsson-2020-parsing, title = &quot;Parsing {I}celandic Al{ th}ingi Transcripts: Parliamentary Speeches as a Genre&quot;, author = &quot;R{ &#39;u}narsson, Kristj{ &#39;a}n and Sigur{ dh}sson, Einar Freyr&quot;, booktitle = &quot;Proceedings of the Second ParlaCLARIN Workshop&quot;, month = may, year = &quot;2020&quot;, address = &quot;Marseille, France&quot;, publisher = &quot;European Language Resources Association&quot;, url = &quot;https://aclanthology.org/2020.parlaclarin-1.9&quot;, pages = &quot;44--50&quot;, language = &quot;English&quot;, ISBN = &quot;979-10-95546-47-4&quot;, } . Unified Speech-Text Pre-training for Speech Translation and Recognition . @misc{tang2022unified, doi = {10.48550/ARXIV.2204.05409}, author = {Tang, Yun and Gong, Hongyu and Dong, Ning and Wang, Changhan and Hsu, Wei-Ning and Gu, Jiatao and Baevski, Alexei and Li, Xian and Mohamed, Abdelrahman and Auli, Michael and Pino, Juan}, title = {Unified Speech-Text Pre-training for Speech Translation and Recognition}, year = {2022}, } . s2s-ft: Sequence-to-Sequence Fine-Tuning . SpeechLM: Enhanced Speech Pre-Training with Unpaired Textual Data . @misc{zhang2022speechlm, doi = {10.48550/ARXIV.2209.15329}, author = {Zhang, Ziqiang and Chen, Sanyuan and Zhou, Long and Wu, Yu and Ren, Shuo and Liu, Shujie and Yao, Zhuoyuan and Gong, Xun and Dai, Lirong and Li, Jinyu and Wei, Furu}, title = {SpeechLM: Enhanced Speech Pre-Training with Unpaired Textual Data}, year = {2022}, } . Active learning in speech recognition . open-mmlab/mmhuman3d – OpenMMLab 3D Human Parametric Model Toolbox and Benchmark . zapis liczb wielocyfrowych – spacjami . r9y9/pyreaper – A python wrapper for REAPER . Fine-tune FLAN-T5 for chat &amp; dialogue summarization . Getting Started with DeepSpeed for Inferencing Transformer based Models . facebookresearch/metaseq – Repo for external large-scale work . NeMo Intro to transducers . NeMo FastPitch . Learning Audio-Video Modalities from Image Captions, github . @inproceedings{nagrani2022learning, title = {Learning Audio Video Modalities from Image Captions}, author = {Nagrani, Arsha and Hongsuck Seo, Paul and Seybold, Bryan, and Hauth Anja, and Santiago, Manen, and Chen, Sun and Schmid, Cordelia}, booktitle = {ECCV}, year = {2022}, } . Serving OPT-175B, BLOOM-176B and CodeGen-16B using Alpa . k2-fsa/sherpa – Speech-to-text server framework with next-gen Kaldi . k2-fsa/kaldifst – Python wrapper for OpenFST and its extensions from Kaldi. Also support reading/writing ark/scp files . NeMo Joint Intent and Slot Classification . jonatasgrosman/wav2vec2-large-xlsr-53-hungarian . huspacy/huspacy . Sami Manual . giellalt/lang-sme . Kvensk grammatikk . JaidedAI/EasyOCR . Sami parliament TV . Telling the time in Hungarian . NbAiLab/whisper-sami-demo, model . Damage Control During Domain Adaptation for Transducer Based Automatic Speech Recognition . @misc{majumdar2022damagecontrol, doi = {10.48550/ARXIV.2210.03255}, author = {Majumdar, Somshubra and Acharya, Shantanu and Lavrukhin, Vitaly and Ginsburg, Boris}, title = {Damage Control During Domain Adaptation for Transducer Based Automatic Speech Recognition}, year = {2022}, } . jonatasgrosman/wav2vec2-large-xlsr-53-hungarian . vitouphy/wav2vec2-xls-r-300m-phoneme, training . lucidrains/audiolm-pytorch – Implementation of AudioLM, a SOTA Language Modeling Approach to Audio Generation out of Google Research, in Pytorch . lucidrains/PaLM-rlhf-pytorch – Implementation of RLHF (Reinforcement Learning with Human Feedback) on top of the PaLM architecture. Basically ChatGPT but with PaLM . google-research/tuning_playbook – A playbook for systematically maximizing the performance of deep learning models. . AN CAIGHDEÁN OIFIGIÚIL . CLDR Irish . stts-se/wikispeech-annotator . Castles and palaces of Greater Budapest . OpenAI’s Whisper: 7 must-know libraries and add-ons built on top of it . Fine-Tune Whisper For Multilingual ASR with 🤗 Transformers . jumon/zac – Zero-shot Audio Classification using Whisper . linto-ai/whisper-timestamped – Multilingual Automatic Speech Recognition with word-level timestamps and confidence . Guiding Frozen Language Models with Learned Soft Prompts . google-research/prompt-tuning – Original Implementation of Prompt Tuning from Lester, et al, 2021 . The Flan Collection: Advancing open source methods for instruction tuning . Active and Semi-Supervised Learning in ASR: Benefits on the Acoustic and Language Models . @article{drugman2019active, doi = {10.48550/ARXIV.1903.02852}, author = {Drugman, Thomas and Pylkkonen, Janne and Kneser, Reinhard}, title = {Active and Semi-Supervised Learning in ASR: Benefits on the Acoustic and Language Models}, year = {2019}, } . Domain-Adversarial Training of Neural Networks . @article{ganin2015domainadversarial, doi = {10.48550/ARXIV.1505.07818}, author = {Ganin, Yaroslav and Ustinova, Evgeniya and Ajakan, Hana and Germain, Pascal and Larochelle, Hugo and Laviolette, François and Marchand, Mario and Lempitsky, Victor}, title = {Domain-Adversarial Training of Neural Networks}, year = {2015}, } . CLSE: Corpus of Linguistically Significant Entities, corpus . @misc{chuklin2022clse, doi = {10.48550/ARXIV.2211.02423}, author = {Chuklin, Aleksandr and Zhao, Justin and Kale, Mihir}, title = {CLSE: Corpus of Linguistically Significant Entities}, year = {2022}, } . Linguistic Framing of Political Terror: Distant and Close Readings of the Discourse on Terrorism in the Swedish Parliament 1993–2018 . @inProceedings{angsal2022framing, title = {Linguistic Framing of Political Terror: Distant and Close Readings of the Discourse on Terrorism in the Swedish Parliament 1993–2018}, booktitle = {CLARIN Annual Conference Proceedings, 10–12 October 2022, Prague, Czechia. Eds. Tomaž Erjavec &amp; Maria Eskevich}, author = {Ängsal, Magnus Pettersson and Brodén, Daniel and Fridlund, Mats and Olsson, Leif-Jöran and Öhberg, Patrik}, year = {2022}, address = {Prag}, } . Finland Swedish Automatic Speech Recognition, pdf . @mastersthesis{raitolahti2022, title={ {Finland Swedish Automatic Speech Recognition}}, author={Raitolahti, Otto-Ville}, year={2022}, language={English}, pages={53}, school={Aalto University. School of Science}, type={Master&#39;s thesis}, url={http://urn.fi/URN:NBN:fi:aalto-202203272601} } . Building an ASR Corpus Using Althingi’s Parliamentary Speeches . @inproceedings{helgadottir2017, author={Inga Rún Helgadóttir and Róbert Kjaran and Anna Björk Nikulásdóttir and Jón Guðnason}, title={Building an ASR Corpus Using Althingi’s Parliamentary Speeches}, year=2017, booktitle={Proc. Interspeech 2017}, pages={2163--2167}, doi={10.21437/Interspeech.2017-903}, url={http://dx.doi.org/10.21437/Interspeech.2017-903} } . Streaming model for Acoustic to Articulatory Inversion with transformer networks, pdf . @inproceedings{udupa22_interspeech, author={Sathvik Udupa and Aravind Illa and Prasanta Ghosh}, title={ {Streaming model for Acoustic to Articulatory Inversion with transformer networks}}, year=2022, booktitle={Proc. Interspeech 2022}, pages={625--629}, doi={10.21437/Interspeech.2022-10159} } . Acquisition of allophonic variation in second language speech: An acoustic and articulatory study of English laterals by Japanese speakers, pdf . @inproceedings{nagamine22_interspeech, author={Takayuki Nagamine}, title={ {Acquisition of allophonic variation in second language speech: An acoustic and articulatory study of English laterals by Japanese speakers}}, year=2022, booktitle={Proc. Interspeech 2022}, pages={644--648}, doi={10.21437/Interspeech.2022-11020} } . Unsupervised Text-to-Speech Synthesis by Unsupervised Automatic Speech Recognition, pdf . @inproceedings{ni22_interspeech, author={Junrui Ni and Liming Wang and Heting Gao and Kaizhi Qian and Yang Zhang and Shiyu Chang and Mark Hasegawa-Johnson}, title={ {Unsupervised Text-to-Speech Synthesis by Unsupervised Automatic Speech Recognition}}, year=2022, booktitle={Proc. Interspeech 2022}, pages={461--465}, doi={10.21437/Interspeech.2022-816} } . Mixed-Phoneme BERT: Improving BERT with Mixed Phoneme and Sup-Phoneme Representations for Text to Speech, pdf . @inproceedings{zhang22i_interspeech, author={Guangyan Zhang and Kaitao Song and Xu Tan and Daxin Tan and Yuzi Yan and Yanqing Liu and Gang Wang and Wei Zhou and Tao Qin and Tan Lee and Sheng Zhao}, title={ {Mixed-Phoneme BERT: Improving BERT with Mixed Phoneme and Sup-Phoneme Representations for Text to Speech}}, year=2022, booktitle={Proc. Interspeech 2022}, pages={456--460}, doi={10.21437/Interspeech.2022-621} } . SIGUL 2023 . Active learning in speech recognition . Diverse Beam Search: Decoding Diverse Solutions from Neural Sequence Models . @misc{vijayakumar2016diversebeamsearch, doi = {10.48550/ARXIV.1610.02424}, author = {Vijayakumar, Ashwin K and Cogswell, Michael and Selvaraju, Ramprasath R. and Sun, Qing and Lee, Stefan and Crandall, David and Batra, Dhruv}, title = {Diverse Beam Search: Decoding Diverse Solutions from Neural Sequence Models}, year = {2016}, } . Towards Multimodal Sarcasm Detection (An Obviously Perfect Paper) . @inproceedings{castro-etal-2019-towards, title = &quot;Towards Multimodal Sarcasm Detection (An { _}{O}bviously{ _} Perfect Paper)&quot;, author = &quot;Castro, Santiago and Hazarika, Devamanyu and P{ &#39;e}rez-Rosas, Ver{ &#39;o}nica and Zimmermann, Roger and Mihalcea, Rada and Poria, Soujanya&quot;, booktitle = &quot;Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics&quot;, month = jul, year = &quot;2019&quot;, address = &quot;Florence, Italy&quot;, publisher = &quot;Association for Computational Linguistics&quot;, url = &quot;https://aclanthology.org/P19-1455&quot;, doi = &quot;10.18653/v1/P19-1455&quot;, pages = &quot;4619--4629&quot;, } . jbetker/wav2vec2-large-robust-ft-libritts-voxpopuli . facebook/wav2vec2-xlsr-53-phon-cv-babel-ft . Aditya3107/wav2vec2-Irish-common-voice-Fleurs-living-audio-300m . microsoft/trocr-large-handwritten . BEiT v2 Pretraining . TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models . @misc{li2021trocr, doi = {10.48550/ARXIV.2109.10282}, author = {Li, Minghao and Lv, Tengchao and Chen, Jingye and Cui, Lei and Lu, Yijuan and Florencio, Dinei and Zhang, Cha and Li, Zhoujun and Wei, Furu}, title = {TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models}, year = {2021}, } . Pauses, gaps and overlaps in conversations . dmort27/morphotactics – Library for implementing morphotactic FSTs using Pynini and OpenFST . 25 Hungarian Words that every foreigner should learn . LMC-SMCA: A New Active Learning Method in ASR . @ARTICLE{9363163, author={Sun, Xiusong and Wang, Bo and Liu, Shaohan and Lu, Tingxiang and Shan, Xin and Yang, Qun}, journal={IEEE Access}, title={LMC-SMCA: A New Active Learning Method in ASR}, year={2021}, volume={9}, number={}, pages={37011-37021}, doi={10.1109/ACCESS.2021.3062157}} . Active Learning For Automatic Speech Recognition . @article{hakkanitur2002active, author = {Hakkani-Tur, Dilek and Gorin, Allen}, year = {2002}, month = {09}, pages = {}, title = {Active Learning For Automatic Speech Recognition}, journal = {Acoustics, Speech, and Signal Processing, 1988. ICASSP-88., 1988 International Conference on}, doi = {10.1109/ICASSP.2002.5745510} } . Maximizing global entropy reduction for active learning in speech recognition . @INPROCEEDINGS{4960685, author={Varadarajan, Balakrishnan and Yu, Dong and Li Deng and Acero, Alex}, booktitle={2009 IEEE International Conference on Acoustics, Speech and Signal Processing}, title={Maximizing global entropy reduction for active learning in speech recognition}, year={2009}, volume={}, number={}, pages={4721-4724}, doi={10.1109/ICASSP.2009.4960685}} . Active learning for accent adaptation in Automatic Speech Recognition . @INPROCEEDINGS{6424250, author={Nallasamy, Udhyakumar and Metze, Florian and Schultz, Tanja}, booktitle={2012 IEEE Spoken Language Technology Workshop (SLT)}, title={Active learning for accent adaptation in Automatic Speech Recognition}, year={2012}, volume={}, number={}, pages={360-365}, doi={10.1109/SLT.2012.6424250}} . Active learning: theory and applications to automatic speech recognition . @ARTICLE{1453593, author={Riccardi, G. and Hakkani-Tur, D.}, journal={IEEE Transactions on Speech and Audio Processing}, title={Active learning: theory and applications to automatic speech recognition}, year={2005}, volume={13}, number={4}, pages={504-511}, doi={10.1109/TSA.2005.848882}} . A confusion network based confidence measure for active learning in speech recognition . @INPROCEEDINGS{4906813, author={Chen, Wei and Liu, Gang and Guo, Jun}, booktitle={2008 International Conference on Natural Language Processing and Knowledge Engineering}, title={A confusion network based confidence measure for active learning in speech recognition}, year={2008}, volume={}, number={}, pages={1-6}, doi={10.1109/NLPKE.2008.4906813}} . Active learning for automatic speech recognition . @INPROCEEDINGS{5745510, author={Hakkani-Tür, Dilek and Riccardi, Giuseppe and Gorin, Allen}, booktitle={2002 IEEE International Conference on Acoustics, Speech, and Signal Processing}, title={Active learning for automatic speech recognition}, year={2002}, volume={4}, number={}, pages={IV-3904-IV-3907}, doi={10.1109/ICASSP.2002.5745510}} . karpathy/nn-zero-to-hero . ej0cl6/deep-active-learning . Overview of Active Learning for Deep Learning . SpeechPainter: Text-conditioned Speech Inpainting . @inproceedings{borsos22_interspeech, author={Zalan Borsos and Matthew Sharifi and Marco Tagliasacchi}, title={ {SpeechPainter: Text-conditioned Speech Inpainting}}, year=2022, booktitle={Proc. Interspeech 2022}, pages={431--435}, doi={10.21437/Interspeech.2022-194} } . Active and unsupervised learning for automatic speech recognition, pdf . @inproceedings{riccardi03_eurospeech, author={Giuseppe Riccardi and Dilek Z. Hakkani-Tur}, title={ {Active and unsupervised learning for automatic speech recognition}}, year=2003, booktitle={Proc. 8th European Conference on Speech Communication and Technology (Eurospeech 2003)}, pages={1825--1828}, doi={10.21437/Eurospeech.2003-552} } . Committee-Based Active Learning for Speech Recognition, pdf . @article{hamanaka2011committee, title={Committee-Based Active Learning for Speech Recognition}, author={Yuzo HAMANAKA and Koichi SHINODA and Takuya TSUTAOKA and Sadaoki FURUI and Tadashi EMORI and Takafumi KOSHINAKA}, journal={IEICE Transactions on Information and Systems}, volume={E94.D}, number={10}, pages={2015-2023}, year={2011}, doi={10.1587/transinf.E94.D.2015} } . Adaptable End-to-End ASR Models using Replaceable Internal LMs and Residual Softmax . @misc{deng2023adaptableasr, doi = {10.48550/ARXIV.2302.08579}, author = {Deng, Keqi and Woodland, Philip C.}, title = {Adaptable End-to-End ASR Models using Replaceable Internal LMs and Residual Softmax}, year = {2023}, } .",
            "url": "https://jimregan.github.io/notes/links/2023/02/22/misc-links.html",
            "relUrl": "/links/2023/02/22/misc-links.html",
            "date": " • Feb 22, 2023"
        }
        
    
  
    
        ,"post42": {
            "title": "Create Huggingface dataset from Hungarian TTS data",
            "content": "PATH = &quot;/Users/joregan/Playing/hu-tts/hungarian-single-speaker-tts&quot; . !pip install datasets librosa . from pathlib import Path import datasets . path = Path(PATH) outdir = path / &quot;data&quot; transcript = path / &quot;transcript.txt&quot; . def clean_text(text, norm = False): if text.endswith(&quot; -&quot;): text = text[:-2] text = text.replace(&quot;.S &quot;, &quot;. S &quot;) if norm: text = text.replace(&quot;. &quot;, &quot; &quot;) if len(text) &gt; 1 and text[-1] in [&quot;.&quot;, &quot;!&quot;, &quot;?&quot;, &quot;:&quot;]: text = text[:-1] text = text.replace(&quot; -, &quot;, &quot; &quot;) text = text.replace(&quot; - &quot;, &quot; &quot;) text = text.replace(&quot;. &quot;, &quot; &quot;) text = text.replace(&quot;, &quot;, &quot; &quot;) text = text.replace(&quot;? &quot;, &quot; &quot;) text = text.replace(&quot;: &quot;, &quot; &quot;) text = text.replace(&quot;! &quot;, &quot; &quot;) text = text.lower() return text . data = [] with open(str(transcript)) as ts: for line in ts.readlines(): data.append(line.strip().split(&quot;|&quot;)) . def data_gen(): for i in data: filepath = i[0] fileid = filepath.split(&quot;/&quot;)[1].replace(&quot;.wav&quot;, &quot;&quot;) text = i[1] lightly_cleaned = clean_text(text) fully_cleaned = clean_text(text, True) yield { &quot;id&quot;: fileid, &quot;audio&quot;: str(path / filepath), &quot;original_text&quot;: lightly_cleaned, &quot;text&quot;: fully_cleaned, &quot;duration&quot;: float(i[3]) } . Features . from datasets import Dataset, Audio dataset = Dataset.from_generator(data_gen).cast_column(&quot;audio&quot;, Audio(sampling_rate=22050)) . dataset.push_to_hub(&quot;KTH/hungarian-single-speaker-tts&quot;, max_shard_size=&quot;500MB&quot;) . 100%|██████████| 1/1 [00:05&lt;00:00, 5.55s/ba] 100%|██████████| 1/1 [00:01&lt;00:00, 1.52s/ba]0%| | 0/7 [00:00&lt;?, ?it/s] 100%|██████████| 1/1 [00:01&lt;00:00, 1.52s/ba]9%|██▊ | 2/7 [00:01&lt;00:03, 1.29it/s] 100%|██████████| 1/1 [00:01&lt;00:00, 1.09s/ba]3%|████▎ | 3/7 [00:03&lt;00:04, 1.11s/it] 100%|██████████| 1/1 [00:01&lt;00:00, 1.69s/ba]7%|█████▋ | 4/7 [00:04&lt;00:03, 1.11s/it] 100%|██████████| 1/1 [00:01&lt;00:00, 1.77s/ba]1%|███████▏ | 5/7 [00:06&lt;00:02, 1.34s/it] 100%|██████████| 1/1 [00:01&lt;00:00, 1.04s/ba]6%|████████▌ | 6/7 [00:07&lt;00:01, 1.49s/it] Pushing dataset shards to the dataset hub: 100%|██████████| 7/7 [00:08&lt;00:00, 1.27s/it] .",
            "url": "https://jimregan.github.io/notes/datasets/hungarian/2023/01/21/create-hungarian-tts-dataset.html",
            "relUrl": "/datasets/hungarian/2023/01/21/create-hungarian-tts-dataset.html",
            "date": " • Jan 21, 2023"
        }
        
    
  
    
        ,"post43": {
            "title": "Liepa to fairseq",
            "content": "BASE = &quot;/mnt/cloud/liepa-split2/&quot; RAW = f&quot;{BASE}/text.tsv&quot; . import soundfile as sf . text = {} frames = {} with open(RAW) as inf: for line in inf.readlines(): if not &quot; t&quot; in line: print(line) pass parts = line.split(&quot; t&quot;) if len(parts) != 2: print(line) pass id = parts[0] text[id] = parts[1] data, sr = sf.read(f&quot;{BASE}/{id}.wav&quot;) if sr != 16000: print(line) pass frames[id] = len(data) . import re def cleantext(text): ALPHA = &quot;aąbcčdeęėfghiįyjklmnoprsštuųūvzžqx&quot; text = text.lower().replace(&quot;-&quot;, &quot; &quot;) chars = [] for ch in text: if ch in ALPHA or ch == &quot; &quot;: chars.append(ch) text = &quot;&quot;.join(chars) text = re.sub(&quot; *&quot;, &quot; &quot;, text) return text.strip() . with open(f&quot;{BASE}/frames-normtext.tsv&quot;, &quot;w&quot;) as outf: for id in text.keys(): norm = cleantext(text[id]) outf.write(f&quot;{id} t{frames[id]} t{norm} n&quot;) . import IPython def playwav(id): return IPython.display.Audio(f&quot;{BASE}/{id}.wav&quot;) . Makes splits; only want 100 hours of train . TRAIN = 16000 * 60 * 60 * 100 TEST = 16000 * 60 * 60 * 5 VALID = 16000 * 60 * 60 * 5 . Not entirely sure about the speaker IDs; worst case scenario, there are 10: F1-5, and M1-5. . BASE = &quot;/tmp/outp&quot; OBASE = &quot;/mnt/cloud/liepa-split2/&quot; with open(f&quot;{BASE}/train.tsv&quot;, &quot;w&quot;) as traintsv, open(f&quot;{BASE}/train.ltr&quot;, &quot;w&quot;) as trainltr, open(f&quot;{BASE}/valid.tsv&quot;, &quot;w&quot;) as validtsv, open(f&quot;{BASE}/valid.ltr&quot;, &quot;w&quot;) as validltr, open(f&quot;{BASE}/test.tsv&quot;, &quot;w&quot;) as testtsv, open(f&quot;{BASE}/test.ltr&quot;, &quot;w&quot;) as testltr, open(f&quot;{OBASE}/frames-normtext.tsv&quot;) as inf: for line in inf.readlines(): parts = line.strip().split(&quot; t&quot;) if len(parts) != 3: print(line) continue id = parts[0] frames = int(parts[1]) text = parts[2] if &quot;_M4_&quot; in id: if (TEST - frames &gt; 0): testtsv.write(f&quot;{id} t{frames} n&quot;) testltr.write(f&quot;{text} n&quot;) TEST = TEST - frames else: continue elif &quot;_M5_&quot; in id: if (VALID - frames &gt; 0): validtsv.write(f&quot;{id} t{frames} n&quot;) validltr.write(f&quot;{text} n&quot;) VALID = VALID - frames else: continue else: if (TRAIN - frames &gt; 0): traintsv.write(f&quot;{id} t{frames} n&quot;) trainltr.write(f&quot;{text} n&quot;) TRAIN = TRAIN - frames else: continue .",
            "url": "https://jimregan.github.io/notes/liepa/lithuanian/asr/corpus/2023/01/13/liepa-to-fairseq.html",
            "relUrl": "/liepa/lithuanian/asr/corpus/2023/01/13/liepa-to-fairseq.html",
            "date": " • Jan 13, 2023"
        }
        
    
  
    
        ,"post44": {
            "title": "Extract audio from .pcm from NST Swedish Speech Synthesis",
            "content": "Corpus available here . import soundfile as sf . import IPython.display as ipd import numpy . from IPython.display import Audio . sample_file = &quot;/content/sw_all_mf_01_5277.pcm&quot; . data, sr = sf.read(sample_file, channels=2, samplerate=44100, endian=&quot;BIG&quot;, dtype=&quot;int16&quot;, format=&quot;RAW&quot;, subtype=&quot;PCM_16&quot;, start=16) . Audio(data[:, 1], rate=sr) .",
            "url": "https://jimregan.github.io/notes/nst/soundfile/2023/01/03/extract-audio-from-nst-swedish-speech-synthesis.html",
            "relUrl": "/nst/soundfile/2023/01/03/extract-audio-from-nst-swedish-speech-synthesis.html",
            "date": " • Jan 3, 2023"
        }
        
    
  
    
        ,"post45": {
            "title": "Scraper for Scientific American on JSTOR",
            "content": "from bs4 import BeautifulSoup . The temporary file below is extracted from JSTOR . with open(&quot;/tmp/sciam&quot;) as inf: html = inf.read() . soup = BeautifulSoup(html, &#39;html.parser&#39;) . top = soup.find(&quot;details&quot;, {&quot;class&quot;: &quot;issues&quot;}) . import re . data = [] data.append(&quot;| Year | Volume | DOI | Issue |&quot;) data.append(&quot;||--|--|-|&quot;) for yearvol in top.find_all(&quot;li&quot;, {&quot;class&quot;: &quot;year-volume-heading&quot;}): yv_text = yearvol.find(&quot;span&quot;) match = re.search(&quot;^( d d d d) (Vol . ( d+) )$&quot;, yv_text.text.strip()) if match: year = match.group(1) vol = match.group(2) ul = yearvol.find(&quot;ul&quot;, {&quot;class&quot;: &quot;year-volume-list&quot;}) for li in ul.find_all(&quot;li&quot;): doi = li.attrs[&quot;data-doi&quot;] coll = li.find(&quot;collection-view-pharos-link&quot;) href = coll.attrs[&quot;href&quot;] text = coll.text.strip().replace(&quot; n&quot;, &quot; &quot;) text = re.sub(&quot; s+&quot;, &quot; &quot;, text) data.append(f&quot;|{year} | {vol} | {doi} | [{text}](https://www.jstor.org{href})&quot;) . from IPython.display import display, Markdown . display(Markdown(&quot; n&quot;.join(data))) . Year Volume DOI Issue . 2017 | 317 | 10.2307/e27109379 | No. 6 DECEMBER 2017 pp. 4-94 | . 2017 | 317 | 10.2307/e27109346 | No. 5 NOVEMBER 2017 pp. 6-84 | . 2017 | 317 | 10.2307/e27109309 | No. 4 OCTOBER 2017 pp. 5-96 | . 2017 | 317 | 10.2307/e27109267 | No. 3 SPECIAL ISSUE : SEX AND GENDER SEPTEMBER 2017 pp. 6-96 | . 2017 | 317 | 10.2307/e27109233 | No. 2 AUGUST 2017 pp. 4-84 | . 2017 | 317 | 10.2307/e27109197 | No. 1 JULY 2017 pp. 4-76 | . 2017 | 316 | 10.2307/e26172668 | No. 6 JUNE 2017 pp. 1-78 | . 2017 | 316 | 10.2307/e26047532 | No. 5 MAY 2017 pp. 1-80 | . 2017 | 316 | 10.2307/e26047499 | No. 4 APRIL 2017 pp. 1-84 | . 2017 | 316 | 10.2307/e26047461 | No. 3 MARCH 2017 pp. 1-80 | . 2017 | 316 | 10.2307/e26047427 | No. 2 FEBRUARY 2017 pp. 1-76 | . 2017 | 316 | 10.2307/e26047371 | No. 1 JANUARY 2017 pp. 1-72 | . 2016 | 315 | 10.2307/e26047227 | No. 6 DECEMBER 2016 pp. 1-88 | . 2016 | 315 | 10.2307/e26047169 | No. 5 NOVEMBER 2016 pp. 1-80 | . 2016 | 315 | 10.2307/e26047133 | No. 4 OCTOBER 2016 pp. 1-88 | . 2016 | 315 | 10.2307/e26047095 | No. 3 SPECIAL ISSUE: 9 KEY QUESTIONS ABOUT OUR FUTURE SEPTEMBER 2016 pp. 1-92 | . 2016 | 315 | 10.2307/e26047038 | No. 2 AUGUST 2016 pp. 1-80 | . 2016 | 315 | 10.2307/e26047001 | No. 1 JULY 2016 pp. 1-76 | . 2016 | 314 | 10.2307/e26046963 | No. 6 JUNE 2016 pp. 1-80 | . 2016 | 314 | 10.2307/e26046923 | No. 5 MAY 2016 pp. 1-76 | . 2016 | 314 | 10.2307/e26046887 | No. 4 APRIL 2016 pp. 1-84 | . 2016 | 314 | 10.2307/e26046853 | No. 3 MARCH 2016 pp. 1-76 | . 2016 | 314 | 10.2307/e26046817 | No. 2 FEBRUARY 2016 pp. 1-76 | . 2016 | 314 | 10.2307/e26046780 | No. 1 JANUARY 2016 pp. 1-80 | . 2015 | 313 | 10.2307/e26046541 | No. 6 DECEMBER 2015 pp. 1-84 | . 2015 | 313 | 10.2307/e26046421 | No. 5 NOVEMBER 2015 pp. 1-80 | . 2015 | 313 | 10.2307/e26046294 | No. 4 OCTOBER 2015 pp. 1-88 | . 2015 | 313 | 10.2307/e26046181 | No. 3 SPECIAL ISSUE: 100 YEARS OF GENERAL RELATIVITY SEPTEMBER 2015 pp. 1-100 | . 2015 | 313 | 10.2307/e26046074 | No. 2 AUGUST 2015 pp. 1-88 | . 2015 | 313 | 10.2307/e26045877 | No. 1 JULY 2015 pp. 1-80 | . 2015 | 312 | 10.2307/e26046615 | No. 6 JUNE 2015 pp. 1-84 | . 2015 | 312 | 10.2307/e26046550 | No. 5 MAY 2015 pp. 1-90 | . 2015 | 312 | 10.2307/e26046487 | No. 4 APRIL 2015 pp. 1-84 | . 2015 | 312 | 10.2307/e26046300 | No. 3 MARCH 2015 pp. 1-78 | . 2015 | 312 | 10.2307/e26046174 | No. 2 FEBRUARY 2015 pp. 1-88 | . 2015 | 312 | 10.2307/e26046036 | No. 1 JANUARY 2015 pp. 1-86 | . 2014 | 311 | 10.2307/e26040678 | No. 6 DECEMBER 2014 pp. 1-100 | . 2014 | 311 | 10.2307/e26041744 | No. 5 NOVEMBER 2014 pp. 1-92 | . 2014 | 311 | 10.2307/e26040340 | No. 4 OCTOBER 2014 pp. 1-100 | . 2014 | 311 | 10.2307/e26040223 | No. 3 SPECIAL EVOLUTION ISSUE: EVOLUTION the human saga SEPTEMBER 2014 pp. 1-100 | . 2014 | 311 | 10.2307/e26040185 | No. 2 AUGUST 2014 pp. 1-84 | . 2014 | 311 | 10.2307/e26040143 | No. 1 JULY 2014 pp. 1-96 | . 2014 | 310 | 10.2307/e26039908 | No. 6 JUNE 2014 pp. 1-86 | . 2014 | 310 | 10.2307/e26039868 | No. 5 MAY 2014 pp. 1-84 | . 2014 | 310 | 10.2307/e26039828 | No. 4 APRIL 2014 pp. 1-92 | . 2014 | 310 | 10.2307/e26039787 | No. 3 MARCH 2014 pp. 1-88 | . 2014 | 310 | 10.2307/e26039743 | No. 2 FEBRUARY 2014 pp. 1-82 | . 2014 | 310 | 10.2307/e26039706 | No. 1 JANUARY 2014 pp. 1-84 | . 2013 | 309 | 10.2307/e26018202 | No. 6 DECEMBER 2013 pp. 1-88 | . 2013 | 309 | 10.2307/e26018118 | No. 5 NOVEMBER 2013 pp. 1-82 | . 2013 | 309 | 10.2307/e26018078 | No. 4 OCTOBER 2013 pp. 1-100 | . 2013 | 309 | 10.2307/e26017935 | No. 3 SEPTEMBER 2013 pp. 1-96 | . 2013 | 309 | 10.2307/e26017838 | No. 2 AUGUST 2013 pp. 1-102 | . 2013 | 309 | 10.2307/e26017795 | No. 1 JULY 2013 pp. 1-98 | . 2013 | 308 | 10.2307/e26018240 | No. 6 JUNE 2013 pp. 1-96 | . 2013 | 308 | 10.2307/e26018159 | No. 5 MAY 2013 pp. 1-88 | . 2013 | 308 | 10.2307/e26018037 | No. 4 APRIL 2013 pp. 1-92 | . 2013 | 308 | 10.2307/e26017998 | No. 3 MARCH 2013 pp. 1-88 | . 2013 | 308 | 10.2307/e26017914 | No. 2 FEBRUARY 2013 pp. 1-82 | . 2013 | 308 | 10.2307/e26017833 | No. 1 JANUARY 2013 pp. 1-80 | . 2012 | 307 | 10.2307/e26016184 | No. 6 DECEMBER 2012 pp. 1-92 | . 2012 | 307 | 10.2307/e26016139 | No. 5 NOVEMBER 2012 pp. 1-92 | . 2012 | 307 | 10.2307/e26016092 | No. 4 OCTOBER 2012 pp. 1-100 | . 2012 | 307 | 10.2307/e26016049 | No. 3 SPECIAL ISSUE: Beyond the Limits of Science SEPTEMBER 2012 pp. 1-96 | . 2012 | 307 | 10.2307/e26016009 | No. 2 August 2012 pp. 1-92 | . 2012 | 307 | 10.2307/e26015970 | No. 1 July 2012 pp. 1-92 | . 2012 | 306 | 10.2307/e26014483 | No. 6 June 2012 pp. 1-96 | . 2012 | 306 | 10.2307/e26014371 | No. 5 May 2012 pp. 1-96 | . 2012 | 306 | 10.2307/e26014288 | No. 4 April 2012 pp. 1-88 | . 2012 | 306 | 10.2307/e26014213 | No. 3 March 2012 pp. 1-88 | . 2012 | 306 | 10.2307/e26014169 | No. 2 February 2012 pp. 1-88 | . 2012 | 306 | 10.2307/e26014129 | No. 1 January 2012 pp. 1-92 | . 2011 | 305 | 10.2307/e26002890 | No. 6 December 2011 pp. 1-110 | . 2011 | 305 | 10.2307/e26002851 | No. 5 November 2011 pp. 1-104 | . 2011 | 305 | 10.2307/e26002808 | No. 4 October 2011 pp. 1-100 | . 2011 | 305 | 10.2307/e26002765 | No. 3 SPECIAL ISSUE: CITIES: Better greener smarter September 2011 pp. 1-96 | . 2011 | 305 | 10.2307/e26002723 | No. 2 August 2011 pp. 1-96 | . 2011 | 305 | 10.2307/e26002679 | No. 1 July 2011 pp. 1-88 | . 2011 | 304 | 10.2307/e26002534 | No. 6 June 2011 pp. 1-92 | . 2011 | 304 | 10.2307/e26002489 | No. 5 May 2011 pp. 1-96 | . 2011 | 304 | 10.2307/e26002448 | No. 4 April 2011 pp. 1-96 | . 2011 | 304 | 10.2307/e26002407 | No. 3 March 2011 pp. 1-80 | . 2011 | 304 | 10.2307/e26002363 | No. 2 February 2011 pp. 1-92 | . 2011 | 304 | 10.2307/e26002318 | No. 1 January 2011 pp. 1-88 | . 2010 | 303 | 10.2307/e26002268 | No. 6 December 2010 pp. 1-108 | . 2010 | 303 | 10.2307/e26002226 | No. 5 November 2010 pp. 1-92 | . 2010 | 303 | 10.2307/e26002179 | No. 4 October 2010 pp. 1-104 | . 2010 | 303 | 10.2307/e26002140 | No. 3 SEPTEMBER 2010 pp. 1-104 | . 2010 | 303 | 10.2307/e26002107 | No. 2 AUGUST 2010 pp. 1-92 | . 2010 | 303 | 10.2307/e26002074 | No. 1 JULY 2010 pp. 1-88 | . 2010 | 302 | 10.2307/e26002041 | No. 6 June 2010 pp. 1-92 | . 2010 | 302 | 10.2307/e26002008 | No. 5 May 2010 pp. 1-88 | . 2010 | 302 | 10.2307/e26001951 | No. 4 April 2010 pp. 1-88 | . 2010 | 302 | 10.2307/e26001917 | No. 3 March 2010 pp. 1-84 | . 2010 | 302 | 10.2307/e26001872 | No. 2 February 2010 pp. 1-88 | . 2010 | 302 | 10.2307/e26001824 | No. 1 January 2010 pp. 1-100 | . 2009 | 301 | 10.2307/e26001633 | No. 6 December 2009 pp. 1-104 | . 2009 | 301 | 10.2307/e26001565 | No. 5 November 2009 pp. 1-96 | . 2009 | 301 | 10.2307/e26001532 | No. 4 October 2009 pp. 1-100 | . 2009 | 301 | 10.2307/e26001504 | No. 3 SPECIAL ISSUE: UNDERSTANDING ORIGINS September 2009 pp. 1-104 | . 2009 | 301 | 10.2307/e26001471 | No. 2 August 2009 pp. 1-80 | . 2009 | 301 | 10.2307/e26001435 | No. 1 July 2009 pp. 1-88 | . 2009 | 300 | 10.2307/e26001352 | No. 6 June 2009 pp. 1-84 | . 2009 | 300 | 10.2307/e26001312 | No. 5 May 2009 pp. 1-80 | . 2009 | 300 | 10.2307/e26001273 | No. 4 April 2009 pp. 1-84 | . 2009 | 300 | 10.2307/e26001232 | No. 3 March 2009 pp. 1-84 | . 2009 | 300 | 10.2307/e26001194 | No. 2 February 2009 pp. 1-84 | . 2009 | 300 | 10.2307/e26001389 | No. 1 SPECIAL ISSUE: The Evolution of EVOLUTION January 2009 pp. 1-108 | . 2008 | 299 | 10.2307/e26000897 | No. 6 December 2008 pp. 1-122 | . 2008 | 299 | 10.2307/e26000857 | No. 5 November 2008 pp. 1-108 | . 2008 | 299 | 10.2307/e26000816 | No. 4 October 2008 pp. 1-104 | . 2008 | 299 | 10.2307/e26000774 | No. 3 September 2008 pp. 1-116 | . 2008 | 299 | 10.2307/e26000732 | No. 2 August 2008 pp. 1-108 | . 2008 | 299 | 10.2307/e26000691 | No. 1 July 2008 pp. 1-100 | . 2008 | 298 | 10.2307/e26000612 | No. 6 June 2008 pp. 1-112 | . 2008 | 298 | 10.2307/e26000572 | No. 5 May 2008 pp. 1-108 | . 2008 | 298 | 10.2307/e26000529 | No. 4 April 2008 pp. 1-116 | . 2008 | 298 | 10.2307/e26000486 | No. 3 March 2008 pp. 1-104 | . 2008 | 298 | 10.2307/e26000441 | No. 2 February 2008 pp. 1-96 | . 2008 | 298 | 10.2307/e26000347 | No. 1 January 2008 pp. 1-112 | . 2007 | 297 | 10.2307/e26069557 | No. 6 December 2007 pp. 1-116 | . 2007 | 297 | 10.2307/e26069513 | No. 5 November 2007 pp. 1-118 | . 2007 | 297 | 10.2307/e26069427 | No. 4 October 2007 pp. 1-116 | . 2007 | 297 | 10.2307/e26069471 | No. 3 SPECIAL ISSUE: FEAST and FAMINE September 2007 pp. 1-126 | . 2007 | 297 | 10.2307/e26069388 | No. 2 August 2007 pp. 1-104 | . 2007 | 297 | 10.2307/e26069345 | No. 1 July 2007 pp. 1-104 | . 2007 | 296 | 10.2307/e26069278 | No. 6 JUNE 2007 pp. 1-104 | . 2007 | 296 | 10.2307/e26069241 | No. 5 MAY 2007 pp. 1-104 | . 2007 | 296 | 10.2307/e26069201 | No. 4 APRIL 2007 pp. 1-108 | . 2007 | 296 | 10.2307/e26069163 | No. 3 MARCH 2007 pp. 1-104 | . 2007 | 296 | 10.2307/e26069122 | No. 2 FEBRUARY 2007 pp. 1-96 | . 2007 | 296 | 10.2307/e26069087 | No. 1 JANUARY 2007 pp. 1-94 | . 2006 | 295 | 10.2307/e26069048 | No. 6 DECEMBER 2006 pp. 1-124 | . 2006 | 295 | 10.2307/e26069013 | No. 5 NOVEMBER 2006 pp. 1-108 | . 2006 | 295 | 10.2307/e26068974 | No. 4 OCTOBER 2006 pp. 1-100 | . 2006 | 295 | 10.2307/e26068935 | No. 3 SPECIAL ISSUE: ENERGY’S FUTURE: BEYOND CARBON SEPTEMBER 2006 pp. 1-126 | . 2006 | 295 | 10.2307/e26068851 | No. 1 JULY 2006 pp. 1-104 | . 2006 | 295 | 10.2307/e26068892 | No. 2 AUGUST 2006 pp. 1-100 | . 2006 | 294 | 10.2307/e26061462 | No. 6 JUNE 2006 pp. 1-98 | . 2006 | 294 | 10.2307/e26061425 | No. 5 MAY 2006 pp. 1-98 | . 2006 | 294 | 10.2307/e26061387 | No. 4 APRIL 2006 pp. 1-104 | . 2006 | 294 | 10.2307/e26061348 | No. 3 MARCH 2006 pp. 1-104 | . 2006 | 294 | 10.2307/e26061310 | No. 2 FEBRUARY 2006 pp. 1-104 | . 2006 | 294 | 10.2307/e26061272 | No. 1 JANUARY 2006 pp. 1-100 | . 2005 | 293 | 10.2307/e26061231 | No. 6 DECEMBER 2005 pp. 1-128 | . 2005 | 293 | 10.2307/e26061194 | No. 5 NOVEMBER 2005 pp. 1-116 | . 2005 | 293 | 10.2307/e26061156 | No. 4 OCTOBER 2005 pp. 1-112 | . 2005 | 293 | 10.2307/e26061117 | No. 3 SPECIAL ISSUE: Crossroads for Planet Earth SEPTEMBER 2005 pp. 1-124 | . 2005 | 293 | 10.2307/e26061081 | No. 2 AUGUST 2005 pp. 1-96 | . 2005 | 293 | 10.2307/e26061046 | No. 1 JULY 2005 pp. 1-96 | . 2005 | 292 | 10.2307/e26061005 | No. 6 JUNE 2005 pp. 1-116 | . 2005 | 292 | 10.2307/e26060967 | No. 5 MAY 2005 pp. 1-102 | . 2005 | 292 | 10.2307/e26060928 | No. 4 APRIL 2005 pp. 1-108 | . 2005 | 292 | 10.2307/e26060890 | No. 3 MARCH 2005 pp. 1-104 | . 2005 | 292 | 10.2307/e26060848 | No. 2 FEBRUARY 2005 pp. 1-106 | . 2005 | 292 | 10.2307/e26060812 | No. 1 JANUARY 2005 pp. 1-104 | . 2004 | 291 | 10.2307/e26060774 | No. 6 DECEMBER 2004 pp. 1-120 | . 2004 | 291 | 10.2307/e26060737 | No. 5 NOVEMBER 2004 pp. 1-112 | . 2004 | 291 | 10.2307/e26060698 | No. 4 OCTOBER 2004 pp. 1-116 | . 2004 | 291 | 10.2307/e26060658 | No. 3 SPECIAL ISSUE: Beyond Einstein SEPTEMBER 2004 pp. 1-122 | . 2004 | 291 | 10.2307/e26060620 | No. 2 AUGUST 2004 pp. 1-100 | . 2004 | 291 | 10.2307/e26060582 | No. 1 JULY 2004 pp. 1-120 | . 2004 | 290 | 10.2307/e26047728 | No. 6 JUNE 2004 pp. 1-116 | . 2004 | 290 | 10.2307/e26047690 | No. 5 MAY 2004 pp. 1-120 | . 2004 | 290 | 10.2307/e26047652 | No. 4 APRIL 2004 pp. 1-112 | . 2004 | 290 | 10.2307/e26047610 | No. 3 MARCH 2004 pp. 1-112 | . 2004 | 290 | 10.2307/e26047569 | No. 2 FEBRUARY 2004 pp. 1-100 | . 2004 | 290 | 10.2307/e26172627 | No. 1 january 2004 pp. 3-110 | . 2003 | 289 | 10.2307/e26060540 | No. 6 DECEMBER 2003 pp. 1-128 | . 2003 | 289 | 10.2307/e26060499 | No. 5 NOVEMBER 2003 pp. 1-108 | . 2003 | 289 | 10.2307/e26060456 | No. 4 OCTOBER 2003 pp. 1-104 | . 2003 | 289 | 10.2307/e26060415 | No. 3 SEPTEMBER 2003 pp. 1-116 | . 2003 | 289 | 10.2307/e26060375 | No. 2 AUGUST 2003 pp. 1-96 | . 2003 | 289 | 10.2307/e26060333 | No. 1 JULY 2003 pp. 1-94 | . 2003 | 288 | 10.2307/e26060295 | No. 6 JUNE 2003 pp. 1-92 | . 2003 | 288 | 10.2307/e26060257 | No. 5 MAY 2003 pp. 1-100 | . 2003 | 288 | 10.2307/e26060217 | No. 4 APRIL 2003 pp. 1-104 | . 2003 | 288 | 10.2307/e26060176 | No. 3 MARCH 2003 pp. 1-112 | . 2003 | 288 | 10.2307/e26060138 | No. 2 FEBRUARY 2003 pp. 1-94 | . 2003 | 288 | 10.2307/e26060097 | No. 1 JANUARY 2003 pp. 1-96 | . 2002 | 287 | 10.2307/e26060057 | No. 6 DECEMBER 2002 pp. 1-139 | . 2002 | 287 | 10.2307/e26060017 | No. 5 NOVEMBER 2002 pp. 1-100 | . 2002 | 287 | 10.2307/e26059978 | No. 4 OCTOBER 2002 pp. 1-108 | . 2002 | 287 | 10.2307/e26059940 | No. 3 SPECIAL ISSUE: A MATTER OF TIME SEPTEMBER 2002 pp. 1-104 | . 2002 | 287 | 10.2307/e26059900 | No. 2 AUGUST 2002 pp. 1-96 | . 2002 | 287 | 10.2307/e26059860 | No. 1 JULY 2002 pp. 1-96 | . 2002 | 286 | 10.2307/e26059695 | No. 6 JUNE 2002 pp. 1-108 | . 2002 | 286 | 10.2307/e26059654 | No. 5 MAY 2002 pp. 1-104 | . 2002 | 286 | 10.2307/e26059613 | No. 4 APRIL 2002 pp. 1-100 | . 2002 | 286 | 10.2307/e26059572 | No. 3 MARCH 2002 pp. 1-104 | . 2002 | 286 | 10.2307/e26059533 | No. 2 FEBRUARY 2002 pp. 1-100 | . 2002 | 286 | 10.2307/e26059491 | No. 1 JANUARY 2002 pp. 1-98 | . 2001 | 285 | 10.2307/e26059432 | No. 6 DECEMBER 2001 pp. 1-104 | . 2001 | 285 | 10.2307/e26059392 | No. 5 NOVEMBER 2001 pp. 1-96 | . 2001 | 285 | 10.2307/e26059350 | No. 4 OCTOBER 2001 pp. 1-96 | . 2001 | 285 | 10.2307/e26059308 | No. 3 SEPTEMBER 2001 pp. 1-104 | . 2001 | 285 | 10.2307/e26059261 | No. 2 AUGUST 2001 pp. 1-96 | . 2001 | 285 | 10.2307/e26059067 | No. 1 JULY 2001 pp. 1-99 | . 2001 | 284 | 10.2307/e26059220 | No. 6 JUNE 2001 pp. 1-107 | . 2001 | 284 | 10.2307/e26059181 | No. 5 MAY 2001 pp. 1-100 | . 2001 | 284 | 10.2307/e26059143 | No. 4 APRIL 2001 pp. 1-116 | . 2001 | 284 | 10.2307/e26059108 | No. 3 MARCH 2001 pp. 1-92 | . 2001 | 284 | 10.2307/e26059029 | No. 2 FEBRUARY 2001 pp. 1-96 | . 2001 | 284 | 10.2307/e26058986 | No. 1 JANUARY 2001 pp. 1-112 | . 2000 | 283 | 10.2307/e26058951 | No. 6 DECEMBER 2000 pp. 1-120 | . 2000 | 283 | 10.2307/e26058911 | No. 5 NOVEMBER 2000 pp. 1-128 | . 2000 | 283 | 10.2307/e26058875 | No. 4 OCTOBER 2000 pp. 1-104 | . 2000 | 283 | 10.2307/e26058840 | No. 3 SEPTEMBER 2000 pp. 1-112 | . 2000 | 283 | 10.2307/e26058805 | No. 2 AUGUST 2000 pp. 1-96 | . 2000 | 283 | 10.2307/e26058765 | No. 1 JULY 2000 pp. 1-112 | . 2000 | 282 | 10.2307/e26058723 | No. 6 JUNE 2000 pp. 1-116 | . 2000 | 282 | 10.2307/e26058689 | No. 5 MAY 2000 pp. 1-122 | . 2000 | 282 | 10.2307/e26058653 | No. 4 APRIL 2000 pp. 1-120 | . 2000 | 282 | 10.2307/e26058611 | No. 3 MARCH 2000 pp. 1-108 | . 2000 | 282 | 10.2307/e26058577 | No. 2 FEBRUARY 2000 pp. 1-108 | . 2000 | 282 | 10.2307/e26058540 | No. 1 JANUARY 2000 pp. 1-108 | . 1999 | 281 | 10.2307/e26058500 | No. 6 END-OF-THE-MILLENNIUM SPECIAL ISSUE: WHAT SCIENCE WILL KNOW IN 2050 DECEMBER 1999 pp. 1-152 | . 1999 | 281 | 10.2307/e26058461 | No. 5 NOVEMBER 1999 pp. 1-132 | . 1999 | 281 | 10.2307/e26058417 | No. 4 OCTOBER 1999 pp. 1-128 | . 1999 | 281 | 10.2307/e26058379 | No. 3 SEPTEMBER 1999 pp. 1-106 | . 1999 | 281 | 10.2307/e26058340 | No. 2 AUGUST 1999 pp. 1-100 | . 1999 | 281 | 10.2307/e26058301 | No. 1 JULY 1999 pp. 1-108 | . 1999 | 280 | 10.2307/e26058265 | No. 6 JUNE 1999 pp. 1-104 | . 1999 | 280 | 10.2307/e26058192 | No. 5 MAY 1999 pp. 1-108 | . 1999 | 280 | 10.2307/e26058114 | No. 4 APRIL 1999 pp. 1-132 | . 1999 | 280 | 10.2307/e26058071 | No. 3 MARCH 1999 pp. 1-114 | . 1999 | 280 | 10.2307/e26058033 | No. 2 FEBRUARY 1999 pp. 1-108 | . 1999 | 280 | 10.2307/e26057979 | No. 1 JANUARY 1999 pp. 1-119 | . 1998 | 279 | 10.2307/e26058191 | No. 6 DECEMBER 1998 pp. 1-127 | . 1998 | 279 | 10.2307/e26058110 | No. 5 NOVEMBER 1998 pp. 1-124 | . 1998 | 279 | 10.2307/e26057955 | No. 4 OCTOBER 1998 pp. 1-135 | . 1998 | 279 | 10.2307/e26057921 | No. 3 SEPTEMBER 1998 pp. 1-109 | . 1998 | 279 | 10.2307/e26070570 | No. 2 AUGUST 1998 pp. 1-104 | . 1998 | 279 | 10.2307/e26057797 | No. 1 JULY 1998 pp. 1-118 | . 1998 | 278 | 10.2307/e26057798 | No. 6 JUNE 1998 pp. 1-102 | . 1998 | 278 | 10.2307/e26057757 | No. 5 MAY 1998 pp. 1-112 | . 1998 | 278 | 10.2307/e26057719 | No. 4 APRIL 1998 pp. 1-108 | . 1998 | 278 | 10.2307/e26057678 | No. 3 MARCH 1998 pp. 1-108 | . 1998 | 278 | 10.2307/e26057638 | No. 2 FEBRUARY 1998 pp. 1-104 | . 1998 | 278 | 10.2307/e26057600 | No. 1 JANUARY 1998 pp. 1-115 | . 1997 | 277 | 10.2307/e24996019 | No. 6 DECEMBER 1997 pp. 1-132 | . 1997 | 277 | 10.2307/e24995980 | No. 5 NOVEMBER 1997 pp. 1-124 | . 1997 | 277 | 10.2307/e24995926 | No. 4 SPECIAL ISSUE: THE FUTURE OF TRANSPORTATION OCTOBER 1997 pp. 1-156 | . 1997 | 277 | 10.2307/e24995885 | No. 3 SEPTEMBER 1997 pp. 1-103 | . 1997 | 277 | 10.2307/e24995847 | No. 2 AUGUST 1997 pp. 1-96 | . 1997 | 277 | 10.2307/e24995805 | No. 1 JULY 1997 pp. 1-105 | . 1997 | 276 | 10.2307/e24993757 | No. 6 JUNE 1997 pp. 1-148 | . 1997 | 276 | 10.2307/e24993719 | No. 5 MAY 1997 pp. 1-120 | . 1997 | 276 | 10.2307/e24993677 | No. 4 APRIL 1997 pp. 1-116 | . 1997 | 276 | 10.2307/e24993628 | No. 3 MARCH 1997 pp. 1-132 | . 1997 | 276 | 10.2307/e24993583 | No. 2 FEBRUARY 1997 pp. 1-108 | . 1997 | 276 | 10.2307/e24993541 | No. 1 JANUARY 1997 pp. 1-119 | . 1996 | 275 | 10.2307/e24993465 | No. 6 DECEMBER 1996 pp. 1-132 | . 1996 | 275 | 10.2307/e24993423 | No. 5 NOVEMBER 1996 pp. 1-127 | . 1996 | 275 | 10.2307/e24993381 | No. 4 OCTOBER 1996 pp. 1-128 | . 1996 | 275 | 10.2307/e24993327 | No. 3 SPECIAL ISSUE: WHAT YOU NEED TO KNOW ABOUT CANCER SEPTEMBER 1996 pp. 1-184 | . 1996 | 275 | 10.2307/e24993286 | No. 2 AUGUST 1996 pp. 1-112 | . 1996 | 275 | 10.2307/e24993243 | No. 1 JULY 1996 pp. 1-108 | . 1996 | 274 | 10.2307/e24989541 | No. 6 JUNE 1996 pp. 1-116 | . 1996 | 274 | 10.2307/e24989498 | No. 5 MAY 1996 pp. 1-112 | . 1996 | 274 | 10.2307/e24989455 | No. 4 APRIL 1996 pp. 1-116 | . 1996 | 274 | 10.2307/e24989412 | No. 3 MARCH 1996 pp. 1-120 | . 1996 | 274 | 10.2307/e24989369 | No. 2 FEBRUARY 1996 pp. 1-136 | . 1996 | 274 | 10.2307/e24989322 | No. 1 JANUARY 1996 pp. 1-112 | . 1995 | 273 | 10.2307/e24985500 | No. 6 DECEMBER 1995 pp. 1-120 | . 1995 | 273 | 10.2307/e24981997 | No. 5 NOVEMBER 1995 pp. 1-111 | . 1995 | 273 | 10.2307/e24981860 | No. 4 OCTOBER 1995 pp. 1-191 | . 1995 | 273 | 10.2307/e24981651 | No. 3 September 1995 pp. 1-216 | . 1995 | 273 | 10.2307/e24981535 | No. 2 AUGUST 1995 pp. 1-108 | . 1995 | 273 | 10.2307/e24981384 | No. 1 JULY 1995 pp. 1-95 | . 1995 | 272 | 10.2307/e24980804 | No. 6 JUNE 1995 pp. 1-120 | . 1995 | 272 | 10.2307/e24980766 | No. 5 MAY 1995 pp. 1-112 | . 1995 | 272 | 10.2307/e24980490 | No. 4 APRIL 1995 pp. 1-140 | . 1995 | 272 | 10.2307/e24980344 | No. 3 MARCH 1995 pp. 1-115 | . 1995 | 272 | 10.2307/e24980191 | No. 2 FEBRUARY 1995 pp. 1-104 | . 1995 | 272 | 10.2307/e24980087 | No. 1 JANUARY 1995 pp. 1-104 | . 1994 | 271 | 10.2307/e24942923 | No. 6 DECEMBER 1994 pp. 1-127 | . 1994 | 271 | 10.2307/e24942889 | No. 5 NOVEMBER 1994 pp. 1-116 | . 1994 | 271 | 10.2307/e24942853 | No. 4 SPECIAL ISSUE: LIFE IN THE UNIVERSE OCTOBER 1994 pp. 1-144 | . 1994 | 271 | 10.2307/e24942818 | No. 3 SEPTEMBER 1994 pp. 1-112 | . 1994 | 271 | 10.2307/e24942784 | No. 2 AUGUST 1994 pp. 1-96 | . 1994 | 271 | 10.2307/e24942749 | No. 1 JULY 1994 pp. 1-112 | . 1994 | 270 | 10.2307/e24942715 | No. 6 JUNE 1994 pp. 1-116 | . 1994 | 270 | 10.2307/e24942677 | No. 5 MAY 1994 pp. 1-128 | . 1994 | 270 | 10.2307/e24942643 | No. 4 APRIL 1994 pp. 1-128 | . 1994 | 270 | 10.2307/e24942608 | No. 3 MARCH 1994 pp. 1-120 | . 1994 | 270 | 10.2307/e24942571 | No. 2 FEBRUARY 1994 pp. 1-124 | . 1994 | 270 | 10.2307/e24942538 | No. 1 JANUARY 1994 pp. 1-159 | . 1993 | 269 | 10.2307/e24941701 | No. 6 DECEMBER 1993 pp. 1-144 | . 1993 | 269 | 10.2307/e24941666 | No. 5 NOVEMBER 1993 pp. 1-120 | . 1993 | 269 | 10.2307/e24941632 | No. 4 OCTOBER 1993 pp. 1-120 | . 1993 | 269 | 10.2307/e24941597 | No. 3 SPECIAL ISSUE: LIFE, DEATH AND THE IMMUNE SYSTEM SEPTEMBER 1993 pp. 1-164 | . 1993 | 269 | 10.2307/e24941562 | No. 2 AUGUST 1993 pp. 1-128 | . 1993 | 269 | 10.2307/e24941530 | No. 1 JULY 1993 pp. 1-120 | . 1993 | 268 | 10.2307/e24941494 | No. 6 JUNE 1993 pp. 1-152 | . 1993 | 268 | 10.2307/e24941459 | No. 5 MAY 1993 pp. 1-144 | . 1993 | 268 | 10.2307/e24941421 | No. 4 APRIL 1993 pp. 1-128 | . 1993 | 268 | 10.2307/e24941390 | No. 3 MARCH 1993 pp. 1-150 | . 1993 | 268 | 10.2307/e24941357 | No. 2 FEBRUARY 1993 pp. 1-120 | . 1993 | 268 | 10.2307/e24941322 | No. 1 JANUARY 1993 pp. 1-160 | . 1992 | 267 | 10.2307/e24939310 | No. 6 DECEMBER 1992 pp. 1-162 | . 1992 | 267 | 10.2307/e24939273 | No. 5 NOVEMBER 1992 pp. 1-138 | . 1992 | 267 | 10.2307/e24939235 | No. 4 OCTOBER 1992 pp. 1-128 | . 1992 | 267 | 10.2307/e24939196 | No. 3 SPECIAL ISSUE: MIND AND BRAIN SEPTEMBER 1992 pp. 1-180 | . 1992 | 267 | 10.2307/e24939156 | No. 2 AUGUST 1992 pp. 1-132 | . 1992 | 267 | 10.2307/e24939119 | No. 1 JULY 1992 pp. 1-122 | . 1992 | 266 | 10.2307/e24939080 | No. 6 JUNE 1992 pp. 1-132 | . 1992 | 266 | 10.2307/e24939039 | No. 5 MAY 1992 pp. 1-144 | . 1992 | 266 | 10.2307/e24939000 | No. 4 APRIL 1992 pp. 1-160 | . 1992 | 266 | 10.2307/e24938958 | No. 3 MARCH 1992 pp. 1-118 | . 1992 | 266 | 10.2307/e24938922 | No. 2 FEBRUARY 1992 pp. 1-120 | . 1992 | 266 | 10.2307/e24938880 | No. 1 JANUARY 1992 pp. 1-150 | . 1991 | 265 | 10.2307/e24938817 | No. 6 DECEMBER 1991 pp. 1-158 | . 1991 | 265 | 10.2307/e24938779 | No. 5 NOVEMBER 1991 pp. 1-144 | . 1991 | 265 | 10.2307/e24938739 | No. 4 OCTOBER 1991 pp. 1-134 | . 1991 | 265 | 10.2307/e24938698 | No. 3 SPECIAL ISSUE: Communications, Computers and Networks: How to Work, Play and Thrive in Cyberspace SEPTEMBER 1991 pp. 1-190 | . 1991 | 265 | 10.2307/e24938660 | No. 2 AUGUST 1991 pp. 1-112 | . 1991 | 265 | 10.2307/e24936960 | No. 1 JULY 1991 pp. 1-128 | . 1991 | 264 | 10.2307/e24936921 | No. 6 JUNE 1991 pp. 1-132 | . 1991 | 264 | 10.2307/e24936887 | No. 5 MAY 1991 pp. 1-136 | . 1991 | 264 | 10.2307/e24936846 | No. 4 APRIL 1991 pp. 1-168 | . 1991 | 264 | 10.2307/e24936809 | No. 3 MARCH 1991 pp. 1-126 | . 1991 | 264 | 10.2307/e24936774 | No. 2 FEBRUARY 1991 pp. 1-144 | . 1991 | 264 | 10.2307/e24936737 | No. 1 JANUARY 1991 pp. 1-126 | . 1990 | 263 | 10.2307/e24996993 | No. 6 DECEMBER 1990 pp. 1-36, J1-J16, 53-144 | . 1990 | 263 | 10.2307/e24996955 | No. 5 NOVEMBER 1990 pp. 1-152 | . 1990 | 263 | 10.2307/e24997042 | No. 4 OCTOBER 1990 pp. 1-135 | . 1990 | 263 | 10.2307/e24996916 | No. 3 SPECIAL ISSUE: ENERGY FOR PLANET EARTH SEPTEMBER 1990 pp. 1-184 | . 1990 | 263 | 10.2307/e24996881 | No. 2 AUGUST 1990 pp. 1-116 | . 1990 | 263 | 10.2307/e24996845 | No. 1 JULY 1990 pp. 1-128 | . 1990 | 262 | 10.2307/e24996805 | No. 6 JUNE 1990 pp. 1-140 | . 1990 | 262 | 10.2307/e24996729 | No. 5 MAY 1990 pp. 1-136 | . 1990 | 262 | 10.2307/e24996695 | No. 4 APRIL 1990 pp. 1-124 | . 1990 | 262 | 10.2307/e24996766 | No. 3 MARCH 1990 pp. 1-128 | . 1990 | 262 | 10.2307/e24996660 | No. 2 FEBRUARY 1990 pp. 1-112 | . 1990 | 262 | 10.2307/e24996624 | No. 1 JANUARY 1990 pp. 1-56, 1-43, 100-154 | . 1989 | 261 | 10.2307/e24987493 | No. 6 DECEMBER 1989 pp. 1-36, J1-J26, 61-158 | . 1989 | 261 | 10.2307/e24987455 | No. 5 NOVEMBER 1989 pp. 1-130 | . 1989 | 261 | 10.2307/e24987417 | No. 4 OCTOBER 1989 pp. 1-128 | . 1989 | 261 | 10.2307/e24987375 | No. 3 SEPTEMBER 1989 pp. 1-190 | . 1989 | 261 | 10.2307/e24987337 | No. 2 AUGUST 1989 pp. 1-112 | . 1989 | 261 | 10.2307/e24987302 | No. 1 JULY 1989 pp. 1-118 | . 1989 | 260 | 10.2307/e24987266 | No. 6 JUNE 1989 pp. 1-132 | . 1989 | 260 | 10.2307/e24987229 | No. 5 MAY 1989 pp. 1-38, W1-W15, 54-148 | . 1989 | 260 | 10.2307/e24987191 | No. 4 APRIL 1989 pp. 1-126 | . 1989 | 260 | 10.2307/e24987155 | No. 3 MARCH 1989 pp. 1-120 | . 1989 | 260 | 10.2307/e24987121 | No. 2 FEBRUARY 1989 pp. 1-116 | . 1989 | 260 | 10.2307/e24987090 | No. 1 JANUARY 1989 pp. 1-114 | . 1988 | 259 | 10.2307/e24989282 | No. 6 DECEMBER 1988 pp. 1-132 | . 1988 | 259 | 10.2307/e24989244 | No. 5 NOVEMBER 1988 pp. 1-68, J1-J20, 85-150 | . 1988 | 259 | 10.2307/e24987908 | No. 4 OCTOBER 1988 pp. 1-152 | . 1988 | 259 | 10.2307/e24989211 | No. 3 SEPTEMBER 1988 pp. 1-60, T1-T24, 85-144 | . 1988 | 259 | 10.2307/e24989176 | No. 2 AUGUST 1988 pp. 1-112 | . 1988 | 259 | 10.2307/e24989140 | No. 1 JULY 1988 pp. 1-12, S1-S18, 31-127 | . 1988 | 258 | 10.2307/e24989101 | No. 6 JUNE 1988 pp. 1-128 | . 1988 | 258 | 10.2307/e24989066 | No. 5 MAY 1988 pp. 1-127 | . 1988 | 258 | 10.2307/e24989031 | No. 4 APRIL 1988 pp. 1-128 | . 1988 | 258 | 10.2307/e24988996 | No. 3 MARCH 1988 pp. 1-123 | . 1988 | 258 | 10.2307/e24988960 | No. 2 FEBRUARY 1988 pp. 1-56, T1-T25, 82-136 | . 1988 | 258 | 10.2307/e24988925 | No. 1 JANUARY 1988 pp. 1-112 | . 1987 | 257 | 10.2307/e24979561 | No. 6 DECEMBER 1987 pp. 1-158 | . 1987 | 257 | 10.2307/e24979528 | No. 5 NOVEMBER 1987 pp. 1-68, J1-J19 88-151 | . 1987 | 257 | 10.2307/e24979492 | No. 4 OCTOBER 1987 pp. 1-98, T1-T17, 116-184 | . 1987 | 257 | 10.2307/e24979457 | No. 3 SEPTEMBER 1987 pp. 1-120 | . 1987 | 257 | 10.2307/e24979435 | No. 2 August 1987 pp. 1-116 | . 1987 | 257 | 10.2307/e24979413 | No. 1 July 1987 pp. 1-116 | . 1987 | 256 | 10.2307/e24979394 | No. 6 June 1987 pp. 1-58B, M1-M27, 80-136 | . 1987 | 256 | 10.2307/e24979372 | No. 5 May 1987 pp. 1-80, T1-T9, 90-128 | . 1987 | 256 | 10.2307/e24979350 | No. 4 April 1987 pp. 1-128 | . 1987 | 256 | 10.2307/e24979328 | No. 3 March 1987 pp. 1-128 | . 1987 | 256 | 10.2307/e24979306 | No. 2 February 1987 pp. 1-140 | . 1987 | 256 | 10.2307/e24979284 | No. 1 January 1987 pp. 1-128 | . 1986 | 255 | 10.2307/e24976094 | No. 6 December 1986 pp. 1-152 | . 1986 | 255 | 10.2307/e24976073 | No. 5 November 1986 pp. 1-84, J1-J25, 106-140 | . 1986 | 255 | 10.2307/e24976046 | No. 4 October 1986 pp. 1-212 | . 1986 | 255 | 10.2307/e24976027 | No. 3 September 1986 pp. 1-120 | . 1986 | 255 | 10.2307/e24976005 | No. 2 August 1986 pp. 1-120 | . 1986 | 255 | 10.2307/e24975983 | No. 1 July 1986 pp. 1-120 | . 1986 | 254 | 10.2307/e24975962 | No. 6 June 1986 pp. 1-128 | . 1986 | 254 | 10.2307/e24975940 | No. 5 May 1986 pp. 1-128 | . 1986 | 254 | 10.2307/e24975921 | No. 4 April 1986 pp. 1-64, I1-I12, 65-124 | . 1986 | 254 | 10.2307/e24975899 | No. 3 March 1986 pp. 1-120 | . 1986 | 254 | 10.2307/e24975880 | No. 2 February 1986 pp. 1-120 | . 1986 | 254 | 10.2307/e24975861 | No. 1 January 1986 pp. 1-127 | . 1985 | 253 | 10.2307/e24967863 | No. 6 December 1985 pp. 1-150 | . 1985 | 253 | 10.2307/e24967823 | No. 5 November 1985 pp. 1-78, J1-J24, 103-178 | . 1985 | 253 | 10.2307/e24967798 | No. 4 October 1985 pp. 1-184 | . 1985 | 253 | 10.2307/e24967775 | No. 3 September 1985 pp. 1-24, NY1-NY8, 33-72, S1-S24, 73-144 | . 1985 | 253 | 10.2307/e24967753 | No. 2 August 1985 pp. 1-120 | . 1985 | 253 | 10.2307/e24967703 | No. 1 July 1985 pp. 1-128 | . 1985 | 252 | 10.2307/e24967651 | No. 6 June 1985 pp. 1-136 | . 1985 | 252 | 10.2307/e24967624 | No. 5 May 1985 pp. 1-144 | . 1985 | 252 | 10.2307/e24967602 | No. 4 April 1985 pp. 1-146 | . 1985 | 252 | 10.2307/e24967578 | No. 3 March 1985 pp. 1-128 | . 1985 | 252 | 10.2307/e24967556 | No. 2 February 1985 pp. 1-128 | . 1985 | 252 | 10.2307/e24967534 | No. 1 January 1985 pp. 1-120 | . 1984 | 251 | 10.2307/e24969489 | No. 6 December 1984 pp. 1-74, A1-A40, 75-146 | . 1984 | 251 | 10.2307/e24969466 | No. 5 November 1984 pp. 1-76, J1-J44, 121-185, B1-B8, 186-194 | . 1984 | 251 | 10.2307/e24969444 | No. 4 October 1984 pp. 1-154 | . 1984 | 251 | 10.2307/e24920334 | No. 3 September 1984 pp. 1-230 | . 1984 | 251 | 10.2307/e24969422 | No. 2 August 1984 pp. 1-66, S1-S16, 67-130 | . 1984 | 251 | 10.2307/e24969400 | No. 1 July 1984 pp. 1-138 | . 1984 | 250 | 10.2307/e24969378 | No. 6 June 1984 pp. 1-26, C1-C14, 41-154 | . 1984 | 250 | 10.2307/e24969356 | No. 5 May 1984 pp. 1-72, B1-B12, 85-98, E1-E9, 108-154 | . 1984 | 250 | 10.2307/e24969333 | No. 4 April 1984 pp. 1-96, P1-P8, 105-154 | . 1984 | 250 | 10.2307/e24969310 | No. 3 March 1984 pp. 1-74, C1-C9, 84-144 | . 1984 | 250 | 10.2307/e24969288 | No. 2 February 1984 pp. 1-20, P1-P12, 33-148 | . 1984 | 250 | 10.2307/e24969266 | No. 1 January 1984 pp. 1-16, C1-C12, 29-76, A1-A52, 77-146 | . 1983 | 249 | 10.2307/e24969042 | No. 6 December 1983 pp. 1-178 | . 1983 | 249 | 10.2307/e24969019 | No. 5 November 1983 pp. 1-80, J1-J45, 126-198 | . 1983 | 249 | 10.2307/e24968996 | No. 4 October 1983 pp. 1-36, D1-D14, 51-88, F1-F20, 89-111, C1-C8, 120-170 | . 1983 | 249 | 10.2307/e24968974 | No. 3 September 1983 pp. 1-28, E1-E8, 37-202 | . 1983 | 249 | 10.2307/e24968952 | No. 2 August 1983 pp. 1-128 | . 1983 | 249 | 10.2307/e24968930 | No. 1 July 1983 pp. 1-130 | . 1983 | 248 | 10.2307/e24968908 | No. 6 June 1983 pp. 1-154 | . 1983 | 248 | 10.2307/e24968885 | No. 5 May 1983 pp. 1-26, E1-E18, 45-170 | . 1983 | 248 | 10.2307/e24968862 | No. 4 April 1983 pp. 1-138 | . 1983 | 248 | 10.2307/e24968839 | No. 3 March 1983 pp. 1-146 | . 1983 | 248 | 10.2307/e24968817 | No. 2 February 1983 pp. 1-154 | . 1983 | 248 | 10.2307/e24968794 | No. 1 January 1983 pp. 1-138 | . 1982 | 247 | 10.2307/e24966737 | No. 6 December 1982 pp. 1-178 | . 1982 | 247 | 10.2307/e24966714 | No. 5 November 1982 pp. 1-92, F1-F32, 125-206 | . 1982 | 247 | 10.2307/e24966692 | No. 4 October 1982 pp. 1-84, J1-J32, 117-194 | . 1982 | 247 | 10.2307/e24966669 | No. 3 September 1982 pp. 1-34, M1-M18, 53-218 | . 1982 | 247 | 10.2307/e24966646 | No. 2 August 1982 pp. 1-68, I1-I16, 85-150 | . 1982 | 247 | 10.2307/e24966624 | No. 1 July 1982 pp. 1-78, F1-F8, 79-154 | . 1982 | 246 | 10.2307/e24966602 | No. 6 June 1982 pp. 1-154 | . 1982 | 246 | 10.2307/e24966579 | No. 5 May 1982 pp. 1-34, D1-D12, 47-178 | . 1982 | 246 | 10.2307/e24966556 | No. 4 April 1982 pp. 1-162 | . 1982 | 246 | 10.2307/e24966533 | No. 3 March 1982 pp. 1-154 | . 1982 | 246 | 10.2307/e24966510 | No. 2 February 1982 pp. 1-78, C1-C17, 96-170 | . 1982 | 246 | 10.2307/e24966488 | No. 1 January 1982 pp. 1-28, S1-S11, 40-80, P1-P19, 100-180 | . 1981 | 245 | 10.2307/e24964612 | No. 6 December 1981 pp. 1-186 | . 1981 | 245 | 10.2307/e24964590 | No. 5 November 1981 pp. 1-202 | . 1981 | 245 | 10.2307/e24964569 | No. 4 October 1981 pp. 1-34, E1-E8, 41-96, J1-J48, 145-238 | . 1981 | 245 | 10.2307/e24964547 | No. 3 September 1981 pp. 1-18, I1-I20, 51-226 | . 1981 | 245 | 10.2307/e24964525 | No. 2 August 1981 pp. 1-74, S1-S8, 83-154 | . 1981 | 245 | 10.2307/e24964476 | No. 1 July 1981 pp. 1-84, G1-G20, 105-188 | . 1981 | 244 | 10.2307/e24964428 | No. 6 June 1981 pp. 1-32, E1-E12, 45-202 | . 1981 | 244 | 10.2307/e24964406 | No. 5 May 1981 pp. 1-186 | . 1981 | 244 | 10.2307/e24964362 | No. 4 April 1981 pp. 1-186 | . 1981 | 244 | 10.2307/e24964316 | No. 3 March 1981 pp. 1-120, SC1-SC13, 134-194 | . 1981 | 244 | 10.2307/e24964270 | No. 2 February 1981 pp. 1-176 | . 1981 | 244 | 10.2307/e24964248 | No. 1 January 1981 pp. 1-14, D1-D6, 21-32, is1-is16, 49-170 | . 1980 | 243 | 10.2307/e24966468 | No. 6 December 1980 pp. 1-28, M1-M18, 47-172, I1-I32, 205-246 | . 1980 | 243 | 10.2307/e24966445 | No. 5 November 1980 pp. 1-210 | . 1980 | 243 | 10.2307/e24966423 | No. 4 October 1980 pp. 1-26B, M1-M8, 35-90, J1-J33, 124-210 | . 1980 | 243 | 10.2307/e24966400 | No. 3 September 1980 pp. 1-132, F1-F19, 152-246 | . 1980 | 243 | 10.2307/e24966378 | No. 2 August 1980 pp. 1-168 | . 1980 | 243 | 10.2307/e24966356 | No. 1 July 1980 pp. 1-162 | . 1980 | 242 | 10.2307/e24966334 | No. 6 June 1980 pp. 1-186 | . 1980 | 242 | 10.2307/e24966312 | No. 5 May 1980 pp. 1-186 | . 1980 | 242 | 10.2307/e24966289 | No. 4 April 1980 pp. 1-178 | . 1980 | 242 | 10.2307/e24966267 | No. 3 March 1980 pp. 1-194 | . 1980 | 242 | 10.2307/e24966243 | No. 2 February 1980 pp. 1-172 | . 1980 | 242 | 10.2307/e24966221 | No. 1 January 1980 pp. 1-162 | . 1979 | 241 | 10.2307/e24965347 | No. 6 December 1979 pp. 1-202 | . 1979 | 241 | 10.2307/e24965324 | No. 5 November 1979 pp. 1-206 | . 1979 | 241 | 10.2307/e24965301 | No. 4 October 1979 pp. 1-186 | . 1979 | 241 | 10.2307/e24965275 | No. 3 September 1979 pp. 1-250 | . 1979 | 241 | 10.2307/e24965252 | No. 2 August 1979 pp. 1-80, S1-S40, 121-198 | . 1979 | 241 | 10.2307/e24965230 | No. 1 July 1979 pp. 1-162 | . 1979 | 240 | 10.2307/e24965207 | No. 6 June 1979 pp. 1-202 | . 1979 | 240 | 10.2307/e24965184 | No. 5 May 1979 pp. 1-184 | . 1979 | 240 | 10.2307/e24965162 | No. 4 April 1979 pp. 1-190 | . 1979 | 240 | 10.2307/e24965139 | No. 3 March 1979 pp. 1-174 | . 1979 | 240 | 10.2307/e24965093 | No. 2 February 1979 pp. 1-168 | . 1979 | 240 | 10.2307/e24965055 | No. 1 January 1979 pp. 1-164 | . 1978 | 239 | 10.2307/e24955857 | No. 6 December 1978 pp. 1-198 | . 1978 | 239 | 10.2307/e24955834 | No. 5 November 1978 pp. 1-198 | . 1978 | 239 | 10.2307/e24955811 | No. 4 October 1978 pp. 1-188 | . 1978 | 239 | 10.2307/e24955787 | No. 3 September 1978 pp. 1-242 | . 1978 | 239 | 10.2307/e24960341 | No. 2 August 1978 pp. 1-148 | . 1978 | 239 | 10.2307/e24955764 | No. 1 July 1978 pp. 1-162 | . 1978 | 238 | 10.2307/e24955742 | No. 6 June 1978 pp. 1-160 | . 1978 | 238 | 10.2307/e24955719 | No. 5 May 1978 pp. 1-172 | . 1978 | 238 | 10.2307/e24955696 | No. 4 April 1978 pp. 1-164 | . 1978 | 238 | 10.2307/e24955647 | No. 3 March 1978 pp. 1-154 | . 1978 | 238 | 10.2307/e24955624 | No. 2 February 1978 pp. 1-162 | . 1978 | 238 | 10.2307/e24955601 | No. 1 January 1978 pp. 1-140 | . 1977 | 237 | 10.2307/e24953861 | No. 6 December 1977 pp. 1-190 | . 1977 | 237 | 10.2307/e24953903 | No. 5 November 1977 pp. 1-164 | . 1977 | 237 | 10.2307/e24953950 | No. 4 October 1977 pp. 1-152 | . 1977 | 237 | 10.2307/e24920309 | No. 3 September 1977 pp. 1-262 | . 1977 | 237 | 10.2307/e24953994 | No. 2 August 1977 pp. 1-140 | . 1977 | 237 | 10.2307/e24954039 | No. 1 July 1977 pp. 1-154 | . 1977 | 236 | 10.2307/e24954062 | No. 6 June 1977 pp. 1-142 | . 1977 | 236 | 10.2307/e24954017 | No. 5 May 1977 pp. 1-148 | . 1977 | 236 | 10.2307/e24953973 | No. 4 April 1977 pp. 1-148 | . 1977 | 236 | 10.2307/e24953929 | No. 3 March 1977 pp. 1-151 | . 1977 | 236 | 10.2307/e24953884 | No. 2 February 1977 pp. 1-138 | . 1977 | 236 | 10.2307/e24953842 | No. 1 January 1977 pp. 1-132 | . 1976 | 235 | 10.2307/e24950496 | No. 6 December 1976 pp. 1-152 | . 1976 | 235 | 10.2307/e24950475 | No. 5 November 1976 pp. 1-150 | . 1976 | 235 | 10.2307/e24950453 | No. 4 October 1976 pp. 1-144 | . 1976 | 235 | 10.2307/e24950428 | No. 3 September 1976 pp. 1-222 | . 1976 | 235 | 10.2307/e24950407 | No. 2 August 1976 pp. 1-116 | . 1976 | 235 | 10.2307/e24950385 | No. 1 July 1976 pp. 1-138 | . 1976 | 234 | 10.2307/e24950363 | No. 6 June 1976 pp. 1-132 | . 1976 | 234 | 10.2307/e24950342 | No. 5 May 1976 pp. 1-132 | . 1976 | 234 | 10.2307/e24950319 | No. 4 April 1976 pp. 1-138 | . 1976 | 234 | 10.2307/e24950296 | No. 3 March 1976 pp. 1-131 | . 1976 | 234 | 10.2307/e24950274 | No. 2 February 1976 pp. 1-140 | . 1976 | 234 | 10.2307/e24950252 | No. 1 January 1976 pp. 1-136 | . 1975 | 233 | 10.2307/e24949953 | No. 6 December 1975 pp. 1-152 | . 1975 | 233 | 10.2307/e24949930 | No. 5 November 1975 pp. 1-152 | . 1975 | 233 | 10.2307/e24949907 | No. 4 October 1975 pp. 1-144 | . 1975 | 233 | 10.2307/e24949879 | No. 3 September 1975 pp. 1-228 | . 1975 | 233 | 10.2307/e24949856 | No. 2 August 1975 pp. 1-132 | . 1975 | 233 | 10.2307/e24949833 | No. 1 July 1975 pp. 1-136 | . 1975 | 232 | 10.2307/e24949811 | No. 6 June 1975 pp. 1-132 | . 1975 | 232 | 10.2307/e24949789 | No. 5 May 1975 pp. 1-128 | . 1975 | 232 | 10.2307/e24949765 | No. 4 April 1975 pp. 1-160 | . 1975 | 232 | 10.2307/e24949743 | No. 3 March 1975 pp. 1-136 | . 1975 | 232 | 10.2307/e24949720 | No. 2 February 1975 pp. 1-120 | . 1975 | 232 | 10.2307/e24949697 | No. 1 January 1975 pp. 1-140 | . 1974 | 231 | 10.2307/e24950231 | No. 6 December 1974 pp. 1-167 | . 1974 | 231 | 10.2307/e24950208 | No. 5 November 1974 pp. 1-146 | . 1974 | 231 | 10.2307/e24950185 | No. 4 October 1974 pp. 1-142 | . 1974 | 231 | 10.2307/e24950157 | No. 3 September 1974 pp. 1-212 | . 1974 | 231 | 10.2307/e24950134 | No. 2 August 1974 pp. 1-116 | . 1974 | 231 | 10.2307/e24950111 | No. 1 July 1974 pp. 1-136 | . 1974 | 230 | 10.2307/e24950089 | No. 6 June 1974 pp. 1-136 | . 1974 | 230 | 10.2307/e24950066 | No. 5 May 1974 pp. 1-144 | . 1974 | 230 | 10.2307/e24950043 | No. 4 April 1974 pp. 1-128 | . 1974 | 230 | 10.2307/e24950019 | No. 3 March 1974 pp. 1-124 | . 1974 | 230 | 10.2307/e24949997 | No. 2 February 1974 pp. 1-124 | . 1974 | 230 | 10.2307/e24949973 | No. 1 January 1974 pp. 1-130 | . 1973 | 229 | 10.2307/e24923257 | No. 6 December 1973 pp. 1-148 | . 1973 | 229 | 10.2307/e24923234 | No. 5 November 1973 pp. 1-17, 17A-17B, 18-123, 123A-123B, 124-136 | . 1973 | 229 | 10.2307/e24923211 | No. 4 October 1973 pp. 1-132 | . 1973 | 229 | 10.2307/e24923183 | No. 3 September 1973 pp. 1-200 | . 1973 | 229 | 10.2307/e24923160 | No. 2 August 1973 pp. 1-116 | . 1973 | 229 | 10.2307/e24923138 | No. 1 July 1973 pp. 1-122 | . 1973 | 228 | 10.2307/e24923063 | No. 6 June 1973 pp. 1-124 | . 1973 | 228 | 10.2307/e24923039 | No. 5 May 1973 pp. 1-120 | . 1973 | 228 | 10.2307/e24923016 | No. 4 April 1973 pp. 1-124 | . 1973 | 228 | 10.2307/e24922993 | No. 3 March 1973 pp. 1-128 | . 1973 | 228 | 10.2307/e24922971 | No. 2 February 1973 pp. 1-124 | . 1973 | 228 | 10.2307/e24922947 | No. 1 January 1973 pp. 1-128 | . 1972 | 227 | 10.2307/e24922927 | No. 6 December 1972 pp. 1-128 | . 1972 | 227 | 10.2307/e24922905 | No. 5 November 1972 pp. 1-136 | . 1972 | 227 | 10.2307/e24922882 | No. 4 October 1972 pp. 1-10, 10A-10B, 11-128 | . 1972 | 227 | 10.2307/e24927420 | No. 3 September 1972 pp. 1-212 | . 1972 | 227 | 10.2307/e24927397 | No. 2 August 1972 pp. 1-124 | . 1972 | 227 | 10.2307/e24927375 | No. 1 July 1972 pp. 1-122 | . 1972 | 226 | 10.2307/e24927351 | No. 6 June 1972 pp. 1-136 | . 1972 | 226 | 10.2307/e24927329 | No. 5 May 1972 pp. 1-140 | . 1972 | 226 | 10.2307/e24927307 | No. 4 April 1972 pp. 1-118 | . 1972 | 226 | 10.2307/e24927284 | No. 3 March 1972 pp. 1-128 | . 1972 | 226 | 10.2307/e24927260 | No. 2 February 1972 pp. 1-118 | . 1972 | 226 | 10.2307/e24923086 | No. 1 January 1972 pp. 1-122 | . 1971 | 225 | 10.2307/e24922862 | No. 6 December 1971 pp. 1-120 | . 1971 | 225 | 10.2307/e24922838 | No. 5 November 1971 pp. 1-138 | . 1971 | 225 | 10.2307/e24922814 | No. 4 October 1971 pp. 1-120 | . 1971 | 225 | 10.2307/e24923110 | No. 3 September 1971 pp. 1-246 | . 1971 | 225 | 10.2307/e24922791 | No. 2 August 1971 pp. 1-120 | . 1971 | 225 | 10.2307/e24922768 | No. 1 July 1971 pp. 1-122 | . 1971 | 224 | 10.2307/e24922744 | No. 6 June 1971 pp. 1-136 | . 1971 | 224 | 10.2307/e24927786 | No. 5 May 1971 pp. 1-132 | . 1971 | 224 | 10.2307/e24927762 | No. 4 April 1971 pp. 1-130 | . 1971 | 224 | 10.2307/e24927739 | No. 3 March 1971 pp. 1-124 | . 1971 | 224 | 10.2307/e24927716 | No. 2 February 1971 pp. 1-130 | . 1971 | 224 | 10.2307/e24927692 | No. 1 January 1971 pp. 1-122 | . 1970 | 223 | 10.2307/e24927672 | No. 6 December 1970 pp. 1-140 | . 1970 | 223 | 10.2307/e24927650 | No. 5 November 1970 pp. 1-132 | . 1970 | 223 | 10.2307/e24927628 | No. 4 October 1970 pp. 1-144 | . 1970 | 223 | 10.2307/e24925887 | No. 3 September 1970 pp. 1-266 | . 1970 | 223 | 10.2307/e24925864 | No. 2 August 1970 pp. 1-128 | . 1970 | 223 | 10.2307/e24925841 | No. 1 July 1970 pp. 1-136 | . 1970 | 222 | 10.2307/e24925818 | No. 6 June 1970 pp. 1-152 | . 1970 | 222 | 10.2307/e24925793 | No. 5 May 1970 pp. 1-148 | . 1970 | 222 | 10.2307/e24925769 | No. 4 April 1970 pp. 1-130 | . 1970 | 222 | 10.2307/e24925746 | No. 3 March 1970 pp. 1-148 | . 1970 | 222 | 10.2307/e24964477 | No. 2 February 1970 pp. 1-126 | . 1970 | 222 | 10.2307/e24964435 | No. 1 January 1970 pp. 1-148 | . 1969 | 221 | 10.2307/e24964371 | No. 6 December 1969 pp. 1-152 | . 1969 | 221 | 10.2307/e24964337 | No. 5 November 1969 pp. 1-168 | . 1969 | 221 | 10.2307/e24964293 | No. 4 October 1969 pp. 1-148 | . 1969 | 221 | 10.2307/e26069602 | No. 3 September 1969 pp. 1-288 | . 1969 | 221 | 10.2307/e24926429 | No. 2 August 1969 pp. 1-136 | . 1969 | 221 | 10.2307/e24926401 | No. 1 July 1969 pp. 1-140 | . 1969 | 220 | 10.2307/e24926376 | No. 6 June 1969 pp. 1-144 | . 1969 | 220 | 10.2307/e24926350 | No. 5 May 1969 pp. 1-160 | . 1969 | 220 | 10.2307/e24926325 | No. 4 April 1969 pp. 1-146 | . 1969 | 220 | 10.2307/e24926300 | No. 3 March 1969 pp. 1-152 | . 1969 | 220 | 10.2307/e24926272 | No. 2 February 1969 pp. 1-132 | . 1969 | 220 | 10.2307/e24927601 | No. 1 January 1969 pp. 1-140 | . 1968 | 219 | 10.2307/e24927581 | No. 6 December 1968 pp. 1-144 | . 1968 | 219 | 10.2307/e24927555 | No. 5 November 1968 pp. 1-172 | . 1968 | 219 | 10.2307/e24927528 | No. 4 October 1968 pp. 1-144 | . 1968 | 219 | 10.2307/e24927497 | No. 3 September 1968 pp. 1-276 | . 1968 | 219 | 10.2307/e24927473 | No. 2 August 1968 pp. 1-124 | . 1968 | 219 | 10.2307/e24927446 | No. 1 July 1968 pp. 1-144 | . 1968 | 218 | 10.2307/e24926246 | No. 6 June 1968 pp. 1-140 | . 1968 | 218 | 10.2307/e24926220 | No. 5 May 1968 pp. 1-160 | . 1968 | 218 | 10.2307/e24926192 | No. 4 April 1968 pp. 1-146 | . 1968 | 218 | 10.2307/e24925990 | No. 3 March 1968 pp. 1-152 | . 1968 | 218 | 10.2307/e24925962 | No. 2 February 1968 pp. 1-144 | . 1968 | 218 | 10.2307/e24925932 | No. 1 January 1968 pp. 1-152 | . 1967 | 217 | 10.2307/e24925912 | No. 6 December 1967 pp. 1-160 | . 1967 | 217 | 10.2307/e24926166 | No. 5 November 1967 pp. 1-156 | . 1967 | 217 | 10.2307/e24926138 | No. 4 October 1967 pp. 1-156 | . 1967 | 217 | 10.2307/e24926106 | No. 3 September 1967 pp. 1-316 | . 1967 | 217 | 10.2307/e24926075 | No. 2 August 1967 pp. 1-128 | . 1967 | 217 | 10.2307/e24926048 | No. 1 July 1967 pp. 1-136 | . 1967 | 216 | 10.2307/e24926019 | No. 6 June 1967 pp. 1-156 | . 1967 | 216 | 10.2307/e24931488 | No. 5 May 1967 pp. 1-168 | . 1967 | 216 | 10.2307/e24931460 | No. 4 April 1967 pp. 1-148 | . 1967 | 216 | 10.2307/e24931424 | No. 3 March 1967 pp. 1-152 | . 1967 | 216 | 10.2307/e24931396 | No. 2 February 1967 pp. 1-148 | . 1967 | 216 | 10.2307/e24931366 | No. 1 January 1967 pp. 1-158 | . 1966 | 215 | 10.2307/e24931346 | No. 6 December 1966 pp. 1-156 | . 1966 | 215 | 10.2307/e24931318 | No. 5 November 1966 pp. 1-160 | . 1966 | 215 | 10.2307/e24931072 | No. 4 October 1966 pp. 1-152 | . 1966 | 215 | 10.2307/e24931041 | No. 3 September 1966 pp. 1-316 | . 1966 | 215 | 10.2307/e24931012 | No. 2 August 1966 pp. 1-116 | . 1966 | 215 | 10.2307/e24930982 | No. 1 July 1966 pp. 1-132 | . 1966 | 214 | 10.2307/e24930955 | No. 6 June 1966 pp. 1-144 | . 1966 | 214 | 10.2307/e24930927 | No. 5 May 1966 pp. 1-148 | . 1966 | 214 | 10.2307/e24930900 | No. 4 April 1966 pp. 1-140 | . 1966 | 214 | 10.2307/e24931289 | No. 3 March 1966 pp. 1-144 | . 1966 | 214 | 10.2307/e24931259 | No. 2 February 1966 pp. 1-140 | . 1966 | 214 | 10.2307/e24931227 | No. 1 January 1966 pp. 1-136 | . 1965 | 213 | 10.2307/e24931207 | No. 6 December 1965 pp. 1-128 | . 1965 | 213 | 10.2307/e24931173 | No. 5 November 1965 pp. 1-144 | . 1965 | 213 | 10.2307/e24931145 | No. 4 October 1965 pp. 1-128 | . 1965 | 213 | 10.2307/e24931104 | No. 3 September 1965 pp. 1-280 | . 1965 | 213 | 10.2307/e24931961 | No. 2 August 1965 pp. 1-120 | . 1965 | 213 | 10.2307/e24931930 | No. 1 July 1965 pp. 1-124 | . 1965 | 212 | 10.2307/e24931900 | No. 6 June 1965 pp. 1-148 | . 1965 | 212 | 10.2307/e24931867 | No. 5 May 1965 pp. 1-152 | . 1965 | 212 | 10.2307/e24931831 | No. 4 April 1965 pp. 1-160 | . 1965 | 212 | 10.2307/e24931803 | No. 3 March 1965 pp. 1-140 | . 1965 | 212 | 10.2307/e24931769 | No. 2 February 1965 pp. 1-136 | . 1965 | 212 | 10.2307/e24931739 | No. 1 January 1965 pp. 1-136 | . 1964 | 211 | 10.2307/e24931719 | No. 6 December 1964 pp. 1-156 | . 1964 | 211 | 10.2307/e24931684 | No. 5 November 1964 pp. 1-156 | . 1964 | 211 | 10.2307/e24931653 | No. 4 October 1964 pp. 1-144 | . 1964 | 211 | 10.2307/e24931618 | No. 3 September 1964 pp. 1-272 | . 1964 | 211 | 10.2307/e24931587 | No. 2 August 1964 pp. 1-116 | . 1964 | 211 | 10.2307/e24931552 | No. 1 July 1964 pp. 1-144 | . 1964 | 210 | 10.2307/e24931518 | No. 6 June 1964 pp. 1-140 | . 1964 | 210 | 10.2307/e24936106 | No. 5 May 1964 pp. 1-152 | . 1964 | 210 | 10.2307/e24936070 | No. 4 April 1964 pp. 1-156 | . 1964 | 210 | 10.2307/e24936036 | No. 3 March 1964 pp. 1-152 | . 1964 | 210 | 10.2307/e24936008 | No. 2 February 1964 pp. 1-152 | . 1964 | 210 | 10.2307/e24935977 | No. 1 January 1964 pp. 1-152 | . 1963 | 209 | 10.2307/e24935956 | No. 6 December 1963 pp. 1-180 | . 1963 | 209 | 10.2307/e24935927 | No. 5 November 1963 pp. 1-188 | . 1963 | 209 | 10.2307/e24936311 | No. 4 October 1963 pp. 1-156 | . 1963 | 209 | 10.2307/e24936277 | No. 3 September 1963 pp. 1-312 | . 1963 | 209 | 10.2307/e24936242 | No. 2 August 1963 pp. 1-140 | . 1963 | 209 | 10.2307/e24936210 | No. 1 July 1963 pp. 1-172 | . 1963 | 208 | 10.2307/e24936177 | No. 6 June 1963 pp. 1-184 | . 1963 | 208 | 10.2307/e24936141 | No. 5 May 1963 pp. 1-196 | . 1963 | 208 | 10.2307/e24936526 | No. 4 April 1963 pp. 1-204 | . 1963 | 208 | 10.2307/e24936492 | No. 3 March 1963 pp. 1-192 | . 1963 | 208 | 10.2307/e24936457 | No. 2 February 1963 pp. 1-188 | . 1963 | 208 | 10.2307/e24936420 | No. 1 January 1963 pp. 1-172 | . 1962 | 207 | 10.2307/e24936378 | No. 6 December 1962 pp. 1-192 | . 1962 | 207 | 10.2307/e24936343 | No. 5 November 1962 pp. 1-208 | . 1962 | 207 | 10.2307/e24936708 | No. 4 October 1962 pp. 1-180 | . 1962 | 207 | 10.2307/e24936660 | No. 3 September 1962 pp. 1-296 | . 1962 | 207 | 10.2307/e24936628 | No. 2 August 1962 pp. 1-152 | . 1962 | 207 | 10.2307/e24936599 | No. 1 July 1962 pp. 1-188 | . 1962 | 206 | 10.2307/e24936563 | No. 6 June 1962 pp. 1-204 | . 1962 | 206 | 10.2307/e24937311 | No. 5 May 1962 pp. 1-200 | . 1962 | 206 | 10.2307/e24937281 | No. 4 April 1962 pp. 1-196 | . 1962 | 206 | 10.2307/e24937249 | No. 3 March 1962 pp. 1-184 | . 1962 | 206 | 10.2307/e24937220 | No. 2 February 1962 pp. 1-192 | . 1962 | 206 | 10.2307/e24937188 | No. 1 January 1962 pp. 1-172 | . 1961 | 205 | 10.2307/e24937156 | No. 6 December 1961 pp. 1-196 | . 1961 | 205 | 10.2307/e24937123 | No. 5 November 1961 pp. 1-208 | . 1961 | 205 | 10.2307/e24937097 | No. 4 October 1961 pp. 1-208 | . 1961 | 205 | 10.2307/e24937061 | No. 3 September 1961 pp. 1-304 | . 1961 | 205 | 10.2307/e24937029 | No. 2 August 1961 pp. 1-172 | . 1961 | 205 | 10.2307/e24936999 | No. 1 July 1961 pp. 1-192 | . 1961 | 204 | 10.2307/e24937483 | No. 6 June 1961 pp. 1-216 | . 1961 | 204 | 10.2307/e24937452 | No. 5 May 1961 pp. 1-208 | . 1961 | 204 | 10.2307/e24937417 | No. 4 April 1961 pp. 1-208 | . 1961 | 204 | 10.2307/e24937385 | No. 3 March 1961 pp. 1-216 | . 1961 | 204 | 10.2307/e24937344 | No. 2 February 1961 pp. 1-188 | . 1961 | 204 | 10.2307/e24940734 | No. 1 January 1961 pp. 1-212 | . 1960 | 203 | 10.2307/e24940714 | No. 6 December 1960 pp. 1-208 | . 1960 | 203 | 10.2307/e24940688 | No. 5 November 1960 pp. 1-239 | . 1960 | 203 | 10.2307/e24940652 | No. 4 October 1960 pp. 1-224 | . 1960 | 203 | 10.2307/e24940610 | No. 3 September 1960 pp. 1-280 | . 1960 | 203 | 10.2307/e24940569 | No. 2 August 1960 pp. 1-196 | . 1960 | 203 | 10.2307/e24940538 | No. 1 July 1960 pp. 1-200 | . 1960 | 202 | 10.2307/e24940506 | No. 6 June 1960 pp. 1-208 | . 1960 | 202 | 10.2307/e24940472 | No. 5 May 1960 pp. 1-232 | . 1960 | 202 | 10.2307/e24940441 | No. 4 April 1960 pp. 1-223 | . 1960 | 202 | 10.2307/e24941285 | No. 3 March 1960 pp. 1-232 | . 1960 | 202 | 10.2307/e24941235 | No. 2 February 1960 pp. 1-184 | . 1960 | 202 | 10.2307/e24941219 | No. 1 January 1960 pp. 1-192 | . 1959 | 201 | 10.2307/e24941171 | No. 6 December 1959 pp. 1-212 | . 1959 | 201 | 10.2307/e24941144 | No. 5 November 1959 pp. 1-232 | . 1959 | 201 | 10.2307/e24940410 | No. 4 October 1959 pp. 1-220 | . 1959 | 201 | 10.2307/e24940380 | No. 3 September 1959 pp. 1-292 | . 1959 | 201 | 10.2307/e24940352 | No. 2 August 1959 pp. 1-172 | . 1959 | 201 | 10.2307/e24940322 | No. 1 July 1959 pp. 1-175 | . 1959 | 200 | 10.2307/e26309501 | No. 6 June, 1959 pp. 3-4, 14-204 | . 1959 | 200 | 10.2307/e24940294 | No. 5 May 1959 pp. 1-208 | . 1959 | 200 | 10.2307/e26172022 | No. 4 April, 1959 pp. 3-202 | . 1959 | 200 | 10.2307/e24944937 | No. 3 March 1959 pp. 1-188 | . 1959 | 200 | 10.2307/e24944909 | No. 2 February 1959 pp. 1-172 | . 1959 | 200 | 10.2307/e24944879 | No. 1 January 1959 pp. 1-164 | . 1958 | 199 | 10.2307/e24944841 | No. 6 December 1958 pp. 1-160 | . 1958 | 199 | 10.2307/e24944813 | No. 5 November 1958 pp. 1-167 | . 1958 | 199 | 10.2307/e24944784 | No. 4 October 1958 pp. 1-152 | . 1958 | 199 | 10.2307/e24941097 | No. 3 September 1958 pp. 1-240 | . 1958 | 199 | 10.2307/e24941072 | No. 2 August 1958 pp. 1-128 | . 1958 | 199 | 10.2307/e24941048 | No. 1 July 1958 pp. 1-128 | . 1958 | 198 | 10.2307/e24941020 | No. 6 June 1958 pp. 1-140 | . 1958 | 198 | 10.2307/e24940992 | No. 5 May 1958 pp. 1-156 | . 1958 | 198 | 10.2307/e24940953 | No. 4 April 1958 pp. 1-159 | . 1958 | 198 | 10.2307/e24940934 | No. 3 March 1958 pp. 1-164 | . 1958 | 198 | 10.2307/e24942052 | No. 2 February 1958 pp. 1-136 | . 1958 | 198 | 10.2307/e24942025 | No. 1 January 1958 pp. 1-124 | . 1957 | 197 | 10.2307/e24941988 | No. 6 December 1957 pp. 1-172 | . 1957 | 197 | 10.2307/e24941962 | No. 5 November 1957 pp. 1-184 | . 1957 | 197 | 10.2307/e24941935 | No. 4 October 1957 pp. 1-171 | . 1957 | 197 | 10.2307/e24941907 | No. 3 September 1957 pp. 1-284 | . 1957 | 197 | 10.2307/e24940899 | No. 2 August 1957 pp. 1-152 | . 1957 | 197 | 10.2307/e24940876 | No. 1 July 1957 pp. 1-180 | . 1957 | 196 | 10.2307/e24940834 | No. 6 June 1957 pp. 1-192 | . 1957 | 196 | 10.2307/e24940818 | No. 5 May 1957 pp. 1-176 | . 1957 | 196 | 10.2307/e24940789 | No. 4 April 1957 pp. 1-192 | . 1957 | 196 | 10.2307/e24940764 | No. 3 March 1957 pp. 1-187 | . 1957 | 196 | 10.2307/e24941876 | No. 2 February 1957 pp. 1-180 | . 1957 | 196 | 10.2307/e24941848 | No. 1 January 1957 pp. 1-164 | . 1956 | 195 | 10.2307/e24941828 | No. 6 December 1956 pp. 1-191 | . 1956 | 195 | 10.2307/e24941801 | No. 5 November 1956 pp. 1-180 | . 1956 | 195 | 10.2307/e24941775 | No. 4 October 1956 pp. 1-172 | . 1956 | 195 | 10.2307/e24941738 | No. 3 September 1956 pp. 1-283 | . 1956 | 195 | 10.2307/e24943930 | No. 2 August 1956 pp. 1-144 | . 1956 | 195 | 10.2307/e24943902 | No. 1 July 1956 pp. 1-148 | . 1956 | 194 | 10.2307/e24943875 | No. 6 June 1956 pp. 1-172 | . 1956 | 194 | 10.2307/e26122353 | No. 5 May 1956 pp. 1-164 | . 1956 | 194 | 10.2307/e26171965 | No. 4 April, 1956 pp. 3-170 | . 1956 | 194 | 10.2307/e24943846 | No. 3 March 1956 pp. 1-156 | . 1956 | 194 | 10.2307/e26171688 | No. 2 February, 1956 pp. 3-146 | . 1956 | 194 | 10.2307/e24943820 | No. 1 January 1956 pp. 1-132 | . 1955 | 193 | 10.2307/e24943801 | No. 6 December 1955 pp. 1-140 | . 1955 | 193 | 10.2307/e24943774 | No. 5 November 1955 pp. 1-140 | . 1955 | 193 | 10.2307/e24943748 | No. 4 October 1955 pp. 1-136 | . 1955 | 193 | 10.2307/e24944748 | No. 3 September 1955 pp. 1-212 | . 1955 | 193 | 10.2307/e24944719 | No. 2 August 1955 pp. 1-100 | . 1955 | 193 | 10.2307/e24944692 | No. 1 July 1955 pp. 1-112 | . 1955 | 192 | 10.2307/e24944662 | No. 6 June 1955 pp. 1-132 | . 1955 | 192 | 10.2307/e24944635 | No. 5 May 1955 pp. 1-128 | . 1955 | 192 | 10.2307/e24944603 | No. 4 April 1955 pp. 1-120 | . 1955 | 192 | 10.2307/e24944569 | No. 3 March 1955 pp. 1-124 | . 1955 | 192 | 10.2307/e24944542 | No. 2 February 1955 pp. 1-128 | . 1955 | 192 | 10.2307/e24943719 | No. 1 January 1955 pp. 1-104 | . 1954 | 191 | 10.2307/e24943700 | No. 6 December 1954 pp. 1-120 | . 1954 | 191 | 10.2307/e24943672 | No. 5 November 1954 pp. 1-124 | . 1954 | 191 | 10.2307/e24943645 | No. 4 October 1954 pp. 1-104 | . 1954 | 191 | 10.2307/e24943610 | No. 3 September 1954 pp. 1-192 | . 1954 | 191 | 10.2307/e24943585 | No. 2 August 1954 pp. 1-92 | . 1954 | 191 | 10.2307/e24943561 | No. 1 July 1954 pp. 1-100 | . 1954 | 190 | 10.2307/e24943534 | No. 6 June 1954 pp. 1-108 | . 1954 | 190 | 10.2307/e24943512 | No. 5 May 1954 pp. 1-104 | . 1954 | 190 | 10.2307/e24944514 | No. 4 April 1954 pp. 1-108 | . 1954 | 190 | 10.2307/e24944485 | No. 3 March 1954 pp. 1-108 | . 1954 | 190 | 10.2307/e24944459 | No. 2 February 1954 pp. 1-108 | . 1954 | 190 | 10.2307/e24944434 | No. 1 January 1954 pp. 1-96 | . 1953 | 189 | 10.2307/e24944415 | No. 6 December 1953 pp. 1-124 | . 1953 | 189 | 10.2307/e24944390 | No. 5 November 1953 pp. 1-124 | . 1953 | 189 | 10.2307/e24944363 | No. 4 October 1953 pp. 1-124 | . 1953 | 189 | 10.2307/e24944328 | No. 3 September 1953 pp. 1-172 | . 1953 | 189 | 10.2307/e24944295 | No. 2 August 1953 pp. 1-100 | . 1953 | 189 | 10.2307/e24944267 | No. 1 July 1953 pp. 1-100 | . 1953 | 188 | 10.2307/e24944243 | No. 6 June 1953 pp. 1-124 | . 1953 | 188 | 10.2307/e24944212 | No. 5 May 1953 pp. 1-112 | . 1953 | 188 | 10.2307/e24944181 | No. 4 April 1953 pp. 1-120 | . 1953 | 188 | 10.2307/e24944149 | No. 3 March 1953 pp. 1-112 | . 1953 | 188 | 10.2307/e24944122 | No. 2 February 1953 pp. 1-112 | . 1953 | 188 | 10.2307/e24944092 | No. 1 January 1953 pp. 1-88 | . 1952 | 187 | 10.2307/e24944073 | No. 6 December 1952 pp. 1-96 | . 1952 | 187 | 10.2307/e24944043 | No. 5 November 1952 pp. 1-104 | . 1952 | 187 | 10.2307/e24944016 | No. 4 October 1952 pp. 1-100 | . 1952 | 187 | 10.2307/e24950774 | No. 3 September 1952 pp. 1-96 | . 1952 | 187 | 10.2307/e24950743 | No. 2 August 1952 pp. 1-80 | . 1952 | 187 | 10.2307/e24950718 | No. 1 July 1952 pp. 1-88 | . 1952 | 186 | 10.2307/e24950701 | No. 6 June 1952 pp. 1-96 | . 1952 | 186 | 10.2307/e24950669 | No. 5 May 1952 pp. 1-92 | . 1952 | 186 | 10.2307/e24950640 | No. 4 April 1952 pp. 1-100 | . 1952 | 186 | 10.2307/e24950617 | No. 3 March 1952 pp. 1-84 | . 1952 | 186 | 10.2307/e24950585 | No. 2 February 1952 pp. 1-88 | . 1952 | 186 | 10.2307/e24950562 | No. 1 January 1952 pp. 1-84 | . 1951 | 185 | 10.2307/e24950544 | No. 6 December 1951 pp. 1-84 | . 1951 | 185 | 10.2307/e24950515 | No. 5 November 1951 pp. 1-84 | . 1951 | 185 | 10.2307/e24945281 | No. 4 October 1951 pp. 1-84 | . 1951 | 185 | 10.2307/e24945258 | No. 3 September 1951 pp. 1-124 | . 1951 | 185 | 10.2307/e24945230 | No. 2 August 1951 pp. 1-72 | . 1951 | 185 | 10.2307/e24945209 | No. 1 July 1951 pp. 1-72 | . 1951 | 184 | 10.2307/e24945185 | No. 6 June 1951 pp. 1-80 | . 1951 | 184 | 10.2307/e24945159 | No. 5 May 1951 pp. 1-80 | . 1951 | 184 | 10.2307/e24945133 | No. 4 April 1951 pp. 1-80 | . 1951 | 184 | 10.2307/e24945107 | No. 3 March 1951 pp. 1-72 | . 1951 | 184 | 10.2307/e24945076 | No. 2 February 1951 pp. 1-76 | . 1951 | 184 | 10.2307/e24945051 | No. 1 January 1951 pp. 1-64 | . 1950 | 183 | 10.2307/e24945025 | No. 6 December 1950 pp. 1-68 | . 1950 | 183 | 10.2307/e24945000 | No. 5 November 1950 pp. 1-64 | . 1950 | 183 | 10.2307/e24944983 | No. 4 October 1950 pp. 1-64 | . 1950 | 183 | 10.2307/e24944962 | No. 3 September 1950 pp. 1-120 | . 1950 | 183 | 10.2307/e24967514 | No. 2 August 1950 pp. 1-64 | . 1950 | 183 | 10.2307/e24967486 | No. 1 July 1950 pp. 1-64 | . 1950 | 182 | 10.2307/e24967466 | No. 6 June 1950 pp. 1-64 | . 1950 | 182 | 10.2307/e24967446 | No. 5 May 1950 pp. 1-64 | . 1950 | 182 | 10.2307/e24967421 | No. 4 April 1950 pp. 1-72 | . 1950 | 182 | 10.2307/e24967397 | No. 3 March 1950 pp. 1-64 | . 1950 | 182 | 10.2307/e24967370 | No. 2 February 1950 pp. 1-64 | . 1950 | 182 | 10.2307/e24967349 | No. 1 January 1950 pp. 1-64 | . 1949 | 181 | 10.2307/e24967331 | No. 6 December 1949 pp. 1-64 | . 1949 | 181 | 10.2307/e24967310 | No. 5 November 1949 pp. 1-64 | . 1949 | 181 | 10.2307/e24967289 | No. 4 October 1949 pp. 1-64 | . 1949 | 181 | 10.2307/e24967266 | No. 3 September 1949 pp. 1-64 | . 1949 | 181 | 10.2307/e24967244 | No. 2 August 1949 pp. 1-64 | . 1949 | 181 | 10.2307/e24967221 | No. 1 July 1949 pp. 1-64 | . 1949 | 180 | 10.2307/e24967201 | No. 6 June 1949 pp. 1-64 | . 1949 | 180 | 10.2307/e24967177 | No. 5 May 1949 pp. 1-64 | . 1949 | 180 | 10.2307/e24967152 | No. 4 April 1949 pp. 1-64 | . 1949 | 180 | 10.2307/e24945979 | No. 3 March 1949 pp. 1-64 | . 1949 | 180 | 10.2307/e24945959 | No. 2 February 1949 pp. 1-64 | . 1949 | 180 | 10.2307/e24945942 | No. 1 January 1949 pp. 1-64 | . 1948 | 179 | 10.2307/e24945924 | No. 6 December 1948 pp. 1-64 | . 1948 | 179 | 10.2307/e24945908 | No. 5 November 1948 pp. 1-64 | . 1948 | 179 | 10.2307/e24945892 | No. 4 October 1948 pp. 1-64 | . 1948 | 179 | 10.2307/e24945875 | No. 3 September 1948 pp. 1-64 | . 1948 | 179 | 10.2307/e24945858 | No. 2 August 1948 pp. 1-64 | . 1948 | 179 | 10.2307/e24945841 | No. 1 July 1948 pp. 1-64 | . 1948 | 178 | 10.2307/e24945824 | No. 6 June 1948 pp. 1-64 | . 1948 | 178 | 10.2307/e24945807 | No. 5 May 1948 pp. 1-64 | . 1948 | 178 | 10.2307/e24945789 | No. 4 APRIL 1948 pp. 145-192 | . 1948 | 178 | 10.2307/e24945773 | No. 3 MARCH 1948 pp. 97-144 | . 1948 | 178 | 10.2307/e24945755 | No. 2 FEBRUARY 1948 pp. 49-96 | . 1948 | 178 | 10.2307/e24945739 | No. 1 JANUARY 1948 pp. 1-48 | . 1947 | 177 | 10.2307/e24945722 | No. 6 DECEMBER 1947 pp. 241-288 | . 1947 | 177 | 10.2307/e24945704 | No. 5 NOVEMBER 1947 pp. 193-240 | . 1947 | 177 | 10.2307/e24945686 | No. 4 OCTOBER 1947 pp. 145-191 | . 1947 | 177 | 10.2307/e24945668 | No. 3 SEPTEMBER 1947 pp. 97-144 | . 1947 | 177 | 10.2307/e24960738 | No. 2 AUGUST 1947 pp. 49-96 | . 1947 | 177 | 10.2307/e24960720 | No. 1 JULY 1947 pp. 1-48 | . 1947 | 176 | 10.2307/e24960703 | No. 6 JUNE 1947 pp. 241-288 | . 1947 | 176 | 10.2307/e24960686 | No. 5 MAY 1947 pp. 193-240 | . 1947 | 176 | 10.2307/e24960667 | No. 4 APRIL 1947 pp. 145-192 | . 1947 | 176 | 10.2307/e24960650 | No. 3 MARCH 1947 pp. 97-144 | . 1947 | 176 | 10.2307/e24960633 | No. 2 FEBRUARY 1947 pp. 49-96 | . 1947 | 176 | 10.2307/e24960616 | No. 1 JANUARY 1947 pp. 1-48 | . 1946 | 175 | 10.2307/e24960599 | No. 6 DECEMBER 1946 pp. 241-288 | . 1946 | 175 | 10.2307/e24960581 | No. 5 NOVEMBER 1946 pp. 193-240 | . 1946 | 175 | 10.2307/e24960563 | No. 4 OCTOBER 1946 pp. 145-192 | . 1946 | 175 | 10.2307/e24960545 | No. 3 SEPTEMBER 1946 pp. 97-144 | . 1946 | 175 | 10.2307/e24960527 | No. 2 AUGUST 1946 pp. 49-96 | . 1946 | 175 | 10.2307/e24960509 | No. 1 JULY 1946 pp. 1-48 | . 1946 | 174 | 10.2307/e24960492 | No. 6 JUNE 1946 pp. 241-288 | . 1946 | 174 | 10.2307/e24960474 | No. 5 MAY 1946 pp. 193-240 | . 1946 | 174 | 10.2307/e24960456 | No. 4 APRIL 1946 pp. 145-192 | . 1946 | 174 | 10.2307/e24960438 | No. 3 MARCH 1946 pp. 97-144 | . 1946 | 174 | 10.2307/e24960420 | No. 2 FEBRUARY 1946 pp. 49-96 | . 1946 | 174 | 10.2307/e24960401 | No. 1 JANUARY 1946 pp. 1-48 | . 1945 | 173 | 10.2307/e24960382 | No. 6 DECEMBER · 1945 pp. 321-384 | . 1945 | 173 | 10.2307/e24960364 | No. 5 NOVEMBER · 1945 pp. 257-320 | . 1945 | 173 | 10.2307/e24997885 | No. 4 OCTOBER · 1945 pp. 193-256 | . 1945 | 173 | 10.2307/e26061673 | No. 3 SEPTEMBER · 1945 pp. 129-192 | . 1945 | 173 | 10.2307/e24997867 | No. 2 AUGUST · 1945 pp. 65-128 | . 1945 | 173 | 10.2307/e24997849 | No. 1 JULY · 1945 pp. 1-64 | . 1945 | 172 | 10.2307/e26061654 | No. 6 JUNE · 1945 pp. 321-384 | . 1945 | 172 | 10.2307/e26061620 | No. 5 MAY · 1945 pp. 257-320 | . 1945 | 172 | 10.2307/e26061602 | No. 4 APRIL · 1945 pp. 193-256 | . 1945 | 172 | 10.2307/e26061585 | No. 3 MARCH · 1945 pp. 130-192 | . 1945 | 172 | 10.2307/e26061567 | No. 2 FEBRUARY · 1945 pp. 65-128 | . 1945 | 172 | 10.2307/e26061549 | No. 1 JANUARY · 1945 pp. 1-64 | . 1944 | 171 | 10.2307/e26061533 | No. 6 DECEMBER 1944 pp. 242-288 | . 1944 | 171 | 10.2307/e26061516 | No. 5 NOVEMBER 1944 pp. 193-240 | . 1944 | 171 | 10.2307/e26061501 | No. 4 OCTOBER 1944 pp. 146-192 | . 1944 | 171 | 10.2307/e24997832 | No. 3 SEPTEMBER 1944 pp. 97-144 | . 1944 | 171 | 10.2307/e24997815 | No. 2 AUGUST 1944 pp. 49-96 | . 1944 | 171 | 10.2307/e24997798 | No. 1 JULY 1944 pp. 1-48 | . 1944 | 170 | 10.2307/e24997781 | No. 6 JUNE 1944 pp. 241-288 | . 1944 | 170 | 10.2307/e24997764 | No. 5 MAY 1944 pp. 193-240 | . 1944 | 170 | 10.2307/e24997747 | No. 4 APRIL 1944 pp. 145-192 | . 1944 | 170 | 10.2307/e24997730 | No. 3 MARCH 1944 pp. 97-144 | . 1944 | 170 | 10.2307/e24968199 | No. 2 FEBRUARY 1944 pp. 49-96 | . 1944 | 170 | 10.2307/e24968182 | No. 1 JANUARY 1944 pp. 1-48 | . 1943 | 169 | 10.2307/e24968163 | No. 6 DECEMBER 1943 pp. 241-296 | . 1943 | 169 | 10.2307/e24968146 | No. 5 NOVEMBER 1943 pp. 193-240 | . 1943 | 169 | 10.2307/e24968129 | No. 4 OCTOBER 1943 pp. 145-192 | . 1943 | 169 | 10.2307/e24968112 | No. 3 SEPTEMBER 1943 pp. 97-144 | . 1943 | 169 | 10.2307/e24968092 | No. 2 AUGUST · 1943 pp. 49-96 | . 1943 | 169 | 10.2307/e24968074 | No. 1 JULY · 1943 pp. 1-48 | . 1943 | 168 | 10.2307/e24968055 | No. 6 JUNE · 1943 pp. 241-288 | . 1943 | 168 | 10.2307/e24968036 | No. 5 MAY · 1943 pp. 193-240 | . 1943 | 168 | 10.2307/e24968016 | No. 4 APRIL · 1943 pp. 145-192 | . 1943 | 168 | 10.2307/e24967997 | No. 3 MARCH · 1943 pp. 97-144 | . 1943 | 168 | 10.2307/e24967980 | No. 2 FEBRUARY · 1943 pp. 49-96 | . 1943 | 168 | 10.2307/e24967963 | No. 1 JANUARY · 1943 pp. 1-48 | . 1942 | 167 | 10.2307/e24967940 | No. 6 DECEMBER · 1942 pp. 241-304 | . 1942 | 167 | 10.2307/e24967922 | No. 5 NOVEMBER · 1942 pp. 193-240 | . 1942 | 167 | 10.2307/e24967903 | No. 4 OCTOBER · 1942 pp. 145-192 | . 1942 | 167 | 10.2307/e24967883 | No. 3 SEPTEMBER · 1942 pp. 97-144 | . 1942 | 167 | 10.2307/e24967824 | No. 2 AUGUST · 1942 pp. 49-96 | . 1942 | 167 | 10.2307/e24967733 | No. 1 JULY · 1942 pp. 1-48 | . 1942 | 166 | 10.2307/e24967690 | No. 6 JUNE · 1942 pp. 266-312 | . 1942 | 166 | 10.2307/e24967647 | No. 5 MAY · 1942 pp. 218-264 | . 1942 | 166 | 10.2307/e24967131 | No. 4 APRIL · 1942 pp. 161-216 | . 1942 | 166 | 10.2307/e24967110 | No. 3 MARCH · 1942 pp. 114-160 | . 1942 | 166 | 10.2307/e24967087 | No. 2 FEBRUARY · 1942 pp. 49-112 | . 1942 | 166 | 10.2307/e26011078 | No. 1 JANUARY · 1942 pp. 1-48 | . 1941 | 165 | 10.2307/e24967064 | No. 6 DECEMBER · 1941 pp. 305-368 | . 1941 | 165 | 10.2307/e24967041 | No. 5 NOVEMBER · 1941 pp. 241-304 | . 1941 | 165 | 10.2307/e24967019 | No. 4 OCTOBER · 1941 pp. 177-240 | . 1941 | 165 | 10.2307/e24966993 | No. 3 SEPTEMBER · 1941 pp. 113-176 | . 1941 | 165 | 10.2307/e24966969 | No. 2 AUGUST · 1941 pp. 50-112 | . 1941 | 165 | 10.2307/e24966947 | No. 1 JULY · 1941 pp. 1-48 | . 1941 | 164 | 10.2307/e24966921 | No. 6 JUNE · 1941 pp. 322-384 | . 1941 | 164 | 10.2307/e24966897 | No. 5 MAY · 1941 pp. 257-320 | . 1941 | 164 | 10.2307/e24966875 | No. 4 APRIL · 1941 pp. 193-256 | . 1941 | 164 | 10.2307/e24966852 | No. 3 MARCH · 1941 pp. 129-191 | . 1941 | 164 | 10.2307/e24966828 | No. 2 FEBRUARY · 1941 pp. 65-128 | . 1941 | 164 | 10.2307/e24966804 | No. 1 JANUARY · 1941 pp. 1-64 | . 1940 | 163 | 10.2307/e24966781 | No. 6 DECEMBER · 1940 pp. 305-368 | . 1940 | 163 | 10.2307/e24966757 | No. 5 NOVEMBER · 1940 pp. 241-304 | . 1940 | 163 | 10.2307/e24988896 | No. 4 OCTOBER 1940 pp. 177-240 | . 1940 | 163 | 10.2307/e24988871 | No. 3 SEPTEMBER 1940 pp. 113-176 | . 1940 | 163 | 10.2307/e24988846 | No. 2 AUGUST 1940 pp. 49-112 | . 1940 | 163 | 10.2307/e24988821 | No. 1 JULY 1940 pp. 1-48 | . 1940 | 162 | 10.2307/e24988793 | No. 6 JUNE 1940 pp. 321-384 | . 1940 | 162 | 10.2307/e24988764 | No. 5 MAY 1940 pp. 257-320 | . 1940 | 162 | 10.2307/e24988738 | No. 4 APRIL 1940 pp. 193-256 | . 1940 | 162 | 10.2307/e24988710 | No. 3 MARCH 1940 pp. 129-192 | . 1940 | 162 | 10.2307/e24988683 | No. 2 FEBRUARY 1940 pp. 65-128 | . 1940 | 162 | 10.2307/e24988656 | No. 1 JANUARY 1940 pp. 1-64 | . 1939 | 161 | 10.2307/e24988630 | No. 6 DECEMBER 1939 pp. 321-384 | . 1939 | 161 | 10.2307/e24988604 | No. 5 NOVEMBER 1939 pp. 258-320 | . 1939 | 161 | 10.2307/e24988579 | No. 4 OCTOBER 1939 pp. 193-256 | . 1939 | 161 | 10.2307/e24988553 | No. 3 SEPTEMBER 1939 pp. 129-192 | . 1939 | 161 | 10.2307/e24988529 | No. 2 AUGUST 1939 pp. 65-128 | . 1939 | 161 | 10.2307/e24988505 | No. 1 JULY 1939 pp. 1-64 | . 1939 | 160 | 10.2307/e24988480 | No. 6 JUNE 1939 pp. 345-408 | . 1939 | 160 | 10.2307/e24955669 | No. 5 MAY 1939 pp. 273-344 | . 1939 | 160 | 10.2307/e24955573 | No. 4 APRIL 1939 pp. 201-272 | . 1939 | 160 | 10.2307/e24955546 | No. 3 MARCH 1939 pp. 129-200 | . 1939 | 160 | 10.2307/e24955523 | No. 2 FEBRUARY 1939 pp. 65-128 | . 1939 | 160 | 10.2307/e24955500 | No. 1 JANUARY 1939 pp. 1-64 | . 1938 | 159 | 10.2307/e24955479 | No. 6 DECEMBER 1938 pp. 281-344 | . 1938 | 159 | 10.2307/e24979592 | No. 5 NOVEMBER 1938 pp. 225-280 | . 1938 | 159 | 10.2307/e24955441 | No. 4 OCTOBER 1938 pp. 169-222 | . 1938 | 159 | 10.2307/e24955418 | No. 3 SEPTEMBER 1938 pp. 113-168 | . 1938 | 159 | 10.2307/e24955398 | No. 2 AUGUST 1938 pp. 57-112 | . 1938 | 159 | 10.2307/e24955375 | No. 1 JULY 1938 pp. 1-56 | . 1938 | 158 | 10.2307/e24955350 | No. 6 JUNE 1938 pp. 321-384 | . 1938 | 158 | 10.2307/e24955327 | No. 5 MAY 1938 pp. 257-320 | . 1938 | 158 | 10.2307/e24955304 | No. 4 April · 1938 pp. 193-256 | . 1938 | 158 | 10.2307/e24955281 | No. 3 March · 1938 pp. 129-192 | . 1938 | 158 | 10.2307/e24955259 | No. 2 February · 1938 pp. 65-128 | . 1938 | 158 | 10.2307/e24955236 | No. 1 January � 1938 pp. 1-64 | . 1937 | 157 | 10.2307/e24997509 | No. 6 December · 1937 pp. 322-384 | . 1937 | 157 | 10.2307/e24997487 | No. 5 November · 1937 pp. 257-320 | . 1937 | 157 | 10.2307/e26070903 | No. 4 October · 1937 pp. 194-255 | . 1937 | 157 | 10.2307/e24997463 | No. 3 September · 1937 pp. 129-192 | . 1937 | 157 | 10.2307/e24997443 | No. 2 August · 1937 pp. 65-128 | . 1937 | 157 | 10.2307/e24997419 | No. 1 July · 1937 pp. 1-64 | . 1937 | 156 | 10.2307/e24997395 | No. 6 June · 1937 pp. 353-423 | . 1937 | 156 | 10.2307/e24997368 | No. 5 May · 1937 pp. 281-352 | . 1937 | 156 | 10.2307/e24997344 | No. 4 April · 1937 pp. 209-280 | . 1937 | 156 | 10.2307/e24997321 | No. 3 March · 1937 pp. 145-208 | . 1937 | 156 | 10.2307/e24997296 | No. 2 February · 1937 pp. 65-144 | . 1937 | 156 | 10.2307/e24997271 | No. 1 January · 1937 pp. 1-64 | . 1936 | 155 | 10.2307/e24997248 | No. 6 December · 1936 pp. 313-376 | . 1936 | 155 | 10.2307/e24997224 | No. 5 November · 1936 pp. 249-312 | . 1936 | 155 | 10.2307/e24997202 | No. 4 October · 1936 pp. 185-248 | . 1936 | 155 | 10.2307/e24997179 | No. 3 September · 1936 pp. 121-184 | . 1936 | 155 | 10.2307/e24997156 | No. 2 August · 1936 pp. 57-120 | . 1936 | 155 | 10.2307/e26144826 | No. 1 July 1936 pp. 1-56 | . 1936 | 154 | 10.2307/e26144801 | No. 6 June 1936 pp. 297-360 | . 1936 | 154 | 10.2307/e26144777 | No. 5 May 1936 pp. 233-296 | . 1936 | 154 | 10.2307/e26144753 | No. 4 April 1936 pp. 169-232 | . 1936 | 154 | 10.2307/e26144730 | No. 3 March 1936 pp. 113-168 | . 1936 | 154 | 10.2307/e26144666 | No. 2 February 1936 pp. 57-112 | . 1936 | 154 | 10.2307/e26144364 | No. 1 January 1936 pp. 1-56 | . 1935 | 153 | 10.2307/e24999744 | No. 6 December 1935 pp. 289-344 | . 1935 | 153 | 10.2307/e24999612 | No. 5 NOVEMBER 1935 pp. 225-288 | . 1935 | 153 | 10.2307/e24999507 | No. 4 October 1935 pp. 169-224 | . 1935 | 153 | 10.2307/e24999426 | No. 3 September 1935 pp. 113-168 | . 1935 | 153 | 10.2307/e24999332 | No. 2 August 1935 pp. 57-112 | . 1935 | 153 | 10.2307/e24999217 | No. 1 July 1935 pp. 1-56 | . 1935 | 152 | 10.2307/e24999128 | No. 6 June 1935 pp. 281-336 | . 1935 | 152 | 10.2307/e24998844 | No. 5 May 1935 pp. 225-280 | . 1935 | 152 | 10.2307/e24998755 | No. 4 April 1935 pp. 169-224 | . 1935 | 152 | 10.2307/e24998672 | No. 3 March 1935 pp. 113-168 | . 1935 | 152 | 10.2307/e24998581 | No. 2 February 1935 pp. 57-112 | . 1935 | 152 | 10.2307/e24998487 | No. 1 January 1935 pp. 1-56 | . 1934 | 151 | 10.2307/e24968669 | No. 6 DECEMBER, 1934 pp. 281-335 | . 1934 | 151 | 10.2307/e24968644 | No. 5 NOVEMBER, 1934 pp. 225-280 | . 1934 | 151 | 10.2307/e24968611 | No. 4 OCTOBER, 1934 pp. 169-224 | . 1934 | 151 | 10.2307/e24968594 | No. 3 SEPTEMBER, 1934 pp. 113-168 | . 1934 | 151 | 10.2307/e24968560 | No. 2 AUGUST, 1934 pp. 57-112 | . 1934 | 151 | 10.2307/e24968545 | No. 1 JULY, 1934 pp. 1-56 | . 1934 | 150 | 10.2307/e24968522 | No. 6 JUNE, 1934 pp. 281-336 | . 1934 | 150 | 10.2307/e24968498 | No. 5 MAY, 1934 pp. 225-280 | . 1934 | 150 | 10.2307/e24968475 | No. 4 APRIL, 1934 pp. 169-224 | . 1934 | 150 | 10.2307/e24968449 | No. 3 MARCH, 1934 pp. 113-168 | . 1934 | 150 | 10.2307/e24968426 | No. 2 FEBRUARY, 1934 pp. 57-112 | . 1934 | 150 | 10.2307/e24968401 | No. 1 JANUARY, 1934 pp. 1-56 | . 1933 | 149 | 10.2307/e24968377 | No. 6 DECEMBER, 1933 pp. 249-304 | . 1933 | 149 | 10.2307/e24968353 | No. 5 NOVEMBER, 1933 pp. 193-248 | . 1933 | 149 | 10.2307/e24968331 | No. 4 October 1933 pp. 145-192 | . 1933 | 149 | 10.2307/e24968307 | No. 3 September 1933 pp. 97-144 | . 1933 | 149 | 10.2307/e24968285 | No. 2 August 1933 pp. 49-96 | . 1933 | 149 | 10.2307/e24968262 | No. 1 July 1933 pp. 1-48 | . 1933 | 148 | 10.2307/e24968238 | No. 6 June 1933 pp. 305-352 | . 1933 | 148 | 10.2307/e24968216 | No. 5 May 1933 pp. 257-304 | . 1933 | 148 | 10.2307/e24966194 | No. 4 April 1933 pp. 193-256 | . 1933 | 148 | 10.2307/e24966171 | No. 3 March 1933 pp. 129-192 | . 1933 | 148 | 10.2307/e24966146 | No. 2 February 1933 pp. 65-128 | . 1933 | 148 | 10.2307/e24966119 | No. 1 January 1933 pp. 1-64 | . 1932 | 147 | 10.2307/e24966093 | No. 6 December 1932 pp. 321-384 | . 1932 | 147 | 10.2307/e24966069 | No. 5 November 1932 pp. 257-320 | . 1932 | 147 | 10.2307/e24966042 | No. 4 OCTOBER · 1932 pp. 193-256 | . 1932 | 147 | 10.2307/e24966015 | No. 3 September 1932 pp. 129-192 | . 1932 | 147 | 10.2307/e24965989 | No. 2 August 1932 pp. 65-128 | . 1932 | 147 | 10.2307/e24965963 | No. 1 July 1932 pp. 1-64 | . 1932 | 146 | 10.2307/e24965936 | No. 6 JUNE · 1932 pp. 321-384 | . 1932 | 146 | 10.2307/e24965910 | No. 5 MAY · 1932 pp. 257-320 | . 1932 | 146 | 10.2307/e24965885 | No. 4 APRIL · 1932 pp. 193-256 | . 1932 | 146 | 10.2307/e24965860 | No. 3 MARCH · 1932 pp. 129-192 | . 1932 | 146 | 10.2307/e24965834 | No. 2 FEBRUARY · 1932 pp. 65-128 | . 1932 | 146 | 10.2307/e24965808 | No. 1 JANUARY · 1932 pp. 1-64 | . 1931 | 145 | 10.2307/e24965781 | No. 6 DECEMBER · 1931 pp. 361-432 | . 1931 | 145 | 10.2307/e24975834 | No. 5 NOVEMBER · 1931 pp. 292-360 | . 1931 | 145 | 10.2307/e24975795 | No. 4 OCTOBER · 1931 pp. 220-288 | . 1931 | 145 | 10.2307/e24975777 | No. 3 SEPTEMBER · 1931 pp. 145-216 | . 1931 | 145 | 10.2307/e24975738 | No. 2 AUGUST · 1931 pp. 73-144 | . 1931 | 145 | 10.2307/e24975721 | No. 1 July · 1931 pp. 1-72 | . 1931 | 144 | 10.2307/e24975690 | No. 6 June · 1931 pp. 361-432 | . 1931 | 144 | 10.2307/e24975664 | No. 5 May · 1931 pp. 289-360 | . 1931 | 144 | 10.2307/e24975636 | No. 4 April · 1931 pp. 217-288 | . 1931 | 144 | 10.2307/e24975577 | No. 3 March · 1931 pp. 145-216 | . 1931 | 144 | 10.2307/e24975606 | No. 2 February · 1931 pp. 73-144 | . 1931 | 144 | 10.2307/e24975525 | No. 1 January · 1931 pp. 1-72 | . 1930 | 143 | 10.2307/e24975517 | No. 6 December · 1930 pp. 419-496 | . 1930 | 143 | 10.2307/e24975487 | No. 5 NOVEMBER · 1930 pp. 337-416 | . 1930 | 143 | 10.2307/e24975449 | No. 4 October 1930 pp. 241-336 | . 1930 | 143 | 10.2307/e24975419 | No. 3 September 1930 pp. 161-240 | . 1930 | 143 | 10.2307/e24976555 | No. 2 August 1930 pp. 81-160 | . 1930 | 143 | 10.2307/e24976518 | No. 1 July 1930 pp. 1-80 | . 1930 | 142 | 10.2307/e24976481 | No. 6 June 1930 pp. 417-496 | . 1930 | 142 | 10.2307/e24976445 | No. 5 May 1930 pp. 337-416 | . 1930 | 142 | 10.2307/e24976411 | No. 4 April 1930 pp. 257-336 | . 1930 | 142 | 10.2307/e24976375 | No. 3 March 1930 pp. 177-256 | . 1930 | 142 | 10.2307/e24976343 | No. 2 February 1930 pp. 97-176 | . 1930 | 142 | 10.2307/e24976302 | No. 1 January 1930 pp. 1-96 | . 1929 | 141 | 10.2307/e24976264 | No. 6 December 1929 pp. 465-560 | . 1929 | 141 | 10.2307/e24976225 | No. 5 November 1929 pp. 369-464 | . 1929 | 141 | 10.2307/e24976190 | No. 4 October 1929 pp. 273-368 | . 1929 | 141 | 10.2307/e24976154 | No. 3 September 1929 pp. 193-272 | . 1929 | 141 | 10.2307/e24976114 | No. 2 August 1929 pp. 97-192 | . 1929 | 141 | 10.2307/e24965739 | No. 1 July 1929 pp. 1-96 | . 1929 | 140 | 10.2307/e24965699 | No. 6 June 1929 pp. 481-576 | . 1929 | 140 | 10.2307/e24965659 | No. 5 May 1929 pp. 385-480 | . 1929 | 140 | 10.2307/e24965624 | No. 4 April 1929 pp. 289-384 | . 1929 | 140 | 10.2307/e24965587 | No. 3 March 1929 pp. 193-288 | . 1929 | 140 | 10.2307/e24965549 | No. 2 February 1929 pp. 97-192 | . 1929 | 140 | 10.2307/e24965512 | No. 1 January 1929 pp. 1-96 | . 1928 | 139 | 10.2307/e24965475 | No. 6 December 1928 pp. 481-576 | . 1928 | 139 | 10.2307/e24965439 | No. 5 November 1928 pp. 385-480 | . 1928 | 139 | 10.2307/e24965402 | No. 4 October 1928 pp. 289-384 | . 1928 | 139 | 10.2307/e24965367 | No. 3 September 1928 pp. 193-288 | . 1928 | 139 | 10.2307/e24965078 | No. 2 August 1928 pp. 97-192 | . 1928 | 139 | 10.2307/e24965013 | No. 1 JULY 1928 pp. 1-96 | . 1928 | 138 | 10.2307/e24964976 | No. 6 JUNE 1928 pp. 481-576 | . 1928 | 138 | 10.2307/e24964938 | No. 5 MAY 1928 pp. 385-480 | . 1928 | 138 | 10.2307/e24964898 | No. 4 APRIL 1928 pp. 289-384 | . 1928 | 138 | 10.2307/e24964857 | No. 3 MARCH 1928 pp. 193-288 | . 1928 | 138 | 10.2307/e26121523 | No. 2 FEBRUARY 1928 pp. 97-192 | . 1928 | 138 | 10.2307/e24964815 | No. 1 JANUARY 1928 pp. 1-96 | . 1927 | 137 | 10.2307/e26121921 | No. 6 DECEMBER 1927 pp. 481-576 | . 1927 | 137 | 10.2307/e24964773 | No. 5 NOVEMBER 1927 pp. 385-480 | . 1927 | 137 | 10.2307/e26121223 | No. 4 OCTOBER 1927 pp. 289-384 | . 1927 | 137 | 10.2307/e24964728 | No. 3 SEPTEMBER 1927 pp. 193-288 | . 1927 | 137 | 10.2307/e24964684 | No. 2 AUGUST 1927 pp. 97-192 | . 1927 | 137 | 10.2307/e24964643 | No. 1 JULY 1927 pp. 1-96 | . 1927 | 136 | 10.2307/e24977327 | No. 6 JUNE 1927 pp. 369-440 | . 1927 | 136 | 10.2307/e24977108 | No. 5 MAY 1927 pp. 297-368 | . 1927 | 136 | 10.2307/e24977071 | No. 4 APRIL 1927 pp. 226-296 | . 1927 | 136 | 10.2307/e24977033 | No. 3 MARCH 1927 pp. 153-224 | . 1927 | 136 | 10.2307/e24976994 | No. 2 FEBRUARY 1927 pp. 82-152 | . 1927 | 136 | 10.2307/e24976954 | No. 1 JANUARY 1927 pp. 1-80 | . 1926 | 135 | 10.2307/e24976910 | No. 6 DECEMBER 1926 pp. 401-480 | . 1926 | 135 | 10.2307/e24976872 | No. 5 NOVEMBER 1926 pp. 321-400 | . 1926 | 135 | 10.2307/e24976832 | No. 4 OCTOBER 1926 pp. 241-320 | . 1926 | 135 | 10.2307/e24976790 | No. 3 SEPTEMBER 1926 pp. 161-240 | . 1926 | 135 | 10.2307/e24976744 | No. 2 AUGUST 1926 pp. 81-160 | . 1926 | 135 | 10.2307/e24976708 | No. 1 JULY 1926 pp. 1-80 | . 1926 | 134 | 10.2307/e24976670 | No. 6 JUNE 1926 pp. 361-432 | . 1926 | 134 | 10.2307/e24976630 | No. 5 MAY 1926 pp. 289-360 | . 1926 | 134 | 10.2307/e24976592 | No. 4 APRIL 1926 pp. 217-288 | . 1926 | 134 | 10.2307/e24979250 | No. 3 MARCH 1926 pp. 145-216 | . 1926 | 134 | 10.2307/e24979214 | No. 2 FEBRUARY 1926 pp. 73-144 | . 1926 | 134 | 10.2307/e24979176 | No. 1 JANUARY 1926 pp. 1-72 | . 1925 | 133 | 10.2307/e24979142 | No. 6 DECEMBER 1925 pp. 361-432 | . 1925 | 133 | 10.2307/e24979109 | No. 5 NOVEMBER 1925 pp. 289-360 | . 1925 | 133 | 10.2307/e24979069 | No. 4 OCTOBER 1925 pp. 217-288 | . 1925 | 133 | 10.2307/e24979032 | No. 3 SEPTEMBER 1925 pp. 145-216 | . 1925 | 133 | 10.2307/e24978991 | No. 2 AUGUST 1925 pp. 73-144 | . 1925 | 133 | 10.2307/e24978956 | No. 1 JULY 1925 pp. 1-72 | . 1925 | 132 | 10.2307/e24978928 | No. 6 JUNE 1925 pp. 361-432 | . 1925 | 132 | 10.2307/e24978896 | No. 5 MAY 1925 pp. 289-360 | . 1925 | 132 | 10.2307/e24978864 | No. 4 APRIL 1925 pp. 217-288 | . 1925 | 132 | 10.2307/e24978835 | No. 3 MARCH 1925 pp. 145-216 | . 1925 | 132 | 10.2307/e24978804 | No. 2 FEBRUARY 1925 pp. 73-144 | . 1925 | 132 | 10.2307/e24978772 | No. 1 JANUARY 1925 pp. 1-72 | . 1924 | 131 | 10.2307/e24975357 | No. 6 DECEMBER 1924 pp. 377-448 | . 1924 | 131 | 10.2307/e24975338 | No. 5 NOVEMBER 1924 pp. 297-376 | . 1924 | 131 | 10.2307/e24975266 | No. 4 OCTOBER 1924 pp. 225-296 | . 1924 | 131 | 10.2307/e24975233 | No. 3 SEPTEMBER 1924 pp. 146-218 | . 1924 | 131 | 10.2307/e24975162 | No. 2 AUGUST 1924 pp. 73-144 | . 1924 | 131 | 10.2307/e24975108 | No. 1 JULY 1924 pp. 1-72 | . 1924 | 130 | 10.2307/e24975031 | No. 6 JUNE 1924 pp. 369-440 | . 1924 | 130 | 10.2307/e24974999 | No. 5 MAY 1924 pp. 297-368 | . 1924 | 130 | 10.2307/e24921328 | No. 4 APRIL 1924 pp. 217-296 | . 1924 | 130 | 10.2307/e24974907 | No. 3 MARCH 1924 pp. 145-216 | . 1924 | 130 | 10.2307/e24974885 | No. 2 FEBRUARY 1924 pp. 73-144 | . 1924 | 130 | 10.2307/e24974843 | No. 1 JANUARY 1924 pp. 1-72 | . 1923 | 129 | 10.2307/e24974786 | No. 6 DECEMBER 1923 pp. 377-448 | . 1923 | 129 | 10.2307/e24974694 | No. 5 NOVEMBER 1923 pp. 297-376 | . 1923 | 129 | 10.2307/e24974658 | No. 4 OCTOBER 1923 pp. 217-296 | . 1923 | 129 | 10.2307/e24994795 | No. 3 SEPTEMBER 1923 pp. 145-216 | . 1923 | 129 | 10.2307/e24994720 | No. 2 AUGUST 1923 pp. 73-144 | . 1923 | 129 | 10.2307/e24994653 | No. 1 JULY 1923 pp. 1-72 | . 1923 | 128 | 10.2307/e24994585 | No. 6 JUNE 1923 pp. 361-432 | . 1923 | 128 | 10.2307/e24994523 | No. 5 MAY 1923 pp. 290-360 | . 1923 | 128 | 10.2307/e24994450 | No. 4 APRIL 1923 pp. 217-288 | . 1923 | 128 | 10.2307/e24994381 | No. 3 MARCH 1923 pp. 145-216 | . 1923 | 128 | 10.2307/e24994303 | No. 2 FEBRUARY 1923 pp. 73-144 | . 1923 | 128 | 10.2307/e24994223 | No. 1 JANUARY 1923 pp. 1-72 | . 1922 | 127 | 10.2307/e24994142 | No. 6 DECEMBER 1922 pp. 369-448 | . 1922 | 127 | 10.2307/e26070838 | No. 5 NOVEMBER 1922 pp. 293-368 | . 1922 | 127 | 10.2307/e24994068 | No. 4 OCTOBER 1922 pp. 217-288 | . 1922 | 127 | 10.2307/e24993994 | No. 3 SEPTEMBER 1922 pp. 145-216 | . 1922 | 127 | 10.2307/e24993903 | No. 2 AUGUST 1922 pp. 73-144 | . 1922 | 127 | 10.2307/e24993801 | No. 1 JULY 1922 pp. 1-72 | . 1922 | 126 | 10.2307/e24996281 | No. 6 JUNE 1922 pp. 365-436 | . 1922 | 126 | 10.2307/e24996159 | No. 5 MAY 1922 pp. 293-364 | . 1922 | 126 | 10.2307/e24996365 | No. 4 APRIL 1922 pp. 221-292 | . 1922 | 126 | 10.2307/e24996497 | No. 3 MARCH 1922 pp. 153-220 | . 1922 | 126 | 10.2307/e24992241 | No. 2 FEBRUARY 1922 pp. 81-152 | . 1922 | 126 | 10.2307/e24980322 | No. 1 JANUARY 1922 pp. 1-80 | . 1921 | 125 | 10.2307/e24980687 | No. 18 December, 1921 pp. 81-160 | . 1921 | 125 | 10.2307/e24980076 | No. 17 November, 1921 pp. 1-80 | . 1921 | 125 | 10.2307/e24980663 | No. 16 OCTOBER 15, 1921 pp. 265-280 | . 1921 | 125 | 10.2307/e24980476 | No. 15 October 8, 1921 pp. 249-264 | . 1921 | 125 | 10.2307/e24979988 | No. 14 OCTOBER 1, 1921 pp. 229-248 | . 1921 | 125 | 10.2307/e24979817 | No. 13 September 24, 1921 pp. 213-228 | . 1921 | 125 | 10.2307/e24980321 | No. 12 SEPTEMBER 17, 1921 pp. 193-212 | . 1921 | 125 | 10.2307/e24980288 | No. 11 SEPTEMBER 10, 1921 pp. 177-192 | . 1921 | 125 | 10.2307/e24979901 | No. 10 SEPTEMBER 3, 1921 pp. 157-176 | . 1921 | 125 | 10.2307/e24980165 | No. 9 August 27, 1921 pp. 141-156 | . 1921 | 125 | 10.2307/e24979734 | No. 8 AUGUST 20, 1921 pp. 125-140 | . 1921 | 125 | 10.2307/e24980037 | No. 7 AUGUST 13, 1921 pp. 109-124 | . 1921 | 125 | 10.2307/e24980419 | No. 6 AUGUST 6, 1921 pp. 89-108 | . 1921 | 125 | 10.2307/e24980190 | No. 5 JULY 30, 1921 pp. 73-88 | . 1921 | 125 | 10.2307/e24979991 | No. 4 JULY 23, 1921 pp. 57-72 | . 1921 | 125 | 10.2307/e24980061 | No. 3 JULY 16, 1921 pp. 37-56 | . 1921 | 125 | 10.2307/e24979682 | No. 2 JULY 9, 1921 pp. 17-36 | . 1921 | 125 | 10.2307/e24979614 | No. 1 JULY 2, 1921 pp. 1-16 | . 1921 | 124 | 10.2307/e26122915 | No. 26 June 25, 1921 pp. 501-524 | . 1921 | 124 | 10.2307/e24979712 | No. 25 June 18, 1921 pp. 481-500 | . 1921 | 124 | 10.2307/e24980581 | No. 24 June 11, 1921 pp. 461-480 | . 1921 | 124 | 10.2307/e24979895 | No. 23 June 4, 1921 pp. 441-460 | . 1921 | 124 | 10.2307/e24979735 | No. 22 May 28, 1921 pp. 421-440 | . 1921 | 124 | 10.2307/e24979789 | No. 21 May 21, 1921 pp. 401-420 | . 1921 | 124 | 10.2307/e24979951 | No. 20 May 14, 1921 pp. 381-400 | . 1921 | 124 | 10.2307/e24979674 | No. 19 May 7, 1921 pp. 361-380 | . 1921 | 124 | 10.2307/e24979888 | No. 18 April 30, 1921 pp. 341-360 | . 1921 | 124 | 10.2307/e24979640 | No. 17 April 23, 1921 pp. 321-340 | . 1921 | 124 | 10.2307/e24996454 | No. 16 April 16, 1921 pp. 301-320 | . 1921 | 124 | 10.2307/e24979803 | No. 15 April 9, 1921 pp. 281-300 | . 1921 | 124 | 10.2307/e24980349 | No. 14 April 2, 1921 pp. 261-280 | . 1921 | 124 | 10.2307/e24990093 | No. 13 March 26, 1921 pp. 241-260 | . 1921 | 124 | 10.2307/e24991124 | No. 12 March 19, 1921 pp. 221-240 | . 1921 | 124 | 10.2307/e24992013 | No. 11 March 12, 1921 pp. 201-220 | . 1921 | 124 | 10.2307/e24990559 | No. 10 March 5, 1921 pp. 181-200 | . 1921 | 124 | 10.2307/e24990343 | No. 9 February 26, 1921 pp. 161-180 | . 1921 | 124 | 10.2307/e24989863 | No. 8 February 19, 1921 pp. 141-160 | . 1921 | 124 | 10.2307/e24991376 | No. 7 February 12, 1921 pp. 121-140 | . 1921 | 124 | 10.2307/e24991070 | No. 6 February 5, 1921 pp. 101-120 | . 1921 | 124 | 10.2307/e24989590 | No. 5 January 29, 1921 pp. 81-100 | . 1921 | 124 | 10.2307/e24991850 | No. 4 January 22, 1921 pp. 61-80 | . 1921 | 124 | 10.2307/e24991315 | No. 3 January 15, 1921 pp. 41-60 | . 1921 | 124 | 10.2307/e24990605 | No. 2 JANUARY 8, 1921 pp. 21-40 | . 1921 | 124 | 10.2307/e24989797 | No. 1 January 1, 1921 pp. 1-20 | . 1920 | 123 | 10.2307/e24990895 | No. 26 DECEMBER 25, 1920 pp. 625-644 | . 1920 | 123 | 10.2307/e24991851 | No. 25 DECEMBER 18, 1920 pp. 605-624 | . 1920 | 123 | 10.2307/e24990342 | No. 24 December 11, 1920 pp. 585-604 | . 1920 | 123 | 10.2307/e24991439 | No. 23 DECEMBER 4, 1920 pp. 561-584 | . 1920 | 123 | 10.2307/e24992201 | No. 22 NOVEMBER 27, 1920 pp. 537-560 | . 1920 | 123 | 10.2307/e24991193 | No. 21 NOVEMBER 20, 1920 pp. 513-536 | . 1920 | 123 | 10.2307/e24991982 | No. 20 NOVEMBER 13, 1920 pp. 489-512 | . 1920 | 123 | 10.2307/e24991712 | No. 19 NOVEMBER 6, 1920 pp. 461-488 | . 1920 | 123 | 10.2307/e24991787 | No. 18 OCTOBER 30, 1920 pp. 441-460 | . 1920 | 123 | 10.2307/e24990227 | No. 17 OCTOBER 23, 1920 pp. 417-440 | . 1920 | 123 | 10.2307/e24991243 | No. 16 OCTOBER 16, 1920 pp. 393-416 | . 1920 | 123 | 10.2307/e24992054 | No. 15 OCTOBER 9, 1920 pp. 369-392 | . 1920 | 123 | 10.2307/e24990686 | No. 14 OCTOBER 2, 1920 pp. 317-368 | . 1920 | 123 | 10.2307/e24991636 | No. 13 SEPTEMBER 25, 1920 pp. 293-316 | . 1920 | 123 | 10.2307/e24990021 | No. 12 SEPTEMBER 18, 1920 pp. 269-292 | . 1920 | 123 | 10.2307/e24992167 | No. 11 SEPTEMBER 11, 1920 pp. 241-268 | . 1920 | 123 | 10.2307/e24990830 | No. 10 SEPTEMBER 4, 1920 pp. 215-240 | . 1920 | 123 | 10.2307/e24991944 | No. 9 AUGUST 28, 1920 pp. 195-212 | . 1920 | 123 | 10.2307/e24990481 | No. 8 AUGUST 21, 1920 pp. 171-194 | . 1920 | 123 | 10.2307/e24991502 | No. 7 AUGUST 14, 1920 pp. 147-170 | . 1920 | 123 | 10.2307/e24989661 | No. 6 AUGUST 7, 1920 pp. 119-146 | . 1920 | 123 | 10.2307/e24989730 | No. 5 JULY 31, 1920 pp. 99-118 | . 1920 | 123 | 10.2307/e24991008 | No. 4 JULY 24, 1920 pp. 79-98 | . 1920 | 123 | 10.2307/e24991898 | No. 3 JULY 17, 1920 pp. 55-78 | . 1920 | 123 | 10.2307/e24990413 | No. 2 JULY 10, 1920 pp. 31-54 | . 1920 | 123 | 10.2307/e24989935 | No. 1 JULY 3, 1920 pp. 1-30 | . 1920 | 122 | 10.2307/e24991069 | No. 26 June 26, 1920 pp. 693-720 | . 1920 | 122 | 10.2307/e24992128 | No. 25 June 19, 1920 pp. 665-692 | . 1920 | 122 | 10.2307/e24990746 | No. 24 June 12, 1920 pp. 637-664 | . 1920 | 122 | 10.2307/e24990159 | No. 23 June 5, 1920 pp. 613-636 | . 1920 | 122 | 10.2307/e24991578 | No. 22 May 29, 1920 pp. 589-612 | . 1920 | 122 | 10.2307/e26122482 | No. 21 May 22, 1920 pp. 561-588 | . 1920 | 122 | 10.2307/e24990938 | No. 20 May 15, 1920 pp. 533-560 | . 1920 | 122 | 10.2307/e24990292 | No. 19 May 8, 1920 pp. 505-532 | . 1920 | 122 | 10.2307/e24992092 | No. 18 May 1, 1920 pp. 477-504 | . 1920 | 122 | 10.2307/e24989587 | No. 17 April 24, 1920 pp. 445-476 | . 1920 | 122 | 10.2307/e24991332 | No. 16 April 17, 1920 pp. 413-444 | . 1920 | 122 | 10.2307/e24990913 | No. 15 April 10, 1920 pp. 381-412 | . 1920 | 122 | 10.2307/e24990311 | No. 14 April 3, 1920 pp. 353-380 | . 1920 | 122 | 10.2307/e24989769 | No. 13 March 27, 1920 pp. 325-352 | . 1920 | 122 | 10.2307/e26123552 | No. 12 March 20, 1920 pp. 293-324 | . 1920 | 122 | 10.2307/e24990572 | No. 11 March 13, 1920 pp. 265-292 | . 1920 | 122 | 10.2307/e24991410 | No. 10 March 6, 1920 pp. 237-264 | . 1920 | 122 | 10.2307/e24990147 | No. 9 February 28, 1920 pp. 209-236 | . 1920 | 122 | 10.2307/e24990980 | No. 8 February 21, 1920 pp. 177-208 | . 1920 | 122 | 10.2307/e24991870 | No. 7 February 14, 1920 pp. 153-176 | . 1920 | 122 | 10.2307/e26121304 | No. 6 February 7, 1920 pp. 125-152 | . 1920 | 122 | 10.2307/e24990773 | No. 5 January 31, 1920 pp. 105-124 | . 1920 | 122 | 10.2307/e24991579 | No. 4 January 24, 1920 pp. 81-104 | . 1920 | 122 | 10.2307/e24991207 | No. 3 January 17, 1920 pp. 53-80 | . 1920 | 122 | 10.2307/e26124375 | No. 2 January 10, 1920 pp. 29-54 | . 1920 | 122 | 10.2307/e24991277 | No. 1 January 3, 1920 pp. 1-28 | . 1919 | 121 | 10.2307/e24990036 | No. 26 Decmeber 27, 1919 pp. 627-654 | . 1919 | 121 | 10.2307/e24990850 | No. 25 December 20, 1919 pp. 599-626 | . 1919 | 121 | 10.2307/e24991635 | No. 24 December 13, 1919 pp. 571-598 | . 1919 | 121 | 10.2307/e24990387 | No. 23 December 6, 1919 pp. 547-570 | . 1919 | 121 | 10.2307/e24991187 | No. 22 November 29, 1919 pp. 527-546 | . 1919 | 121 | 10.2307/e24989894 | No. 21 November 22, 1919 pp. 503-526 | . 1919 | 121 | 10.2307/e24991820 | No. 20 November 15, 1919 pp. 475-502 | . 1919 | 121 | 10.2307/e24990515 | No. 19 November 8, 1919 pp. 453-472 | . 1919 | 121 | 10.2307/e24991532 | No. 18 November 1, 1919 pp. 437-452 | . 1919 | 121 | 10.2307/e24990266 | No. 17 October 25, 1919 pp. 413-436 | . 1919 | 121 | 10.2307/e24991062 | No. 16 October 18, 1919 pp. 381-412 | . 1919 | 121 | 10.2307/e24989634 | No. 14 October 4, 1919 pp. 333-356 | . 1919 | 121 | 10.2307/e24989689 | No. 13 September 27, 1919 pp. 301-332 | . 1919 | 121 | 10.2307/e24990694 | No. 12 September 20, 1919 pp. 273-300 | . 1919 | 121 | 10.2307/e24991473 | No. 11 September 13, 1919 pp. 245-272 | . 1919 | 121 | 10.2307/e24990218 | No. 10 September 6, 1919 pp. 221-244 | . 1919 | 121 | 10.2307/e24989842 | No. 9 August 30, 1919 pp. 197-220 | . 1919 | 121 | 10.2307/e24990726 | No. 8 August 23, 1919 pp. 177-196 | . 1919 | 121 | 10.2307/e24991770 | No. 7 August 16, 1919 pp. 149-176 | . 1919 | 121 | 10.2307/e24990446 | No. 6 August 9, 1919 pp. 125-148 | . 1919 | 121 | 10.2307/e24989957 | No. 5 August 2, 1919 pp. 101-124 | . 1919 | 121 | 10.2307/e24991121 | No. 4 July 26, 1919 pp. 77-100 | . 1919 | 121 | 10.2307/e24990631 | No. 3 July 19, 1919 pp. 49-76 | . 1919 | 121 | 10.2307/e24990104 | No. 2 July 12, 1919 pp. 25-48 | . 1919 | 121 | 10.2307/e24991688 | No. 1 July 5, 1919 pp. 1-24 | . 1919 | 120 | 10.2307/e26039662 | No. 26 June 28, 1919 pp. 677-704 | . 1919 | 120 | 10.2307/e26039621 | No. 25 June 21, 1919 pp. 645-676 | . 1919 | 120 | 10.2307/e26039582 | No. 24 June 14, 1919 pp. 617-644 | . 1919 | 120 | 10.2307/e26039556 | No. 23 June 7, 1919 pp. 593-616 | . 1919 | 120 | 10.2307/e26039522 | No. 22 May 31, 1919 pp. 565-592 | . 1919 | 120 | 10.2307/e26039485 | No. 21 May 24, 1919 pp. 533-564 | . 1919 | 120 | 10.2307/e26039450 | No. 20 May 17, 1919 pp. 501-532 | . 1919 | 120 | 10.2307/e26039419 | No. 19 May 10, 1919 pp. 477-500 | . 1919 | 120 | 10.2307/e26039389 | No. 18 May 3, 1919 pp. 449-476 | . 1919 | 120 | 10.2307/e26039362 | No. 17 April 26, 1919 pp. 421-448 | . 1919 | 120 | 10.2307/e26039334 | No. 16 April 19, 1919 pp. 389-420 | . 1919 | 120 | 10.2307/e26039305 | No. 15 April 12, 1919 pp. 361-388 | . 1919 | 120 | 10.2307/e26039268 | No. 14 April 5, 1919 pp. 329-360 | . 1919 | 120 | 10.2307/e26039236 | No. 13 March 29, 1919 pp. 309-328 | . 1919 | 120 | 10.2307/e26039207 | No. 12 March 22, 1919 pp. 277-308 | . 1919 | 120 | 10.2307/e26039171 | No. 11 March 15, 1919 pp. 245-276 | . 1919 | 120 | 10.2307/e26039138 | No. 10 March 8, 1919 pp. 217-244 | . 1919 | 120 | 10.2307/e26123980 | No. 9 March 1, 1919 pp. 193-216 | . 1919 | 120 | 10.2307/e26121850 | No. 8 February 22, 1919 pp. 161-192 | . 1919 | 120 | 10.2307/e26038580 | No. 7 February 15, 1919 pp. 133-160 | . 1919 | 120 | 10.2307/e26038546 | No. 6 February 8, 1919 pp. 109-132 | . 1919 | 120 | 10.2307/e26122347 | No. 5 February 1, 1919 pp. 89-108 | . 1919 | 120 | 10.2307/e26038491 | No. 4 January 25, 1919 pp. 65-88 | . 1919 | 120 | 10.2307/e26038464 | No. 3 January 18, 1919 pp. 45-64 | . 1919 | 120 | 10.2307/e26038428 | No. 2 January 11, 1919 pp. 21-44 | . 1919 | 120 | 10.2307/e26038290 | No. 1 JANUARY 4, 1919 pp. 3-19 | . 1918 | 119 | 10.2307/e26038098 | No. 26 December 28, 1918 pp. 509-540 | . 1918 | 119 | 10.2307/e26037981 | No. 25 December 21, 1918 pp. 489-508 | . 1918 | 119 | 10.2307/e26037821 | No. 24 December 14, 1918 pp. 469-488 | . 1918 | 119 | 10.2307/e26037782 | No. 23 December 7, 1918 pp. 449-468 | . 1918 | 119 | 10.2307/e26037616 | No. 22 November 30, 1918 pp. 429-448 | . 1918 | 119 | 10.2307/e26037471 | No. 21 November 23, 1918 pp. 405-428 | . 1918 | 119 | 10.2307/e26037342 | No. 20 November 16, 1918 pp. 385-404 | . 1918 | 119 | 10.2307/e26037269 | No. 19 November 9, 1918 pp. 369-384 | . 1918 | 119 | 10.2307/e26037130 | No. 18 November 2, 1918 pp. 349-368 | . 1918 | 119 | 10.2307/e26037025 | No. 17 October 26, 1918 pp. 329-348 | . 1918 | 119 | 10.2307/e26036881 | No. 16 October 19, 1918 pp. 305-328 | . 1918 | 119 | 10.2307/e26036807 | No. 15 October 12, 1918 pp. 285-304 | . 1918 | 119 | 10.2307/e26036712 | No. 14 October 5, 1918 pp. 265-284 | . 1918 | 119 | 10.2307/e26036598 | No. 13 September 28, 1918 pp. 245-264 | . 1918 | 119 | 10.2307/e26036557 | No. 12 September 21, 1918 pp. 221-244 | . 1918 | 119 | 10.2307/e26036429 | No. 11 September 14, 1918 pp. 205-220 | . 1918 | 119 | 10.2307/e26036341 | No. 10 September 7, 1918 pp. 181-204 | . 1918 | 119 | 10.2307/e26033291 | No. 9 August 31, 1918 pp. 161-180 | . 1918 | 119 | 10.2307/e26033212 | No. 8 August 24, 1918 pp. 145-160 | . 1918 | 119 | 10.2307/e26033091 | No. 7 August 17, 1918 pp. 117-144 | . 1918 | 119 | 10.2307/e26033021 | No. 6 August 10, 1918 pp. 101-116 | . 1918 | 119 | 10.2307/e26032920 | No. 5 August 3, 1918 pp. 81-100 | . 1918 | 119 | 10.2307/e26032876 | No. 4 July 27, 1918 pp. 61-80 | . 1918 | 119 | 10.2307/e26032760 | No. 3 July 20, 1918 pp. 41-60 | . 1918 | 119 | 10.2307/e26032721 | No. 2 July 13, 1918 pp. 25-40 | . 1918 | 119 | 10.2307/e26032593 | No. 1 July 6, 1918 pp. 1-24 | . 1918 | 118 | 10.2307/e26032451 | No. 26 JUNE 29, 1918 pp. 581-600 | . 1918 | 118 | 10.2307/e26032404 | No. 25 June 22, 1918 pp. 561-580 | . 1918 | 118 | 10.2307/e26032280 | No. 24 June 15, 1918 pp. 541-560 | . 1918 | 118 | 10.2307/e26032225 | No. 23 June 8, 1918 pp. 517-540 | . 1918 | 118 | 10.2307/e26032120 | No. 22 June 1, 1918 pp. 493-516 | . 1918 | 118 | 10.2307/e26031989 | No. 21 May 25, 1918 pp. 473-492 | . 1918 | 118 | 10.2307/e26031905 | No. 20 May 18, 1918 pp. 445-472 | . 1918 | 118 | 10.2307/e26031808 | No. 19 May 11, 1918 pp. 425-444 | . 1918 | 118 | 10.2307/e26031653 | No. 18 May 4, 1918 pp. 401-424 | . 1918 | 118 | 10.2307/e26031514 | No. 17 April 27, 1918 pp. 373-400 | . 1918 | 118 | 10.2307/e26031465 | No. 16 April 20, 1918 pp. 353-372 | . 1918 | 118 | 10.2307/e26031345 | No. 15 April 13, 1918 pp. 337-352 | . 1918 | 118 | 10.2307/e26031203 | No. 14 April 6, 1918 pp. 289-336 | . 1918 | 118 | 10.2307/e26024935 | No. 13 March 30, 1918 pp. 269-288 | . 1918 | 118 | 10.2307/e26024800 | No. 12 March 23, 1918 pp. 249-268 | . 1918 | 118 | 10.2307/e26024682 | No. 11 March 16, 1918 pp. 225-248 | . 1918 | 118 | 10.2307/e26024586 | No. 10 March 9, 1918 pp. 205-224 | . 1918 | 118 | 10.2307/e26024466 | No. 9 March 2, 1918 pp. 181-204 | . 1918 | 118 | 10.2307/e26024323 | No. 8 February 23, 1918 pp. 161-180 | . 1918 | 118 | 10.2307/e26024241 | No. 7 February 16, 1918 pp. 141-160 | . 1918 | 118 | 10.2307/e26024174 | No. 6 February 9, 1918 pp. 125-140 | . 1918 | 118 | 10.2307/e26024040 | No. 5 FEBRUARY 2, 1918 pp. 99-124 | . 1918 | 118 | 10.2307/e26024004 | No. 4 January 26, 1918 pp. 81-96 | . 1918 | 118 | 10.2307/e26023884 | No. 3 January 19, 1918 pp. 65-80 | . 1918 | 118 | 10.2307/e26023824 | No. 2 January 12, 1918 pp. 49-64 | . 1918 | 118 | 10.2307/e26023735 | No. 1 January 5, 1918 pp. 1-48 | . 1917 | 117 | 10.2307/e26023571 | No. 26 December 29, 1917 pp. 489-504 | . 1917 | 117 | 10.2307/e26023502 | No. 25 December 22, 1917 pp. 469-488 | . 1917 | 117 | 10.2307/e26023318 | No. 24 December 15, 1917 pp. 449-468 | . 1917 | 117 | 10.2307/e26023218 | No. 23 December 8, 1917 pp. 433-448 | . 1917 | 117 | 10.2307/e26023085 | No. 22 December 1, 1917 pp. 397-432 | . 1917 | 117 | 10.2307/e26022941 | No. 21 November 24, 1917 pp. 377-396 | . 1917 | 117 | 10.2307/e26022842 | No. 20 November 17, 1917 pp. 357-376 | . 1917 | 117 | 10.2307/e26022721 | No. 19 November 10, 1917 pp. 341-356 | . 1917 | 117 | 10.2307/e26022614 | No. 18 November 3, 1917 pp. 321-340 | . 1917 | 117 | 10.2307/e26022513 | No. 17 October 27, 1917 pp. 305-320 | . 1917 | 117 | 10.2307/e26022449 | No. 16 October 20, 1917 pp. 281-304 | . 1917 | 117 | 10.2307/e26021967 | No. 15 October 13, 1917 pp. 265-280 | . 1917 | 117 | 10.2307/e26021937 | No. 14 October 6, 1917 pp. 237-264 | . 1917 | 117 | 10.2307/e26021898 | No. 13 September 29, 1917 pp. 221-236 | . 1917 | 117 | 10.2307/e26021863 | No. 12 September 22, 1917 pp. 201-220 | . 1917 | 117 | 10.2307/e26021833 | No. 11 September 15, 1917 pp. 185-200 | . 1917 | 117 | 10.2307/e26121476 | No. 10 September 8, 1917 pp. 169-184 | . 1917 | 117 | 10.2307/e26021792 | No. 9 September 1, 1917 pp. 149-168 | . 1917 | 117 | 10.2307/e26021760 | No. 8 August 25, 1917 pp. 129-148 | . 1917 | 117 | 10.2307/e26021717 | No. 7 August 18, 1917 pp. 109-128 | . 1917 | 117 | 10.2307/e26021641 | No. 6 August 11, 1917 pp. 93-108 | . 1917 | 117 | 10.2307/e26123318 | No. 5 August 4, 1917 pp. 69-92 | . 1917 | 117 | 10.2307/e26021611 | No. 4 July 28, 1917 pp. 53-68 | . 1917 | 117 | 10.2307/e26021580 | No. 3 July 21, 1917 pp. 37-52 | . 1917 | 117 | 10.2307/e26021549 | No. 2 July 14, 1917 pp. 21-36 | . 1917 | 117 | 10.2307/e26121607 | No. 1 JULY 7, 1917 pp. 1-20 | . 1917 | 116 | 10.2307/e26124574 | No. 26 June 30, 1917 pp. 637-656 | . 1917 | 116 | 10.2307/e26021509 | No. 25 June 23, 1917 pp. 613-632 | . 1917 | 116 | 10.2307/e26021477 | No. 24 June 16, 1917 pp. 589-608 | . 1917 | 116 | 10.2307/e26021448 | No. 23 June 9, 1917 pp. 569-584 | . 1917 | 116 | 10.2307/e26021412 | No. 22 JUNE 2, 1917 pp. 539-566 | . 1917 | 116 | 10.2307/e26021384 | No. 21 May 26, 1917 pp. 517-536 | . 1917 | 116 | 10.2307/e26021345 | No. 20 May 19, 1917 pp. 481-512 | . 1917 | 116 | 10.2307/e26021313 | No. 19 May 12, 1917 pp. 463-478 | . 1917 | 116 | 10.2307/e26021275 | No. 18 May 5, 1917 pp. 433-460 | . 1917 | 116 | 10.2307/e26021175 | No. 17 April 28, 1917 pp. 415-430 | . 1917 | 116 | 10.2307/e26021079 | No. 16 April 21, 1917 pp. 385-412 | . 1917 | 116 | 10.2307/e26020884 | No. 15 April 14, 1917 pp. 367-382 | . 1917 | 116 | 10.2307/e26020770 | No. 14 April 7, 1917 pp. 337-364 | . 1917 | 116 | 10.2307/e26017764 | No. 13 March 31, 1917 pp. 319-334 | . 1917 | 116 | 10.2307/e26017725 | No. 12 March 24, 1917 pp. 299-314 | . 1917 | 116 | 10.2307/e26017698 | No. 11 March 17, 1917 pp. 275-294 | . 1917 | 116 | 10.2307/e26017667 | No. 10 March 10, 1917 pp. 255-270 | . 1917 | 116 | 10.2307/e26017633 | No. 9 March 3, 1917 pp. 213-252 | . 1917 | 116 | 10.2307/e26017552 | No. 8 February 24, 1917 pp. 195-210 | . 1917 | 116 | 10.2307/e26017453 | No. 7 February 17, 1917 pp. 167-190 | . 1917 | 116 | 10.2307/e26017351 | No. 6 February 10, 1917 pp. 147-162 | . 1917 | 116 | 10.2307/e26017246 | No. 5 February 3, 1917 pp. 113-143 | . 1917 | 116 | 10.2307/e26017079 | No. 4 January 27, 1917 pp. 95-110 | . 1917 | 116 | 10.2307/e26017024 | No. 3 January 20, 1917 pp. 75-90 | . 1917 | 116 | 10.2307/e26016933 | No. 2 January 13, 1917 pp. 55-70 | . 1917 | 116 | 10.2307/e26016826 | No. 1 January 6, 1917 pp. 1-52 | . 1916 | 115 | 10.2307/e26016756 | No. 27 December 30, 1916 pp. 587-602 | . 1916 | 115 | 10.2307/e26016726 | No. 26 December 23, 1916 pp. 567-582 | . 1916 | 115 | 10.2307/e26016663 | No. 25 December 16, 1916 pp. 543-562 | . 1916 | 115 | 10.2307/e26016598 | No. 24 December 9, 1916 pp. 523-538 | . 1916 | 115 | 10.2307/e26016564 | No. 23 December 2, 1916 pp. 489-520 | . 1916 | 115 | 10.2307/e26016503 | No. 22 November 25, 1916 pp. 471-486 | . 1916 | 115 | 10.2307/e26016446 | No. 21 November 18, 1916 pp. 451-466 | . 1916 | 115 | 10.2307/e26016411 | No. 20 November 11, 1916 pp. 431-446 | . 1916 | 115 | 10.2307/e26016325 | No. 19 November 4, 1916 pp. 401-428 | . 1916 | 115 | 10.2307/e26016259 | No. 18 October 28, 1916 pp. 383-398 | . 1916 | 115 | 10.2307/e26016223 | No. 17 October 21, 1916 pp. 363-378 | . 1916 | 115 | 10.2307/e26015142 | No. 16 October 14, 1916 pp. 345-358 | . 1916 | 115 | 10.2307/e26015093 | No. 15 October 7, 1916 pp. 313-344 | . 1916 | 115 | 10.2307/e26123815 | No. 14 September 30, 1916 pp. 295-310 | . 1916 | 115 | 10.2307/e26015060 | No. 13 September 23, 1916 pp. 275-290 | . 1916 | 115 | 10.2307/e26015021 | No. 12 September 16, 1916 pp. 255-270 | . 1916 | 115 | 10.2307/e26014987 | No. 11 September 9, 1916 pp. 235-250 | . 1916 | 115 | 10.2307/e26123090 | No. 10 September 2, 1916 pp. 201-232 | . 1916 | 115 | 10.2307/e26014959 | No. 9 August 26, 1916 pp. 185-198 | . 1916 | 115 | 10.2307/e26014920 | No. 8 August 19, 1916 pp. 167-182 | . 1916 | 115 | 10.2307/e26014886 | No. 7 August 12, 1916 pp. 147-162 | . 1916 | 115 | 10.2307/e26014858 | No. 6 August 5, 1916 pp. 109-144 | . 1916 | 115 | 10.2307/e26014835 | No. 5 July 29, 1916 pp. 93-106 | . 1916 | 115 | 10.2307/e26014804 | No. 4 July 22, 1916 pp. 75-90 | . 1916 | 115 | 10.2307/e26014774 | No. 3 July 15, 1916 pp. 55-70 | . 1916 | 115 | 10.2307/e26122771 | No. 2 July 1, 1916 pp. 35-50 | . 1916 | 115 | 10.2307/e26014739 | No. 1 July 1, 1916 pp. 1-32 | . 1916 | 114 | 10.2307/e26014708 | No. 26 June 24, 1916 pp. 657-676 | . 1916 | 114 | 10.2307/e26014674 | No. 25 June 17, 1916 pp. 633-652 | . 1916 | 114 | 10.2307/e26014639 | No. 24 June 10, 1916 pp. 613-628 | . 1916 | 114 | 10.2307/e26014610 | No. 23 June 3, 1916 pp. 571-610 | . 1916 | 114 | 10.2307/e26014579 | No. 22 May 27, 1916 pp. 547-566 | . 1916 | 114 | 10.2307/e26014551 | No. 21 May 20, 1916 pp. 523-542 | . 1916 | 114 | 10.2307/e26014506 | No. 20 May 13, 1916 pp. 503-518 | . 1916 | 114 | 10.2307/e26014445 | No. 19 May 6, 1916 pp. 461-500 | . 1916 | 114 | 10.2307/e26014369 | No. 18 April 29, 1916 pp. 443-458 | . 1916 | 114 | 10.2307/e26014337 | No. 17 April 22, 1916 pp. 419-438 | . 1916 | 114 | 10.2307/e26014267 | No. 16 April 15, 1916 pp. 395-414 | . 1916 | 114 | 10.2307/e26002654 | No. 15 April 8, 1916 pp. 375-390 | . 1916 | 114 | 10.2307/e26017566 | No. 14 April 1, 1916 pp. 341-372 | . 1916 | 114 | 10.2307/e26017525 | No. 13 March 25, 1916 pp. 319-338 | . 1916 | 114 | 10.2307/e26017454 | No. 12 March 18, 1916 pp. 295-314 | . 1916 | 114 | 10.2307/e26017407 | No. 11 March 11, 1916 pp. 275-290 | . 1916 | 114 | 10.2307/e26017374 | No. 10 March 4, 1916 pp. 233-272 | . 1916 | 114 | 10.2307/e26017317 | No. 9 February 26, 1916 pp. 215-230 | . 1916 | 114 | 10.2307/e26017277 | No. 8 February 19, 1916 pp. 191-210 | . 1916 | 114 | 10.2307/e26017193 | No. 7 February 12, 1916 pp. 171-186 | . 1916 | 114 | 10.2307/e26017178 | No. 6 February 5, 1916 pp. 137-168 | . 1916 | 114 | 10.2307/e26017083 | No. 5 January 29, 1916 pp. 119-134 | . 1916 | 114 | 10.2307/e26017068 | No. 4 January 22, 1916 pp. 93-114 | . 1916 | 114 | 10.2307/e26017000 | No. 2 January 8, 1916 pp. 53-70 | . 1916 | 114 | 10.2307/e26016937 | No. 1 January 1, 1916 pp. 1-52 | . 1915 | 113 | 10.2307/e26016903 | No. 26 December 25, 1915 pp. 551-568 | . 1915 | 113 | 10.2307/e26016832 | No. 25 December 18, 1915 pp. 533-548 | . 1915 | 113 | 10.2307/e26016755 | No. 24 December 11, 1915 pp. 513-528 | . 1915 | 113 | 10.2307/e26016688 | No. 23 December 4, 1915 pp. 479-510 | . 1915 | 113 | 10.2307/e26016622 | No. 22 November 27, 1915 pp. 461-476 | . 1915 | 113 | 10.2307/e26016529 | No. 21 November 20, 1915 pp. 441-456 | . 1915 | 113 | 10.2307/e26016476 | No. 20 November 13, 1915 pp. 421-436 | . 1915 | 113 | 10.2307/e26016365 | No. 19 November 6, 1915 pp. 391-418 | . 1915 | 113 | 10.2307/e26016295 | No. 18 October 30, 1915 pp. 373-388 | . 1915 | 113 | 10.2307/e26023586 | No. 17 October 23, 1915 pp. 353-368 | . 1915 | 113 | 10.2307/e26023558 | No. 16 October 16, 1915 pp. 333-348 | . 1915 | 113 | 10.2307/e26023463 | No. 15 October 9, 1915 pp. 315-330 | . 1915 | 113 | 10.2307/e26023354 | No. 14 October 2, 1915 pp. 283-314 | . 1915 | 113 | 10.2307/e26023311 | No. 13 September 25, 1915 pp. 263-282 | . 1915 | 113 | 10.2307/e26023166 | No. 12 September 18, 1915 pp. 243-262 | . 1915 | 113 | 10.2307/e26023122 | No. 11 September 11, 1915 pp. 225-240 | . 1915 | 113 | 10.2307/e26022989 | No. 10 September 4, 1915 pp. 191-222 | . 1915 | 113 | 10.2307/e26022943 | No. 9 August 28, 1915 pp. 175-190 | . 1915 | 113 | 10.2307/e26022836 | No. 8 August 21, 1915 pp. 153-172 | . 1915 | 113 | 10.2307/e26171658 | No. 7 August 14, 1915 pp. 136-149 | . 1915 | 113 | 10.2307/e26022797 | No. 6 August 7, 1915 pp. 105-132 | . 1915 | 113 | 10.2307/e26022711 | No. 5 July 31, 1915 pp. 89-104 | . 1915 | 113 | 10.2307/e26022687 | No. 4 July 24, 1915 pp. 73-88 | . 1915 | 113 | 10.2307/e26022571 | No. 3 July 17, 1915 pp. 57-72 | . 1915 | 113 | 10.2307/e26022544 | No. 2 July 10, 1915 pp. 37-56 | . 1915 | 113 | 10.2307/e26022257 | No. 1 July 3, 1915 pp. 1-36 | . 1915 | 112 | 10.2307/e26122122 | No. 26 June 26, 1915 pp. 621-640 | . 1915 | 112 | 10.2307/e26022236 | No. 25 June 19, 1915 pp. 603-618 | . 1915 | 112 | 10.2307/e26024862 | No. 24 June 12, 1915 pp. 585-600 | . 1915 | 112 | 10.2307/e26022214 | No. 23 June 5, 1915 pp. 505-584 | . 1915 | 112 | 10.2307/e26022186 | No. 22 May 29, 1915 pp. 487-504 | . 1915 | 112 | 10.2307/e26022157 | No. 21 May 22, 1915 pp. 465-484 | . 1915 | 112 | 10.2307/e26121705 | No. 20 May 15, 1915 pp. 445-464 | . 1915 | 112 | 10.2307/e26022094 | No. 19 May 8, 1915 pp. 425-444 | . 1915 | 112 | 10.2307/e26022037 | No. 18 May 1, 1915 pp. 393-424 | . 1915 | 112 | 10.2307/e26015925 | No. 17 April 24, 1915 pp. 373-392 | . 1915 | 112 | 10.2307/e26015901 | No. 16 April 17, 1915 pp. 353-372 | . 1915 | 112 | 10.2307/e26015867 | No. 15 April 10, 1915 pp. 333-352 | . 1915 | 112 | 10.2307/e26015817 | No. 14 April 3, 1915 pp. 301-332 | . 1915 | 112 | 10.2307/e26121143 | No. 13 March 27, 1915 pp. 283-300 | . 1915 | 112 | 10.2307/e26015793 | No. 12 March 20, 1915 pp. 261-280 | . 1915 | 112 | 10.2307/e26015754 | No. 11 March 13, 1915 pp. 241-260 | . 1915 | 112 | 10.2307/e26015708 | No. 10 March 6, 1915 pp. 209-240 | . 1915 | 112 | 10.2307/e26015681 | No. 9 February 27, 1915 pp. 191-208 | . 1915 | 112 | 10.2307/e26015649 | No. 8 February 20, 1915 pp. 169-188 | . 1915 | 112 | 10.2307/e26015628 | No. 7 February 13, 1915 pp. 149-168 | . 1915 | 112 | 10.2307/e26015577 | No. 6 February 6, 1915 pp. 113-148 | . 1915 | 112 | 10.2307/e26015557 | No. 5 January 30, 1915 pp. 93-112 | . 1915 | 112 | 10.2307/e26015514 | No. 4 January 23, 1915 pp. 77-92 | . 1915 | 112 | 10.2307/e26015497 | No. 3 January 16, 1915 pp. 61-76 | . 1915 | 112 | 10.2307/e26015474 | No. 2 January 9, 1915 pp. 45-60 | . 1915 | 112 | 10.2307/e26124159 | No. 1 January 2, 1915 pp. 1-44 | . 1914 | 111 | 10.2307/e26015445 | No. 26 December 26, 1914 pp. 517-536 | . 1914 | 111 | 10.2307/e26124600 | No. 25 December 19, 1914 pp. 501-516 | . 1914 | 111 | 10.2307/e26015416 | No. 24 December 12, 1914 pp. 485-500 | . 1914 | 111 | 10.2307/e26015380 | No. 23 December 5, 1914 pp. 449-484 | . 1914 | 111 | 10.2307/e26015350 | No. 22 November 28, 1914 pp. 433-448 | . 1914 | 111 | 10.2307/e26015328 | No. 21 November 21, 1914 pp. 417-432 | . 1914 | 111 | 10.2307/e26123502 | No. 20 November 14, 1914 pp. 401-416 | . 1914 | 111 | 10.2307/e26015288 | No. 19 November 7, 1914 pp. 361-400 | . 1914 | 111 | 10.2307/e26015258 | No. 18 October 31, 1914 pp. 345-360 | . 1914 | 111 | 10.2307/e26015229 | No. 17 October 24, 1914 pp. 329-344 | . 1914 | 111 | 10.2307/e26125814 | No. 16 October 17, 1914 pp. 313-328 | . 1914 | 111 | 10.2307/e26015197 | No. 15 October 10, 1914 pp. 297-312 | . 1914 | 111 | 10.2307/e26015169 | No. 14 October 3, 1914 pp. 257-296 | . 1914 | 111 | 10.2307/e26013794 | No. 13 September 26, 1914 pp. 241-254 | . 1914 | 111 | 10.2307/e26122369 | No. 12 September 19, 1914 pp. 221-240 | . 1914 | 111 | 10.2307/e26013762 | No. 11 September 12, 1914 pp. 205-220 | . 1914 | 111 | 10.2307/e26124824 | No. 10 September 5, 1914 pp. 157-204 | . 1914 | 111 | 10.2307/e26013734 | No. 9 August 29, 1914 pp. 141-156 | . 1914 | 111 | 10.2307/e26013701 | No. 8 August 22, 1914 pp. 125-140 | . 1914 | 111 | 10.2307/e26013672 | No. 7 August 15, 1914 pp. 109-124 | . 1914 | 111 | 10.2307/e26013641 | No. 6 August 8, 1914 pp. 93-108 | . 1914 | 111 | 10.2307/e26123101 | No. 5 August 1, 1914 pp. 69-92 | . 1914 | 111 | 10.2307/e26013615 | No. 4 July 25, 1914 pp. 53-68 | . 1914 | 111 | 10.2307/e26013589 | No. 3 July 18, 1914 pp. 37-52 | . 1914 | 111 | 10.2307/e26013552 | No. 2 July 11, 1914 pp. 21-36 | . 1914 | 111 | 10.2307/e26013512 | No. 1 July 4, 1914 pp. 1-20 | . 1914 | 110 | 10.2307/e26013485 | No. 26 June 27, 1914 pp. 513-530 | . 1914 | 110 | 10.2307/e26013449 | No. 25 June 20, 1914 pp. 495-512 | . 1914 | 110 | 10.2307/e26013410 | No. 24 June 13, 1914 pp. 479-494 | . 1914 | 110 | 10.2307/e26013369 | No. 23 June 6, 1914 pp. 455-478 | . 1914 | 110 | 10.2307/e26013338 | No. 22 May 30, 1914 pp. 439-454 | . 1914 | 110 | 10.2307/e26013300 | No. 21 May 23, 1914 pp. 423-438 | . 1914 | 110 | 10.2307/e26013270 | No. 20 May 16, 1914 pp. 407-422 | . 1914 | 110 | 10.2307/e26013216 | No. 19 May 9, 1914 pp. 391-406 | . 1914 | 110 | 10.2307/e26013162 | No. 18 MAY 2, 1914 pp. 355-390 | . 1914 | 110 | 10.2307/e26013128 | No. 17 APRIL 25, 1914 pp. 339-354 | . 1914 | 110 | 10.2307/e26013093 | No. 16 April 18, 1914 pp. 323-338 | . 1914 | 110 | 10.2307/e26013060 | No. 15 April 11, 1914 pp. 303-322 | . 1914 | 110 | 10.2307/e26013024 | No. 14 APRIL 4, 1914 pp. 277-302 | . 1914 | 110 | 10.2307/e26012991 | No. 13 March 28, 1914 pp. 259-274 | . 1914 | 110 | 10.2307/e26012964 | No. 12 March 21, 1914 pp. 243-258 | . 1914 | 110 | 10.2307/e26012927 | No. 11 March 14, 1914 pp. 225-242 | . 1914 | 110 | 10.2307/e26012883 | No. 10 March 7, 1914 pp. 189-224 | . 1914 | 110 | 10.2307/e26012810 | No. 9 February 28, 1914 pp. 173-188 | . 1914 | 110 | 10.2307/e26012838 | No. 8 February 21, 1914 pp. 153-172 | . 1914 | 110 | 10.2307/e26012759 | No. 7 February 14, 1914 pp. 137-152 | . 1914 | 110 | 10.2307/e26012736 | No. 6 February 7, 1914 pp. 109-136 | . 1914 | 110 | 10.2307/e26012703 | No. 5 January 31, 1914 pp. 93-108 | . 1914 | 110 | 10.2307/e26012656 | No. 4 January 24, 1914 pp. 75-92 | . 1914 | 110 | 10.2307/e26012633 | No. 3 January 17, 1914 pp. 59-74 | . 1914 | 110 | 10.2307/e26012587 | No. 2 January 10, 1914 pp. 41-58 | . 1914 | 110 | 10.2307/e26012561 | No. 1 January 3, 1914 pp. 1-40 | . 1913 | 109 | 10.2307/e26012515 | No. 26 December 27, 1913 pp. 485-502 | . 1913 | 109 | 10.2307/e26012498 | No. 25 December 20, 1913 pp. 465-484 | . 1913 | 109 | 10.2307/e26012402 | No. 24 December 13, 1913 pp. 449-464 | . 1913 | 109 | 10.2307/e26012393 | No. 23 December 6, 1913 pp. 421-448 | . 1913 | 109 | 10.2307/e26012313 | No. 22 November 29, 1913 pp. 405-420 | . 1913 | 109 | 10.2307/e26012262 | No. 21 November 22, 1913 pp. 389-404 | . 1913 | 109 | 10.2307/e26012233 | No. 20 November 15, 1913 pp. 373-388 | . 1913 | 109 | 10.2307/e26012178 | No. 19 November 8, 1913 pp. 357-372 | . 1913 | 109 | 10.2307/e26012116 | No. 18 NOVEMBER 1, 1913 pp. 329-356 | . 1913 | 109 | 10.2307/e26012094 | No. 17 October 25, 1913 pp. 313-328 | . 1913 | 109 | 10.2307/e26012017 | No. 16 October 18, 1913 pp. 297-312 | . 1913 | 109 | 10.2307/e26011876 | No. 15 OCTOBER 11, 1913 pp. 277-296 | . 1913 | 109 | 10.2307/e26011778 | No. 14 October 4, 1913 pp. 253-276 | . 1913 | 109 | 10.2307/e26011707 | No. 13 SEPTEMBER 27, 1913 pp. 237-252 | . 1913 | 109 | 10.2307/e26011641 | No. 12 SEPTEMBER 20, 1913 pp. 221-236 | . 1913 | 109 | 10.2307/e26011563 | No. 11 SEPTEMBER 13, 1913 pp. 205-220 | . 1913 | 109 | 10.2307/e26011465 | No. 10 September 6, 1913 pp. 173-204 | . 1913 | 109 | 10.2307/e26020202 | No. 9 AUGUST 30, 1913 pp. 157-172 | . 1913 | 109 | 10.2307/e26020162 | No. 8 AUGUST 23, 1913 pp. 137-156 | . 1913 | 109 | 10.2307/e26020125 | No. 7 AUGUST 16, 1913 pp. 121-136 | . 1913 | 109 | 10.2307/e26020094 | No. 6 AUGUST 9, 1913 pp. 105-120 | . 1913 | 109 | 10.2307/e26020050 | No. 5 August 2, 1913 pp. 81-104 | . 1913 | 109 | 10.2307/e26020010 | No. 4 JULY 26, 1913 pp. 61-80 | . 1913 | 109 | 10.2307/e26019982 | No. 3 JULY 19, 1913 pp. 45-60 | . 1913 | 109 | 10.2307/e26019943 | No. 2 JULY 12, 1913 pp. 25-44 | . 1913 | 109 | 10.2307/e26019900 | No. 1 JULY 5, 1913 pp. 1-24 | . 1913 | 108 | 10.2307/e26019870 | No. 26 JUNE 28, 1913 pp. 573-590 | . 1913 | 108 | 10.2307/e26019833 | No. 25 JUNE 21, 1913 pp. 553-571 | . 1913 | 108 | 10.2307/e26019799 | No. 24 JUNE 14, 1913 pp. 533-552 | . 1913 | 108 | 10.2307/e26019758 | No. 23 JUNE 7, 1913 pp. 505-532 | . 1913 | 108 | 10.2307/e26019715 | No. 22 MAY 31, 1913 pp. 485-504 | . 1913 | 108 | 10.2307/e26019679 | No. 21 MAY 24, 1913 pp. 465-484 | . 1913 | 108 | 10.2307/e26019644 | No. 20 MAY 17, 1913 pp. 445-464 | . 1913 | 108 | 10.2307/e26019608 | No. 19 MAY 10, 1913 pp. 425-444 | . 1913 | 108 | 10.2307/e26019561 | No. 18 MAY 3, 1913 pp. 389-424 | . 1913 | 108 | 10.2307/e26019535 | No. 17 APRIL 26, 1913 pp. 369-388 | . 1913 | 108 | 10.2307/e26019497 | No. 16 APRIL 19, 1913 pp. 349-368 | . 1913 | 108 | 10.2307/e26019456 | No. 15 APRIL 12, 1913 pp. 329-348 | . 1913 | 108 | 10.2307/e26019415 | No. 14 APRIL 5, 1913 pp. 301-328 | . 1913 | 108 | 10.2307/e26019387 | No. 13 MARCH 29, 1913 pp. 281-299 | . 1913 | 108 | 10.2307/e26019349 | No. 12 MARCH 22, 1913 pp. 261-280 | . 1913 | 108 | 10.2307/e26019314 | No. 11 MARCH 15, 1913 pp. 237-260 | . 1913 | 108 | 10.2307/e26019287 | No. 10 MARCH 8, 1913 pp. 217-236 | . 1913 | 108 | 10.2307/e26019250 | No. 9 MARCH 1, 1913 pp. 191-216 | . 1913 | 108 | 10.2307/e26012446 | No. 8 FEBRUARY 22, 1913 pp. 169-188 | . 1913 | 108 | 10.2307/e26012356 | No. 7 FEBRUARY 15, 1913 pp. 149-168 | . 1913 | 108 | 10.2307/e26012261 | No. 6 FEBRUARY 8, 1913 pp. 133-148 | . 1913 | 108 | 10.2307/e26012163 | No. 5 FEBRUARY 1, 1913 pp. 105-132 | . 1913 | 108 | 10.2307/e26012037 | No. 4 JANUARY 25, 1913 pp. 81-104 | . 1913 | 108 | 10.2307/e26011988 | No. 3 JANUARY 18, 1913 pp. 61-80 | . 1913 | 108 | 10.2307/e26011951 | No. 2 JANUARY 11, 1913 pp. 23-58 | . 1913 | 108 | 10.2307/e26011916 | No. 1 JANUARY 4, 1913 pp. 1-20 | . 1912 | 107 | 10.2307/e26011849 | No. 26 DECEMBER 28, 1912 pp. 545-564 | . 1912 | 107 | 10.2307/e26011781 | No. 25 DECEMBER 21, 1912 pp. 525-544 | . 1912 | 107 | 10.2307/e26011712 | No. 24 DECEMBER 14, 1912 pp. 505-524 | . 1912 | 107 | 10.2307/e26011657 | No. 23 DECEMBER 7, 1912 pp. 473-504 | . 1912 | 107 | 10.2307/e26011600 | No. 22 NOVEMBER 30, 1912 pp. 453-472 | . 1912 | 107 | 10.2307/e26011534 | No. 21 NOVEMBER 23, 1912 pp. 433-452 | . 1912 | 107 | 10.2307/e26011455 | No. 20 NOVEMBER 16, 1912 pp. 413-432 | . 1912 | 107 | 10.2307/e26011421 | No. 19 NOVEMBER 9, 1912 pp. 381-412 | . 1912 | 107 | 10.2307/e26011390 | No. 18 NOVEMBER 2, 1912 pp. 361-380 | . 1912 | 107 | 10.2307/e26011357 | No. 17 OCTOBER 26, 1912 pp. 341-360 | . 1912 | 107 | 10.2307/e26011322 | No. 16 OCTOBER 19, 1912 pp. 321-340 | . 1912 | 107 | 10.2307/e26011292 | No. 15 OCTOBER 12, 1912 pp. 293-320 | . 1912 | 107 | 10.2307/e26011251 | No. 14 OCTOBER 5, 1912 pp. 273-292 | . 1912 | 107 | 10.2307/e26011210 | No. 13 SEPTEMBER 28, 1912 pp. 253-272 | . 1912 | 107 | 10.2307/e26011174 | No. 10 SEPTEMBER 7, 1912 pp. 189-208 | . 1912 | 107 | 10.2307/e26011140 | No. 9 AUGUST 31, 1912 pp. 173-188 | . 1912 | 107 | 10.2307/e26011100 | No. 8 AUGUST 24, 1912 pp. 153-172 | . 1912 | 107 | 10.2307/e26011044 | No. 7 AUGUST 17, 1912 pp. 129-152 | . 1912 | 107 | 10.2307/e26011012 | No. 6 AUGUST 10, 1912 pp. 109-128 | . 1912 | 107 | 10.2307/e26010974 | No. 5 AUGUST 3, 1912 pp. 89-108 | . 1912 | 107 | 10.2307/e26010941 | No. 4 JULY 27, 1912 pp. 69-88 | . 1912 | 107 | 10.2307/e26010910 | No. 3 JULY 20, 1912 pp. 49-68 | . 1912 | 107 | 10.2307/e26010869 | No. 2 JULY 13, 1912 pp. 21-48 | . 1912 | 107 | 10.2307/e26010835 | No. 1 JULY 6, 1912 pp. 1-20 | . 1912 | 106 | 10.2307/e26010807 | No. 26 JUNE 29, 1912 pp. 577-596 | . 1912 | 106 | 10.2307/e26010777 | No. 25 JUNE 22, 1912 pp. 557-576 | . 1912 | 106 | 10.2307/e26010743 | No. 24 JUNE 15, 1912 pp. 529-556 | . 1912 | 106 | 10.2307/e26010710 | No. 23 JUNE 8, 1912 pp. 509-528 | . 1912 | 106 | 10.2307/e26010669 | No. 22 JUNE 1, 1912 pp. 489-508 | . 1912 | 106 | 10.2307/e26010618 | No. 21 MAY 25, 1912 pp. 469-488 | . 1912 | 106 | 10.2307/e26010574 | No. 20 MAY 18, 1912 pp. 433-468 | . 1912 | 106 | 10.2307/e26010543 | No. 18 MAY 4, 1912 pp. 393-412 | . 1912 | 106 | 10.2307/e26010512 | No. 17 APRIL 27, 1912 pp. 373-392 | . 1912 | 106 | 10.2307/e26010476 | No. 16 APRIL 20, 1912 pp. 353-372 | . 1912 | 106 | 10.2307/e26010439 | No. 15 APRIL 13, 1912 pp. 321-351 | . 1912 | 106 | 10.2307/e26010409 | No. 14 APRIL 6, 1912 pp. 301-320 | . 1912 | 106 | 10.2307/e26010373 | No. 13 MARCH 30, 1912 pp. 281-300 | . 1912 | 106 | 10.2307/e26010341 | No. 12 MARCH 23, 1912 pp. 261-280 | . 1912 | 106 | 10.2307/e26010300 | No. 11 MARCH 16, 1912 pp. 229-260 | . 1912 | 106 | 10.2307/e26010267 | No. 10 MARCH 9, 1912 pp. 209-228 | . 1912 | 106 | 10.2307/e26010233 | No. 9 MARCH 2, 1912 pp. 189-208 | . 1912 | 106 | 10.2307/e26010206 | No. 8 FEBRUARY 24, 1912 pp. 169-188 | . 1912 | 106 | 10.2307/e26010119 | No. 7 FEBRUARY 17, 1912 pp. 149-168 | . 1912 | 106 | 10.2307/e26010080 | No. 6 FEBRUARY 10, 1912 pp. 121-148 | . 1912 | 106 | 10.2307/e26010050 | No. 5 FEBRUARY 3, 1912 pp. 101-120 | . 1912 | 106 | 10.2307/e26010019 | No. 4 JANUARY 27, 1912 pp. 81-100 | . 1912 | 106 | 10.2307/e26009987 | No. 3 JANUARY 20, 1912 pp. 61-80 | . 1912 | 106 | 10.2307/e26009953 | No. 2 JANUARY 13, 1912 pp. 41-60 | . 1912 | 106 | 10.2307/e26009931 | No. 1 JANUARY 6, 1912 pp. 1-40 | . 1911 | 105 | 10.2307/e26009911 | No. 27 DECEMBER 30, 1911 pp. 589-608 | . 1911 | 105 | 10.2307/e26009879 | No. 26 DECEMBER 23, 1911 pp. 569-588 | . 1911 | 105 | 10.2307/e26009852 | No. 25 DECEMBER 16, 1911 pp. 549-568 | . 1911 | 105 | 10.2307/e26009824 | No. 24 DECEMBER 9, 1911 pp. 509-550 | . 1911 | 105 | 10.2307/e26009794 | No. 23 DECEMBER 2, 1911 pp. 489-508 | . 1911 | 105 | 10.2307/e26009741 | No. 22 NOVEMBER 25, 1911 pp. 469-488 | . 1911 | 105 | 10.2307/e26009714 | No. 21 NOVEMBER 18, 1911 pp. 441-468 | . 1911 | 105 | 10.2307/e26009651 | No. 20 NOVEMBER 11, 1911 pp. 421-440 | . 1911 | 105 | 10.2307/e26009624 | No. 19 NOVEMBER 4, 1911 pp. 401-420 | . 1911 | 105 | 10.2307/e26009594 | No. 18 OCTOBER 28, 1911 pp. 381-400 | . 1911 | 105 | 10.2307/e26009567 | No. 17 OCTOBER 21, 1911 pp. 361-380 | . 1911 | 105 | 10.2307/e26009531 | No. 16 OCTOBER 14, 1911 pp. 329-360 | . 1911 | 105 | 10.2307/e26009495 | No. 15 OCTOBER 7, 1911 pp. 309-328 | . 1911 | 105 | 10.2307/e26009468 | No. 14 SEPTEMBER 30, 1911 pp. 289-308 | . 1911 | 105 | 10.2307/e26009441 | No. 13 SEPTEMBER 23, 1911 pp. 269-288 | . 1911 | 105 | 10.2307/e26009383 | No. 12 SEPTEMBER 16, 1911 pp. 241-268 | . 1911 | 105 | 10.2307/e26009350 | No. 11 SEPTEMBER 9, 1911 pp. 221-240 | . 1911 | 105 | 10.2307/e26009179 | No. 10 SEPTEMBER 2, 1911 pp. 201-220 | . 1911 | 105 | 10.2307/e26009143 | No. 9 AUGUST 26, 1911 pp. 181-200 | . 1911 | 105 | 10.2307/e26009109 | No. 8 AUGUST 19, 1911 pp. 161-180 | . 1911 | 105 | 10.2307/e26009077 | No. 7 AUGUST 12, 1911 pp. 133-160 | . 1911 | 105 | 10.2307/e26009044 | No. 6 AUGUST 5, 1911 pp. 113-132 | . 1911 | 105 | 10.2307/e26009007 | No. 5 JULY 29, 1911 pp. 93-112 | . 1911 | 105 | 10.2307/e26008977 | No. 4 JULY 22, 1911 pp. 73-92 | . 1911 | 105 | 10.2307/e26008944 | No. 2 JULY 8, 1911 pp. 21-40 | . 1911 | 105 | 10.2307/e26008907 | No. 1 JULY 1, 1911 pp. 1-20 | . 1911 | 104 | 10.2307/e26008874 | No. 25 JUNE 24, 1911 pp. 613-636 | . 1911 | 104 | 10.2307/e26008856 | No. 24 JUNE 17, 1911 pp. 581-610 | . 1911 | 104 | 10.2307/e26008829 | No. 23 JUNE 10, 1911 pp. 561-580 | . 1911 | 104 | 10.2307/e26008801 | No. 22 JUNE 3, 1911 pp. 541-560 | . 1911 | 104 | 10.2307/e26008764 | No. 21 MAY 27, 1911 pp. 517-540 | . 1911 | 104 | 10.2307/e26008733 | No. 20 MAY 20, 1911 pp. 497-516 | . 1911 | 104 | 10.2307/e26008701 | No. 19 MAY 13, 1911 pp. 461-496 | . 1911 | 104 | 10.2307/e26008661 | No. 18 MAY 6, 1911 pp. 441-460 | . 1911 | 104 | 10.2307/e26008628 | No. 17 APRIL 29, 1911 pp. 421-440 | . 1911 | 104 | 10.2307/e26008584 | No. 16 APRIL 22, 1911 pp. 397-420 | . 1911 | 104 | 10.2307/e26008554 | No. 15 APRIL 15, 1911 pp. 369-396 | . 1911 | 104 | 10.2307/e26008516 | No. 14 APRIL 8, 1911 pp. 345-368 | . 1911 | 104 | 10.2307/e26008476 | No. 13 APRIL 1, 1911 pp. 321-344 | . 1911 | 104 | 10.2307/e26008439 | No. 12 MARCH 25, 1911 pp. 297-320 | . 1911 | 104 | 10.2307/e26008395 | No. 11 MARCH 18, 1911 pp. 265-296 | . 1911 | 104 | 10.2307/e26021239 | No. 10 MARCH 11, 1911 pp. 241-264 | . 1911 | 104 | 10.2307/e26021668 | No. 9 MARCH 4, 1911 pp. 217-240 | . 1911 | 104 | 10.2307/e26021158 | No. 8 FEBRUARY 25, 1911 pp. 193-216 | . 1911 | 104 | 10.2307/e26021116 | No. 7 FEBRUARY 18, 1911 pp. 153-192 | . 1911 | 104 | 10.2307/e26021048 | No. 6 FEBRUARY 11, 1911 pp. 129-152 | . 1911 | 104 | 10.2307/e26020997 | No. 5 FEBRUARY 4, 1911 pp. 105-128 | . 1911 | 104 | 10.2307/e26020953 | No. 4 JANUARY 28, 1911 pp. 81-104 | . 1911 | 104 | 10.2307/e26020898 | No. 3 JANUARY 21, 1911 pp. 57-80 | . 1911 | 104 | 10.2307/e26020830 | No. 2 JANUARY 14, 1911 pp. 25-56 | . 1911 | 104 | 10.2307/e26020780 | No. 1 JANUARY 7, 1911 pp. 1-24 | . 1910 | 103 | 10.2307/e26020715 | No. 27 DECEMBER 31, 1910 pp. 513-532 | . 1910 | 103 | 10.2307/e26020706 | No. 26 DECEMBER 24, 1910 pp. 493-512 | . 1910 | 103 | 10.2307/e26020660 | No. 25 DECEMBER 17, 1910 pp. 473-492 | . 1910 | 103 | 10.2307/e26020639 | No. 24 DECEMBER 10, 1910 pp. 453-472 | . 1910 | 103 | 10.2307/e26020604 | No. 23 DECEMBER 3, 1910 pp. 433-452 | . 1910 | 103 | 10.2307/e26020584 | No. 22 NOVEMBER 26, 1910 pp. 413-432 | . 1910 | 103 | 10.2307/e26020528 | No. 21 NOVEMBER 19, 1910 pp. 393-412 | . 1910 | 103 | 10.2307/e26020504 | No. 20 NOVEMBER 12, 1910 pp. 373-392 | . 1910 | 103 | 10.2307/e26020474 | No. 19 NOVEMBER 5, 1910 pp. 353-372 | . 1910 | 103 | 10.2307/e26020446 | No. 18 OCTOBER 29, 1910 pp. 333-352 | . 1910 | 103 | 10.2307/e26020418 | No. 17 OCTOBER 22, 1910 pp. 309-332 | . 1910 | 103 | 10.2307/e26020377 | No. 16 OCTOBER 15, 1910 pp. 289-308 | . 1910 | 103 | 10.2307/e26020336 | No. 15 OCTOBER 8, 1910 pp. 269-288 | . 1910 | 103 | 10.2307/e26020309 | No. 14 OCTOBER 1, 1910 pp. 249-268 | . 1910 | 103 | 10.2307/e26020278 | No. 13 SEPTEMBER 24, 1910 pp. 229-248 | . 1910 | 103 | 10.2307/e26020237 | No. 12 SEPTEMBER 17, 1910 pp. 209-228 | . 1910 | 103 | 10.2307/e26039097 | No. 11 SEPTEMBER 10, 1910 pp. 193-208 | . 1910 | 103 | 10.2307/e26039026 | No. 10 SEPTEMBER 3, 1910 pp. 173-192 | . 1910 | 103 | 10.2307/e26038978 | No. 9 AUGUST 27, 1910 pp. 153-172 | . 1910 | 103 | 10.2307/e26038932 | No. 8 AUGUST 20, 1910 pp. 137-152 | . 1910 | 103 | 10.2307/e26038872 | No. 7 AUGUST 13, 1910 pp. 117-136 | . 1910 | 103 | 10.2307/e26038829 | No. 6 AUGUST 6, 1910 pp. 97-116 | . 1910 | 103 | 10.2307/e26069978 | No. 5 JULY 30, 1910 pp. 77-96 | . 1910 | 103 | 10.2307/e26038801 | No. 4 JULY 23, 1910 pp. 61-76 | . 1910 | 103 | 10.2307/e26038767 | No. 3 JULY 16, 1910 pp. 41-60 | . 1910 | 103 | 10.2307/e26038730 | No. 2 JULY 9, 1910 pp. 21-40 | . 1910 | 103 | 10.2307/e26038701 | No. 1 JULY 2, 1910 pp. 3-20 | . 1910 | 102 | 10.2307/e26038640 | No. 26 JUNE 25, 1910 pp. 513-532 | . 1910 | 102 | 10.2307/e26038594 | No. 25 JUNE 18, 1910 pp. 493-512 | . 1910 | 102 | 10.2307/e26038514 | No. 24 JUNE 11, 1910 pp. 473-492 | . 1910 | 102 | 10.2307/e26038647 | No. 23 JUNE 4, 1910 pp. 453-472 | . 1910 | 102 | 10.2307/e26038320 | No. 22 MAY 28, 1910 pp. 433-452 | . 1910 | 102 | 10.2307/e26038279 | No. 21 MAY 21, 1910 pp. 413-432 | . 1910 | 102 | 10.2307/e26038251 | No. 20 MAY 14, 1910 pp. 389-412 | . 1910 | 102 | 10.2307/e26038185 | No. 19 MAY 7, 1910 pp. 369-388 | . 1910 | 102 | 10.2307/e26038060 | No. 18 APRIL 30, 1910 pp. 353-368 | . 1910 | 102 | 10.2307/e26037876 | No. 17 APRIL 23, 1910 pp. 333-352 | . 1910 | 102 | 10.2307/e26037866 | No. 16 APRIL 16, 1910 pp. 313-332 | . 1910 | 102 | 10.2307/e26037717 | No. 15 APRIL 9, 1910 pp. 293-312 | . 1910 | 102 | 10.2307/e26037623 | No. 14 APRIL 2, 1910 pp. 273-292 | . 1910 | 102 | 10.2307/e26037528 | No. 13 MARCH 26, 1910 pp. 253-272 | . 1910 | 102 | 10.2307/e26037463 | No. 12 MARCH 19, 1910 pp. 233-252 | . 1910 | 102 | 10.2307/e26037359 | No. 11 MARCH 12, 1910 pp. 213-232 | . 1910 | 102 | 10.2307/e26037199 | No. 10 MARCH 5, 1910 pp. 193-212 | . 1910 | 102 | 10.2307/e26037072 | No. 9 FEBRUARY 26, 1910 pp. 177-192 | . 1910 | 102 | 10.2307/e26036903 | No. 8 FEBRUARY 19, 1910 pp. 157-176 | . 1910 | 102 | 10.2307/e26008259 | No. 7 FEBRUARY 12, 1910 pp. 137-156 | . 1910 | 102 | 10.2307/e26008225 | No. 6 FEBRUARY 5, 1910 pp. 117-136 | . 1910 | 102 | 10.2307/e26008190 | No. 5 JANUARY 29, 1910 pp. 97-116 | . 1910 | 102 | 10.2307/e26008159 | No. 4 JANUARY 22, 1910 pp. 81-96 | . 1910 | 102 | 10.2307/e26008127 | No. 3 JANUARY 15, 1910 pp. 41-80 | . 1910 | 102 | 10.2307/e26008096 | No. 2 JANUARY 8, 1910 pp. 21-40 | . 1910 | 102 | 10.2307/e26008064 | No. 1 JANUARY 1, 1910 pp. 1-20 | . 1909 | 101 | 10.2307/e26008029 | No. 26 DECEMBER 25, 1909 pp. 481-500 | . 1909 | 101 | 10.2307/e26007989 | No. 25 DECEMBER 18, 1909 pp. 461-480 | . 1909 | 101 | 10.2307/e26007958 | No. 24 DECEMBER 11, 1909 pp. 425-460 | . 1909 | 101 | 10.2307/e26007927 | No. 23 DECEMBER 4, 1909 pp. 405-424 | . 1909 | 101 | 10.2307/e26007884 | No. 22 NOVEMBER 27, 1909 pp. 385-404 | . 1909 | 101 | 10.2307/e26007842 | No. 21 NOVEMBER 20, 1909 pp. 365-384 | . 1909 | 101 | 10.2307/e26007799 | No. 20 NOVEMBER 13, 1909 pp. 345-364 | . 1909 | 101 | 10.2307/e26007768 | No. 19 NOVEMBER 6, 1909 pp. 325-344 | . 1909 | 101 | 10.2307/e26007730 | No. 18 OCTOBER 30, 1909 pp. 309-324 | . 1909 | 101 | 10.2307/e26007685 | No. 17 OCTOBER 23, 1909 pp. 289-308 | . 1909 | 101 | 10.2307/e26007656 | No. 16 OCTOBER 16, 1909 pp. 273-288 | . 1909 | 101 | 10.2307/e26007617 | No. 15 OCTOBER 9, 1909 pp. 253-272 | . 1909 | 101 | 10.2307/e26007590 | No. 14 OCTOBER 2, 1909 pp. 237-252 | . 1909 | 101 | 10.2307/e26007563 | No. 13 SEPTEMBER 25, 1909 pp. 205-236 | . 1909 | 101 | 10.2307/e26007528 | No. 12 SEPTEMBER 18, 1909 pp. 189-204 | . 1909 | 101 | 10.2307/e26007505 | No. 11 SEPTEMBER 11, 1909 pp. 173-188 | . 1909 | 101 | 10.2307/e26007477 | No. 10 SEPTEMBER 4, 1909 pp. 153-172 | . 1909 | 101 | 10.2307/e26007444 | No. 9 AUGUST 28, 1909 pp. 137-152 | . 1909 | 101 | 10.2307/e26007416 | No. 8 AUGUST 21, 1909 pp. 121-136 | . 1909 | 101 | 10.2307/e26007383 | No. 7 AUGUST 14, 1909 pp. 105-120 | . 1909 | 101 | 10.2307/e26007341 | No. 6 AUGUST 7, 1909 pp. 85-104 | . 1909 | 101 | 10.2307/e26007308 | No. 5 JULY 31, 1909 pp. 69-84 | . 1909 | 101 | 10.2307/e26030403 | No. 4 JULY 24, 1909 pp. 53-68 | . 1909 | 101 | 10.2307/e26030238 | No. 3 JULY 17, 1909 pp. 37-52 | . 1909 | 101 | 10.2307/e26030199 | No. 2 JULY 10, 1909 pp. 21-36 | . 1909 | 101 | 10.2307/e26030034 | No. 1 JULY 3, 1909 pp. 3-20 | . 1909 | 100 | 10.2307/e26029893 | No. 26 JUNE 26, 1909 pp. 473-492 | . 1909 | 100 | 10.2307/e26029829 | No. 25 JUNE 19, 1909 pp. 453-472 | . 1909 | 100 | 10.2307/e26029760 | No. 24 JUNE 12, 1909 pp. 437-452 | . 1909 | 100 | 10.2307/e26029650 | No. 23 JUNE 5, 1909 pp. 417-436 | . 1909 | 100 | 10.2307/e26029594 | No. 22 MAY 29, 1909 pp. 401-416 | . 1909 | 100 | 10.2307/e26029475 | No. 21 MAY 22, 1909 pp. 385-400 | . 1909 | 100 | 10.2307/e26029413 | No. 20 MAY 15, 1909 pp. 365-384 | . 1909 | 100 | 10.2307/e26029256 | No. 19 MAY 8, 1909 pp. 345-364 | . 1909 | 100 | 10.2307/e26029168 | No. 18 MAY 1, 1909 pp. 329-344 | . 1909 | 100 | 10.2307/e26029112 | No. 17 APRIL 24, 1909 pp. 309-328 | . 1909 | 100 | 10.2307/e26028911 | No. 16 APRIL 17, 1909 pp. 289-308 | . 1909 | 100 | 10.2307/e26028866 | No. 15 APRIL 10, 1909 pp. 273-288 | . 1909 | 100 | 10.2307/e26028739 | No. 14 APRIL 3, 1909 pp. 257-272 | . 1909 | 100 | 10.2307/e26028614 | No. 13 MARCH 27, 1909 pp. 237-256 | . 1909 | 100 | 10.2307/e26028555 | No. 12 MARCH 20, 1909 pp. 217-236 | . 1909 | 100 | 10.2307/e26034507 | No. 11 MARCH 13, 1909 pp. 197-216 | . 1909 | 100 | 10.2307/e26028418 | No. 10 MARCH 6, 1909 pp. 181-196 | . 1909 | 100 | 10.2307/e26028299 | No. 9 FEBRUARY 27, 1909 pp. 165-180 | . 1909 | 100 | 10.2307/e26028249 | No. 8 FEBRUARY 20, 1909 pp. 145-164 | . 1909 | 100 | 10.2307/e26028152 | No. 7 FEBRUARY 13, 1909 pp. 129-144 | . 1909 | 100 | 10.2307/e26028103 | No. 6 FEBRUARY 6, 1909 pp. 109-128 | . 1909 | 100 | 10.2307/e26125391 | No. 5 JANUARY 30, 1909 pp. 93-108 | . 1909 | 100 | 10.2307/e26027986 | No. 4 JANUARY 23, 1909 pp. 77-92 | . 1909 | 100 | 10.2307/e26027822 | No. 3 JANUARY 16, 1909 pp. 37-76 | . 1909 | 100 | 10.2307/e26027610 | No. 2 JANUARY 9, 1909 pp. 17-36 | . 1909 | 100 | 10.2307/e26027503 | No. 1 JANUARY 2, 1909 pp. 1-16 | . 1908 | 99 | 10.2307/e26027369 | No. 26 DECEMBER 26, 1908 pp. 465-484 | . 1908 | 99 | 10.2307/e26027122 | No. 25 DECEMBER 19, 1908 pp. 445-464 | . 1908 | 99 | 10.2307/e26019217 | No. 24 DECEMBER 12, 1908 pp. 425-444 | . 1908 | 99 | 10.2307/e26019196 | No. 23 DECEMBER 5, 1908 pp. 389-424 | . 1908 | 99 | 10.2307/e26019158 | No. 22 NOVEMBER 28, 1908 pp. 369-388 | . 1908 | 99 | 10.2307/e26019126 | No. 21 NOVEMBER 21, 1908 pp. 349-368 | . 1908 | 99 | 10.2307/e26019095 | No. 20 NOVEMBER 14, 1908 pp. 329-348 | . 1908 | 99 | 10.2307/e26019053 | No. 19 NOVEMBER 7, 1908 pp. 309-328 | . 1908 | 99 | 10.2307/e26019021 | No. 18 OCTOBER 31, 1908 pp. 293-308 | . 1908 | 99 | 10.2307/e26018995 | No. 17 OCTOBER 24, 1908 pp. 273-292 | . 1908 | 99 | 10.2307/e26018962 | No. 16 OCTOBER 17, 1908 pp. 253-272 | . 1908 | 99 | 10.2307/e26018893 | No. 15 OCTOBER 10, 1908 pp. 237-252 | . 1908 | 99 | 10.2307/e26018894 | No. 14 OCTOBER 3, 1908 pp. 217-236 | . 1908 | 99 | 10.2307/e26018856 | No. 13 SEPTEMBER 26, 1908 pp. 201-216 | . 1908 | 99 | 10.2307/e26018805 | No. 12 SEPTEMBER 19, 1908 pp. 181-200 | . 1908 | 99 | 10.2307/e26018841 | No. 11 SEPTEMBER 12, 1908 pp. 165-180 | . 1908 | 99 | 10.2307/e26018756 | No. 10 SEPTEMBER 5, 1908 pp. 149-164 | . 1908 | 99 | 10.2307/e26018744 | No. 9 AUGUST 29, 1908 pp. 133-148 | . 1908 | 99 | 10.2307/e26125266 | No. 8 AUGUST 22, 1908 pp. 117-132 | . 1908 | 99 | 10.2307/e26018712 | No. 7 AUGUST 15, 1908 pp. 101-116 | . 1908 | 99 | 10.2307/e26018689 | No. 6 AUGUST 8, 1908 pp. 85-100 | . 1908 | 99 | 10.2307/e26018641 | No. 5 AUGUST 1, 1908 pp. 69-84 | . 1908 | 99 | 10.2307/e26018631 | No. 4 JULY 25, 1908 pp. 53-68 | . 1908 | 99 | 10.2307/e26018587 | No. 3 JULY 18, 1908 pp. 37-52 | . 1908 | 99 | 10.2307/e26018566 | No. 2 JULY 11, 1908 pp. 21-36 | . 1908 | 99 | 10.2307/e26018525 | No. 1 JULY 4, 1908 pp. 3-20 | . 1908 | 98 | 10.2307/e26018502 | No. 26 JUNE 27, 1908 pp. 453-472 | . 1908 | 98 | 10.2307/e26123387 | No. 25 JUNE 20, 1908 pp. 437-452 | . 1908 | 98 | 10.2307/e26018469 | No. 24 JUNE 13, 1908 pp. 421-436 | . 1908 | 98 | 10.2307/e26018454 | No. 23 JUNE 6, 1908 pp. 405-420 | . 1908 | 98 | 10.2307/e26018420 | No. 22 MAY 30, 1908 pp. 385-404 | . 1908 | 98 | 10.2307/e26018389 | No. 21 MAY 23, 1908 pp. 365-384 | . 1908 | 98 | 10.2307/e26018354 | No. 20 MAY 16, 1908 pp. 345-364 | . 1908 | 98 | 10.2307/e26018313 | No. 19 MAY 9, 1908 pp. 325-344 | . 1908 | 98 | 10.2307/e26018282 | No. 18 MAY 2, 1908 pp. 305-324 | . 1908 | 98 | 10.2307/e26007260 | No. 17 APRIL 25, 1908 pp. 289-304 | . 1908 | 98 | 10.2307/e26007222 | No. 16 APRIL 18, 1908 pp. 269-288 | . 1908 | 98 | 10.2307/e26007189 | No. 15 APRIL 11, 1908 pp. 253-268 | . 1908 | 98 | 10.2307/e26007159 | No. 14 APRIL 4, 1908 pp. 237-252 | . 1908 | 98 | 10.2307/e26007134 | No. 13 MARCH 28, 1908 pp. 217-236 | . 1908 | 98 | 10.2307/e26007101 | No. 12 MARCH 21, 1908 pp. 197-216 | . 1908 | 98 | 10.2307/e26007067 | No. 11 MARCH 14, 1908 pp. 177-196 | . 1908 | 98 | 10.2307/e26007041 | No. 10 MARCH 7, 1908 pp. 161-176 | . 1908 | 98 | 10.2307/e26007017 | No. 9 FEBRUARY 29, 1908 pp. 137-160 | . 1908 | 98 | 10.2307/e26006986 | No. 8 FEBRUARY 22, 1908 pp. 121-136 | . 1908 | 98 | 10.2307/e26006955 | No. 7 FEBRUARY 15, 1908 pp. 105-120 | . 1908 | 98 | 10.2307/e26006924 | No. 6 FEBRUARY 8, 1908 pp. 89-104 | . 1908 | 98 | 10.2307/e26006893 | No. 5 FEBRUARY 1, 1908 pp. 73-88 | . 1908 | 98 | 10.2307/e26006859 | No. 4 JANUARY 25, 1908 pp. 53-72 | . 1908 | 98 | 10.2307/e26006829 | No. 3 JANUARY 18, 1908 pp. 37-52 | . 1908 | 98 | 10.2307/e26006799 | No. 2 JANUARY 11, 1908 pp. 21-36 | . 1908 | 98 | 10.2307/e26006771 | No. 1 JANUARY 4, 1908 pp. 1-20 | . 1907 | 97 | 10.2307/e26006741 | No. 26 DECEMBER 28, 1907 pp. 469-488 | . 1907 | 97 | 10.2307/e26006710 | No. 25 DECEMBER 21, 1907 pp. 453-467 | . 1907 | 97 | 10.2307/e26006677 | No. 24 DECEMBER 14, 1907 pp. 437-452 | . 1907 | 97 | 10.2307/e26006655 | No. 23 DECEMBER 7, 1907 pp. 405-436 | . 1907 | 97 | 10.2307/e26006623 | No. 22 NOVEMBER 30, 1907 pp. 389-404 | . 1907 | 97 | 10.2307/e26006592 | No. 21 NOVEMBER 23, 1907 pp. 373-388 | . 1907 | 97 | 10.2307/e26126081 | No. 20 NOVEMBER 16, 1907 pp. 353-372 | . 1907 | 97 | 10.2307/e26006550 | No. 19 NOVEMBER 9, 1907 pp. 317-352 | . 1907 | 97 | 10.2307/e26006517 | No. 18 NOVEMBER 2, 1907 pp. 301-316 | . 1907 | 97 | 10.2307/e26006488 | No. 16 OCTOBER 19, 1907 pp. 269-284 | . 1907 | 97 | 10.2307/e26006457 | No. 15 OCTOBER 12, 1907 pp. 253-268 | . 1907 | 97 | 10.2307/e26006422 | No. 14 OCTOBER 5, 1907 pp. 233-252 | . 1907 | 97 | 10.2307/e26006393 | No. 13 SEPTEMBER 28, 1907 pp. 217-232 | . 1907 | 97 | 10.2307/e26006361 | No. 12 SEPTEMBER 21, 1907 pp. 201-216 | . 1907 | 97 | 10.2307/e26006332 | No. 11 SEPTEMBER 14, 1907 pp. 181-200 | . 1907 | 97 | 10.2307/e26006226 | No. 10 SEPTEMBER 7, 1907 pp. 161-180 | . 1907 | 97 | 10.2307/e26006199 | No. 9 AUGUST 31, 1907 pp. 145-160 | . 1907 | 97 | 10.2307/e26006171 | No. 8 AUGUST 24, 1907 pp. 129-144 | . 1907 | 97 | 10.2307/e26006141 | No. 7 AUGUST 17, 1907 pp. 113-128 | . 1907 | 97 | 10.2307/e26006104 | No. 6 AUGUST 10, 1907 pp. 93-112 | . 1907 | 97 | 10.2307/e26006074 | No. 5 AUGUST 3, 1907 pp. 73-92 | . 1907 | 97 | 10.2307/e26006042 | No. 4 JULY 27, 1907 pp. 57-72 | . 1907 | 97 | 10.2307/e26006012 | No. 3 JULY 20, 1907 pp. 41-56 | . 1907 | 97 | 10.2307/e26005973 | No. 2 JULY 13, 1907 pp. 21-40 | . 1907 | 97 | 10.2307/e26005939 | No. 1 JULY 6, 1907 pp. 3-20 | . 1907 | 96 | 10.2307/e26005914 | No. 26 JUNE 29, 1907 pp. 525-544 | . 1907 | 96 | 10.2307/e26005881 | No. 25 JUNE 22, 1907 pp. 505-524 | . 1907 | 96 | 10.2307/e26005851 | No. 24 JUNE 15, 1907 pp. 485-504 | . 1907 | 96 | 10.2307/e26005813 | No. 23 JUNE 8, 1907 pp. 465-484 | . 1907 | 96 | 10.2307/e26005783 | No. 22 JUNE 1, 1907 pp. 445-464 | . 1907 | 96 | 10.2307/e26005753 | No. 21 MAY 25, 1907 pp. 425-444 | . 1907 | 96 | 10.2307/e26005723 | No. 20 MAY 18, 1907 pp. 405-424 | . 1907 | 96 | 10.2307/e26005686 | No. 19 MAY 11, 1907 pp. 385-404 | . 1907 | 96 | 10.2307/e26005656 | No. 18 MAY 4, 1907 pp. 365-384 | . 1907 | 96 | 10.2307/e26005624 | No. 17 APRIL 27, 1907 pp. 345-364 | . 1907 | 96 | 10.2307/e26005590 | No. 16 APRIL 20, 1907 pp. 325-344 | . 1907 | 96 | 10.2307/e26005561 | No. 15 APRIL 13, 1907 pp. 305-324 | . 1907 | 96 | 10.2307/e26005531 | No. 14 APRIL 6, 1907 pp. 285-304 | . 1907 | 96 | 10.2307/e26005492 | No. 13 MARCH 30, 1907 pp. 265-284 | . 1907 | 96 | 10.2307/e26005457 | No. 12 MARCH 23, 1907 pp. 245-264 | . 1907 | 96 | 10.2307/e26005427 | No. 11 MARCH 16, 1907 pp. 225-244 | . 1907 | 96 | 10.2307/e26005394 | No. 10 MARCH 9, 1907 pp. 205-224 | . 1907 | 96 | 10.2307/e26005363 | No. 9 MARCH 2, 1907 pp. 185-204 | . 1907 | 96 | 10.2307/e26005338 | No. 8 FEBRUARY 23, 1907 pp. 161-184 | . 1907 | 96 | 10.2307/e26005309 | No. 7 FEBRUARY 16, 1907 pp. 145-160 | . 1907 | 96 | 10.2307/e26005274 | No. 6 FEBRUARY 9, 1907 pp. 125-144 | . 1907 | 96 | 10.2307/e24998754 | No. 5 FEBRUARY 2, 1907 pp. 105-124 | . 1907 | 96 | 10.2307/e26005240 | No. 4 JANUARY 26, 1907 pp. 85-104 | . 1907 | 96 | 10.2307/e24999221 | No. 3 JANUARY 19, 1907 pp. 65-84 | . 1907 | 96 | 10.2307/e26005177 | No. 2 JANUARY 12, 1907 pp. 21-64 | . 1907 | 96 | 10.2307/e26005153 | No. 1 JANUARY 5, 1907 pp. 1-20 | . 1906 | 95 | 10.2307/e24999363 | No. 26 DECEMBER 29, 1906 pp. 481-500 | . 1906 | 95 | 10.2307/e26005121 | No. 25 DECEMBER 22, 1906 pp. 461-480 | . 1906 | 95 | 10.2307/e26005094 | No. 24 DECEMBER 15, 1906 pp. 441-460 | . 1906 | 95 | 10.2307/e26005061 | No. 23 DECEMBER 8, 1906 pp. 417-440 | . 1906 | 95 | 10.2307/e24999484 | No. 22 DECEMBER 1, 1906 pp. 397-416 | . 1906 | 95 | 10.2307/e24998972 | No. 21 NOVEMBER 24, 1906 pp. 377-396 | . 1906 | 95 | 10.2307/e24999853 | No. 20 NOVEMBER 17, 1906 pp. 357-376 | . 1906 | 95 | 10.2307/e24998064 | No. 19 NOVEMBER 10, 1906 pp. 337-356 | . 1906 | 95 | 10.2307/e26005032 | No. 18 NOVEMBER 3, 1906 pp. 317-336 | . 1906 | 95 | 10.2307/e26004998 | No. 17 OCTOBER 27, 1906 pp. 297-316 | . 1906 | 95 | 10.2307/e24998430 | No. 16 OCTOBER 20, 1906 pp. 277-296 | . 1906 | 95 | 10.2307/e24998863 | No. 15 OCTOBER 13, 1906 pp. 257-276 | . 1906 | 95 | 10.2307/e24998169 | No. 14 OCTOBER 6, 1906 pp. 241-256 | . 1906 | 95 | 10.2307/e24999743 | No. 13 SEPTEMBER 29, 1906 pp. 225-240 | . 1906 | 95 | 10.2307/e24998260 | No. 12 SEPTEMBER 22, 1906 pp. 205-224 | . 1906 | 95 | 10.2307/e26004963 | No. 11 SEPTEMBER 15, 1906 pp. 185-204 | . 1906 | 95 | 10.2307/e26004935 | No. 10 SEPTEMBER 8, 1906 pp. 169-184 | . 1906 | 95 | 10.2307/e24999611 | No. 9 SEPTEMBER 1, 1906 pp. 149-168 | . 1906 | 95 | 10.2307/e24999076 | No. 8 AUGUST 25, 1906 pp. 129-148 | . 1906 | 95 | 10.2307/e24998646 | No. 7 AUGUST 18, 1906 pp. 109-128 | . 1906 | 95 | 10.2307/e24998364 | No. 6 AUGUST 11, 1906 pp. 93-108 | . 1906 | 95 | 10.2307/e24998000 | No. 5 AUGUST 4, 1906 pp. 77-92 | . 1906 | 95 | 10.2307/e26004903 | No. 4 JULY 28, 1906 pp. 61-76 | . 1906 | 95 | 10.2307/e24998669 | No. 3 JULY 21, 1906 pp. 41-60 | . 1906 | 95 | 10.2307/e24999881 | No. 2 JULY 14, 1906 pp. 21-40 | . 1906 | 95 | 10.2307/e26004869 | No. 1 JULY 7, 1906 pp. 3-20 | . 1906 | 94 | 10.2307/e26004841 | No. 26 JUNE 30, 1906 pp. 529-548 | . 1906 | 94 | 10.2307/e26004812 | No. 25 JUNE 23, 1906 pp. 509-528 | . 1906 | 94 | 10.2307/e24999216 | No. 24 JUNE 16, 1906 pp. 489-508 | . 1906 | 94 | 10.2307/e26004775 | No. 23 JUNE 9, 1906 pp. 469-488 | . 1906 | 94 | 10.2307/e24998464 | No. 22 JUNE 2, 1906 pp. 449-468 | . 1906 | 94 | 10.2307/e26004746 | No. 21 MAY 26, 1906 pp. 429-448 | . 1906 | 94 | 10.2307/e24999326 | No. 20 MAY 19, 1906 pp. 409-428 | . 1906 | 94 | 10.2307/e24998918 | No. 19 MAY 12, 1906 pp. 381-408 | . 1906 | 94 | 10.2307/e24999717 | No. 18 MAY 5, 1906 pp. 361-380 | . 1906 | 94 | 10.2307/e24997979 | No. 17 APRIL 28, 1906 pp. 341-360 | . 1906 | 94 | 10.2307/e26004721 | No. 16 APRIL 21, 1906 pp. 321-340 | . 1906 | 94 | 10.2307/e26004687 | No. 15 APRIL 14, 1906 pp. 301-320 | . 1906 | 94 | 10.2307/e24998366 | No. 14 APRIL 7, 1906 pp. 281-300 | . 1906 | 94 | 10.2307/e24998813 | No. 13 MARCH 31, 1906 pp. 265-280 | . 1906 | 94 | 10.2307/e24998048 | No. 12 MARCH 24, 1906 pp. 245-264 | . 1906 | 94 | 10.2307/e24999590 | No. 11 MARCH 17, 1906 pp. 225-244 | . 1906 | 94 | 10.2307/e24998159 | No. 10 MARCH 10, 1906 pp. 205-224 | . 1906 | 94 | 10.2307/e26004649 | No. 9 MARCH 3, 1906 pp. 185-204 | . 1906 | 94 | 10.2307/e26004614 | No. 8 FEBRUARY 24, 1906 pp. 165-184 | . 1906 | 94 | 10.2307/e24999430 | No. 7 FEBRUARY 17, 1906 pp. 145-164 | . 1906 | 94 | 10.2307/e24999027 | No. 6 FEBRUARY 10, 1906 pp. 125-144 | . 1906 | 94 | 10.2307/e24998579 | No. 5 FEBRUARY 3, 1906 pp. 105-124 | . 1906 | 94 | 10.2307/e24998262 | No. 4 JANUARY 27, 1906 pp. 85-104 | . 1906 | 94 | 10.2307/e24997919 | No. 3 JANUARY 20, 1906 pp. 65-84 | . 1906 | 94 | 10.2307/e26004561 | No. 2 JANUARY 13, 1906 pp. 21-64 | . 1906 | 94 | 10.2307/e26004121 | No. 1 JANUARY 6, 1906 pp. 3-20 | . 1905 | 93 | 10.2307/e24998633 | No. 27 DECEMBER 30, 1905 pp. 521-540 | . 1905 | 93 | 10.2307/e24999880 | No. 26 DECEMBER 23, 1905 pp. 501-520 | . 1905 | 93 | 10.2307/e24999017 | No. 25 DECEMBER 16, 1905 pp. 473-500 | . 1905 | 93 | 10.2307/e26004092 | No. 24 DECEMBER 9, 1905 pp. 453-472 | . 1905 | 93 | 10.2307/e26004068 | No. 23 DECEMBER 2, 1905 pp. 433-452 | . 1905 | 93 | 10.2307/e24999124 | No. 22 NOVEMBER 25, 1905 pp. 413-432 | . 1905 | 93 | 10.2307/e26004040 | No. 21 NOVEMBER 18, 1905 pp. 393-412 | . 1905 | 93 | 10.2307/e24998392 | No. 20 NOVEMBER 11, 1905 pp. 373-392 | . 1905 | 93 | 10.2307/e24999803 | No. 19 NOVEMBER 4, 1905 pp. 353-372 | . 1905 | 93 | 10.2307/e24999277 | No. 18 OCTOBER 28, 1905 pp. 333-352 | . 1905 | 93 | 10.2307/e26004005 | No. 17 OCTOBER 21, 1905 pp. 313-332 | . 1905 | 93 | 10.2307/e24999699 | No. 16 OCTOBER 14, 1905 pp. 293-312 | . 1905 | 93 | 10.2307/e24997945 | No. 15 OCTOBER 7, 1905 pp. 273-292 | . 1905 | 93 | 10.2307/e26003963 | No. 14 SEPTEMBER 30, 1905 pp. 253-272 | . 1905 | 93 | 10.2307/e26003930 | No. 13 SEPTEMBER 23, 1905 pp. 233-252 | . 1905 | 93 | 10.2307/e24998288 | No. 12 SEPTEMBER 16, 1905 pp. 213-232 | . 1905 | 93 | 10.2307/e24998730 | No. 11 SEPTEMBER 9, 1905 pp. 193-212 | . 1905 | 93 | 10.2307/e24998008 | No. 10 SEPTEMBER 2, 1905 pp. 173-192 | . 1905 | 93 | 10.2307/e24999553 | No. 9 AUGUST 26, 1905 pp. 153-172 | . 1905 | 93 | 10.2307/e24998096 | No. 8 AUGUST 19, 1905 pp. 133-152 | . 1905 | 93 | 10.2307/e26003903 | No. 7 AUGUST 12, 1905 pp. 117-132 | . 1905 | 93 | 10.2307/e26003868 | No. 6 AUGUST 5, 1905 pp. 97-116 | . 1905 | 93 | 10.2307/e26003830 | No. 5 JULY 29, 1905 pp. 77-96 | . 1905 | 93 | 10.2307/e24998954 | No. 4 JULY 22, 1905 pp. 61-76 | . 1905 | 93 | 10.2307/e24998486 | No. 3 JULY 15, 1905 pp. 41-60 | . 1905 | 93 | 10.2307/e24998192 | No. 2 JULY 8, 1905 pp. 21-40 | . 1905 | 93 | 10.2307/e24997913 | No. 1 JULY 1, 1905 pp. 3-20 | . 1905 | 92 | 10.2307/e26003801 | No. 25 JUNE 24, 1905 pp. 497-516 | . 1905 | 92 | 10.2307/e26003742 | No. 24 JUNE 17, 1905 pp. 477-496 | . 1905 | 92 | 10.2307/e24995421 | No. 23 JUNE 10, 1905 pp. 457-476 | . 1905 | 92 | 10.2307/e24995196 | No. 22 JUNE 3, 1905 pp. 437-456 | . 1905 | 92 | 10.2307/e24995508 | No. 21 MAY 27, 1905 pp. 417-436 | . 1905 | 92 | 10.2307/e24995474 | No. 20 MAY 20, 1905 pp. 397-416 | . 1905 | 92 | 10.2307/e24995230 | No. 19 MAY 13, 1905 pp. 377-396 | . 1905 | 92 | 10.2307/e24995658 | No. 18 MAY 6, 1905 pp. 357-376 | . 1905 | 92 | 10.2307/e24995041 | No. 17 APRIL 29, 1905 pp. 337-356 | . 1905 | 92 | 10.2307/e24995390 | No. 16 APRIL 22, 1905 pp. 317-336 | . 1905 | 92 | 10.2307/e24995256 | No. 15 APRIL 15, 1905 pp. 297-316 | . 1905 | 92 | 10.2307/e24995145 | No. 14 APRIL 8, 1905 pp. 277-296 | . 1905 | 92 | 10.2307/e24995358 | No. 13 APRIL 1, 1905 pp. 257-276 | . 1905 | 92 | 10.2307/e24994874 | No. 12 MARCH 25, 1905 pp. 237-256 | . 1905 | 92 | 10.2307/e24995582 | No. 11 MARCH 18, 1905 pp. 217-236 | . 1905 | 92 | 10.2307/e24995443 | No. 10 MARCH 11, 1905 pp. 197-216 | . 1905 | 92 | 10.2307/e24995009 | No. 9 MARCH 4, 1905 pp. 177-196 | . 1905 | 92 | 10.2307/e24995112 | No. 8 FEBRUARY 25, 1905 pp. 157-176 | . 1905 | 92 | 10.2307/e24994902 | No. 7 FEBRUARY 18, 1905 pp. 137-156 | . 1905 | 92 | 10.2307/e24995325 | No. 6 FEBRUARY 11, 1905 pp. 117-136 | . 1905 | 92 | 10.2307/e24994938 | No. 5 FEBRUARY 4, 1905 pp. 97-116 | . 1905 | 92 | 10.2307/e24995610 | No. 4 JANUARY 28, 1905 pp. 53-96 | . 1905 | 92 | 10.2307/e24995422 | No. 3 JANUARY 21, 1905 pp. 37-52 | . 1905 | 92 | 10.2307/e24995291 | No. 2 JANUARY 14, 1905 pp. 17-36 | . 1905 | 92 | 10.2307/e24995173 | No. 1 JANUARY 7, 1905 pp. 1-16 | . 1904 | 91 | 10.2307/e24995071 | No. 27 DECEMBER 31, 1904 pp. 473-492 | . 1904 | 91 | 10.2307/e24994974 | No. 26 DECEMBER 24, 1904 pp. 457-472 | . 1904 | 91 | 10.2307/e24994873 | No. 25 DECEMBER 17, 1904 pp. 425-456 | . 1904 | 91 | 10.2307/e24995541 | No. 24 DECEMBER 10, 1904 pp. 405-424 | . 1904 | 91 | 10.2307/e24993081 | No. 23 DECEMBER 3, 1904 pp. 389-404 | . 1904 | 91 | 10.2307/e24992956 | No. 22 NOVEMBER 26, 1904 pp. 369-388 | . 1904 | 91 | 10.2307/e24992825 | No. 21 NOVEMBER 19, 1904 pp. 349-368 | . 1904 | 91 | 10.2307/e24992688 | No. 20 NOVEMBER 12, 1904 pp. 329-348 | . 1904 | 91 | 10.2307/e24993150 | No. 19 NOVEMBER 5, 1904 pp. 309-328 | . 1904 | 91 | 10.2307/e24992515 | No. 18 OCTOBER 29, 1904 pp. 293-308 | . 1904 | 91 | 10.2307/e24992858 | No. 17 OCTOBER 22, 1904 pp. 277-292 | . 1904 | 91 | 10.2307/e24992629 | No. 16 OCTOBER 15, 1904 pp. 257-276 | . 1904 | 91 | 10.2307/e24993015 | No. 15 OCTOBER 8, 1904 pp. 241-256 | . 1904 | 91 | 10.2307/e24992991 | No. 14 OCTOBER 1, 1904 pp. 225-240 | . 1904 | 91 | 10.2307/e26003681 | No. 13 SEPTEMBER 24, 1904 pp. 209-224 | . 1904 | 91 | 10.2307/e24993183 | No. 12 SEPTEMBER 17, 1904 pp. 189-208 | . 1904 | 91 | 10.2307/e24992456 | No. 11 SEPTEMBER 10, 1904 pp. 173-188 | . 1904 | 91 | 10.2307/e24992795 | No. 10 SEPTEMBER 3, 1904 pp. 153-172 | . 1904 | 91 | 10.2307/e24992719 | No. 9 AUGUST 27, 1904 pp. 137-152 | . 1904 | 91 | 10.2307/e24992572 | No. 8 AUGUST 20, 1904 pp. 121-136 | . 1904 | 91 | 10.2307/e24992764 | No. 7 AUGUST 13, 1904 pp. 105-120 | . 1904 | 91 | 10.2307/e24992355 | No. 6 AUGUST 6, 1904 pp. 89-104 | . 1904 | 91 | 10.2307/e24993113 | No. 5 JULY 30, 1904 pp. 73-88 | . 1904 | 91 | 10.2307/e24992927 | No. 4 JULY 23, 1904 pp. 57-72 | . 1904 | 91 | 10.2307/e24992419 | No. 3 JULY 16, 1904 pp. 37-56 | . 1904 | 91 | 10.2307/e24992543 | No. 2 JULY 9, 1904 pp. 21-36 | . 1904 | 91 | 10.2307/e26003576 | No. 1 JULY 2, 1904 pp. 3-20 | . 1904 | 90 | 10.2307/e26003642 | No. 26 JUNE 25, 1904 pp. 489-507 | . 1904 | 90 | 10.2307/e24992388 | No. 25 JUNE 18, 1904 pp. 473-487 | . 1904 | 90 | 10.2307/e26003606 | No. 24 JUNE 11, 1904 pp. 453-471 | . 1904 | 90 | 10.2307/e24992883 | No. 23 JUNE 4, 1904 pp. 433-452 | . 1904 | 90 | 10.2307/e24992742 | No. 22 MAY 28, 1904 pp. 417-432 | . 1904 | 90 | 10.2307/e24992602 | No. 21 MAY 21, 1904 pp. 397-416 | . 1904 | 90 | 10.2307/e24992485 | No. 20 MAY 14, 1904 pp. 381-396 | . 1904 | 90 | 10.2307/e24992389 | No. 19 MAY 7, 1904 pp. 357-380 | . 1904 | 90 | 10.2307/e24992331 | No. 18 APRIL 30, 1904 pp. 341-356 | . 1904 | 90 | 10.2307/e24993044 | No. 17 APRIL 23, 1904 pp. 321-340 | . 1904 | 90 | 10.2307/e24988376 | No. 16 APRIL 16, 1904 pp. 305-320 | . 1904 | 90 | 10.2307/e24987892 | No. 15 APRIL 9, 1904 pp. 285-304 | . 1904 | 90 | 10.2307/e24988196 | No. 14 APRIL 2, 1904 pp. 265-284 | . 1904 | 90 | 10.2307/e24988057 | No. 13 MARCH 26, 1904 pp. 245-264 | . 1904 | 90 | 10.2307/e26003543 | No. 12 MARCH 19, 1904 pp. 225-244 | . 1904 | 90 | 10.2307/e24988273 | No. 11 MARCH 12, 1904 pp. 209-224 | . 1904 | 90 | 10.2307/e26003509 | No. 10 MARCH 5, 1904 pp. 189-208 | . 1904 | 90 | 10.2307/e24988444 | No. 9 FEBRUARY 27, 1904 pp. 169-188 | . 1904 | 90 | 10.2307/e24987826 | No. 8 FEBRUARY 20, 1904 pp. 149-168 | . 1904 | 90 | 10.2307/e26003481 | No. 7 FEBRUARY 13, 1904 pp. 129-147 | . 1904 | 90 | 10.2307/e24988093 | No. 6 FEBRUARY 6, 1904 pp. 113-128 | . 1904 | 90 | 10.2307/e24987958 | No. 5 JANUARY 30, 1904 pp. 73-112 | . 1904 | 90 | 10.2307/e24988194 | No. 4 JANUARY 23, 1904 pp. 57-72 | . 1904 | 90 | 10.2307/e24987660 | No. 3 JANUARY 16, 1904 pp. 37-56 | . 1904 | 90 | 10.2307/e24988342 | No. 2 JANUARY 9, 1904 pp. 21-36 | . 1904 | 90 | 10.2307/e26003451 | No. 1 JANUARY 2, 1904 pp. 3-20 | . 1903 | 89 | 10.2307/e24987795 | No. 26 DECEMBER 26, 1903 pp. 477-494 | . 1903 | 89 | 10.2307/e26003403 | No. 25 DECEMBER 19, 1903 pp. 457-476 | . 1903 | 89 | 10.2307/e24987697 | No. 24 DECEMBER 12, 1903 pp. 421-456 | . 1903 | 89 | 10.2307/e24988160 | No. 23 DECEMBER 5, 1903 pp. 401-420 | . 1903 | 89 | 10.2307/e24987726 | No. 22 NOVEMBER 28, 1903 pp. 381-400 | . 1903 | 89 | 10.2307/e24988408 | No. 21 NOVEMBER 21, 1903 pp. 365-380 | . 1903 | 89 | 10.2307/e24988229 | No. 20 NOVEMBER 14, 1903 pp. 337-364 | . 1903 | 89 | 10.2307/e24988129 | No. 19 NOVEMBER 7, 1903 pp. 321-336 | . 1903 | 89 | 10.2307/e24988024 | No. 18 OCTOBER 31, 1903 pp. 301-320 | . 1903 | 89 | 10.2307/e24987861 | No. 17 OCTOBER 24, 1903 pp. 285-300 | . 1903 | 89 | 10.2307/e24987757 | No. 16 OCTOBER 17, 1903 pp. 269-284 | . 1903 | 89 | 10.2307/e24987631 | No. 15 OCTOBER 10, 1903 pp. 253-268 | . 1903 | 89 | 10.2307/e24988297 | No. 14 OCTOBER 3, 1903 pp. 233-252 | . 1903 | 89 | 10.2307/e24985915 | No. 13 SEPTEMBER 26, 1903 pp. 213-232 | . 1903 | 89 | 10.2307/e24985377 | No. 12 SEPTEMBER 19, 1903 pp. 197-212 | . 1903 | 89 | 10.2307/e24986681 | No. 11 SEPTEMBER 12, 1903 pp. 181-196 | . 1903 | 89 | 10.2307/e24984743 | No. 10 SEPTEMBER 5, 1903 pp. 161-180 | . 1903 | 89 | 10.2307/e24986030 | No. 9 AUGUST 29, 1903 pp. 145-160 | . 1903 | 89 | 10.2307/e24985151 | No. 8 AUGUST 22, 1903 pp. 129-144 | . 1903 | 89 | 10.2307/e24986476 | No. 7 AUGUST 15, 1903 pp. 113-128 | . 1903 | 89 | 10.2307/e24986373 | No. 6 AUGUST 8, 1903 pp. 93-112 | . 1903 | 89 | 10.2307/e24985258 | No. 5 AUGUST 1, 1903 pp. 77-92 | . 1903 | 89 | 10.2307/e24986854 | No. 4 JULY 25, 1903 pp. 57-76 | . 1903 | 89 | 10.2307/e24984610 | No. 3 JULY 18, 1903 pp. 41-56 | . 1903 | 89 | 10.2307/e24985799 | No. 2 JULY 11, 1903 pp. 21-40 | . 1903 | 89 | 10.2307/e26003366 | No. 1 JULY 4, 1903 pp. 3-20 | . 1903 | 88 | 10.2307/e24984964 | No. 26 JUNE 27, 1903 pp. 479-498 | . 1903 | 88 | 10.2307/e24985731 | No. 25 JUNE 20, 1903 pp. 463-478 | . 1903 | 88 | 10.2307/e24984012 | No. 24 JUNE 13, 1903 pp. 443-462 | . 1903 | 88 | 10.2307/e24986582 | No. 23 JUNE 6, 1903 pp. 423-442 | . 1903 | 88 | 10.2307/e24986263 | No. 22 MAY 30, 1903 pp. 407-422 | . 1903 | 88 | 10.2307/e24984467 | No. 21 MAY 23, 1903 pp. 387-406 | . 1903 | 88 | 10.2307/e24984857 | No. 20 MAY 16, 1903 pp. 369-385 | . 1903 | 88 | 10.2307/e24984150 | No. 19 MAY 9, 1903 pp. 349-368 | . 1903 | 88 | 10.2307/e24985631 | No. 18 MAY 2, 1903 pp. 329-347 | . 1903 | 88 | 10.2307/e24984260 | No. 17 APRIL 25, 1903 pp. 309-328 | . 1903 | 88 | 10.2307/e24986728 | No. 16 APRIL 18, 1903 pp. 293-308 | . 1903 | 88 | 10.2307/e24986114 | No. 15 APRIL 11, 1903 pp. 253-292 | . 1903 | 88 | 10.2307/e24985491 | No. 14 APRIL 4, 1903 pp. 237-252 | . 1903 | 88 | 10.2307/e24985052 | No. 13 MARCH 28, 1903 pp. 219-236 | . 1903 | 88 | 10.2307/e24984685 | No. 12 MARCH 21, 1903 pp. 201-218 | . 1903 | 88 | 10.2307/e24984378 | No. 11 MARCH 14, 1903 pp. 185-200 | . 1903 | 88 | 10.2307/e24983907 | No. 10 MARCH 7, 1903 pp. 167-184 | . 1903 | 88 | 10.2307/e26003341 | No. 9 FEBRUARY 28, 1903 pp. 147-165 | . 1903 | 88 | 10.2307/e24986350 | No. 8 FEBRUARY 21, 1903 pp. 129-146 | . 1903 | 88 | 10.2307/e24986063 | No. 7 FEBRUARY 14, 1903 pp. 109-128 | . 1903 | 88 | 10.2307/e24985375 | No. 6 FEBRUARY 7, 1903 pp. 89-108 | . 1903 | 88 | 10.2307/e24986853 | No. 5 JANUARY 31, 1903 pp. 71-88 | . 1903 | 88 | 10.2307/e24984742 | No. 4 JANUARY 24, 1903 pp. 53-70 | . 1903 | 88 | 10.2307/e24986156 | No. 3 JANUARY 17, 1903 pp. 35-52 | . 1903 | 88 | 10.2307/e24985115 | No. 2 JANUARY 10, 1903 pp. 17-34 | . 1903 | 88 | 10.2307/e24986564 | No. 1 JANUARY 3, 1903 pp. 1-16 | . 1902 | 87 | 10.2307/e24986447 | No. 26 DECEMBER 27, 1902 pp. 457-476 | . 1902 | 87 | 10.2307/e24985223 | No. 25 DECEMBER 20, 1902 pp. 439-456 | . 1902 | 87 | 10.2307/e24987005 | No. 24 DECEMBER 13, 1902 pp. 387-438 | . 1902 | 87 | 10.2307/e24984514 | No. 23 DECEMBER 6, 1902 pp. 371-386 | . 1902 | 87 | 10.2307/e24985947 | No. 22 NOVEMBER 29, 1902 pp. 353-370 | . 1902 | 87 | 10.2307/e24985499 | No. 21 NOVEMBER 22, 1902 pp. 337-352 | . 1902 | 87 | 10.2307/e24984937 | No. 20 NOVEMBER 15, 1902 pp. 321-336 | . 1902 | 87 | 10.2307/e24985832 | No. 19 NOVEMBER 8, 1902 pp. 303-320 | . 1902 | 87 | 10.2307/e24983936 | No. 18 NOVEMBER 1, 1902 pp. 285-302 | . 1902 | 87 | 10.2307/e24986751 | No. 17 OCTOBER 25, 1902 pp. 267-284 | . 1902 | 87 | 10.2307/e24986247 | No. 16 OCTOBER 18, 1902 pp. 251-266 | . 1902 | 87 | 10.2307/e24984405 | No. 15 OCTOBER 11, 1902 pp. 233-250 | . 1902 | 87 | 10.2307/e24984820 | No. 14 OCTOBER 4, 1902 pp. 215-232 | . 1902 | 87 | 10.2307/e24984067 | No. 13 SEPTEMBER 27, 1902 pp. 197-214 | . 1902 | 87 | 10.2307/e24985740 | No. 12 SEPTEMBER 20, 1902 pp. 181-196 | . 1902 | 87 | 10.2307/e24984189 | No. 11 SEPTEMBER 13, 1902 pp. 165-180 | . 1902 | 87 | 10.2307/e24986906 | No. 10 SEPTEMBER 6, 1902 pp. 147-164 | . 1902 | 87 | 10.2307/e26002578 | No. 9 AUGUST 30, 1902 pp. 131-146 | . 1902 | 87 | 10.2307/e24985646 | No. 8 AUGUST 23, 1902 pp. 115-130 | . 1902 | 87 | 10.2307/e24985018 | No. 7 AUGUST 16, 1902 pp. 99-114 | . 1902 | 87 | 10.2307/e24984635 | No. 6 AUGUST 9, 1902 pp. 83-98 | . 1902 | 87 | 10.2307/e24984297 | No. 5 AUGUST 2, 1902 pp. 65-82 | . 1902 | 87 | 10.2307/e24983869 | No. 4 JULY 26, 1902 pp. 49-64 | . 1902 | 87 | 10.2307/e24986659 | No. 3 JULY 19, 1902 pp. 33-48 | . 1902 | 87 | 10.2307/e24986313 | No. 2 JULY 12, 1902 pp. 17-32 | . 1902 | 87 | 10.2307/e24985931 | No. 1 JULY 5, 1902 pp. 1-16 | . 1902 | 86 | 10.2307/e24985238 | No. 26 JUNE 28, 1902 pp. 443-460 | . 1902 | 86 | 10.2307/e24986855 | No. 25 JUNE 21, 1902 pp. 427-442 | . 1902 | 86 | 10.2307/e24984717 | No. 24 JUNE 14, 1902 pp. 409-425 | . 1902 | 86 | 10.2307/e24986037 | No. 23 JUNE 7, 1902 pp. 391-408 | . 1902 | 86 | 10.2307/e24985017 | No. 22 MAY 31, 1902 pp. 375-390 | . 1902 | 86 | 10.2307/e24986534 | No. 21 MAY 24, 1902 pp. 359-374 | . 1902 | 86 | 10.2307/e24986427 | No. 20 MAY 17, 1902 pp. 341-358 | . 1902 | 86 | 10.2307/e24985116 | No. 19 MAY 10, 1902 pp. 323-340 | . 1902 | 86 | 10.2307/e24987021 | No. 18 MAY 3, 1902 pp. 305-322 | . 1902 | 86 | 10.2307/e24984492 | No. 17 APRIL 26, 1902 pp. 287-304 | . 1902 | 86 | 10.2307/e24985833 | No. 16 APRIL 19, 1902 pp. 269-286 | . 1902 | 86 | 10.2307/e24985337 | No. 15 APRIL 12, 1902 pp. 251-268 | . 1902 | 86 | 10.2307/e24984882 | No. 14 APRIL 5 1902 pp. 233-250 | . 1902 | 86 | 10.2307/e24985732 | No. 13 MARCH 29, 1902 pp. 217-232 | . 1902 | 86 | 10.2307/e24983911 | No. 12 MARCH 22, 1902 pp. 199-216 | . 1902 | 86 | 10.2307/e24986752 | No. 11 MARCH 15, 1902 pp. 181-198 | . 1902 | 86 | 10.2307/e24986206 | No. 10 MARCH 8, 1902 pp. 165-180 | . 1902 | 86 | 10.2307/e24984340 | No. 9 MARCH 1, 1902 pp. 133-164 | . 1902 | 86 | 10.2307/e24984771 | No. 8 FEBRUARY 22, 1902 pp. 117-132 | . 1902 | 86 | 10.2307/e24984046 | No. 7 FEBRUARY 15, 1902 pp. 101-116 | . 1902 | 86 | 10.2307/e24985607 | No. 6 FEBRUARY 8, 1902 pp. 83-100 | . 1902 | 86 | 10.2307/e24984148 | No. 5 FEBRUARY 1, 1902 pp. 67-82 | . 1902 | 86 | 10.2307/e24986935 | No. 4 JANUARY 25, 1902 pp. 49-66 | . 1902 | 86 | 10.2307/e24986142 | No. 3 JANUARY 18, 1902 pp. 33-48 | . 1902 | 86 | 10.2307/e24985473 | No. 2 JANUARY 11, 1902 pp. 17-32 | . 1902 | 86 | 10.2307/e24984947 | No. 1 JANUARY 4, 1902 pp. 1-16 | . 1901 | 85 | 10.2307/e24984614 | No. 26 DECEMBER 28, 1901 pp. 421-440 | . 1901 | 85 | 10.2307/e24984253 | No. 25 DECEMBER 21, 1901 pp. 405-420 | . 1901 | 85 | 10.2307/e24983868 | No. 24 DECEMBER 14, 1901 pp. 373-406 | . 1901 | 85 | 10.2307/e24986655 | No. 23 DECEMBER 7, 1901 pp. 357-372 | . 1901 | 85 | 10.2307/e24982381 | No. 22 NOVEMBER 30, 1901 pp. 339-356 | . 1901 | 85 | 10.2307/e24981652 | No. 21 NOVEMBER 23, 1901 pp. 323-338 | . 1901 | 85 | 10.2307/e24980946 | No. 20 NOVEMBER 16, 1901 pp. 307-322 | . 1901 | 85 | 10.2307/e24982077 | No. 19 NOVEMBER 9, 1901 pp. 289-306 | . 1901 | 85 | 10.2307/e24982870 | No. 18 NOVEMBER 2, 1901 pp. 273-288 | . 1901 | 85 | 10.2307/e24981438 | No. 17 OCTOBER 26, 1901 pp. 257-272 | . 1901 | 85 | 10.2307/e24982475 | No. 16 OCTOBER 19, 1901 pp. 241-256 | . 1901 | 85 | 10.2307/e24983300 | No. 15 OCTOBER 12, 1901 pp. 225-240 | . 1901 | 85 | 10.2307/e24982293 | No. 14 OCTOBER 5, 1901 pp. 209-224 | . 1901 | 85 | 10.2307/e24983008 | No. 13 SEPTEMBER 28, 1901 pp. 193-208 | . 1901 | 85 | 10.2307/e24982678 | No. 12 SEPTEMBER 21, 1901 pp. 177-192 | . 1901 | 85 | 10.2307/e24982790 | No. 11 SEPTEMBER 14, 1901 pp. 161-176 | . 1901 | 85 | 10.2307/e24981269 | No. 10 SEPTEMBER 7, 1901 pp. 145-160 | . 1901 | 85 | 10.2307/e26121970 | No. 9 AUGUST 31, 1901 pp. 129-144 | . 1901 | 85 | 10.2307/e24982331 | No. 8 AUGUST 24, 1901 pp. 113-128 | . 1901 | 85 | 10.2307/e24983110 | No. 7 AUGUST 17, 1901 pp. 97-112 | . 1901 | 85 | 10.2307/e24981765 | No. 6 AUGUST 10, 1901 pp. 81-96 | . 1901 | 85 | 10.2307/e24982646 | No. 5 AUGUST 3, 1901 pp. 65-80 | . 1901 | 85 | 10.2307/e24981117 | No. 4 JULY 27, 1901 pp. 49-64 | . 1901 | 85 | 10.2307/e24983244 | No. 3 JULY 20, 1901 pp. 33-48 | . 1901 | 85 | 10.2307/e24981984 | No. 2 JULY 13, 1901 pp. 17-32 | . 1901 | 85 | 10.2307/e24982940 | No. 1 JULY 6, 1901 pp. 1-16 | . 1901 | 84 | 10.2307/e24981638 | No. 26 JUNE 29, 1901 pp. 401-418 | . 1901 | 84 | 10.2307/e24982533 | No. 25 JUNE 22, 1901 pp. 385-400 | . 1901 | 84 | 10.2307/e24980845 | No. 24 JUNE 15, 1901 pp. 369-384 | . 1901 | 84 | 10.2307/e24980924 | No. 23 JUNE 8, 1901 pp. 353-368 | . 1901 | 84 | 10.2307/e24982176 | No. 22 JUNE 1, 1901 pp. 337-352 | . 1901 | 84 | 10.2307/e24982939 | No. 21 MAY 25, 1901 pp. 321-336 | . 1901 | 84 | 10.2307/e24981530 | No. 20 MAY 18, 1901 pp. 305-320 | . 1901 | 84 | 10.2307/e24981038 | No. 19 MAY 11, 1901 pp. 289-304 | . 1901 | 84 | 10.2307/e24982212 | No. 18 MAY 4, 1901 pp. 273-288 | . 1901 | 84 | 10.2307/e24983198 | No. 17 APRIL 27, 1901 pp. 257-272 | . 1901 | 84 | 10.2307/e24981826 | No. 16 APRIL 20, 1901 pp. 241-256 | . 1901 | 84 | 10.2307/e24981188 | No. 15 APRIL 13, 1901 pp. 225-240 | . 1901 | 84 | 10.2307/e24982608 | No. 14 APRIL 6, 1901 pp. 209-224 | . 1901 | 84 | 10.2307/e24982101 | No. 13 MARCH 30, 1901 pp. 193-208 | . 1901 | 84 | 10.2307/e24981346 | No. 12 MARCH 23, 1901 pp. 177-192 | . 1901 | 84 | 10.2307/e24983125 | No. 11 MARCH 16, 1901 pp. 161-176 | . 1901 | 84 | 10.2307/e24982865 | No. 10 MARCH 9, 1901 pp. 145-160 | . 1901 | 84 | 10.2307/e24981964 | No. 9 MARCH 2, 1901 pp. 129-144 | . 1901 | 84 | 10.2307/e24980960 | No. 8 FEBRUARY 23, 1901 pp. 113-128 | . 1901 | 84 | 10.2307/e24982401 | No. 7 FEBRUARY 16, 1901 pp. 97-112 | . 1901 | 84 | 10.2307/e24983476 | No. 6 FEBRUARY 9, 1901 pp. 81-96 | . 1901 | 84 | 10.2307/e26124473 | No. 5 FEBRUARY 2, 1901 pp. 65-80 | . 1901 | 84 | 10.2307/e24981534 | No. 4 JANUARY 26, 1901 pp. 49-64 | . 1901 | 84 | 10.2307/e24982938 | No. 3 JANUARY 19, 1901 pp. 33-48 | . 1901 | 84 | 10.2307/e24983828 | No. 2 JANUARY 12, 1901 pp. 17-32 | . 1901 | 84 | 10.2307/e26003777 | No. 1 JANUARY 5, 1901 pp. 3-16 | . 1900 | 83 | 10.2307/e24983607 | No. 26 DECEMBER 29, 1900 pp. 401-420 | . 1900 | 83 | 10.2307/e24983341 | No. 25 DECEMBER 22, 1900 pp. 385-400 | . 1900 | 83 | 10.2307/e24983437 | No. 24 DECEMBER 15, 1900 pp. 369-384 | . 1900 | 83 | 10.2307/e26123724 | No. 23 DECEMBER 8, 1900 pp. 353-368 | . 1900 | 83 | 10.2307/e26122784 | No. 22 DECEMBER 1, 1900 pp. 337-352 | . 1900 | 83 | 10.2307/e26124236 | No. 21 NOVEMBER 24, 1900 pp. 321-336 | . 1900 | 83 | 10.2307/e24981333 | No. 20 NOVEMBER 17, 1900 pp. 305-320 | . 1900 | 83 | 10.2307/e26121163 | No. 19 NOVEMBER 10, 1900 pp. 289-304 | . 1900 | 83 | 10.2307/e24982770 | No. 18 NOVEMBER 3, 1900 pp. 273-288 | . 1900 | 83 | 10.2307/e26125642 | No. 17 OCTOBER 27, 1900 pp. 257-272 | . 1900 | 83 | 10.2307/e24983642 | No. 16 OCTOBER 20, 1900 pp. 241-256 | . 1900 | 83 | 10.2307/e24982079 | No. 15 OCTOBER 13, 1900 pp. 225-240 | . 1900 | 83 | 10.2307/e24983224 | No. 14 OCTOBER 6, 1900 pp. 209-224 | . 1900 | 83 | 10.2307/e24981150 | No. 13 SEPTEMBER 29, 1900 pp. 193-208 | . 1900 | 83 | 10.2307/e26125064 | No. 12 SEPTEMBER 22, 1900 pp. 177-192 | . 1900 | 83 | 10.2307/e26121766 | No. 11 SEPTEMBER 15, 1900 pp. 161-176 | . 1900 | 83 | 10.2307/e26122557 | No. 10 SEPTEMBER 8, 1900 pp. 145-160 | . 1900 | 83 | 10.2307/e24983778 | No. 9 SEPTEMBER 1, 1900 pp. 129-144 | . 1900 | 83 | 10.2307/e26121319 | No. 8 AUGUST 25, 1900 pp. 113-128 | . 1900 | 83 | 10.2307/e26124069 | No. 7 AUGUST 18, 1900 pp. 97-112 | . 1900 | 83 | 10.2307/e24982295 | No. 6 AUGUST 11, 1900 pp. 81-96 | . 1900 | 83 | 10.2307/e26121475 | No. 5 AUGUST 4, 1900 pp. 65-80 | . 1900 | 83 | 10.2307/e24983562 | No. 4 JULY 28, 1900 pp. 49-64 | . 1900 | 83 | 10.2307/e24981808 | No. 3 JULY 21, 1900 pp. 33-48 | . 1900 | 83 | 10.2307/e24983020 | No. 2 JULY 14, 1900 pp. 17-32 | . 1900 | 83 | 10.2307/e26125910 | No. 1 JULY 7, 1900 pp. 1-16 | . 1900 | 82 | 10.2307/e26124976 | No. 26 JUNE 30, 1900 pp. 401-416 | . 1900 | 82 | 10.2307/e26123868 | No. 25 JUNE 23, 1900 pp. 385-400 | . 1900 | 82 | 10.2307/e24980844 | No. 24 JUNE 16, 1900 pp. 369-384 | . 1900 | 82 | 10.2307/e24980883 | No. 23 JUNE 9, 1900 pp. 353-368 | . 1900 | 82 | 10.2307/e24982576 | No. 22 JUNE 2, 1900 pp. 337-352 | . 1900 | 82 | 10.2307/e26122966 | No. 21 MAY 26, 1900 pp. 321-336 | . 1900 | 82 | 10.2307/e26122139 | No. 20 MAY 19, 1900 pp. 305-320 | . 1900 | 82 | 10.2307/e24983522 | No. 19 MAY 12, 1900 pp. 289-304 | . 1900 | 82 | 10.2307/e24981650 | No. 18 MAY 5, 1900 pp. 273-288 | . 1900 | 82 | 10.2307/e24981070 | No. 17 APRIL 28, 1900 pp. 257-272 | . 1900 | 82 | 10.2307/e26121631 | No. 16 APRIL 21, 1900 pp. 241-256 | . 1900 | 82 | 10.2307/e24982650 | No. 15 APRIL 14, 1900 pp. 225-240 | . 1900 | 82 | 10.2307/e24983726 | No. 14 APRIL 7, 1900 pp. 209-224 | . 1900 | 82 | 10.2307/e24982174 | No. 13 MARCH 31, 1900 pp. 193-208 | . 1900 | 82 | 10.2307/e24981234 | No. 12 MARCH 24, 1900 pp. 177-192 | . 1900 | 82 | 10.2307/e24983124 | No. 11 MARCH 17, 1900 pp. 161-176 | . 1900 | 82 | 10.2307/e26121032 | No. 10 MARCH 10, 1900 pp. 145-160 | . 1900 | 82 | 10.2307/e26125493 | No. 9 MARCH 3, 1900 pp. 129-144 | . 1900 | 82 | 10.2307/e24982504 | No. 8 FEBRUARY 24, 1900 pp. 113-128 | . 1900 | 82 | 10.2307/e24981436 | No. 7 FEBRUARY 17, 1900 pp. 97-112 | . 1900 | 82 | 10.2307/e24983685 | No. 6 FEBRUARY 10, 1900 pp. 81-96 | . 1900 | 82 | 10.2307/e26122916 | No. 5 FEBRUARY 3, 1900 pp. 65-80 | . 1900 | 82 | 10.2307/e26121292 | No. 4 JANUARY 27, 1900 pp. 49-64 | . 1900 | 82 | 10.2307/e26123601 | No. 3 JANUARY 20, 1900 pp. 33-48 | . 1900 | 82 | 10.2307/e24971876 | No. 2 JANUARY 13, 1900 pp. 17-32 | . 1900 | 82 | 10.2307/e24973809 | No. 1 JANUARY 6, 1900 pp. 3-16 | . 1899 | 81 | 10.2307/e26125852 | No. 27 DECEMBER 30, 1899 pp. 417-432 | . 1899 | 81 | 10.2307/e26122356 | No. 26 DECEMBER 23, 1899 pp. 401-416 | . 1899 | 81 | 10.2307/e26124815 | No. 25 DECEMBER 16, 1899 pp. 385-400 | . 1899 | 81 | 10.2307/e26127318 | No. 24 DECEMBER 9, 1899 pp. 369-384 | . 1899 | 81 | 10.2307/e24973399 | No. 23 DECEMBER 2, 1899 pp. 353-368 | . 1899 | 81 | 10.2307/e26124408 | No. 22 NOVEMBER 25, 1899 pp. 337-352 | . 1899 | 81 | 10.2307/e26126424 | No. 21 NOVEMBER 18, 1899 pp. 321-336 | . 1899 | 81 | 10.2307/e24972595 | No. 20 NOVEMBER 11, 1899 pp. 305-320 | . 1899 | 81 | 10.2307/e26125541 | No. 19 NOVEMBER 4, 1899 pp. 289-304 | . 1899 | 81 | 10.2307/e24971879 | No. 18 OCTOBER 28, 1899 pp. 273-288 | . 1899 | 81 | 10.2307/e26125727 | No. 17 OCTOBER 21, 1899 pp. 257-272 | . 1899 | 81 | 10.2307/e24973032 | No. 16 OCTOBER 14, 1899 pp. 241-256 | . 1899 | 81 | 10.2307/e26121991 | No. 15 OCTOBER 7, 1899 pp. 225-240 | . 1899 | 81 | 10.2307/e26124584 | No. 14 SEPTEMBER 30, 1899 pp. 209-224 | . 1899 | 81 | 10.2307/e24973810 | No. 13 SEPTEMBER 23, 1899 pp. 193-208 | . 1899 | 81 | 10.2307/e26126595 | No. 12 SEPTEMBER 16, 1899 pp. 177-192 | . 1899 | 81 | 10.2307/e26123011 | No. 11 SEPTEMBER 9, 1899 pp. 161-176 | . 1899 | 81 | 10.2307/e26125402 | No. 10 SEPTEMBER 2, 1899 pp. 145-160 | . 1899 | 81 | 10.2307/e24972461 | No. 9 AUGUST 26, 1899 pp. 129-144 | . 1899 | 81 | 10.2307/e24973478 | No. 8 AUGUST 19, 1899 pp. 113-128 | . 1899 | 81 | 10.2307/e24974153 | No. 7 AUGUST 12, 1899 pp. 97-112 | . 1899 | 81 | 10.2307/e24973255 | No. 6 AUGUST 5, 1899 pp. 81-96 | . 1899 | 81 | 10.2307/e24973813 | No. 5 JULY 29, 1899 pp. 65-80 | . 1899 | 81 | 10.2307/e24973722 | No. 4 JULY 22, 1899 pp. 49-64 | . 1899 | 81 | 10.2307/e26121661 | No. 3 JULY 15, 1899 pp. 33-48 | . 1899 | 81 | 10.2307/e26127135 | No. 2 JULY 8, 1899 pp. 17-32 | . 1899 | 81 | 10.2307/e24973808 | No. 1 JULY 1, 1899 pp. 3-16 | . 1899 | 80 | 10.2307/e24972252 | No. 25 JUNE 24, 1899 pp. 403-418 | . 1899 | 80 | 10.2307/e26123420 | No. 24 JUNE 17, 1899 pp. 387-402 | . 1899 | 80 | 10.2307/e26126279 | No. 23 JUNE 10, 1899 pp. 371-386 | . 1899 | 80 | 10.2307/e26122664 | No. 22 JUNE 3, 1899 pp. 355-370 | . 1899 | 80 | 10.2307/e24973328 | No. 21 MAY 27, 1899 pp. 339-354 | . 1899 | 80 | 10.2307/e24973903 | No. 20 MAY 20, 1899 pp. 323-338 | . 1899 | 80 | 10.2307/e26125000 | No. 19 MAY 13, 1899 pp. 291-322 | . 1899 | 80 | 10.2307/e26121015 | No. 18 MAY 6, 1899 pp. 275-290 | . 1899 | 80 | 10.2307/e24972706 | No. 17 APRIL 29, 1899 pp. 259-274 | . 1899 | 80 | 10.2307/e24973653 | No. 16 APRIL 22, 1899 pp. 243-258 | . 1899 | 80 | 10.2307/e24972013 | No. 15 APRIL 15, 1899 pp. 227-242 | . 1899 | 80 | 10.2307/e24974066 | No. 14 APRIL 8, 1899 pp. 211-226 | . 1899 | 80 | 10.2307/e26121113 | No. 13 APRIL 1, 1899 pp. 193-210 | . 1899 | 80 | 10.2307/e26123992 | No. 12 MARCH 25, 1899 pp. 177-192 | . 1899 | 80 | 10.2307/e26126057 | No. 11 MARCH 18, 1899 pp. 161-176 | . 1899 | 80 | 10.2307/e26122479 | No. 10 MARCH 11, 1899 pp. 145-158 | . 1899 | 80 | 10.2307/e26121474 | No. 9 MARCH 4, 1899 pp. 129-144 | . 1899 | 80 | 10.2307/e24972917 | No. 8 FEBRUARY 25, 1899 pp. 113-128 | . 1899 | 80 | 10.2307/e26124193 | No. 7 FEBRUARY 18, 1899 pp. 97-112 | . 1899 | 80 | 10.2307/e26126913 | No. 6 FEBRUARY 11, 1899 pp. 81-96 | . 1899 | 80 | 10.2307/e26123188 | No. 5 FEBRUARY 4, 1899 pp. 65-80 | . 1899 | 80 | 10.2307/e26121797 | No. 4 JANUARY 28, 1899 pp. 49-64 | . 1899 | 80 | 10.2307/e26125247 | No. 3 JANUARY 21, 1899 pp. 33-48 | . 1899 | 80 | 10.2307/e26123822 | No. 2 JANUARY 14, 1899 pp. 17-32 | . 1899 | 80 | 10.2307/e26122140 | No. 1 JANUARY 7, 1899 pp. 3-16 | . 1898 | 79 | 10.2307/e26126780 | No. 27 DECEMBER 31, 1898 pp. 417-430 | . 1898 | 79 | 10.2307/e26117753 | No. 26 DECEMBER 24, 1898 pp. 401-414 | . 1898 | 79 | 10.2307/e26116996 | No. 25 DECEMBER 17, 1898 pp. 385-398 | . 1898 | 79 | 10.2307/e26119418 | No. 24 DECEMBER 10, 1898 pp. 369-380 | . 1898 | 79 | 10.2307/e26118956 | No. 23 DECEMBER 3, 1898 pp. 353-366 | . 1898 | 79 | 10.2307/e24973812 | No. 22 NOVEMBER 26, 1898 pp. 337-350 | . 1898 | 79 | 10.2307/e26116567 | No. 21 NOVEMBER 19, 1898 pp. 321-334 | . 1898 | 79 | 10.2307/e26120121 | No. 20 NOVEMBER 12, 1898 pp. 305-316 | . 1898 | 79 | 10.2307/e26119305 | No. 19 NOVEMBER 5, 1898 pp. 289-300 | . 1898 | 79 | 10.2307/e24972592 | No. 18 OCTOBER 29, 1898 pp. 273-286 | . 1898 | 79 | 10.2307/e26118049 | No. 17 OCTOBER 22, 1898 pp. 257-270 | . 1898 | 79 | 10.2307/e24973563 | No. 16 OCTOBER 15, 1898 pp. 241-254 | . 1898 | 79 | 10.2307/e26116874 | No. 15 OCTOBER 8, 1898 pp. 225-238 | . 1898 | 79 | 10.2307/e26118510 | No. 14 OCTOBER 1, 1898 pp. 209-222 | . 1898 | 79 | 10.2307/e26120177 | No. 13 SEPTEMBER 24, 1898 pp. 193-206 | . 1898 | 79 | 10.2307/e26117627 | No. 12 SEPTEMBER 17, 1898 pp. 177-190 | . 1898 | 79 | 10.2307/e26119508 | No. 11 SEPTEMBER 10, 1898 pp. 161-174 | . 1898 | 79 | 10.2307/e26120581 | No. 10 SEPTEMBER 3, 1898 pp. 145-158 | . 1898 | 79 | 10.2307/e24971877 | No. 9 AUGUST 27, 1898 pp. 129-142 | . 1898 | 79 | 10.2307/e26119075 | No. 8 AUGUST 20, 1898 pp. 113-126 | . 1898 | 79 | 10.2307/e26120394 | No. 7 AUGUST 13, 1898 pp. 97-110 | . 1898 | 79 | 10.2307/e24971878 | No. 6 AUGUST 6, 1898 pp. 81-92 | . 1898 | 79 | 10.2307/e26119884 | No. 5 JULY 30, 1898 pp. 65-78 | . 1898 | 79 | 10.2307/e26120039 | No. 4 JULY 23, 1898 pp. 49-62 | . 1898 | 79 | 10.2307/e26117431 | No. 3 JULY 16, 1898 pp. 33-46 | . 1898 | 79 | 10.2307/e26119199 | No. 2 JULY 9, 1898 pp. 17-30 | . 1898 | 79 | 10.2307/e24973248 | No. 1 JULY 2, 1898 pp. 3-12 | . 1898 | 78 | 10.2307/e24973811 | No. 26 JUNE 25, 1898 pp. 401-414 | . 1898 | 78 | 10.2307/e26120434 | No. 25 JUNE 18, 1898 pp. 385-398 | . 1898 | 78 | 10.2307/e26118160 | No. 24 JUNE 11, 1898 pp. 369-382 | . 1898 | 78 | 10.2307/e26070037 | No. 23 JUNE 4, 1898 pp. 353-364 | . 1898 | 78 | 10.2307/e26070003 | No. 22 MAY 28, 1898 pp. 337-350 | . 1898 | 78 | 10.2307/e24973252 | No. 21 MAY 21, 1898 pp. 321-334 | . 1898 | 78 | 10.2307/e26119789 | No. 20 MAY 14, 1898 pp. 305-318 | . 1898 | 78 | 10.2307/e26117202 | No. 19 MAY 7, 1898 pp. 289-300 | . 1898 | 78 | 10.2307/e26120547 | No. 18 APRIL 30, 1898 pp. 273-284 | . 1898 | 78 | 10.2307/e26118386 | No. 17 APRIL 23, 1898 pp. 257-270 | . 1898 | 78 | 10.2307/e26120330 | No. 16 APRIL 16, 1898 pp. 241-254 | . 1898 | 78 | 10.2307/e26117950 | No. 15 APRIL 9, 1898 pp. 225-238 | . 1898 | 78 | 10.2307/e26119599 | No. 14 APRIL 2, 1898 pp. 209-220 | . 1898 | 78 | 10.2307/e26116661 | No. 13 MARCH 26, 1898 pp. 193-206 | . 1898 | 78 | 10.2307/e26116770 | No. 12 MARCH 19, 1898 pp. 177-188 | . 1898 | 78 | 10.2307/e24974065 | No. 11 MARCH 12, 1898 pp. 161-174 | . 1898 | 78 | 10.2307/e26118723 | No. 10 MARCH 5, 1898 pp. 145-156 | . 1898 | 78 | 10.2307/e26120250 | No. 9 FEBRUARY 26, 1898 pp. 129-142 | . 1898 | 78 | 10.2307/e26117840 | No. 8 FEBRUARY 19, 1898 pp. 113-126 | . 1898 | 78 | 10.2307/e26117089 | No. 7 FEBRUARY 12, 1898 pp. 97-110 | . 1898 | 78 | 10.2307/e26118838 | No. 6 FEBRUARY 5, 1898 pp. 81-94 | . 1898 | 78 | 10.2307/e26120504 | No. 5 JANUARY 29, 1898 pp. 65-78 | . 1898 | 78 | 10.2307/e26118283 | No. 4 JANUARY 22, 1898 pp. 49-62 | . 1898 | 78 | 10.2307/e26117323 | No. 3 JANUARY 15, 1898 pp. 33-46 | . 1898 | 78 | 10.2307/e26119703 | No. 2 JANUARY 8, 1898 pp. 17-30 | . 1898 | 78 | 10.2307/e26118632 | No. 1 JANUARY 1, 1898 pp. 3-14 | . 1897 | 77 | 10.2307/e26117521 | No. 26 DECEMBER 25, 1897 pp. 401-416 | . 1897 | 77 | 10.2307/e26120471 | No. 25 DECEMBER 18, 1897 pp. 385-400 | . 1897 | 77 | 10.2307/e26124714 | No. 24 DECEMBER 11, 1897 pp. 369-384 | . 1897 | 77 | 10.2307/e26122788 | No. 23 DECEMBER 4, 1897 pp. 353-368 | . 1897 | 77 | 10.2307/e26121120 | No. 22 NOVEMBER 27, 1897 pp. 337-352 | . 1897 | 77 | 10.2307/e26123538 | No. 21 NOVEMBER 20, 1897 pp. 321-336 | . 1897 | 77 | 10.2307/e26126055 | No. 20 NOVEMBER 13, 1897 pp. 305-320 | . 1897 | 77 | 10.2307/e26122121 | No. 19 NOVEMBER 6, 1897 pp. 289-304 | . 1897 | 77 | 10.2307/e26124876 | No. 18 OCTOBER 30, 1897 pp. 273-288 | . 1897 | 77 | 10.2307/e26127287 | No. 17 OCTOBER 23, 1897 pp. 257-272 | . 1897 | 77 | 10.2307/e26124284 | No. 16 OCTOBER 16, 1897 pp. 241-256 | . 1897 | 77 | 10.2307/e26126561 | No. 15 OCTOBER 9, 1897 pp. 225-240 | . 1897 | 77 | 10.2307/e24972810 | No. 14 OCTOBER 2, 1897 pp. 209-224 | . 1897 | 77 | 10.2307/e26125561 | No. 13 SEPTEMBER 25, 1897 pp. 193-208 | . 1897 | 77 | 10.2307/e26125765 | No. 12 SEPTEMBER 18, 1897 pp. 177-192 | . 1897 | 77 | 10.2307/e26121768 | No. 11 SEPTEMBER 11, 1897 pp. 161-176 | . 1897 | 77 | 10.2307/e26124494 | No. 10 SEPTEMBER 4, 1897 pp. 145-160 | . 1897 | 77 | 10.2307/e24972141 | No. 9 AUGUST 28, 1897 pp. 129-144 | . 1897 | 77 | 10.2307/e26126697 | No. 8 AUGUST 21, 1897 pp. 113-128 | . 1897 | 77 | 10.2307/e24973564 | No. 7 AUGUST 14, 1897 pp. 97-112 | . 1897 | 77 | 10.2307/e26122970 | No. 6 AUGUST 7, 1897 pp. 81-96 | . 1897 | 77 | 10.2307/e24973141 | No. 5 JULY 31, 1897 pp. 65-80 | . 1897 | 77 | 10.2307/e26125366 | No. 4 JULY 24, 1897 pp. 49-64 | . 1897 | 77 | 10.2307/e26121376 | No. 3 JULY 17, 1897 pp. 33-48 | . 1897 | 77 | 10.2307/e26127173 | No. 2 JULY 10, 1897 pp. 17-32 | . 1897 | 77 | 10.2307/e26123394 | No. 1 JULY 3, 1897 pp. 3-16 | . 1897 | 76 | 10.2307/e26126349 | No. 26 JUNE 26, 1897 pp. 401-416 | . 1897 | 76 | 10.2307/e24972345 | No. 25 JUNE 19, 1897 pp. 385-400 | . 1897 | 76 | 10.2307/e26122554 | No. 24 JUNE 12, 1897 pp. 369-384 | . 1897 | 76 | 10.2307/e26125037 | No. 23 JUNE 5, 1897 pp. 353-368 | . 1897 | 76 | 10.2307/e26120986 | No. 22 MAY 29, 1897 pp. 337-352 | . 1897 | 76 | 10.2307/e26121031 | No. 21 MAY 22, 1897 pp. 321-336 | . 1897 | 76 | 10.2307/e26123891 | No. 20 MAY 15, 1897 pp. 305-320 | . 1897 | 76 | 10.2307/e26126236 | No. 19 MAY 8, 1897 pp. 289-304 | . 1897 | 76 | 10.2307/e26122370 | No. 18 MAY 1, 1897 pp. 273-288 | . 1897 | 76 | 10.2307/e26121242 | No. 17 APRIL 24, 1897 pp. 257-272 | . 1897 | 76 | 10.2307/e26124114 | No. 16 APRIL 17, 1897 pp. 241-256 | . 1897 | 76 | 10.2307/e26127000 | No. 15 APRIL 10, 1897 pp. 225-240 | . 1897 | 76 | 10.2307/e26123172 | No. 14 APRIL 3, 1897 pp. 209-224 | . 1897 | 76 | 10.2307/e26121552 | No. 13 MARCH 27, 1897 pp. 193-208 | . 1897 | 76 | 10.2307/e26125195 | No. 12 MARCH 20, 1897 pp. 177-192 | . 1897 | 76 | 10.2307/e26123738 | No. 11 MARCH 13, 1897 pp. 161-176 | . 1897 | 76 | 10.2307/e26121972 | No. 10 MARCH 6, 1897 pp. 145-160 | . 1897 | 76 | 10.2307/e26126825 | No. 9 FEBRUARY 27, 1897 pp. 129-144 | . 1897 | 76 | 10.2307/e26117514 | No. 8 FEBRUARY 20, 1897 pp. 113-128 | . 1897 | 76 | 10.2307/e26118939 | No. 7 FEBRUARY 13, 1897 pp. 97-112 | . 1897 | 76 | 10.2307/e26116784 | No. 6 FEBRUARY 6, 1897 pp. 81-96 | . 1897 | 76 | 10.2307/e26118214 | No. 5 JANUARY 30, 1897 pp. 65-80 | . 1897 | 76 | 10.2307/e26119928 | No. 4 JANUARY 23, 1897 pp. 49-64 | . 1897 | 76 | 10.2307/e26117997 | No. 3 JANUARY 16, 1897 pp. 33-48 | . 1897 | 76 | 10.2307/e24973981 | No. 2 JANUARY 9, 1897 pp. 17-32 | . 1897 | 76 | 10.2307/e26119315 | No. 1 JANUARY 2, 1897 pp. 3-16 | . 1896 | 75 | 10.2307/e24972966 | No. 26 DECEMBER 26, 1896 pp. 453-468 | . 1896 | 75 | 10.2307/e26118711 | No. 25 DECEMBER 19, 1896 pp. 437-452 | . 1896 | 75 | 10.2307/e26118837 | No. 24 DECEMBER 12, 1896 pp. 421-436 | . 1896 | 75 | 10.2307/e26116549 | No. 23 DECEMBER 5, 1896 pp. 405-420 | . 1896 | 75 | 10.2307/e26118089 | No. 22 NOVEMBER 28, 1896 pp. 389-404 | . 1896 | 75 | 10.2307/e26119396 | No. 21 NOVEMBER 21, 1896 pp. 373-388 | . 1896 | 75 | 10.2307/e26117166 | No. 20 NOVEMBER 14, 1896 pp. 357-372 | . 1896 | 75 | 10.2307/e26118577 | No. 19 NOVEMBER 7, 1896 pp. 341-356 | . 1896 | 75 | 10.2307/e26116359 | No. 18 OCTOBER 31, 1896 pp. 325-340 | . 1896 | 75 | 10.2307/e26119815 | No. 17 OCTOBER 24, 1896 pp. 309-324 | . 1896 | 75 | 10.2307/e26117409 | No. 16 OCTOBER 17, 1896 pp. 293-308 | . 1896 | 75 | 10.2307/e26119203 | No. 15 OCTOBER 10, 1896 pp. 277-292 | . 1896 | 75 | 10.2307/e26117035 | No. 14 OCTOBER 3, 1896 pp. 261-276 | . 1896 | 75 | 10.2307/e26118320 | No. 13 SEPTEMBER 26, 1896 pp. 245-260 | . 1896 | 75 | 10.2307/e26116116 | No. 12 SEPTEMBER 19, 1896 pp. 229-244 | . 1896 | 75 | 10.2307/e26116195 | No. 11 SEPTEMBER 12, 1896 pp. 213-228 | . 1896 | 75 | 10.2307/e26117769 | No. 10 SEPTEMBER 5, 1896 pp. 197-212 | . 1896 | 75 | 10.2307/e26119066 | No. 9 AUGUST 29, 1896 pp. 181-196 | . 1896 | 75 | 10.2307/e26116904 | No. 8 AUGUST 22, 1896 pp. 165-180 | . 1896 | 75 | 10.2307/e26116284 | No. 7 AUGUST 15, 1896 pp. 149-164 | . 1896 | 75 | 10.2307/e24972051 | No. 6 AUGUST 8, 1896 pp. 133-148 | . 1896 | 75 | 10.2307/e26117882 | No. 5 AUGUST 1, 1896 pp. 117-132 | . 1896 | 75 | 10.2307/e26119632 | No. 4 JULY 25, 1896 pp. 49-116 | . 1896 | 75 | 10.2307/e26117303 | No. 3 JULY 18, 1896 pp. 33-48 | . 1896 | 75 | 10.2307/e26116443 | No. 2 JULY 11, 1896 pp. 17-32 | . 1896 | 75 | 10.2307/e26118446 | No. 1 JULY 4, 1896 pp. 1-16 | . 1896 | 74 | 10.2307/e26117624 | No. 26 JUNE 27, 1896 pp. 401-416 | . 1896 | 74 | 10.2307/e26116668 | No. 25 JUNE 20, 1896 pp. 385-400 | . 1896 | 74 | 10.2307/e26119525 | No. 24 JUNE 13, 1896 pp. 369-384 | . 1896 | 74 | 10.2307/e26118547 | No. 23 JUNE 6, 1896 pp. 353-368 | . 1896 | 74 | 10.2307/e26117314 | No. 22 MAY 30, 1896 pp. 337-352 | . 1896 | 74 | 10.2307/e26116238 | No. 21 MAY 23, 1896 pp. 321-336 | . 1896 | 74 | 10.2307/e26117788 | No. 20 MAY 16, 1896 pp. 305-320 | . 1896 | 74 | 10.2307/e26119444 | No. 19 MAY 9, 1896 pp. 289-304 | . 1896 | 74 | 10.2307/e26116875 | No. 18 MAY 2, 1896 pp. 273-288 | . 1896 | 74 | 10.2307/e26118667 | No. 17 APRIL 25, 1896 pp. 257-271 | . 1896 | 74 | 10.2307/e24973364 | No. 16 APRIL 18, 1896 pp. 241-256 | . 1896 | 74 | 10.2307/e26120292 | No. 15 APRIL 11, 1896 pp. 225-240 | . 1896 | 74 | 10.2307/e26118290 | No. 14 APRIL 4, 1896 pp. 209-224 | . 1896 | 74 | 10.2307/e26119792 | No. 13 MARCH 28, 1896 pp. 193-208 | . 1896 | 74 | 10.2307/e26119201 | No. 12 MARCH 21, 1896 pp. 177-192 | . 1896 | 74 | 10.2307/e26119338 | No. 11 MARCH 14, 1896 pp. 161-176 | . 1896 | 74 | 10.2307/e26116597 | No. 10 MARCH 7, 1896 pp. 145-160 | . 1896 | 74 | 10.2307/e26118418 | No. 9 FEBRUARY 29, 1896 pp. 129-144 | . 1896 | 74 | 10.2307/e26119906 | No. 8 FEBRUARY 22, 1896 pp. 113-128 | . 1896 | 74 | 10.2307/e26117437 | No. 7 FEBRUARY 15, 1896 pp. 97-112 | . 1896 | 74 | 10.2307/e26119044 | No. 6 FEBRUARY 8, 1896 pp. 81-96 | . 1896 | 74 | 10.2307/e26116398 | No. 5 FEBRUARY 1, 1896 pp. 65-80 | . 1896 | 74 | 10.2307/e26120209 | No. 4 JANUARY 25, 1896 pp. 49-64 | . 1896 | 74 | 10.2307/e26117667 | No. 3 JANUARY 18, 1896 pp. 33-48 | . 1896 | 74 | 10.2307/e26119707 | No. 2 JANUARY 11, 1896 pp. 17-32 | . 1896 | 74 | 10.2307/e26117152 | No. 1 JANUARY 4, 1896 pp. 1-16 | . 1895 | 73 | 10.2307/e26118795 | No. 26 DECEMBER 28, 1895 pp. 401-416 | . 1895 | 73 | 10.2307/e26116089 | No. 25 DECEMBER 21, 1895 pp. 385-400 | . 1895 | 73 | 10.2307/e26116146 | No. 24 DECEMBER 14, 1895 pp. 369-384 | . 1895 | 73 | 10.2307/e26118019 | No. 23 DECEMBER 7, 1895 pp. 353-368 | . 1895 | 73 | 10.2307/e26119553 | No. 22 NOVEMBER 30, 1895 pp. 337-352 | . 1895 | 73 | 10.2307/e26171763 | No. 21 NOVEMBER 23, 1895 pp. 321-336 | . 1895 | 73 | 10.2307/e26117005 | No. 20 NOVEMBER 16, 1895 pp. 305-320 | . 1895 | 73 | 10.2307/e26116322 | No. 19 NOVEMBER 9, 1895 pp. 289-304 | . 1895 | 73 | 10.2307/e26118171 | No. 18 NOVEMBER 2, 1895 pp. 273-288 | . 1895 | 73 | 10.2307/e26120125 | No. 17 OCTOBER 26, 1895 pp. 257-272 | . 1895 | 73 | 10.2307/e26117548 | No. 16 OCTOBER 19, 1895 pp. 241-256 | . 1895 | 73 | 10.2307/e26116494 | No. 15 OCTOBER 12, 1895 pp. 225-240 | . 1895 | 73 | 10.2307/e26118897 | No. 14 OCTOBER 5, 1895 pp. 209-224 | . 1895 | 73 | 10.2307/e26117897 | No. 13 SEPTEMBER 28, 1895 pp. 193-208 | . 1895 | 73 | 10.2307/e26116713 | No. 12 SEPTEMBER 21, 1895 pp. 177-192 | . 1895 | 73 | 10.2307/e26120038 | No. 11 SEPTEMBER 14, 1895 pp. 161-176 | . 1895 | 73 | 10.2307/e26114486 | No. 10 SEPTEMBER 7, 1895 pp. 145-160 | . 1895 | 73 | 10.2307/e26113493 | No. 9 AUGUST 31, 1895 pp. 129-144 | . 1895 | 73 | 10.2307/e26112593 | No. 8 AUGUST 24, 1895 pp. 113-128 | . 1895 | 73 | 10.2307/e26113868 | No. 7 AUGUST 17, 1895 pp. 97-112 | . 1895 | 73 | 10.2307/e26115226 | No. 6 AUGUST 10, 1895 pp. 81-96 | . 1895 | 73 | 10.2307/e26113193 | No. 5 AUGUST 3, 1895 pp. 65-80 | . 1895 | 73 | 10.2307/e26114567 | No. 4 JULY 27, 1895 pp. 49-64 | . 1895 | 73 | 10.2307/e26115929 | No. 3 JULY 20, 1895 pp. 33-48 | . 1895 | 73 | 10.2307/e26114264 | No. 2 JULY 13, 1895 pp. 17-32 | . 1895 | 73 | 10.2307/e26115528 | No. 1 JULY 6, 1895 pp. 1-16 | . 1895 | 72 | 10.2307/e26114994 | No. 26 JUNE 29, 1895 pp. 401-416 | . 1895 | 72 | 10.2307/e26115094 | No. 25 JUNE 22, 1895 pp. 385-400 | . 1895 | 72 | 10.2307/e26112987 | No. 24 JUNE 15, 1895 pp. 369-384 | . 1895 | 72 | 10.2307/e26114380 | No. 23 JUNE 8, 1895 pp. 353-368 | . 1895 | 72 | 10.2307/e26115624 | No. 22 JUNE 1, 1895 pp. 337-352 | . 1895 | 72 | 10.2307/e26113580 | No. 21 MAY 25, 1895 pp. 321-336 | . 1895 | 72 | 10.2307/e26114868 | No. 20 MAY 18, 1895 pp. 305-320 | . 1895 | 72 | 10.2307/e26112805 | No. 19 MAY 11, 1895 pp. 289-304 | . 1895 | 72 | 10.2307/e26115887 | No. 18 MAY 4, 1895 pp. 273-288 | . 1895 | 72 | 10.2307/e26113750 | No. 17 APRIL 27, 1895 pp. 257-272 | . 1895 | 72 | 10.2307/e26115425 | No. 16 APRIL 20, 1895 pp. 241-256 | . 1895 | 72 | 10.2307/e26113399 | No. 15 APRIL 13, 1895 pp. 225-240 | . 1895 | 72 | 10.2307/e26114670 | No. 14 APRIL 6, 1895 pp. 209-224 | . 1895 | 72 | 10.2307/e26112389 | No. 13 MARCH 30, 1895 pp. 193-208 | . 1895 | 72 | 10.2307/e26112482 | No. 12 MARCH 23, 1895 pp. 177-192 | . 1895 | 72 | 10.2307/e26114060 | No. 11 MARCH 16, 1895 pp. 161-176 | . 1895 | 72 | 10.2307/e26115305 | No. 10 MARCH 9, 1895 pp. 145-160 | . 1895 | 72 | 10.2307/e26113290 | No. 9 MARCH 2, 1895 pp. 129-144 | . 1895 | 72 | 10.2307/e26112697 | No. 8 FEBRUARY 23, 1895 pp. 113-128 | . 1895 | 72 | 10.2307/e26114165 | No. 7 FEBRUARY 16, 1895 pp. 97-112 | . 1895 | 72 | 10.2307/e26115784 | No. 6 FEBRUARY 9, 1895 pp. 81-96 | . 1895 | 72 | 10.2307/e26113659 | No. 5 FEBRUARY 2, 1895 pp. 65-80 | . 1895 | 72 | 10.2307/e26112896 | No. 4 JANUARY 26, 1895 pp. 49-64 | . 1895 | 72 | 10.2307/e26114777 | No. 3 JANUARY 19, 1895 pp. 33-48 | . 1895 | 72 | 10.2307/e26113959 | No. 2 JANUARY 12, 1895 pp. 17-32 | . 1895 | 72 | 10.2307/e26113089 | No. 1 JANUARY 5, 1895 pp. 1-16 | . 1894 | 71 | 10.2307/e26115701 | No. 26 DECEMBER 29, 1894 pp. 401-416 | . 1894 | 71 | 10.2307/e26113140 | No. 25 DECEMBER 22, 1894 pp. 385-400 | . 1894 | 71 | 10.2307/e26113244 | No. 24 DECEMBER 15, 1894 pp. 369-384 | . 1894 | 71 | 10.2307/e26112388 | No. 23 DECEMBER 8, 1894 pp. 353-368 | . 1894 | 71 | 10.2307/e26113581 | No. 22 DECEMBER 1, 1894 pp. 337-352 | . 1894 | 71 | 10.2307/e26114896 | No. 21 NOVEMBER 24, 1894 pp. 321-336 | . 1894 | 71 | 10.2307/e26112935 | No. 20 NOVEMBER 17, 1894 pp. 305-320 | . 1894 | 71 | 10.2307/e26114261 | No. 19 NOVEMBER 10, 1894 pp. 289-304 | . 1894 | 71 | 10.2307/e26115719 | No. 18 NOVEMBER 3, 1894 pp. 273-288 | . 1894 | 71 | 10.2307/e26114071 | No. 17 OCTOBER 27, 1894 pp. 257-272 | . 1894 | 71 | 10.2307/e26115233 | No. 16 OCTOBER 20, 1894 pp. 241-256 | . 1894 | 71 | 10.2307/e26114675 | No. 15 OCTOBER 13, 1894 pp. 225-240 | . 1894 | 71 | 10.2307/e26114787 | No. 14 OCTOBER 6, 1894 pp. 209-224 | . 1894 | 71 | 10.2307/e26112752 | No. 13 SEPTEMBER 29, 1894 pp. 193-208 | . 1894 | 71 | 10.2307/e26114168 | No. 12 SEPTEMBER 22, 1894 pp. 177-192 | . 1894 | 71 | 10.2307/e26115324 | No. 11 SEPTEMBER 15, 1894 pp. 161-176 | . 1894 | 71 | 10.2307/e26113349 | No. 10 SEPTEMBER 8, 1894 pp. 145-160 | . 1894 | 71 | 10.2307/e26114579 | No. 9 SEPTEMBER 1, 1894 pp. 129-144 | . 1894 | 71 | 10.2307/e26112561 | No. 8 AUGUST 25, 1894 pp. 113-128 | . 1894 | 71 | 10.2307/e26115632 | No. 7 AUGUST 18, 1894 pp. 97-112 | . 1894 | 71 | 10.2307/e26113538 | No. 6 AUGUST 11, 1894 pp. 81-96 | . 1894 | 71 | 10.2307/e26115118 | No. 5 AUGUST 4, 1894 pp. 65-80 | . 1894 | 71 | 10.2307/e26113867 | No. 4 JULY 28, 1894 pp. 49-64 | . 1894 | 71 | 10.2307/e26114379 | No. 3 JULY 21, 1894 pp. 33-48 | . 1894 | 71 | 10.2307/e26112294 | No. 2 JULY 14, 1894 pp. 17-32 | . 1894 | 71 | 10.2307/e26112345 | No. 1 JULY 7, 1894 pp. 1-16 | . 1894 | 70 | 10.2307/e26113765 | No. 25 JUNE 23, 1894 pp. 385-400 | . 1894 | 70 | 10.2307/e26115019 | No. 24 JUNE 16, 1894 pp. 369-384 | . 1894 | 70 | 10.2307/e26113038 | No. 23 JUNE 9, 1894 pp. 353-368 | . 1894 | 70 | 10.2307/e26112476 | No. 22 JUNE 2, 1894 pp. 337-352 | . 1894 | 70 | 10.2307/e26113968 | No. 21 MAY 26, 1894 pp. 321-336 | . 1894 | 70 | 10.2307/e26115526 | No. 20 MAY 19, 1894 pp. 305-320 | . 1894 | 70 | 10.2307/e26113448 | No. 19 MAY 12, 1894 pp. 289-304 | . 1894 | 70 | 10.2307/e26112645 | No. 18 MAY 5, 1894 pp. 273-288 | . 1894 | 70 | 10.2307/e26114493 | No. 17 APRIL 28, 1894 pp. 257-272 | . 1894 | 70 | 10.2307/e26113675 | No. 16 APRIL 21, 1894 pp. 241-256 | . 1894 | 70 | 10.2307/e26112861 | No. 15 APRIL 14, 1894 pp. 225-240 | . 1894 | 70 | 10.2307/e26115424 | No. 14 APRIL 7, 1894 pp. 209-224 | . 1894 | 70 | 10.2307/e26111203 | No. 13 MARCH 31, 1894 pp. 193-208 | . 1894 | 70 | 10.2307/e26110767 | No. 12 MARCH 24, 1894 pp. 177-192 | . 1894 | 70 | 10.2307/e26110317 | No. 11 MARCH 17, 1894 pp. 161-176 | . 1894 | 70 | 10.2307/e26110983 | No. 10 MARCH 10, 1894 pp. 145-160 | . 1894 | 70 | 10.2307/e26111533 | No. 9 MARCH 3, 1894 pp. 129-144 | . 1894 | 70 | 10.2307/e26110612 | No. 8 FEBRUARY 24, 1894 pp. 113-128 | . 1894 | 70 | 10.2307/e26111248 | No. 7 FEBRUARY 17, 1894 pp. 97-112 | . 1894 | 70 | 10.2307/e26111887 | No. 6 FEBRUARY 10, 1894 pp. 81-96 | . 1894 | 70 | 10.2307/e26111120 | No. 5 FEBRUARY 3, 1894 pp. 65-80 | . 1894 | 70 | 10.2307/e26111660 | No. 4 JANUARY 27, 1894 pp. 49-64 | . 1894 | 70 | 10.2307/e26111427 | No. 3 JANUARY 20, 1894 pp. 33-48 | . 1894 | 70 | 10.2307/e26111492 | No. 2 JANUARY 13, 1894 pp. 17-32 | . 1894 | 70 | 10.2307/e26110533 | No. 1 JANUARY 6, 1894 pp. 1-16 | . 1893 | 69 | 10.2307/e26111171 | No. 27 DECEMBER 30, 1893 pp. 417-432 | . 1893 | 69 | 10.2307/e26111711 | No. 26 DECEMBER 23, 1893 pp. 401-416 | . 1893 | 69 | 10.2307/e26110812 | No. 25 DECEMBER 16, 1893 pp. 385-400 | . 1893 | 69 | 10.2307/e26111383 | No. 24 DECEMBER 9, 1893 pp. 369-384 | . 1893 | 69 | 10.2307/e26110420 | No. 23 DECEMBER 2, 1893 pp. 353-368 | . 1893 | 69 | 10.2307/e26111838 | No. 22 NOVEMBER 25, 1893 pp. 337-352 | . 1893 | 69 | 10.2307/e26110926 | No. 21 NOVEMBER 18, 1893 pp. 321-336 | . 1893 | 69 | 10.2307/e26111623 | No. 20 NOVEMBER 11, 1893 pp. 305-320 | . 1893 | 69 | 10.2307/e26110726 | No. 19 NOVEMBER 4, 1893 pp. 289-304 | . 1893 | 69 | 10.2307/e26111298 | No. 18 OCTOBER 28, 1893 pp. 273-288 | . 1893 | 69 | 10.2307/e26110223 | No. 17 OCTOBER 21, 1893 pp. 257-272 | . 1893 | 69 | 10.2307/e26110262 | No. 16 OCTOBER 14, 1893 pp. 241-256 | . 1893 | 69 | 10.2307/e26111047 | No. 15 OCTOBER 7, 1893 pp. 225-240 | . 1893 | 69 | 10.2307/e26111577 | No. 14 SEPTEMBER 30, 1893 pp. 209-224 | . 1893 | 69 | 10.2307/e26110656 | No. 13 SEPTEMBER 23, 1893 pp. 193-208 | . 1893 | 69 | 10.2307/e26110366 | No. 12 SEPTEMBER 16, 1893 pp. 177-192 | . 1893 | 69 | 10.2307/e26111082 | No. 11 SEPTEMBER 9, 1893 pp. 161-176 | . 1893 | 69 | 10.2307/e26111793 | No. 10 SEPTEMBER 2, 1893 pp. 145-160 | . 1893 | 69 | 10.2307/e26110870 | No. 9 AUGUST 26, 1893 pp. 129-144 | . 1893 | 69 | 10.2307/e26110484 | No. 8 AUGUST 19, 1893 pp. 113-128 | . 1893 | 69 | 10.2307/e26111341 | No. 7 AUGUST 12, 1893 pp. 97-112 | . 1893 | 69 | 10.2307/e26111015 | No. 6 AUGUST 5, 1893 pp. 81-96 | . 1893 | 69 | 10.2307/e26110581 | No. 5 JULY 29, 1893 pp. 65-80 | . 1893 | 69 | 10.2307/e26111762 | No. 4 JULY 22, 1893 pp. 49-64 | . 1893 | 69 | 10.2307/e26109549 | No. 3 JULY 15, 1893 pp. 33-48 | . 1893 | 69 | 10.2307/e26108747 | No. 2 JULY 8, 1893 pp. 17-32 | . 1893 | 69 | 10.2307/e26108013 | No. 1 JULY 1, 1893 pp. 1-16 | . 1893 | 68 | 10.2307/e26109094 | No. 25 JUNE 24, 1893 pp. 385-400 | . 1893 | 68 | 10.2307/e26109840 | No. 24 JUNE 17, 1893 pp. 369-384 | . 1893 | 68 | 10.2307/e26108500 | No. 23 JUNE 10, 1893 pp. 353-368 | . 1893 | 68 | 10.2307/e26109590 | No. 22 JUNE 3, 1893 pp. 337-352 | . 1893 | 68 | 10.2307/e26110181 | No. 21 MAY 27, 1893 pp. 321-336 | . 1893 | 68 | 10.2307/e26109435 | No. 20 MAY 20, 1893 pp. 305-320 | . 1893 | 68 | 10.2307/e26109974 | No. 19 MAY 13, 1893 pp. 289-304 | . 1893 | 68 | 10.2307/e26109767 | No. 18 MAY 6, 1893 pp. 273-288 | . 1893 | 68 | 10.2307/e26109808 | No. 17 APRIL 29, 1893 pp. 257-272 | . 1893 | 68 | 10.2307/e26108315 | No. 16 APRIL 22, 1893 pp. 241-256 | . 1893 | 68 | 10.2307/e26109514 | No. 15 APRIL 15, 1893 pp. 225-240 | . 1893 | 68 | 10.2307/e26110010 | No. 14 APRIL 8, 1893 pp. 209-224 | . 1893 | 68 | 10.2307/e26108833 | No. 13 APRIL 1, 1893 pp. 193-208 | . 1893 | 68 | 10.2307/e26109720 | No. 12 MARCH 25, 1893 pp. 178-192 | . 1893 | 68 | 10.2307/e26108157 | No. 11 MARCH 18, 1893 pp. 161-176 | . 1893 | 68 | 10.2307/e26110141 | No. 10 MARCH 11, 1893 pp. 145-160 | . 1893 | 68 | 10.2307/e26109016 | No. 9 MARCH 4, 1893 pp. 129-144 | . 1893 | 68 | 10.2307/e26109929 | No. 8 FEBRUARY 25, 1893 pp. 113-128 | . 1893 | 68 | 10.2307/e26108666 | No. 7 FEBRUARY 18, 1893 pp. 97-112 | . 1893 | 68 | 10.2307/e26109632 | No. 6 FEBRUARY 11, 1893 pp. 81-96 | . 1893 | 68 | 10.2307/e26107822 | No. 5 FEBRUARY 4, 1893 pp. 65-80 | . 1893 | 68 | 10.2307/e26107921 | No. 4 JANUARY 28, 1893 pp. 49-64 | . 1893 | 68 | 10.2307/e26109270 | No. 3 JANUARY 21, 1893 pp. 33-48 | . 1893 | 68 | 10.2307/e26109887 | No. 2 JANUARY 14, 1893 pp. 17-32 | . 1893 | 68 | 10.2307/e26108602 | No. 1 JANUARY 7, 1893 pp. 1-16 | . 1892 | 67 | 10.2307/e26108098 | No. 27 DECEMBER 31, 1892 pp. 415-428 | . 1892 | 67 | 10.2307/e26109372 | No. 26 DECEMBER 24, 1892 pp. 399-414 | . 1892 | 67 | 10.2307/e26110094 | No. 25 DECEMBER 17, 1892 pp. 383-398 | . 1892 | 67 | 10.2307/e26108918 | No. 24 DECEMBER 10, 1892 pp. 367-382 | . 1892 | 67 | 10.2307/e26108228 | No. 23 DECEMBER 3, 1892 pp. 351-366 | . 1892 | 67 | 10.2307/e26109672 | No. 22 NOVEMBER 26, 1892 pp. 335-350 | . 1892 | 67 | 10.2307/e26109180 | No. 21 NOVEMBER 19, 1892 pp. 319-334 | . 1892 | 67 | 10.2307/e26108410 | No. 20 NOVEMBER 12, 1892 pp. 303-318 | . 1892 | 67 | 10.2307/e26110053 | No. 19 NOVEMBER 5, 1892 pp. 287-302 | . 1892 | 67 | 10.2307/e26108102 | No. 18 OCTOBER 29, 1892 pp. 271-286 | . 1892 | 67 | 10.2307/e26107548 | No. 17 OCTOBER 22, 1892 pp. 255-270 | . 1892 | 67 | 10.2307/e26107131 | No. 16 OCTOBER 15, 1892 pp. 239-254 | . 1892 | 67 | 10.2307/e26107697 | No. 15 OCTOBER 8, 1892 pp. 223-238 | . 1892 | 67 | 10.2307/e26108712 | No. 14 OCTOBER 1, 1892 pp. 207-222 | . 1892 | 67 | 10.2307/e26107397 | No. 13 SEPTEMBER 24, 1892 pp. 191-206 | . 1892 | 67 | 10.2307/e26108189 | No. 12 SEPTEMBER 17, 1892 pp. 175-190 | . 1892 | 67 | 10.2307/e26109436 | No. 11 SEPTEMBER 10, 1892 pp. 159-174 | . 1892 | 67 | 10.2307/e26107927 | No. 10 SEPTEMBER 3, 1892 pp. 143-158 | . 1892 | 67 | 10.2307/e26108974 | No. 9 AUGUST 27, 1892 pp. 127-142 | . 1892 | 67 | 10.2307/e26108561 | No. 8 AUGUST 20, 1892 pp. 111-126 | . 1892 | 67 | 10.2307/e26108628 | No. 7 AUGUST 13, 1892 pp. 95-110 | . 1892 | 67 | 10.2307/e26107315 | No. 6 AUGUST 6, 1892 pp. 79-94 | . 1892 | 67 | 10.2307/e26108015 | No. 5 JULY 30, 1892 pp. 63-78 | . 1892 | 67 | 10.2307/e26109060 | No. 4 JULY 23, 1892 pp. 47-62 | . 1892 | 67 | 10.2307/e26107585 | No. 3 JULY 16, 1892 pp. 31-46 | . 1892 | 67 | 10.2307/e26108449 | No. 2 JULY 9, 1892 pp. 15-30 | . 1892 | 67 | 10.2307/e26107222 | No. 1 JULY 2, 1892 pp. 1-14 | . 1892 | 66 | 10.2307/e26109361 | No. 26 JUNE 25, 1892 pp. 399-414 | . 1892 | 66 | 10.2307/e26107660 | No. 25 JUNE 18, 1892 pp. 383-398 | . 1892 | 66 | 10.2307/e26108884 | No. 24 JUNE 11, 1892 pp. 367-382 | . 1892 | 66 | 10.2307/e26107505 | No. 23 JUNE 4, 1892 pp. 351-366 | . 1892 | 66 | 10.2307/e26108270 | No. 22 MAY 28, 1892 pp. 335-350 | . 1892 | 66 | 10.2307/e26107063 | No. 21 MAY 21, 1892 pp. 319-334 | . 1892 | 66 | 10.2307/e26107096 | No. 20 MAY 14, 1892 pp. 303-318 | . 1892 | 66 | 10.2307/e26107788 | No. 19 MAY 7, 1892 pp. 287-302 | . 1892 | 66 | 10.2307/e26108789 | No. 18 APRIL 30, 1892 pp. 271-286 | . 1892 | 66 | 10.2307/e26107460 | No. 17 APRIL 23, 1892 pp. 255-270 | . 1892 | 66 | 10.2307/e26107170 | No. 16 APRIL 16, 1892 pp. 239-254 | . 1892 | 66 | 10.2307/e26107840 | No. 15 APRIL 9, 1892 pp. 223-238 | . 1892 | 66 | 10.2307/e26109259 | No. 14 APRIL 2, 1892 pp. 207-222 | . 1892 | 66 | 10.2307/e26107624 | No. 13 MARCH 26, 1892 pp. 191-206 | . 1892 | 66 | 10.2307/e26107271 | No. 12 MARCH 19, 1892 pp. 175-190 | . 1892 | 66 | 10.2307/e26108377 | No. 11 MARCH 12, 1892 pp. 159-174 | . 1892 | 66 | 10.2307/e26107742 | No. 10 MARCH 5, 1892 pp. 143-158 | . 1892 | 66 | 10.2307/e26107353 | No. 9 FEBRUARY 27, 1892 pp. 127-142 | . 1892 | 66 | 10.2307/e26109158 | No. 8 FEBRUARY 20, 1892 pp. 111-126 | . 1892 | 66 | 10.2307/e26105228 | No. 7 FEBRUARY 13, 1892 pp. 95-110 | . 1892 | 66 | 10.2307/e26104719 | No. 6 FEBRUARY 6, 1892 pp. 79-94 | . 1892 | 66 | 10.2307/e26104303 | No. 5 JANUARY 30, 1892 pp. 63-78 | . 1892 | 66 | 10.2307/e26104922 | No. 4 JANUARY 23, 1892 pp. 47-62 | . 1892 | 66 | 10.2307/e26105545 | No. 3 JANUARY 16, 1892 pp. 31-46 | . 1892 | 66 | 10.2307/e26104574 | No. 2 JANUARY 9, 1892 pp. 15-30 | . 1892 | 66 | 10.2307/e26105271 | No. 1 JANUARY 2, 1892 pp. 1-14 | . 1891 | 65 | 10.2307/e26105887 | No. 26 DECEMBER 26, 1891 pp. 399-414 | . 1891 | 65 | 10.2307/e26105127 | No. 25 DECEMBER 19, 1891 pp. 383-398 | . 1891 | 65 | 10.2307/e26105709 | No. 24 DECEMBER 12, 1891 pp. 367-382 | . 1891 | 65 | 10.2307/e26105447 | No. 23 DECEMBER 5, 1891 pp. 351-366 | . 1891 | 65 | 10.2307/e26105498 | No. 22 NOVEMBER 28, 1891 pp. 335-350 | . 1891 | 65 | 10.2307/e26104474 | No. 21 NOVEMBER 21, 1891 pp. 319-334 | . 1891 | 65 | 10.2307/e26105175 | No. 20 NOVEMBER 14, 1891 pp. 303-318 | . 1891 | 65 | 10.2307/e26105745 | No. 19 NOVEMBER 7, 1891 pp. 287-302 | . 1891 | 65 | 10.2307/e26104776 | No. 18 OCTOBER 31, 1891 pp. 271-286 | . 1891 | 65 | 10.2307/e26105409 | No. 17 OCTOBER 24, 1891 pp. 255-270 | . 1891 | 65 | 10.2307/e26104389 | No. 16 OCTOBER 17, 1891 pp. 239-254 | . 1891 | 65 | 10.2307/e26105844 | No. 15 OCTOBER 10, 1891 pp. 223-238 | . 1891 | 65 | 10.2307/e26104868 | No. 14 OCTOBER 3, 1891 pp. 207-222 | . 1891 | 65 | 10.2307/e26105642 | No. 13 SEPTEMBER 26, 1891 pp. 191-206 | . 1891 | 65 | 10.2307/e26104676 | No. 12 SEPTEMBER 19, 1891 pp. 175-190 | . 1891 | 65 | 10.2307/e26105308 | No. 11 SEPTEMBER 12, 1891 pp. 159-174 | . 1891 | 65 | 10.2307/e26104211 | No. 10 SEPTEMBER 5, 1891 pp. 143-158 | . 1891 | 65 | 10.2307/e26104255 | No. 9 AUGUST 29, 1891 pp. 127-142 | . 1891 | 65 | 10.2307/e26105022 | No. 8 AUGUST 22, 1891 pp. 111-126 | . 1891 | 65 | 10.2307/e26105590 | No. 7 AUGUST 15, 1891 pp. 95-110 | . 1891 | 65 | 10.2307/e26104629 | No. 6 AUGUST 8, 1891 pp. 79-94 | . 1891 | 65 | 10.2307/e26104354 | No. 5 AUGUST 1, 1891 pp. 63-78 | . 1891 | 65 | 10.2307/e26105061 | No. 4 JULY 25, 1891 pp. 47-62 | . 1891 | 65 | 10.2307/e26105843 | No. 3 JULY 18, 1891 pp. 31-46 | . 1891 | 65 | 10.2307/e26104823 | No. 2 JULY 11, 1891 pp. 15-30 | . 1891 | 65 | 10.2307/e26104430 | No. 1 JULY 4, 1891 pp. 1-14 | . 1891 | 64 | 10.2307/e26105364 | No. 26 JUNE 27, 1891 pp. 399-414 | . 1891 | 64 | 10.2307/e26104975 | No. 25 JUNE 20, 1891 pp. 383-398 | . 1891 | 64 | 10.2307/e26104526 | No. 24 JUNE 13, 1891 pp. 367-382 | . 1891 | 64 | 10.2307/e26105802 | No. 23 JUNE 6, 1891 pp. 351-366 | . 1891 | 64 | 10.2307/e26102990 | No. 22 MAY 30, 1891 pp. 335-350 | . 1891 | 64 | 10.2307/e26101584 | No. 21 MAY 23, 1891 pp. 319-334 | . 1891 | 64 | 10.2307/e26100321 | No. 20 MAY 16, 1891 pp. 303-318 | . 1891 | 64 | 10.2307/e26102203 | No. 19 MAY 9, 1891 pp. 287-302 | . 1891 | 64 | 10.2307/e26103581 | No. 18 MAY 2, 1891 pp. 271-286 | . 1891 | 64 | 10.2307/e26101194 | No. 17 APRIL 25, 1891 pp. 255-270 | . 1891 | 64 | 10.2307/e26103067 | No. 16 APRIL 18, 1891 pp. 239-254 | . 1891 | 64 | 10.2307/e26104127 | No. 15 APRIL 11, 1891 pp. 223-238 | . 1891 | 64 | 10.2307/e26102806 | No. 14 APRIL 4, 1891 pp. 207-222 | . 1891 | 64 | 10.2307/e26103828 | No. 13 MARCH 28, 1891 pp. 191-206 | . 1891 | 64 | 10.2307/e26103399 | No. 12 MARCH 21, 1891 pp. 175-190 | . 1891 | 64 | 10.2307/e26103498 | No. 11 MARCH 14, 1891 pp. 159-174 | . 1891 | 64 | 10.2307/e26100892 | No. 10 MARCH 7, 1891 pp. 143-158 | . 1891 | 64 | 10.2307/e26102903 | No. 9 FEBRUARY 28, 1891 pp. 127-142 | . 1891 | 64 | 10.2307/e26103918 | No. 8 FEBRUARY 21, 1891 pp. 111-126 | . 1891 | 64 | 10.2307/e26101719 | No. 7 FEBRUARY 14, 1891 pp. 95-110 | . 1891 | 64 | 10.2307/e26103306 | No. 6 FEBRUARY 7, 1891 pp. 79-94 | . 1891 | 64 | 10.2307/e26100620 | No. 5 JANUARY 31, 1891 pp. 63-78 | . 1891 | 64 | 10.2307/e26104076 | No. 4 JANUARY 24, 1891 pp. 47-62 | . 1891 | 64 | 10.2307/e26102069 | No. 3 JANUARY 17, 1891 pp. 31-46 | . 1891 | 64 | 10.2307/e26103729 | No. 2 JANUARY 10, 1891 pp. 15-30 | . 1891 | 64 | 10.2307/e26101468 | No. 1 JANUARY 3, 1891 pp. 1-14 | . 1890 | 63 | 10.2307/e26103140 | No. 26 DECEMBER 27, 1890 pp. 399-414 | . 1890 | 63 | 10.2307/e26100045 | No. 25 DECEMBER 20, 1890 pp. 383-398 | . 1890 | 63 | 10.2307/e26100168 | No. 24 DECEMBER 13, 1890 pp. 367-382 | . 1890 | 63 | 10.2307/e26102503 | No. 23 DECEMBER 6, 1890 pp. 351-366 | . 1890 | 63 | 10.2307/e26103652 | No. 22 NOVEMBER 29, 1890 pp. 335-350 | . 1890 | 63 | 10.2307/e26101328 | No. 21 NOVEMBER 22, 1890 pp. 319-334 | . 1890 | 63 | 10.2307/e26100485 | No. 20 NOVEMBER 15, 1890 pp. 303-318 | . 1890 | 63 | 10.2307/e26102644 | No. 19 NOVEMBER 8, 1890 pp. 287-302 | . 1890 | 63 | 10.2307/e26104033 | No. 18 NOVEMBER 1, 1890 pp. 271-286 | . 1890 | 63 | 10.2307/e26101917 | No. 17 OCTOBER 25, 1890 pp. 255-270 | . 1890 | 63 | 10.2307/e26100734 | No. 16 OCTOBER 18, 1890 pp. 239-254 | . 1890 | 63 | 10.2307/e26103220 | No. 15 OCTOBER 11, 1890 pp. 223-238 | . 1890 | 63 | 10.2307/e26102358 | No. 14 OCTOBER 4, 1890 pp. 207-222 | . 1890 | 63 | 10.2307/e26101038 | No. 13 SEPTEMBER 27, 1890 pp. 191-206 | . 1890 | 63 | 10.2307/e26103975 | No. 12 SEPTEMBER 20, 1890 pp. 175-190 | . 1890 | 63 | 10.2307/e26100455 | No. 11 SEPTEMBER 13, 1890 pp. 159-174 | . 1890 | 63 | 10.2307/e26099347 | No. 10 SEPTEMBER 6, 1890 pp. 143-158 | . 1890 | 63 | 10.2307/e26098865 | No. 9 AUGUST 30, 1890 pp. 127-142 | . 1890 | 63 | 10.2307/e26099733 | No. 8 AUGUST 23, 1890 pp. 111-126 | . 1890 | 63 | 10.2307/e26101469 | No. 7 AUGUST 16, 1890 pp. 95-110 | . 1890 | 63 | 10.2307/e26099156 | No. 6 AUGUST 9, 1890 pp. 79-94 | . 1890 | 63 | 10.2307/e26100610 | No. 5 AUGUST 2, 1890 pp. 63-78 | . 1890 | 63 | 10.2307/e26102662 | No. 4 JULY 26, 1890 pp. 47-62 | . 1890 | 63 | 10.2307/e26100185 | No. 3 JULY 19, 1890 pp. 31-46 | . 1890 | 63 | 10.2307/e26101922 | No. 2 JULY 12, 1890 pp. 15-30 | . 1890 | 63 | 10.2307/e26101183 | No. 1 JULY 5, 1890 pp. 1-14 | . 1890 | 62 | 10.2307/e26101318 | No. 26 JUNE 28, 1890 pp. 401-416 | . 1890 | 62 | 10.2307/e26099065 | No. 25 JUNE 21, 1890 pp. 385-400 | . 1890 | 62 | 10.2307/e26100322 | No. 24 JUNE 14, 1890 pp. 369-384 | . 1890 | 62 | 10.2307/e26102076 | No. 23 JUNE 7, 1890 pp. 353-368 | . 1890 | 62 | 10.2307/e26099432 | No. 22 MAY 31, 1890 pp. 337-352 | . 1890 | 62 | 10.2307/e26101037 | No. 21 MAY 24, 1890 pp. 321-336 | . 1890 | 62 | 10.2307/e26098960 | No. 20 MAY 17, 1890 pp. 305-320 | . 1890 | 62 | 10.2307/e26102502 | No. 19 MAY 10, 1890 pp. 289-304 | . 1890 | 62 | 10.2307/e26099635 | No. 18 MAY 3, 1890 pp. 273-288 | . 1890 | 62 | 10.2307/e26101754 | No. 17 APRIL 26, 1890 pp. 257-272 | . 1890 | 62 | 10.2307/e26099264 | No. 16 APRIL 19, 1890 pp. 241-256 | . 1890 | 62 | 10.2307/e26100765 | No. 15 APRIL 12, 1890 pp. 225-240 | . 1890 | 62 | 10.2307/e26098778 | No. 14 APRIL 5, 1890 pp. 209-224 | . 1890 | 62 | 10.2307/e26098824 | No. 13 MARCH 29, 1890 pp. 193-208 | . 1890 | 62 | 10.2307/e26099931 | No. 12 MARCH 22, 1890 pp. 177-192 | . 1890 | 62 | 10.2307/e26101605 | No. 11 MARCH 15, 1890 pp. 161-176 | . 1890 | 62 | 10.2307/e26099208 | No. 10 MARCH 8, 1890 pp. 145-160 | . 1890 | 62 | 10.2307/e26098908 | No. 9 MARCH 1, 1890 pp. 129-144 | . 1890 | 62 | 10.2307/e26100052 | No. 8 FEBRUARY 22, 1890 pp. 113-128 | . 1890 | 62 | 10.2307/e26102361 | No. 7 FEBRUARY 15, 1890 pp. 97-112 | . 1890 | 62 | 10.2307/e26099538 | No. 6 FEBRUARY 8, 1890 pp. 81-96 | . 1890 | 62 | 10.2307/e26099019 | No. 5 FEBRUARY 1, 1890 pp. 65-80 | . 1890 | 62 | 10.2307/e26100902 | No. 4 JANUARY 25, 1890 pp. 49-64 | . 1890 | 62 | 10.2307/e26099842 | No. 3 JANUARY 18, 1890 pp. 33-48 | . 1890 | 62 | 10.2307/e26099112 | No. 2 JANUARY 11, 1890 pp. 17-32 | . 1890 | 62 | 10.2307/e26102242 | No. 1 JANUARY 4, 1890 pp. 1-16 | . 1889 | 61 | 10.2307/e26092839 | No. 26 DECEMBER 28, 1889 pp. 399-414 | . 1889 | 61 | 10.2307/e26092288 | No. 25 DECEMBER 21, 1889 pp. 383-398 | . 1889 | 61 | 10.2307/e26092449 | No. 24 DECEMBER 14, 1889 pp. 367-382 | . 1889 | 61 | 10.2307/e26091888 | No. 23 DECEMBER 7, 1889 pp. 351-366 | . 1889 | 61 | 10.2307/e26091039 | No. 22 NOVEMBER 30, 1889 pp. 335-350 | . 1889 | 61 | 10.2307/e26089773 | No. 21 NOVEMBER 23, 1889 pp. 319-334 | . 1889 | 61 | 10.2307/e26091339 | No. 20 NOVEMBER 16, 1889 pp. 303-318 | . 1889 | 61 | 10.2307/e26091698 | No. 19 NOVEMBER 9, 1889 pp. 287-302 | . 1889 | 61 | 10.2307/e26090655 | No. 18 NOVEMBER 2, 1889 pp. 271-286 | . 1889 | 61 | 10.2307/e26091161 | No. 17 OCTOBER 26, 1889 pp. 255-270 | . 1889 | 61 | 10.2307/e26090072 | No. 16 OCTOBER 19, 1889 pp. 239-254 | . 1889 | 61 | 10.2307/e26091494 | No. 15 OCTOBER 12, 1889 pp. 223-238 | . 1889 | 61 | 10.2307/e26090383 | No. 14 OCTOBER 5, 1889 pp. 207-222 | . 1889 | 61 | 10.2307/e26092092 | No. 13 SEPTEMBER 28, 1889 pp. 191-206 | . 1889 | 61 | 10.2307/e26090899 | No. 12 SEPTEMBER 21, 1889 pp. 175-190 | . 1889 | 61 | 10.2307/e26092605 | No. 11 SEPTEMBER 14, 1889 pp. 159-174 | . 1889 | 61 | 10.2307/e26101973 | No. 10 SEPTEMBER 7, 1889 pp. 143-158 | . 1889 | 61 | 10.2307/e26100498 | No. 9 AUGUST 31, 1889 pp. 127-142 | . 1889 | 61 | 10.2307/e26099451 | No. 8 AUGUST 24, 1889 pp. 111-126 | . 1889 | 61 | 10.2307/e26101087 | No. 7 AUGUST 17, 1889 pp. 95-110 | . 1889 | 61 | 10.2307/e26102999 | No. 6 AUGUST 10, 1889 pp. 79-94 | . 1889 | 61 | 10.2307/e26100031 | No. 5 AUGUST 3, 1889 pp. 63-78 | . 1889 | 61 | 10.2307/e26102118 | No. 4 JULY 27, 1889 pp. 47-62 | . 1889 | 61 | 10.2307/e26103783 | No. 3 JULY 20, 1889 pp. 31-46 | . 1889 | 61 | 10.2307/e26101666 | No. 2 JULY 13, 1889 pp. 15-30 | . 1889 | 61 | 10.2307/e26103268 | No. 1 JULY 6, 1889 pp. 1-14 | . 1889 | 60 | 10.2307/e26102743 | No. 26 JUNE 29, 1889 pp. 399-414 | . 1889 | 60 | 10.2307/e26102896 | No. 25 JUNE 22, 1889 pp. 383-398 | . 1889 | 60 | 10.2307/e26099841 | No. 24 JUNE 15, 1889 pp. 367-382 | . 1889 | 60 | 10.2307/e26101817 | No. 23 JUNE 8, 1889 pp. 351-366 | . 1889 | 60 | 10.2307/e26103391 | No. 22 JUNE 1, 1889 pp. 335-350 | . 1889 | 60 | 10.2307/e26100654 | No. 21 MAY 25, 1889 pp. 319-334 | . 1889 | 60 | 10.2307/e26102589 | No. 20 MAY 18, 1889 pp. 303-318 | . 1889 | 60 | 10.2307/e26099652 | No. 19 MAY 11, 1889 pp. 287-302 | . 1889 | 60 | 10.2307/e26103687 | No. 18 MAY 4, 1889 pp. 271-286 | . 1889 | 60 | 10.2307/e26100944 | No. 17 APRIL 27, 1889 pp. 255-270 | . 1889 | 60 | 10.2307/e26103184 | No. 16 APRIL 20, 1889 pp. 239-253 | . 1889 | 60 | 10.2307/e26100335 | No. 15 APRIL 13, 1889 pp. 223-238 | . 1889 | 60 | 10.2307/e26102271 | No. 14 APRIL 6, 1889 pp. 207-222 | . 1889 | 60 | 10.2307/e26099265 | No. 13 MARCH 30, 1889 pp. 191-206 | . 1889 | 60 | 10.2307/e26099364 | No. 12 MARCH 23, 1889 pp. 175-190 | . 1889 | 60 | 10.2307/e26101378 | No. 11 MARCH 16, 1889 pp. 159-174 | . 1889 | 60 | 10.2307/e26103099 | No. 10 MARCH 9, 1889 pp. 143-158 | . 1889 | 60 | 10.2307/e26100152 | No. 9 MARCH 2, 1889 pp. 127-142 | . 1889 | 60 | 10.2307/e26099547 | No. 8 FEBRUARY 23, 1889 pp. 111-126 | . 1889 | 60 | 10.2307/e26101526 | No. 7 FEBRUARY 16, 1889 pp. 95-110 | . 1889 | 60 | 10.2307/e26103587 | No. 6 FEBRUARY 9, 1889 pp. 79-94 | . 1889 | 60 | 10.2307/e26100808 | No. 5 FEBRUARY 2, 1889 pp. 63-78 | . 1889 | 60 | 10.2307/e26099746 | No. 4 JANUARY 26, 1889 pp. 47-62 | . 1889 | 60 | 10.2307/e26102414 | No. 3 JANUARY 19, 1889 pp. 31-46 | . 1889 | 60 | 10.2307/e26101236 | No. 2 JANUARY 12, 1889 pp. 15-30 | . 1889 | 60 | 10.2307/e26099942 | No. 1 JANUARY 5, 1889 pp. 1-14 | . 1888 | 59 | 10.2307/e26103499 | No. 26 DECEMBER 29, 1888 pp. 399-414 | . 1888 | 59 | 10.2307/e26096259 | No. 25 DECEMBER 22, 1888 pp. 383-398 | . 1888 | 59 | 10.2307/e26096032 | No. 24 DECEMBER 15, 1888 pp. 367-382 | . 1888 | 59 | 10.2307/e26095827 | No. 23 DECEMBER 8, 1888 pp. 351-366 | . 1888 | 59 | 10.2307/e26096144 | No. 22 DECEMBER 1, 1888 pp. 335-350 | . 1888 | 59 | 10.2307/e26096524 | No. 21 NOVEMBER 24, 1888 pp. 319-334 | . 1888 | 59 | 10.2307/e26095928 | No. 20 NOVEMBER 17, 1888 pp. 303-318 | . 1888 | 59 | 10.2307/e26096375 | No. 19 NOVEMBER 10, 1888 pp. 287-302 | . 1888 | 59 | 10.2307/e26097683 | No. 18 NOVEMBER 3, 1888 pp. 271-286 | . 1888 | 59 | 10.2307/e26096935 | No. 17 OCTOBER 27, 1888 pp. 255-270 | . 1888 | 59 | 10.2307/e26097504 | No. 16 OCTOBER 20, 1888 pp. 239-254 | . 1888 | 59 | 10.2307/e26097273 | No. 15 OCTOBER 13, 1888 pp. 223-238 | . 1888 | 59 | 10.2307/e26097409 | No. 14 OCTOBER 6, 1888 pp. 207-222 | . 1888 | 59 | 10.2307/e26096719 | No. 13 SEPTEMBER 29, 1888 pp. 191-205 | . 1888 | 59 | 10.2307/e26097048 | No. 12 SEPTEMBER 22, 1888 pp. 175-190 | . 1888 | 59 | 10.2307/e26097581 | No. 11 SEPTEMBER 15, 1888 pp. 159-174 | . 1888 | 59 | 10.2307/e26096846 | No. 10 SEPTEMBER 8, 1888 pp. 143-158 | . 1888 | 59 | 10.2307/e26097163 | No. 9 SEPTEMBER 1, 1888 pp. 127-142 | . 1888 | 59 | 10.2307/e26093567 | No. 8 AUGUST 25, 1888 pp. 111-126 | . 1888 | 59 | 10.2307/e26095565 | No. 7 AUGUST 18, 1888 pp. 95-110 | . 1888 | 59 | 10.2307/e26094637 | No. 6 AUGUST 11, 1888 pp. 79-94 | . 1888 | 59 | 10.2307/e26095313 | No. 5 AUGUST 4, 1888 pp. 63-78 | . 1888 | 59 | 10.2307/e26094122 | No. 4 JULY 28, 1888 pp. 47-62 | . 1888 | 59 | 10.2307/e26095093 | No. 3 JULY 21, 1888 pp. 31-46 | . 1888 | 59 | 10.2307/e26092687 | No. 2 JULY 14, 1888 pp. 15-30 | . 1888 | 59 | 10.2307/e26092982 | No. 1 JULY 7, 1888 pp. 1-14 | . 1888 | 58 | 10.2307/e26094858 | No. 26 JUNE 30, 1888 pp. 399-414 | . 1888 | 58 | 10.2307/e26093907 | No. 24 JUNE 16, 1888 pp. 367-382 | . 1888 | 58 | 10.2307/e26093281 | No. 23 JUNE 9, 1888 pp. 351-365 | . 1888 | 58 | 10.2307/e26094950 | No. 22 JUNE 2, 1888 pp. 335-350 | . 1888 | 58 | 10.2307/e26095450 | No. 21 MAY 26, 1888 pp. 319-334 | . 1888 | 58 | 10.2307/e26094414 | No. 20 MAY 19, 1888 pp. 303-318 | . 1888 | 58 | 10.2307/e26091427 | No. 19 MAY 12, 1888 pp. 287-302 | . 1888 | 58 | 10.2307/e26092081 | No. 18 MAY 5, 1888 pp. 271-286 | . 1888 | 58 | 10.2307/e26091870 | No. 17 APRIL 28, 1888 pp. 255-270 | . 1888 | 58 | 10.2307/e26091664 | No. 16 APRIL 21, 1888 pp. 239-254 | . 1888 | 58 | 10.2307/e26092287 | No. 15 APRIL 14, 1888 pp. 223-238 | . 1888 | 58 | 10.2307/e26093564 | No. 14 APRIL 7, 1888 pp. 207-222 | . 1888 | 58 | 10.2307/e26093091 | No. 13 MARCH 31, 1888 pp. 191-206 | . 1888 | 58 | 10.2307/e26092574 | No. 12 MARCH 24, 1888 pp. 175-190 | . 1888 | 58 | 10.2307/e26093384 | No. 11 MARCH 17, 1888 pp. 159-174 | . 1888 | 58 | 10.2307/e26094069 | No. 10 MARCH 10, 1888 pp. 143-158 | . 1888 | 58 | 10.2307/e26092809 | No. 9 MARCH 3, 1888 pp. 127-142 | . 1888 | 58 | 10.2307/e26093864 | No. 8 FEBRUARY 25, 1888 pp. 111-126 | . 1888 | 58 | 10.2307/e26094641 | No. 7 FEBRUARY 18, 1888 pp. 95-110 | . 1888 | 58 | 10.2307/e26092950 | No. 6 FEBRUARY 11, 1888 pp. 79-94 | . 1888 | 58 | 10.2307/e26094208 | No. 5 FEBRUARY 4, 1888 pp. 63-78 | . 1888 | 58 | 10.2307/e26093659 | No. 4 JANUARY 28, 1888 pp. 47-62 | . 1888 | 58 | 10.2307/e26093966 | No. 3 JANUARY 21, 1888 pp. 31-46 | . 1888 | 58 | 10.2307/e26092468 | No. 2 JANUARY 14, 1888 pp. 15-30 | . 1888 | 58 | 10.2307/e26093228 | No. 1 JANUARY 7, 1888 pp. 1-14 | . 1887 | 57 | 10.2307/e26094458 | No. 27 DECEMBER 31, 1887 pp. 415-434 | . 1887 | 57 | 10.2307/e26092675 | No. 26 DECEMBER 24, 1887 pp. 399-414 | . 1887 | 57 | 10.2307/e26093470 | No. 25 DECEMBER 17, 1887 pp. 383-398 | . 1887 | 57 | 10.2307/e26088653 | No. 24 DECEMBER 10, 1887 pp. 367-382 | . 1887 | 57 | 10.2307/e26090633 | No. 23 DECEMBER 3, 1887 pp. 351-366 | . 1887 | 57 | 10.2307/e26089161 | No. 22 NOVEMBER 26, 1887 pp. 335-350 | . 1887 | 57 | 10.2307/e26090340 | No. 21 NOVEMBER 19, 1887 pp. 319-334 | . 1887 | 57 | 10.2307/e26088948 | No. 20 NOVEMBER 12, 1887 pp. 303-318 | . 1887 | 57 | 10.2307/e26089744 | No. 19 NOVEMBER 5, 1887 pp. 287-302 | . 1887 | 57 | 10.2307/e26088194 | No. 18 OCTOBER 29, 1887 pp. 271-286 | . 1887 | 57 | 10.2307/e26088435 | No. 17 OCTOBER 22, 1887 pp. 255-270 | . 1887 | 57 | 10.2307/e26089441 | No. 16 OCTOBER 15, 1887 pp. 239-254 | . 1887 | 57 | 10.2307/e26090031 | No. 15 OCTOBER 8, 1887 pp. 223-238 | . 1887 | 57 | 10.2307/e26088395 | No. 14 OCTOBER 1, 1887 pp. 207-222 | . 1887 | 57 | 10.2307/e26087912 | No. 13 SEPTEMBER 24, 1887 pp. 191-206 | . 1887 | 57 | 10.2307/e26089199 | No. 12 SEPTEMBER 17, 1887 pp. 175-190 | . 1887 | 57 | 10.2307/e26089789 | No. 11 SEPTEMBER 10, 1887 pp. 159-174 | . 1887 | 57 | 10.2307/e26088724 | No. 10 SEPTEMBER 3, 1887 pp. 143-158 | . 1887 | 57 | 10.2307/e26088168 | No. 9 AUGUST 27, 1887 pp. 127-142 | . 1887 | 57 | 10.2307/e26089452 | No. 8 AUGUST 20, 1887 pp. 111-126 | . 1887 | 57 | 10.2307/e26088955 | No. 7 AUGUST 13, 1887 pp. 95-110 | . 1887 | 57 | 10.2307/e26087307 | No. 6 AUGUST 6, 1887 pp. 79-94 | . 1887 | 57 | 10.2307/e26087586 | No. 5 JULY 30, 1887 pp. 63-78 | . 1887 | 57 | 10.2307/e26096874 | No. 4 JULY 23, 1887 pp. 47-62 | . 1887 | 57 | 10.2307/e26095890 | No. 3 JULY 16, 1887 pp. 31-46 | . 1887 | 57 | 10.2307/e26095147 | No. 2 JULY 9, 1887 pp. 15-30 | . 1887 | 57 | 10.2307/e26096363 | No. 1 JULY 2, 1887 pp. 1-14 | . 1887 | 56 | 10.2307/e26097605 | No. 26 JUNE 25, 1887 pp. 399-414 | . 1887 | 56 | 10.2307/e26095722 | No. 25 JUNE 18, 1887 pp. 383-398 | . 1887 | 56 | 10.2307/e26096972 | No. 24 JUNE 11, 1887 pp. 367-382 | . 1887 | 56 | 10.2307/e26098116 | No. 23 JUNE 4, 1887 pp. 351-366 | . 1887 | 56 | 10.2307/e26096718 | No. 22 MAY 28, 1887 pp. 335-350 | . 1887 | 56 | 10.2307/e26097861 | No. 21 MAY 21, 1887 pp. 319-334 | . 1887 | 56 | 10.2307/e26097414 | No. 20 MAY 14, 1887 pp. 303-318 | . 1887 | 56 | 10.2307/e26097505 | No. 19 MAY 7, 1887 pp. 287-302 | . 1887 | 56 | 10.2307/e26095552 | No. 18 APRIL 30, 1887 pp. 271-286 | . 1887 | 56 | 10.2307/e26096792 | No. 17 APRIL 23, 1887 pp. 255-270 | . 1887 | 56 | 10.2307/e26097903 | No. 16 APRIL 16, 1887 pp. 239-254 | . 1887 | 56 | 10.2307/e26095995 | No. 15 APRIL 9, 1887 pp. 223-238 | . 1887 | 56 | 10.2307/e26097292 | No. 14 APRIL 2, 1887 pp. 207-222 | . 1887 | 56 | 10.2307/e26095349 | No. 13 MARCH 26, 1887 pp. 191-206 | . 1887 | 56 | 10.2307/e26098047 | No. 12 MARCH 19, 1887 pp. 175-190 | . 1887 | 56 | 10.2307/e26096240 | No. 11 MARCH 12, 1887 pp. 159-174 | . 1887 | 56 | 10.2307/e26097804 | No. 10 MARCH 5, 1887 pp. 143-158 | . 1887 | 56 | 10.2307/e26095826 | No. 9 FEBRUARY 26, 1887 pp. 127-142 | . 1887 | 56 | 10.2307/e26097088 | No. 8 FEBRUARY 19, 1887 pp. 111-126 | . 1887 | 56 | 10.2307/e26094859 | No. 7 FEBRUARY 12, 1887 pp. 95-110 | . 1887 | 56 | 10.2307/e26095011 | No. 6 FEBRUARY 5, 1887 pp. 79-94 | . 1887 | 56 | 10.2307/e26096581 | No. 5 JANUARY 29, 1887 pp. 63-78 | . 1887 | 56 | 10.2307/e26097700 | No. 4 JANUARY 22, 1887 pp. 47-62 | . 1887 | 56 | 10.2307/e26095774 | No. 3 JANUARY 15, 1887 pp. 31-46 | . 1887 | 56 | 10.2307/e26095248 | No. 2 JANUARY 8, 1887 pp. 15-30 | . 1887 | 56 | 10.2307/e26096674 | No. 1 JANUARY 1, 1887 pp. 1-14 | . 1886 | 55 | 10.2307/e26098012 | No. 26 DECEMBER 25, 1886 pp. 399-414 | . 1886 | 55 | 10.2307/e26096104 | No. 25 DECEMBER 18, 1886 pp. 383-398 | . 1886 | 55 | 10.2307/e26095458 | No. 24 DECEMBER 11, 1886 pp. 367-382 | . 1886 | 55 | 10.2307/e26097191 | No. 23 DECEMBER 4, 1886 pp. 351-366 | . 1886 | 55 | 10.2307/e26096475 | No. 22 NOVEMBER 27, 1886 pp. 335-350 | . 1886 | 55 | 10.2307/e26095637 | No. 21 NOVEMBER 20, 1886 pp. 319-334 | . 1886 | 55 | 10.2307/e26097954 | No. 20 NOVEMBER 13, 1886 pp. 303-318 | . 1886 | 55 | 10.2307/e26091628 | No. 19 NOVEMBER 6, 1886 pp. 287-302 | . 1886 | 55 | 10.2307/e26089307 | No. 18 OCTOBER 30, 1886 pp. 271-286 | . 1886 | 55 | 10.2307/e26087090 | No. 17 OCTOBER 23, 1886 pp. 255-270 | . 1886 | 55 | 10.2307/e26090623 | No. 16 OCTOBER 16, 1886 pp. 239-254 | . 1886 | 55 | 10.2307/e26093195 | No. 15 OCTOBER 9, 1886 pp. 223-238 | . 1886 | 55 | 10.2307/e26088516 | No. 14 OCTOBER 2, 1886 pp. 207-222 | . 1886 | 55 | 10.2307/e26091772 | No. 13 SEPTEMBER 25, 1886 pp. 191-206 | . 1886 | 55 | 10.2307/e26094943 | No. 12 SEPTEMBER 18, 1886 pp. 175-190 | . 1886 | 55 | 10.2307/e26091337 | No. 11 SEPTEMBER 11, 1886 pp. 159-174 | . 1886 | 55 | 10.2307/e26093936 | No. 10 SEPTEMBER 4, 1886 pp. 143-158 | . 1886 | 55 | 10.2307/e26092621 | No. 9 AUGUST 28, 1886 pp. 127-142 | . 1886 | 55 | 10.2307/e26092904 | No. 8 AUGUST 21, 1886 pp. 111-126 | . 1886 | 55 | 10.2307/e26088021 | No. 7 AUGUST 14, 1886 pp. 95-110 | . 1886 | 55 | 10.2307/e26091447 | No. 6 AUGUST 7, 1886 pp. 79-94 | . 1886 | 55 | 10.2307/e26094175 | No. 5 JULY 31, 1886 pp. 63-78 | . 1886 | 55 | 10.2307/e26089634 | No. 4 JULY 24, 1886 pp. 47-62 | . 1886 | 55 | 10.2307/e26092397 | No. 3 JULY 17, 1886 pp. 31-46 | . 1886 | 55 | 10.2307/e26087570 | No. 2 JULY 10, 1886 pp. 15-30 | . 1886 | 55 | 10.2307/e26094853 | No. 1 JULY 3, 1886 pp. 1-14 | . 1886 | 54 | 10.2307/e26090346 | No. 26 JUNE 26, 1886 pp. 399-414 | . 1886 | 54 | 10.2307/e26093584 | No. 25 JUNE 19, 1886 pp. 383-398 | . 1886 | 54 | 10.2307/e26089063 | No. 23 JUNE 5, 1886 pp. 351-366 | . 1886 | 54 | 10.2307/e26092004 | No. 22 MAY 29, 1886 pp. 335-350 | . 1886 | 54 | 10.2307/e26086691 | No. 21 MAY 22, 1886 pp. 319-334 | . 1886 | 54 | 10.2307/e26086905 | No. 20 MAY 15, 1886 pp. 303-318 | . 1886 | 54 | 10.2307/e26091003 | No. 19 MAY 8, 1886 pp. 287-302 | . 1886 | 54 | 10.2307/e26093460 | No. 18 MAY 1, 1886 pp. 271-286 | . 1886 | 54 | 10.2307/e26088785 | No. 17 APRIL 24, 1886 pp. 255-270 | . 1886 | 54 | 10.2307/e26087305 | No. 16 APRIL 17, 1886 pp. 239-254 | . 1886 | 54 | 10.2307/e26091158 | No. 15 APRIL 10, 1886 pp. 223-238 | . 1886 | 54 | 10.2307/e26094646 | No. 14 APRIL 3, 1886 pp. 207-222 | . 1886 | 54 | 10.2307/e26089975 | No. 13 MARCH 27, 1886 pp. 191-206 | . 1886 | 54 | 10.2307/e26087755 | No. 12 MARCH 20, 1886 pp. 175-190 | . 1886 | 54 | 10.2307/e26092228 | No. 11 MARCH 13, 1886 pp. 159-174 | . 1886 | 54 | 10.2307/e26090884 | No. 10 MARCH 6, 1886 pp. 143-158 | . 1886 | 54 | 10.2307/e26088281 | No. 9 FEBRUARY 27, 1886 pp. 127-142 | . 1886 | 54 | 10.2307/e26094452 | No. 8 FEBRUARY 20, 1886 pp. 111-126 | . 1886 | 54 | 10.2307/e26091338 | No. 7 FEBRUARY 13, 1886 pp. 95-110 | . 1886 | 54 | 10.2307/e26088839 | No. 6 FEBRUARY 6, 1886 pp. 79-94 | . 1886 | 54 | 10.2307/e26086893 | No. 5 JANUARY 30, 1886 pp. 63-78 | . 1886 | 54 | 10.2307/e26089951 | No. 4 JANUARY 23, 1886 pp. 47-62 | . 1886 | 54 | 10.2307/e26092614 | No. 3 JANUARY 16, 1886 pp. 31-46 | . 1886 | 54 | 10.2307/e26088102 | No. 2 JANUARY 9, 1886 pp. 15-30 | . 1886 | 54 | 10.2307/e26091473 | No. 1 JANUARY 2, 1886 pp. 1-14 | . 1885 | 53 | 10.2307/e26094542 | No. 25 DECEMBER 19, 1885 pp. 383-398 | . 1885 | 53 | 10.2307/e26091047 | No. 24 DECEMBER 12, 1885 pp. 367-382 | . 1885 | 53 | 10.2307/e26093443 | No. 23 DECEMBER 5, 1885 pp. 351-366 | . 1885 | 53 | 10.2307/e26092229 | No. 22 NOVEMBER 28, 1885 pp. 335-350 | . 1885 | 53 | 10.2307/e26092403 | No. 21 NOVEMBER 21, 1885 pp. 319-334 | . 1885 | 53 | 10.2307/e26087624 | No. 20 NOVEMBER 14, 1885 pp. 303-318 | . 1885 | 53 | 10.2307/e26091186 | No. 19 NOVEMBER 7, 1885 pp. 287-302 | . 1885 | 53 | 10.2307/e26093644 | No. 18 OCTOBER 31, 1885 pp. 271-286 | . 1885 | 53 | 10.2307/e26089094 | No. 17 OCTOBER 24, 1885 pp. 255-270 | . 1885 | 53 | 10.2307/e26092065 | No. 16 OCTOBER 17, 1885 pp. 239-254 | . 1885 | 53 | 10.2307/e26087287 | No. 15 OCTOBER 10, 1885 pp. 223-238 | . 1885 | 53 | 10.2307/e26094405 | No. 14 OCTOBER 3, 1885 pp. 207-222 | . 1885 | 53 | 10.2307/e26089631 | No. 13 SEPTEMBER 26, 1885 pp. 191-206 | . 1885 | 53 | 10.2307/e26093121 | No. 12 SEPTEMBER 19, 1885 pp. 175-190 | . 1885 | 53 | 10.2307/e26088565 | No. 11 SEPTEMBER 12, 1885 pp. 159-174 | . 1885 | 53 | 10.2307/e26091674 | No. 10 SEPTEMBER 5, 1885 pp. 143-158 | . 1885 | 53 | 10.2307/e26086560 | No. 9 AUGUST 29, 1885 pp. 127-142 | . 1885 | 53 | 10.2307/e26086672 | No. 8 AUGUST 22, 1885 pp. 111-126 | . 1885 | 53 | 10.2307/e26090603 | No. 7 AUGUST 15, 1885 pp. 95-110 | . 1885 | 53 | 10.2307/e26092849 | No. 6 AUGUST 8, 1885 pp. 79-94 | . 1885 | 53 | 10.2307/e26088298 | No. 5 AUGUST 1, 1885 pp. 63-78 | . 1885 | 53 | 10.2307/e26087068 | No. 4 JULY 25, 1885 pp. 47-62 | . 1885 | 53 | 10.2307/e26090883 | No. 3 JULY 18, 1885 pp. 31-46 | . 1885 | 53 | 10.2307/e26094178 | No. 2 JULY 11, 1885 pp. 15-30 | . 1885 | 53 | 10.2307/e26089380 | No. 1 JULY 4, 1885 pp. 1-14 | . 1885 | 52 | 10.2307/e26087372 | No. 26 JUNE 27, 1885 pp. 399-414 | . 1885 | 52 | 10.2307/e26091853 | No. 25 JUNE 20, 1885 pp. 383-398 | . 1885 | 52 | 10.2307/e26090242 | No. 23 JUNE 6, 1885 pp. 351-366 | . 1885 | 52 | 10.2307/e26087881 | No. 22 MAY 30, 1885 pp. 335-350 | . 1885 | 52 | 10.2307/e26093939 | No. 21 MAY 23, 1885 pp. 319-334 | . 1885 | 52 | 10.2307/e26085225 | No. 20 MAY 16, 1885 pp. 303-318 | . 1885 | 52 | 10.2307/e26083291 | No. 19 MAY 9, 1885 pp. 287-302 | . 1885 | 52 | 10.2307/e26085992 | No. 18 MAY 2, 1885 pp. 271-286 | . 1885 | 52 | 10.2307/e26088254 | No. 17 APRIL 25, 1885 pp. 255-270 | . 1885 | 52 | 10.2307/e26084661 | No. 16 APRIL 18, 1885 pp. 239-254 | . 1885 | 52 | 10.2307/e26086826 | No. 15 APRIL 11, 1885 pp. 223-238 | . 1885 | 52 | 10.2307/e26090616 | No. 14 APRIL 4, 1885 pp. 207-222 | . 1885 | 52 | 10.2307/e26086544 | No. 13 MARCH 28, 1885 pp. 191-206 | . 1885 | 52 | 10.2307/e26089060 | No. 12 MARCH 21, 1885 pp. 175-190 | . 1885 | 52 | 10.2307/e26087787 | No. 11 MARCH 14, 1885 pp. 159-174 | . 1885 | 52 | 10.2307/e26088014 | No. 10 MARCH 7, 1885 pp. 143-158 | . 1885 | 52 | 10.2307/e26084208 | No. 9 FEBRUARY 28, 1885 pp. 127-142 | . 1885 | 52 | 10.2307/e26086654 | No. 8 FEBRUARY 21, 1885 pp. 111-126 | . 1885 | 52 | 10.2307/e26089311 | No. 7 FEBRUARY 14, 1885 pp. 95-110 | . 1885 | 52 | 10.2307/e26085438 | No. 6 FEBRUARY 7, 1885 pp. 79-94 | . 1885 | 52 | 10.2307/e26087541 | No. 5 JANUARY 31, 1885 pp. 63-78 | . 1885 | 52 | 10.2307/e26083715 | No. 4 JANUARY 24, 1885 pp. 47-62 | . 1885 | 52 | 10.2307/e26090294 | No. 3 JANUARY 17, 1885 pp. 31-46 | . 1885 | 52 | 10.2307/e26085818 | No. 2 JANUARY 10, 1885 pp. 15-30 | . 1885 | 52 | 10.2307/e26088784 | No. 1 JANUARY 3, 1885 pp. 1-14 | . 1884 | 51 | 10.2307/e26085125 | No. 26 DECEMBER 27, 1884 pp. 423-436 | . 1884 | 51 | 10.2307/e26087057 | No. 25 DECEMBER 20, 1884 pp. 407-422 | . 1884 | 51 | 10.2307/e26082779 | No. 24 DECEMBER 13, 1884 pp. 391-406 | . 1884 | 51 | 10.2307/e26082960 | No. 23 DECEMBER 6, 1884 pp. 351-390 | . 1884 | 51 | 10.2307/e26086283 | No. 22 NOVEMBER 29, 1884 pp. 335-350 | . 1884 | 51 | 10.2307/e26088473 | No. 21 NOVEMBER 22, 1884 pp. 319-334 | . 1884 | 51 | 10.2307/e26084880 | No. 20 NOVEMBER 15, 1884 pp. 303-318 | . 1884 | 51 | 10.2307/e26083473 | No. 19 NOVEMBER 8, 1884 pp. 287-302 | . 1884 | 51 | 10.2307/e26086431 | No. 18 NOVEMBER 1, 1884 pp. 271-286 | . 1884 | 51 | 10.2307/e26089954 | No. 17 OCTOBER 25, 1884 pp. 255-270 | . 1884 | 51 | 10.2307/e26085648 | No. 15 OCTOBER 11, 1884 pp. 223-238 | . 1884 | 51 | 10.2307/e26083966 | No. 14 OCTOBER 4, 1884 pp. 207-222 | . 1884 | 51 | 10.2307/e26087294 | No. 13 SEPTEMBER 27, 1884 pp. 191-204 | . 1884 | 51 | 10.2307/e26086141 | No. 12 SEPTEMBER 20, 1884 pp. 175-190 | . 1884 | 51 | 10.2307/e26084456 | No. 11 SEPTEMBER 13, 1884 pp. 159-174 | . 1884 | 51 | 10.2307/e26089632 | No. 10 SEPTEMBER 6, 1884 pp. 143-158 | . 1884 | 51 | 10.2307/e26084779 | No. 9 AUGUST 30, 1884 pp. 127-142 | . 1884 | 51 | 10.2307/e26082502 | No. 8 AUGUST 23, 1884 pp. 111-126 | . 1884 | 51 | 10.2307/e26080880 | No. 7 AUGUST 16, 1884 pp. 95-110 | . 1884 | 51 | 10.2307/e26083362 | No. 6 AUGUST 9, 1884 pp. 79-94 | . 1884 | 51 | 10.2307/e26086276 | No. 5 AUGUST 2, 1884 pp. 63-78 | . 1884 | 51 | 10.2307/e26081939 | No. 4 JULY 26, 1884 pp. 47-62 | . 1884 | 51 | 10.2307/e26085011 | No. 3 JULY 19, 1884 pp. 31-46 | . 1884 | 51 | 10.2307/e26087865 | No. 2 JULY 12, 1884 pp. 15-30 | . 1884 | 51 | 10.2307/e26084440 | No. 1 JULY 5, 1884 pp. 1-14 | . 1884 | 50 | 10.2307/e26086719 | No. 26 JUNE 28, 1884 pp. 399-412 | . 1884 | 50 | 10.2307/e26085871 | No. 25 JUNE 21, 1884 pp. 383-398 | . 1884 | 50 | 10.2307/e26086057 | No. 24 JUNE 14, 1884 pp. 367-382 | . 1884 | 50 | 10.2307/e26081594 | No. 23 JUNE 7, 1884 pp. 351-366 | . 1884 | 50 | 10.2307/e26084587 | No. 22 MAY 31, 1884 pp. 335-350 | . 1884 | 50 | 10.2307/e26086926 | No. 21 MAY 24, 1884 pp. 319-334 | . 1884 | 50 | 10.2307/e26082670 | No. 20 MAY 17, 1884 pp. 303-318 | . 1884 | 50 | 10.2307/e26085726 | No. 19 MAY 10, 1884 pp. 287-302 | . 1884 | 50 | 10.2307/e26081270 | No. 18 MAY 3, 1884 pp. 271-286 | . 1884 | 50 | 10.2307/e26087566 | No. 17 APRIL 26, 1884 pp. 255-270 | . 1884 | 50 | 10.2307/e26083106 | No. 16 APRIL 19, 1884 pp. 239-254 | . 1884 | 50 | 10.2307/e26086580 | No. 15 APRIL 12, 1884 pp. 223-238 | . 1884 | 50 | 10.2307/e26082333 | No. 14 APRIL 5, 1884 pp. 207-222 | . 1884 | 50 | 10.2307/e26085271 | No. 13 MARCH 29, 1884 pp. 191-206 | . 1884 | 50 | 10.2307/e26080460 | No. 12 MARCH 22, 1884 pp. 175-190 | . 1884 | 50 | 10.2307/e26080652 | No. 11 MARCH 15, 1884 pp. 159-174 | . 1884 | 50 | 10.2307/e26083890 | No. 10 MARCH 8, 1884 pp. 143-158 | . 1884 | 50 | 10.2307/e26086443 | No. 9 MARCH 1, 1884 pp. 127-142 | . 1884 | 50 | 10.2307/e26082113 | No. 8 FEBRUARY 23, 1884 pp. 111-126 | . 1884 | 50 | 10.2307/e26081050 | No. 7 FEBRUARY 16, 1884 pp. 95-110 | . 1884 | 50 | 10.2307/e26084179 | No. 6 FEBRUARY 9, 1884 pp. 79-94 | . 1884 | 50 | 10.2307/e26087306 | No. 5 FEBRUARY 2, 1884 pp. 63-78 | . 1884 | 50 | 10.2307/e26082867 | No. 4 JANUARY 26, 1884 pp. 47-62 | . 1884 | 50 | 10.2307/e26081406 | No. 3 JANUARY 19, 1884 pp. 31-46 | . 1884 | 50 | 10.2307/e26085512 | No. 2 JANUARY 12, 1884 pp. 15-30 | . 1884 | 50 | 10.2307/e26083636 | No. 1 JANUARY 5, 1884 pp. 1-14 | . 1883 | 49 | 10.2307/e26081789 | No. 26 DECEMBER 29, 1883 pp. 399-414 | . 1883 | 49 | 10.2307/e26087147 | No. 25 DECEMBER 22, 1883 pp. 383-398 | . 1883 | 49 | 10.2307/e26082668 | No. 24 DECEMBER 15, 1883 pp. 367-382 | . 1883 | 49 | 10.2307/e26080862 | No. 23 DECEMBER 8, 1883 pp. 351-366 | . 1883 | 49 | 10.2307/e26079603 | No. 22 DECEMBER 1, 1883 pp. 335-350 | . 1883 | 49 | 10.2307/e26081582 | No. 21 NOVEMBER 24, 1883 pp. 319-334 | . 1883 | 49 | 10.2307/e26084410 | No. 20 NOVEMBER 17, 1883 pp. 303-316 | . 1883 | 49 | 10.2307/e26080335 | No. 19 NOVEMBER 10, 1883 pp. 287-302 | . 1883 | 49 | 10.2307/e26082873 | No. 18 NOVEMBER 3, 1883 pp. 271-286 | . 1883 | 49 | 10.2307/e26086165 | No. 17 OCTOBER 27, 1883 pp. 255-270 | . 1883 | 49 | 10.2307/e26082325 | No. 16 OCTOBER 20, 1883 pp. 239-254 | . 1883 | 49 | 10.2307/e26085155 | No. 15 OCTOBER 13, 1883 pp. 223-238 | . 1883 | 49 | 10.2307/e26083899 | No. 14 OCTOBER 6, 1883 pp. 207-222 | . 1883 | 49 | 10.2307/e26084159 | No. 13 SEPTEMBER 29, 1883 pp. 191-206 | . 1883 | 49 | 10.2307/e26080065 | No. 12 SEPTEMBER 22, 1883 pp. 175-190 | . 1883 | 49 | 10.2307/e26082505 | No. 11 SEPTEMBER 15, 1883 pp. 159-174 | . 1883 | 49 | 10.2307/e26085383 | No. 10 SEPTEMBER 8, 1883 pp. 143-158 | . 1883 | 49 | 10.2307/e26081081 | No. 9 SEPTEMBER 1, 1883 pp. 127-142 | . 1883 | 49 | 10.2307/e26083638 | No. 8 AUGUST 25, 1883 pp. 111-126 | . 1883 | 49 | 10.2307/e26079853 | No. 7 AUGUST 18, 1883 pp. 95-110 | . 1883 | 49 | 10.2307/e26085983 | No. 6 AUGUST 11, 1883 pp. 79-94 | . 1883 | 49 | 10.2307/e26081410 | No. 5 AUGUST 4, 1883 pp. 63-78 | . 1883 | 49 | 10.2307/e26084912 | No. 4 JULY 28, 1883 pp. 47-62 | . 1883 | 49 | 10.2307/e26080600 | No. 3 JULY 21, 1883 pp. 31-46 | . 1883 | 49 | 10.2307/e26083112 | No. 2 JULY 14, 1883 pp. 15-30 | . 1883 | 49 | 10.2307/e26079406 | No. 1 JULY 7, 1883 pp. 1-14 | . 1883 | 48 | 10.2307/e26079501 | No. 26 JUNE 30, 1883 pp. 399-414 | . 1883 | 48 | 10.2307/e26081957 | No. 25 JUNE 23, 1883 pp. 383-398 | . 1883 | 48 | 10.2307/e26084689 | No. 24 JUNE 16, 1883 pp. 367-382 | . 1883 | 48 | 10.2307/e26080475 | No. 23 JUNE 9, 1883 pp. 351-364 | . 1883 | 48 | 10.2307/e26079747 | No. 22 JUNE 2, 1883 pp. 335-350 | . 1883 | 48 | 10.2307/e26082164 | No. 21 MAY 26, 1883 pp. 319-334 | . 1883 | 48 | 10.2307/e26085822 | No. 17 APRIL 28, 1883 pp. 255-270 | . 1883 | 48 | 10.2307/e26081264 | No. 16 APRIL 21, 1883 pp. 239-254 | . 1883 | 48 | 10.2307/e26079971 | No. 15 APRIL 14, 1883 pp. 223-238 | . 1883 | 48 | 10.2307/e26083411 | No. 14 APRIL 7, 1883 pp. 207-222 | . 1883 | 48 | 10.2307/e26081788 | No. 13 MARCH 31, 1883 pp. 191-206 | . 1883 | 48 | 10.2307/e26080197 | No. 12 MARCH 24, 1883 pp. 175-190 | . 1883 | 48 | 10.2307/e26085647 | No. 11 MARCH 17, 1883 pp. 159-174 | . 1883 | 48 | 10.2307/e26082249 | No. 10 MARCH 10, 1883 pp. 143-156 | . 1883 | 48 | 10.2307/e26080525 | No. 9 MARCH 3, 1883 pp. 127-142 | . 1883 | 48 | 10.2307/e26079506 | No. 8 FEBRUARY 24, 1883 pp. 111-126 | . 1883 | 48 | 10.2307/e26081247 | No. 7 FEBRUARY 17, 1883 pp. 95-110 | . 1883 | 48 | 10.2307/e26083639 | No. 6 FEBRUARY 10, 1883 pp. 79-94 | . 1883 | 48 | 10.2307/e26080166 | No. 5 FEBRUARY 3, 1883 pp. 63-78 | . 1883 | 48 | 10.2307/e26082424 | No. 4 JANUARY 27, 1883 pp. 47-62 | . 1883 | 48 | 10.2307/e26085316 | No. 3 JANUARY 20, 1883 pp. 31-46 | . 1883 | 48 | 10.2307/e26081853 | No. 2 JANUARY 13, 1883 pp. 15-30 | . 1883 | 48 | 10.2307/e26084234 | No. 1 JANUARY 6, 1883 pp. 1-14 | . 1882 | 47 | 10.2307/e26083181 | No. 27 DECEMBER 30, 1882 pp. 415-430 | . 1882 | 47 | 10.2307/e26083414 | No. 26 DECEMBER 23, 1882 pp. 399-414 | . 1882 | 47 | 10.2307/e26079939 | No. 25 DECEMBER 16, 1882 pp. 383-398 | . 1882 | 47 | 10.2307/e26082085 | No. 24 DECEMBER 9, 1882 pp. 367-382 | . 1882 | 47 | 10.2307/e26084462 | No. 23 DECEMBER 2, 1882 pp. 351-366 | . 1882 | 47 | 10.2307/e26080696 | No. 22 NOVEMBER 25, 1882 pp. 335-350 | . 1882 | 47 | 10.2307/e26082994 | No. 21 NOVEMBER 18, 1882 pp. 319-334 | . 1882 | 47 | 10.2307/e26079746 | No. 20 NOVEMBER 11, 1882 pp. 303-318 | . 1882 | 47 | 10.2307/e26085138 | No. 19 NOVEMBER 4, 1882 pp. 287-302 | . 1882 | 47 | 10.2307/e26081062 | No. 18 OCTOBER 28, 1882 pp. 271-286 | . 1882 | 47 | 10.2307/e26084006 | No. 17 OCTOBER 21, 1882 pp. 255-270 | . 1882 | 47 | 10.2307/e26080390 | No. 16 OCTOBER 14, 1882 pp. 239-254 | . 1882 | 47 | 10.2307/e26082628 | No. 15 OCTOBER 7, 1882 pp. 223-236 | . 1882 | 47 | 10.2307/e26079337 | No. 14 SEPTEMBER 30, 1882 pp. 207-222 | . 1882 | 47 | 10.2307/e26079407 | No. 13 SEPTEMBER 23, 1882 pp. 191-206 | . 1882 | 47 | 10.2307/e26081563 | No. 12 SEPTEMBER 16, 1882 pp. 175-190 | . 1882 | 47 | 10.2307/e26083858 | No. 11 SEPTEMBER 9, 1882 pp. 159-174 | . 1882 | 47 | 10.2307/e26080264 | No. 10 SEPTEMBER 2, 1882 pp. 143-158 | . 1882 | 47 | 10.2307/e26079623 | No. 9 AUGUST 26, 1882 pp. 127-142 | . 1882 | 47 | 10.2307/e26081685 | No. 8 AUGUST 19, 1882 pp. 111-126 | . 1882 | 47 | 10.2307/e26084920 | No. 7 AUGUST 12, 1882 pp. 95-110 | . 1882 | 47 | 10.2307/e26080896 | No. 6 AUGUST 5, 1882 pp. 79-94 | . 1882 | 47 | 10.2307/e26079854 | No. 5 JULY 29, 1882 pp. 63-78 | . 1882 | 47 | 10.2307/e26082786 | No. 4 JULY 22, 1882 pp. 47-62 | . 1882 | 47 | 10.2307/e26081392 | No. 3 JULY 15, 1882 pp. 31-46 | . 1882 | 47 | 10.2307/e26080028 | No. 2 JULY 8, 1882 pp. 15-30 | . 1882 | 47 | 10.2307/e26084696 | No. 1 JULY 1, 1882 pp. 1-14 | . 1882 | 46 | 10.2307/e26077519 | No. 25 JUNE 24, 1882 pp. 391-406 | . 1882 | 46 | 10.2307/e26078154 | No. 24 JUNE 17, 1882 pp. 375-390 | . 1882 | 46 | 10.2307/e26078816 | No. 23 JUNE 10, 1882 pp. 359-374 | . 1882 | 46 | 10.2307/e26077828 | No. 22 JUNE 3, 1882 pp. 343-358 | . 1882 | 46 | 10.2307/e26078462 | No. 21 MAY 27, 1882 pp. 327-342 | . 1882 | 46 | 10.2307/e26079270 | No. 20 MAY 20, 1882 pp. 307-326 | . 1882 | 46 | 10.2307/e26078339 | No. 19 MAY 13, 1882 pp. 287-306 | . 1882 | 46 | 10.2307/e26078984 | No. 18 MAY 6, 1882 pp. 271-286 | . 1882 | 46 | 10.2307/e26078673 | No. 17 APRIL 29, 1882 pp. 255-270 | . 1882 | 46 | 10.2307/e26078749 | No. 16 APRIL 22, 1882 pp. 239-254 | . 1882 | 46 | 10.2307/e26077719 | No. 15 APRIL 15, 1882 pp. 223-238 | . 1882 | 46 | 10.2307/e26078412 | No. 14 APRIL 8, 1882 pp. 207-222 | . 1882 | 46 | 10.2307/e26079041 | No. 13 APRIL 1, 1882 pp. 191-206 | . 1882 | 46 | 10.2307/e26077977 | No. 12 MARCH 25, 1882 pp. 175-190 | . 1882 | 46 | 10.2307/e26078613 | No. 11 MARCH 18, 1882 pp. 159-174 | . 1882 | 46 | 10.2307/e26077602 | No. 10 MARCH 11, 1882 pp. 143-158 | . 1882 | 46 | 10.2307/e26079204 | No. 9 MARCH 4, 1882 pp. 127-142 | . 1882 | 46 | 10.2307/e26078101 | No. 8 FEBRUARY 25, 1882 pp. 111-126 | . 1882 | 46 | 10.2307/e26078917 | No. 7 FEBRUARY 18, 1882 pp. 95-110 | . 1882 | 46 | 10.2307/e26077921 | No. 6 FEBRUARY 11, 1882 pp. 79-94 | . 1882 | 46 | 10.2307/e26078514 | No. 5 FEBRUARY 4, 1882 pp. 63-78 | . 1882 | 46 | 10.2307/e26077414 | No. 4 JANUARY 28, 1882 pp. 47-62 | . 1882 | 46 | 10.2307/e26077461 | No. 3 JANUARY 21, 1882 pp. 31-46 | . 1882 | 46 | 10.2307/e26078258 | No. 2 JANUARY 14, 1882 pp. 15-30 | . 1882 | 46 | 10.2307/e26078864 | No. 1 JANUARY 7, 1882 pp. 1-14 | . 1881 | 45 | 10.2307/e26077880 | No. 27 DECEMBER 31, 1881 pp. 415-450 | . 1881 | 45 | 10.2307/e26077558 | No. 26 DECEMBER 24, 1881 pp. 399-414 | . 1881 | 45 | 10.2307/e26078308 | No. 25 DECEMBER 17, 1881 pp. 383-398 | . 1881 | 45 | 10.2307/e26079144 | No. 24 DECEMBER 10, 1881 pp. 367-382 | . 1881 | 45 | 10.2307/e26078043 | No. 23 DECEMBER 3, 1881 pp. 351-366 | . 1881 | 45 | 10.2307/e26077666 | No. 22 NOVEMBER 26, 1881 pp. 335-350 | . 1881 | 45 | 10.2307/e26078565 | No. 21 NOVEMBER 19, 1881 pp. 319-334 | . 1881 | 45 | 10.2307/e26078206 | No. 20 NOVEMBER 12, 1881 pp. 303-318 | . 1881 | 45 | 10.2307/e26077770 | No. 19 NOVEMBER 5, 1881 pp. 287-302 | . 1881 | 45 | 10.2307/e26079097 | No. 18 OCTOBER 29, 1881 pp. 271-286 | . 1881 | 45 | 10.2307/e26076234 | No. 17 OCTOBER 22, 1881 pp. 255-270 | . 1881 | 45 | 10.2307/e26075822 | No. 16 OCTOBER 15, 1881 pp. 239-254 | . 1881 | 45 | 10.2307/e26075603 | No. 15 OCTOBER 8, 1881 pp. 223-238 | . 1881 | 45 | 10.2307/e26075930 | No. 14 OCTOBER 1, 1881 pp. 207-222 | . 1881 | 45 | 10.2307/e26076665 | No. 13 SEPTEMBER 24, 1881 pp. 191-206 | . 1881 | 45 | 10.2307/e26075703 | No. 11 SEPTEMBER 10, 1881 pp. 159-174 | . 1881 | 45 | 10.2307/e26076344 | No. 9 AUGUST 27, 1881 pp. 127-142 | . 1881 | 45 | 10.2307/e26076868 | No. 8 AUGUST 20, 1881 pp. 111-126 | . 1881 | 45 | 10.2307/e26076051 | No. 7 AUGUST 13, 1881 pp. 95-110 | . 1881 | 45 | 10.2307/e26076774 | No. 5 JULY 30, 1881 pp. 63-78 | . 1881 | 45 | 10.2307/e26076451 | No. 4 JULY 23, 1881 pp. 47-62 | . 1881 | 45 | 10.2307/e26076567 | No. 3 JULY 16, 1881 pp. 31-46 | . 1881 | 45 | 10.2307/e26075482 | No. 2 JULY 9, 1881 pp. 15-30 | . 1881 | 45 | 10.2307/e26076511 | No. 1 JULY 2, 1881 pp. 1-14 | . 1881 | 44 | 10.2307/e26077075 | No. 26 JUNE 25, 1881 pp. 399-414 | . 1881 | 44 | 10.2307/e26075799 | No. 25 JUNE 18, 1881 pp. 383-398 | . 1881 | 44 | 10.2307/e26076775 | No. 24 JUNE 11, 1881 pp. 367-382 | . 1881 | 44 | 10.2307/e26075368 | No. 23 JUNE 4, 1881 pp. 351-366 | . 1881 | 44 | 10.2307/e26077237 | No. 22 MAY 28, 1881 pp. 335-350 | . 1881 | 44 | 10.2307/e26076031 | No. 21 MAY 21, 1881 pp. 319-334 | . 1881 | 44 | 10.2307/e26077008 | No. 20 MAY 14, 1881 pp. 303-318 | . 1881 | 44 | 10.2307/e26075702 | No. 19 MAY 7, 1881 pp. 287-302 | . 1881 | 44 | 10.2307/e26076618 | No. 18 APRIL 30, 1881 pp. 271-286 | . 1881 | 44 | 10.2307/e26075188 | No. 17 APRIL 23, 1881 pp. 255-270 | . 1881 | 44 | 10.2307/e26075252 | No. 16 APRIL 16, 1881 pp. 239-254 | . 1881 | 44 | 10.2307/e26076311 | No. 15 APRIL 9, 1881 pp. 223-238 | . 1881 | 44 | 10.2307/e26076895 | No. 14 APRIL 2, 1881 pp. 207-222 | . 1881 | 44 | 10.2307/e26075602 | No. 13 MARCH 26, 1881 pp. 191-206 | . 1881 | 44 | 10.2307/e26075305 | No. 12 MARCH 19, 1881 pp. 175-190 | . 1881 | 44 | 10.2307/e26076393 | No. 11 MARCH 12, 1881 pp. 159-174 | . 1881 | 44 | 10.2307/e26077123 | No. 10 MARCH 5, 1881 pp. 143-158 | . 1881 | 44 | 10.2307/e26171603 | No. 9 FEBRUARY 26, 1881 pp. 127-142 | . 1881 | 44 | 10.2307/e26075903 | No. 8 FEBRUARY 19, 1881 pp. 111-126 | . 1881 | 44 | 10.2307/e26075434 | No. 7 FEBRUARY 12, 1881 pp. 95-110 | . 1881 | 44 | 10.2307/e26076723 | No. 6 FEBRUARY 5, 1881 pp. 79-94 | . 1881 | 44 | 10.2307/e26076184 | No. 5 JANUARY 29, 1881 pp. 63-78 | . 1881 | 44 | 10.2307/e26075543 | No. 4 JANUARY 22, 1881 pp. 47-62 | . 1881 | 44 | 10.2307/e26077121 | No. 3 JANUARY 15, 1881 pp. 31-46 | . 1881 | 44 | 10.2307/e26074251 | No. 2 JANUARY 8, 1881 pp. 15-30 | . 1881 | 44 | 10.2307/e26073541 | No. 1 JANUARY 1, 1881 pp. 1-14 | . 1880 | 43 | 10.2307/e26072593 | No. 26 DECEMBER 25, 1880 pp. 399-414 | . 1880 | 43 | 10.2307/e26073960 | No. 25 DECEMBER 18, 1880 pp. 383-398 | . 1880 | 43 | 10.2307/e26074674 | No. 24 DECEMBER 11, 1880 pp. 367-382 | . 1880 | 43 | 10.2307/e26073236 | No. 23 DECEMBER 4, 1880 pp. 351-366 | . 1880 | 43 | 10.2307/e26074313 | No. 22 NOVEMBER 27, 1880 pp. 335-350 | . 1880 | 43 | 10.2307/e26075076 | No. 21 NOVEMBER 20, 1880 pp. 319-334 | . 1880 | 43 | 10.2307/e26074183 | No. 20 NOVEMBER 13, 1880 pp. 303-318 | . 1880 | 43 | 10.2307/e26074842 | No. 19 NOVEMBER 6, 1880 pp. 287-302 | . 1880 | 43 | 10.2307/e26074546 | No. 18 OCTOBER 30, 1880 pp. 271-286 | . 1880 | 43 | 10.2307/e26074613 | No. 17 OCTOBER 23, 1880 pp. 255-270 | . 1880 | 43 | 10.2307/e26072939 | No. 16 OCTOBER 16, 1880 pp. 239-254 | . 1880 | 43 | 10.2307/e26074184 | No. 15 OCTOBER 9, 1880 pp. 223-238 | . 1880 | 43 | 10.2307/e26074902 | No. 14 OCTOBER 2, 1880 pp. 207-222 | . 1880 | 43 | 10.2307/e26073633 | No. 13 SEPTEMBER 25, 1880 pp. 191-206 | . 1880 | 43 | 10.2307/e26074485 | No. 12 SEPTEMBER 18, 1880 pp. 175-190 | . 1880 | 43 | 10.2307/e26072678 | No. 11 SEPTEMBER 11, 1880 pp. 159-174 | . 1880 | 43 | 10.2307/e26075075 | No. 10 SEPTEMBER 4, 1880 pp. 143-158 | . 1880 | 43 | 10.2307/e26073897 | No. 9 AUGUST 28, 1880 pp. 127-142 | . 1880 | 43 | 10.2307/e26074786 | No. 8 AUGUST 21, 1880 pp. 111-126 | . 1880 | 43 | 10.2307/e26073423 | No. 7 AUGUST 14, 1880 pp. 95-110 | . 1880 | 43 | 10.2307/e26074375 | No. 6 AUGUST 7, 1880 pp. 79-94 | . 1880 | 43 | 10.2307/e26072473 | No. 5 JULY 31, 1880 pp. 63-78 | . 1880 | 43 | 10.2307/e26072538 | No. 4 JULY 24, 1880 pp. 47-62 | . 1880 | 43 | 10.2307/e26074050 | No. 3 JULY 17, 1880 pp. 31-46 | . 1880 | 43 | 10.2307/e26074720 | No. 2 JULY 10, 1880 pp. 15-30 | . 1880 | 43 | 10.2307/e26073337 | No. 1 JULY 3, 1880 pp. 1-14 | . 1880 | 42 | 10.2307/e26072635 | No. 26 JUNE 26, 1880 pp. 399-414 | . 1880 | 42 | 10.2307/e26074114 | No. 25 JUNE 19, 1880 pp. 383-398 | . 1880 | 42 | 10.2307/e26075025 | No. 24 JUNE 12, 1880 pp. 367-382 | . 1880 | 42 | 10.2307/e26073759 | No. 23 JUNE 5, 1880 pp. 351-366 | . 1880 | 42 | 10.2307/e26072796 | No. 22 MAY 29, 1880 pp. 335-350 | . 1880 | 42 | 10.2307/e26074435 | No. 21 MAY 22, 1880 pp. 319-334 | . 1880 | 42 | 10.2307/e26074005 | No. 20 MAY 15, 1880 pp. 303-318 | . 1880 | 42 | 10.2307/e26073123 | No. 19 MAY 8, 1880 pp. 287-302 | . 1880 | 42 | 10.2307/e26074963 | No. 18 MAY 1, 1880 pp. 271-286 | . 1880 | 42 | 10.2307/e26073124 | No. 17 APRIL 24, 1880 pp. 255-270 | . 1880 | 42 | 10.2307/e26072925 | No. 16 APRIL 17, 1880 pp. 239-254 | . 1880 | 42 | 10.2307/e26072636 | No. 15 APRIL 10, 1880 pp. 223-238 | . 1880 | 42 | 10.2307/e26072835 | No. 14 APRIL 3, 1880 pp. 207-222 | . 1880 | 42 | 10.2307/e26073565 | No. 13 MARCH 27, 1880 pp. 191-206 | . 1880 | 42 | 10.2307/e26072725 | No. 12 MARCH 20, 1880 pp. 175-190 | . 1880 | 42 | 10.2307/e26073218 | No. 11 MARCH 13, 1880 pp. 159-174 | . 1880 | 42 | 10.2307/e26073783 | No. 10 MARCH 6, 1880 pp. 143-158 | . 1880 | 42 | 10.2307/e26072950 | No. 9 FEBRUARY 28, 1880 pp. 127-142 | . 1880 | 42 | 10.2307/e26073673 | No. 8 FEBRUARY 21, 1880 pp. 111-126 | . 1880 | 42 | 10.2307/e26073341 | No. 7 FEBRUARY 14, 1880 pp. 95-110 | . 1880 | 42 | 10.2307/e26073458 | No. 6 FEBRUARY 7, 1880 pp. 79-94 | . 1880 | 42 | 10.2307/e26071740 | No. 5 JANUARY 31, 1880 pp. 63-78 | . 1880 | 42 | 10.2307/e26072030 | No. 4 JANUARY 24, 1880 pp. 47-62 | . 1880 | 42 | 10.2307/e26072277 | No. 3 JANUARY 17, 1880 pp. 31-46 | . 1880 | 42 | 10.2307/e26071854 | No. 2 JANUARY 10, 1880 pp. 15-30 | . 1880 | 42 | 10.2307/e26072163 | No. 1 JANUARY 3, 1880 pp. 1-14 | . 1879 | 41 | 10.2307/e26071681 | No. 26 DECEMBER 27, 1879 pp. 407-422 | . 1879 | 41 | 10.2307/e26072332 | No. 25 DECEMBER 20, 1879 pp. 391-406 | . 1879 | 41 | 10.2307/e26071909 | No. 24 DECEMBER 13, 1879 pp. 375-390 | . 1879 | 41 | 10.2307/e26072227 | No. 23 DECEMBER 6, 1879 pp. 351-374 | . 1879 | 41 | 10.2307/e26071795 | No. 22 NOVEMBER 29, 1879 pp. 335-350 | . 1879 | 41 | 10.2307/e26171543 | No. 21 NOVEMBER 22, 1879 pp. 319-334 | . 1879 | 41 | 10.2307/e26072108 | No. 20 NOVEMBER 15, 1879 pp. 303-318 | . 1879 | 41 | 10.2307/e26071560 | No. 19 NOVEMBER 8, 1879 pp. 287-302 | . 1879 | 41 | 10.2307/e26071626 | No. 18 NOVEMBER 1, 1879 pp. 271-286 | . 1879 | 41 | 10.2307/e26071969 | No. 17 OCTOBER 25, 1879 pp. 255-270 | . 1879 | 41 | 10.2307/e26072226 | No. 16 OCTOBER 18, 1879 pp. 239-254 | . 1879 | 41 | 10.2307/e26071112 | No. 15 OCTOBER 11, 1879 pp. 223-238 | . 1879 | 41 | 10.2307/e26070921 | No. 14 OCTOBER 4, 1879 pp. 207-222 | . 1879 | 41 | 10.2307/e26071306 | No. 13 SEPTEMBER 27, 1879 pp. 191-206 | . 1879 | 41 | 10.2307/e26071498 | No. 12 SEPTEMBER 20, 1879 pp. 175-190 | . 1879 | 41 | 10.2307/e26071173 | No. 11 SEPTEMBER 13, 1879 pp. 159-174 | . 1879 | 41 | 10.2307/e26070972 | No. 10 SEPTEMBER 6, 1879 pp. 143-158 | . 1879 | 41 | 10.2307/e26071365 | No. 9 AUGUST 30, 1879 pp. 127-142 | . 1879 | 41 | 10.2307/e26071246 | No. 8 AUGUST 23, 1879 pp. 111-126 | . 1879 | 41 | 10.2307/e26071045 | No. 7 AUGUST 16, 1879 pp. 95-110 | . 1879 | 41 | 10.2307/e26071426 | No. 6 AUGUST 9, 1879 pp. 79-94 | . 1879 | 41 | 10.2307/e26065731 | No. 5 AUGUST 2, 1879 pp. 63-78 | . 1879 | 41 | 10.2307/e26064039 | No. 4 JULY 26, 1879 pp. 47-62 | . 1879 | 41 | 10.2307/e26062531 | No. 3 JULY 19, 1879 pp. 31-46 | . 1879 | 41 | 10.2307/e26064698 | No. 2 JULY 12, 1879 pp. 15-30 | . 1879 | 41 | 10.2307/e26066978 | No. 1 JULY 5, 1879 pp. 1-14 | . 1879 | 40 | 10.2307/e26063534 | No. 26 JUNE 28, 1879 pp. 399-414 | . 1879 | 40 | 10.2307/e26065877 | No. 25 JUNE 21, 1879 pp. 383-398 | . 1879 | 40 | 10.2307/e26068222 | No. 24 JUNE 14, 1879 pp. 367-382 | . 1879 | 40 | 10.2307/e26065429 | No. 23 JUNE 7, 1879 pp. 351-366 | . 1879 | 40 | 10.2307/e26067514 | No. 22 MAY 31, 1879 pp. 335-350 | . 1879 | 40 | 10.2307/e26066654 | No. 21 MAY 24, 1879 pp. 319-334 | . 1879 | 40 | 10.2307/e26066834 | No. 20 MAY 17, 1879 pp. 303-318 | . 1879 | 40 | 10.2307/e26063159 | No. 19 MAY 10, 1879 pp. 287-302 | . 1879 | 40 | 10.2307/e26065585 | No. 18 MAY 3, 1879 pp. 271-286 | . 1879 | 40 | 10.2307/e26067651 | No. 17 APRIL 26, 1879 pp. 255-270 | . 1879 | 40 | 10.2307/e26064181 | No. 16 APRIL 19, 1879 pp. 239-254 | . 1879 | 40 | 10.2307/e26066417 | No. 15 APRIL 12, 1879 pp. 223-238 | . 1879 | 40 | 10.2307/e26062868 | No. 14 APRIL 5, 1879 pp. 207-222 | . 1879 | 40 | 10.2307/e26068117 | No. 13 MARCH 29, 1879 pp. 191-206 | . 1879 | 40 | 10.2307/e26064539 | No. 12 MARCH 22, 1879 pp. 175-190 | . 1879 | 40 | 10.2307/e26067322 | No. 11 MARCH 15, 1879 pp. 159-174 | . 1879 | 40 | 10.2307/e26063857 | No. 10 MARCH 8, 1879 pp. 143-158 | . 1879 | 40 | 10.2307/e26066059 | No. 9 MARCH 1, 1879 pp. 127-142 | . 1879 | 40 | 10.2307/e26062273 | No. 8 FEBRUARY 22, 1879 pp. 111-126 | . 1879 | 40 | 10.2307/e26062392 | No. 7 FEBRUARY 15, 1879 pp. 95-110 | . 1879 | 40 | 10.2307/e26065082 | No. 6 FEBRUARY 8, 1879 pp. 79-94 | . 1879 | 40 | 10.2307/e26067147 | No. 5 FEBRUARY 1, 1879 pp. 63-78 | . 1879 | 40 | 10.2307/e26063698 | No. 4 JANUARY 25, 1879 pp. 47-62 | . 1879 | 40 | 10.2307/e26062713 | No. 3 JANUARY 18, 1879 pp. 31-46 | . 1879 | 40 | 10.2307/e26065277 | No. 2 JANUARY 11, 1879 pp. 15-30 | . 1879 | 40 | 10.2307/e26068022 | No. 1 JANUARY 4, 1879 pp. 1-14 | . 1878 | 39 | 10.2307/e26064362 | No. 26 DECEMBER 28, 1878 pp. 399-414 | . 1878 | 39 | 10.2307/e26063009 | No. 25 DECEMBER 21, 1878 pp. 383-398 | . 1878 | 39 | 10.2307/e26066259 | No. 24 DECEMBER 14, 1878 pp. 367-382 | . 1878 | 39 | 10.2307/e26064894 | No. 23 DECEMBER 7, 1878 pp. 351-366 | . 1878 | 39 | 10.2307/e26063318 | No. 22 NOVEMBER 30, 1878 pp. 335-350 | . 1878 | 39 | 10.2307/e26067858 | No. 21 NOVEMBER 23, 1878 pp. 319-334 | . 1878 | 39 | 10.2307/e26065990 | No. 20 NOVEMBER 16, 1878 pp. 303-318 | . 1878 | 39 | 10.2307/e26064262 | No. 19 NOVEMBER 9, 1878 pp. 287-302 | . 1878 | 39 | 10.2307/e26062735 | No. 18 NOVEMBER 2, 1878 pp. 271-286 | . 1878 | 39 | 10.2307/e26064973 | No. 17 OCTOBER 26, 1878 pp. 255-270 | . 1878 | 39 | 10.2307/e26067015 | No. 16 OCTOBER 19, 1878 pp. 239-254 | . 1878 | 39 | 10.2307/e26063749 | No. 15 OCTOBER 12, 1878 pp. 223-238 | . 1878 | 39 | 10.2307/e26066162 | No. 14 OCTOBER 5, 1878 pp. 207-222 | . 1878 | 39 | 10.2307/e26068223 | No. 13 SEPTEMBER 28, 1878 pp. 191-206 | . 1878 | 39 | 10.2307/e26065661 | No. 12 SEPTEMBER 21, 1878 pp. 175-190 | . 1878 | 39 | 10.2307/e26067521 | No. 11 SEPTEMBER 14, 1878 pp. 159-174 | . 1878 | 39 | 10.2307/e26066680 | No. 10 SEPTEMBER 7, 1878 pp. 143-158 | . 1878 | 39 | 10.2307/e26066851 | No. 9 AUGUST 31, 1878 pp. 127-142 | . 1878 | 39 | 10.2307/e26063387 | No. 8 AUGUST 24, 1878 pp. 111-126 | . 1878 | 39 | 10.2307/e26065829 | No. 7 AUGUST 17, 1878 pp. 95-110 | . 1878 | 39 | 10.2307/e26067631 | No. 6 AUGUST 10, 1878 pp. 79-94 | . 1878 | 39 | 10.2307/e26064456 | No. 5 AUGUST 3, 1878 pp. 63-78 | . 1878 | 39 | 10.2307/e26066502 | No. 4 JULY 27, 1878 pp. 47-62 | . 1878 | 39 | 10.2307/e26063058 | No. 3 JULY 20, 1878 pp. 31-46 | . 1878 | 39 | 10.2307/e26068096 | No. 2 JULY 13, 1878 pp. 15-30 | . 1878 | 39 | 10.2307/e26064788 | No. 1 JULY 6, 1878 pp. 1-14 | . 1878 | 38 | 10.2307/e26067351 | No. 26 JUNE 29, 1878 pp. 399-414 | . 1878 | 38 | 10.2307/e26064085 | No. 25 JUNE 22, 1878 pp. 383-398 | . 1878 | 38 | 10.2307/e26066342 | No. 24 JUNE 15, 1878 pp. 367-382 | . 1878 | 38 | 10.2307/e26062393 | No. 23 JUNE 8, 1878 pp. 351-366 | . 1878 | 38 | 10.2307/e26062556 | No. 22 JUNE 1, 1878 pp. 335-350 | . 1878 | 38 | 10.2307/e26065331 | No. 21 MAY 25, 1878 pp. 319-334 | . 1878 | 38 | 10.2307/e26067176 | No. 20 MAY 18, 1878 pp. 303-318 | . 1878 | 38 | 10.2307/e26063923 | No. 19 MAY 11, 1878 pp. 287-302 | . 1878 | 38 | 10.2307/e26062902 | No. 18 MAY 4, 1878 pp. 271-286 | . 1878 | 38 | 10.2307/e26065498 | No. 17 APRIL 27, 1878 pp. 255-270 | . 1878 | 38 | 10.2307/e26067979 | No. 16 APRIL 20, 1878 pp. 239-254 | . 1878 | 38 | 10.2307/e26064597 | No. 15 APRIL 13, 1878 pp. 223-238 | . 1878 | 38 | 10.2307/e26063210 | No. 14 APRIL 6, 1878 pp. 207-222 | . 1878 | 38 | 10.2307/e26066343 | No. 13 MARCH 30, 1878 pp. 191-206 | . 1878 | 38 | 10.2307/e26065156 | No. 12 MARCH 23, 1878 pp. 175-190 | . 1878 | 38 | 10.2307/e26063584 | No. 11 MARCH 16, 1878 pp. 159-174 | . 1878 | 38 | 10.2307/e26067821 | No. 10 MARCH 9, 1878 pp. 143-158 | . 1878 | 38 | 10.2307/e26065493 | No. 9 MARCH 2, 1878 pp. 127-142 | . 1878 | 38 | 10.2307/e26063843 | No. 8 FEBRUARY 23, 1878 pp. 111-126 | . 1878 | 38 | 10.2307/e26062388 | No. 7 FEBRUARY 16, 1878 pp. 95-110 | . 1878 | 38 | 10.2307/e26064542 | No. 6 FEBRUARY 9, 1878 pp. 79-94 | . 1878 | 38 | 10.2307/e26066612 | No. 5 FEBRUARY 2, 1878 pp. 63-78 | . 1878 | 38 | 10.2307/e26063325 | No. 4 JANUARY 26, 1878 pp. 47-62 | . 1878 | 38 | 10.2307/e26065644 | No. 3 JANUARY 19, 1878 pp. 31-46 | . 1878 | 38 | 10.2307/e26067870 | No. 2 JANUARY 12, 1878 pp. 15-30 | . 1878 | 38 | 10.2307/e26065152 | No. 1 JANUARY 5, 1878 pp. 1-14 | . 1877 | 37 | 10.2307/e26067049 | No. 26 DECEMBER 29, 1877 pp. 399-414 | . 1877 | 37 | 10.2307/e26066309 | No. 25 DECEMBER 22, 1877 pp. 383-398 | . 1877 | 37 | 10.2307/e26066462 | No. 24 DECEMBER 15, 1877 pp. 367-382 | . 1877 | 37 | 10.2307/e26062983 | No. 23 DECEMBER 8, 1877 pp. 351-366 | . 1877 | 37 | 10.2307/e26065301 | No. 22 DECEMBER 1, 1877 pp. 335-350 | . 1877 | 37 | 10.2307/e26067194 | No. 21 NOVEMBER 24, 1877 pp. 319-334 | . 1877 | 37 | 10.2307/e26064040 | No. 20 NOVEMBER 17, 1877 pp. 303-318 | . 1877 | 37 | 10.2307/e26066148 | No. 19 NOVEMBER 10, 1877 pp. 287-302 | . 1877 | 37 | 10.2307/e26062694 | No. 18 NOVEMBER 3, 1877 pp. 271-286 | . 1877 | 37 | 10.2307/e26067684 | No. 17 OCTOBER 27, 1877 pp. 255-270 | . 1877 | 37 | 10.2307/e26064384 | No. 16 OCTOBER 20, 1877 pp. 239-254 | . 1877 | 37 | 10.2307/e26066908 | No. 15 OCTOBER 13, 1877 pp. 223-238 | . 1877 | 37 | 10.2307/e26063683 | No. 14 OCTOBER 6, 1877 pp. 207-222 | . 1877 | 37 | 10.2307/e26065822 | No. 13 SEPTEMBER 29, 1877 pp. 191-206 | . 1877 | 37 | 10.2307/e26062224 | No. 12 SEPTEMBER 22, 1877 pp. 175-190 | . 1877 | 37 | 10.2307/e26062272 | No. 11 SEPTEMBER 15, 1877 pp. 159-174 | . 1877 | 37 | 10.2307/e26064802 | No. 10 SEPTEMBER 8, 1877 pp. 143-158 | . 1877 | 37 | 10.2307/e26066738 | No. 9 SEPTEMBER 1, 1877 pp. 127-142 | . 1877 | 37 | 10.2307/e26063506 | No. 8 AUGUST 25, 1877 pp. 111-126 | . 1877 | 37 | 10.2307/e26062530 | No. 7 AUGUST 18, 1877 pp. 95-110 | . 1877 | 37 | 10.2307/e26120641 | No. 6 AUGUST 11, 1877 pp. 79-94 | . 1877 | 37 | 10.2307/e26067522 | No. 5 AUGUST 4, 1877 pp. 63-78 | . 1877 | 37 | 10.2307/e26064171 | No. 4 JULY 28, 1877 pp. 47-62 | . 1877 | 37 | 10.2307/e26062834 | No. 3 JULY 21, 1877 pp. 31-46 | . 1877 | 37 | 10.2307/e26065983 | No. 2 JULY 14, 1877 pp. 15-30 | . 1877 | 37 | 10.2307/e26064674 | No. 1 JULY 7, 1877 pp. 1-14 | . 1877 | 36 | 10.2307/e26063160 | No. 26 JUNE 30, 1877 pp. 399-414 | . 1877 | 36 | 10.2307/e26067363 | No. 25 JUNE 23, 1877 pp. 383-398 | . 1877 | 36 | 10.2307/e26056593 | No. 24 JUNE 16, 1877 pp. 367-382 | . 1877 | 36 | 10.2307/e26055991 | No. 23 JUNE 9, 1877 pp. 351-366 | . 1877 | 36 | 10.2307/e26055398 | No. 22 JUNE 2, 1877 pp. 335-350 | . 1877 | 36 | 10.2307/e26056258 | No. 21 MAY 26, 1877 pp. 319-334 | . 1877 | 36 | 10.2307/e26056947 | No. 20 MAY 19, 1877 pp. 303-318 | . 1877 | 36 | 10.2307/e26055692 | No. 19 MAY 12, 1877 pp. 287-302 | . 1877 | 36 | 10.2307/e26056642 | No. 18 MAY 5, 1877 pp. 271-286 | . 1877 | 36 | 10.2307/e26057360 | No. 17 APRIL 28, 1877 pp. 255-270 | . 1877 | 36 | 10.2307/e26056503 | No. 16 APRIL 21, 1877 pp. 239-254 | . 1877 | 36 | 10.2307/e26057099 | No. 15 APRIL 14, 1877 pp. 223-238 | . 1877 | 36 | 10.2307/e26056841 | No. 14 APRIL 7, 1877 pp. 207-222 | . 1877 | 36 | 10.2307/e26056894 | No. 13 MARCH 31, 1877 pp. 191-206 | . 1877 | 36 | 10.2307/e26055592 | No. 12 MARCH 24, 1877 pp. 175-190 | . 1877 | 36 | 10.2307/e26056547 | No. 11 MARCH 17, 1877 pp. 159-174 | . 1877 | 36 | 10.2307/e26057169 | No. 10 MARCH 10, 1877 pp. 143-158 | . 1877 | 36 | 10.2307/e26056108 | No. 9 MARCH 3, 1877 pp. 127-142 | . 1877 | 36 | 10.2307/e26056791 | No. 8 FEBRUARY 24, 1877 pp. 111-126 | . 1877 | 36 | 10.2307/e26055490 | No. 7 FEBRUARY 17, 1877 pp. 95-110 | . 1877 | 36 | 10.2307/e26057307 | No. 6 FEBRUARY 10, 1877 pp. 79-94 | . 1877 | 36 | 10.2307/e26056203 | No. 5 FEBRUARY 3, 1877 pp. 63-78 | . 1877 | 36 | 10.2307/e26057048 | No. 4 JANUARY 27, 1877 pp. 47-62 | . 1877 | 36 | 10.2307/e26055884 | No. 3 JANUARY 20, 1877 pp. 31-46 | . 1877 | 36 | 10.2307/e26056690 | No. 2 JANUARY 13, 1877 pp. 15-30 | . 1877 | 36 | 10.2307/e26055296 | No. 1 JANUARY 6, 1877 pp. 1-14 | . 1876 | 35 | 10.2307/e26055342 | No. 26 DECEMBER 23 AND DECEMBER 30, 1876 pp. 399-414 | . 1876 | 35 | 10.2307/e26056397 | No. 25 DECEMBER 16, 1876 pp. 383-398 | . 1876 | 35 | 10.2307/e26056997 | No. 24 DECEMBER 9, 1876 pp. 367-382 | . 1876 | 35 | 10.2307/e26055792 | No. 23 DECEMBER 2, 1876 pp. 351-366 | . 1876 | 35 | 10.2307/e26055443 | No. 22 NOVEMBER 25, 1876 pp. 335-350 | . 1876 | 35 | 10.2307/e26056455 | No. 21 NOVEMBER 18, 1876 pp. 319-334 | . 1876 | 35 | 10.2307/e26057257 | No. 20 NOVEMBER 11, 1876 pp. 303-318 | . 1876 | 35 | 10.2307/e26056148 | No. 19 NOVEMBER 4, 1876 pp. 287-302 | . 1876 | 35 | 10.2307/e26055547 | No. 18 OCTOBER 28, 1876 pp. 271-286 | . 1876 | 35 | 10.2307/e26056738 | No. 17 OCTOBER 21, 1876 pp. 255-270 | . 1876 | 35 | 10.2307/e26056306 | No. 16 OCTOBER 14, 1876 pp. 239-254 | . 1876 | 35 | 10.2307/e26055629 | No. 15 OCTOBER 7, 1876 pp. 223-238 | . 1876 | 35 | 10.2307/e26057218 | No. 14 SEPTEMBER 30, 1876 pp. 207-222 | . 1876 | 35 | 10.2307/e26052364 | No. 13 SEPTEMBER 23, 1876 pp. 191-206 | . 1876 | 35 | 10.2307/e26050527 | No. 12 SEPTEMBER 16, 1876 pp. 175-190 | . 1876 | 35 | 10.2307/e26048737 | No. 11 SEPTEMBER 9, 1876 pp. 159-174 | . 1876 | 35 | 10.2307/e26051189 | No. 10 SEPTEMBER 2, 1876 pp. 143-158 | . 1876 | 35 | 10.2307/e26053711 | No. 9 AUGUST 26, 1876 pp. 127-142 | . 1876 | 35 | 10.2307/e26049887 | No. 8 AUGUST 19, 1876 pp. 111-126 | . 1876 | 35 | 10.2307/e26052601 | No. 7 AUGUST 12, 1876 pp. 95-110 | . 1876 | 35 | 10.2307/e26055222 | No. 6 AUGUST 5, 1876 pp. 79-94 | . 1876 | 35 | 10.2307/e26051979 | No. 5 JULY 29, 1876 pp. 63-78 | . 1876 | 35 | 10.2307/e26054261 | No. 4 JULY 22, 1876 pp. 47-62 | . 1876 | 35 | 10.2307/e26053374 | No. 3 JULY 15, 1876 pp. 31-46 | . 1876 | 35 | 10.2307/e26053562 | No. 2 JULY 8, 1876 pp. 15-30 | . 1876 | 35 | 10.2307/e26049516 | No. 1 JULY 1, 1876 pp. 1-14 | . 1876 | 34 | 10.2307/e26052223 | No. 26 JUNE 24, 1876 pp. 399-414 | . 1876 | 34 | 10.2307/e26054469 | No. 25 JUNE 17, 1876 pp. 383-398 | . 1876 | 34 | 10.2307/e26050647 | No. 24 JUNE 10, 1876 pp. 367-382 | . 1876 | 34 | 10.2307/e26053164 | No. 23 JUNE 3, 1876 pp. 351-366 | . 1876 | 34 | 10.2307/e26049092 | No. 22 MAY 27, 1876 pp. 335-350 | . 1876 | 34 | 10.2307/e26055113 | No. 21 MAY 20, 1876 pp. 319-334 | . 1876 | 34 | 10.2307/e26051021 | No. 20 MAY 13, 1876 pp. 303-318 | . 1876 | 34 | 10.2307/e26054098 | No. 19 MAY 6, 1876 pp. 287-302 | . 1876 | 34 | 10.2307/e26050293 | No. 18 APRIL 29, 1876 pp. 271-286 | . 1876 | 34 | 10.2307/e26052796 | No. 17 APRIL 22, 1876 pp. 255-270 | . 1876 | 34 | 10.2307/e26048291 | No. 16 APRIL 15, 1876 pp. 239-254 | . 1876 | 34 | 10.2307/e26048517 | No. 15 APRIL 8, 1876 pp. 223-238 | . 1876 | 34 | 10.2307/e26051547 | No. 14 APRIL 1, 1876 pp. 207-222 | . 1876 | 34 | 10.2307/e26053928 | No. 13 MARCH 25, 1876 pp. 191-206 | . 1876 | 34 | 10.2307/e26050095 | No. 12 MARCH 18, 1876 pp. 175-190 | . 1876 | 34 | 10.2307/e26048935 | No. 11 MARCH 11, 1876 pp. 159-174 | . 1876 | 34 | 10.2307/e26051763 | No. 10 MARCH 4, 1876 pp. 143-158 | . 1876 | 34 | 10.2307/e26054893 | No. 9 FEBRUARY 26, 1876 pp. 127-142 | . 1876 | 34 | 10.2307/e26050820 | No. 8 FEBRUARY 19, 1876 pp. 111-126 | . 1876 | 34 | 10.2307/e26049276 | No. 7 FEBRUARY 12, 1876 pp. 95-110 | . 1876 | 34 | 10.2307/e26052972 | No. 6 FEBRUARY 5, 1876 pp. 79-94 | . 1876 | 34 | 10.2307/e26051382 | No. 5 JANUARY 29, 1876 pp. 63-78 | . 1876 | 34 | 10.2307/e26049682 | No. 4 JANUARY 22, 1876 pp. 47-62 | . 1876 | 34 | 10.2307/e26054651 | No. 3 JANUARY 15, 1876 pp. 31-46 | . 1876 | 34 | 10.2307/e26052060 | No. 2 JANUARY 8, 1876 pp. 15-30 | . 1876 | 34 | 10.2307/e26050246 | No. 1 JANUARY 1, 1876 pp. 1-14 | . 1875 | 33 | 10.2307/e26048543 | No. 26 DECEMBER 25, 1875 pp. 399-414 | . 1875 | 33 | 10.2307/e26050890 | No. 25 DECEMBER 18, 1875 pp. 383-398 | . 1875 | 33 | 10.2307/e26053378 | No. 24 DECEMBER 11, 1875 pp. 367-382 | . 1875 | 33 | 10.2307/e26049650 | No. 23 DECEMBER 4, 1875 pp. 351-366 | . 1875 | 33 | 10.2307/e26052260 | No. 22 NOVEMBER 27, 1875 pp. 335-350 | . 1875 | 33 | 10.2307/e26054787 | No. 21 NOVEMBER 20, 1875 pp. 319-334 | . 1875 | 33 | 10.2307/e26051661 | No. 20 NOVEMBER 13, 1875 pp. 303-318 | . 1875 | 33 | 10.2307/e26053927 | No. 19 NOVEMBER 6, 1875 pp. 287-302 | . 1875 | 33 | 10.2307/e26052974 | No. 18 OCTOBER 30 1875 pp. 271-286 | . 1875 | 33 | 10.2307/e26053165 | No. 17 OCTOBER 23, 1875 pp. 255-270 | . 1875 | 33 | 10.2307/e26049282 | No. 16 OCTOBER 16, 1875 pp. 239-254 | . 1875 | 33 | 10.2307/e26051835 | No. 15 OCTOBER 9, 1875 pp. 223-238 | . 1875 | 33 | 10.2307/e26054101 | No. 14 OCTOBER 2, 1875 pp. 207-222 | . 1875 | 33 | 10.2307/e26050409 | No. 13 SEPTEMBER 25, 1875 pp. 191-206 | . 1875 | 33 | 10.2307/e26052803 | No. 12 SEPTEMBER 18, 1875 pp. 175-190 | . 1875 | 33 | 10.2307/e26048873 | No. 11 SEPTEMBER 11, 1875 pp. 159-174 | . 1875 | 33 | 10.2307/e26054614 | No. 10 SEPTEMBER 4, 1875 pp. 143-158 | . 1875 | 33 | 10.2307/e26050702 | No. 9 AUGUST 28, 1875 pp. 127-142 | . 1875 | 33 | 10.2307/e26053726 | No. 8 AUGUST 21, 1875 pp. 111-126 | . 1875 | 33 | 10.2307/e26050022 | No. 7 AUGUST 14, 1875 pp. 95-110 | . 1875 | 33 | 10.2307/e26052409 | No. 6 AUGUST 7, 1875 pp. 79-94 | . 1875 | 33 | 10.2307/e26048178 | No. 5 JULY 31, 1875 pp. 63-78 | . 1875 | 33 | 10.2307/e26048338 | No. 4 JULY 24, 1875 pp. 47-62 | . 1875 | 33 | 10.2307/e26051287 | No. 3 JULY 17, 1875 pp. 31-46 | . 1875 | 33 | 10.2307/e26053573 | No. 2 JULY 10, 1875 pp. 15-30 | . 1875 | 33 | 10.2307/e26049849 | No. 1 JULY 3, 1875 pp. 1-14 | . 1875 | 32 | 10.2307/e26048712 | No. 26 JUNE 26, 1875 pp. 399-414 | . 1875 | 32 | 10.2307/e26051471 | No. 25 JUNE 19, 1875 pp. 383-398 | . 1875 | 32 | 10.2307/e26054463 | No. 24 JUNE 12, 1875 pp. 367-382 | . 1875 | 32 | 10.2307/e26050586 | No. 23 JUNE 5, 1875 pp. 351-366 | . 1875 | 32 | 10.2307/e26049062 | No. 22 MAY 29, 1875 pp. 335-350 | . 1875 | 32 | 10.2307/e26052605 | No. 21 MAY 22, 1875 pp. 319-334 | . 1875 | 32 | 10.2307/e26051098 | No. 20 MAY 15, 1875 pp. 303-318 | . 1875 | 32 | 10.2307/e26049447 | No. 19 MAY 8, 1875 pp. 287-302 | . 1875 | 32 | 10.2307/e26054258 | No. 18 MAY 1, 1875 pp. 271-286 | . 1875 | 32 | 10.2307/e26052264 | No. 17 APRIL 24, 1875 pp. 255-270 | . 1875 | 32 | 10.2307/e26050244 | No. 16 APRIL 17, 1875 pp. 239-254 | . 1875 | 32 | 10.2307/e26048435 | No. 15 APRIL 10, 1875 pp. 223-238 | . 1875 | 32 | 10.2307/e26051004 | No. 14 APRIL 3, 1875 pp. 207-222 | . 1875 | 32 | 10.2307/e26053561 | No. 13 MARCH 27, 1875 pp. 191-206 | . 1875 | 32 | 10.2307/e26049623 | No. 12 MARCH 20, 1875 pp. 175-190 | . 1875 | 32 | 10.2307/e26052414 | No. 11 MARCH 13, 1875 pp. 159-174 | . 1875 | 32 | 10.2307/e26055112 | No. 10 MARCH 6, 1875 pp. 143-158 | . 1875 | 32 | 10.2307/e26051808 | No. 9 FEBRUARY 27, 1875 pp. 127-142 | . 1875 | 32 | 10.2307/e26054119 | No. 8 FEBRUARY 20, 1875 pp. 111-126 | . 1875 | 32 | 10.2307/e26053159 | No. 7 FEBRUARY 13, 1875 pp. 95-110 | . 1875 | 32 | 10.2307/e26053348 | No. 6 FEBRUARY 6, 1875 pp. 79-94 | . 1875 | 32 | 10.2307/e26049174 | No. 5 JANUARY 30, 1875 pp. 63-78 | . 1875 | 32 | 10.2307/e26052047 | No. 4 JANUARY 23, 1875 pp. 47-62 | . 1875 | 32 | 10.2307/e26054314 | No. 3 JANUARY 16, 1875 pp. 31-46 | . 1875 | 32 | 10.2307/e26050434 | No. 2 JANUARY 9, 1875 pp. 15-30 | . 1875 | 32 | 10.2307/e26052987 | No. 1 JANUARY 2, 1875 pp. 1-14 | . 1874 | 31 | 10.2307/e26048813 | No. 26 DECEMBER 26, 1874 pp. 399-414 | . 1874 | 31 | 10.2307/e26054899 | No. 25 DECEMBER 19, 1874 pp. 383-398 | . 1874 | 31 | 10.2307/e26050840 | No. 24 DECEMBER 12, 1874 pp. 367-382 | . 1874 | 31 | 10.2307/e26053929 | No. 23 DECEMBER 5, 1874 pp. 351-366 | . 1874 | 31 | 10.2307/e26050026 | No. 22 NOVEMBER 28, 1874 pp. 335-350 | . 1874 | 31 | 10.2307/e26052610 | No. 21 NOVEMBER 21, 1874 pp. 319-334 | . 1874 | 31 | 10.2307/e26048177 | No. 20 NOVEMBER 14, 1874 pp. 303-318 | . 1874 | 31 | 10.2307/e26048245 | No. 19 NOVEMBER 7, 1874 pp. 287-302 | . 1874 | 31 | 10.2307/e26051395 | No. 18 OCTOBER 31, 1874 pp. 271-286 | . 1874 | 31 | 10.2307/e26053727 | No. 17 OCTOBER 24, 1874 pp. 255-270 | . 1874 | 31 | 10.2307/e26049858 | No. 16 OCTOBER 17, 1874 pp. 239-254 | . 1874 | 31 | 10.2307/e26048642 | No. 15 OCTOBER 10, 1874 pp. 223-238 | . 1874 | 31 | 10.2307/e26051596 | No. 14 OCTOBER 3, 1874 pp. 207-222 | . 1874 | 31 | 10.2307/e26054678 | No. 13 SEPTEMBER 26, 1874 pp. 191-206 | . 1874 | 31 | 10.2307/e26050631 | No. 12 SEPTEMBER 19, 1874 pp. 175-190 | . 1874 | 31 | 10.2307/e26049004 | No. 11 SEPTEMBER 12, 1874 pp. 159-174 | . 1874 | 31 | 10.2307/e26052807 | No. 10 SEPTEMBER 5, 1874 pp. 143-158 | . 1874 | 31 | 10.2307/e26051211 | No. 9 AUGUST 29, 1874 pp. 127-142 | . 1874 | 31 | 10.2307/e26049372 | No. 8 AUGUST 22, 1874 pp. 111-126 | . 1874 | 31 | 10.2307/e26054517 | No. 7 AUGUST 15, 1874 pp. 95-110 | . 1874 | 31 | 10.2307/e26035940 | No. 6 AUGUST 8, 1874 pp. 79-94 | . 1874 | 31 | 10.2307/e26034988 | No. 5 AUGUST 1, 1874 pp. 63-78 | . 1874 | 31 | 10.2307/e26034073 | No. 4 JULY 25, 1874 pp. 47-62 | . 1874 | 31 | 10.2307/e26035359 | No. 3 JULY 18, 1874 pp. 31-46 | . 1874 | 31 | 10.2307/e26036689 | No. 2 JULY 11, 1874 pp. 15-30 | . 1874 | 31 | 10.2307/e26034744 | No. 1 JULY 4, 1874 pp. 1-14 | . 1874 | 30 | 10.2307/e26036010 | No. 26 JUNE 27, 1874 pp. 399-414 | . 1874 | 30 | 10.2307/e26038250 | No. 25 JUNE 20, 1874 pp. 383-398 | . 1874 | 30 | 10.2307/e26035727 | No. 24 JUNE 13, 1874 pp. 367-382 | . 1874 | 30 | 10.2307/e26037201 | No. 23 JUNE 6, 1874 pp. 351-366 | . 1874 | 30 | 10.2307/e26036361 | No. 22 MAY 30, 1874 pp. 335-350 | . 1874 | 30 | 10.2307/e26036547 | No. 21 MAY 23, 1874 pp. 319-334 | . 1874 | 30 | 10.2307/e26034504 | No. 20 MAY 16, 1874 pp. 303-318 | . 1874 | 30 | 10.2307/e26035837 | No. 19 MAY 9, 1874 pp. 287-302 | . 1874 | 30 | 10.2307/e26037355 | No. 18 MAY 2, 1874 pp. 271-286 | . 1874 | 30 | 10.2307/e26035088 | No. 17 APRIL 25, 1874 pp. 255-270 | . 1874 | 30 | 10.2307/e26036264 | No. 16 APRIL 18, 1874 pp. 239-254 | . 1874 | 30 | 10.2307/e26034310 | No. 14 APRIL 4, 1874 pp. 207-222 | . 1874 | 30 | 10.2307/e26038049 | No. 12 MARCH 21, 1874 pp. 175-190 | . 1874 | 30 | 10.2307/e26035274 | No. 11 MARCH 14, 1874 pp. 159-174 | . 1874 | 30 | 10.2307/e26037008 | No. 10 MARCH 7, 1874 pp. 143-158 | . 1874 | 30 | 10.2307/e26034919 | No. 9 FEBRUARY 28, 1874 pp. 127-142 | . 1874 | 30 | 10.2307/e26036076 | No. 8 FEBRUARY 21, 1874 pp. 111-126 | . 1874 | 30 | 10.2307/e26033781 | No. 7 FEBRUARY 14, 1874 pp. 95-110 | . 1874 | 30 | 10.2307/e26033933 | No. 6 FEBRUARY 7, 1874 pp. 79-94 | . 1874 | 30 | 10.2307/e26035581 | No. 5 JANUARY 31, 1874 pp. 63-78 | . 1874 | 30 | 10.2307/e26036809 | No. 4 JANUARY 24, 1874 pp. 47-62 | . 1874 | 30 | 10.2307/e26034843 | No. 3 JANUARY 17, 1874 pp. 31-46 | . 1874 | 30 | 10.2307/e26034223 | No. 2 JANUARY 10, 1874 pp. 15-30 | . 1874 | 30 | 10.2307/e26035635 | No. 1 JANUARY 3, 1874 pp. 1-14 | . 1873 | 29 | 10.2307/e26037809 | No. 26 DECEMBER 27, 1873 pp. 399-414 | . 1873 | 29 | 10.2307/e26035180 | No. 25 DECEMBER 20, 1873 pp. 383-398 | . 1873 | 29 | 10.2307/e26034413 | No. 24 DECEMBER 13, 1873 pp. 367-382 | . 1873 | 29 | 10.2307/e26036169 | No. 23 DECEMBER 6, 1873 pp. 351-366 | . 1873 | 29 | 10.2307/e26035477 | No. 22 NOVEMBER 29, 1873 pp. 335-350 | . 1873 | 29 | 10.2307/e26034646 | No. 21 NOVEMBER 22, 1873 pp. 319-334 | . 1873 | 29 | 10.2307/e26037601 | No. 20 NOVEMBER 15, 1873 pp. 303-318 | . 1873 | 29 | 10.2307/e26045072 | No. 19 NOVEMBER 8, 1873 pp. 287-302 | . 1873 | 29 | 10.2307/e26043653 | No. 18 NOVEMBER 1, 1873 pp. 271-286 | . 1873 | 29 | 10.2307/e26042226 | No. 17 OCTOBER 25, 1873 pp. 255-270 | . 1873 | 29 | 10.2307/e26044232 | No. 16 OCTOBER 18, 1873 pp. 239-254 | . 1873 | 29 | 10.2307/e26045676 | No. 15 OCTOBER 11, 1873 pp. 223-238 | . 1873 | 29 | 10.2307/e26043178 | No. 14 OCTOBER 4, 1873 pp. 207-222 | . 1873 | 29 | 10.2307/e26045203 | No. 13 SEPTEMBER 27, 1873 pp. 191-206 | . 1873 | 29 | 10.2307/e26046293 | No. 12 SEPTEMBER 20, 1873 pp. 175-190 | . 1873 | 29 | 10.2307/e26044839 | No. 11 SEPTEMBER 13, 1873 pp. 159-174 | . 1873 | 29 | 10.2307/e26045822 | No. 10 SEPTEMBER 6, 1873 pp. 143-158 | . 1873 | 29 | 10.2307/e26045581 | No. 9 AUGUST 30, 1873 pp. 127-142 | . 1873 | 29 | 10.2307/e26045629 | No. 8 AUGUST 23, 1873 pp. 111-126 | . 1873 | 29 | 10.2307/e26042869 | No. 7 AUGUST 16, 1873 pp. 95-110 | . 1873 | 29 | 10.2307/e26044979 | No. 6 AUGUST 9, 1873 pp. 79-94 | . 1873 | 29 | 10.2307/e26045874 | No. 5 AUGUST 2, 1873 pp. 63-78 | . 1873 | 29 | 10.2307/e26043795 | No. 4 JULY 26, 1873 pp. 47-62 | . 1873 | 29 | 10.2307/e26045529 | No. 3 JULY 19, 1873 pp. 31-46 | . 1873 | 29 | 10.2307/e26042544 | No. 2 JULY 12, 1873 pp. 15-30 | . 1873 | 29 | 10.2307/e26046173 | No. 1 JULY 5, 1873 pp. 1-14 | . 1873 | 28 | 10.2307/e26044090 | No. 26 JUNE 28, 1873 pp. 399-414 | . 1873 | 28 | 10.2307/e26045770 | No. 25 JUNE 21, 1873 pp. 383-398 | . 1873 | 28 | 10.2307/e26043477 | No. 24 JUNE 14, 1873 pp. 367-382 | . 1873 | 28 | 10.2307/e26045363 | No. 23 JUNE 7, 1873 pp. 351-366 | . 1873 | 28 | 10.2307/e26041983 | No. 22 MAY 31, 1873 pp. 335-350 | . 1873 | 28 | 10.2307/e26042103 | No. 21 MAY 24, 1873 pp. 319-334 | . 1873 | 28 | 10.2307/e26044537 | No. 20 MAY 17, 1873 pp. 303-318 | . 1873 | 28 | 10.2307/e26045721 | No. 19 MAY 10, 1873 pp. 287-302 | . 1873 | 28 | 10.2307/e26043319 | No. 18 MAY 3, 1873 pp. 271-286 | . 1873 | 28 | 10.2307/e26042406 | No. 17 APRIL 26, 1873 pp. 255-270 | . 1873 | 28 | 10.2307/e26044677 | No. 16 APRIL 19, 1873 pp. 239-254 | . 1873 | 28 | 10.2307/e26046043 | No. 15 APRIL 12, 1873 pp. 223-238 | . 1873 | 28 | 10.2307/e26043938 | No. 14 APRIL 5, 1873 pp. 207-222 | . 1873 | 28 | 10.2307/e26042692 | No. 13 MARCH 29, 1873 pp. 191-206 | . 1873 | 28 | 10.2307/e26045472 | No. 12 MARCH 22, 1873 pp. 175-190 | . 1873 | 28 | 10.2307/e26044382 | No. 11 MARCH 15, 1873 pp. 159-174 | . 1873 | 28 | 10.2307/e26043016 | No. 10 MARCH 8, 1873 pp. 143-158 | . 1873 | 28 | 10.2307/e26045970 | No. 9 MARCH 1, 1873 pp. 127-142 | . 1873 | 28 | 10.2307/e26052271 | No. 8 FEBRUARY 22, 1873 pp. 111-126 | . 1873 | 28 | 10.2307/e26050249 | No. 7 FEBRUARY 15, 1873 pp. 95-110 | . 1873 | 28 | 10.2307/e26048284 | No. 6 FEBRUARY 8, 1873 pp. 79-94 | . 1873 | 28 | 10.2307/e26051083 | No. 5 FEBRUARY 1, 1873 pp. 63-78 | . 1873 | 28 | 10.2307/e26053588 | No. 4 JANUARY 25, 1873 pp. 47-62 | . 1873 | 28 | 10.2307/e26049586 | No. 3 JANUARY 18, 1873 pp. 31-46 | . 1873 | 28 | 10.2307/e26052496 | No. 2 JANUARY 11, 1873 pp. 15-30 | . 1873 | 28 | 10.2307/e26055055 | No. 1 JANUARY 4, 1873 pp. 1-14 | . 1872 | 27 | 10.2307/e26051952 | No. 26 DECEMBER 28, 1872 pp. 399-414 | . 1872 | 27 | 10.2307/e26054128 | No. 25 DECEMBER 21, 1872 pp. 383-398 | . 1872 | 27 | 10.2307/e26053367 | No. 24 DECEMBER 14, 1872 pp. 367-382 | . 1872 | 27 | 10.2307/e26053574 | No. 23 DECEMBER 7, 1872 pp. 351-366 | . 1872 | 27 | 10.2307/e26049133 | No. 22 NOVEMBER 30, 1872 pp. 335-350 | . 1872 | 27 | 10.2307/e26052188 | No. 21 NOVEMBER 23, 1872 pp. 319-334 | . 1872 | 27 | 10.2307/e26054321 | No. 20 NOVEMBER 16, 1872 pp. 303-318 | . 1872 | 27 | 10.2307/e26050468 | No. 19 NOVEMBER 9, 1872 pp. 287-302 | . 1872 | 27 | 10.2307/e26053103 | No. 18 NOVEMBER 2, 1872 pp. 271-286 | . 1872 | 27 | 10.2307/e26048728 | No. 17 OCTOBER 26, 1872 pp. 255-270 | . 1872 | 27 | 10.2307/e26054852 | No. 16 OCTOBER 19, 1872 pp. 239-254 | . 1872 | 27 | 10.2307/e26050857 | No. 15 OCTOBER 12, 1872 pp. 223-238 | . 1872 | 27 | 10.2307/e26053930 | No. 14 OCTOBER 5, 1872 pp. 207-222 | . 1872 | 27 | 10.2307/e26050033 | No. 13 SEPTEMBER 28, 1872 pp. 191-206 | . 1872 | 27 | 10.2307/e26052712 | No. 12 SEPTEMBER 21, 1872 pp. 175-190 | . 1872 | 27 | 10.2307/e26048126 | No. 11 SEPTEMBER 14, 1872 pp. 159-174 | . 1872 | 27 | 10.2307/e26048176 | No. 10 SEPTEMBER 7, 1872 pp. 143-158 | . 1872 | 27 | 10.2307/e26051470 | No. 9 AUGUST 31, 1872 pp. 127-142 | . 1872 | 27 | 10.2307/e26053784 | No. 8 AUGUST 24, 1872 pp. 111-126 | . 1872 | 27 | 10.2307/e26049804 | No. 7 AUGUST 17, 1872 pp. 95-110 | . 1872 | 27 | 10.2307/e26048516 | No. 6 AUGUST 10, 1872 pp. 79-94 | . 1872 | 27 | 10.2307/e26051730 | No. 5 AUGUST 3, 1872 pp. 63-78 | . 1872 | 27 | 10.2307/e26054634 | No. 4 JULY 27, 1872 pp. 47-62 | . 1872 | 27 | 10.2307/e26050662 | No. 3 JULY 20, 1872 pp. 31-46 | . 1872 | 27 | 10.2307/e26048950 | No. 2 JULY 13, 1872 pp. 15-30 | . 1872 | 27 | 10.2307/e26052957 | No. 1 JULY 6, 1872 pp. 1-14 | . 1872 | 26 | 10.2307/e26051279 | No. 26 JUNE 22, 1872 pp. 407-422 | . 1872 | 26 | 10.2307/e26049362 | No. 25 JUNE 15, 1872 pp. 391-406 | . 1872 | 26 | 10.2307/e26054529 | No. 24 JUNE 8, 1872 pp. 375-390 | . 1872 | 26 | 10.2307/e26042952 | No. 23 JUNE 1, 1872 pp. 359-374 | . 1872 | 26 | 10.2307/e26041583 | No. 22 MAY 25, 1872 pp. 343-358 | . 1872 | 26 | 10.2307/e26040517 | No. 21 MAY 18, 1872 pp. 319-334 | . 1872 | 26 | 10.2307/e26042127 | No. 20 MAY 11, 1872 pp. 303-318 | . 1872 | 26 | 10.2307/e26044058 | No. 19 MAY 4, 1872 pp. 287-302 | . 1872 | 26 | 10.2307/e26041242 | No. 18 APRIL 27, 1872 pp. 271-286 | . 1872 | 26 | 10.2307/e26043097 | No. 17 APRIL 20, 1872 pp. 255-270 | . 1872 | 26 | 10.2307/e26045298 | No. 16 APRIL 13, 1872 pp. 239-254 | . 1872 | 26 | 10.2307/e26042636 | No. 15 APRIL 6, 1872 pp. 223-238 | . 1872 | 26 | 10.2307/e26044535 | No. 14 MARCH 30, 1872 pp. 207-222 | . 1872 | 26 | 10.2307/e26043764 | No. 13 MARCH 23, 1872 pp. 191-206 | . 1872 | 26 | 10.2307/e26043905 | No. 12 MARCH 16, 1872 pp. 175-190 | . 1872 | 26 | 10.2307/e26040989 | No. 11 MARCH 9, 1872 pp. 159-174 | . 1872 | 26 | 10.2307/e26042795 | No. 10 MARCH 2, 1872 pp. 143-158 | . 1872 | 26 | 10.2307/e26044681 | No. 9 FEBRUARY 24, 1872 pp. 127-142 | . 1872 | 26 | 10.2307/e26041708 | No. 8 FEBRUARY 17, 1872 pp. 111-126 | . 1872 | 26 | 10.2307/e26043591 | No. 7 FEBRUARY 10, 1872 pp. 95-110 | . 1872 | 26 | 10.2307/e26040748 | No. 6 FEBRUARY 3, 1872 pp. 79-94 | . 1872 | 26 | 10.2307/e26045141 | No. 5 JANUARY 27, 1872 pp. 63-78 | . 1872 | 26 | 10.2307/e26041987 | No. 4 JANUARY 20, 1872 pp. 47-62 | . 1872 | 26 | 10.2307/e26044385 | No. 3 JANUARY 13, 1872 pp. 31-46 | . 1872 | 26 | 10.2307/e26041466 | No. 2 JANUARY 6, 1872 pp. 15-30 | . 1872 | 26 | 10.2307/e26043264 | No. 1 JANUARY 1, 1872 pp. 1-14 | . 1871 | 25 | 10.2307/e26040280 | No. 26 DECEMBER 23, 1871 pp. 399-414 | . 1871 | 25 | 10.2307/e26040373 | No. 25 DECEMBER 16, 1871 pp. 383-398 | . 1871 | 25 | 10.2307/e26042473 | No. 24 DECEMBER 9, 1871 pp. 367-382 | . 1871 | 25 | 10.2307/e26044202 | No. 23 DECEMBER 2, 1871 pp. 351-366 | . 1871 | 25 | 10.2307/e26041344 | No. 22 NOVEMBER 25, 1871 pp. 335-350 | . 1871 | 25 | 10.2307/e26040627 | No. 21 NOVEMBER 18, 1871 pp. 319-334 | . 1871 | 25 | 10.2307/e26042474 | No. 20 NOVEMBER 11, 1871 pp. 303-318 | . 1871 | 25 | 10.2307/e26044992 | No. 19 NOVEMBER 4, 1871 pp. 287-302 | . 1871 | 25 | 10.2307/e26041857 | No. 18 OCTOBER 28, 1871 pp. 271-286 | . 1871 | 25 | 10.2307/e26040846 | No. 17 OCTOBER 21, 1871 pp. 255-270 | . 1871 | 25 | 10.2307/e26043424 | No. 16 OCTOBER 14, 1871 pp. 239-254 | . 1871 | 25 | 10.2307/e26042261 | No. 15 OCTOBER 7, 1871 pp. 223-238 | . 1871 | 25 | 10.2307/e26041123 | No. 14 SEPTEMBER 30, 1871 pp. 207-222 | . 1871 | 25 | 10.2307/e26044840 | No. 13 SEPTEMBER 23, 1871 pp. 191-206 | . 1871 | 25 | 10.2307/e26042926 | No. 12 SEPTEMBER 16, 1871 pp. 175-190 | . 1871 | 25 | 10.2307/e26041459 | No. 11 SEPTEMBER 9, 1871 pp. 159-174 | . 1871 | 25 | 10.2307/e26040445 | No. 10 SEPTEMBER 2, 1871 pp. 143-158 | . 1871 | 25 | 10.2307/e26041980 | No. 9 AUGUST 26, 1871 pp. 127-142 | . 1871 | 25 | 10.2307/e26044014 | No. 8 AUGUST 19, 1871 pp. 111-126 | . 1871 | 25 | 10.2307/e26041121 | No. 7 AUGUST 12, 1871 pp. 95-110 | . 1871 | 25 | 10.2307/e26043073 | No. 6 AUGUST 5, 1871 pp. 79-94 | . 1871 | 25 | 10.2307/e26045260 | No. 5 JULY 29, 1871 pp. 63-78 | . 1871 | 25 | 10.2307/e26042583 | No. 4 JULY 22, 1871 pp. 47-62 | . 1871 | 25 | 10.2307/e26044493 | No. 3 JULY 15, 1871 pp. 31-46 | . 1871 | 25 | 10.2307/e26043725 | No. 2 JULY 8, 1871 pp. 15-30 | . 1871 | 25 | 10.2307/e26043874 | No. 1 JULY 1, 1871 pp. 1-14 | . 1871 | 24 | 10.2307/e26040909 | No. 26 JUNE 24, 1871 pp. 399-414 | . 1871 | 24 | 10.2307/e26042760 | No. 25 JUNE 17, 1871 pp. 383-398 | . 1871 | 24 | 10.2307/e26044662 | No. 24 JUNE 10, 1871 pp. 367-382 | . 1871 | 24 | 10.2307/e26041584 | No. 23 JUNE 3, 1871 pp. 351-366 | . 1871 | 24 | 10.2307/e26043548 | No. 22 MAY 27, 1871 pp. 335-350 | . 1871 | 24 | 10.2307/e26040653 | No. 21 MAY 20, 1871 pp. 319-334 | . 1871 | 24 | 10.2307/e26045104 | No. 20 MAY 13, 1871 pp. 303-318 | . 1871 | 24 | 10.2307/e26041858 | No. 19 MAY 6, 1871 pp. 287-302 | . 1871 | 24 | 10.2307/e26044331 | No. 18 APRIL 29, 1871 pp. 271-286 | . 1871 | 24 | 10.2307/e26171380 | No. 17 APRIL 22, 1871 pp. 255-270 | . 1871 | 24 | 10.2307/e26041332 | No. 16 APRIL 15, 1871 pp. 239-254 | . 1871 | 24 | 10.2307/e26043237 | No. 14 APRIL 1, 1871 pp. 207-222 | . 1871 | 24 | 10.2307/e26040253 | No. 13 MARCH 25, 1871 pp. 191-206 | . 1871 | 24 | 10.2307/e26040317 | No. 12 MARCH 18, 1871 pp. 175-190 | . 1871 | 24 | 10.2307/e26042279 | No. 11 MARCH 11, 1871 pp. 159-174 | . 1871 | 24 | 10.2307/e26044165 | No. 10 MARCH 4, 1871 pp. 143-158 | . 1871 | 24 | 10.2307/e26041201 | No. 9 FEBRUARY 25, 1871 pp. 127-142 | . 1871 | 24 | 10.2307/e26040550 | No. 8 FEBRUARY 18, 1871 pp. 111-126 | . 1871 | 24 | 10.2307/e26042450 | No. 7 FEBRUARY 11, 1871 pp. 95-110 | . 1871 | 24 | 10.2307/e26044967 | No. 6 FEBRUARY 4, 1871 pp. 79-94 | . 1871 | 24 | 10.2307/e26041709 | No. 5 JANUARY 28, 1871 pp. 63-78 | . 1871 | 24 | 10.2307/e26040800 | No. 4 JANUARY 21, 1871 pp. 47-62 | . 1871 | 24 | 10.2307/e26043383 | No. 3 JANUARY 14, 1871 pp. 31-46 | . 1871 | 24 | 10.2307/e26042140 | No. 2 JANUARY 7, 1871 pp. 15-30 | . 1871 | 24 | 10.2307/e26041029 | No. 1 JANUARY 1, 1871 pp. 1-14 | . 1870 | 23 | 10.2307/e26044818 | No. 26 DECEMBER 24, 1870 pp. 399-414 | . 1870 | 23 | 10.2307/e26032241 | No. 25 DECEMBER 17, 1870 pp. 383-398 | . 1870 | 23 | 10.2307/e26171486 | No. 24 DECEMBER 10, 1870 pp. 367-382 | . 1870 | 23 | 10.2307/e26030922 | No. 23 DECEMBER 3, 1870 pp. 351-366 | . 1870 | 23 | 10.2307/e26029147 | No. 22 NOVEMBER 26, 1870 pp. 335-350 | . 1870 | 23 | 10.2307/e26031344 | No. 21 NOVEMBER 19, 1870 pp. 319-334 | . 1870 | 23 | 10.2307/e26033292 | No. 20 NOVEMBER 12, 1870 pp. 303-318 | . 1870 | 23 | 10.2307/e26030487 | No. 19 NOVEMBER 5, 1870 pp. 287-302 | . 1870 | 23 | 10.2307/e26032426 | No. 18 OCTOBER 29, 1870 pp. 271-286 | . 1870 | 23 | 10.2307/e26034064 | No. 17 OCTOBER 22, 1870 pp. 255-270 | . 1870 | 23 | 10.2307/e26031984 | No. 16 OCTOBER 15, 1870 pp. 239-254 | . 1870 | 23 | 10.2307/e26033532 | No. 15 OCTOBER 8, 1870 pp. 223-238 | . 1870 | 23 | 10.2307/e26033003 | No. 14 OCTOBER 1, 1870 pp. 207-222 | . 1870 | 23 | 10.2307/e26033163 | No. 13 SEPTEMBER 24, 1870 pp. 191-206 | . 1870 | 23 | 10.2307/e26030111 | No. 12 SEPTEMBER 17, 1870 pp. 175-190 | . 1870 | 23 | 10.2307/e26032119 | No. 11 SEPTEMBER 10, 1870 pp. 159-174 | . 1870 | 23 | 10.2307/e26033579 | No. 10 SEPTEMBER 3, 1870 pp. 143-158 | . 1870 | 23 | 10.2307/e26031017 | No. 9 AUGUST 27, 1870 pp. 127-142 | . 1870 | 23 | 10.2307/e26032856 | No. 8 AUGUST 20, 1870 pp. 111-126 | . 1870 | 23 | 10.2307/e26029648 | No. 7 AUGUST 13, 1870 pp. 95-110 | . 1870 | 23 | 10.2307/e26033888 | No. 6 AUGUST 6, 1870 pp. 79-94 | . 1870 | 23 | 10.2307/e26031202 | No. 5 JULY 30, 1870 pp. 63-78 | . 1870 | 23 | 10.2307/e26033475 | No. 4 JULY 23, 1870 pp. 47-62 | . 1870 | 23 | 10.2307/e26030826 | No. 3 JULY 16, 1870 pp. 31-46 | . 1870 | 23 | 10.2307/e26032585 | No. 2 JULY 9, 1870 pp. 15-30 | . 1870 | 23 | 10.2307/e26028652 | No. 1 JULY 2, 1870 pp. 1-14 | . 1870 | 22 | 10.2307/e26028869 | No. 26 JUNE 25, 1870 pp. 407-422 | . 1870 | 22 | 10.2307/e26031652 | No. 25 JUNE 18, 1870 pp. 391-406 | . 1870 | 22 | 10.2307/e26033425 | No. 24 JUNE 11, 1870 pp. 375-390 | . 1870 | 22 | 10.2307/e26030643 | No. 23 JUNE 4, 1870 pp. 359-374 | . 1870 | 22 | 10.2307/e26029417 | No. 22 MAY 28, 1870 pp. 343-358 | . 1870 | 22 | 10.2307/e26031807 | No. 21 MAY 21, 1870 pp. 327-342 | . 1870 | 22 | 10.2307/e26033751 | No. 20 MAY 14, 1870 pp. 311-326 | . 1870 | 22 | 10.2307/e26171327 | No. 19 MAY 7, 1870 pp. 295-310 | . 1870 | 22 | 10.2307/e26031100 | No. 18 APRIL 30, 1870 pp. 279-294 | . 1870 | 22 | 10.2307/e26029892 | No. 17 APRIL 23, 1870 pp. 263-278 | . 1870 | 22 | 10.2307/e26032719 | No. 16 APRIL 16, 1870 pp. 247-262 | . 1870 | 22 | 10.2307/e26031478 | No. 15 APRIL 9, 1870 pp. 231-246 | . 1870 | 22 | 10.2307/e26030315 | No. 14 APRIL 2, 1870 pp. 215-230 | . 1870 | 22 | 10.2307/e26033683 | No. 13 MARCH 26, 1870 pp. 199-214 | . 1870 | 22 | 10.2307/e26035677 | No. 12 MARCH 19, 1870 pp. 183-198 | . 1870 | 22 | 10.2307/e26034743 | No. 11 MARCH 12, 1870 pp. 167-182 | . 1870 | 22 | 10.2307/e26033684 | No. 10 MARCH 5, 1870 pp. 151-166 | . 1870 | 22 | 10.2307/e26035174 | No. 9 FEBRUARY 26, 1870 pp. 135-150 | . 1870 | 22 | 10.2307/e26036428 | No. 8 FEBRUARY 19, 1870 pp. 119-134 | . 1870 | 22 | 10.2307/e26034396 | No. 7 FEBRUARY 12, 1870 pp. 103-118 | . 1870 | 22 | 10.2307/e26035754 | No. 6 FEBRUARY 5, 1870 pp. 87-102 | . 1870 | 22 | 10.2307/e26037956 | No. 5 JANUARY 29, 1870 pp. 71-86 | . 1870 | 22 | 10.2307/e26035582 | No. 4 JANUARY 22, 1870 pp. 55-70 | . 1870 | 22 | 10.2307/e26036880 | No. 3 JANUARY 15, 1870 pp. 39-54 | . 1870 | 22 | 10.2307/e26036123 | No. 2 JANUARY 8, 1870 pp. 23-38 | . 1870 | 22 | 10.2307/e26036249 | No. 1 JANUARY 1, 1870 pp. 1-22 | . 1869 | 21 | 10.2307/e26034231 | No. 26 DECEMBER 25, 1869 pp. 401-414 | . 1869 | 21 | 10.2307/e26035583 | No. 25 DECEMBER 18, 1869 pp. 385-400 | . 1869 | 21 | 10.2307/e26037065 | No. 24 DECEMBER 11, 1869 pp. 369-384 | . 1869 | 21 | 10.2307/e26034844 | No. 23 DECEMBER 4, 1869 pp. 353-368 | . 1869 | 21 | 10.2307/e26036037 | No. 22 NOVEMBER 27, 1869 pp. 337-352 | . 1869 | 21 | 10.2307/e26033934 | No. 21 NOVEMBER 20, 1869 pp. 321-336 | . 1869 | 21 | 10.2307/e26037725 | No. 20 NOVEMBER 13, 1869 pp. 305-320 | . 1869 | 21 | 10.2307/e26035062 | No. 19 NOVEMBER 6, 1869 pp. 289-304 | . 1869 | 21 | 10.2307/e26036744 | No. 18 OCTOBER 30, 1869 pp. 273-288 | . 1869 | 21 | 10.2307/e26034638 | No. 17 OCTOBER 23, 1869 pp. 257-272 | . 1869 | 21 | 10.2307/e26035855 | No. 16 OCTOBER 16, 1869 pp. 241-256 | . 1869 | 21 | 10.2307/e26033556 | No. 15 OCTOBER 9, 1869 pp. 225-240 | . 1869 | 21 | 10.2307/e26033670 | No. 14 OCTOBER 2, 1869 pp. 209-224 | . 1869 | 21 | 10.2307/e26035364 | No. 13 SEPTEMBER 25, 1869 pp. 193-208 | . 1869 | 21 | 10.2307/e26036583 | No. 12 SEPTEMBER 18, 1869 pp. 177-192 | . 1869 | 21 | 10.2307/e26034454 | No. 11 SEPTEMBER 11, 1869 pp. 161-176 | . 1869 | 21 | 10.2307/e26033783 | No. 10 SEPTEMBER 4, 1869 pp. 145-160 | . 1869 | 21 | 10.2307/e26035474 | No. 9 AUGUST 28, 1869 pp. 129-144 | . 1869 | 21 | 10.2307/e26037462 | No. 8 AUGUST 21, 1869 pp. 113-128 | . 1869 | 21 | 10.2307/e26034945 | No. 7 AUGUST 14, 1869 pp. 97-112 | . 1869 | 21 | 10.2307/e26034082 | No. 6 AUGUST 7, 1869 pp. 81-96 | . 1869 | 21 | 10.2307/e26035944 | No. 5 JULY 31, 1869 pp. 65-80 | . 1869 | 21 | 10.2307/e26035273 | No. 4 JULY 24, 1869 pp. 49-64 | . 1869 | 21 | 10.2307/e26034315 | No. 2 JULY 10, 1869 pp. 17-32 | . 1869 | 21 | 10.2307/e26037283 | No. 1 JULY 3, 1869 pp. 1-16 | . 1869 | 20 | 10.2307/e26030989 | No. 26 JUNE 26, 1869 pp. 401-414 | . 1869 | 20 | 10.2307/e26029128 | No. 24 JUNE 12, 1869 pp. 369-384 | . 1869 | 20 | 10.2307/e26027010 | No. 23 JUNE 5, 1869 pp. 353-368 | . 1869 | 20 | 10.2307/e26030026 | No. 21 MAY 22, 1869 pp. 321-336 | . 1869 | 20 | 10.2307/e26031956 | No. 20 MAY 15, 1869 pp. 305-320 | . 1869 | 20 | 10.2307/e26028351 | No. 19 MAY 8, 1869 pp. 289-304 | . 1869 | 20 | 10.2307/e26031052 | No. 18 MAY 1, 1869 pp. 273-288 | . 1869 | 20 | 10.2307/e26033211 | No. 17 APRIL 24, 1869 pp. 257-272 | . 1869 | 20 | 10.2307/e26030730 | No. 16 APRIL 17, 1869 pp. 241-256 | . 1869 | 20 | 10.2307/e26032429 | No. 15 APRIL 10, 1869 pp. 225-240 | . 1869 | 20 | 10.2307/e26031642 | No. 14 APRIL 3, 1869 pp. 209-224 | . 1869 | 20 | 10.2307/e26031789 | No. 13 MARCH 27, 1869 pp. 193-208 | . 1869 | 20 | 10.2307/e26027928 | No. 12 MARCH 20, 1869 pp. 177-192 | . 1869 | 20 | 10.2307/e26030880 | No. 11 MARCH 13, 1869 pp. 161-176 | . 1869 | 20 | 10.2307/e26032592 | No. 10 MARCH 6, 1869 pp. 145-160 | . 1869 | 20 | 10.2307/e26029401 | No. 9 FEBRUARY 27, 1869 pp. 129-144 | . 1869 | 20 | 10.2307/e26031455 | No. 8 FEBRUARY 20, 1869 pp. 113-128 | . 1869 | 20 | 10.2307/e26027552 | No. 6 FEBRUARY 6, 1869 pp. 81-96 | . 1869 | 20 | 10.2307/e26033072 | No. 5 JANUARY 30, 1869 pp. 65-80 | . 1869 | 20 | 10.2307/e26029801 | No. 4 JANUARY 23, 1869 pp. 49-64 | . 1869 | 20 | 10.2307/e26032254 | No. 3 JANUARY 16, 1869 pp. 33-48 | . 1869 | 20 | 10.2307/e26028733 | No. 2 JANUARY 9, 1869 pp. 17-32 | . 1869 | 20 | 10.2307/e26031157 | No. 1 JANUARY 1, 1869 pp. 1-16 | . 1868 | 19 | 10.2307/e26026757 | No. 26 DECEMBER 23, 1868 pp. 401-414 | . 1868 | 19 | 10.2307/e26026859 | No. 25 DECEMBER 16, 1868 pp. 385-400 | . 1868 | 19 | 10.2307/e26030402 | No. 24 DECEMBER 9, 1868 pp. 369-384 | . 1868 | 19 | 10.2307/e26032118 | No. 23 DECEMBER 2, 1868 pp. 353-368 | . 1868 | 19 | 10.2307/e26028533 | No. 22 NOVEMBER 25, 1868 pp. 337-352 | . 1868 | 19 | 10.2307/e26027314 | No. 21 NOVEMBER 18, 1868 pp. 321-336 | . 1868 | 19 | 10.2307/e26030598 | No. 20 NOVEMBER 11, 1868 pp. 305-320 | . 1868 | 19 | 10.2307/e26032900 | No. 19 NOVEMBER 4, 1868 pp. 289-304 | . 1868 | 19 | 10.2307/e26029584 | No. 18 OCTOBER 28, 1868 pp. 273-288 | . 1868 | 19 | 10.2307/e26027785 | No. 17 OCTOBER 21, 1868 pp. 257-272 | . 1868 | 19 | 10.2307/e26031318 | No. 16 OCTOBER 14, 1868 pp. 241-256 | . 1868 | 19 | 10.2307/e26030198 | No. 15 OCTOBER 7, 1868 pp. 225-239 | . 1868 | 19 | 10.2307/e26028153 | No. 14 SEPTEMBER 30, 1868 pp. 209-224 | . 1868 | 19 | 10.2307/e26032732 | No. 13 SEPTEMBER 23, 1868 pp. 193-208 | . 1868 | 19 | 10.2307/e26027396 | No. 12 SEPTEMBER 16, 1868 pp. 177-192 | . 1868 | 19 | 10.2307/e26025859 | No. 11 SEPTEMBER 9, 1868 pp. 161-176 | . 1868 | 19 | 10.2307/e26024633 | No. 10 SEPTEMBER 2, 1868 pp. 145-160 | . 1868 | 19 | 10.2307/e26026408 | No. 9 AUGUST 26, 1868 pp. 129-144 | . 1868 | 19 | 10.2307/e26028843 | No. 8 AUGUST 19, 1868 pp. 113-128 | . 1868 | 19 | 10.2307/e26025466 | No. 7 AUGUST 12, 1868 pp. 97-112 | . 1868 | 19 | 10.2307/e26027603 | No. 6 AUGUST 5, 1868 pp. 81-96 | . 1868 | 19 | 10.2307/e26030592 | No. 5 JULY 29, 1868 pp. 65-80 | . 1868 | 19 | 10.2307/e26026946 | No. 4 JULY 22, 1868 pp. 49-64 | . 1868 | 19 | 10.2307/e26029526 | No. 3 JULY 15, 1868 pp. 33-48 | . 1868 | 19 | 10.2307/e26028400 | No. 2 JULY 8, 1868 pp. 17-32 | . 1868 | 19 | 10.2307/e26028598 | No. 1 JULY 1, 1868 pp. 1-16 | . 1868 | 18 | 10.2307/e26025280 | No. 26 JUNE 27, 1868 pp. 401-414 | . 1868 | 18 | 10.2307/e26027121 | No. 25 JUNE 20, 1868 pp. 385-400 | . 1868 | 18 | 10.2307/e26029777 | No. 24 JUNE 13, 1868 pp. 369-384 | . 1868 | 18 | 10.2307/e26026008 | No. 23 JUNE 6, 1868 pp. 353-368 | . 1868 | 18 | 10.2307/e26028243 | No. 22 MAY 30, 1868 pp. 337-352 | . 1868 | 18 | 10.2307/e26024970 | No. 21 MAY 23, 1868 pp. 321-336 | . 1868 | 18 | 10.2307/e26030385 | No. 20 MAY 16, 1868 pp. 305-320 | . 1868 | 18 | 10.2307/e26026261 | No. 19 MAY 9, 1868 pp. 289-304 | . 1868 | 18 | 10.2307/e26029292 | No. 18 MAY 2, 1868 pp. 273-288 | . 1868 | 18 | 10.2307/e26025734 | No. 17 APRIL 25, 1868 pp. 257-272 | . 1868 | 18 | 10.2307/e26027823 | No. 16 APRIL 18, 1868 pp. 241-256 | . 1868 | 18 | 10.2307/e26024209 | No. 15 APRIL 11, 1868 pp. 225-240 | . 1868 | 18 | 10.2307/e26024434 | No. 14 APRIL 4, 1868 pp. 209-224 | . 1868 | 18 | 10.2307/e26026675 | No. 13 MARCH 28, 1868 pp. 193-208 | . 1868 | 18 | 10.2307/e26029088 | No. 12 MARCH 21, 1868 pp. 177-192 | . 1868 | 18 | 10.2307/e26025613 | No. 11 MARCH 14, 1868 pp. 161-176 | . 1868 | 18 | 10.2307/e26024762 | No. 10 MARCH 7, 1868 pp. 145-160 | . 1868 | 18 | 10.2307/e26026795 | No. 9 FEBRUARY 29, 1868 pp. 129-144 | . 1868 | 18 | 10.2307/e26030179 | No. 8 FEBRUARY 22, 1868 pp. 113-128 | . 1868 | 18 | 10.2307/e26026128 | No. 7 FEBRUARY 15, 1868 pp. 97-112 | . 1868 | 18 | 10.2307/e26025132 | No. 6 FEBRUARY 8, 1868 pp. 81-96 | . 1868 | 18 | 10.2307/e26027987 | No. 5 FEBRUARY 1, 1868 pp. 65-80 | . 1868 | 18 | 10.2307/e26026532 | No. 4 JANUARY 25, 1868 pp. 49-64 | . 1868 | 18 | 10.2307/e26025343 | No. 3 JANUARY 18, 1868 pp. 33-48 | . 1868 | 18 | 10.2307/e26030016 | No. 2 JANUARY 11, 1868 pp. 17-32 | . 1868 | 18 | 10.2307/e26026334 | No. 1 JANUARY 4, 1868 pp. 1-16 | . 1867 | 17 | 10.2307/e26025065 | No. 26 DECEMBER 28, 1867 pp. 401-410 | . 1867 | 17 | 10.2307/e26023535 | No. 25 DECEMBER 21, 1867 pp. 385-400 | . 1867 | 17 | 10.2307/e26025564 | No. 24 DECEMBER 14, 1867 pp. 369-384 | . 1867 | 17 | 10.2307/e26027558 | No. 23 DECEMBER 7, 1867 pp. 353-368 | . 1867 | 17 | 10.2307/e26024505 | No. 22 NOVEMBER 30, 1867 pp. 337-352 | . 1867 | 17 | 10.2307/e26026458 | No. 21 NOVEMBER 23, 1867 pp. 321-336 | . 1867 | 17 | 10.2307/e26029142 | No. 20 NOVEMBER 16, 1867 pp. 305-320 | . 1867 | 17 | 10.2307/e26026062 | No. 19 NOVEMBER 9, 1867 pp. 289-304 | . 1867 | 17 | 10.2307/e26028119 | No. 18 NOVEMBER 2, 1867 pp. 273-288 | . 1867 | 17 | 10.2307/e26027083 | No. 17 OCTOBER 26, 1867 pp. 257-272 | . 1867 | 17 | 10.2307/e26027352 | No. 16 OCTOBER 19, 1867 pp. 241-256 | . 1867 | 17 | 10.2307/e26024173 | No. 15 OCTOBER 12, 1867 pp. 225-240 | . 1867 | 17 | 10.2307/e26026199 | No. 14 OCTOBER 5, 1867 pp. 209-224 | . 1867 | 17 | 10.2307/e26028244 | No. 13 SEPTEMBER 28, 1867 pp. 193-208 | . 1867 | 17 | 10.2307/e26025168 | No. 12 SEPTEMBER 21, 1867 pp. 177-192 | . 1867 | 17 | 10.2307/e26026910 | No. 11 SEPTEMBER 14, 1867 pp. 161-176 | . 1867 | 17 | 10.2307/e26023859 | No. 10 SEPTEMBER 7, 1867 pp. 145-160 | . 1867 | 17 | 10.2307/e26028879 | No. 9 AUGUST 31, 1867 pp. 129-142 | . 1867 | 17 | 10.2307/e26025413 | No. 8 AUGUST 24, 1867 pp. 113-128 | . 1867 | 17 | 10.2307/e26027935 | No. 7 AUGUST 17, 1867 pp. 97-112 | . 1867 | 17 | 10.2307/e26024877 | No. 6 AUGUST 10, 1867 pp. 81-96 | . 1867 | 17 | 10.2307/e26026617 | No. 5 AUGUST 3, 1867 pp. 65-80 | . 1867 | 17 | 10.2307/e26023011 | No. 4 JULY 27, 1867 pp. 49-64 | . 1867 | 17 | 10.2307/e26023310 | No. 3 JULY 20, 1867 pp. 33-48 | . 1867 | 17 | 10.2307/e26025815 | No. 2 JULY 13, 1867 pp. 17-32 | . 1867 | 17 | 10.2307/e26171440 | No. 1 JULY 6, 1867 pp. I-IV, 1-16 | . 1867 | 16 | 10.2307/e26171057 | No. 26 JUNE 29, 1867 pp. 405-420, I-IV | . 1867 | 16 | 10.2307/e26027781 | No. 24 JUNE 15, 1867 pp. 373-388 | . 1867 | 16 | 10.2307/e26024681 | No. 23 JUNE 8, 1867 pp. 357-372 | . 1867 | 16 | 10.2307/e26023729 | No. 22 JUNE 1, 1867 pp. 341-356 | . 1867 | 16 | 10.2307/e26025948 | No. 21 MAY 25, 1867 pp. 325-340 | . 1867 | 16 | 10.2307/e26028668 | No. 20 MAY 18, 1867 pp. 309-324 | . 1867 | 16 | 10.2307/e26025290 | No. 19 MAY 11, 1867 pp. 293-308 | . 1867 | 16 | 10.2307/e26024010 | No. 18 MAY 4, 1867 pp. 277-292 | . 1867 | 16 | 10.2307/e26026742 | No. 17 APRIL 27, 1867 pp. 261-276 | . 1867 | 16 | 10.2307/e26025681 | No. 16 APRIL 20, 1867 pp. 245-260 | . 1867 | 16 | 10.2307/e26024314 | No. 15 APRIL 13, 1867 pp. 229-244 | . 1867 | 16 | 10.2307/e26028466 | No. 14 APRIL 6, 1867 pp. 213-228 | . 1867 | 16 | 10.2307/e26022690 | No. 13 MARCH 30, 1867 pp. 197-212 | . 1867 | 16 | 10.2307/e26024678 | No. 12 MARCH 23, 1867 pp. 181-196 | . 1867 | 16 | 10.2307/e26026310 | No. 11 MARCH 16, 1867 pp. 165-180 | . 1867 | 16 | 10.2307/e26023862 | No. 10 MARCH 9, 1867 pp. 149-164 | . 1867 | 16 | 10.2307/e26025570 | No. 9 MARCH 2, 1867 pp. 133-148 | . 1867 | 16 | 10.2307/e26027483 | No. 8 FEBRUARY 23, 1867 pp. 117-132 | . 1867 | 16 | 10.2307/e26025291 | No. 7 FEBRUARY 16, 1867 pp. 101-116 | . 1867 | 16 | 10.2307/e26026646 | No. 6 FEBRUARY 9, 1867 pp. 85-100 | . 1867 | 16 | 10.2307/e26026035 | No. 5 FEBRUARY 2, 1867 pp. 69-84 | . 1867 | 16 | 10.2307/e26026174 | No. 4 JANUARY 26, 1867 pp. 53-68 | . 1867 | 16 | 10.2307/e26023485 | No. 3 JANUARY 19, 1867 pp. 33-52 | . 1867 | 16 | 10.2307/e26025411 | No. 2 JANUARY 12, 1867 pp. 17-32 | . 1867 | 16 | 10.2307/e26026753 | No. 1 JANUARY 5, 1867 pp. 1-16 | . 1866 | 15 | 10.2307/e26024257 | No. 26 DECEMBER 22, 1866 pp. 419-438 | . 1866 | 15 | 10.2307/e26025941 | No. 25 DECEMBER 15, 1866 pp. 401-418 | . 1866 | 15 | 10.2307/e26023084 | No. 24 DECEMBER 8, 1866 pp. 383-400 | . 1866 | 15 | 10.2307/e26027349 | No. 23 DECEMBER 1, 1866 pp. 367-382 | . 1866 | 15 | 10.2307/e26024577 | No. 22 NOVEMBER 24, 1866 pp. 349-366 | . 1866 | 15 | 10.2307/e26026531 | No. 21 NOVEMBER 17, 1866 pp. 331-348 | . 1866 | 15 | 10.2307/e26024172 | No. 20 NOVEMBER 10, 1866 pp. 315-330 | . 1866 | 15 | 10.2307/e26025692 | No. 19 NOVEMBER 3, 1866 pp. 297-314 | . 1866 | 15 | 10.2307/e26022452 | No. 18 OCTOBER 27, 1866 pp. 279-296 | . 1866 | 15 | 10.2307/e26022534 | No. 17 OCTOBER 20, 1866 pp. 263-278 | . 1866 | 15 | 10.2307/e26025038 | No. 16 OCTOBER 13, 1866 pp. 245-262 | . 1866 | 15 | 10.2307/e26026415 | No. 15 OCTOBER 6, 1866 pp. 229-244 | . 1866 | 15 | 10.2307/e26024017 | No. 14 SEPTEMBER 29, 1866 pp. 213-228 | . 1866 | 15 | 10.2307/e26022892 | No. 13 SEPTEMBER 22, 1866 pp. 195-212 | . 1866 | 15 | 10.2307/e26025155 | No. 12 SEPTEMBER 15, 1866 pp. 179-194 | . 1866 | 15 | 10.2307/e26027079 | No. 11 SEPTEMBER 8, 1866 pp. 159-178 | . 1866 | 15 | 10.2307/e26024447 | No. 10 SEPTEMBER 1, 1866 pp. 143-158 | . 1866 | 15 | 10.2307/e26023309 | No. 9 AUGUST 25, 1866 pp. 127-142 | . 1866 | 15 | 10.2307/e26025816 | No. 6 AUGUST 4, 1866 pp. 79-94 | . 1866 | 15 | 10.2307/e26024857 | No. 5 JULY 28, 1866 pp. 63-78 | . 1866 | 15 | 10.2307/e26023736 | No. 4 JULY 21, 1866 pp. 47-62 | . 1866 | 15 | 10.2307/e26026937 | No. 3 JULY 14, 1866 pp. 31-46 | . 1866 | 15 | 10.2307/e26140174 | No. 2 JULY 7, 1866 pp. 15-30 | . 1866 | 15 | 10.2307/e26140210 | No. 1 JUNE 30, 1866 pp. 1-14 | . 1866 | 14 | 10.2307/e24974303 | No. 26 JUNE 23, 1866 pp. 423-442 | . 1866 | 14 | 10.2307/e24972655 | No. 25 JUNE 16, 1866 pp. 407-422 | . 1866 | 14 | 10.2307/e24973881 | No. 24 JUNE 9, 1866 pp. 391-406 | . 1866 | 14 | 10.2307/e24974625 | No. 23 JUNE 2, 1866 pp. 375-390 | . 1866 | 14 | 10.2307/e24973682 | No. 22 MAY 26, 1866 pp. 355-374 | . 1866 | 14 | 10.2307/e24974420 | No. 21 MAY 19, 1866 pp. 335-354 | . 1866 | 14 | 10.2307/e24974126 | No. 20 MAY 12, 1866 pp. 315-334 | . 1866 | 14 | 10.2307/e24974246 | No. 19 MAY 5, 1866 pp. 295-314 | . 1866 | 14 | 10.2307/e24972526 | No. 18 APRIL 28, 1866 pp. 275-294 | . 1866 | 14 | 10.2307/e24973780 | No. 17 APRIL 21, 1866 pp. 255-274 | . 1866 | 14 | 10.2307/e24974473 | No. 16 APRIL 14, 1866 pp. 239-254 | . 1866 | 14 | 10.2307/e24973052 | No. 15 APRIL 7, 1866 pp. 223-238 | . 1866 | 14 | 10.2307/e24974027 | No. 14 MARCH 31, 1866 pp. 207-222 | . 1866 | 14 | 10.2307/e24972294 | No. 13 MARCH 24, 1866 pp. 191-206 | . 1866 | 14 | 10.2307/e24974593 | No. 12 MARCH 17, 1866 pp. 175-190 | . 1866 | 14 | 10.2307/e24973283 | No. 11 MARCH 10, 1866 pp. 159-174 | . 1866 | 14 | 10.2307/e24974383 | No. 10 MARCH 3, 1866 pp. 143-158 | . 1866 | 14 | 10.2307/e24972879 | No. 9 FEBRUARY 24, 1866 pp. 127-142 | . 1866 | 14 | 10.2307/e24973953 | No. 8 FEBRUARY 17, 1866 pp. 111-126 | . 1866 | 14 | 10.2307/e24971860 | No. 7 FEBRUARY 10, 1866 pp. 95-110 | . 1866 | 14 | 10.2307/e24971927 | No. 6 FEBRUARY 3, 1866 pp. 79-94 | . 1866 | 14 | 10.2307/e24973522 | No. 5 JANUARY 27, 1866 pp. 63-78 | . 1866 | 14 | 10.2307/e24974339 | No. 4 JANUARY 20, 1866 pp. 47-62 | . 1866 | 14 | 10.2307/e24972766 | No. 3 JANUARY 13, 1866 pp. 31-46 | . 1866 | 14 | 10.2307/e24972171 | No. 2 JANUARY 7 1866 pp. 15-30 | . 1866 | 14 | 10.2307/e24973622 | No. 1 JANUARY 1, 1866 pp. 1-14 | . 1865 | 13 | 10.2307/e24974556 | No. 26 DECEMBER 23, 1865 pp. 399-414 | . 1865 | 13 | 10.2307/e24973172 | No. 25 DECEMBER 16, 1865 pp. 383-398 | . 1865 | 13 | 10.2307/e24972407 | No. 24 DECEMBER 9, 1865 pp. 367-382 | . 1865 | 13 | 10.2307/e24974024 | No. 23 DECEMBER 2, 1865 pp. 351-366 | . 1865 | 13 | 10.2307/e24973438 | No. 22 NOVEMBER 25, 1865 pp. 335-350 | . 1865 | 13 | 10.2307/e24972527 | No. 21 NOVEMBER 18, 1865 pp. 319-334 | . 1865 | 13 | 10.2307/e24974513 | No. 20 NOVEMBER 11, 1865 pp. 303-318 | . 1865 | 13 | 10.2307/e24978164 | No. 19 NOVEMBER 4, 1865 pp. 287-302 | . 1865 | 13 | 10.2307/e24977739 | No. 18 OCTOBER 28, 1865 pp. 271-286 | . 1865 | 13 | 10.2307/e24977326 | No. 17 OCTOBER 21, 1865 pp. 255-270 | . 1865 | 13 | 10.2307/e24977902 | No. 16 OCTOBER 14, 1865 pp. 239-254 | . 1865 | 13 | 10.2307/e24978394 | No. 15 OCTOBER 7, 1865 pp. 223-238 | . 1865 | 13 | 10.2307/e24977611 | No. 14 SEPTEMBER 30, 1865 pp. 207-222 | . 1865 | 13 | 10.2307/e24978195 | No. 13 SEPTEMBER 23, 1865 pp. 191-206 | . 1865 | 13 | 10.2307/e24978729 | No. 12 SEPTEMBER 16, 1865 pp. 175-190 | . 1865 | 13 | 10.2307/e24978084 | No. 11 SEPTEMBER 9, 1865 pp. 159-174 | . 1865 | 13 | 10.2307/e24978505 | No. 10 SEPTEMBER 2, 1865 pp. 143-158 | . 1865 | 13 | 10.2307/e26001116 | No. 9 AUGUST 26, 1865 pp. 127-142 | . 1865 | 13 | 10.2307/e24978362 | No. 8 AUGUST 19, 1865 pp. 111-126 | . 1865 | 13 | 10.2307/e24977527 | No. 7 AUGUST 12, 1865 pp. 95-110 | . 1865 | 13 | 10.2307/e24978132 | No. 6 AUGUST 5, 1865 pp. 79-94 | . 1865 | 13 | 10.2307/e24978554 | No. 5 JULY 29, 1865 pp. 63-78 | . 1865 | 13 | 10.2307/e24977774 | No. 4 JULY 22, 1865 pp. 47-62 | . 1865 | 13 | 10.2307/e24978320 | No. 3 JULY 15, 1865 pp. 31-46 | . 1865 | 13 | 10.2307/e24977449 | No. 2 JULY 8, 1865 pp. 15-30 | . 1865 | 13 | 10.2307/e24978691 | No. 1 JULY 1, 1865 pp. 1-14 | . 1865 | 12 | 10.2307/e24977858 | No. 26 JUNE 24, 1865 pp. 399-414 | . 1865 | 12 | 10.2307/e24978470 | No. 25 JUNE 17, 1865 pp. 383-398 | . 1865 | 12 | 10.2307/e24977696 | No. 24 JUNE 10, 1865 pp. 367-382 | . 1865 | 12 | 10.2307/e24978234 | No. 23 JUNE 3, 1865 pp. 351-366 | . 1865 | 12 | 10.2307/e24977232 | No. 22 MAY 27, 1865 pp. 335-350 | . 1865 | 12 | 10.2307/e24977281 | No. 21 MAY 20, 1865 pp. 319-334 | . 1865 | 12 | 10.2307/e24977991 | No. 20 MAY 13, 1865 pp. 303-318 | . 1865 | 12 | 10.2307/e24978426 | No. 19 MAY 6, 1865 pp. 287-302 | . 1865 | 12 | 10.2307/e24977652 | No. 18 APRIL 29, 1865 pp. 271-286 | . 1865 | 12 | 10.2307/e24977400 | No. 17 APRIL 22, 1865 pp. 255-270 | . 1865 | 12 | 10.2307/e24978040 | No. 16 APRIL 15, 1865 pp. 239-254 | . 1865 | 12 | 10.2307/e24978641 | No. 15 APRIL 8, 1865 pp. 223-238 | . 1865 | 12 | 10.2307/e24977817 | No. 14 APRIL 1, 1865 pp. 207-222 | . 1865 | 12 | 10.2307/e24977488 | No. 13 MARCH 25, 1865 pp. 191-206 | . 1865 | 12 | 10.2307/e24978278 | No. 12 MARCH 18, 1865 pp. 175-190 | . 1865 | 12 | 10.2307/e24977940 | No. 11 MARCH 11, 1865 pp. 159-174 | . 1865 | 12 | 10.2307/e24977565 | No. 10 MARCH 4, 1865 pp. 143-158 | . 1865 | 12 | 10.2307/e24978593 | No. 9 FEBRUARY 25, 1865 pp. 127-142 | . 1865 | 12 | 10.2307/e24971662 | No. 8 FEBRUARY 18, 1865 pp. 111-126 | . 1865 | 12 | 10.2307/e24971238 | No. 7 FEBRUARY 11, 1865 pp. 95-110 | . 1865 | 12 | 10.2307/e24970724 | No. 6 FEBRUARY 4, 1865 pp. 79-94 | . 1865 | 12 | 10.2307/e24971385 | No. 5 JANUARY 28, 1865 pp. 63-78 | . 1865 | 12 | 10.2307/e24972138 | No. 4 JANUARY 21, 1865 pp. 47-62 | . 1865 | 12 | 10.2307/e24971103 | No. 3 JANUARY 14, 1865 pp. 31-46 | . 1865 | 12 | 10.2307/e24971711 | No. 2 JANUARY 9, 1865 pp. 15-30 | . 1865 | 12 | 10.2307/e24973145 | No. 1 JANUARY 2, 1865 pp. 1-14 | . 1864 | 11 | 10.2307/e24971573 | No. 26 DECEMBER 24, 1864 pp. 401-414 | . 1864 | 11 | 10.2307/e24972502 | No. 25 DECEMBER 17, 1864 pp. 385-400 | . 1864 | 11 | 10.2307/e24971875 | No. 24 DECEMBER 10, 1864 pp. 369-384 | . 1864 | 11 | 10.2307/e24972012 | No. 23 DECEMBER 3, 1864 pp. 353-368 | . 1864 | 11 | 10.2307/e24971012 | No. 22 NOVEMBER 26, 1864 pp. 337-352 | . 1864 | 11 | 10.2307/e24971611 | No. 21 NOVEMBER 19, 1864 pp. 321-336 | . 1864 | 11 | 10.2307/e24972635 | No. 20 NOVEMBER 12, 1864 pp. 305-320 | . 1864 | 11 | 10.2307/e24971278 | No. 19 NOVEMBER 5, 1864 pp. 289-304 | . 1864 | 11 | 10.2307/e24971832 | No. 18 OCTOBER 29, 1864 pp. 273-288 | . 1864 | 11 | 10.2307/e24970928 | No. 17 OCTOBER 22, 1864 pp. 257-272 | . 1864 | 11 | 10.2307/e24973010 | No. 16 OCTOBER 15, 1864 pp. 241-256 | . 1864 | 11 | 10.2307/e24971384 | No. 15 OCTOBER 8, 1864 pp. 225-240 | . 1864 | 11 | 10.2307/e24972390 | No. 14 OCTOBER 1, 1864 pp. 209-224 | . 1864 | 11 | 10.2307/e24971197 | No. 13 SEPTEMBER 24, 1864 pp. 193-208 | . 1864 | 11 | 10.2307/e24971755 | No. 12 SEPTEMBER 17, 1864 pp. 177-192 | . 1864 | 11 | 10.2307/e24970514 | No. 11 SEPTEMBER 10, 1864 pp. 161-176 | . 1864 | 11 | 10.2307/e24970626 | No. 10 SEPTEMBER 3, 1864 pp. 145-160 | . 1864 | 11 | 10.2307/e24971478 | No. 9 AUGUST 27, 1864 pp. 129-144 | . 1864 | 11 | 10.2307/e24972274 | No. 8 AUGUST 20, 1864 pp. 113-128 | . 1864 | 11 | 10.2307/e24971149 | No. 7 AUGUST 13, 1864 pp. 97-112 | . 1864 | 11 | 10.2307/e24970814 | No. 6 AUGUST 6, 1864 pp. 81-96 | . 1864 | 11 | 10.2307/e24971528 | No. 5 JULY 30, 1864 pp. 65-80 | . 1864 | 11 | 10.2307/e24972885 | No. 4 JULY 23, 1864 pp. 49-64 | . 1864 | 11 | 10.2307/e24971332 | No. 3 JULY 16, 1864 pp. 33-48 | . 1864 | 11 | 10.2307/e24970967 | No. 2 JULY 9, 1864 pp. 17-32 | . 1864 | 11 | 10.2307/e24971792 | No. 1 JULY 2, 1864 pp. 1-16 | . 1864 | 10 | 10.2307/e24971439 | No. 26 JUNE 25, 1864 pp. 401-414 | . 1864 | 10 | 10.2307/e24971062 | No. 25 JUNE 18, 1864 pp. 385-400 | . 1864 | 10 | 10.2307/e24972762 | No. 24 JUNE 11, 1864 pp. 369-384 | . 1864 | 10 | 10.2307/e24970755 | No. 23 JUNE 4, 1864 pp. 353-368 | . 1864 | 10 | 10.2307/e24970563 | No. 22 MAY 28, 1864 pp. 337-352 | . 1864 | 10 | 10.2307/e24970513 | No. 21 MAY 21, 1864 pp. 321-336 | . 1864 | 10 | 10.2307/e24970669 | No. 20 MAY 14, 1864 pp. 305-320 | . 1864 | 10 | 10.2307/e24970834 | No. 19 MAY 7, 1864 pp. 289-304 | . 1864 | 10 | 10.2307/e26003252 | No. 18 APRIL 30, 1864 pp. 273-288 | . 1864 | 10 | 10.2307/e24970368 | No. 17 APRIL 23, 1864 pp. 257-272 | . 1864 | 10 | 10.2307/e24970431 | No. 16 APRIL 16, 1864 pp. 241-256 | . 1864 | 10 | 10.2307/e24970111 | No. 15 APRIL 9, 1864 pp. 225-240 | . 1864 | 10 | 10.2307/e24970392 | No. 14 APRIL 2, 1864 pp. 209-224 | . 1864 | 10 | 10.2307/e24970247 | No. 13 MARCH 26, 1864 pp. 193-208 | . 1864 | 10 | 10.2307/e24970338 | No. 12 MARCH 19, 1864 pp. 177-192 | . 1864 | 10 | 10.2307/e24969951 | No. 11 MARCH 12, 1864 pp. 161-176 | . 1864 | 10 | 10.2307/e24970096 | No. 10 MARCH 5, 1864 pp. 145-160 | . 1864 | 10 | 10.2307/e24970272 | No. 9 FEBRUARY 27, 1864 pp. 129-144 | . 1864 | 10 | 10.2307/e24969999 | No. 8 FEBRUARY 20, 1864 pp. 113-128 | . 1864 | 10 | 10.2307/e24970169 | No. 7 FEBRUARY 13, 1864 pp. 97-112 | . 1864 | 10 | 10.2307/e24969598 | No. 6 FEBRUARY 6, 1864 pp. 81-96 | . 1864 | 10 | 10.2307/e24969903 | No. 5 JANUARY 30, 1864 pp. 65-80 | . 1864 | 10 | 10.2307/e24969863 | No. 4 JANUARY 23, 1864 pp. 49-64 | . 1864 | 10 | 10.2307/e24969902 | No. 3 JANUARY 16, 1864 pp. 33-48 | . 1864 | 10 | 10.2307/e26003156 | No. 2 JANUARY 9, 1864 pp. 17-32 | . 1864 | 10 | 10.2307/e26003121 | No. 1 JANUARY 2, 1864 pp. 1-16 | . 1863 | 9 | 10.2307/e24969510 | No. 26 DECEMBER 26, 1863 pp. 401-414 | . 1863 | 9 | 10.2307/e26003076 | No. 25 DECEMBER 19, 1863 pp. 385-400 | . 1863 | 9 | 10.2307/e24969557 | No. 24 DECEMBER 12, 1863 pp. 369-384 | . 1863 | 9 | 10.2307/e24969645 | No. 23 DECEMBER 5, 1863 pp. 353-368 | . 1863 | 9 | 10.2307/e26003021 | No. 22 NOVEMBER 28, 1863 pp. 337-352 | . 1863 | 9 | 10.2307/e24969488 | No. 21 NOVEMBER 21, 1863 pp. 321-336 | . 1863 | 9 | 10.2307/e24969731 | No. 20 NOVEMBER 14, 1863 pp. 305-320 | . 1863 | 9 | 10.2307/e26003211 | No. 19 NOVEMBER 7, 1863 pp. 289-304 | . 1863 | 9 | 10.2307/e24969604 | No. 18 OCTOBER 31, 1863 pp. 273-288 | . 1863 | 9 | 10.2307/e24969062 | No. 17 OCTOBER 24, 1863 pp. 257-272 | . 1863 | 9 | 10.2307/e26002970 | No. 16 OCTOBER 17, 1863 pp. 241-256 | . 1863 | 9 | 10.2307/e26002929 | No. 15 OCTOBER 10, 1863 pp. 225-240 | . 1863 | 9 | 10.2307/e24969102 | No. 14 OCTOBER 3, 1863 pp. 209-224 | . 1863 | 9 | 10.2307/e24969228 | No. 13 SEPTEMBER 26, 1863 pp. 193-208 | . 1863 | 9 | 10.2307/e24963330 | No. 12 SEPTEMBER 19, 1863 pp. 177-192 | . 1863 | 9 | 10.2307/e24962769 | No. 11 SEPTEMBER 12, 1863 pp. 161-176 | . 1863 | 9 | 10.2307/e24961832 | No. 10 SEPTEMBER 5, 1863 pp. 145-160 | . 1863 | 9 | 10.2307/e24961022 | No. 9 AUGUST 29, 1863 pp. 129-144 | . 1863 | 9 | 10.2307/e24962189 | No. 8 AUGUST 22, 1863 pp. 113-128 | . 1863 | 9 | 10.2307/e24963420 | No. 7 AUGUST 15, 1863 pp. 97-112 | . 1863 | 9 | 10.2307/e24961572 | No. 6 AUGUST 8, 1863 pp. 81-96 | . 1863 | 9 | 10.2307/e24962878 | No. 5 AUGUST 1, 1863 pp. 65-80 | . 1863 | 9 | 10.2307/e24964125 | No. 4 JULY 25, 1863 pp. 49-64 | . 1863 | 9 | 10.2307/e24962605 | No. 3 JULY 18, 1863 pp. 33-48 | . 1863 | 9 | 10.2307/e24963692 | No. 2 JULY 11, 1863 pp. 17-32 | . 1863 | 9 | 10.2307/e24963160 | No. 1 JULY 4, 1863 pp. 1-16 | . 1863 | 8 | 10.2307/e24963257 | No. 26 JUNE 27, 1863 pp. 401-414 | . 1863 | 8 | 10.2307/e24961381 | No. 25 JUNE 20, 1863 pp. 385-400 | . 1863 | 8 | 10.2307/e24962691 | No. 24 JUNE 13, 1863 pp. 369-384 | . 1863 | 8 | 10.2307/e24963748 | No. 23 JUNE 6, 1863 pp. 353-368 | . 1863 | 8 | 10.2307/e24961920 | No. 22 MAY 30, 1863 pp. 337-352 | . 1863 | 8 | 10.2307/e24963159 | No. 21 MAY 23, 1863 pp. 321-336 | . 1863 | 8 | 10.2307/e24961199 | No. 20 MAY 16, 1863 pp. 305-320 | . 1863 | 8 | 10.2307/e24964043 | No. 19 MAY 9, 1863 pp. 289-304 | . 1863 | 8 | 10.2307/e24962108 | No. 18 MAY 2, 1863 pp. 273-288 | . 1863 | 8 | 10.2307/e24963604 | No. 17 APRIL 25, 1863 pp. 257-272 | . 1863 | 8 | 10.2307/e24961748 | No. 16 APRIL 18, 1863 pp. 241-256 | . 1863 | 8 | 10.2307/e24962973 | No. 15 APRIL 11, 1863 pp. 225-240 | . 1863 | 8 | 10.2307/e24960885 | No. 14 APRIL 4, 1863 pp. 209-224 | . 1863 | 8 | 10.2307/e24960988 | No. 13 MARCH 28, 1863 pp. 193-208 | . 1863 | 8 | 10.2307/e24962389 | No. 12 MARCH 21, 1863 pp. 177-192 | . 1863 | 8 | 10.2307/e24963509 | No. 11 MARCH 14, 1863 pp. 161-176 | . 1863 | 8 | 10.2307/e24961656 | No. 10 MARCH 7, 1863 pp. 145-160 | . 1863 | 8 | 10.2307/e24961105 | No. 9 FEBRUARY 28, 1863 pp. 129-144 | . 1863 | 8 | 10.2307/e24962504 | No. 8 FEBRUARY 21, 1863 pp. 113-128 | . 1863 | 8 | 10.2307/e24963956 | No. 7 FEBRUARY 14, 1863 pp. 97-112 | . 1863 | 8 | 10.2307/e24961988 | No. 6 FEBRUARY 7, 1863 pp. 81-96 | . 1863 | 8 | 10.2307/e24961271 | No. 5 JANUARY 31, 1863 pp. 65-80 | . 1863 | 8 | 10.2307/e24963069 | No. 4 JANUARY 24, 1863 pp. 49-64 | . 1863 | 8 | 10.2307/e24962263 | No. 3 JANUARY 17, 1863 pp. 33-48 | . 1863 | 8 | 10.2307/e24961453 | No. 2 JANUARY 10, 1863 pp. 17-32 | . 1863 | 8 | 10.2307/e24963878 | No. 1 JANUARY 3, 1863 pp. 1-16 | . 1862 | 7 | 10.2307/e24961847 | No. 26 DECEMBER 27, 1862 pp. 401-414 | . 1862 | 7 | 10.2307/e24961035 | No. 25 DECEMBER 20, 1862 pp. 385-400 | . 1862 | 7 | 10.2307/e24962224 | No. 24 DECEMBER 13, 1862 pp. 369-384 | . 1862 | 7 | 10.2307/e24963415 | No. 23 DECEMBER 6, 1862 pp. 353-368 | . 1862 | 7 | 10.2307/e24961590 | No. 22 NOVEMBER 29, 1862 pp. 337-352 | . 1862 | 7 | 10.2307/e24962812 | No. 21 NOVEMBER 22, 1862 pp. 321-336 | . 1862 | 7 | 10.2307/e24964158 | No. 20 NOVEMBER 15, 1862 pp. 305-320 | . 1862 | 7 | 10.2307/e24962630 | No. 19 NOVEMBER 8, 1862 pp. 289-304 | . 1862 | 7 | 10.2307/e24963697 | No. 18 NOVEMBER 1, 1862 pp. 273-288 | . 1862 | 7 | 10.2307/e24963221 | No. 17 OCTOBER 25, 1862 pp. 257-272 | . 1862 | 7 | 10.2307/e24963305 | No. 16 OCTOBER 18, 1862 pp. 241-256 | . 1862 | 7 | 10.2307/e24961410 | No. 15 OCTOBER 11, 1862 pp. 225-240 | . 1862 | 7 | 10.2307/e24962722 | No. 14 OCTOBER 4, 1862 pp. 209-224 | . 1862 | 7 | 10.2307/e24963789 | No. 13 SEPTEMBER 27, 1862 pp. 193-206 | . 1862 | 7 | 10.2307/e24961930 | No. 12 SEPTEMBER 20, 1862 pp. 177-192 | . 1862 | 7 | 10.2307/e24963124 | No. 11 SEPTEMBER 13, 1862 pp. 161-176 | . 1862 | 7 | 10.2307/e24961223 | No. 10 SEPTEMBER 6, 1862 pp. 145-160 | . 1862 | 7 | 10.2307/e24964075 | No. 9 AUGUST 30, 1862 pp. 129-144 | . 1862 | 7 | 10.2307/e24962124 | No. 8 AUGUST 23, 1862 pp. 113-128 | . 1862 | 7 | 10.2307/e24963600 | No. 7 AUGUST 16, 1862 pp. 97-112 | . 1862 | 7 | 10.2307/e24961755 | No. 6 AUGUST 9, 1862 pp. 81-96 | . 1862 | 7 | 10.2307/e24962929 | No. 5 AUGUST 2, 1862 pp. 65-80 | . 1862 | 7 | 10.2307/e24960884 | No. 4 JULY 26, 1862 pp. 49-64 | . 1862 | 7 | 10.2307/e24960966 | No. 3 JULY 19, 1862 pp. 33-48 | . 1862 | 7 | 10.2307/e24962430 | No. 2 JULY 12, 1862 pp. 17-32 | . 1862 | 7 | 10.2307/e24963502 | No. 1 JULY 5, 1862 pp. 1-16 | . 1862 | 6 | 10.2307/e24961676 | No. 26 JUNE 28, 1862 pp. 401-414 | . 1862 | 6 | 10.2307/e24961131 | No. 25 JUNE 21, 1862 pp. 385-400 | . 1862 | 6 | 10.2307/e24962529 | No. 24 JUNE 14, 1862 pp. 369-384 | . 1862 | 6 | 10.2307/e24963979 | No. 23 JUNE 7, 1862 pp. 353-368 | . 1862 | 6 | 10.2307/e24962026 | No. 22 MAY 31, 1862 pp. 337-352 | . 1862 | 6 | 10.2307/e24961318 | No. 21 MAY 24, 1862 pp. 321-336 | . 1862 | 6 | 10.2307/e24963025 | No. 20 MAY 17, 1862 pp. 305-320 | . 1862 | 6 | 10.2307/e24962318 | No. 19 MAY 10, 1862 pp. 289-304 | . 1862 | 6 | 10.2307/e24961496 | No. 18 MAY 3, 1862 pp. 273-288 | . 1862 | 6 | 10.2307/e24963886 | No. 17 APRIL 26, 1862 pp. 257-272 | . 1862 | 6 | 10.2307/e24958688 | No. 16 APRIL 19, 1862 pp. 241-256 | . 1862 | 6 | 10.2307/e24957367 | No. 15 APRIL 12, 1862 pp. 225-240 | . 1862 | 6 | 10.2307/e24956229 | No. 14 APRIL 5, 1862 pp. 209-224 | . 1862 | 6 | 10.2307/e24957868 | No. 13 MARCH 29, 1862 pp. 193-208 | . 1862 | 6 | 10.2307/e24959562 | No. 12 MARCH 22, 1862 pp. 177-192 | . 1862 | 6 | 10.2307/e24957049 | No. 11 MARCH 15, 1862 pp. 161-176 | . 1862 | 6 | 10.2307/e24958777 | No. 10 MARCH 8, 1862 pp. 145-160 | . 1862 | 6 | 10.2307/e24960287 | No. 9 MARCH 1, 1862 pp. 129-144 | . 1862 | 6 | 10.2307/e24958462 | No. 8 FEBRUARY 22, 1862 pp. 113-128 | . 1862 | 6 | 10.2307/e24959951 | No. 7 FEBRUARY 15, 1862 pp. 97-112 | . 1862 | 6 | 10.2307/e24959302 | No. 6 FEBRUARY 8, 1862 pp. 81-96 | . 1862 | 6 | 10.2307/e24959428 | No. 5 FEBRUARY 1, 1862 pp. 65-80 | . 1862 | 6 | 10.2307/e24956734 | No. 4 JANUARY 25, 1862 pp. 49-64 | . 1862 | 6 | 10.2307/e24958578 | No. 3 JANUARY 18, 1862 pp. 33-48 | . 1862 | 6 | 10.2307/e24960038 | No. 2 JANUARY 11, 1862 pp. 17-32 | . 1862 | 6 | 10.2307/e24957489 | No. 1 JANUARY 4, 1862 pp. 1-16 | . 1861 | 5 | 10.2307/e24959191 | No. 26 DECEMBER 28, 1861 pp. 401-414 | . 1861 | 5 | 10.2307/e24956509 | No. 25 DECEMBER 21, 1861 pp. 385-400 | . 1861 | 5 | 10.2307/e24960235 | No. 24 DECEMBER 14, 1861 pp. 369-384 | . 1861 | 5 | 10.2307/e24957739 | No. 23 DECEMBER 7, 1861 pp. 353-368 | . 1861 | 5 | 10.2307/e24959840 | No. 22 NOVEMBER 30, 1861 pp. 337-352 | . 1861 | 5 | 10.2307/e24957198 | No. 21 NOVEMBER 23, 1861 pp. 321-336 | . 1861 | 5 | 10.2307/e24958924 | No. 20 NOVEMBER 16, 1861 pp. 305-320 | . 1861 | 5 | 10.2307/e24955956 | No. 19 NOVEMBER 9, 1861 pp. 289-304 | . 1861 | 5 | 10.2307/e24956086 | No. 18 NOVEMBER 2, 1861 pp. 273-288 | . 1861 | 5 | 10.2307/e24958171 | No. 17 OCTOBER 26, 1861 pp. 257-272 | . 1861 | 5 | 10.2307/e24959699 | No. 16 OCTOBER 19, 1861 pp. 241-256 | . 1861 | 5 | 10.2307/e24957177 | No. 15 OCTOBER 12, 1861 pp. 225-240 | . 1861 | 5 | 10.2307/e24956378 | No. 14 OCTOBER 5, 1861 pp. 209-224 | . 1861 | 5 | 10.2307/e24958322 | No. 13 SEPTEMBER 28, 1861 pp. 193-208 | . 1861 | 5 | 10.2307/e24960180 | No. 12 SEPTEMBER 21, 1861 pp. 177-192 | . 1861 | 5 | 10.2307/e24957621 | No. 11 SEPTEMBER 14, 1861 pp. 161-176 | . 1861 | 5 | 10.2307/e24956626 | No. 10 SEPTEMBER 7, 1861 pp. 145-160 | . 1861 | 5 | 10.2307/e24959055 | No. 9 AUGUST 31, 1861 pp. 129-144 | . 1861 | 5 | 10.2307/e24958038 | No. 8 AUGUST 24, 1861 pp. 113-128 | . 1861 | 5 | 10.2307/e24956914 | No. 7 AUGUST 17, 1861 pp. 97-112 | . 1861 | 5 | 10.2307/e24960139 | No. 6 AUGUST 10, 1861 pp. 81-96 | . 1861 | 5 | 10.2307/e24958292 | No. 5 AUGUST 3, 1861 pp. 65-80 | . 1861 | 5 | 10.2307/e24957180 | No. 4 JULY 27, 1861 pp. 49-64 | . 1861 | 5 | 10.2307/e24956124 | No. 3 JULY 20, 1861 pp. 33-48 | . 1861 | 5 | 10.2307/e24957544 | No. 2 JULY 13, 1861 pp. 17-32 | . 1861 | 5 | 10.2307/e24959048 | No. 1 JULY 6, 1861 pp. 1-16 | . 1861 | 4 | 10.2307/e24956805 | No. 26 JUNE 29, 1861 pp. 401-414 | . 1861 | 4 | 10.2307/e24958417 | No. 25 JUNE 22, 1861 pp. 385-400 | . 1861 | 4 | 10.2307/e24959994 | No. 24 JUNE 15, 1861 pp. 369-384 | . 1861 | 4 | 10.2307/e26141021 | No. 23 JUNE 8, 1861 pp. 353-368 | . 1861 | 4 | 10.2307/e24958049 | No. 22 JUNE 1, 1861 pp. 337-352 | . 1861 | 4 | 10.2307/e26139350 | No. 21 MAY 25, 1861 pp. 321-336 | . 1861 | 4 | 10.2307/e26140041 | No. 20 MAY 18, 1861 pp. 305-320 | . 1861 | 4 | 10.2307/e24959420 | No. 19 MAY 11, 1861 pp. 289-304 | . 1861 | 4 | 10.2307/e24958816 | No. 18 MAY 4, 1861 pp. 273-288 | . 1861 | 4 | 10.2307/e24958933 | No. 17 APRIL 27, 1861 pp. 257-272 | . 1861 | 4 | 10.2307/e24956573 | No. 16 APRIL 20, 1861 pp. 241-254 | . 1861 | 4 | 10.2307/e24958192 | No. 15 APRIL 13, 1861 pp. 225-240 | . 1861 | 4 | 10.2307/e26139088 | No. 14 APRIL 6, 1861 pp. 209-224 | . 1861 | 4 | 10.2307/e24959561 | No. 13 MARCH 30, 1861 pp. 193-208 | . 1861 | 4 | 10.2307/e24957272 | No. 12 MARCH 23, 1861 pp. 177-192 | . 1861 | 4 | 10.2307/e24958693 | No. 11 MARCH 16, 1861 pp. 161-176 | . 1861 | 4 | 10.2307/e24956372 | No. 10 MARCH 9, 1861 pp. 145-160 | . 1861 | 4 | 10.2307/e24959897 | No. 9 MARCH 2, 1861 pp. 129-144 | . 1861 | 4 | 10.2307/e24957523 | No. 8 FEBRUARY 23, 1861 pp. 113-128 | . 1861 | 4 | 10.2307/e24959306 | No. 7 FEBRUARY l6, 1861 pp. 97-112 | . 1861 | 4 | 10.2307/e24957047 | No. 6 FEBRUARY 9, 1861 pp. 81-96 | . 1861 | 4 | 10.2307/e24958536 | No. 5 FEBRUARY 2, 1861 pp. 65-80 | . 1861 | 4 | 10.2307/e26141251 | No. 4 JANUARY 26, 1861 pp. 49-64 | . 1861 | 4 | 10.2307/e24955922 | No. 3 JANUARY 19, 1861 pp. 33-48 | . 1861 | 4 | 10.2307/e24956004 | No. 2 JANUARY 12, 1861 pp. 17-32 | . 1861 | 4 | 10.2307/e24957795 | No. 1 JANUARY 5, 1861 pp. 1-16 | . 1860 | 3 | 10.2307/e26141548 | No. 26 DECEMBER 22, 1860 pp. 401-414 | . 1860 | 3 | 10.2307/e26139644 | No. 25 DECEMBER 15, 1860 pp. 385-400 | . 1860 | 3 | 10.2307/e24959197 | No. 24 DECEMBER 8, 1860 pp. 369-384 | . 1860 | 3 | 10.2307/e24956937 | No. 22 NOVEMBER 24, 1860 pp. 337-352 | . 1860 | 3 | 10.2307/e24956262 | No. 21 NOVEMBER 17, 1860 pp. 321-336 | . 1860 | 3 | 10.2307/e24957928 | No. 20 NOVEMBER 10, 1860 pp. 305-320 | . 1860 | 3 | 10.2307/e24959803 | No. 19 NOVEMBER 3, 1860 pp. 289-304 | . 1860 | 3 | 10.2307/e24957406 | No. 18 OCTOBER 27, 1860 pp. 273-288 | . 1860 | 3 | 10.2307/e24956477 | No. 17 OCTOBER 20, 1860 pp. 257-272 | . 1860 | 3 | 10.2307/e24958674 | No. 16 OCTOBER 13, 1860 pp. 241-256 | . 1860 | 3 | 10.2307/e24957688 | No. 15 OCTOBER 6, 1860 pp. 225-240 | . 1860 | 3 | 10.2307/e24956688 | No. 14 SEPTEMBER 29, 1860 pp. 209-224 | . 1860 | 3 | 10.2307/e24959696 | No. 13 SEPTEMBER 22, 1860 pp. 193-208 | . 1860 | 3 | 10.2307/e24958213 | No. 12 SEPTEMBER 15, 1860 pp. 177-192 | . 1860 | 3 | 10.2307/e24957066 | No. 11 SEPTEMBER 8, 1860 pp. 161-176 | . 1860 | 3 | 10.2307/e24955962 | No. 10 SEPTEMBER 1, 1860 pp. 145-160 | . 1860 | 3 | 10.2307/e24957516 | No. 9 AUGUST 25, 1860 pp. 129-144 | . 1860 | 3 | 10.2307/e24958862 | No. 8 AUGUST 18, 1860 pp. 113-128 | . 1860 | 3 | 10.2307/e24956665 | No. 7 AUGUST 11, 1860 pp. 97-112 | . 1860 | 3 | 10.2307/e24958332 | No. 6 AUGUST 4, 1860 pp. 81-96 | . 1860 | 3 | 10.2307/e24959737 | No. 5 JULY 28, 1860 pp. 65-80 | . 1860 | 3 | 10.2307/e26140784 | No. 4 JULY 21, 1860 pp. 49-64 | . 1860 | 3 | 10.2307/e24957975 | No. 3 JULY 14, 1860 pp. 33-48 | . 1860 | 3 | 10.2307/e24959236 | No. 2 JULY 7, 1860 pp. 17-32 | . 1860 | 3 | 10.2307/e24958692 | No. 1 JULY 2, 1860 pp. 1-16 | . 1860 | 2 | 10.2307/e24958800 | No. 26 JUNE 23, 1860 pp. 401-414 | . 1860 | 2 | 10.2307/e24956427 | No. 25 JUNE 16, 1860 pp. 385-400 | . 1860 | 2 | 10.2307/e24958083 | No. 24 JUNE 9, 1860 pp. 369-384 | . 1860 | 2 | 10.2307/e24959240 | No. 23 JUNE 2, 1860 pp. 353-368 | . 1860 | 2 | 10.2307/e24957192 | No. 22 MAY 26, 1860 pp. 337-352 | . 1860 | 2 | 10.2307/e24958554 | No. 21 MAY 19, 1860 pp. 321-336 | . 1860 | 2 | 10.2307/e24956189 | No. 20 MAY 12, 1860 pp. 305-320 | . 1860 | 2 | 10.2307/e24959614 | No. 19 MAY 5, 1860 pp. 289-304 | . 1860 | 2 | 10.2307/e24957405 | No. 18 APRIL 28, 1860 pp. 273-288 | . 1860 | 2 | 10.2307/e24959096 | No. 17 APRIL 21, 1860 pp. 257-272 | . 1860 | 2 | 10.2307/e24956936 | No. 16 APRIL 14, 1860 pp. 241-256 | . 1860 | 2 | 10.2307/e26046741 | No. 15 APRIL 7, 1860 pp. 225-240 | . 1860 | 2 | 10.2307/e24955877 | No. 14 MARCH 31, 1860 pp. 209-224 | . 1860 | 2 | 10.2307/e24955921 | No. 13 MARCH 24, 1860 pp. 193-208 | . 1860 | 2 | 10.2307/e24957698 | No. 12 MARCH 17, 1860 pp. 177-192 | . 1860 | 2 | 10.2307/e24958984 | No. 11 MARCH 10, 1860 pp. 161-176 | . 1860 | 2 | 10.2307/e24956801 | No. 10 MARCH 3, 1860 pp. 145-160 | . 1860 | 2 | 10.2307/e24956087 | No. 9 FEBRUARY 25, 1860 pp. 129-144 | . 1860 | 2 | 10.2307/e24957834 | No. 8 FEBRUARY 18, 1860 pp. 113-128 | . 1860 | 2 | 10.2307/e24959473 | No. 7 FEBRUARY 11, 1860 pp. 97-112 | . 1860 | 2 | 10.2307/e24957273 | No. 6 FEBRUARY 4, 1860 pp. 81-96 | . 1860 | 2 | 10.2307/e24956293 | No. 5 JANUARY 28, 1860 pp. 65-80 | . 1860 | 2 | 10.2307/e24958439 | No. 4 JANUARY 21, 1860 pp. 49-64 | . 1860 | 2 | 10.2307/e24957597 | No. 3 JANUARY 14, 1860 pp. 33-48 | . 1860 | 2 | 10.2307/e24956533 | No. 2 JANUARY 7, 1860 pp. 17-32 | . 1860 | 2 | 10.2307/e24959338 | No. 1 JANUARY 2, 1860 pp. 1-16 | . 1859 | 1 | 10.2307/e26171096 | No. 26 DECEMBER 24, 1859 pp. 409-422 | . 1859 | 1 | 10.2307/e26170514 | No. 25 DECEMBER 17, 1859 pp. 393-408 | . 1859 | 1 | 10.2307/e26170901 | No. 24 DECEMBER 10, 1859 pp. 377-392 | . 1859 | 1 | 10.2307/e26171171 | No. 23 DECEMBER 3, 1859 pp. 361-376 | . 1859 | 1 | 10.2307/e26170668 | No. 22 NOVEMBER 26, 1859 pp. 345-360 | . 1859 | 1 | 10.2307/e26171025 | No. 21 NOVEMBER 19, 1859 pp. 329-344 | . 1859 | 1 | 10.2307/e26170437 | No. 20 NOVEMBER 12, 1859 pp. 313-328 | . 1859 | 1 | 10.2307/e26171287 | No. 19 NOVEMBER 5, 1859 pp. 297-312 | . 1859 | 1 | 10.2307/e26170756 | No. 18 OCTOBER 29, 1859 pp. 281-296 | . 1859 | 1 | 10.2307/e26171129 | No. 17 OCTOBER 22, 1859 pp. 265-280 | . 1859 | 1 | 10.2307/e26170630 | No. 16 OCTOBER 15, 1859 pp. 249-264 | . 1859 | 1 | 10.2307/e26170940 | No. 15 OCTOBER 8, 1859 pp. 233-248 | . 1859 | 1 | 10.2307/e26170315 | No. 14 OCTOBER 1, 1859 pp. 217-232 | . 1859 | 1 | 10.2307/e26170359 | No. 13 SEPTEMBER 24, 1859 pp. 201-216 | . 1859 | 1 | 10.2307/e26170826 | No. 12 SEPTEMBER 17, 1859 pp. 185-200 | . 1859 | 1 | 10.2307/e26172586 | No. 11 SEPTEMBER 10, 1859 pp. 161-184 | . 1859 | 1 | 10.2307/e26170590 | No. 10 SEPTEMBER 3, 1859 pp. 145-160 | . 1859 | 1 | 10.2307/e26170397 | No. 9 AUGUST 27, 1859 pp. 129-144 | . 1859 | 1 | 10.2307/e26170871 | No. 8 AUGUST 20, 1859 pp. 113-128 | . 1859 | 1 | 10.2307/e26171246 | No. 7 AUGUST 13, 1859 pp. 97-112 | . 1859 | 1 | 10.2307/e26170710 | No. 6 AUGUST 6, 1859 pp. 81-96 | . 1859 | 1 | 10.2307/e26170471 | No. 5 JULY 30, 1859 pp. 65-80 | . 1859 | 1 | 10.2307/e26170976 | No. 4 JULY 23, 1859 pp. 49-64 | . 1859 | 1 | 10.2307/e26170791 | No. 3 JULY 16, 1859 pp. 33-48 | . 1859 | 1 | 10.2307/e26170549 | No. 2 JULY 9, 1859 pp. 17-32 | . 1859 | 1 | 10.2307/e26171211 | No. 1 JULY 2, 1859 pp. 1-16 | . 1859 | 14 | 10.2307/e24954396 | No. 42 JUNE 25, 1859 pp. 345-352 | . 1859 | 14 | 10.2307/e26140470 | No. 41 JUNE 18, 1859 pp. 337-344 | . 1859 | 14 | 10.2307/e24954127 | No. 39 JUNE 4, 1859 pp. 321-328 | . 1859 | 14 | 10.2307/e26141379 | No. 38 MAY 28, 1859 pp. 313-320 | . 1859 | 14 | 10.2307/e24954528 | No. 37 MAY 21, 1859 pp. 305-312 | . 1859 | 14 | 10.2307/e24954653 | No. 36 MAY 14, 1859 pp. 297-304 | . 1859 | 14 | 10.2307/e24954259 | No. 35 MAY 7, 1859 pp. 289-296 | . 1859 | 14 | 10.2307/e24954437 | No. 34 APRIL 30, 1859 pp. 281-288 | . 1859 | 14 | 10.2307/e24954172 | No. 33 APRIL 23, 1859 pp. 273-280 | . 1859 | 14 | 10.2307/e24954585 | No. 32 APRIL 16, 1859 pp. 257-272 | . 1859 | 14 | 10.2307/e24954194 | No. 31 APRIL 9, 1859 pp. 249-256 | . 1859 | 14 | 10.2307/e24954717 | No. 30 APRIL 2, 1859 pp. 241-248 | . 1859 | 14 | 10.2307/e24954318 | No. 29 MARCH 26, 1859 pp. 233-240 | . 1859 | 14 | 10.2307/e24954783 | No. 28 MARCH 19, 1859 pp. 225-232 | . 1859 | 14 | 10.2307/e24955076 | No. 27 MARCH 12, 1859 pp. 217-224 | . 1859 | 14 | 10.2307/e24955048 | No. 26 MARCH 5, 1859 pp. 209-216 | . 1859 | 14 | 10.2307/e26070538 | No. 25 FEBRUARY 26, 1859 pp. 197-208 | . 1859 | 14 | 10.2307/e24955208 | No. 24 FEBRUARY 19, 1859 pp. 189-196 | . 1859 | 14 | 10.2307/e24954473 | No. 23 FEBRUARY 12, 1859 pp. 181-188 | . 1859 | 14 | 10.2307/e24954954 | No. 22 FEBRUARY 5, 1859 pp. 173-180 | . 1859 | 14 | 10.2307/e24954749 | No. 21 JANUARY 29, 1859 pp. 165-172 | . 1859 | 14 | 10.2307/e24954615 | No. 20 JANUARY 22, 1859 pp. 157-164 | . 1859 | 14 | 10.2307/e24954915 | No. 19 JANUARY 15, 1859 pp. 149-156 | . 1859 | 14 | 10.2307/e24954173 | No. 18 JANUARY 8, 1859 pp. 141-148 | . 1859 | 14 | 10.2307/e24955143 | No. 17 JANUARY 1, 1859 pp. 133-140 | . 1858 | 14 | 10.2307/e24955011 | No. 16 DECEMBER 25, 1858 pp. 121-132 | . 1858 | 14 | 10.2307/e24954413 | No. 15 DECEMBER 18, 1858 pp. 113-120 | . 1858 | 14 | 10.2307/e24954584 | No. 14 DECEMBER 11, 1858 pp. 105-112 | . 1858 | 14 | 10.2307/e24954228 | No. 13 DECEMBER 4, 1858 pp. 97-104 | . 1858 | 14 | 10.2307/e24954883 | No. 12 NOVEMBER 27, 1858 pp. 89-96 | . 1858 | 14 | 10.2307/e24954292 | No. 11 NOVEMBER 20, 1858 pp. 81-88 | . 1858 | 14 | 10.2307/e24955175 | No. 10 NOVEMBER 13, 1858 pp. 73-80 | . 1858 | 14 | 10.2307/e24954986 | No. 9 NOVEMBER 6, 1858 pp. 65-72 | . 1858 | 14 | 10.2307/e24954822 | No. 8 OCTOBER 30, 1858 pp. 57-64 | . 1858 | 14 | 10.2307/e26141452 | No. 7 OCTOBER 23, 1858 pp. 49-56 | . 1858 | 14 | 10.2307/e24954680 | No. 6 OCTOBER 16, 1858 pp. 41-48 | . 1858 | 14 | 10.2307/e24954527 | No. 5 OCTOBER 9, 1858 pp. 33-40 | . 1858 | 14 | 10.2307/e26140617 | No. 4 OCTOBER 2, 1858 pp. 25-32 | . 1858 | 14 | 10.2307/e24954354 | No. 3 SEPTEMBER 25, 1858 pp. 17-24 | . 1858 | 14 | 10.2307/e24954126 | No. 2 SEPTEMBER 18, 1858 pp. 9-16 | . 1858 | 14 | 10.2307/e24955117 | No. 1 SEPTEMBER 11, 1858 pp. 1-8 | . 1858 | 13 | 10.2307/e24952182 | No. 51 AUGUST 28, 1858 pp. 401-408 | . 1858 | 13 | 10.2307/e24953224 | No. 50 AUGUST 21, 1858 pp. 393-400 | . 1858 | 13 | 10.2307/e24953118 | No. 49 AUGUST 14, 1858 pp. 385-392 | . 1858 | 13 | 10.2307/e24952285 | No. 48 AUGUST 7, 1858 pp. 377-384 | . 1858 | 13 | 10.2307/e24953628 | No. 47 JULY 31, 1858 pp. 369-376 | . 1858 | 13 | 10.2307/e24951670 | No. 46 JULY 24, 1858 pp. 361-368 | . 1858 | 13 | 10.2307/e24952802 | No. 45 JULY 17, 1858 pp. 353-360 | . 1858 | 13 | 10.2307/e24952380 | No. 44 JULY 10, 1858 pp. 345-352 | . 1858 | 13 | 10.2307/e26139610 | No. 43 JULY 3, 1858 pp. 337-344 | . 1858 | 13 | 10.2307/e24951980 | No. 42 JUNE 26, 1858 pp. 329-336 | . 1858 | 13 | 10.2307/e26138749 | No. 41 JUNE 19, 1858 pp. 321-328 | . 1858 | 13 | 10.2307/e24952693 | No. 40 JUNE 12, 1858 pp. 313-320 | . 1858 | 13 | 10.2307/e24951137 | No. 39 JUNE 5, 1858 pp. 305-312 | . 1858 | 13 | 10.2307/e24953414 | No. 38 MAY 29, 1858 pp. 297-304 | . 1858 | 13 | 10.2307/e26140370 | No. 37 MAY 22, 1858 pp. 289-296 | . 1858 | 13 | 10.2307/e24952982 | No. 36 MAY 15, 1858 pp. 281-288 | . 1858 | 13 | 10.2307/e24951569 | No. 35 MAY 8, 1858 pp. 273-280 | . 1858 | 13 | 10.2307/e24951881 | No. 34 MAY 1, 1858 pp. 265-272 | . 1858 | 13 | 10.2307/e24951231 | No. 33 APRIL 24, 1858 pp. 257-264 | . 1858 | 13 | 10.2307/e24952589 | No. 32 APRIL 17, 1858 pp. 249-256 | . 1858 | 13 | 10.2307/e24951338 | No. 31 APRIL 10, 1858 pp. 241-248 | . 1858 | 13 | 10.2307/e24953501 | No. 30 APRIL 3, 1858 pp. 233-240 | . 1858 | 13 | 10.2307/e26141168 | No. 29 MARCH 28, 1858 pp. 225-232 | . 1858 | 13 | 10.2307/e24952898 | No. 28 MARCH 20, 1858 pp. 217-224 | . 1858 | 13 | 10.2307/e24952474 | No. 27 MARCH 13, 1858 pp. 209-216 | . 1858 | 13 | 10.2307/e24952087 | No. 26 MARCH 6, 1858 pp. 201-208 | . 1858 | 13 | 10.2307/e24951782 | No. 25 FEBRUARY 27, 1858 pp. 193-200 | . 1858 | 13 | 10.2307/e24951453 | No. 24 FEBRUARY 20, 1858 pp. 185-192 | . 1858 | 13 | 10.2307/e24951053 | No. 22 FEBRUARY 6, 1858 pp. 169-176 | . 1858 | 13 | 10.2307/e24953309 | No. 21 JANUARY 30, 1858 pp. 161-168 | . 1858 | 13 | 10.2307/e24953314 | No. 20 JANUARY 23, 1858 pp. 153-160 | . 1858 | 13 | 10.2307/e24953174 | No. 19 JANUARY 16, 1858 pp. 145-152 | . 1858 | 13 | 10.2307/e24952146 | No. 18 JANUARY 9, 1858 pp. 137-144 | . 1858 | 13 | 10.2307/e24953694 | No. 17 JANUARY 2, 1858 pp. 129-136 | . 1857 | 13 | 10.2307/e24951487 | No. 14 DECEMBER 12, 1857 pp. 105-112 | . 1857 | 13 | 10.2307/e24952782 | No. 13 DECEMBER 5, 1857 pp. 97-104 | . 1857 | 13 | 10.2307/e24952236 | No. 12 NOVEMBER 28, 1857 pp. 89-96 | . 1857 | 13 | 10.2307/e24951874 | No. 11 NOVEMBER 21, 1857 pp. 81-88 | . 1857 | 13 | 10.2307/e26139946 | No. 10 NOVEMBER 14, 1857 pp. 73-80 | . 1857 | 13 | 10.2307/e24952659 | No. 6 OCTOBER 17, 1857 pp. 41-48 | . 1857 | 13 | 10.2307/e24950964 | No. 5 OCTOBER 10, 1857 pp. 33-40 | . 1857 | 13 | 10.2307/e26138786 | No. 4 OCTOBER 3, 1857 pp. 25-32 | . 1857 | 13 | 10.2307/e24953465 | No. 3 SEPTEMBER 26, 1857 pp. 17-24 | . 1857 | 13 | 10.2307/e24953062 | No. 2 SEPTEMBER 19, 1857 pp. 9-16 | . 1857 | 13 | 10.2307/e24951397 | No. 1 SEPTEMBER 12, 1857 pp. 1-8 | . 1857 | 12 | 10.2307/e24951738 | No. 52 SEPTEMBER 5, 1857 pp. 409-418 | . 1857 | 12 | 10.2307/e24951055 | No. 51 AUGUST 29, 1857 pp. 401-408 | . 1857 | 12 | 10.2307/e24952524 | No. 50 AUGUST 22, 1857 pp. 393-400 | . 1857 | 12 | 10.2307/e24951170 | No. 49 AUGUST 15, 1857 pp. 385-392 | . 1857 | 12 | 10.2307/e24953598 | No. 48 AUGUST 8, 1857 pp. 377-384 | . 1857 | 12 | 10.2307/e24952914 | No. 47 AUGUST 1, 1857 pp. 369-376 | . 1857 | 12 | 10.2307/e24952405 | No. 46 JULY 25, 1857 pp. 361-368 | . 1857 | 12 | 10.2307/e24952019 | No. 45 JULY 18, 1857 pp. 353-360 | . 1857 | 12 | 10.2307/e24951620 | No. 44 JULY 11, 1857 pp. 345-352 | . 1857 | 12 | 10.2307/e24951277 | No. 43 JULY 4, 1857 pp. 337-344 | . 1857 | 12 | 10.2307/e24950886 | No. 42 JUNE 27, 1857 pp. 329-336 | . 1857 | 12 | 10.2307/e24953415 | No. 41 JUNE 20, 1857 pp. 321-328 | . 1857 | 12 | 10.2307/e24952051 | No. 40 JUNE 13, 1857 pp. 313-320 | . 1857 | 12 | 10.2307/e24953242 | No. 39 JUNE 6, 1857 pp. 305-312 | . 1857 | 12 | 10.2307/e24953105 | No. 38 MAY 30, 1857 pp. 297-304 | . 1857 | 12 | 10.2307/e24952171 | No. 37 MAY 23, 1857 pp. 289-296 | . 1857 | 12 | 10.2307/e24953748 | No. 36 MAY 16, 1857 pp. 281-288 | . 1857 | 12 | 10.2307/e24951455 | No. 35 MAY 9, 1857 pp. 273-280 | . 1857 | 12 | 10.2307/e24952736 | No. 34 MAY 2, 1857 pp. 265-272 | . 1857 | 12 | 10.2307/e24952284 | No. 33 APRIL 25, 1857 pp. 257-264 | . 1857 | 12 | 10.2307/e24951804 | No. 32 APRIL 18, 1857 pp. 249-256 | . 1857 | 12 | 10.2307/e24952631 | No. 31 APRIL 11, 1857 pp. 241-248 | . 1857 | 12 | 10.2307/e24950949 | No. 30 APRIL 4, 1857 pp. 233-240 | . 1857 | 12 | 10.2307/e24953477 | No. 29 MARCH 28, 1857 pp. 225-232 | . 1857 | 12 | 10.2307/e24952974 | No. 28 MARCH 21, 1857 pp. 217-224 | . 1857 | 12 | 10.2307/e24951343 | No. 27 MARCH 14, 1857 pp. 209-216 | . 1857 | 12 | 10.2307/e24951717 | No. 26 MARCH 7, 1857 pp. 201-208 | . 1857 | 12 | 10.2307/e24951044 | No. 25 FEBRUARY 28, 1857 pp. 193-200 | . 1857 | 12 | 10.2307/e24952483 | No. 24 FEBRUARY 21, 1857 pp. 185-192 | . 1857 | 12 | 10.2307/e24951134 | No. 23 FEBRUARY 14, 1857 pp. 177-184 | . 1857 | 12 | 10.2307/e24953607 | No. 22 FEBRUARY 7, 1857 pp. 169-176 | . 1857 | 12 | 10.2307/e24952846 | No. 21 JANUARY 31, 1857 pp. 161-168 | . 1857 | 12 | 10.2307/e24952379 | No. 20 JANUARY 24, 1857 pp. 153-160 | . 1857 | 12 | 10.2307/e24951916 | No. 19 JANUARY 17, 1857 pp. 145-152 | . 1857 | 12 | 10.2307/e24951593 | No. 18 JANUARY 10, 1857 pp. 137-144 | . 1857 | 12 | 10.2307/e24951248 | No. 17 JANUARY 3, 1857 pp. 129-136 | . 1856 | 12 | 10.2307/e24950856 | No. 16 DECEMBER 27, 1856 pp. 121-128 | . 1856 | 12 | 10.2307/e24953347 | No. 15 DECEMBER 20, 1856 pp. 113-120 | . 1856 | 12 | 10.2307/e24948085 | No. 14 DECEMBER 13, 1856 pp. 105-112 | . 1856 | 12 | 10.2307/e24949445 | No. 13 DECEMBER 6, 1856 pp. 97-104 | . 1856 | 12 | 10.2307/e24949316 | No. 12 NOVEMBER 29, 1856 pp. 89-96 | . 1856 | 12 | 10.2307/e24948233 | No. 11 NOVEMBER 23, 1856 pp. 81-88 | . 1856 | 12 | 10.2307/e24949658 | No. 10 NOVEMBER 15, 1856 pp. 73-80 | . 1856 | 12 | 10.2307/e24947442 | No. 9 NOVEMBER 8, 1856 pp. 65-72 | . 1856 | 12 | 10.2307/e24948864 | No. 8 NOVEMBER 1, 1856 pp. 57-64 | . 1856 | 12 | 10.2307/e24948368 | No. 7 OCTOBER 25, 1856 pp. 49-56 | . 1856 | 12 | 10.2307/e24947817 | No. 6 OCTOBER 18, 1856 pp. 41-48 | . 1856 | 12 | 10.2307/e24948742 | No. 5 OCTOBER 11, 1856 pp. 33-40 | . 1856 | 12 | 10.2307/e24946794 | No. 4 OCTOBER 4, 1856 pp. 25-32 | . 1856 | 12 | 10.2307/e24949574 | No. 3 SEPTEMBER 27, 1856 pp. 17-24 | . 1856 | 12 | 10.2307/e24949194 | No. 2 SEPTEMBER 20, 1856 pp. 9-16 | . 1856 | 12 | 10.2307/e24947294 | No. 1 SEPTEMBER 13, 1856 pp. 1-8 | . 1856 | 11 | 10.2307/e24947734 | No. 52 SEPTEMBER 6, 1856 pp. 409-414 | . 1856 | 11 | 10.2307/e24946938 | No. 51 AUGUST 30, 1856 pp. 401-408 | . 1856 | 11 | 10.2307/e24948620 | No. 50 AUGUST 23, 1856 pp. 393-400 | . 1856 | 11 | 10.2307/e24947072 | No. 49 AUGUST 16, 1856 pp. 385-392 | . 1856 | 11 | 10.2307/e24949616 | No. 48 AUGUST 9, 1856 pp. 377-384 | . 1856 | 11 | 10.2307/e24949066 | No. 47 AUGUST 2, 1856 pp. 369-376 | . 1856 | 11 | 10.2307/e24948485 | No. 46 JULY 26, 1856 pp. 361-368 | . 1856 | 11 | 10.2307/e24947985 | No. 45 JULY 19, 1856 pp. 353-360 | . 1856 | 11 | 10.2307/e24947616 | No. 44 JULY 12, 1856 pp. 345-352 | . 1856 | 11 | 10.2307/e24947154 | No. 43 JULY 5, 1856 pp. 337-344 | . 1856 | 11 | 10.2307/e24946674 | No. 42 JUNE 28, 1856 pp. 329-336 | . 1856 | 11 | 10.2307/e24949535 | No. 41 JUNE 21, 1856 pp. 321-328 | . 1856 | 11 | 10.2307/e24947765 | No. 40 JUNE 14, 1856 pp. 313-320 | . 1856 | 11 | 10.2307/e24948825 | No. 39 JUNE 7, 1856 pp. 305-312 | . 1856 | 11 | 10.2307/e24948732 | No. 38 MAY 31, 1856 pp. 297-304 | . 1856 | 11 | 10.2307/e24947871 | No. 37 MAY 24, 1856 pp. 289-296 | . 1856 | 11 | 10.2307/e24949284 | No. 36 MAY 17, 1856 pp. 281-288 | . 1856 | 11 | 10.2307/e24947164 | No. 35 MAY 10, 1856 pp. 273-280 | . 1856 | 11 | 10.2307/e24948361 | No. 34 MAY 3, 1856 pp. 265-272 | . 1856 | 11 | 10.2307/e24947997 | No. 33 APRIL 26, 1856 pp. 257-264 | . 1856 | 11 | 10.2307/e24947503 | No. 32 APRIL 19, 1856 pp. 249-256 | . 1856 | 11 | 10.2307/e24948242 | No. 31 APRIL 12, 1856 pp. 241-248 | . 1856 | 11 | 10.2307/e24946647 | No. 30 APRIL 5, 1856 pp. 233-240 | . 1856 | 11 | 10.2307/e24949082 | No. 29 MARCH 29, 1856 pp. 225-232 | . 1856 | 11 | 10.2307/e24948599 | No. 28 MARCH 22, 1856 pp. 217-224 | . 1856 | 11 | 10.2307/e24947041 | No. 27 MARCH 15, 1856 pp. 209-216 | . 1856 | 11 | 10.2307/e24947388 | No. 26 MARCH 8, 1856 pp. 201-208 | . 1856 | 11 | 10.2307/e24946673 | No. 25 MARCH 1, 1856 pp. 193-200 | . 1856 | 11 | 10.2307/e24948227 | No. 24 FEBRUARY 23, 1856 pp. 185-192 | . 1856 | 11 | 10.2307/e24946770 | No. 23 FEBRUARY 16, 1856 pp. 177-184 | . 1856 | 11 | 10.2307/e24949163 | No. 22 FEBRUARY 9, 1856 pp. 169-176 | . 1856 | 11 | 10.2307/e24948452 | No. 21 FEBRUARY 2, 1856 pp. 161-168 | . 1856 | 11 | 10.2307/e24948099 | No. 20 JANUARY 26, 1856 pp. 153-160 | . 1856 | 11 | 10.2307/e24947643 | No. 19 JANUARY 19, 1856 pp. 145-152 | . 1856 | 11 | 10.2307/e24947271 | No. 18 JANUARY 12, 1856 pp. 137-144 | . 1856 | 11 | 10.2307/e24946932 | No. 17 JANUARY 5, 1856 pp. 129-136 | . 1855 | 11 | 10.2307/e24946559 | No. 16 DECEMBER 29, 1855 pp. 121-128 | . 1855 | 11 | 10.2307/e24948940 | No. 15 DECEMBER 23, 1855 pp. 113-120 | . 1855 | 11 | 10.2307/e24947614 | No. 14 DECEMBER 15, 1855 pp. 105-112 | . 1855 | 11 | 10.2307/e24948810 | No. 13 DECEMBER 8, 1855 pp. 97-104 | . 1855 | 11 | 10.2307/e26140003 | No. 12 DECEMBER 1, 1855 pp. 89-96 | . 1855 | 11 | 10.2307/e26138908 | No. 11 NOVEMBER 24, 1855 pp. 81-88 | . 1855 | 11 | 10.2307/e26140336 | No. 10 NOVEMBER 17, 1855 pp. 73-80 | . 1855 | 11 | 10.2307/e26139912 | No. 9 NOVEMBER 10, 1855 pp. 65-72 | . 1855 | 11 | 10.2307/e26140827 | No. 8 NOVEMBER 3, 1855 pp. 57-64 | . 1855 | 11 | 10.2307/e26139219 | No. 7 OCTOBER 27, 1855 pp. 49-56 | . 1855 | 11 | 10.2307/e26140579 | No. 6 OCTOBER 20, 1855 pp. 41-48 | . 1855 | 11 | 10.2307/e26141403 | No. 5 OCTOBER 13, 1855 pp. 33-40 | . 1855 | 11 | 10.2307/e26140090 | No. 4 OCTOBER 6, 1855 pp. 25-32 | . 1855 | 11 | 10.2307/e26139782 | No. 3 SEPTEMBER 29, 1855 pp. 17-24 | . 1855 | 11 | 10.2307/e24948713 | No. 2 SEPTEMBER 22, 1855 pp. 9-16 | . 1855 | 11 | 10.2307/e26139046 | No. 1 SEPTEMBER 15, 1855 pp. 1-8 | . 1855 | 10 | 10.2307/e26140725 | No. 52 SEPTEMBER 8, 1855 pp. 409-414 | . 1855 | 10 | 10.2307/e26140547 | No. 51 SEPTEMBER 1, 1855 pp. 401-408 | . 1855 | 10 | 10.2307/e26138819 | No. 50 AUGUST 25, 1855 pp. 393-400 | . 1855 | 10 | 10.2307/e24947697 | No. 49 AUGUST 18, 1855 pp. 385-392 | . 1855 | 10 | 10.2307/e26141135 | No. 48 AUGUST 11, 1855 pp. 377-384 | . 1855 | 10 | 10.2307/e26140692 | No. 47 AUGUST 4, 1855 pp. 369-376 | . 1855 | 10 | 10.2307/e26140091 | No. 46 JULY 28, 1855 pp. 361-368 | . 1855 | 10 | 10.2307/e26139001 | No. 45 JULY 21, 1855 pp. 353-360 | . 1855 | 10 | 10.2307/e26140371 | No. 44 JULY 14, 1855 pp. 353-360 | . 1855 | 10 | 10.2307/e26141197 | No. 43 JULY 7, 1855 pp. 337-344 | . 1855 | 10 | 10.2307/e26139741 | No. 42 JUNE 30, 1855 pp. 329-336 | . 1855 | 10 | 10.2307/e26140743 | No. 41 JUNE 23, 1855 pp. 321-328 | . 1855 | 10 | 10.2307/e24949333 | No. 40 JUNE 16, 1855 pp. 313-320 | . 1855 | 10 | 10.2307/e26141673 | No. 39 JUNE 9, 1855 pp. 305-312 | . 1855 | 10 | 10.2307/e26140649 | No. 38 JUNE 2, 1855 pp. 297-304 | . 1855 | 10 | 10.2307/e26141402 | No. 37 MAY 26, 1855 pp. 289-296 | . 1855 | 10 | 10.2307/e24946941 | No. 36 MAY 19, 1855 pp. 281-288 | . 1855 | 10 | 10.2307/e26140962 | No. 35 MAY 12, 1855 pp. 273-280 | . 1855 | 10 | 10.2307/e26141078 | No. 34 MAY 5, 1855 pp. 265-272 | . 1855 | 10 | 10.2307/e26139508 | No. 33 APRIL 28, 1855 pp. 257-264 | . 1855 | 10 | 10.2307/e26140650 | No. 32 APRIL 21, 1855 pp. 249-256 | . 1855 | 10 | 10.2307/e24948291 | No. 31 APRIL 14, 1855 pp. 241-248 | . 1855 | 10 | 10.2307/e26141453 | No. 30 APRIL 7, 1855 pp. 233-240 | . 1855 | 10 | 10.2307/e24947834 | No. 29 MARCH 31, 1855 pp. 225-232 | . 1855 | 10 | 10.2307/e24947318 | No. 28 MARCH 24, 1855 pp. 217-224 | . 1855 | 10 | 10.2307/e24948192 | No. 27 MARCH 17, 1855 pp. 209-216 | . 1855 | 10 | 10.2307/e26140127 | No. 26 MARCH 10, 1855 pp. 201-208 | . 1855 | 10 | 10.2307/e26140926 | No. 25 MARCH 3, 1855 pp. 193-200 | . 1855 | 10 | 10.2307/e26139165 | No. 24 FEBRUARY 24, 1855 pp. 185-192 | . 1855 | 10 | 10.2307/e26141626 | No. 23 FEBRUARY 17, 1855 pp. 177-184 | . 1855 | 10 | 10.2307/e26140290 | No. 22 FEBRUARY 10, 1855 pp. 169-176 | . 1855 | 10 | 10.2307/e24946548 | No. 21 FEBRUARY 3, 1855 pp. 161-168 | . 1855 | 10 | 10.2307/e26141339 | No. 20 JANUARY 27, 1855 pp. 153-160 | . 1855 | 10 | 10.2307/e26139864 | No. 19 JANUARY 20, 1855 pp. 145-152 | . 1855 | 10 | 10.2307/e26140785 | No. 18 JANUARY 13, 1855 pp. 137-144 | . 1855 | 10 | 10.2307/e26138864 | No. 17 JANUARY 6, 1855 pp. 129-136 | . 1854 | 10 | 10.2307/e26138942 | No. 16 DECEMBER 30, 1854 pp. 121-128 | . 1854 | 10 | 10.2307/e26140437 | No. 15 DECEMBER 23, 1854 pp. 113-120 | . 1854 | 10 | 10.2307/e26141291 | No. 14 DECEMBER 16, 1854 pp. 105-112 | . 1854 | 10 | 10.2307/e26139818 | No. 13 DECEMBER 9, 1854 pp. 97-104 | . 1854 | 10 | 10.2307/e26139120 | No. 12 DECEMBER 2, 1854 pp. 89-96 | . 1854 | 10 | 10.2307/e26140501 | No. 11 NOVEMBER 25, 1854 pp. 81-88 | . 1854 | 10 | 10.2307/e26141581 | No. 10 NOVEMBER 18, 1854 pp. 73-80 | . 1854 | 10 | 10.2307/e26140243 | No. 9 NOVEMBER 11, 1854 pp. 65-72 | . 1854 | 10 | 10.2307/e26139254 | No. 8 NOVEMBER 4, 1854 pp. 57-64 | . 1854 | 10 | 10.2307/e24949081 | No. 7 OCTOBER 28, 1854 pp. 49-56 | . 1854 | 10 | 10.2307/e26140886 | No. 6 OCTOBER 21, 1854 pp. 41-48 | . 1854 | 10 | 10.2307/e26140398 | No. 5 OCTOBER 14, 1854 pp. 33-40 | . 1854 | 10 | 10.2307/e26139690 | No. 4 OCTOBER 7, 1854 pp. 25-32 | . 1854 | 10 | 10.2307/e26141501 | No. 3 SEPTEMBER 30, 1854 pp. 17-24 | . 1854 | 10 | 10.2307/e26135601 | No. 2 SEPTEMBER 23, 1854 pp. 9-16 | . 1854 | 10 | 10.2307/e26133258 | No. 1 SEPTEMBER 16, 1854 pp. 1-8 | . 1854 | 9 | 10.2307/e24948575 | No. 51 SEPTEMBER 2, 1854 pp. 401-408 | . 1854 | 9 | 10.2307/e24946793 | No. 50 AUGUST 26, 1854 pp. 393-400 | . 1854 | 9 | 10.2307/e24947197 | No. 49 AUGUST 19, 1854 pp. 385-392 | . 1854 | 9 | 10.2307/e24946593 | No. 48 AUGUST 12, 1854 pp. 377-384 | . 1854 | 9 | 10.2307/e24948098 | No. 47 AUGUST 5, 1854 pp. 369-376 | . 1854 | 9 | 10.2307/e24946672 | No. 46 JULY 29, 1854 pp. 361-368 | . 1854 | 9 | 10.2307/e24949209 | No. 45 JULY 22, 1854 pp. 353-360 | . 1854 | 9 | 10.2307/e24948423 | No. 44 JULY 15, 1854 pp. 345-352 | . 1854 | 9 | 10.2307/e24948003 | No. 43 JULY 8, 1854 pp. 337-344 | . 1854 | 9 | 10.2307/e24947470 | No. 42 JULY 1, 1854 pp. 329-336 | . 1854 | 9 | 10.2307/e24947078 | No. 41 JUNE 24, 1854 pp. 321-328 | . 1854 | 9 | 10.2307/e26133395 | No. 40 JUNE 17, 1854 pp. 313-320 | . 1854 | 9 | 10.2307/e26042275 | No. 39 JUNE 10, 1854 pp. 305-312 | . 1854 | 9 | 10.2307/e24946513 | No. 38 JUNE 3, 1854 pp. 297-304 | . 1854 | 9 | 10.2307/e24948943 | No. 37 MAY 27, 1854 pp. 289-296 | . 1854 | 9 | 10.2307/e24938002 | No. 36 MAY 20, 1854 pp. 281-288 | . 1854 | 9 | 10.2307/e24938447 | No. 35 MAY 13, 1854 pp. 273-280 | . 1854 | 9 | 10.2307/e24938397 | No. 34 MAY 6, 1854 pp. 265-272 | . 1854 | 9 | 10.2307/e26137118 | No. 33 APRIL 29, 1854 pp. 257-264 | . 1854 | 9 | 10.2307/e24938045 | No. 32 APRIL 22, 1854 pp. 249-256 | . 1854 | 9 | 10.2307/e26130961 | No. 31 APRIL 15, 1854 pp. 241-248 | . 1854 | 9 | 10.2307/e24938631 | No. 30 APRIL 8, 1854 pp. 233-240 | . 1854 | 9 | 10.2307/e24937786 | No. 29 APRIL 1, 1854 pp. 225-232 | . 1854 | 9 | 10.2307/e24938269 | No. 28 MARCH 25, 1854 pp. 217-224 | . 1854 | 9 | 10.2307/e24938092 | No. 27 MARCH 18, 1854 pp. 209-216 | . 1854 | 9 | 10.2307/e26132668 | No. 26 MARCH 11, 1854 pp. 201-208 | . 1854 | 9 | 10.2307/e26130161 | No. 25 MARCH 4, 1854 pp. 193-200 | . 1854 | 9 | 10.2307/e26137630 | No. 24 FEBRUARY 25, 1854 pp. 185-192 | . 1854 | 9 | 10.2307/e26138545 | No. 23 FEBRUARY 18, 1854 pp. 177-184 | . 1854 | 9 | 10.2307/e26131377 | No. 22 FEBRUARY 11, 1854 pp. 169-176 | . 1854 | 9 | 10.2307/e26136098 | No. 21 FEBRUARY 4, 1854 pp. 161-168 | . 1854 | 9 | 10.2307/e26136570 | No. 20 JANUARY 28, 1854 pp. 153-160 | . 1854 | 9 | 10.2307/e26134560 | No. 19 JANUARY 21, 1854 pp. 145-152 | . 1854 | 9 | 10.2307/e26137946 | No. 18 JANUARY 14, 1854 pp. 137-144 | . 1854 | 9 | 10.2307/e26138237 | No. 17 JANUARY 7, 1854 pp. 129-136 | . 1853 | 9 | 10.2307/e26135128 | No. 16 DECEMBER 31, 1853 pp. 121-128 | . 1853 | 9 | 10.2307/e26131247 | No. 15 DECEMBER 24, 1853 pp. 113-120 | . 1853 | 9 | 10.2307/e26128933 | No. 14 DECEMBER 17, 1853 pp. 105-112 | . 1853 | 9 | 10.2307/e26134072 | No. 13 DECEMBER 10, 1853 pp. 97-104 | . 1853 | 9 | 10.2307/e26137399 | No. 12 DECEMBER 3, 1853 pp. 89-96 | . 1853 | 9 | 10.2307/e26132394 | No. 11 NOVEMBER 26, 1853 pp. 81-88 | . 1853 | 9 | 10.2307/e26129136 | No. 10 NOVEMBER 19, 1853 pp. 73-80 | . 1853 | 9 | 10.2307/e26132549 | No. 9 NOVEMBER 12, 1853 pp. 65-72 | . 1853 | 9 | 10.2307/e26129560 | No. 8 NOVEMBER 5, 1853 pp. 57-64 | . 1853 | 9 | 10.2307/e26133930 | No. 7 OCTOBER 29, 1853 pp. 49-56 | . 1853 | 9 | 10.2307/e26132296 | No. 6 OCTOBER 22, 1853 pp. 41-48 | . 1853 | 9 | 10.2307/e26136442 | No. 5 OCTOBER 15, 1853 pp. 33-40 | . 1853 | 9 | 10.2307/e26130693 | No. 4 OCTOBER 8, 1853 pp. 25-32 | . 1853 | 9 | 10.2307/e26134965 | No. 3 OCTOBER 1, 1853 pp. 17-24 | . 1853 | 9 | 10.2307/e26138156 | No. 2 SEPTEMBER 24, 1853 pp. 9-16 | . 1853 | 9 | 10.2307/e26132790 | No. 1 SEPTEMBER 17, 1853 pp. 1-8 | . 1853 | 8 | 10.2307/e24937919 | No. 51 SEPTEMBER 3, 1853 pp. 401-408 | . 1853 | 8 | 10.2307/e24938229 | No. 50 AUGUST 27, 1853 pp. 393-400 | . 1853 | 8 | 10.2307/e24937568 | No. 49 AUGUST 20, 1853 pp. 385-392 | . 1853 | 8 | 10.2307/e24938541 | No. 48 AUGUST 13, 1853 pp. 377-384 | . 1853 | 8 | 10.2307/e24938357 | No. 46 JULY 30, 1853 pp. 361-368 | . 1853 | 8 | 10.2307/e24937731 | No. 44 JULY 16, 1853 pp. 345-352 | . 1853 | 8 | 10.2307/e24937875 | No. 42 JULY 2, 1853 pp. 329-336 | . 1853 | 8 | 10.2307/e24937608 | No. 41 JUNE 25, 1853 pp. 321-328 | . 1853 | 8 | 10.2307/e24938189 | No. 40 JUNE 18, 1853 pp. 313-320 | . 1853 | 8 | 10.2307/e24937651 | No. 39 JUNE 11, 1853 pp. 305-312 | . 1853 | 8 | 10.2307/e24938583 | No. 38 JUNE 4, 1853 pp. 297-304 | . 1853 | 8 | 10.2307/e24938308 | No. 37 MAY 28, 1853 pp. 289-296 | . 1853 | 8 | 10.2307/e24938142 | No. 36 MAY 21, 1853 pp. 281-288 | . 1853 | 8 | 10.2307/e24937958 | No. 35 MAY 14, 1853 pp. 273-280 | . 1853 | 8 | 10.2307/e24937826 | No. 33 APRIL 30, 1853 pp. 257-264 | . 1853 | 8 | 10.2307/e24937692 | No. 32 APRIL 25, 1853 pp. 249-256 | . 1853 | 8 | 10.2307/e24937521 | No. 31 APRIL 16, 1853 pp. 241-248 | . 1853 | 8 | 10.2307/e24938490 | No. 30 APRIL 9, 1853 pp. 233-240 | . 1853 | 8 | 10.2307/e24935212 | No. 29 APRIL 2, 1853 pp. 225-232 | . 1853 | 8 | 10.2307/e24935673 | No. 28 MARCH 26, 1853 pp. 217-224 | . 1853 | 8 | 10.2307/e26046653 | No. 27 MARCH 19, 1853 pp. 209-216 | . 1853 | 8 | 10.2307/e26131888 | No. 26 MARCH 12, 1853 pp. 201-208 | . 1853 | 8 | 10.2307/e26129998 | No. 25 MARCH 5, 1853 pp. 193-200 | . 1853 | 8 | 10.2307/e26135824 | No. 24 FEBRUARY 26, 1853 pp. 185-192 | . 1853 | 8 | 10.2307/e26134877 | No. 23 FEBRUARY 19, 1853 pp. 177-184 | . 1853 | 8 | 10.2307/e26129251 | No. 22 FEBRUARY 12, 1853 pp. 169-176 | . 1853 | 8 | 10.2307/e26137356 | No. 21 FEBRUARY 5, 1853 pp. 161-168 | . 1853 | 8 | 10.2307/e26135544 | No. 20 JANUARY 29, 1853 pp. 153-160 | . 1853 | 8 | 10.2307/e26132989 | No. 19 JANUARY 22, 1853 pp. 145-152 | . 1853 | 8 | 10.2307/e26129884 | No. 18 JANUARY 15, 1853 pp. 137-144 | . 1853 | 8 | 10.2307/e26134233 | No. 17 JANUARY 8, 1853 pp. 129-136 | . 1853 | 8 | 10.2307/e26137520 | No. 16 JANUARY 1, 1853 pp. 121-128 | . 1852 | 8 | 10.2307/e26131730 | No. 15 DECEMBER 25, 1852 pp. 113-120 | . 1852 | 8 | 10.2307/e26135954 | No. 14 DECEMBER 18, 1852 pp. 105-112 | . 1852 | 8 | 10.2307/e26138706 | No. 13 DECEMBER 11, 1852 pp. 97-104 | . 1852 | 8 | 10.2307/e26135264 | No. 12 DECEMBER 4, 1852 pp. 89-96 | . 1852 | 8 | 10.2307/e26138056 | No. 11 NOVEMBER 27, 1852 pp. 81-88 | . 1852 | 8 | 10.2307/e26136998 | No. 10 NOVEMBER 20, 1852 pp. 73-80 | . 1852 | 8 | 10.2307/e26137183 | No. 9 NOVEMBER 13, 1852 pp. 65-72 | . 1852 | 8 | 10.2307/e26131103 | No. 8 NOVEMBER 6, 1852 pp. 57-64 | . 1852 | 8 | 10.2307/e26135387 | No. 7 OCTOBER 30, 1852 pp. 49-56 | . 1852 | 8 | 10.2307/e26138362 | No. 6 OCTOBER 23, 1852 pp. 41-48 | . 1852 | 8 | 10.2307/e26133067 | No. 5 OCTOBER 16, 1852 pp. 33-40 | . 1852 | 8 | 10.2307/e26136854 | No. 3 OCTOBER 2, 1852 pp. 17-24 | . 1852 | 8 | 10.2307/e26130465 | No. 2 SEPTEMBER 25, 1852 pp. 9-16 | . 1852 | 8 | 10.2307/e26138648 | No. 1 SEPTEMBER 18, 1852 pp. 1-8 | . 1852 | 7 | 10.2307/e24935263 | No. 52 SEPTEMBER 11, 1852 pp. 409-414 | . 1852 | 7 | 10.2307/e24935873 | No. 51 SEPTEMBER 4, 1852 pp. 401-408 | . 1852 | 7 | 10.2307/e24934924 | No. 50 AUGUST 28, 1852 pp. 393-400 | . 1852 | 7 | 10.2307/e24935519 | No. 49 AUGUST 21, 1852 pp. 385-392 | . 1852 | 7 | 10.2307/e24935283 | No. 48 AUGUST 14, 1852 pp. 377-384 | . 1852 | 7 | 10.2307/e24935096 | No. 47 AUGUST 7, 1852 pp. 369-376 | . 1852 | 7 | 10.2307/e24935463 | No. 46 JULY 31, 1852 pp. 361-368 | . 1852 | 7 | 10.2307/e24934649 | No. 45 JULY 25, 1852 pp. 353-360 | . 1852 | 7 | 10.2307/e24935766 | No. 44 JULY 17, 1852 pp. 345-352 | . 1852 | 7 | 10.2307/e24935620 | No. 43 JULY 10, 1852 pp. 337-344 | . 1852 | 7 | 10.2307/e24934872 | No. 42 JULY 3, 1852 pp. 329-336 | . 1852 | 7 | 10.2307/e24935041 | No. 41 JUNE 26, 1852 pp. 321-328 | . 1852 | 7 | 10.2307/e24934710 | No. 40 JUNE 19, 1852 pp. 313-320 | . 1852 | 7 | 10.2307/e24935402 | No. 39 JUNE 12, 1852 pp. 305-312 | . 1852 | 7 | 10.2307/e24934762 | No. 38 JUNE 5, 1852 pp. 297-304 | . 1852 | 7 | 10.2307/e24935820 | No. 37 MAY 29, 1852 pp. 289-296 | . 1852 | 7 | 10.2307/e24935565 | No. 36 MAY 22, 1852 pp. 281-288 | . 1852 | 7 | 10.2307/e24935348 | No. 35 MAY 15, 1852 pp. 273-280 | . 1852 | 7 | 10.2307/e24935152 | No. 34 MAY 8, 1852 pp. 265-272 | . 1852 | 7 | 10.2307/e24934977 | No. 33 MAY 1, 1852 pp. 257-264 | . 1852 | 7 | 10.2307/e24934814 | No. 32 APRIL 24, 1852 pp. 249-256 | . 1852 | 7 | 10.2307/e24934594 | No. 31 APRIL 17, 1852 pp. 241-248 | . 1852 | 7 | 10.2307/e24935713 | No. 30 APRIL 10, 1852 pp. 233-240 | . 1852 | 7 | 10.2307/e24933947 | No. 29 APRIL 3, 1852 pp. 225-232 | . 1852 | 7 | 10.2307/e24934373 | No. 28 MARCH 27, 1852 pp. 217-224 | . 1852 | 7 | 10.2307/e24934319 | No. 27 MARCH 20, 1852 pp. 209-216 | . 1852 | 7 | 10.2307/e26133766 | No. 26 MARCH 13, 1852 pp. 201-208 | . 1852 | 7 | 10.2307/e26137853 | No. 25 MARCH 6, 1852 pp. 193-200 | . 1852 | 7 | 10.2307/e26132121 | No. 24 FEBRUARY 28, 1852 pp. 185-192 | . 1852 | 7 | 10.2307/e26136271 | No. 23 FEBRUARY 21, 1852 pp. 177-184 | . 1852 | 7 | 10.2307/e26129418 | No. 22 FEBRUARY 14, 1852 pp. 169-176 | . 1852 | 7 | 10.2307/e26129664 | No. 21 FEBRUARY 7, 1852 pp. 161-168 | . 1852 | 7 | 10.2307/e26134441 | No. 20 JANUARY 31, 1852 pp. 153-160 | . 1852 | 7 | 10.2307/e26137743 | No. 19 JANUARY 24, 1852 pp. 145-152 | . 1852 | 7 | 10.2307/e26131980 | No. 18 JANUARY 17, 1852 pp. 137-144 | . 1852 | 7 | 10.2307/e26130292 | No. 17 JANUARY 10, 1852 pp. 129-136 | . 1852 | 7 | 10.2307/e26134681 | No. 16 JANUARY 3, 1852 pp. 121-128 | . 1851 | 7 | 10.2307/e26138595 | No. 15 DECEMBER 27, 1851 pp. 113-120 | . 1851 | 7 | 10.2307/e26133584 | No. 14 DECEMBER 20, 1851 pp. 105-112 | . 1851 | 7 | 10.2307/e26130797 | No. 13 DECEMBER 13, 1851 pp. 97-104 | . 1851 | 7 | 10.2307/e26136704 | No. 12 DECEMBER 6, 1851 pp. 89-96 | . 1851 | 7 | 10.2307/e26134285 | No. 11 NOVEMBER 29, 1851 pp. 81-88 | . 1851 | 7 | 10.2307/e26131567 | No. 10 NOVEMBER 22, 1851 pp. 73-80 | . 1851 | 7 | 10.2307/e26138413 | No. 9 NOVEMBER 15, 1851 pp. 65-72 | . 1851 | 7 | 10.2307/e26128059 | No. 8 NOVEMBER 8, 1851 pp. 57-64 | . 1851 | 7 | 10.2307/e26129540 | No. 7 NOVEMBER 1, 1851 pp. 49-56 | . 1851 | 7 | 10.2307/e26127332 | No. 6 OCTOBER 25, 1851 pp. 41-48 | . 1851 | 7 | 10.2307/e26134443 | No. 5 OCTOBER 18, 1851 pp. 33-40 | . 1851 | 7 | 10.2307/e26136046 | No. 4 OCTOBER 11, 1851 pp. 25-32 | . 1851 | 7 | 10.2307/e26128338 | No. 3 OCTOBER 4, 1851 pp. 17-24 | . 1851 | 7 | 10.2307/e26132844 | No. 2 SEPTEMBER 27, 1851 pp. 9-16 | . 1851 | 7 | 10.2307/e26133344 | No. 1 SEPTEMBER 20, 1851 pp. 1-8 | . 1851 | 6 | 10.2307/e24933984 | No. 52 SEPTEMBER 13, 1851 pp. 409-414 | . 1851 | 6 | 10.2307/e24934546 | No. 51 SEPTEMBER 6, 1851 pp. 401-408 | . 1851 | 6 | 10.2307/e24933725 | No. 50 AUGUST 30, 1851 pp. 393-400 | . 1851 | 6 | 10.2307/e24934182 | No. 49 AUGUST 23, 1851 pp. 385-392 | . 1851 | 6 | 10.2307/e24934015 | No. 48 AUGUST 16, 1851 pp. 377-384 | . 1851 | 6 | 10.2307/e24933852 | No. 47 AUGUST 9, 1851 pp. 369-376 | . 1851 | 6 | 10.2307/e24934139 | No. 46 AUGUST 2, 1851 pp. 361-368 | . 1851 | 6 | 10.2307/e24933464 | No. 45 JULY 26, 1851 pp. 353-360 | . 1851 | 6 | 10.2307/e24934458 | No. 44 JULY 19, 1851 pp. 345-352 | . 1851 | 6 | 10.2307/e24934272 | No. 43 JULY 12, 1851 pp. 337-344 | . 1851 | 6 | 10.2307/e24933671 | No. 42 JULY 5, 1851 pp. 329-336 | . 1851 | 6 | 10.2307/e24933816 | No. 41 JUNE 28, 1851 pp. 321-328 | . 1851 | 6 | 10.2307/e24933515 | No. 40 JUNE 21, 1851 pp. 313-320 | . 1851 | 6 | 10.2307/e24934102 | No. 39 JUNE 14, 1851 pp. 305-312 | . 1851 | 6 | 10.2307/e24933569 | No. 38 JUNE 7, 1851 pp. 297-304 | . 1851 | 6 | 10.2307/e24934500 | No. 37 MAY 31, 1851 pp. 289-296 | . 1851 | 6 | 10.2307/e24934231 | No. 36 MAY 24, 1851 pp. 281-288 | . 1851 | 6 | 10.2307/e24934060 | No. 35 MAY 17, 1851 pp. 273-280 | . 1851 | 6 | 10.2307/e24933899 | No. 34 MAY 10, 1851 pp. 265-272 | . 1851 | 6 | 10.2307/e24933773 | No. 33 MAY 3, 1851 pp. 257-264 | . 1851 | 6 | 10.2307/e24933617 | No. 32 APRIL 26, 1851 pp. 249-256 | . 1851 | 6 | 10.2307/e26000238 | No. 31 APRIL 19, 1851 pp. 241-248 | . 1851 | 6 | 10.2307/e24934421 | No. 30 APRIL 12, 1851 pp. 233-240 | . 1851 | 6 | 10.2307/e24932657 | No. 29 APRIL 3, 1851 pp. 225-232 | . 1851 | 6 | 10.2307/e24933185 | No. 28 MARCH 29, 1851 pp. 217-224 | . 1851 | 6 | 10.2307/e24933145 | No. 27 MARCH 22, 1851 pp. 209-216 | . 1851 | 6 | 10.2307/e26131371 | No. 26 MARCH 15, 1851 pp. 201-208 | . 1851 | 6 | 10.2307/e26135003 | No. 25 MARCH 8, 1851 pp. 193-200 | . 1851 | 6 | 10.2307/e26135548 | No. 24 MARCH 1, 1851 pp. 185-192 | . 1851 | 6 | 10.2307/e26132054 | No. 23 FEBRUARY 22, 1851 pp. 177-184 | . 1851 | 6 | 10.2307/e26128260 | No. 22 FEBRUARY 15, 1851 pp. 169-176 | . 1851 | 6 | 10.2307/e26126082 | No. 21 FEBRUARY 8, 1851 pp. 161-168 | . 1851 | 6 | 10.2307/e26130682 | No. 20 FEBRUARY 1, 1851 pp. 153-160 | . 1851 | 6 | 10.2307/e26134258 | No. 19 JANUARY 25, 1851 pp. 145-152 | . 1851 | 6 | 10.2307/e26129255 | No. 18 JANUARY 18, 1851 pp. 137-144 | . 1851 | 6 | 10.2307/e26126276 | No. 17 JANUARY 11, 1851 pp. 129-136 | . 1851 | 6 | 10.2307/e26129415 | No. 16 JANUARY 4, 1851 pp. 121-128 | . 1850 | 6 | 10.2307/e26126725 | No. 15 DECEMBER 28, 1850 pp. 113-120 | . 1850 | 6 | 10.2307/e26130477 | No. 14 DECEMBER 21, 1850 pp. 105-112 | . 1850 | 6 | 10.2307/e26129132 | No. 13 DECEMBER 14, 1850 pp. 97-104 | . 1850 | 6 | 10.2307/e26133192 | No. 12 DECEMBER 7, 1850 pp. 89-96 | . 1850 | 6 | 10.2307/e26127798 | No. 11 NOVEMBER 30, 1850 pp. 81-88 | . 1850 | 6 | 10.2307/e26131893 | No. 10 NOVEMBER 23, 1850 pp. 73-80 | . 1850 | 6 | 10.2307/e26135384 | No. 9 NOVEMBER 16, 1850 pp. 65-72 | . 1850 | 6 | 10.2307/e26129645 | No. 8 NOVEMBER 9, 1850 pp. 57-64 | . 1850 | 6 | 10.2307/e26128681 | No. 7 NOVEMBER 2, 1850 pp. 49-56 | . 1850 | 6 | 10.2307/e26127225 | No. 6 OCTOBER 26, 1850 pp. 41-48 | . 1850 | 6 | 10.2307/e26132586 | No. 5 OCTOBER 19, 1850 pp. 33-40 | . 1850 | 6 | 10.2307/e26131726 | No. 4 OCTOBER 12, 1850 pp. 25-32 | . 1850 | 6 | 10.2307/e26126390 | No. 3 OCTOBER 5, 1850 pp. 17-24 | . 1850 | 6 | 10.2307/e26134192 | No. 2 SEPTEMBER 28, 1850 pp. 9-16 | . 1850 | 6 | 10.2307/e26132457 | No. 1 SEPTEMBER 21, 1850 pp. 1-8 | . 1850 | 5 | 10.2307/e24932712 | No. 52 SEPTEMBER 14, 1850 pp. 409-416 | . 1850 | 5 | 10.2307/e24933418 | No. 51 SEPTEMBER 7, 1850 pp. 401-408 | . 1850 | 5 | 10.2307/e24932373 | No. 50 AUGUST 31, 1850 pp. 393-400 | . 1850 | 5 | 10.2307/e24932973 | No. 49 AUGUST 24, 1850 pp. 385-392 | . 1850 | 5 | 10.2307/e24932751 | No. 48 AUGUST 17, 1850 pp. 377-384 | . 1850 | 5 | 10.2307/e24932524 | No. 47 AUGUST 10, 1850 pp. 369-376 | . 1850 | 5 | 10.2307/e24932914 | No. 46 AUGUST 3, 1850 pp. 361-368 | . 1850 | 5 | 10.2307/e24932049 | No. 45 JULY 27, 1850 pp. 353-360 | . 1850 | 5 | 10.2307/e24933290 | No. 44 JULY 20, 1850 pp. 345-352 | . 1850 | 5 | 10.2307/e24933089 | No. 43 JULY 13, 1850 pp. 337-344 | . 1850 | 5 | 10.2307/e24932323 | No. 42 JULY 6, 1850 pp. 329-336 | . 1850 | 5 | 10.2307/e24932480 | No. 41 JUNE 29, 1850 pp. 321-328 | . 1850 | 5 | 10.2307/e24932118 | No. 40 JUNE 22, 1850 pp. 313-320 | . 1850 | 5 | 10.2307/e24932852 | No. 39 JUNE 15, 1850 pp. 305-312 | . 1850 | 5 | 10.2307/e24932179 | No. 38 JUNE 8, 1850 pp. 297-304 | . 1850 | 5 | 10.2307/e24933362 | No. 37 JUNE 1, 1850 pp. 289-296 | . 1850 | 5 | 10.2307/e24933030 | No. 36 MAY 25, 1850 pp. 281-288 | . 1850 | 5 | 10.2307/e24932796 | No. 35 MAY 18, 1850 pp. 273-280 | . 1850 | 5 | 10.2307/e24932593 | No. 34 MAY 11, 1850 pp. 265-272 | . 1850 | 5 | 10.2307/e24932427 | No. 33 MAY 4, 1850 pp. 257-264 | . 1850 | 5 | 10.2307/e24932237 | No. 32 APRIL 27, 1850 pp. 249-256 | . 1850 | 5 | 10.2307/e24931996 | No. 31 APRIL 20, 1850 pp. 241-248 | . 1850 | 5 | 10.2307/e24933233 | No. 30 APRIL 13, 1850 pp. 233-240 | . 1850 | 5 | 10.2307/e24929886 | No. 29 APRIL 6, 1850 pp. 225-232 | . 1850 | 5 | 10.2307/e24930559 | No. 28 MARCH 30, 1850 pp. 217-224 | . 1850 | 5 | 10.2307/e24930513 | No. 27 MARCH 23, 1850 pp. 209-216 | . 1850 | 5 | 10.2307/e26129789 | No. 26 MARCH 16, 1850 pp. 201-208 | . 1850 | 5 | 10.2307/e26127018 | No. 25 MARCH 9, 1850 pp. 193-200 | . 1850 | 5 | 10.2307/e26130786 | No. 24 MARCH 2, 1850 pp. 185-192 | . 1850 | 5 | 10.2307/e26134286 | No. 23 FEBRUARY 23, 1850 pp. 177-184 | . 1850 | 5 | 10.2307/e26128589 | No. 22 FEBRUARY 16, 1850 pp. 169-176 | . 1850 | 5 | 10.2307/e26132723 | No. 21 FEBRUARY 9, 1850 pp. 161-168 | . 1850 | 5 | 10.2307/e26136602 | No. 20 FEBRUARY 2, 1850 pp. 153-160 | . 1850 | 5 | 10.2307/e26132120 | No. 19 JANUARY 26, 1850 pp. 145-152 | . 1850 | 5 | 10.2307/e26135195 | No. 18 JANUARY 19, 1850 pp. 137-144 | . 1850 | 5 | 10.2307/e26133869 | No. 17 JANUARY 12, 1850 pp. 129-136 | . 1850 | 5 | 10.2307/e26134057 | No. 16 JANUARY 5, 1850 pp. 121-128 | . 1849 | 5 | 10.2307/e26128128 | No. 15 DECEMBER 29, 1849 pp. 113-120 | . 1849 | 5 | 10.2307/e26132297 | No. 14 DECEMBER 22, 1849 pp. 105-112 | . 1849 | 5 | 10.2307/e26135668 | No. 13 DECEMBER 15, 1849 pp. 97-104 | . 1849 | 5 | 10.2307/e26129927 | No. 12 DECEMBER 8, 1849 pp. 89-96 | . 1849 | 5 | 10.2307/e26133715 | No. 11 DECEMBER 1, 1849 pp. 81-88 | . 1849 | 5 | 10.2307/e26127664 | No. 10 NOVEMBER 24, 1849 pp. 73-80 | . 1849 | 5 | 10.2307/e26136421 | No. 9 NOVEMBER 17, 1849 pp. 65-72 | . 1849 | 5 | 10.2307/e26130349 | No. 8 NOVEMBER 10, 1849 pp. 57-64 | . 1849 | 5 | 10.2307/e26134810 | No. 7 NOVEMBER 3, 1849 pp. 49-56 | . 1849 | 5 | 10.2307/e26128927 | No. 6 OCTOBER 27, 1849 pp. 41-48 | . 1849 | 5 | 10.2307/e26133031 | No. 5 OCTOBER 20, 1849 pp. 33-40 | . 1849 | 5 | 10.2307/e26126559 | No. 4 OCTOBER 13, 1849 pp. 25-32 | . 1849 | 5 | 10.2307/e26126788 | No. 3 OCTOBER 6, 1849 pp. 17-24 | . 1849 | 5 | 10.2307/e26131148 | No. 2 SEPTEMBER 29, 1849 pp. 9-16 | . 1849 | 5 | 10.2307/e26134609 | No. 1 SEPTEMBER 22, 1849 pp. 1-8 | . 1849 | 4 | 10.2307/e24929938 | No. 52 September 15, 1849 pp. 409-416 | . 1849 | 4 | 10.2307/e24930769 | No. 51 September 8, 1849 pp. 401-408 | . 1849 | 4 | 10.2307/e24929538 | No. 50 September 1, 1849 pp. 393-400 | . 1849 | 4 | 10.2307/e24930280 | No. 49 August 25, 1849 pp. 385-392 | . 1849 | 4 | 10.2307/e24930018 | No. 48 August 18, 1849 pp. 377-384 | . 1849 | 4 | 10.2307/e24929751 | No. 47 August 11, 1849 pp. 369-376 | . 1849 | 4 | 10.2307/e24930209 | No. 46 August 4, 1849 pp. 361-368 | . 1849 | 4 | 10.2307/e24929190 | No. 45 July 28, 1849 pp. 353-360 | . 1849 | 4 | 10.2307/e24930631 | No. 44 July 21, 1849 pp. 345-352 | . 1849 | 4 | 10.2307/e24930436 | No. 43 July 14, 1849 pp. 337-344 | . 1849 | 4 | 10.2307/e24929479 | No. 42 July 7, 1849 pp. 329-336 | . 1849 | 4 | 10.2307/e24929685 | No. 41 June 30, 1849 pp. 321-328 | . 1849 | 4 | 10.2307/e24929259 | No. 40 June 23, 1849 pp. 313-320 | . 1849 | 4 | 10.2307/e24930145 | No. 39 June 16, 1849 pp. 305-312 | . 1849 | 4 | 10.2307/e24929326 | No. 38 June 9, 1849 pp. 297-304 | . 1849 | 4 | 10.2307/e24930695 | No. 37 June 2, 1849 pp. 289-296 | . 1849 | 4 | 10.2307/e24930358 | No. 36 May 26, 1849 pp. 281-288 | . 1849 | 4 | 10.2307/e24930084 | No. 35 May 19, 1849 pp. 273-280 | . 1849 | 4 | 10.2307/e24929821 | No. 34 May 12, 1849 pp. 265-272 | . 1849 | 4 | 10.2307/e24929623 | No. 33 May 5, 1849 pp. 257-264 | . 1849 | 4 | 10.2307/e24929405 | No. 32 April 28, 1849 pp. 249-256 | . 1849 | 4 | 10.2307/e24929115 | No. 31 April 21, 1849 pp. 241-248 | . 1849 | 4 | 10.2307/e24930560 | No. 30 April 14, 1849 pp. 233-240 | . 1849 | 4 | 10.2307/e24928234 | No. 29 April 7, 1849 pp. 225-232 | . 1849 | 4 | 10.2307/e24928694 | No. 28 March 31, 1849 pp. 217-224 | . 1849 | 4 | 10.2307/e24928616 | No. 27 March 24, 1849 pp. 209-216 | . 1849 | 4 | 10.2307/e26128770 | No. 26 March 17, 1849 pp. 201-208 | . 1849 | 4 | 10.2307/e26127552 | No. 25 March 10, 1849 pp. 193-200 | . 1849 | 4 | 10.2307/e26131490 | No. 24 March 3, 1849 pp. 185-192 | . 1849 | 4 | 10.2307/e26136156 | No. 23 February, 24 1849 pp. 177-184 | . 1849 | 4 | 10.2307/e26130142 | No. 22 February 17, 1849 pp. 169-176 | . 1849 | 4 | 10.2307/e26127930 | No. 21 February 10, 1849 pp. 161-168 | . 1849 | 4 | 10.2307/e26133526 | No. 20 February 3, 1849 pp. 153-160 | . 1849 | 4 | 10.2307/e26130962 | No. 19 January 27, 1849 pp. 145-152 | . 1849 | 4 | 10.2307/e26128463 | No. 18 January 20, 1849 pp. 137-144 | . 1849 | 4 | 10.2307/e26135853 | No. 17 January 13, 1849 pp. 129-136 | . 1849 | 4 | 10.2307/e26135142 | No. 16 January 6, 1849 pp. 121-128 | . 1848 | 4 | 10.2307/e26126075 | No. 15 December 30, 1848 pp. 113-120 | . 1848 | 4 | 10.2307/e26128611 | No. 14 December 23, 1848 pp. 105-112 | . 1848 | 4 | 10.2307/e26124839 | No. 13 December 16, 1848 pp. 97-104 | . 1848 | 4 | 10.2307/e26136338 | No. 12 December 9, 1848 pp. 89-96 | . 1848 | 4 | 10.2307/e26137897 | No. 11 December 2, 1848 pp. 81-88 | . 1848 | 4 | 10.2307/e26126756 | No. 10 November 25, 1848 pp. 73-80 | . 1848 | 4 | 10.2307/e26133580 | No. 9 November 18, 1848 pp. 65-72 | . 1848 | 4 | 10.2307/e26134257 | No. 8 November 11, 1848 pp. 57-64 | . 1848 | 4 | 10.2307/e26131136 | No. 7 November 4, 1848 pp. 49-56 | . 1848 | 4 | 10.2307/e26137012 | No. 6 October 28, 1848 pp. 41-48 | . 1848 | 4 | 10.2307/e26137504 | No. 5 October 21, 1848 pp. 33-40 | . 1848 | 4 | 10.2307/e26132083 | No. 4 October 14, 1848 pp. 25-32 | . 1848 | 4 | 10.2307/e26126537 | No. 3 October 7, 1848 pp. 17-24 | . 1848 | 4 | 10.2307/e26122000 | No. 2 September 30, 1848 pp. 9-16 | . 1848 | 4 | 10.2307/e26130159 | No. 1 September 23, 1848 pp. 1-8 | . 1848 | 3 | 10.2307/e24928311 | No. 52 September 16, 1848 pp. 409-416 | . 1848 | 3 | 10.2307/e24928772 | No. 51 September 9, 1848 pp. 401-408 | . 1848 | 3 | 10.2307/e24927989 | No. 50 September 2, 1848 pp. 393-400 | . 1848 | 3 | 10.2307/e24928527 | No. 49 August 26, 1848 pp. 385-392 | . 1848 | 3 | 10.2307/e24928377 | No. 48 August 19, 1848 pp. 377-384 | . 1848 | 3 | 10.2307/e24928158 | No. 47 August 12, 1848 pp. 369-376 | . 1848 | 3 | 10.2307/e24928448 | No. 46 August 5, 1848 pp. 361-368 | . 1848 | 3 | 10.2307/e24921385 | No. 46 August 5, 1848 pp. 361-368 | . 1848 | 3 | 10.2307/e24928856 | No. 45 July 29, 1848 pp. 353-360 | . 1848 | 3 | 10.2307/e24929027 | No. 44 July 22, 1848 pp. 345-352 | . 1848 | 3 | 10.2307/e24928937 | No. 43 July 15, 1848 pp. 337-344 | . 1848 | 3 | 10.2307/e24927904 | No. 42 July 8, 1848 pp. 329-336 | . 1848 | 3 | 10.2307/e24928073 | No. 41 July 1, 1848 pp. 321-328 | . 1848 | 3 | 10.2307/e24927809 | No. 40 June 24, 1848 pp. 313-320 | . 1848 | 3 | 10.2307/e24927032 | No. 39 June 17, 1848 pp. 305-312 | . 1848 | 3 | 10.2307/e24926951 | No. 38 June 10, 1848 pp. 297-304 | . 1848 | 3 | 10.2307/e24927187 | No. 37 June 3, 1848 pp. 289-296 | . 1848 | 3 | 10.2307/e24927104 | No. 36 May 27, 1848 pp. 281-288 | . 1848 | 3 | 10.2307/e24926783 | No. 35 May 20, 1848 pp. 273-280 | . 1848 | 3 | 10.2307/e24926711 | No. 34 May 13, 1848 pp. 265-272 | . 1848 | 3 | 10.2307/e24926648 | No. 33 May 6, 1848 pp. 257-264 | . 1848 | 3 | 10.2307/e24926553 | No. 32 April 29, 1848 pp. 249-256 | . 1848 | 3 | 10.2307/e24926454 | No. 31 April 22, 1848 pp. 241-248 | . 1848 | 3 | 10.2307/e24926870 | No. 30 April 15, 1848 pp. 233-240 | . 1848 | 3 | 10.2307/e24925418 | No. 29 April 8, 1848 pp. 225-232 | . 1848 | 3 | 10.2307/e24925239 | No. 28 April 1, 1848 pp. 217-224 | . 1848 | 3 | 10.2307/e24925156 | No. 27 March 25, 1848 pp. 209-216 | . 1848 | 3 | 10.2307/e24924839 | No. 26 March 18, 1848 pp. 201-208 | . 1848 | 3 | 10.2307/e24925500 | No. 25 March 11, 1848 pp. 193-200 | . 1848 | 3 | 10.2307/e26135806 | No. 24 March 4, 1848 pp. 185-192 | . 1848 | 3 | 10.2307/e26128282 | No. 23 February 26, 1848 pp. 177-184 | . 1848 | 3 | 10.2307/e26122350 | No. 22 February 19, 1848 pp. 169-176 | . 1848 | 3 | 10.2307/e26128447 | No. 21 February 12, 1848 pp. 161-168 | . 1848 | 3 | 10.2307/e26123408 | No. 20 February 5, 1848 pp. 153-160 | . 1848 | 3 | 10.2307/e26129873 | No. 19 January 29, 1848 pp. 145-152 | . 1848 | 3 | 10.2307/e26128092 | No. 18 January 22, 1848 pp. 137-144 | . 1848 | 3 | 10.2307/e26133998 | No. 17 January 15, 1848 pp. 129-136 | . 1848 | 3 | 10.2307/e26125444 | No. 16 January 8 1848 pp. 121-128 | . 1848 | 3 | 10.2307/e26131854 | No. 15 January 1, 1848 pp. 113-120 | . 1847 | 3 | 10.2307/e26137345 | No. 14 December 25, 1847 pp. 105-112 | . 1847 | 3 | 10.2307/e26128726 | No. 13 December 18, 1847 pp. 97-104 | . 1847 | 3 | 10.2307/e26127572 | No. 12 December 11, 1847 pp. 89-96 | . 1847 | 3 | 10.2307/e26124484 | No. 11 December 4, 1847 pp. 81-88 | . 1847 | 3 | 10.2307/e26133023 | No. 10 November 27, 1847 pp. 73-80 | . 1847 | 3 | 10.2307/e26131550 | No. 9 November 20, 1847 pp. 65-72 | . 1847 | 3 | 10.2307/e26122612 | No. 8 November 13, 1847 pp. 57-64 | . 1847 | 3 | 10.2307/e26135551 | No. 7 November 6, 1847 pp. 49-56 | . 1847 | 3 | 10.2307/e26132708 | No. 6 October 30, 1847 pp. 41-48 | . 1847 | 3 | 10.2307/e26128882 | No. 5 October 23, 1847 pp. 33-40 | . 1847 | 3 | 10.2307/e26124105 | No. 4 October 16, 1847 pp. 25-32 | . 1847 | 3 | 10.2307/e26130352 | No. 3 October 9, 1847 pp. 17-24 | . 1847 | 3 | 10.2307/e26136060 | No. 2 October 2, 1847 pp. 9-16 | . 1847 | 3 | 10.2307/e26127201 | No. 1 September 25, 1847 pp. 1-8 | . 1847 | 2 | 10.2307/e24925314 | No. 52 SEPTEMBER 18, 1847 pp. 409-416 | . 1847 | 2 | 10.2307/e26133265 | No. 51 SEPTEMBER 11, 1847 pp. 401-408 | . 1847 | 2 | 10.2307/e24925037 | No. 50 SEPTEMBER 4, 1847 pp. 393-400 | . 1847 | 2 | 10.2307/e24924933 | No. 49 AUGUST 28, 1847 pp. 385-392 | . 1847 | 2 | 10.2307/e24924722 | No. 48 AUGUST 21, 1847 pp. 377-384 | . 1847 | 2 | 10.2307/e24924132 | No. 47 AUGUST 14, 1847 pp. 369-376 | . 1847 | 2 | 10.2307/e26138351 | No. 46 AUGUST 7, 1847 pp. 361-368 | . 1847 | 2 | 10.2307/e24923335 | No. 45 JULY 31, 1847 pp. 353-360 | . 1847 | 2 | 10.2307/e24924514 | No. 44 JULY 24, 1847 pp. 345-352 | . 1847 | 2 | 10.2307/e24924317 | No. 43 JULY 17, 1847 pp. 337-344 | . 1847 | 2 | 10.2307/e24923716 | No. 42 JULY 10, 1847 pp. 329-336 | . 1847 | 2 | 10.2307/e24923817 | No. 41 JULY 3, 1847 pp. 321-328 | . 1847 | 2 | 10.2307/e24923449 | No. 40 JUNE 26, 1847 pp. 313-320 | . 1847 | 2 | 10.2307/e26132276 | No. 39 JUNE 19, 1847 pp. 305-312 | . 1847 | 2 | 10.2307/e24924023 | No. 38 JUNE 12, 1847 pp. 297-304 | . 1847 | 2 | 10.2307/e26137130 | No. 37 JUNE 5, 1847 pp. 289-296 | . 1847 | 2 | 10.2307/e24923568 | No. 36 MAY 29, 1847 pp. 281-288 | . 1847 | 2 | 10.2307/e24924615 | No. 35 MAY 22, 1847 pp. 273-280 | . 1847 | 2 | 10.2307/e26134880 | No. 34 MAY 15, 1847 pp. 265-272 | . 1847 | 2 | 10.2307/e24924244 | No. 33 MAY 8, 1847 pp. 257-264 | . 1847 | 2 | 10.2307/e24924022 | No. 32 MAY 1, 1847 pp. 249-256 | . 1847 | 2 | 10.2307/e24923927 | No. 31 APRIL 24, 1847 pp. 241-248 | . 1847 | 2 | 10.2307/e24923816 | No. 30 APRIL 17, 1847 pp. 233-240 | . 1847 | 2 | 10.2307/e24923652 | No. 29 APRIL 10, 1847 pp. 225-232 | . 1847 | 2 | 10.2307/e24923277 | No. 28 APRIL 3, 1847 pp. 217-224 | . 1847 | 2 | 10.2307/e24924428 | No. 27 MARCH 27, 1847 pp. 209-216 | . 1847 | 2 | 10.2307/e26135305 | No. 26 MARCH 20, 1847 pp. 201-208 | . 1847 | 2 | 10.2307/e26126266 | No. 25 MARCH 13, 1847 pp. 193-200 | . 1847 | 2 | 10.2307/e26132523 | No. 24 MARCH 6, 1847 pp. 185-192 | . 1847 | 2 | 10.2307/e26137616 | No. 23 FEBRUARY 27, 1847 pp. 177-184 | . 1847 | 2 | 10.2307/e26129153 | No. 22 FEBRUARY 20, 1847 pp. 169-176 | . 1847 | 2 | 10.2307/e26134638 | No. 21 FEBRUARY 13, 1847 pp. 161-168 | . 1847 | 2 | 10.2307/e26125242 | No. 20 FEBRUARY 6, 1847 pp. 153-160 | . 1847 | 2 | 10.2307/e26138192 | No. 19 JANUARY 30, 1847 pp. 145-152 | . 1847 | 2 | 10.2307/e26129582 | No. 18 JANUARY 23, 1847 pp. 137-144 | . 1847 | 2 | 10.2307/e26136807 | No. 17 JANUARY 16, 1847 pp. 129-136 | . 1847 | 2 | 10.2307/e26127937 | No. 16 JANUARY 9, 1847 pp. 121-128 | . 1847 | 2 | 10.2307/e26133785 | No. 15 JANUARY 2, 1847 pp. 113-120 | . 1846 | 2 | 10.2307/e26123061 | No. 14 DECEMBER 26, 1846 pp. 105-112 | . 1846 | 2 | 10.2307/e26123742 | No. 13 DECEMBER 19, 1846 pp. 97-104 | . 1846 | 2 | 10.2307/e26130889 | No. 12 DECEMBER 12, 1846 pp. 89-96 | . 1846 | 2 | 10.2307/e26136526 | No. 11 DECEMBER 5, 1846 pp. 81-88 | . 1846 | 2 | 10.2307/e26127765 | No. 10 NOVEMBER 28, 1846 pp. 73-80 | . 1846 | 2 | 10.2307/e26125012 | No. 9 NOVEMBER 21, 1846 pp. 65-72 | . 1846 | 2 | 10.2307/e26131296 | No. 8 NOVEMBER 14, 1846 pp. 57-64 | . 1846 | 2 | 10.2307/e26138046 | No. 7 NOVEMBER 6, 1846 pp. 49-56 | . 1846 | 2 | 10.2307/e26129390 | No. 6 OCTOBER 31, 1846 pp. 41-48 | . 1846 | 2 | 10.2307/e26125777 | No. 5 OCTOBER 24, 1846 pp. 33-40 | . 1846 | 2 | 10.2307/e26134399 | No. 4 OCTOBER 17, 1846 pp. 25-32 | . 1846 | 2 | 10.2307/e26130664 | No. 3 OCTOBER 10, 1846 pp. 17-24 | . 1846 | 2 | 10.2307/e26126935 | No. 2 OCTOBER 3, 1846 pp. 9-16 | . 1846 | 2 | 10.2307/e26137762 | No. 1 SEPTEMBER 26, 1846 pp. 1-8 | . 1846 | 1 | 10.2307/e24922661 | No. 52 SEPTEMBER 17, 1846 pp. | . 1846 | 1 | 10.2307/e24922639 | No. 51 SEPTEMBER 10, 1846 pp. | . 1846 | 1 | 10.2307/e24922621 | No. 50 SEPTEMBER 3, 1846 pp. | . 1846 | 1 | 10.2307/e24922582 | No. 49 AUGUST 27, 1846 pp. | . 1846 | 1 | 10.2307/e24922600 | No. 48 AUGUST 20, 1846 pp. | . 1846 | 1 | 10.2307/e24922530 | No. 47 AUGUST 13, 1846 pp. | . 1846 | 1 | 10.2307/e24922547 | No. 46 AUGUST 6, 1846 pp. | . 1846 | 1 | 10.2307/e24922564 | No. 45 JULY 30, 1846 pp. | . 1846 | 1 | 10.2307/e24922510 | No. 44 JULY 23, 1846 pp. | . 1846 | 1 | 10.2307/e24922491 | No. 43 JULY 16, 1846 pp. | . 1846 | 1 | 10.2307/e24922375 | No. 42 JULY 9, 1846 pp. | . 1846 | 1 | 10.2307/e24922451 | No. 41 JULY 2, 1846 pp. | . 1846 | 1 | 10.2307/e24922395 | No. 40 JUNE 25, 1846 pp. | . 1846 | 1 | 10.2307/e24922690 | No. 39 JUNE 18, 1846 pp. | . 1846 | 1 | 10.2307/e24922716 | No. 38 JUNE 4, 1846 pp. | . 1846 | 1 | 10.2307/e24922374 | No. 37 MAY 28, 1846 pp. | . 1846 | 1 | 10.2307/e24922355 | No. 36 MAY 21, 1846 pp. | . 1846 | 1 | 10.2307/e24922204 | No. 35 MAY 14, 1846 pp. | . 1846 | 1 | 10.2307/e24922239 | No. 34 MAY 6, 1846 pp. | . 1846 | 1 | 10.2307/e24922315 | No. 33 APRIL 30, 1846 pp. | . 1846 | 1 | 10.2307/e24922221 | No. 32 APRIL 23, 1846 pp. | . 1846 | 1 | 10.2307/e24922260 | No. 31 APRIL 16, 1846 pp. | . 1846 | 1 | 10.2307/e24922338 | No. 30 APRIL 9, 1846 pp. | . 1846 | 1 | 10.2307/e24922413 | No. 29 APRIL 2, 1846 pp. | . 1846 | 1 | 10.2307/e24922470 | No. 28 MARCH 26, 1846 pp. | . 1846 | 1 | 10.2307/e24922273 | No. 27 MARCH 19, 1846 pp. | . 1846 | 1 | 10.2307/e24922292 | No. 26 MARCH 12, 1846 pp. | . 1846 | 1 | 10.2307/e24922162 | No. 25 MARCH 5, 1846 pp. | . 1846 | 1 | 10.2307/e24922184 | No. 24 FEBRUARY 26, 1846 pp. | . 1846 | 1 | 10.2307/e24922122 | No. 23 FEBRUARY 19, 1846 pp. | . 1846 | 1 | 10.2307/e24922045 | No. 22 FEBRUARY 12, 1846 pp. | . 1846 | 1 | 10.2307/e24922082 | No. 21 FEBRUARY 5, 1846 pp. | . 1846 | 1 | 10.2307/e24922022 | No. 20 JANUARY 29, 1846 pp. | . 1846 | 1 | 10.2307/e24922146 | No. 19 JANUARY 22, 1846 pp. | . 1846 | 1 | 10.2307/e24922063 | No. 18 JANUARY 15,1846 pp. | . 1846 | 1 | 10.2307/e24922103 | No. 17 JANUARY 8, 1846 pp. | . 1846 | 1 | 10.2307/e24921934 | No. 16 JANUARY 1, 1846 pp. | . 1845 | 1 | 10.2307/e24921976 | No. 15 DECEMBER 25, 1845 pp. | . 1845 | 1 | 10.2307/e24921889 | No. 14 DECEMBER 18, 1845 pp. | . 1845 | 1 | 10.2307/e24921913 | No. 13 DECEMBER 11, 1845 pp. | . 1845 | 1 | 10.2307/e24921954 | No. 12 DECEMBER 4, 1845 pp. | . 1845 | 1 | 10.2307/e24921846 | No. 11 NOVEMBER 27, 1845 pp. | . 1845 | 1 | 10.2307/e24921745 | No. 10 NOVEMBER 20, 1845 pp. | . 1845 | 1 | 10.2307/e24921684 | No. 9 NOVEMBER 13, 1845 pp. | . 1845 | 1 | 10.2307/e24921802 | No. 8 OCTOBER 16, 1845 pp. | . 1845 | 1 | 10.2307/e24921869 | No. 7 OCTOBER 9, 1845 pp. | . 1845 | 1 | 10.2307/e24921765 | No. 6 OCTOBER 2, 1845 pp. | . 1845 | 1 | 10.2307/e24921703 | No. 5 SEPTEMBER 25, 1845 pp. | . 1845 | 1 | 10.2307/e24921825 | No. 4 SEPTEMBER 18, 1845 pp. | . 1845 | 1 | 10.2307/e24921782 | No. 3 SEPTEMBER 11, 1845 pp. | . 1845 | 1 | 10.2307/e24921724 | No. 2 SEPTEMBER 4, 1845 pp. | . 1845 | 1 | 10.2307/e24921868 | No. 1 AUGUST 28, 1845 pp. | .",
            "url": "https://jimregan.github.io/notes/scraper/sciam/2022/12/08/sciam-jstor.html",
            "relUrl": "/scraper/sciam/2022/12/08/sciam-jstor.html",
            "date": " • Dec 8, 2022"
        }
        
    
  
    
        ,"post46": {
            "title": "Scraper for Interspeech, etc.",
            "content": "from bs4 import BeautifulSoup import requests . req = requests.get(&quot;https://www.isca-speech.org/archive/&quot;) . assert req.status_code == 200 . soup = BeautifulSoup(req.text, &#39;html.parser&#39;) . for div in soup.find_all(&quot;div&quot;, {&quot;class&quot;: &quot;w3-container&quot;}): if div.text.strip().endswith(&quot;1987&quot;): top = div . raw_data = [] for a_tag in top.find_all(&quot;a&quot;): href = a_tag.attrs[&quot;href&quot;] conf = href.split(&quot;_&quot;)[0] year = href.split(&quot;/&quot;)[0].split(&quot;_&quot;)[-1] if conf.endswith(&quot;speech&quot;): doi = f&quot;10.21437/{conf[0].upper()}{conf[1:]}.{year}&quot; elif conf == &quot;icslp&quot;: doi = f&quot;10.21437/{conf.upper()}.{year}&quot; else: doi = &quot;&quot; raw_data.append([href, conf, year, doi]) . output = [] output.append(&quot;| Year | Conference | Title | DOI |&quot;) output.append(&quot;|||-|--|&quot;) for item in raw_data: output.append(f&quot;| {item[2]} | {item[1]} | [{item[1].upper()} {item[2]}](https://www.isca-speech.org/archive/{item[0]}) | {item[3]} |&quot;) . from IPython.display import display, Markdown . display(Markdown(&quot; n&quot;.join(output))) . Year Conference Title DOI . 2022 | interspeech | INTERSPEECH 2022 | 10.21437/Interspeech.2022 | . 2021 | interspeech | INTERSPEECH 2021 | 10.21437/Interspeech.2021 | . 2020 | interspeech | INTERSPEECH 2020 | 10.21437/Interspeech.2020 | . 2019 | interspeech | INTERSPEECH 2019 | 10.21437/Interspeech.2019 | . 2018 | interspeech | INTERSPEECH 2018 | 10.21437/Interspeech.2018 | . 2017 | interspeech | INTERSPEECH 2017 | 10.21437/Interspeech.2017 | . 2016 | interspeech | INTERSPEECH 2016 | 10.21437/Interspeech.2016 | . 2015 | interspeech | INTERSPEECH 2015 | 10.21437/Interspeech.2015 | . 2014 | interspeech | INTERSPEECH 2014 | 10.21437/Interspeech.2014 | . 2013 | interspeech | INTERSPEECH 2013 | 10.21437/Interspeech.2013 | . 2012 | interspeech | INTERSPEECH 2012 | 10.21437/Interspeech.2012 | . 2011 | interspeech | INTERSPEECH 2011 | 10.21437/Interspeech.2011 | . 2010 | interspeech | INTERSPEECH 2010 | 10.21437/Interspeech.2010 | . 2009 | interspeech | INTERSPEECH 2009 | 10.21437/Interspeech.2009 | . 2008 | interspeech | INTERSPEECH 2008 | 10.21437/Interspeech.2008 | . 2007 | interspeech | INTERSPEECH 2007 | 10.21437/Interspeech.2007 | . 2006 | interspeech | INTERSPEECH 2006 | 10.21437/Interspeech.2006 | . 2005 | interspeech | INTERSPEECH 2005 | 10.21437/Interspeech.2005 | . 2004 | interspeech | INTERSPEECH 2004 | 10.21437/Interspeech.2004 | . 2003 | eurospeech | EUROSPEECH 2003 | 10.21437/Eurospeech.2003 | . 2002 | icslp | ICSLP 2002 | 10.21437/ICSLP.2002 | . 2001 | eurospeech | EUROSPEECH 2001 | 10.21437/Eurospeech.2001 | . 2000 | icslp | ICSLP 2000 | 10.21437/ICSLP.2000 | . 1999 | eurospeech | EUROSPEECH 1999 | 10.21437/Eurospeech.1999 | . 1998 | icslp | ICSLP 1998 | 10.21437/ICSLP.1998 | . 1997 | eurospeech | EUROSPEECH 1997 | 10.21437/Eurospeech.1997 | . 1996 | icslp | ICSLP 1996 | 10.21437/ICSLP.1996 | . 1995 | eurospeech | EUROSPEECH 1995 | 10.21437/Eurospeech.1995 | . 1994 | icslp | ICSLP 1994 | 10.21437/ICSLP.1994 | . 1993 | eurospeech | EUROSPEECH 1993 | 10.21437/Eurospeech.1993 | . 1992 | icslp | ICSLP 1992 | 10.21437/ICSLP.1992 | . 1991 | eurospeech | EUROSPEECH 1991 | 10.21437/Eurospeech.1991 | . 1990 | icslp | ICSLP 1990 | 10.21437/ICSLP.1990 | . 1989 | eurospeech | EUROSPEECH 1989 | 10.21437/Eurospeech.1989 | . 1987 | ecst | ECST 1987 | | .",
            "url": "https://jimregan.github.io/notes/scraper/interspeech/2022/12/08/interspeech-scraper.html",
            "relUrl": "/scraper/interspeech/2022/12/08/interspeech-scraper.html",
            "date": " • Dec 8, 2022"
        }
        
    
  
    
        ,"post47": {
            "title": "Scraper for ICASSP from IEEE",
            "content": "from bs4 import BeautifulSoup . The temporary file below is extracted from IEEE . with open(&quot;/tmp/icassp&quot;) as inf: html = inf.read() . soup = BeautifulSoup(html, &#39;html.parser&#39;) . top = soup.find(&quot;div&quot;, {&quot;class&quot;: &quot;issue-list-container&quot;}) . import re . data = [] for li in top.find_all(&quot;li&quot;, {&quot;_ngcontent-ftl-c305&quot;: &quot;&quot;}): raw = li.text.strip() a_tag = li.find(&quot;a&quot;) href = a_tag.attrs[&quot;href&quot;] title = a_tag.text.strip() m1 = re.search(&quot;^ICASSP (20 d d).*&quot;, raw) m2 = re.search(&quot;.*((?:20|19) d d) (?:IEEE )?International.*&quot;, raw) m3 = re.search(&quot;.*ICASSP &#39;( d d).*&quot;, raw) if m1: year = m1.group(1) elif m2: year = m2.group(1) elif m3: year = m3.group(1) # Why yes, in this, the Year of Our Lord, 2022, # writing this scraper has meant having to do # Y2K compensation if year.startswith(&quot;0&quot;): year = &quot;20&quot; + year else: year = &quot;19&quot; + year elif raw == &quot;International Conference on Acoustics, Speech, and Signal Processing&quot;: year = &quot;1990&quot; elif raw == &quot;International Conference on Acoustics, Speech, and Signal Processing,&quot;: year == &quot;1989&quot; elif raw.startswith(&quot;ICASSP-88.,&quot;): year = &quot;1988&quot; loc_tag = li.find(&quot;span&quot;, {&quot;_ngcontent-ftl-c305&quot;: &quot;&quot;}) if loc_tag: loc = loc_tag.text.strip().replace(&quot;Location: &quot;, &quot;&quot;) data.append([href, title, year, loc]) . count = 1 data.reverse() for item in data: item.append(str(count)) count += 1 data.reverse() . template = &quot;https://ieeexplore.ieee.org/rest/publication/home/metadata?pubid=&quot; . import requests . raw_json = requests.get(template + &quot;9413349&quot;) . raw_json.text . &#39;&lt;HTML&gt;&lt;HEAD&gt;&lt;TITLE&gt;Error&lt;/TITLE&gt;&lt;/HEAD&gt;&lt;BODY&gt; nAn error occurred while processing your request.&lt;p&gt; nReference&amp;#32;&amp;#35;30&amp;#46;64aa2617&amp;#46;1670514466&amp;#46;8894ff4 n&lt;/BODY&gt;&lt;/HTML&gt; n&#39; . Bah. Ok, API is a waste of time: limit is too low, registering for a key is a bit annoying for a one-time operation. . DOIs = &quot;&quot;&quot; 10.1109/ICASSP43922.2022 10.1109/ICASSP39728.2021 DOI: 10.1109/ICASSP40776.2020 DOI: 10.1109/ICASSP35589.2019 DOI: 10.1109/ICASSP34228.2018 DOI: 10.1109/ICASSP31846.2017 DOI: 10.1109/ICASSP17257.2015 DOI: 10.1109/ICASSP18874.2014 DOI: 10.1109/ICASSP16080.2013 DOI: 10.1109/ICASSP15465.2012 DOI: 10.1109/ICASSP15948.2011 DOI: 10.1109/ICASSP15600.2010 DOI: 10.1109/ICASSP13629.2009 DOI: 10.1109/ICASSP12235.2008 DOI: 10.1109/ICASSP10710.2007 DOI: 10.1109/ICASSP10488.2006 DOI: 10.1109/ICASSP8829.2005 DOI: 10.1109/ICASSP.2004 DOI: 10.1109/ICASSP.2003 DOI: 10.1109/ICASSP.2002 DOI: 10.1109/ICASSP.2001 DOI: 10.1109/ICASSP.2000 DOI: 10.1109/ICASSP.1999 DOI: 10.1109/ICASSP.1998 DOI: 10.1109/ICASSP.1997 DOI: 10.1109/ICASSP.1996 DOI: 10.1109/ICASSP.1995 DOI: 10.1109/ICASSP.1994 DOI: 10.1109/ICASSP.1993 DOI: 10.1109/ICASSP.1992 DOI: 10.1109/ICASSP.1991 DOI: 10.1109/ICASSP.1990 DOI: 10.1109/ICASSP.1989 DOI: 10.1109/ICASSP.1988 DOI: 10.1109/ICASSP.1987 DOI: 10.1109/ICASSP.1986 DOI: 10.1109/ICASSP.1985 DOI: 10.1109/ICASSP.1984 DOI: 10.1109/ICASSP.1983 DOI: 10.1109/ICASSP.1982 DOI: 10.1109/ICASSP.1981 DOI: 10.1109/ICASSP.1980 DOI: 10.1109/ICASSP.1979 DOI: 10.1109/ICASSP.1978 DOI: 10.1109/ICASSP.1977 DOI: 10.1109/ICASSP.1976 &quot;&quot;&quot; . doi_dict = {} for line in DOIs.replace(&quot;DOI: &quot;, &quot;&quot;).split(&quot; n&quot;): if line == &quot;&quot;: continue parts = line.split(&quot;.&quot;) doi_dict[parts[-1]] = line . output = [] output.append(&quot;| Year | Ordinal | DOI | Issue | Location |&quot;) output.append(&quot;|||--|-|-|&quot;) for item in data: #[href, title, year, loc, ord] if item[2] == &quot;2016&quot;: doi = &quot;&quot; else: doi = doi_dict[item[2]] output.append(f&quot;| {item[2]} | {item[4]} | {doi} | [{item[1]}](https://ieeexplore.ieee.org/{item[0]}) | {item[3]} |&quot;) . from IPython.display import display, Markdown . display(Markdown(&quot; n&quot;.join(output))) . Year Ordinal DOI Issue Location . 2022 | 47 | 10.1109/ICASSP43922.2022 | ICASSP 2022 - 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) | Singapore, Singapore | . 2021 | 46 | 10.1109/ICASSP39728.2021 | ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) | Toronto, ON, Canada | . 2020 | 45 | 10.1109/ICASSP40776.2020 | ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) | Barcelona, Spain | . 2019 | 44 | 10.1109/ICASSP35589.2019 | ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) | Brighton, UK | . 2018 | 43 | 10.1109/ICASSP34228.2018 | 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) | Calgary, AB, Canada | . 2017 | 42 | 10.1109/ICASSP31846.2017 | 2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) | New Orleans, LA, USA | . 2016 | 41 | | 2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) | Shanghai, China | . 2015 | 40 | 10.1109/ICASSP17257.2015 | 2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) | South Brisbane, QLD, Australia | . 2014 | 39 | 10.1109/ICASSP18874.2014 | 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) | Florence, Italy | . 2013 | 38 | 10.1109/ICASSP16080.2013 | 2013 IEEE International Conference on Acoustics, Speech and Signal Processing | Vancouver, BC, Canada | . 2012 | 37 | 10.1109/ICASSP15465.2012 | 2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) | Kyoto, Japan | . 2011 | 36 | 10.1109/ICASSP15948.2011 | 2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) | Prague, Czech Republic | . 2010 | 35 | 10.1109/ICASSP15600.2010 | 2010 IEEE International Conference on Acoustics, Speech and Signal Processing | Dallas, TX, USA | . 2009 | 34 | 10.1109/ICASSP13629.2009 | 2009 IEEE International Conference on Acoustics, Speech and Signal Processing | Taipei, Taiwan | . 2008 | 33 | 10.1109/ICASSP12235.2008 | 2008 IEEE International Conference on Acoustics, Speech and Signal Processing | Las Vegas, NV, USA | . 2007 | 32 | 10.1109/ICASSP10710.2007 | 2007 IEEE International Conference on Acoustics, Speech and Signal Processing - ICASSP &#39;07 | Honolulu, HI, USA | . 2006 | 31 | 10.1109/ICASSP10488.2006 | 2006 IEEE International Conference on Acoustics Speech and Signal Processing Proceedings | Toulouse, France | . 2005 | 30 | 10.1109/ICASSP8829.2005 | Proceedings. (ICASSP &#39;05). IEEE International Conference on Acoustics, Speech, and Signal Processing, 2005. | Philadelphia, PA, USA | . 2004 | 29 | 10.1109/ICASSP.2004 | 2004 IEEE International Conference on Acoustics, Speech, and Signal Processing | Montreal, QC, Canada | . 2003 | 28 | 10.1109/ICASSP.2003 | 2003 IEEE International Conference on Acoustics, Speech, and Signal Processing, 2003. Proceedings. (ICASSP &#39;03). | Hong Kong, China | . 2002 | 27 | 10.1109/ICASSP.2002 | 2002 IEEE International Conference on Acoustics, Speech, and Signal Processing | Orlando, FL, USA | . 2001 | 26 | 10.1109/ICASSP.2001 | 2001 IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings (Cat. No.01CH37221) | Salt Lake City, UT, USA | . 2000 | 25 | 10.1109/ICASSP.2000 | 2000 IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings (Cat. No.00CH37100) | Istanbul, Turkey | . 1999 | 24 | 10.1109/ICASSP.1999 | 1999 IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings. ICASSP99 (Cat. No.99CH36258) | Phoenix, AZ, USA | . 1998 | 23 | 10.1109/ICASSP.1998 | Proceedings of the 1998 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP &#39;98 (Cat. No.98CH36181) | Seattle, WA, USA | . 1997 | 22 | 10.1109/ICASSP.1997 | 1997 IEEE International Conference on Acoustics, Speech, and Signal Processing | Munich, Germany | . 1996 | 21 | 10.1109/ICASSP.1996 | 1996 IEEE International Conference on Acoustics, Speech, and Signal Processing Conference Proceedings | Atlanta, GA, USA | . 1995 | 20 | 10.1109/ICASSP.1995 | 1995 International Conference on Acoustics, Speech, and Signal Processing | Detroit, MI, USA | . 1994 | 19 | 10.1109/ICASSP.1994 | Proceedings of ICASSP &#39;94. IEEE International Conference on Acoustics, Speech and Signal Processing | Adelaide, SA, Australia | . 1993 | 18 | 10.1109/ICASSP.1993 | 1993 IEEE International Conference on Acoustics, Speech, and Signal Processing | Minneapolis, MN, USA | . 1992 | 17 | 10.1109/ICASSP.1992 | [Proceedings] ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech, and Signal Processing | San Francisco, CA, USA | . 1991 | 16 | 10.1109/ICASSP.1991 | [Proceedings] ICASSP 91: 1991 International Conference on Acoustics, Speech, and Signal Processing | Toronto, ON, Canada | . 1991 | 15 | 10.1109/ICASSP.1991 | International Conference on Acoustics, Speech, and Signal Processing | Albuquerque, NM, USA | . 1991 | 14 | 10.1109/ICASSP.1991 | International Conference on Acoustics, Speech, and Signal Processing, | Glasgow, UK | . 1988 | 13 | 10.1109/ICASSP.1988 | ICASSP-88., International Conference on Acoustics, Speech, and Signal Processing | New York, NY, USA | . 1987 | 12 | 10.1109/ICASSP.1987 | ICASSP &#39;87. IEEE International Conference on Acoustics, Speech, and Signal Processing | Dallas, TX, USA | . 1986 | 11 | 10.1109/ICASSP.1986 | ICASSP &#39;86. IEEE International Conference on Acoustics, Speech, and Signal Processing | Tokyo, Japan | . 1985 | 10 | 10.1109/ICASSP.1985 | ICASSP &#39;85. IEEE International Conference on Acoustics, Speech, and Signal Processing | Tampa, FL, USA | . 1984 | 9 | 10.1109/ICASSP.1984 | ICASSP &#39;84. IEEE International Conference on Acoustics, Speech, and Signal Processing | San Diego, CA, USA | . 1983 | 8 | 10.1109/ICASSP.1983 | ICASSP &#39;83. IEEE International Conference on Acoustics, Speech, and Signal Processing | Boston, MA, USA | . 1982 | 7 | 10.1109/ICASSP.1982 | ICASSP &#39;82. IEEE International Conference on Acoustics, Speech, and Signal Processing | Paris, France | . 1981 | 6 | 10.1109/ICASSP.1981 | ICASSP &#39;81. IEEE International Conference on Acoustics, Speech, and Signal Processing | Atlanta, GA,USA | . 1980 | 5 | 10.1109/ICASSP.1980 | ICASSP &#39;80. IEEE International Conference on Acoustics, Speech, and Signal Processing | Denver, CO, USA | . 1979 | 4 | 10.1109/ICASSP.1979 | ICASSP &#39;79. IEEE International Conference on Acoustics, Speech, and Signal Processing | Washington, DC, USA | . 1978 | 3 | 10.1109/ICASSP.1978 | ICASSP &#39;78. IEEE International Conference on Acoustics, Speech, and Signal Processing | Tulsa, OK, USA | . 1977 | 2 | 10.1109/ICASSP.1977 | ICASSP &#39;77. IEEE International Conference on Acoustics, Speech, and Signal Processing | Hartford, CT, USA | . 1976 | 1 | 10.1109/ICASSP.1976 | ICASSP &#39;76. IEEE International Conference on Acoustics, Speech, and Signal Processing | Philadelphia, PA, USA | .",
            "url": "https://jimregan.github.io/notes/scraper/icassp/2022/12/08/icassp-scraper.html",
            "relUrl": "/scraper/icassp/2022/12/08/icassp-scraper.html",
            "date": " • Dec 8, 2022"
        }
        
    
  
    
        ,"post48": {
            "title": "Playing with SimpleLanguageModel from pynlpl",
            "content": "!pip install pynlpl . from pynlpl.lm.lm import SimpleLanguageModel . WARNING: The FoLiA library pynlpl.formats.folia is being used but this version is now deprecated and is replaced by FoLiAPy (pip install folia), see https://github.com/proycon/foliapy. Please update your software if you are a developer, if you are an end-user you can safely ignore this message. . lm = SimpleLanguageModel(3) . lm.append(&quot;test sentence one&quot;) lm.append(&quot;also a test sentence&quot;) . lm.save(&quot;simple.lm&quot;) . !cat simple.lm . [simplelanguagemodel] n=3 sentences=2 beginmarker=&lt;begin&gt; endmarker=&lt;end&gt; casesensitive=1 [freqlistN] &lt;begin&gt; &lt;begin&gt; test 1 &lt;begin&gt; test sentence 1 test sentence one 1 sentence one &lt;end&gt; 1 one &lt;end&gt; &lt;end&gt; 1 &lt;begin&gt; &lt;begin&gt; also 1 &lt;begin&gt; also a 1 also a test 1 a test sentence 1 test sentence &lt;end&gt; 1 sentence &lt;end&gt; &lt;end&gt; 1 [freqlistNm1] test sentence 2 &lt;begin&gt; test 1 sentence one 1 one &lt;end&gt; 1 &lt;begin&gt; also 1 also a 1 a test 1 sentence &lt;end&gt; 1 .",
            "url": "https://jimregan.github.io/notes/pynlpl/lm/arpa/2022/12/06/pynlpl-simplelanguagemodel.html",
            "relUrl": "/pynlpl/lm/arpa/2022/12/06/pynlpl-simplelanguagemodel.html",
            "date": " • Dec 6, 2022"
        }
        
    
  
    
        ,"post49": {
            "title": "Interesting links, 05/12/2022",
            "content": "udon2/udon2 — A package for manipulating Universal Dependencies trees . Generalization problem in ASR acoustic model training and adaptation . AudioCLIP: Extending CLIP to Image, Text and Audio AndreyGuzhov/AudioCLIP . Linear model and neural net from scratch . Trigonometry Concepts - Don’t Memorize! Visualize! . . Binnabánnaš på lulesamiska . Viessohattit ain njidjet . NRK Sápmi, NRK Sápmi . North Saami (Guovdageaidnu) lexicon . . Fecal Matter - Illiteracy will prevail . Nirvana - ‘Skid Row’ Rehearsal 1987 .",
            "url": "https://jimregan.github.io/notes/links/2022/12/05/misc-links.html",
            "relUrl": "/links/2022/12/05/misc-links.html",
            "date": " • Dec 5, 2022"
        }
        
    
  
    
        ,"post50": {
            "title": "Convert WebVTT to Elan",
            "content": "!pip install pympi-ling webvtt-py . from pympi import Eaf import webvtt . from pathlib import Path . def convert_vtt_to_elan(filename, tiername=&quot;whisper&quot;): outfile = filename.replace(&quot;.vtt&quot;, &quot;.eaf&quot;) eaf = Eaf() eaf.add_tier(tiername) count = 1 for caption in webvtt.read(filename): start = int(caption.start_in_seconds * 1000) end = int(caption.end_in_seconds * 1000) text = caption.text.replace(&quot; n&quot;, &quot; &quot;).replace(&quot; r&quot;, &quot;&quot;) eaf.add_annotation(tiername, start, end, text) eaf.to_file(outfile) . for file in Path(&quot;.&quot;).glob(&quot;*vtt&quot;): convert_vtt_to_elan(str(file)) .",
            "url": "https://jimregan.github.io/notes/webvtt/elan/whisper/2022/11/11/convert-webvtt-to-elan.html",
            "relUrl": "/webvtt/elan/whisper/2022/11/11/convert-webvtt-to-elan.html",
            "date": " • Nov 11, 2022"
        }
        
    
  
    
        ,"post51": {
            "title": "Simple replacement for Kaldi's align-text",
            "content": "from difflib import SequenceMatcher import copy . a = [&#39;a&#39;, &#39;bad&#39;, &#39;time&#39;, &#39;today&#39;, &#39;etc&#39;] b = [&#39;not&#39;, &#39;really&#39;, &#39;bad&#39;, &#39;time&#39;, &#39;now&#39;] . s = SequenceMatcher(None, a, b) . def pad_replacements(a_in, b_in): a = copy.deepcopy(a_in) b = copy.deepcopy(b_in) if len(a) &gt; len(b): diff = len(a) - len(b) for i in range(0, diff+1): b.append(&quot;&lt;eps&gt;&quot;) elif len(b) &gt; len(a): diff = len(b) - len(a) for i in range(0, diff+1): a.append(&quot;&lt;eps&gt;&quot;) return [x for x in zip(a, b)] . assert pad_replacements([&quot;a&quot;, &quot;b&quot;], [&quot;a&quot;]) == [(&#39;a&#39;, &#39;a&#39;), (&#39;b&#39;, &#39;&lt;eps&gt;&#39;)] assert pad_replacements([&quot;a&quot;, &quot;b&quot;, &quot;c&quot;], [&quot;a&quot;]) == [(&#39;a&#39;, &#39;a&#39;), (&#39;b&#39;, &#39;&lt;eps&gt;&#39;), (&#39;c&#39;, &#39;&lt;eps&gt;&#39;)] assert pad_replacements([&quot;a&quot;], [&quot;a&quot;, &quot;b&quot;, &quot;c&quot;]) == [(&#39;a&#39;, &#39;a&#39;), (&#39;&lt;eps&gt;&#39;, &#39;b&#39;), (&#39;&lt;eps&gt;&#39;, &#39;c&#39;)] . outputs = [] for tag, i1, i2, j1, j2 in s.get_opcodes(): if tag == &quot;equal&quot;: for x in a[i1:i2]: outputs.append(f&quot;{x} {x}&quot;) elif tag == &quot;insert&quot;: for x in b[j1:j2]: outputs.append(f&quot;&lt;eps&gt; {x}&quot;) elif tag == &quot;delete&quot;: for x in a[i1:i2]: outputs.append(f&quot;{x} &lt;eps&gt;&quot;) elif tag == &quot;replace&quot;: for x, y in pad_replacements(a[i1:i2], b[j1:j2]): outputs.append(f&quot;{x} {y}&quot;) . &quot; ; &quot;.join(outputs) . &#39;a not ; &lt;eps&gt; really ; bad bad ; time time ; today now ; etc &lt;eps&gt;&#39; .",
            "url": "https://jimregan.github.io/notes/align/difflib/2022/11/10/align-text.html",
            "relUrl": "/align/difflib/2022/11/10/align-text.html",
            "date": " • Nov 10, 2022"
        }
        
    
  
    
        ,"post52": {
            "title": "Phonetic transcription with HuggingFace",
            "content": "Based on an earlier notebook . %%capture !pip install youtube-dl !pip install phonemizer . %%capture !apt install espeak-ng . !youtube-dl -x --audio-format best -o &#39;%(id)s.%(ext)s&#39; https://www.youtube.com/watch?v=Kw5jkyLGFGc . [youtube] Kw5jkyLGFGc: Downloading webpage [youtube] Kw5jkyLGFGc: Downloading MPD manifest [download] Destination: Kw5jkyLGFGc.m4a [download] 100% of 10.98MiB in 04:05 [ffmpeg] Correcting container in &#34;Kw5jkyLGFGc.m4a&#34; [ffmpeg] Post-process file Kw5jkyLGFGc.m4a exists, skipping . %%capture !ffmpeg -i Kw5jkyLGFGc.m4a -acodec pcm_s16le -ac 1 -ar 16000 Kw5jkyLGFGc.wav . Here starts the actual ASR stuff. . %%capture !pip install transformers . _SWE_MODEL = &quot;facebook/wav2vec2-lv-60-espeak-cv-ft&quot; . from transformers import pipeline . pipe = pipeline(model=_SWE_MODEL, device=0) . output = pipe(&quot;/content/Kw5jkyLGFGc.wav&quot;, chunk_length_s=10, return_timestamps=&quot;char&quot;) . import json with open(&quot;/content/Kw5jkyLGFGc.json&quot;, &quot;w&quot;) as f: json.dump(output, f) .",
            "url": "https://jimregan.github.io/notes/phonetic/espeak/wav2vec2/huggingface/timestamps/2022/10/18/wav2vec2-phonetic-transcription.html",
            "relUrl": "/phonetic/espeak/wav2vec2/huggingface/timestamps/2022/10/18/wav2vec2-phonetic-transcription.html",
            "date": " • Oct 18, 2022"
        }
        
    
  
    
        ,"post53": {
            "title": "Using IrishNLP's chunker with NLTK",
            "content": "%%capture !pip install nltk . %%capture !pip install svgling . from nltk.tree import Tree . The output from the default sentence for the Irish chunker. . sample1 = &quot;&quot;&quot; [S [V Rith ] [NP siad NP] [NP an rás NP] S] &quot;&quot;&quot; . buf = [] for tok in sample1.replace(&quot; n&quot;, &quot; &quot;).split(&quot; &quot;): if tok.endswith(&quot;]&quot;): buf.append(&quot;)&quot;) else: buf.append(tok.replace(&quot;[&quot;, &quot;(&quot;)) intree = &quot; &quot;.join(buf) newt = Tree.fromstring(intree) . newt . SVRithNPsiadNPanrás sample2 = &quot;&quot;&quot; [S [V Rith rith+Verb+VTI+PastInd+Len+@FMV ] [NP siad siad+Pron+Pers+3P+Pl+Sbj+@SUBJ NP] [NP an an+Art+Sg+Def+@&gt;N rás rás+Noun+Masc+Com+Sg+DefArt+@OBJ NP] S] &quot;&quot;&quot; . buf = [] last_word = &quot;&quot; for line in sample2.split(&quot; n&quot;): for tok in line.split(&quot; &quot;): if tok.startswith(&quot;[&quot;): buf.append(tok.replace(&quot;[&quot;, &quot;(&quot;)) elif tok.endswith(&quot;]&quot;): buf.append(&quot;)&quot;) elif &quot;+&quot; in tok: parts = tok.split(&quot;+&quot;) buf.append(&quot;(&quot; + parts[1]) buf.append(last_word) buf.append(&quot;)&quot;) last_word = &quot;&quot; else: last_word = tok . Tree.fromstring(&quot; &quot;.join(buf)) . SVVerbRithNPPronsiadNPArtanNounrás def fix_tree(tree_string): buf = [] last_word = &quot;&quot; for line in tree_string.split(&quot; n&quot;): for tok in line.split(&quot; &quot;): if tok.startswith(&quot;[&quot;): buf.append(tok.replace(&quot;[&quot;, &quot;(&quot;)) elif tok.endswith(&quot;]&quot;): buf.append(&quot;)&quot;) elif &quot;+&quot; in tok: parts = tok.split(&quot;+&quot;) buf.append(&quot;(&quot; + parts[1]) buf.append(last_word) buf.append(&quot;)&quot;) last_word = &quot;&quot; else: last_word = tok return &quot; &quot;.join(buf).replace(&quot;(S )&quot;, &quot;&quot;) . new_samp = &quot;&quot;&quot; [S [COP An is+Cop+Pres+Q+@COP_WH ] [PRED tusa tú+Pron+Pers+2P+Sg+Emph+@PRED ] [V a a+Part+Vb+Rel+Direct+@&gt;V chonaic feic+Verb+VTI+PastInd+Len+@FMV_REL ] [NP é é+Pron+Pers+3P+Sg+Masc+@OBJ NP] ? ?+Punct+Fin+Q+ S] [S S] &quot;&quot;&quot; . Tree.fromstring(fix_tree(new_samp)) . SCOPCopAnPREDProntusaVPartaVerbchonaicNPPronéPunct?",
            "url": "https://jimregan.github.io/notes/nltk/irish/parse%20trees/2022/10/03/irishnlp-chunker-with-nltk.html",
            "relUrl": "/nltk/irish/parse%20trees/2022/10/03/irishnlp-chunker-with-nltk.html",
            "date": " • Oct 3, 2022"
        }
        
    
  
    
        ,"post54": {
            "title": "Interesting links, 07/09/2022",
            "content": "Towards End-to-end Unsupervised Speech Recognition . @misc{https://doi.org/10.48550/arxiv.2204.02492, doi = {10.48550/ARXIV.2204.02492}, url = {https://arxiv.org/abs/2204.02492}, author = {Liu, Alexander H. and Hsu, Wei-Ning and Auli, Michael and Baevski, Alexei}, title = {Towards End-to-end Unsupervised Speech Recognition}, year = {2022}, } . Segmental Audio Word2Vec: Representing Utterances as Sequences of Vectors with Applications in Spoken Term Detection . @misc{https://doi.org/10.48550/arxiv.1808.02228, doi = {10.48550/ARXIV.1808.02228}, url = {https://arxiv.org/abs/1808.02228}, author = {Wang, Yu-Hsuan and Lee, Hung-yi and Lee, Lin-shan}, title = {Segmental Audio Word2Vec: Representing Utterances as Sequences of Vectors with Applications in Spoken Term Detection}, year = {2018}, } . zhenghuatan/rVADfast . SpeechT5: Unified-Modal Encoder-Decoder Pre-Training for Spoken Language Processing, microsoft/SpeechT5 . @misc{https://doi.org/10.48550/arxiv.2110.07205, doi = {10.48550/ARXIV.2110.07205}, url = {https://arxiv.org/abs/2110.07205}, author = {Ao, Junyi and Wang, Rui and Zhou, Long and Wang, Chengyi and Ren, Shuo and Wu, Yu and Liu, Shujie and Ko, Tom and Li, Qing and Zhang, Yu and Wei, Zhihua and Qian, Yao and Li, Jinyu and Wei, Furu}, title = {SpeechT5: Unified-Modal Encoder-Decoder Pre-Training for Spoken Language Processing}, year = {2021}, } . . How to load the pretrained models in pytorch . Multilingual and Multimodal Learning for Brazilian Portuguese . RoomReader: A Multimodal Corpus of Online Multiparty Conversational Interactions . Investigating Independence vs. Control: Agenda-Setting in Russian News Coverage on Social Media . Diachronic Parsing of Pre-Standard Irish . probabilisticai/probai-2022, videos . . Using AI to decode speech from brain activity . . add wav2vec2_alignment . Add fairseq FastSpeech2 . Add Emformer . data2vec-vision Onnx ready-made configuration . Add a TF in-graph tokenizer for BERT . add MobileNetV2 model . Adding Omnivore Model to HF . Layoutlmv2 tesseractconfig . pyannote/embedding . ASR chunking . . LITHME . CLARIN Annual Conference 2022 . . google/lyra — A Very Low-Bitrate Codec for Speech Compression . salesforce/awd-lstm-lm . MKD: a Multi-Task Knowledge Distillation Approach for Pretrained Language Models . Transflower: probabilistic autoregressive dance generation with multimodal attention, code . Pre-Training Transformer Decoder for End-to-End ASR Model with Unpaired Speech Data . An investigation of phone-based subword units for end-to-end speech recognition . Sequence-to-sequence learning with Transducers . Pushing the Limits of Semi-Supervised Learning for Automatic Speech Recognition . ONLINE ASR WITH EMFORMER RNN-T . We published Tuda german model from https://t.co/4xPzWgW6fwhttps://t.co/7mdkimirTjit is big (4.4G) and slightly more accurate than Vosk on audiobooks and well covers CV test9.48 (Tuda-de test), 25.82 (podcast) 4.97 (cv-test) 11.01 (mls) 35.20 (mtedx) . &mdash; AlphaCephei (@alphacep) August 10, 2022 code . Recordings Database . spaces/k2-fsa/automatic-speech-recognition . csukuangfj/optimized_transducer . Recurrent Neural Aligner: An Encoder-Decoder Neural Network Model for Sequence to Sequence Mapping . Integrating Lattice-Free MMI into End-to-End Speech Recognition . clarin-eric/parla-clarin . clarin-eric/ParlaMint . MASC-MEG . But what is the Fourier Transform? A visual introduction. . AudioLM: a Language Modeling Approach to Audio Generation . . Pre-Training Transformer Decoder for End-to-End ASR Model with Unpaired Speech Data . Layer-wise analysis of a self-supervised speech representation . . L2-ARCTIC .",
            "url": "https://jimregan.github.io/notes/links/2022/09/07/misc-links.html",
            "relUrl": "/links/2022/09/07/misc-links.html",
            "date": " • Sep 7, 2022"
        }
        
    
  
    
        ,"post55": {
            "title": "Interesting links, 13/07/2022",
            "content": "patrick-kidger/equinox — Callable PyTrees and filtered transforms =&gt; neural networks in JAX. . patrick-kidger/diffrax — Numerical differential equation solvers in JAX. Autodifferentiable and GPU-capable. . . M-Adapter: Modality Adaptation for End-to-End Speech-to-Text Translation . @misc{https://doi.org/10.48550/arxiv.2207.00952, doi = {10.48550/ARXIV.2207.00952}, url = {https://arxiv.org/abs/2207.00952}, author = {Zhao, Jinming and Yang, Hao and Shareghi, Ehsan and Haffari, Gholamreza}, title = {M-Adapter: Modality Adaptation for End-to-End Speech-to-Text Translation}, publisher = {arXiv}, year = {2022}, copyright = {arXiv.org perpetual, non-exclusive license} } . . Check out our latest breakthrough in machine translation that Mark Zuckerberg just announced. We built and open sourced a state-of-the-art AI model that now translates between 200 different languages. . &mdash; AI at Meta (@AIatMeta) July 6, 2022 Code is open source, model is not . . Trillson in transformers . . Emformer: Efficient Memory Transformer Based Acoustic Model for Low Latency Streaming Speech Recognition . @INPROCEEDINGS{9414560, author={Shi, Yangyang and Wang, Yongqiang and Wu, Chunyang and Yeh, Ching-Feng and Chan, Julian and Zhang, Frank and Le, Duc and Seltzer, Mike}, booktitle={ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, title={Emformer: Efficient Memory Transformer Based Acoustic Model for Low Latency Streaming Speech Recognition}, year={2021}, volume={}, number={}, pages={6783-6787}, doi={10.1109/ICASSP39728.2021.9414560}} . . lumaku/ctc-segmentation — Segment an audio file and obtain utterance alignments. . . This past week I spent some time learning about SentenceTransformers (https://t.co/5ZAV7lJq7u), and I&#39;m pretty blown away by what sentence embeddings can be used for.If you&#39;re curious to see what researchers have been getting up to with it, here&#39;s a 🧵 with some highlights: . &mdash; Nima Boscarino (@NimaBoscarino) June 10, 2022 . How much data do you need for a good MFA alignment? . If you care only about alignments of the training data, 3-5 hours should be enough. Caveat: increasing the number of speakers/varieties in the training data will likely need more training data | . | If you care about generating models for more widespread use, 8-10 should be enough for generalizing to the same variety The more speakers the better, but also more speakers should need more data | I usually recommend about 20 hours for a decently performant model | . | . . google-research/t5x — essentially a new and improved implementation of the T5 codebase (based on Mesh TensorFlow) in JAX and Flax. . google/seqio — Task-based datasets, preprocessing, and evaluation for sequence models. . . r/weirddalle . . Towards End-to-end Unsupervised Speech Recognition . @misc{https://doi.org/10.48550/arxiv.2204.02492, doi = {10.48550/ARXIV.2204.02492}, url = {https://arxiv.org/abs/2204.02492}, author = {Liu, Alexander H. and Hsu, Wei-Ning and Auli, Michael and Baevski, Alexei}, title = {Towards End-to-end Unsupervised Speech Recognition}, publisher = {arXiv}, year = {2022}, copyright = {Creative Commons Attribution 4.0 International} } . . Unified Speech-Text Pre-training for Speech Translation and Recognition . @misc{tang2022unified, title={Unified Speech-Text Pre-training for Speech Translation and Recognition}, author={Yun Tang and Hongyu Gong and Ning Dong and Changhan Wang and Wei-Ning Hsu and Jiatao Gu and Alexei Baevski and Xian Li and Abdelrahman Mohamed and Michael Auli and Juan Pino}, year={2022}, eprint={2204.05409}, archivePrefix={arXiv}, primaryClass={cs.CL} } . .",
            "url": "https://jimregan.github.io/notes/links/2022/07/13/misc-links.html",
            "relUrl": "/links/2022/07/13/misc-links.html",
            "date": " • Jul 13, 2022"
        }
        
    
  
    
        ,"post56": {
            "title": "WER calculations for minute and hour splits",
            "content": "import matplotlib.pyplot as plt import pandas as pd . HOURS_DATA = &quot;&quot;&quot; 2 0.02571327932370553 4 0.014705882352941176 6 0.01655512504402959 8 0.014705882352941176 10 0.013825290595280029 12 0.012152166255723846 14 0.011271574498062698 16 0.010302923564635434 &quot;&quot;&quot; . hours = [] wer = [] for line in HOURS_DATA.split(&quot; n&quot;): if &quot; t&quot; in line: parts = line.split(&quot; t&quot;) hours.append(int(parts[0])) wer.append(float(parts[1]) * 100) . df = pd.DataFrame(data={&quot;Hours&quot;: hours, &quot;WER&quot;: wer}) . ax = plt.gca() df.plot(kind=&#39;line&#39;,x=&#39;Hours&#39;,y=&#39;WER&#39;,ax=ax) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fc7ef72add0&gt; . MINS_DATA = &quot;&quot;&quot; 5 0.05336386051426559 10 0.05309968298696724 15 0.05301162381120113 20 0.03346248679112364 25 0.03355054596688975 30 0.03355054596688975 35 0.03222965833039803 40 0.03126100739697076 45 0.03196548080309968 50 0.028883409651285663 55 0.029059528002817893 60 0.028531172948221203 65 0.02694610778443114 70 0.029411764705882353 75 0.02588939767523776 80 0.027738640366326173 85 0.026681930257132794 90 0.025977456851003874 95 0.02386403663261712 100 0.02536104262064107 105 0.025096865093342725 110 0.02588939767523776 115 0.02712222613596337 120 0.02571327932370553 &quot;&quot;&quot; . df . Hours WER . 0 2 | 2.571328 | . 1 4 | 1.470588 | . 2 6 | 1.655513 | . 3 8 | 1.470588 | . 4 10 | 1.382529 | . 5 12 | 1.215217 | . 6 14 | 1.127157 | . 7 16 | 1.030292 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; mins = [] wer = [] for line in MINS_DATA.split(&quot; n&quot;): if &quot; t&quot; in line: parts = line.split(&quot; t&quot;) mins.append(int(parts[0])) wer.append(float(parts[1]) * 100) . pd.options.display.float_format = &#39;{:,.2f}&#39;.format df = pd.DataFrame(data={&quot;Minutes&quot;: mins, &quot;WER&quot;: wer}) . df . Minutes WER . 0 5 | 5.34 | . 1 10 | 5.31 | . 2 15 | 5.30 | . 3 20 | 3.35 | . 4 25 | 3.36 | . 5 30 | 3.36 | . 6 35 | 3.22 | . 7 40 | 3.13 | . 8 45 | 3.20 | . 9 50 | 2.89 | . 10 55 | 2.91 | . 11 60 | 2.85 | . 12 65 | 2.69 | . 13 70 | 2.94 | . 14 75 | 2.59 | . 15 80 | 2.77 | . 16 85 | 2.67 | . 17 90 | 2.60 | . 18 95 | 2.39 | . 19 100 | 2.54 | . 20 105 | 2.51 | . 21 110 | 2.59 | . 22 115 | 2.71 | . 23 120 | 2.57 | . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; import numpy as np ax = plt.gca() ax.set_xticks(np.arange(5, 125, 5)) ax.set_xticklabels(labels=mins, minor=True) df.plot(kind=&#39;line&#39;, x=&#39;Minutes&#39;, y=&#39;WER&#39;, ax=ax, figsize=(12.8, 4.8)) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f400bffbdd0&gt; . MINS_DATA = &quot;&quot;&quot; 5 0.05336386051426559 10 0.05309968298696724 15 0.05301162381120113 20 0.03346248679112364 25 0.03355054596688975 30 0.03355054596688975 &quot;&quot;&quot; MINS2 = &quot;&quot;&quot; 5 4.11 10 4.08 15 3.72 20 3.49 25 3.43 30 3.34 &quot;&quot;&quot; . mins = [] wer = [] for line in MINS_DATA.split(&quot; n&quot;): if &quot; t&quot; in line: parts = line.split(&quot; t&quot;) mins.append(int(parts[0])) wer.append(float(parts[1]) * 100) . mins2 = [] wer2 = [] for line in MINS2.split(&quot; n&quot;): if &quot; t&quot; in line: parts = line.split(&quot; t&quot;) mins2.append(int(parts[0])) wer2.append(float(parts[1])) . len(mins) . 12 . fig, ax = plt.subplots() ax.plot(mins, wer) ax.plot(mins, wer2) newx = ax.lines[0].get_ydata() newy = ax.lines[0].get_xdata() # set new x- and y- data for the line ax.lines[0].set_xdata(newx) ax.lines[0].set_ydata(newy) newx = ax.lines[1].get_ydata() newy = ax.lines[1].get_xdata() # set new x- and y- data for the line ax.lines[1].set_xdata(newx) ax.lines[1].set_ydata(newy) ax.set_xlim([0, 10]) ax.set_ylim([0, 10]) . (0.0, 10.0) . import numpy as np import pandas as pd ax = plt.gca() df = pd.DataFrame(data={&quot;300&quot;: wer, &quot;1000&quot;: wer2}, index=mins) . [&lt;matplotlib.lines.Line2D at 0x7f8728e72210&gt;] .",
            "url": "https://jimregan.github.io/notes/wer/adaptation/2022/05/07/speaker-adaptation-wer-hours-minutes.html",
            "relUrl": "/wer/adaptation/2022/05/07/speaker-adaptation-wer-hours-minutes.html",
            "date": " • May 7, 2022"
        }
        
    
  
    
        ,"post57": {
            "title": "Adapt `cmu_us_awb_arctic` to fairseq",
            "content": "RAWTEXT = &quot;../input/cmu-us-awb-arctic-tts-dataset/cmu_us_awb_arctic/etc/txt.done.data&quot; . NORMS = { &quot;0.75&quot;: &quot;zero point seven five&quot;, &quot;t.h&quot;: &quot;t h&quot;, &quot;1880&quot;: &quot;eighteen eighty&quot;, &quot;16&quot;: &quot;sixteenth&quot;, &quot;1908&quot;: &quot;nineteen oh eight&quot;, &quot;18&quot;: &quot;eighteenth&quot;, &quot;17&quot;: &quot;seventeenth&quot;, &quot;29th&quot;: &quot;twenty ninth&quot;, &quot;mrs&quot;: &quot;misses&quot;, &quot;etc&quot;: &quot;etcetera&quot;, &quot;etc.&quot;: &quot;etcetera&quot;, &quot;to-day&quot;: &quot;today&quot;, &quot;to-day&#39;s&quot;: &quot;today&#39;s&quot;, &quot;to-morrow&quot;: &quot;tomorrow&quot; } . def _check_apos(word): if word.endswith(&quot;&#39;s&quot;): return word elif word.endswith(&quot;s&#39;&quot;): return word elif word.endswith(&quot;&#39;d&quot;): return word elif word.endswith(&quot;&#39;ve&quot;): return word elif word.endswith(&quot;&#39;re&quot;): return word elif word.endswith(&quot;&#39;ll&quot;): return word elif word.endswith(&quot;n&#39;t&quot;): return word elif word.endswith(&quot;&#39;ve&quot;): return word elif word in [&quot;i&#39;m&quot;, &quot;&#39;em&quot;, &quot;o&#39;brien&quot;]: return word else: return word.replace(&quot;&#39;&quot;, &quot;&quot;) def fix_apos(text): words = [_check_apos(w) for w in text.split(&quot; &quot;)] return &quot; &quot;.join(words) . def normalise(text): if text[-1] == &quot;.&quot;: text = text[:-1] text = text.lower() words = [] text = text.replace(&quot;,&quot;, &quot;&quot;) for word in text.split(&quot; &quot;): if word in NORMS: words.append(NORMS[word]) else: words.append(word) text = &quot; &quot;.join(words) text = text.replace(&quot;.&quot;, &quot;&quot;) text = text.replace(&quot;?&quot;, &quot;&quot;) text = text.replace(&quot;!&quot;, &quot;&quot;) text = text.replace(&quot;:&quot;, &quot;&quot;) text = text.replace(&quot;;&quot;, &quot;&quot;) text = text.replace(&quot;--&quot;, &quot; &quot;) text = text.replace(&quot; &quot;, &quot; &quot;) text = text.replace(&quot; - &quot;, &quot; &quot;) text = text.replace(&quot;to- morrow&quot;, &quot;tomorrow&quot;) text = fix_apos(text) text = text.replace(&quot;-&quot;, &quot; &quot;) return text.strip().upper() . data = {} with open(RAWTEXT) as inf: for line in inf.readlines(): first_space = line.find(&#39; &#39;) first_quote = line.find(&#39;&quot;&#39;) last_quote = line.rfind(&#39;&quot;&#39;) id = line[first_space+1:first_quote].strip() text = line[first_quote+1:last_quote] data[id] = normalise(text) . with open(&quot;text.tsv&quot;, &quot;w&quot;) as of: for id in data.keys(): of.write(f&quot;{id} t{data[id]} n&quot;) . from pathlib import Path import soundfile as sf total = 0 WAVPATH = Path(&quot;../input/cmu-us-awb-arctic-tts-dataset/cmu_us_awb_arctic/wav/&quot;) with open(&quot;frames.tsv&quot;, &quot;w&quot;) as of: for wav in WAVPATH.glob(&quot;*.wav&quot;): frames, sr = sf.read(str(wav)) assert sr == 16000 total += len(frames) of.write(f&quot;{wav.stem}.wav t{len(frames)} n&quot;) print(&quot;Total:&quot;, total / 16000) . Total: 4777.0 . lines=!wc -l frames.tsv|awk &#39;{print $1}&#39; !tail -n 114 frames.tsv |head -n 57 &gt; test.tsv !tail -n 114 frames.tsv |tail -n 57 &gt; dev.tsv !head -n $((1138-114)) frames.tsv &gt; train.tsv . def do_fairseq(text): words = text.split(&quot; &quot;) owords = [&quot; &quot;.join(w) for w in words] return &quot; | &quot;.join(owords) + &quot; |&quot; . for part in [&quot;test&quot;, &quot;train&quot;, &quot;dev&quot;]: ids = [] with open(f&quot;{part}.ltr&quot;, &quot;w&quot;) as of, open(f&quot;{part}.tsv&quot;) as inf: for line in inf.readlines(): if &quot; t&quot; in line: parts = line.strip().split(&quot; t&quot;) id = parts[0].replace(&quot;.wav&quot;, &quot;&quot;) of.write(do_fairseq(data[id]) + &quot; n&quot;) .",
            "url": "https://jimregan.github.io/notes/kaggle/awb/2022/05/07/cmu-us-awb-arctic-fairseq-files.html",
            "relUrl": "/kaggle/awb/2022/05/07/cmu-us-awb-arctic-fairseq-files.html",
            "date": " • May 7, 2022"
        }
        
    
  
    
        ,"post58": {
            "title": "Create LJSpeech splits",
            "content": "Split into train/test/valid . !echo /kaggle/input/ljspeech-for-asr/wav16/ &gt; valid.tsv !cat ../input/ljspeech-for-asr/frames.tsv | tail -n $((1310)) | tail -n $((1310 / 2)) |awk -F&#39; t&#39; &#39;{print $1 &quot;.wav t&quot; $2}&#39; &gt;&gt; valid.tsv . !echo /kaggle/input/ljspeech-for-asr/wav16/ &gt; test.tsv !cat ../input/ljspeech-for-asr/frames.tsv | tail -n $((1310)) | head -n $((1310 / 2)) |awk -F&#39; t&#39; &#39;{print $1 &quot;.wav t&quot; $2}&#39; &gt;&gt; test.tsv . !echo /kaggle/input/ljspeech-for-asr/wav16/ &gt; train.tsv !cat ../input/ljspeech-for-asr/frames.tsv | head -n $((13100 - 1310)) |awk -F&#39; t&#39; &#39;{print $1 &quot;.wav t&quot; $2}&#39; &gt;&gt; train.tsv . Load frame lengths . train_frames = {} with open(&quot;train.tsv&quot;) as f: for line in f.readlines(): if not &quot; t&quot; in line: continue pieces = line.strip().split(&quot; t&quot;) assert len(pieces) == 2 id = pieces[0].replace(&quot;.wav&quot;, &quot;&quot;) train_frames[id] = int(pieces[1]) . MINS = [i * 5 for i in range(1, 25)] HOURS = [i * 2 for i in range(1, 9)] . WAVDIR = &quot;/kaggle/input/ljspeech-for-asr/wav16&quot; . Minute splits . for min in MINS: frames = min * 60 * 16000 idlist = [k for k in train_frames.keys()] outtsv = f&quot;{min}mins.tsv&quot; with open(outtsv, &quot;w&quot;) as of: current = 0 of.write(f&quot;{WAVDIR} n&quot;) while frames &gt; 0 and frames &gt; current: id = idlist.pop(0) current = train_frames[id] of.write(f&quot;{id}.wav t{current} n&quot;) frames = frames - current max = 0 maxid = &quot;&quot; for id in idlist: time = train_frames[id] if time &gt; current: continue if time &gt; max: max = time maxid = id of.write(f&quot;{maxid}.wav t{max} n&quot;) . Hour splits . for min in HOURS: frames = min * 60 * 60 * 16000 idlist = [k for k in train_frames.keys()] outtsv = f&quot;{min}hrs.tsv&quot; with open(outtsv, &quot;w&quot;) as of: current = 0 of.write(f&quot;{WAVDIR} n&quot;) while frames &gt; 0 and frames &gt; current: id = idlist.pop(0) current = train_frames[id] of.write(f&quot;{id}.wav t{current} n&quot;) frames = frames - current max = 0 maxid = &quot;&quot; for id in idlist: time = train_frames[id] if time &gt; current: continue if time &gt; max: max = time maxid = id of.write(f&quot;{maxid}.wav t{max} n&quot;) . Generate ltr files . def fairseqify(text): text = text.strip().replace(&quot; &quot;, &quot; &quot;) words = text.split(&quot; &quot;) spread = [&quot; &quot;.join(a) for a in words] return &quot; | &quot;.join(spread) + &quot; |&quot; . transcripts = {} with open(&quot;../input/ljspeech-for-asr/transcripts.tsv&quot;) as tf: for line in tf.readlines(): line = line.strip() if not &quot; t&quot; in line: pass parts = line.split(&quot; t&quot;) assert len(parts) == 2 transcripts[parts[0]] = fairseqify(parts[1]) . import glob for tsv in glob.glob(&quot;*.tsv&quot;): out = tsv.replace(&quot;.tsv&quot;, &quot;.ltr&quot;) with open(tsv) as inf, open(out, &quot;w&quot;) as outf: for line in inf.readlines()[1:]: id, _ = line.split(&quot; t&quot;) id = id.replace(&quot;.wav&quot;, &quot;&quot;) outf.write(f&quot;{transcripts[id]} n&quot;) . Tidy up . !for i in *mins.tsv;do b=$(basename $i &quot;.tsv&quot;);mkdir $b; mv $b.tsv $b/train.tsv; mv $b.ltr $b/train.ltr; cp test.* valid.* $b/;done !for i in *hrs.tsv;do b=$(basename $i &quot;.tsv&quot;);mkdir $b; mv $b.tsv $b/train.tsv; mv $b.ltr $b/train.ltr; cp test.* valid.* $b/;done .",
            "url": "https://jimregan.github.io/notes/kaggle/ljspeech/2022/05/05/create-ljspeech-splits.html",
            "relUrl": "/kaggle/ljspeech/2022/05/05/create-ljspeech-splits.html",
            "date": " • May 5, 2022"
        }
        
    
  
    
        ,"post59": {
            "title": "LJSpeech for ASR",
            "content": "Step 1: Convert sampling rate to 16,000 . !mkdir wav16 . %%capture !for wav in ../input/the-lj-speech-dataset/LJSpeech-1.1/wavs/*wav; do ffmpeg -i $wav -ar 16000 wav16/$(basename $wav &#39;.wav&#39;).wav;done . Step 2: (Further) normalise the transcripts . PATH = &quot;../input/the-lj-speech-dataset/LJSpeech-1.1/metadata.csv&quot; . def fix_text(text): text = text.lower() text = text.replace(&quot; -- &quot;, &quot; &quot;) text = text.replace(&quot;ü&quot;, &quot;u&quot;) text = text.replace(&quot;etc.&quot;, &quot;etcetera&quot;) text = text.replace(&quot;i.e.&quot;, &quot;i e &quot;) text = text.replace(&quot;;&quot;, &quot;&quot;) text = text.replace(&quot;. &quot;, &quot; &quot;) text = text.replace(&quot;,&quot;, &quot;&quot;) text = text.replace(&quot; &quot;&quot;, &quot;&quot;) text = text.replace(&quot; &quot;, &quot; &quot;) alpha = &quot;abcdefghijklmnopqrstuvwxyz&quot; i = 0 buf = [] while i &lt; len(text): if text[i] in alpha or text[i] == &quot; &quot;: buf.append(text[i]) elif text[i:i+2] == &quot;&#39;s&quot; or text[i-1:i+2] == &quot;s&#39; &quot;: buf.append(text[i]) elif i == len(text)-1 and text[-2:] == &quot;s&#39;&quot;: buf.append(text[i]) elif text[i:i+2] == &quot;&#39;d&quot; or text[i:i+3] == &quot;&#39;ve&quot;: buf.append(text[i]) elif text[i] == &quot;-&quot; and text[i-1] in alpha: buf.append(&quot; &quot;) else: pass i += 1 text = &quot;&quot;.join(buf) return text . items = {} with open(PATH) as f: for line in f.readlines(): arr = line.split(&quot;|&quot;) if len(arr) != 3: print(line) id = arr[0] text = fix_text(arr[2]) items[id] = text . OUTPATH = &quot;transcripts.tsv&quot; with open(OUTPATH, &quot;w&quot;) as outf: for key in items.keys(): outf.write(f&quot;{key} t{items[key]} n&quot;) . Step 3: Extract number of frames . This is needed by fairseq . from pathlib import Path import soundfile as sf . WAVPATH = Path(&quot;wav16&quot;) . times = {} for wavfile in WAVPATH.glob(&quot;*.wav&quot;): data, sr = sf.read(str(wavfile)) times[wavfile.stem] = len(data) . with open(&quot;frames.tsv&quot;, &quot;w&quot;) as framef: for key in times.keys(): framef.write(f&quot;{key} t{times[key]} n&quot;) .",
            "url": "https://jimregan.github.io/notes/kaggle/ljspeech/2022/05/04/ljspeech-for-asr.html",
            "relUrl": "/kaggle/ljspeech/2022/05/04/ljspeech-for-asr.html",
            "date": " • May 4, 2022"
        }
        
    
  
    
        ,"post60": {
            "title": "Split Liepa2",
            "content": "DATAPATH = &quot;/mnt/cloud/lithuanian-asr/data&quot; . !pip install pympi-ling . Collecting pympi-ling Downloading pympi_ling-1.70.2-py2.py3-none-any.whl (24 kB) Installing collected packages: pympi-ling Successfully installed pympi-ling-1.70.2 . import pympi from pathlib import Path from pydub import AudioSegment . def get_eaf_data(filename): filepath = Path(filename) base = filepath.stem eaf = pympi.Elan.Eaf(filename) tiers = [] def is_simple_layout(tiers): if len(tiers) == 1 and &#39;speech&#39; in tiers: return True elif len(tiers) == 2 and &#39;speech&#39; in tiers and &#39;noise&#39; in tiers: return True elif len(tiers) == 3 and &#39;speech&#39; in tiers and &#39;noise&#39; in tiers and &#39;ss&#39; in tiers: return True else: return False if is_simple_layout(eaf.tiers): tiernames = [&#39;speech&#39;] simple = True else: skip = [&#39;noise&#39;, &#39;ss&#39;] tiernames = [a for a in eaf.tiers.keys() if a not in skip] simple = False for tiername in tiernames: for tier in eaf.tiers[tiername][0].keys(): current = {} id = f&quot;{base}_{tier}&quot; if not simple: id = f&quot;{base}_{tiername}_{tier}&quot; current[&quot;id&quot;] = id data = eaf.tiers[tiername][0][tier] current[&quot;start&quot;] = eaf.timeslots[data[0]] current[&quot;end&quot;] = eaf.timeslots[data[1]] current[&quot;text&quot;] = data[2].replace(&quot; t&quot;, &quot; &quot;).replace(&quot; n&quot;, &quot; &quot;).strip() if current[&quot;text&quot;] != &quot;&quot;: tiers.append(current) return tiers . def write_split_wavs(outdir, filename, data): outpath = Path(outdir) original = AudioSegment.from_wav(filename) for piece in data: outfile = outpath / f&quot;{piece[&#39;id&#39;]}.wav&quot; audio = original[piece[&quot;start&quot;]:piece[&quot;end&quot;]] audio.export(str(outfile), format=&quot;wav&quot;) . def append_to_tsv(tsv_file, data): with open(tsv_file, &quot;a&quot;) as f: for item in data: f.write(f&quot;{item[&#39;id&#39;]} t{item[&#39;text&#39;]} n&quot;) . SAMPLE = &quot;/mnt/cloud/lithuanian-asr/data/R_RS_F3_AS113_01.eaf&quot; SAMPLE_WAV = SAMPLE.replace(&quot;.eaf&quot;, &quot;.wav&quot;) data = get_eaf_data(SAMPLE) write_split_wavs(&quot;/tmp/foo&quot;, SAMPLE_WAV, data) . for eaf_file in Path(DATAPATH).glob(&quot;*.eaf&quot;): data = get_eaf_data(eaf_file) wav_file = str(eaf_file).replace(&quot;.eaf&quot;, &quot;.wav&quot;) write_split_wavs(&quot;/mnt/cloud/liepa-split&quot;, wav_file, data) append_to_tsv(&quot;/mnt/cloud/liepa-split/text.tsv&quot;, data) .",
            "url": "https://jimregan.github.io/notes/liepa/lithuanian/asr/corpus/elan/eaf/2022/05/04/liepa2-split.html",
            "relUrl": "/liepa/lithuanian/asr/corpus/elan/eaf/2022/05/04/liepa2-split.html",
            "date": " • May 4, 2022"
        }
        
    
  
    
        ,"post61": {
            "title": "Convert Waxholm to wav",
            "content": "%%capture !sudo apt-get install git-lfs . !git lfs install . Error: Failed to call git rev-parse --git-dir: exit status 128 Git LFS initialized. . !git clone https://huggingface.co/datasets/KTH/waxholm . Cloning into &#39;waxholm&#39;... remote: Enumerating objects: 7501, done. remote: Counting objects: 100% (7501/7501), done. remote: Compressing objects: 100% (7422/7422), done. remote: Total 7501 (delta 84), reused 7487 (delta 77), pack-reused 0 Receiving objects: 100% (7501/7501), 207.52 MiB | 24.12 MiB/s, done. Resolving deltas: 100% (84/84), done. Updating files: 100% (7334/7334), done. Filtering content: 100% (2522/2522), 282.66 MiB | 1.39 MiB/s, done. . !mkdir wav . import soundfile as sf def smp_headers(filename: str): with open(filename, &quot;rb&quot;) as f: f.seek(0) raw_headers = f.read(1024) raw_headers = raw_headers.rstrip(b&#39; x00&#39;) asc_headers = raw_headers.decode(&quot;ascii&quot;) asc_headers.rstrip(&#39; x00&#39;) tmp = [a for a in asc_headers.split(&quot; r n&quot;)] back = -1 while abs(back) &gt; len(tmp) + 1: if tmp[back] == &#39;=&#39;: break back -= 1 tmp = tmp[0:back-1] return dict(a.split(&quot;=&quot;) for a in tmp) def smp_read_sf(filename: str): headers = smp_headers(filename) if headers[&quot;msb&quot;] == &quot;last&quot;: ENDIAN = &quot;LITTLE&quot; else: ENDIAN = &quot;BIG&quot; data, sr = sf.read(filename, channels=int(headers[&quot;nchans&quot;]), samplerate=16000, endian=ENDIAN, start=512, dtype=&quot;int16&quot;, format=&quot;RAW&quot;, subtype=&quot;PCM_16&quot;) return (data, sr) def write_wav(filename, arr): import wave with wave.open(filename, &quot;w&quot;) as f: f.setnchannels(1) f.setsampwidth(2) f.setframerate(16000) f.writeframes(arr) . from pathlib import Path for smp in Path(&quot;./waxholm/scenes_formatted&quot;).glob(&quot;**/*.smp&quot;): arr, sr = smp_read_sf(str(smp)) write_wav(f&quot;wav/{smp.stem}.wav&quot;, arr) . import IPython.display as ipd ipd.Audio(&#39;wav/fp2001.1.00.wav&#39;) . Your browser does not support the audio element.",
            "url": "https://jimregan.github.io/notes/kaggle/waxholm/2022/05/04/convert-waxholm-to-wav.html",
            "relUrl": "/kaggle/waxholm/2022/05/04/convert-waxholm-to-wav.html",
            "date": " • May 4, 2022"
        }
        
    
  
    
        ,"post62": {
            "title": "Interesting links, 02/05/2022",
            "content": "Wavelet Browser — from PyWavelets . Identity Vector Extraction by Perceptual Wavelet Packet Entropy and Convolutional Neural Network for Voice Authentication . @Article{e20080600, AUTHOR = {Lei, Lei and She, Kun}, TITLE = {Identity Vector Extraction by Perceptual Wavelet Packet Entropy and Convolutional Neural Network for Voice Authentication}, JOURNAL = {Entropy}, VOLUME = {20}, YEAR = {2018}, NUMBER = {8}, ARTICLE-NUMBER = {600}, URL = {https://www.mdpi.com/1099-4300/20/8/600}, ISSN = {1099-4300}, DOI = {10.3390/e20080600} } . Speaker Recognition Using Wavelet Packet Entropy, I-Vector, and Cosine Distance Scoring . @Article{Lei2017, author={Lei, Lei and Kun, She}, title={Speaker Recognition Using Wavelet Packet Entropy, I-Vector, and Cosine Distance Scoring}, journal={Journal of Electrical and Computer Engineering}, year={2017}, month={May}, day={14}, publisher={Hindawi}, volume={2017}, pages={1735698}, issn={2090-0147}, doi={10.1155/2017/1735698}, } . Fairseq wav2vec2 hydra migration .",
            "url": "https://jimregan.github.io/notes/links/2022/05/02/misc-links.html",
            "relUrl": "/links/2022/05/02/misc-links.html",
            "date": " • May 2, 2022"
        }
        
    
  
    
        ,"post63": {
            "title": "Fix LJSpeech text",
            "content": "Updated here . PATH = &quot;/home/joregan/ljspeech/LJSpeech-1.1/metadata.csv&quot; . def fix_text(text): text = text.lower() text = text.replace(&quot; -- &quot;, &quot; &quot;) text = text.replace(&quot;ü&quot;, &quot;u&quot;) text = text.replace(&quot;etc.&quot;, &quot;etcetera&quot;) text = text.replace(&quot;i.e.&quot;, &quot;i e &quot;) text = text.replace(&quot;;&quot;, &quot;&quot;) text = text.replace(&quot;. &quot;, &quot; &quot;) text = text.replace(&quot;,&quot;, &quot;&quot;) text = text.replace(&quot; &quot;&quot;, &quot;&quot;) text = text.replace(&quot; &quot;, &quot; &quot;) alpha = &quot;abcdefghijklmnopqrstuvwxyz&quot; i = 0 buf = [] while i &lt; len(text): if text[i] in alpha or text[i] == &quot; &quot;: buf.append(text[i]) elif text[i:i+2] == &quot;&#39;s&quot; or text[i-1:i+2] == &quot;s&#39; &quot;: buf.append(text[i]) elif i == len(text)-1 and text[-2:] == &quot;s&#39;&quot;: buf.append(text[i]) elif text[i:i+2] == &quot;&#39;d&quot; or text[i:i+3] == &quot;&#39;ve&quot;: buf.append(text[i]) elif text[i] == &quot;-&quot; and text[i-1] in alpha: buf.append(&quot; &quot;) else: pass i += 1 text = &quot;&quot;.join(buf) return text . items = {} with open(PATH) as f: for line in f.readlines(): arr = line.split(&quot;|&quot;) if len(arr) != 3: print(line) id = arr[0] text = fix_text(arr[2]) items[id] = text . OUTPATH = &quot;/home/joregan/ljspeech/LJSpeech-1.1/text.tsv&quot; with open(OUTPATH, &quot;w&quot;) as outf: for key in items.keys(): outf.write(f&quot;{key} t{items[key]} n&quot;) .",
            "url": "https://jimregan.github.io/notes/ljspeech/2022/05/02/fix-ljspeech.html",
            "relUrl": "/ljspeech/2022/05/02/fix-ljspeech.html",
            "date": " • May 2, 2022"
        }
        
    
  
    
        ,"post64": {
            "title": "Recreating PSST challenge parameters in YAML",
            "content": "The following cell is an attempt to recreate the parameters for the PSST challenge in YAML. . common: fp16: true log_format: json log_interval: 50 checkpoint: no_epoch_checkpoints: true best_checkpoint_metric: uer task: _name: audio_finetuning data: ??? max_sample_size: 1120000 normalize: false labels: ltr dataset: num_workers: 1 max_tokens: 1120000 skip_invalid_size_inputs_valid_test: true validate_after_updates: 1000 validate_interval: 1 valid_subset: valid distributed_training: ddp_backend: no_c10d distributed_world_size: 1 criterion: _name: ctc zero_infinity: true optimization: max_update: 12000 lr: [0.00005] sentence_avg: true weight_decay: 0.0 update_freq: [] optimizer: _name: adam adam_betas: (0.9,0.98) adam_eps: 1e-08 lr_scheduler: _name: tri_stage phase_ratio: [0.33, 0.33, 0.33] final_lr_scale: 0.05 model: _name: wav2vec_ctc w2v_path: ??? apply_mask: true mask_prob: 0.65 mask_channel_prob: 0.25 mask_channel_length: 64 layerdrop: 0.1 activation_dropout: 0.1 feature_grad_mult: 0.0 freeze_finetune_updates: 0 final_dropout: 0.1 attention_dropout: 0.1 . This cell is a modification of base_10m.yaml from the fairseq source . # @package _group_ common: fp16: true log_format: json log_interval: 50 checkpoint: save_interval: 1000 save_interval_updates: 50 keep_interval_updates: 1 no_epoch_checkpoints: true best_checkpoint_metric: uer task: _name: audio_pretraining data: ??? max_sample_size: 1120000 normalize: false labels: ltr dataset: num_workers: 1 max_tokens: 1120000 skip_invalid_size_inputs_valid_test: true validate_after_updates: 1000 validate_interval: 1 valid_subset: valid distributed_training: ddp_backend: no_c10d distributed_world_size: 1 criterion: _name: ctc zero_infinity: true optimization: max_update: 12000 lr: [0.00005] sentence_avg: true update_freq: [4] optimizer: _name: adam adam_betas: (0.9,0.98) adam_eps: 1e-08 lr_scheduler: _name: tri_stage phase_ratio: [0.1, 0.4, 0.5] final_lr_scale: 0.05 model: _name: wav2vec_ctc w2v_path: ??? apply_mask: true mask_prob: 0.65 mask_channel_prob: 0.25 mask_channel_length: 64 layerdrop: 0.1 activation_dropout: 0.1 feature_grad_mult: 0.0 final_dropout: 0.1 attention_dropout: 0.1 freeze_finetune_updates: 0 .",
            "url": "https://jimregan.github.io/notes/fairseq/psst/yaml/2022/05/02/fairseq-config.html",
            "relUrl": "/fairseq/psst/yaml/2022/05/02/fairseq-config.html",
            "date": " • May 2, 2022"
        }
        
    
  
    
        ,"post65": {
            "title": "Hyphenisation with pyphen",
            "content": "!pip install pyphen . Collecting pyphen Downloading pyphen-0.12.0-py3-none-any.whl (2.0 MB) |████████████████████████████████| 2.0 MB 3.8 MB/s Installing collected packages: pyphen Successfully installed pyphen-0.12.0 . import pyphen . &#39;sv&#39; in pyphen.LANGUAGES . True . dic = pyphen.Pyphen(lang=&#39;sv&#39;) . dic.inserted(&quot;internetbaserad&quot;).replace(&quot;-&quot;, &quot; &quot;) . &#39;in ter net ba se rad&#39; .",
            "url": "https://jimregan.github.io/notes/pyphen/hyphenisation/snippet/2022/04/26/pyphen-sv.html",
            "relUrl": "/pyphen/hyphenisation/snippet/2022/04/26/pyphen-sv.html",
            "date": " • Apr 26, 2022"
        }
        
    
  
    
        ,"post66": {
            "title": "Instaloader to ntriples",
            "content": "import lzma . from pathlib import Path BASE = Path(&quot;/Users/joregan/Playing/instascr&quot;) . import json . from datetime import datetime datestr = datetime.today().strftime(&#39;%Y%m%d&#39;) . print(data[&#39;node&#39;].keys()) . dict_keys([&#39;__typename&#39;, &#39;id&#39;, &#39;gating_info&#39;, &#39;fact_check_overall_rating&#39;, &#39;fact_check_information&#39;, &#39;media_overlay_info&#39;, &#39;sensitivity_friction_info&#39;, &#39;sharing_friction_info&#39;, &#39;dimensions&#39;, &#39;display_url&#39;, &#39;display_resources&#39;, &#39;is_video&#39;, &#39;media_preview&#39;, &#39;tracking_token&#39;, &#39;edge_media_to_tagged_user&#39;, &#39;accessibility_caption&#39;, &#39;edge_media_to_caption&#39;, &#39;shortcode&#39;, &#39;edge_media_to_comment&#39;, &#39;edge_media_to_sponsor_user&#39;, &#39;comments_disabled&#39;, &#39;taken_at_timestamp&#39;, &#39;edge_media_preview_like&#39;, &#39;owner&#39;, &#39;location&#39;, &#39;viewer_has_liked&#39;, &#39;viewer_has_saved&#39;, &#39;viewer_has_saved_to_collection&#39;, &#39;viewer_in_photo_of_you&#39;, &#39;viewer_can_reshare&#39;, &#39;thumbnail_src&#39;, &#39;thumbnail_resources&#39;, &#39;edge_sidecar_to_children&#39;]) . testf = &#39;/Users/joregan/Playing/instascr/mollyryanxo/2020-06-06_20-36-58_UTC.json.xz&#39; jsons = lzma.open(testf).read().decode(&#39;utf-8&#39;) data = json.loads(jsons) username = data[&#39;node&#39;][&#39;owner&#39;][&#39;username&#39;] #for edge in data[&#39;node&#39;][&#39;edge_sidecar_to_children&#39;][&#39;edges&#39;]: # if &#39;video_url&#39; in edge[&#39;node&#39;]: # print(edge[&#39;node&#39;][&#39;video_url&#39;]) . def get_from_data(data): urls = set() if &#39;node&#39; not in data: print(f&quot;Error reading file&quot;) if &#39;edge_sidecar_to_children&#39; in data[&#39;node&#39;]: for edge in data[&#39;node&#39;][&#39;edge_sidecar_to_children&#39;][&#39;edges&#39;]: urls.add(edge[&#39;node&#39;][&#39;display_url&#39;]) if &#39;video_url&#39; in data[&#39;node&#39;]: urls.add(data[&#39;node&#39;][&#39;video_url&#39;]) urls.add(data[&#39;node&#39;][&#39;display_url&#39;]) if &#39;video_url&#39; in data[&#39;node&#39;]: urls.add(data[&#39;node&#39;][&#39;video_url&#39;]) return list(urls) . get_from_data(data) . datestr = &quot;20220417&quot; . from pathlib import Path BASE = Path(&quot;/Users/joregan/Playing/instascr&quot;) . with open(f&quot;/Users/joregan/Playing/400bcacf78036990182af6bbd7e41a71/instascrape-{datestr}.nt&quot;, &quot;w&quot;) as outf: for xzfile in BASE.glob(&quot;**/*.xz&quot;): jsons = lzma.open(xzfile).read().decode(&#39;utf-8&#39;) data = json.loads(jsons) if not &#39;owner&#39; in data[&#39;node&#39;]: print(f&quot;Skipping {str(xzfile)}&quot;) continue if not &#39;shortcode&#39; in data[&#39;node&#39;]: print(f&quot;Missing shortcode: {str(xzfile)}&quot;) continue username = data[&#39;node&#39;][&#39;owner&#39;][&#39;username&#39;] short = data[&#39;node&#39;][&#39;shortcode&#39;] urls = get_from_data(data) for url in urls: outf.write(f&quot;&lt;{url}&gt; &lt;http://xmlns.com/foaf/0.1/page&gt; &lt;https://www.instagram.com/p/{short}/?taken-by={username}&gt; n&quot;) .",
            "url": "https://jimregan.github.io/notes/instaloader/rdf/2022/04/16/extract-instaloader.html",
            "relUrl": "/instaloader/rdf/2022/04/16/extract-instaloader.html",
            "date": " • Apr 16, 2022"
        }
        
    
  
    
        ,"post67": {
            "title": "Interesting links, 15/04/2022",
            "content": "StackEdit — online markdown editor . jimregan/psst-partial-timit — excessively detailed set of experiments for the PSST Challenge . PnG BERT: Augmented BERT on Phonemes and Graphemes for Neural TTS . EchoThief and IR Survey .",
            "url": "https://jimregan.github.io/notes/links/2022/04/15/misc-links.html",
            "relUrl": "/links/2022/04/15/misc-links.html",
            "date": " • Apr 15, 2022"
        }
        
    
  
    
        ,"post68": {
            "title": "Prepping TIMIT for Fairseq (for PSST)",
            "content": "from datasets import load_dataset, concatenate_datasets import soundfile as sf . PAD = &quot;&lt;pad&gt;&quot; UNK = &quot;&lt;unk&gt;&quot; SIL = &quot;&lt;sil&gt;&quot; SPN = &quot;&lt;spn&gt;&quot; . VOCAB_ITEMS =&quot;&quot;&quot; AA AE AH AO AW AX AY EH ER EY IH IY OW OY UH UW UX B CH D DH DX EL EM EN F G HH JH K L M N NG NX P Q R S SH T TH V W WH Y Z ZH . , ? ! &quot;&quot;&quot; . _VOCAB_SPLIT = VOCAB_ITEMS.split(&quot; n&quot;)[1:-1] . VOCAB = {e[1]:e[0] for e in enumerate(_VOCAB_SPLIT)} . TIMIT_MAPPING = { &#39;ax&#39;: &#39;AH&#39;, &#39;ax-h&#39;: &#39;AH&#39;, &#39;axr&#39;: &#39;ER&#39;, &#39;dx&#39;: &#39;T&#39;, &#39;el&#39;: [&#39;AH&#39;, &#39;L&#39;], &#39;em&#39;: [&#39;AH&#39;, &#39;M&#39;], &#39;en&#39;: [&#39;AH&#39;, &#39;N&#39;], &#39;eng&#39;: [&#39;IH&#39;, &#39;NG&#39;], &#39;hv&#39;: &#39;HH&#39;, &#39;ix&#39;: &#39;IH&#39;, &#39;nx&#39;: [&#39;N&#39;, &#39;T&#39;], &#39;pau&#39;: &#39;&lt;sil&gt;&#39;, &#39;epi&#39;: &#39;&lt;sil&gt;&#39;, &#39;ux&#39;: &#39;UW&#39; } TIMIT_IGNORE = [&#39;bcl&#39;, &#39;dcl&#39;, &#39;gcl&#39;, &#39;kcl&#39;, &#39;pcl&#39;, &#39;tcl&#39;] TIMIT_DISCARD = [&#39;dx&#39;, &#39;nx&#39;, &#39;q&#39;] . def map_timit_to_cmudict(timit): output = [] start = 1 if timit[0] == &quot;h#&quot; else 0 end = -1 if timit[-1] == &quot;h#&quot; else None timit = timit[start:end] for phone in timit: if phone in TIMIT_MAPPING: if type(TIMIT_MAPPING[phone]) == list: output += TIMIT_MAPPING[phone] else: output.append(TIMIT_MAPPING[phone]) elif phone in TIMIT_IGNORE: pass else: if not phone.upper() in VOCAB: print(&quot;Invalid phone&quot;, phone.upper()) output.append(phone.upper()) return output . timit = load_dataset(&#39;timit_asr&#39;) . def is_discardable(batch): for phoneme in batch[&quot;phonetic_detail&quot;][&quot;utterance&quot;]: if phoneme in TIMIT_DISCARD: return False return True . timit_filt = timit[&quot;train&quot;].filter(lambda eg: is_discardable(eg)) . timit_filt2 = timit[&quot;test&quot;].filter(lambda eg: is_discardable(eg)) . timit = concatenate_datasets([timit_filt, timit_filt2]) . MAX_TOKENS = 1120000 . manifest_path = &quot;manifest.tsv&quot; transcript_path = &quot;transcript&quot; . BASE = timit[0][&quot;file&quot;].split(&quot;/data/&quot;)[0] + &quot;/data/&quot; . resplit = timit.train_test_split(test_size=0.1) . for split in [&quot;train&quot;, &quot;test&quot;]: fsplit = split if fsplit == &quot;test&quot;: fsplit = &quot;valid&quot; with open(f&quot;{fsplit}.tsv&quot;, &quot;w&quot;) as manifest, open(f&quot;{fsplit}.ltr&quot;, &quot;w&quot;) as transcript: manifest.write(BASE + &quot; n&quot;) for item in resplit[split]: frames, sr = sf.read(item[&quot;file&quot;]) manifest.write(f&quot;{item[&#39;file&#39;].replace(BASE, &#39;&#39;)} t{len(frames)} n&quot;) utt = item[&#39;phonetic_detail&#39;][&#39;utterance&#39;] mapped = map_timit_to_cmudict(utt) transcript.write(f&quot;{&#39; &#39;.join(mapped)} n&quot;) .",
            "url": "https://jimregan.github.io/notes/timit/fairseq/psst/2022/04/04/timit-fairseq.html",
            "relUrl": "/timit/fairseq/psst/2022/04/04/timit-fairseq.html",
            "date": " • Apr 4, 2022"
        }
        
    
  
    
        ,"post69": {
            "title": "OpenCV and Riksdag",
            "content": "%%capture !pip install opencv-python !pip install dlib !pip install face_recognition . %%capture !wget https://mhdownload.riksdagen.se/VOD1/188373_20000_965995.mp4 . SAMPLE = &quot;188373_20000_965995.mp4&quot; . import face_recognition import cv2 . video = cv2.VideoCapture(SAMPLE) frameno = 1 detections = [] while True: ret, frame = video.read() try: small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25) except: frameno += 1 continue face_locations = face_recognition.face_locations(small_frame, model=&quot;cnn&quot;) locations = [] for top, right, bottom, left in face_locations: current = {} current[&quot;top&quot;] = top * 4 current[&quot;right&quot;] = right * 4 current[&quot;bottom&quot;] = bottom * 4 current[&quot;left&quot;] = left * 4 locations.append(current) # skip empty output if len(locations) != 0: current_frame = {} current_frame[&quot;frame&quot;] = frameno current_frame[&quot;detections&quot;] = locations detections.append(current_frame) frameno += 1 . detections .",
            "url": "https://jimregan.github.io/notes/riksdag/opencv/incomplete/2022/03/24/cv2-riksdag.html",
            "relUrl": "/riksdag/opencv/incomplete/2022/03/24/cv2-riksdag.html",
            "date": " • Mar 24, 2022"
        }
        
    
  
    
        ,"post70": {
            "title": "Interesting links, 16/03/2022",
            "content": "Transformer Memory as a Differentiable Search Index . It’s Raw! Audio Generation with State-Space Models, code . Learning Discrete Representations via Constrained Clustering for Effective and Efficient Dense Retrieval, code . Hierarchical Perceiver . mSLAM: Massively multilingual joint pre-training for speech and text . Who spoke when! How to Build your own Speaker Diarization Module, code . Do massive multilingual models that recognize language-specific units (e.g. words, phonemes) work on *all* speech?IMO, no! Multilingual =/= Universal.Check out our #INTERSPEECH2021 paper, Differentiable Allophone Graphs for Language-Universal ASR! https://t.co/haRflRUGSh 1/N pic.twitter.com/YBx3lPtgNJ . &mdash; Brian Yan (@brianyan918) July 29, 2021 Differentiable Allophone Graphs for Language-Universal Speech Recognition . NLP Seminar 220216 - Omar Sanseviero (Hugging Face) . 11L – Speech recognition and Graph Transformer Networks . How can I get duration of all video files in a folder containing multiple subfolders? . exiftool -n -q -p &#39;${Duration;our $sum;$_=ConvertDuration($sum+=$_)}&#39; ./*.mp4| tail -n1 . Breathing and Speech Planning in Spontaneous Speech Synthesis . mchaput/whoosh . Yann LeCun: “Energy-Based Self-Supervised Learning . Pseudo-Labeling for Massively Multilingual Speech Recognition . Implicit Language Model in LSTM for OCR . Exploring neural transducers for end-to-end speech recognition . Advancing Connectionist Temporal Classification with Attention Modeling . Advancing Acoustic-to-Word CTC Model . Direct Acoustics-to-Word Models for English Conversational Speech Recognition . Do End-to-End Speech Recognition Models Care About Context? . A study on effects of implicit and explicit language model information for DBLSTM-CTC based handwriting recognition . microsoft/mutransformers . How to Train a Joint Embedding using Pytorch . adefossez/julius — Fast PyTorch based DSP for audio and 1D signals . Julius Orion Smith III Home Page . ageron/handson-ml2 . asteroid-team/Libri_VAD . microsoft/DNS-Challenge — This repo contains the scripts, models, and required files for the Deep Noise Suppression (DNS) Challenge. . The Norwegian Parliamentary Speech Corpus . Who Takes the Parliamentary Floor? The Role of Gender in Speech-making in the Swedish Riksdag .",
            "url": "https://jimregan.github.io/notes/links/2022/03/16/misc-links.html",
            "relUrl": "/links/2022/03/16/misc-links.html",
            "date": " • Mar 16, 2022"
        }
        
    
  
    
        ,"post71": {
            "title": "Filter Riksdag by year",
            "content": "import json from pathlib import Path _API_DIR = Path(&quot;/Users/joregan/riksdag/riksdag-api-out&quot;) . def endswith_list(text, items): for it in items: if text.endswith(it): return True return False . def viddata_get_single_stream(videodata, hires=True): videos = [] if videodata is None: return [] if &#39;streams&#39; not in videodata: #raise Exception(&quot;videodata is missing &#39;streams&#39;&quot;) return [] if videodata[&#39;streams&#39;] is None: return [] if &#39;files&#39; not in videodata[&#39;streams&#39;]: #raise Exception(&quot;videodata[&#39;streams&#39;] is missing &#39;files&#39;&quot;) return [] if type(videodata[&#39;streams&#39;][&#39;files&#39;]) == list: for vfile in videodata[&#39;streams&#39;][&#39;files&#39;]: for bw in vfile[&#39;bandwidth&#39;]: if hires and bw[&#39;name&#39;] == &#39;Hög kvalitet&#39;: videos.append(bw[&#39;downloadurl&#39;]) elif not hires and bw[&#39;name&#39;] == &#39;Låg kvalitet&#39;: videos.append(bw[&#39;downloadurl&#39;]) else: #raise Exception(f&quot;Expected a list, got {type(videodata[&#39;streams&#39;][&#39;files&#39;])}&quot;) return [] return videos def viddata_get_streams(videodata, hires=True): output = [] if &#39;videodata&#39; not in videodata: #raise Exception(&quot;&#39;videodata&#39; missing&quot;) return [] for vdata in videodata[&#39;videodata&#39;]: output += viddata_get_single_stream(vdata, hires) return output def viddata_from_file(videofile, hires=True): with open(videofile) as jsonf: data = json.load(jsonf) return viddata_get_streams(data, hires) . def json_matches_years(filename, years): ret_val = False with open(filename) as f: data = json.load(f) if not &quot;videodata&quot; in data: #raise Exception(f&quot;File {filename} missing key &#39;videodata&#39;&quot;) return False videodata = data[&quot;videodata&quot;] if videodata is None: print(f&quot;Empty videodata: {filename}&quot;) return False for vdata in videodata: if vdata is None: print(f&quot;Empty videodata: {filename}&quot;) return False if &quot;debatedate&quot; in vdata and vdata[&quot;debatedate&quot;] is not None and vdata[&quot;debatedate&quot;] != &quot;&quot;: date = vdata[&quot;debatedate&quot;] if endswith_list(date.strip(), years): return True return False . matches = [] for file in _API_DIR.glob(&quot;H*&quot;): if json_matches_years(file, [&quot;2017&quot;, &quot;2018&quot;]): matches.append(str(file)) . Empty videodata: /Users/joregan/riksdag/riksdag-api-out/H8C120210621zz . with open(&quot;2017-2018.txt&quot;, &quot;w&quot;) as outf: for m in matches: outf.write(m + &quot; n&quot;) . with open(&quot;2017-2018-videos.txt&quot;, &quot;w&quot;) as outf: for file in _API_DIR.glob(&quot;H*&quot;): if json_matches_years(file, [&quot;2017&quot;, &quot;2018&quot;]): videos = viddata_from_file(file) vidsout = &quot; t&quot;.join(videos) outf.write(f&quot;{file.stem} t{vidsout} n&quot;) . Empty videodata: /Users/joregan/riksdag/riksdag-api-out/H8C120210621zz . def get_speaker_data(data): output = [] if not &quot;videodata&quot; in data or data[&quot;videodata&quot;] is None: #raise Exception(f&quot;File {filename} missing key &#39;videodata&#39;&quot;) return [] for vdata in data[&quot;videodata&quot;]: if vdata is not None and &quot;speakers&quot; in vdata and vdata[&quot;speakers&quot;] is not None: for speaker in vdata[&quot;speakers&quot;]: output.append(speaker) return output . with open(&quot;/Users/joregan/riksdag/riksdag-api-out/H501CU20&quot;) as inp: vdata = json.load(inp) speakers = get_speaker_data(vdata) sample_speech = speakers[0][&quot;anftext&quot;] . from bs4 import BeautifulSoup . !pip install mosestokenizer . from mosestokenizer import MosesSentenceSplitter splitter = MosesSentenceSplitter(&quot;sv&quot;) . stdbuf was not found; communication with perl may hang due to stdio buffering. . def split_text(sample_speech, by_paras=False): soup = BeautifulSoup(sample_speech, &#39;html.parser&#39;) paras = [] for para in soup.findAll(&quot;p&quot;): if not para.text.strip().startswith(&quot;STYLEREF Kantrubrik&quot;): paras.append(para.text.strip()) splitparas = [splitter([p]) for p in paras if p.strip() != &quot;&quot;] if by_paras: return splitparas else: flattened = [sent for sents in splitparas for sent in sents] return flattened . with open(&quot;2017-2018-text.txt&quot;, &quot;w&quot;) as outf: for file in _API_DIR.glob(&quot;H*&quot;): if json_matches_years(file, [&quot;2017&quot;, &quot;2018&quot;]): with open(file) as inp: vdata = json.load(inp) speakers = get_speaker_data(vdata) for speaker in speakers: if &quot;anftext&quot; in speaker: text = split_text(speaker[&quot;anftext&quot;]) for line in text: outf.write(line + &quot; n&quot;) . Empty videodata: /Users/joregan/riksdag/riksdag-api-out/H8C120210621zz . with open(&quot;all-text.txt&quot;, &quot;w&quot;) as outf: for file in _API_DIR.glob(&quot;H*&quot;): with open(file) as inp: vdata = json.load(inp) speakers = get_speaker_data(vdata) for speaker in speakers: if &quot;anftext&quot; in speaker: text = split_text(speaker[&quot;anftext&quot;]) for line in text: outf.write(line + &quot; n&quot;) .",
            "url": "https://jimregan.github.io/notes/riksdag/2022/03/15/filter-by-year.html",
            "relUrl": "/riksdag/2022/03/15/filter-by-year.html",
            "date": " • Mar 15, 2022"
        }
        
    
  
    
        ,"post72": {
            "title": "Getting timestamps on long audio",
            "content": "First, an audio sample. Using this video from youtube. Youtube says it&#39;s 11 minutes, 51 seconds, so that should be enough to check that striding works. . !pip install youtube-dl . !youtube-dl -x --audio-format best -o &#39;%(id)s.%(ext)s&#39; https://www.youtube.com/watch?v=Kw5jkyLGFGc . !ffmpeg -i Kw5jkyLGFGc.m4a -acodec pcm_s16le -ac 1 -ar 16000 Kw5jkyLGFGc.wav . Here starts the actual ASR stuff. . !pip install transformers . _SWE_MODEL = &quot;KBLab/wav2vec2-large-voxrex-swedish&quot; . from transformers import pipeline . pipe = pipeline(model=_SWE_MODEL) . For working with strides, there&#39;s information in a blog post. . There isn&#39;t much information on getting timestamps from a pipeline, but the detail is in the pull request. . output = pipe(&quot;/content/Kw5jkyLGFGc.wav&quot;, chunk_length_s=10) . output = pipe(&quot;/content/Kw5jkyLGFGc.wav&quot;, chunk_length_s=10, return_timestamps=&quot;word&quot;) . import json with open(&quot;/content/Kw5jkyLGFGc.json&quot;, &quot;w&quot;) as f: json.dump(output, f) .",
            "url": "https://jimregan.github.io/notes/long%20audio/wav2vec2/huggingface/timestamps/2022/03/08/getting-timestamps-on-long-audio-with-wav2vec2-and-huggingface.html",
            "relUrl": "/long%20audio/wav2vec2/huggingface/timestamps/2022/03/08/getting-timestamps-on-long-audio-with-wav2vec2-and-huggingface.html",
            "date": " • Mar 8, 2022"
        }
        
    
  
    
        ,"post73": {
            "title": "difflib opcodes",
            "content": "texta = &quot;this is a small test&quot; textb = &quot;this isa small text&quot; . from difflib import SequenceMatcher def print_replacements(texta, textb): sm = SequenceMatcher(a=texta, b=textb) for op, a_start, a_end, b_start, b_end in sm.get_opcodes(): frag_a = texta[a_start:a_end] frag_b = textb[b_start:b_end] a_pre = a_start - 1 if a_start &gt; 0 else 0 b_pre = b_start - 1 if b_start &gt; 0 else 0 a_post = a_end + 1 if a_end &lt; (len(texta) - 1) else a_end b_post = b_end + 1 if b_end &lt; (len(textb) - 1) else b_end if op == &quot;equal&quot;: continue elif op == &quot;delete&quot;: if frag_a == &quot; &quot;: continue print(f&quot;del t{texta[a_pre:a_post]} t{textb[b_pre:b_post]}&quot;) elif op == &quot;insert&quot;: if frag_b == &quot; &quot;: continue print(f&quot;ins t{texta[a_pre:a_post]} t{textb[b_pre:b_post]}&quot;) elif op == &quot;replace&quot;: print(f&quot;repl t{frag_a} t{frag_b}&quot;) . print_replacements(texta, textb) . repl s x .",
            "url": "https://jimregan.github.io/notes/difflib/2022/03/08/difflib-find-pieces.html",
            "relUrl": "/difflib/2022/03/08/difflib-find-pieces.html",
            "date": " • Mar 8, 2022"
        }
        
    
  
    
        ,"post74": {
            "title": "Read SMP file (with soundfile)",
            "content": "import soundfile as sf def fix_text(text): return text.replace(&quot;{&quot;, &quot;ä&quot;).replace(&quot;}&quot;, &quot;å&quot;).replace(&quot;|&quot;, &quot;ö&quot;) def smp_headers(filename): with open(filename, &quot;rb&quot;) as f: f.seek(0) raw_headers = f.read(1024) raw_headers = raw_headers.rstrip(b&#39; x00&#39;) asc_headers = raw_headers.decode(&quot;ascii&quot;) asc_headers.rstrip(&#39; x00&#39;) tmp = [a for a in asc_headers.split(&quot; r n&quot;)] back = -1 while abs(back) &gt; len(tmp) + 1: if tmp[back] == &#39;=&#39;: break back -= 1 tmp = tmp[0:back-1] return dict(a.split(&quot;=&quot;) for a in tmp) def smp_read_sf(filename): headers = smp_headers(filename) if headers[&quot;msb&quot;] == &quot;last&quot;: ENDIAN = &quot;LITTLE&quot; else: ENDIAN = &quot;BIG&quot; data, sr = sf.read(filename, channels=int(headers[&quot;nchans&quot;]), samplerate=16000, endian=ENDIAN, start=512, dtype=&quot;int16&quot;, format=&quot;RAW&quot;, subtype=&quot;PCM_16&quot;) return (data, sr) def write_wav(filename, arr): import wave with wave.open(filename, &quot;w&quot;) as f: f.setnchannels(1) f.setsampwidth(2) f.setframerate(16000) f.writeframes(arr) arr, sr = smp_read_sf(&quot;fp2060.pr.09.smp&quot;) write_wav(&quot;out.wav&quot;, arr) . import IPython IPython.display.Audio(&quot;out.wav&quot;) . Your browser does not support the audio element.",
            "url": "https://jimregan.github.io/notes/smp/soundfile/snack/wavesurfer/2022/03/02/read-smp-file.html",
            "relUrl": "/smp/soundfile/snack/wavesurfer/2022/03/02/read-smp-file.html",
            "date": " • Mar 2, 2022"
        }
        
    
  
    
        ,"post75": {
            "title": "Interesting links, 02/03/2022",
            "content": "Fonetik 2022 . The EMU-webApp . TorchStudio Features — Looks interesting, doesn’t seem to run on ARM Mac though . Fast Development of ASR in African Languages using Self Supervised Speech Representation Learning . The Effects of Automatic Speech Recognition Quality on Human Transcription Latency “Our studies with 160 participants recruited on Amazon’s Mechanical Turk indicate that starting with the ASR output is worse unless it is sufficiently accurate (Word Error Rate (WER) is under 30%)” . Differentiable Allophone Graphs for Language-Universal Speech Recognition, tweet . birgermoell/lm-swedish . Boosting Wav2Vec2 with n-grams in 🤗 Transformers . Irish ASR demo . QPSR . Gunnar Fant publications . Neural Instrument Cloning from very few samples . AI-Nordics/the-nordic-pile . Berzelius . chinedufn/swift-bridge — swift-bridge facilitates Rust and Swift interop. . qarmin/czkawka — Multi functional app to find duplicates, empty folders, similar images etc. . PyO3/pyo3 — Rust bindings for the Python interpreter . N-gram Language Model with NLTK . speechbrain.lm.counting module . Google cloud ASR languages . FLAME, pytorch . Bried intro to Linen . NbAiLab/NPSC — Norwegian Parliamentary Speech Corpus . XGLM: HuggingFace . fsspec . FNet: Mixing Tokens with Fourier Transforms, code, HF . HF: wav2vec update for tiny audio . Adding vs. concatenating positional embeddings &amp; Learned positional encodings . Math - Differential Calculus . BirgerMoell/ToMaHawk . Making automatic speech recognition work on large files with Wav2Vec2 in 🤗 Transformers . Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation, OpenReview, code . 02 – Neural nets: rotation and squashing . Audio augmentation . facebookresearch/AugLy . iver56/audiomentations . asteroid-team/torch-audiomentations . Spijkervet/torchaudio-augmentations . spotify/pedalboard . facebookresearch/WavAugment . VOiCES Corpus . Fonetik . FM-modulation unit for tape-recording . Voice fundamental frequency tracking . Formant frequency tracking . Detection of voicing and Automatic segmentation schemes . Evaluation of spectrographic data sampling techniques . Structural classification of Swedish phonemes . In search of the conversational homunculus . Automatic classification of ‘front’ and ‘back’ pronunciation variants of /r/ in the Götaland dialects of Swedish .",
            "url": "https://jimregan.github.io/notes/links/2022/03/02/misc-links.html",
            "relUrl": "/links/2022/03/02/misc-links.html",
            "date": " • Mar 2, 2022"
        }
        
    
  
    
        ,"post76": {
            "title": "QPSR gap checking",
            "content": "import json . with open(&quot;qpsr.json&quot;) as f: data = json.load(f) . res = {} for item in data: if not &quot;pages&quot; in item: print(f&quot;Missing pages: {item[&#39;title&#39;]} ({item[&#39;year&#39;]})&quot;) pages = &quot;?-?&quot; else: pages = item[&quot;pages&quot;] year = item[&quot;year&quot;] if not &quot;volume&quot; in item: print(f&quot;Missing volume: {item[&#39;title&#39;]} ({item[&#39;year&#39;]})&quot;) vol = &quot;??&quot; else: vol = item[&quot;volume&quot;] if not &quot;edition&quot; in item: print(f&quot;Missing edition: {item[&#39;title&#39;]} ({item[&#39;year&#39;]})&quot;) ed = &quot;??&quot; else: ed = item[&quot;edition&quot;] if not &quot;-&quot; in pages: if pages.isdigit(): start = end = pages else: raise IOError(f&quot;No &#39;-&#39; in pages: {pages} ({key})&quot;) else: start, end = pages.split(&quot;-&quot;) if item[&quot;title&quot;] == &quot;.&quot;: print(item[&quot;pdf&quot;]) key = f&quot;{year}_{vol}_{ed}&quot; if not key in res: res[key] = [{&quot;start&quot;: start, &quot;end&quot;: end}] else: res[key].append({&quot;start&quot;: start, &quot;end&quot;: end}) . from functools import cmp_to_key def compare(item1, item2): if item1[&quot;end&quot;] &lt; item2[&quot;start&quot;]: return -1 elif item1[&quot;start&quot;] &gt; item2[&quot;end&quot;]: return 1 else: return 0 def same_or_next(a, b): return (a == b) or (a == b-1) output = {} last_pages = {} for item in res.keys(): for subitem in res[item]: subitem[&quot;start&quot;] = int(subitem[&quot;start&quot;]) subitem[&quot;end&quot;] = int(subitem[&quot;end&quot;]) tmp = res[item] tmp = sorted(tmp, key=cmp_to_key(compare)) last_pages[item] = tmp[-1][&quot;end&quot;] cnt = 0 outtmp = [] if tmp[0][&#39;start&#39;] &gt; 1: outtmp.append({&quot;start&quot;: 1, &quot;end&quot;: tmp[0][&#39;start&#39;]-1}) while cnt &lt; len(tmp) - 1: if not same_or_next(tmp[cnt][&quot;end&quot;], tmp[cnt+1][&quot;start&quot;]): toadd = {&quot;start&quot;: tmp[cnt][&quot;end&quot;]+1, &quot;end&quot;: tmp[cnt+1][&quot;start&quot;]-1} if toadd[&quot;start&quot;] == toadd[&quot;end&quot;]: toadd = {&quot;page&quot;: toadd[&quot;start&quot;]} outtmp.append(toadd) cnt += 1 output[item] = outtmp . with open(&quot;pages.txt&quot;, &quot;w&quot;) as f: for (ed, page) in last_pages.items(): f.write(f&#39;{ed.replace(&quot;_&quot;, &quot; &quot;)} t{page} n&#39;) . def _single_page(page): if &quot;page&quot; in page: return str(page[&quot;page&quot;]) else: return f&quot;{page[&#39;start&#39;]}-{page[&#39;end&#39;]}&quot; def _join_pages(pagelist): return &quot;, &quot;.join([_single_page(a) for a in pagelist]) merged = {a: _join_pages(b) for (a, b) in output.items()} . with open(&quot;missing-pages.txt&quot;, &quot;w&quot;) as f: for (a, b) in merged.items(): if b and b != &quot;&quot;: f.write(f&quot;{a} t{b} n&quot;) . with open(&quot;number-of-articles.txt&quot;, &quot;w&quot;) as f: for (a, b) in res.items(): f.write(f&quot;{a} t{len(b)} n&quot;) . import json with open(&quot;gaps.json&quot;, &quot;w&quot;) as out: out.write(json.dumps(output, indent=4)) .",
            "url": "https://jimregan.github.io/notes/qpsr/tmh/2022/02/23/qpsr-check-gaps.html",
            "relUrl": "/qpsr/tmh/2022/02/23/qpsr-check-gaps.html",
            "date": " • Feb 23, 2022"
        }
        
    
  
    
        ,"post77": {
            "title": "QPSR scraper",
            "content": "import requests from bs4 import BeautifulSoup . def get_years(): _TOP = &quot;https://www.speech.kth.se/qpsr/&quot; _TOP_HTML = requests.get(_TOP) assert _TOP_HTML.status_code == 200 _TOP_SOUP = BeautifulSoup(_TOP_HTML.text, &#39;html.parser&#39;) by_years = _TOP_SOUP.find_all(&quot;select&quot;, {&quot;name&quot;: &quot;year&quot;}) years = [opt.text for by_year in by_years for opt in by_year.find_all(&quot;option&quot;)] return years . _TITLES = &quot;&quot;&quot; http://www.speech.kth.se/prod/publications/files/3605.pdf tProductive Vocabulary Size Development in Children Aged 18-24 Months – Gender Differences tIda Andersson, Jenny Gauding, Anna Graca, Katarina Holm, Linda Öhlin, Ulrika Marklund, Anna Ericsson http://www.speech.kth.se/prod/publications/files/3607.pdf tChildren’s perception of their modified speech – preliminary findings tSofia Strömbergsson http://www.speech.kth.se/prod/publications/files/3579.pdf tImitation of bird song in folklore – onomatopoeia or not? tÅsa Abelin http://www.speech.kth.se/prod/publications/files/3586.pdf tAnticipatory lip rounding– a pilot study using The Wave Speech Research System tGabrielsson, D., Kirchner, S., Nilsson, K., Norberg, A., Widlund, C. http://www.speech.kth.se/prod/publications/files/qpsr/2007/2007_50_1_121-124.pdf tSIMULEKT – modelling Swedish regional intonation tGösta Bruce, Susanne Schötz, Björn Granström http://www.speech.kth.se/prod/publications/files/qpsr/2007/2007_50_1_033-036.pdf tFilibuster – a new Swedish text-to-speech system tChristina Ericsson, Jesper Klein, Kåre Sjölander, Lars Sönnebo http://www.speech.kth.se/prod/publications/files/qpsr/2007/2007_50_1_049-052.pdf tSwedish word accents in a ‘confirmation’ context tGilbert Ambrazaitis http://www.speech.kth.se/prod/publications/files/qpsr/2007/2007_50_1_053-056.pdf tEstimates of Infants’ Vocabulary Composition and the Role of Adult-instructions for Early Word-learning tKlintfors E., Lacerda F., Sundberg U. http://www.speech.kth.se/prod/publications/files/qpsr/2007/2007_50_1_061-064.pdf tMushyPeek – an experiment framework for controlled investigation of human-human interaction control behaviour tJens Edlund, Jonas Beskow, Mattias Heldner http://www.speech.kth.se/prod/publications/files/qpsr/2007/2007_50_1_077-080.pdf tWhat you Hear is what you See – a study of visual vs. auditive noise tAnna Berg, Annelie Brandt http://www.speech.kth.se/prod/publications/files/qpsr/2007/2007_50_1_093-096.pdf tLinguistic challenges for bilingual schoolchildren in Rosengård tPetra Bodén, Gudrun Svensson http://www.speech.kth.se/prod/publications/files/qpsr/2007/2007_50_1_097-100.pdf tVoxalys – a Pedagogical Praat Plugin for Voice Analysis tJonas Lindh http://www.speech.kth.se/prod/publications/files/qpsr/2006/2006_48_1_035-043.pdf tMusical structure: A translation of István Ipolyi: Innføring i Musikkspråkets Opprinnelse og Struktur tFalkenberg Hansen, K. http://www.speech.kth.se/prod/publications/files/qpsr/2002/2002_44_1_085-088.pdf tStød and Vowel Length: Acoustic and Cognitive Reality? tGrønnum, N. http://www.speech.kth.se/prod/publications/files/qpsr/2002/2002_44_1_145-148.pdf tStress judgements by naïve listeners tMolin, J. http://www.speech.kth.se/prod/publications/files/qpsr/1995/1995_36_2-3_063-070.pdf tMatching the rule parameters of PHRASE ARCH to performances of ”Träumerei”: a preliminary study tFriberg, A. http://www.speech.kth.se/prod/publications/files/qpsr/1975/1975_16_4_027-035.pdf tLippenablesehilfe für Gehörlose: Visuelle oder taktile Darbietung von Ergänzungsinformation? tTraunmuller, H. &quot;&quot;&quot; . MISSING = {} for missed in _TITLES.split(&quot; n&quot;): if not &quot; t&quot; in missed: continue parts = missed.split(&quot; t&quot;) MISSING[parts[0]] = parts[1:] . def read_page(page): if page.startswith(&quot;http&quot;): url = page year = page[len(page)-4:] else: url = f&quot;https://www.speech.kth.se/qpsr/show_by_year.php?year={page}&quot; year = page req = requests.get(url) assert req.status_code == 200 soup = BeautifulSoup(req.text, &#39;html.parser&#39;) pubs = [] for pub in soup.find_all(&quot;p&quot;, class_=&quot;publications_apa_entry&quot;): data = {} data[&quot;year&quot;] = year raw_text = pub.text author = pub.find(&quot;span&quot;, class_=&quot;publications_apa_author&quot;) if author.text == &quot;, . (Ed.).&quot;: data[&quot;author&quot;] = &quot;&quot; else: data[&quot;author&quot;] = author.text raw_text = raw_text.replace(author.text, &quot;&quot;).lstrip() if not raw_text.startswith(f&quot;({year}).&quot;): raise Exception(f&quot;Expected year {year}, but got {raw_text[1:5]} - &quot; + pub.text) raw_text = raw_text[8:] pub_title = pub.find(&quot;span&quot;, class_=&quot;publications_apa_title&quot;) data[&quot;publication_full&quot;] = pub_title.text pub_pieces = pub_title.text.split(&quot;, &quot;) if pub_pieces[-1].isdigit(): data[&quot;volume&quot;] = pub_pieces[-1] data[&quot;publication&quot;] = &quot;, &quot;.join(pub_pieces[0:-1]) pub_title_start = raw_text.find(pub_title.text) pub_title_end = pub_title_start + len(pub_title.text) data[&quot;title&quot;] = raw_text[0:pub_title_start].strip() if data[&quot;title&quot;].endswith(&quot;. In&quot;): data[&quot;title&quot;] = data[&quot;title&quot;][0:-3] for pdf_link in pub.find_all(&quot;a&quot;): if pdf_link is None or not pdf_link.has_attr(&quot;href&quot;): print(&quot;Missing link: &quot; + pub.text) else: if pdf_link[&quot;href&quot;].endswith(&quot;pdf&quot;): data[&quot;pdf&quot;] = pdf_link[&quot;href&quot;] else: if pdf_link.has_attr(&quot;onclick&quot;): abs_start = pdf_link[&quot;onclick&quot;].find(&quot;abstract_&quot;) abs_end = pdf_link[&quot;onclick&quot;][abs_start:].find(&quot;&#39;&quot;) abs_id = pdf_link[&quot;onclick&quot;][abs_start:abs_start+abs_end] abs_soup = soup.find(&quot;p&quot;, {&quot;id&quot;: abs_id}) abs_text = abs_soup.text.strip() if abs_text.startswith(&quot;Abstract:&quot;): abs_text = abs_text[9:].strip() abs_text = abs_text.replace(&quot; r n&quot;, &quot; &quot;).replace(&quot; r&quot;, &quot; &quot;).replace(&quot; n&quot;, &quot; &quot;) data[&quot;abstract&quot;] = abs_text if &quot;pdf&quot; in data and data[&quot;pdf&quot;].endswith(&quot;/1937.pdf&quot;): data[&quot;pages&quot;] = &quot;1-6&quot; data[&quot;volume&quot;] = &quot;49&quot; data[&quot;edition&quot;] = &quot;1&quot; data[&quot;title&quot;] = &quot;Sopranos with a singer’s formant? Historical, Physiological, and Acoustical Aspects of Castrato Singing&quot; data[&quot;author_full&quot;] = &quot;Johan Sundberg, Marianne Trovén, Bernhard Richter&quot; data[&quot;author&quot;] = &quot;Sundberg, J., Trovén, M., Richter, B.&quot; pubs.append(data) continue raw_text = raw_text[pub_title_end:].strip() if raw_text.endswith(&quot; [pdf]&quot;): raw_text = raw_text[0:-6] if raw_text[-1:] == &quot;.&quot;: raw_text = raw_text[0:-1] if &quot;, &quot; in raw_text: if raw_text.startswith(&quot;(pp.&quot;): parts = raw_text.split(&quot;). &quot;) data[&quot;pages&quot;] = parts[0][5:] # manual fix if data[&quot;pdf&quot;].endswith(&quot;/3597.pdf&quot;): data[&quot;volume&quot;] = &quot;51&quot; data[&quot;edition&quot;] = &quot;1&quot; elif data[&quot;pdf&quot;].endswith(&quot;/2002_44_1_153-156.pdf&quot;): data[&quot;volume&quot;] = &quot;44&quot; data[&quot;edition&quot;] = &quot;1&quot; else: parts = raw_text.split(&quot;, &quot;) if parts[0].startswith(&quot;(&quot;): to_mark = parts[0].find(&quot;)&quot;) data[&quot;edition&quot;] = parts[0][1:to_mark] if &quot; [abstract]&quot; in parts[1]: data[&quot;pages&quot;] = parts[1].replace(&quot; [abstract]&quot;, &quot;&quot;) if data[&quot;pages&quot;].endswith(&quot;.&quot;): data[&quot;pages&quot;] = data[&quot;pages&quot;][0:-1] else: data[&quot;pages&quot;] = parts[1] if &quot;pages&quot; in data and &quot;. [html]&quot; in data[&quot;pages&quot;]: data[&quot;pages&quot;] = data[&quot;pages&quot;].replace(&quot;. [html]&quot;, &quot;&quot;) if &quot;pdf&quot; in data: if data[&quot;pdf&quot;].endswith(&quot;2007_50_1_065-068.pdf&quot;): data[&quot;title&quot;] = &quot;The Parrot Effect – a study of the ability to imitate a foreign language&quot; data[&quot;author_full&quot;] = &quot;Johanna Persson, Linda Westholm&quot; data[&quot;edition&quot;] = &quot;1&quot; data[&quot;pages&quot;] = &quot;065-068&quot; elif data[&quot;pdf&quot;].endswith(&quot;2007_50_1_113-116.pdf&quot;): data[&quot;title&quot;] = &quot;Automatic classification of &#39;front&#39; and &#39;back&#39; pronunciation variants of /r/ in the Götaland dialects of Swedish&quot; data[&quot;author_full&quot;] = &quot;Johan Frid&quot; elif data[&quot;pdf&quot;].endswith(&quot;2007_50_1_073-076.pdf&quot;): data[&quot;title&quot;] = &quot;Emotional McGurk effect in Swedish&quot; data[&quot;pages&quot;] = &quot;073-076&quot; data[&quot;volume&quot;] = &quot;50&quot; data[&quot;edition&quot;] = &quot;1&quot; data[&quot;author_full&quot;] = &quot;Åsa Abelin&quot; data[&quot;author_full&quot;] = &quot;Abelin, Å.&quot; elif data[&quot;pdf&quot;] in MISSING: data[&quot;title&quot;] = MISSING[data[&quot;pdf&quot;]][0] data[&quot;author_full&quot;] = MISSING[data[&quot;pdf&quot;]][1] pubs.append(data) return pubs . import json all = [] for year in get_years(): all += read_page(year) with open(&quot;qpsr.json&quot;, &quot;w&quot;) as out: out.write(json.dumps(all, indent=4)) .",
            "url": "https://jimregan.github.io/notes/qpsr/tmh/2022/02/22/qpsr-scraper.html",
            "relUrl": "/qpsr/tmh/2022/02/22/qpsr-scraper.html",
            "date": " • Feb 22, 2022"
        }
        
    
  
    
        ,"post78": {
            "title": "Interesting links, 20/02/2022",
            "content": "autopilot-rs/autopy — A simple, cross-platform GUI automation module for Python and Rust. . JupyterLite: Jupyter ❤️ WebAssembly ❤️ Python . How we made Jupyter Notebooks collaborative with Yjs . VertaAI/modeldb — Open Source ML Model Versioning, Metadata, and Experiment Management . google/compare_gan . pfnet-research/sngan_projection . Spectral Normalization for Generative Adversarial Networks, code . Progressive Growing of GANs for Improved Quality, Stability, and Variation . Spoken dialogue data collected in the WAXHOLM project, dataset, phoneset . NST Pronunciation Lexicon for Swedish . shivammehta007/Neural-HMM . Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation . urvashik/knnlm . SlimIPL: Language-Model-Free Iterative Pseudo-Labeling . Joint Masked CPC and CTC Training for ASR . The Curious Case of Neural Text Degeneration . lukakerr/Pine . AI Sweden Youtube . LibriVox - An Sgéaluidhe Gaedhealach by Dúbhglas de h-Íde, scan . Eclipse Mosquitto . mSLAM: Massively multilingual joint pre-training for speech and text . Wav2Vec2 Time Stamps #15687 . Distilling the Knowledge of BERT for Sequence-to-Sequence ASR . google-research/t5x . google-research/mozolm — MozoLM: A language model (LM) serving library . Any-to-One Sequence-to-Sequence Voice Conversion using Self-Supervised Discrete Speech Representations . spaces/microsoft/wavlm-speaker-verification . Multistream CNN for Robust Acoustic Modeling, code, script . W2v-BERT: Combining Contrastive Learning and Masked Language Modeling for Self-Supervised Speech Pre-Training . VocalTractLab . chdh/klatt-syn . makcedward/nlpaug . Star Temporal Classification: Sequence Classification with Partially Labeled Data . Differentiable Allophone Graphs for Language-Universal Speech Recognition, twitter thread . BPE-Dropout: Simple and Effective Subword Regularization . Subword Regularization: Improving Neural Network Translation Models with Multiple Subword Candidates . Non-Autoregressive Predictive Coding for Learning Speech Representations from Local Dependencies, code . facebookresearch/CPC_audio . FastPitchFormant: Source-Filter Based Decomposed Modeling for Speech Synthesis .",
            "url": "https://jimregan.github.io/notes/links/2022/02/20/misc-links.html",
            "relUrl": "/links/2022/02/20/misc-links.html",
            "date": " • Feb 20, 2022"
        }
        
    
  
    
        ,"post79": {
            "title": "Festus Dockerfile",
            "content": "FROM ubuntu:18.04 ENV DEBIAN_FRONTEND=&quot;noninteractive&quot; RUN apt update &amp;&amp; apt install -y g++ git &amp;&amp; apt install -y apt-transport-https ca-certificates RUN apt install -y curl gnupg pkg-config zip zlib1g-dev unzip python # This stuff doesn&#39;t work, the apt repo seems broken #RUN curl https://bazel.build/bazel-release.pub.gpg | apt-key add - #RUN echo &quot;deb [arch=amd64] https://storage.googleapis.com/bazel-apt stable jdk1.8&quot; | tee /etc/apt/sources.list.d/bazel.list #RUN apt update #RUN apt install -y bazel RUN curl -L https://github.com/bazelbuild/bazel/releases/download/6.0.0-pre.20220201.3/bazel-6.0.0-pre.20220201.3-linux-arm64 &gt; /usr/local/bin/bazel RUN chmod a+x /usr/local/bin/bazel RUN bazel version RUN git clone https://github.com/google/language-resources/ RUN cd language-resources &amp;&amp; cat WORKSPACE | sed -e &#39;s/googletest-master/googletest-main/;s!googletest/archive/master!googletest/archive/main!;s!re2-master!re2-main!;s!/re2/archive/master!/re2/archive/main!;s/benchmark-master/benchmark-main/;s!benchmark/archive/master!benchmark/archive/main!;s/abseil-py-master/abseil-py-main/;s!abseil-py/archive/master!abseil-py/archive/main!;&#39; &gt; TMP &amp;&amp; mv TMP WORKSPACE &amp;&amp; cd festus &amp;&amp; bazel build //festus:ngramfinalize &amp;&amp; bazel build //festus:make-alignable-symbols &amp;&amp; bazel build //festus:fst2re &amp;&amp; bazel build //festus:fstnbinom &amp;&amp; bazel build //festus:fstrmepscycle &amp;&amp; bazel build //festus:best-labeling &amp;&amp; bazel build //festus:lexicon-diagnostics &amp;&amp; bazel build //festus:make-runtime-fsts .",
            "url": "https://jimregan.github.io/notes/docker/festus/todo/2022/02/15/festus-dockerfile.html",
            "relUrl": "/docker/festus/todo/2022/02/15/festus-dockerfile.html",
            "date": " • Feb 15, 2022"
        }
        
    
  
    
        ,"post80": {
            "title": "Extract SLT metadata",
            "content": "!pip install ffmpeg-python . _BASE = &quot;/Users/joregan/asr/slt/audio&quot; . import json from pathlib import Path . slt = {} with open(&quot;/Users/joregan/asr/slt.json&quot;) as slt_file: for line in slt_file.readlines(): linedata = json.loads(line) slt_id = Path(linedata[&quot;path&quot;]).stem slt[slt_id] = linedata . from pathlib import Path base = Path(_BASE) for shn in base.glob(&quot;**/*.shn&quot;): meta = {} meta[&quot;id&quot;] = shn.stem probe = ffmpeg.probe(shn) if not &quot;format&quot; in probe and not &quot;tags&quot; in probe[&quot;format&quot;]: continue tags = probe[&quot;format&quot;][&quot;tags&quot;] if &quot;Gender&quot; in tags: meta[&quot;gender&quot;] = tags[&quot;Gender&quot;] if &quot;UserID&quot; in tags: meta[&quot;user_id&quot;] = tags[&quot;UserID&quot;] if &quot;Dialect&quot; in tags: meta[&quot;dialect&quot;] = tags[&quot;Dialect&quot;] if &quot;recording_date&quot; in tags: meta[&quot;recording_date&quot;] = tags[&quot;recording_date&quot;] if &quot;recording_time&quot; in tags: meta[&quot;recording_time&quot;] = tags[&quot;recording_time&quot;] if meta[&quot;id&quot;] in slt: slt[meta[&quot;id&quot;]].update(meta) else: slt[meta[&quot;id&quot;]] = meta . with open(&quot;slt-meta.json&quot;, &quot;w&quot;) as slt_out: for item in slt.keys(): slt_out.write(json.dumps(slt[item]) + &quot; n&quot;) .",
            "url": "https://jimregan.github.io/notes/slt/asr/swedish/2022/02/14/extract-slt-metadata.html",
            "relUrl": "/slt/asr/swedish/2022/02/14/extract-slt-metadata.html",
            "date": " • Feb 14, 2022"
        }
        
    
  
    
        ,"post81": {
            "title": "Running speaker diarisation with pyannote audio",
            "content": "conda install pytorch torchaudio -c pytorch conda install numpy cffi conda install libsndfile=1.0.28 -c conda-forge pip install https://github.com/pyannote/pyannote-audio/archive/develop.zip pip install speechbrain pip install pydub pip install librosa pip install ipykernel . import librosa import torch . !youtube-dl --write-sub --sub-lang &#39;sv&#39; -o &#39;%(id)s.%(ext)s&#39; j8AH29Ad-zU . from pyannote.audio import Pipeline SAMPLE = &quot;j8AH29Ad-zU.mp4&quot; pipeline = Pipeline.from_pretrained(&quot;pyannote/speaker-diarization&quot;) . audio, sr = librosa.load(SAMPLE, mono=False) audiot = torch.from_numpy(audio) diarization = pipeline({&quot;waveform&quot;: audiot, &quot;sample_rate&quot;: sr}) . [W NNPACK.cpp:79] Could not initialize NNPACK! Reason: Unsupported hardware. . diarization.uri = &#39;j8AH29Ad-zU&#39; . with open(&quot;j8AH29Ad-zU.rttm&quot;, &quot;w&quot;) as f: diarization.write_rttm(f) .",
            "url": "https://jimregan.github.io/notes/diarisation/pyannote/2022/02/07/pyannote-diarization.html",
            "relUrl": "/diarisation/pyannote/2022/02/07/pyannote-diarization.html",
            "date": " • Feb 7, 2022"
        }
        
    
  
    
        ,"post82": {
            "title": "Read Waxholm corpus",
            "content": "def fix_text(text): return text.replace(&quot;{&quot;, &quot;ä&quot;).replace(&quot;}&quot;, &quot;å&quot;).replace(&quot;|&quot;, &quot;ö&quot;) . TESTF = &quot;/Users/joregan/Playing/waxholm/scenes_formatted//fp2033/fp2033.6.20.smp.mix&quot; . class FR: def __init__(self, text): if not text.startswith(&quot;FR&quot;): raise IOError(&quot;Unknown line type (does not begin with &#39;FR&#39;): &quot; + text) parts = text.split(&quot; t&quot;) if len(parts) == 5: self.type = &#39;B&#39; if len(parts) == 4: self.type = &#39;I&#39; if len(parts) == 3: self.type = &#39;E&#39; if parts[1].strip() != &quot;OK&quot;: raise IOError(&quot;Unexpected line: &quot; + text) self.frame = parts[0][2:].strip() if len(parts) &gt; 3: self.phone_type = parts[1].strip()[0:1] self.phone = parts[1].strip()[1:] if not parts[2].strip().startswith(&quot;&gt;pm &quot;): raise IOError(&quot;Unexpected line: &quot; + text) self.pm_type = parts[2].strip()[4:5] self.pm = parts[2].strip()[5:] if len(parts) == 5: if not parts[3].strip().startswith(&quot;&gt;w &quot;): raise IOError(&quot;Unexpected line: &quot; + text) self.word = fix_text(parts[3].strip()[3:]) if parts[-1].strip().endswith(&quot; sec&quot;): self.seconds = parts[-1].strip()[0:-4] def __repr__(self): parts = [] parts.append(f&quot;type: {self.type}&quot;) parts.append(f&quot;frame: {self.frame}&quot;) if self.type != &#39;E&#39;: parts.append(f&quot;phone: {self.phone}&quot;) if &#39;word&#39; in self.__dict__: parts.append(f&quot;word: {self.word}&quot;) if &#39;pm_type&#39; in self.__dict__: parts.append(f&quot;pm_type: {self.pm_type}&quot;) if &#39;pm&#39; in self.__dict__: parts.append(f&quot;pm: {self.pm}&quot;) parts.append(f&quot;sec: {self.seconds}&quot;) return f&quot;FR(&quot; + &quot;, &quot;.join(parts) + &quot;)&quot; . class Mix(): def __init__(self, filepath): self.fr = [] with open(filepath) as inpf: saw_text = False saw_phoneme = False saw_labels = False for line in inpf.readlines(): if line.startswith(&quot;Waxholm dialog.&quot;): self.filepath = line[15:].strip() if line.startswith(&quot;TEXT:&quot;): saw_text = True if saw_text: self.text = fix_text(line.strip()) saw_text = False if line.startswith(&quot;FR &quot;): if saw_labels: saw_labels = False self.fr.append(FR(line)) if line.startswith(&quot;Labels: &quot;): self.labels = line[8:].strip() saw_labels = True if saw_labels and line.startswith(&quot; &quot;): self.labels += line.strip() . def smp_probe(filename): with open(filename, &quot;rb&quot;) as f: return f.read(9) == b&quot;file=samp&quot; . def smp_headers(filename): with open(filename, &quot;rb&quot;) as f: f.seek(0) raw_headers = f.read(1024) raw_headers = raw_headers.rstrip(b&#39; x00&#39;) asc_headers = raw_headers.decode(&quot;ascii&quot;) asc_headers.rstrip(&#39; x00&#39;) tmp = [a for a in asc_headers.split(&quot; r n&quot;)] back = -1 while abs(back) &gt; len(tmp) + 1: if tmp[back] == &#39;=&#39;: break back -= 1 tmp = tmp[0:back-1] return dict(a.split(&quot;=&quot;) for a in tmp) . import soundfile as sf def smp_read_sf(filename): headers = smp_headers(filename) if headers[&quot;msb&quot;] == &quot;last&quot;: ENDIAN = &quot;LITTLE&quot; else: ENDIAN = &quot;BIG&quot; data, sr = sf.read(filename, channels=int(headers[&quot;nchans&quot;]), samplerate=16000, endian=ENDIAN, start=512, dtype=&quot;int16&quot;, format=&quot;RAW&quot;, subtype=&quot;PCM_16&quot;) return (data, sr) . def write_wav(filename, arr): import wave with wave.open(filename, &quot;w&quot;) as f: f.setnchannels(1) f.setsampwidth(2) f.setframerate(16000) f.writeframes(arr) arr, sr = smp_read_sf(&quot;/Users/joregan/Playing/waxholm/scenes_formatted//fp2060/fp2060.pr.09.smp&quot;) write_wav(&quot;out.wav&quot;, arr) .",
            "url": "https://jimregan.github.io/notes/waxholm/2022/02/01/waxholm.html",
            "relUrl": "/waxholm/2022/02/01/waxholm.html",
            "date": " • Feb 1, 2022"
        }
        
    
  
    
        ,"post83": {
            "title": "Extract Riksdag videos from API",
            "content": "import requests import json . sample = requests.get(&quot;https://data.riksdagen.se/api/mhs-vodapi?H210308&quot;) . data = json.loads(sample.text) . data[&#39;videodata&#39;][0] . def viddata_get_single_stream(videodata, hires=True): videos = [] if videodata is None: return [] if &#39;streams&#39; not in videodata: #raise Exception(&quot;videodata is missing &#39;streams&#39;&quot;) return [] if videodata[&#39;streams&#39;] is None: return [] if &#39;files&#39; not in videodata[&#39;streams&#39;]: #raise Exception(&quot;videodata[&#39;streams&#39;] is missing &#39;files&#39;&quot;) return [] if type(videodata[&#39;streams&#39;][&#39;files&#39;]) == list: for vfile in videodata[&#39;streams&#39;][&#39;files&#39;]: for bw in vfile[&#39;bandwidth&#39;]: if hires and bw[&#39;name&#39;] == &#39;Hög kvalitet&#39;: videos.append(bw[&#39;downloadurl&#39;]) elif not hires and bw[&#39;name&#39;] == &#39;Låg kvalitet&#39;: videos.append(bw[&#39;downloadurl&#39;]) else: #raise Exception(f&quot;Expected a list, got {type(videodata[&#39;streams&#39;][&#39;files&#39;])}&quot;) return [] return videos def viddata_get_streams(videodata, hires=True): output = [] if &#39;videodata&#39; not in videodata: #raise Exception(&quot;&#39;videodata&#39; missing&quot;) return [] for vdata in videodata[&#39;videodata&#39;]: output += viddata_get_single_stream(vdata, hires) return output . def fix_speaker_name(name, party): if name.endswith(f&quot; ({party})&quot;): name = name[0:name.rfind(f&quot; ({party})&quot;)] return name def extract_speakers(data): speakers = [] for viddata in data[&#39;videodata&#39;]: for speaker in viddata[&#39;speakers&#39;]: speaker[&#39;text&#39;] = fix_speaker_name(speaker[&#39;text&#39;], speaker[&#39;party&#39;]) speakers.append(speaker) return speakers #print(data[&#39;videodata&#39;][0]) speakers = extract_speakers(data) viddata_get_streams(data) . [&#39;https://mhdownload.riksdagen.se/VOD1/PAL169/2442207160019939321_480p.mp4&#39;] . viddata_get_streams(data, False) . [] . from pathlib import Path import glob urls = [] for f in glob.glob(&#39;/Users/joregan/riksdag/riksdag-api-out/[GH]*&#39;): fpath = Path(f) if not fpath.is_file(): continue with open(f) as inf: data = json.load(inf) for url in viddata_get_streams(data): urls.append(url) . with open(&#39;/Users/joregan/riksdag/riksdag-api-out/video-urls.txt&#39;, &#39;w&#39;) as outf: for url in urls: outf.write(url + &quot; n&quot;) .",
            "url": "https://jimregan.github.io/notes/riksdag/speech/2022/01/31/extract-riksdag-videos-from-api.html",
            "relUrl": "/riksdag/speech/2022/01/31/extract-riksdag-videos-from-api.html",
            "date": " • Jan 31, 2022"
        }
        
    
  
    
        ,"post84": {
            "title": "Interesting links, 23/01/2022",
            "content": "data2vec, paper, code . r/panelshows . jik876/hifi-gan . Hindi TTS demo space . Open-Speech-EkStep/vakyansh-tts . mjansche/ctc_sampling . X-SAMPA to IPA converter . Lexin multilingual dictionary, data . Sprakbanken_Swe lexicon . clean_and_segment_data.sh . DT2112 . Bostadsförmedlingen i Stockholm AB . Continual learning using lattice-free MMI for speech recognition .",
            "url": "https://jimregan.github.io/notes/links/2022/01/23/misc-links.html",
            "relUrl": "/links/2022/01/23/misc-links.html",
            "date": " • Jan 23, 2022"
        }
        
    
  
    
        ,"post85": {
            "title": "Fix NST lexicon accents",
            "content": "_VOWELS = [ &quot;}:&quot;, &quot;2:&quot;, &quot;9&quot;, &quot;a&quot;, &quot;a*U&quot;, &quot;A:&quot;, &quot;e&quot;, &quot;E&quot;, &quot;E*U&quot;, &quot;e:&quot;, &quot;E:&quot;, &quot;I&quot;, &quot;i:&quot;, &quot;O&quot;, &quot;o:&quot;, &quot;U&quot;, &quot;u:&quot;, &quot;u0&quot;, &quot;Y&quot;, &quot;y:&quot; ] . _SAMPLE = &quot;&quot;&quot; AFTENPOSTEN &quot;a f t e n %p O s t e n AFTONBLADET &quot;a f t O n %b l A: d e t AFTONBLADETS &quot;a f t O n %b l A: d e t s AFTONBRISVÄGEN &quot;a f t O n b r i: s %v E: g e n AFTONGATAN &quot;a f t O N %g A: t a n AFTONVÄGEN &quot;a f t O n %v E: g e n AFZELIIVÄGEN a f &quot;s e: l I %v E: g e n AFZELIUS a f &quot;s e: l I u0 s AGADIR a g a &quot;d i: r AGAMEMNON a g a &quot;m E m n O n AGARD &quot;A: g a d` AGARDH &quot;A: g a d` AGARDHSGATAN &quot;A: g a d` s` %g A: t a n AGARDSSON &quot;A: g a d` s` O n AGASSI a &quot;g a s I AGASSIS a &quot;g a s I s AGATA a &quot;g A: t a AGATAS a &quot;g A: t a s &quot;&quot;&quot; . def split_phone(inphone): _STRESSMARKS = [&#39;&quot;&quot;&#39;, &#39;&quot;&#39;, &#39;%&#39;] outmark = &#39;&#39; outphone = inphone for sm in _STRESSMARKS: if inphone.startswith(sm): outmark = sm outphone = inphone.replace(sm, &#39;&#39;) return (outmark, outphone) . out_words = [] for line in _SAMPLE.split(&#39; n&#39;): if line == &#39;&#39;: continue phones_out = [] parts = line.split(&#39; t&#39;) assert len(parts) == 2 current_mark = &#39;&#39; for phone in parts[1].split(&#39; &#39;): tmp_mark, actual_phone = split_phone(phone) if tmp_mark != &#39;&#39;: current_mark = tmp_mark if actual_phone in _VOWELS and current_mark != &#39;&#39;: phones_out.append(current_mark + actual_phone) current_mark = &#39;&#39; else: phones_out.append(actual_phone) new_phones = &#39; &#39;.join(phones_out) out_words.append(f&quot;{parts[0]} t{new_phones}&quot;) . out_words . [&#39;AFTENPOSTEN t&#34;a f t e n p %O s t e n&#39;, &#39;AFTONBLADET t&#34;a f t O n b l %A: d e t&#39;, &#39;AFTONBLADETS t&#34;a f t O n b l %A: d e t s&#39;, &#39;AFTONBRISVÄGEN t&#34;a f t O n b r i: s v %E: g e n&#39;, &#39;AFTONGATAN t&#34;a f t O N g %A: t a n&#39;, &#39;AFTONVÄGEN t&#34;a f t O n v %E: g e n&#39;, &#39;AFZELIIVÄGEN ta f s &#34;e: l I v %E: g e n&#39;, &#39;AFZELIUS ta f s &#34;e: l I u0 s&#39;, &#39;AGADIR ta g a d &#34;i: r&#39;, &#39;AGAMEMNON ta g a m &#34;E m n O n&#39;, &#39;AGARD t&#34;A: g a d`&#39;, &#39;AGARDH t&#34;A: g a d`&#39;, &#39;AGARDHSGATAN t&#34;A: g a d` s` g %A: t a n&#39;, &#39;AGARDSSON t&#34;A: g a d` s` O n&#39;, &#39;AGASSI ta g &#34;a s I&#39;, &#39;AGASSIS ta g &#34;a s I s&#39;, &#39;AGATA ta g &#34;A: t a&#39;, &#39;AGATAS ta g &#34;A: t a s&#39;] .",
            "url": "https://jimregan.github.io/notes/g2p/nst/2022/01/20/swe-lexicon-fix-accents.html",
            "relUrl": "/g2p/nst/2022/01/20/swe-lexicon-fix-accents.html",
            "date": " • Jan 20, 2022"
        }
        
    
  
    
        ,"post86": {
            "title": "Convert NST Swedish pronunciation lexicon to JSON",
            "content": "Set up field reading . import csv . !pip install pyicu . field_names = [ &quot;orthography&quot;, &quot;extended_pos&quot;, &quot;morphology&quot;, &quot;decomp&quot;, &quot;decpos&quot;, &quot;source&quot;, &quot;language_code&quot;, &quot;garbage&quot;, &quot;domain&quot;, &quot;abbr_acr&quot;, &quot;expansion&quot;, &quot;transliteration1&quot;, &quot;certainty_trans_1&quot;, &quot;status_trans_1&quot;, &quot;language_code_trans_1&quot;, &quot;transliteration2&quot;, &quot;certainty_trans_2&quot;, &quot;status_trans_2&quot;, &quot;language_code_trans_2&quot;, &quot;transliteration3&quot;, &quot;certainty_trans_3&quot;, &quot;status_trans_3&quot;, &quot;language_code_trans_3&quot;, &quot;transliteration4&quot;, &quot;certainty_trans_4&quot;, &quot;status_trans_4&quot;, &quot;language_code_trans_4&quot;, &quot;auto_gen_variants&quot;, &quot;set_id&quot;, &quot;set_name&quot;, &quot;style_status&quot;, &quot;inflector_role&quot;, &quot;lemma&quot;, &quot;inflection_rule&quot;, &quot;morph_label&quot;, &quot;compounder_code&quot;, &quot;semantic_info&quot;, &quot;available_field1&quot;, &quot;available_field2&quot;, &quot;available_field3&quot;, &quot;available_field4&quot;, &quot;available_field5&quot;, &quot;available_field6&quot;, &quot;available_field7&quot;, &quot;available_field8&quot;, &quot;available_field9&quot;, &quot;frequency&quot;, &quot;original_orthography&quot;, &quot;comment_field&quot;, &quot;update_info&quot;, &quot;unique_id&quot; ] . Get data . !wget http://www.nb.no/sbfil/leksikalske_databaser/leksikon/sv.leksikon.tar.gz -O /tmp/sv.leksikon.tar.gz . URL transformed to HTTPS due to an HSTS policy --2023-01-24 19:57:44-- https://www.nb.no/sbfil/leksikalske_databaser/leksikon/sv.leksikon.tar.gz Resolving www.nb.no (www.nb.no)... 158.39.129.53 Connecting to www.nb.no (www.nb.no)|158.39.129.53|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 22041470 (21M) [application/octet-stream] Saving to: ‘/tmp/sv.leksikon.tar.gz’ /tmp/sv.leksikon.ta 100%[===================&gt;] 21,02M 3,54MB/s in 5,4s 2023-01-24 19:57:50 (3,92 MB/s) - ‘/tmp/sv.leksikon.tar.gz’ saved [22041470/22041470] . import tarfile with tarfile.open(&quot;/tmp/sv.leksikon.tar.gz&quot;) as tar: f = tar.extractfile(&quot;NST svensk leksikon/swe030224NST.pron/swe030224NST.pron&quot;) prondata = f.read() prondata = prondata.decode(&#39;latin1&#39;) . Set up transliterator . TRANSLIT = &quot;&quot;&quot; n ` → ɳ ; s ` → ʂ ; l ` → ɭ ; t ` → ʈ ; d ` → ɖ ; A → ɑ ; O → ɔ ; I → ɪ ; E * U → e u2040 ʊ ; E → ɛ ; U → ʊ ; Y → ʏ ; 2 → ø ; 9 → ø ; u 0 → ɵ ; N → ŋ ; &#39;&quot;&quot;&#39; → ² ; &#39;&quot;&#39; → ˈ ; % → ˌ ; : → ː ; $ → . ; g → ɡ ; s &#39; → ɕ ; x → ɧ ; * → u2040 ; &quot;&quot;&quot; . import icu def transliterator_from_rules(name, rules): fromrules = icu.Transliterator.createFromRules(name, rules) icu.Transliterator.registerInstance(fromrules) return icu.Transliterator.createInstance(name) . swelex_trans = transliterator_from_rules(&quot;swelex_trans&quot;, TRANSLIT) . assert swelex_trans.transliterate(&#39;&quot;&quot;bA:n`s`$%ma$man&#39;) == &quot;²bɑːɳʂ.ˌma.man&quot; assert swelex_trans.transliterate(&#39;&quot;b9r$mIN$ham&#39;) == &quot;ˈbør.mɪŋ.ham&quot; assert swelex_trans.transliterate(&#39;&quot;bI$rU&#39;) == &quot;ˈbɪ.rʊ&quot; assert swelex_trans.transliterate(&#39;&quot;&quot;bIsp$%go:$d`en&#39;) == &quot;²bɪsp.ˌɡoː.ɖen&quot; assert swelex_trans.transliterate(&#39;&quot;x A:l&#39;) == &quot;ˈɧɑːl&quot; assert swelex_trans.transliterate(&quot; &quot;s&#39;u:$lens&quot;) == &quot;ˈɕuː.lens&quot; assert swelex_trans.transliterate(&#39;a$&quot;lE*U$te$n`a&#39;) == &#39;a.ˈle⁀ʊ.te.ɳa&#39; assert swelex_trans.transliterate(&#39;&quot;fu0l&#39;) == &#39;ˈfɵl&#39; . def collapse_available_fields(data): output = [] for i in range(1, 10): if data[f&quot;available_field{i}&quot;] != &quot;&quot;: output.append(data[f&quot;available_field{i}&quot;]) del data[f&quot;available_field{i}&quot;] data[&quot;available_fields&quot;] = output return data . def collapse_transliterations(data): output = [] for i in range(1, 5): if data[f&quot;transliteration{i}&quot;] != &quot;&quot;: tmp = {} tmp[&quot;transliteration&quot;] = data[f&quot;transliteration{i}&quot;] tmp[&quot;ipa&quot;] = swelex_trans.transliterate(data[f&quot;transliteration{i}&quot;]) tmp[&quot;certainty&quot;] = data[f&quot;certainty_trans_{i}&quot;] tmp[&quot;status&quot;] = data[f&quot;status_trans_{i}&quot;] tmp[&quot;language_code&quot;] = data[f&quot;language_code_trans_{i}&quot;] output.append(tmp) del data[f&quot;transliteration{i}&quot;] del data[f&quot;certainty_trans_{i}&quot;] del data[f&quot;status_trans_{i}&quot;] del data[f&quot;language_code_trans_{i}&quot;] data[&quot;transliterations&quot;] = output return data . import json import io with open(&quot;svlex.json&quot;, &quot;w&quot;) as outf: swelexf = io.StringIO(prondata) swelex = csv.DictReader(swelexf, delimiter=&#39;;&#39;, fieldnames=field_names, quoting=csv.QUOTE_NONE) for row in swelex: row[&quot;decomp&quot;] = [f for f in row[&quot;decomp&quot;].split(&quot;+&quot;) if f != &quot;&quot;] row = collapse_available_fields(row) row = collapse_transliterations(row) jsonstr = json.dumps(row) outf.write(jsonstr + &quot; n&quot;) .",
            "url": "https://jimregan.github.io/notes/nst/swedish/pronunciation/icu/2022/01/12/convert-nst-lexicon.html",
            "relUrl": "/nst/swedish/pronunciation/icu/2022/01/12/convert-nst-lexicon.html",
            "date": " • Jan 12, 2022"
        }
        
    
  
    
        ,"post87": {
            "title": "Sweachum reader",
            "content": "SAMPLE = &quot;&quot;&quot; &lt;corpus id=&quot;sweachum&quot;&gt; &lt;text datefrom=&quot;20120101&quot; dateto=&quot;20121231&quot; timefrom=&quot;000000&quot; timeto=&quot;235959&quot; lix=&quot;55.44&quot; ovix=&quot;65.03&quot; nk=&quot;2.01&quot; subject=&quot;Filosofi&quot; type=&quot;PhD&quot; date=&quot;2012&quot;&gt; &lt;sentence id=&quot;b60ceaf85-b604d04ed&quot; _geocontext=&quot;|&quot;&gt; &lt;ne ex=&quot;ENAMEX&quot; type=&quot;PRS&quot; subtype=&quot;HUM&quot; name=&quot;Marton&quot;&gt; &lt;w pos=&quot;PM&quot; msd=&quot;PM.NOM&quot; lemma=&quot;|&quot; lex=&quot;|&quot; sense=&quot;|&quot; prefix=&quot;|&quot; suffix=&quot;|&quot; compwf=&quot;|&quot; complemgram=&quot;|&quot; ref=&quot;01&quot; deprel=&quot;ROOT&quot;&gt;Marton&lt;/w&gt; &lt;/ne&gt; &lt;w pos=&quot;MID&quot; msd=&quot;MID&quot; lemma=&quot;|&quot; lex=&quot;|&quot; sense=&quot;|&quot; prefix=&quot;|&quot; suffix=&quot;|&quot; compwf=&quot;|&quot; complemgram=&quot;|&quot; ref=&quot;02&quot; dephead=&quot;01&quot; deprel=&quot;IK&quot;&gt;,&lt;/w&gt; &lt;w pos=&quot;PM&quot; msd=&quot;PM.NOM&quot; lemma=&quot;|&quot; lex=&quot;|&quot; sense=&quot;|&quot; prefix=&quot;|&quot; suffix=&quot;|&quot; compwf=&quot;|&quot; complemgram=&quot;|&quot; ref=&quot;03&quot; dephead=&quot;01&quot; deprel=&quot;ET&quot;&gt;F.&lt;/w&gt; &lt;w pos=&quot;KN&quot; msd=&quot;KN.AN&quot; lemma=&quot;|&amp;amp;|&quot; lex=&quot;|o..kna.2|&quot; sense=&quot;|och..1:-1.000|&quot; prefix=&quot;|&quot; suffix=&quot;|&quot; compwf=&quot;|&quot; complemgram=&quot;|&quot; ref=&quot;04&quot; dephead=&quot;03&quot; deprel=&quot;HD&quot;&gt;&amp;amp;&lt;/w&gt; &lt;w pos=&quot;NN&quot; msd=&quot;NN.UTR.SIN.IND.NOM&quot; lemma=&quot;|&quot; lex=&quot;|&quot; sense=&quot;|&quot; prefix=&quot;|&quot; suffix=&quot;|&quot; compwf=&quot;|&quot; complemgram=&quot;|&quot; ref=&quot;05&quot; dephead=&quot;03&quot; deprel=&quot;HD&quot;&gt;amp&lt;/w&gt; &lt;w pos=&quot;MID&quot; msd=&quot;MID&quot; lemma=&quot;|&quot; lex=&quot;|&quot; sense=&quot;|&quot; prefix=&quot;|&quot; suffix=&quot;|&quot; compwf=&quot;|&quot; complemgram=&quot;|&quot; ref=&quot;06&quot; dephead=&quot;01&quot; deprel=&quot;IS&quot;&gt;;&lt;/w&gt; &lt;w pos=&quot;PM&quot; msd=&quot;PM.NOM&quot; lemma=&quot;|&quot; lex=&quot;|&quot; sense=&quot;|&quot; prefix=&quot;|&quot; suffix=&quot;|&quot; compwf=&quot;|&quot; complemgram=&quot;|&quot; ref=&quot;07&quot; dephead=&quot;01&quot; deprel=&quot;AN&quot;&gt;Booth&lt;/w&gt; &lt;w pos=&quot;MID&quot; msd=&quot;MID&quot; lemma=&quot;|&quot; lex=&quot;|&quot; sense=&quot;|&quot; prefix=&quot;|&quot; suffix=&quot;|&quot; compwf=&quot;|&quot; complemgram=&quot;|&quot; ref=&quot;08&quot; dephead=&quot;07&quot; deprel=&quot;IK&quot;&gt;,&lt;/w&gt; &lt;w pos=&quot;PM&quot; msd=&quot;PM.NOM&quot; lemma=&quot;|&quot; lex=&quot;|&quot; sense=&quot;|&quot; prefix=&quot;|&quot; suffix=&quot;|&quot; compwf=&quot;|&quot; complemgram=&quot;|&quot; ref=&quot;09&quot; dephead=&quot;07&quot; deprel=&quot;ET&quot;&gt;S&lt;/w&gt; &lt;w pos=&quot;MAD&quot; msd=&quot;MAD&quot; lemma=&quot;|&quot; lex=&quot;|&quot; sense=&quot;|&quot; prefix=&quot;|&quot; suffix=&quot;|&quot; compwf=&quot;|&quot; complemgram=&quot;|&quot; ref=&quot;10&quot; dephead=&quot;01&quot; deprel=&quot;IP&quot;&gt;.&lt;/w&gt; &lt;/sentence&gt; &lt;/text&gt; &lt;/corpus&gt; &quot;&quot;&quot; . Corpus is here, CC BY 4.0 . import xml.etree.ElementTree as ET import xml.sax.saxutils as saxutils import io . source = io.StringIO(SAMPLE) tree = ET.parse(source) root = tree.getroot() . words = [] for word in root.findall(&#39;.//w&#39;): words.append(word.text.strip()) . words . [&#39;Marton&#39;, &#39;,&#39;, &#39;F.&#39;, &#39;&amp;&#39;, &#39;amp&#39;, &#39;;&#39;, &#39;Booth&#39;, &#39;,&#39;, &#39;S&#39;, &#39;.&#39;] . def _clean_amps(inlist): htmlamp = [&#39;&amp;&#39;, &#39;amp&#39;, &#39;;&#39;] outlist = [] i = 0 while i &lt; len(inlist): if inlist[i:i+3] == htmlamp: outlist.append(&#39;&amp;&#39;) i += 3 continue else: outlist.append(inlist[i]) i += 1 return outlist . _clean_amps(words) . [&#39;Marton&#39;, &#39;,&#39;, &#39;F.&#39;, &#39;&amp;&#39;, &#39;Booth&#39;, &#39;,&#39;, &#39;S&#39;, &#39;.&#39;] . def _get_or_blank(text): if text == &quot;|&quot;: return &quot;&quot; if text[0:1] == &quot;|&quot; and text[-1:] == &quot;|&quot;: text = text[1:-1] return text class Word(): def __init__(self, text, pos, msd, lemma, lex, sense, prefix, suffix, compwf, complemgram, ref, dephead, deprel): self.text = text self.pos = _get_or_blank(pos) self.msd = _get_or_blank(msd) self.lex = _get_or_blank(lex) .",
            "url": "https://jimregan.github.io/notes/sweachum/corpus/2022/01/10/sweachum.html",
            "relUrl": "/sweachum/corpus/2022/01/10/sweachum.html",
            "date": " • Jan 10, 2022"
        }
        
    
  
    
        ,"post88": {
            "title": "Clean Irish text",
            "content": "def _ga_lc_word(text): if text[0:1] in &quot;nt&quot; and text[1:2] in &quot;AÁEÉIÍOÓUÚ&quot;: return text[0:1] + &quot;-&quot; + text[1:].lower() else: return text.lower() def ga_lower(text): words = [_ga_lc_word(word) for word in text.split()] return &quot; &quot;.join(words) . test = &quot;Cuairt an tAthair&quot; assert ga_lower(test) == &quot;cuairt an t-athair&quot; . import re def clean_text(text): # keep only word-internal apostrophes text = re.sub(&quot;^&#39;+&quot;, &quot;&quot;, text) text = re.sub(&quot;[&#39;]+$&quot;, &quot;&quot;, text) text = text.replace(&quot;&#39; &quot;, &quot; &quot;).replace(&quot; &#39;&quot;, &quot; &quot;) text = text.replace(&quot;’&quot;, &quot;&#39;&quot;) text = re.sub(&quot;[‘“” &quot; ( ) [ ] { }]&quot;, &quot;&quot;, text) # keep punctuation that can correspond to silence text = re.sub(&quot;([,; .!?])&quot;, &quot; 1&quot;, text) # leave spaced hyphens, which also can be silences, except at EOS text = re.sub(&quot; -$&quot;, &quot;&quot;, text) return ga_lower(text) . test = &quot;&#39;cuairt (an) “tAthair”&#39;&#39;&quot; assert clean_text(test) == &quot;cuairt an t-athair&quot; . test = &quot;&#39;cuairt, (an) “tAthair”!&quot; assert clean_text(test) == &quot;cuairt , an t-athair !&quot; . test = &quot;&#39;cuairt, (an) “tAthair”! -&quot; assert clean_text(test) == &quot;cuairt , an t-athair !&quot; . Actually using it. . from pathlib import Path . OUT = Path(&quot;&lt;SNIP&gt;&quot;) SRC = Path(&quot;&lt;SNIP&gt;&quot;) . for filename in SRC.glob(&quot;*.txt&quot;): base = filename.stem wav = OUT / f&quot;{base}.wav&quot; if wav.is_file(): out = OUT / f&quot;{base}.txt&quot; with open(out, &quot;w&quot;) as outf, open(filename) as inf: text = inf.read() clean = clean_text(text) outf.write(clean) .",
            "url": "https://jimregan.github.io/notes/irish/cleaning/alignment/2021/12/06/clean-irish-for-mfa-with-silences.html",
            "relUrl": "/irish/cleaning/alignment/2021/12/06/clean-irish-for-mfa-with-silences.html",
            "date": " • Dec 6, 2021"
        }
        
    
  
    
        ,"post89": {
            "title": "NER with gaELECTRA",
            "content": "This is a lightly edited version of this notebook. . If you&#39;re opening this Notebook on colab, you will probably need to install 🤗 Transformers and 🤗 Datasets. Uncomment the following cell and run it. . %%capture !pip install datasets transformers seqeval . If you&#39;re opening this notebook locally, make sure your environment has an install from the last version of those libraries. . To be able to share your model with the community and generate results like the one shown in the picture below via the inference API, there are a few more steps to follow. . First you have to store your authentication token from the Hugging Face website (sign up here if you haven&#39;t already!) then execute the following cell and input your username and password: . (Huggingface notebooks skip this bit, but you need to set credential.helper before anything else works). . !git config --global credential.helper store . from huggingface_hub import notebook_login notebook_login() . Login successful Your token has been saved to /root/.huggingface/token . Then you need to install Git-LFS. Uncomment the following instructions: . !apt install git-lfs . Reading package lists... Done Building dependency tree Reading state information... Done git-lfs is already the newest version (2.3.4-1). 0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded. . Make sure your version of Transformers is at least 4.11.0 since the functionality was introduced in that version: . import transformers print(transformers.__version__) . 4.12.5 . You can find a script version of this notebook to fine-tune your model in a distributed fashion using multiple GPUs or TPUs here. . Fine-tuning a model on a token classification task . In this notebook, we will see how to fine-tune one of the 🤗 Transformers model to a token classification task, which is the task of predicting a label for each token. . . The most common token classification tasks are: . NER (Named-entity recognition) Classify the entities in the text (person, organization, location...). | POS (Part-of-speech tagging) Grammatically classify the tokens (noun, verb, adjective...) | Chunk (Chunking) Grammatically classify the tokens and group them into &quot;chunks&quot; that go together | . We will see how to easily load a dataset for these kinds of tasks and use the Trainer API to fine-tune a model on it. . This notebook is built to run on any token classification task, with any model checkpoint from the Model Hub as long as that model has a version with a token classification head and a fast tokenizer (check on this table if this is the case). It might just need some small adjustments if you decide to use a different dataset than the one used here. Depending on you model and the GPU you are using, you might need to adjust the batch size to avoid out-of-memory errors. Set those three parameters, then the rest of the notebook should run smoothly: . task = &quot;ner&quot; # Should be one of &quot;ner&quot;, &quot;pos&quot; or &quot;chunk&quot; model_checkpoint = &quot;DCU-NLP/electra-base-irish-cased-generator-v1&quot; batch_size = 16 . Loading the dataset . We will use the 🤗 Datasets library to download the data and get the metric we need to use for evaluation (to compare our model to the benchmark). This can be easily done with the functions load_dataset and load_metric. . from datasets import load_dataset, load_metric . For our example here, we&#39;ll use the CONLL 2003 dataset. The notebook should work with any token classification dataset provided by the 🤗 Datasets library. If you&#39;re using your own dataset defined from a JSON or csv file (see the Datasets documentation on how to load them), it might need some adjustments in the names of the columns used. . datasets = load_dataset(&quot;wikiann&quot;, &quot;ga&quot;) . Reusing dataset wikiann (/root/.cache/huggingface/datasets/wikiann/ga/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e) . The datasets object itself is DatasetDict, which contains one key for the training, validation and test set. . datasets . DatasetDict({ validation: Dataset({ features: [&#39;tokens&#39;, &#39;ner_tags&#39;, &#39;langs&#39;, &#39;spans&#39;], num_rows: 1000 }) test: Dataset({ features: [&#39;tokens&#39;, &#39;ner_tags&#39;, &#39;langs&#39;, &#39;spans&#39;], num_rows: 1000 }) train: Dataset({ features: [&#39;tokens&#39;, &#39;ner_tags&#39;, &#39;langs&#39;, &#39;spans&#39;], num_rows: 1000 }) }) . We can see the training, validation and test sets all have a column for the tokens (the input texts split into words) and one column of labels for each kind of task we introduced before. . To access an actual element, you need to select a split first, then give an index: . datasets[&quot;train&quot;][0] . {&#39;langs&#39;: [&#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;], &#39;ner_tags&#39;: [0, 1, 2, 2, 0, 0, 0, 0, 5, 0, 0, 0], &#39;spans&#39;: [&#39;PER: Pádraig Mac Piarais&#39;, &#39;LOC: Éireannach&#39;], &#39;tokens&#39;: [&#39;**&#39;, &#39;Pádraig&#39;, &#39;Mac&#39;, &#39;Piarais&#39;, &#39;,&#39;, &#39;36&#39;, &#39;,&#39;, &#39;réabhlóidí&#39;, &#39;Éireannach&#39;, &#39;agus&#39;, &#39;[[file&#39;, &#39;.&#39;]} . The labels are already coded as integer ids to be easily usable by our model, but the correspondence with the actual categories is stored in the features of the dataset: . datasets[&quot;train&quot;].features[f&quot;ner_tags&quot;] . Sequence(feature=ClassLabel(num_classes=7, names=[&#39;O&#39;, &#39;B-PER&#39;, &#39;I-PER&#39;, &#39;B-ORG&#39;, &#39;I-ORG&#39;, &#39;B-LOC&#39;, &#39;I-LOC&#39;], names_file=None, id=None), length=-1, id=None) . So for the NER tags, 0 corresponds to &#39;O&#39;, 1 to &#39;B-PER&#39; etc... On top of the &#39;O&#39; (which means no special entity), there are four labels for NER here, each prefixed with &#39;B-&#39; (for beginning) or &#39;I-&#39; (for intermediate), that indicate if the token is the first one for the current group with the label or not: . &#39;PER&#39; for person | &#39;ORG&#39; for organization | &#39;LOC&#39; for location | &#39;MISC&#39; for miscellaneous | . Since the labels are lists of ClassLabel, the actual names of the labels are nested in the feature attribute of the object above: . label_list = datasets[&quot;train&quot;].features[f&quot;{task}_tags&quot;].feature.names label_list . [&#39;O&#39;, &#39;B-PER&#39;, &#39;I-PER&#39;, &#39;B-ORG&#39;, &#39;I-ORG&#39;, &#39;B-LOC&#39;, &#39;I-LOC&#39;] . To get a sense of what the data looks like, the following function will show some examples picked randomly in the dataset (automatically decoding the labels in passing). . from datasets import ClassLabel, Sequence import random import pandas as pd from IPython.display import display, HTML def show_random_elements(dataset, num_examples=10): assert num_examples &lt;= len(dataset), &quot;Can&#39;t pick more elements than there are in the dataset.&quot; picks = [] for _ in range(num_examples): pick = random.randint(0, len(dataset)-1) while pick in picks: pick = random.randint(0, len(dataset)-1) picks.append(pick) df = pd.DataFrame(dataset[picks]) for column, typ in dataset.features.items(): if isinstance(typ, ClassLabel): df[column] = df[column].transform(lambda i: typ.names[i]) elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel): df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x]) display(HTML(df.to_html())) . show_random_elements(datasets[&quot;train&quot;]) . tokens ner_tags langs spans . 0 [Burghley, House, ,, Belton, House] | [B-ORG, I-ORG, O, B-ORG, I-ORG] | [ga, ga, ga, ga, ga] | [ORG: Burghley House, ORG: Belton House] | . 1 [Ollscoil, Chathair, Bhaile, Átha, Cliath] | [B-ORG, I-ORG, I-ORG, I-ORG, I-ORG] | [ga, ga, ga, ga, ga] | [ORG: Ollscoil Chathair Bhaile Átha Cliath] | . 2 [Dúchasach, do, réigiún, na, Meánmhara, .] | [O, O, O, B-LOC, I-LOC, O] | [ga, ga, ga, ga, ga, ga] | [LOC: na Meánmhara] | . 3 [Páirc, an, Chrócaigh, ,, Baile, Átha, Cliath] | [B-ORG, I-ORG, I-ORG, O, B-LOC, I-LOC, I-LOC] | [ga, ga, ga, ga, ga, ga, ga] | [ORG: Páirc an Chrócaigh, LOC: Baile Átha Cliath] | . 4 [Tráigh, Mhór, ,, An, Tuirc] | [B-ORG, I-ORG, O, B-LOC, I-LOC] | [ga, ga, ga, ga, ga] | [ORG: Tráigh Mhór, LOC: An Tuirc] | . 5 [Bhí, turas, An, Ríocht, Aontaithe, agus, Éire, acu, ón, Eanair, go, dtí, mBealtaine, .] | [O, O, B-LOC, I-LOC, I-LOC, O, B-LOC, O, O, O, O, O, O, O] | [ga, ga, ga, ga, ga, ga, ga, ga, ga, ga, ga, ga, ga, ga] | [LOC: An Ríocht Aontaithe, LOC: Éire] | . 6 [Tá, an, staid, tógtha, ar, shuíomh, Bhóthair, Lansdúin, .] | [O, O, O, O, O, O, B-ORG, I-ORG, O] | [ga, ga, ga, ga, ga, ga, ga, ga, ga] | [ORG: Bhóthair Lansdúin] | . 7 [athsheoladh, Pól, I, na, Rúise] | [O, B-PER, I-PER, I-PER, I-PER] | [ga, ga, ga, ga, ga] | [PER: Pól I na Rúise] | . 8 [Liam, Ó, Leathlobhair] | [B-PER, I-PER, I-PER] | [ga, ga, ga] | [PER: Liam Ó Leathlobhair] | . 9 [athsheoladh, Séamas, II, Shasana] | [O, B-PER, I-PER, I-PER] | [ga, ga, ga, ga] | [PER: Séamas II Shasana] | . Preprocessing the data . Before we can feed those texts to our model, we need to preprocess them. This is done by a 🤗 Transformers Tokenizer which will (as the name indicates) tokenize the inputs (including converting the tokens to their corresponding IDs in the pretrained vocabulary) and put it in a format the model expects, as well as generate the other inputs that model requires. . To do all of this, we instantiate our tokenizer with the AutoTokenizer.from_pretrained method, which will ensure: . we get a tokenizer that corresponds to the model architecture we want to use, | we download the vocabulary used when pretraining this specific checkpoint. | . That vocabulary will be cached, so it&#39;s not downloaded again the next time we run the cell. . from transformers import AutoTokenizer tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, add_prefix_space=True) . loading configuration file https://huggingface.co/DCU-NLP/electra-base-irish-cased-generator-v1/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/5239b8cd72f5caa8610a21bf2b225bb65fe3529da8491628fe2fb57a9feb5807.f9336c0d71d0b04cbbee5746d7d5e3444a26fcf7a3ff5262d8e655443181d939 Model config ElectraConfig { &#34;architectures&#34;: [ &#34;ElectraForMaskedLM&#34; ], &#34;attention_probs_dropout_prob&#34;: 0.1, &#34;classifier_dropout&#34;: null, &#34;embedding_size&#34;: 768, &#34;hidden_act&#34;: &#34;gelu&#34;, &#34;hidden_dropout_prob&#34;: 0.1, &#34;hidden_size&#34;: 256, &#34;initializer_range&#34;: 0.02, &#34;intermediate_size&#34;: 1024, &#34;layer_norm_eps&#34;: 1e-12, &#34;max_position_embeddings&#34;: 512, &#34;model_type&#34;: &#34;electra&#34;, &#34;num_attention_heads&#34;: 4, &#34;num_hidden_layers&#34;: 12, &#34;pad_token_id&#34;: 0, &#34;position_embedding_type&#34;: &#34;absolute&#34;, &#34;summary_activation&#34;: &#34;gelu&#34;, &#34;summary_last_dropout&#34;: 0.1, &#34;summary_type&#34;: &#34;first&#34;, &#34;summary_use_proj&#34;: true, &#34;transformers_version&#34;: &#34;4.12.5&#34;, &#34;type_vocab_size&#34;: 2, &#34;use_cache&#34;: true, &#34;vocab_size&#34;: 30101 } https://huggingface.co/DCU-NLP/electra-base-irish-cased-generator-v1/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp2i5o9fje storing https://huggingface.co/DCU-NLP/electra-base-irish-cased-generator-v1/resolve/main/vocab.txt in cache at /root/.cache/huggingface/transformers/212cfff55e4717258e776a1735350b6b4f369ab225dfe43bc9e68b77fe83d013.45aeed8a99309e07fa03353cdc46e256411be991056eacba22ce6491dc8cd515 creating metadata file for /root/.cache/huggingface/transformers/212cfff55e4717258e776a1735350b6b4f369ab225dfe43bc9e68b77fe83d013.45aeed8a99309e07fa03353cdc46e256411be991056eacba22ce6491dc8cd515 loading file https://huggingface.co/DCU-NLP/electra-base-irish-cased-generator-v1/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/212cfff55e4717258e776a1735350b6b4f369ab225dfe43bc9e68b77fe83d013.45aeed8a99309e07fa03353cdc46e256411be991056eacba22ce6491dc8cd515 loading file https://huggingface.co/DCU-NLP/electra-base-irish-cased-generator-v1/resolve/main/tokenizer.json from cache at None loading file https://huggingface.co/DCU-NLP/electra-base-irish-cased-generator-v1/resolve/main/added_tokens.json from cache at None loading file https://huggingface.co/DCU-NLP/electra-base-irish-cased-generator-v1/resolve/main/special_tokens_map.json from cache at None loading file https://huggingface.co/DCU-NLP/electra-base-irish-cased-generator-v1/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/a6f921ced163632560dda531384ca2933ff36b280e3b91dc14e25d76d3da8449.c70618325b9fc2d2d041e439766d360b48a086a8841cc2896322f6b8aefc0225 loading configuration file https://huggingface.co/DCU-NLP/electra-base-irish-cased-generator-v1/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/5239b8cd72f5caa8610a21bf2b225bb65fe3529da8491628fe2fb57a9feb5807.f9336c0d71d0b04cbbee5746d7d5e3444a26fcf7a3ff5262d8e655443181d939 Model config ElectraConfig { &#34;architectures&#34;: [ &#34;ElectraForMaskedLM&#34; ], &#34;attention_probs_dropout_prob&#34;: 0.1, &#34;classifier_dropout&#34;: null, &#34;embedding_size&#34;: 768, &#34;hidden_act&#34;: &#34;gelu&#34;, &#34;hidden_dropout_prob&#34;: 0.1, &#34;hidden_size&#34;: 256, &#34;initializer_range&#34;: 0.02, &#34;intermediate_size&#34;: 1024, &#34;layer_norm_eps&#34;: 1e-12, &#34;max_position_embeddings&#34;: 512, &#34;model_type&#34;: &#34;electra&#34;, &#34;num_attention_heads&#34;: 4, &#34;num_hidden_layers&#34;: 12, &#34;pad_token_id&#34;: 0, &#34;position_embedding_type&#34;: &#34;absolute&#34;, &#34;summary_activation&#34;: &#34;gelu&#34;, &#34;summary_last_dropout&#34;: 0.1, &#34;summary_type&#34;: &#34;first&#34;, &#34;summary_use_proj&#34;: true, &#34;transformers_version&#34;: &#34;4.12.5&#34;, &#34;type_vocab_size&#34;: 2, &#34;use_cache&#34;: true, &#34;vocab_size&#34;: 30101 } loading configuration file https://huggingface.co/DCU-NLP/electra-base-irish-cased-generator-v1/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/5239b8cd72f5caa8610a21bf2b225bb65fe3529da8491628fe2fb57a9feb5807.f9336c0d71d0b04cbbee5746d7d5e3444a26fcf7a3ff5262d8e655443181d939 Model config ElectraConfig { &#34;architectures&#34;: [ &#34;ElectraForMaskedLM&#34; ], &#34;attention_probs_dropout_prob&#34;: 0.1, &#34;classifier_dropout&#34;: null, &#34;embedding_size&#34;: 768, &#34;hidden_act&#34;: &#34;gelu&#34;, &#34;hidden_dropout_prob&#34;: 0.1, &#34;hidden_size&#34;: 256, &#34;initializer_range&#34;: 0.02, &#34;intermediate_size&#34;: 1024, &#34;layer_norm_eps&#34;: 1e-12, &#34;max_position_embeddings&#34;: 512, &#34;model_type&#34;: &#34;electra&#34;, &#34;num_attention_heads&#34;: 4, &#34;num_hidden_layers&#34;: 12, &#34;pad_token_id&#34;: 0, &#34;position_embedding_type&#34;: &#34;absolute&#34;, &#34;summary_activation&#34;: &#34;gelu&#34;, &#34;summary_last_dropout&#34;: 0.1, &#34;summary_type&#34;: &#34;first&#34;, &#34;summary_use_proj&#34;: true, &#34;transformers_version&#34;: &#34;4.12.5&#34;, &#34;type_vocab_size&#34;: 2, &#34;use_cache&#34;: true, &#34;vocab_size&#34;: 30101 } . The following assertion ensures that our tokenizer is a fast tokenizers (backed by Rust) from the 🤗 Tokenizers library. Those fast tokenizers are available for almost all models, and we will need some of the special features they have for our preprocessing. . import transformers assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast) . You can check which type of models have a fast tokenizer available and which don&#39;t on the big table of models. . You can directly call this tokenizer on one sentence: . tokenizer(&quot;Is abairt amháin é seo!&quot;) . {&#39;input_ids&#39;: [102, 311, 3280, 556, 186, 222, 711, 103], &#39;token_type_ids&#39;: [0, 0, 0, 0, 0, 0, 0, 0], &#39;attention_mask&#39;: [1, 1, 1, 1, 1, 1, 1, 1]} . Depending on the model you selected, you will see different keys in the dictionary returned by the cell above. They don&#39;t matter much for what we&#39;re doing here (just know they are required by the model we will instantiate later), you can learn more about them in this tutorial if you&#39;re interested. . If, as is the case here, your inputs have already been split into words, you should pass the list of words to your tokenzier with the argument is_split_into_words=True: . tokenizer([&quot;Hello&quot;, &quot;,&quot;, &quot;this&quot;, &quot;is&quot;, &quot;one&quot;, &quot;sentence&quot;, &quot;split&quot;, &quot;into&quot;, &quot;words&quot;, &quot;.&quot;], is_split_into_words=True) . {&#39;input_ids&#39;: [102, 6148, 855, 116, 8536, 198, 13064, 25549, 4666, 333, 19211, 209, 12322, 19942, 29909, 118, 103], &#39;token_type_ids&#39;: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], &#39;attention_mask&#39;: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} . Note that transformers are often pretrained with subword tokenizers, meaning that even if your inputs have been split into words already, each of those words could be split again by the tokenizer. Let&#39;s look at an example of that: . example = datasets[&quot;train&quot;][4] print(example[&quot;tokens&quot;]) . [&#39;Tá&#39;, &#39;Áras&#39;, &#39;an&#39;, &#39;Uachtaráin&#39;, &#39;(&#39;, &#39;áit&#39;, &#39;chónaithe&#39;, &#39;oifigiúil&#39;, &#39;Uachtarán&#39;, &#39;na&#39;, &#39;hÉireann&#39;, &#39;)&#39;, &#39;,&#39;, &#34;&#39;&#39;Deerfield&#34;, &#34;&#39;&#39;&#34;, &#39;(&#39;, &#39;áit&#39;, &#39;chónaithe&#39;, &#39;oifigiúil&#39;, &#39;Ambasadóir&#39;, &#39;Stáit&#39;, &#39;Aontaithe&#39;, &#39;Mheiriceá&#39;, &#39;)&#39;, &#39;,&#39;, &#39;Zú&#39;, &#39;Bhaile&#39;, &#39;Átha&#39;, &#39;Cliath&#39;, &#39;,&#39;, &#39;agus&#39;, &#39;Ceanncheathrú&#39;, &#39;an&#39;, &#39;Gharda&#39;, &#39;Síochána&#39;, &#39;go&#39;, &#39;léir&#39;, &#39;laistigh&#39;, &#39;den&#39;, &#39;pháirc&#39;, &#39;.&#39;] . tokenized_input = tokenizer(example[&quot;tokens&quot;], is_split_into_words=True) tokens = tokenizer.convert_ids_to_tokens(tokenized_input[&quot;input_ids&quot;]) print(tokens) . [&#39;[CLS]&#39;, &#39;Tá&#39;, &#39;Áras&#39;, &#39;an&#39;, &#39;Uachtaráin&#39;, &#39;(&#39;, &#39;áit&#39;, &#39;chónaithe&#39;, &#39;oifigiúil&#39;, &#39;Uachtarán&#39;, &#39;na&#39;, &#39;hÉireann&#39;, &#39;)&#39;, &#39;,&#39;, &#34;&#39;&#34;, &#34;&#39;&#34;, &#39;De&#39;, &#39;##er&#39;, &#39;##field&#39;, &#34;&#39;&#34;, &#34;&#39;&#34;, &#39;(&#39;, &#39;áit&#39;, &#39;chónaithe&#39;, &#39;oifigiúil&#39;, &#39;Ambasadóir&#39;, &#39;Stáit&#39;, &#39;Aontaithe&#39;, &#39;Mheiriceá&#39;, &#39;)&#39;, &#39;,&#39;, &#39;Z&#39;, &#39;##ú&#39;, &#39;Bhaile&#39;, &#39;Átha&#39;, &#39;Cliath&#39;, &#39;,&#39;, &#39;agus&#39;, &#39;Ceanncheathrú&#39;, &#39;an&#39;, &#39;Gharda&#39;, &#39;Síochána&#39;, &#39;go&#39;, &#39;léir&#39;, &#39;laistigh&#39;, &#39;den&#39;, &#39;pháirc&#39;, &#39;.&#39;, &#39;[SEP]&#39;] . Here the words &quot;Zwingmann&quot; and &quot;sheepmeat&quot; have been split in three subtokens. . This means that we need to do some processing on our labels as the input ids returned by the tokenizer are longer than the lists of labels our dataset contain, first because some special tokens might be added (we can a [CLS] and a [SEP] above) and then because of those possible splits of words in multiple tokens: . len(example[f&quot;{task}_tags&quot;]), len(tokenized_input[&quot;input_ids&quot;]) . (41, 49) . Thankfully, the tokenizer returns outputs that have a word_ids method which can help us. . print(tokenized_input.word_ids()) . [None, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 13, 13, 13, 13, 14, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, None] . As we can see, it returns a list with the same number of elements as our processed input ids, mapping special tokens to None and all other tokens to their respective word. This way, we can align the labels with the processed input ids. . word_ids = tokenized_input.word_ids() aligned_labels = [-100 if i is None else example[f&quot;{task}_tags&quot;][i] for i in word_ids] print(len(aligned_labels), len(tokenized_input[&quot;input_ids&quot;])) . 49 49 . Here we set the labels of all special tokens to -100 (the index that is ignored by PyTorch) and the labels of all other tokens to the label of the word they come from. Another strategy is to set the label only on the first token obtained from a given word, and give a label of -100 to the other subtokens from the same word. We propose the two strategies here, just change the value of the following flag: . label_all_tokens = True . We&#39;re now ready to write the function that will preprocess our samples. We feed them to the tokenizer with the argument truncation=True (to truncate texts that are bigger than the maximum size allowed by the model) and is_split_into_words=True (as seen above). Then we align the labels with the token ids using the strategy we picked: . def tokenize_and_align_labels(examples): tokenized_inputs = tokenizer(examples[&quot;tokens&quot;], truncation=True, is_split_into_words=True) labels = [] for i, label in enumerate(examples[f&quot;{task}_tags&quot;]): word_ids = tokenized_inputs.word_ids(batch_index=i) previous_word_idx = None label_ids = [] for word_idx in word_ids: # Special tokens have a word id that is None. We set the label to -100 so they are automatically # ignored in the loss function. if word_idx is None: label_ids.append(-100) # We set the label for the first token of each word. elif word_idx != previous_word_idx: label_ids.append(label[word_idx]) # For the other tokens in a word, we set the label to either the current label or -100, depending on # the label_all_tokens flag. else: label_ids.append(label[word_idx] if label_all_tokens else -100) previous_word_idx = word_idx labels.append(label_ids) tokenized_inputs[&quot;labels&quot;] = labels return tokenized_inputs . This function works with one or several examples. In the case of several examples, the tokenizer will return a list of lists for each key: . tokenize_and_align_labels(datasets[&#39;train&#39;][:5]) . {&#39;input_ids&#39;: [[102, 2663, 2663, 3406, 1216, 19858, 116, 3662, 116, 19321, 1900, 138, 468, 468, 4421, 118, 103], [102, 2663, 2663, 9344, 10452, 188, 188, 170, 2409, 160, 171, 103], [102, 695, 24864, 29907, 7366, 188, 116, 7766, 188, 103], [102, 188, 188, 188, 3556, 557, 409, 188, 188, 188, 103], [102, 300, 9724, 115, 8377, 170, 498, 6907, 2701, 2501, 140, 879, 171, 116, 188, 188, 924, 291, 8708, 188, 188, 170, 498, 6907, 2701, 24116, 1370, 1343, 2731, 171, 116, 2047, 29922, 1854, 1133, 1157, 116, 138, 24507, 115, 4950, 3668, 173, 646, 1331, 290, 8617, 118, 103]], &#39;token_type_ids&#39;: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], &#39;attention_mask&#39;: [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], &#39;labels&#39;: [[-100, 0, 0, 1, 2, 2, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, -100], [-100, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, -100], [-100, 1, 1, 1, 0, 0, 0, 0, 0, -100], [-100, 0, 0, 0, 5, 5, 5, 0, 0, 0, -100], [-100, 0, 3, 4, 4, 0, 0, 0, 0, 3, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 6, 0, 0, 3, 3, 4, 4, 4, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, -100]]} . To apply this function on all the sentences (or pairs of sentences) in our dataset, we just use the map method of our dataset object we created earlier. This will apply the function on all the elements of all the splits in dataset, so our training, validation and testing data will be preprocessed in one single command. . tokenized_datasets = datasets.map(tokenize_and_align_labels, batched=True) . Even better, the results are automatically cached by the 🤗 Datasets library to avoid spending time on this step the next time you run your notebook. The 🤗 Datasets library is normally smart enough to detect when the function you pass to map has changed (and thus requires to not use the cache data). For instance, it will properly detect if you change the task in the first cell and rerun the notebook. 🤗 Datasets warns you when it uses cached files, you can pass load_from_cache_file=False in the call to map to not use the cached files and force the preprocessing to be applied again. . Note that we passed batched=True to encode the texts by batches together. This is to leverage the full benefit of the fast tokenizer we loaded earlier, which will use multi-threading to treat the texts in a batch concurrently. . Fine-tuning the model . Now that our data is ready, we can download the pretrained model and fine-tune it. Since all our tasks are about token classification, we use the AutoModelForTokenClassification class. Like with the tokenizer, the from_pretrained method will download and cache the model for us. The only thing we have to specify is the number of labels for our problem (which we can get from the features, as seen before): . from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer, AutoConfig config = AutoConfig.from_pretrained(model_checkpoint, id2label={i: label for i, label in enumerate(label_list)}, label2id={label: i for i, label in enumerate(label_list)}) model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, config=config) . loading configuration file https://huggingface.co/DCU-NLP/electra-base-irish-cased-generator-v1/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/5239b8cd72f5caa8610a21bf2b225bb65fe3529da8491628fe2fb57a9feb5807.f9336c0d71d0b04cbbee5746d7d5e3444a26fcf7a3ff5262d8e655443181d939 Model config ElectraConfig { &#34;architectures&#34;: [ &#34;ElectraForMaskedLM&#34; ], &#34;attention_probs_dropout_prob&#34;: 0.1, &#34;classifier_dropout&#34;: null, &#34;embedding_size&#34;: 768, &#34;hidden_act&#34;: &#34;gelu&#34;, &#34;hidden_dropout_prob&#34;: 0.1, &#34;hidden_size&#34;: 256, &#34;id2label&#34;: { &#34;0&#34;: &#34;O&#34;, &#34;1&#34;: &#34;B-PER&#34;, &#34;2&#34;: &#34;I-PER&#34;, &#34;3&#34;: &#34;B-ORG&#34;, &#34;4&#34;: &#34;I-ORG&#34;, &#34;5&#34;: &#34;B-LOC&#34;, &#34;6&#34;: &#34;I-LOC&#34; }, &#34;initializer_range&#34;: 0.02, &#34;intermediate_size&#34;: 1024, &#34;label2id&#34;: { &#34;B-LOC&#34;: 5, &#34;B-ORG&#34;: 3, &#34;B-PER&#34;: 1, &#34;I-LOC&#34;: 6, &#34;I-ORG&#34;: 4, &#34;I-PER&#34;: 2, &#34;O&#34;: 0 }, &#34;layer_norm_eps&#34;: 1e-12, &#34;max_position_embeddings&#34;: 512, &#34;model_type&#34;: &#34;electra&#34;, &#34;num_attention_heads&#34;: 4, &#34;num_hidden_layers&#34;: 12, &#34;pad_token_id&#34;: 0, &#34;position_embedding_type&#34;: &#34;absolute&#34;, &#34;summary_activation&#34;: &#34;gelu&#34;, &#34;summary_last_dropout&#34;: 0.1, &#34;summary_type&#34;: &#34;first&#34;, &#34;summary_use_proj&#34;: true, &#34;transformers_version&#34;: &#34;4.12.5&#34;, &#34;type_vocab_size&#34;: 2, &#34;use_cache&#34;: true, &#34;vocab_size&#34;: 30101 } https://huggingface.co/DCU-NLP/electra-base-irish-cased-generator-v1/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpct8a4eaz storing https://huggingface.co/DCU-NLP/electra-base-irish-cased-generator-v1/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/8711d609c9402986d8c3bc7016d08db57bbf19a81067ef583c7badeb001f89b0.6c2cc587a2dcba7325cbf8221f9756c114c56f4cfb05f6fc1607064ba0d510b2 creating metadata file for /root/.cache/huggingface/transformers/8711d609c9402986d8c3bc7016d08db57bbf19a81067ef583c7badeb001f89b0.6c2cc587a2dcba7325cbf8221f9756c114c56f4cfb05f6fc1607064ba0d510b2 loading weights file https://huggingface.co/DCU-NLP/electra-base-irish-cased-generator-v1/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/8711d609c9402986d8c3bc7016d08db57bbf19a81067ef583c7badeb001f89b0.6c2cc587a2dcba7325cbf8221f9756c114c56f4cfb05f6fc1607064ba0d510b2 Some weights of the model checkpoint at DCU-NLP/electra-base-irish-cased-generator-v1 were not used when initializing ElectraForTokenClassification: [&#39;generator_predictions.LayerNorm.bias&#39;, &#39;generator_predictions.LayerNorm.weight&#39;, &#39;generator_lm_head.bias&#39;, &#39;generator_predictions.dense.bias&#39;, &#39;generator_lm_head.weight&#39;, &#39;generator_predictions.dense.weight&#39;] - This IS expected if you are initializing ElectraForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model). - This IS NOT expected if you are initializing ElectraForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model). Some weights of ElectraForTokenClassification were not initialized from the model checkpoint at DCU-NLP/electra-base-irish-cased-generator-v1 and are newly initialized: [&#39;classifier.weight&#39;, &#39;classifier.bias&#39;] You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference. . The warning is telling us we are throwing away some weights (the vocab_transform and vocab_layer_norm layers) and randomly initializing some other (the pre_classifier and classifier layers). This is absolutely normal in this case, because we are removing the head used to pretrain the model on a masked language modeling objective and replacing it with a new head for which we don&#39;t have pretrained weights, so the library warns us we should fine-tune this model before using it for inference, which is exactly what we are going to do. . To instantiate a Trainer, we will need to define three more things. The most important is the TrainingArguments, which is a class that contains all the attributes to customize the training. It requires one folder name, which will be used to save the checkpoints of the model, and all other arguments are optional: . model_name = model_checkpoint.split(&quot;/&quot;)[-1] args = TrainingArguments( f&quot;electra-base-irish-cased-discriminator-v1-finetuned-{task}&quot;, evaluation_strategy = &quot;epoch&quot;, learning_rate=2e-5, per_device_train_batch_size=batch_size, per_device_eval_batch_size=batch_size, num_train_epochs=5, weight_decay=0.01, push_to_hub=True, ) . PyTorch: setting up devices The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-). . Here we set the evaluation to be done at the end of each epoch, tweak the learning rate, use the batch_size defined at the top of the notebook and customize the number of epochs for training, as well as the weight decay. . The last argument to setup everything so we can push the model to the Hub regularly during training. Remove it if you didn&#39;t follow the installation steps at the top of the notebook. If you want to save your model locally in a name that is different than the name of the repository it will be pushed, or if you want to push your model under an organization and not your name space, use the hub_model_id argument to set the repo name (it needs to be the full name, including your namespace: for instance &quot;sgugger/bert-finetuned-ner&quot; or &quot;huggingface/bert-finetuned-ner&quot;). . Then we will need a data collator that will batch our processed examples together while applying padding to make them all the same size (each pad will be padded to the length of its longest example). There is a data collator for this task in the Transformers library, that not only pads the inputs, but also the labels: . from transformers import DataCollatorForTokenClassification data_collator = DataCollatorForTokenClassification(tokenizer) . The last thing to define for our Trainer is how to compute the metrics from the predictions. Here we will load the seqeval metric (which is commonly used to evaluate results on the CONLL dataset) via the Datasets library. . metric = load_metric(&quot;seqeval&quot;) . This metric takes list of labels for the predictions and references: . labels = [label_list[i] for i in example[f&quot;{task}_tags&quot;]] metric.compute(predictions=[labels], references=[labels]) . {&#39;LOC&#39;: {&#39;f1&#39;: 1.0, &#39;number&#39;: 1, &#39;precision&#39;: 1.0, &#39;recall&#39;: 1.0}, &#39;ORG&#39;: {&#39;f1&#39;: 1.0, &#39;number&#39;: 4, &#39;precision&#39;: 1.0, &#39;recall&#39;: 1.0}, &#39;overall_accuracy&#39;: 1.0, &#39;overall_f1&#39;: 1.0, &#39;overall_precision&#39;: 1.0, &#39;overall_recall&#39;: 1.0} . So we will need to do a bit of post-processing on our predictions: . select the predicted index (with the maximum logit) for each token | convert it to its string label | ignore everywhere we set a label of -100 | . The following function does all this post-processing on the result of Trainer.evaluate (which is a namedtuple containing predictions and labels) before applying the metric: . import numpy as np def compute_metrics(p): predictions, labels = p predictions = np.argmax(predictions, axis=2) # Remove ignored index (special tokens) true_predictions = [ [label_list[p] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels) ] true_labels = [ [label_list[l] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels) ] results = metric.compute(predictions=true_predictions, references=true_labels) return { &quot;precision&quot;: results[&quot;overall_precision&quot;], &quot;recall&quot;: results[&quot;overall_recall&quot;], &quot;f1&quot;: results[&quot;overall_f1&quot;], &quot;accuracy&quot;: results[&quot;overall_accuracy&quot;], } . Note that we drop the precision/recall/f1 computed for each category and only focus on the overall precision/recall/f1/accuracy. . Then we just need to pass all of this along with our datasets to the Trainer: . trainer = Trainer( model, args, train_dataset=tokenized_datasets[&quot;train&quot;], eval_dataset=tokenized_datasets[&quot;validation&quot;], data_collator=data_collator, tokenizer=tokenizer, compute_metrics=compute_metrics ) . Cloning https://huggingface.co/jimregan/electra-base-irish-cased-discriminator-v1-finetuned-ner into local empty directory. . We can now finetune our model by just calling the train method: . trainer.train() . The following columns in the training set don&#39;t have a corresponding argument in `ElectraForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running training ***** Num examples = 1000 Num Epochs = 5 Instantaneous batch size per device = 16 Total train batch size (w. parallel, distributed &amp; accumulation) = 16 Gradient Accumulation steps = 1 Total optimization steps = 315 . . [315/315 06:59, Epoch 5/5] Epoch Training Loss Validation Loss Precision Recall F1 Accuracy . 1 | No log | 1.323088 | 0.104612 | 0.041704 | 0.059634 | 0.544900 | . 2 | No log | 0.971045 | 0.387882 | 0.335874 | 0.360010 | 0.748616 | . 3 | No log | 0.772262 | 0.471313 | 0.445740 | 0.458170 | 0.815239 | . 4 | No log | 0.689249 | 0.525684 | 0.491031 | 0.507767 | 0.834663 | . 5 | No log | 0.665405 | 0.541392 | 0.516143 | 0.528466 | 0.841982 | . &lt;/div&gt; &lt;/div&gt; The following columns in the evaluation set don&#39;t have a corresponding argument in `ElectraForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running Evaluation ***** Num examples = 1000 Batch size = 16 The following columns in the evaluation set don&#39;t have a corresponding argument in `ElectraForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running Evaluation ***** Num examples = 1000 Batch size = 16 The following columns in the evaluation set don&#39;t have a corresponding argument in `ElectraForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running Evaluation ***** Num examples = 1000 Batch size = 16 The following columns in the evaluation set don&#39;t have a corresponding argument in `ElectraForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running Evaluation ***** Num examples = 1000 Batch size = 16 The following columns in the evaluation set don&#39;t have a corresponding argument in `ElectraForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running Evaluation ***** Num examples = 1000 Batch size = 16 Training completed. Do not forget to share your model on huggingface.co/models =) . TrainOutput(global_step=315, training_loss=1.046156238374256, metrics={&#39;train_runtime&#39;: 421.4027, &#39;train_samples_per_second&#39;: 11.865, &#39;train_steps_per_second&#39;: 0.748, &#39;total_flos&#39;: 9365012561232.0, &#39;train_loss&#39;: 1.046156238374256, &#39;epoch&#39;: 5.0}) . &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; The evaluate method allows you to evaluate again on the evaluation dataset or on another dataset: . trainer.evaluate() . The following columns in the evaluation set don&#39;t have a corresponding argument in `ElectraForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running Evaluation ***** Num examples = 1000 Batch size = 16 . . [63/63 00:15] {&#39;epoch&#39;: 5.0, &#39;eval_accuracy&#39;: 0.8419817960026273, &#39;eval_f1&#39;: 0.5284664830119375, &#39;eval_loss&#39;: 0.6654045581817627, &#39;eval_precision&#39;: 0.5413922859830668, &#39;eval_recall&#39;: 0.5161434977578475, &#39;eval_runtime&#39;: 15.7195, &#39;eval_samples_per_second&#39;: 63.615, &#39;eval_steps_per_second&#39;: 4.008} . To get the precision/recall/f1 computed for each category now that we have finished training, we can apply the same function as before on the result of the predict method: . predictions, labels, _ = trainer.predict(tokenized_datasets[&quot;validation&quot;]) predictions = np.argmax(predictions, axis=2) # Remove ignored index (special tokens) true_predictions = [ [label_list[p] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels) ] true_labels = [ [label_list[l] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels) ] results = metric.compute(predictions=true_predictions, references=true_labels) results . The following columns in the test set don&#39;t have a corresponding argument in `ElectraForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running Prediction ***** Num examples = 1000 Batch size = 16 . . [63/63 00:30] {&#39;LOC&#39;: {&#39;f1&#39;: 0.611111111111111, &#39;number&#39;: 1059, &#39;precision&#39;: 0.5901495162708883, &#39;recall&#39;: 0.6336166194523135}, &#39;ORG&#39;: {&#39;f1&#39;: 0.32798573975044565, &#39;number&#39;: 624, &#39;precision&#39;: 0.36947791164658633, &#39;recall&#39;: 0.2948717948717949}, &#39;PER&#39;: {&#39;f1&#39;: 0.5703275529865126, &#39;number&#39;: 547, &#39;precision&#39;: 0.6028513238289206, &#39;recall&#39;: 0.5411334552102377}, &#39;overall_accuracy&#39;: 0.8419817960026273, &#39;overall_f1&#39;: 0.5284664830119375, &#39;overall_precision&#39;: 0.5413922859830668, &#39;overall_recall&#39;: 0.5161434977578475} . You can now upload the result of the training to the Hub, just execute this instruction: . trainer.push_to_hub() . Saving model checkpoint to electra-base-irish-cased-discriminator-v1-finetuned-ner Configuration saved in electra-base-irish-cased-discriminator-v1-finetuned-ner/config.json Model weights saved in electra-base-irish-cased-discriminator-v1-finetuned-ner/pytorch_model.bin tokenizer config file saved in electra-base-irish-cased-discriminator-v1-finetuned-ner/tokenizer_config.json Special tokens file saved in electra-base-irish-cased-discriminator-v1-finetuned-ner/special_tokens_map.json To https://huggingface.co/jimregan/electra-base-irish-cased-discriminator-v1-finetuned-ner ff80640..8e0c67b main -&gt; main To https://huggingface.co/jimregan/electra-base-irish-cased-discriminator-v1-finetuned-ner 8e0c67b..de8c10a main -&gt; main . &#39;https://huggingface.co/jimregan/electra-base-irish-cased-discriminator-v1-finetuned-ner/commit/8e0c67b1396fb46c77f0d4ec21922a123d9faf94&#39; . You can now share this model with all your friends, family, favorite pets: they can all load it with the identifier &quot;your-username/the-name-you-picked&quot; so for instance: . from transformers import AutoModelForTokenClassification model = AutoModelForTokenClassification.from_pretrained(&quot;sgugger/my-awesome-model&quot;) . &lt;/div&gt; .",
            "url": "https://jimregan.github.io/notes/irish/ner/bert/gaelectra/2021/12/01/token_classification_gaelectra.html",
            "relUrl": "/irish/ner/bert/gaelectra/2021/12/01/token_classification_gaelectra.html",
            "date": " • Dec 1, 2021"
        }
        
    
  
    
        ,"post90": {
            "title": "NER with gaBERT",
            "content": "This is a lightly edited version of this notebook. . If you&#39;re opening this Notebook on colab, you will probably need to install 🤗 Transformers and 🤗 Datasets. Uncomment the following cell and run it. . %%capture !pip install datasets transformers seqeval . If you&#39;re opening this notebook locally, make sure your environment has an install from the last version of those libraries. . To be able to share your model with the community and generate results like the one shown in the picture below via the inference API, there are a few more steps to follow. . First you have to store your authentication token from the Hugging Face website (sign up here if you haven&#39;t already!) then execute the following cell and input your username and password: . (Huggingface notebooks skip this bit, but you need to set credential.helper before anything else works). . !git config --global credential.helper store . from huggingface_hub import notebook_login notebook_login() . Login successful Your token has been saved to /root/.huggingface/token . Then you need to install Git-LFS. Uncomment the following instructions: . !apt install git-lfs . Reading package lists... Done Building dependency tree Reading state information... Done The following NEW packages will be installed: git-lfs 0 upgraded, 1 newly installed, 0 to remove and 37 not upgraded. Need to get 2,129 kB of archives. After this operation, 7,662 kB of additional disk space will be used. Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 git-lfs amd64 2.3.4-1 [2,129 kB] Fetched 2,129 kB in 1s (2,915 kB/s) Selecting previously unselected package git-lfs. (Reading database ... 155222 files and directories currently installed.) Preparing to unpack .../git-lfs_2.3.4-1_amd64.deb ... Unpacking git-lfs (2.3.4-1) ... Setting up git-lfs (2.3.4-1) ... Processing triggers for man-db (2.8.3-2ubuntu0.1) ... . Make sure your version of Transformers is at least 4.11.0 since the functionality was introduced in that version: . import transformers print(transformers.__version__) . 4.12.5 . You can find a script version of this notebook to fine-tune your model in a distributed fashion using multiple GPUs or TPUs here. . Fine-tuning a model on a token classification task . In this notebook, we will see how to fine-tune one of the 🤗 Transformers model to a token classification task, which is the task of predicting a label for each token. . . The most common token classification tasks are: . NER (Named-entity recognition) Classify the entities in the text (person, organization, location...). | POS (Part-of-speech tagging) Grammatically classify the tokens (noun, verb, adjective...) | Chunk (Chunking) Grammatically classify the tokens and group them into &quot;chunks&quot; that go together | . We will see how to easily load a dataset for these kinds of tasks and use the Trainer API to fine-tune a model on it. . This notebook is built to run on any token classification task, with any model checkpoint from the Model Hub as long as that model has a version with a token classification head and a fast tokenizer (check on this table if this is the case). It might just need some small adjustments if you decide to use a different dataset than the one used here. Depending on you model and the GPU you are using, you might need to adjust the batch size to avoid out-of-memory errors. Set those three parameters, then the rest of the notebook should run smoothly: . task = &quot;ner&quot; # Should be one of &quot;ner&quot;, &quot;pos&quot; or &quot;chunk&quot; model_checkpoint = &quot;DCU-NLP/bert-base-irish-cased-v1&quot; batch_size = 16 . Loading the dataset . We will use the 🤗 Datasets library to download the data and get the metric we need to use for evaluation (to compare our model to the benchmark). This can be easily done with the functions load_dataset and load_metric. . from datasets import load_dataset, load_metric . For our example here, we&#39;ll use the CONLL 2003 dataset. The notebook should work with any token classification dataset provided by the 🤗 Datasets library. If you&#39;re using your own dataset defined from a JSON or csv file (see the Datasets documentation on how to load them), it might need some adjustments in the names of the columns used. . datasets = load_dataset(&quot;wikiann&quot;, &quot;ga&quot;) . Downloading and preparing dataset wikiann/ga (download: 223.17 MiB, generated: 690.65 KiB, post-processed: Unknown size, total: 223.84 MiB) to /root/.cache/huggingface/datasets/wikiann/ga/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e... Dataset wikiann downloaded and prepared to /root/.cache/huggingface/datasets/wikiann/ga/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e. Subsequent calls will reuse this data. . The datasets object itself is DatasetDict, which contains one key for the training, validation and test set. . datasets . DatasetDict({ validation: Dataset({ features: [&#39;tokens&#39;, &#39;ner_tags&#39;, &#39;langs&#39;, &#39;spans&#39;], num_rows: 1000 }) test: Dataset({ features: [&#39;tokens&#39;, &#39;ner_tags&#39;, &#39;langs&#39;, &#39;spans&#39;], num_rows: 1000 }) train: Dataset({ features: [&#39;tokens&#39;, &#39;ner_tags&#39;, &#39;langs&#39;, &#39;spans&#39;], num_rows: 1000 }) }) . We can see the training, validation and test sets all have a column for the tokens (the input texts split into words) and one column of labels for each kind of task we introduced before. . To access an actual element, you need to select a split first, then give an index: . datasets[&quot;train&quot;][0] . {&#39;langs&#39;: [&#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;], &#39;ner_tags&#39;: [0, 1, 2, 2, 0, 0, 0, 0, 5, 0, 0, 0], &#39;spans&#39;: [&#39;PER: Pádraig Mac Piarais&#39;, &#39;LOC: Éireannach&#39;], &#39;tokens&#39;: [&#39;**&#39;, &#39;Pádraig&#39;, &#39;Mac&#39;, &#39;Piarais&#39;, &#39;,&#39;, &#39;36&#39;, &#39;,&#39;, &#39;réabhlóidí&#39;, &#39;Éireannach&#39;, &#39;agus&#39;, &#39;[[file&#39;, &#39;.&#39;]} . The labels are already coded as integer ids to be easily usable by our model, but the correspondence with the actual categories is stored in the features of the dataset: . datasets[&quot;train&quot;].features[f&quot;ner_tags&quot;] . Sequence(feature=ClassLabel(num_classes=7, names=[&#39;O&#39;, &#39;B-PER&#39;, &#39;I-PER&#39;, &#39;B-ORG&#39;, &#39;I-ORG&#39;, &#39;B-LOC&#39;, &#39;I-LOC&#39;], names_file=None, id=None), length=-1, id=None) . So for the NER tags, 0 corresponds to &#39;O&#39;, 1 to &#39;B-PER&#39; etc... On top of the &#39;O&#39; (which means no special entity), there are four labels for NER here, each prefixed with &#39;B-&#39; (for beginning) or &#39;I-&#39; (for intermediate), that indicate if the token is the first one for the current group with the label or not: . &#39;PER&#39; for person | &#39;ORG&#39; for organization | &#39;LOC&#39; for location | &#39;MISC&#39; for miscellaneous | . Since the labels are lists of ClassLabel, the actual names of the labels are nested in the feature attribute of the object above: . label_list = datasets[&quot;train&quot;].features[f&quot;{task}_tags&quot;].feature.names label_list . [&#39;O&#39;, &#39;B-PER&#39;, &#39;I-PER&#39;, &#39;B-ORG&#39;, &#39;I-ORG&#39;, &#39;B-LOC&#39;, &#39;I-LOC&#39;] . To get a sense of what the data looks like, the following function will show some examples picked randomly in the dataset (automatically decoding the labels in passing). . from datasets import ClassLabel, Sequence import random import pandas as pd from IPython.display import display, HTML def show_random_elements(dataset, num_examples=10): assert num_examples &lt;= len(dataset), &quot;Can&#39;t pick more elements than there are in the dataset.&quot; picks = [] for _ in range(num_examples): pick = random.randint(0, len(dataset)-1) while pick in picks: pick = random.randint(0, len(dataset)-1) picks.append(pick) df = pd.DataFrame(dataset[picks]) for column, typ in dataset.features.items(): if isinstance(typ, ClassLabel): df[column] = df[column].transform(lambda i: typ.names[i]) elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel): df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x]) display(HTML(df.to_html())) . show_random_elements(datasets[&quot;train&quot;]) . tokens ner_tags langs spans . 0 [An, Bhantiarna, Jane, Grey] | [B-PER, I-PER, I-PER, I-PER] | [ga, ga, ga, ga] | [PER: An Bhantiarna Jane Grey] | . 1 [athsheoladh, Pápa, Pól, IV] | [O, B-PER, I-PER, I-PER] | [ga, ga, ga, ga] | [PER: Pápa Pól IV] | . 2 [Launceston, ,, Devonport, ,, agus, Burnie] | [B-LOC, O, B-LOC, O, O, B-LOC] | [ga, ga, ga, ga, ga, ga] | [LOC: Launceston, LOC: Devonport, LOC: Burnie] | . 3 [Holborn, ,, Hyde, Park] | [B-LOC, O, B-ORG, I-ORG] | [ga, ga, ga, ga] | [LOC: Holborn, ORG: Hyde Park] | . 4 [athsheoladh, Ollscoil, Chathair, Bhaile, Átha, Cliath] | [O, B-ORG, I-ORG, I-ORG, I-ORG, I-ORG] | [ga, ga, ga, ga, ga, ga] | [ORG: Ollscoil Chathair Bhaile Átha Cliath] | . 5 [Broadgate, ,, Billingsgate, ,, Bishopsgate, ,, Blackfriars] | [B-ORG, O, B-LOC, O, B-LOC, O, B-LOC] | [ga, ga, ga, ga, ga, ga, ga] | [ORG: Broadgate, LOC: Billingsgate, LOC: Bishopsgate, LOC: Blackfriars] | . 6 [Major, Antônio, Couto, Pereira, Staidiam] | [B-ORG, I-ORG, I-ORG, I-ORG, I-ORG] | [ga, ga, ga, ga, ga] | [ORG: Major Antônio Couto Pereira Staidiam] | . 7 [Ruairí, Ó, Cuinn] | [B-PER, I-PER, I-PER] | [ga, ga, ga] | [PER: Ruairí Ó Cuinn] | . 8 [&#39;, &#39;&#39;, Razoul, &#39;&#39;, &#39;, -, Jim, Cummings] | [O, O, O, O, O, O, B-PER, I-PER] | [ga, ga, ga, ga, ga, ga, ga, ga] | [PER: Jim Cummings] | . 9 [Is, iomaí, laoch, de, chuid, an, gharrfhicsin, a, chuaigh, i, dtáin, an, phopchultúir, dhomhanda, ,, go, háirithe, iad, siúd, ar, chuir, Hollywood, suim, iontu, .] | [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-LOC, O, O, O] | [ga, ga, ga, ga, ga, ga, ga, ga, ga, ga, ga, ga, ga, ga, ga, ga, ga, ga, ga, ga, ga, ga, ga, ga, ga] | [LOC: Hollywood] | . Preprocessing the data . Before we can feed those texts to our model, we need to preprocess them. This is done by a 🤗 Transformers Tokenizer which will (as the name indicates) tokenize the inputs (including converting the tokens to their corresponding IDs in the pretrained vocabulary) and put it in a format the model expects, as well as generate the other inputs that model requires. . To do all of this, we instantiate our tokenizer with the AutoTokenizer.from_pretrained method, which will ensure: . we get a tokenizer that corresponds to the model architecture we want to use, | we download the vocabulary used when pretraining this specific checkpoint. | . That vocabulary will be cached, so it&#39;s not downloaded again the next time we run the cell. . from transformers import AutoTokenizer tokenizer = AutoTokenizer.from_pretrained(model_checkpoint) . The following assertion ensures that our tokenizer is a fast tokenizers (backed by Rust) from the 🤗 Tokenizers library. Those fast tokenizers are available for almost all models, and we will need some of the special features they have for our preprocessing. . import transformers assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast) . You can check which type of models have a fast tokenizer available and which don&#39;t on the big table of models. . You can directly call this tokenizer on one sentence: . tokenizer(&quot;Is abairt amháin é seo!&quot;) . {&#39;input_ids&#39;: [102, 311, 3280, 556, 186, 222, 711, 103], &#39;token_type_ids&#39;: [0, 0, 0, 0, 0, 0, 0, 0], &#39;attention_mask&#39;: [1, 1, 1, 1, 1, 1, 1, 1]} . Depending on the model you selected, you will see different keys in the dictionary returned by the cell above. They don&#39;t matter much for what we&#39;re doing here (just know they are required by the model we will instantiate later), you can learn more about them in this tutorial if you&#39;re interested. . If, as is the case here, your inputs have already been split into words, you should pass the list of words to your tokenzier with the argument is_split_into_words=True: . tokenizer([&quot;Hello&quot;, &quot;,&quot;, &quot;this&quot;, &quot;is&quot;, &quot;one&quot;, &quot;sentence&quot;, &quot;split&quot;, &quot;into&quot;, &quot;words&quot;, &quot;.&quot;], is_split_into_words=True) . {&#39;input_ids&#39;: [101, 7592, 1010, 2023, 2003, 2028, 6251, 3975, 2046, 2616, 1012, 102], &#39;attention_mask&#39;: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} . Note that transformers are often pretrained with subword tokenizers, meaning that even if your inputs have been split into words already, each of those words could be split again by the tokenizer. Let&#39;s look at an example of that: . example = datasets[&quot;train&quot;][4] print(example[&quot;tokens&quot;]) . [&#39;Tá&#39;, &#39;Áras&#39;, &#39;an&#39;, &#39;Uachtaráin&#39;, &#39;(&#39;, &#39;áit&#39;, &#39;chónaithe&#39;, &#39;oifigiúil&#39;, &#39;Uachtarán&#39;, &#39;na&#39;, &#39;hÉireann&#39;, &#39;)&#39;, &#39;,&#39;, &#34;&#39;&#39;Deerfield&#34;, &#34;&#39;&#39;&#34;, &#39;(&#39;, &#39;áit&#39;, &#39;chónaithe&#39;, &#39;oifigiúil&#39;, &#39;Ambasadóir&#39;, &#39;Stáit&#39;, &#39;Aontaithe&#39;, &#39;Mheiriceá&#39;, &#39;)&#39;, &#39;,&#39;, &#39;Zú&#39;, &#39;Bhaile&#39;, &#39;Átha&#39;, &#39;Cliath&#39;, &#39;,&#39;, &#39;agus&#39;, &#39;Ceanncheathrú&#39;, &#39;an&#39;, &#39;Gharda&#39;, &#39;Síochána&#39;, &#39;go&#39;, &#39;léir&#39;, &#39;laistigh&#39;, &#39;den&#39;, &#39;pháirc&#39;, &#39;.&#39;] . tokenized_input = tokenizer(example[&quot;tokens&quot;], is_split_into_words=True) tokens = tokenizer.convert_ids_to_tokens(tokenized_input[&quot;input_ids&quot;]) print(tokens) . [&#39;[CLS]&#39;, &#39;Tá&#39;, &#39;Áras&#39;, &#39;an&#39;, &#39;Uachtaráin&#39;, &#39;(&#39;, &#39;áit&#39;, &#39;chónaithe&#39;, &#39;oifigiúil&#39;, &#39;Uachtarán&#39;, &#39;na&#39;, &#39;hÉireann&#39;, &#39;)&#39;, &#39;,&#39;, &#34;&#39;&#34;, &#34;&#39;&#34;, &#39;De&#39;, &#39;##er&#39;, &#39;##field&#39;, &#34;&#39;&#34;, &#34;&#39;&#34;, &#39;(&#39;, &#39;áit&#39;, &#39;chónaithe&#39;, &#39;oifigiúil&#39;, &#39;Ambasadóir&#39;, &#39;Stáit&#39;, &#39;Aontaithe&#39;, &#39;Mheiriceá&#39;, &#39;)&#39;, &#39;,&#39;, &#39;Z&#39;, &#39;##ú&#39;, &#39;Bhaile&#39;, &#39;Átha&#39;, &#39;Cliath&#39;, &#39;,&#39;, &#39;agus&#39;, &#39;Ceanncheathrú&#39;, &#39;an&#39;, &#39;Gharda&#39;, &#39;Síochána&#39;, &#39;go&#39;, &#39;léir&#39;, &#39;laistigh&#39;, &#39;den&#39;, &#39;pháirc&#39;, &#39;.&#39;, &#39;[SEP]&#39;] . Here the words &quot;Zwingmann&quot; and &quot;sheepmeat&quot; have been split in three subtokens. . This means that we need to do some processing on our labels as the input ids returned by the tokenizer are longer than the lists of labels our dataset contain, first because some special tokens might be added (we can a [CLS] and a [SEP] above) and then because of those possible splits of words in multiple tokens: . len(example[f&quot;{task}_tags&quot;]), len(tokenized_input[&quot;input_ids&quot;]) . (41, 49) . Thankfully, the tokenizer returns outputs that have a word_ids method which can help us. . print(tokenized_input.word_ids()) . [None, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 13, 13, 13, 13, 14, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, None] . As we can see, it returns a list with the same number of elements as our processed input ids, mapping special tokens to None and all other tokens to their respective word. This way, we can align the labels with the processed input ids. . word_ids = tokenized_input.word_ids() aligned_labels = [-100 if i is None else example[f&quot;{task}_tags&quot;][i] for i in word_ids] print(len(aligned_labels), len(tokenized_input[&quot;input_ids&quot;])) . 49 49 . Here we set the labels of all special tokens to -100 (the index that is ignored by PyTorch) and the labels of all other tokens to the label of the word they come from. Another strategy is to set the label only on the first token obtained from a given word, and give a label of -100 to the other subtokens from the same word. We propose the two strategies here, just change the value of the following flag: . label_all_tokens = True . We&#39;re now ready to write the function that will preprocess our samples. We feed them to the tokenizer with the argument truncation=True (to truncate texts that are bigger than the maximum size allowed by the model) and is_split_into_words=True (as seen above). Then we align the labels with the token ids using the strategy we picked: . def tokenize_and_align_labels(examples): tokenized_inputs = tokenizer(examples[&quot;tokens&quot;], truncation=True, is_split_into_words=True) labels = [] for i, label in enumerate(examples[f&quot;{task}_tags&quot;]): word_ids = tokenized_inputs.word_ids(batch_index=i) previous_word_idx = None label_ids = [] for word_idx in word_ids: # Special tokens have a word id that is None. We set the label to -100 so they are automatically # ignored in the loss function. if word_idx is None: label_ids.append(-100) # We set the label for the first token of each word. elif word_idx != previous_word_idx: label_ids.append(label[word_idx]) # For the other tokens in a word, we set the label to either the current label or -100, depending on # the label_all_tokens flag. else: label_ids.append(label[word_idx] if label_all_tokens else -100) previous_word_idx = word_idx labels.append(label_ids) tokenized_inputs[&quot;labels&quot;] = labels return tokenized_inputs . This function works with one or several examples. In the case of several examples, the tokenizer will return a list of lists for each key: . tokenize_and_align_labels(datasets[&#39;train&#39;][:5]) . Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation. . {&#39;input_ids&#39;: [[102, 2663, 2663, 3406, 1216, 19858, 116, 3662, 116, 19321, 1900, 138, 468, 468, 4421, 118, 103], [102, 2663, 2663, 9344, 10452, 188, 188, 170, 2409, 160, 171, 103], [102, 695, 24864, 29907, 7366, 188, 116, 7766, 188, 103], [102, 188, 188, 188, 3556, 557, 409, 188, 188, 188, 103], [102, 300, 9724, 115, 8377, 170, 498, 6907, 2701, 2501, 140, 879, 171, 116, 188, 188, 924, 291, 8708, 188, 188, 170, 498, 6907, 2701, 24116, 1370, 1343, 2731, 171, 116, 2047, 29922, 1854, 1133, 1157, 116, 138, 24507, 115, 4950, 3668, 173, 646, 1331, 290, 8617, 118, 103]], &#39;token_type_ids&#39;: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], &#39;attention_mask&#39;: [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], &#39;labels&#39;: [[-100, 0, 0, 1, 2, 2, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, -100], [-100, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, -100], [-100, 1, 1, 1, 0, 0, 0, 0, 0, -100], [-100, 0, 0, 0, 5, 5, 5, 0, 0, 0, -100], [-100, 0, 3, 4, 4, 0, 0, 0, 0, 3, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 6, 0, 0, 3, 3, 4, 4, 4, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, -100]]} . To apply this function on all the sentences (or pairs of sentences) in our dataset, we just use the map method of our dataset object we created earlier. This will apply the function on all the elements of all the splits in dataset, so our training, validation and testing data will be preprocessed in one single command. . tokenized_datasets = datasets.map(tokenize_and_align_labels, batched=True) . Even better, the results are automatically cached by the 🤗 Datasets library to avoid spending time on this step the next time you run your notebook. The 🤗 Datasets library is normally smart enough to detect when the function you pass to map has changed (and thus requires to not use the cache data). For instance, it will properly detect if you change the task in the first cell and rerun the notebook. 🤗 Datasets warns you when it uses cached files, you can pass load_from_cache_file=False in the call to map to not use the cached files and force the preprocessing to be applied again. . Note that we passed batched=True to encode the texts by batches together. This is to leverage the full benefit of the fast tokenizer we loaded earlier, which will use multi-threading to treat the texts in a batch concurrently. . Fine-tuning the model . Now that our data is ready, we can download the pretrained model and fine-tune it. Since all our tasks are about token classification, we use the AutoModelForTokenClassification class. Like with the tokenizer, the from_pretrained method will download and cache the model for us. The only thing we have to specify is the number of labels for our problem (which we can get from the features, as seen before): . from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer, AutoConfig config = AutoConfig.from_pretrained(model_checkpoint, id2label={i: label for i, label in enumerate(label_list)}, label2id={label: i for i, label in enumerate(label_list)}) model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, config=config) . Some weights of the model checkpoint at DCU-NLP/bert-base-irish-cased-v1 were not used when initializing BertForTokenClassification: [&#39;cls.predictions.transform.dense.weight&#39;, &#39;cls.predictions.decoder.weight&#39;, &#39;cls.seq_relationship.bias&#39;, &#39;cls.predictions.decoder.bias&#39;, &#39;cls.predictions.transform.dense.bias&#39;, &#39;cls.predictions.transform.LayerNorm.weight&#39;, &#39;cls.predictions.bias&#39;, &#39;cls.seq_relationship.weight&#39;, &#39;cls.predictions.transform.LayerNorm.bias&#39;] - This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model). - This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model). Some weights of BertForTokenClassification were not initialized from the model checkpoint at DCU-NLP/bert-base-irish-cased-v1 and are newly initialized: [&#39;classifier.weight&#39;, &#39;classifier.bias&#39;] You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference. . The warning is telling us we are throwing away some weights (the vocab_transform and vocab_layer_norm layers) and randomly initializing some other (the pre_classifier and classifier layers). This is absolutely normal in this case, because we are removing the head used to pretrain the model on a masked language modeling objective and replacing it with a new head for which we don&#39;t have pretrained weights, so the library warns us we should fine-tune this model before using it for inference, which is exactly what we are going to do. . To instantiate a Trainer, we will need to define three more things. The most important is the TrainingArguments, which is a class that contains all the attributes to customize the training. It requires one folder name, which will be used to save the checkpoints of the model, and all other arguments are optional: . model_name = model_checkpoint.split(&quot;/&quot;)[-1] args = TrainingArguments( f&quot;bert-base-irish-cased-v1-finetuned-{task}&quot;, evaluation_strategy = &quot;epoch&quot;, learning_rate=2e-5, per_device_train_batch_size=batch_size, per_device_eval_batch_size=batch_size, num_train_epochs=5, weight_decay=0.01, push_to_hub=True, ) . Here we set the evaluation to be done at the end of each epoch, tweak the learning rate, use the batch_size defined at the top of the notebook and customize the number of epochs for training, as well as the weight decay. . The last argument to setup everything so we can push the model to the Hub regularly during training. Remove it if you didn&#39;t follow the installation steps at the top of the notebook. If you want to save your model locally in a name that is different than the name of the repository it will be pushed, or if you want to push your model under an organization and not your name space, use the hub_model_id argument to set the repo name (it needs to be the full name, including your namespace: for instance &quot;sgugger/bert-finetuned-ner&quot; or &quot;huggingface/bert-finetuned-ner&quot;). . Then we will need a data collator that will batch our processed examples together while applying padding to make them all the same size (each pad will be padded to the length of its longest example). There is a data collator for this task in the Transformers library, that not only pads the inputs, but also the labels: . from transformers import DataCollatorForTokenClassification data_collator = DataCollatorForTokenClassification(tokenizer) . The last thing to define for our Trainer is how to compute the metrics from the predictions. Here we will load the seqeval metric (which is commonly used to evaluate results on the CONLL dataset) via the Datasets library. . metric = load_metric(&quot;seqeval&quot;) . This metric takes list of labels for the predictions and references: . labels = [label_list[i] for i in example[f&quot;{task}_tags&quot;]] metric.compute(predictions=[labels], references=[labels]) . {&#39;LOC&#39;: {&#39;f1&#39;: 1.0, &#39;number&#39;: 1, &#39;precision&#39;: 1.0, &#39;recall&#39;: 1.0}, &#39;ORG&#39;: {&#39;f1&#39;: 1.0, &#39;number&#39;: 4, &#39;precision&#39;: 1.0, &#39;recall&#39;: 1.0}, &#39;overall_accuracy&#39;: 1.0, &#39;overall_f1&#39;: 1.0, &#39;overall_precision&#39;: 1.0, &#39;overall_recall&#39;: 1.0} . So we will need to do a bit of post-processing on our predictions: . select the predicted index (with the maximum logit) for each token | convert it to its string label | ignore everywhere we set a label of -100 | . The following function does all this post-processing on the result of Trainer.evaluate (which is a namedtuple containing predictions and labels) before applying the metric: . import numpy as np def compute_metrics(p): predictions, labels = p predictions = np.argmax(predictions, axis=2) # Remove ignored index (special tokens) true_predictions = [ [label_list[p] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels) ] true_labels = [ [label_list[l] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels) ] results = metric.compute(predictions=true_predictions, references=true_labels) return { &quot;precision&quot;: results[&quot;overall_precision&quot;], &quot;recall&quot;: results[&quot;overall_recall&quot;], &quot;f1&quot;: results[&quot;overall_f1&quot;], &quot;accuracy&quot;: results[&quot;overall_accuracy&quot;], } . Note that we drop the precision/recall/f1 computed for each category and only focus on the overall precision/recall/f1/accuracy. . Then we just need to pass all of this along with our datasets to the Trainer: . trainer = Trainer( model, args, train_dataset=tokenized_datasets[&quot;train&quot;], eval_dataset=tokenized_datasets[&quot;validation&quot;], data_collator=data_collator, tokenizer=tokenizer, compute_metrics=compute_metrics ) . Cloning https://huggingface.co/jimregan/bert-base-irish-cased-v1-finetuned-ner into local empty directory. . We can now finetune our model by just calling the train method: . trainer.train() . The following columns in the training set don&#39;t have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running training ***** Num examples = 1000 Num Epochs = 5 Instantaneous batch size per device = 16 Total train batch size (w. parallel, distributed &amp; accumulation) = 16 Gradient Accumulation steps = 1 Total optimization steps = 315 . . [315/315 42:13, Epoch 5/5] Epoch Training Loss Validation Loss Precision Recall F1 Accuracy . 1 | No log | 0.490215 | 0.557930 | 0.526906 | 0.541974 | 0.845829 | . 2 | No log | 0.322674 | 0.716948 | 0.741704 | 0.729116 | 0.899127 | . 3 | No log | 0.271966 | 0.789521 | 0.783857 | 0.786679 | 0.918645 | . 4 | No log | 0.258545 | 0.812830 | 0.829596 | 0.821127 | 0.926433 | . 5 | No log | 0.246760 | 0.819060 | 0.836323 | 0.827602 | 0.930656 | . &lt;/div&gt; &lt;/div&gt; The following columns in the evaluation set don&#39;t have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running Evaluation ***** Num examples = 1000 Batch size = 16 The following columns in the evaluation set don&#39;t have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running Evaluation ***** Num examples = 1000 Batch size = 16 The following columns in the evaluation set don&#39;t have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running Evaluation ***** Num examples = 1000 Batch size = 16 The following columns in the evaluation set don&#39;t have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running Evaluation ***** Num examples = 1000 Batch size = 16 The following columns in the evaluation set don&#39;t have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running Evaluation ***** Num examples = 1000 Batch size = 16 Training completed. Do not forget to share your model on huggingface.co/models =) . TrainOutput(global_step=315, training_loss=0.3794897654699901, metrics={&#39;train_runtime&#39;: 2539.5447, &#39;train_samples_per_second&#39;: 1.969, &#39;train_steps_per_second&#39;: 0.124, &#39;total_flos&#39;: 82316282047824.0, &#39;train_loss&#39;: 0.3794897654699901, &#39;epoch&#39;: 5.0}) . &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; The evaluate method allows you to evaluate again on the evaluation dataset or on another dataset: . trainer.evaluate() . The following columns in the evaluation set don&#39;t have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running Evaluation ***** Num examples = 1000 Batch size = 16 . . [63/63 01:31] {&#39;epoch&#39;: 5.0, &#39;eval_accuracy&#39;: 0.9306559069156423, &#39;eval_f1&#39;: 0.8276015087641446, &#39;eval_loss&#39;: 0.2467602640390396, &#39;eval_precision&#39;: 0.8190601668862538, &#39;eval_recall&#39;: 0.8363228699551569, &#39;eval_runtime&#39;: 92.5448, &#39;eval_samples_per_second&#39;: 10.806, &#39;eval_steps_per_second&#39;: 0.681} . To get the precision/recall/f1 computed for each category now that we have finished training, we can apply the same function as before on the result of the predict method: . predictions, labels, _ = trainer.predict(tokenized_datasets[&quot;validation&quot;]) predictions = np.argmax(predictions, axis=2) # Remove ignored index (special tokens) true_predictions = [ [label_list[p] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels) ] true_labels = [ [label_list[l] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels) ] results = metric.compute(predictions=true_predictions, references=true_labels) results . The following columns in the test set don&#39;t have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running Prediction ***** Num examples = 1000 Batch size = 16 . . [63/63 03:13] {&#39;LOC&#39;: {&#39;f1&#39;: 0.8707735062528948, &#39;number&#39;: 1059, &#39;precision&#39;: 0.8545454545454545, &#39;recall&#39;: 0.8876298394711992}, &#39;ORG&#39;: {&#39;f1&#39;: 0.7434210526315789, &#39;number&#39;: 624, &#39;precision&#39;: 0.7635135135135135, &#39;recall&#39;: 0.7243589743589743}, &#39;PER&#39;: {&#39;f1&#39;: 0.8356890459363958, &#39;number&#39;: 547, &#39;precision&#39;: 0.8085470085470086, &#39;recall&#39;: 0.8647166361974405}, &#39;overall_accuracy&#39;: 0.9306559069156423, &#39;overall_f1&#39;: 0.8276015087641446, &#39;overall_precision&#39;: 0.8190601668862538, &#39;overall_recall&#39;: 0.8363228699551569} . You can now upload the result of the training to the Hub, just execute this instruction: . trainer.push_to_hub() . Saving model checkpoint to bert-base-irish-cased-v1-finetuned-ner Configuration saved in bert-base-irish-cased-v1-finetuned-ner/config.json Model weights saved in bert-base-irish-cased-v1-finetuned-ner/pytorch_model.bin tokenizer config file saved in bert-base-irish-cased-v1-finetuned-ner/tokenizer_config.json Special tokens file saved in bert-base-irish-cased-v1-finetuned-ner/special_tokens_map.json To https://huggingface.co/jimregan/bert-base-irish-cased-v1-finetuned-ner 1e8d5f1..335cab8 main -&gt; main To https://huggingface.co/jimregan/bert-base-irish-cased-v1-finetuned-ner 335cab8..346f537 main -&gt; main . &#39;https://huggingface.co/jimregan/bert-base-irish-cased-v1-finetuned-ner/commit/335cab89dba6a89a8bc06c22d70abeec27c1f60c&#39; . You can now share this model with all your friends, family, favorite pets: they can all load it with the identifier &quot;your-username/the-name-you-picked&quot; so for instance: . from transformers import AutoModelForTokenClassification model = AutoModelForTokenClassification.from_pretrained(&quot;sgugger/my-awesome-model&quot;) . &lt;/div&gt; .",
            "url": "https://jimregan.github.io/notes/irish/ner/bert/gabert/2021/12/01/token_classification_gabert.html",
            "relUrl": "/irish/ner/bert/gabert/2021/12/01/token_classification_gabert.html",
            "date": " • Dec 1, 2021"
        }
        
    
  
    
        ,"post91": {
            "title": "NER with bertreach",
            "content": "This is a lightly edited version of this notebook. . If you&#39;re opening this Notebook on colab, you will probably need to install 🤗 Transformers and 🤗 Datasets. Uncomment the following cell and run it. . %%capture !pip install datasets transformers seqeval . If you&#39;re opening this notebook locally, make sure your environment has an install from the last version of those libraries. . To be able to share your model with the community and generate results like the one shown in the picture below via the inference API, there are a few more steps to follow. . First you have to store your authentication token from the Hugging Face website (sign up here if you haven&#39;t already!) then execute the following cell and input your username and password: . (Huggingface notebooks skip this bit, but you need to set credential.helper before anything else works). . !git config --global credential.helper store . from huggingface_hub import notebook_login notebook_login() . Login successful Your token has been saved to /root/.huggingface/token . Then you need to install Git-LFS. Uncomment the following instructions: . !apt install git-lfs . Reading package lists... Done Building dependency tree Reading state information... Done git-lfs is already the newest version (2.3.4-1). 0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded. . Make sure your version of Transformers is at least 4.11.0 since the functionality was introduced in that version: . import transformers print(transformers.__version__) . 4.12.5 . You can find a script version of this notebook to fine-tune your model in a distributed fashion using multiple GPUs or TPUs here. . Fine-tuning a model on a token classification task . In this notebook, we will see how to fine-tune one of the 🤗 Transformers model to a token classification task, which is the task of predicting a label for each token. . . The most common token classification tasks are: . NER (Named-entity recognition) Classify the entities in the text (person, organization, location...). | POS (Part-of-speech tagging) Grammatically classify the tokens (noun, verb, adjective...) | Chunk (Chunking) Grammatically classify the tokens and group them into &quot;chunks&quot; that go together | . We will see how to easily load a dataset for these kinds of tasks and use the Trainer API to fine-tune a model on it. . This notebook is built to run on any token classification task, with any model checkpoint from the Model Hub as long as that model has a version with a token classification head and a fast tokenizer (check on this table if this is the case). It might just need some small adjustments if you decide to use a different dataset than the one used here. Depending on you model and the GPU you are using, you might need to adjust the batch size to avoid out-of-memory errors. Set those three parameters, then the rest of the notebook should run smoothly: . task = &quot;ner&quot; # Should be one of &quot;ner&quot;, &quot;pos&quot; or &quot;chunk&quot; model_checkpoint = &quot;jimregan/BERTreach&quot; batch_size = 16 . Loading the dataset . We will use the 🤗 Datasets library to download the data and get the metric we need to use for evaluation (to compare our model to the benchmark). This can be easily done with the functions load_dataset and load_metric. . from datasets import load_dataset, load_metric . For our example here, we&#39;ll use the CONLL 2003 dataset. The notebook should work with any token classification dataset provided by the 🤗 Datasets library. If you&#39;re using your own dataset defined from a JSON or csv file (see the Datasets documentation on how to load them), it might need some adjustments in the names of the columns used. . datasets = load_dataset(&quot;wikiann&quot;, &quot;ga&quot;) . Reusing dataset wikiann (/root/.cache/huggingface/datasets/wikiann/ga/1.1.0/4bfd4fe4468ab78bb6e096968f61fab7a888f44f9d3371c2f3fea7e74a5a354e) . The datasets object itself is DatasetDict, which contains one key for the training, validation and test set. . datasets . DatasetDict({ validation: Dataset({ features: [&#39;tokens&#39;, &#39;ner_tags&#39;, &#39;langs&#39;, &#39;spans&#39;], num_rows: 1000 }) test: Dataset({ features: [&#39;tokens&#39;, &#39;ner_tags&#39;, &#39;langs&#39;, &#39;spans&#39;], num_rows: 1000 }) train: Dataset({ features: [&#39;tokens&#39;, &#39;ner_tags&#39;, &#39;langs&#39;, &#39;spans&#39;], num_rows: 1000 }) }) . We can see the training, validation and test sets all have a column for the tokens (the input texts split into words) and one column of labels for each kind of task we introduced before. . To access an actual element, you need to select a split first, then give an index: . datasets[&quot;train&quot;][0] . {&#39;langs&#39;: [&#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;, &#39;ga&#39;], &#39;ner_tags&#39;: [0, 1, 2, 2, 0, 0, 0, 0, 5, 0, 0, 0], &#39;spans&#39;: [&#39;PER: Pádraig Mac Piarais&#39;, &#39;LOC: Éireannach&#39;], &#39;tokens&#39;: [&#39;**&#39;, &#39;Pádraig&#39;, &#39;Mac&#39;, &#39;Piarais&#39;, &#39;,&#39;, &#39;36&#39;, &#39;,&#39;, &#39;réabhlóidí&#39;, &#39;Éireannach&#39;, &#39;agus&#39;, &#39;[[file&#39;, &#39;.&#39;]} . The labels are already coded as integer ids to be easily usable by our model, but the correspondence with the actual categories is stored in the features of the dataset: . datasets[&quot;train&quot;].features[f&quot;ner_tags&quot;] . Sequence(feature=ClassLabel(num_classes=7, names=[&#39;O&#39;, &#39;B-PER&#39;, &#39;I-PER&#39;, &#39;B-ORG&#39;, &#39;I-ORG&#39;, &#39;B-LOC&#39;, &#39;I-LOC&#39;], names_file=None, id=None), length=-1, id=None) . So for the NER tags, 0 corresponds to &#39;O&#39;, 1 to &#39;B-PER&#39; etc... On top of the &#39;O&#39; (which means no special entity), there are four labels for NER here, each prefixed with &#39;B-&#39; (for beginning) or &#39;I-&#39; (for intermediate), that indicate if the token is the first one for the current group with the label or not: . &#39;PER&#39; for person | &#39;ORG&#39; for organization | &#39;LOC&#39; for location | &#39;MISC&#39; for miscellaneous | . Since the labels are lists of ClassLabel, the actual names of the labels are nested in the feature attribute of the object above: . label_list = datasets[&quot;train&quot;].features[f&quot;{task}_tags&quot;].feature.names label_list . [&#39;O&#39;, &#39;B-PER&#39;, &#39;I-PER&#39;, &#39;B-ORG&#39;, &#39;I-ORG&#39;, &#39;B-LOC&#39;, &#39;I-LOC&#39;] . To get a sense of what the data looks like, the following function will show some examples picked randomly in the dataset (automatically decoding the labels in passing). . from datasets import ClassLabel, Sequence import random import pandas as pd from IPython.display import display, HTML def show_random_elements(dataset, num_examples=10): assert num_examples &lt;= len(dataset), &quot;Can&#39;t pick more elements than there are in the dataset.&quot; picks = [] for _ in range(num_examples): pick = random.randint(0, len(dataset)-1) while pick in picks: pick = random.randint(0, len(dataset)-1) picks.append(pick) df = pd.DataFrame(dataset[picks]) for column, typ in dataset.features.items(): if isinstance(typ, ClassLabel): df[column] = df[column].transform(lambda i: typ.names[i]) elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel): df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x]) display(HTML(df.to_html())) . show_random_elements(datasets[&quot;train&quot;]) . tokens ner_tags langs spans . 0 [Burghley, House, ,, Belton, House] | [B-ORG, I-ORG, O, B-ORG, I-ORG] | [ga, ga, ga, ga, ga] | [ORG: Burghley House, ORG: Belton House] | . 1 [Ollscoil, Chathair, Bhaile, Átha, Cliath] | [B-ORG, I-ORG, I-ORG, I-ORG, I-ORG] | [ga, ga, ga, ga, ga] | [ORG: Ollscoil Chathair Bhaile Átha Cliath] | . 2 [Dúchasach, do, réigiún, na, Meánmhara, .] | [O, O, O, B-LOC, I-LOC, O] | [ga, ga, ga, ga, ga, ga] | [LOC: na Meánmhara] | . 3 [Páirc, an, Chrócaigh, ,, Baile, Átha, Cliath] | [B-ORG, I-ORG, I-ORG, O, B-LOC, I-LOC, I-LOC] | [ga, ga, ga, ga, ga, ga, ga] | [ORG: Páirc an Chrócaigh, LOC: Baile Átha Cliath] | . 4 [Tráigh, Mhór, ,, An, Tuirc] | [B-ORG, I-ORG, O, B-LOC, I-LOC] | [ga, ga, ga, ga, ga] | [ORG: Tráigh Mhór, LOC: An Tuirc] | . 5 [Bhí, turas, An, Ríocht, Aontaithe, agus, Éire, acu, ón, Eanair, go, dtí, mBealtaine, .] | [O, O, B-LOC, I-LOC, I-LOC, O, B-LOC, O, O, O, O, O, O, O] | [ga, ga, ga, ga, ga, ga, ga, ga, ga, ga, ga, ga, ga, ga] | [LOC: An Ríocht Aontaithe, LOC: Éire] | . 6 [Tá, an, staid, tógtha, ar, shuíomh, Bhóthair, Lansdúin, .] | [O, O, O, O, O, O, B-ORG, I-ORG, O] | [ga, ga, ga, ga, ga, ga, ga, ga, ga] | [ORG: Bhóthair Lansdúin] | . 7 [athsheoladh, Pól, I, na, Rúise] | [O, B-PER, I-PER, I-PER, I-PER] | [ga, ga, ga, ga, ga] | [PER: Pól I na Rúise] | . 8 [Liam, Ó, Leathlobhair] | [B-PER, I-PER, I-PER] | [ga, ga, ga] | [PER: Liam Ó Leathlobhair] | . 9 [athsheoladh, Séamas, II, Shasana] | [O, B-PER, I-PER, I-PER] | [ga, ga, ga, ga] | [PER: Séamas II Shasana] | . Preprocessing the data . Before we can feed those texts to our model, we need to preprocess them. This is done by a 🤗 Transformers Tokenizer which will (as the name indicates) tokenize the inputs (including converting the tokens to their corresponding IDs in the pretrained vocabulary) and put it in a format the model expects, as well as generate the other inputs that model requires. . To do all of this, we instantiate our tokenizer with the AutoTokenizer.from_pretrained method, which will ensure: . we get a tokenizer that corresponds to the model architecture we want to use, | we download the vocabulary used when pretraining this specific checkpoint. | . That vocabulary will be cached, so it&#39;s not downloaded again the next time we run the cell. . from transformers import RobertaTokenizerFast tokenizer = RobertaTokenizerFast.from_pretrained(model_checkpoint, add_prefix_space=True) . loading file https://huggingface.co/jimregan/BERTreach/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/9f02739afcb15f79a914d1dc3852921b35c28165868f21dc938b1219ff615ae7.dc1449771f2e5fcd30cf6d6723ec65f8c1106371f6ba60c9466df8d5e1567bca loading file https://huggingface.co/jimregan/BERTreach/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/0bd2316742dd7dd681cffbf4529ec3e97708bf173b741af7c38e60b3f649ed5a.2cbdc9a92c69faaa4556153a1d778a80b85e34b0d4cedb5774e31773edef57fd loading file https://huggingface.co/jimregan/BERTreach/resolve/main/tokenizer.json from cache at None loading file https://huggingface.co/jimregan/BERTreach/resolve/main/added_tokens.json from cache at None loading file https://huggingface.co/jimregan/BERTreach/resolve/main/special_tokens_map.json from cache at None loading file https://huggingface.co/jimregan/BERTreach/resolve/main/tokenizer_config.json from cache at None loading configuration file https://huggingface.co/jimregan/BERTreach/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/82da4bf21418a60a0d196c50342fe927af2c9187b87d319e7def1608dfdc0954.f6ebc79ab803ca349ef7b469b0fbe6aa40d053e3c1c2da0501521c46c2a51bb7 Model config RobertaConfig { &#34;architectures&#34;: [ &#34;RobertaForMaskedLM&#34; ], &#34;attention_probs_dropout_prob&#34;: 0.1, &#34;bos_token_id&#34;: 0, &#34;classifier_dropout&#34;: null, &#34;eos_token_id&#34;: 2, &#34;gradient_checkpointing&#34;: false, &#34;hidden_act&#34;: &#34;gelu&#34;, &#34;hidden_dropout_prob&#34;: 0.1, &#34;hidden_size&#34;: 768, &#34;initializer_range&#34;: 0.02, &#34;intermediate_size&#34;: 3072, &#34;layer_norm_eps&#34;: 1e-12, &#34;max_position_embeddings&#34;: 514, &#34;model_type&#34;: &#34;roberta&#34;, &#34;num_attention_heads&#34;: 12, &#34;num_hidden_layers&#34;: 6, &#34;pad_token_id&#34;: 1, &#34;position_embedding_type&#34;: &#34;absolute&#34;, &#34;transformers_version&#34;: &#34;4.12.5&#34;, &#34;type_vocab_size&#34;: 1, &#34;use_cache&#34;: true, &#34;vocab_size&#34;: 52000 } loading configuration file https://huggingface.co/jimregan/BERTreach/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/82da4bf21418a60a0d196c50342fe927af2c9187b87d319e7def1608dfdc0954.f6ebc79ab803ca349ef7b469b0fbe6aa40d053e3c1c2da0501521c46c2a51bb7 Model config RobertaConfig { &#34;architectures&#34;: [ &#34;RobertaForMaskedLM&#34; ], &#34;attention_probs_dropout_prob&#34;: 0.1, &#34;bos_token_id&#34;: 0, &#34;classifier_dropout&#34;: null, &#34;eos_token_id&#34;: 2, &#34;gradient_checkpointing&#34;: false, &#34;hidden_act&#34;: &#34;gelu&#34;, &#34;hidden_dropout_prob&#34;: 0.1, &#34;hidden_size&#34;: 768, &#34;initializer_range&#34;: 0.02, &#34;intermediate_size&#34;: 3072, &#34;layer_norm_eps&#34;: 1e-12, &#34;max_position_embeddings&#34;: 514, &#34;model_type&#34;: &#34;roberta&#34;, &#34;num_attention_heads&#34;: 12, &#34;num_hidden_layers&#34;: 6, &#34;pad_token_id&#34;: 1, &#34;position_embedding_type&#34;: &#34;absolute&#34;, &#34;transformers_version&#34;: &#34;4.12.5&#34;, &#34;type_vocab_size&#34;: 1, &#34;use_cache&#34;: true, &#34;vocab_size&#34;: 52000 } . The following assertion ensures that our tokenizer is a fast tokenizers (backed by Rust) from the 🤗 Tokenizers library. Those fast tokenizers are available for almost all models, and we will need some of the special features they have for our preprocessing. . import transformers assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast) . You can check which type of models have a fast tokenizer available and which don&#39;t on the big table of models. . You can directly call this tokenizer on one sentence: . tokenizer(&quot;Is abairt amháin é seo!&quot;) . {&#39;input_ids&#39;: [0, 574, 3152, 799, 350, 369, 5, 2], &#39;attention_mask&#39;: [1, 1, 1, 1, 1, 1, 1, 1]} . Depending on the model you selected, you will see different keys in the dictionary returned by the cell above. They don&#39;t matter much for what we&#39;re doing here (just know they are required by the model we will instantiate later), you can learn more about them in this tutorial if you&#39;re interested. . If, as is the case here, your inputs have already been split into words, you should pass the list of words to your tokenzier with the argument is_split_into_words=True: . tokenizer([&quot;Hello&quot;, &quot;,&quot;, &quot;this&quot;, &quot;is&quot;, &quot;one&quot;, &quot;sentence&quot;, &quot;split&quot;, &quot;into&quot;, &quot;words&quot;, &quot;.&quot;], is_split_into_words=True) . {&#39;input_ids&#39;: [0, 838, 25201, 1094, 10285, 381, 15195, 50991, 5359, 809, 786, 2512, 22339, 38628, 968, 2], &#39;attention_mask&#39;: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]} . Note that transformers are often pretrained with subword tokenizers, meaning that even if your inputs have been split into words already, each of those words could be split again by the tokenizer. Let&#39;s look at an example of that: . example = datasets[&quot;train&quot;][4] print(example[&quot;tokens&quot;]) . [&#39;Tá&#39;, &#39;Áras&#39;, &#39;an&#39;, &#39;Uachtaráin&#39;, &#39;(&#39;, &#39;áit&#39;, &#39;chónaithe&#39;, &#39;oifigiúil&#39;, &#39;Uachtarán&#39;, &#39;na&#39;, &#39;hÉireann&#39;, &#39;)&#39;, &#39;,&#39;, &#34;&#39;&#39;Deerfield&#34;, &#34;&#39;&#39;&#34;, &#39;(&#39;, &#39;áit&#39;, &#39;chónaithe&#39;, &#39;oifigiúil&#39;, &#39;Ambasadóir&#39;, &#39;Stáit&#39;, &#39;Aontaithe&#39;, &#39;Mheiriceá&#39;, &#39;)&#39;, &#39;,&#39;, &#39;Zú&#39;, &#39;Bhaile&#39;, &#39;Átha&#39;, &#39;Cliath&#39;, &#39;,&#39;, &#39;agus&#39;, &#39;Ceanncheathrú&#39;, &#39;an&#39;, &#39;Gharda&#39;, &#39;Síochána&#39;, &#39;go&#39;, &#39;léir&#39;, &#39;laistigh&#39;, &#39;den&#39;, &#39;pháirc&#39;, &#39;.&#39;] . tokenized_input = tokenizer(example[&quot;tokens&quot;], is_split_into_words=True) tokens = tokenizer.convert_ids_to_tokens(tokenized_input[&quot;input_ids&quot;]) print(tokens) . [&#39;&lt;s&gt;&#39;, &#39;ĠTÃ¡&#39;, &#39;ĠÃģras&#39;, &#39;Ġan&#39;, &#39;ĠUachtarÃ¡in&#39;, &#39;Ġ(&#39;, &#39;ĠÃ¡it&#39;, &#39;ĠchÃ³naithe&#39;, &#39;ĠoifigiÃºil&#39;, &#39;ĠUachtarÃ¡n&#39;, &#39;Ġna&#39;, &#39;ĠhÃīireann&#39;, &#39;Ġ)&#39;, &#39;Ġ,&#39;, &#34;Ġ&#39;&#39;&#34;, &#39;De&#39;, &#39;er&#39;, &#39;field&#39;, &#34;Ġ&#39;&#39;&#34;, &#39;Ġ(&#39;, &#39;ĠÃ¡it&#39;, &#39;ĠchÃ³naithe&#39;, &#39;ĠoifigiÃºil&#39;, &#39;ĠAmbasadÃ³ir&#39;, &#39;ĠStÃ¡it&#39;, &#39;ĠAontaithe&#39;, &#39;ĠMheiriceÃ¡&#39;, &#39;Ġ)&#39;, &#39;Ġ,&#39;, &#39;ĠZ&#39;, &#39;Ãº&#39;, &#39;ĠBhaile&#39;, &#39;ĠÃģtha&#39;, &#39;ĠCliath&#39;, &#39;Ġ,&#39;, &#39;Ġagus&#39;, &#39;ĠCeanncheathrÃº&#39;, &#39;Ġan&#39;, &#39;ĠGharda&#39;, &#39;ĠSÃŃochÃ¡na&#39;, &#39;Ġgo&#39;, &#39;ĠlÃ©ir&#39;, &#39;Ġlaistigh&#39;, &#39;Ġden&#39;, &#39;ĠphÃ¡irc&#39;, &#39;Ġ.&#39;, &#39;&lt;/s&gt;&#39;] . Here the words &quot;Zwingmann&quot; and &quot;sheepmeat&quot; have been split in three subtokens. . This means that we need to do some processing on our labels as the input ids returned by the tokenizer are longer than the lists of labels our dataset contain, first because some special tokens might be added (we can a [CLS] and a [SEP] above) and then because of those possible splits of words in multiple tokens: . len(example[f&quot;{task}_tags&quot;]), len(tokenized_input[&quot;input_ids&quot;]) . (41, 47) . Thankfully, the tokenizer returns outputs that have a word_ids method which can help us. . print(tokenized_input.word_ids()) . [None, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 13, 13, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, None] . As we can see, it returns a list with the same number of elements as our processed input ids, mapping special tokens to None and all other tokens to their respective word. This way, we can align the labels with the processed input ids. . word_ids = tokenized_input.word_ids() aligned_labels = [-100 if i is None else example[f&quot;{task}_tags&quot;][i] for i in word_ids] print(len(aligned_labels), len(tokenized_input[&quot;input_ids&quot;])) . 47 47 . Here we set the labels of all special tokens to -100 (the index that is ignored by PyTorch) and the labels of all other tokens to the label of the word they come from. Another strategy is to set the label only on the first token obtained from a given word, and give a label of -100 to the other subtokens from the same word. We propose the two strategies here, just change the value of the following flag: . label_all_tokens = True . We&#39;re now ready to write the function that will preprocess our samples. We feed them to the tokenizer with the argument truncation=True (to truncate texts that are bigger than the maximum size allowed by the model) and is_split_into_words=True (as seen above). Then we align the labels with the token ids using the strategy we picked: . def tokenize_and_align_labels(examples): tokenized_inputs = tokenizer(examples[&quot;tokens&quot;], truncation=True, is_split_into_words=True) labels = [] for i, label in enumerate(examples[f&quot;{task}_tags&quot;]): word_ids = tokenized_inputs.word_ids(batch_index=i) previous_word_idx = None label_ids = [] for word_idx in word_ids: # Special tokens have a word id that is None. We set the label to -100 so they are automatically # ignored in the loss function. if word_idx is None: label_ids.append(-100) # We set the label for the first token of each word. elif word_idx != previous_word_idx: label_ids.append(label[word_idx]) # For the other tokens in a word, we set the label to either the current label or -100, depending on # the label_all_tokens flag. else: label_ids.append(label[word_idx] if label_all_tokens else -100) previous_word_idx = word_idx labels.append(label_ids) tokenized_inputs[&quot;labels&quot;] = labels return tokenized_inputs . This function works with one or several examples. In the case of several examples, the tokenizer will return a list of lists for each key: . tokenize_and_align_labels(datasets[&#39;train&#39;][:5]) . Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation. . {&#39;input_ids&#39;: [[0, 5236, 14, 3650, 1619, 21240, 1094, 8584, 1094, 40980, 3337, 306, 6292, 74, 1806, 968, 2], [0, 5236, 14, 15068, 12965, 15693, 384, 4010, 17, 4294, 2], [0, 1146, 80, 1494, 15796, 691, 1094, 17961, 691, 2], [0, 691, 15693, 6207, 48172, 15693, 691, 2], [0, 1281, 11516, 275, 9918, 384, 756, 9978, 4030, 3476, 304, 1147, 4294, 1094, 15693, 1855, 553, 10428, 15693, 384, 756, 9978, 4030, 34067, 1647, 1927, 3616, 4294, 1094, 3999, 276, 2268, 1461, 1397, 1094, 306, 49963, 275, 5247, 4226, 341, 896, 1813, 460, 8981, 968, 2]], &#39;attention_mask&#39;: [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], &#39;labels&#39;: [[-100, 0, 0, 1, 2, 2, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, -100], [-100, 0, 0, 3, 4, 0, 0, 0, 0, 0, -100], [-100, 1, 1, 1, 0, 0, 0, 0, 0, -100], [-100, 0, 0, 5, 5, 0, 0, -100], [-100, 0, 3, 4, 4, 0, 0, 0, 0, 3, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 6, 6, 0, 0, 3, 3, 4, 4, 4, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, -100]]} . To apply this function on all the sentences (or pairs of sentences) in our dataset, we just use the map method of our dataset object we created earlier. This will apply the function on all the elements of all the splits in dataset, so our training, validation and testing data will be preprocessed in one single command. . tokenized_datasets = datasets.map(tokenize_and_align_labels, batched=True) . Even better, the results are automatically cached by the 🤗 Datasets library to avoid spending time on this step the next time you run your notebook. The 🤗 Datasets library is normally smart enough to detect when the function you pass to map has changed (and thus requires to not use the cache data). For instance, it will properly detect if you change the task in the first cell and rerun the notebook. 🤗 Datasets warns you when it uses cached files, you can pass load_from_cache_file=False in the call to map to not use the cached files and force the preprocessing to be applied again. . Note that we passed batched=True to encode the texts by batches together. This is to leverage the full benefit of the fast tokenizer we loaded earlier, which will use multi-threading to treat the texts in a batch concurrently. . Fine-tuning the model . Now that our data is ready, we can download the pretrained model and fine-tune it. Since all our tasks are about token classification, we use the AutoModelForTokenClassification class. Like with the tokenizer, the from_pretrained method will download and cache the model for us. The only thing we have to specify is the number of labels for our problem (which we can get from the features, as seen before): . from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer, AutoConfig config = AutoConfig.from_pretrained(model_checkpoint, id2label={i: label for i, label in enumerate(label_list)}, label2id={label: i for i, label in enumerate(label_list)}) model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, config=config) . loading configuration file https://huggingface.co/jimregan/BERTreach/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/82da4bf21418a60a0d196c50342fe927af2c9187b87d319e7def1608dfdc0954.f6ebc79ab803ca349ef7b469b0fbe6aa40d053e3c1c2da0501521c46c2a51bb7 Model config RobertaConfig { &#34;architectures&#34;: [ &#34;RobertaForMaskedLM&#34; ], &#34;attention_probs_dropout_prob&#34;: 0.1, &#34;bos_token_id&#34;: 0, &#34;classifier_dropout&#34;: null, &#34;eos_token_id&#34;: 2, &#34;gradient_checkpointing&#34;: false, &#34;hidden_act&#34;: &#34;gelu&#34;, &#34;hidden_dropout_prob&#34;: 0.1, &#34;hidden_size&#34;: 768, &#34;id2label&#34;: { &#34;0&#34;: &#34;O&#34;, &#34;1&#34;: &#34;B-PER&#34;, &#34;2&#34;: &#34;I-PER&#34;, &#34;3&#34;: &#34;B-ORG&#34;, &#34;4&#34;: &#34;I-ORG&#34;, &#34;5&#34;: &#34;B-LOC&#34;, &#34;6&#34;: &#34;I-LOC&#34; }, &#34;initializer_range&#34;: 0.02, &#34;intermediate_size&#34;: 3072, &#34;label2id&#34;: { &#34;B-LOC&#34;: 5, &#34;B-ORG&#34;: 3, &#34;B-PER&#34;: 1, &#34;I-LOC&#34;: 6, &#34;I-ORG&#34;: 4, &#34;I-PER&#34;: 2, &#34;O&#34;: 0 }, &#34;layer_norm_eps&#34;: 1e-12, &#34;max_position_embeddings&#34;: 514, &#34;model_type&#34;: &#34;roberta&#34;, &#34;num_attention_heads&#34;: 12, &#34;num_hidden_layers&#34;: 6, &#34;pad_token_id&#34;: 1, &#34;position_embedding_type&#34;: &#34;absolute&#34;, &#34;transformers_version&#34;: &#34;4.12.5&#34;, &#34;type_vocab_size&#34;: 1, &#34;use_cache&#34;: true, &#34;vocab_size&#34;: 52000 } https://huggingface.co/jimregan/BERTreach/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpv5o9vvd8 storing https://huggingface.co/jimregan/BERTreach/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/dd1b4fd9cac1b246d8d0fd055990d19837145ab67cc89c1c8a1af624e6679469.1da935a4b98fa14d6de9a52c0e4217ff97b262012d6f20bce405f3128b3b539d creating metadata file for /root/.cache/huggingface/transformers/dd1b4fd9cac1b246d8d0fd055990d19837145ab67cc89c1c8a1af624e6679469.1da935a4b98fa14d6de9a52c0e4217ff97b262012d6f20bce405f3128b3b539d loading weights file https://huggingface.co/jimregan/BERTreach/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/dd1b4fd9cac1b246d8d0fd055990d19837145ab67cc89c1c8a1af624e6679469.1da935a4b98fa14d6de9a52c0e4217ff97b262012d6f20bce405f3128b3b539d Some weights of the model checkpoint at jimregan/BERTreach were not used when initializing RobertaForTokenClassification: [&#39;lm_head.decoder.weight&#39;, &#39;lm_head.layer_norm.weight&#39;, &#39;lm_head.decoder.bias&#39;, &#39;lm_head.bias&#39;, &#39;lm_head.dense.bias&#39;, &#39;lm_head.layer_norm.bias&#39;, &#39;lm_head.dense.weight&#39;] - This IS expected if you are initializing RobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model). - This IS NOT expected if you are initializing RobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model). Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at jimregan/BERTreach and are newly initialized: [&#39;classifier.weight&#39;, &#39;classifier.bias&#39;] You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference. . The warning is telling us we are throwing away some weights (the vocab_transform and vocab_layer_norm layers) and randomly initializing some other (the pre_classifier and classifier layers). This is absolutely normal in this case, because we are removing the head used to pretrain the model on a masked language modeling objective and replacing it with a new head for which we don&#39;t have pretrained weights, so the library warns us we should fine-tune this model before using it for inference, which is exactly what we are going to do. . To instantiate a Trainer, we will need to define three more things. The most important is the TrainingArguments, which is a class that contains all the attributes to customize the training. It requires one folder name, which will be used to save the checkpoints of the model, and all other arguments are optional: . model_name = model_checkpoint.split(&quot;/&quot;)[-1] args = TrainingArguments( f&quot;BERTreach-finetuned-{task}&quot;, evaluation_strategy = &quot;epoch&quot;, learning_rate=2e-5, per_device_train_batch_size=batch_size, per_device_eval_batch_size=batch_size, num_train_epochs=5, weight_decay=0.01, push_to_hub=True, ) . PyTorch: setting up devices The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-). . Here we set the evaluation to be done at the end of each epoch, tweak the learning rate, use the batch_size defined at the top of the notebook and customize the number of epochs for training, as well as the weight decay. . The last argument to setup everything so we can push the model to the Hub regularly during training. Remove it if you didn&#39;t follow the installation steps at the top of the notebook. If you want to save your model locally in a name that is different than the name of the repository it will be pushed, or if you want to push your model under an organization and not your name space, use the hub_model_id argument to set the repo name (it needs to be the full name, including your namespace: for instance &quot;sgugger/bert-finetuned-ner&quot; or &quot;huggingface/bert-finetuned-ner&quot;). . Then we will need a data collator that will batch our processed examples together while applying padding to make them all the same size (each pad will be padded to the length of its longest example). There is a data collator for this task in the Transformers library, that not only pads the inputs, but also the labels: . from transformers import DataCollatorForTokenClassification data_collator = DataCollatorForTokenClassification(tokenizer) . The last thing to define for our Trainer is how to compute the metrics from the predictions. Here we will load the seqeval metric (which is commonly used to evaluate results on the CONLL dataset) via the Datasets library. . metric = load_metric(&quot;seqeval&quot;) . This metric takes list of labels for the predictions and references: . labels = [label_list[i] for i in example[f&quot;{task}_tags&quot;]] metric.compute(predictions=[labels], references=[labels]) . {&#39;LOC&#39;: {&#39;f1&#39;: 1.0, &#39;number&#39;: 1, &#39;precision&#39;: 1.0, &#39;recall&#39;: 1.0}, &#39;ORG&#39;: {&#39;f1&#39;: 1.0, &#39;number&#39;: 4, &#39;precision&#39;: 1.0, &#39;recall&#39;: 1.0}, &#39;overall_accuracy&#39;: 1.0, &#39;overall_f1&#39;: 1.0, &#39;overall_precision&#39;: 1.0, &#39;overall_recall&#39;: 1.0} . So we will need to do a bit of post-processing on our predictions: . select the predicted index (with the maximum logit) for each token | convert it to its string label | ignore everywhere we set a label of -100 | . The following function does all this post-processing on the result of Trainer.evaluate (which is a namedtuple containing predictions and labels) before applying the metric: . import numpy as np def compute_metrics(p): predictions, labels = p predictions = np.argmax(predictions, axis=2) # Remove ignored index (special tokens) true_predictions = [ [label_list[p] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels) ] true_labels = [ [label_list[l] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels) ] results = metric.compute(predictions=true_predictions, references=true_labels) return { &quot;precision&quot;: results[&quot;overall_precision&quot;], &quot;recall&quot;: results[&quot;overall_recall&quot;], &quot;f1&quot;: results[&quot;overall_f1&quot;], &quot;accuracy&quot;: results[&quot;overall_accuracy&quot;], } . Note that we drop the precision/recall/f1 computed for each category and only focus on the overall precision/recall/f1/accuracy. . Then we just need to pass all of this along with our datasets to the Trainer: . trainer = Trainer( model, args, train_dataset=tokenized_datasets[&quot;train&quot;], eval_dataset=tokenized_datasets[&quot;validation&quot;], data_collator=data_collator, tokenizer=tokenizer, compute_metrics=compute_metrics ) . Cloning https://huggingface.co/jimregan/BERTreach-finetuned-ner into local empty directory. . We can now finetune our model by just calling the train method: . trainer.train() . The following columns in the training set don&#39;t have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running training ***** Num examples = 1000 Num Epochs = 5 Instantaneous batch size per device = 16 Total train batch size (w. parallel, distributed &amp; accumulation) = 16 Gradient Accumulation steps = 1 Total optimization steps = 315 . . [315/315 20:00, Epoch 5/5] Epoch Training Loss Validation Loss Precision Recall F1 Accuracy . 1 | No log | 0.724926 | 0.364474 | 0.390508 | 0.377042 | 0.758436 | . 2 | No log | 0.585039 | 0.452903 | 0.494831 | 0.472940 | 0.807228 | . 3 | No log | 0.519152 | 0.494885 | 0.545583 | 0.518999 | 0.828796 | . 4 | No log | 0.504173 | 0.520788 | 0.559211 | 0.539316 | 0.834835 | . 5 | No log | 0.494351 | 0.520052 | 0.566729 | 0.542388 | 0.836561 | . &lt;/div&gt; &lt;/div&gt; The following columns in the evaluation set don&#39;t have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running Evaluation ***** Num examples = 1000 Batch size = 16 The following columns in the evaluation set don&#39;t have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running Evaluation ***** Num examples = 1000 Batch size = 16 The following columns in the evaluation set don&#39;t have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running Evaluation ***** Num examples = 1000 Batch size = 16 The following columns in the evaluation set don&#39;t have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running Evaluation ***** Num examples = 1000 Batch size = 16 The following columns in the evaluation set don&#39;t have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running Evaluation ***** Num examples = 1000 Batch size = 16 Training completed. Do not forget to share your model on huggingface.co/models =) . TrainOutput(global_step=315, training_loss=0.5451592823815724, metrics={&#39;train_runtime&#39;: 1204.9135, &#39;train_samples_per_second&#39;: 4.15, &#39;train_steps_per_second&#39;: 0.261, &#39;total_flos&#39;: 40232543021088.0, &#39;train_loss&#39;: 0.5451592823815724, &#39;epoch&#39;: 5.0}) . &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; The evaluate method allows you to evaluate again on the evaluation dataset or on another dataset: . trainer.evaluate() . The following columns in the evaluation set don&#39;t have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running Evaluation ***** Num examples = 1000 Batch size = 16 . . [63/63 00:44] {&#39;epoch&#39;: 5.0, &#39;eval_accuracy&#39;: 0.8365605828220859, &#39;eval_f1&#39;: 0.5423881268270744, &#39;eval_loss&#39;: 0.49435117840766907, &#39;eval_precision&#39;: 0.5200517464424321, &#39;eval_recall&#39;: 0.5667293233082706, &#39;eval_runtime&#39;: 45.3099, &#39;eval_samples_per_second&#39;: 22.07, &#39;eval_steps_per_second&#39;: 1.39} . To get the precision/recall/f1 computed for each category now that we have finished training, we can apply the same function as before on the result of the predict method: . predictions, labels, _ = trainer.predict(tokenized_datasets[&quot;validation&quot;]) predictions = np.argmax(predictions, axis=2) # Remove ignored index (special tokens) true_predictions = [ [label_list[p] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels) ] true_labels = [ [label_list[l] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels) ] results = metric.compute(predictions=true_predictions, references=true_labels) results . The following columns in the test set don&#39;t have a corresponding argument in `RobertaForTokenClassification.forward` and have been ignored: spans, tokens, ner_tags, langs. ***** Running Prediction ***** Num examples = 1000 Batch size = 16 . . [63/63 01:29] {&#39;LOC&#39;: {&#39;f1&#39;: 0.602130616025938, &#39;number&#39;: 1026, &#39;precision&#39;: 0.5736981465136805, &#39;recall&#39;: 0.6335282651072125}, &#39;ORG&#39;: {&#39;f1&#39;: 0.45705024311183146, &#39;number&#39;: 572, &#39;precision&#39;: 0.4259818731117825, &#39;recall&#39;: 0.493006993006993}, &#39;PER&#39;: {&#39;f1&#39;: 0.5199240986717268, &#39;number&#39;: 530, &#39;precision&#39;: 0.5229007633587787, &#39;recall&#39;: 0.5169811320754717}, &#39;overall_accuracy&#39;: 0.8365605828220859, &#39;overall_f1&#39;: 0.5423881268270744, &#39;overall_precision&#39;: 0.5200517464424321, &#39;overall_recall&#39;: 0.5667293233082706} . You can now upload the result of the training to the Hub, just execute this instruction: . trainer.push_to_hub() . Saving model checkpoint to BERTreach-finetuned-ner Configuration saved in BERTreach-finetuned-ner/config.json Model weights saved in BERTreach-finetuned-ner/pytorch_model.bin tokenizer config file saved in BERTreach-finetuned-ner/tokenizer_config.json Special tokens file saved in BERTreach-finetuned-ner/special_tokens_map.json To https://huggingface.co/jimregan/BERTreach-finetuned-ner cbc2561..d938626 main -&gt; main To https://huggingface.co/jimregan/BERTreach-finetuned-ner d938626..bc9642b main -&gt; main . &#39;https://huggingface.co/jimregan/BERTreach-finetuned-ner/commit/d938626d52f5779f475e84e8c628740fda278353&#39; . You can now share this model with all your friends, family, favorite pets: they can all load it with the identifier &quot;your-username/the-name-you-picked&quot; so for instance: . from transformers import AutoModelForTokenClassification model = AutoModelForTokenClassification.from_pretrained(&quot;sgugger/my-awesome-model&quot;) . &lt;/div&gt; .",
            "url": "https://jimregan.github.io/notes/irish/ner/bert/bertreach/2021/12/01/token_classification_bertreach.html",
            "relUrl": "/irish/ner/bert/bertreach/2021/12/01/token_classification_bertreach.html",
            "date": " • Dec 1, 2021"
        }
        
    
  
    
        ,"post92": {
            "title": "Interesting links, 29/11/2021",
            "content": "Acmhainní Gaedhilge . Voces Uladh - mo sheanfhoclóirín do Ghaeilge Uladh . Taisce Focal.doc . Mion-ċaint na Miḋe agus Ulaḋ : Pádraig Ó Dubhthaigh . The Irish Language in Rathlin Island, Co. Antrim : Nils M. Holmer . Duanaire na Miḋe : Laoide, Seosamh, d. 1939 . Seaċrán Ċairn tSiaḋail : aṁrán ilċeardaiḋeaċta agus seanċas síor-ċuartaiḋeċta : Ó hÍr, Micheál . Léightheoracht . Sean-Ghnás Mhuinntir Mhusgrave . Cnuasacht Béaloideas Uladh . BBC - Irish - Ceann Dubhrann - sraith le John Ghráinne ó Rann na Feirste . BBC Radio Ulster - Ceann Dubhrann, 05/07/2011, Ceann Dubhrann - eipeasóid 1 . An Embryonic English-Ulster Irish Dictionary . Stair Faoi Cheilt . GAELDICT - Gaelic Textbase - An Milliún Focal Conallach . Tobar na Gaedhilge . Cruinneas Gaedhilge . Focla agus Cainnteanna Gaedhilge I .",
            "url": "https://jimregan.github.io/notes/links/2021/11/29/misc-links.html",
            "relUrl": "/links/2021/11/29/misc-links.html",
            "date": " • Nov 29, 2021"
        }
        
    
  
    
        ,"post93": {
            "title": "Title",
            "content": "Scrape Europarl . &quot;Scrape Europarl for video data&quot; . toc:false- branch: master | badges: false | comments: true | hidden: true | categories: [europarl, scraper] | . import requests from bs4 import BeautifulSoup import json . _URL = &quot;https://multimedia.europarl.europa.eu/ga/search?sn=true&amp;st=EPV_EDITED_VIDEOS-WS_VIDEO&amp;ut=EPV_REPLAY-EPV_VIDEO_FOOTAGE-EPV_PHOTO-EPV_AUDIO&amp;ol=EPV_EDITED_VIDEOS&amp;lg=ga_IE&amp;at=1&amp;p_p_id=advanced_search_portlet_AdvancedSearchPortlet&amp;_advanced_search_portlet_AdvancedSearchPortlet_p=&quot; . def get_soup(num = &quot;1&quot;): req = requests.get(_URL + num) if req.status_code != 200: raise Exception(&quot;Problem scraping page &quot; + num) return BeautifulSoup(req.content, &quot;lxml&quot;) . def get_last_page_number(soup): for last_candidate in soup.find_all(&quot;li&quot;, {&quot;class&quot;: &quot;last&quot;}): anchors = last_candidate.find_all(&quot;a&quot;) for anchor in anchors: # if &quot;href&quot; in anchor and &quot;AdvancedSearchPortlet_p&quot; in anchor[&quot;href&quot;]: if &quot;AdvancedSearchPortlet_p&quot; in anchor[&quot;href&quot;]: eq_pos = anchor[&quot;href&quot;].rfind(&quot;=&quot;) return anchor[&quot;href&quot;][eq_pos + 1:] . def get_video_urls(videos): video_urls = [] no_url = [] for video in videos: item = {} if &quot;europarltv-link&quot; not in video.text: no_url.append(video) vid_url = video.find(&quot;a&quot;, {&quot;class&quot;, &quot;europarltv-link&quot;}) item[&quot;url&quot;] = &quot;https://multimedia.europarl.europa.eu&quot; + vid_url[&quot;href&quot;] data_divs = video.find_all(&quot;div&quot;, {&quot;class&quot;: &quot;media-quick-actions&quot;}) for data_div in data_divs: if data_div.has_attr(&quot;data-id&quot;): item[&quot;data_id&quot;] = data_div[&quot;data-id&quot;] video_urls.append(item) return video_urls . def scrape_video_page(num = &quot;1&quot;, soup = None): if soup is None: req = requests.get(_URL + num) if req.status_code != 200: raise Exception(&quot;Problem scraping page &quot; + num) soup = BeautifulSoup(req.content, &quot;lxml&quot;) videos = soup.find_all(&quot;div&quot;, {&quot;class&quot;: &quot;media-preview&quot;}) return get_video_urls(videos) . soup = get_soup() last = get_last_page_number(soup) videos = scrape_video_page(num = &quot;1&quot;) for num in range(2, int(last) + 1): videos += scrape_video_page(num = str(num)) . _JSON_REQUEST = &quot;&quot;&quot; { &quot;1&quot;:{&quot;service&quot;:&quot;session&quot;,&quot;action&quot;:&quot;startWidgetSession&quot;,&quot;widgetId&quot;:&quot;_102&quot;}, &quot;2&quot;:{&quot;service&quot;:&quot;baseEntry&quot;,&quot;action&quot;:&quot;list&quot;,&quot;ks&quot;:&quot;{1:result:ks}&quot;, &quot;filter&quot;:{&quot;redirectFromEntryId&quot;:&quot;DUMMY_ENTRY_ID&quot;}, &quot;responseProfile&quot;:{&quot;type&quot;:1, &quot;fields&quot;:&quot;id,referenceId,name,description,thumbnailUrl,dataUrl,duration,msDuration,flavorParamsIds,mediaType,type,tags,dvrStatus,externalSourceType,status&quot;}}, &quot;3&quot;:{&quot;service&quot;:&quot;baseEntry&quot;,&quot;action&quot;:&quot;getPlaybackContext&quot;, &quot;entryId&quot;:&quot;{2:result:objects:0:id}&quot;,&quot;ks&quot;:&quot;{1:result:ks}&quot;, &quot;contextDataParams&quot;:{&quot;objectType&quot;:&quot;KalturaContextDataParams&quot;,&quot;flavorTags&quot;:&quot;all&quot;}}, &quot;4&quot;:{&quot;service&quot;:&quot;metadata_metadata&quot;,&quot;action&quot;:&quot;list&quot;, &quot;filter&quot;:{&quot;objectType&quot;:&quot;KalturaMetadataFilter&quot;, &quot;objectIdEqual&quot;:&quot;DUMMY_ENTRY_ID&quot;,&quot;metadataObjectTypeEqual&quot;:&quot;1&quot;}, &quot;ks&quot;:&quot;{1:result:ks}&quot;},&quot;apiVersion&quot;:&quot;3.3.0&quot;,&quot;format&quot;:1,&quot;ks&quot;:&quot;&quot;, &quot;clientTag&quot;:&quot;html5:v0.53.7&quot;,&quot;partnerId&quot;:102 } &quot;&quot;&quot; . _MULT_HEADERS = { &quot;Content-Type&quot;: &quot;application/json&quot;, &quot;Origin&quot;: &quot;https://multimedia.europarl.europa.eu&quot;, &quot;Sec-Fetch-Site&quot;: &quot;same-site&quot;, &quot;Sec-Fetch-Mode&quot;: &quot;cors&quot;, &quot;Sec-Fetch-Dest&quot;: &quot;empty&quot; } . def get_vid_id(url): response = requests.get(url) if response.status_code != 200: #print(&quot;Problem scraping page &quot; + url) return None soup = BeautifulSoup(response.content, &quot;lxml&quot;) ogvid = soup.find(&quot;meta&quot;, {&quot;property&quot;: &quot;og:video&quot;}) if ogvid and ogvid.has_attr(&quot;content&quot;): cont = ogvid[&quot;content&quot;] cont = cont.split(&quot;entryId/&quot;)[1] cont = cont.split(&quot;/v/&quot;)[0] return cont else: return None . def get_vid_id2(content_id): response = requests.get(f&quot;https://multimedia.europarl.europa.eu/ga/c/portal/layout?p_l_id=39691&amp;p_p_id=media_quick_actions_portlet_MediaQuickActionsPortlet&amp;p_p_lifecycle=0&amp;p_p_state=exclusive&amp;_media_quick_actions_portlet_MediaQuickActionsPortlet_mvcPath=%2Fhtml%2Ftogglers%2Fpreview_toggler.jsp&amp;_media_quick_actions_portlet_MediaQuickActionsPortlet_mediaId={content_id}&amp;_media_quick_actions_portlet_MediaQuickActionsPortlet_arrowDivXPositionStart=-912.4258792266845&amp;_media_quick_actions_portlet_MediaQuickActionsPortlet_arrowDivXLength=461&quot;) if response.status_code != 200: return None if not &quot;kalturaPlayer.loadMedia&quot; in response.text: return None prune = response.text.split(&quot;kalturaPlayer.loadMedia&quot;)[1] return prune.split(&quot;&#39;&quot;)[1] . def get_json_body(vid_id): actual_json = _JSON_REQUEST.replace(&quot; n&quot;, &quot;&quot;).replace(&quot;DUMMY_ENTRY_ID&quot;, vid_id) response = requests.post(&quot;https://kmc.europarltv.europa.eu/api_v3/service/multirequest&quot;, headers=_MULT_HEADERS, data=actual_json) body = json.loads(response.content) return body . def get_subtitles(body): subtitles = {} for part in body: if &#39;playbackCaptions&#39; in part: for subtitle in part[&#39;playbackCaptions&#39;]: if &#39;languageCode&#39; in subtitle: lang_code = subtitle[&#39;languageCode&#39;] else: lang_code = None if &#39;webVttUrl&#39; in subtitle: webvtt = subtitle[&#39;webVttUrl&#39;] else: webvtt = None if webvtt is not None and lang_code is not None: subtitles[lang_code] = webvtt else: continue return subtitles . def get_video(body): for part in body: if &quot;sources&quot; in part: for source in part[&quot;sources&quot;]: if source[&quot;url&quot;].endswith(&quot;.mp4&quot;): return source[&quot;url&quot;] . data = [] for item in videos: url = item[&quot;url&quot;] item[&quot;id&quot;] = get_vid_id2(item[&quot;data_id&quot;]) if &quot;id&quot; not in item or item[&quot;id&quot;] is None: item[&quot;id&quot;] = get_vid_id(url) if &quot;id&quot; not in item or item[&quot;id&quot;] is None: print(url) continue body = get_json_body(item[&quot;id&quot;]) item[&quot;video&quot;] = get_video(body) item[&quot;vtts&quot;] = get_subtitles(body) data.append(item) . https://multimedia.europarl.europa.eu/ga/how-we-do-it-rationalise-policy-on-illegal-immigrants-long-version_Y009-00017-L_ev . with open(&#39;europarl.json&#39;, &#39;w&#39;) as outfile: json.dump(data, outfile) .",
            "url": "https://jimregan.github.io/notes/2021/11/27/scrape-europarl-videos.html",
            "relUrl": "/2021/11/27/scrape-europarl-videos.html",
            "date": " • Nov 27, 2021"
        }
        
    
  
    
        ,"post94": {
            "title": "Sgéilíní na Finne",
            "content": "The original site is mirrored here . URLS = &quot;&quot;&quot; http://web.archive.org/web/20160720003620/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal01.html http://web.archive.org/web/20160612133120/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal02.html http://web.archive.org/web/20160612133013/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal03.html http://web.archive.org/web/20160612133127/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal04.html http://web.archive.org/web/20160612132904/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal05.html http://web.archive.org/web/20160612133018/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal06.html http://web.archive.org/web/20160612133132/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal07.html http://web.archive.org/web/20160612133302/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal08.html http://web.archive.org/web/20160612132911/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal09.html http://web.archive.org/web/20160612133023/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal10.html http://web.archive.org/web/20160612133308/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal11.html http://web.archive.org/web/20160612133028/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal12.html http://web.archive.org/web/20160612133137/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal13.html http://web.archive.org/web/20160612133033/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal14.html http://web.archive.org/web/20160612133313/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal15.html http://web.archive.org/web/20160612132916/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal16.html http://web.archive.org/web/20160612133144/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal17.html http://web.archive.org/web/20160612133149/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal18.html http://web.archive.org/web/20160612133154/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal19.html http://web.archive.org/web/20160612132921/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal20.html http://web.archive.org/web/20160612133039/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal21.html http://web.archive.org/web/20160612133159/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal22.html http://web.archive.org/web/20160612132926/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal23.html http://web.archive.org/web/20160612133204/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal24.html http://web.archive.org/web/20160612133044/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal25.html http://web.archive.org/web/20160612133059/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal26.html http://web.archive.org/web/20160612132931/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal27.html http://web.archive.org/web/20160612133318/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal28.html http://web.archive.org/web/20160612133323/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal29.html http://web.archive.org/web/20160612132936/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal30.html http://web.archive.org/web/20160612132941/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal31.html http://web.archive.org/web/20160612132946/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal32.html http://web.archive.org/web/20160612133328/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal33.html http://web.archive.org/web/20160612132951/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal34.html http://web.archive.org/web/20160612133209/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal35.html http://web.archive.org/web/20160612133218/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal36.html http://web.archive.org/web/20160608213843/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal37.html &quot;&quot;&quot; . MODERN = &quot;&quot;&quot; ruadh rua ruaidh ruaí chomhnuidhe chónaí cheann-tuigheadh cheann tuíadh rabh raibh da dá muinteardha muinteartha chroidhe chroí saoghal saol éirghe éirí leath-mheasardha leathmheasartha brúighte brúite cráidhte cráite báidhte báite de&#39;n den &quot;&quot;&quot; . For the most part, the modernised forms are the standard forms. Others, such as &#39;ruaí&#39;, exist as dialectal forms, while &#39;ceann tuíadh&#39; does not, but this matches what was spoken. . UNATTESTED = &quot;&quot;&quot; cheann-tuigheadh &quot;&quot;&quot; . STANDARD = &quot;&quot;&quot; ruaidh rua caidé cad é cheann-tuigheadh cheann tuí &quot;&quot;&quot; . PREPEND_SCEAL = &quot;02 03&quot; PREPEND_CEACHT = &quot;04 05&quot; PREPEND_UIMHIR = &quot;06 07 08 09 10 11 12 13 14 15 16 18 23&quot; . _tmp_mod = [a.split(&quot; t&quot;) for a in MODERN.split(&quot; n&quot;) if &quot; t&quot; in a] . modern = {a[0]: a[1] for a in _tmp_mod} . _END_TB = &quot;&lt;!-- END WAYBACK TOOLBAR INSERT --&gt;&quot; . import requests from bs4 import BeautifulSoup . test = &quot;http://web.archive.org/web/20160612132931/http://www.smo.uhi.ac.uk/~oduibhin/sf/sceal27.html&quot; req = requests.get(test) . req.status_code . 200 . text = req.text if _END_TB in text: text = text.split(_END_TB)[1] if &quot;&lt;hr&gt;&quot; in text: text = text.split(&quot;&lt;hr&gt;&quot;)[0].strip() . text . extt = BeautifulSoup(text, &quot;lxml&quot;) . extt.text . header = extt.find(&quot;font&quot;, {&quot;size&quot;: 5}) . titles = header.find_all(&quot;b&quot;) . if len(titles) == 1: title = titles[0].text . title . &#39;Críonnacht Madaidh.&#39; . for i in extt.find_all(&quot;font&quot;, {&quot;size&quot;: 5}): i.decompose() . extt .",
            "url": "https://jimregan.github.io/notes/irish/scraper/todo/2021/11/26/sgeilini-na-finne.html",
            "relUrl": "/irish/scraper/todo/2021/11/26/sgeilini-na-finne.html",
            "date": " • Nov 26, 2021"
        }
        
    
  
    
        ,"post95": {
            "title": "Interesting links, 25/11/2021",
            "content": "ELS-RD/transformer-deploy — Deploy optimized transformer based models in production . davidbrochart/nbterm . Fine-tuning XLS-R for Multi-Lingual ASR with 🤗 Transformers, fairseq, Facebook AI blog . facebookresearch/covost . CoVoST 2 and Massively Multilingual Speech-to-Text Translation . Pygments lexer . jusText 3 — jusText is a tool for removing boilerplate content . Onion — onion (ONe Instance ONly) is a tool for removing duplicate parts from large collections of texts. . rsling/texrex — texrex web page cleaning &amp; ClaraX random walk crawler . Common Crawled web corpora . Representation Learning with Contrastive Predictive Coding, facebookresearch/CPC_audio . bshall/VectorQuantizedCPC . menelik3/cmudict-ipa — The CMU Pronouncing Dictionary converted to IPA . A cross-linguistic database of phonetic transcription systems . glottobank/potential-of-cognate-detection — Source code and data accompanying the paper “The Potential of Automatic Word Comparison for Historical Linguistics” . glottobank/tukano — Repository for computer-guided reconstruction with Jena wordlist standard for Tukano language data . Cpc vox populi #965 . flashlight/flashlight/app/asr/tools/alignment . wav2letter/recipes/lexicon_free . CMU Advanced NLP 2021 Prompting + Sequence-to-sequence Pre-training . ming024/FastSpeech2 — An implementation of Microsoft’s “FastSpeech 2: Fast and High-Quality End-to-End Text to Speech” . [Phrase Retrieval and Beyond | Princeton NLP Group](https://princeton-nlp.github.io/phrase-retrieval-and-beyond/) | . princeton-nlp/PURE A Frustratingly Easy Approach for Entity and Relation Extraction . princeton-nlp/LM-BFF LM-BFF. Better Few-shot Fine-tuning of Language Models . Docusaurus . camelot-dev/camelot — A Python library to extract tabular data from PDFs . neural-network-and-data-loading.ipynb . jina-ai/finetuner — Finetuning any DNN for better embedding on neural search tasks . ddbourgin/numpy-ml . jina-ai/jina — Cloud-native neural search framework for 𝙖𝙣𝙮 kind of data . kaldialign/setup.py . nnmnkwii_gallery/01-DNN-based statistical speech synthesis (en).ipynb . Character-level Convolutional Networks for Text Classification . toganlabs/seanchlo_keyboard/ . Todo . Die araner mundart/Lautlehre . Die araner mundart/Wörterbuch/æ ȧ – Wikisource . L’Accent dans le gaëlique du Munster - Wikisource . patrickvonplaten/Wav2Vec2_PyCTCDecode . kensho-technologies/pyctcdecode . What’s New in v3.2 . kaldi/run_segmentation_long_utts.sh . kaldi/egs/wsj/s5/steps/cleanup . kaldi/clean_and_segment_data.sh . kaldi/decode_segmentation.sh . Paracrawl . [OSCAR 21.09 | OSCAR](https://oscar-corpus.com/post/oscar-v21-09/) | . kaldialign/calign.pxd . ga-conj-1a .",
            "url": "https://jimregan.github.io/notes/links/2021/11/25/misc-links.html",
            "relUrl": "/links/2021/11/25/misc-links.html",
            "date": " • Nov 25, 2021"
        }
        
    
  
    
        ,"post96": {
            "title": "Interesting links, 23/11/2021",
            "content": "Tutorial on ASR inference and alignment with CTC model . gaBERT – an Irish Language Model . Speech Resynthesis from Discrete Disentangled Self-Supervised Representations . facebookresearch/libri-light, blog . Libri-light Data Preparation and Download . fairseq/examples/textless_nlp/gslm/speech2unit/clustering . fairseq/cpc_feature_reader.py . fairseq/examples/textless_nlp/gslm . fairseq/resynthesize_speech.py . flashlight/InferenceAndAlignmentCTC.ipynb . libri-light/make_vad_inputs.py . libri-light/data_preparation . Data Preparation · flashlight/wav2letter Wiki . libri-light/wl_decoder.py . format-corpus/pdfCabinetOfHorrors . [Text and tables Extraction from docx in Python | by Mukesh Kumar | Medium](https://medium.com/@Mukesh_Kumar/text-extraction-from-docx-readable-pdf-and-scanned-pdf-formats-in-python-b6c5712271ee) | . language-resources/make-alignable-symbols.cc .",
            "url": "https://jimregan.github.io/notes/links/2021/11/23/misc-links.html",
            "relUrl": "/links/2021/11/23/misc-links.html",
            "date": " • Nov 23, 2021"
        }
        
    
  
    
        ,"post97": {
            "title": "Interesting links, 18/11/2021",
            "content": "Comhairle Gaeilge . PEIG.ie . Seó Bóthair - Conradh na Gaeilge . Gaeilge.ie . An Ghaeilge . An Gum . XML Sitemap . Gluaiseacht . Tuiscint don Ealaín - An Gum . XML Sitemap Feed . [An Tairseach | COGG](https://www.cogg.ie/tairseach/) | . [Acmhainní Tacaíochta | COGG](https://www.cogg.ie/acmhainni-tacaiochta—gaeilge-na-sraithe-sinsearai/) | . Tíreolaíocht na hArdteiste . Studyclix . [Acmhainní Teanga ar Líne | COGG](https://www.cogg.ie/focloiri/) | . Ranganna.com . Gaeilge na Sraithe Sinsearaí . Léann Teanga - An Reiviú . www.acadamh.ie . An Taibhdhearc . [Taighde COGG | COGG](https://www.cogg.ie/taighde-cogg/) | . Wayback Machine . Acadamh - NUI Galway .",
            "url": "https://jimregan.github.io/notes/links/todo/irish/scraper/2021/11/18/irish-to-scrape.html",
            "relUrl": "/links/todo/irish/scraper/2021/11/18/irish-to-scrape.html",
            "date": " • Nov 18, 2021"
        }
        
    
  
    
        ,"post98": {
            "title": "Interesting links, 17/11/2021",
            "content": "lumaku/ctc-segmentation — Segment an audio file and obtain utterance alignments. (Python package) . My Munster Irish Library . Multilingual Transfer of Acoustic Word Embeddings Improves When Training on Languages Related to the Target Zero-Resource Language, pdf . @inproceedings{jacobs21_interspeech, author={Christiaan Jacobs and Herman Kamper}, title={Multilingual {T}ransfer of {A}coustic {W}ord {E}mbeddings {I}mproves when {T}raining on {L}anguages {R}elated to the {T}arget {Z}ero-{R}esource {L}anguage}, year=2021, booktitle={Proc. Interspeech 2021}, pages={1549--1553}, doi={10.21437/Interspeech.2021-461} } . Towards Unsupervised Phone and Word Segmentation Using Self-Supervised Vector-Quantized Neural Networks, pdf . @inproceedings{kamper21_interspeech, author={Herman Kamper and Benjamin van Niekerk}, title={Towards {U}nsupervised {P}hone and {W}ord {S}egmentation Using {S}elf-{S}upervised {V}ector-{Q}uantized {N}eural {N}etworks}, year=2021, booktitle={Proc. Interspeech 2021}, pages={1539--1543}, doi={10.21437/Interspeech.2021-50} } . bshall/VectorQuantizedCPC — Vector-Quantized Contrastive Predictive Coding for Acoustic Unit Discovery and Voice Conversion . worldveil/dejavu — Audio fingerprinting and recognition in Python . Self-Supervised End-to-End ASR for Low Resource L2 Swedish, pdf, data to appear in Kielipankki . @inproceedings{alghezi21_interspeech, author={Ragheb Al-Ghezi and Yaroslav Getman and Aku Rouhe and Raili Hildén and Mikko Kurimo}, title={Self-{S}upervised {E}nd-to-{E}nd {ASR} for {L}ow {R}esource {L2} {S}wedish}, year=2021, booktitle={Proc. Interspeech 2021}, pages={1429--1433}, doi={10.21437/Interspeech.2021-1710} } . xinjli/allosaurus — Allosaurus is a pretrained universal phone recognizer for more than 2000 languages . cldf/cldf[https://github.com/cldf/cldf] CLDF — Cross-Linguistic Data Formats . kylebgorman/perceptronix — Sparse and dense linear models, for C++ and Python, with funny optimizations . AI - Here for Good — National Artificial Intelligence Strategy for Ireland . National-AI-Strategy.pdf . neulab/awesome-align — A neural word aligner based on multilingual BERT . xinjli/allosaurus — Allosaurus is a pretrained universal phone recognizer for more than 2000 languages . neuspell/neuspell — A Neural Spelling Correction Toolkit . Gender in Irish between continuity and change . Re-open . kaldi-long-audio-alignment/build-trigram.sh . voxpopuli/voxpopuli/segmentation . voxpopuli/get_segment_pyannote_speaker.py . amsehili/auditok — An audio/acoustic activity detection and audio segmentation tool . voxpopuli/run_pyannote_sd.py . silero-vad.ipynb . kaldi/make_biased_lm_graphs.sh at master . kaldi/learn_lexicon_greedy.sh at master . kaldi/egs/wsj/s5/steps/segmentation at master . Wymysorys . Wymysorys pronunciation . Wp/wym/Adam Mickiewicz . A Andrason and T Krol WYMYSORYS GRAMMAR . Language attitudes in Wilamowice part 2 wym . Józef Gara - Słownik języka wilamowskiego . Józef Gara - Zbiór wierszy o wilamowskich obrzędach i obyczajach.pdf . Vilamovian terms with IPA pronunciation - Wiktionary . Slownik jezyka wilamowskiego . Aragonese . Arredol . Academia de l’Aragon .",
            "url": "https://jimregan.github.io/notes/links/2021/11/17/misc-links.html",
            "relUrl": "/links/2021/11/17/misc-links.html",
            "date": " • Nov 17, 2021"
        }
        
    
  
    
        ,"post99": {
            "title": "Split sentences from datasets",
            "content": "!pip install mosestokenizer . from datasets import load_dataset . script = &quot;/home/jim/Playing/notes/_drafts/nos.py&quot; nos = load_dataset(script, &#39;documents&#39;) . from mosestokenizer import * . sentences = 0 with MosesSentenceSplitter(&#39;ga&#39;) as splitsents: with open(&quot;/tmp/nos.txt&quot;, &quot;w&quot;) as outf: for item in nos[&#39;train&#39;]: outf.write(item[&#39;title&#39;] + &quot; n&quot;) sentences += 1 if not item[&#39;text&#39;]: continue sents = splitsents([item[&#39;text&#39;]]) sentences += len(sents) for sentence in sents: outf.write(sentence + &quot; n&quot;) . sentences .",
            "url": "https://jimregan.github.io/notes/datasets/2021/11/16/split-sentences-datasets.html",
            "relUrl": "/datasets/2021/11/16/split-sentences-datasets.html",
            "date": " • Nov 16, 2021"
        }
        
    
  
    
        ,"post100": {
            "title": "Convert to flac for wav2vec",
            "content": "BASE_PATH = &quot;/home/jim/Playing/unlabelled&quot; . files = [] with open(f&quot;{BASE_PATH}/ina/no-music&quot;) as inf: for line in inf.readlines(): stripped = line.strip() if stripped.startswith(&quot;./&quot;): stripped = stripped[2:] if stripped.endswith(&quot;.csv&quot;): stripped = stripped[0:-4] files.append(stripped) . exts = [&quot;m4a&quot;, &quot;mkv&quot;, &quot;mp3&quot;, &quot;MP3&quot;, &quot;mp4&quot;, &quot;wav&quot;] . from pathlib import Path . data = {} for file in files: for ext in exts: pathstr = f&quot;{BASE_PATH}/{file}.{ext}&quot; cur_path = Path(pathstr) if cur_path.is_file(): data[file] = pathstr . from pydub import AudioSegment . for basename, fname in data.items(): outstr = f&quot;{BASE_PATH}/flac/{basename}.flac&quot; audio = AudioSegment.from_file(fname) audio.export(outstr, format=&quot;flac&quot;, parameters=[&quot;-ac&quot;, &quot;1&quot;, &quot;-ar&quot;, &quot;16000&quot;]) . count = 1 with open(f&quot;{BASE_PATH}/vad_input.txt&quot;, &quot;w&quot;) as outf: for basename, fname in data.items(): outstr = f&quot;{BASE_PATH}/flac/{basename}.flac&quot; audio = AudioSegment.from_file(outstr) outf.write(f&quot;train{count:04d} {outstr} {audio.duration_seconds} n&quot;) count += 1 .",
            "url": "https://jimregan.github.io/notes/pydub/2021/11/12/convert-flac-for-fairseq.html",
            "relUrl": "/pydub/2021/11/12/convert-flac-for-fairseq.html",
            "date": " • Nov 12, 2021"
        }
        
    
  
    
        ,"post101": {
            "title": "Allosaurus to list",
            "content": "def allosaurus_to_list(filename): output = [] with open(filename) as f: for l in f.readlines(): line = l.strip().split(&quot; &quot;) output.append([line[0], line[2]]) return output . %%writefile test.txt 0.510 0.045 n 0.600 0.045 i 0.900 0.045 a 0.990 0.045 l 1.050 0.045 d 1.110 0.045 pʲ 1.170 0.045 a 1.290 0.045 j 1.410 0.045 d . Writing test.txt . l = allosaurus_to_list(&quot;test.txt&quot;) . starts = [&#39;0.00&#39;] + [f[0] for f in l[0:-1]] . massaged = . [&#39;0.00&#39;, &#39;0.510&#39;, &#39;0.600&#39;, &#39;0.900&#39;, &#39;0.990&#39;, &#39;1.050&#39;, &#39;1.110&#39;, &#39;1.170&#39;, &#39;1.290&#39;] .",
            "url": "https://jimregan.github.io/notes/allosaurus/2021/11/11/allosaurus-to-list.html",
            "relUrl": "/allosaurus/2021/11/11/allosaurus-to-list.html",
            "date": " • Nov 11, 2021"
        }
        
    
  
    
        ,"post102": {
            "title": "Interesting links, 9/11/2021",
            "content": "Open English WordNet, github . babysor/MockingBird — Chinese voice cloning . Paste to Markdown . Middle Irish for Festus . erikrose/parsimonious . Irish lemmatiser for SpaCy, commit + data, commit . PyTorch Implementation of Daft-Exprt Robust Prosody Transfer Across Speakers for Expressive Speech Synthesis . kylebgorman/SOTA-taggers — Code for Gorman &amp; Bedrick’s “We need to talk about standard splits” (ACL ‘19) . kylebgorman/latin_scansion . google/WikipediaHomographData . kylebgorman/swipe — A pitch tracker using Camacho’s SWIPE’ algorithm, written in C . kylebgorman/perceptronix . microsoft/UniSpeech — UniSpeech - Large Scale Self-Supervised Learning for Speech . facebookresearch/speech-resynthesis — An official reimplementation of the method described in the INTERSPEECH 2021 paper - Speech Resynthesis from Discrete Disentangled Self-Supervised Representations. arXiv — not open source . flashlight/InferenceAndAlignmentCTC.ipynb . facebookresearch/libri-light . Leveraging Phone Mask Training for Phonetic-Reduction-Robust E2E Uyghur Speech Recognition, pdf . @inproceedings{ma21_interspeech, author={Guodong Ma and Pengfei Hu and Jian Kang and Shen Huang and Hao Huang}, title={Leveraging {P}hone {M}ask {T}raining for {P}honetic-{R}eduction-{R}obust {E2E} {U}yghur {S}peech {R}ecognition}, year=2021, booktitle={Proc. Interspeech 2021}, pages={306--310}, doi={10.21437/Interspeech.2021-964} } . Robust wav2vec 2.0: Analyzing Domain Shift in Self-Supervised Pre-Training, pdf . @inproceedings{hsu21_interspeech, author={Wei-Ning Hsu and Anuroop Sriram and Alexei Baevski and Tatiana Likhomanenko and Qiantong Xu and Vineel Pratap and Jacob Kahn and Ann Lee and Ronan Collobert and Gabriel Synnaeve and Michael Auli}, title={Robust wav2vec 2.0&amp;: {A}nalyzing {D}omain {S}hift in {S}elf-{S}upervised {P}re-{T}raining}, year=2021, booktitle={Proc. Interspeech 2021}, pages={721--725}, doi={10.21437/Interspeech.2021-236} } . wav2vec-C: A Self-Supervised Model for Speech Representation Learning, pdf . @inproceedings{sadhu21_interspeech, author={Samik Sadhu and Di He and Che-Wei Huang and Sri Harish Mallidi and Minhua Wu and Ariya Rastrow and Andreas Stolcke and Jasha Droppo and Roland Maas}, title={wav2vec-{C}: {A} {S}elf-{S}upervised {M}odel for {S}peech {R}epresentation {L}earning}, year=2021, booktitle={Proc. Interspeech 2021}, pages={711--715}, doi={10.21437/Interspeech.2021-717} } . audino A Modern Annotation Tool for Audio and Speech, midas-research/audino . CNN Explainer . Description d’un parler irlandais de Kerry . Die araner mundart . Getting to Know the Mel Spectrogram . The Most Important Music Theory And How It Helps You Play Better . Diatonic Triads Diatonic 7th Chords . C: C E G B | Cmaj7 | . Dm: D F A C | Dm7 | . Em: E G B D | Em7 | . F: F A C E | Fmaj7 | . G: G B D F | G7 | . Am: A C E G | Am7 | . Bo: B D F A | Bm7b5 (Bø) | .",
            "url": "https://jimregan.github.io/notes/links/2021/11/09/misc-links.html",
            "relUrl": "/links/2021/11/09/misc-links.html",
            "date": " • Nov 9, 2021"
        }
        
    
  
    
        ,"post103": {
            "title": "Basic wiki template parser using parsimonious",
            "content": "from parsimonious.grammar import Grammar grammar = Grammar( &quot;&quot;&quot; tplcall = tplopen tpltext (tplinner)+ tplclose tplinner = named / positional named = bar tpltext eq tpltext positional = bar tpltext tpltext = (&quot;{{=}}&quot; / ~r&quot;[^ } |=]&quot;)* tplchar = ~r&quot;[^ } |=]&quot; tplopen = &quot;{{&quot; tplclose = &quot;}}&quot; eq = &quot;=&quot; bar = &quot;|&quot; &quot;&quot;&quot; ) . test1 = &quot;{{tpl|foo|bar=baz||fooish{{=}}bar}}&quot; . print(grammar.parse(test1)) . &lt;Node called &#34;tplcall&#34; matching &#34;{{tpl|foo|bar=baz||fooish{{=}}bar}}&#34;&gt; &lt;Node called &#34;tplopen&#34; matching &#34;{{&#34;&gt; &lt;Node called &#34;tpltext&#34; matching &#34;tpl&#34;&gt; &lt;Node matching &#34;t&#34;&gt; &lt;RegexNode matching &#34;t&#34;&gt; &lt;Node matching &#34;p&#34;&gt; &lt;RegexNode matching &#34;p&#34;&gt; &lt;Node matching &#34;l&#34;&gt; &lt;RegexNode matching &#34;l&#34;&gt; &lt;Node matching &#34;|foo|bar=baz||fooish{{=}}bar&#34;&gt; &lt;Node called &#34;tplinner&#34; matching &#34;|foo&#34;&gt; &lt;Node called &#34;positional&#34; matching &#34;|foo&#34;&gt; &lt;Node called &#34;bar&#34; matching &#34;|&#34;&gt; &lt;Node called &#34;tpltext&#34; matching &#34;foo&#34;&gt; &lt;Node matching &#34;f&#34;&gt; &lt;RegexNode matching &#34;f&#34;&gt; &lt;Node matching &#34;o&#34;&gt; &lt;RegexNode matching &#34;o&#34;&gt; &lt;Node matching &#34;o&#34;&gt; &lt;RegexNode matching &#34;o&#34;&gt; &lt;Node called &#34;tplinner&#34; matching &#34;|bar=baz&#34;&gt; &lt;Node called &#34;named&#34; matching &#34;|bar=baz&#34;&gt; &lt;Node called &#34;bar&#34; matching &#34;|&#34;&gt; &lt;Node called &#34;tpltext&#34; matching &#34;bar&#34;&gt; &lt;Node matching &#34;b&#34;&gt; &lt;RegexNode matching &#34;b&#34;&gt; &lt;Node matching &#34;a&#34;&gt; &lt;RegexNode matching &#34;a&#34;&gt; &lt;Node matching &#34;r&#34;&gt; &lt;RegexNode matching &#34;r&#34;&gt; &lt;Node called &#34;eq&#34; matching &#34;=&#34;&gt; &lt;Node called &#34;tpltext&#34; matching &#34;baz&#34;&gt; &lt;Node matching &#34;b&#34;&gt; &lt;RegexNode matching &#34;b&#34;&gt; &lt;Node matching &#34;a&#34;&gt; &lt;RegexNode matching &#34;a&#34;&gt; &lt;Node matching &#34;z&#34;&gt; &lt;RegexNode matching &#34;z&#34;&gt; &lt;Node called &#34;tplinner&#34; matching &#34;|&#34;&gt; &lt;Node called &#34;positional&#34; matching &#34;|&#34;&gt; &lt;Node called &#34;bar&#34; matching &#34;|&#34;&gt; &lt;Node called &#34;tpltext&#34; matching &#34;&#34;&gt; &lt;Node called &#34;tplinner&#34; matching &#34;|fooish{{=}}bar&#34;&gt; &lt;Node called &#34;positional&#34; matching &#34;|fooish{{=}}bar&#34;&gt; &lt;Node called &#34;bar&#34; matching &#34;|&#34;&gt; &lt;Node called &#34;tpltext&#34; matching &#34;fooish{{=}}bar&#34;&gt; &lt;Node matching &#34;f&#34;&gt; &lt;RegexNode matching &#34;f&#34;&gt; &lt;Node matching &#34;o&#34;&gt; &lt;RegexNode matching &#34;o&#34;&gt; &lt;Node matching &#34;o&#34;&gt; &lt;RegexNode matching &#34;o&#34;&gt; &lt;Node matching &#34;i&#34;&gt; &lt;RegexNode matching &#34;i&#34;&gt; &lt;Node matching &#34;s&#34;&gt; &lt;RegexNode matching &#34;s&#34;&gt; &lt;Node matching &#34;h&#34;&gt; &lt;RegexNode matching &#34;h&#34;&gt; &lt;Node matching &#34;{{=}}&#34;&gt; &lt;Node matching &#34;{{=}}&#34;&gt; &lt;Node matching &#34;b&#34;&gt; &lt;RegexNode matching &#34;b&#34;&gt; &lt;Node matching &#34;a&#34;&gt; &lt;RegexNode matching &#34;a&#34;&gt; &lt;Node matching &#34;r&#34;&gt; &lt;RegexNode matching &#34;r&#34;&gt; &lt;Node called &#34;tplclose&#34; matching &#34;}}&#34;&gt; .",
            "url": "https://jimregan.github.io/notes/wiki/parsimonious/2021/11/08/basic-wiki-template-parser-with-parsimonious.html",
            "relUrl": "/wiki/parsimonious/2021/11/08/basic-wiki-template-parser-with-parsimonious.html",
            "date": " • Nov 8, 2021"
        }
        
    
  
    
        ,"post104": {
            "title": "Basic parser for Finck",
            "content": "!pip install parsimonious . from parsimonious.grammar import Grammar grammar = Grammar( &quot;&quot;&quot; node = seealso / translation seealso = italictxt comma ws see ws italictxt fullstop translation = italictxt fullstop ws german german = openq qtext closeq italictxt = italics phntext italics italics = &quot;*&quot; see = &quot;s.&quot; comma = &quot;,&quot; fullstop = &quot;.&quot; trscr = ~r&quot;[-æšaiŕəhxkšŕ̥cĺlāl̄ȧēmvńun̄]+&quot; phntext = ~r&#39;[^ *]+&#39; qtext = ~r&#39;[^&quot;]+&#39; num = ~r&#39;[0-9]+&#39; ref = &quot;St.-B.&quot; / &quot;W.&quot; gen = &quot;gen.&quot; ctext = ~r&#39;[^,]+&#39; openq = &quot;„&quot; closeq = &#39;&quot;&#39; ws = ~&quot; s*&quot; &quot;&quot;&quot;) . test = &quot;*ævńəxə*, s. *auən̄*.&quot; test2 = &#39;*ḱŕeȷĭm ə n-æš-aiŕə nə gorp*. „Ich glaube an eine auferstehung des fleisches.&quot;&#39; . print(grammar.parse(test2)) . &lt;Node called &#34;node&#34; matching &#34;*ḱŕeȷĭm ə n-æš-aiŕə nə gorp*. „Ich glaube an eine auferstehung des fleisches.&#34;&#34;&gt; &lt;Node called &#34;translation&#34; matching &#34;*ḱŕeȷĭm ə n-æš-aiŕə nə gorp*. „Ich glaube an eine auferstehung des fleisches.&#34;&#34;&gt; &lt;Node called &#34;italictxt&#34; matching &#34;*ḱŕeȷĭm ə n-æš-aiŕə nə gorp*&#34;&gt; &lt;Node called &#34;italics&#34; matching &#34;*&#34;&gt; &lt;RegexNode called &#34;phntext&#34; matching &#34;ḱŕeȷĭm ə n-æš-aiŕə nə gorp&#34;&gt; &lt;Node called &#34;italics&#34; matching &#34;*&#34;&gt; &lt;Node called &#34;fullstop&#34; matching &#34;.&#34;&gt; &lt;RegexNode called &#34;ws&#34; matching &#34; &#34;&gt; &lt;Node called &#34;german&#34; matching &#34;„Ich glaube an eine auferstehung des fleisches.&#34;&#34;&gt; &lt;Node called &#34;openq&#34; matching &#34;„&#34;&gt; &lt;RegexNode called &#34;qtext&#34; matching &#34;Ich glaube an eine auferstehung des fleisches.&#34;&gt; &lt;Node called &#34;closeq&#34; matching &#34;&#34;&#34;&gt; .",
            "url": "https://jimregan.github.io/notes/finck/parsimonious/2021/11/07/parsimonious-for-finck.html",
            "relUrl": "/finck/parsimonious/2021/11/07/parsimonious-for-finck.html",
            "date": " • Nov 7, 2021"
        }
        
    
  
    
        ,"post105": {
            "title": "Interesting links, 3/11/2021",
            "content": "Wikisource . Crime and Punishment . Misc . Lochlann Vol III . cldf/cookbook . CUNY-CL/wikipron . CUNY-CL/wikipron-modeling/ .",
            "url": "https://jimregan.github.io/notes/links/2021/11/03/misc-links.html",
            "relUrl": "/links/2021/11/03/misc-links.html",
            "date": " • Nov 3, 2021"
        }
        
    
  
    
        ,"post106": {
            "title": "Irish IPA and alternatives from enwiktionary",
            "content": "https://dumps.wikimedia.org/enwiktionary/ . !wget https://dumps.wikimedia.org/enwiktionary/20211101/enwiktionary-20211101-pages-articles.xml.bz2 . --2021-11-02 17:31:36-- https://dumps.wikimedia.org/enwiktionary/20211101/enwiktionary-20211101-pages-articles.xml.bz2 Resolving dumps.wikimedia.org (dumps.wikimedia.org)... 208.80.154.7, 2620:0:861:1:208:80:154:7 Connecting to dumps.wikimedia.org (dumps.wikimedia.org)|208.80.154.7|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 892543646 (851M) [application/octet-stream] Saving to: ‘enwiktionary-20211101-pages-articles.xml.bz2’ enwiktionary-202111 100%[===================&gt;] 851.20M 4.25MB/s in 3m 21s 2021-11-02 17:34:58 (4.23 MB/s) - ‘enwiktionary-20211101-pages-articles.xml.bz2’ saved [892543646/892543646] . %%writefile extract-ipa.pl #!/usr/bin/perl use warnings; use strict; use utf8; binmode(STDIN, &quot;:utf8&quot;); binmode(STDOUT, &quot;:utf8&quot;); binmode(STDERR, &quot;:utf8&quot;); my $title = &#39;&#39;; while(&lt;&gt;) { chomp; if(/&lt;title&gt;([^&lt;]*)&lt; /title&gt;/) { $title = $1; } if(m! { {IPA |ga |!) { print &quot;$title t$_ n&quot;; } } . Writing extract-ipa.pl . !bzcat enwiktionary-20211101-pages-articles.xml.bz2|perl extract-ipa.pl &gt; wikt-ipa.txt . @phdthesis{hughes1986gaelic, title={The gaelic of Tangaveane and Commeen, County Donegal (texts, phonology, aspects of grammar and a vocabulary).}, author={Hughes, Arthur John}, year={1986}, school={Queen&#39;s University of Belfast} } . %%writefile extract-ulster.pl #!/usr/bin/perl while(&lt;&gt;) { chomp; print &quot;# $_ n&quot;; if(/^([^ t]+) t * ? { {a |[^}]+ } } { {IPA |ga |([^|]+) |qual1=before { {m |ga |sé } }, { {m |ga |sí } }, { {m |ga |sibh } }, { {m |ga |siad } } | /([^ /]+) / |qual2=elsewhere } }/) { print &quot;$1 t$2 t t t tbefore sé, sí, sibh, siad n&quot;; print &quot;$1 t$3 t t t telsewhere n&quot;; } elsif(/^([^ t]+) t * { {a |([^}]+) } } { {IPA |ga |([^}]+) } }$/) { my $word = $1; my $dial = $2; my $pron = $3; $pron =~ s/ ///g; if($dial eq &#39;Ulster&#39;) { $dial = &quot;&quot;; } else { $dial = &quot; t t t t t t t t t t$dial&quot;; } if($pron =~ / |/) { for my $pp (split(/ |/, $pron)) { print &quot;$word t$pp&quot; . $dial . &quot; n&quot;; } } else { $pron =~ s/ [//g; $pron =~ s/ ]//g; print &quot;$word t$pron&quot; . $dial . &quot; n&quot;; } } } . %%writefile extract-alt-form.pl #!/usr/bin/perl use warnings; use strict; use utf8; binmode(STDIN, &quot;:utf8&quot;); binmode(STDOUT, &quot;:utf8&quot;); binmode(STDERR, &quot;:utf8&quot;); my $title = &#39;&#39;; my $polish_seen = 0; while(&lt;&gt;) { chomp; if(/&lt;title&gt;([^&lt;]*)&lt; /title&gt;/) { $title = $1; } if(m! { {alternative form of |ga |!) { print &quot;$title t$_ n&quot;; } } . Writing extract-alt-form.pl . !bzcat enwiktionary-20211101-pages-articles.xml.bz2|perl extract-alt-form.pl &gt; wikt-alts.txt .",
            "url": "https://jimregan.github.io/notes/irish/ipa/wiktionary/2021/11/02/irish-ipa-from-enwiktionary.html",
            "relUrl": "/irish/ipa/wiktionary/2021/11/02/irish-ipa-from-enwiktionary.html",
            "date": " • Nov 2, 2021"
        }
        
    
  
    
        ,"post107": {
            "title": "Interesting links, 1/11/2021",
            "content": "Grapheme-to-Phoneme Transduction for Cross-Language ASR, preprint . uiuc-sst/g2ps . Zero-shot Cross-Lingual Phonetic Recognition with External Language Embedding . tkipf/gcn — Implementation of Graph Convolutional Networks in TensorFlow . hpcaitech/ColossalAI . fairseq - add TTS . mgaido91/FBK-fairseq-ST . lumaku/ctc-segmentation — Segment an audio file and obtain utterance alignments . microsoft/unilm . microsoft/layoutxlm-base . microsoft/icecaps — Intelligent Conversation Engine: Code and Pre-trained Systems. Version 0.2.0. . chenzhuo1011/libri_css — Continuous speech separation . microsoft/UniSpeech — UniSpeech - Large Scale Self-Supervised Learning for Speech, transformers .",
            "url": "https://jimregan.github.io/notes/links/2021/11/01/misc-links.html",
            "relUrl": "/links/2021/11/01/misc-links.html",
            "date": " • Nov 1, 2021"
        }
        
    
  
    
        ,"post108": {
            "title": "Textgrid to .lab, take 2",
            "content": "from praatio import textgrid . from pathlib import Path . def get_combined_words_and_phones(filename): from praatio import textgrid tg = textgrid.openTextgrid(filename, False) if not tg.tierNameList: return [] if tg.tierNameList == [&#39;words&#39;, &#39;phones&#39;]: word_tier = &#39;words&#39; elif tg.tierNameList == [&#39;Word&#39;, &#39;phones&#39;]: word_tier = &#39;Word&#39; word = tg.tierDict[word_tier] phones = tg.tierDict[&#39;phones&#39;] i = 0 j = 0 out = [] def it_to_dict(it): ret = {} ret[&#39;start&#39;] = it.start ret[&#39;end&#39;] = it.end ret[&#39;label&#39;] = it.label return ret while i &lt; len(word.entryList) and j &lt; len(phones.entryList): cur_word = it_to_dict(word.entryList[i]) cur_word[&#39;phones&#39;] = [] while j &lt; len(phones.entryList) and phones.entryList[j].end &lt;= cur_word[&#39;end&#39;]: end_time = phones.entryList[j].end tmp_phone = it_to_dict(phones.entryList[j]) cur_word[&#39;phones&#39;].append(tmp_phone) j += 1 if end_time == cur_word[&#39;end&#39;]: i += 1 out.append(cur_word) continue return out . This phone merging is only intended to merge a silence or spoken noise &#39;phone&#39; to the left, but for the most part this doesn&#39;t do what I&#39;d wanted, as it often means a silence &#39;word&#39; has been inserted. . def merge_phones(word): outphones = [] if len(word[&#39;phones&#39;]) == 1: return word[&#39;phones&#39;] for i in range(0, len(word[&#39;phones&#39;])): if i &gt; 0 and word[&#39;phones&#39;][i][&#39;label&#39;] in [&quot;&quot;, &quot;sil&quot;, &quot;spn&quot;]: outphones[-1][&#39;end&#39;] = word[&#39;phones&#39;][i][&#39;end&#39;] else: outphones.append(word[&#39;phones&#39;][i]) return outphones . def tg_to_lab(filename, target=&quot;phones&quot;): combined = get_combined_words_and_phones(filename) merged = [merge_phones(x) for x in combined] flattened = [item for sublist in merged for item in sublist] out = [] for tmp_phone in flattened: start = int(tmp_phone[&#39;start&#39;] * 10000000) end = int(tmp_phone[&#39;end&#39;] * 10000000) label = tmp_phone[&#39;label&#39;] out.append(f&quot;{start} {end} {label}&quot;) return out . inpath = Path(&quot;/home/jim/Playing/mfa_alignments/snc-out&quot;) outpath = Path(&quot;/home/jim/Playing/mfa_alignments/snc-lab&quot;) for filename in inpath.glob(&quot;*.TextGrid&quot;): out = outpath / f&quot;{filename.stem}.lab&quot; lab = tg_to_lab(filename) with open(out, &quot;w&quot;) as outf: for line in lab: outf.write(line + &quot; n&quot;) .",
            "url": "https://jimregan.github.io/notes/textgrid/lab/2021/10/27/textgrid-to-lab-merging.html",
            "relUrl": "/textgrid/lab/2021/10/27/textgrid-to-lab-merging.html",
            "date": " • Oct 27, 2021"
        }
        
    
  
    
        ,"post109": {
            "title": "Interesting links, 25/10/2021",
            "content": "Swedish conversation fillers . Vad heter det? / Vahettere | Hur/vad var det nu, då | Vad skulle jag säga nu, då | Du vet (y’know) | Typ/liksom (…like) | Så att (so that…) | . jmccrae/irish_saffron . chartbeat-labs/textacy . Swagger editor . Using OntoLex-Lemon for Representing and Interlinking Lexicographic Collections of Bavarian Dialects . @inproceedings{abgaz-2020-using, title = &quot;Using {O}nto{L}ex-Lemon for Representing and Interlinking Lexicographic Collections of {B}avarian Dialects&quot;, author = &quot;Abgaz, Yalemisew&quot;, booktitle = &quot;Proceedings of the 7th Workshop on Linked Data in Linguistics (LDL-2020)&quot;, month = may, year = &quot;2020&quot;, address = &quot;Marseille, France&quot;, publisher = &quot;European Language Resources Association&quot;, url = &quot;https://aclanthology.org/2020.ldl-1.9&quot;, pages = &quot;61--69&quot;, language = &quot;English&quot;, ISBN = &quot;979-10-95546-36-8&quot;, } . pdf, code (not open source) . ming024/FastSpeech2 — An implementation of Microsoft’s “FastSpeech 2: Fast and High-Quality End-to-End Text to Speech” . bigscience-workshop/promptsource . aimhubio/aim . from aim.hugging_face import AimCallback # ... aim_callback = AimCallback(repo=&#39;/path/to/logs/dir&#39;, experiment=&#39;mnli&#39;) trainer = Trainer( model=model, args=training_args, train_dataset=train_dataset if training_args.do_train else None, eval_dataset=eval_dataset if training_args.do_eval else None, callbacks=[aim_callback], # ... ) . d99kris/spacy-cpp . r9y9/nnmnkwii . R2R .",
            "url": "https://jimregan.github.io/notes/links/2021/10/25/misc-links.html",
            "relUrl": "/links/2021/10/25/misc-links.html",
            "date": " • Oct 25, 2021"
        }
        
    
  
    
        ,"post110": {
            "title": "Interesting links, 23/10/2021",
            "content": "Phrase Retrieval and Beyond, princeton-nlp/DensePhrases . gong-io/gecko — Gecko - A Tool for Effective Annotation of Human Conversations . camelot-dev/camelot — A Python library to extract tabular data from PDFs . SheetJS/sheetjs — Spreadsheet Data Toolkit . html2pdf.js . trekhleb/javascript-algorithms . norvig/paip-lisp — Lisp code for the textbook “Paradigms of Artificial Intelligence Programming” . electron/asar — Simple extensive tar-like archive format with indexing . ElementAI/picard — PICARD - Parsing Incrementally for Constrained Auto-Regressive Decoding from Language Models . aimhubio/aim — an easy-to-use and performant open-source experiment tracker. . jina-ai/finetuner — Finetuning any DNN for better embedding on neural search tasks .",
            "url": "https://jimregan.github.io/notes/links/2021/10/23/misc-links.html",
            "relUrl": "/links/2021/10/23/misc-links.html",
            "date": " • Oct 23, 2021"
        }
        
    
  
    
        ,"post111": {
            "title": "TextGrid to lab",
            "content": "from praatio import textgrid . from pathlib import Path . def tg_to_lab(filename, target=&quot;phones&quot;): tg = textgrid.openTextgrid(filename, False) if not tg.tierNameList or target not in tg.tierNameList: return [] phones = tg.tierDict[target] out = [] def it_to_dict(it): ret = {} ret[&#39;start&#39;] = it.start ret[&#39;end&#39;] = it.end ret[&#39;label&#39;] = it.label return ret for phone in phones.entryList: tmp_phone = it_to_dict(phone) start = int(tmp_phone[&#39;start&#39;] * 10000000) end = int(tmp_phone[&#39;end&#39;] * 10000000) label = tmp_phone[&#39;label&#39;] out.append(f&quot;{start} {end} {label}&quot;) return out . inpath = Path(&quot;/PATH/TO/FILES/INPUT&quot;) outpath = Path(&quot;/PATH/TO/FILES/OUTPUT&quot;) for filename in inpath.glob(&quot;*.TextGrid&quot;): out = outpath / f&quot;{filename.stem}.lab&quot; lab = tg_to_lab(filename) with open(out, &quot;w&quot;) as outf: for line in lab: outf.write(line + &quot; n&quot;) .",
            "url": "https://jimregan.github.io/notes/textgrid/lab/phonetic/todo/2021/10/22/textgrid-to-lab.html",
            "relUrl": "/textgrid/lab/phonetic/todo/2021/10/22/textgrid-to-lab.html",
            "date": " • Oct 22, 2021"
        }
        
    
  
    
        ,"post112": {
            "title": "Interesting links, 20/10/2021",
            "content": "Whose Language is it?: Struggles for Language Ownership in an Irish Language Classroom . Beaker Browser, beakerbrowser/beaker . Simple and Effective Zero-shot Cross-lingual Phoneme Recognition, models .",
            "url": "https://jimregan.github.io/notes/links/2021/10/20/misc-links.html",
            "relUrl": "/links/2021/10/20/misc-links.html",
            "date": " • Oct 20, 2021"
        }
        
    
  
    
        ,"post113": {
            "title": "Flashlight docker, 20/10/2021",
            "content": "$ docker pull flml/flashlight:cuda-latest cuda-latest: Pulling from flml/flashlight Digest: sha256:fbf98d7b813c05605a930c99d28942106232de0f2051ba8bd6f9066e22d5c1b6 . $ docker run -it flml/flashlight:cuda-latest bash . # export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/intel/compilers_and_libraries_2020.4.304/linux/mkl/lib/intel64_lin/:/opt/arrayfire/lib/ # ldconfig .",
            "url": "https://jimregan.github.io/notes/flashlight/docker/2021/10/20/flashlight-docker.html",
            "relUrl": "/flashlight/docker/2021/10/20/flashlight-docker.html",
            "date": " • Oct 20, 2021"
        }
        
    
  
    
        ,"post114": {
            "title": "Irish number normalisation with Pynini",
            "content": "!pip install -q condacolab import condacolab condacolab.install() . ⏬ Downloading https://github.com/jaimergp/miniforge/releases/latest/download/Mambaforge-colab-Linux-x86_64.sh... 📦 Installing... 📌 Adjusting configuration... 🩹 Patching environment... ⏲ Done in 0:00:39 🔁 Restarting kernel... . %%capture !conda install -c conda-forge pynini . %%capture !pip install pyicu . import pynini . import icu formatter = icu.RuleBasedNumberFormat(icu.URBNFRuleSetTag.SPELLOUT, icu.Locale(&#39;ga&#39;)) . for i in range(0, 10): print(formatter.format(i)) . a náid a haon a dó a trí a ceathair a cúig a sé a seacht a hocht a naoi . pynini.cross(&quot;0&quot;, &quot;a náid&quot;) | pynini.cross(&quot;1&quot;, &quot;a haon&quot;) . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; FST 15 15 0 0 15&#45;&gt;0 0:0 8 8 15&#45;&gt;8 0:0 1 1 0&#45;&gt;1 48:97 9 9 8&#45;&gt;9 49:97 2 2 1&#45;&gt;2 0:32 3 3 2&#45;&gt;3 0:110 4 4 3&#45;&gt;4 0:195 5 5 4&#45;&gt;5 0:161 6 6 5&#45;&gt;6 0:105 7 7 6&#45;&gt;7 0:100 10 10 9&#45;&gt;10 0:32 11 11 10&#45;&gt;11 0:104 12 12 11&#45;&gt;12 0:97 13 13 12&#45;&gt;13 0:111 14 14 13&#45;&gt;14 0:110 i = 1 print(f&quot;{i:03d}&quot;) . 001 . count_1_999 = pynini.union(*[pynini.cross(f&quot;{i:03d}&quot;, formatter.format(i)) for i in range(1, 1000)]) . count_1_999_x1000 = pynini.union(*[pynini.cross(f&quot;{i:03d}&quot;, formatter.format(i * 1000)) for i in range(1, 1000)]) . (&quot;999&quot; @ count_1_999_x1000).string() . &#39;naoi gcéad nócha is naoi míle&#39; . count_1_999_x1000000 = pynini.union(*[pynini.cross(f&quot;{i:03d}&quot;, formatter.format(i * 1000000)) for i in range(1, 1000)]) . drop_000 = pynini.cross(&quot;000&quot;, &quot;&quot;) . ins_space = pynini.cross(&quot;&quot;, &quot; &quot;) . ins_space_or_is = (pynini.cross(&quot;&quot;, &quot; &quot;) | pynini.cross(&quot;&quot;, &quot; is &quot;)) . (&quot;999&quot; @ count_1_999_x1000000).string() . &#39;naoi gcéad nócha is naoi milliún&#39; . count_1_999999 = (count_1_999_x1000 + drop_000 | count_1_999_x1000 + ins_space + count_1_999 | drop_000 + count_1_999) . (&quot;000001&quot; @ count_1_999999).string() . &#39;a haon&#39; . We want a fairly large number for this to be worth it; unfortunately, memory limits get in the way, so building up in sections is the only way forward. . IOW, pynini gives no advantage over thrax. . #count_0_1000000000000 = pynini.union(*[pynini.cross(f&quot;{i:03d}&quot;, formatter.format(i)) for i in range(0, 1000000000000)]) . I can still generate list parts, though . with open(&quot;count-1-999.tsv&quot;, &quot;w&quot;) as outf: for i in range(1, 1000): outf.write(f&quot;{i:03d} t{formatter.format(i)} n&quot;) . with open(&quot;count-1-999-thousands.tsv&quot;, &quot;w&quot;) as outf: for i in range(1, 1000): outf.write(f&quot;{i:03d} t{formatter.format(i * 1000)} n&quot;) . with open(&quot;count-1-999-billions.tsv&quot;, &quot;w&quot;) as outf: for i in range(1, 1000): outf.write(f&quot;{i:03d} t{formatter.format(i * 1000000000)} n&quot;) .",
            "url": "https://jimregan.github.io/notes/colab/pynini/2021/10/19/irish-numbers-with-pynini.html",
            "relUrl": "/colab/pynini/2021/10/19/irish-numbers-with-pynini.html",
            "date": " • Oct 19, 2021"
        }
        
    
  
    
        ,"post115": {
            "title": "Interesting links, 18/10/2021",
            "content": "xtermjs/xterm.js . l0phtcrack is open source. Haven’t used it since 1998, but good to know. . bigscience/T0pp · Hugging Face . What every software engineer should know about search . McRank | LambdaRank | MatrixNet | Neural Vector Spaces for Unsupervised Information Retrieval | . Focus - Free edition .",
            "url": "https://jimregan.github.io/notes/links/2021/10/18/misc-links.html",
            "relUrl": "/links/2021/10/18/misc-links.html",
            "date": " • Oct 18, 2021"
        }
        
    
  
    
        ,"post116": {
            "title": "Merge TextGrid files",
            "content": "Turns out there&#39;s an example . from praatio import textgrid . from pathlib import Path . _BARE = Path(&quot;/home/jim/Playing/snc-comparison/bare/&quot;) _AUG = Path(&quot;/home/jim/Playing/snc-comparison/augmented/&quot;) _MRG = Path(&quot;/home/jim/Playing/snc-comparison/merged/&quot;) . for tg_file in _BARE.glob(&quot;*.TextGrid&quot;): aug_tg_file = _AUG / f&quot;{tg_file.stem}.TextGrid&quot; mrg_tg_file = _MRG / f&quot;{tg_file.stem}.TextGrid&quot; tg_bare = textgrid.openTextgrid(tg_file, False) tg_aug = textgrid.openTextgrid(aug_tg_file, False) tg_bare.addTier(textgrid.IntervalTier(&quot;words1&quot;, tg_aug.tierDict[&#39;words&#39;].entryList)) tg_bare.addTier(textgrid.IntervalTier(&quot;phones1&quot;, tg_aug.tierDict[&#39;phones&#39;].entryList)) tg_bare.save(mrg_tg_file, &quot;long_textgrid&quot;, True) .",
            "url": "https://jimregan.github.io/notes/praat/mfa/2021/10/18/merge-textgrids.html",
            "relUrl": "/praat/mfa/2021/10/18/merge-textgrids.html",
            "date": " • Oct 18, 2021"
        }
        
    
  
    
        ,"post117": {
            "title": "Download files as zip",
            "content": "See here . from zipfile import ZipFile from pathlib import Path zipname = &#39;audio.zip&#39; dirp = Path(&quot;/home/jim/Playing/mfa-corp/snc&quot;) filenames = dirp.glob(&#39;*.wav&#39;) with ZipFile(zipname, &#39;w&#39;) as zipf: for name in filenames: zipf.write(name) . from IPython.display import FileLink display(FileLink(&#39;audio.zip&#39;)) . audio.zip",
            "url": "https://jimregan.github.io/notes/jupyter/2021/10/18/download-files-as-zip.html",
            "relUrl": "/jupyter/2021/10/18/download-files-as-zip.html",
            "date": " • Oct 18, 2021"
        }
        
    
  
    
        ,"post118": {
            "title": "Expand Connaught lexicon",
            "content": "dictionary = open(&quot;/home/jim/Playing/mfa_alignments/snc.dict&quot;) dictionary2 = open(&quot;/home/jim/Playing/mfa_alignments/snc.dict.exp&quot;, &quot;w&quot;) . alts = { &quot;acu&quot;: &quot;acub&quot;, &quot;againn&quot;: &quot;ainn&quot;, &quot;agam&quot;: &quot;am&quot;, &quot;agamsa&quot;: &quot;amsa&quot;, &quot;agat&quot;: &quot;ad&quot;, &quot;agatsa&quot;: &quot;adsa&quot;, &quot;arís&quot;: &quot;aríst&quot;, &quot;bóthar&quot;: &quot;bór&quot;, &quot;ceistigh&quot;: &quot;ceisnigh&quot;, &quot;claí&quot;: &quot;cladh&quot;, &quot;cluiche&quot;: &quot;cluife&quot;, &quot;contae&quot;: &quot;condae&quot;, &quot;croitheadh&quot;: &quot;crathadh&quot;, &quot;dada&quot;: &quot;tada&quot;, &quot;daoibh&quot;: &quot;dhaoib&quot;, &quot;de&quot;: &quot;dhe&quot;, &quot;de&quot;: &quot;ge&quot;, &quot;deartháir&quot;: &quot;driotháir&quot;, &quot;dheirfiúr&quot;: &quot;dhrifiúr&quot;, &quot;dheirfiúracha&quot;: &quot;dhrifiúracha&quot;, &quot;dom&quot;: &quot;dhom&quot;, &quot;domsa&quot;: &quot;dhomsa&quot;, &quot;droichead&quot;: [&quot;draed&quot;, &quot;draighead&quot;], &quot;duit&quot;: &quot;dhuit&quot;, &quot;duitse&quot;: &quot;dhuitse&quot;, &quot;díbh&quot;: &quot;díofa&quot;, &quot;díobh&quot;: &quot;díob&quot;, &quot;dócha&quot;: &quot;dóiche&quot;, &quot;dóibh&quot;: &quot;dóib&quot;, &quot;dóigh&quot;: &quot;dóiche&quot;, &quot;dúinn&quot;: &quot;dhúinn&quot;, &quot;féin&quot;: &quot;fhéin&quot;, &quot;foighne&quot;: &quot;foighid&quot;, &quot;folach&quot;: &quot;falach&quot;, &quot;foscadh&quot;: &quot;fascadh&quot;, &quot;gnaithe&quot;: &quot;gnaíthe&quot;, &quot;iúdás&quot;: &quot;iúdas&quot;, &quot;leo&quot;: [&quot;leob&quot;, &quot;leofa&quot;], &quot;léi&quot;: [&quot;léithe&quot;, &quot;léí&quot;], &quot;litir&quot;: &quot;leitir&quot;, &quot;luigh&quot;: &quot;loigh&quot;, &quot;luí&quot;: &quot;loighe&quot;, &quot;mé&quot;: &quot;me&quot;, &quot;naimhdeach&quot;: &quot;náimhdeach&quot;, &quot;namhaid&quot;: &quot;náimhid&quot;, &quot;nuacht&quot;: &quot;nuaíocht&quot;, &quot;nuachta&quot;: &quot;nuaíochta&quot;, &quot;nóiméad&quot;: [&quot;móiméad&quot;, &quot;mhóiméad&quot;], &quot;nóiméid&quot;: [&quot;móiméid&quot;, &quot;mhóiméid&quot;], &quot;orthu&quot;: &quot;orthub&quot;, &quot;scafánta&quot;: &quot;scufánta&quot;, &quot;scornach&quot;: &quot;scórnach&quot;, &quot;sé&quot;: &quot;se&quot;, &quot;sibh&quot;: &quot;sib&quot;, &quot;taispeáin&quot;: &quot;taspáin&quot;, &quot;taispeánfaidh&quot;: &quot;taspánfaidh&quot;, &quot;teacht&quot;: &quot;tíocht&quot;, &quot;theacht&quot;: &quot;thíocht&quot;, } nonwords = { &quot;bór&quot;: &quot;b oo r&quot;, &quot;draed&quot;: &quot;d r ee d&quot;, &quot;draighead&quot;: &quot;d r ai d&quot;, &quot;ge&quot;: &quot;g @&quot;, &quot;léí&quot;: &quot;lj ee ii&quot;, } maybe_missing = { &quot;duit&quot;: &quot;d i tj&quot;, &quot;nuaíocht&quot;: &quot;n uu i@ x t&quot;, &quot;nuaíochta&quot;: &quot;n uu i@ x t @&quot;, &quot;am&quot;: &quot;a m&quot;, # a&#39;m &quot;móiméad&quot;: &quot;m oo mj ee d&quot;, &quot;móiméid&quot;: &quot;m oo mj ee dj&quot;, &quot;mhóiméad&quot;: &quot;v oo mj ee d&quot;, &quot;mhóiméid&quot;: &quot;v oo mj ee dj&quot;, &quot;taspánfaidh&quot;: &quot;t @ s p aa nn h @&quot;, # 0 t @ s . 1 p aa nn . 0 h @ } _ALTS = {**nonwords, **maybe_missing} _SOUGHT = [] _SKIP_ALTS = [] for (a, b) in alts.items(): if type(b) == list: for x in b: if x not in _ALTS.keys(): _SOUGHT.append(x) else: if b not in _ALTS.keys(): _SOUGHT.append(b) _REVERSE_ALTS = {} for item in alts.items(): if type(item[1]) == list: items = item[1] else: items = [item[1]] for sitem in items: if sitem not in _REVERSE_ALTS.keys(): _REVERSE_ALTS[sitem] = set() _REVERSE_ALTS[sitem].add(item[0]) . def deletable_schwa_single(word, phones): out = [] out.append((word, phones)) if len(phones) == 1 and phones[0] == &#39;@&#39;: out.append((word, [&quot;sil&quot;])) else: if phones[0] == &#39;@&#39;: out.append((word, phones[1:])) if phones[-1] == &#39;@&#39;: out.append((word, phones[1:-1])) if phones[-1] == &#39;@&#39;: out.append((word, phones[:-1])) return out def deletable_schwa(wordlist): out = [] for item in wordlist: out += deletable_schwa_single(item[0], item[1]) return out . def nasal_o(item): # FIXME: way too simplistic word = item[0] phones = item[1] phonestr = &quot; &quot;.join(phones) out = [item] if &quot;mó&quot; in word and &quot;m oo&quot; in phonestr: outph = phonestr.replace(&quot;m oo&quot;, &quot;m uu&quot;).split(&quot; &quot;) out.append((word, outph)) if &quot;mhó&quot; in word and &quot;v oo&quot; in phonestr: outph = phonestr.replace(&quot;v oo&quot;, &quot;v uu&quot;).split(&quot; &quot;) out.append((word, outph)) if &quot;nó&quot; in word and &quot;n oo&quot; in phonestr: outph = phonestr.replace(&quot;n oo&quot;, &quot;n uu&quot;).split(&quot; &quot;) out.append((word, outph)) return out . def endswith_list(text, endings): for ending in endings: if text.endswith(ending): return True return False def handle_igh(item): if type(item) != tuple: raise Exception(&quot;item is not a tuple: &quot; + item) word = item[0] phones = item[1] out = [item] if word.endswith(&quot;igh&quot;) and phones[-1] == &quot;@&quot;: out.append((word, phones[0:-1] + [&quot;ii&quot;])) if word.endswith(&quot;igh&quot;) and phones[-1] == &quot;ii&quot;: if not endswith_list(word, [&quot;uigh&quot;, &quot;aoigh&quot;]): out.append((word, phones[0:-1] + [&quot;@&quot;])) if word.endswith(&quot;dh&quot;) and phones[-1] == &quot;@&quot;: out.append((word, phones + [&quot;x&quot;])) out.append((word, phones + [&quot;tj&quot;])) out.append((word, phones + [&quot;v&quot;])) if word.endswith(&quot;dh&quot;) and phones[-1] == &quot;x&quot;: out.append((word, phones[0:-1])) out.append((word, phones[0:-1] + [&quot;tj&quot;])) out.append((word, phones[0:-1] + [&quot;v&quot;])) return out . for line in dictionary.readlines(): line = line.strip() pieces = line.split(&quot; t&quot;) word = pieces[0] phones = pieces[1].split(&quot; &quot;) entries = list() tmptup = (word, phones) entries.append(tmptup) if word in _SOUGHT: for replacement_word in _REVERSE_ALTS[word]: tmp_replace = [(replacement_word, b) for (a, b) in entries] entries.extend(tmp_replace) elif word in alts.keys(): if type(alts[word]) == list: tmp_words = alts[word] else: tmp_words = [alts[word]] for tmp_word in tmp_words: if tmp_word not in _SOUGHT: entries.append((word, _ALTS[tmp_word].split(&quot; &quot;))) if word.endswith(&quot;acha&quot;) or word.endswith(&quot;anna&quot;): entries.append((word, phones[:-1] + [&quot;ii&quot;])) if word.endswith(&quot;igh&quot;) or word.endswith(&quot;dh&quot;): tmp_igh = [] for entry in entries: tmp_igh.extend(handle_igh(entry)) entries.extend(tmp_igh) tmp_nasal = [] for entry in entries: tmp_nasal.extend(nasal_o(entry)) entries.extend(tmp_nasal) tmp_schwa = deletable_schwa(entries) entries.extend(tmp_schwa) joined = [&quot; &quot;.join([a] + b) for (a, b) in entries] sort_join = sorted(joined) for entry in set(sort_join): dictionary2.write(entry + &quot; n&quot;) . dictionary.close() dictionary2.close() .",
            "url": "https://jimregan.github.io/notes/irish/phonetic/2021/10/17/expand-connaught-lexicon.html",
            "relUrl": "/irish/phonetic/2021/10/17/expand-connaught-lexicon.html",
            "date": " • Oct 17, 2021"
        }
        
    
  
    
        ,"post119": {
            "title": "Connaught -igh check",
            "content": "import IPython . 0018 éirigh &lt;igh&gt; -&gt; /ə/ 0020 thosaigh &lt;igh&gt; -&gt; /ə/ 0040 d&#39;imigh &lt;igh&gt; -&gt; /ə/ 0041 Shuigh &lt;igh&gt; -&gt; /i:/ 0043 Dhúisigh &lt;igh&gt; -&gt; /ə/ 0044 chuaigh &lt;igh&gt; -&gt; /ə/ 0050 d&#39;imigh &lt;igh&gt; -&gt; /ə/ 0079 Breathnaigh &lt;igh&gt; -&gt; /ə/ 0092 chuimhnigh &lt;igh&gt; -&gt; /ə/ 0094 D&#39;ísligh &lt;igh&gt; -&gt; /ə/ 0107 éadaigh &lt;igh&gt; -&gt; /ə/ 0108 chuaigh &lt;igh&gt; -&gt; /ə/ 0108 thosaigh &lt;igh&gt; -&gt; /ə/ 0122 chuimhnigh &lt;igh&gt; -&gt; /ə/ x ii nj @ 0140 Shocraigh &lt;igh&gt; -&gt; /ə/ 0143 d&#39;éirigh &lt;igh&gt; -&gt; /ə/ 0152 tigh &lt;igh&gt; -&gt; /i:/ 0167 ndóigh nn uu 0180 Ghlaoigh &lt;igh&gt; -&gt; /i:/ 0180 istigh &lt;igh&gt; -&gt; /ə/ 0183 bhailigh &lt;igh&gt; -&gt; /ə/ 0186 Corraigh &lt;igh&gt; -&gt; /ə/ 0186 istigh &lt;igh&gt; -&gt; /ə/ 0206 dóigh &lt;igh&gt; -&gt; /ə/ 0231 dóigh &lt;igh&gt; -&gt; /ə/ [ɪ] 0234 chompánaigh &lt;igh&gt; -&gt; /i:/ 0237 airigh &lt;igh&gt; -&gt; /ə/ 0248 ndóigh nn uu 0258 dóigh &lt;igh&gt; -&gt; /i:/ 0261 amuigh (@) m u 0267 d&#39;éirigh &lt;igh&gt; -&gt; /ə/ 0267 orlaigh &lt;igh&gt; -&gt; /i:/ 0268 dhúisigh &lt;igh&gt; -&gt; /ə/ 0269 chorraigh &lt;igh&gt; -&gt; /ə/ 0272 amuigh @ m u 0281 tharrthaigh &lt;igh&gt; -&gt; /ə/ 0284 ndóigh nn uu 0286 d&#39;éirigh &lt;igh&gt; -&gt; /ə/ 0287 brionglóidigh &lt;igh&gt; -&gt; /i:/ 0288 Mhothaigh &lt;igh&gt; -&gt; /ə/ 0289 d&#39;eirigh &lt;igh&gt; -&gt; /ə/ 0295 Bhreathnaigh &lt;igh&gt; -&gt; /ə/ 0303 Chuaigh &lt;igh&gt; -&gt; /ə/ 0321 ghlaoigh &lt;igh&gt; -&gt; /i:/ 0327 choinnigh &lt;igh&gt; -&gt; /ə/ 0343 ráinigh &lt;igh&gt; -&gt; /ə/ 0351 amuigh @ m u 0354 chuaigh &lt;igh&gt; -&gt; /ə/ 0366 amuigh @ m u 0367 amuigh @ m u 0368 amuigh @ m u 0369 d&#39;imigh &lt;igh&gt; -&gt; /ə/ 0370 ndóigh nn uu 0371 d&#39;imigh &lt;igh&gt; -&gt; /ə/ 0373 d&#39;imigh &lt;igh&gt; -&gt; /ə/ 0400 d&#39;éirigh &lt;igh&gt; -&gt; /ə/ 0404 suigh &lt;igh&gt; -&gt; /i:/ 0405 shuigh &lt;igh&gt; -&gt; /i:/ 0407 éadaigh &lt;igh&gt; -&gt; /ə/ 0409 nigh &lt;igh&gt; -&gt; /i:/ 0422 shuigh &lt;igh&gt; -&gt; /i:/ 0423 thosaigh &lt;igh&gt; -&gt; /ə/ 0428 d&#39;fhuadaigh &lt;igh&gt; -&gt; /ə/ 0435 ghlaoigh &lt;igh&gt; -&gt; /i:/ 0436 ghlaoigh &lt;igh&gt; -&gt; /i:/ 0449 d&#39;éirigh &lt;igh&gt; -&gt; /ə/ 0453 Chuaigh &lt;igh&gt; -&gt; /ə/ 0461 tigh &lt;igh&gt; -&gt; /i:/ 0477 mharaigh &lt;igh&gt; -&gt; /ə/ 0480 mharaigh &lt;igh&gt; -&gt; /ə/ 0484 d&#39;éirigh &lt;igh&gt; -&gt; /ə/ 0499 teallaigh &lt;igh&gt; -&gt; /i:/ 0502 Neachtanaigh &lt;igh&gt; -&gt; /i:/ 0506 ghlaoigh &lt;igh&gt; -&gt; /i:/ 0527 Thiontaigh &lt;igh&gt; -&gt; /ə/ 0531 Chuaigh &lt;igh&gt; -&gt; /ə/ 0542 airigh &lt;igh&gt; -&gt; /ə/ 0544 Chuaigh &lt;igh&gt; -&gt; /ə/ 0546 Cheistigh &lt;igh&gt; -&gt; /ə/ 0548 Chuardaigh &lt;igh&gt; -&gt; /ə/ 0568 D&#39;imigh &lt;igh&gt; -&gt; /ə/ 0572 Luigh &lt;igh&gt; -&gt; /i:/ 0581 mharaigh &lt;igh&gt; -&gt; /ə/ 0587 d&#39;éirigh &lt;igh&gt; -&gt; /ə/ 0612 mhionnaigh &lt;igh&gt; -&gt; /ə/ 0615 mhionnaigh &lt;igh&gt; -&gt; /ə/ 0616 mhionnaigh &lt;igh&gt; -&gt; /ə/ 0628 mhionnaigh &lt;igh&gt; -&gt; /ə/ 0629 mhionnaigh &lt;igh&gt; -&gt; /ə/ 0642 Chuaigh &lt;igh&gt; -&gt; /ə/ 0647 Chuaigh &lt;igh&gt; -&gt; /ə/ 0649 Dheasaigh &lt;igh&gt; -&gt; /ə/ 0650 istigh &lt;igh&gt; -&gt; /ə/ 0650 amuigh @ m u 0652 éadaigh &lt;igh&gt; -&gt; /i:/ 0652 dhathaigh &lt;igh&gt; -&gt; /ə/ 0664 Domhnaigh &lt;igh&gt; -&gt; /ə/ 0671 ndóigh nn uu 0675 éirigh &lt;igh&gt; -&gt; /ə/ 0678 Chuaigh &lt;igh&gt; -&gt; /ə/ 0678 shuigh &lt;igh&gt; -&gt; /i:/ 0690 chuaigh &lt;igh&gt; -&gt; /ə/ 0691 Chuardaigh &lt;igh&gt; -&gt; /ə/ 0701 chuaigh &lt;igh&gt; -&gt; /ə/ 0704 D&#39;imigh &lt;igh&gt; -&gt; /ə/ 0711 chuaigh &lt;igh&gt; -&gt; /ə/ 0715 theastaigh &lt;igh&gt; -&gt; /ə/ 0720 chuaigh &lt;igh&gt; -&gt; /ə/ 0724 chuaigh &lt;igh&gt; -&gt; /ə/ 0726 chuaigh &lt;igh&gt; -&gt; /ə/ 0729 chuaigh &lt;igh&gt; -&gt; /ə/ 0736 léigh &lt;éigh&gt; -&gt; /e:/ 0745 D&#39;umhlaigh &lt;igh&gt; -&gt; /ə/ 0745 d&#39;imigh &lt;igh&gt; -&gt; /ə/ 0746 léigh &lt;éigh&gt; -&gt; /e:/ 0758 d&#39;imigh &lt;igh&gt; -&gt; /ə/ 0760 d&#39;imigh &lt;igh&gt; -&gt; /ə/ 0762 d&#39;imigh &lt;igh&gt; -&gt; /ə/ 0772 chuaigh &lt;igh&gt; -&gt; /ə/ 0773 amuigh @ m u 0805 mharaigh &lt;igh&gt; -&gt; /ə/ 0808 mharaigh &lt;igh&gt; -&gt; /ə/ 0822 choinnigh &lt;igh&gt; -&gt; /ə/ 1316 Turlaigh &lt;igh&gt; -&gt; /i:/ 1325 Mhaigh &lt;igh&gt; -&gt; /i:/ 1339 chuaigh &lt;igh&gt; -&gt; /ə/ 1369 chuaigh &lt;igh&gt; -&gt; /ə/ 1373 Turlaigh &lt;igh&gt; -&gt; /i:/ 1383 tosaigh &lt;igh&gt; -&gt; /i:/ 1395 tosaigh &lt;igh&gt; -&gt; /ə/ 1408 chuimhnigh &lt;igh&gt; -&gt; /ə/ 1427 éadaigh &lt;igh&gt; -&gt; /ə/ 1436 Bhailigh &lt;igh&gt; -&gt; /ə/ 1439 éadaigh &lt;igh&gt; -&gt; /ə/ 1440 éadaigh &lt;igh&gt; -&gt; /ə/ 1442 Sháigh h aa 1443 Chuimhnigh &lt;igh&gt; -&gt; /ə/ 1449 chuimhnigh &lt;igh&gt; -&gt; /ə/ 1455 thiontaigh &lt;igh&gt; -&gt; /ə/ 1455 théaltaigh &lt;igh&gt; -&gt; /ə/ 1458 théaltaigh &lt;igh&gt; -&gt; /ə/ 1458 chuaigh &lt;igh&gt; -&gt; /ə/ 1461 Turlaigh &lt;igh&gt; -&gt; /i:/ 1464 istigh &lt;igh&gt; -&gt; /ə/ 1466 chuaigh &lt;igh&gt; -&gt; /ə/ 1467 d&#39;éirigh &lt;igh&gt; -&gt; /ə/ 1467 istigh &lt;igh&gt; -&gt; /ə/ 1469 thosaigh &lt;igh&gt; -&gt; /ə/ 1474 chuimhnigh &lt;igh&gt; -&gt; /ə/ 1483 chuimhnigh &lt;igh&gt; -&gt; /ə/ 1486 chuaigh &lt;igh&gt; -&gt; /ə/ 1493 chuaigh &lt;igh&gt; -&gt; /ə/ 1497 folaigh &lt;igh&gt; -&gt; /i:/ 1510 imigh &lt;igh&gt; -&gt; /ə/ 1511 d&#39;imigh &lt;igh&gt; -&gt; /ə/ 1519 chuimhnigh &lt;igh&gt; -&gt; /ə/ 1519 d&#39;umhlaigh &lt;igh&gt; -&gt; /ə/ 1527 Turlaigh &lt;igh&gt; -&gt; /i:/ 1528 d&#39;éirigh &lt;igh&gt; -&gt; /ə/ 1537 chuimhnigh &lt;igh&gt; -&gt; /ə/ 1539 Ghéaraigh &lt;igh&gt; -&gt; /ə/ 1540 thosaigh &lt;igh&gt; -&gt; /ə/ 1551 chuimhnigh &lt;igh&gt; -&gt; /ə/ 1554 Thiontaigh &lt;igh&gt; -&gt; /ə/ 1555 ndeachaigh &lt;igh&gt; -&gt; /ə/ 1556 mhothaigh &lt;igh&gt; -&gt; /ə/ 1573 ualaigh &lt;igh&gt; -&gt; /i:/ 1577 éadaigh &lt;igh&gt; -&gt; /ə/ 1578 d&#39;imigh &lt;igh&gt; -&gt; /ə/ 1581 Mhothaigh &lt;igh&gt; -&gt; /ə/ 1584 imigh &lt;igh&gt; -&gt; /ə/ 1586 Luigh &lt;igh&gt; -&gt; /i:/ 1587 bhealaigh &lt;igh&gt; -&gt; /i:/ 1588 istigh &lt;igh&gt; -&gt; /ə/ 1589 D&#39;imigh &lt;igh&gt; -&gt; /ə/ 1599 malraigh &lt;igh&gt; -&gt; /i:/ 1600 amuigh &lt;igh&gt; -&gt; /ə/ 1601 Mhaigh &lt;igh&gt; -&gt; /i:/ 1602 Maigh &lt;igh&gt; -&gt; /i:/ 1605 Mhaigh &lt;igh&gt; -&gt; /i:/ 1613 theastaigh &lt;igh&gt; -&gt; /ə/ 1619 Chuaigh &lt;igh&gt; -&gt; /ə/ 1622 hógánaigh &lt;igh&gt; -&gt; /i:/ 1627 Chuaigh &lt;igh&gt; -&gt; /ə/ 1628 Chuaigh &lt;igh&gt; -&gt; /ə/ 1630 Thosaigh &lt;igh&gt; -&gt; /ə/ 1635 Chuaigh &lt;igh&gt; -&gt; /ə/ 1639 D&#39;éirigh &lt;igh&gt; -&gt; /ə/ 1643 ghnóthaigh &lt;igh&gt; -&gt; /i:/ 1647 Mhaigh w aa 1647 Maigh m aa 1653 chruthaigh &lt;igh&gt; -&gt; /ə/ 1654 d&#39;éirigh &lt;igh&gt; -&gt; /ə/ 1658 Maigh &lt;igh&gt; -&gt; /i:/ 1661 d&#39;éirigh &lt;igh&gt; -&gt; /ə/ 1664 d&#39;imigh &lt;igh&gt; -&gt; /ə/ 1667 Maigh m aa 1669 bhealaigh &lt;igh&gt; -&gt; /i:/ 1669 éadaigh &lt;igh&gt; -&gt; /ə/ 1670 Shuigh &lt;igh&gt; -&gt; /i:/ 1673 D&#39;éirigh &lt;igh&gt; -&gt; /ə/ 1673 chuaigh &lt;igh&gt; -&gt; /ə/ 1673 thosaigh &lt;igh&gt; -&gt; /ə/ 1673 Mhaigh &lt;igh&gt; -&gt; /i:/ 1674 chríochnaigh &lt;igh&gt; -&gt; /ə/ 1676 Thosaigh &lt;igh&gt; -&gt; /ə/ 1678 thosaigh &lt;igh&gt; -&gt; /ə/ 1683 istigh &lt;igh&gt; -&gt; /ə/ 1690 teallaigh &lt;igh&gt; -&gt; /i:/ 1692 éadaigh &lt;igh&gt; -&gt; /ə/ 1704 thosaigh &lt;igh&gt; -&gt; /ə/ 1721 d&#39;iontaigh &lt;igh&gt; -&gt; /ə/ 1724 Éirigh &lt;igh&gt; -&gt; /ə/ 1725 D&#39;éirigh &lt;igh&gt; -&gt; /ə/ 1730 bhealaigh &lt;igh&gt; -&gt; /i:/ 1737 éadaigh &lt;igh&gt; -&gt; /ə/ 1738 d&#39;éirigh &lt;igh&gt; -&gt; /ə/ 1745 D&#39;imigh &lt;igh&gt; -&gt; /ə/ 1746 thriomaigh &lt;igh&gt; -&gt; /ə/ 1749 thosaigh &lt;igh&gt; -&gt; /ə/ 1750 mhothaigh &lt;igh&gt; -&gt; /ə/ 1752 d&#39;airigh &lt;igh&gt; -&gt; /ə/ 1763 thosaigh &lt;igh&gt; -&gt; /ə/ 1769 D&#39;imigh &lt;igh&gt; -&gt; /ə/ 1771 Chuaigh &lt;igh&gt; -&gt; /ə/ 1775 Chuaigh &lt;igh&gt; -&gt; /ə/ 1779 Chuaigh &lt;igh&gt; -&gt; /ə/ 1787 earraigh &lt;igh&gt; -&gt; /i:/ 1816 ndóigh nn uu 1825 amuigh @ m u 1830 Chuaigh &lt;igh&gt; -&gt; /ə/ 1832 Nigh &lt;igh&gt; -&gt; /i:/ 1835 Dheasaigh &lt;igh&gt; -&gt; /ə/ 1838 shuigh &lt;igh&gt; -&gt; /i:/ 1839 thosaigh &lt;igh&gt; -&gt; /ə/ 1840 teallaigh &lt;igh&gt; -&gt; /i:/ 1843 Ghlaoigh &lt;igh&gt; -&gt; /i:/ 1844 Chuaigh &lt;igh&gt; -&gt; /ə/ 1846 D&#39;ísligh &lt;igh&gt; -&gt; /ə/ 1867 mhalraigh &lt;igh&gt; -&gt; /i:/ 1877 D&#39;ísligh &lt;igh&gt; -&gt; /ə/ 1877 thiontaigh &lt;igh&gt; -&gt; /ə/ 1877 d&#39;éirigh &lt;igh&gt; -&gt; /ə/ 1877 d&#39;ísligh &lt;igh&gt; -&gt; /ə/ 1877 thiontaigh &lt;igh&gt; -&gt; /ə/ 1878 luigh &lt;igh&gt; -&gt; /i:/ 1878 neadaigh &lt;igh&gt; -&gt; /ə/ 1881 uaignigh &lt;igh&gt; -&gt; /i:/ 1883 chompánaigh &lt;igh&gt; -&gt; /i:/ 1884 d&#39;éirigh &lt;igh&gt; -&gt; /ə/ 1886 D&#39;éirigh &lt;igh&gt; -&gt; /ə/ 1886 luigh &lt;igh&gt; -&gt; /i:/ 1893 mhalraigh &lt;igh&gt; -&gt; /i:/ 1903 Chuaigh &lt;igh&gt; -&gt; /ə/ 1908 Bheannaigh &lt;igh&gt; -&gt; /ə/ 1910 malraigh &lt;igh&gt; -&gt; /i:/ 1913 Bhreathnaigh &lt;igh&gt; -&gt; /ə/ 1920 amuigh @ m u . 1577: troighe -&gt; troiche? . 1647: sniff at end . 1653, 1667: sniff/paper slide . 1738: leanbh -&gt; leana . 1839: píobaire -&gt; paobaire? . ids = &quot;1932 1950 1951 1952 1955 1989 1999 2001 2002 2003 2007 2010 2012 2022 2024 2028 2029 2030&quot; idlist = ids.split(&quot; &quot;) print(len(idlist)) . for fid in idlist[0:10]: print(fid + &quot; n&quot;) !cat /home/jim/Playing/snc_ga_co/txt/SNC_Gearrscealta_an_Phiarsaigh_{fid}.txt IPython.display.display(IPython.display.Audio(f&quot;/home/jim/Playing/snc_ga_co/original_wav/SNC0001SNC_Gearrscealta_an_Phiarsaigh_{fid}.wav&quot;)) . def clearp(text): return text.replace(&quot;,&quot;, &quot;&quot;).replace(&quot;.&quot;, &quot;&quot;).replace(&quot;;&quot;, &quot;&quot;).replace(&quot;:&quot;, &quot;&quot;) for fid in idlist[0:5]: ftext = !cat /home/jim/Playing/snc_ga_co/txt/SNC_Gearrscealta_an_Phiarsaigh_{fid}.txt text = clearp(ftext[0]) for word in text.split(&quot; &quot;): if word.endswith(&quot;igh&quot;): print(f&quot;{fid} t{word} t&lt;igh&gt; -&gt; /ə/&quot;) .",
            "url": "https://jimregan.github.io/notes/irish/phonetic/2021/10/16/connaught-igh-check.html",
            "relUrl": "/irish/phonetic/2021/10/16/connaught-igh-check.html",
            "date": " • Oct 16, 2021"
        }
        
    
  
    
        ,"post120": {
            "title": "Plotting segmentation from TextGrid with librosa",
            "content": "%%capture !pip install seaborn . Based on Onset-based Segmentation with Backtracking . %matplotlib inline import seaborn import numpy as np, scipy, matplotlib.pyplot as plt, IPython.display as ipd import librosa, librosa.display plt.rcParams[&#39;figure.figsize&#39;] = (13, 5) . Change to match files: . _TEXTGRID = &quot;&quot; _AUDIO = &quot;&quot; . from praatio import textgrid tg = textgrid.openTextgrid(_TEXTGRID, False) . x, sr = librosa.load(_AUDIO) . ends = [tg.tierDict[&#39;phones&#39;].entryList[0].start] + [end.end for end in tg.tierDict[&#39;phones&#39;].entryList] . phones = [end.label for end in tg.tierDict[&#39;phones&#39;].entryList] . S = librosa.stft(x, n_fft=2048, hop_length=512) logS = librosa.amplitude_to_db(np.abs(S), ref=np.max) librosa.display.specshow(logS, sr=sr, x_axis=&#39;time&#39;, y_axis=&#39;log&#39;) for xc in ends: plt.axvline(x=xc, color=&#39;w&#39;) .",
            "url": "https://jimregan.github.io/notes/textgrid/spectrogram/librosa/2021/10/15/plotting-segmentation-from-textgrid-with-librosa.html",
            "relUrl": "/textgrid/spectrogram/librosa/2021/10/15/plotting-segmentation-from-textgrid-with-librosa.html",
            "date": " • Oct 15, 2021"
        }
        
    
  
    
        ,"post121": {
            "title": "Extract a dictionary from MFA-aligned TextGrids",
            "content": "%%capture !pip install praatio . def irish_lc(word): if word[0:1] in &quot;nt&quot; and word[1:2] in &quot;AEIOUÁÉÍÓÚ&quot;: return word[0:1] + &quot;-&quot; + word[1:].lower() else: return word.lower() . assert irish_lc(&quot;nAthair&quot;) == &quot;n-athair&quot; assert irish_lc(&quot;nDeas&quot;) == &quot;ndeas&quot; . def get_combined_words_and_phones(filename): from praatio import textgrid tg = textgrid.openTextgrid(filename, False) if not tg.tierNameList or tg.tierNameList != [&#39;Word&#39;, &#39;phones&#39;]: return [] word = tg.tierDict[&#39;Word&#39;] phones = tg.tierDict[&#39;phones&#39;] i = 0 j = 0 out = [] def it_to_dict(it): ret = {} ret[&#39;start&#39;] = it.start ret[&#39;end&#39;] = it.end ret[&#39;label&#39;] = it.label return ret while i &lt; len(word.entryList) and j &lt; len(phones.entryList): cur_word = it_to_dict(word.entryList[i]) cur_word[&#39;phones&#39;] = [] while j &lt; len(phones.entryList) and phones.entryList[j].end &lt;= cur_word[&#39;end&#39;]: end_time = phones.entryList[j].end tmp_phone = it_to_dict(phones.entryList[j]) cur_word[&#39;phones&#39;].append(tmp_phone) j += 1 if end_time == cur_word[&#39;end&#39;]: i += 1 out.append(cur_word) continue return out . def get_wordlist_from_combined(items, wordnorm=None): tmp = [] for item in items: word = item[&#39;label&#39;] if wordnorm is None: word = word.lower() else: word = wordnorm(word) phones = &quot; &quot;.join([a[&#39;label&#39;] for a in item[&#39;phones&#39;]]) if phones == &quot;sil&quot;: continue tmp.append((word, phones)) return tmp . from pathlib import Path wd = Path(&quot;PATH TO FILES&quot;) tg_data = {} for tg in wd.glob(&quot;*.TextGrid&quot;): tg_data[tg.stem] = get_wordlist_from_combined(get_combined_words_and_phones(tg), wordnorm=irish_lc) . dictionary = set() for (tg_name, tg_words) in tg_data.items(): dictionary.update(set(tg_words)) . joined = [&quot; &quot;.join(a) for a in dictionary] . with open(&quot;output.dict&quot;, &quot;w&quot;) as outf: for word in sorted(joined): outf.write(word + &quot; n&quot;) .",
            "url": "https://jimregan.github.io/notes/textgrid/mfa/2021/10/15/extract-dictionary-from-mfa-textgrids.html",
            "relUrl": "/textgrid/mfa/2021/10/15/extract-dictionary-from-mfa-textgrids.html",
            "date": " • Oct 15, 2021"
        }
        
    
  
    
        ,"post122": {
            "title": "Interesting links, 12/10/2021",
            "content": "Can Cognate Prediction Be Modelled as a Low-Resource Machine Translation Task?, pdf, code . @inproceedings{fourrier-etal-2021-cognate, title = &quot;Can Cognate Prediction Be Modelled as a Low-Resource Machine Translation Task?&quot;, author = &quot;Fourrier, Cl{ &#39;e}mentine and Bawden, Rachel and Sagot, Beno{ ^ i}t&quot;, booktitle = &quot;Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021&quot;, month = aug, year = &quot;2021&quot;, address = &quot;Online&quot;, publisher = &quot;Association for Computational Linguistics&quot;, url = &quot;https://aclanthology.org/2021.findings-acl.75&quot;, doi = &quot;10.18653/v1/2021.findings-acl.75&quot;, pages = &quot;847--861&quot;, } . OntoEA: Ontology-guided Entity Alignment via Joint Knowledge Graph Embedding, pdf, code . @inproceedings{xiang-etal-2021-ontoea, title = &quot;{O}nto{EA}: Ontology-guided Entity Alignment via Joint Knowledge Graph Embedding&quot;, author = &quot;Xiang, Yuejia and Zhang, Ziheng and Chen, Jiaoyan and Chen, Xi and Lin, Zhenxi and Zheng, Yefeng&quot;, booktitle = &quot;Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021&quot;, month = aug, year = &quot;2021&quot;, address = &quot;Online&quot;, publisher = &quot;Association for Computational Linguistics&quot;, url = &quot;https://aclanthology.org/2021.findings-acl.96&quot;, doi = &quot;10.18653/v1/2021.findings-acl.96&quot;, pages = &quot;1117--1128&quot;, } . As Good as New. How to Successfully Recycle English GPT-2 to Make Models for Other Languages, pdf, code . @inproceedings{de-vries-nissim-2021-good, title = &quot;As Good as New. How to Successfully Recycle {E}nglish {GPT}-2 to Make Models for Other Languages&quot;, author = &quot;de Vries, Wietse and Nissim, Malvina&quot;, booktitle = &quot;Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021&quot;, month = aug, year = &quot;2021&quot;, address = &quot;Online&quot;, publisher = &quot;Association for Computational Linguistics&quot;, url = &quot;https://aclanthology.org/2021.findings-acl.74&quot;, doi = &quot;10.18653/v1/2021.findings-acl.74&quot;, pages = &quot;836--846&quot;, } . Parallel Attention Network with Sequence Matching for Video Grounding, pdf, (code link is broken) . @inproceedings{zhang-etal-2021-parallel, title = &quot;Parallel Attention Network with Sequence Matching for Video Grounding&quot;, author = &quot;Zhang, Hao and Sun, Aixin and Jing, Wei and Zhen, Liangli and Zhou, Joey Tianyi and Goh, Siow Mong Rick&quot;, booktitle = &quot;Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021&quot;, month = aug, year = &quot;2021&quot;, address = &quot;Online&quot;, publisher = &quot;Association for Computational Linguistics&quot;, url = &quot;https://aclanthology.org/2021.findings-acl.69&quot;, doi = &quot;10.18653/v1/2021.findings-acl.69&quot;, pages = &quot;776--790&quot;, } . REPT: Bridging Language Models and Machine Reading Comprehension via Retrieval-Based Pre-training, pdf, code . @inproceedings{jiao-etal-2021-rept, title = &quot;{REPT}: Bridging Language Models and Machine Reading Comprehension via Retrieval-Based Pre-training&quot;, author = &quot;Jiao, Fangkai and Guo, Yangyang and Niu, Yilin and Ji, Feng and Li, Feng-Lin and Nie, Liqiang&quot;, booktitle = &quot;Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021&quot;, month = aug, year = &quot;2021&quot;, address = &quot;Online&quot;, publisher = &quot;Association for Computational Linguistics&quot;, url = &quot;https://aclanthology.org/2021.findings-acl.13&quot;, doi = &quot;10.18653/v1/2021.findings-acl.13&quot;, pages = &quot;150--163&quot;, } . Cross-Lingual Transfer in Zero-Shot Cross-Language Entity Linking, pdf, [code[(https://github.com/elliotschu/crosslingual-el) (not open source) . @inproceedings{schumacher-etal-2021-cross, title = &quot;Cross-Lingual Transfer in Zero-Shot Cross-Language Entity Linking&quot;, author = &quot;Schumacher, Elliot and Mayfield, James and Dredze, Mark&quot;, booktitle = &quot;Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021&quot;, month = aug, year = &quot;2021&quot;, address = &quot;Online&quot;, publisher = &quot;Association for Computational Linguistics&quot;, url = &quot;https://aclanthology.org/2021.findings-acl.52&quot;, doi = &quot;10.18653/v1/2021.findings-acl.52&quot;, pages = &quot;583--595&quot;, } . WikiTableT: A Large-Scale Data-to-Text Dataset for Generating Wikipedia Article Sections, pdf, code . @inproceedings{chen-etal-2021-wikitablet, title = &quot;{W}iki{T}able{T}: A Large-Scale Data-to-Text Dataset for Generating {W}ikipedia Article Sections&quot;, author = &quot;Chen, Mingda and Wiseman, Sam and Gimpel, Kevin&quot;, booktitle = &quot;Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021&quot;, month = aug, year = &quot;2021&quot;, address = &quot;Online&quot;, publisher = &quot;Association for Computational Linguistics&quot;, url = &quot;https://aclanthology.org/2021.findings-acl.17&quot;, doi = &quot;10.18653/v1/2021.findings-acl.17&quot;, pages = &quot;193--209&quot;, } . Discrete Cosine Transform as Universal Sentence Encoder, pdf . @inproceedings{almarwani-diab-2021-discrete, title = &quot;Discrete Cosine Transform as Universal Sentence Encoder&quot;, author = &quot;Almarwani, Nada and Diab, Mona&quot;, booktitle = &quot;Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)&quot;, month = aug, year = &quot;2021&quot;, address = &quot;Online&quot;, publisher = &quot;Association for Computational Linguistics&quot;, url = &quot;https://aclanthology.org/2021.acl-short.53&quot;, doi = &quot;10.18653/v1/2021.acl-short.53&quot;, pages = &quot;419--426&quot;, } . mTVR: Multilingual Moment Retrieval in Videos, pdf, dataset . @inproceedings{lei-etal-2021-mtvr, title = &quot;m{TVR}: Multilingual Moment Retrieval in Videos&quot;, author = &quot;Lei, Jie and Berg, Tamara and Bansal, Mohit&quot;, booktitle = &quot;Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)&quot;, month = aug, year = &quot;2021&quot;, address = &quot;Online&quot;, publisher = &quot;Association for Computational Linguistics&quot;, url = &quot;https://aclanthology.org/2021.acl-short.92&quot;, doi = &quot;10.18653/v1/2021.acl-short.92&quot;, pages = &quot;726--734&quot;, } . nmT5 - Is parallel data still relevant for pre-training massively multilingual language models?, pdf . @inproceedings{kale-etal-2021-nmt5, title = &quot;nm{T}5 - Is parallel data still relevant for pre-training massively multilingual language models?&quot;, author = &quot;Kale, Mihir and Siddhant, Aditya and Al-Rfou, Rami and Xue, Linting and Constant, Noah and Johnson, Melvin&quot;, booktitle = &quot;Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)&quot;, month = aug, year = &quot;2021&quot;, address = &quot;Online&quot;, publisher = &quot;Association for Computational Linguistics&quot;, url = &quot;https://aclanthology.org/2021.acl-short.87&quot;, doi = &quot;10.18653/v1/2021.acl-short.87&quot;, pages = &quot;683--691&quot;, } . Anchor-based Bilingual Word Embeddings for Low-Resource Languages, pdf, website . @inproceedings{eder-etal-2021-anchor, title = &quot;Anchor-based Bilingual Word Embeddings for Low-Resource Languages&quot;, author = &quot;Eder, Tobias and Hangya, Viktor and Fraser, Alexander&quot;, booktitle = &quot;Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)&quot;, month = aug, year = &quot;2021&quot;, address = &quot;Online&quot;, publisher = &quot;Association for Computational Linguistics&quot;, url = &quot;https://aclanthology.org/2021.acl-short.30&quot;, doi = &quot;10.18653/v1/2021.acl-short.30&quot;, pages = &quot;227--232&quot;, } . DefSent: Sentence Embeddings using Definition Sentences, pdf, code (not open source) . @inproceedings{tsukagoshi-etal-2021-defsent, title = &quot;{D}ef{S}ent: Sentence Embeddings using Definition Sentences&quot;, author = &quot;Tsukagoshi, Hayato and Sasano, Ryohei and Takeda, Koichi&quot;, booktitle = &quot;Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)&quot;, month = aug, year = &quot;2021&quot;, address = &quot;Online&quot;, publisher = &quot;Association for Computational Linguistics&quot;, url = &quot;https://aclanthology.org/2021.acl-short.52&quot;, doi = &quot;10.18653/v1/2021.acl-short.52&quot;, pages = &quot;411--418&quot;, } . Is Sparse Attention more Interpretable? pdf . @inproceedings{meister-etal-2021-sparse, title = &quot;Is Sparse Attention more Interpretable?&quot;, author = &quot;Meister, Clara and Lazov, Stefan and Augenstein, Isabelle and Cotterell, Ryan&quot;, booktitle = &quot;Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)&quot;, month = aug, year = &quot;2021&quot;, address = &quot;Online&quot;, publisher = &quot;Association for Computational Linguistics&quot;, url = &quot;https://aclanthology.org/2021.acl-short.17&quot;, doi = &quot;10.18653/v1/2021.acl-short.17&quot;, pages = &quot;122--129&quot;, } . Bilingual Mutual Information Based Adaptive Training for Neural Machine Translation, pdf, code (not open source) . @inproceedings{xu-etal-2021-bilingual, title = &quot;Bilingual Mutual Information Based Adaptive Training for Neural Machine Translation&quot;, author = &quot;Xu, Yangyifan and Liu, Yijin and Meng, Fandong and Zhang, Jiajun and Xu, Jinan and Zhou, Jie&quot;, booktitle = &quot;Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)&quot;, month = aug, year = &quot;2021&quot;, address = &quot;Online&quot;, publisher = &quot;Association for Computational Linguistics&quot;, url = &quot;https://aclanthology.org/2021.acl-short.65&quot;, doi = &quot;10.18653/v1/2021.acl-short.65&quot;, pages = &quot;511--516&quot;, } . X-Fact: A New Benchmark Dataset for Multilingual Fact Checking, pdf, dataset . @inproceedings{gupta-srikumar-2021-x, title = &quot;{X}-Fact: A New Benchmark Dataset for Multilingual Fact Checking&quot;, author = &quot;Gupta, Ashim and Srikumar, Vivek&quot;, booktitle = &quot;Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)&quot;, month = aug, year = &quot;2021&quot;, address = &quot;Online&quot;, publisher = &quot;Association for Computational Linguistics&quot;, url = &quot;https://aclanthology.org/2021.acl-short.86&quot;, doi = &quot;10.18653/v1/2021.acl-short.86&quot;, pages = &quot;675--682&quot;, } . An Improved Model for Voicing Silent Speech, pdf, code . @inproceedings{gaddy-klein-2021-improved, title = &quot;An Improved Model for Voicing Silent Speech&quot;, author = &quot;Gaddy, David and Klein, Dan&quot;, booktitle = &quot;Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)&quot;, month = aug, year = &quot;2021&quot;, address = &quot;Online&quot;, publisher = &quot;Association for Computational Linguistics&quot;, url = &quot;https://aclanthology.org/2021.acl-short.23&quot;, doi = &quot;10.18653/v1/2021.acl-short.23&quot;, pages = &quot;175--181&quot;, } . Higher-order Derivatives of Weighted Finite-state Machines, pdf, code . @inproceedings{zmigrod-etal-2021-higher, title = &quot;Higher-order Derivatives of Weighted Finite-state Machines&quot;, author = &quot;Zmigrod, Ran and Vieira, Tim and Cotterell, Ryan&quot;, booktitle = &quot;Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)&quot;, month = aug, year = &quot;2021&quot;, address = &quot;Online&quot;, publisher = &quot;Association for Computational Linguistics&quot;, url = &quot;https://aclanthology.org/2021.acl-short.32&quot;, doi = &quot;10.18653/v1/2021.acl-short.32&quot;, pages = &quot;240--248&quot;, } .",
            "url": "https://jimregan.github.io/notes/links/2021/10/12/misc-links.html",
            "relUrl": "/links/2021/10/12/misc-links.html",
            "date": " • Oct 12, 2021"
        }
        
    
  
    
        ,"post123": {
            "title": "Octave v. numpy",
            "content": "%%capture !apt install octave . import numpy as np . Convolve . %%writefile conv1.m % https://www.mathworks.com/help/matlab/ref/conv.html u = [1 1 1]; v = [1 1 0 0 0 1 1]; w = conv(u,v) . Writing conv1.m . !octave conv1.m . octave: X11 DISPLAY environment variable not set octave: disabling GUI features w = 1 2 2 1 0 1 2 2 1 . u = [1, 1, 1] v = [1, 1, 0, 0, 0, 1, 1] w = np.convolve(u, v) w . array([1, 2, 2, 1, 0, 1, 2, 2, 1]) . Matrix multiplication . %%writefile matmul.m % https://www.tutorialspoint.com/matlab/matlab_matrix_multiplication.htm a = [ 1 2 3; 2 3 4; 1 2 5] b = [ 2 1 3 ; 5 0 -2; 2 3 -1] prod = a * b . Writing matmul.m . !octave matmul.m . octave: X11 DISPLAY environment variable not set octave: disabling GUI features a = 1 2 3 2 3 4 1 2 5 b = 2 1 3 5 0 -2 2 3 -1 prod = 18 10 -4 27 14 -4 22 16 -6 . a = np.array([[1, 2, 3], [2, 3, 4], [1, 2, 5]]) b = np.array([[2, 1, 3], [5, 0, -2], [2, 3, -1]]) prod = a @ b prod . array([[18, 10, -4], [27, 14, -4], [22, 16, -6]]) . Element-wise multiplication . %%writefile ew_matmul.m % https://www.tutorialspoint.com/matlab/matlab_matrix_multiplication.htm a = [ 1 2 3; 2 3 4; 1 2 5] b = [ 2 1 3 ; 5 0 -2; 2 3 -1] prod = a .* b . Writing ew_matmul.m . !octave ew_matmul.m . octave: X11 DISPLAY environment variable not set octave: disabling GUI features a = 1 2 3 2 3 4 1 2 5 b = 2 1 3 5 0 -2 2 3 -1 prod = 2 2 9 10 0 -8 2 6 -5 . prod = a * b prod . array([[ 2, 2, 9], [10, 0, -8], [ 2, 6, -5]]) .",
            "url": "https://jimregan.github.io/notes/matlab/octave/numpy/2021/10/11/octave_v_numpy.html",
            "relUrl": "/matlab/octave/numpy/2021/10/11/octave_v_numpy.html",
            "date": " • Oct 11, 2021"
        }
        
    
  
    
        ,"post124": {
            "title": "What Makes the Cepstral Peak Prominence Different to Other Acoustic Correlates of Vocal Quality?",
            "content": "What Makes the Cepstral Peak Prominence Different to Other Acoustic Correlates of Vocal Quality? . @article{riesgo2020makes, title={{What Makes the Cepstral Peak Prominence Different to Other Acoustic Correlates of Vocal Quality?}}, author={Riesgo, Carlos A Ferrer and N{ &quot;o}th, Elmar}, journal={Journal of Voice}, volume={34}, number={5}, pages={806.E1--E6}, doi={10.1016/j.jvoice.2019.01.004}, year={2020} } .",
            "url": "https://jimregan.github.io/notes/journal%20club/2021/10/11/journal-club.html",
            "relUrl": "/journal%20club/2021/10/11/journal-club.html",
            "date": " • Oct 11, 2021"
        }
        
    
  
    
        ,"post125": {
            "title": "Extract phonemes from merlin lab files",
            "content": "def break_phones(string): i = 0 mark = 0 toks = [] pieces = { 0: &#39;^&#39;, 1: &#39;-&#39;, 2: &#39;+&#39;, 3: &#39;=&#39;, 4: &#39;@&#39; } piece = 0 while i &lt;= len(string): if string[i:i+1] == pieces[piece]: if piece &lt; 4: toks.append(string[mark:i]) else: if string[i+1:i+2].isdigit(): toks.append(string[mark:i]) else: toks.append(&quot;@&quot;) break piece += 1 mark = i + 1 i += 1 return toks . assert break_phones(&#39;nnj^ii-lj+sil=@@3_2/&#39;) == [&#39;nnj&#39;, &#39;ii&#39;, &#39;lj&#39;, &#39;sil&#39;, &#39;@&#39;] assert break_phones(&quot;x^sil-nnj+ii=lj@1_4&quot;) == [&#39;x&#39;, &#39;sil&#39;, &#39;nnj&#39;, &#39;ii&#39;, &#39;lj&#39;] assert break_phones(&quot;oo^r-sil+x=x@1_1&quot;) == [&#39;oo&#39;, &#39;r&#39;, &#39;sil&#39;, &#39;x&#39;, &#39;x&#39;] . def read_phonemes_lab(filename): phn_bits = [] with open(filename, &quot;r&quot;) as f: for line in f.readlines(): _, _, phones = line.split(&#39; &#39;) phones = break_phones(phones) phn_bits.append(phones) return phn_bits . def check_len(phone_list): length = str(len(phone_list)) return (length[-1] == &quot;0&quot; or length[-1] == &quot;5&quot;) . def prune_phones(phone_list): if not check_len(phone_list): return [] return [a[2] for a in phone_list[::5]] . lab_phonemes_raw = {a: read_phonemes_lab(b) for (a, b) in label_files.items()} . lab_phonemes = {a: prune_phones(b) for (a, b) in lab_phonemes_raw.items()} .",
            "url": "https://jimregan.github.io/notes/lab/merlin/2021/10/08/extract-phonemes-from-merlin-lab-files.html",
            "relUrl": "/lab/merlin/2021/10/08/extract-phonemes-from-merlin-lab-files.html",
            "date": " • Oct 8, 2021"
        }
        
    
  
    
        ,"post126": {
            "title": "Interesting links, 7/10/2021",
            "content": "CMU Advanced NLP 2021 (10): Prompting + Sequence-to-sequence Pre-training . gong-io/gecko — Gecko - A Tool for Effective Annotation of Human Conversations . datasets - opus_dogc.py . def _generate_examples(self, filepath): xml_lang = &quot;{http://www.w3.org/XML/1998/namespace}lang&quot; with open(filepath, encoding=&quot;utf-8&quot;) as f: id_ = 0 for _, elem in ET.iterparse(f): if elem.tag == &quot;tuv&quot;: language = elem.attrib[xml_lang] sentence = elem.find(&quot;seg&quot;).text if language == &quot;ca&quot;: ca_sentence = sentence elif language == &quot;es&quot;: es_sentence = sentence elif elem.tag == &quot;tu&quot;: yield id_, { &quot;translation&quot;: {&quot;ca&quot;: ca_sentence, &quot;es&quot;: es_sentence}, } id_ += 1 elem.clear() . _parse_tmx() . spaCy : en : test_noun_chunks.py . spacy/lang/en/syntax_iterators.py . Add task template for automatic speech recognition . task = AutomaticSpeechRecognition(audio_file_column=&quot;file&quot;, transcription_column=&quot;text&quot;) ds.prepare_for_task(task) . Create Audio feature #2324 . BigSSL: Exploring the Frontier of Large-Scale Semi-Supervised Learning for Automatic Speech Recognition . We summarize the results of a host of efforts using giant automatic speech recognition (ASR) models pre-trained using large, diverse unlabeled datasets containing approximately a million hours of audio. We find that the combination of pre-training, self-training and scaling up model size greatly increases data efficiency, even for extremely large tasks with tens of thousands of hours of labeled data. In particular, on an ASR task with 34k hours of labeled data, by fine-tuning an 8 billion parameter pre-trained Conformer model we can match state-of-the-art (SoTA) performance with only 3% of the training data and significantly improve SoTA with the full training set. We also report on the universal benefits gained from using big pre-trained and self-trained models for a large set of downstream tasks that cover a wide range of speech domains and span multiple orders of magnitudes of dataset sizes, including obtaining SoTA performance on many public benchmarks. In addition, we utilize the learned representation of pre-trained networks to achieve SoTA results on non-ASR tasks. . Turn-to-Diarize: Online Speaker Diarization Constrained by Transformer Transducer Speaker Turn Detection . In this paper, we present a novel speaker diarization system for streaming on-device applications. In this system, we use a transformer transducer to detect the speaker turns, represent each speaker turn by a speaker embedding, then cluster these embeddings with constraints from the detected speaker turns. Compared with conventional clustering-based diarization systems, our system largely reduces the computational cost of clustering due to the sparsity of speaker turns. Unlike other supervised speaker diarization systems which require annotations of time-stamped speaker labels for training, our system only requires including speaker turn tokens during the transcribing process, which largely reduces the human efforts involved in data collection. . flite_sapi_usenglish.c, FliteTTSEngineObj.cpp . Wav2vec2 pretraining 2 #13520 . Seoladh Gaelscéal - nuacht24 . nuacht24 . Ar Chanúintí na Gaeilge (audio) . rspeer/python-ftfy — Fixes mojibake and other glitches in Unicode text, after the fact. . tkipf/gcn — Implementation of Graph Convolutional Networks in TensorFlow . Grapheme-to-Phoneme Transduction for Cross-Language ASR, preprint . @InProceedings{hasegawa20g2p, author=&quot;Hasegawa-Johnson, Mark and Rolston, Leanne and Goudeseune, Camille and Levow, Gina-Anne and Kirchhoff, Katrin&quot;, editor=&quot;Espinosa-Anke, Luis and Mart{ &#39;i}n-Vide, Carlos and Spasi{ &#39;{c}}, Irena&quot;, title=&quot;Grapheme-to-Phoneme Transduction for Cross-Language ASR&quot;, booktitle=&quot;Statistical Language and Speech Processing&quot;, year=&quot;2020&quot;, publisher=&quot;Springer International Publishing&quot;, address=&quot;Cham&quot;, pages=&quot;3--19&quot;, doi=&quot;10.1007/978-3-030-59430-5_1&quot;, isbn=&quot;978-3-030-59430-5&quot; } .",
            "url": "https://jimregan.github.io/notes/links/2021/10/07/misc-links.html",
            "relUrl": "/links/2021/10/07/misc-links.html",
            "date": " • Oct 7, 2021"
        }
        
    
  
    
        ,"post127": {
            "title": "Loading Foinse dataset",
            "content": "!pip install datasets . from datasets import load_dataset . foinse = load_dataset(&quot;jimregan/foinse&quot;, &quot;documents&quot;) . Downloading and preparing dataset foinse_dataset/documents to /root/.cache/huggingface/datasets/foinse_dataset/documents/1.1.0/1f38b24860415793797d1e25734a8f044b0621b08c7618392c4aae9740097b34... Dataset foinse_dataset downloaded and prepared to /root/.cache/huggingface/datasets/foinse_dataset/documents/1.1.0/1f38b24860415793797d1e25734a8f044b0621b08c7618392c4aae9740097b34. Subsequent calls will reuse this data. . foinse . DatasetDict({ train: Dataset({ features: [&#39;title&#39;, &#39;url&#39;, &#39;author&#39;, &#39;date_text&#39;, &#39;text&#39;, &#39;category&#39;, &#39;subcategory&#39;, &#39;summary&#39;], num_rows: 4283 }) }) .",
            "url": "https://jimregan.github.io/notes/irish/foinse/datasets/2021/10/05/loading-foinse-dataset.html",
            "relUrl": "/irish/foinse/datasets/2021/10/05/loading-foinse-dataset.html",
            "date": " • Oct 5, 2021"
        }
        
    
  
    
        ,"post128": {
            "title": "Foinse scraper pieces, ctd",
            "content": "Continued . link = &quot;http://web.archive.org/web/20171209002240/http://www.foinse.ie/sport/eile/6412-an-dornalai-john-joe-nevin-rangaithe-ag-uimhir-a-haon-anois&quot; . import requests from bs4 import BeautifulSoup . def extract_summary(inlist): if len(inlist) &gt; 2: if inlist[-2] == &quot;Did you understand this story? Here are the main points:&quot;: return inlist[-1] return &quot;&quot; . def filter_para_list(inlist): out = [] for para in inlist: if para == &quot;&quot;: continue elif para.strip() == &quot;Foinse - News as Gaeilge&quot;: return out elif para.strip() == &quot;Did you understand this story? Here are the main points:&quot;: return out else: out.append(para) return out . def get_content(url, text=&quot;&quot;): out = {} if text: page_content = text else: page = requests.get(url) if page.status_code != 200: return {} page_content = page.text soup = BeautifulSoup(page_content, &quot;lxml&quot;) content = soup.find(&quot;div&quot;, {&quot;class&quot;: &quot;item-page&quot;}) if not content: content = soup.find(&quot;div&quot;, {&quot;id&quot;: &quot;ja-main&quot;}) if not content: return {} breadcrumbs = soup.find(&quot;div&quot;, {&quot;class&quot;: &quot;ja-breadcrums&quot;}) if breadcrumbs: here = breadcrumbs.find(&quot;a&quot;, {&quot;class&quot;: &quot;pathway&quot;}) if not here: here = breadcrumbs.find(&quot;span&quot;, {&quot;class&quot;: &quot;pathway&quot;}) if here: out[&quot;category&quot;] = here.text.strip() # junk jc = content.find(&quot;div&quot;, {&quot;id&quot;: &quot;jc&quot;}) if jc: jc.extract() pagenav = content.find(&quot;ul&quot;, {&quot;class&quot;: &quot;pagenav&quot;}) if pagenav: pagenav.extract() for js in content.find_all(&quot;script&quot;, {&quot;type&quot;: &quot;text/javascript&quot;}): js.extract() h2 = content.find(&quot;h2&quot;) if h2: title = h2.text.strip() if title: out[&quot;title&quot;] = title h2.extract() h1 = content.find(&quot;h1&quot;) if h1: heading = h1.text.strip() if heading: out[&quot;subcategory&quot;] = heading h1.extract() published_tag = content.find(&quot;dd&quot;, {&quot;class&quot;: &quot;published&quot;}) if not published_tag: published_tag = content.find(&quot;span&quot;, {&quot;class&quot;: &quot;createdate&quot;}) if published_tag: out[&quot;published&quot;] = published_tag.text.strip() author_tag = content.find(&quot;dd&quot;, {&quot;class&quot;: &quot;createdby&quot;}) if not author_tag: author_tag = content.find(&quot;span&quot;, {&quot;class&quot;: &quot;createby&quot;}) if author_tag: out[&quot;author&quot;] = author_tag.text.strip() artinfo = content.find(&quot;dl&quot;, {&quot;class&quot;: &quot;article-info&quot;}) if not artinfo: artinfo = content.find(&quot;div&quot;, {&quot;class&quot;: &quot;article-meta&quot;}) if artinfo: artinfo.extract() paragraphs_tags = content.find_all(&quot;p&quot;) paragraphs = [p.text.replace(&quot; xa0&quot;, &quot; &quot;).strip() for p in paragraphs_tags] out[&quot;text&quot;] = paragraphs raw_text = content.text raw_out = [] for raw_line in raw_text.split(&quot; n&quot;): line = raw_line.replace(&quot; xa0&quot;, &quot; &quot;).strip() if line == &quot;&quot;: continue raw_out.append(line) if paragraphs != raw_out: out[&quot;text&quot;] = raw_out summary = extract_summary(out[&quot;text&quot;]) if summary: out[&quot;summary&quot;] = summary out[&quot;text&quot;] = filter_para_list(out[&quot;text&quot;]) vocab_list = [] for vocab in content.find_all(&quot;a&quot;, {&quot;class&quot;: &quot;glossarylink&quot;}): item = {} item[&quot;en&quot;] = vocab.get(&quot;title&quot;).strip() item[&quot;ga&quot;] = vocab.text.strip() vocab_list.append(item) out[&quot;vocab&quot;] = vocab_list return out . page = requests.get(link) soup = BeautifulSoup(page.text, &quot;lxml&quot;) content = soup.find(&quot;div&quot;, {&quot;class&quot;: &quot;item-page&quot;}) if not content: print(&quot;Empty&quot;) . Oh, hey, I&#39;ve already downloaded this stuff and made a list of likely good articles. Might not work out well for anyone else. . BASE_DIR = &quot;/home/jim/Playing/foinseunpacked&quot; file = open(f&quot;{BASE_DIR}/attempt1&quot;, &quot;r&quot;) pages = [] for link in file.readlines(): pages.append(link.strip()) . foinse_data = [] with open(&quot;/home/jim/foinse-bad.txt&quot;, &quot;w&quot;) as bad_list: for page in pages: print(page) page_path = BASE_DIR + page.strip()[6:] with open(page_path, &quot;r&quot;) as pagef: plines = pagef.readlines() ptext = &quot; n&quot;.join(plines) content = get_content(page_path, ptext) if content: foinse_data.append(content) else: bad_list.write(page + &quot; n&quot;) . import json with open(&#39;foinse.json&#39;, &#39;w&#39;) as outfile: json.dump(foinse_data, outfile) .",
            "url": "https://jimregan.github.io/notes/irish/scraper/foinse/2021/10/05/foinse-scraper-pieces-ctd.html",
            "relUrl": "/irish/scraper/foinse/2021/10/05/foinse-scraper-pieces-ctd.html",
            "date": " • Oct 5, 2021"
        }
        
    
  
    
        ,"post129": {
            "title": "Interspeech papers",
            "content": "A Comparison of Acoustic Correlates of Voice Quality Across Different Recording Devices: A Cautionary Tale . Joshua Penney, Andy Gibson, Felicity Cox, Michael Proctor, Anita Szakay . PDF . @inproceedings{penney21_interspeech, author={Joshua Penney and Andy Gibson and Felicity Cox and Michael Proctor and Anita Szakay}, title={{A Comparison of Acoustic Correlates of Voice Quality Across Different Recording Devices: A Cautionary Tale}}, year=2021, booktitle={Proc. Interspeech 2021}, pages={1389--1393}, doi={10.21437/Interspeech.2021-729} } . . Emotional Prosody Control for Speech Generation . Sarath Sivaprasad, Saiteja Kosgi, Vineet Gandhi . PDF, samples . @inproceedings{sivaprasad21_interspeech, author={Sarath Sivaprasad and Saiteja Kosgi and Vineet Gandhi}, title={{Emotional Prosody Control for Speech Generation}}, year=2021, booktitle={Proc. Interspeech 2021}, pages={4653--4657}, doi={10.21437/Interspeech.2021-307} } . . Excitation Source Feature Based Dialect Identification in Ao — A Low Resource Language . Moakala Tzudir, Shikha Baghel, Priyankoo Sarmah, S.R. Mahadeva Prasanna . PDF . @inproceedings{tzudir21_interspeech, author={Moakala Tzudir and Shikha Baghel and Priyankoo Sarmah and S.R. Mahadeva Prasanna}, title={{Excitation Source Feature Based Dialect Identification in Ao — A Low Resource Language}}, year=2021, booktitle={Proc. Interspeech 2021}, pages={1524--1528}, doi={10.21437/Interspeech.2021-1672} } . . Phoneme Recognition Through Fine Tuning of Phonetic Representations: A Case Study on Luhya Language Varieties . Kathleen Siminyu, Xinjian Li, Antonios Anastasopoulos, David R. Mortensen, Michael R. Marlo, Graham Neubig . PDF, arXiv . @inproceedings{siminyu21_interspeech, author={Kathleen Siminyu and Xinjian Li and Antonios Anastasopoulos and David R. Mortensen and Michael R. Marlo and Graham Neubig}, title={{Phoneme Recognition Through Fine Tuning of Phonetic Representations: A Case Study on Luhya Language Varieties}}, year=2021, booktitle={Proc. Interspeech 2021}, pages={271--275}, doi={10.21437/Interspeech.2021-1434} } . . How Reliable Are Phonetic Data Collected Remotely? Comparison of Recording Devices and Environments on Acoustic Measurements . Chunyu Ge, Yixuan Xiong, Peggy Mok . PDF . @inproceedings{ge21b_interspeech, author={Chunyu Ge and Yixuan Xiong and Peggy Mok}, title={{How Reliable Are Phonetic Data Collected Remotely? Comparison of Recording Devices and Environments on Acoustic Measurements}}, year=2021, booktitle={Proc. Interspeech 2021}, pages={3984--3988}, doi={10.21437/Interspeech.2021-1122} } . . Sound Change in Spontaneous Bilingual Speech: A Corpus Study on the Cantonese n-l Merger in Cantonese-English Bilinguals . Rachel Soo, Khia A. Johnson, Molly Babel . PDF . @inproceedings{soo21_interspeech, author={Rachel Soo and Khia A. Johnson and Molly Babel}, title={{Sound Change in Spontaneous Bilingual Speech: A Corpus Study on the Cantonese n-l Merger in Cantonese-English Bilinguals}}, year=2021, booktitle={Proc. Interspeech 2021}, pages={421--425}, doi={10.21437/Interspeech.2021-1754} } . . (Not read) . Parsing Speech for Grouping and Prominence, and the Typology of Rhythm . Michael Wagner, Alvaro Iturralde Zurita, Sijia Zhang . PDF . @inproceedings{wagner21_interspeech, author={Michael Wagner and Alvaro Iturralde Zurita and Sijia Zhang}, title={{Parsing Speech for Grouping and Prominence, and the Typology of Rhythm}}, year=2021, booktitle={Proc. Interspeech 2021}, pages={2656--2660}, doi={10.21437/Interspeech.2021-1684} } .",
            "url": "https://jimregan.github.io/notes/journal%20club/2021/10/04/journal-club.html",
            "relUrl": "/journal%20club/2021/10/04/journal-club.html",
            "date": " • Oct 4, 2021"
        }
        
    
  
    
        ,"post130": {
            "title": "Interspeech papers",
            "content": "End-to-End Spelling Correction Conditioned on Acoustic Feature for Code-Switching Speech Recognition . Shuai Zhang, Jiangyan Yi, Zhengkun Tian, Ye Bai, Jianhua Tao, Xuefei Liu, Zhengqi Wen . PDF . @inproceedings{zhang21d_interspeech, author={Shuai Zhang and Jiangyan Yi and Zhengkun Tian and Ye Bai and Jianhua Tao and Xuefei Liu and Zhengqi Wen}, title={{End-to-End Spelling Correction Conditioned on Acoustic Feature for Code-Switching Speech Recognition}}, year=2021, booktitle={Proc. Interspeech 2021}, pages={266--270}, doi={10.21437/Interspeech.2021-1242} } . Spell checking as conditioned language model for code-switching in ASR. . Dataset: . ASRU 2019 Mandarin-English code-switching Challenge dataset 500 hours Mandarin | 200 hours code-switching | only used code-switching | . | . Augmentation: . ASR text: 10-fold cross validation | beam size 10 | . | audio: SpecAugment | dropout | . | . Metric: . Mix error rate (MER): WER for English, CER for Mandarin | . Experimental setup: . ASR Kaldi | 40-dim Mel filter-bank | 25ms windowing | 10ms frame shift | 3 * 2D CNN downsampling layers w/ stride 2 for acoustic features | attention dimensions 256 for both encode and decoder | 4 heards | position-wise feed-forward networks dim 1024 | 12 encoder blocks, 6 decoder blocks | . | LM 6-gram, KenLM | unidirectional LSTM | . | Spelling correction Encoder/decoder dims 256, num. heads: 4 | position-wise feed-forward networks dim 512 | dimension conversion layer to unify text &amp; acoustic features | uniform label smoothing, 0.1 | residual dropout: 0.1 applied to each sub-block | learning rate set by warm up | average last 5 checkpoints | wordpiece vocab: 1k for English, Chinese characters appearing more than 5 times in training set | . | . . Phoneme Recognition Through Fine Tuning of Phonetic Representations: A Case Study on Luhya Language Varieties . Kathleen Siminyu, Xinjian Li, Antonios Anastasopoulos, David R. Mortensen, Michael R. Marlo, Graham Neubig . PDF, arXiv . @inproceedings{siminyu21_interspeech, author={Kathleen Siminyu and Xinjian Li and Antonios Anastasopoulos and David R. Mortensen and Michael R. Marlo and Graham Neubig}, title={{Phoneme Recognition Through Fine Tuning of Phonetic Representations: A Case Study on Luhya Language Varieties}}, year=2021, booktitle={Proc. Interspeech 2021}, pages={271--275}, doi={10.21437/Interspeech.2021-1434} } . Fine tuning of allosaurus (“universal phone recognizer”) for three varieties of Luhya. . Data: . Saamia bible.is via CMU Wilderness | 18.2 hours | . | Bukusu Dictionary pronunciations | 3.7 hours | . | East Tusom Tusom2021 | 55.3 minutes | . | G2P with epitran | Splits: Bukusu: 6442 (train), 1001 (dev), 2458 (test) | Saamia: 7254 (train), 1000 (dev), 1500 (test) | East Tusom: 1600 (train), 400 (dev), 392 (test) | . | . Experiment: . sizes: 10, 25, 50, 100, 250, 500 and 1000 (approx. doubling progression) | fine-tuning is done on one model: same encoder 6 layer bilstm | hidden size 1024 per layer | . | 250 epochs of fine tuning | . Results: PER (relative improvement) .   Bukusu Saamia East Tusom . Allosaurus | 72.8 | 63.7 | 67.5 | . &amp; constraint | 52.5 | 37.4 | 56.7 | . &amp; fine-tuning (100) | 41.2 (21.5%) | 15.5 (58.5%) | 44.8 (20.9%) | . &amp; fine-tuning (1000) | 17.3 (67.0%) | 11.7 (65.7%) | 34.6 (38.9%) | . &amp; fine-tuning (all) | 5.2 (90.1%) | 9.2 (75.4%) | 33.1 (41.6%) | . . Exploring wav2vec 2.0 on Speaker Verification and Language Identification . Zhiyun Fan, Meng Li, Shiyu Zhou, Bo Xu . PDF . @inproceedings{fan21_interspeech, author={Zhiyun Fan and Meng Li and Shiyu Zhou and Bo Xu}, title={{Exploring wav2vec 2.0 on Speaker Verification and Language Identification}}, year=2021, booktitle={Proc. Interspeech 2021}, pages={1509--1513}, doi={10.21437/Interspeech.2021-1280} } . Finetunes monolingual English wav2vec model for speaker verification and/or language ID. . Fine tuning average pooling layer and fully connected layer | Loss: cross-entropy (AM-softmax for speaker classification) | . | Fine tuning, multi-task (speaker + language) average pooling, two parallel fully connected layers | loss is weighted sum of individual losses | . | Datasets VoxCeleb1 (speaker verification) | AP17-OLR (language ID) | . | Metric Equal error rate (EER) | . | . Results (single): . SV: 3.61 | LID: 3.47 | . Results (multitask): . SV: 4.18 | LID: 4.88 | . . Low Resource ASR: The Surprising Effectiveness of High Resource Transliteration . Shreya Khare, Ashish Mittal, Anuj Diwan, Sunita Sarawagi, Preethi Jyothi, Samarth Bharadwaj . pdf . @inproceedings{khare21_interspeech, author={Shreya Khare and Ashish Mittal and Anuj Diwan and Sunita Sarawagi and Preethi Jyothi and Samarth Bharadwaj}, title={{Low Resource ASR: The Surprising Effectiveness of High Resource Transliteration}}, year=2021, booktitle={Proc. Interspeech 2021}, pages={1529--1533}, doi={10.21437/Interspeech.2021-2062} } . Uses text in a second language transliterated to target language to augment training data for ASR. . We observe that for languages like Hindi and Telugu where the KL distance in phone distribution is small and the transliteration PER is low, we get consistent gains across different architectures and training data sizes. . G2P: epitran, g2ps | Tools: ESPnet, wav2vec2 | Datasets Microsoft Speech Corpus (Indian Languages): Gujarati and Telugu | Hindi ASR Challenge dataset | OpenSLR Large Bengali dataset | Zeroth Korean | ALFFA Amharic | . | . there’s a significant improvement in performance across both training settings with using Hindi instead of English during pretraining. Using both transliterated English and Hindi data during pretraining for the 10-hour Gujarati task further reduces WERs from 55.8% to 32.4% . . Improving Accent Identification and Accented Speech Recognition Under a Framework of Self-Supervised Learning pdf . @inproceedings{deng21b_interspeech, author={Keqi Deng and Songjun Cao and Long Ma}, title={{Improving Accent Identification and Accented Speech Recognition Under a Framework of Self-Supervised Learning}}, year=2021, booktitle={Proc. Interspeech 2021}, pages={1504--1508}, doi={10.21437/Interspeech.2021-1186} } . Fine tuning wav2vec2 for accented speech recognition/accent ID . Dataset: . LibriSpeech (pretrain) | AESRC2020 (finetune) | . . TODO . Robust wav2vec 2.0: Analyzing Domain Shift in Self-Supervised Pre-Training . AST: Audio Spectrogram Transformer . Raw Waveform Encoder with Multi-Scale Globally Attentive Locally Recurrent Networks for End-to-End Speech Recognition . Y-Vector: Multiscale Waveform Encoder for Speaker Embedding . Speech Acoustic Modelling Using Raw Source and Filter Components . Leveraging Phone Mask Training for Phonetic-Reduction-Robust E2E Uyghur Speech Recognition . Rethinking Evaluation in ASR: Are Our Models Robust Enough? . wav2vec-C: A Self-Supervised Model for Speech Representation Learning . Multimodal Speech Summarization Through Semantic Concept Learning . A Noise Robust Method for Word-Level Pronunciation Assessment . Improving RNN-T for Domain Scaling Using Semi-Supervised Training with Neural TTS . Phonetically Motivated Self-Supervised Speech Representation Learning . slimIPL: Language-Model-Free Iterative Pseudo-Labeling . Semi-Supervision in ASR: Sequential MixMatch and Factorized TTS-Based Augmentation . A Comparison of Supervised and Unsupervised Pre-Training of End-to-End Models . Momentum Pseudo-Labeling for Semi-Supervised Speech Recognition . On the Learning Dynamics of Semi-Supervised Training for ASR . Improving Streaming Transformer Based ASR Under a Framework of Self-Supervised Learning . Data Augmentation Methods for End-to-End Speech Recognition on Distant-Talk Scenarios . Multi-Channel Transformer Transducer for Speech Recognition . Scaling Sparsemax Based Channel Selection for Speech Recognition with ad-hoc Microphone Arrays . IR-GAN: Room Impulse Response Generator for Far-Field Speech Recognition . Noise Robust Acoustic Modeling for Single-Channel Speech Recognition Based on a Stream-Wise Transformer Architecture . Phoneme-Aware and Channel-Wise Attentive Learning for Text Dependent Speaker Verification .",
            "url": "https://jimregan.github.io/notes/links/2021/10/04/interspeech-papers.html",
            "relUrl": "/links/2021/10/04/interspeech-papers.html",
            "date": " • Oct 4, 2021"
        }
        
    
  
    
        ,"post131": {
            "title": "L’Accent dans le gaëlique du Munster",
            "content": "Original . Transcription Irish French IPA Standard Modern . l̬um | liom | avec moi | lʲʊmˠ |   |   | . flⁱuĉ | fliuch | mouillé, humide | fʲlʲʊx |   |   | . qilā́n | cuileán | jeune chien | kɪˈlʲaːn̪ˠ | coileán |   | . qiŝlán | caisleán | château | kəˈʃlʲɑːn̪ˠ |   |   | . tᵘₑršạĉ | tuirseach | fatigué | t̪ˠəɾˠˈʃax |   |   | . bon-āt̬ | bunáit | principale résidence, fondation |   |   |   | . múⁱnt̬óⁱr | múinteóir | professeur | mˠuːn̠ʲˈtʲoːɾʲ | múinteoir |   | . drifⁱúr | deirbhshiur | sœur | dʲɾʲəˈfʲuːɾˠ | deirfiúr | drifiúr | . ₑmₑdạ̄́n | amadán | un fou | ɑmˠəˈd̪ˠɑːnˠ |   |   | . màontₑĉạ̄́n | manntachán | qui a les dents ébréchées |   | mantachán |   | . O’ Sùleƀáⁱn | O’ Súilleabháin | nom propre |   | Ó Súilleabháin |   | . cliₑƀạ̄́n | cliabhán | berceau |   |   |   | . baləƀạ̄́n | balbhán | muet |   |   |   | . bₑgạ̄́n | beagán | un peu, peu |   |   |   | . qịlạ̄́n | cuileán | jeune chien | kɪˈlʲaːn̪ˠ | coileán |   | . bₑrạ̄́nₑ/brā́n | biorán | épingle, un rien | bʲɪˈɾˠɑːn̪ˠ, bɾʲɑːn̪ˠ |   |   | . brₑdạ̄́n | bradán | saumon | bˠɾˠəˈd̪ˠaːn̪ˠ |   |   | . qišlạ̄́n | caisleán | château |   |   |   | . pǫrtạ̄́n | portán | crabe |   |   |   | . ₑrạ̄́n | arán | pain | əˈɾˠɑːn̪ˠ |   |   | . cupạ̄́n | cupán | coupe | kʊˈpˠɑːnˠ |   |   | . ẹlạ̄́n | oileán | île | əˈlʲɑːnˠ |   |   | . scạ̄hạ̄́n | scáthán | mirroir, à côté de | sˠkɑːˈhɑːn̪ˠ |   |   | . scₑhā́n | scathán | buisson |   | scothán |   | . mọ̄rā́n | mórán | beaucoup | mˠoːˈɾˠɑːn̪ˠ |   |   | . awrā́n | abhrán | poème, chant | əuˈɾˠɑːn̪ˠ | amhrán |   | . bǫĉtā́n | bochtán | un pauvre |   |   |   | . capₑlī́n | capaillín | petit cheval |   |   |   | . lanₑƀī́n | leanbhín | petit enfant | lʲanəˈvʲiːnʲ |   |   | . cąlī́n | cailín | fillette | kaˈlʲiːnʲ |   |   | . gₑrtī́n | guirtín | petit champ |   | goirtín |   | . trₑhī́n | troighthín | petit pied |   | troighín |   | . ạyntī́n | aintín | tante | ɑːnʲˈtʲiːnʲ (áintín) |   |   | . spalpī́n | spailpín | journalier, laboureur errant |   |   |   | . crūšcī́n | crúiscín | cruche |   |   |   | . cábī́n | cáibín | vieux chapeau | kaːˈbʲiːnʲ |   |   | . drōlī́n | dreoilín | roitelet |   |   |   | . bǭrhī́n | bóithrín | petit sentier |   |   |   | . trāʰnī́n | tráithnín | brin d’herbe |   |   |   | . crīƀī́n | craoibhín | petite branche |   |   |   | . fįn̬ọ̄́g | fuinneóg | fenêtre | fˠəˈn̠ʲoːɡ | fuinneog |   | . fwīn̬šọ̄́g | fuinnseóg | frêne |   | fuinseog |   | . cesọ̄́g | casóg | veston | kəˈsˠoːɡ |   |   | . fwišọ́g | fuiseóg | alouette | fˠəˈʃoːɡ | fuiseog |   | . išó̦g | an fhuiseóg | l’alouette |   | an fhuiseog |   | . qīnlọ̄́ir | coinnleóir | chandelier |   | coinnleoir |   | . dlīdǫ́ir | dligheadóir | homme de loi |   | dlíodóir |   | . múⁱntǭ́ⁱr | múinteóir | professeur |   | múinteoir |   | . āęršoⁱr | aidhbheirseóir | l’adversaire (le diable) |   | áibhirseoir |   | . slānₑhǭ́ⁱr | slánuightheóir | le sauveur |   | slánaitheoir |   | . šc̬ₑbǭl | sgioból | grenier | ʃcɪˈbˠoːl̪ˠ | scioból |   | .",
            "url": "https://jimregan.github.io/notes/irish/munster/2021/10/03/laccent-dans-le-gaelique-du-munster.html",
            "relUrl": "/irish/munster/2021/10/03/laccent-dans-le-gaelique-du-munster.html",
            "date": " • Oct 3, 2021"
        }
        
    
  
    
        ,"post132": {
            "title": "Interesting links, 1/10/2021",
            "content": "Irish lemmatiser (merged) . Irish lemmatisation data (merged) . Best Python based AutoML frameworks in 2021 . jonmagic/copy-excel-paste-markdown . . The New Corpus of Ireland – ELRC-SHARE . The UCD Bórd na Gaeilge Corpus of bilingual PDFs and Word documents – ELRC-SHARE . Toiliú don Scagthástáil Scoile um Amhairc &amp; Éisteachta – ELRC-SHARE . Tuairisc a thug Máire Nic Shiubhlaigh, Aisteoir Tionscanta de chuid Amharlann na Mainistreach, ar ghéilleadh gharastún mhonarcha Jacob – ELRC-SHARE . Tuarascáil Bhliantúil Chomhairle Chontae Longfoirt (2017) – ELRC-SHARE . Tuarascálaca Bliantúla na Roinne Leanaí agus Gnóthaí Óige – ELRC-SHARE . Foirm FSS Iarratais Duine ar a Shonraí – ELRC-SHARE . Irish Monolingual Corpus from contents of health.gov.ie web site – ELRC-SHARE . LáithreánGréasáinOÉG – ELRC-SHARE . Leabhrán d’Aonad Altranais Pobail Teach Uí Riada – ELRC-SHARE . Legal acts of Ireland as Irish Monolingual Corpus – ELRC-SHARE . Litir ó Oifig an Choimisinéara Teanga – ELRC-SHARE . Manufactured data based on ParaCrawl 8 v2 – ELRC-SHARE . Material in Irish and English from RTÉ – ELRC-SHARE . Oifigí Ombudsman in Éirinn – ELRC-SHARE . Pleananna ITBÁC le comóradh a dhéanamh ar 1916 – ELRC-SHARE . Póstaer faoi scoil ag clárú – ELRC-SHARE . Preasráiteas faoi foirgneamh nua scoile – ELRC-SHARE . Preasráiteas faoi Uachtarán nua – ELRC-SHARE . Preasráiteas: Mí Iúil – ELRC-SHARE . Preasráitis Gaois, Fiontar &amp; Scoil na Gaeilge, DCU (1) – ELRC-SHARE . Preasráitis Gaois, Fiontar &amp; Scoil na Gaeilge, DCU (2) – ELRC-SHARE . Preasráitis Oifig an Choimisinéara Teanga – ELRC-SHARE . Preasráitis Ollscoil Mhá Nuad Earrach 2019 – ELRC-SHARE . Preasráitis Ollscoil Mhá Nuad Samhradh 2019 – ELRC-SHARE . PRINCIPLE Anonymized English-Irish DCHG parallel translation memory dataset – ELRC-SHARE . PRINCIPLE An tAonad Aistriúcháin agus Ateangaireachta ÓEG/NUIG Translation Unit dataset – ELRC-SHARE . PRINCIPLE Dept of Justice parallel English-Irish secondary legislation – ELRC-SHARE . PRINCIPLE Dept of Justice parallel English-Irish secondary legislation (evaluated) – ELRC-SHARE . PRINCIPLE English-Irish Annual Reports from the Houses of the Oireachtas – ELRC-SHARE . PRINCIPLE English-Irish eJustice Corpus (Evaluated) – ELRC-SHARE . PRINCIPLE English-Irish glossary of terms relating to primary legislation in Ireland – ELRC-SHARE . PRINCIPLE English-Irish Houses of the Oireachtas ancillary material dataset – ELRC-SHARE . Compilation of Irish-Polish parallel corpora resources used for training of NTEU Machine Translation engines. – ELRC-SHARE . COVID-19 ANTIBIOTIC dataset. Multilingual (CEF languages) – ELRC-SHARE . COVID-19 EC-EUROPA v1 dataset. Bilingual (EN-GA) – ELRC-SHARE . COVID-19 EC-EUROPA v1 dataset. Multilingual (CEF languages) – ELRC-SHARE . COVID-19 EU presscorner v1 dataset. Bilingual (EN-GA) – ELRC-SHARE . COVID-19 EU presscorner v2 dataset. Bilingual (EN-GA) – ELRC-SHARE . English-Irish website parallel corpus (Processed) – ELRC-SHARE . Faisnéis faoi IDS – ELRC-SHARE . PRINCIPLE Dept of Justice parallel English-Irish secondary legislation – ELRC-SHARE . Bilingual corpus from the European Vaccination Portal (GA-EN) – ELRC-SHARE .",
            "url": "https://jimregan.github.io/notes/links/2021/10/01/misc-links.html",
            "relUrl": "/links/2021/10/01/misc-links.html",
            "date": " • Oct 1, 2021"
        }
        
    
  
    
        ,"post133": {
            "title": "Convert LASID",
            "content": "Set up ICU . %%capture !pip install pyicu . import icu def transliterator_from_rules(name, rules): fromrules = icu.Transliterator.createFromRules(name, rules) icu.Transliterator.registerInstance(fromrules) return icu.Transliterator.createInstance(name) . Download data . _URL = &quot;https://www3.smo.uhi.ac.uk/oduibhin/oideasra/lasid/lasid.zip&quot; . %%capture !wget {_URL} . %%capture !unzip lasid.zip . LASID transliterators . lasid_icu = &quot;&quot;&quot; x07 → ᵏ ; t → ᵉ ; # x09 x0e → ᴵ ; x11 → ʰ ; x12 → ⁱ ; x13 → ᵒ ; x14 → ᵒ̤ ; x15 → ʳ ; x16 → ˢ ; x17 → ᶴ ; x18 → ᵗ ; x19 → ᵘ ; x1a → ᵘ̯ ; x1c → ᵛ ; x1d → ʷ ; x1e → ᶾ ; x1f → ᵊ ; # → ᶠ ; # x23 $ → ᵠ ; # x24 % → ᵍ ; # x25 &amp; → ᵞ ; # x26 ˠ for IPA &#39; → ’ ; # x27 : → ː ; # x3a &lt; → ⁱ̈ ; # x3c = → ⁱ̯ ; # x3d ? → ʔ ; # x3f @ → ʲ ; # x40 E → ᴇ ; # x45 I → ɪ ; # x49 L → ʟ ; N → ɴ ; R → ʀ ; ^ → ᵐ ; # x5e _ → ǰ ; # crane, 021 # x5f ` → ɛ̀̃ ; # limekiln, 078: x60 | → ⁿ ; # lamb, 055: x7c ~ → ᵑ ; # dreaming, 078; maybe ⁿ̠ ? # x7e x7f → ᴇ̃ ; x80 → φ ; # ɸ x81 → ü ; x83 → ɛ u0300 ; x84 → è u0323 ; # FIXME x85 → è̃ ; # this is �, so it needs to be escaped x86 → ũ̜ ; # lamb, 038 x87 → u̜ ; # finger-nails, 043 x88 → ʈ ; # looks like t̜ : toothache, 033 x89 → ᵃ ; # eggs, 066 x8a → è ; x8b → ï ; x8c → ɔ̜̃ ; # grandmother, 007 x8d → ɔ̜ ; x8e → ɔ̆ ; # before i go, 078 x8f → õ̜ ; # as cute, 062 x91 → æ ; x92 → o̜ ; x93 → ɖ ; x94 → ö ; x95 → ɑ̜̃ ; x96 → û ; # milking, 067 x97 → ɑ u0323 ; # FIXME (maybe α̩ or ɑ̜ ?) x98 → v̠ ; x99 → t̠ ; # toothache, 021 x9a → r̠ ; x9b → ø ; x9c → ɴ̠ ; # sick, 034 x9d → ŋ̠ ; # grazing, 002 x9e → n̠ ; x9f → l̠ ; # plumage, 068 xa4 → k̠ ; # plumage, 068 xa5 → g̠ ; xa6 → d̠ ; # wedge, 021 xa7 → ŭ ; xa8 → ö̆ ; xa9 → ŏ ; xaa → ĭ ; xab → ɛ̆ ; xac → ĕ ; xad → o̤ ; xae → λ ; xaf → ɑ ; # α in the software xb0 → ɔ ; xb1 → ɑ̆ u0323 ; # FIXME xb2 → ə ; xb4 → ᵈ ; # tail, 007 xb6 → ɑ̆ ; # ᾰ in the software xb7 → ă ; xb8 → λ u0323 ; # FIXME xb9 → ɛ ; xba → ʃ u030c ; # calling, 067 xbb → š ; xbc → ř ; xbd → ɑ̃ ; xbe → ẽ ; # tied, 88N xc1 → ′ ; # superscript prime xc5 → ᴍ̠ ; # fart, 071 xc6 → ã ; # calf, 046 xc7 → t u0323 ; # probably t̞ xc8 → λ̯ ; # mane, 067 xc9 → o̯ ; # hare, 088 xca → Ɫ ; # loaf, 001 xcb → ɫ ; # loaf, 003 xcc → m̥ ; # awake, 001 xcd → ʀ̥ ; # thieving, 003 xce → ˈ ; xcf → ˌ ; # cattle, 040 xd0 → ð ; # boar, 88N xd1 → s u0323 ; # FIXME # slime 008 xd2 → r u0323 ; # FIXME # bulls 067 xd3 → ɪ̆ ; # suit of clothes 039 xd4 → ᴇ̀ ; xd5 → p u0323 ; # FIXME # castrating 053 xd7 → ɪ̃ ; # slime, 007 xd8 → ɪ̈ ; # calf 027 xdb → o u0323 ; # FIXME # cow 028 xdc → ŋ u0323 ; # FIXME # tied 078 xdd → ö̤ ; xde → k u0323 ; # FIXME xdf → i u0323 ; # FIXME # sick 069 xe1 → g u0323 ; # FIXME xe2 → e u0323 ; # FIXME xe3 → d u0323 ; # FIXME # agut 052 xe4 → õ ; # I shall tie 062 xe5 → b u0323 ; # FIXME # castrating 071 xe6 → ɑ̃ u0323 ; #FIXME # barking 049 xe7 → ɑ u0323 ; # FIXME # slime 008 xe8 → ỹ ; xea → λ̃ ; xeb → ü̃ ; # churn-dash, 011 xec → ũ ; xed → ɔ̃ ; # cow 074 xee → õ̤ ; # barking 055 xef → ′ ; xf0 → ″ ; xf1 → ö̤̃ ; # dreaming, 078 xf2 → ö̃ ; # sheep shears 074 xf3 → ï̃ ; # churn-dash, 034 xf4 → ĩ ; # sick 001 xf5 → ɣ̃ ; # tied 075 xf6 → ɛ̃ ; # tied 067 xf7 → n̥ ; # awake, 059 xf8 → r̥ ; # slime 002 xf9 → ʃ ; xfb → · ; # slime 058 xfa → ɣ ; xfc → χ ; # limekiln, 080 xfd → ʒ ; # sheep shears 054 xfe → ŋ ; &quot;&quot;&quot; . lasid_titles_icu = &quot;&quot;&quot; xb5 → Á ; xd6 → Í ; x90 → É ; xe0 → Ó ; xe9 → Ú ; &quot;&quot;&quot; . I&#39;m not sure if there&#39;s something wrong with this, or if it&#39;s that there are just no spaces in a lot of the transcriptions, but this is best avoided. . lasid_spacing = &quot;&quot;&quot; $sp = &#39; u0020&#39;; $sp $sp $sp $sp $sp → _; [^[0-9]] { $sp → ; ::null; _ → $sp ; &quot;&quot;&quot; . lasid = transliterator_from_rules(&#39;lasid_icu&#39;, lasid_icu) titles = transliterator_from_rules(&#39;lasid_titles&#39;, lasid_titles_icu) spacing = transliterator_from_rules(&#39;lasid_spacing&#39;, lasid_spacing) . def translit_phon(text, spaces=True): # could have been any 8-bit encoding line = lasid.transliterate(text.decode(&#39;ISO-8859-1&#39;).rstrip()) if spaces: return spacing.transliterate(line) else: return line . def translit_irish(text, spaces=True): line = titles.transliterate(text.decode(&#39;ISO-8859-1&#39;).rstrip()) if spaces: return spacing.transliterate(line) else: return line . Process . file = open(&quot;mapdata.dat&quot;, &quot;rb&quot;) . data = {} cur = {} ga = &#39;&#39; id = &#39;&#39; en = &#39;&#39; . for line in file.readlines(): if b&#39;{M&#39; in line: prev_en = en text = line.decode(&#39;ISO-8859-1&#39;).rstrip() id = text[3:7].strip() en = text[7:-1].strip() tmp = {} tmp[&#39;en&#39;] = prev_en tmp[&#39;id&#39;] = id tmp[&#39;ga&#39;] = ga tmp[&#39;data&#39;] = cur data[id] = tmp cur = {} elif b&#39;{F&#39; in line: raw = translit_irish(line, False) ga = raw[3:-1].strip() elif line.decode(&#39;ISO-8859-1&#39;)[0:1].isnumeric(): pid = line.decode(&#39;ISO-8859-1&#39;)[0:3] ptext = translit_phon(line[3:-1], False) if ptext[-1] == &#39;*&#39;: ptext = ptext[0:-1] cur[pid] = ptext.strip() . import json with open(&#39;lasid.json&#39;, &#39;w&#39;) as outfile: json.dump(data, outfile) .",
            "url": "https://jimregan.github.io/notes/irish/lasid/2021/09/28/lasid.html",
            "relUrl": "/irish/lasid/2021/09/28/lasid.html",
            "date": " • Sep 28, 2021"
        }
        
    
  
    
        ,"post134": {
            "title": "Task list, 28/9/2021",
            "content": "Today . separation script: spleeter: see run_spleeter.py . | Extend abair xml to return list of timestamps; segment long recordings: notebook . | Rebase w2v notebook on this or this . | Add LM and timings: see here, repo, file, this issue, parlance/ctcdecode, wav2vec2_kenlm.py . | Fingerprint for known audio: dejavu . | Pass over input data, with this or something similar . | MFA, based on this . | . Look into: . Add official ASR CTC example to examples/pytorch/speech-recognition | Rewrite padding logic from pure python to numpy | Non-Adversarial Unsupervised Word Translation | Phonetic-and-Semantic Embedding of Spoken Words with Applications in Spoken Content Retrieval | grtzsohalf/Audio-Phonetic-and-Semantic-Embedding | SpeechToolsWorkers | . Personal . Run this See this: | . --match-filter &quot;license=&#39;Creative Commons Attribution license (reuse allowed)&#39;&quot; . Living audio . Longer term . TG4 Foghlaim scraper Lessons . | Scrape more Ros na Rún . | Compare this with stuff from last year . | Segmentation: run_cleanup_segmentation.sh, tedlium, AMI . | VOSK LM . | CUNY-CL . | . Look at: . 2dot71mily/youtube_captions_corrections | microsoft/Recognizers-Text | hiromis/notes | Alexander-H-Liu/NPC | andi611/Mockingjay-Speech-Representation | jina-ai/jina | Continue this — p. 18 | scrapinghub/portia | wav2vec2-large-voxrex, Kungbib/swedish-bert-models | .",
            "url": "https://jimregan.github.io/notes/tasklist/2021/09/27/tasklist.html",
            "relUrl": "/tasklist/2021/09/27/tasklist.html",
            "date": " • Sep 27, 2021"
        }
        
    
  
    
        ,"post135": {
            "title": "Pronunciations from Simple Lessons in Irish, part 1",
            "content": "Source . Section Word Modern Transcription Wiktionary Abair Ulster Abair Connacht Abair Munster . 10 | sál |   | saul | sˠɑːlˠ | ˈsˠaːʟˠ | ˈsˠɑːʟˠ | ˈsˠɑːlˠ | . 14 | tobar |   | thŭbăr | ˈt̪ˠɔbˠəɾˠ | ˈtˠobˠəɾˠ | ˈtˠobˠəɾˠ | ˈtˠobˠəɾˠ | . 17 | mine |   | min′-ě | ˈmʲɪnʲə | ˈmʲinʲə | ˈmʲinʲə | ˈmʲinʲə | . 17 | míle |   | meel′-ě | ˈmʲiːlʲə | ˈmʲiːlʲə | ˈmʲiːlʲə | ˈmʲiːlʲə | . 19 | an |   | ăn | ənˠ | ˈəɴˠ | əɴˠ | ənˠ | . 19 | gort |   | gŭrth | ɡɔɾˠt̪ˠ | ˈgˠoɾˠtˠ | ˈgˠauɾˠtˠ | ˈgˠoɾˠtˠ | . 20 | cú |   | koo | kuː | ˈkˠuː | ˈkˠuː | ˈkˠuː | . 20 | óg |   | ōg | oːɡ | ˈoːgˠ | ˈoːgˠ | ˈoːgˠ | . 21 | árd | ard | aurdh | ɑːɾˠd̪ˠ | ˈaːɾˠdˠ | ˈɑːɾˠdˠ | ˈɑːɾˠdˠ | . 21 | mé |   | mae | mʲeː | ˈmʲeː | ˈmʲe | mʲe | . 21 | bó |   | bō | bˠoː | ˈbˠoː | ˈbˠoː | ˈbˠoː | . 21 | mór |   | mōr | mˠoːɾˠ | ˈmˠoːɾˠ | ˈmˠoːɾˠ | ˈmˠuːɾˠ | . 21 | bos |   | bŭs |   | ˈbˠasˠ | ˈbˠosˠ | ˈbˠosˠ | . 21 | cos |   | kŭs | kɔsˠ | ˈkˠosˠ | ˈkˠosˠ | ˈkˠosˠ | . 21 | glas |   | glos | ɡlˠasˠ | ˈgˠʟˠasˠ | ˈgˠʟˠasˠ | ˈgˠlˠasˠ | . 21 | srón |   | srōn | sˠɾˠoːnˠ | ˈsˠɾˠoːɴˠ | ˈsˠɾˠoːɴˠ | ˈsˠɾˠoːnˠ | . 21 | glún | glúin | gloon | ɡl̪ˠuːnʲ | ˈgˠʟˠuːɴˠ | ˈgˠʟˠuːɴˠ | ˈgˠlˠuːnˠ | . 21 | tú |   | thoo | t̪ˠuː | ˈtˠuː | ˈtˠuː | ˈtˠuː | . 21 | úr |   | oor | uːɾˠ | ˈuːɾˠ | ˈuːɾˠ | ˈuːɾˠ | . 21 | Art |   | orth |   | ˈaɾˠtˠ | ˈaɾˠtˠ | ˈaɾˠtˠ | . 21 | Úna |   | oon′-ă | ˈuːnˠə | ˈuːɴˠə | ˈuːɴˠə | ˈuːnˠə | . 21 | agus |   | og-ăs | ˈɑɡəsˠ | ˈagˠəsˠ | ˈagˠəsˠ | ˈagˠəsˠ | . 25 | atá |   | ă-thau′ | əˈt̪ˠɑː | əˈtˠaː | əˈtˠɑː | əˈtˠɑː | . 25 | tá |   | thau | t̪ˠɑː | ˈtˠaː | ˈtˠɑː | ˈtˠɑː | . 29 | asal |   | os′-ăl | ˈasˠəlˠ | ˈasˠəʟˠ | ˈasˠəʟˠ | ˈasˠəlˠ | . 29 | fál |   | faul | fˠɑːlˠ | ˈfˠaːʟˠ | ˈfˠɑːʟˠ | ˈfˠɑːlˠ | . 29 | doras |   | dhŭr′-ăs | ˈd̪ˠɔɾˠəsˠ | ˈdˠoɾˠəsˠ | ˈdˠoɾˠəsˠ | ˈdˠoɾˠəsˠ | . 29 | glan |   | glon | ɡlˠanˠ | ˈgˠʟˠaɴˠ | ˈgˠʟˠaɴˠ | ˈgˠlˠanˠ | . 29 | dún |   | dhoon | d̪ˠuːnˠ | ˈdˠuːɴˠ | ˈdˠuːɴˠ | ˈdˠuːnˠ | . 29 | tobar |   | thŭb`-ăr | ˈt̪ˠɔbˠəɾˠ | ˈtˠobˠəɾˠ | ˈtˠobˠəɾˠ | ˈtˠobˠəɾˠ | . 35 | ag |   | og |   |   |   |   | . 35 | ag |   | e𝘨 | əɟ | ˈeɟ | eɟ | əɟ | . 35 | fós |   | fōs | fˠoːsˠ | ˈfˠoːsˠ | ˈfˠoːsˠ | ˈfˠoːsˠ | . 35 | bog |   | bug | bˠɔɡ | ˈbˠogˠ | ˈbˠogˠ | ˈbˠogˠ | . 35 | sé |   | shae | ʃeː | ˈʃeː | ʃe | ˈʃeː | . 35 | bróg |   | brōg | bˠɾˠoːɡ | ˈbˠɾˠoːgˠ | ˈbˠɾˠoːgˠ | ˈbˠɾˠoːgˠ | . 35 | sí |   | shee | ʃiː | ˈʃiː | ˈʃiː | ˈʃiː | . 35 | dún |   | dhoon | d̪ˠuːnˠ | ˈdˠuːɴˠ | ˈdˠuːɴˠ | ˈdˠuːnˠ | . 35 | stól |   | sthōl | sˠt̪ˠoːlˠ | ˈsˠtˠoːʟˠ | ˈsˠtˠoːʟˠ | ˈsˠtˠoːlˠ | . 35 | fada |   | fodh-ă | ˈfˠad̪ˠə | ˈfˠadˠə | ˈfˠadˠə | ˈfˠadˠə | . 35 | te |   | 𝘵e | tʲɛ | ˈtʲe | ˈtʲe | ˈtʲe | . 35 | fág |   | faug | fˠɑːɡ | ˈfˠaːgˠ | ˈfˠɑːgˠ | ˈfˠɑːgˠ | . 35 | tír |   | 𝘵ee𝘳 | tʲiːɾʲ | ˈtʲiːɾʲ | ˈtʲiːɾʲ | ˈtʲiːɾʲ | . 35 | tirim |   | 𝘵i𝘳′-im | ˈtʲɪɾʲəmʲ | ˈtʲiɾʲəmʲ | ˈtʲiɾʲəmʲ | ˈtʲiɾʲəmʲ | . 39 | ar |   | or |   |   |   |   | . 39 | ar |   | e𝘳 | ɛɾʲ | ˈeɾʲ | eɾʲ | əɾˠ | . 39 | glas |   | glos | ɡlˠasˠ | ˈgˠʟˠasˠ | ˈgˠʟˠasˠ | ˈgˠlˠasˠ | . 39 | bád |   | baudh | bˠɑːd̪ˠ | ˈbˠaːdˠ | ˈbˠɑːdˠ | ˈbˠɑːdˠ | . 39 | mála |   | maul′-ă | ˈmˠɑːl̪ˠə | ˈmˠaːʟˠə | ˈmˠɑːʟˠə | ˈmˠɑːlˠə | . 39 | cóta |   | kōth′-ă | ˈkoːt̪ˠə | ˈkˠoːtˠə | ˈkˠoːtˠə | ˈkˠoːtˠə | . 50 | mála |   | maul-a′ | ˈmˠɑːl̪ˠə | ˈmˠaːʟˠə | ˈmˠɑːʟˠə | ˈmˠɑːlˠə | . 50 | milis |   | mil′ish | ˈmʲɪlʲəʃ | ˈmʲilʲəʃ | ˈmʲilʲəʃ | ˈmʲilʲiʃ | . 50 | Úna |   | oo′-na |   | ˈuːɴˠə | ˈuːɴˠə | ˈuːnˠə | . 50 | minic |   | min′ik | ˈmʲɪnʲɪc | ˈmʲinʲic | ˈmʲinʲəc | ˈmʲinʲəc | . 50 | bán |   | baun | bˠɑːn̪ˠ | ˈbˠaːɴˠ | ˈbˠɑːɴˠ | ˈbˠɑːnˠ | . 50 | asal |   | os′-al | ˈasˠəlˠ | ˈasˠəʟˠ | ˈasˠəʟˠ | ˈasˠəlˠ | . 50 | olc |   | ŭlk | ɔlˠk | ˈoʟˠkˠ | ˈoʟˠkˠ | ˈolˠkˠ | . 50 | blas |   | blos | bˠlˠasˠ | ˈbˠʟˠasˠ | ˈbˠʟˠasˠ | ˈbˠlˠasˠ | . 51 | lag |   | Log | l̪ˠaɡ | ˈʟˠagˠ | ˈʟˠagˠ | ˈlˠagˠ | . 51 | log |   | Lŭg | l̪ˠɔɡ | ˈʟˠogˠ | ˈʟˠogˠ | ˈlˠogˠ | . 51 | slán |   | sLaun | sˠl̪ˠɑːn̪ˠ | ˈsˠʟˠaːɴˠ | ˈsˠʟˠɑːɴˠ | ˈsˠlˠɑːnˠ | . 51 | dlún |   | dhLoon |   | ˈdˠʟˠuːɴˠ | ˈdˠʟˠuːɴˠ | ˈdˠlˠuːnˠ | . 51 | tlú |   | thLoo | t̪ˠlˠuː | ˈtˠʟˠuː | ˈtˠʟˠuː | ˈtˠl̪ˠuː | . 51 | lín |   | 𝘭een |   | ˈʟʲiːnʲ | ˈʟʲiːnʲ | ˈlʲiːnʲ | . 51 | slím |   | sh𝘭eem |   | ˈʃlʲiːmʲ | ˈʃlʲiːmʲ | ˈʃlʲiːmʲ | . 51 | fille |   | fi𝘭′-e | ˈfʲiːl̠ʲə | ˈfʲiʟʲə | ˈfʲiʟʲə | ˈfʲilʲə | . 51 | Nús |   | Noos |   | ˈɴˠuːsˠ | ˈɴˠuːsˠ | ˈnˠuːsˠ | . 51 | snag |   | sNog | sˠn̪ˠaɡ | ˈsˠɴˠagˠ | ˈsˠɴˠagˠ | ˈsˠnˠagˠ | . 51 | Nóra |   | Nōr′ă | ˈn̪ˠoːɾˠə | ˈɴˠoːɾˠə | ˈɴˠuːɾˠə | ˈnˠoːɾˠə | . 51 | Finne |   | fi𝘯′-ĕ | ˈfʲɪn̠ʲə | ˈfʲiɴʲə | ˈfʲiɴʲə | ˈfʲinʲə | . 51 | binne |   | bi𝘯′-ĕ | ˈbʲɪn̠ʲə | ˈbʲiɴʲə | ˈbʲiɴʲə | ˈbʲinʲə | . 51 | ní |   | 𝘯ee | n̠ʲiː | ˈɴʲiː | ˈɴʲiː | ˈnʲiː | . 52 | balla |   | boL′-ă | ˈbˠal̪ˠə | ˈbˠoʟˠə | ˈbˠaʟˠə |   | . 52 | falla |   | foL′-ă | ˈfˠɑl̪ˠə |   |   | ˈfˠalˠə | . 52 | bán |   | baun | bˠɑːn̪ˠ | ˈbˠaːɴˠ | ˈbˠɑːɴˠ | ˈbˠɑːnˠ | . 52 | capall |   | kop′-ăL | ˈkapˠəl̪ˠ | ˈkˠapˠəʟˠ | ˈkˠapˠəʟˠ | ˈkˠapˠəlˠ | . 52 | Conn |   | kŭN |   | ˈkˠoɴˠ | ˈkˠauɴˠ | ˈkˠoːnˠ | . 52 | fan |   | fon | fˠanˠ | ˈfˠaɴˠ | ˈfˠaɴˠ | ˈfˠanˠ | . 52 | glan |   | glon | ɡlˠanˠ | ˈgˠʟˠaɴˠ | ˈgˠʟˠaɴˠ | ˈgˠlˠanˠ | . 52 | lá |   | Lau | l̪ˠɑː | ˈʟˠaː | ˈʟˠɑː | ˈlˠɑː | . 52 | lán |   | Laun | l̪ˠɑːnˠ | ˈʟˠaːɴˠ | ˈʟˠɑːɴˠ | ˈlˠɑːnˠ | . 52 | milis |   | mil′-ish | ˈmʲɪlʲəʃ | ˈmʲilʲəʃ | ˈmʲilʲəʃ | ˈmʲilʲiʃ | . 52 | ná |   | Nau | n̪ˠɑː | ˈɴˠaː | ˈɴˠɑː | ˈnˠɑː | . 52 | slán |   | sLaun | sˠl̪ˠɑːn̪ˠ | ˈsˠʟˠaːɴˠ | ˈsˠʟˠɑːɴˠ | ˈsˠlˠɑːnˠ | . 52 | solas |   | sŭl′-ăs | ˈsˠɔlˠəsˠ | ˈsˠoʟˠəsˠ | ˈsˠuʟˠəsˠ | ˈsˠolˠəsˠ | . 55 | blas |   | blos | bˠlˠasˠ | ˈbˠʟˠasˠ | ˈbˠʟˠasˠ | ˈbˠlˠasˠ | . 55 | Gránárd | Gránard | graun′-aurdh |   | ˈgˠɾˠaːɴˠaːɾˠdˠ | ˈgˠɾˠɑːɴˠɑːɾˠdˠ | gˠɾˠɑːˈnˠɑːɾˠdˠ | . 55 | bris |   | brish | bʲɾʲɪʃ | ˈbʲɾʲiʃ | ˈbʲɾʲiʃ | ˈbʲɾʲiʃ | . 55 | lag |   | Log | l̪ˠaɡ | ˈʟˠagˠ | ˈʟˠagˠ | ˈlˠagˠ | . 55 | dúnta |   | dhooN′-thă | ˈd̪ˠuːn̪ˠt̪ˠə | ˈdˠuːɴˠtˠə | ˈdˠuːɴˠtˠə | ˈdˠuːnˠtˠə | . 55 | mol |   | mŭl | mˠɔlˠ | ˈmˠoʟˠ | ˈmˠoʟˠ | ˈmˠolˠ | . 59 | níl |   | 𝘯eel | n̠ʲiːlʲ | ˈɴʲiːlʲ | ˈɴʲiːlʲ | ˈnʲiːlʲ | . 60 | fir |   | fi𝘳 | fʲɪɾʲ | ˈfʲiɾʲ | ˈfʲiɾʲ | ˈfʲiɾʲ | . 61 | ag |   | ă | ə |   |   |   | . 61 | fás |   | faus | fˠɑːsˠ | ˈfˠaːsˠ | ˈfˠɑːsˠ | ˈfˠɑːsˠ | . 61 | dul |   | dul | d̪ˠʊlˠ |   |   | ˈdˠulˠ | . 61 | dul | goil | gul | ɡɔlʲ |   | ˈgˠolʲ |   | . 61 | imirt |   | im′i𝘳𝘵 | ˈɪmʲəɾˠtʲ | ˈimʲəɾˠtʲ | ˈimʲəɾˠtʲ | ˈimʲəɾˠtʲ | . 62 | do |   | dhŭ | d̪ˠɔ | ˈdˠə | dˠo | dˠo | . 62 | níl |   | neel | n̠ʲiːlʲ | ˈɴʲiːlʲ | ˈɴʲiːlʲ | ˈnʲiːlʲ | . 62 | do’n | don | dhǔn | d̪ˠənˠ | ˈdˠoɴˠ | ˈdˠoɴˠ | ˈdˠonˠ | . 62 | ó |   | ō | oː | ˈoː | ˈoː | ˈoː | . 62 | dul |   | dhul | d̪ˠʊlˠ | ˈdˠuʟˠ | ˈdˠuʟˠ | ˈdˠulˠ | . 62 | fás |   | faus | fˠɑːsˠ | ˈfˠaːsˠ | ˈfˠɑːsˠ | ˈfˠɑːsˠ | . 62 | olann |   | ŭl′-ăN | ˈɔlˠən̪ˠ | ˈoʟˠəɴˠ | ˈoʟˠəɴˠ | ˈolˠənˠ | .",
            "url": "https://jimregan.github.io/notes/irish/ogrowney/2021/09/27/simple-lessons-in-irish-pronunciation1.html",
            "relUrl": "/irish/ogrowney/2021/09/27/simple-lessons-in-irish-pronunciation1.html",
            "date": " • Sep 27, 2021"
        }
        
    
  
    
        ,"post136": {
            "title": "Interesting links, 27/9/2021",
            "content": "KTH Academic year 2021-22 . Irish pronunciation: practice and theory . A grammar of the Irish language . perfall/Edyson . Low Resource ASR: The Surprising Effectiveness of High Resource Transliteration pdf . @inproceedings{khare21_interspeech, author={Shreya Khare and Ashish Mittal and Anuj Diwan and Sunita Sarawagi and Preethi Jyothi and Samarth Bharadwaj}, title={{Low Resource ASR: The Surprising Effectiveness of High Resource Transliteration}}, year=2021, booktitle={Proc. Interspeech 2021}, pages={1529--1533}, doi={10.21437/Interspeech.2021-2062} } . Exploring wav2vec 2.0 on Speaker Verification and Language Identification pdf . @inproceedings{fan21_interspeech, author={Zhiyun Fan and Meng Li and Shiyu Zhou and Bo Xu}, title={{Exploring wav2vec 2.0 on Speaker Verification and Language Identification}}, year=2021, booktitle={Proc. Interspeech 2021}, pages={1509--1513}, doi={10.21437/Interspeech.2021-1280} } . Improving Accent Identification and Accented Speech Recognition Under a Framework of Self-Supervised Learning pdf . @inproceedings{deng21b_interspeech, author={Keqi Deng and Songjun Cao and Long Ma}, title={{Improving Accent Identification and Accented Speech Recognition Under a Framework of Self-Supervised Learning}}, year=2021, booktitle={Proc. Interspeech 2021}, pages={1504--1508}, doi={10.21437/Interspeech.2021-1186} } .",
            "url": "https://jimregan.github.io/notes/links/2021/09/27/misc-links.html",
            "relUrl": "/links/2021/09/27/misc-links.html",
            "date": " • Sep 27, 2021"
        }
        
    
  
    
        ,"post137": {
            "title": "Cognitive and Structural Correlates of Conversational Speech Timing in Mild Cognitive Impairment and Mild-to-Moderate Alzheimer’s Disease - Relevance for Early Detection Approaches",
            "content": "Cognitive and Structural Correlates of Conversational Speech Timing in Mild Cognitive Impairment and Mild-to-Moderate Alzheimer’s Disease: Relevance for Early Detection Approaches . Background | . The present study examines whether the temporal characteristics of speech in a collaborative referencing task are associated with cognitive function and the volumes of brain regions involved in speech production and known to be reduced in MCI and AD pathology. . Method | Results | Conclusion | . Introduction . Speech and language impairments are indeed salient characteristics of MCI and early AD link . However, the cognitive and structural underpinnings of these speech-based measures in classification approaches have not been systematically investigated and are not fully established. link . Deficits in the lexical, semantic, executive, discourse and pragmatic domains of language are commonly observed in MCI and early AD link . AD speech is characterized by slower speech rate (global speed of speech including pauses), a higher number of silent pauses, longer pauses and shorter interpausal units (or chunks of speech bounded by silent pauses link . Expectations . | Participants . | Neuropsychological Tests . | Speech Annotation and Measure Extraction . | . The pause threshold used in the automatic procedure was set at 100 ms to ensure its distinction with silent plosives link . The significance level was set at α = 0.006 link . Classification used cgplibrary . our exploratory analyses showed moderate accuracy rates for the speech-based classifiers in the pairwise contrasts link . Limitations . Abbreviations — might have been more useful earlier .",
            "url": "https://jimregan.github.io/notes/journal%20club/2021/09/27/journal-club.html",
            "relUrl": "/journal%20club/2021/09/27/journal-club.html",
            "date": " • Sep 27, 2021"
        }
        
    
  
    
        ,"post138": {
            "title": "Foinse scraper pieces",
            "content": "link = &quot;http://web.archive.org/web/20130922081459/http://www.foinse.ie/nuacht/nuacht-is-deanai/6765-suil-go-gcruthofar-158-post-nua-le-tograi-ata-ceadaithe-ag-unag&quot; . import requests from bs4 import BeautifulSoup . page = requests.get(link) assert page.status_code == 200 . In purely text terms, much of the junk can be discarded using these comments: . if &quot;&lt;!-- CONTENT --&gt;&quot; in page.text: trim = page.text.split(&quot;&lt;!-- CONTENT --&gt;&quot;)[1] . if trim and &quot;&lt;!-- //CONTENT --&gt;&quot; in trim: trim = trim.split(&quot;&lt;!-- //CONTENT --&gt;&quot;)[0] . ... but it&#39;s easier with BeautifulSoup to just extract &lt;div class=&quot;item-page&quot;&gt; . soup = BeautifulSoup(page.text, &quot;lxml&quot;) . content = soup.find(&quot;div&quot;, {&quot;class&quot;: &quot;item-page&quot;}) . title = content.find(&quot;h2&quot;).text.strip() . &#39;Súil go gcruthófar 158 post nua le tograí atá ceadaithe ag ÚnaG&#39; . published_tag = content.find(&quot;dd&quot;, {&quot;class&quot;: &quot;published&quot;}) . if published_tag: published = published_tag.text.strip() . author_tag = content.find(&quot;dd&quot;, {&quot;class&quot;: &quot;createdby&quot;}) if author_tag: author = author_tag.text.strip() . author . &#39;Scríofa ag Foinse&#39; . paragraphs_tags = content.find_all(&quot;p&quot;, {&quot;class&quot;: &quot;MsoNormal&quot;}) . paragraphs = [p.text.replace(&quot; xa0&quot;, &quot; &quot;).strip() for p in paragraphs_tags] . vocab_list = [] for p in paragraphs_tags: for vocab in p.find_all(&quot;a&quot;, {&quot;class&quot;: &quot;glossarylink&quot;}): item = {} item[&quot;en&quot;] = vocab.get(&quot;title&quot;).strip() item[&quot;ga&quot;] = vocab.text.strip() vocab_list.append(item) . check = &quot;http://web.archive.org/web/20171222073817/http://www.foinse.ie/nuacht/nuacht-is-deanai/6822-seanoiri-ag-dul-i-mbun-agoide-maidir-le-ciorruithe&quot; . page2 = requests.get(check) assert page2.status_code == 200 . def get_content(url): out = {} page = requests.get(url) if page.status_code != 200: return {} soup = BeautifulSoup(page.text, &quot;lxml&quot;) content = soup.find(&quot;div&quot;, {&quot;class&quot;: &quot;item-page&quot;}) if not content: return {} title = content.find(&quot;h2&quot;).text.strip() if title: out[&quot;title&quot;] = title published_tag = content.find(&quot;dd&quot;, {&quot;class&quot;: &quot;published&quot;}) if published_tag: out[&quot;published&quot;] = published_tag.text.strip() author_tag = content.find(&quot;dd&quot;, {&quot;class&quot;: &quot;createdby&quot;}) if author_tag: out[&quot;author&quot;] = author_tag.text.strip() paragraphs_tags = content.find_all(&quot;p&quot;, {&quot;class&quot;: &quot;MsoNormal&quot;}) paragraphs = [p.text.replace(&quot; xa0&quot;, &quot; &quot;).strip() for p in paragraphs_tags] out[&quot;text&quot;] = paragraphs vocab_list = [] for p in paragraphs_tags: for vocab in p.find_all(&quot;a&quot;, {&quot;class&quot;: &quot;glossarylink&quot;}): item = {} item[&quot;en&quot;] = vocab.get(&quot;title&quot;).strip() item[&quot;ga&quot;] = vocab.text.strip() vocab_list.append(item) out[&quot;vocab&quot;] = vocab_list return out . def filter_para_list(inlist): out = [] for para in inlist: if para == &quot;&quot;: continue elif para.strip() == &quot;Foinse - News as Gaeilge&quot;: return out else: out.append(para) return out . def extract_summary(inlist): if len(inlist) &gt; 2: if inlist[-2] == &quot;Did you understand this story? Here are the main points:&quot;: return inlist[-1] return &quot;&quot; .",
            "url": "https://jimregan.github.io/notes/irish/scraper/foinse/2021/09/27/foinse_scraper_pieces.html",
            "relUrl": "/irish/scraper/foinse/2021/09/27/foinse_scraper_pieces.html",
            "date": " • Sep 27, 2021"
        }
        
    
  
    
        ,"post139": {
            "title": "Interesting links, 26/9/2021",
            "content": "A Framework for Any-to-Any Voice Conversion with Self-Supervised Pretrained Representations . howard1337/S2VC . yistLin/universal-vocoder; paper: Towards achieving robust universal neural vocoding . cywang97/unispeech; paper: UniSpeech: Unified Speech Representation Learning with Labeled and Unlabeled Data . microsoft/unilm — UniLM AI - Large-scale Self-supervised Pre-training across Tasks, Languages, and Modalities . Continual-wav2vec2: an Application of Continual Learning for Self-Supervised Automatic Speech Recognition . Interactive demo: LayoutLMv2 . Improving Pretrained Cross-Lingual Language Models via Self-Labeled Word Alignment; CZWin32768/XLM-Align . waydroid/waydroid . huseinzol05/malaya-speech . Fine-tuning XLSR-Wav2Vec2 for WOLOF ASR with 🤗 . model = Wav2Vec2ForCTC.from_pretrained( &quot;facebook/wav2vec2-large-xlsr-53&quot;, attention_dropout=0.1, hidden_dropout=0.1, feat_proj_dropout=0.0, mask_time_prob=0.05, layerdrop=0.1, gradient_checkpointing=True, ctc_loss_reduction=&quot;mean&quot;, pad_token_id=processor.tokenizer.pad_token_id, vocab_size=len(processor.tokenizer) ) training_args = TrainingArguments( output_dir=&quot;./wav2vec2-large-xlsr-WOLOF&quot;, group_by_length=True, per_device_train_batch_size=16, gradient_accumulation_steps=2, evaluation_strategy=&quot;steps&quot;, num_train_epochs=40, fp16=True, save_steps=500, eval_steps=500, logging_steps=500, learning_rate=3e-4, warmup_steps=1000, save_total_limit=2, ) . run_spleeter.py . Few-shot Intent Classification and Slot Filling with Retrieved Examples . Comparing CTC and LFMMI for out-of-domain adaptation of wav2vec 2.0 acoustic model . Unsupervised Cross-Modal Alignment of Speech and Text Embedding Spaces .",
            "url": "https://jimregan.github.io/notes/links/2021/09/26/misc-links.html",
            "relUrl": "/links/2021/09/26/misc-links.html",
            "date": " • Sep 26, 2021"
        }
        
    
  
    
        ,"post140": {
            "title": "Interesting links, 25/9/2021",
            "content": "Add an official audio classification example #13722 . To use your own dataset, convert your data into a csv or json format with the fields file and label like so: . worldveil/dejavu — Audio fingerprinting and recognition in Python Blog . Perlence/PyGuitarPro — Read, write and manipulate GP3, GP4 and GP5 files . alphaTab . microsoft/muzic — Muzic: Music Understanding and Generation with Artificial Intelligence . ESPNet Colab . open-mmlab/mmaction2 — OpenMMLab’s Next Generation Video Understanding Toolbox and Benchmark . Assisting the Human Fact-Checkers: Detecting All Previously Fact-Checked Claims in a Document . tree-sitter/tree-sitter . lima-vm/lima — Linux virtual machines, on macOS (aka “Linux-on-Mac”, “macOS subsystem for Linux”, “containerd for Mac”, unofficially) . openai/triton — a language and compiler for writing highly efficient custom Deep-Learning primitives . JohnSnowLabs/spark-nlp . Haskell Liftoff . mingrammer/diagrams — Diagram as Code for prototyping cloud system architectures . babysor/MockingBird — Clone a voice in 5 seconds to generate arbitrary speech in real-time . PaddlePaddle/PaddleOCR . jina-ai/jina . iperov/DeepFaceLive — Real-time face swap for PC streaming or video calls . paulgavrikov/visualkeras/ . HarisIqbal88/PlotNeuralNet — Latex code for making neural networks diagrams . keplr-io/quiver — Interactive convnet features visualization for Keras . asappresearch/sew — SEW (Squeezed and Efficient Wav2vec) Performance-Efficiency Trade-offs in Unsupervised Pre-training for Speech Recognition . Efficient Nearest Neighbor Language Models . google/fnet-base — FNet is a transformers model with attention replaced with fourier transforms . Block Pruning For Faster Transformers . aterenin/phdthesis . pzelasko/kaldialign . bytedance/music_source_separation . mlflow/mlflow . willmcgugan/rich — Rich is a Python library for rich text and beautiful formatting in the terminal. . smacke/ffsubsync — Automagically synchronize subtitles with video. . chriskiehl/Gooey — Turn (almost) any Python command line program into a full GUI application with one line . deanmalmgren/textract . scrapinghub/portia . bohanli/BERT-flow — TensorFlow implementation of On the Sentence Embeddings from Pre-trained Language Models (EMNLP 2020) . 5 Podcasts To Listen To If You’re Learning Swedish . brapodcast.se . Podcast om Wikipedia . DeepFovea: Neural Reconstruction for Foveated Rendering and Video Compression using Learned Statistics of Natural Videos . PySimpleGUI/PySimpleGUI . tyiannak/pyAudioAnalysis .",
            "url": "https://jimregan.github.io/notes/links/2021/09/25/misc-links.html",
            "relUrl": "/links/2021/09/25/misc-links.html",
            "date": " • Sep 25, 2021"
        }
        
    
  
    
        ,"post141": {
            "title": "Utterance XML to json",
            "content": "import xml.etree.ElementTree as ET . class Utterance: def __init__(self, input, sentences): self.input = input self.sentences = sentences . class Sentence: def __init__(self, input, tokens): self.input = input self.tokens = tokens . class Token: def __init__(self, input, words): self.input = input self.words = words . class Word: def __init__(self, input, source, syllables, pos=&quot;&quot;): self.input = input self.source = source self.pos = pos self.syllables = syllables if self.syllables is None: self.syllables = [] def get_phonemes(self): return &quot; &quot;.join([a.get_phonemes() for a in self.syllables]) def get_clean_word(self): word = self.input if word[0:1] in &quot;nt&quot; and word[1:2] in &quot;AÁEÉIÍOÓUÚ&quot;: return word[0:1] + &quot;-&quot; + word[1:].lower() else: return word.lower() . class Syllable: def __init__(self, stress: int = 0, phonemes = None): self.stress = stress self.phonemes = phonemes if self.phonemes is None: self.phonemes = [] def get_phonemes(self): return &quot; &quot;.join([a.symbol for a in self.phonemes]) . class Phoneme: def __init__(self, symbol: str = &quot;&quot;, end: float = 0.0): self.symbol = symbol self.end = end . def from_xml(source): tree = ET.parse(source) root = tree.getroot() if &#39;input_string&#39; in root.attrib: input = root.attrib[&#39;input_string&#39;] else: input = &#39;&#39; sentences = [] for sentence in root.findall(&#39;./sentence&#39;): if &#39;input_string&#39; in sentence.attrib: input = sentence.attrib[&#39;input_string&#39;] else: input = &#39;&#39; tokens = [] for token in sentence.findall(&#39;./token&#39;): if &#39;input_string&#39; in token.attrib: input = token.attrib[&#39;input_string&#39;] else: input = &#39;&#39; words = [] for word in token.findall(&#39;./word&#39;): if &#39;input_string&#39; in word.attrib: input = word.attrib[&#39;input_string&#39;] else: input = &quot;&quot; if &#39;trans_source&#39; in word.attrib: source = word.attrib[&#39;trans_source&#39;] else: source = &quot;&quot; if &#39;pos&#39; in word.attrib: pos = word.attrib[&#39;pos&#39;] else: pos = &quot;&quot; syllables = [] for syllable in word.findall(&#39;./syllable&#39;): phonemes = [] if &#39;stress&#39; in syllable.attrib: if syllable.attrib[&#39;stress&#39;] == &#39;None&#39;: stress = 0 else: stress = int(syllable.attrib[&#39;stress&#39;]) else: stress = 0 for phoneme in syllable.findall(&#39;./phoneme&#39;): if &#39;symbol&#39; in phoneme.attrib: symbol = phoneme.attrib[&#39;symbol&#39;] else: symbol = &#39;&#39; if &#39;end&#39; in phoneme.attrib: end = float(phoneme.attrib[&#39;end&#39;]) else: symbol = 0.0 phonemes.append(Phoneme(symbol, end)) syllables.append(Syllable(stress, phonemes)) words.append(Word(input, source, syllables, pos)) tokens.append(Token(input, words)) sentences.append(Sentence(input, tokens)) return Utterance(input, sentences) . def get_dictionary(utt): prons = {} for sent in utt.sentences: for tok in sent.tokens: for word in tok.words: if not word.get_clean_word() in prons.keys(): prons[word.get_clean_word()] = set() prons[word.get_clean_word()].add(word.get_phonemes()) return prons . utt = from_xml(&quot;/home/jim/tmp/pmg_ga_co/RCPiarsachALL/xml/MI0001RCPiarsachBairbre_0021.xml&quot;) . import json json.dumps(utt, default=lambda o: o.__dict__) . get_dictionary(utt) . co_pron_replacements = { &quot;thosaigh&quot;: &quot;h o s @&quot;, &quot;féin&quot;: &quot;h ee nj&quot;, &quot;haghaidh&quot;: &quot;h ai&quot; } . co_text_word_fixes = { &quot;RCPiarsachBairbre_0021.xml&quot;: [(&quot;ar&quot;, &quot;ar ar&quot;), (&quot;súl&quot;, &quot;súile&quot;), (&quot;máthair&quot;, &quot;mothair&quot;)], } . import IPython.display as ipd ipd.Audio(&#39;/home/jim/tmp/pmg_ga_co/RCPiarsachALL/wav44_trimmed/MI0001RCPiarsachBairbre_0021.wav&#39;) .",
            "url": "https://jimregan.github.io/notes/irish/abair/mfa/2021/09/23/utterance-xml-to-mfa.html",
            "relUrl": "/irish/abair/mfa/2021/09/23/utterance-xml-to-mfa.html",
            "date": " • Sep 23, 2021"
        }
        
    
  
    
        ,"post142": {
            "title": "Swedish youtube scrape 1",
            "content": "Original on Kaggle . !pip install youtube-dl . !youtube-dl -o &#39;%(id)s.%(ext)s&#39; --match-filter &quot;license=&#39;Creative Commons Attribution license (reuse allowed)&#39;&quot; https://www.youtube.com/channel/UCagnPy0JPimGTqTzv1YQBpQ . [youtube:tab] UCagnPy0JPimGTqTzv1YQBpQ: Downloading webpage [download] Downloading playlist: Riksantikvarieämbetet - Home [youtube:tab] playlist Riksantikvarieämbetet - Home: Downloading 2 videos [download] Downloading video 1 of 2 [youtube:tab] heritageboard: Downloading webpage [download] Downloading playlist: Riksantikvarieämbetet - Videos [youtube:tab] Downloading page 1 [youtube:tab] Downloading page 2 [youtube:tab] Downloading page 3 [youtube:tab] Downloading page 4 [youtube:tab] Downloading page 5 [youtube:tab] Downloading page 6 [youtube:tab] Downloading page 7 [youtube:tab] Downloading page 8 [youtube:tab] Downloading page 9 [youtube:tab] Downloading page 10 [youtube:tab] Downloading page 11 [youtube:tab] Downloading page 12 [youtube:tab] Downloading page 13 [youtube:tab] Downloading page 14 [youtube:tab] Downloading page 15 [youtube:tab] Downloading page 16 [youtube:tab] playlist Riksantikvarieämbetet - Videos: Downloading 481 videos [download] Downloading video 1 of 481 [youtube] uU4M5-ajGt4: Downloading webpage [youtube] uU4M5-ajGt4: Downloading MPD manifest [download] Omvärld och insikt - Museipanelen does not pass filter license=&#39;Creative Commons Attribution license (reuse allowed)&#39;, skipping .. [download] Downloading video 2 of 481 [youtube] Kvz2xeTHN50: Downloading webpage [download] Destination: Kvz2xeTHN50.f137.mp4 [download] 100% of 412.77MiB in 00:30 [download] Destination: Kvz2xeTHN50.f140.m4a [download] 100% of 20.05MiB in 00:01 [ffmpeg] Merging formats into &#34;Kvz2xeTHN50.mp4&#34; Deleting original file Kvz2xeTHN50.f137.mp4 (pass -k to keep) Deleting original file Kvz2xeTHN50.f140.m4a (pass -k to keep) [download] Downloading video 3 of 481 [youtube] RafIRgJ-qPw: Downloading webpage [youtube] RafIRgJ-qPw: Downloading MPD manifest [download] Omvärld och insikt - Museipanelen does not pass filter license=&#39;Creative Commons Attribution license (reuse allowed)&#39;, skipping .. [download] Downloading video 4 of 481 [youtube] lnw92d5msqQ: Downloading webpage [youtube] lnw92d5msqQ: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 342 [download] Destination: lnw92d5msqQ.f247.webm [download] 100% of 178.10MiB in 02:07 [download] Destination: lnw92d5msqQ.f140.m4a [download] 100% of 28.11MiB in 00:01 [ffmpeg] Merging formats into &#34;lnw92d5msqQ.mkv&#34; Deleting original file lnw92d5msqQ.f247.webm (pass -k to keep) Deleting original file lnw92d5msqQ.f140.m4a (pass -k to keep) [download] Downloading video 5 of 481 [youtube] iJol2hdgYdw: Downloading webpage [youtube] iJol2hdgYdw: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 140 [download] Destination: iJol2hdgYdw.f248.webm [download] 100% of 82.07MiB in 00:50 [download] Destination: iJol2hdgYdw.f140.m4a [download] 100% of 10.96MiB in 00:00 [ffmpeg] Merging formats into &#34;iJol2hdgYdw.mkv&#34; Deleting original file iJol2hdgYdw.f248.webm (pass -k to keep) Deleting original file iJol2hdgYdw.f140.m4a (pass -k to keep) [download] Downloading video 6 of 481 [youtube] BoJ1-urZ5b4: Downloading webpage [youtube] BoJ1-urZ5b4: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 267 [download] Destination: BoJ1-urZ5b4.f248.webm [download] 100% of 130.54MiB in 01:36 [download] Destination: BoJ1-urZ5b4.f140.m4a [download] 100% of 20.99MiB in 00:01 [ffmpeg] Merging formats into &#34;BoJ1-urZ5b4.mkv&#34; Deleting original file BoJ1-urZ5b4.f248.webm (pass -k to keep) Deleting original file BoJ1-urZ5b4.f140.m4a (pass -k to keep) [download] Downloading video 7 of 481 [youtube] qDVkZW7BTQs: Downloading webpage [youtube] qDVkZW7BTQs: Downloading MPD manifest [download] Dag 3 - 03: Nonesthic – en plattform för virtuella besök i kulturarvsbyggnader &amp; ”Pop In &amp; Play” does not pass filter license=&#39;Creative Commons Attribution license (reuse allowed)&#39;, skipping .. [download] Downloading video 8 of 481 [youtube] kfz1WOs30LE: Downloading webpage [youtube] kfz1WOs30LE: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 217 [download] Destination: kfz1WOs30LE.f248.webm [download] 100% of 36.33MiB in 01:17 [download] Destination: kfz1WOs30LE.f140.m4a [download] 100% of 17.08MiB in 00:01 [ffmpeg] Merging formats into &#34;kfz1WOs30LE.mkv&#34; Deleting original file kfz1WOs30LE.f248.webm (pass -k to keep) Deleting original file kfz1WOs30LE.f140.m4a (pass -k to keep) [download] Downloading video 9 of 481 [youtube] MPHHH_bN7ic: Downloading webpage [youtube] MPHHH_bN7ic: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 288 [download] Destination: MPHHH_bN7ic.f248.webm [download] 100% of 177.75MiB in 01:38 [download] Destination: MPHHH_bN7ic.f140.m4a [download] 100% of 22.62MiB in 00:03 [ffmpeg] Merging formats into &#34;MPHHH_bN7ic.mkv&#34; Deleting original file MPHHH_bN7ic.f248.webm (pass -k to keep) Deleting original file MPHHH_bN7ic.f140.m4a (pass -k to keep) [download] Downloading video 10 of 481 [youtube] 1Wbzean_07g: Downloading webpage [youtube] 1Wbzean_07g: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 240 [download] Destination: 1Wbzean_07g.f248.webm [download] 100% of 201.56MiB in 01:32 [download] Destination: 1Wbzean_07g.f140.m4a [download] 100% of 18.83MiB in 00:01 [ffmpeg] Merging formats into &#34;1Wbzean_07g.mkv&#34; Deleting original file 1Wbzean_07g.f248.webm (pass -k to keep) Deleting original file 1Wbzean_07g.f140.m4a (pass -k to keep) [download] Downloading video 11 of 481 [youtube] CnfKrwDxGag: Downloading webpage [youtube] CnfKrwDxGag: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 211 [download] Destination: CnfKrwDxGag.f248.webm [download] 100% of 128.89MiB in 01:14 [download] Destination: CnfKrwDxGag.f140.m4a [download] 100% of 17.25MiB in 00:01 [ffmpeg] Merging formats into &#34;CnfKrwDxGag.mkv&#34; Deleting original file CnfKrwDxGag.f248.webm (pass -k to keep) Deleting original file CnfKrwDxGag.f140.m4a (pass -k to keep) [download] Downloading video 12 of 481 [youtube] j8_pzb0Zj0c: Downloading webpage [youtube] j8_pzb0Zj0c: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 217 [download] Destination: j8_pzb0Zj0c.f248.webm [download] 100% of 69.01MiB in 01:19 [download] Destination: j8_pzb0Zj0c.f140.m4a [download] 100% of 17.75MiB in 00:01 [ffmpeg] Merging formats into &#34;j8_pzb0Zj0c.mkv&#34; Deleting original file j8_pzb0Zj0c.f248.webm (pass -k to keep) Deleting original file j8_pzb0Zj0c.f140.m4a (pass -k to keep) [download] Downloading video 13 of 481 [youtube] 5pJdR7pXEKA: Downloading webpage [youtube] 5pJdR7pXEKA: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 227 [download] Destination: 5pJdR7pXEKA.f248.webm [download] 100% of 129.12MiB in 01:25 [download] Destination: 5pJdR7pXEKA.f140.m4a [download] 100% of 18.58MiB in 06:54 [ffmpeg] Merging formats into &#34;5pJdR7pXEKA.mkv&#34; Deleting original file 5pJdR7pXEKA.f248.webm (pass -k to keep) Deleting original file 5pJdR7pXEKA.f140.m4a (pass -k to keep) [download] Downloading video 14 of 481 [youtube] k4dQAQ4grow: Downloading webpage [youtube] k4dQAQ4grow: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 212 [download] Destination: k4dQAQ4grow.f248.webm [download] 100% of 54.52MiB in 01:14 [download] Destination: k4dQAQ4grow.f140.m4a [download] 100% of 17.36MiB in 00:02 [ffmpeg] Merging formats into &#34;k4dQAQ4grow.mkv&#34; Deleting original file k4dQAQ4grow.f248.webm (pass -k to keep) Deleting original file k4dQAQ4grow.f140.m4a (pass -k to keep) [download] Downloading video 15 of 481 [youtube] kHX0PvydWQQ: Downloading webpage [youtube] kHX0PvydWQQ: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 207 [download] Destination: kHX0PvydWQQ.f248.webm [download] 100% of 120.15MiB in 01:15 [download] Destination: kHX0PvydWQQ.f140.m4a [download] 100% of 16.96MiB in 00:01 [ffmpeg] Merging formats into &#34;kHX0PvydWQQ.mkv&#34; Deleting original file kHX0PvydWQQ.f248.webm (pass -k to keep) Deleting original file kHX0PvydWQQ.f140.m4a (pass -k to keep) [download] Downloading video 16 of 481 [youtube] 2dmtx_ytJBc: Downloading webpage [youtube] 2dmtx_ytJBc: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 235 [download] Destination: 2dmtx_ytJBc.f248.webm [download] 100% of 169.85MiB in 01:28 [download] Destination: 2dmtx_ytJBc.f140.m4a [download] 100% of 19.24MiB in 05:52 [ffmpeg] Merging formats into &#34;2dmtx_ytJBc.mkv&#34; Deleting original file 2dmtx_ytJBc.f248.webm (pass -k to keep) Deleting original file 2dmtx_ytJBc.f140.m4a (pass -k to keep) [download] Downloading video 17 of 481 [youtube] mdsyDk4oG2I: Downloading webpage [youtube] mdsyDk4oG2I: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 183 [download] Destination: mdsyDk4oG2I.f248.webm [download] 100% of 68.80MiB in 01:04 [download] Destination: mdsyDk4oG2I.f140.m4a [download] 100% of 14.34MiB in 00:01 [ffmpeg] Merging formats into &#34;mdsyDk4oG2I.mkv&#34; Deleting original file mdsyDk4oG2I.f248.webm (pass -k to keep) Deleting original file mdsyDk4oG2I.f140.m4a (pass -k to keep) [download] Downloading video 18 of 481 [youtube] 3ydSZ9Uk-3A: Downloading webpage [youtube] 3ydSZ9Uk-3A: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 280 [download] Destination: 3ydSZ9Uk-3A.f248.webm [download] 100% of 41.92MiB in 01:37 [download] Destination: 3ydSZ9Uk-3A.f140.m4a [download] 100% of 22.00MiB in 00:02 [ffmpeg] Merging formats into &#34;3ydSZ9Uk-3A.mkv&#34; Deleting original file 3ydSZ9Uk-3A.f248.webm (pass -k to keep) Deleting original file 3ydSZ9Uk-3A.f140.m4a (pass -k to keep) [download] Downloading video 19 of 481 [youtube] tiM2l9rYrVw: Downloading webpage [youtube] tiM2l9rYrVw: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 252 [download] Destination: tiM2l9rYrVw.f248.webm [download] 100% of 95.93MiB in 01:34 [download] Destination: tiM2l9rYrVw.f140.m4a [download] 100% of 19.82MiB in 00:01 [ffmpeg] Merging formats into &#34;tiM2l9rYrVw.mkv&#34; Deleting original file tiM2l9rYrVw.f248.webm (pass -k to keep) Deleting original file tiM2l9rYrVw.f140.m4a (pass -k to keep) [download] Downloading video 20 of 481 [youtube] FPdgF5zRPcc: Downloading webpage [youtube] FPdgF5zRPcc: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 248 [download] Destination: FPdgF5zRPcc.f248.webm [download] 100% of 30.54MiB in 01:25 [download] Destination: FPdgF5zRPcc.f140.m4a [download] 100% of 19.52MiB in 00:03 [ffmpeg] Merging formats into &#34;FPdgF5zRPcc.mkv&#34; Deleting original file FPdgF5zRPcc.f248.webm (pass -k to keep) Deleting original file FPdgF5zRPcc.f140.m4a (pass -k to keep) [download] Downloading video 21 of 481 [youtube] XhoTQzu4VAE: Downloading webpage [youtube] XhoTQzu4VAE: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 157 [download] Destination: XhoTQzu4VAE.f248.webm [download] 100% of 100.06MiB in 00:58 [download] Destination: XhoTQzu4VAE.f140.m4a [download] 100% of 12.28MiB in 00:01 [ffmpeg] Merging formats into &#34;XhoTQzu4VAE.mkv&#34; Deleting original file XhoTQzu4VAE.f248.webm (pass -k to keep) Deleting original file XhoTQzu4VAE.f140.m4a (pass -k to keep) [download] Downloading video 22 of 481 [youtube] -5DwojwgLe0: Downloading webpage [youtube] -5DwojwgLe0: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 310 [download] Destination: -5DwojwgLe0.f248.webm [download] 100% of 52.16MiB in 01:47 [download] Destination: -5DwojwgLe0.f140.m4a [download] 100% of 24.42MiB in 00:01 [ffmpeg] Merging formats into &#34;-5DwojwgLe0.mkv&#34; Deleting original file -5DwojwgLe0.f248.webm (pass -k to keep) Deleting original file -5DwojwgLe0.f140.m4a (pass -k to keep) [download] Downloading video 23 of 481 [youtube] Lfz3yDI2rdY: Downloading webpage [youtube] Lfz3yDI2rdY: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 15 [download] Destination: Lfz3yDI2rdY.f248.webm [download] 100% of 10.16MiB in 00:05 [download] Destination: Lfz3yDI2rdY.f140.m4a [download] 100% of 1.12MiB in 00:01 [ffmpeg] Merging formats into &#34;Lfz3yDI2rdY.mkv&#34; Deleting original file Lfz3yDI2rdY.f248.webm (pass -k to keep) Deleting original file Lfz3yDI2rdY.f140.m4a (pass -k to keep) [download] Downloading video 24 of 481 [youtube] vOu-MuP4mLA: Downloading webpage [youtube] vOu-MuP4mLA: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 39 [download] Destination: vOu-MuP4mLA.f303.webm [download] 100% of 36.90MiB in 00:15 [download] Destination: vOu-MuP4mLA.f140.m4a [download] 100% of 2.99MiB in 00:00 [ffmpeg] Merging formats into &#34;vOu-MuP4mLA.mkv&#34; Deleting original file vOu-MuP4mLA.f303.webm (pass -k to keep) Deleting original file vOu-MuP4mLA.f140.m4a (pass -k to keep) [download] Downloading video 25 of 481 [youtube] QtFRPmTRyWw: Downloading webpage [youtube] QtFRPmTRyWw: Downloading MPD manifest [download] Destination: QtFRPmTRyWw.f137.mp4 [download] 100% of 148.39MiB in 00:05 [download] Destination: QtFRPmTRyWw.f140.m4a [download] 100% of 7.13MiB in 00:00 [ffmpeg] Merging formats into &#34;QtFRPmTRyWw.mp4&#34; Deleting original file QtFRPmTRyWw.f137.mp4 (pass -k to keep) Deleting original file QtFRPmTRyWw.f140.m4a (pass -k to keep) [download] Downloading video 26 of 481 [youtube] Gci-BbB0i5g: Downloading webpage [youtube] Gci-BbB0i5g: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 206 [download] Destination: Gci-BbB0i5g.f248.webm [download] 100% of 34.73MiB in 01:12 [download] Destination: Gci-BbB0i5g.f140.m4a [download] 100% of 16.87MiB in 00:01 [ffmpeg] Merging formats into &#34;Gci-BbB0i5g.mkv&#34; Deleting original file Gci-BbB0i5g.f248.webm (pass -k to keep) Deleting original file Gci-BbB0i5g.f140.m4a (pass -k to keep) [download] Downloading video 27 of 481 [youtube] 8jSE5bzQVbk: Downloading webpage [youtube] 8jSE5bzQVbk: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 504 [download] Destination: 8jSE5bzQVbk.f248.webm [download] 100% of 388.26MiB in 03:09 [download] Destination: 8jSE5bzQVbk.f140.m4a [download] 100% of 41.41MiB in 00:03 [ffmpeg] Merging formats into &#34;8jSE5bzQVbk.mkv&#34; Deleting original file 8jSE5bzQVbk.f248.webm (pass -k to keep) Deleting original file 8jSE5bzQVbk.f140.m4a (pass -k to keep) [download] Downloading video 28 of 481 [youtube] hm7RZHfFKeA: Downloading webpage [youtube] hm7RZHfFKeA: Downloading MPD manifest [download] Omvärld och insikt - Museipanelen does not pass filter license=&#39;Creative Commons Attribution license (reuse allowed)&#39;, skipping .. [download] Downloading video 29 of 481 [youtube] xMZu6MR5BrM: Downloading webpage [youtube] xMZu6MR5BrM: Downloading MPD manifest [dashsegments] Total fragments: 206 [download] Destination: xMZu6MR5BrM.f137.mp4 [download] 100% of 136.54MiB in 01:18 [download] Destination: xMZu6MR5BrM.f140.m4a [download] 100% of 16.81MiB in 00:01 [ffmpeg] Merging formats into &#34;xMZu6MR5BrM.mp4&#34; Deleting original file xMZu6MR5BrM.f137.mp4 (pass -k to keep) Deleting original file xMZu6MR5BrM.f140.m4a (pass -k to keep) [download] Downloading video 30 of 481 [youtube] YeNcvCrF_V4: Downloading webpage [youtube] YeNcvCrF_V4: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 295 [download] Destination: YeNcvCrF_V4.f244.webm [download] 100% of 12.36MiB in 01:38 [download] Destination: YeNcvCrF_V4.f140.m4a [download] 100% of 23.24MiB in 00:04 [ffmpeg] Merging formats into &#34;YeNcvCrF_V4.mkv&#34; Deleting original file YeNcvCrF_V4.f244.webm (pass -k to keep) Deleting original file YeNcvCrF_V4.f140.m4a (pass -k to keep) [download] Downloading video 31 of 481 [youtube] HQiNjDVARxI: Downloading webpage [youtube] HQiNjDVARxI: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 273 [download] Destination: HQiNjDVARxI.f248.webm [download] 100% of 65.31MiB in 01:36 [download] Destination: HQiNjDVARxI.f140.m4a [download] 100% of 22.34MiB in 00:02 [ffmpeg] Merging formats into &#34;HQiNjDVARxI.mkv&#34; Deleting original file HQiNjDVARxI.f248.webm (pass -k to keep) Deleting original file HQiNjDVARxI.f140.m4a (pass -k to keep) [download] Downloading video 32 of 481 [youtube] A_pmPIyDfXw: Downloading webpage [youtube] A_pmPIyDfXw: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 403 [download] Destination: A_pmPIyDfXw.f248.webm [download] 100% of 262.74MiB in 02:36 [download] Destination: A_pmPIyDfXw.f140.m4a [download] 100% of 33.03MiB in 00:01 [ffmpeg] Merging formats into &#34;A_pmPIyDfXw.mkv&#34; Deleting original file A_pmPIyDfXw.f248.webm (pass -k to keep) Deleting original file A_pmPIyDfXw.f140.m4a (pass -k to keep) [download] Downloading video 33 of 481 [youtube] sQyC8woJwR8: Downloading webpage [youtube] sQyC8woJwR8: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 158 [download] Destination: sQyC8woJwR8.f248.webm [download] 100% of 38.34MiB in 00:55 [download] Destination: sQyC8woJwR8.f140.m4a [download] 100% of 12.88MiB in 04:21 [ffmpeg] Merging formats into &#34;sQyC8woJwR8.mkv&#34; Deleting original file sQyC8woJwR8.f248.webm (pass -k to keep) Deleting original file sQyC8woJwR8.f140.m4a (pass -k to keep) [download] Downloading video 34 of 481 [youtube] mwNFSiKza00: Downloading webpage [youtube] mwNFSiKza00: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 30 [download] Destination: mwNFSiKza00.f248.webm [download] 100% of 15.28MiB in 00:11 [download] Destination: mwNFSiKza00.f140.m4a [download] 100% of 2.38MiB in 00:00 [ffmpeg] Merging formats into &#34;mwNFSiKza00.mkv&#34; Deleting original file mwNFSiKza00.f248.webm (pass -k to keep) Deleting original file mwNFSiKza00.f140.m4a (pass -k to keep) [download] Downloading video 35 of 481 [youtube] GKpnihA9Am0: Downloading webpage [youtube] GKpnihA9Am0: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 283 [download] Destination: GKpnihA9Am0.f248.webm [download] 100% of 70.30MiB in 01:39 [download] Destination: GKpnihA9Am0.f140.m4a [download] 100% of 23.21MiB in 00:02 [ffmpeg] Merging formats into &#34;GKpnihA9Am0.mkv&#34; Deleting original file GKpnihA9Am0.f248.webm (pass -k to keep) Deleting original file GKpnihA9Am0.f140.m4a (pass -k to keep) [download] Downloading video 36 of 481 [youtube] ELz_eDr2Jxg: Downloading webpage [youtube] ELz_eDr2Jxg: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 180 [download] Destination: ELz_eDr2Jxg.f248.webm [download] 100% of 34.08MiB in 01:03 [download] Destination: ELz_eDr2Jxg.f140.m4a [download] 100% of 14.72MiB in 00:02 [ffmpeg] Merging formats into &#34;ELz_eDr2Jxg.mkv&#34; Deleting original file ELz_eDr2Jxg.f248.webm (pass -k to keep) Deleting original file ELz_eDr2Jxg.f140.m4a (pass -k to keep) [download] Downloading video 37 of 481 [youtube] eS3vz6en90Q: Downloading webpage [youtube] eS3vz6en90Q: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 252 [download] Destination: eS3vz6en90Q.f248.webm [download] 100% of 41.49MiB in 01:29 [download] Destination: eS3vz6en90Q.f140.m4a [download] 100% of 20.60MiB in 00:02 [ffmpeg] Merging formats into &#34;eS3vz6en90Q.mkv&#34; Deleting original file eS3vz6en90Q.f248.webm (pass -k to keep) Deleting original file eS3vz6en90Q.f140.m4a (pass -k to keep) [download] Downloading video 38 of 481 [youtube] Gpr7RETcS6A: Downloading webpage [youtube] Gpr7RETcS6A: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 229 [download] Destination: Gpr7RETcS6A.f248.webm [download] 100% of 50.44MiB in 01:21 [download] Destination: Gpr7RETcS6A.f140.m4a [download] 100% of 18.73MiB in 00:02 [ffmpeg] Merging formats into &#34;Gpr7RETcS6A.mkv&#34; Deleting original file Gpr7RETcS6A.f248.webm (pass -k to keep) Deleting original file Gpr7RETcS6A.f140.m4a (pass -k to keep) [download] Downloading video 39 of 481 [youtube] P0GRef2Nn0g: Downloading webpage [youtube] P0GRef2Nn0g: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 55 [download] Destination: P0GRef2Nn0g.f136.mp4 [download] 100% of 80.24MiB in 00:21 [download] Destination: P0GRef2Nn0g.f251.webm [download] 100% of 4.52MiB in 00:00 [ffmpeg] Merging formats into &#34;P0GRef2Nn0g.mkv&#34; Deleting original file P0GRef2Nn0g.f136.mp4 (pass -k to keep) Deleting original file P0GRef2Nn0g.f251.webm (pass -k to keep) [download] Downloading video 40 of 481 [youtube] BJpmB6tpKKY: Downloading webpage [youtube] BJpmB6tpKKY: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 445 [download] Destination: BJpmB6tpKKY.f137.mp4 [download] 100% of 1.48GiB in 03:52 [download] Destination: BJpmB6tpKKY.f251.webm [download] 100% of 39.22MiB in 00:03 [ffmpeg] Merging formats into &#34;BJpmB6tpKKY.mkv&#34; Deleting original file BJpmB6tpKKY.f137.mp4 (pass -k to keep) Deleting original file BJpmB6tpKKY.f251.webm (pass -k to keep) [download] Downloading video 41 of 481 [youtube] wIwi4JxORsQ: Downloading webpage [youtube] wIwi4JxORsQ: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 560 [download] Destination: wIwi4JxORsQ.f247.webm [download] 100% of 103.88MiB in 03:58 [download] Destination: wIwi4JxORsQ.f140.m4a [download] 100% of 46.02MiB in 00:07 [ffmpeg] Merging formats into &#34;wIwi4JxORsQ.mkv&#34; Deleting original file wIwi4JxORsQ.f247.webm (pass -k to keep) Deleting original file wIwi4JxORsQ.f140.m4a (pass -k to keep) [download] Downloading video 42 of 481 [youtube] 1M9i1bhqG4k: Downloading webpage [youtube] 1M9i1bhqG4k: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 425 [download] Destination: 1M9i1bhqG4k.f248.webm [download] 100% of 322.71MiB in 02:43 [download] Destination: 1M9i1bhqG4k.f140.m4a [download] 100% of 34.91MiB in 00:03 [ffmpeg] Merging formats into &#34;1M9i1bhqG4k.mkv&#34; Deleting original file 1M9i1bhqG4k.f248.webm (pass -k to keep) Deleting original file 1M9i1bhqG4k.f140.m4a (pass -k to keep) [download] Downloading video 43 of 481 [youtube] 4lSp2mN9c0c: Downloading webpage [youtube] 4lSp2mN9c0c: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 290 [download] Destination: 4lSp2mN9c0c.f247.webm [download] 100% of 183.10MiB in 02:24 [download] Destination: 4lSp2mN9c0c.f140.m4a [download] 100% of 23.76MiB in 00:02 [ffmpeg] Merging formats into &#34;4lSp2mN9c0c.mkv&#34; Deleting original file 4lSp2mN9c0c.f247.webm (pass -k to keep) Deleting original file 4lSp2mN9c0c.f140.m4a (pass -k to keep) [download] Downloading video 44 of 481 [youtube] S8JHEfd6UYo: Downloading webpage [youtube] S8JHEfd6UYo: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 260 [download] Destination: S8JHEfd6UYo.f248.webm [download] 100% of 32.58MiB in 01:30 [download] Destination: S8JHEfd6UYo.f140.m4a [download] 100% of 21.28MiB in 00:03 [ffmpeg] Merging formats into &#34;S8JHEfd6UYo.mkv&#34; Deleting original file S8JHEfd6UYo.f248.webm (pass -k to keep) Deleting original file S8JHEfd6UYo.f140.m4a (pass -k to keep) [download] Downloading video 45 of 481 [youtube] wJjAaArYzJs: Downloading webpage [youtube] wJjAaArYzJs: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 217 [download] Destination: wJjAaArYzJs.f248.webm [download] 100% of 93.03MiB in 01:18 [download] Destination: wJjAaArYzJs.f140.m4a [download] 100% of 17.75MiB in 00:02 [ffmpeg] Merging formats into &#34;wJjAaArYzJs.mkv&#34; Deleting original file wJjAaArYzJs.f248.webm (pass -k to keep) Deleting original file wJjAaArYzJs.f140.m4a (pass -k to keep) [download] Downloading video 46 of 481 [youtube] HjUJKVFLfGc: Downloading webpage [youtube] HjUJKVFLfGc: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 335 [download] Destination: HjUJKVFLfGc.f248.webm [download] 100% of 62.32MiB in 01:56 [download] Destination: HjUJKVFLfGc.f140.m4a [download] 100% of 27.44MiB in 00:01 [ffmpeg] Merging formats into &#34;HjUJKVFLfGc.mkv&#34; Deleting original file HjUJKVFLfGc.f248.webm (pass -k to keep) Deleting original file HjUJKVFLfGc.f140.m4a (pass -k to keep) [download] Downloading video 47 of 481 [youtube] 5-WvzW6Goq0: Downloading webpage [youtube] 5-WvzW6Goq0: Downloading MPD manifest [download] Museipanelen does not pass filter license=&#39;Creative Commons Attribution license (reuse allowed)&#39;, skipping .. [download] Downloading video 48 of 481 [youtube] -O8QKVL4IWY: Downloading webpage [youtube] -O8QKVL4IWY: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 223 [download] Destination: -O8QKVL4IWY.f248.webm [download] 100% of 41.78MiB in 01:21 [download] Destination: -O8QKVL4IWY.f140.m4a [download] 100% of 18.24MiB in 00:02 [ffmpeg] Merging formats into &#34;-O8QKVL4IWY.mkv&#34; Deleting original file -O8QKVL4IWY.f248.webm (pass -k to keep) Deleting original file -O8QKVL4IWY.f140.m4a (pass -k to keep) [download] Downloading video 49 of 481 [youtube] _aPZ9kc7pSE: Downloading webpage [youtube] _aPZ9kc7pSE: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 313 [download] Destination: _aPZ9kc7pSE.f247.webm [download] 58.1% of ~170.35MiB at 28.65MiB/s ETA 01:30[download] Got server HTTP error: HTTP Error 404: Not Found. Retrying fragment 183 (attempt 1 of 10)... [download] 83.4% of ~170.80MiB at 24.78MiB/s ETA 00:36[download] Got server HTTP error: HTTP Error 404: Not Found. Retrying fragment 262 (attempt 1 of 10)... [download] Got server HTTP error: HTTP Error 404: Not Found. Retrying fragment 262 (attempt 2 of 10)... [download] 100% of 169.40MiB in 03:39 [download] Destination: _aPZ9kc7pSE.f140.m4a [download] 100% of 24.60MiB in 00:01 [ffmpeg] Merging formats into &#34;_aPZ9kc7pSE.mkv&#34; Deleting original file _aPZ9kc7pSE.f247.webm (pass -k to keep) Deleting original file _aPZ9kc7pSE.f140.m4a (pass -k to keep) [download] Downloading video 50 of 481 [youtube] c_wqdJMJbhc: Downloading webpage [youtube] c_wqdJMJbhc: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 203 [download] Destination: c_wqdJMJbhc.f248.webm [download] 100% of 34.47MiB in 01:23 [download] Destination: c_wqdJMJbhc.f140.m4a [download] 100% of 16.64MiB in 00:03 [ffmpeg] Merging formats into &#34;c_wqdJMJbhc.mkv&#34; Deleting original file c_wqdJMJbhc.f248.webm (pass -k to keep) Deleting original file c_wqdJMJbhc.f140.m4a (pass -k to keep) [download] Downloading video 51 of 481 [youtube] pigyLnE0DmA: Downloading webpage [youtube] pigyLnE0DmA: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 425 [download] Destination: pigyLnE0DmA.f248.webm [download] 100% of 107.17MiB in 02:34 [download] Destination: pigyLnE0DmA.f140.m4a [download] 100% of 34.87MiB in 08:25 [ffmpeg] Merging formats into &#34;pigyLnE0DmA.mkv&#34; Deleting original file pigyLnE0DmA.f248.webm (pass -k to keep) Deleting original file pigyLnE0DmA.f140.m4a (pass -k to keep) [download] Downloading video 52 of 481 [youtube] ngxK_PvUSIo: Downloading webpage [youtube] ngxK_PvUSIo: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 357 [download] Destination: ngxK_PvUSIo.f248.webm [download] 100% of 70.31MiB in 02:05 [download] Destination: ngxK_PvUSIo.f140.m4a [download] 100% of 29.26MiB in 00:01 [ffmpeg] Merging formats into &#34;ngxK_PvUSIo.mkv&#34; Deleting original file ngxK_PvUSIo.f248.webm (pass -k to keep) Deleting original file ngxK_PvUSIo.f140.m4a (pass -k to keep) [download] Downloading video 53 of 481 [youtube] c_0BcUmqM50: Downloading webpage [youtube] c_0BcUmqM50: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 11 [download] Destination: c_0BcUmqM50.f248.webm [download] 100% of 5.73MiB in 00:04 ERROR: unable to download video data: HTTP Error 403: Forbidden .",
            "url": "https://jimregan.github.io/notes/kaggle/swedish/2021/09/21/scrape-swedish-youtube-take1.html",
            "relUrl": "/kaggle/swedish/2021/09/21/scrape-swedish-youtube-take1.html",
            "date": " • Sep 21, 2021"
        }
        
    
  
    
        ,"post143": {
            "title": "Check Riksantikvarieämbetet youtube for licence",
            "content": "Original on Kaggle . %%capture !pip install youtube-dl . !youtube-dl -j --flat-playlist &quot;https://www.youtube.com/c/heritageboard/playlists?view=1&amp;sort=dd&amp;shelf_id=0&quot; &gt; rplist.json . !cat rplist.json | awk -F&#39;&quot;url&quot;: &quot;&#39; &#39;{print $2}&#39;|awk -F&#39;&quot;&#39; &#39;{print $1}&#39; | while read i;do youtube-dl -j --flat-playlist $i &gt;&gt; pl_videos.json || echo $i &gt;&gt; retry;done . !youtube-dl -j --flat-playlist &quot;https://www.youtube.com/c/heritageboard/videos?view=0&amp;sort=dd&amp;shelf_id=0&quot; &gt; uploads.json . None of the following works . import json import requests cc_by = [] other = [] retry = [] seen = [] . lic = &#39;&quot;Creative Commons Attribution licence (reuse allowed)&quot;&#39; def inner(cur_id): if cur_id in seen: return req = requests.get(f&quot;https://www.youtube.com/watch?v={cur_id}&quot;) if req.status_code != 200: retry.append(cur_id) if lic in req.text: cc_by.append(cur_id) else: other.append(cur_id) seen.append(cur_id) . with open(&quot;pl_videos.json&quot;) as pl_videos: for line in pl_videos.readlines(): line_data = json.loads(line.strip()) inner(line_data[&#39;id&#39;]) with open(&quot;uploads.json&quot;) as pl_videos: for line in pl_videos.readlines(): line_data = json.loads(line.strip()) inner(line_data[&#39;id&#39;]) . with open(&#39;proc.json&#39;, &#39;w&#39;) as outfile: json.dump({&#39;cc-by&#39;: cc_by, &#39;other&#39;: other, &#39;retry&#39;: retry}, outfile) . Instead, this works: . !cat pl_videos.json uploads.json|awk -F&#39;&quot;id&quot;: &quot;&#39; &#39;{print $2}&#39;|awk -F&#39;&quot;&#39; &#39;{print $1}&#39; | while read i;do youtube-dl --write-info-json --skip-download -o &#39;%(id)s.%(ext)s&#39; -- &quot;$i&quot; ;done . !cat cc-by-ids.txt |while read i;do youtube-dl -o &#39;%(id)s.%(ext)s&#39; --write-sub --sub-lang sv -- &quot;$i&quot; ;done .",
            "url": "https://jimregan.github.io/notes/kaggle/swedish/2021/09/21/check-riksantikvarieambetet-youtube-for-licence.html",
            "relUrl": "/kaggle/swedish/2021/09/21/check-riksantikvarieambetet-youtube-for-licence.html",
            "date": " • Sep 21, 2021"
        }
        
    
  
    
        ,"post144": {
            "title": "The New Statistics Why and How",
            "content": "The New Statistics: Why and How . @article{cumming2014newstatistics, author = {Geoff Cumming}, title ={The New Statistics: Why and How}, journal = {Psychological Science}, volume = {25}, number = {1}, pages = {7-29}, year = {2014}, doi = {10.1177/0956797613504966}, note ={PMID: 24220629} } . The problem: . Research Integrity . Published research is a biased selection of all research; | data analysis and reporting are often selective and biased; and | in many research fields, studies are rarely replicated, so false conclusions persist. | . a decision to report research […] must be independent of the results. . Agree, but… . The best way to ensure this is to make a commitment to report research in advance of conducting it . Not sure I agree. . No matter how intriguing, however, the results of such pilot work rarely deserve even a brief mention in a report. . Strongly disagree. . PHONEME TRANSPOSITION AND TEMPORAL ENCODING IN HUMAN SPEECH RECOGNITION - example pre-registration that seems relevant to the lab. .",
            "url": "https://jimregan.github.io/notes/journal%20club/2021/09/20/journal-club.html",
            "relUrl": "/journal%20club/2021/09/20/journal-club.html",
            "date": " • Sep 20, 2021"
        }
        
    
  
    
        ,"post145": {
            "title": "Interesting links, 19/9/2021",
            "content": "German ASR: Fine-Tuning Wav2Vec2 . torchaudio.resample is faster than librosa.resample | disable group_by_length if there’s a long delay before training starts Made no difference to the outcome | . | . . ASR Systems as Models of Phonetic Category Perception in Adults . PHONEME TRANSPOSITION AND TEMPORAL ENCODING IN HUMAN SPEECH RECOGNITION . . 19th-Century Cockney and RP .",
            "url": "https://jimregan.github.io/notes/links/2021/09/19/misc-links.html",
            "relUrl": "/links/2021/09/19/misc-links.html",
            "date": " • Sep 19, 2021"
        }
        
    
  
    
        ,"post146": {
            "title": "Interesting links, 16/9/2021",
            "content": "A comparative acoustic analysis of purring in four cats . @inproceedings{Schotz539090, author = {Sch{ &quot;o}tz, Susanne and Eklund, Robert}, booktitle = {Proceedings from Fonetik 2011, Quarterly Progress and Status Report TMH-QPSR, Volume 51, 2011}, pages = {5--8}, publisher = {Universitetsservice}, title = {A comparative acoustic analysis of purring in four cats}, series = {Quarterly Progress and Status Report TMH-QPSR}, number = {51}, URL = {http://www.speech.kth.se/fonetik2011/}, year = {2011} } . spotify/pedalboard - library for adding effects to audio, supports VST3 and Audio Unit plugins. . Jam3/math-as-code - “a cheat-sheet for mathematical notation in code form” . VOSK language model adaptation . Svito-zar/gesticulator: “Gesticulator: A framework for semantically-aware speech-driven gesture generation” . Remember the context! ASR slot error correction through memorization . Setup - ngrok . optuna/optuna: A hyperparameter optimization framework . dataqa/dataqa: Labelling platform for text using distant supervision . That XOR Trick . abhishekkrthakur/colabcode: Run VSCode (codeserver) on Google Colab or Kaggle Notebooks . tarun-bisht/wav2vec2-asr: wav2vec2 asr with transformers .",
            "url": "https://jimregan.github.io/notes/links/2021/09/16/misc-links.html",
            "relUrl": "/links/2021/09/16/misc-links.html",
            "date": " • Sep 16, 2021"
        }
        
    
  
    
        ,"post147": {
            "title": "XOR number guessing",
            "content": "def make_1ton_missing_number(n, to_remove): return [a for a in range(1, n + 1) if a != to_remove] . n = 12 l = make_1ton_missing_number(n, 8) . l . [1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12] . def get_missing_number(l1ton, n): res = 0 for val in range(1, n + 1): res ^= val for val in l1ton: res ^= val return res . get_missing_number(l, n) . 8 . 8 ^ 8 . 0 . 0 ^ 8 . 8 .",
            "url": "https://jimregan.github.io/notes/xor/misc/2021/09/15/xor-number-guessing.html",
            "relUrl": "/xor/misc/2021/09/15/xor-number-guessing.html",
            "date": " • Sep 15, 2021"
        }
        
    
  
    
        ,"post148": {
            "title": "Utterance XML to json",
            "content": "sample = &quot;&quot;&quot; &lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt; &lt;utterance input_string=&quot;&quot;&gt; &lt;sentence input_string=&quot;&quot;&gt; &lt;token input_string=&quot;SILENCE_TOKEN&quot;&gt; &lt;word input_string=&quot;SILENCE_TOKEN&quot; trans_source=&quot;src&quot; trans_output_format=&quot;final&quot;&gt; &lt;syllable &gt; &lt;phoneme symbol=&quot;sil&quot; end=&quot;1.19&quot;/&gt; &lt;/syllable&gt; &lt;/word&gt; &lt;/token&gt; &lt;/sentence&gt; &lt;/utterance&gt; &quot;&quot;&quot; . import xml.etree.ElementTree as ET . class Utterance: def __init__(self, input, sentences): self.input = input self.sentences = sentences . class Sentence: def __init__(self, input, tokens): self.input = input self.tokens = tokens . class Token: def __init__(self, input, words): self.input = input self.words = words . class Word: def __init__(self, input, source, syllables): self.input = input self.source = source self.syllables = syllables if self.syllables is None: self.syllables = [] def get_phonemes(self): return &quot; &quot;.join([a.get_phonemes() for a in self.syllables]) def get_clean_word(self): word = self.input if word[0:1] in &quot;nt&quot; and word[1:2] in &quot;AÁEÉIÍOÓUÚ&quot;: return word[0:1] + &quot;-&quot; + word[1:].lower() else: return word.lower() . class Syllable: def __init__(self, stress: int = 0, phonemes = None): self.stress = stress self.phonemes = phonemes if self.phonemes is None: self.phonemes = [] def get_phonemes(self): return &quot; &quot;.join([a.symbol for a in self.phonemes]) . class Phoneme: def __init__(self, symbol: str = &quot;&quot;, end: float = 0.0): self.symbol = symbol self.end = end . import io sio = io.StringIO(sample.strip()) . def from_xml(source): tree = ET.parse(source) root = tree.getroot() if &#39;input_string&#39; in root.attrib: input = root.attrib[&#39;input_string&#39;] else: input = &#39;&#39; sentences = [] for sentence in root.findall(&#39;./sentence&#39;): if &#39;input_string&#39; in sentence.attrib: input = sentence.attrib[&#39;input_string&#39;] else: input = &#39;&#39; tokens = [] for token in sentence.findall(&#39;./token&#39;): if &#39;input_string&#39; in token.attrib: input = token.attrib[&#39;input_string&#39;] else: input = &#39;&#39; words = [] for word in token.findall(&#39;./word&#39;): if &#39;input_string&#39; in word.attrib: input = word.attrib[&#39;input_string&#39;] else: input = &quot;&quot; if &#39;trans_source&#39; in word.attrib: source = word.attrib[&#39;trans_source&#39;] else: source = &quot;&quot; syllables = [] for syllable in word.findall(&#39;./syllable&#39;): phonemes = [] if &#39;stress&#39; in syllable.attrib: if syllable.attrib[&#39;stress&#39;] == &#39;None&#39;: stress = 0 else: stress = int(syllable.attrib[&#39;stress&#39;]) else: stress = 0 for phoneme in syllable.findall(&#39;./phoneme&#39;): if &#39;symbol&#39; in phoneme.attrib: symbol = phoneme.attrib[&#39;symbol&#39;] else: symbol = &#39;&#39; if &#39;end&#39; in phoneme.attrib: end = float(phoneme.attrib[&#39;end&#39;]) else: symbol = 0.0 phonemes.append(Phoneme(symbol, end)) syllables.append(Syllable(stress, phonemes)) words.append(Word(input, source, syllables)) tokens.append(Token(input, words)) sentences.append(Sentence(input, tokens)) return Utterance(input, sentences) . utt = from_xml(sio) . import json json.dumps(utt, default=lambda o: o.__dict__) . &#39;{&#34;input&#34;: &#34;SILENCE_TOKEN&#34;, &#34;sentences&#34;: [{&#34;input&#34;: &#34;SILENCE_TOKEN&#34;, &#34;tokens&#34;: [{&#34;input&#34;: &#34;SILENCE_TOKEN&#34;, &#34;words&#34;: [{&#34;input&#34;: &#34;SILENCE_TOKEN&#34;, &#34;source&#34;: &#34;src&#34;, &#34;syllables&#34;: [{&#34;stress&#34;: 0, &#34;phonemes&#34;: [{&#34;symbol&#34;: &#34;sil&#34;, &#34;end&#34;: 1.19}]}]}]}]}]}&#39; . for sent in utt.sentences: for tok in sent.tokens: for word in tok.words: print(f&#39;{word.get_clean_word()} {word.get_phonemes()}&#39;) . silence_token sil .",
            "url": "https://jimregan.github.io/notes/irish/abair/mfa/2021/09/15/utterance-xml-to-mfa.html",
            "relUrl": "/irish/abair/mfa/2021/09/15/utterance-xml-to-mfa.html",
            "date": " • Sep 15, 2021"
        }
        
    
  
    
        ,"post149": {
            "title": "Interesting links, roughly 15/9/2021",
            "content": "H5P – used for learning materials on TG4 and Tuairisc . Commits on transformers: Add SpeechEncoderDecoder &amp; Speech2Text2, Add the AudioClassificationPipeline, Add Wav2Vec2 &amp; Hubert ForSequenceClassification (based on converting s3rpl checkpoints) . monologg/JointBERT – (Unofficial) Pytorch implementation of JointBERT: BERT for Joint Intent Classification and Slot Filling . deezer/spleeter – Deezer source separation library including pretrained models. . VoxLingua107: a Dataset for Spoken Language Recognition – no Irish . Appen/UHV-OTS-Speech – A data annotation pipeline to generate high-quality, large-scale speech datasets with machine pre-labeling and fully manual auditing. Paper . The Effects of Automatic Speech Recognition Quality on Human Transcription Latency . @inproceedings{gaur16latency, author = {Yashesh Gaur and Walter S. Lasecki and Florian Metze and Jeffrey P. Bigham}, editor = {Gregory R. Gay and Tiago Jo{ ~{a}}o Guerreiro}, title = {The {E}ffects of {A}utomatic {S}peech {R}ecognition {Q}uality on {H}uman {T}ranscription {L}atency}, booktitle = {Proceedings of the 13th Web for All Conference, {W4A} &#39;16, Montreal, Canada, April 11-13, 2016}, pages = {23&amp;#58;1--23&amp;#58;8}, publisher = , year = {2016}, doi = {10.1145/2899475.2899478}, } . BirgerMoell/tmh . as-ideas/DeepPhonemizer See: Transformer based Grapheme-to-Phoneme Conversion . Unifying Speech and Gesture Synthesis . Locals create CD-ROM celebrating Gaeltacht area of Dun Chaochain . Facebook’s latest: Textless NLP: Generating expressive speech from raw audio Demo Code, Generative Spoken Language Modeling from Raw Audio, Speech Resynthesis from Discrete Disentangled Self-Supervised Representations, Text-Free Prosody-Aware Generative Spoken Language Modeling . AIdeaLab/wav2vec2_docker – pretraining wav2vec docker for sagemaker . as-ideas/DeepForcedAligner . citizensinformation.ie mojibake . kingabzpro/fine-tuning-xlsr-wav2vec2-for-wolof-asr-with . ceyda/wav2vec2-base-760 – Turkish wav2vec2 base model . Excessive GPU-GPU communication with GPT2 making multi-GPU training slow? . Vosk LM . Svito-zar/gesticulator . run_cleanup_segmentation.sh from malach, based on AMI, in turn based on Tedlium . Numbers . Classroom materials .",
            "url": "https://jimregan.github.io/notes/links/2021/09/15/misc-links.html",
            "relUrl": "/links/2021/09/15/misc-links.html",
            "date": " • Sep 15, 2021"
        }
        
    
  
    
        ,"post150": {
            "title": "T5G2P -- Using Text-to-Text Transfer Transformer for Grapheme-to-Phoneme Conversion",
            "content": "T5G2P: Using Text-to-Text Transfer Transformer for Grapheme-to-Phoneme Conversion . @inproceedings{rezackova21_interspeech, author={Markéta Řezáčková and Jan Švec and Daniel Tihelka}, title={T5{G2P}: {U}sing {T}ext-to-{T}ext {T}ransfer {T}ransformer for {G}rapheme-to-{P}honeme {C}onversion}, year=2021, booktitle={Proc. Interspeech 2021}, pages={6--10}, doi={10.21437/Interspeech.2021-546} } . Phonological Corpus of Czech – seems similar enough to the described corpus for Czech. .",
            "url": "https://jimregan.github.io/notes/journal%20club/2021/09/13/journal-club.html",
            "relUrl": "/journal%20club/2021/09/13/journal-club.html",
            "date": " • Sep 13, 2021"
        }
        
    
  
    
        ,"post151": {
            "title": "CoNLL 2017 Irish data",
            "content": "CoNLL 2017 Shared Task - Automatically Annotated Raw Texts and Word Embeddings . There was a web page with raw text; the Irish data has some stuff that looks weird. There are items that look like they were poorly split, but there are items from Logos Poetry like this: . 41] Ná tréig neamh ar ní nach lat; . where the line numbering and brace were intentional. Not that there aren’t odd splits because of poor sentence splitting. The sentence at line 4467 of ga-common_crawl-000.conllu.xz is: . do giallaibh) .i. tech lán do ghiallaibh aigi. . which comes from here: . Nó Eochaid Domplén .i. domus (.i. tech) plena (.i. do giallaibh) .i. tech lán do ghiallaibh aigi. Is de rohainmniged Eochaid Domplén de. . (i.e., it’s not even modern Irish). .",
            "url": "https://jimregan.github.io/notes/irish/2021/09/13/conll-2017.html",
            "relUrl": "/irish/2021/09/13/conll-2017.html",
            "date": " • Sep 13, 2021"
        }
        
    
  
    
        ,"post152": {
            "title": "Read a .wav file with Vosk API",
            "content": "import vosk import wave . from vosk import Model, KaldiRecognizer, SetLogLevel model = Model(&quot;model&quot;) rec = KaldiRecognizer(model, 16000) rec.SetWords(True) . wave_file = WAV_FILE . wf = wave.open(wave_file) . while True: data = wf.readframes(4000) if len(data) == 0: break if rec.AcceptWaveform(data): print(rec.Result()) else: print(rec.PartialResult()) rec.Result() .",
            "url": "https://jimregan.github.io/notes/vosk/2021/09/10/vosk-wav.html",
            "relUrl": "/vosk/2021/09/10/vosk-wav.html",
            "date": " • Sep 10, 2021"
        }
        
    
  
    
        ,"post153": {
            "title": "Abair wav2vec text",
            "content": "dir = &quot;/home/jim/abair-corpora/&quot; col_names = [&quot;id&quot;, &quot;set&quot;, &quot;gender&quot;, &quot;url&quot;, &quot;text&quot;, &quot;phonemes&quot;] . import os . inputs = [] for (path, dirs, files) in os.walk(dir): if &quot;/comhra&quot; in path: continue if &quot;corpusfile.txt&quot; in files: inputs.append(os.path.join(path, &quot;corpusfile.txt&quot;)) . from datasets import load_dataset dset = load_dataset(&quot;csv&quot;, data_files=inputs, column_names=col_names, delimiter=&quot; t&quot;, split=&quot;train&quot;, index_col=False) dset = dset.filter(lambda x: x[&#39;text&#39;] is not None) . def irish_lc(text): def lcword(word): if word[0:1] in &quot;nt&quot; and word[1:2] in &quot;AÁEÉIÍOÓUÚ&quot;: return word[0:1] + &quot;-&quot; + word[1:].lower() else: return word.lower() return &quot; &quot;.join(list(map(lcword, text.split(&quot; &quot;)))) . assert irish_lc(&quot;bhúr nAthair&quot;) == &quot;bhúr n-athair&quot; . import re chars_to_ignore_regex = &#39;[ , ? . ! - ; : &quot; “ % ‘ ”…—– ( )]&#39; def remove_special_characters(batch): batch[&quot;text&quot;] = batch[&quot;text&quot;].replace(&quot;’&quot;, &quot;&#39;&quot;) batch[&quot;text&quot;] = batch[&quot;text&quot;].replace(&quot;(Tor@m)&quot;, &quot;&quot;) batch[&quot;text&quot;] = re.sub(chars_to_ignore_regex, &#39;&#39;, irish_lc(batch[&quot;text&quot;])) batch[&quot;text&quot;] = re.sub(&#39; +$&#39;, &#39;&#39;, batch[&quot;text&quot;]) batch[&quot;text&quot;] = batch[&quot;text&quot;].replace(&quot; xa0&quot;, &quot; &quot;) batch[&quot;text&quot;] = batch[&quot;text&quot;].replace(&quot; ufeff&quot;, &quot;&quot;) batch[&quot;text&quot;] = batch[&quot;text&quot;].replace(&quot;1983&quot;, &quot;naoi déag ochtó a trí&quot;) batch[&quot;text&quot;] = batch[&quot;text&quot;].replace(&quot;tg4&quot;, &quot;t g ceathair&quot;) batch[&quot;text&quot;] = re.sub(&#39; +&#39;, &#39; &#39;, irish_lc(batch[&quot;text&quot;])) + &quot; &quot; return batch dset = dset.map(remove_special_characters) . def is_all_alphabetic(batch): sentence = batch[&quot;text&quot;] for char in sentence: if char not in &quot;aábcdeéfghiíjklmnoópqrstuúvwxyz&#39; &quot;: return False return True dset = dset.filter(is_all_alphabetic) . def extract_all_chars(batch): all_text = &quot; &quot;.join(batch[&quot;text&quot;]) vocab = list(set(all_text)) return {&quot;vocab&quot;: [vocab], &quot;all_text&quot;: [all_text]} vocab_train = dset.map(extract_all_chars, batched=True, batch_size=-1, keep_in_memory=True, remove_columns=dset.column_names) . vocab_list = list(set(vocab_train[&quot;vocab&quot;][0])) vocab_dict = {v: k for k, v in enumerate(vocab_list)} print(vocab_dict) . def fix_path(batch): batch[&quot;audio&quot;] = batch[&quot;url&quot;].replace(&quot;https://www.abair.tcd.ie/asr_data_irish_audio/&quot;, &quot;/media/phonetics/asr_data_irish/audio/&quot;) return batch dset = dset.map(fix_path) . from pathlib import Path def check_paths(batch): audio_path = Path(batch[&quot;audio&quot;]) return audio_path.is_file() dset = dset.filter(check_paths) . vocab_dict[&quot;|&quot;] = vocab_dict[&quot; &quot;] del vocab_dict[&quot; &quot;] . vocab_dict[&quot;[UNK]&quot;] = len(vocab_dict) vocab_dict[&quot;[PAD]&quot;] = len(vocab_dict) print(len(vocab_dict)) . import json with open(&#39;/home/jim/w2v-out/vocab.json&#39;, &#39;w&#39;) as vocab_file: json.dump(vocab_dict, vocab_file) . from transformers import Wav2Vec2CTCTokenizer tokenizer = Wav2Vec2CTCTokenizer(&quot;/home/jim/w2v-out/vocab.json&quot;, unk_token=&quot;[UNK]&quot;, pad_token=&quot;[PAD]&quot;, word_delimiter_token=&quot;|&quot;) . from transformers import Wav2Vec2FeatureExtractor feature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=True) . from transformers import Wav2Vec2Processor processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer) . import torchaudio def speech_file_to_array_fn(batch): speech_array, sampling_rate = torchaudio.load(batch[&quot;audio&quot;]) batch[&quot;speech&quot;] = speech_array[0].numpy() batch[&quot;sampling_rate&quot;] = sampling_rate batch[&quot;target_text&quot;] = batch[&quot;text&quot;] return batch dset = dset.map(speech_file_to_array_fn, remove_columns=dset.column_names) . import librosa import numpy as np def resample(batch): batch[&quot;duration&quot;] = librosa.get_duration(y=batch[&quot;speech&quot;], sr=batch[&quot;sampling_rate&quot;]) if batch[&quot;sampling_rate&quot;] != 16_000: batch[&quot;speech&quot;] = librosa.resample(np.asarray(batch[&quot;speech&quot;]), batch[&quot;sampling_rate&quot;], 16_000) batch[&quot;sampling_rate&quot;] = 16_000 return batch dset = dset.map(resample, num_proc=4) . def filter_length(batch): length = batch[&quot;duration&quot;] return length &gt; 1.0 and length &lt; 9.0 dset = dset.filter(filter_length) . def prepare_dataset(batch): # check that all files have the correct sampling rate assert ( len(set(batch[&quot;sampling_rate&quot;])) == 1 ), f&quot;Make sure all inputs have the same sampling rate of {processor.feature_extractor.sampling_rate}.&quot; batch[&quot;input_values&quot;] = processor(batch[&quot;speech&quot;], sampling_rate=batch[&quot;sampling_rate&quot;][0]).input_values with processor.as_target_processor(): batch[&quot;labels&quot;] = processor(batch[&quot;target_text&quot;]).input_ids return batch dset = dset.map(prepare_dataset, remove_columns=dset.column_names, batch_size=8, num_proc=4, batched=True) . import torch from dataclasses import dataclass, field from typing import Any, Dict, List, Optional, Union @dataclass class DataCollatorCTCWithPadding: &quot;&quot;&quot; Data collator that will dynamically pad the inputs received. Args: processor (:class:`~transformers.Wav2Vec2Processor`) The processor used for proccessing the data. padding (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.PaddingStrategy`, `optional`, defaults to :obj:`True`): Select a strategy to pad the returned sequences (according to the model&#39;s padding side and padding index) among: * :obj:`True` or :obj:`&#39;longest&#39;`: Pad to the longest sequence in the batch (or no padding if only a single sequence if provided). * :obj:`&#39;max_length&#39;`: Pad to a maximum length specified with the argument :obj:`max_length` or to the maximum acceptable input length for the model if that argument is not provided. * :obj:`False` or :obj:`&#39;do_not_pad&#39;` (default): No padding (i.e., can output a batch with sequences of different lengths). max_length (:obj:`int`, `optional`): Maximum length of the ``input_values`` of the returned list and optionally padding length (see above). max_length_labels (:obj:`int`, `optional`): Maximum length of the ``labels`` returned list and optionally padding length (see above). pad_to_multiple_of (:obj:`int`, `optional`): If set will pad the sequence to a multiple of the provided value. This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability &gt;= 7.5 (Volta). &quot;&quot;&quot; processor: Wav2Vec2Processor padding: Union[bool, str] = True max_length: Optional[int] = None max_length_labels: Optional[int] = None pad_to_multiple_of: Optional[int] = None pad_to_multiple_of_labels: Optional[int] = None def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -&gt; Dict[str, torch.Tensor]: # split inputs and labels since they have to be of different lenghts and need # different padding methods input_features = [{&quot;input_values&quot;: feature[&quot;input_values&quot;]} for feature in features] label_features = [{&quot;input_ids&quot;: feature[&quot;labels&quot;]} for feature in features] batch = self.processor.pad( input_features, padding=self.padding, max_length=self.max_length, pad_to_multiple_of=self.pad_to_multiple_of, return_tensors=&quot;pt&quot;, ) with self.processor.as_target_processor(): labels_batch = self.processor.pad( label_features, padding=self.padding, max_length=self.max_length_labels, pad_to_multiple_of=self.pad_to_multiple_of_labels, return_tensors=&quot;pt&quot;, ) # replace padding with -100 to ignore loss correctly labels = labels_batch[&quot;input_ids&quot;].masked_fill(labels_batch.attention_mask.ne(1), -100) batch[&quot;labels&quot;] = labels return batch . data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True) . from datasets import load_metric wer_metric = load_metric(&quot;wer&quot;) . def compute_metrics(pred): pred_logits = pred.predictions pred_ids = np.argmax(pred_logits, axis=-1) pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id pred_str = processor.batch_decode(pred_ids) # we do not want to group tokens when computing the metrics label_str = processor.batch_decode(pred.label_ids, group_tokens=False) wer = wer_metric.compute(predictions=pred_str, references=label_str) return {&quot;wer&quot;: wer} . from transformers import Wav2Vec2ForCTC model = Wav2Vec2ForCTC.from_pretrained( &quot;facebook/wav2vec2-large-xlsr-53&quot;, attention_dropout=0.1, hidden_dropout=0.1, feat_proj_dropout=0.0, mask_time_prob=0.05, layerdrop=0.1, gradient_checkpointing=False, ctc_loss_reduction=&quot;mean&quot;, pad_token_id=processor.tokenizer.pad_token_id, vocab_size=len(processor.tokenizer) ) . model.freeze_feature_extractor() . from transformers import TrainingArguments training_args = TrainingArguments( output_dir=&quot;/home/jim/w2v-out&quot;, group_by_length=True, per_device_train_batch_size=16, gradient_accumulation_steps=2, evaluation_strategy=&quot;steps&quot;, num_train_epochs=30, fp16=True, save_steps=400, eval_steps=400, logging_steps=400, learning_rate=5e-4, warmup_steps=500, save_total_limit=2, ) . dset = dset.shuffle(seed=42) . train_testvalid = dset.train_test_split(test_size=0.05) if not &#39;train&#39; in train_testvalid: raise Exception(&quot;train_test_split() is broken: no &#39;train&#39;&quot;) if not &#39;test&#39; in train_testvalid: raise Exception(&quot;train_test_split() is broken: no &#39;test&#39;&quot;) . from transformers import Trainer trainer = Trainer( model=model, data_collator=data_collator, args=training_args, compute_metrics=compute_metrics, train_dataset=train_testvalid[&quot;train&quot;], eval_dataset=train_testvalid[&quot;test&quot;], tokenizer=processor.feature_extractor, ) . trainer.train() . trainer.save_model(&quot;/home/jim/w2v-test-run&quot;) tokenizer.save_pretrained(&quot;/home/jim/w2v-test-run&quot;) .",
            "url": "https://jimregan.github.io/notes/abair/irish/2021/09/09/w2v-text-irish-abair.html",
            "relUrl": "/abair/irish/2021/09/09/w2v-text-irish-abair.html",
            "date": " • Sep 9, 2021"
        }
        
    
  
    
        ,"post154": {
            "title": "Tuairisc scraper pieces",
            "content": "_SITEMAP=&#39;https://tuairisc.ie/sitemap.xml&#39; . import requests from bs4 import BeautifulSoup . def _read_main_sitemap(): output = [] sm = requests.get(_SITEMAP) if sm.status_code != 200: raise Exception(&quot;Failed to read sitemap&quot;) base_soup = BeautifulSoup(sm.text, &#39;lxml&#39;) for submap in base_soup.findAll(&#39;sitemap&#39;): location = submap.find(&#39;loc&#39;).text if &#39;sitemap-pt&#39; in location: output.append(_read_sub_sitemap(location)) return output . def _read_sub_sitemap(url): output = [] sm = requests.get(url) if sm.status_code != 200: raise Exception(&quot;Failed to read sitemap&quot;) base_soup = BeautifulSoup(sm.text, &quot;lxml&quot;) for submap in base_soup.findAll(&quot;url&quot;): output.append(submap.find(&quot;loc&quot;).text) return output . def _fetch_article(url): page = requests.get(url) if page.status_code != 200: raise Exception(&quot;Failed to read page: &quot; + url) return page.text . def _get_article_text(content): base_soup = BeautifulSoup(content, &quot;lxml&quot;) main = base_soup.find(&quot;div&quot;, {&quot;class&quot;: &quot;article--full__content&quot;}) paras = [p.text.strip() for p in main.findAll(&quot;p&quot;) if p.text.strip() != &#39;&#39;] return(paras) . def _get_pub_date(content): base_soup = BeautifulSoup(content, &quot;lxml&quot;) date = base_soup.find(&quot;time&quot;, {&quot;itemprop&quot;: &quot;datePublished&quot;}) return date[&quot;datetime&quot;] .",
            "url": "https://jimregan.github.io/notes/irish/scraper/tuairisc/2021/09/09/tuairisc-foghlaimeoiri-scraper.html",
            "relUrl": "/irish/scraper/tuairisc/2021/09/09/tuairisc-foghlaimeoiri-scraper.html",
            "date": " • Sep 9, 2021"
        }
        
    
  
    
        ,"post155": {
            "title": "TG4 Foghlaim scraper pieces",
            "content": "import requests from bs4 import BeautifulSoup . landing = &quot;https://www.tg4.ie/ga/brandai-eile/foghlaim/ceachtanna/&quot; . landing_page = requests.get(landing) assert landing_page.status_code == 200 . soup = BeautifulSoup(landing_page.text, &quot;lxml&quot;) . lessons = [] for lesson_item in soup.find_all(&quot;a&quot;, {&quot;class&quot;: &quot;prog-panel&quot;}): lessons.append(lesson_item.get(&quot;href&quot;)) . def _reamhobair_text(url): out = [] page = requests.get(url) assert page.status_code == 200 soup = BeautifulSoup(page.text, &quot;lxml&quot;) for part in soup.find(&quot;div&quot;, {&quot;class&quot;: &quot;arconix-toggle-content&quot;}): #out.append(part.text) print(part) return out . _reamhobair_text(&quot;https://www.tg4.ie/ga/brandai-eile/foghlaim/ceachtanna/an-scoil/reamhobair/&quot;) . def _reamhobair_questions(url): import json out = [] page = requests.get(url) assert page.status_code == 200 soup = BeautifulSoup(page.text, &quot;lxml&quot;) for script_tag in soup.find_all(&quot;script&quot;): if script_tag.text.startswith(&quot;H5PIntegration=&quot;): if script_tag.text.endswith(&quot;;&quot;): json_inner = json.loads(script_tag.text[15:-1]) else: json_inner = json.loads(script_tag.text[15:]) if &quot;contents&quot; in json_inner: for k in json_inner[&quot;contents&quot;].keys(): if &quot;library&quot; in json_inner[&quot;contents&quot;][k].keys(): if &quot;jsonContent&quot; in json_inner[&quot;contents&quot;][k].keys(): jsc = json_inner[&quot;contents&quot;][k][&quot;jsonContent&quot;] if type(jsc) == str and &quot;questions&quot; in jsc: jsc_l = json.loads(jsc) out.append((k, json_inner[&quot;contents&quot;][k][&quot;library&quot;], jsc_l[&quot;questions&quot;])) else: continue return out _reamhobair_questions(&quot;https://www.tg4.ie/ga/brandai-eile/foghlaim/ceachtanna/an-scoil/reamhobair/&quot;) . _reamhobair_questions(&quot;https://www.tg4.ie/ga/brandai-eile/foghlaim/ceachtanna/ras-na-bpointi/mir-a-haon/&quot;) .",
            "url": "https://jimregan.github.io/notes/irish/scraper/tg4/incomplete/2021/09/07/tg4-foghlaim-scraper.html",
            "relUrl": "/irish/scraper/tg4/incomplete/2021/09/07/tg4-foghlaim-scraper.html",
            "date": " • Sep 7, 2021"
        }
        
    
  
    
        ,"post156": {
            "title": "Interesting links, 6/9/2021",
            "content": "Kungbib/swedish-bert-models. Paper: Playing with Words at the National Library of Sweden – Making a Swedish BERT Huggingface: KBLab . NST Swedish Dictation (22 kHz) . SCRIBE - Spoken Corpus of British English . The available audio recordings and annotations were released on eleven CD-ROMs (labelled SCRIBE_0 to SCRIBE_11) in April . These were originally distributed by the Speech Group at the National Physical Laboratory, but after this was closed down the disks were passed to the MOD Speech Research Unit at Malvern which passed the disks on to a private contractor (who kept them in his garage). | google/cld3 . google-research/text-to-text-transfer-transformer . superb benchmark models . . Scraping notes: . Gaelchultúr eolaire . Cogg: Áiseanna Tacaíochta don Oideachas Speisialta, Bain Súp As, Leabhair Dhigiteacha . TG4: an-scoil/reamhobair, cursai-idirnaisiunta/reamhobair/, fadhbanna/reamhobair/, cursai-timpeallachta, cursai-airgid/mir-a-do, ponc/ponc-reamhobair . Fís agus Foghlaim . Comhar . Coiscéim . Club Leabhar: PODCHRAOLTAÍ LÉIRMHEASTÓIREACHTA AR LEABHAIR NA MÍOSA, AGALLAIMH ATÁ DÉANTA AGAINN LE HÚDAIR AGUS LE CRITICEOIRÍ LITEARTHA, Tintin mar charachtar an scéil .",
            "url": "https://jimregan.github.io/notes/links/scraping/2021/09/06/misc-links.html",
            "relUrl": "/links/scraping/2021/09/06/misc-links.html",
            "date": " • Sep 6, 2021"
        }
        
    
  
    
        ,"post157": {
            "title": "The processing of rhythmic structures in music and prosody by children with developmental dyslexia and developmental language disorder",
            "content": "The processing of rhythmic structures in music and prosody by children with developmental dyslexia and developmental language disorder . @article{caccia2021process, author = {Caccia, Martina and Lorusso, Maria Luisa}, title = {The processing of rhythmic structures in music and prosody by children with developmental dyslexia and developmental language disorder}, journal = {Developmental Science}, volume = {24}, number = {1}, pages = {e12981}, doi = {https://doi.org/10.1111/desc.12981}, year = {2021} } .",
            "url": "https://jimregan.github.io/notes/journal%20club/2021/09/06/journal-club.html",
            "relUrl": "/journal%20club/2021/09/06/journal-club.html",
            "date": " • Sep 6, 2021"
        }
        
    
  
    
        ,"post158": {
            "title": "Playing .wav files",
            "content": "from pathlib import Path import wave ncb_path = Path(&quot;/media/storage/phonetics/corpas_ncb/corpas_full_split_210415/&quot;) . files = [] for wf in ncb_path.glob(&quot;*.wav&quot;): cur = {} cur[&quot;id&quot;] = wf.stem wav = wave.open(str(wf)) fr = wav.getframerate() cur[&quot;framerate&quot;] = fr cur[&quot;duration&quot;] = wav.getnframes() / fr files.append(cur) . import json with open(&quot;out.json&quot;, &quot;w&quot;) as outf: json.dump(files, outf) .",
            "url": "https://jimregan.github.io/notes/test/2021/09/05/wav-playing.html",
            "relUrl": "/test/2021/09/05/wav-playing.html",
            "date": " • Sep 5, 2021"
        }
        
    
  
    
        ,"post159": {
            "title": "Playing with pyannote.audio 2",
            "content": "%%capture !pip install condacolab . Requirement already satisfied: condacolab in /usr/local/lib/python3.7/dist-packages (0.1.3) . import condacolab condacolab.install() . ⏬ Downloading https://github.com/jaimergp/miniforge/releases/latest/download/Mambaforge-colab-Linux-x86_64.sh... 📦 Installing... 📌 Adjusting configuration... 🩹 Patching environment... ⏲ Done in 0:00:39 🔁 Restarting kernel... . !conda create -n pyannote python=3.8.5 !conda activate pyannote !conda install numpy cffi !conda install libsndfile=1.0.28 -c conda-forge !pip install https://github.com/pyannote/pyannote-audio/archive/develop.zip . %%capture !wget https://podcast.rasset.ie/podcasts/audio/2021/0626/20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.mp3 . %%capture !ffmpeg -i /content/20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.mp3 -acodec pcm_s16le -ac 1 -ar 16000 /content/20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.wav . from pyannote.audio.pipelines import VoiceActivityDetection pipeline = VoiceActivityDetection(segmentation=&quot;pyannote/segmentation&quot;) HYPER_PARAMETERS = { # onset/offset activation thresholds &quot;onset&quot;: 0.5, &quot;offset&quot;: 0.5, # remove speech regions shorter than that many seconds. &quot;min_duration_on&quot;: 0.0, # fill non-speech regions shorter than that many seconds. &quot;min_duration_off&quot;: 0.0 } pipeline.instantiate(HYPER_PARAMETERS) vad = pipeline(&quot;/content/20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.wav&quot;) . ImportError Traceback (most recent call last) &lt;ipython-input-5-e82545d3d9d2&gt; in &lt;module&gt;() -&gt; 1 from pyannote.audio.pipelines import VoiceActivityDetection 2 pipeline = VoiceActivityDetection(segmentation=&#34;pyannote/segmentation&#34;) 3 HYPER_PARAMETERS = { 4 # onset/offset activation thresholds 5 &#34;onset&#34;: 0.5, &#34;offset&#34;: 0.5, /usr/local/lib/python3.7/site-packages/pyannote/audio/__init__.py in &lt;module&gt;() 27 28 &gt; 29 from .core.inference import Inference 30 from .core.io import Audio 31 from .core.model import Model /usr/local/lib/python3.7/site-packages/pyannote/audio/core/inference.py in &lt;module&gt;() 28 import torch 29 from einops import rearrange &gt; 30 from pytorch_lightning.utilities.memory import is_oom_error 31 32 from pyannote.audio.core.io import AudioFile /usr/local/lib/python3.7/site-packages/pytorch_lightning/__init__.py in &lt;module&gt;() 18 _PROJECT_ROOT = os.path.dirname(_PACKAGE_ROOT) 19 &gt; 20 from pytorch_lightning import metrics # noqa: E402 21 from pytorch_lightning.callbacks import Callback # noqa: E402 22 from pytorch_lightning.core import LightningDataModule, LightningModule # noqa: E402 /usr/local/lib/python3.7/site-packages/pytorch_lightning/metrics/__init__.py in &lt;module&gt;() 13 # limitations under the License. 14 &gt; 15 from pytorch_lightning.metrics.classification import ( # noqa: F401 16 Accuracy, 17 AUC, /usr/local/lib/python3.7/site-packages/pytorch_lightning/metrics/classification/__init__.py in &lt;module&gt;() 12 # See the License for the specific language governing permissions and 13 # limitations under the License. &gt; 14 from pytorch_lightning.metrics.classification.accuracy import Accuracy # noqa: F401 15 from pytorch_lightning.metrics.classification.auc import AUC # noqa: F401 16 from pytorch_lightning.metrics.classification.auroc import AUROC # noqa: F401 /usr/local/lib/python3.7/site-packages/pytorch_lightning/metrics/classification/accuracy.py in &lt;module&gt;() 16 from torchmetrics import Accuracy as _Accuracy 17 &gt; 18 from pytorch_lightning.metrics.utils import deprecated_metrics, void 19 20 /usr/local/lib/python3.7/site-packages/pytorch_lightning/metrics/utils.py in &lt;module&gt;() 27 from torchmetrics.utilities.distributed import reduce as _reduce 28 &gt; 29 from pytorch_lightning.utilities import rank_zero_deprecation 30 from pytorch_lightning.utilities.imports import _TORCHMETRICS_GREATER_EQUAL_0_3, _TORCHMETRICS_LOWER_THAN_0_3 31 /usr/local/lib/python3.7/site-packages/pytorch_lightning/utilities/__init__.py in &lt;module&gt;() 16 import numpy 17 &gt; 18 from pytorch_lightning.utilities.apply_func import move_data_to_device # noqa: F401 19 from pytorch_lightning.utilities.distributed import AllGatherGrad, rank_zero_info, rank_zero_only # noqa: F401 20 from pytorch_lightning.utilities.enums import ( # noqa: F401 /usr/local/lib/python3.7/site-packages/pytorch_lightning/utilities/apply_func.py in &lt;module&gt;() 28 29 if _TORCHTEXT_AVAILABLE: &gt; 30 if _compare_version(&#34;torchtext&#34;, operator.ge, &#34;0.9.0&#34;): 31 from torchtext.legacy.data import Batch 32 else: /usr/local/lib/python3.7/site-packages/pytorch_lightning/utilities/imports.py in _compare_version(package, op, version) 52 &#34;&#34;&#34; 53 try: &gt; 54 pkg = importlib.import_module(package) 55 except (ModuleNotFoundError, DistributionNotFound): 56 return False /usr/lib/python3.7/importlib/__init__.py in import_module(name, package) 125 break 126 level += 1 --&gt; 127 return _bootstrap._gcd_import(name[level:], package, level) 128 129 /usr/local/lib/python3.7/dist-packages/torchtext/__init__.py in &lt;module&gt;() 3 from . import datasets 4 from . import utils -&gt; 5 from . import vocab 6 from . import legacy 7 /usr/local/lib/python3.7/dist-packages/torchtext/vocab.py in &lt;module&gt;() 11 from typing import Dict, List, Optional, Iterable 12 from collections import Counter, OrderedDict &gt; 13 from torchtext._torchtext import ( 14 Vocab as VocabPybind, 15 ) ImportError: /usr/local/lib/python3.7/dist-packages/torchtext/_torchtext.so: undefined symbol: _ZN2at6detail10noopDeleteEPv NOTE: If your import is failing due to a missing package, you can manually install dependencies using either !pip or !apt. To view examples of installing some common dependencies, click the &#34;Open Examples&#34; button below. .",
            "url": "https://jimregan.github.io/notes/diarisation/pyannote/2021/09/05/playing-with-pyannote-audio2.html",
            "relUrl": "/diarisation/pyannote/2021/09/05/playing-with-pyannote-audio2.html",
            "date": " • Sep 5, 2021"
        }
        
    
  
    
        ,"post160": {
            "title": "Playing with inaSpeechSegmenter",
            "content": "%%capture !pip install inaSpeechSegmenter . from inaSpeechSegmenter import Segmenter . %%capture !wget https://podcast.rasset.ie/podcasts/audio/2021/0626/20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.mp3 . seg = Segmenter() . segmentation = seg(&#39;20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.mp3&#39;) . /usr/local/lib/python3.7/dist-packages/pyannote/algorithms/utils/viterbi.py:88: FutureWarning: arrays to stack must be passed as a &#34;sequence&#34; type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future. for e, c in six.moves.zip(emission.T, consecutive) /usr/local/lib/python3.7/dist-packages/pyannote/algorithms/utils/viterbi.py:97: FutureWarning: arrays to stack must be passed as a &#34;sequence&#34; type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future. for e, c in six.moves.zip(constraint.T, consecutive) . segmentation[0:6] . [(&#39;noEnergy&#39;, 0.0, 0.88), (&#39;music&#39;, 0.88, 4.72), (&#39;female&#39;, 4.72, 6.82), (&#39;male&#39;, 6.82, 11.34), (&#39;music&#39;, 11.34, 15.38), (&#39;male&#39;, 15.38, 26.68)] . !pip install pydub . Collecting pydub Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB) Installing collected packages: pydub Successfully installed pydub-0.25.1 . from pydub import AudioSegment audio = AudioSegment.from_mp3(&#39;20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.mp3&#39;) . clip1 = audio[int(0.88 * 1000):int(4.72 * 1000)] . clip1.export(&quot;clip1.ogg&quot;, format=&quot;ogg&quot;) . &lt;_io.BufferedRandom name=&#39;clip1.ogg&#39;&gt; . import IPython IPython.display.Audio(&quot;clip1.ogg&quot;) . clip2 = audio[int(4.72 * 1000):int(11.34 * 1000)] clip2.export(&quot;clip2.ogg&quot;, format=&quot;ogg&quot;) IPython.display.Audio(&quot;clip2.ogg&quot;) . clip3 = audio[int(981.08 * 1000):int(992.74 * 1000)] clip3.export(&quot;clip3.ogg&quot;, format=&quot;ogg&quot;) IPython.display.Audio(&quot;clip3.ogg&quot;) .",
            "url": "https://jimregan.github.io/notes/inaspeechsegmenter/segmentation/2021/09/05/playing-with-inaspeechsegmenter.html",
            "relUrl": "/inaspeechsegmenter/segmentation/2021/09/05/playing-with-inaspeechsegmenter.html",
            "date": " • Sep 5, 2021"
        }
        
    
  
    
        ,"post161": {
            "title": "Playing with Asteroid",
            "content": "%%capture !pip install -U asteroid . %%capture !wget https://podcast.rasset.ie/podcasts/audio/2021/0626/20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.mp3 . %%capture !ffmpeg -i /content/20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.mp3 -acodec pcm_s16le -ac 1 -ar 16000 /content/20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.wav . !asteroid-infer &quot;mpariente/ConvTasNet_WHAM!_sepclean&quot; --files /content/20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.wav --resample --ola-window 8000 --ola-hop 4000 . 100% 19.3M/19.3M [00:03&lt;00:00, 5.35MB/s] .",
            "url": "https://jimregan.github.io/notes/asteroid/separation/2021/09/05/playing-with-asteroid.html",
            "relUrl": "/asteroid/separation/2021/09/05/playing-with-asteroid.html",
            "date": " • Sep 5, 2021"
        }
        
    
  
    
        ,"post162": {
            "title": "Nós scraper pieces",
            "content": "sample = &#39;http://nos.ie/cultur/scannain/fisean-out-of-innocence-agallamh-le-heoin-o-dubhghaill/&#39; . import requests from bs4 import BeautifulSoup . page = requests.get(sample) . soup = BeautifulSoup(page.text, &#39;lxml&#39;) . vid = soup.find(&#39;div&#39;, {&#39;id&#39;, &#39;video-wrapper&#39;}) . _get_video(soup) . &#39;https://www.youtube.com/embed/lXr1QZPY7aY&#39; . def _get_video(soup): vid = soup.find(&#39;div&#39;, {&#39;id&#39;: &#39;video-wrapper&#39;}) if vid: iframe = vid.find(&#39;iframe&#39;) if iframe: return iframe.get(&#39;src&#39;, &#39;&#39;) return &#39;&#39; . def _get_details(soup): details = {} pubdet = soup.find(&quot;div&quot;, {&quot;id&quot;: &quot;single-publish-details&quot;}) ptags = [p for p in pubdet.find_all(&#39;p&#39;)] if ptags[0].b: details[&#39;author&#39;] = ptags[0].b.get_text(strip=True) if ptags[1]: details[&#39;date&#39;] = ptags[1].get_text(strip=True) broll = pubdet.find(&quot;div&quot;, {&quot;class&quot;: &quot;blogroll-tag-category&quot;}) cats = set() for cat in broll.find_all(&quot;a&quot;, {&quot;class&quot;: &quot;featured-category&quot;}): if cat.get_text(strip=True) != &quot;&quot;: cats.add(cat.get_text(strip=True)) if len(cats) &gt; 0: details[&#39;categories&#39;] = list(cats) tags = set() for tag in broll.find_all(&quot;a&quot;, {&quot;class&quot;: &quot;featured-tag&quot;}): if tag.get_text(strip=True) != &quot;&quot;: tags.add(tag.get_text(strip=True)) if len(tags) &gt; 0: details[&#39;tags&#39;] = list(tags) return details . _get_subhead(soup) . &#39;&#39; . def _get_subhead(soup): out = [] content = soup.find(&quot;div&quot;, {&quot;id&quot;: &quot;single-area-center&quot;}) if content.h1 and content.h1.span: return content.h1.span.get_text(strip=True) else: return &#39;&#39; . def _mksoup(url): page = requests.get(url) soup = BeautifulSoup(page.text, &#39;lxml&#39;) return soup . def _read_menu(): page = requests.get(&quot;http://nos.ie/&quot;) soup = BeautifulSoup(page.text, &#39;lxml&#39;) menu = soup.find(&quot;ul&quot;, {&quot;id&quot;: &quot;menu-main-menu&quot;}) cat_pages = set() for li in menu.find_all(&quot;li&quot;): if li.a: cat_pages.add(li.a[&#39;href&#39;]) return cat_pages . links = _read_menu() . a = _get_article_list(links) . len(a) . 296 . def _get_article_list(urls): rest = set() articles = set() for url in urls: page = requests.get(url) soup = BeautifulSoup(page.text, &#39;lxml&#39;) new = _get_remainder(soup) rest = rest.union(new) art = _collect_articles(soup) articles = articles.union(art) for url in rest: page = requests.get(url) soup = BeautifulSoup(page.text, &#39;lxml&#39;) art = _collect_articles(soup) articles = articles.union(art) return list(articles) . def _get_remainder(soup): import re pagination = soup.find(&quot;div&quot;, {&quot;class&quot;: &quot;pagination&quot;}) if not pagination: return [] current = pagination.find(&quot;span&quot;, {&quot;class&quot;: &quot;current&quot;}) if not (current and current.get_text(strip=True) == &quot;1&quot;): return [] cats = [a for a in pagination.find_all(&#39;a&#39;)] last_cat = cats[-1] last_url = last_cat.get(&#39;href&#39;, &#39;&#39;) if not last_url: return [] print(last_url) m = re.match(&quot;(.*/)([0-9]+)/$&quot;, last_url) if not m: return [] base = m.group(1) num = int(m.group(2)) + 1 return [f&#39;{base}{i}/&#39; for i in range(2, num)] . def _collect_articles(soup): out = set() for art in soup.find_all(&quot;article&quot;, {&quot;class&quot;: &quot;blogroll-post&quot;}): a = art.find(&#39;a&#39;) out.add(a.get(&#39;href&#39;)) return list(out) . top = _read_menu() . page = requests.get(&quot;http://nos.ie/category/cultur/ceol/&quot;) soup = BeautifulSoup(page.text, &#39;lxml&#39;) _collect_articles(soup) . arts = _get_article_list(top) .",
            "url": "https://jimregan.github.io/notes/irish/scraper/nos/2021/09/04/nos-scraper-pieces.html",
            "relUrl": "/irish/scraper/nos/2021/09/04/nos-scraper-pieces.html",
            "date": " • Sep 4, 2021"
        }
        
    
  
    
        ,"post163": {
            "title": "Interesting links, 3/9/2021",
            "content": "2dot71mily/youtube_captions_corrections: dataset here . facebookresearch/detr: End-to-End Object Detection with Transformers . timmahrt/praatIO: A python library for working with praat, textgrids, time aligned audio transcripts, and audio files. It is primarily used for extracting features from and making manipulations on audio files given hierarchical time-aligned transcriptions (utterance &gt; word &gt; syllable &gt; phone, etc). . nypl-openaudio/transcript-editor: Web-based tool for correcting speech-to-text generated transcripts. Runs Together We Listen . WGBH-MLA/transcript-editor: Web-based tool for correcting speech-to-text generated transcripts. . CNN Explainer . https://github.com/m3hrdadfi/soxan: Wav2Vec for speech recognition, classification, and audio classification . Irish relative clause . Indirect vs Direct Relative Clause – Irish for English Speakers/Gaeilge do Bhéarlóirí . Notes on Nolan (the Relative Clause) . Irish Gaelic dialects .",
            "url": "https://jimregan.github.io/notes/links/2021/09/03/misc-links.html",
            "relUrl": "/links/2021/09/03/misc-links.html",
            "date": " • Sep 3, 2021"
        }
        
    
  
    
        ,"post164": {
            "title": "Scraper pieces for beo.ie",
            "content": "sample_url = &#39;http://beo.ie/alt-an-eaglais-fein-a-bheas-thios-leis-ma-chuirtear-ba.aspx&#39; . import requests from bs4 import BeautifulSoup . page = requests.get(sample_url) . soup = BeautifulSoup(page.text, &#39;html.parser&#39;) . def _get_translations(soup): out = [] for gloss in soup.find_all(&#39;span&#39;, {&#39;class&#39;: &#39;gloss&#39;}): if gloss.get(&#39;title&#39;) != None and gloss.text: out.append({&#39;en&#39;: gloss.get(&#39;title&#39;), &#39;ga&#39;: gloss.text}) return out . def _get_captioned_images(soup): out = [] for pic in soup.find_all(&#39;div&#39;, {&#39;class&#39;: &#39;pic&#39;}): title = pic.find(&#39;div&#39;, {&#39;class&#39;: &#39;title&#39;}) if title: imgtag = pic.find(&#39;img&#39;) out.append({&#39;image&#39;: f&quot;http://beo.ie/{imgtag.get(&#39;src&#39;)}&quot;, &#39;caption&#39;: title.text}) return out . def _get_title(soup): title = soup.find(&#39;title&#39;).text if title and title.startswith(&#39;Beo! - &#39;): return(title[7:]) else: return None . def _get_blurb(soup): return soup.find(&#39;div&#39;, {&#39;class&#39;, &#39;blurb&#39;}).text.strip() . def _get_author(soup): dauth = soup.find(&#39;div&#39;, {&#39;class&#39;: &#39;author&#39;}) return dauth.find(&#39;span&#39;, {&#39;class&#39;: &#39;smallscreenInline&#39;}).text.strip() . def _get_paragraphs(soup): out = [] content = soup.find(&#39;div&#39;, {&#39;class&#39;: &#39;content&#39;}) for p in content.find_all(&#39;p&#39;): text = p.text.strip() if text: out.append(text) return out . edition_sample = &#39;http://beo.ie/eagran-2014-09.aspx&#39; . def _get_article_links(url): out = set() page = requests.get(url) soup = BeautifulSoup(page.text, &#39;html.parser&#39;) for article in soup.find_all(&#39;div&#39;, {&#39;class&#39;: &#39;articleListing&#39;}): for a in article.find_all(&#39;a&#39;): link = a.get(&#39;href&#39;) if link: out.add(f&quot;http://beo.ie/{link}&quot;) return list(out) . def _get_edition_links(): out = set() for i in range(1, 15): url = f&quot;http://beo.ie/Editions.aspx?Year=20{i:02}&quot; page = requests.get(url) soup = BeautifulSoup(page.text, &#39;html.parser&#39;) eds = soup.find(&#39;ul&#39;, {&#39;class&#39;: &#39;editions&#39;}) for ed in eds.find_all(&#39;a&#39;): if ed.get(&#39;href&#39;): out.add(f&quot;http://beo.ie/{ed.get(&#39;href&#39;)}&quot;) return list(out) .",
            "url": "https://jimregan.github.io/notes/irish/text/2021/09/01/beo-scraper-pieces.html",
            "relUrl": "/irish/text/2021/09/01/beo-scraper-pieces.html",
            "date": " • Sep 1, 2021"
        }
        
    
  
    
        ,"post165": {
            "title": "Convert .lab to textgrid",
            "content": "!pip install praatio . Collecting praatio Downloading praatio-5.0.0-py3-none-any.whl (76 kB) |████████████████████████████████| 76 kB 2.9 MB/s Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from praatio) (3.7.4.3) Installing collected packages: praatio Successfully installed praatio-5.0.0 . def _read_lab(filename: str, skip_empty_labels: bool = True): ret = [] with open(filename) as file: for line in file.readlines(): if line.strip() == &#39;&#39;: continue if line.startswith(&#39;#&#39;): continue l = line.rstrip().split(&#39; &#39;) if skip_empty_labels and len(l) != 3: continue tmp = {} tmp[&#39;start&#39;] = l[0] tmp[&#39;end&#39;] = l[1] if len(l) == 3: tmp[&#39;phone&#39;] = l[2] else: tmp[&#39;phone&#39;] = &#39;&#39; ret.append(tmp) return ret . %%writefile sample.lab 0 9700000 sil 9700000 10900000 i 10900000 12400000 mj 12400000 13100000 lj 13100000 15200000 au 15200000 16300000 r 16300000 18100000 sil 18100000 19100000 sil 19100000 23700000 . Writing sample.lab . ll = _read_lab(&#39;sample.lab&#39;, False) . from praatio import textgrid . from praatio.utilities.constants import Interval . out = [] for l in ll: out.append(Interval(int(l[&#39;start&#39;])/10000000.0, int(l[&#39;end&#39;])/10000000.0, l[&#39;phone&#39;])) . tier_start = out[0][0] tier_end = out[-1][1] . out . [Interval(start=0.0, end=0.97, label=&#39;sil&#39;), Interval(start=0.97, end=1.09, label=&#39;i&#39;), Interval(start=1.09, end=1.24, label=&#39;mj&#39;), Interval(start=1.24, end=1.31, label=&#39;lj&#39;), Interval(start=1.31, end=1.52, label=&#39;au&#39;), Interval(start=1.52, end=1.63, label=&#39;r&#39;), Interval(start=1.63, end=1.81, label=&#39;sil&#39;), Interval(start=1.81, end=1.91, label=&#39;sil&#39;), Interval(start=1.91, end=2.37, label=&#39;&#39;)] . tg = textgrid.Textgrid() phone_tier = textgrid.IntervalTier(&#39;phones&#39;, out, tier_start, tier_end) tg.addTier(phone_tier) tg.save(&#39;out.TextGrid&#39;, format=&quot;long_textgrid&quot;, includeBlankSpaces=False) . !cat out.TextGrid . File type = &#34;ooTextFile&#34; Object class = &#34;TextGrid&#34; xmin = 0 xmax = 2.37 tiers? &lt;exists&gt; size = 1 item []: item [1]: class = &#34;IntervalTier&#34; name = &#34;phones&#34; xmin = 0 xmax = 2.37 intervals: size = 9 intervals [1]: xmin = 0 xmax = 0.97 text = &#34;sil&#34; intervals [2]: xmin = 0.97 xmax = 1.09 text = &#34;i&#34; intervals [3]: xmin = 1.09 xmax = 1.24 text = &#34;mj&#34; intervals [4]: xmin = 1.24 xmax = 1.31 text = &#34;lj&#34; intervals [5]: xmin = 1.31 xmax = 1.52 text = &#34;au&#34; intervals [6]: xmin = 1.52 xmax = 1.63 text = &#34;r&#34; intervals [7]: xmin = 1.63 xmax = 1.81 text = &#34;sil&#34; intervals [8]: xmin = 1.81 xmax = 1.91 text = &#34;sil&#34; intervals [9]: xmin = 1.91 xmax = 2.37 text = &#34;&#34; .",
            "url": "https://jimregan.github.io/notes/lab/speech/textgrid/2021/08/31/lab_to_textgrid.html",
            "relUrl": "/lab/speech/textgrid/2021/08/31/lab_to_textgrid.html",
            "date": " • Aug 31, 2021"
        }
        
    
  
    
        ,"post166": {
            "title": "Read .lab files",
            "content": "%%writefile test.lab # 0 230 f 230 350 o 350 470 n . Writing test.lab . def _read_lab(filename: str): ret = [] with open(filename) as file: for line in file.readlines(): if line.strip() == &#39;&#39;: continue if line.startswith(&#39;#&#39;): continue l = line.rstrip().split(&#39; &#39;) if len(l) != 3: continue tmp = {} tmp[&#39;start&#39;] = l[0] tmp[&#39;end&#39;] = l[1] tmp[&#39;phone&#39;] = l[2] ret.append(tmp) return ret . _read_lab(&#39;test.lab&#39;) . [{&#39;end&#39;: &#39;230&#39;, &#39;phone&#39;: &#39;f&#39;, &#39;start&#39;: &#39;0&#39;}, {&#39;end&#39;: &#39;350&#39;, &#39;phone&#39;: &#39;o&#39;, &#39;start&#39;: &#39;230&#39;}, {&#39;end&#39;: &#39;470&#39;, &#39;phone&#39;: &#39;n&#39;, &#39;start&#39;: &#39;350&#39;}] .",
            "url": "https://jimregan.github.io/notes/lab/speech/2021/08/30/read_lab_file.html",
            "relUrl": "/lab/speech/2021/08/30/read_lab_file.html",
            "date": " • Aug 30, 2021"
        }
        
    
  
    
        ,"post167": {
            "title": "Parse Swedish gigaword XML",
            "content": "example = &quot;&quot;&quot; &lt;corpus id=&quot;1960-0000&quot;&gt; &lt;text date=&quot;1965-02-14&quot; datefrom=&quot;19650214&quot; dateto=&quot;19650214&quot; genre=&quot;news&quot; publisher=&quot;Stockholms Tidningen &quot; timefrom=&quot;000000&quot; timeto=&quot;235959&quot; topic=&quot;Politik och samhällsfrågor&quot; year=&quot;1965&quot;&gt; &lt;sentence id=&quot;aa9c2ac8-ae5dd1a1&quot;&gt; &lt;w dephead=&quot;4&quot; deprel=&quot;RA&quot; lemma=&quot;|i|&quot; lex=&quot;|i..pp.1|&quot; msd=&quot;PP&quot; pos=&quot;PP&quot; prefix=&quot;|&quot; ref=&quot;1&quot; saldo=&quot;|i..2|&quot; suffix=&quot;|&quot;&gt;I&lt;/w&gt; &lt;w dephead=&quot;3&quot; deprel=&quot;DT&quot; lemma=&quot;|&quot; lex=&quot;|&quot; msd=&quot;HD.UTR.SIN.IND&quot; pos=&quot;HD&quot; prefix=&quot;|&quot; ref=&quot;2&quot; saldo=&quot;|&quot; suffix=&quot;|&quot;&gt;vilken&lt;/w&gt; &lt;/sentence&gt; &lt;/text&gt; &lt;/corpus&gt; &quot;&quot;&quot; . import xml.etree.ElementTree as ET def _attrib(node, attrib: str) -&gt; str: if attrib in node.attrib: return node.attrib[attrib].strip() else: return &quot;&quot; def _iattrib(node, attrib: str) -&gt; str: if attrib in node.attrib: try: return int(node.attrib[attrib].strip()) except ValueError: return 0 else: return 0 class Corpus: def __init__(self, source): tree = ET.parse(source) root = tree.getroot() self.id = _attrib(root, &#39;id&#39;) self.texts = [] for text_node in root.findall(&#39;./text&#39;): self.texts.append(Text(text_node)) class Text: def __init__(self, node): self.date = _attrib(node, &#39;date&#39;) self.datefrom = _iattrib(node, &#39;datefrom&#39;) self.dateto = _iattrib(node, &#39;dateto&#39;) self.genre = _attrib(node, &#39;genre&#39;) self.publisher = _attrib(node, &#39;publisher&#39;) self.timefrom = _iattrib(node, &#39;timefrom&#39;) self.timeto = _iattrib(node, &#39;timeto&#39;) self.topic = _attrib(node, &#39;topic&#39;) self.year = _iattrib(node, &#39;year&#39;) self.sentences = [] for sent_node in node.findall(&#39;./sentence&#39;): self.sentences.append(Sentence(sent_node)) class Sentence: def __init__(self, node): self.id = _attrib(node, &#39;id&#39;) self.words = [] for w_node in node.findall(&#39;./w&#39;): self.words.append(Word(w_node)) class Word: def __init__(self, node): self.dephead = _attrib(node, &#39;dephead&#39;) self.deprel = _attrib(node, &#39;deprel&#39;) self.lemma = _attrib(node, &#39;lemma&#39;) self.lex = _attrib(node, &#39;lex&#39;) self.msd = _attrib(node, &#39;msd&#39;) self.pos = _attrib(node, &#39;pos&#39;) self.prefix = _attrib(node, &#39;prefix&#39;) self.ref = _attrib(node, &#39;ref&#39;) self.saldo = _attrib(node, &#39;saldo&#39;) self.suffix = _attrib(node, &#39;suffix&#39;) self.word = node.text.strip() . import io sio = io.StringIO(example) corp = Corpus(sio) . import json json.dumps(corp, default=lambda o: o.__dict__) . &#39;{&#34;id&#34;: &#34;1960-0000&#34;, &#34;texts&#34;: [{&#34;date&#34;: &#34;1965-02-14&#34;, &#34;datefrom&#34;: 19650214, &#34;dateto&#34;: 19650214, &#34;genre&#34;: &#34;news&#34;, &#34;publisher&#34;: &#34;Stockholms Tidningen&#34;, &#34;timefrom&#34;: 0, &#34;timeto&#34;: 235959, &#34;topic&#34;: &#34;Politik och samh u00e4llsfr u00e5gor&#34;, &#34;year&#34;: 1965, &#34;sentences&#34;: [{&#34;id&#34;: &#34;aa9c2ac8-ae5dd1a1&#34;, &#34;words&#34;: [{&#34;dephead&#34;: &#34;4&#34;, &#34;deprel&#34;: &#34;RA&#34;, &#34;lemma&#34;: &#34;|i|&#34;, &#34;lex&#34;: &#34;|i..pp.1|&#34;, &#34;msd&#34;: &#34;PP&#34;, &#34;pos&#34;: &#34;PP&#34;, &#34;prefix&#34;: &#34;|&#34;, &#34;ref&#34;: &#34;1&#34;, &#34;saldo&#34;: &#34;|i..2|&#34;, &#34;suffix&#34;: &#34;|&#34;, &#34;word&#34;: &#34;I&#34;}, {&#34;dephead&#34;: &#34;3&#34;, &#34;deprel&#34;: &#34;DT&#34;, &#34;lemma&#34;: &#34;|&#34;, &#34;lex&#34;: &#34;|&#34;, &#34;msd&#34;: &#34;HD.UTR.SIN.IND&#34;, &#34;pos&#34;: &#34;HD&#34;, &#34;prefix&#34;: &#34;|&#34;, &#34;ref&#34;: &#34;2&#34;, &#34;saldo&#34;: &#34;|&#34;, &#34;suffix&#34;: &#34;|&#34;, &#34;word&#34;: &#34;vilken&#34;}]}]}]}&#39; .",
            "url": "https://jimregan.github.io/notes/swedish/gigaword/xml/2021/08/30/parse_swedish_gigaword.html",
            "relUrl": "/swedish/gigaword/xml/2021/08/30/parse_swedish_gigaword.html",
            "date": " • Aug 30, 2021"
        }
        
    
  
    
        ,"post168": {
            "title": "Playing with pyannote.audio",
            "content": "Only the dia pipeline seems to work. . %%capture !pip install -q pyannote.audio==1.1 . %%capture !wget https://podcast.rasset.ie/podcasts/audio/2021/0626/20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.mp3 . %%capture !ffmpeg -i /content/20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.mp3 -acodec pcm_s16le -ac 1 -ar 16000 /content/20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.wav . import torch pipeline = torch.hub.load(&#39;pyannote/pyannote-audio&#39;, &#39;dia&#39;) diarization = pipeline({&#39;audio&#39;: &#39;/content/20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.wav&#39;}) . diarization . with open(&#39;/content/20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.rttm&#39;, &#39;w&#39;) as f: diarization.write_rttm(f) . %%capture !pip install youtube-dl . %%capture !youtube-dl f3wKxcP7hYE . %%capture !ffmpeg -i &#39;Sraith 2 Eip 1-f3wKxcP7hYE.mp4&#39; -acodec pcm_s16le -ac 1 -ar 16000 f3wKxcP7hYE.wav . diarization2 = pipeline({&#39;audio&#39;: &#39;/content/f3wKxcP7hYE.wav&#39;}) . diarization2 . No good; first 8 seconds are silence (ok), next 30 are theme music (not ok). . with open(&#39;/content/f3wKxcP7hYE.rttm&#39;, &#39;w&#39;) as f2: diarization2.write_rttm(f2) .",
            "url": "https://jimregan.github.io/notes/diarisation/pyannote/2021/08/27/playing-with-pyannote-audio.html",
            "relUrl": "/diarisation/pyannote/2021/08/27/playing-with-pyannote-audio.html",
            "date": " • Aug 27, 2021"
        }
        
    
  
    
        ,"post169": {
            "title": "Utterance XML to json",
            "content": "sample = &quot;&quot;&quot; &lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt; &lt;utterance input_string=&quot;&quot;&gt; &lt;sentence input_string=&quot;&quot;&gt; &lt;token input_string=&quot;SILENCE_TOKEN&quot;&gt; &lt;word input_string=&quot;SILENCE_TOKEN&quot; trans_source=&quot;src&quot; trans_output_format=&quot;final&quot;&gt; &lt;syllable &gt; &lt;phoneme symbol=&quot;sil&quot; end=&quot;1.19&quot;/&gt; &lt;/syllable&gt; &lt;/word&gt; &lt;/token&gt; &lt;/sentence&gt; &lt;/utterance&gt; &quot;&quot;&quot; . import xml.etree.ElementTree as ET . class Utterance: def __init__(self, input, sentences): self.input = input self.sentences = sentences . class Sentence: def __init__(self, input, tokens): self.input = input self.tokens = tokens . class Token: def __init__(self, input, words): self.input = input self.words = words . class Word: def __init__(self, input, source, syllables): self.input = input self.source = source self.syllables = syllables if self.syllables is None: self.syllables = [] . class Syllable: def __init__(self, stress: int = 0, phonemes = None): self.stress = stress self.phonemes = phonemes if self.phonemes is None: self.phonemes = [] . class Phoneme: def __init__(self, symbol: str = &quot;&quot;, end: float = 0.0): self.symbol = symbol self.end = end . import io sio = io.StringIO(sample.strip()) . def from_xml(source): tree = ET.parse(source) root = tree.getroot() if &#39;input_string&#39; in root.attrib: input = root.attrib[&#39;input_string&#39;] else: input = &#39;&#39; sentences = [] for sentence in root.findall(&#39;./sentence&#39;): if &#39;input_string&#39; in sentence.attrib: input = sentence.attrib[&#39;input_string&#39;] else: input = &#39;&#39; tokens = [] for token in sentence.findall(&#39;./token&#39;): if &#39;input_string&#39; in token.attrib: input = token.attrib[&#39;input_string&#39;] else: input = &#39;&#39; words = [] for word in token.findall(&#39;./word&#39;): if &#39;input_string&#39; in word.attrib: input = word.attrib[&#39;input_string&#39;] else: input = &quot;&quot; if &#39;trans_source&#39; in word.attrib: source = word.attrib[&#39;trans_source&#39;] else: source = &quot;&quot; syllables = [] for syllable in word.findall(&#39;./syllable&#39;): phonemes = [] if &#39;stress&#39; in syllable.attrib: stress = int(syllable.attrib[&#39;stress&#39;]) else: stress = 0 for phoneme in syllable.findall(&#39;./phoneme&#39;): if &#39;symbol&#39; in phoneme.attrib: symbol = phoneme.attrib[&#39;symbol&#39;] else: symbol = &#39;&#39; if &#39;end&#39; in phoneme.attrib: end = float(phoneme.attrib[&#39;end&#39;]) else: symbol = 0.0 phonemes.append(Phoneme(symbol, end)) syllables.append(Syllable(stress, phonemes)) words.append(Word(input, source, syllables)) tokens.append(Token(input, words)) sentences.append(Sentence(input, tokens)) return Utterance(input, sentences) . utt = from_xml(sio) . import json json.dumps(utt, default=lambda o: o.__dict__) . &#39;{&#34;input&#34;: &#34;SILENCE_TOKEN&#34;, &#34;sentences&#34;: [{&#34;input&#34;: &#34;SILENCE_TOKEN&#34;, &#34;tokens&#34;: [{&#34;input&#34;: &#34;SILENCE_TOKEN&#34;, &#34;words&#34;: [{&#34;input&#34;: &#34;SILENCE_TOKEN&#34;, &#34;source&#34;: &#34;src&#34;, &#34;syllables&#34;: [{&#34;stress&#34;: 0, &#34;phonemes&#34;: [{&#34;symbol&#34;: &#34;sil&#34;, &#34;end&#34;: 1.19}]}]}]}]}]}&#39; .",
            "url": "https://jimregan.github.io/notes/irish/abair/2021/08/22/utterance_xml_to_json.html",
            "relUrl": "/irish/abair/2021/08/22/utterance_xml_to_json.html",
            "date": " • Aug 22, 2021"
        }
        
    
  
    
        ,"post170": {
            "title": "Soundcloud - Raidió na Gaeltachta/Raidió Fáilte",
            "content": "!pip install youtube-dl !youtube-dl -o &#39;%(id)s.%(ext)s&#39; https://soundcloud.com/rte-rnag/ !youtube-dl -o &#39;%(id)s.%(ext)s&#39; https://soundcloud.com/raidio-f .",
            "url": "https://jimregan.github.io/notes/kaggle/irish/soundcloud/dataset/unlabelled/rnag/raidiofailte/2021/08/21/soundcloud-raidio-na-gaeltachta.html",
            "relUrl": "/kaggle/irish/soundcloud/dataset/unlabelled/rnag/raidiofailte/2021/08/21/soundcloud-raidio-na-gaeltachta.html",
            "date": " • Aug 21, 2021"
        }
        
    
  
    
        ,"post171": {
            "title": "Download Cúla4 ar Scoil video",
            "content": "urls = &quot;&quot;&quot; https://www.youtube.com/playlist?list=PLbcLsUBW9b3DvFSKW94bXDkVT0rIIbDTk https://www.youtube.com/playlist?list=PLbcLsUBW9b3ArxQoB-GhdSzGtYhhU-KGT https://www.youtube.com/playlist?list=PLbcLsUBW9b3CZJpM59kQ76Wxdfm3buABK https://www.youtube.com/playlist?list=PLbcLsUBW9b3ATOk7Kdzxb5KGM1wOFmwby https://www.youtube.com/playlist?list=PLbcLsUBW9b3DknBLzIWl0tRC_jYpmYdc5 https://www.youtube.com/playlist?list=PLbcLsUBW9b3B0D2MrdXYyxT9kgADvHfIJ https://www.youtube.com/playlist?list=PLbcLsUBW9b3AgMxkiet3mnzspREWj6o54 https://www.youtube.com/playlist?list=PLbcLsUBW9b3BWCOmTz3PNNsH2B71h2EeR https://www.youtube.com/playlist?list=PLbcLsUBW9b3A-N-5701r8dhxstLqBQFKm https://www.youtube.com/playlist?list=PLbcLsUBW9b3CZAzppIH9EidEIIvNdZFsL https://www.youtube.com/playlist?list=PLbcLsUBW9b3B5DD8uXW0rJySgsqAeed1C https://www.youtube.com/playlist?list=PLbcLsUBW9b3DVprPwU4hHT73VdmmY45bc https://www.youtube.com/playlist?list=PLbcLsUBW9b3AcCrGgD04ryY6bnN8h7GSr https://www.youtube.com/playlist?list=PLbcLsUBW9b3COzIi5Rnl0F9yRZVR3tf_1 https://www.youtube.com/playlist?list=PLbcLsUBW9b3BHkhYBvNIlQknE-wpBT5vp https://www.youtube.com/playlist?list=PLbcLsUBW9b3AJVck8CCw35QGPYHxPXi-F &quot;&quot;&quot; . for url in urls.strip().split(&#39; n&#39;): !youtube-dl -i -o &#39;%(id)s.%(ext)s&#39; {url} .",
            "url": "https://jimregan.github.io/notes/irish/dataset/cula4/2021/08/21/download-cula4-ar-scoil-video.html",
            "relUrl": "/irish/dataset/cula4/2021/08/21/download-cula4-ar-scoil-video.html",
            "date": " • Aug 21, 2021"
        }
        
    
  
    
        ,"post172": {
            "title": "Download BBC Gaeilge clips",
            "content": "for i in range(1, 27): !youtube-dl -o &#39;%(id)s.%(ext)s&#39; &#39;https://www.bbc.co.uk/programmes/b007cpvp/clips?page={i}&#39; .",
            "url": "https://jimregan.github.io/notes/irish/dataset/bbc/2021/08/21/download-bbc-gaeilge-clips.html",
            "relUrl": "/irish/dataset/bbc/2021/08/21/download-bbc-gaeilge-clips.html",
            "date": " • Aug 21, 2021"
        }
        
    
  
    
        ,"post173": {
            "title": "Soundcloud - Raidio na Life",
            "content": "Original on Kaggle (private) . !pip install youtube-dl !youtube-dl https://soundcloud.com/rnl .",
            "url": "https://jimregan.github.io/notes/kaggle/irish/soundcloud/dataset/unlabelled/raidionalife/2021/08/01/soundcloud-raidio-na-life.html",
            "relUrl": "/kaggle/irish/soundcloud/dataset/unlabelled/raidionalife/2021/08/01/soundcloud-raidio-na-life.html",
            "date": " • Aug 1, 2021"
        }
        
    
  
    
        ,"post174": {
            "title": "Soundcloud - NÓS",
            "content": "Original on Kaggle (private) . !pip install youtube-dl !youtube-dl https://soundcloud.com/nosmag .",
            "url": "https://jimregan.github.io/notes/kaggle/irish/soundcloud/dataset/unlabelled/nos/2021/08/01/soundcloud-nos-pod.html",
            "relUrl": "/kaggle/irish/soundcloud/dataset/unlabelled/nos/2021/08/01/soundcloud-nos-pod.html",
            "date": " • Aug 1, 2021"
        }
        
    
  
    
        ,"post175": {
            "title": "Soundcloud - Cois Life",
            "content": "Original on Kaggle (private) . !pip install youtube-dl !youtube-dl https://soundcloud.com/cois-life-teoranta .",
            "url": "https://jimregan.github.io/notes/kaggle/irish/soundcloud/dataset/unlabelled/coislife/2021/08/01/soundcloud-cois-life.html",
            "relUrl": "/kaggle/irish/soundcloud/dataset/unlabelled/coislife/2021/08/01/soundcloud-cois-life.html",
            "date": " • Aug 1, 2021"
        }
        
    
  
    
        ,"post176": {
            "title": "Soundcloud - Club Leabhar",
            "content": "Original on Kaggle . !pip install youtube-dl !youtube-dl https://soundcloud.com/clubleabhar .",
            "url": "https://jimregan.github.io/notes/kaggle/irish/clubleabhar/dataset/unlabelled/2021/08/01/soundcloud-club-leabhar.html",
            "relUrl": "/kaggle/irish/clubleabhar/dataset/unlabelled/2021/08/01/soundcloud-club-leabhar.html",
            "date": " • Aug 1, 2021"
        }
        
    
  
    
        ,"post177": {
            "title": "Download Ros na Rún season 2",
            "content": "Original on Kaggle . %%capture !pip install youtube-dl . !youtube-dl -f bestaudio PLtVSQEQG0xVHeyao6vZyaY3kXGfbFFiAk .",
            "url": "https://jimregan.github.io/notes/kaggle/irish/rosnarun/dataset/unlabelled/2021/08/01/ros-na-run-s2.html",
            "relUrl": "/kaggle/irish/rosnarun/dataset/unlabelled/2021/08/01/ros-na-run-s2.html",
            "date": " • Aug 1, 2021"
        }
        
    
  
    
        ,"post178": {
            "title": "RnaG Podchraoltaí",
            "content": "!curl https://www.rte.ie/radio/rnag/articles/eolas/2021/0712/1234521-podchraoltai/|grep &#39;il/Download&lt;/a&gt;&#39;|awk -F&#39;href=&quot;&#39; &#39;{print $2}&#39;|awk -F&#39;&quot;&#39; &#39;{print $1}&#39;|sed -e &#39;s/http:/https:/&#39; &gt; urls !cat urls |while read i;do wget $(curl $i|grep &#39;&lt;enclosure&#39;|awk -F&#39;url=&quot;&#39; &#39;{print $2}&#39;|awk -F&#39;&quot;&#39; &#39;{print $1}&#39;);done . https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-adhmhaidin-adhmhaidin_c21985558_21985605_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-adhmhaidin-nuachtnisi_c21985559_21985606_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-adhmhaidin-nuachtande_c21985560_21985607_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-adhmhaidin-nuachtantu_c21985561_21985608_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-adhmhaidin-nuachtania_c21985562_21985609_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-adhmhaidin-promhscalt_c21985563_21985610_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-adhmhaidin-promhscalt_c21985564_21985611_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-adhmhaidin-drcolmhenr_c21985565_21985612_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-adhmhaidin-tomssochin_c21985566_21985613_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-adhmhaidin-gearidnnic_c21985567_21985614_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-adhmhaidin-murtcualin_c21985568_21985615_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-adhmhaidin-sendebuitl_c21985569_21985616_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-adhmhaidin-anthonymol_c21985570_21985617_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-adhmhaidin-eoincathai_c21985571_21985618_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-adhmhaidin-adhmhaidin_c21985442_21985543_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-adhmhaidin-nuachtnisi_c21985443_21985544_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-adhmhaidin-nuachtande_c21985445_21985546_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-adhmhaidin-promhscalt_c21985447_21985548_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-adhmhaidin-antuairisc_c21985448_21985549_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-adhmhaidin-gearidnnic_c21985449_21985550_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-adhmhaidin-jimkeoghat_c21985450_21985551_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-adhmhaidin-gearidtuat_c21985451_21985552_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-adhmhaidin-eoincathai_c21985452_21985553_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-adhmhaidin-catherinec_c21985453_21985554_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-adhmhaidin-sencadhain_c21985454_21985555_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-adhmhaidin-crnanighal_c21985455_21985556_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-adhmhaidin-samuscosam_c21985456_21985557_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-adhmhaidin-adhmhaidin_c21984630_21984658_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-adhmhaidin-nuachtnisi_c21984631_21984659_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-adhmhaidin-nuachtantu_c21984632_21984660_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-adhmhaidin-nuachtania_c21984633_21984661_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-adhmhaidin-nuachtande_c21984634_21984662_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-adhmhaidin-promhscalt_c21984635_21984663_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-adhmhaidin-antuairisc_c21984636_21984664_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-adhmhaidin-gearidnnic_c21984637_21984665_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-adhmhaidin-eoincathin_c21984638_21984666_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-adhmhaidin-dithdemrdh_c21984639_21984667_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-adhmhaidin-drciarnfea_c21984640_21984668_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-adhmhaidin-aengussnod_c21984641_21984669_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-adhmhaidin-johnshamui_c21984642_21984670_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-adhmhaidin-johnconnol_c21984643_21984671_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-adhmhaidin-adhmhaidin_c21984065_21984079_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-adhmhaidin-nuachtnisi_c21984066_21984080_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-adhmhaidin-nuachtande_c21984067_21984081_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-adhmhaidin-nuachtantu_c21984068_21984082_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-adhmhaidin-nuachtania_c21984069_21984083_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-adhmhaidin-promhscalt_c21984070_21984084_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-adhmhaidin-antuairisc_c21984071_21984085_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-adhmhaidin-eoincathin_c21984072_21984086_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-adhmhaidin-pilnnchiar_c21984073_21984087_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-adhmhaidin-breandnmac_c21984074_21984088_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-adhmhaidin-rnndomhnai_c21984075_21984089_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-adhmhaidin-thomasotoo_c21984076_21984090_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-adhmhaidin-francesnic_c21984077_21984091_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-adhmhaidin-mirnuchidi_c21984078_21984092_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-adhmhaidin-adhmhaidin_c21983518_21983580_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-adhmhaidin-nuachtnisi_c21983519_21983581_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-adhmhaidin-nuachtania_c21983520_21983582_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-adhmhaidin-nuachtande_c21983521_21983583_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-adhmhaidin-nuachtantu_c21983522_21983584_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-adhmhaidin-promhscalt_c21983523_21983585_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-adhmhaidin-antuairisc_c21983524_21983586_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-adhmhaidin-eoghancorr_c21983525_21983587_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-adhmhaidin-anthonydoo_c21983526_21983588_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-adhmhaidin-jasonmongi_c21983527_21983589_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-adhmhaidin-cathalseoi_c21983528_21983590_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-adhmhaidin-johndownin_c21983529_21983591_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-adhmhaidin-slinenchat_c21983530_21983592_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-adhmhaidin-seosaimhcu_c21983531_21983593_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-adhmhaidin-adhmhaidin_c21982311_21982326_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-adhmhaidin-nuachtnisi_c21982312_21982327_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-adhmhaidin-nuachtantu_c21982313_21982328_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-adhmhaidin-nuachtania_c21982314_21982329_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-adhmhaidin-nuachtande_c21982315_21982330_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-adhmhaidin-promhscalt_c21982316_21982331_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-adhmhaidin-antuairisc_c21982317_21982332_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-adhmhaidin-drniallcle_c21982318_21982333_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-adhmhaidin-eoincathin_c21982319_21982334_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-adhmhaidin-pidbrowneo_c21982320_21982335_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-adhmhaidin-niallmurch_c21982321_21982336_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-adhmhaidin-pilnnchiar_c21982322_21982337_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-adhmhaidin-kevinohara_c21982323_21982338_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-adhmhaidin-aindriasmu_c21982324_21982339_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-adhmhaidin-niallmuill_c21982325_21982340_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-adhmhaidin-adhmhaidin_c21981849_21981901_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-adhmhaidin-nuachtnisi_c21981850_21981902_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-adhmhaidin-nuachtande_c21981851_21981903_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-adhmhaidin-nuachtantu_c21981852_21981904_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-adhmhaidin-nuachtania_c21981853_21981905_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-adhmhaidin-promhscalt_c21981854_21981906_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-ansaolodheas-ansaoldhea_c21988383_21988390_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-ansaolodheas-malachamac_c21988384_21988391_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-ansaolodheas-cathalfian_c21988385_21988392_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-ansaolodheas-jacquidesi_c21988386_21988393_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-ansaolodheas-gearidnnic_c21988387_21988394_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-ansaolodheas-michelmacg_c21988388_21988395_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-ansaolodheas-aoifenchob_c21988389_21988396_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-ansaolodheas-ansaoldhea_c21987459_21987473_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-ansaolodheas-michelglia_c21987460_21987474_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-ansaolodheas-edelnloibh_c21987461_21987475_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-ansaolodheas-padalypdra_c21987462_21987476_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-ansaolodheas-dnalliathi_c21987463_21987477_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-ansaolodheas-caitlnbrea_c21987464_21987478_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-ansaolodheas-crthachfao_c21987465_21987479_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-ansaolodheas-ansaoldhea_c21987011_21987017_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-ansaolodheas-gearidnnic_c21987012_21987018_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-ansaolodheas-peadarriad_c21987013_21987019_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-ansaolodheas-niallluasa_c21987014_21987020_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-ansaolodheas-aoifenghra_c21987015_21987021_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-ansaolodheas-gearidnnic_c21987016_21987022_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0726/20210726_rteraidion-ansaolodheas-ansaoldhea_c21986466_21986472_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0726/20210726_rteraidion-ansaolodheas-michelmuir_c21986467_21986473_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0726/20210726_rteraidion-ansaolodheas-michelcrod_c21986468_21986474_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0726/20210726_rteraidion-ansaolodheas-diarmaiddu_c21986469_21986475_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0726/20210726_rteraidion-ansaolodheas-mikeosheac_c21986470_21986476_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0726/20210726_rteraidion-ansaolodheas-valeriench_c21986471_21986477_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-ansaolodheas-ansaoldhea_c21985661_21985682_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-ansaolodheas-pdraigcear_c21985662_21985683_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-ansaolodheas-niamhndhri_c21985663_21985684_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-ansaolodheas-ritanbheag_c21985664_21985685_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-ansaolodheas-breandncob_c21985665_21985686_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-ansaolodheas-michelcrod_c21985666_21985687_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-ansaolodheas-aoifenchob_c21985667_21985688_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-ansaolodheas-ansaoldhea_c21985439_21985441_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-ansaolodheas-ansaoldhea_c21984759_21984765_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-ansaolodheas-johndownin_c21984760_21984766_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-ansaolodheas-nramarianm_c21984761_21984767_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-ansaolodheas-mirtnmacio_c21984762_21984768_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-ansaolodheas-samusciobh_c21984763_21984769_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-ansaolodheas-diarmuiddo_c21984764_21984770_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-ansaolodheas-ansaoldhea_c21984294_21984300_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-ansaolodheas-liamrchinl_c21984295_21984301_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-ansaolodheas-macdaramac_c21984296_21984302_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-ansaolodheas-donnchafia_c21984297_21984303_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-ansaolodheas-johngoduib_c21984298_21984304_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-ansaolodheas-pdraigcdri_c21984299_21984305_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-ansaolodheas-ansaoldhea_c21983702_21983707_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-ansaolodheas-michelmuir_c21983703_21983708_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-ansaolodheas-senceallai_c21983704_21983709_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-ansaolodheas-seghansuil_c21983705_21983710_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-ansaolodheas-miresebrea_c21983706_21983711_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0716/20210716_rteraidion-ansaolodheas-ansaoldhea_c21983345_21983346_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-ansaolodheas-ansaoldhea_c21982591_21982593_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-ansaolodheas-ansaoldhea_c21982052_21982073_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-ansaolodheas-senlionird_c21982053_21982074_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-ansaolodheas-slenchonai_c21982054_21982075_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-ansaolodheas-fredanicgi_c21982055_21982076_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-ansaolodheas-ruthnriada_c21982056_21982077_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-ansaolodheas-deirdrenic_c21982057_21982078_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-ansaolodheas-liambeagla_c21982058_21982079_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0713/20210713_rteraidion-ansaolodheas-ansaoldhea_c21981432_21981438_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0713/20210713_rteraidion-ansaolodheas-breandnmac_c21981433_21981439_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0713/20210713_rteraidion-ansaolodheas-samusdrisc_c21981434_21981440_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0713/20210713_rteraidion-ansaolodheas-mireniccra_c21981435_21981441_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0713/20210713_rteraidion-ansaolodheas-breandnbea_c21981436_21981442_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0713/20210713_rteraidion-ansaolodheas-michelceal_c21981437_21981443_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-ansaolodheas-ansaoldhea_c21980962_21980968_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-ansaolodheas-dithdemord_c21980963_21980969_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-ansaolodheas-padalytdbe_c21980964_21980970_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-ansaolodheas-andreapala_c21980965_21980971_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-ansaolodheas-mabhuainif_c21980966_21980972_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-ansaolodheas-michelcinn_c21980967_21980973_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-ansaolodheas-ansaolodhe_c21980827_21980839_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-ansaolodheas-deaglnragi_c21980828_21980840_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-ansaolodheas-aoifenchro_c21980829_21980841_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-ansaolodheas-ineuchuill_c21980830_21980842_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-ansaolodheas-amonnbraon_c21980831_21980843_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-ansaolodheas-oifenchobh_c21980832_21980844_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0708/20210708_rteraidion-ansaolodheas-ansaoldhea_c21979524_21979531_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0708/20210708_rteraidion-ansaolodheas-dnalgruagi_c21979525_21979532_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0708/20210708_rteraidion-ansaolodheas-angelaughr_c21979526_21979533_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0708/20210708_rteraidion-ansaolodheas-johnkenned_c21979527_21979534_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0708/20210708_rteraidion-ansaolodheas-sensilleab_c21979528_21979535_232_drm_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0708/20210708_rteraidion-ansaolodheas-ruthnriada_c21979529_21979536_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0708/20210708_rteraidion-ansaolodheas-drbreandnc_c21979530_21979537_232_drm_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0707/20210707_rteraidion-ansaolodheas-ansaoldhea_c21979272_21979273_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0706/20210706_rteraidion-ansaolodheas-ansaoldhea_c21978234_21978239_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0706/20210706_rteraidion-ansaolodheas-antathairc_c21978235_21978240_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0706/20210706_rteraidion-ansaolodheas-macdaramac_c21978236_21978241_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0706/20210706_rteraidion-ansaolodheas-sensuillea_c21978237_21978242_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-barrscealta-barrscalta_c21988305_21988432_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-barrscealta-inenbhreis_c21988306_21988433_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-barrscealta-nicolanbha_c21988307_21988434_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-barrscealta-marybnmhic_c21988308_21988435_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-barrscealta-ciarnrabha_c21988309_21988436_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-barrscealta-lorcnmirtn_c21988310_21988437_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-barrscealta-eimearngha_c21988311_21988438_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-barrscealta-maryaggiea_c21988312_21988439_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-barrscealta-barrscalta_c21987865_21987872_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-barrscealta-pilnnicgei_c21987866_21987873_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-barrscealta-andrteaghl_c21987867_21987874_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-barrscealta-michealdui_c21987868_21987875_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-barrscealta-conalldomh_c21987869_21987876_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-barrscealta-fearnaromh_c21987870_21987877_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-barrscealta-geneeoghai_c21987871_21987878_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-barrscealta-barrscalta_c21987378_21987385_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-barrscealta-inenbhreis_c21987379_21987386_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-barrscealta-michelhean_c21987380_21987387_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-barrscealta-aoifenicse_c21987381_21987388_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-barrscealta-taynanicga_c21987382_21987389_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-barrscealta-anradomhna_c21987383_21987390_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-barrscealta-antathaire_c21987384_21987391_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-barrscealta-barrscalta_c21986924_21986930_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-barrscealta-inenbhreis_c21986925_21986931_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-barrscealta-ancomhairl_c21986926_21986932_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-barrscealta-edwardmaol_c21986927_21986933_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-barrscealta-ansirsintj_c21986928_21986934_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-barrscealta-sylvesterm_c21986929_21986935_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-barrscealta-barrscalta_c21985619_21985696_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-barrscealta-francesnic_c21985620_21985697_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-barrscealta-caitlnnbhr_c21985621_21985698_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-barrscealta-deirdrenbh_c21985622_21985699_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-barrscealta-eoghanmacg_c21985623_21985700_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-barrscealta-gearidnnic_c21985624_21985701_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-barrscealta-slenfhearr_c21985625_21985702_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-barrscealta-maryaggiea_c21985626_21985703_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-barrscealta-barrscalta_c21985027_21985033_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-barrscealta-maighradua_c21985028_21985034_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-barrscealta-andrteaghl_c21985029_21985035_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-barrscealta-anteachtad_c21985030_21985036_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-barrscealta-cathalmacs_c21985031_21985037_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-barrscealta-fearnaromh_c21985032_21985038_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-barrscealta-barrscalta_c21984708_21984715_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-barrscealta-francesnic_c21984709_21984716_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-barrscealta-antathairb_c21984710_21984717_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-barrscealta-marjorienc_c21984711_21984718_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-barrscealta-siobhnocon_c21984712_21984719_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-barrscealta-annienmhio_c21984713_21984720_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-barrscealta-dianenchan_c21984714_21984721_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-barrscealta-pilnnicgid_c21984183_21984190_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-barrscealta-paddybrown_c21984184_21984191_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-barrscealta-ansirsintj_c21984185_21984192_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-barrscealta-willieghri_c21984186_21984193_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-barrscealta-rnndochart_c21984187_21984194_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-barrscealta-dnallceall_c21984188_21984195_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-barrscealta-barrscalta_c21983753_21983759_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-barrscealta-nascaltanu_c21983754_21983760_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-barrscealta-msdoogiedu_c21983755_21983761_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-barrscealta-turasireac_c21983756_21983762_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-barrscealta-sriantasli_c21983757_21983763_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-barrscealta-crsaspirtl_c21983758_21983764_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0716/20210716_rteraidion-barrscealta-barrscalta_c21982973_21982979_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0716/20210716_rteraidion-barrscealta-maighradua_c21982974_21982980_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0716/20210716_rteraidion-barrscealta-eilsndhoch_c21982975_21982981_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0716/20210716_rteraidion-barrscealta-antdarsenc_c21982976_21982982_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0716/20210716_rteraidion-barrscealta-maryaggiea_c21982977_21982983_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0716/20210716_rteraidion-barrscealta-charliever_c21982978_21982984_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-barrscealta-barrscalta_c21982443_21982450_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-barrscealta-pilnnicgid_c21982444_21982451_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-barrscealta-andrteaghl_c21982445_21982452_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-barrscealta-anteachtad_c21982446_21982453_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-barrscealta-caoimhnbao_c21982447_21982454_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-barrscealta-ancomhairl_c21982448_21982455_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-barrscealta-ciaranstii_c21982449_21982456_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-barrscealta-scaltanuac_c21980995_21981010_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-barrscealta-mrturasire_c21980996_21981011_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-barrscealta-kayleighnm_c21980997_21981012_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-barrscealta-antathairm_c21980998_21981013_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-barrscealta-nacluichga_c21980999_21981014_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-barrscealta-barrscalta_c21980223_21980230_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-barrscealta-pilnnicgid_c21980224_21980231_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-barrscealta-dnallcnimh_c21980225_21980232_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-barrscealta-conorgallc_c21980226_21980233_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-barrscealta-patriciada_c21980227_21980234_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-barrscealta-dannydomhn_c21980228_21980235_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-barrscealta-maryaggiea_c21980229_21980236_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0708/20210708_rteraidion-barrscealta-barrscalta_c21979436_21979442_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0708/20210708_rteraidion-barrscealta-francesnic_c21979437_21979443_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0708/20210708_rteraidion-barrscealta-annabeanug_c21979438_21979444_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0708/20210708_rteraidion-barrscealta-andrteaghl_c21979439_21979445_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0604/20210604_rteraidion-bladhairernag-igecilleac_c21963252_21963259_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0604/20210604_rteraidion-bladhairernag-jessiesmit_c21963253_21963260_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0604/20210604_rteraidion-bladhairernag-ancraoltir_c21963256_21963263_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0604/20210604_rteraidion-bladhairernag-johnfearra_c21963257_21963264_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0604/20210604_rteraidion-bladhairernag-michaelcur_c21963316_21963324_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0603/20210603_rteraidion-bladhairernag-filenageal_c21962703_21963068_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0603/20210603_rteraidion-bladhairernag-jamiesugru_c21962705_21963070_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0603/20210603_rteraidion-bladhairernag-eimearmcgo_c21962706_21963071_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0603/20210603_rteraidion-bladhairernag-marcusmacc_c21962707_21963072_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0528/20210528_rteraidion-bladhairernag-nadescalta_c21959922_21959928_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0528/20210528_rteraidion-bladhairernag-leahndhoch_c21959924_21959930_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0528/20210528_rteraidion-bladhairernag-conorbrumm_c21959925_21959931_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0528/20210528_rteraidion-bladhairernag-conormaccr_c21959926_21959932_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0527/20210527_rteraidion-bladhairernag-susancolem_c21959338_21959344_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0527/20210527_rteraidion-bladhairernag-ilsndhuibh_c21959339_21959345_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0527/20210527_rteraidion-bladhairernag-deirdrench_c21959340_21959346_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0527/20210527_rteraidion-bladhairernag-namonaghan_c21959341_21959347_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0527/20210527_rteraidion-bladhairernag-diarmuidma_c21959342_21959348_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0521/20210521_rteraidion-bladhairernag-nadescalta_c21956962_21957052_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0521/20210521_rteraidion-bladhairernag-clarenchea_c21956964_21957054_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0521/20210521_rteraidion-bladhairernag-pamelapren_c21956965_21957055_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0521/20210521_rteraidion-bladhairernag-gaeltharsi_c21956966_21957056_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0520/20210520_rteraidion-bladhairernag-lisanicanb_c21956281_21956288_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0520/20210520_rteraidion-bladhairernag-comrtasnag_c21956282_21956289_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0520/20210520_rteraidion-bladhairernag-taiscevint_c21956283_21956290_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0520/20210520_rteraidion-bladhairernag-richieconr_c21956284_21956291_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0520/20210520_rteraidion-bladhairernag-tessaflemi_c21956285_21956292_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0520/20210520_rteraidion-bladhairernag-rosienghai_c21956286_21956293_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0514/20210514_rteraidion-bladhairernag-bladhairec_c21954020_21954027_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0514/20210514_rteraidion-bladhairernag-nadescalta_c21954021_21954028_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0514/20210514_rteraidion-bladhairernag-ceolbeobil_c21954022_21954029_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0514/20210514_rteraidion-bladhairernag-edelnbhrao_c21954023_21954030_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0514/20210514_rteraidion-bladhairernag-pdraigcong_c21954024_21954031_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0514/20210514_rteraidion-bladhairernag-mrteilifse_c21954025_21954032_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0514/20210514_rteraidion-bladhairernag-claresands_c21954026_21954033_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0513/20210513_rteraidion-bladhairernag-bladhairec_c21953402_21953408_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0513/20210513_rteraidion-bladhairernag-filenascco_c21953403_21953409_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0513/20210513_rteraidion-bladhairernag-aoisachath_c21953404_21953410_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0513/20210513_rteraidion-bladhairernag-claramurra_c21953405_21953411_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0513/20210513_rteraidion-bladhairernag-franktorma_c21953406_21953412_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0513/20210513_rteraidion-bladhairernag-gearidcobh_c21953407_21953413_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0507/20210507_rteraidion-bladhairernag-bladhairec_c21950931_21951100_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0507/20210507_rteraidion-bladhairernag-nadescalta_c21950932_21951101_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0507/20210507_rteraidion-bladhairernag-aoisachath_c21950933_21951102_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0507/20210507_rteraidion-bladhairernag-mrceoilemm_c21950934_21951103_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0507/20210507_rteraidion-bladhairernag-cultrlannm_c21950935_21951104_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0507/20210507_rteraidion-bladhairernag-comhdhilna_c21950936_21951105_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0506/20210506_rteraidion-bladhairernag-bladhairec_c21950342_21950351_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0506/20210506_rteraidion-bladhairernag-deirdrendh_c21950343_21950352_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0506/20210506_rteraidion-bladhairernag-comrtasnab_c21950344_21950353_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0506/20210506_rteraidion-bladhairernag-branmacglo_c21950345_21950354_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0506/20210506_rteraidion-bladhairernag-ceolbeomar_c21950346_21950355_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0506/20210506_rteraidion-bladhairernag-buachailln_c21950347_21950356_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0506/20210506_rteraidion-bladhairernag-ceolbeomar_c21950348_21950357_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0506/20210506_rteraidion-bladhairernag-pdraigjack_c21950349_21950358_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0506/20210506_rteraidion-bladhairernag-ceolbeocat_c21950350_21950359_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0430/20210430_rteraidion-bladhairernag-bladhairec_c21948145_21948153_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0430/20210430_rteraidion-bladhairernag-nadescalta_c21948146_21948154_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0430/20210430_rteraidion-bladhairernag-jonnydillo_c21948147_21948155_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0430/20210430_rteraidion-bladhairernag-diarmuidma_c21948148_21948156_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0430/20210430_rteraidion-bladhairernag-geariddris_c21948149_21948157_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0430/20210430_rteraidion-bladhairernag-paddyglack_c21948150_21948158_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0430/20210430_rteraidion-bladhairernag-cianmaonla_c21948151_21948159_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0430/20210430_rteraidion-bladhairernag-aonachmhac_c21948152_21948160_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0429/20210429_rteraidion-bladhairernag-bladhairec_c21947633_21947911_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0429/20210429_rteraidion-bladhairernag-seoirsnnmh_c21947634_21947912_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0429/20210429_rteraidion-bladhairernag-aoisachath_c21947635_21947913_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0429/20210429_rteraidion-bladhairernag-darraghcao_c21947636_21947914_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0429/20210429_rteraidion-bladhairernag-brdnfoxant_c21947637_21947915_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0429/20210429_rteraidion-bladhairernag-muireannni_c21947638_21947916_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0429/20210429_rteraidion-bladhairernag-nascoilnas_c21947639_21947917_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0423/20210423_rteraidion-bladhairernag-bladhairec_c21943846_21943852_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0423/20210423_rteraidion-bladhairernag-hughmacgio_c21943847_21943853_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0423/20210423_rteraidion-bladhairernag-helendiamo_c21943848_21943854_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0423/20210423_rteraidion-bladhairernag-eoinmuirch_c21943849_21943855_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0423/20210423_rteraidion-bladhairernag-ruthnicaoi_c21943850_21943856_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0423/20210423_rteraidion-bladhairernag-risnagusei_c21943851_21943857_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0422/20210422_rteraidion-bladhairernag-bladhairec_c21943159_21943166_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0422/20210422_rteraidion-bladhairernag-mollyheste_c21943160_21943167_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0422/20210422_rteraidion-bladhairernag-garrymacdo_c21943161_21943168_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0422/20210422_rteraidion-bladhairernag-culchaintl_c21943162_21943169_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0422/20210422_rteraidion-bladhairernag-ciaraoconn_c21943163_21943170_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0422/20210422_rteraidion-bladhairernag-gaeltharsi_c21943164_21943171_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0422/20210422_rteraidion-bladhairernag-andrcillia_c21943165_21943172_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0416/20210416_rteraidion-bladhairernag-bladhairec_c21940555_21940562_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0416/20210416_rteraidion-bladhairernag-juliejayna_c21940556_21940563_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0416/20210416_rteraidion-bladhairernag-aoisachath_c21940557_21940564_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0416/20210416_rteraidion-bladhairernag-bhalnamban_c21940558_21940565_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0416/20210416_rteraidion-bladhairernag-paulinesca_c21940559_21940566_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0416/20210416_rteraidion-bladhairernag-gaeltharsi_c21940560_21940567_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0725/20210725_rteraidion-cartlannbhothar-citpheatsa_c21986304_21986305_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0718/20210718_rteraidion-cartlannbhothar-katepheats_c21984168_21984169_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0711/20210711_rteraidion-cartlannbhothar-mirencheoc_c21981051_21981052_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0627/20210627_rteraidion-cartlannbhothar-cartlannbh_c21974782_21974852_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0620/20210620_rteraidion-cartlannbhothar-cartlannbh_c21971339_21972928_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0620/20210620_rteraidion-cartlannbhothar-samuspound_c21971340_21972929_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0620/20210620_rteraidion-cartlannbhothar-muirisgogc_c21971341_21972930_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0620/20210620_rteraidion-cartlannbhothar-seanchasan_c21971342_21972931_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0613/20210613_rteraidion-cartlannbhothar-cartlannbh_c21967487_21967522_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0606/20210606_rteraidion-cartlannbhothar-leabharanp_c21965134_21965135_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0530/20210530_rteraidion-cartlannbhothar-clriomln30_c21961256_21961259_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0530/20210530_rteraidion-cartlannbhothar-nracitinna_c21961257_21961260_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0530/20210530_rteraidion-cartlannbhothar-nrauchoiti_c21961258_21961261_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0523/20210523_rteraidion-cartlannbhothar-cartlannbh_c21957611_21957615_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0523/20210523_rteraidion-cartlannbhothar-tadhgdrisc_c21957612_21957616_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0523/20210523_rteraidion-cartlannbhothar-michelmaol_c21957613_21957617_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0523/20210523_rteraidion-cartlannbhothar-annradeblc_c21957614_21957618_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0516/20210516_rteraidion-cartlannbhothar-cartlannbh_c21954551_21954552_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0509/20210509_rteraidion-cartlannbhothar-cartlannbh_c21951494_21951647_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0425/20210425_rteraidion-cartlannbhothar-cartlannbh_c21945215_21945216_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0418/20210418_rteraidion-cartlannbhothar-clriomln18_c21941195_21941196_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0404/20210404_rteraidion-cartlannbhothar-cartlannbh_c21934559_21934560_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0321/20210321_rteraidion-cartlannbhothar-cartlannbh_c21927145_21927146_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0314/20210314_rteraidion-cartlannbhothar-cartlannbh_c21924362_21924363_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0221/20210221_rteraidion-cartlannbhothar-cartlannbh_c21913398_21913399_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0207/20210207_rteraidion-cartlannbhothar-cartlannbh_c21907422_21907423_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0117/20210117_rteraidion-cartlannbhothar-cuasabhoda_c21894664_21894665_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/1230/20201230_rteraidion-cartlannbhothar-cartlannbh_c21888929_21888933_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/1230/20201230_rteraidion-cartlannbhothar-tommhicgro_c21888930_21888934_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/1230/20201230_rteraidion-cartlannbhothar-siobhngrom_c21888931_21888935_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/1230/20201230_rteraidion-cartlannbhothar-peigsayers_c21888932_21888936_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/1220/20201220_rteraidion-cartlannbhothar-cartlannbh_c21886239_21886240_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/1025/20201025_rteraidion-cartlannbhothar-clriomln25_c21856360_21856365_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/1025/20201025_rteraidion-cartlannbhothar-dnallliath_c21856361_21856366_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/1025/20201025_rteraidion-cartlannbhothar-plarluacha_c21856362_21856367_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/1025/20201025_rteraidion-cartlannbhothar-simcionnfh_c21856363_21856368_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/1025/20201025_rteraidion-cartlannbhothar-sendehra_c21856364_21856369_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/1018/20201018_rteraidion-cartlannbhothar-cartlannbh_c21854576_21854577_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/1011/20201011_rteraidion-cartlannbhothar-cartlannbh_c21849866_21849867_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/0927/20200927_rteraidion-cartlannbhothar-cartlannbh_c21842121_21842122_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/0920/20200920_rteraidion-cartlannbhothar-cartlannbh_c21837633_21837637_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/0920/20200920_rteraidion-cartlannbhothar-cearnaigha_c21837634_21837638_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/0920/20200920_rteraidion-cartlannbhothar-mirenshcai_c21837635_21837639_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2020/0920/20200920_rteraidion-cartlannbhothar-donnchasha_c21837636_21837640_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-irisaniar-irisaniard_c21988256_21988263_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-irisaniar-andrneasan_c21988260_21988264_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-irisaniar-michaelfra_c21988261_21988265_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0730/20210730_rteraidion-irisaniar-senbnbreat_c21988262_21988266_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-irisaniar-irisaniard_c21987809_21987816_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-irisaniar-caomhnmacc_c21987811_21987817_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-irisaniar-deborahugh_c21987812_21987818_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-irisaniar-barrafthar_c21987813_21987819_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-irisaniar-pidtombnbr_c21987814_21987820_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-irisaniar-senbnbreat_c21987815_21987821_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-irisaniar-irisaniard_c21987335_21987342_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-irisaniar-mirnurinne_c21987336_21987343_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-irisaniar-angardabib_c21987337_21987344_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-irisaniar-bernienche_c21987338_21987345_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-irisaniar-senbnbreat_c21987339_21987346_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-irisaniar-aifrickeog_c21987341_21987347_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-irisaniar-tomsmaccon_c21986984_21986993_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-irisaniar-senbnbreat_c21986985_21986994_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0726/20210726_rteraidion-irisaniar-jimkeoghat_c21986327_21986332_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0726/20210726_rteraidion-irisaniar-breanndnbe_c21986328_21986333_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0726/20210726_rteraidion-irisaniar-chloenmhil_c21986329_21986334_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0726/20210726_rteraidion-irisaniar-senbnbreat_c21986330_21986335_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-irisaniar-irisaniard_c21984136_21984146_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-irisaniar-michelsmac_c21984137_21984147_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-irisaniar-desmondfen_c21984141_21984148_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-irisaniar-maryseoigh_c21984145_21984149_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-irisaniar-antollamhc_c21982413_21982417_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-irisaniar-michelsmac_c21982414_21982418_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-irisaniar-siobhnngha_c21982415_21982419_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-irisaniar-angardamic_c21982416_21982420_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-irisaniar-antiriseoi_c21981925_21981928_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-irisaniar-tomsruairc_c21981926_21981929_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-irisaniar-jenniferni_c21981927_21981930_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0713/20210713_rteraidion-irisaniar-endacongha_c21981362_21981365_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0713/20210713_rteraidion-irisaniar-bredanmhui_c21981363_21981366_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0713/20210713_rteraidion-irisaniar-bairbrenic_c21981364_21981367_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-irisaniar-geariddevn_c21980815_21980818_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-irisaniar-ritagibbon_c21980816_21980819_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-irisaniar-donnchamac_c21980817_21980820_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0702/20210702_rteraidion-irisaniar-irisaniard_c21976845_21976851_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0702/20210702_rteraidion-irisaniar-mairadfarr_c21976846_21976852_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0702/20210702_rteraidion-irisaniar-franorourk_c21976847_21976853_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0702/20210702_rteraidion-irisaniar-deirdrendh_c21976850_21976854_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0701/20210701_rteraidion-irisaniar-irisaniard_c21976185_21976215_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0701/20210701_rteraidion-irisaniar-deirdrensh_c21976211_21976216_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0701/20210701_rteraidion-irisaniar-pdraigmacd_c21976212_21976217_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0701/20210701_rteraidion-irisaniar-darachtuai_c21976213_21976218_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0701/20210701_rteraidion-irisaniar-muireannnd_c21976214_21976219_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0630/20210630_rteraidion-irisaniar-irisaniard_c21975584_21975593_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0630/20210630_rteraidion-irisaniar-breandnseo_c21975587_21975594_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0630/20210630_rteraidion-irisaniar-angardasti_c21975591_21975595_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0630/20210630_rteraidion-irisaniar-bridgebark_c21975592_21975596_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0625/20210625_rteraidion-irisaniar-antathairp_c21974114_21974115_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0623/20210623_rteraidion-irisaniar-pdraigloid_c21973019_21973024_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0623/20210623_rteraidion-irisaniar-colmanragh_c21973020_21973025_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0623/20210623_rteraidion-irisaniar-mairadmacc_c21973021_21973026_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0623/20210623_rteraidion-irisaniar-louisendhi_c21973022_21973027_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0623/20210623_rteraidion-irisaniar-annemarieu_c21973023_21973028_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0622/20210622_rteraidion-irisaniar-cilnneacht_c21972408_21972413_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0622/20210622_rteraidion-irisaniar-johnconnol_c21972409_21972414_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0622/20210622_rteraidion-irisaniar-ruairnillb_c21972410_21972415_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0622/20210622_rteraidion-irisaniar-inenfhgart_c21972411_21972416_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0622/20210622_rteraidion-irisaniar-samusrchin_c21972412_21972417_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0618/20210618_rteraidion-irisaniar-colmcuaiga_c21969857_21969862_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0618/20210618_rteraidion-irisaniar-brianstaun_c21969858_21969863_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0618/20210618_rteraidion-irisaniar-mirtncathi_c21969859_21969864_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0618/20210618_rteraidion-irisaniar-frankfahyc_c21969860_21969865_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0617/20210617_rteraidion-irisaniar-johnbhabaj_c21969299_21969318_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0617/20210617_rteraidion-irisaniar-fergusmacs_c21969300_21969319_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0617/20210617_rteraidion-irisaniar-donnchahal_c21969301_21969320_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0617/20210617_rteraidion-irisaniar-aislingnic_c21969302_21969321_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0616/20210616_rteraidion-irisaniar-mireumhaol_c21968788_21968792_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0616/20210616_rteraidion-irisaniar-orladebrca_c21968789_21968793_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0616/20210616_rteraidion-irisaniar-angardasal_c21968790_21968794_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0615/20210615_rteraidion-irisaniar-daramaoild_c21968302_21968307_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0615/20210615_rteraidion-irisaniar-emernrogin_c21968303_21968308_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0615/20210615_rteraidion-irisaniar-mirenneach_c21968304_21968309_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0615/20210615_rteraidion-irisaniar-edelnchurr_c21968305_21968310_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0614/20210614_rteraidion-irisaniar-samusbreat_c21967529_21967533_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0614/20210614_rteraidion-irisaniar-daramcgees_c21967530_21967534_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0611/20210611_rteraidion-irisaniar-aoifepower_c21966698_21966703_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0611/20210611_rteraidion-irisaniar-barryfthar_c21966699_21966704_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0611/20210611_rteraidion-irisaniar-lasairfhon_c21966700_21966705_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0611/20210611_rteraidion-irisaniar-andrsiobhn_c21966701_21966706_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0611/20210611_rteraidion-irisaniar-martndonnc_c21966702_21966707_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0610/20210610_rteraidion-irisaniar-inenchiari_c21966108_21966111_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0610/20210610_rteraidion-irisaniar-senhanaigh_c21966109_21966112_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0610/20210610_rteraidion-irisaniar-gearidcrib_c21966110_21966113_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0608/20210608_rteraidion-irisaniar-mireineuai_c21964956_21964960_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0608/20210608_rteraidion-irisaniar-cilliandon_c21964957_21964961_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-tusaite-tsite29721_c21988022_21988036_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-tusaite-tsitetuara_c21988023_21988037_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-tusaite-tsitepolai_c21988024_21988038_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-tusaite-tsiterbuai_c21988025_21988039_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-tusaite-tsitecscir_c21988026_21988040_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-tusaite-tsitemrnal_c21988027_21988041_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0729/20210729_rteraidion-tusaite-tsitemrnan_c21988028_21988042_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-tusaite-tsite28721_c21987525_21987533_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-tusaite-tsitenasco_c21987526_21987534_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-tusaite-tsitepolai_c21987527_21987535_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-tusaite-tsiteceapa_c21987528_21987536_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-tusaite-tsitegarch_c21987529_21987537_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-tusaite-tsitejoeca_c21987530_21987538_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-tusaite-tsiteansca_c21987531_21987539_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0728/20210728_rteraidion-tusaite-tsitemrnam_c21987532_21987540_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-tusaite-tsite27721_c21987049_21987054_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-tusaite-tsitepolai_c21987050_21987055_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-tusaite-tsitevacsa_c21987051_21987056_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-tusaite-tsitecosdo_c21987052_21987057_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0727/20210727_rteraidion-tusaite-tsiteanpai_c21987053_21987058_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0726/20210726_rteraidion-tusaite-tsite26721_c21986532_21986536_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0726/20210726_rteraidion-tusaite-tsiteathos_c21986533_21986537_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0726/20210726_rteraidion-tusaite-tsitevacsa_c21986534_21986538_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0726/20210726_rteraidion-tusaite-tsitebagai_c21986535_21986539_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-tusaite-tsite23721_c21985898_21985905_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-tusaite-tsitepolai_c21985899_21985906_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-tusaite-tsitetreoi_c21985900_21985907_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-tusaite-tsitefiosr_c21985901_21985908_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-tusaite-tsitesilsi_c21985902_21985909_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-tusaite-tsitescalt_c21985903_21985910_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0723/20210723_rteraidion-tusaite-tsitecrsas_c21985904_21985911_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-tusaite-tsite22721_c21985214_21985221_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-tusaite-tsitepolai_c21985215_21985222_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-tusaite-tsitedeacr_c21985216_21985223_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-tusaite-tsitenuach_c21985217_21985224_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-tusaite-tsitecluic_c21985218_21985225_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-tusaite-tsiteleasu_c21985219_21985226_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0722/20210722_rteraidion-tusaite-tsitemrnan_c21985220_21985227_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-tusaite-tsite21721_c21984807_21984814_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-tusaite-tsitepolai_c21984808_21984815_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-tusaite-tsitebsdes_c21984809_21984816_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-tusaite-tsiteathos_c21984810_21984817_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-tusaite-tsiteleasu_c21984811_21984818_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-tusaite-tsitemrnam_c21984812_21984819_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0721/20210721_rteraidion-tusaite-tsitemrnal_c21984813_21984820_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-tusaite-tsite20721_c21984357_21984363_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-tusaite-tsitedeaai_c21984358_21984364_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-tusaite-tsitepolai_c21984359_21984365_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-tusaite-tsitereach_c21984360_21984366_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-tusaite-tsiteancoi_c21984361_21984367_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0720/20210720_rteraidion-tusaite-tsiteanpai_c21984362_21984368_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-tusaite-tsite19721_c21983790_21983795_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-tusaite-tsitemaols_c21983791_21983796_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-tusaite-tsitedeire_c21983792_21983797_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-tusaite-tsiteeasao_c21983793_21983798_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0719/20210719_rteraidion-tusaite-tsitebsdea_c21983794_21983799_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0716/20210716_rteraidion-tusaite-tsite16721_c21983160_21983166_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0716/20210716_rteraidion-tusaite-tsitepolai_c21983161_21983167_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0716/20210716_rteraidion-tusaite-tsiteceart_c21983162_21983168_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0716/20210716_rteraidion-tusaite-tsitesilsi_c21983163_21983169_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0716/20210716_rteraidion-tusaite-tsitescalt_c21983164_21983170_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0716/20210716_rteraidion-tusaite-tsitecrsas_c21983165_21983171_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-tusaite-tsite15721_c21982632_21982639_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-tusaite-tsitepolai_c21982633_21982640_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-tusaite-tsitelonna_c21982634_21982641_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-tusaite-tsitedroch_c21982635_21982642_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-tusaite-tsitemrnal_c21982636_21982643_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-tusaite-tsitemrnan_c21982637_21982644_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0715/20210715_rteraidion-tusaite-tsitedeaai_c21982638_21982645_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-tusaite-tsite14721_c21982121_21982127_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-tusaite-tsitepolai_c21982122_21982128_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-tusaite-tsiteconco_c21982123_21982129_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-tusaite-tsitereach_c21982124_21982130_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-tusaite-tsitetarma_c21982125_21982131_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0714/20210714_rteraidion-tusaite-tsitemrnam_c21982126_21982132_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0713/20210713_rteraidion-tusaite-tsite13721_c21981552_21981558_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0713/20210713_rteraidion-tusaite-tsitepolai_c21981553_21981559_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0713/20210713_rteraidion-tusaite-tsiteathos_c21981554_21981560_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0713/20210713_rteraidion-tusaite-tsitebreat_c21981555_21981561_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0713/20210713_rteraidion-tusaite-tsitesaigh_c21981556_21981562_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0713/20210713_rteraidion-tusaite-tsiteanpai_c21981557_21981563_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-tusaite-tsite12721_c21981073_21981093_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-tusaite-tsiteathos_c21981074_21981094_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-tusaite-tsitestdas_c21981075_21981095_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-tusaite-tsiteandar_c21981076_21981096_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-tusaite-tsitenaeur_c21981077_21981097_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-tusaite-tsite9721_c21980451_21980457_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-tusaite-tsitefotho_c21980452_21980458_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-tusaite-tsitepolai_c21980453_21980459_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0709/20210709_rteraidion-tusaite-tsitesilsi_c21980454_21980460_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0706/20210706_rteraidion-ancheadghluineile-clr3tinnch_c21978343_21978617_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0629/20210629_rteraidion-ancheadghluineile-clr2aedrae_c21977827_21977828_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0622/20210622_rteraidion-ancheadghluineile-clr1evelyn_c21973179_21975128_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-aistionaer-antidsceas_c21985799_21985809_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-aistionaer-oilithreac_c21985800_21985810_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-aistionaer-seandaoine_c21985801_21985811_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-aistionaer-mchmagusla_c21985802_21985812_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0712/20210712_rteraidion-aistionaer-seanlitrea_c21985803_21985813_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0724/20210724_rteraidion-bailiuchanbhairbre-bailichnbh_c21986295_21986296_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0717/20210717_rteraidion-bailiuchanbhairbre-clr6cuairt_c21984170_21984171_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0710/20210710_rteraidion-bailiuchanbhairbre-clr5btharg_c21981049_21981050_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0703/20210703_rteraidion-bailiuchanbhairbre-clr4anscoi_c21977529_21977530_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0626/20210626_rteraidion-bailiuchanbhairbre-bailichnbh_c21974765_21975131_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0619/20210619_rteraidion-bailiuchanbhairbre-bailichnbh_c21971319_21975130_232_.mp3 https://podcast.rasset.ie/podcasts/audio/2021/0612/20210612_rteraidion-bailiuchanbhairbre-bailichnbh_c21967481_21975129_232_.mp3 .",
            "url": "https://jimregan.github.io/notes/irish/kaggle/dataset/2021/08/01/rnag-podchraoltai.html",
            "relUrl": "/irish/kaggle/dataset/2021/08/01/rnag-podchraoltai.html",
            "date": " • Aug 1, 2021"
        }
        
    
  
    
        ,"post179": {
            "title": "Unpack Swedish Gigaword",
            "content": "Original on Kaggle . !for i in ../input/download-swedish-gigaword/*.tar;do tar xvf $i;done .",
            "url": "https://jimregan.github.io/notes/kaggle/swedish/incomplete/2021/07/31/unpack-swedish-gigaword.html",
            "relUrl": "/kaggle/swedish/incomplete/2021/07/31/unpack-swedish-gigaword.html",
            "date": " • Jul 31, 2021"
        }
        
    
  
    
        ,"post180": {
            "title": "Soundcloud - Foras na Gaeilge",
            "content": "Original on Kaggle (private) . !pip install youtube-dl !youtube-dl https://soundcloud.com/forasnagaeilge .",
            "url": "https://jimregan.github.io/notes/kaggle/irish/soundcloud/dataset/unlabelled/forasnagaeilge/2021/07/31/soundcloud-foras-na-gaeilge.html",
            "relUrl": "/kaggle/irish/soundcloud/dataset/unlabelled/forasnagaeilge/2021/07/31/soundcloud-foras-na-gaeilge.html",
            "date": " • Jul 31, 2021"
        }
        
    
  
    
        ,"post181": {
            "title": "Download Swedish Gigaword",
            "content": "Original on Kaggle . !wget http://spraakbanken.gu.se/lb/resurser/meningsmangder/gigaword-1950-59.tar !wget http://spraakbanken.gu.se/lb/resurser/meningsmangder/gigaword-1960-69.tar !wget http://spraakbanken.gu.se/lb/resurser/meningsmangder/gigaword-1970-79.tar !wget http://spraakbanken.gu.se/lb/resurser/meningsmangder/gigaword-1980-89.tar !wget http://spraakbanken.gu.se/lb/resurser/meningsmangder/gigaword-1990-99.tar !wget http://spraakbanken.gu.se/lb/resurser/meningsmangder/gigaword-2000-09.tar !wget http://spraakbanken.gu.se/lb/resurser/meningsmangder/gigaword-2010-15.tar .",
            "url": "https://jimregan.github.io/notes/swedish/kaggle/2021/07/31/download-swedish-gigaword.html",
            "relUrl": "/swedish/kaggle/2021/07/31/download-swedish-gigaword.html",
            "date": " • Jul 31, 2021"
        }
        
    
  
    
        ,"post182": {
            "title": "Github asset release from Colab",
            "content": "!pip install -q condacolab import condacolab condacolab.install() . ⏬ Downloading https://github.com/jaimergp/miniforge/releases/latest/download/Mambaforge-colab-Linux-x86_64.sh... 📦 Installing... 📌 Adjusting configuration... 🩹 Patching environment... ⏲ Done in 0:00:44 🔁 Restarting kernel... . !conda install gh --channel conda-forge . !pip install youtube-dl . !youtube-dl -i --write-sub --sub-lang ga -o &#39;%(id)s.%(ext)s&#39; PLbcLsUBW9b3BvuTbtMKBXmuyJq6Ygg3Rg . !ls ./*.vtt|zip subtitles.zip -@ . from google.colab import files files.download(&#39;subtitles.zip&#39;) . !ls ./*.mp4 ./*.mkv |zip videos.zip -@ . !echo $KEY |gh auth login --with-token . !git clone $REPO . %cd $REPO . !gh release upload v0.1 ../videos.zip . Successfully uploaded 1 asset to v0.1 .",
            "url": "https://jimregan.github.io/notes/github/colab/2021/07/30/github-release-from-colab.html",
            "relUrl": "/github/colab/2021/07/30/github-release-from-colab.html",
            "date": " • Jul 30, 2021"
        }
        
    
  
    
        ,"post183": {
            "title": "ICU RBNF format in Python",
            "content": "%%capture !pip install pyicu . import icu formatter = icu.RuleBasedNumberFormat(icu.URBNFRuleSetTag.SPELLOUT, icu.Locale(&#39;ga&#39;)) formatter.format(23) . &#39;fiche a trí&#39; .",
            "url": "https://jimregan.github.io/notes/irish/icu/rbnf/2021/07/22/icu-rbnf-format.html",
            "relUrl": "/irish/icu/rbnf/2021/07/22/icu-rbnf-format.html",
            "date": " • Jul 22, 2021"
        }
        
    
  
    
        ,"post184": {
            "title": "Getting lmt to work",
            "content": "tl;dr -- lmt needs there to be either: . markdown after the last file piece | two newline characters | . !git clone https://github.com/driusan/lmt . fatal: destination path &#39;lmt&#39; already exists and is not an empty directory. . %cd lmt . /content/lmt . %%capture !apt install golang . !go build . import os os.environ[&#39;PATH&#39;] = f&#39;{os.environ[&quot;PATH&quot;]}:/content/lmt&#39; . %cd /content . /content . %%writefile test.go.md # Thing go test.go package main import ( fmt ) . Overwriting test.go.md . !lmt test.go.md . !cat test.go . cat: test.go: No such file or directory . %%writefile test2.go.md # Thing go test2.go package main import ( fmt ) . Overwriting test2.go.md . !lmt test2.go.md . !cat test2.go . cat: test2.go: No such file or directory . %%writefile test3.go.md # Thing go test3.go package main import ( fmt ) # Blah . Writing test3.go.md . !lmt test3.go.md !cat test3.go . //line test3.go.md:4 package main import ( fmt ) . %%writefile test4.go.md # Thing go test4.go package main import ( fmt ) . Writing test4.go.md . !lmt test4.go.md !cat test4.go . //line test4.go.md:4 package main import ( fmt ) .",
            "url": "https://jimregan.github.io/notes/lmt/2021/07/22/getting-lmt-to-work.html",
            "relUrl": "/lmt/2021/07/22/getting-lmt-to-work.html",
            "date": " • Jul 22, 2021"
        }
        
    
  
    
        ,"post185": {
            "title": "Render offline map with ipyleaflet and ipywebrtc",
            "content": "%%capture !pip install ipyleaflet ipywebrtc . from ipyleaflet import * thurles_point = (52.6801064,-7.804442099999999) thurles = Map(center=(52.8001064,-7.804442099999999), zoom=8, basemap=basemaps.Esri.DeLorme) marker = Marker(location=thurles_point, draggable=False) thurles.add_layer(marker) . The map needs to be rendered for ipywebrtc to work . thurles . from ipywebrtc import WidgetStream, ImageRecorder thurles_stream = WidgetStream(widget=thurles, max_fps=1) . thurles_img = ImageRecorder(stream=thurles_stream) thurles_img.recording = True thurles_img.autosave = False thurles_img.download() . import PIL.Image import PIL.ImageFilter import io thurles_pil = PIL.Image.open(io.BytesIO(thurles_img.image.value)) . thurles_pil .",
            "url": "https://jimregan.github.io/notes/ipyleaflet/ipywebrtc/map/2021/07/15/ipyleaflet-and-ipywebrtc.html",
            "relUrl": "/ipyleaflet/ipywebrtc/map/2021/07/15/ipyleaflet-and-ipywebrtc.html",
            "date": " • Jul 15, 2021"
        }
        
    
  
    
        ,"post186": {
            "title": "Swedish data from nb.no",
            "content": "Original on Kaggle (private) . !wget https://www.nb.no/sbfil/talegjenkjenning/22kHz/sv.22khz.txt.tar.gz . !tar zxvf sv.22khz.txt.tar.gz . !cat ./txt/dsm_txt/sw_mod_010.txt . !wget https://www.nb.no/sbfil/talegjenkjenning/16kHz_2020/se_2020/lydfiler_16_1.tar.gz . !tar zxvf lydfiler_16_1.tar.gz . !wget https://www.nb.no/sbfil/talegjenkjenning/16kHz_2020/se_2020/ADB_SWE_0467.tar.gz . !tar zxvf ADB_SWE_0467.tar.gz . !wget http://www.nb.no/sbfil/talegjenkjenning/16kHz/sve.16khz.0467-1.tar.gz . !tar zxvf sve.16khz.0467-1.tar.gz . !wget https://www.nb.no/sbfil/talesyntese/sve.ibm.talesyntese.tar.gz . !tar zxvf sve.ibm.talesyntese.tar.gz . !cat se10x016-08071999-1334_r4670016.json . ls -al se/se16x735-04111999-1559/se16x735-04111999-1559_u0107303-1.wav .",
            "url": "https://jimregan.github.io/notes/kaggle/swedish/incomplete/2021/07/09/nbno-swedish-data-links.html",
            "relUrl": "/kaggle/swedish/incomplete/2021/07/09/nbno-swedish-data-links.html",
            "date": " • Jul 9, 2021"
        }
        
    
  
    
        ,"post187": {
            "title": "Syllabify Phonetisaurus output",
            "content": "def is_schwa(phone, is_timit=True): if is_timit: return phone in [&quot;ax&quot;, &quot;axr&quot;, &quot;ix&quot;] else: return phone == &quot;AH0&quot; # CMUdict doesn&#39;t have syllabic consonants def is_syllabic_consonant(phone, is_timit=True): SYLLC = [&quot;el&quot;, &quot;em&quot;, &quot;en&quot;, &quot;er&quot;, &quot;er1&quot;, &quot;er2&quot;] if is_timit and phone in SYLLC: return True else: return False def is_vowel(phone): VOWELS = [&quot;aa&quot;, &quot;ae&quot;, &quot;ah&quot;, &quot;ao&quot;, &quot;aw&quot;, &quot;ax&quot;, &quot;axr&quot;, &quot;ay&quot;, &quot;eh&quot;, &quot;ey&quot;, &quot;ih&quot;, &quot;ix&quot;, &quot;iy&quot;, &quot;ow&quot;, &quot;oy&quot;, &quot;uh&quot;, &quot;uw&quot;] if phone[-1] in &quot;012&quot;: return phone[:-1].lower() in VOWELS else: return phone.lower() in VOWELS def is_vocalic(phone): return is_vowel(phone) or is_syllabic_consonant(phone) # http://web.archive.org/web/20100614180508/http://semarch.linguistics.fas.nyu.edu/barker/Syllables/syllabify.pl def sonority(phone): STOPS = [&quot;p&quot;, &quot;b&quot;, &quot;t&quot;, &quot;d&quot;, &quot;k&quot;, &quot;g&quot;] AFFRICATES = [&quot;ch&quot;, &quot;jh&quot;] FRICATIVES = [&quot;th&quot;, &quot;dh&quot;, &quot;f&quot;, &quot;v&quot;, &quot;s&quot;, &quot;z&quot;, &quot;sh&quot;, &quot;zh&quot;] NASALS = [&quot;m&quot;, &quot;n&quot;, &quot;ng&quot;] LIQUIDS = [&quot;l&quot;, &quot;r&quot;] GLIDES = [&quot;w&quot;, &quot;y&quot;] # &#39;s&#39; is special if phone == &quot;s&quot;: return 1 elif phone in STOPS: return 1 elif phone in AFFRICATES: return 2 elif phone in FRICATIVES: return 3 elif phone in NASALS: return 4 elif phone in LIQUIDS: return 5 elif phone == &quot;hh&quot;: return 6 elif phone in GLIDES: return 6 else: return 7 . def last_phoneme(graphone): grapheme, phoneme = graphone.split(&#39;}&#39;) return phoneme.split(&#39;|&#39;)[-1] def first_phoneme(graphone): grapheme, phoneme = graphone.split(&#39;}&#39;) return phoneme.split(&#39;|&#39;)[0] . assert last_phoneme(&#39;x}e|k|s&#39;) == &#39;s&#39; assert first_phoneme(&#39;x}e|k|s&#39;) == &#39;e&#39; . def voicing_mismatch(phone1, phone2): VOICED = [&quot;b&quot;, &quot;d&quot;, &quot;g&quot;, &quot;jh&quot;, &quot;dh&quot;, &quot;v&quot;, &quot;z&quot;, &quot;zh&quot;] DEVOICED = [&quot;p&quot;, &quot;t&quot;, &quot;k&quot;, &quot;ch&quot;, &quot;th&quot;, &quot;f&quot;, &quot;s&quot;, &quot;sh&quot;] if phone1 in VOICED and phone2 in DEVOICED: return True elif phone2 in VOICED and phone1 in DEVOICED: return True else: return False . def merge_graphones(graphones): graphemes = [] phonemes = [] for graphone in graphones: graphemes_string, phonemes_string = graphone.split(&#39;}&#39;) cur_graphemes = graphemes_string.split(&#39;|&#39;) cur_phonemes = phonemes_string.split(&#39;|&#39;) graphemes += cur_graphemes phonemes += cur_phonemes if len(graphemes) &gt; 1: pruned_graphemes = [a for a in graphemes if a != &#39;_&#39;] if len(pruned_graphemes) == 0: pruned_graphemes = [&#39;_&#39;] else: pruned_graphemes = graphemes if len(phonemes) &gt; 1: pruned_phonemes = [a for a in phonemes if a != &#39;_&#39;] if len(pruned_phonemes) == 0: pruned_phonemes = [&#39;_&#39;] else: pruned_phonemes = phonemes return &#39;}&#39;.join((&#39;|&#39;.join(pruned_graphemes), &#39;|&#39;.join(pruned_phonemes))) . assert merge_graphones(&quot;a}a t|h}th x}k|s&quot;.split(&#39; &#39;)) == &#39;a|t|h|x}a|th|k|s&#39; assert merge_graphones(&quot;a}a t|h}th x}k|s e}_&quot;.split(&#39; &#39;)) == &#39;a|t|h|x|e}a|th|k|s&#39; assert merge_graphones(&quot;a}_ t|h}_ x}_ e}_&quot;.split(&#39; &#39;)) == &#39;a|t|h|x|e}_&#39; assert merge_graphones(&quot;_}a _}th _}k|s&quot;.split(&#39; &#39;)) == &#39;_}a|th|k|s&#39; . def syllabify(graphones): sonority_up = True last_sonority_up = True last_sonority = 0 isvowel = False last_isvowel = False saw_vowel = False stack = [] output = [] last_phoneme = &quot;&quot; labials = [&quot;p&quot;, &quot;b&quot;, &quot;m&quot;, &quot;f&quot;, &quot;v&quot;] s_sh = [&quot;s&quot;, &quot;sh&quot;] for graphone in graphones[::-1]: phoneme = first_phoneme(graphone) phone_sonority = sonority(phoneme) isvowel = is_vocalic(phoneme) sonority_up = last_sonority &lt; phone_sonority # For timit if graphone == &#39;_&#39;: stack.append(graphone) continue if last_sonority == 3 and phone_sonority == 1: sonority_up = True if last_phoneme == &#39;w&#39; and phoneme in labials: last_sonority_up = False sonority_up = True if last_phoneme == &quot;m&quot; and not sonority_up and not phoneme in s_sh: last_sonority_up = False sonority_up = True if phoneme == &quot;m&quot; and not sonority_up and last_sonority &lt; 7: last_sonority_up = False sonority_up = True if phoneme == &quot;n&quot; and not sonority_up and last_sonority &lt; 6: last_sonority_up = False sonority_up = True if last_phoneme == &quot;m&quot; and not sonority_up and not phoneme in s_sh: last_sonority_up = False sonority_up = True if not sonority_up and phoneme == &quot;ng&quot;: last_sonority_up = False sonority_up = True if last_sonority == 7 and phone_sonority == 7: last_sonority_up = True sonority_up = True if sonority_up and last_sonority == 1 and sonority == 1 and phoneme != &quot;s&quot;: sonority_up = True # avoid bs/ps onsets if last_phoneme in [&quot;s&quot;, &quot;sh&quot;, &quot;z&quot;, &quot;zh&quot;] and phoneme in &quot;bp&quot;: last_sonority_up = False sonority_up = True if last_phoneme == &#39;l&#39; and phoneme in [&#39;d&#39;, &#39;t&#39;, &#39;dh&#39;, &#39;th&#39;]: last_sonority_up = False sonority_up = True def splitsyll(): if not saw_vowel: return False if isvowel and saw_vowel: return True if last_isvowel and isvowel: return True if voicing_mismatch(phoneme, last_phoneme): return True if not last_sonority_up and sonority_up: return True return False if splitsyll(): output.append(merge_graphones(stack[::-1])) stack = [] saw_vowel = False stack.append(graphone) last_sonority_up = sonority_up last_phoneme = phoneme last_sonority = phone_sonority last_isvowel = isvowel saw_vowel = saw_vowel or isvowel output.append(merge_graphones(stack[::-1])) return output[::-1] . assert syllabify(&#39;a}ax b}b o|u}aw1 t}t&#39;.split(&#39; &#39;)) == [&#39;a}ax&#39;, &#39;b|o|u|t}b|aw1|t&#39;] . with open(&#39;TIMIT.clean.corpus&#39;, &#39;r&#39;) as f, open(&#39;TIMIT.syllable.corpus&#39;, &#39;w&#39;) as of: for line in f.readlines(): graphones = line.split(&#39; &#39;) syll = syllabify(graphones) print(&#39; &#39;.join(syll), file=of) .",
            "url": "https://jimregan.github.io/notes/colab/timit/phonetisaurus/syllabification/2021/07/03/syllabify-phonetisaurus-output.html",
            "relUrl": "/colab/timit/phonetisaurus/syllabification/2021/07/03/syllabify-phonetisaurus-output.html",
            "date": " • Jul 3, 2021"
        }
        
    
  
    
        ,"post188": {
            "title": "Run phonetisaurus on TIMIT",
            "content": "The first few cells set up phonetisaurus; they are adapted from the instructions in the git README. . %%capture !apt-get -y install git g++ autoconf-archive make libtool # Python bindings !apt-get -y install python-setuptools python-dev # mitlm (to build a quick play model) !apt-get -y install gfortran . %%capture !wget http://www.openfst.org/twiki/pub/FST/FstDownload/openfst-1.6.2.tar.gz !tar -xvzf openfst-1.6.2.tar.gz %cd openfst-1.6.2 # Minimal configure, compatible with current defaults for Kaldi !./configure --enable-static --enable-shared --enable-far --enable-ngram-fsts !make -j 4 # Now wait a while... !make install . import os ldlibpath = os.environ[&#39;LD_LIBRARY_PATH&#39;] #_STORED_LD = &quot;/usr/local/nvidia/lib:/usr/local/nvidia/lib64&quot; newld = f&#39;{ldlibpath}:/usr/local/lib:/usr/local/lib/fst&#39; os.environ[&#39;LD_LIBRARY_PATH&#39;]=newld %env LD_LIBRARY_PATH . &#39;/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/lib:/usr/local/lib/fst&#39; . %%capture %cd /content !git clone https://github.com/AdolfVonKleist/Phonetisaurus.git %cd Phonetisaurus !./configure !make !make install . %cd /content/ . /content . We also need MITLM . %%capture !git clone https://github.com/mitlm/mitlm %cd mitlm !autoreconf -i !./configure !make !make install . %cd /content . /content . The TIMIT dictionary is relatively clean, so there are only a few small changes that are needed for phonetisaurus. . !cat TIMITDIC.txt|grep -v &#39;^;&#39;|tr -d &#39;/&#39;|sed -e &#39;s/ */ /g;s/~adj//;s/~v_past//;s/~v_pres//;s/~v//;s/~n//;&#39; &gt; TIMIT.cleaned !cat TIMIT.cleaned | perl -pe &#39;s/ s+/ /g; s/^ s+//; s/ s+$//; @_ = split (/ s+/); $w = shift (@_); $_ = $w.&quot; t&quot;.join (&quot; &quot;, @_).&quot; n&quot;;&#39; &gt; TIMIT.clean . !phonetisaurus-align --input=TIMIT.clean --ofile=TIMIT.clean.corpus --seq1_del=false . GitRevision: 0.9.1 Loading input file: TIMIT.clean Alignment failed: x Starting EM... Finished first iter... Iteration: 1 Change: 2.70318 Iteration: 2 Change: 0.0603504 Iteration: 3 Change: 0.0425539 Iteration: 4 Change: 0.0206814 Iteration: 5 Change: 0.0114756 Iteration: 6 Change: 0.00711536 Iteration: 7 Change: 0.0042429 Iteration: 8 Change: 0.00297546 Iteration: 9 Change: 0.00223923 Iteration: 10 Change: 0.00151825 Iteration: 11 Change: 0.00115204 Last iteration: 0.001 Loading corpus TIMIT.clean.corpus... 0.037 Smoothing[1] = ModKN 0.037 Smoothing[2] = ModKN 0.037 Smoothing[3] = ModKN 0.037 Smoothing[4] = ModKN 0.037 Smoothing[5] = ModKN 0.037 Smoothing[6] = ModKN 0.037 Smoothing[7] = ModKN 0.037 Smoothing[8] = ModKN 0.037 Set smoothing algorithms... 0.037 Y 6.063492e-01 0.037 Y 6.304450e-01 0.037 Y 7.305669e-01 0.037 Y 7.950124e-01 0.037 Y 8.524463e-01 0.038 Y 9.033717e-01 0.038 Y 9.355036e-01 0.038 Y 9.092702e-01 0.038 Estimating full n-gram model... 0.040 Saving LM to timit.arpa... GitRevision: 0.9.1 Initializing... Converting... . That thing I just said about the TIMIT dictionary being relatively clean? Nah. There are some errors, particularly with &#39;c&#39; being transcribed as &#39;ao&#39; (which is a vowel sound). Also, the default output of phonetisaurus-align only does 1:1, 1:0, 0:1, 2:1, and 1:2 mappings of graphemes and phonemes, which means some of the alignments look quite strange. . %%writefile clean_ngrams.pl #!/usr/bin/perl # Fix some of the alignments from phonetisaurus-align to be more recognisable to humans # Also fixes some transcription errors in the TIMIT dictionary (mostly c -&gt; ao) use warnings; use strict; use utf8; my $raw_replacements = &lt;&lt;_HERE_; e}_ l}el e|l}el e}_ d}ed e|d}ed e}_ d}d e|d}d e}iy1 e}_ e|e}iy1 i}ix o|n}n i|o}ix n}n r}_ t|-}r t}t r}r t|-|t}t -|k}n n|a}ae1 -}_ k|n}n a}ae1 a|c}ax c}k a}ax c|c}k c}k h}_ c|h}k c}k q|u}w c|q}k u}w n}n|t c}s n}n c}t|s i|c}ih1 k|-}k i}ih1 c|k}k -}_ a|k}ey1 e|-}k a}ey1 k}k e|-}_ -|k}n n|a}ae2 -}_ k|n}n a}ae2 a|t}ax e}_ -|e}t y}ay1 a}ax t}t e}_ -}_ e|y}ay1 t|u}ch r}axr t}ch u|r}axr e}_ d}d e|d}d a}ae1 e}_ a|e}ae1 a}ih e}_ a|e}ih -|c}ao -}_ c}k x}eh1|k -}s x}eh1|k|s -}_ e}_ l|l}el e|l|l}el w|h}hh y}w|ay1 w|h}hh|w y}ay1 a|d}ax j|o}jh u|r}er1 a}ax d|j}jh o|u|r}er1 a|d}ae2 u}jh|uw a}ae2 d}jh u}uw u}y|uh a|b}b u|a}y|uh b}b x}k -}s x}k|s -}_ u|r}er1 r}_ u|r|r}er1 o|r}axr r}_ o|r|r}axr u|r}axr r}_ u|r|r}axr e|r}axr r}_ e|r|r}axr a|r}axr r}_ h|o}iy1 e}_ a|r|r|h}axr o|e}iy1 e|r}er r}_ e|r|r}er i|r}er1 r}_ i|r|r}er1 u}_ a}aa1 u|a}aa1 w|h}hh i}w|er1 r}_ w|h}hh|w i|r}er1 b|o}b r}r b}b o|r}r e}_ a|r}er1 e|a|r}er1 q|u}k a}w|ey2 q}k u}w a}ey2 q|u}k a}w|ao1 q}k u}w a}ao1 w|h}hh a}w|ax w|h}hh|w a}ax t|u}ch r}axr t}ch u|r}axr d|u}jh a}uw|ax d}jh u}uw a}ax c|i}sh a}iy|ey2 c}sh i}iy a}ey2 i}ix a|t}t i|a}ix t}t w|h}hh e}w|iy1 a|t}t w|h}hh|w e|a}iy1 t}t q|u}k a}w|aa1 q}k u}w a}aa1 q|u}k a}w|ao2 q}k u}w a}ao2 q|u}k a}w|ae1 q}k u}w a}ae1 w|h}hh a}w|aa1 w|h}hh|w a}aa1 w|h}hh a}w|aa2 w|h}hh|w a}aa2 w|h}hh e}w|ae1 w|h}hh|w a}ae1 w|h}hh e}w|ae2 w|h}hh|w a}ae2 w|h}hh i}w|ay1 w|h}hh|w a}ay1 w|h}hh o}w|aa1 w|h}hh|w o}aa1 y|a}y c|h}aa1 t}t y}y a}aa1 c|h}_ t}t i}iy1 e}_ i|e}iy1 m|a}m &#39;}_ a}ae1 m}m a|&#39;|a}ae1 g|u}g e}_ g}g u|e}_ r}r h}_ r|h}r s}z s|a}ix s|s}z a}ix _HERE_ my %replacements = (); for my $rl (split(&#39; n&#39;, $raw_replacements)) { next if($rl !~ / t/); my @tmp = split(/ t/, $rl); $replacements{$tmp[0]} = $tmp[1]; } my $regex_inner = join(&#39;|&#39;, map { quotemeta $_ } keys %replacements); while(&lt;&gt;) { chomp; while(/(?:^| )($regex_inner)(?:$| )/g) { my $m = $1; my $qm = quotemeta($m); s/$qm/$replacements{$m}/; } my @phns = split/ /; my @out = (); for my $phn (@phns) { if($phn =~ /^([-&#39;]) |/) { my $ch = $1; push @out, &quot;$ch}_&quot;; push @out, substr($phn,2); } elsif($phn =~ /^([^ |]) |([-&#39;]) }(.*)$/) { my $ch1 = $1; my $ch2 = $2; my $ch3 = $3; push @out, &quot;$ch1}$ch3&quot;; push @out, &quot;$ch2}_&quot;; } elsif($phn eq &#39;c}ao&#39;) { if($phns[0] eq &#39;n}n&#39;) { push @out, &#39;c}s&#39;; } else { push @out, &#39;c}k&#39;; } } else { push @out, $phn; } } print join(&#39; &#39;, @out) . &quot; n&quot;; } . Writing clean_ngrams.pl . !cat TIMIT.clean.corpus | perl clean_ngrams.pl &gt; TIMIT.cleaner.corpus . !estimate-ngram -o 8 -t TIMIT.cleaner.corpus -wl timit.arpa # Convert to OpenFst format (10s-20s): !phonetisaurus-arpa2wfst --lm=timit.arpa --ofile=timit.fst . 0.001 Loading corpus TIMIT.cleaner.corpus... 0.026 Smoothing[1] = ModKN 0.026 Smoothing[2] = ModKN 0.026 Smoothing[3] = ModKN 0.026 Smoothing[4] = ModKN 0.026 Smoothing[5] = ModKN 0.026 Smoothing[6] = ModKN 0.026 Smoothing[7] = ModKN 0.026 Smoothing[8] = ModKN 0.026 Set smoothing algorithms... 0.026 Y 6.390977e-01 0.026 Y 6.202592e-01 0.026 Y 7.251729e-01 0.026 Y 7.967686e-01 0.027 Y 8.548704e-01 0.027 Y 9.046288e-01 0.027 Y 9.354281e-01 0.027 Y 9.105453e-01 0.027 Estimating full n-gram model... 0.029 Saving LM to timit.arpa... GitRevision: 0.9.1 Initializing... Converting... . .",
            "url": "https://jimregan.github.io/notes/colab/timit/phonetisaurus/2021/07/03/run-phonetisaurus-on-timit.html",
            "relUrl": "/colab/timit/phonetisaurus/2021/07/03/run-phonetisaurus-on-timit.html",
            "date": " • Jul 3, 2021"
        }
        
    
  
    
        ,"post189": {
            "title": "Run phonetisaurus on TIMIT via Kaggle",
            "content": "Original on Kaggle . The first few cells set up phonetisaurus; they are adapted from the instructions in the git README. . %%capture !apt-get -y install git g++ autoconf-archive make libtool # Python bindings !apt-get -y install python-setuptools python-dev !apt-get -y install gfortran . %%capture %cd /tmp !wget http://www.openfst.org/twiki/pub/FST/FstDownload/openfst-1.6.2.tar.gz !tar -xvzf openfst-1.6.2.tar.gz %cd openfst-1.6.2 !./configure --enable-static --enable-shared --enable-far --enable-ngram-fsts !make -j 4 # Now wait a while... !make install . import os ldlibpath = os.environ[&#39;LD_LIBRARY_PATH&#39;] newld = f&#39;{ldlibpath}:/usr/local/lib:/usr/local/lib/fst&#39; os.environ[&#39;LD_LIBRARY_PATH&#39;]=newld %env LD_LIBRARY_PATH . &#39;/opt/conda/lib:/usr/local/lib:/usr/local/lib/fst&#39; . %%capture %cd /tmp !git clone https://github.com/AdolfVonKleist/Phonetisaurus.git %cd Phonetisaurus !./configure !make !make install . %cd /tmp/ . /tmp . We also need MITLM . %%capture !git clone https://github.com/mitlm/mitlm %cd mitlm !autoreconf -i !./configure !make !make install . %cd /kaggle/working . /kaggle/working . The TIMIT dictionary is relatively clean, so there are only a few small changes that are needed for phonetisaurus. . !cat ../input/darpa-timit-acousticphonetic-continuous-speech/TIMITDIC.TXT|grep -v &#39;^;&#39;|tr -d &#39;/&#39;|sed -e &#39;s/ */ /g;s/~adj//;s/~v_past//;s/~v_pres//;s/~v//;s/~n//;&#39; &gt; /tmp/TIMIT.cleaned !cat /tmp/TIMIT.cleaned | perl -pe &#39;s/ s+/ /g; s/^ s+//; s/ s+$//; @_ = split (/ s+/); $w = shift (@_); $_ = $w.&quot; t&quot;.join (&quot; &quot;, @_).&quot; n&quot;;&#39; &gt; /tmp/TIMIT.clean . !phonetisaurus-align --input=/tmp/TIMIT.clean --ofile=TIMIT.clean.corpus --seq1_del=false . GitRevision: 0.9.1 Loading input file: /tmp/TIMIT.clean Alignment failed: x Starting EM... Finished first iter... Iteration: 1 Change: 2.70318 Iteration: 2 Change: 0.0603504 Iteration: 3 Change: 0.0425539 Iteration: 4 Change: 0.0206814 Iteration: 5 Change: 0.0114756 Iteration: 6 Change: 0.00711536 Iteration: 7 Change: 0.0042429 Iteration: 8 Change: 0.00297546 Iteration: 9 Change: 0.00223923 Iteration: 10 Change: 0.00151825 Iteration: 11 Change: 0.00115204 Last iteration: . That thing I just said about the TIMIT dictionary being relatively clean? Nah. There are some errors, particularly with &#39;c&#39; being transcribed as &#39;ao&#39; (which is a vowel sound). Also, the default output of phonetisaurus-align only does 1:1, 1:0, 0:1, 2:1, and 1:2 mappings of graphemes and phonemes, which means some of the alignments look quite strange. . %%writefile clean_ngrams.pl #!/usr/bin/perl # Fix some of the alignments from phonetisaurus-align to be more recognisable to humans # Also fixes some transcription errors in the TIMIT dictionary (mostly c -&gt; ao) use warnings; use strict; use utf8; my $raw_replacements = &lt;&lt;_HERE_; e}_ l}el e|l}el e}_ d}ed e|d}ed e}_ d}d e|d}d e}iy1 e}_ e|e}iy1 i}ix o|n}n i|o}ix n}n r}_ t|-}r t}t r}r t|-|t}t -|k}n n|a}ae1 -}_ k|n}n a}ae1 a|c}ax c}k a}ax c|c}k c}k h}_ c|h}k c}k q|u}w c|q}k u}w n}n|t c}s n}n c}t|s i|c}ih1 k|-}k i}ih1 c|k}k -}_ a|k}ey1 e|-}k a}ey1 k}k e|-}_ -|k}n n|a}ae2 -}_ k|n}n a}ae2 a|t}ax e}_ -|e}t y}ay1 a}ax t}t e}_ -}_ e|y}ay1 t|u}ch r}axr t}ch u|r}axr e}_ d}d e|d}d a}ae1 e}_ a|e}ae1 a}ih e}_ a|e}ih -|c}ao -}_ c}k x}eh1|k -}s x}eh1|k|s -}_ e}_ l|l}el e|l|l}el w|h}hh y}w|ay1 w|h}hh|w y}ay1 a|d}ax j|o}jh u|r}er1 a}ax d|j}jh o|u|r}er1 a|d}ae2 u}jh|uw a}ae2 d}jh u}uw u}y|uh a|b}b u|a}y|uh b}b x}k -}s x}k|s -}_ u|r}er1 r}_ u|r|r}er1 o|r}axr r}_ o|r|r}axr u|r}axr r}_ u|r|r}axr e|r}axr r}_ e|r|r}axr a|r}axr r}_ h|o}iy1 e}_ a|r|r|h}axr o|e}iy1 e|r}er r}_ e|r|r}er i|r}er1 r}_ i|r|r}er1 u}_ a}aa1 u|a}aa1 w|h}hh i}w|er1 r}_ w|h}hh|w i|r}er1 b|o}b r}r b}b o|r}r e}_ a|r}er1 e|a|r}er1 q|u}k a}w|ey2 q}k u}w a}ey2 q|u}k a}w|ao1 q}k u}w a}ao1 w|h}hh a}w|ax w|h}hh|w a}ax t|u}ch r}axr t}ch u|r}axr d|u}jh a}uw|ax d}jh u}uw a}ax c|i}sh a}iy|ey2 c}sh i}iy a}ey2 i}ix a|t}t i|a}ix t}t w|h}hh e}w|iy1 a|t}t w|h}hh|w e|a}iy1 t}t q|u}k a}w|aa1 q}k u}w a}aa1 q|u}k a}w|ao2 q}k u}w a}ao2 q|u}k a}w|ae1 q}k u}w a}ae1 w|h}hh a}w|aa1 w|h}hh|w a}aa1 w|h}hh a}w|aa2 w|h}hh|w a}aa2 w|h}hh e}w|ae1 w|h}hh|w a}ae1 w|h}hh e}w|ae2 w|h}hh|w a}ae2 w|h}hh i}w|ay1 w|h}hh|w a}ay1 w|h}hh o}w|aa1 w|h}hh|w o}aa1 y|a}y c|h}aa1 t}t y}y a}aa1 c|h}_ t}t i}iy1 e}_ i|e}iy1 m|a}m &#39;}_ a}ae1 m}m a|&#39;|a}ae1 g|u}g e}_ g}g u|e}_ r}r h}_ r|h}r s}z s|a}ix s|s}z a}ix _HERE_ my %replacements = (); for my $rl (split(&#39; n&#39;, $raw_replacements)) { next if($rl !~ / t/); my @tmp = split(/ t/, $rl); $replacements{$tmp[0]} = $tmp[1]; } my $regex_inner = join(&#39;|&#39;, map { quotemeta $_ } keys %replacements); while(&lt;&gt;) { chomp; while(/(?:^| )($regex_inner)(?:$| )/g) { my $m = $1; my $qm = quotemeta($m); s/$qm/$replacements{$m}/; } my @phns = split/ /; my @out = (); for my $phn (@phns) { if($phn =~ /^([-&#39;]) |/) { my $ch = $1; push @out, &quot;$ch}_&quot;; push @out, substr($phn,2); } elsif($phn =~ /^([^ |]) |([-&#39;]) }(.*)$/) { my $ch1 = $1; my $ch2 = $2; my $ch3 = $3; push @out, &quot;$ch1}$ch3&quot;; push @out, &quot;$ch2}_&quot;; } elsif($phn eq &#39;c}ao&#39;) { if($phns[0] eq &#39;n}n&#39;) { push @out, &#39;c}s&#39;; } else { push @out, &#39;c}k&#39;; } } else { push @out, $phn; } } print join(&#39; &#39;, @out) . &quot; n&quot;; } . Writing clean_ngrams.pl . !cat TIMIT.clean.corpus | perl clean_ngrams.pl &gt; TIMIT.cleaner.corpus . !estimate-ngram -o 8 -t TIMIT.cleaner.corpus -wl timit.arpa # Convert to OpenFst format (10s-20s): !phonetisaurus-arpa2wfst --lm=timit.arpa --ofile=timit.fst . 0.001 Loading corpus TIMIT.cleaner.corpus... 0.026 Smoothing[1] = ModKN 0.026 Smoothing[2] = ModKN 0.026 Smoothing[3] = ModKN 0.026 Smoothing[4] = ModKN 0.026 Smoothing[5] = ModKN 0.026 Smoothing[6] = ModKN 0.026 Smoothing[7] = ModKN 0.026 Smoothing[8] = ModKN 0.026 Set smoothing algorithms... 0.026 Y 6.390977e-01 0.026 Y 6.202592e-01 0.026 Y 7.251729e-01 0.026 Y 7.967686e-01 0.027 Y 8.548704e-01 0.027 Y 9.046288e-01 0.027 Y 9.354281e-01 0.027 Y 9.105453e-01 0.027 Estimating full n-gram model... 0.029 Saving LM to timit.arpa... GitRevision: 0.9.1 Initializing... Converting... . .",
            "url": "https://jimregan.github.io/notes/kaggle/timit/phonetisaurus/2021/07/03/run-phonetisaurus-on-timit-kaggle.html",
            "relUrl": "/kaggle/timit/phonetisaurus/2021/07/03/run-phonetisaurus-on-timit-kaggle.html",
            "date": " • Jul 3, 2021"
        }
        
    
  
    
        ,"post190": {
            "title": "Install phonetisaurus on Colab",
            "content": "%%capture !apt-get -y install git g++ autoconf-archive make libtool # Python bindings !apt-get -y install python-setuptools python-dev # mitlm (to build a quick play model) !apt-get -y install gfortran . %%capture !wget http://www.openfst.org/twiki/pub/FST/FstDownload/openfst-1.6.2.tar.gz !tar -xvzf openfst-1.6.2.tar.gz %cd openfst-1.6.2 # Minimal configure, compatible with current defaults for Kaldi !./configure --enable-static --enable-shared --enable-far --enable-ngram-fsts !make -j 4 # Now wait a while... !make install . import os ldlibpath = os.environ[&#39;LD_LIBRARY_PATH&#39;] #_STORED_LD = &quot;/usr/local/nvidia/lib:/usr/local/nvidia/lib64&quot; newld = f&#39;{ldlibpath}:/usr/local/lib:/usr/local/lib/fst&#39; os.environ[&#39;LD_LIBRARY_PATH&#39;]=newld %env LD_LIBRARY_PATH . &#39;/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/lib:/usr/local/lib/fst&#39; . %%capture %cd /content !git clone https://github.com/AdolfVonKleist/Phonetisaurus.git %cd Phonetisaurus !./configure !make !make install . %cd /content/ . /content .",
            "url": "https://jimregan.github.io/notes/phonetisaurus/colab/2021/07/03/install-phonetisaurus.html",
            "relUrl": "/phonetisaurus/colab/2021/07/03/install-phonetisaurus.html",
            "date": " • Jul 3, 2021"
        }
        
    
  
    
        ,"post191": {
            "title": "English hyphenation from Wiktionary",
            "content": "Original on Kaggle . %%capture !wget https://dumps.wikimedia.org/enwiktionary/20210620/enwiktionary-20210620-pages-articles-multistream.xml.bz2 . !bzcat enwiktionary-20210620-pages-articles-multistream.xml.bz2|grep &#39;hyphenation|en&#39; &gt; /tmp/rawhyph . !grep &#39;{{a|U.S.&#39; /tmp/rawhyph|sed -e &#39;s/{a|U.S.}//;s/{}//&#39; . * {{hyphenation|en|caption=|tub|er|vil}} . !cat /tmp/rawhyph|sed -e &#39;s/{a|U.S.}//;s/{}//;&#39;|sed -e &quot;s/&#39;&#39;&#39;:&#39;&#39;&#39;/|/g&quot;|awk -F&#39;{{hyphenation |en |&#39; &#39;{print $2}&#39;|awk -F&#39;}}&#39; &#39;{print $1}&#39;|perl -ane &#39;chomp;@l=split/ |/;if($l[0] =~ /=/){shift @l};if($l[$#l] =~ /=/){pop @l};print join(&quot;&quot;, @l) . &quot; t&quot; . join(&quot; &quot;, @l). &quot; n&quot;&#39;|sort|uniq &gt; hyphenation.tsv .",
            "url": "https://jimregan.github.io/notes/english/wiktionary/hyphenation/2021/06/24/english-hyphenation-from-wiktionary.html",
            "relUrl": "/english/wiktionary/hyphenation/2021/06/24/english-hyphenation-from-wiktionary.html",
            "date": " • Jun 24, 2021"
        }
        
    
  
    
        ,"post192": {
            "title": "Sine curve unit circle on Colab",
            "content": "%%capture # https://docs.manim.community/en/stable/installation/colab.html !sudo apt update !sudo apt install libcairo2-dev ffmpeg texlive texlive-latex-extra texlive-fonts-extra texlive-latex-recommended texlive-science tipa libpango1.0-dev !pip install manim !pip install IPython --upgrade . from manim import * . Manim Community v0.7.0 . %%manim -v WARNING --disable_caching -qm SineCurveUnitCircle # https://docs.manim.community/en/stable/examples.html#sinecurveunitcircle class SineCurveUnitCircle(Scene): # contributed by heejin_park, https://infograph.tistory.com/230 def construct(self): self.show_axis() self.show_circle() self.move_dot_and_draw_curve() self.wait() def show_axis(self): x_start = np.array([-6,0,0]) x_end = np.array([6,0,0]) y_start = np.array([-4,-2,0]) y_end = np.array([-4,2,0]) x_axis = Line(x_start, x_end) y_axis = Line(y_start, y_end) self.add(x_axis, y_axis) self.add_x_labels() self.origin_point = np.array([-4,0,0]) self.curve_start = np.array([-3,0,0]) def add_x_labels(self): x_labels = [ MathTex(&quot; pi&quot;), MathTex(&quot;2 pi&quot;), MathTex(&quot;3 pi&quot;), MathTex(&quot;4 pi&quot;), ] for i in range(len(x_labels)): x_labels[i].next_to(np.array([-1 + 2*i, 0, 0]), DOWN) self.add(x_labels[i]) def show_circle(self): circle = Circle(radius=1) circle.move_to(self.origin_point) self.add(circle) self.circle = circle def move_dot_and_draw_curve(self): orbit = self.circle origin_point = self.origin_point dot = Dot(radius=0.08, color=YELLOW) dot.move_to(orbit.point_from_proportion(0)) self.t_offset = 0 rate = 0.25 def go_around_circle(mob, dt): self.t_offset += (dt * rate) # print(self.t_offset) mob.move_to(orbit.point_from_proportion(self.t_offset % 1)) def get_line_to_circle(): return Line(origin_point, dot.get_center(), color=BLUE) def get_line_to_curve(): x = self.curve_start[0] + self.t_offset * 4 y = dot.get_center()[1] return Line(dot.get_center(), np.array([x,y,0]), color=YELLOW_A, stroke_width=2 ) self.curve = VGroup() self.curve.add(Line(self.curve_start,self.curve_start)) def get_curve(): last_line = self.curve[-1] x = self.curve_start[0] + self.t_offset * 4 y = dot.get_center()[1] new_line = Line(last_line.get_end(),np.array([x,y,0]), color=YELLOW_D) self.curve.add(new_line) return self.curve dot.add_updater(go_around_circle) origin_to_circle_line = always_redraw(get_line_to_circle) dot_to_curve_line = always_redraw(get_line_to_curve) sine_curve_line = always_redraw(get_curve) self.add(dot) self.add(orbit, origin_to_circle_line, dot_to_curve_line, sine_curve_line) self.wait(8.5) dot.remove_updater(go_around_circle) . . Your browser does not support the video tag.",
            "url": "https://jimregan.github.io/notes/manim/colab/2021/06/23/manim_sine_curve_colab.html",
            "relUrl": "/manim/colab/2021/06/23/manim_sine_curve_colab.html",
            "date": " • Jun 23, 2021"
        }
        
    
  
    
        ,"post193": {
            "title": "Scoring librispeech with Kaldi on Kaggle",
            "content": "Original here. This basically recreates this blog post, but with different test sets, and on Kaggle, where setting up Kaldi is a little more involved than usual. . Results: . test-clean test-other . tgsmall LM | 7.13 | 17.92 | . rnnlm rescored: | 5.85 | 15.98 | . Unpack Kaldi . %cd /opt . /opt . %%capture !tar xvf /kaggle/input/extract-prebuilt-kaldi-from-docker/kaldi.tar . import os os.environ[&#39;LD_LIBRARY_PATH&#39;] = &#39;/opt/conda/lib:/opt/kaldi/tools/openfst-1.6.7/lib:/opt/kaldi/src/lib:&#39; EXISTING_PATH = os.environ[&#39;PATH&#39;] . %cd / . / . %%capture !tar xvf /kaggle/input/extract-cuda-from-kaldi-docker/cuda.tar . import os os.environ[&#39;LD_LIBRARY_PATH&#39;] = f&#39;{os.environ[&quot;LD_LIBRARY_PATH&quot;]}:/usr/local/cuda-10.0/targets/x86_64-linux/lib/&#39; . %cd /opt/kaldi/egs . /opt/kaldi/egs . Install flac . %%capture !apt install -y flac . Create a work directory . !mkdir -p usels/s5 %cd usels/s5 . /opt/kaldi/egs/usels/s5 . !mkdir /kaggle/working/data !mkdir /kaggle/working/exp !ln -s /kaggle/working/data !ln -s /kaggle/working/exp . !ln -s ../../wsj/s5/steps !ln -s ../../wsj/s5/utils !ln -s ../../librispeech/s5/local . !mkdir conf . %%writefile conf/mfcc_hires.conf # config for high-resolution MFCC features, intended for neural network training # Note: we keep all cepstra, so it has the same info as filterbank features, # but MFCC is more easily compressible (because less correlated) which is why # we prefer this method. --use-energy=false # use average of log energy, not energy. --num-mel-bins=40 # similar to Google&#39;s setup. --num-ceps=40 # there is no dimensionality reduction. --low-freq=20 # low cutoff frequency for mel bins... this is high-bandwidth data, so # there might be some information at the low end. --high-freq=-400 # high cutoff frequently, relative to Nyquist of 8000 (=7600) . Writing conf/mfcc_hires.conf . Setting up paths . (In the scripts, you just source path.sh) . %env KALDI_ROOT=/opt/kaldi . env: KALDI_ROOT=/opt/kaldi . !cat ../../wsj/s5/path.sh . export KALDI_ROOT=`pwd`/../../.. [ -f $KALDI_ROOT/tools/env.sh ] &amp;&amp; . $KALDI_ROOT/tools/env.sh export PATH=$PWD/utils/:$KALDI_ROOT/tools/openfst/bin:$PWD:$PATH [ ! -f $KALDI_ROOT/tools/config/common_path.sh ] &amp;&amp; echo &gt;&amp;2 &#34;The standard file $KALDI_ROOT/tools/config/common_path.sh is not present -&gt; Exit!&#34; &amp;&amp; exit 1 . $KALDI_ROOT/tools/config/common_path.sh export LC_ALL=C . %env LC_ALL=C #PWD = !pwd PWD = &#39;/opt/kaldi/egs/usels/s5&#39; KALDI_ROOT = &#39;/opt/kaldi&#39; WSJ_PATH = f&#39;{PWD}/utils/:{KALDI_ROOT}/tools/openfst/bin:{PWD}:{EXISTING_PATH}&#39; . env: LC_ALL=C . !cat $KALDI_ROOT/tools/config/common_path.sh . # we assume KALDI_ROOT is already defined [ -z &#34;$KALDI_ROOT&#34; ] &amp;&amp; echo &gt;&amp;2 &#34;The variable KALDI_ROOT must be already defined&#34; &amp;&amp; exit 1 # The formatting of the path export command is intentionally weird, because # this allows for easy diff&#39;ing export PATH= ${KALDI_ROOT}/src/bin: ${KALDI_ROOT}/src/chainbin: ${KALDI_ROOT}/src/featbin: ${KALDI_ROOT}/src/fgmmbin: ${KALDI_ROOT}/src/fstbin: ${KALDI_ROOT}/src/gmmbin: ${KALDI_ROOT}/src/ivectorbin: ${KALDI_ROOT}/src/kwsbin: ${KALDI_ROOT}/src/latbin: ${KALDI_ROOT}/src/lmbin: ${KALDI_ROOT}/src/nnet2bin: ${KALDI_ROOT}/src/nnet3bin: ${KALDI_ROOT}/src/nnetbin: ${KALDI_ROOT}/src/online2bin: ${KALDI_ROOT}/src/onlinebin: ${KALDI_ROOT}/src/rnnlmbin: ${KALDI_ROOT}/src/sgmm2bin: ${KALDI_ROOT}/src/sgmmbin: ${KALDI_ROOT}/src/tfrnnlmbin: ${KALDI_ROOT}/src/cudadecoderbin: $PATH . raw_kaldi_paths=!cat $KALDI_ROOT/tools/config/common_path.sh|grep &#39;/src/&#39;|awk -F&#39;:&#39; &#39;{print $1}&#39;|awk -F&#39;/&#39; &#39;{print &quot;/opt/kaldi/src/&quot;$NF}&#39; . KALDI_PATHS=raw_kaldi_paths.nlstr.replace(&#39; n&#39;,&#39;:&#39;) . !cat $KALDI_ROOT/tools/env.sh . export PATH=/opt/kaldi/tools/python:${PATH} export PHONETISAURUS=&#34;/tmp/output/opt/kaldi/tools/phonetisaurus-g2p&#34; export PATH=&#34;$PATH:${PHONETISAURUS}:${PHONETISAURUS}/src/scripts&#34; . PHONETISAURUS = &quot;/tmp/output/opt/kaldi/tools/phonetisaurus-g2p&quot; TOOLS_PATH = f&#39;/opt/kaldi/tools/python:{PHONETISAURUS}:{PHONETISAURUS}/src/scripts&#39; . %env PATH = f&quot;{WSJ_PATH}:{KALDI_PATHS}:{TOOLS_PATH}&quot; . env: PATH=f&#34;/opt/kaldi/egs/usels/s5/utils/:/opt/kaldi/tools/openfst/bin:/opt/kaldi/egs/usels/s5:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/opt/kaldi/src/bin:/opt/kaldi/src/chainbin:/opt/kaldi/src/featbin:/opt/kaldi/src/fgmmbin:/opt/kaldi/src/fstbin:/opt/kaldi/src/gmmbin:/opt/kaldi/src/ivectorbin:/opt/kaldi/src/kwsbin:/opt/kaldi/src/latbin:/opt/kaldi/src/lmbin:/opt/kaldi/src/nnet2bin:/opt/kaldi/src/nnet3bin:/opt/kaldi/src/nnetbin:/opt/kaldi/src/online2bin:/opt/kaldi/src/onlinebin:/opt/kaldi/src/rnnlmbin:/opt/kaldi/src/sgmm2bin:/opt/kaldi/src/sgmmbin:/opt/kaldi/src/tfrnnlmbin:/opt/kaldi/src/cudadecoderbin:/opt/kaldi/tools/python:/tmp/output/opt/kaldi/tools/phonetisaurus-g2p:/tmp/output/opt/kaldi/tools/phonetisaurus-g2p/src/scripts&#34; . !cat ../../wsj/s5/cmd.sh . # you can change cmd.sh depending on what type of queue you are using. # If you have no queueing system and want to run on a local machine, you # can change all instances &#39;queue.pl&#39; to run.pl (but be careful and run # commands one by one: most recipes will exhaust the memory on your # machine). queue.pl works with GridEngine (qsub). slurm.pl works # with slurm. Different queues are configured differently, with different # queue names and different ways of specifying things like memory; # to account for these differences you can create and edit the file # conf/queue.conf to match your queue&#39;s configuration. Search for # conf/queue.conf in http://kaldi-asr.org/doc/queue.html for more information, # or search for the string &#39;default_config&#39; in utils/queue.pl or utils/slurm.pl. export train_cmd=queue.pl export decode_cmd=&#34;queue.pl --mem 2G&#34; # the use of cuda_cmd is deprecated, used only in &#39;nnet1&#39;, export cuda_cmd=&#34;queue.pl --gpu 1&#34; if [ &#34;$(hostname -d)&#34; == &#34;fit.vutbr.cz&#34; ]; then queue_conf=$HOME/queue_conf/default.conf # see example /homes/kazi/iveselyk/queue_conf/default.conf, export train_cmd=&#34;queue.pl --config $queue_conf --mem 2G --matylda 0.2&#34; export decode_cmd=&#34;queue.pl --config $queue_conf --mem 3G --matylda 0.1&#34; export cuda_cmd=&#34;queue.pl --config $queue_conf --gpu 1 --mem 10G --tmp 40G&#34; fi . %env train_cmd=run.pl %env decode_cmd=run.pl . env: train_cmd=run.pl env: decode_cmd=run.pl . !ln -s ../../wsj/s5/cmd.sh !ln -s ../../wsj/s5/path.sh !ln -s utils/queue.pl !ln -s utils/run.pl . !rm *.pl . Data prep . !local/data_prep.sh /kaggle/input/librispeech-test-clean-and-other/LibriSpeech/test-other data/test-other !local/data_prep.sh /kaggle/input/librispeech-test-clean-and-other/LibriSpeech/test-clean data/test-clean . utils/validate_data_dir.sh: Successfully validated data-directory data/test-other local/data_prep.sh: successfully prepared data in data/test-other utils/validate_data_dir.sh: Successfully validated data-directory data/test-clean local/data_prep.sh: successfully prepared data in data/test-clean . !utils/copy_data_dir.sh data/test-clean data/test-clean_hires !utils/copy_data_dir.sh data/test-other data/test-other_hires . utils/copy_data_dir.sh: copied data from data/test-clean to data/test-clean_hires utils/validate_data_dir.sh: Successfully validated data-directory data/test-clean_hires utils/copy_data_dir.sh: copied data from data/test-other to data/test-other_hires utils/validate_data_dir.sh: Successfully validated data-directory data/test-other_hires . !ln -s utils/parse_options.sh . !steps/make_mfcc.sh --nj 20 --mfcc-config conf/mfcc_hires.conf --cmd &quot;$train_cmd&quot; data/test-clean_hires !steps/compute_cmvn_stats.sh data/test-clean_hires !utils/fix_data_dir.sh data/test-clean_hires !steps/make_mfcc.sh --nj 20 --mfcc-config conf/mfcc_hires.conf --cmd &quot;$train_cmd&quot; data/test-other_hires !steps/compute_cmvn_stats.sh data/test-other_hires !utils/fix_data_dir.sh data/test-other_hires . steps/make_mfcc.sh --nj 20 --mfcc-config conf/mfcc_hires.conf --cmd run.pl data/test-clean_hires utils/validate_data_dir.sh: Successfully validated data-directory data/test-clean_hires steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance. steps/make_mfcc.sh: Succeeded creating MFCC features for test-clean_hires steps/compute_cmvn_stats.sh data/test-clean_hires Succeeded creating CMVN stats for test-clean_hires fix_data_dir.sh: kept all 2620 utterances. fix_data_dir.sh: old files are kept in data/test-clean_hires/.backup steps/make_mfcc.sh --nj 20 --mfcc-config conf/mfcc_hires.conf --cmd run.pl data/test-other_hires utils/validate_data_dir.sh: Successfully validated data-directory data/test-other_hires steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance. steps/make_mfcc.sh: Succeeded creating MFCC features for test-other_hires steps/compute_cmvn_stats.sh data/test-other_hires Succeeded creating CMVN stats for test-other_hires fix_data_dir.sh: kept all 2939 utterances. fix_data_dir.sh: old files are kept in data/test-other_hires/.backup . Extract i-vectors . !ln -s /kaggle/input/kaldi-librispeech-model/exp/nnet3_cleaned/ exp/nnet3_cleaned !ln -s /kaggle/input/kaldi-librispeech-model/exp/chain_cleaned/ exp/chain_cleaned . %env nspk=$(wc -l &lt;data/test-clean_hires/spk2utt) !steps/online/nnet2/extract_ivectors_online.sh --cmd &quot;$train_cmd&quot; --nj &quot;${nspk}&quot; data/test-clean_hires exp/nnet3_cleaned/extractor exp/nnet3_cleaned_out/ivectors_test-clean_hires %env nspk=$(wc -l &lt;data/test-other_hires/spk2utt) !steps/online/nnet2/extract_ivectors_online.sh --cmd &quot;$train_cmd&quot; --nj &quot;${nspk}&quot; data/test-other_hires exp/nnet3_cleaned/extractor exp/nnet3_cleaned_out/ivectors_test-other_hires . env: nspk=$(wc -l &lt;data/test-clean_hires/spk2utt) steps/online/nnet2/extract_ivectors_online.sh --cmd run.pl --nj $(wc -l &lt;data/test-clean_hires/spk2utt) data/test-clean_hires exp/nnet3_cleaned/extractor exp/nnet3_cleaned_out/ivectors_test-clean_hires steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to exp/nnet3_cleaned_out/ivectors_test-clean_hires using the extractor in exp/nnet3_cleaned/extractor. env: nspk=$(wc -l &lt;data/test-other_hires/spk2utt) steps/online/nnet2/extract_ivectors_online.sh --cmd run.pl --nj $(wc -l &lt;data/test-other_hires/spk2utt) data/test-other_hires exp/nnet3_cleaned/extractor exp/nnet3_cleaned_out/ivectors_test-other_hires steps/online/nnet2/extract_ivectors_online.sh: extracting iVectors steps/online/nnet2/extract_ivectors_online.sh: combining iVectors across jobs steps/online/nnet2/extract_ivectors_online.sh: done extracting (online) iVectors to exp/nnet3_cleaned_out/ivectors_test-other_hires using the extractor in exp/nnet3_cleaned/extractor. . Build decoding graph . Just linking this directory won&#39;t work, as it expects to be able to write to it (Kaldi scripts, smh) . !cp -r /kaggle/input/kaldi-librispeech-model/data/lang_test_tgsmall data . %env tdnndir=exp/chain_cleaned/tdnn_1d_sp %env graph_dir=exp/chain_cleaned_out/graph_tgsmall !utils/mkgraph.sh --self-loop-scale 1.0 --remove-oov data/lang_test_tgsmall $tdnndir $graph_dir . env: tdnndir=exp/chain_cleaned/tdnn_1d_sp env: graph_dir=exp/chain_cleaned_out/graph_tgsmall tree-info exp/chain_cleaned/tdnn_1d_sp/tree tree-info exp/chain_cleaned/tdnn_1d_sp/tree fstpushspecial fstdeterminizestar --use-log=true fstminimizeencoded fsttablecompose data/lang_test_tgsmall/L_disambig.fst data/lang_test_tgsmall/G.fst fstisstochastic data/lang_test_tgsmall/tmp/LG.fst -0.0459745 -0.0466771 [info]: LG not stochastic. fstcomposecontext --context-size=2 --central-position=1 --read-disambig-syms=data/lang_test_tgsmall/phones/disambig.int --write-disambig-syms=data/lang_test_tgsmall/tmp/disambig_ilabels_2_1.int data/lang_test_tgsmall/tmp/ilabels_2_1.113735 data/lang_test_tgsmall/tmp/LG.fst fstisstochastic data/lang_test_tgsmall/tmp/CLG_2_1.fst -0.0459745 -0.0466771 [info]: CLG not stochastic. make-h-transducer --disambig-syms-out=exp/chain_cleaned_out/graph_tgsmall/disambig_tid.int --transition-scale=1.0 data/lang_test_tgsmall/tmp/ilabels_2_1 exp/chain_cleaned/tdnn_1d_sp/tree exp/chain_cleaned/tdnn_1d_sp/final.mdl fstdeterminizestar --use-log=true fsttablecompose exp/chain_cleaned_out/graph_tgsmall/Ha.fst &#39;fstrmsymbols --remove-arcs=true --apply-to-output=true data/lang_test_tgsmall/oov.int data/lang_test_tgsmall/tmp/CLG_2_1.fst|&#39; fstminimizeencoded fstrmsymbols exp/chain_cleaned_out/graph_tgsmall/disambig_tid.int fstrmepslocal fstrmsymbols --remove-arcs=true --apply-to-output=true data/lang_test_tgsmall/oov.int data/lang_test_tgsmall/tmp/CLG_2_1.fst fstisstochastic exp/chain_cleaned_out/graph_tgsmall/HCLGa.fst 3.39453 -0.209239 HCLGa is not stochastic add-self-loops --self-loop-scale=1.0 --reorder=true exp/chain_cleaned/tdnn_1d_sp/final.mdl exp/chain_cleaned_out/graph_tgsmall/HCLGa.fst fstisstochastic exp/chain_cleaned_out/graph_tgsmall/HCLG.fst 3.05078 -0.127788 [info]: final HCLG is not stochastic. . Decode . !mkdir exp/tdnn_1d_sp %pushd exp/tdnn_1d_sp !for i in /kaggle/input/kaldi-librispeech-model/exp/chain_cleaned/tdnn_1d_sp/*;do ln -s $i;done %popd . /kaggle/working/exp/tdnn_1d_sp /opt/kaldi/egs/usels/s5 popd -&gt; /opt/kaldi/egs/usels/s5 . %env tdnndir=exp/tdnn_1d_sp !steps/nnet3/decode.sh --acwt 1.0 --post-decode-acwt 10.0 --nj 8 --cmd &quot;$decode_cmd&quot; --online-ivector-dir exp/nnet3_cleaned_out/ivectors_test-clean_hires $graph_dir data/test-clean_hires $tdnndir/decode_test-clean_tgsmall !steps/nnet3/decode.sh --acwt 1.0 --post-decode-acwt 10.0 --nj 8 --cmd &quot;$decode_cmd&quot; --online-ivector-dir exp/nnet3_cleaned_out/ivectors_test-other_hires $graph_dir data/test-other_hires $tdnndir/decode_test-other_tgsmall . env: tdnndir=exp/tdnn_1d_sp steps/nnet3/decode.sh --acwt 1.0 --post-decode-acwt 10.0 --nj 8 --cmd run.pl --online-ivector-dir exp/nnet3_cleaned_out/ivectors_test-clean_hires exp/chain_cleaned_out/graph_tgsmall data/test-clean_hires exp/tdnn_1d_sp/decode_test-clean_tgsmall steps/nnet3/decode.sh: feature type is raw steps/diagnostic/analyze_lats.sh --cmd run.pl --iter final exp/chain_cleaned_out/graph_tgsmall exp/tdnn_1d_sp/decode_test-clean_tgsmall steps/diagnostic/analyze_lats.sh: see stats in exp/tdnn_1d_sp/decode_test-clean_tgsmall/log/analyze_alignments.log Overall, lattice depth (10,50,90-percentile)=(1,2,5) and mean=2.8 steps/diagnostic/analyze_lats.sh: see stats in exp/tdnn_1d_sp/decode_test-clean_tgsmall/log/analyze_lattice_depth_stats.log score best paths score confidence and timing with sclite Decoding done. steps/nnet3/decode.sh --acwt 1.0 --post-decode-acwt 10.0 --nj 8 --cmd run.pl --online-ivector-dir exp/nnet3_cleaned_out/ivectors_test-other_hires exp/chain_cleaned_out/graph_tgsmall data/test-other_hires exp/tdnn_1d_sp/decode_test-other_tgsmall steps/nnet3/decode.sh: feature type is raw steps/diagnostic/analyze_lats.sh --cmd run.pl --iter final exp/chain_cleaned_out/graph_tgsmall exp/tdnn_1d_sp/decode_test-other_tgsmall steps/diagnostic/analyze_lats.sh: see stats in exp/tdnn_1d_sp/decode_test-other_tgsmall/log/analyze_alignments.log Overall, lattice depth (10,50,90-percentile)=(1,3,13) and mean=6.3 steps/diagnostic/analyze_lats.sh: see stats in exp/tdnn_1d_sp/decode_test-other_tgsmall/log/analyze_lattice_depth_stats.log score best paths score confidence and timing with sclite Decoding done. . Score . !steps/score_kaldi.sh --cmd &quot;run.pl&quot; data/test-clean_hires $graph_dir $tdnndir/decode_test-clean_tgsmall !steps/score_kaldi.sh --cmd &quot;run.pl&quot; data/test-other_hires $graph_dir $tdnndir/decode_test-other_tgsmall . steps/score_kaldi.sh --cmd run.pl data/test-clean_hires exp/chain_cleaned_out/graph_tgsmall exp/tdnn_1d_sp/decode_test-clean_tgsmall steps/score_kaldi.sh: scoring with word insertion penalty=0.0,0.5,1.0 steps/score_kaldi.sh --cmd run.pl data/test-other_hires exp/chain_cleaned_out/graph_tgsmall exp/tdnn_1d_sp/decode_test-other_tgsmall steps/score_kaldi.sh: scoring with word insertion penalty=0.0,0.5,1.0 . !cat exp/tdnn_1d_sp/decode_test-clean_tgsmall/scoring_kaldi/best_wer !cat exp/tdnn_1d_sp/decode_test-other_tgsmall/scoring_kaldi/best_wer . %WER 7.13 [ 3747 / 52576, 648 ins, 242 del, 2857 sub ] exp/tdnn_1d_sp/decode_test-clean_tgsmall/wer_17_0.5 %WER 17.92 [ 9378 / 52343, 1384 ins, 723 del, 7271 sub ] exp/tdnn_1d_sp/decode_test-other_tgsmall/wer_17_1.0 . Rescoring . !cp -r /kaggle/input/kaldi-librispeech-model/exp/rnnlm_lstm_1a/ exp . !ln -s /opt/kaldi/scripts/rnnlm . %env decode_dir=exp/tdnn_1d_sp/decode_test-clean_tgsmall !rnnlm/lmrescore_pruned.sh --cmd &quot;$decode_cmd&quot; --weight 0.45 --max-ngram-order 4 data/lang_test_tgsmall exp/rnnlm_lstm_1a data/test-clean_hires ${decode_dir} $tdnndir/decode_test-clean_rescore %env decode_dir=exp/tdnn_1d_sp/decode_test-other_tgsmall !rnnlm/lmrescore_pruned.sh --cmd &quot;$decode_cmd&quot; --weight 0.45 --max-ngram-order 4 data/lang_test_tgsmall exp/rnnlm_lstm_1a data/test-other_hires ${decode_dir} $tdnndir/decode_test-other_rescore . env: decode_dir=exp/tdnn_1d_sp/decode_test-clean_tgsmall rnnlm/lmrescore_pruned.sh --cmd run.pl --weight 0.45 --max-ngram-order 4 data/lang_test_tgsmall exp/rnnlm_lstm_1a data/test-clean_hires exp/tdnn_1d_sp/decode_test-clean_tgsmall exp/tdnn_1d_sp/decode_test-clean_rescore local/score.sh --cmd run.pl data/test-clean_hires data/lang_test_tgsmall exp/tdnn_1d_sp/decode_test-clean_rescore env: decode_dir=exp/tdnn_1d_sp/decode_test-other_tgsmall rnnlm/lmrescore_pruned.sh --cmd run.pl --weight 0.45 --max-ngram-order 4 data/lang_test_tgsmall exp/rnnlm_lstm_1a data/test-other_hires exp/tdnn_1d_sp/decode_test-other_tgsmall exp/tdnn_1d_sp/decode_test-other_rescore local/score.sh --cmd run.pl data/test-other_hires data/lang_test_tgsmall exp/tdnn_1d_sp/decode_test-other_rescore . !steps/score_kaldi.sh --cmd &quot;run.pl&quot; data/test-clean_hires $graph_dir $tdnndir/decode_test-clean_rescore !steps/score_kaldi.sh --cmd &quot;run.pl&quot; data/test-other_hires $graph_dir $tdnndir/decode_test-other_rescore . steps/score_kaldi.sh --cmd run.pl data/test-clean_hires exp/chain_cleaned_out/graph_tgsmall exp/tdnn_1d_sp/decode_test-clean_rescore steps/score_kaldi.sh: scoring with word insertion penalty=0.0,0.5,1.0 steps/score_kaldi.sh --cmd run.pl data/test-other_hires exp/chain_cleaned_out/graph_tgsmall exp/tdnn_1d_sp/decode_test-other_rescore steps/score_kaldi.sh: scoring with word insertion penalty=0.0,0.5,1.0 . !cat $tdnndir/decode_test-clean_rescore/scoring_kaldi/best_wer !cat $tdnndir/decode_test-other_rescore/scoring_kaldi/best_wer . %WER 5.85 [ 3078 / 52576, 617 ins, 198 del, 2263 sub ] exp/tdnn_1d_sp/decode_test-clean_rescore/wer_17_0.5 %WER 15.98 [ 8362 / 52343, 1381 ins, 588 del, 6393 sub ] exp/tdnn_1d_sp/decode_test-other_rescore/wer_17_1.0 . .",
            "url": "https://jimregan.github.io/notes/asr/kaldi/kaggle/2021/06/22/run-kaldi-on-librispeech-test.html",
            "relUrl": "/asr/kaldi/kaggle/2021/06/22/run-kaldi-on-librispeech-test.html",
            "date": " • Jun 22, 2021"
        }
        
    
  
    
        ,"post194": {
            "title": "Kaldi LibriSpeech model on Kaggle",
            "content": "Setting up the LibriSpeech Kaldi model on Kaggle: see here . %%capture !wget http://kaldi-asr.org/models/13/0013_librispeech_v1_chain.tar.gz !wget http://kaldi-asr.org/models/13/0013_librispeech_v1_extractor.tar.gz !wget http://kaldi-asr.org/models/13/0013_librispeech_v1_lm.tar.gz . %%capture !for i in *.tar.gz;do tar zxvf $i;done . !find . -type l !find . -type l -exec ls -al {} ; . ./exp/chain_cleaned/tdnn_1d_sp/configs/lda.mat ./exp/nnet3_cleaned/extractor/final.ie lrwxrwxrwx 1 61208 fax 10 Feb 2 2020 ./exp/chain_cleaned/tdnn_1d_sp/configs/lda.mat -&gt; ../lda.mat lrwxrwxrwx 1 61208 fax 5 Feb 2 2020 ./exp/nnet3_cleaned/extractor/final.ie -&gt; 10.ie . !rm exp/chain_cleaned/tdnn_1d_sp/configs/lda.mat !rm exp/nnet3_cleaned/extractor/final.ie !cp exp/chain_cleaned/tdnn_1d_sp/lda.mat exp/chain_cleaned/tdnn_1d_sp/configs/lda.mat !cp exp/nnet3_cleaned/extractor/10.ie exp/nnet3_cleaned/extractor/final.ie .",
            "url": "https://jimregan.github.io/notes/kaggle/kaldi/librispeech/2021/06/21/kaldi-librispeech-model.html",
            "relUrl": "/kaggle/kaldi/librispeech/2021/06/21/kaldi-librispeech-model.html",
            "date": " • Jun 21, 2021"
        }
        
    
  
    
        ,"post195": {
            "title": "wav2vec-u CV-sv - w2vu_generate",
            "content": "This is based on this. The main difference is the script that&#39;s being run, and setting up flashlight&#39;s python bindings . I already had the GAN model in gdrive; those files are available here. . Preparation . !pip install condacolab . Collecting condacolab Using cached condacolab-0.1.2-py3-none-any.whl (6.0 kB) Installing collected packages: condacolab Successfully installed condacolab-0.1.2 . import condacolab condacolab.install() . ✨🍰✨ Everything looks OK! . %%capture !conda install -c pykaldi pykaldi -y . !git clone https://github.com/pytorch/fairseq/ . fatal: destination path &#39;fairseq&#39; already exists and is not an empty directory. . !git clone https://github.com/kpu/kenlm . fatal: destination path &#39;kenlm&#39; already exists and is not an empty directory. . %%capture !apt-get -y install libeigen3-dev liblzma-dev zlib1g-dev libbz2-dev . The python build doesn&#39;t build utils, so this is (probably) necessary . %cd /content/kenlm !mkdir build %cd build !cmake .. !make -j 4 . %%capture %cd /content/kenlm !python setup.py install %cd /tmp . import os os.environ[&#39;PATH&#39;] = f&quot;{os.environ[&#39;PATH&#39;]}:/content/kenlm/build/bin/&quot; os.environ[&#39;FAIRSEQ_ROOT&#39;] = &#39;/content/fairseq&#39; . %cd /content/fairseq/ . /content/fairseq . For next cell, see here . %%capture !pip install --editable ./ !python setup.py build develop . os.environ[&#39;HYDRA_FULL_ERROR&#39;] = &#39;1&#39; . %%capture !pip install editdistance . https://colab.research.google.com/github/corrieann/kaggle/blob/master/kaggle_api_in_colab.ipynb . %%capture !pip install kaggle . from google.colab import files uploaded = files.upload() for fn in uploaded.keys(): print(&#39;User uploaded file &quot;{name}&quot; with length {length} bytes&#39;.format( name=fn, length=len(uploaded[fn]))) # Then move kaggle.json into the folder where the API expects to find it. !mkdir -p ~/.kaggle/ &amp;&amp; mv kaggle.json ~/.kaggle/ &amp;&amp; chmod 600 ~/.kaggle/kaggle.json . Upload widget is only available when the cell has been executed in the current browser session. Please rerun this cell to enable. Saving kaggle.json to kaggle.json User uploaded file &#34;kaggle.json&#34; with length 64 bytes . %cd /content . /content . !kaggle datasets download &quot;jimregan/w2vu-cvsv-audio-processed&quot; . Downloading w2vu-cvsv-audio-processed.zip to /content 100% 4.31G/4.31G [01:24&lt;00:00, 102MB/s] 100% 4.31G/4.31G [01:24&lt;00:00, 54.7MB/s] . %%capture !unzip /content/w2vu-cvsv-audio-processed.zip . !kaggle datasets download -d jimregan/w2vu-cvsv-prepared-text . Downloading w2vu-cvsv-prepared-text.zip to /content 80% 14.0M/17.4M [00:00&lt;00:00, 33.7MB/s] 100% 17.4M/17.4M [00:00&lt;00:00, 44.2MB/s] . %%capture !unzip w2vu-cvsv-prepared-text.zip . !rm *.zip . !cp /content/preppedtext/phones/dict* /content/precompute_pca512_cls128_mean . %cd /content . /content . !git clone https://github.com/flashlight/flashlight . Cloning into &#39;flashlight&#39;... remote: Enumerating objects: 17649, done. remote: Counting objects: 100% (1523/1523), done. remote: Compressing objects: 100% (718/718), done. remote: Total 17649 (delta 827), reused 1336 (delta 761), pack-reused 16126 Receiving objects: 100% (17649/17649), 14.23 MiB | 24.82 MiB/s, done. Resolving deltas: 100% (12298/12298), done. . %%capture !apt install -q libfftw3-dev . Reading package lists... Building dependency tree... Reading state information... libfftw3-dev is already the newest version (3.3.7-1). cmake is already the newest version (3.10.2-1ubuntu2.18.04.1). 0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded. . %cd flashlight/bindings/python . /content/flashlight/bindings/python . %%capture !pip install packaging . !USE_MKL=0 KENLM_ROOT=/content/kenlm python setup.py install . w2vu-generate . import torch torch.version.cuda . &#39;10.2&#39; . torch.backends.cudnn.version() . 7605 . %cd /content/fairseq . /content/fairseq . from google.colab import drive drive.mount(&#39;/content/drive&#39;) . Mounted at /content/drive . %cd /content/fairseq/examples/wav2vec/unsupervised . /content/fairseq/examples/wav2vec/unsupervised . %%writefile rungan.sh python w2vu_generate.py --config-dir config/generate --config-name viterbi fairseq.common.user_dir=/content/fairseq/examples/wav2vec/unsupervised fairseq.task.data=/content/precompute_pca512_cls128_mean fairseq.common_eval.path=/content/drive/MyDrive/w2vu/checkpoint_best.pt fairseq.dataset.gen_subset=valid results_path=/content/drive/MyDrive/w2vures . Overwriting rungan.sh . !bash rungan.sh . [2021-06-19 19:24:18,601][__main__][INFO] - {&#39;_name&#39;: None, &#39;fairseq&#39;: {&#39;_name&#39;: None, &#39;common&#39;: {&#39;_name&#39;: None, &#39;no_progress_bar&#39;: False, &#39;log_interval&#39;: 100, &#39;log_format&#39;: None, &#39;log_file&#39;: None, &#39;tensorboard_logdir&#39;: None, &#39;wandb_project&#39;: None, &#39;azureml_logging&#39;: False, &#39;seed&#39;: 1, &#39;cpu&#39;: False, &#39;tpu&#39;: False, &#39;bf16&#39;: False, &#39;memory_efficient_bf16&#39;: False, &#39;fp16&#39;: False, &#39;memory_efficient_fp16&#39;: False, &#39;fp16_no_flatten_grads&#39;: False, &#39;fp16_init_scale&#39;: 128, &#39;fp16_scale_window&#39;: None, &#39;fp16_scale_tolerance&#39;: 0.0, &#39;on_cpu_convert_precision&#39;: False, &#39;min_loss_scale&#39;: 0.0001, &#39;threshold_loss_scale&#39;: None, &#39;amp&#39;: False, &#39;amp_batch_retries&#39;: 2, &#39;amp_init_scale&#39;: 128, &#39;amp_scale_window&#39;: None, &#39;user_dir&#39;: &#39;/content/fairseq/examples/wav2vec/unsupervised&#39;, &#39;empty_cache_freq&#39;: 0, &#39;all_gather_list_size&#39;: 16384, &#39;model_parallel_size&#39;: 1, &#39;quantization_config_path&#39;: None, &#39;profile&#39;: False, &#39;reset_logging&#39;: False, &#39;suppress_crashes&#39;: False, &#39;use_plasma_view&#39;: False, &#39;plasma_path&#39;: &#39;/tmp/plasma&#39;}, &#39;common_eval&#39;: {&#39;_name&#39;: None, &#39;path&#39;: &#39;/content/drive/MyDrive/w2vu/checkpoint_best.pt&#39;, &#39;post_process&#39;: None, &#39;quiet&#39;: True, &#39;model_overrides&#39;: &#39;{}&#39;, &#39;results_path&#39;: None}, &#39;distributed_training&#39;: {&#39;_name&#39;: None, &#39;distributed_world_size&#39;: 1, &#39;distributed_num_procs&#39;: 1, &#39;distributed_rank&#39;: 0, &#39;distributed_backend&#39;: &#39;nccl&#39;, &#39;distributed_init_method&#39;: None, &#39;distributed_port&#39;: -1, &#39;device_id&#39;: 0, &#39;distributed_no_spawn&#39;: False, &#39;ddp_backend&#39;: pytorch_ddp, &#39;ddp_comm_hook&#39;: none, &#39;bucket_cap_mb&#39;: 25, &#39;fix_batches_to_gpus&#39;: False, &#39;find_unused_parameters&#39;: False, &#39;fast_stat_sync&#39;: False, &#39;heartbeat_timeout&#39;: -1, &#39;broadcast_buffers&#39;: False, &#39;slowmo_momentum&#39;: None, &#39;slowmo_algorithm&#39;: &#39;LocalSGD&#39;, &#39;localsgd_frequency&#39;: 3, &#39;nprocs_per_node&#39;: 1, &#39;pipeline_model_parallel&#39;: False, &#39;pipeline_balance&#39;: None, &#39;pipeline_devices&#39;: None, &#39;pipeline_chunks&#39;: 0, &#39;pipeline_encoder_balance&#39;: None, &#39;pipeline_encoder_devices&#39;: None, &#39;pipeline_decoder_balance&#39;: None, &#39;pipeline_decoder_devices&#39;: None, &#39;pipeline_checkpoint&#39;: never, &#39;zero_sharding&#39;: none, &#39;fp16&#39;: &#39;${common.fp16}&#39;, &#39;memory_efficient_fp16&#39;: &#39;${common.memory_efficient_fp16}&#39;, &#39;tpu&#39;: &#39;${common.tpu}&#39;, &#39;no_reshard_after_forward&#39;: False, &#39;fp32_reduce_scatter&#39;: False, &#39;cpu_offload&#39;: False, &#39;use_sharded_state&#39;: False}, &#39;dataset&#39;: {&#39;_name&#39;: None, &#39;num_workers&#39;: 1, &#39;skip_invalid_size_inputs_valid_test&#39;: False, &#39;max_tokens&#39;: None, &#39;batch_size&#39;: 1, &#39;required_batch_size_multiple&#39;: 8, &#39;required_seq_len_multiple&#39;: 1, &#39;dataset_impl&#39;: None, &#39;data_buffer_size&#39;: 10, &#39;train_subset&#39;: &#39;train&#39;, &#39;valid_subset&#39;: &#39;valid&#39;, &#39;combine_valid_subsets&#39;: None, &#39;ignore_unused_valid_subsets&#39;: False, &#39;validate_interval&#39;: 1, &#39;validate_interval_updates&#39;: 0, &#39;validate_after_updates&#39;: 0, &#39;fixed_validation_seed&#39;: None, &#39;disable_validation&#39;: False, &#39;max_tokens_valid&#39;: &#39;${dataset.max_tokens}&#39;, &#39;batch_size_valid&#39;: &#39;${dataset.batch_size}&#39;, &#39;max_valid_steps&#39;: None, &#39;curriculum&#39;: 0, &#39;gen_subset&#39;: &#39;valid&#39;, &#39;num_shards&#39;: 1, &#39;shard_id&#39;: 0}, &#39;optimization&#39;: {&#39;_name&#39;: None, &#39;max_epoch&#39;: 0, &#39;max_update&#39;: 0, &#39;stop_time_hours&#39;: 0.0, &#39;clip_norm&#39;: 0.0, &#39;sentence_avg&#39;: False, &#39;update_freq&#39;: [1], &#39;lr&#39;: [0.25], &#39;stop_min_lr&#39;: -1.0, &#39;use_bmuf&#39;: False}, &#39;checkpoint&#39;: {&#39;_name&#39;: None, &#39;save_dir&#39;: &#39;checkpoints&#39;, &#39;restore_file&#39;: &#39;checkpoint_last.pt&#39;, &#39;finetune_from_model&#39;: None, &#39;reset_dataloader&#39;: False, &#39;reset_lr_scheduler&#39;: False, &#39;reset_meters&#39;: False, &#39;reset_optimizer&#39;: False, &#39;optimizer_overrides&#39;: &#39;{}&#39;, &#39;save_interval&#39;: 1, &#39;save_interval_updates&#39;: 0, &#39;keep_interval_updates&#39;: -1, &#39;keep_interval_updates_pattern&#39;: -1, &#39;keep_last_epochs&#39;: -1, &#39;keep_best_checkpoints&#39;: -1, &#39;no_save&#39;: False, &#39;no_epoch_checkpoints&#39;: False, &#39;no_last_checkpoints&#39;: False, &#39;no_save_optimizer_state&#39;: False, &#39;best_checkpoint_metric&#39;: &#39;loss&#39;, &#39;maximize_best_checkpoint_metric&#39;: False, &#39;patience&#39;: -1, &#39;checkpoint_suffix&#39;: &#39;&#39;, &#39;checkpoint_shard_count&#39;: 1, &#39;load_checkpoint_on_all_dp_ranks&#39;: False, &#39;write_checkpoints_asynchronously&#39;: False, &#39;model_parallel_size&#39;: &#39;${common.model_parallel_size}&#39;}, &#39;bmuf&#39;: {&#39;_name&#39;: None, &#39;block_lr&#39;: 1.0, &#39;block_momentum&#39;: 0.875, &#39;global_sync_iter&#39;: 50, &#39;warmup_iterations&#39;: 500, &#39;use_nbm&#39;: False, &#39;average_sync&#39;: False, &#39;distributed_world_size&#39;: &#39;${distributed_training.distributed_world_size}&#39;}, &#39;generation&#39;: {&#39;_name&#39;: None, &#39;beam&#39;: 5, &#39;nbest&#39;: 1, &#39;max_len_a&#39;: 0.0, &#39;max_len_b&#39;: 200, &#39;min_len&#39;: 1, &#39;match_source_len&#39;: False, &#39;unnormalized&#39;: False, &#39;no_early_stop&#39;: False, &#39;no_beamable_mm&#39;: False, &#39;lenpen&#39;: 1.0, &#39;unkpen&#39;: 0.0, &#39;replace_unk&#39;: None, &#39;sacrebleu&#39;: False, &#39;score_reference&#39;: False, &#39;prefix_size&#39;: 0, &#39;no_repeat_ngram_size&#39;: 0, &#39;sampling&#39;: False, &#39;sampling_topk&#39;: -1, &#39;sampling_topp&#39;: -1.0, &#39;constraints&#39;: None, &#39;temperature&#39;: 1.0, &#39;diverse_beam_groups&#39;: -1, &#39;diverse_beam_strength&#39;: 0.5, &#39;diversity_rate&#39;: -1.0, &#39;print_alignment&#39;: None, &#39;print_step&#39;: False, &#39;lm_path&#39;: None, &#39;lm_weight&#39;: 0.0, &#39;iter_decode_eos_penalty&#39;: 0.0, &#39;iter_decode_max_iter&#39;: 10, &#39;iter_decode_force_max_iter&#39;: False, &#39;iter_decode_with_beam&#39;: 1, &#39;iter_decode_with_external_reranker&#39;: False, &#39;retain_iter_history&#39;: False, &#39;retain_dropout&#39;: False, &#39;retain_dropout_modules&#39;: None, &#39;decoding_format&#39;: None, &#39;no_seed_provided&#39;: False}, &#39;eval_lm&#39;: {&#39;_name&#39;: None, &#39;output_word_probs&#39;: False, &#39;output_word_stats&#39;: False, &#39;context_window&#39;: 0, &#39;softmax_batch&#39;: 9223372036854775807}, &#39;interactive&#39;: {&#39;_name&#39;: None, &#39;buffer_size&#39;: 0, &#39;input&#39;: &#39;-&#39;}, &#39;model&#39;: &#39;???&#39;, &#39;task&#39;: {&#39;_name&#39;: &#39;unpaired_audio_text&#39;, &#39;labels&#39;: &#39;phn&#39;, &#39;data&#39;: &#39;/content/precompute_pca512_cls128_mean&#39;, &#39;sort_by_length&#39;: False, &#39;shuffle&#39;: False, &#39;text_data&#39;: &#39;&#39;}, &#39;criterion&#39;: None, &#39;optimizer&#39;: None, &#39;lr_scheduler&#39;: None, &#39;scoring&#39;: None, &#39;bpe&#39;: None, &#39;tokenizer&#39;: None}, &#39;lm_weight&#39;: 2.0, &#39;w2l_decoder&#39;: &lt;DecoderType.VITERBI: 1&gt;, &#39;kaldi_decoder_config&#39;: None, &#39;lexicon&#39;: None, &#39;lm_model&#39;: None, &#39;unit_lm&#39;: False, &#39;beam_threshold&#39;: 50.0, &#39;beam_size_token&#39;: 100.0, &#39;beam&#39;: 5, &#39;nbest&#39;: 1, &#39;word_score&#39;: 1.0, &#39;unk_weight&#39;: -inf, &#39;sil_weight&#39;: 0.0, &#39;targets&#39;: None, &#39;results_path&#39;: &#39;/content/drive/MyDrive/w2vures&#39;, &#39;post_process&#39;: &#39;silence&#39;, &#39;vocab_usage_power&#39;: 2.0, &#39;viterbi_transcript&#39;: None, &#39;min_lm_ppl&#39;: 0.0, &#39;min_vt_uer&#39;: 0.0, &#39;blank_weight&#39;: 0.0, &#39;blank_mode&#39;: &#39;set&#39;, &#39;sil_is_blank&#39;: False, &#39;unsupervised_tuning&#39;: False, &#39;is_ax&#39;: False, &#39;job_logging_cfg&#39;: {&#39;version&#39;: 1, &#39;formatters&#39;: {&#39;simple&#39;: {&#39;format&#39;: &#39;[%(asctime)s][%(name)s][%(levelname)s] - %(message)s&#39;}}, &#39;handlers&#39;: {&#39;console&#39;: {&#39;class&#39;: &#39;logging.StreamHandler&#39;, &#39;formatter&#39;: &#39;simple&#39;, &#39;stream&#39;: &#39;ext://sys.stdout&#39;}, &#39;file&#39;: {&#39;class&#39;: &#39;logging.FileHandler&#39;, &#39;formatter&#39;: &#39;simple&#39;, &#39;filename&#39;: &#39;w2vu_generate.log&#39;}}, &#39;root&#39;: {&#39;level&#39;: &#39;INFO&#39;, &#39;handlers&#39;: [&#39;console&#39;, &#39;file&#39;]}, &#39;disable_existing_loggers&#39;: False}} [2021-06-19 19:24:18,629][__main__][INFO] - | loading model(s) from /content/drive/MyDrive/w2vu/checkpoint_best.pt [2021-06-19 19:24:22,829][unsupervised.data.extracted_features_dataset][INFO] - loaded 2019, skipped 0 samples [2021-06-19 19:24:22,829][unsupervised.tasks.unpaired_audio_text][INFO] - split valid has unpaired text? False [2021-06-19 19:24:22,833][__main__][INFO] - | /content/precompute_pca512_cls128_mean valid 2019 examples [2021-06-19 19:24:41,807][__main__][INFO] - WER: 158.79173813943652 [2021-06-19 19:24:41,808][__main__][INFO] - | Processed 2019 sentences (80270 tokens) in 18.9s (106.61 sentences/s, 4238.35 tokens/s) [2021-06-19 19:24:41,809][__main__][INFO] - | Generate valid with beam=5, lm_weight=2.0, word_score=1.0, sil_weight=0.0, blank_weight=0.0, WER: 158.79173813943652, LM_PPL: inf, num feats: 130753, length: 80270, UER to viterbi: 0, score: inf .",
            "url": "https://jimregan.github.io/notes/colab/wav2vec-u/2021/06/19/wav2vec-u-cv-swedish-w2vu-generate.html",
            "relUrl": "/colab/wav2vec-u/2021/06/19/wav2vec-u-cv-swedish-w2vu-generate.html",
            "date": " • Jun 19, 2021"
        }
        
    
  
    
        ,"post196": {
            "title": "Download Swedish Literature Bank",
            "content": "Original on Kaggle . !wget http://spraakbanken.gu.se/lb/resurser/meningsmangder/lb.xml.bz2 . !wget https://svn.spraakdata.gu.se/sb-arkiv/pub/frekvens/stats_LB.txt .",
            "url": "https://jimregan.github.io/notes/kaggle/swedish/2021/06/18/download-swedish-literature-bank.html",
            "relUrl": "/kaggle/swedish/2021/06/18/download-swedish-literature-bank.html",
            "date": " • Jun 18, 2021"
        }
        
    
  
    
        ,"post197": {
            "title": "Diarisation with pyannote.audio",
            "content": "!pip install pyannote.audio==1.1 . !wget http://www.bealoideasbeo.ie/bealoideas/httpdocs/fuaim/iomlan/teip/010T0013.mp3 . !ffmpeg -i 010T0013.mp3 -acodec pcm_s16le -ac 1 -ar 16000 010T0013.wav . import pyannote.core . import torch import pyannote.core pipeline = torch.hub.load(&#39;pyannote/pyannote-audio&#39;, &#39;dia&#39;) diarization = pipeline({&#39;audio&#39;: &#39;010T0013.wav&#39;}) . json = pyannote.core.json.dumps(diarization) . with open(&#39;010T0013.json&#39;, &#39;w&#39;) as f: f.write(json) .",
            "url": "https://jimregan.github.io/notes/diarisation/pyannote/2021/06/17/diarisation-with-pyannote.html",
            "relUrl": "/diarisation/pyannote/2021/06/17/diarisation-with-pyannote.html",
            "date": " • Jun 17, 2021"
        }
        
    
  
    
        ,"post198": {
            "title": "Poleval 2021 through wav2vec2",
            "content": "%%capture !pip install gdown . !gdown https://drive.google.com/uc?id=1b6MyyqgA9D1U7DX3Vtgda7f9ppkxjCXJ . Downloading... From: https://drive.google.com/uc?id=1b6MyyqgA9D1U7DX3Vtgda7f9ppkxjCXJ To: /content/poleval_wav.train.tar.gz 2.14GB [00:38, 55.7MB/s] . %%capture !tar zxvf poleval_wav.train.tar.gz &amp;&amp; rm poleval_wav.train.tar.gz . %%capture !pip install librosa webrtcvad . # VAD wrapper is taken from PyTorch Speaker Verification: # https://github.com/HarryVolek/PyTorch_Speaker_Verification # Copyright (c) 2019, HarryVolek # License: BSD-3-Clause # based on https://github.com/wiseman/py-webrtcvad/blob/master/example.py # Copyright (c) 2016 John Wiseman # License: MIT import collections import contextlib import numpy as np import sys import librosa import wave import webrtcvad #from hparam import hparam as hp sr = 16000 def read_wave(path, sr): &quot;&quot;&quot;Reads a .wav file. Takes the path, and returns (PCM audio data, sample rate). Assumes sample width == 2 &quot;&quot;&quot; with contextlib.closing(wave.open(path, &#39;rb&#39;)) as wf: num_channels = wf.getnchannels() assert num_channels == 1 sample_width = wf.getsampwidth() assert sample_width == 2 sample_rate = wf.getframerate() assert sample_rate in (8000, 16000, 32000, 48000) pcm_data = wf.readframes(wf.getnframes()) data, _ = librosa.load(path, sr) assert len(data.shape) == 1 assert sr in (8000, 16000, 32000, 48000) return data, pcm_data class Frame(object): &quot;&quot;&quot;Represents a &quot;frame&quot; of audio data.&quot;&quot;&quot; def __init__(self, bytes, timestamp, duration): self.bytes = bytes self.timestamp = timestamp self.duration = duration def frame_generator(frame_duration_ms, audio, sample_rate): &quot;&quot;&quot;Generates audio frames from PCM audio data. Takes the desired frame duration in milliseconds, the PCM data, and the sample rate. Yields Frames of the requested duration. &quot;&quot;&quot; n = int(sample_rate * (frame_duration_ms / 1000.0) * 2) offset = 0 timestamp = 0.0 duration = (float(n) / sample_rate) / 2.0 while offset + n &lt; len(audio): yield Frame(audio[offset:offset + n], timestamp, duration) timestamp += duration offset += n def vad_collector(sample_rate, frame_duration_ms, padding_duration_ms, vad, frames): &quot;&quot;&quot;Filters out non-voiced audio frames. Given a webrtcvad.Vad and a source of audio frames, yields only the voiced audio. Uses a padded, sliding window algorithm over the audio frames. When more than 90% of the frames in the window are voiced (as reported by the VAD), the collector triggers and begins yielding audio frames. Then the collector waits until 90% of the frames in the window are unvoiced to detrigger. The window is padded at the front and back to provide a small amount of silence or the beginnings/endings of speech around the voiced frames. Arguments: sample_rate - The audio sample rate, in Hz. frame_duration_ms - The frame duration in milliseconds. padding_duration_ms - The amount to pad the window, in milliseconds. vad - An instance of webrtcvad.Vad. frames - a source of audio frames (sequence or generator). Returns: A generator that yields PCM audio data. &quot;&quot;&quot; num_padding_frames = int(padding_duration_ms / frame_duration_ms) # We use a deque for our sliding window/ring buffer. ring_buffer = collections.deque(maxlen=num_padding_frames) # We have two states: TRIGGERED and NOTTRIGGERED. We start in the # NOTTRIGGERED state. triggered = False voiced_frames = [] for frame in frames: is_speech = vad.is_speech(frame.bytes, sample_rate) if not triggered: ring_buffer.append((frame, is_speech)) num_voiced = len([f for f, speech in ring_buffer if speech]) # If we&#39;re NOTTRIGGERED and more than 90% of the frames in # the ring buffer are voiced frames, then enter the # TRIGGERED state. if num_voiced &gt; 0.9 * ring_buffer.maxlen: triggered = True start = ring_buffer[0][0].timestamp # We want to yield all the audio we see from now until # we are NOTTRIGGERED, but we have to start with the # audio that&#39;s already in the ring buffer. for f, s in ring_buffer: voiced_frames.append(f) ring_buffer.clear() else: # We&#39;re in the TRIGGERED state, so collect the audio data # and add it to the ring buffer. voiced_frames.append(frame) ring_buffer.append((frame, is_speech)) num_unvoiced = len([f for f, speech in ring_buffer if not speech]) # If more than 90% of the frames in the ring buffer are # unvoiced, then enter NOTTRIGGERED and yield whatever # audio we&#39;ve collected. if num_unvoiced &gt; 0.9 * ring_buffer.maxlen: triggered = False yield (start, frame.timestamp + frame.duration) ring_buffer.clear() voiced_frames = [] # If we have any leftover voiced audio when we run out of input, # yield it. if voiced_frames: yield (start, frame.timestamp + frame.duration) def VAD_chunk(aggressiveness, path): audio, byte_audio = read_wave(path, sr) vad = webrtcvad.Vad(int(aggressiveness)) frames = frame_generator(20, byte_audio, sr) frames = list(frames) times = vad_collector(sr, 20, 200, vad, frames) speech_times = [] speech_segs = [] for i, time in enumerate(times): start = np.round(time[0],decimals=2) end = np.round(time[1],decimals=2) j = start while j + .4 &lt; end: end_j = np.round(j+.4,decimals=2) speech_times.append((j, end_j)) speech_segs.append(audio[int(j*sr):int(end_j*sr)]) j = end_j else: speech_times.append((j, end)) speech_segs.append(audio[int(j*sr):int(end*sr)]) return speech_times, speech_segs . . # Based on code from PyTorch Speaker Verification: # https://github.com/HarryVolek/PyTorch_Speaker_Verification # Copyright (c) 2019, HarryVolek # Additions Copyright (c) 2021, Jim O&#39;Regan # License: MIT import numpy as np # wav2vec2&#39;s max duration is 40 seconds, using 39 by default # to be a little safer def vad_concat(times, segs, max_duration=39.0): &quot;&quot;&quot; Concatenate continuous times and their segments, where the end time of a segment is the same as the start time of the next Parameters: times: list of tuple (start, end) segs: list of segments (audio frames) max_duration: maximum duration of the resulting concatenated segments; the kernel size of wav2vec2 is 40 seconds, so the default max_duration is 39, to ensure the resulting list of segments will fit Returns: concat_times: list of tuple (start, end) concat_segs: list of segments (audio frames) &quot;&quot;&quot; absolute_maximum=40.0 if max_duration &gt; absolute_maximum: raise Exception(&#39;`max_duration` {:.2f} larger than kernel size (40 seconds)&#39;.format(max_duration)) # we take 0.0 to mean &quot;don&#39;t concatenate&quot; do_concat = (max_duration != 0.0) concat_seg = [] concat_times = [] seg_concat = segs[0] time_concat = times[0] for i in range(0, len(times)-1): can_concat = (times[i+1][1] - time_concat[0]) &lt; max_duration if time_concat[1] == times[i+1][0] and do_concat and can_concat: seg_concat = np.concatenate((seg_concat, segs[i+1])) time_concat = (time_concat[0], times[i+1][1]) else: concat_seg.append(seg_concat) seg_concat = segs[i+1] concat_times.append(time_concat) time_concat = times[i+1] else: concat_seg.append(seg_concat) concat_times.append(time_concat) return concat_times, concat_seg . . def make_dataset(concat_times, concat_segs): starts = [s[0] for s in concat_times] ends = [s[1] for s in concat_times] return {&#39;start&#39;: starts, &#39;end&#39;: ends, &#39;speech&#39;: concat_segs} . %%capture !pip install datasets . from datasets import Dataset def vad_to_dataset(path, max_duration): t,s = VAD_chunk(3, path) if max_duration &gt; 0.0: ct, cs = vad_concat(t, s, max_duration) dset = make_dataset(ct, cs) else: dset = make_dataset(t, s) return Dataset.from_dict(dset) . %%capture !pip install -q transformers . %%capture from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC # load model and tokenizer processor = Wav2Vec2Processor.from_pretrained(&quot;mbien/wav2vec2-large-xlsr-polish&quot;) model = Wav2Vec2ForCTC.from_pretrained(&quot;mbien/wav2vec2-large-xlsr-polish&quot;) model.to(&quot;cuda&quot;) . def speech_file_to_array_fn(batch): import torchaudio speech_array, sampling_rate = torchaudio.load(batch[&quot;path&quot;]) batch[&quot;speech&quot;] = speech_array[0].numpy() batch[&quot;sampling_rate&quot;] = sampling_rate batch[&quot;target_text&quot;] = batch[&quot;sentence&quot;] return batch def evaluate(batch): import torch inputs = processor(batch[&quot;speech&quot;], sampling_rate=16_000, return_tensors=&quot;pt&quot;, padding=True) with torch.no_grad(): logits = model(inputs.input_values.to(&quot;cuda&quot;), attention_mask=inputs.attention_mask.to(&quot;cuda&quot;)).logits pred_ids = torch.argmax(logits, dim=-1) batch[&quot;pred_strings&quot;] = processor.batch_decode(pred_ids) return batch . import json def process_wave(filename, duration): import json dataset = vad_to_dataset(filename, duration) result = dataset.map(evaluate, batched=True, batch_size=16) speechless = result.remove_columns([&#39;speech&#39;]) d=speechless.to_dict() tlog = list() for i in range(0, len(d[&#39;end&#39;]) - 1): out = dict() out[&#39;start&#39;] = d[&#39;start&#39;][i] out[&#39;end&#39;] = d[&#39;end&#39;][i] out[&#39;transcript&#39;] = d[&#39;pred_strings&#39;][i] tlog.append(out) with open(&#39;{}.tlog&#39;.format(filename), &#39;w&#39;) as outfile: json.dump(tlog, outfile) . import glob for f in glob.glob(&#39;/content/poleval_final_dataset_wav/train/*.wav&#39;): print(f) process_wave(f, 10.0) . !find . -name &#39;*tlog&#39;|zip poleval-train.zip -@ .",
            "url": "https://jimregan.github.io/notes/wav2vec2/poleval/colab/2021/06/16/poleval-through-wav2vec2.html",
            "relUrl": "/wav2vec2/poleval/colab/2021/06/16/poleval-through-wav2vec2.html",
            "date": " • Jun 16, 2021"
        }
        
    
  
    
        ,"post199": {
            "title": "Poleval 2021 punctuation restoration data",
            "content": "Original here . !pip install gdown . !gdown https://drive.google.com/uc?id=1PYfEhg-zGwnJ07HIaimlD3EgILPOBojq !gdown https://drive.google.com/uc?id=1b6MyyqgA9D1U7DX3Vtgda7f9ppkxjCXJ !gdown https://drive.google.com/uc?id=1gwQRvrUtFqz3xGnmEN8znAzkBwC12Czu !gdown https://drive.google.com/uc?id=16MaKgexMtMhQL6sftMsS3H1pPjJqY_zx . Downloading... From: https://drive.google.com/uc?id=1PYfEhg-zGwnJ07HIaimlD3EgILPOBojq To: /kaggle/working/poleval_fa.train.tar.gz 100%|██████████████████████████████████████| 1.45M/1.45M [00:00&lt;00:00, 95.9MB/s] Downloading... From: https://drive.google.com/uc?id=1b6MyyqgA9D1U7DX3Vtgda7f9ppkxjCXJ To: /kaggle/working/poleval_wav.train.tar.gz 2.14GB [00:24, 86.7MB/s] Downloading... From: https://drive.google.com/uc?id=1gwQRvrUtFqz3xGnmEN8znAzkBwC12Czu To: /kaggle/working/poleval_wav.validation.tar.gz 537MB [00:08, 64.6MB/s] Downloading... From: https://drive.google.com/uc?id=16MaKgexMtMhQL6sftMsS3H1pPjJqY_zx To: /kaggle/working/poleval_text.rest.tar.gz 48.8MB [00:01, 29.6MB/s] .",
            "url": "https://jimregan.github.io/notes/asr/polish/kaggle/2021/06/16/poleval-2021-punctuation-restoration-data.html",
            "relUrl": "/asr/polish/kaggle/2021/06/16/poleval-2021-punctuation-restoration-data.html",
            "date": " • Jun 16, 2021"
        }
        
    
  
    
        ,"post200": {
            "title": "Poleval 2021 wav durations",
            "content": "%cd /tmp . /tmp . %%capture !tar zxvf /kaggle/input/poleval-2021-punctuation-restoration-data/poleval_wav.train.tar.gz . !for i in poleval_final_dataset_wav/train/*.wav;do ffmpeg -i $i 2&gt;&amp;1 | grep &quot;Duration&quot;;done . Duration: 00:01:50.34, bitrate: 256 kb/s Duration: 00:01:24.78, bitrate: 256 kb/s Duration: 00:01:17.90, bitrate: 256 kb/s Duration: 00:01:53.58, bitrate: 256 kb/s Duration: 00:01:09.72, bitrate: 256 kb/s Duration: 00:02:34.74, bitrate: 256 kb/s Duration: 00:01:22.14, bitrate: 256 kb/s Duration: 00:01:58.56, bitrate: 256 kb/s Duration: 00:01:45.78, bitrate: 256 kb/s Duration: 00:02:14.04, bitrate: 256 kb/s Duration: 00:01:34.72, bitrate: 256 kb/s Duration: 00:01:11.61, bitrate: 256 kb/s Duration: 00:01:07.25, bitrate: 256 kb/s Duration: 00:01:26.52, bitrate: 256 kb/s Duration: 00:01:40.56, bitrate: 256 kb/s Duration: 00:02:03.72, bitrate: 256 kb/s Duration: 00:02:13.02, bitrate: 256 kb/s Duration: 00:01:42.19, bitrate: 256 kb/s Duration: 00:01:26.94, bitrate: 256 kb/s Duration: 00:01:17.22, bitrate: 256 kb/s Duration: 00:01:55.62, bitrate: 256 kb/s Duration: 00:01:14.52, bitrate: 256 kb/s Duration: 00:01:22.14, bitrate: 256 kb/s Duration: 00:01:38.28, bitrate: 256 kb/s Duration: 00:01:44.52, bitrate: 256 kb/s Duration: 00:01:27.66, bitrate: 256 kb/s Duration: 00:01:55.97, bitrate: 256 kb/s Duration: 00:01:31.44, bitrate: 256 kb/s Duration: 00:01:54.71, bitrate: 256 kb/s Duration: 00:01:52.38, bitrate: 256 kb/s Duration: 00:01:56.28, bitrate: 256 kb/s Duration: 00:01:39.15, bitrate: 256 kb/s Duration: 00:02:26.28, bitrate: 256 kb/s Duration: 00:01:33.30, bitrate: 256 kb/s Duration: 00:01:57.72, bitrate: 256 kb/s Duration: 00:01:21.96, bitrate: 256 kb/s Duration: 00:01:39.36, bitrate: 256 kb/s Duration: 00:01:22.32, bitrate: 256 kb/s Duration: 00:01:34.36, bitrate: 256 kb/s Duration: 00:02:29.35, bitrate: 256 kb/s Duration: 00:01:22.13, bitrate: 256 kb/s Duration: 00:01:37.74, bitrate: 256 kb/s Duration: 00:01:47.04, bitrate: 256 kb/s Duration: 00:02:51.36, bitrate: 256 kb/s Duration: 00:01:05.40, bitrate: 256 kb/s Duration: 00:01:23.10, bitrate: 256 kb/s Duration: 00:01:33.22, bitrate: 256 kb/s Duration: 00:01:21.00, bitrate: 256 kb/s Duration: 00:01:21.15, bitrate: 256 kb/s Duration: 00:01:24.22, bitrate: 256 kb/s Duration: 00:01:31.62, bitrate: 256 kb/s Duration: 00:01:28.98, bitrate: 256 kb/s Duration: 00:01:15.30, bitrate: 256 kb/s Duration: 00:01:32.40, bitrate: 256 kb/s Duration: 00:01:08.44, bitrate: 256 kb/s Duration: 00:01:17.88, bitrate: 256 kb/s Duration: 00:01:15.66, bitrate: 256 kb/s Duration: 00:01:54.19, bitrate: 256 kb/s Duration: 00:01:41.34, bitrate: 256 kb/s Duration: 00:01:26.24, bitrate: 256 kb/s Duration: 00:02:12.45, bitrate: 256 kb/s Duration: 00:01:12.23, bitrate: 256 kb/s Duration: 00:01:13.10, bitrate: 256 kb/s Duration: 00:01:12.90, bitrate: 256 kb/s Duration: 00:01:14.70, bitrate: 256 kb/s Duration: 00:01:33.24, bitrate: 256 kb/s Duration: 00:01:20.70, bitrate: 256 kb/s Duration: 00:02:06.66, bitrate: 256 kb/s Duration: 00:01:34.74, bitrate: 256 kb/s Duration: 00:01:38.64, bitrate: 256 kb/s Duration: 00:02:02.07, bitrate: 256 kb/s Duration: 00:01:25.25, bitrate: 256 kb/s Duration: 00:01:06.68, bitrate: 256 kb/s Duration: 00:01:35.94, bitrate: 256 kb/s Duration: 00:02:09.75, bitrate: 256 kb/s Duration: 00:02:04.29, bitrate: 256 kb/s Duration: 00:01:44.12, bitrate: 256 kb/s Duration: 00:01:22.44, bitrate: 256 kb/s Duration: 00:01:00.60, bitrate: 256 kb/s Duration: 00:01:25.44, bitrate: 256 kb/s Duration: 00:02:00.00, bitrate: 256 kb/s Duration: 00:02:30.72, bitrate: 256 kb/s Duration: 00:01:51.30, bitrate: 256 kb/s Duration: 00:02:00.41, bitrate: 256 kb/s Duration: 00:01:46.62, bitrate: 256 kb/s Duration: 00:01:22.50, bitrate: 256 kb/s Duration: 00:01:33.20, bitrate: 256 kb/s Duration: 00:01:29.58, bitrate: 256 kb/s Duration: 00:01:47.70, bitrate: 256 kb/s Duration: 00:02:40.32, bitrate: 256 kb/s Duration: 00:01:26.70, bitrate: 256 kb/s Duration: 00:02:05.34, bitrate: 256 kb/s Duration: 00:01:23.64, bitrate: 256 kb/s Duration: 00:01:20.16, bitrate: 256 kb/s Duration: 00:02:21.60, bitrate: 256 kb/s Duration: 00:01:19.26, bitrate: 256 kb/s Duration: 00:01:54.04, bitrate: 256 kb/s Duration: 00:01:34.02, bitrate: 256 kb/s Duration: 00:01:21.96, bitrate: 256 kb/s Duration: 00:01:42.66, bitrate: 256 kb/s Duration: 00:01:44.45, bitrate: 256 kb/s Duration: 00:01:58.26, bitrate: 256 kb/s Duration: 00:00:59.18, bitrate: 256 kb/s Duration: 00:02:40.20, bitrate: 256 kb/s Duration: 00:01:49.02, bitrate: 256 kb/s Duration: 00:01:17.52, bitrate: 256 kb/s Duration: 00:01:13.98, bitrate: 256 kb/s Duration: 00:01:11.77, bitrate: 256 kb/s Duration: 00:01:13.38, bitrate: 256 kb/s Duration: 00:01:34.98, bitrate: 256 kb/s Duration: 00:02:47.88, bitrate: 256 kb/s Duration: 00:01:03.36, bitrate: 256 kb/s Duration: 00:00:56.88, bitrate: 256 kb/s Duration: 00:01:29.54, bitrate: 256 kb/s Duration: 00:01:28.84, bitrate: 256 kb/s Duration: 00:02:08.34, bitrate: 256 kb/s Duration: 00:00:55.47, bitrate: 256 kb/s Duration: 00:02:00.84, bitrate: 256 kb/s Duration: 00:01:43.44, bitrate: 256 kb/s Duration: 00:02:03.39, bitrate: 256 kb/s Duration: 00:01:12.30, bitrate: 256 kb/s Duration: 00:00:59.40, bitrate: 256 kb/s Duration: 00:01:21.18, bitrate: 256 kb/s Duration: 00:01:11.52, bitrate: 256 kb/s Duration: 00:02:04.74, bitrate: 256 kb/s Duration: 00:01:31.44, bitrate: 256 kb/s Duration: 00:01:07.68, bitrate: 256 kb/s Duration: 00:01:23.10, bitrate: 256 kb/s Duration: 00:02:44.94, bitrate: 256 kb/s Duration: 00:01:52.43, bitrate: 256 kb/s Duration: 00:01:16.86, bitrate: 256 kb/s Duration: 00:01:34.56, bitrate: 256 kb/s Duration: 00:01:57.12, bitrate: 256 kb/s Duration: 00:02:18.18, bitrate: 256 kb/s Duration: 00:01:28.26, bitrate: 256 kb/s Duration: 00:01:31.38, bitrate: 256 kb/s Duration: 00:02:25.02, bitrate: 256 kb/s Duration: 00:01:19.92, bitrate: 256 kb/s Duration: 00:01:14.04, bitrate: 256 kb/s Duration: 00:01:14.16, bitrate: 256 kb/s Duration: 00:01:15.00, bitrate: 256 kb/s Duration: 00:01:44.92, bitrate: 256 kb/s Duration: 00:01:30.66, bitrate: 256 kb/s Duration: 00:01:57.90, bitrate: 256 kb/s Duration: 00:01:59.76, bitrate: 256 kb/s Duration: 00:01:32.58, bitrate: 256 kb/s Duration: 00:01:16.56, bitrate: 256 kb/s Duration: 00:01:34.38, bitrate: 256 kb/s Duration: 00:01:37.96, bitrate: 256 kb/s Duration: 00:01:49.74, bitrate: 256 kb/s Duration: 00:01:15.54, bitrate: 256 kb/s Duration: 00:01:23.04, bitrate: 256 kb/s Duration: 00:02:08.38, bitrate: 256 kb/s Duration: 00:01:41.76, bitrate: 256 kb/s Duration: 00:01:12.54, bitrate: 256 kb/s Duration: 00:01:24.96, bitrate: 256 kb/s Duration: 00:01:52.43, bitrate: 256 kb/s Duration: 00:00:58.51, bitrate: 256 kb/s Duration: 00:01:48.06, bitrate: 256 kb/s Duration: 00:01:10.27, bitrate: 256 kb/s Duration: 00:02:35.73, bitrate: 256 kb/s Duration: 00:02:28.26, bitrate: 256 kb/s Duration: 00:02:08.96, bitrate: 256 kb/s Duration: 00:01:19.91, bitrate: 256 kb/s Duration: 00:01:20.21, bitrate: 256 kb/s Duration: 00:01:11.68, bitrate: 256 kb/s Duration: 00:01:38.46, bitrate: 256 kb/s Duration: 00:01:58.80, bitrate: 256 kb/s Duration: 00:01:16.68, bitrate: 256 kb/s Duration: 00:01:18.36, bitrate: 256 kb/s Duration: 00:01:18.07, bitrate: 256 kb/s Duration: 00:01:29.64, bitrate: 256 kb/s Duration: 00:02:06.12, bitrate: 256 kb/s Duration: 00:01:05.64, bitrate: 256 kb/s Duration: 00:01:25.80, bitrate: 256 kb/s Duration: 00:02:22.32, bitrate: 256 kb/s Duration: 00:02:00.00, bitrate: 256 kb/s Duration: 00:01:13.98, bitrate: 256 kb/s Duration: 00:01:14.42, bitrate: 256 kb/s Duration: 00:01:22.50, bitrate: 256 kb/s Duration: 00:02:00.79, bitrate: 256 kb/s Duration: 00:02:13.68, bitrate: 256 kb/s Duration: 00:02:18.24, bitrate: 256 kb/s Duration: 00:01:21.49, bitrate: 256 kb/s Duration: 00:01:34.21, bitrate: 256 kb/s Duration: 00:01:34.80, bitrate: 256 kb/s Duration: 00:02:17.52, bitrate: 256 kb/s Duration: 00:01:20.28, bitrate: 256 kb/s Duration: 00:01:27.78, bitrate: 256 kb/s Duration: 00:01:56.28, bitrate: 256 kb/s Duration: 00:01:14.46, bitrate: 256 kb/s Duration: 00:01:11.94, bitrate: 256 kb/s Duration: 00:01:32.82, bitrate: 256 kb/s Duration: 00:02:18.66, bitrate: 256 kb/s Duration: 00:01:45.96, bitrate: 256 kb/s Duration: 00:01:29.30, bitrate: 256 kb/s Duration: 00:01:52.20, bitrate: 256 kb/s Duration: 00:01:15.72, bitrate: 256 kb/s Duration: 00:01:20.40, bitrate: 256 kb/s Duration: 00:01:33.54, bitrate: 256 kb/s Duration: 00:01:43.32, bitrate: 256 kb/s Duration: 00:01:53.76, bitrate: 256 kb/s Duration: 00:01:12.06, bitrate: 256 kb/s Duration: 00:01:26.27, bitrate: 256 kb/s Duration: 00:01:19.68, bitrate: 256 kb/s Duration: 00:01:24.82, bitrate: 256 kb/s Duration: 00:01:33.53, bitrate: 256 kb/s Duration: 00:01:28.74, bitrate: 256 kb/s Duration: 00:01:53.16, bitrate: 256 kb/s Duration: 00:01:29.64, bitrate: 256 kb/s Duration: 00:01:28.56, bitrate: 256 kb/s Duration: 00:01:44.38, bitrate: 256 kb/s Duration: 00:02:02.46, bitrate: 256 kb/s Duration: 00:01:09.29, bitrate: 256 kb/s Duration: 00:01:35.80, bitrate: 256 kb/s Duration: 00:00:59.95, bitrate: 256 kb/s Duration: 00:01:46.32, bitrate: 256 kb/s Duration: 00:01:32.40, bitrate: 256 kb/s Duration: 00:01:23.82, bitrate: 256 kb/s Duration: 00:01:45.02, bitrate: 256 kb/s Duration: 00:01:57.90, bitrate: 256 kb/s Duration: 00:01:37.32, bitrate: 256 kb/s Duration: 00:01:58.44, bitrate: 256 kb/s Duration: 00:01:28.66, bitrate: 256 kb/s Duration: 00:01:33.78, bitrate: 256 kb/s Duration: 00:01:49.23, bitrate: 256 kb/s Duration: 00:01:35.34, bitrate: 256 kb/s Duration: 00:01:44.63, bitrate: 256 kb/s Duration: 00:01:46.50, bitrate: 256 kb/s Duration: 00:01:56.04, bitrate: 256 kb/s Duration: 00:01:13.72, bitrate: 256 kb/s Duration: 00:01:14.76, bitrate: 256 kb/s Duration: 00:01:29.16, bitrate: 256 kb/s Duration: 00:01:13.38, bitrate: 256 kb/s Duration: 00:01:27.08, bitrate: 256 kb/s Duration: 00:01:50.10, bitrate: 256 kb/s Duration: 00:02:05.27, bitrate: 256 kb/s Duration: 00:01:59.07, bitrate: 256 kb/s Duration: 00:01:25.03, bitrate: 256 kb/s Duration: 00:01:25.89, bitrate: 256 kb/s Duration: 00:01:37.68, bitrate: 256 kb/s Duration: 00:01:12.53, bitrate: 256 kb/s Duration: 00:01:40.26, bitrate: 256 kb/s Duration: 00:01:25.80, bitrate: 256 kb/s Duration: 00:01:31.44, bitrate: 256 kb/s Duration: 00:01:02.29, bitrate: 256 kb/s Duration: 00:01:42.06, bitrate: 256 kb/s Duration: 00:01:47.82, bitrate: 256 kb/s Duration: 00:01:13.86, bitrate: 256 kb/s Duration: 00:01:27.44, bitrate: 256 kb/s Duration: 00:01:18.84, bitrate: 256 kb/s Duration: 00:01:28.38, bitrate: 256 kb/s Duration: 00:02:04.50, bitrate: 256 kb/s Duration: 00:01:27.49, bitrate: 256 kb/s Duration: 00:01:41.28, bitrate: 256 kb/s Duration: 00:01:30.06, bitrate: 256 kb/s Duration: 00:02:03.42, bitrate: 256 kb/s Duration: 00:01:39.54, bitrate: 256 kb/s Duration: 00:01:05.76, bitrate: 256 kb/s Duration: 00:02:08.76, bitrate: 256 kb/s Duration: 00:02:29.34, bitrate: 256 kb/s Duration: 00:01:15.00, bitrate: 256 kb/s Duration: 00:01:07.26, bitrate: 256 kb/s Duration: 00:02:16.06, bitrate: 256 kb/s Duration: 00:01:35.58, bitrate: 256 kb/s Duration: 00:01:37.62, bitrate: 256 kb/s Duration: 00:02:07.32, bitrate: 256 kb/s Duration: 00:01:33.66, bitrate: 256 kb/s Duration: 00:01:42.30, bitrate: 256 kb/s Duration: 00:01:52.02, bitrate: 256 kb/s Duration: 00:01:36.24, bitrate: 256 kb/s Duration: 00:01:20.70, bitrate: 256 kb/s Duration: 00:01:09.47, bitrate: 256 kb/s Duration: 00:01:34.27, bitrate: 256 kb/s Duration: 00:01:33.12, bitrate: 256 kb/s Duration: 00:01:21.32, bitrate: 256 kb/s Duration: 00:01:43.56, bitrate: 256 kb/s Duration: 00:01:13.26, bitrate: 256 kb/s Duration: 00:01:20.10, bitrate: 256 kb/s Duration: 00:01:18.96, bitrate: 256 kb/s Duration: 00:01:50.76, bitrate: 256 kb/s Duration: 00:01:53.16, bitrate: 256 kb/s Duration: 00:01:16.25, bitrate: 256 kb/s Duration: 00:02:17.51, bitrate: 256 kb/s Duration: 00:01:26.58, bitrate: 256 kb/s Duration: 00:01:03.96, bitrate: 256 kb/s Duration: 00:01:14.45, bitrate: 256 kb/s Duration: 00:01:39.06, bitrate: 256 kb/s Duration: 00:01:17.10, bitrate: 256 kb/s Duration: 00:01:23.46, bitrate: 256 kb/s Duration: 00:01:20.46, bitrate: 256 kb/s Duration: 00:01:40.62, bitrate: 256 kb/s Duration: 00:01:10.45, bitrate: 256 kb/s Duration: 00:01:59.04, bitrate: 256 kb/s Duration: 00:02:12.95, bitrate: 256 kb/s Duration: 00:01:11.28, bitrate: 256 kb/s Duration: 00:01:47.52, bitrate: 256 kb/s Duration: 00:01:38.05, bitrate: 256 kb/s Duration: 00:01:53.45, bitrate: 256 kb/s Duration: 00:01:49.08, bitrate: 256 kb/s Duration: 00:01:20.13, bitrate: 256 kb/s Duration: 00:01:31.20, bitrate: 256 kb/s Duration: 00:01:54.96, bitrate: 256 kb/s Duration: 00:02:13.74, bitrate: 256 kb/s Duration: 00:01:52.56, bitrate: 256 kb/s Duration: 00:02:05.04, bitrate: 256 kb/s Duration: 00:01:47.28, bitrate: 256 kb/s Duration: 00:01:30.70, bitrate: 256 kb/s Duration: 00:01:48.54, bitrate: 256 kb/s Duration: 00:01:19.80, bitrate: 256 kb/s Duration: 00:02:17.28, bitrate: 256 kb/s Duration: 00:01:53.04, bitrate: 256 kb/s Duration: 00:01:14.34, bitrate: 256 kb/s Duration: 00:01:24.78, bitrate: 256 kb/s Duration: 00:01:40.56, bitrate: 256 kb/s Duration: 00:01:26.22, bitrate: 256 kb/s Duration: 00:01:21.66, bitrate: 256 kb/s Duration: 00:01:49.48, bitrate: 256 kb/s Duration: 00:01:41.46, bitrate: 256 kb/s Duration: 00:01:13.74, bitrate: 256 kb/s Duration: 00:01:52.38, bitrate: 256 kb/s Duration: 00:01:26.94, bitrate: 256 kb/s Duration: 00:01:45.30, bitrate: 256 kb/s Duration: 00:01:26.58, bitrate: 256 kb/s Duration: 00:02:02.10, bitrate: 256 kb/s Duration: 00:01:22.73, bitrate: 256 kb/s Duration: 00:01:42.84, bitrate: 256 kb/s Duration: 00:02:14.52, bitrate: 256 kb/s Duration: 00:02:09.66, bitrate: 256 kb/s Duration: 00:01:30.98, bitrate: 256 kb/s Duration: 00:02:09.54, bitrate: 256 kb/s Duration: 00:01:18.60, bitrate: 256 kb/s Duration: 00:01:33.24, bitrate: 256 kb/s Duration: 00:01:33.78, bitrate: 256 kb/s Duration: 00:02:07.74, bitrate: 256 kb/s Duration: 00:01:22.02, bitrate: 256 kb/s Duration: 00:01:50.98, bitrate: 256 kb/s Duration: 00:01:32.10, bitrate: 256 kb/s Duration: 00:01:59.40, bitrate: 256 kb/s Duration: 00:01:25.20, bitrate: 256 kb/s Duration: 00:01:40.26, bitrate: 256 kb/s Duration: 00:01:07.08, bitrate: 256 kb/s Duration: 00:01:48.38, bitrate: 256 kb/s Duration: 00:01:26.28, bitrate: 256 kb/s Duration: 00:02:14.94, bitrate: 256 kb/s Duration: 00:02:10.54, bitrate: 256 kb/s Duration: 00:01:37.50, bitrate: 256 kb/s Duration: 00:02:26.70, bitrate: 256 kb/s Duration: 00:01:57.72, bitrate: 256 kb/s Duration: 00:01:20.94, bitrate: 256 kb/s Duration: 00:01:36.06, bitrate: 256 kb/s Duration: 00:01:48.78, bitrate: 256 kb/s Duration: 00:01:32.76, bitrate: 256 kb/s Duration: 00:01:45.64, bitrate: 256 kb/s Duration: 00:02:19.26, bitrate: 256 kb/s Duration: 00:01:13.75, bitrate: 256 kb/s Duration: 00:01:54.90, bitrate: 256 kb/s Duration: 00:01:16.12, bitrate: 256 kb/s Duration: 00:01:42.84, bitrate: 256 kb/s Duration: 00:01:22.68, bitrate: 256 kb/s Duration: 00:01:25.62, bitrate: 256 kb/s Duration: 00:01:33.18, bitrate: 256 kb/s Duration: 00:01:34.74, bitrate: 256 kb/s Duration: 00:01:45.42, bitrate: 256 kb/s Duration: 00:01:41.04, bitrate: 256 kb/s Duration: 00:01:58.14, bitrate: 256 kb/s Duration: 00:02:11.52, bitrate: 256 kb/s Duration: 00:02:01.04, bitrate: 256 kb/s Duration: 00:01:39.36, bitrate: 256 kb/s Duration: 00:01:26.70, bitrate: 256 kb/s Duration: 00:01:59.28, bitrate: 256 kb/s Duration: 00:02:12.72, bitrate: 256 kb/s Duration: 00:01:33.96, bitrate: 256 kb/s Duration: 00:01:44.03, bitrate: 256 kb/s Duration: 00:01:44.10, bitrate: 256 kb/s Duration: 00:01:06.12, bitrate: 256 kb/s Duration: 00:02:28.46, bitrate: 256 kb/s Duration: 00:02:06.78, bitrate: 256 kb/s Duration: 00:01:57.18, bitrate: 256 kb/s Duration: 00:01:20.52, bitrate: 256 kb/s Duration: 00:01:42.84, bitrate: 256 kb/s Duration: 00:01:33.54, bitrate: 256 kb/s Duration: 00:01:41.10, bitrate: 256 kb/s Duration: 00:02:47.74, bitrate: 256 kb/s Duration: 00:02:25.32, bitrate: 256 kb/s Duration: 00:01:50.58, bitrate: 256 kb/s Duration: 00:01:39.18, bitrate: 256 kb/s Duration: 00:01:52.80, bitrate: 256 kb/s Duration: 00:01:23.58, bitrate: 256 kb/s Duration: 00:01:10.36, bitrate: 256 kb/s Duration: 00:01:36.30, bitrate: 256 kb/s Duration: 00:01:36.06, bitrate: 256 kb/s Duration: 00:01:34.32, bitrate: 256 kb/s Duration: 00:02:53.40, bitrate: 256 kb/s Duration: 00:02:19.55, bitrate: 256 kb/s Duration: 00:01:07.02, bitrate: 256 kb/s Duration: 00:01:24.84, bitrate: 256 kb/s Duration: 00:01:26.36, bitrate: 256 kb/s Duration: 00:01:36.30, bitrate: 256 kb/s Duration: 00:01:28.65, bitrate: 256 kb/s Duration: 00:01:59.64, bitrate: 256 kb/s Duration: 00:01:59.82, bitrate: 256 kb/s Duration: 00:02:19.69, bitrate: 256 kb/s Duration: 00:01:48.42, bitrate: 256 kb/s Duration: 00:01:27.89, bitrate: 256 kb/s Duration: 00:02:45.30, bitrate: 256 kb/s Duration: 00:01:53.34, bitrate: 256 kb/s Duration: 00:01:52.80, bitrate: 256 kb/s Duration: 00:01:37.80, bitrate: 256 kb/s Duration: 00:02:03.54, bitrate: 256 kb/s Duration: 00:01:35.70, bitrate: 256 kb/s Duration: 00:02:00.42, bitrate: 256 kb/s Duration: 00:02:21.60, bitrate: 256 kb/s Duration: 00:01:24.95, bitrate: 256 kb/s Duration: 00:02:11.34, bitrate: 256 kb/s Duration: 00:01:07.16, bitrate: 256 kb/s Duration: 00:01:29.94, bitrate: 256 kb/s Duration: 00:02:53.46, bitrate: 256 kb/s Duration: 00:02:24.96, bitrate: 256 kb/s Duration: 00:01:21.24, bitrate: 256 kb/s Duration: 00:03:23.48, bitrate: 256 kb/s Duration: 00:02:08.40, bitrate: 256 kb/s Duration: 00:01:32.40, bitrate: 256 kb/s Duration: 00:01:55.92, bitrate: 256 kb/s Duration: 00:01:58.79, bitrate: 256 kb/s Duration: 00:01:18.36, bitrate: 256 kb/s Duration: 00:02:33.36, bitrate: 256 kb/s Duration: 00:01:05.83, bitrate: 256 kb/s Duration: 00:01:47.94, bitrate: 256 kb/s Duration: 00:01:45.60, bitrate: 256 kb/s Duration: 00:01:19.14, bitrate: 256 kb/s Duration: 00:01:27.18, bitrate: 256 kb/s Duration: 00:02:19.32, bitrate: 256 kb/s Duration: 00:01:36.90, bitrate: 256 kb/s Duration: 00:02:06.90, bitrate: 256 kb/s Duration: 00:01:49.46, bitrate: 256 kb/s Duration: 00:02:03.24, bitrate: 256 kb/s Duration: 00:01:34.80, bitrate: 256 kb/s Duration: 00:01:57.24, bitrate: 256 kb/s Duration: 00:01:25.26, bitrate: 256 kb/s Duration: 00:01:13.69, bitrate: 256 kb/s Duration: 00:01:16.56, bitrate: 256 kb/s Duration: 00:01:36.72, bitrate: 256 kb/s Duration: 00:01:27.18, bitrate: 256 kb/s Duration: 00:01:25.86, bitrate: 256 kb/s Duration: 00:01:17.35, bitrate: 256 kb/s Duration: 00:01:01.50, bitrate: 256 kb/s Duration: 00:01:09.85, bitrate: 256 kb/s Duration: 00:02:00.78, bitrate: 256 kb/s Duration: 00:01:33.40, bitrate: 256 kb/s Duration: 00:01:23.94, bitrate: 256 kb/s Duration: 00:02:27.96, bitrate: 256 kb/s Duration: 00:01:23.64, bitrate: 256 kb/s Duration: 00:01:37.66, bitrate: 256 kb/s Duration: 00:01:24.82, bitrate: 256 kb/s Duration: 00:01:22.38, bitrate: 256 kb/s Duration: 00:01:35.88, bitrate: 256 kb/s Duration: 00:01:13.75, bitrate: 256 kb/s Duration: 00:01:37.38, bitrate: 256 kb/s Duration: 00:01:11.58, bitrate: 256 kb/s Duration: 00:01:32.88, bitrate: 256 kb/s Duration: 00:01:51.42, bitrate: 256 kb/s Duration: 00:01:52.52, bitrate: 256 kb/s Duration: 00:01:17.40, bitrate: 256 kb/s Duration: 00:01:34.50, bitrate: 256 kb/s Duration: 00:01:55.11, bitrate: 256 kb/s Duration: 00:01:57.60, bitrate: 256 kb/s Duration: 00:01:33.01, bitrate: 256 kb/s Duration: 00:01:51.90, bitrate: 256 kb/s Duration: 00:02:30.22, bitrate: 256 kb/s Duration: 00:01:36.48, bitrate: 256 kb/s Duration: 00:02:14.91, bitrate: 256 kb/s Duration: 00:01:59.64, bitrate: 256 kb/s Duration: 00:04:04.50, bitrate: 256 kb/s Duration: 00:01:50.70, bitrate: 256 kb/s Duration: 00:02:13.20, bitrate: 256 kb/s Duration: 00:02:20.94, bitrate: 256 kb/s Duration: 00:01:26.52, bitrate: 256 kb/s Duration: 00:02:15.18, bitrate: 256 kb/s Duration: 00:01:14.82, bitrate: 256 kb/s Duration: 00:01:23.16, bitrate: 256 kb/s Duration: 00:01:15.60, bitrate: 256 kb/s Duration: 00:01:38.18, bitrate: 256 kb/s Duration: 00:01:20.40, bitrate: 256 kb/s Duration: 00:01:25.14, bitrate: 256 kb/s Duration: 00:01:35.28, bitrate: 256 kb/s Duration: 00:02:10.26, bitrate: 256 kb/s Duration: 00:01:23.93, bitrate: 256 kb/s Duration: 00:01:17.46, bitrate: 256 kb/s Duration: 00:01:01.61, bitrate: 256 kb/s Duration: 00:01:43.42, bitrate: 256 kb/s Duration: 00:01:13.81, bitrate: 256 kb/s Duration: 00:02:34.32, bitrate: 256 kb/s Duration: 00:01:16.14, bitrate: 256 kb/s Duration: 00:01:25.92, bitrate: 256 kb/s Duration: 00:01:10.22, bitrate: 256 kb/s Duration: 00:01:16.48, bitrate: 256 kb/s Duration: 00:01:09.60, bitrate: 256 kb/s Duration: 00:02:37.31, bitrate: 256 kb/s Duration: 00:01:19.32, bitrate: 256 kb/s Duration: 00:02:04.02, bitrate: 256 kb/s Duration: 00:01:27.90, bitrate: 256 kb/s Duration: 00:01:34.92, bitrate: 256 kb/s Duration: 00:02:00.42, bitrate: 256 kb/s Duration: 00:01:25.94, bitrate: 256 kb/s Duration: 00:01:26.40, bitrate: 256 kb/s Duration: 00:01:56.28, bitrate: 256 kb/s Duration: 00:02:10.80, bitrate: 256 kb/s Duration: 00:02:05.10, bitrate: 256 kb/s Duration: 00:01:25.93, bitrate: 256 kb/s Duration: 00:01:18.02, bitrate: 256 kb/s Duration: 00:01:15.66, bitrate: 256 kb/s Duration: 00:02:11.24, bitrate: 256 kb/s Duration: 00:01:11.04, bitrate: 256 kb/s Duration: 00:01:27.68, bitrate: 256 kb/s Duration: 00:01:21.46, bitrate: 256 kb/s Duration: 00:01:24.18, bitrate: 256 kb/s Duration: 00:01:10.14, bitrate: 256 kb/s Duration: 00:01:29.52, bitrate: 256 kb/s Duration: 00:01:38.94, bitrate: 256 kb/s Duration: 00:01:33.12, bitrate: 256 kb/s Duration: 00:01:39.18, bitrate: 256 kb/s Duration: 00:01:33.82, bitrate: 256 kb/s Duration: 00:01:13.68, bitrate: 256 kb/s Duration: 00:01:36.42, bitrate: 256 kb/s Duration: 00:01:37.08, bitrate: 256 kb/s Duration: 00:01:02.38, bitrate: 256 kb/s Duration: 00:01:24.54, bitrate: 256 kb/s Duration: 00:02:15.18, bitrate: 256 kb/s Duration: 00:02:34.62, bitrate: 256 kb/s Duration: 00:01:31.68, bitrate: 256 kb/s Duration: 00:03:07.56, bitrate: 256 kb/s Duration: 00:01:20.16, bitrate: 256 kb/s Duration: 00:01:59.40, bitrate: 256 kb/s Duration: 00:01:33.95, bitrate: 256 kb/s Duration: 00:01:51.87, bitrate: 256 kb/s Duration: 00:01:23.40, bitrate: 256 kb/s Duration: 00:01:03.60, bitrate: 256 kb/s Duration: 00:01:20.34, bitrate: 256 kb/s Duration: 00:01:47.70, bitrate: 256 kb/s Duration: 00:02:43.50, bitrate: 256 kb/s Duration: 00:01:24.47, bitrate: 256 kb/s Duration: 00:01:37.56, bitrate: 256 kb/s Duration: 00:01:54.42, bitrate: 256 kb/s Duration: 00:01:15.66, bitrate: 256 kb/s Duration: 00:01:33.31, bitrate: 256 kb/s Duration: 00:02:07.32, bitrate: 256 kb/s Duration: 00:01:39.18, bitrate: 256 kb/s Duration: 00:01:46.16, bitrate: 256 kb/s Duration: 00:01:50.40, bitrate: 256 kb/s Duration: 00:02:35.70, bitrate: 256 kb/s Duration: 00:01:51.54, bitrate: 256 kb/s Duration: 00:01:41.46, bitrate: 256 kb/s Duration: 00:01:29.52, bitrate: 256 kb/s Duration: 00:02:40.62, bitrate: 256 kb/s Duration: 00:02:14.76, bitrate: 256 kb/s Duration: 00:01:25.32, bitrate: 256 kb/s Duration: 00:01:04.68, bitrate: 256 kb/s Duration: 00:01:30.54, bitrate: 256 kb/s Duration: 00:01:18.90, bitrate: 256 kb/s Duration: 00:01:05.45, bitrate: 256 kb/s Duration: 00:01:21.24, bitrate: 256 kb/s Duration: 00:02:01.09, bitrate: 256 kb/s Duration: 00:02:14.21, bitrate: 256 kb/s Duration: 00:01:17.22, bitrate: 256 kb/s Duration: 00:01:46.44, bitrate: 256 kb/s Duration: 00:02:39.54, bitrate: 256 kb/s Duration: 00:02:03.31, bitrate: 256 kb/s Duration: 00:01:38.52, bitrate: 256 kb/s Duration: 00:02:04.98, bitrate: 256 kb/s Duration: 00:01:51.54, bitrate: 256 kb/s Duration: 00:02:44.94, bitrate: 256 kb/s Duration: 00:01:40.32, bitrate: 256 kb/s Duration: 00:01:25.62, bitrate: 256 kb/s Duration: 00:01:28.33, bitrate: 256 kb/s Duration: 00:01:13.20, bitrate: 256 kb/s Duration: 00:01:18.30, bitrate: 256 kb/s Duration: 00:01:47.40, bitrate: 256 kb/s Duration: 00:02:05.10, bitrate: 256 kb/s Duration: 00:02:42.72, bitrate: 256 kb/s Duration: 00:01:22.80, bitrate: 256 kb/s Duration: 00:01:37.02, bitrate: 256 kb/s Duration: 00:01:27.73, bitrate: 256 kb/s Duration: 00:01:42.96, bitrate: 256 kb/s Duration: 00:01:24.12, bitrate: 256 kb/s Duration: 00:01:25.67, bitrate: 256 kb/s Duration: 00:01:30.23, bitrate: 256 kb/s Duration: 00:01:19.14, bitrate: 256 kb/s Duration: 00:01:24.06, bitrate: 256 kb/s Duration: 00:01:26.64, bitrate: 256 kb/s Duration: 00:01:33.39, bitrate: 256 kb/s Duration: 00:01:40.68, bitrate: 256 kb/s Duration: 00:01:41.38, bitrate: 256 kb/s Duration: 00:02:34.62, bitrate: 256 kb/s Duration: 00:01:27.36, bitrate: 256 kb/s Duration: 00:01:58.68, bitrate: 256 kb/s Duration: 00:01:36.78, bitrate: 256 kb/s Duration: 00:01:58.26, bitrate: 256 kb/s Duration: 00:01:09.21, bitrate: 256 kb/s Duration: 00:01:24.78, bitrate: 256 kb/s Duration: 00:01:17.65, bitrate: 256 kb/s Duration: 00:01:34.80, bitrate: 256 kb/s Duration: 00:01:20.58, bitrate: 256 kb/s Duration: 00:01:22.38, bitrate: 256 kb/s Duration: 00:01:59.06, bitrate: 256 kb/s Duration: 00:01:22.26, bitrate: 256 kb/s Duration: 00:01:09.12, bitrate: 256 kb/s Duration: 00:01:41.94, bitrate: 256 kb/s Duration: 00:01:34.32, bitrate: 256 kb/s Duration: 00:01:07.88, bitrate: 256 kb/s Duration: 00:01:41.28, bitrate: 256 kb/s Duration: 00:01:43.08, bitrate: 256 kb/s Duration: 00:01:45.51, bitrate: 256 kb/s Duration: 00:01:24.96, bitrate: 256 kb/s Duration: 00:01:42.42, bitrate: 256 kb/s Duration: 00:02:27.78, bitrate: 256 kb/s Duration: 00:01:59.34, bitrate: 256 kb/s Duration: 00:01:37.52, bitrate: 256 kb/s Duration: 00:01:51.12, bitrate: 256 kb/s Duration: 00:02:26.16, bitrate: 256 kb/s Duration: 00:02:15.36, bitrate: 256 kb/s Duration: 00:02:04.08, bitrate: 256 kb/s Duration: 00:01:30.06, bitrate: 256 kb/s Duration: 00:02:04.98, bitrate: 256 kb/s Duration: 00:02:35.94, bitrate: 256 kb/s Duration: 00:02:03.72, bitrate: 256 kb/s Duration: 00:01:45.78, bitrate: 256 kb/s Duration: 00:01:34.56, bitrate: 256 kb/s Duration: 00:01:30.78, bitrate: 256 kb/s Duration: 00:01:34.98, bitrate: 256 kb/s Duration: 00:02:13.56, bitrate: 256 kb/s Duration: 00:02:09.02, bitrate: 256 kb/s Duration: 00:01:11.76, bitrate: 256 kb/s Duration: 00:02:07.80, bitrate: 256 kb/s Duration: 00:01:23.94, bitrate: 256 kb/s Duration: 00:01:17.64, bitrate: 256 kb/s Duration: 00:01:12.24, bitrate: 256 kb/s Duration: 00:01:43.32, bitrate: 256 kb/s Duration: 00:01:50.88, bitrate: 256 kb/s Duration: 00:01:01.98, bitrate: 256 kb/s Duration: 00:01:48.24, bitrate: 256 kb/s Duration: 00:02:04.69, bitrate: 256 kb/s Duration: 00:01:18.72, bitrate: 256 kb/s Duration: 00:03:08.58, bitrate: 256 kb/s Duration: 00:01:38.58, bitrate: 256 kb/s Duration: 00:01:12.72, bitrate: 256 kb/s Duration: 00:01:58.56, bitrate: 256 kb/s Duration: 00:01:33.90, bitrate: 256 kb/s Duration: 00:00:49.74, bitrate: 256 kb/s Duration: 00:01:13.38, bitrate: 256 kb/s Duration: 00:00:49.83, bitrate: 256 kb/s Duration: 00:01:44.04, bitrate: 256 kb/s Duration: 00:02:37.92, bitrate: 256 kb/s Duration: 00:02:17.52, bitrate: 256 kb/s Duration: 00:01:10.38, bitrate: 256 kb/s Duration: 00:01:37.44, bitrate: 256 kb/s Duration: 00:01:23.40, bitrate: 256 kb/s Duration: 00:01:52.86, bitrate: 256 kb/s Duration: 00:01:54.84, bitrate: 256 kb/s Duration: 00:01:29.04, bitrate: 256 kb/s Duration: 00:01:28.62, bitrate: 256 kb/s Duration: 00:01:14.82, bitrate: 256 kb/s Duration: 00:01:31.02, bitrate: 256 kb/s Duration: 00:01:04.92, bitrate: 256 kb/s Duration: 00:01:40.78, bitrate: 256 kb/s Duration: 00:01:27.60, bitrate: 256 kb/s Duration: 00:01:37.38, bitrate: 256 kb/s Duration: 00:01:17.00, bitrate: 256 kb/s Duration: 00:01:20.34, bitrate: 256 kb/s Duration: 00:01:03.12, bitrate: 256 kb/s Duration: 00:01:24.18, bitrate: 256 kb/s Duration: 00:02:44.70, bitrate: 256 kb/s Duration: 00:01:48.06, bitrate: 256 kb/s Duration: 00:01:49.08, bitrate: 256 kb/s Duration: 00:01:26.28, bitrate: 256 kb/s Duration: 00:01:56.34, bitrate: 256 kb/s Duration: 00:01:20.52, bitrate: 256 kb/s Duration: 00:01:23.10, bitrate: 256 kb/s Duration: 00:01:13.42, bitrate: 256 kb/s Duration: 00:01:57.42, bitrate: 256 kb/s Duration: 00:01:42.30, bitrate: 256 kb/s Duration: 00:02:21.42, bitrate: 256 kb/s Duration: 00:01:29.34, bitrate: 256 kb/s Duration: 00:02:02.64, bitrate: 256 kb/s Duration: 00:01:37.96, bitrate: 256 kb/s Duration: 00:01:40.62, bitrate: 256 kb/s Duration: 00:01:51.60, bitrate: 256 kb/s Duration: 00:02:05.76, bitrate: 256 kb/s Duration: 00:01:08.64, bitrate: 256 kb/s Duration: 00:01:51.54, bitrate: 256 kb/s Duration: 00:01:19.08, bitrate: 256 kb/s Duration: 00:02:02.58, bitrate: 256 kb/s Duration: 00:01:42.84, bitrate: 256 kb/s Duration: 00:01:52.02, bitrate: 256 kb/s Duration: 00:01:15.42, bitrate: 256 kb/s Duration: 00:01:53.58, bitrate: 256 kb/s Duration: 00:01:15.68, bitrate: 256 kb/s Duration: 00:02:07.92, bitrate: 256 kb/s Duration: 00:01:56.10, bitrate: 256 kb/s Duration: 00:01:48.67, bitrate: 256 kb/s Duration: 00:01:24.42, bitrate: 256 kb/s Duration: 00:01:33.60, bitrate: 256 kb/s Duration: 00:02:18.02, bitrate: 256 kb/s Duration: 00:01:11.86, bitrate: 256 kb/s Duration: 00:01:18.66, bitrate: 256 kb/s Duration: 00:01:51.30, bitrate: 256 kb/s Duration: 00:01:32.40, bitrate: 256 kb/s Duration: 00:01:52.32, bitrate: 256 kb/s Duration: 00:00:58.62, bitrate: 256 kb/s Duration: 00:02:19.68, bitrate: 256 kb/s Duration: 00:01:20.52, bitrate: 256 kb/s Duration: 00:02:10.20, bitrate: 256 kb/s Duration: 00:02:06.78, bitrate: 256 kb/s Duration: 00:02:08.10, bitrate: 256 kb/s Duration: 00:02:51.96, bitrate: 256 kb/s Duration: 00:01:01.65, bitrate: 256 kb/s Duration: 00:01:09.72, bitrate: 256 kb/s Duration: 00:01:53.40, bitrate: 256 kb/s Duration: 00:01:26.34, bitrate: 256 kb/s Duration: 00:01:44.88, bitrate: 256 kb/s Duration: 00:02:13.56, bitrate: 256 kb/s Duration: 00:01:58.80, bitrate: 256 kb/s Duration: 00:01:48.62, bitrate: 256 kb/s Duration: 00:02:03.54, bitrate: 256 kb/s Duration: 00:01:46.02, bitrate: 256 kb/s Duration: 00:01:03.60, bitrate: 256 kb/s Duration: 00:01:36.38, bitrate: 256 kb/s Duration: 00:01:19.98, bitrate: 256 kb/s Duration: 00:01:15.00, bitrate: 256 kb/s Duration: 00:01:47.04, bitrate: 256 kb/s Duration: 00:00:59.64, bitrate: 256 kb/s Duration: 00:01:34.02, bitrate: 256 kb/s Duration: 00:01:39.06, bitrate: 256 kb/s Duration: 00:02:23.64, bitrate: 256 kb/s Duration: 00:01:49.74, bitrate: 256 kb/s Duration: 00:01:50.68, bitrate: 256 kb/s Duration: 00:02:03.84, bitrate: 256 kb/s Duration: 00:01:40.62, bitrate: 256 kb/s Duration: 00:01:47.58, bitrate: 256 kb/s Duration: 00:00:54.18, bitrate: 256 kb/s Duration: 00:01:37.68, bitrate: 256 kb/s Duration: 00:01:22.24, bitrate: 256 kb/s Duration: 00:00:54.54, bitrate: 256 kb/s Duration: 00:01:37.74, bitrate: 256 kb/s Duration: 00:02:02.22, bitrate: 256 kb/s Duration: 00:01:38.64, bitrate: 256 kb/s Duration: 00:01:32.88, bitrate: 256 kb/s Duration: 00:02:04.14, bitrate: 256 kb/s Duration: 00:01:05.56, bitrate: 256 kb/s Duration: 00:01:53.58, bitrate: 256 kb/s Duration: 00:01:59.76, bitrate: 256 kb/s Duration: 00:01:21.54, bitrate: 256 kb/s Duration: 00:01:54.10, bitrate: 256 kb/s Duration: 00:01:59.88, bitrate: 256 kb/s Duration: 00:00:29.94, bitrate: 256 kb/s Duration: 00:01:24.86, bitrate: 256 kb/s Duration: 00:01:20.82, bitrate: 256 kb/s Duration: 00:01:58.20, bitrate: 256 kb/s Duration: 00:01:15.96, bitrate: 256 kb/s Duration: 00:01:53.28, bitrate: 256 kb/s Duration: 00:01:05.94, bitrate: 256 kb/s Duration: 00:01:20.34, bitrate: 256 kb/s Duration: 00:01:53.88, bitrate: 256 kb/s Duration: 00:02:10.80, bitrate: 256 kb/s Duration: 00:00:56.76, bitrate: 256 kb/s Duration: 00:01:32.88, bitrate: 256 kb/s Duration: 00:01:01.92, bitrate: 256 kb/s Duration: 00:01:49.38, bitrate: 256 kb/s Duration: 00:01:19.14, bitrate: 256 kb/s Duration: 00:00:54.48, bitrate: 256 kb/s Duration: 00:01:31.26, bitrate: 256 kb/s Duration: 00:01:35.22, bitrate: 256 kb/s Duration: 00:01:08.40, bitrate: 256 kb/s Duration: 00:02:02.40, bitrate: 256 kb/s Duration: 00:01:19.14, bitrate: 256 kb/s Duration: 00:02:09.30, bitrate: 256 kb/s Duration: 00:01:27.62, bitrate: 256 kb/s Duration: 00:01:59.46, bitrate: 256 kb/s Duration: 00:02:50.64, bitrate: 256 kb/s Duration: 00:00:47.76, bitrate: 256 kb/s Duration: 00:01:31.92, bitrate: 256 kb/s Duration: 00:01:13.44, bitrate: 256 kb/s Duration: 00:01:23.22, bitrate: 256 kb/s Duration: 00:01:31.74, bitrate: 256 kb/s Duration: 00:01:43.16, bitrate: 256 kb/s Duration: 00:01:29.64, bitrate: 256 kb/s Duration: 00:02:13.62, bitrate: 256 kb/s Duration: 00:02:01.80, bitrate: 256 kb/s Duration: 00:02:21.18, bitrate: 256 kb/s Duration: 00:01:55.92, bitrate: 256 kb/s Duration: 00:01:03.00, bitrate: 256 kb/s Duration: 00:01:29.82, bitrate: 256 kb/s Duration: 00:01:42.00, bitrate: 256 kb/s Duration: 00:02:18.78, bitrate: 256 kb/s Duration: 00:01:40.80, bitrate: 256 kb/s Duration: 00:02:55.74, bitrate: 256 kb/s Duration: 00:01:28.08, bitrate: 256 kb/s Duration: 00:01:57.78, bitrate: 256 kb/s Duration: 00:01:58.38, bitrate: 256 kb/s Duration: 00:01:12.00, bitrate: 256 kb/s .",
            "url": "https://jimregan.github.io/notes/asr/polish/kaggle/2021/06/16/poleval-2021-durations.html",
            "relUrl": "/asr/polish/kaggle/2021/06/16/poleval-2021-durations.html",
            "date": " • Jun 16, 2021"
        }
        
    
  
    
        ,"post201": {
            "title": "Irish Texts from South West Donegal, Abair comparison.",
            "content": "The table below compares the transcription of Texts 1 &amp; 2: (“Poitín” and “An mhóin”) from O’Neill’s1 “Irish Texts from South West Donegal”, comparing it with Abair’s transcription. . Texts 1—4 were contributed by Seamus Ó Beirn (Jim Phat James), aged c. 70 years, cobbler, from the townland of Mín na Gaoithe, Teelin. . A special feature of his speech is the clearness and strength of the affricates t′ʃ and d′ʒ due to the deliberate manner in which each word is enunciated. . The phonetic rules were mostly to help with automatic comparison, though the places where verb froms were pronounced differently before a pronoun was interesting enough to note. . Original Transcript Abair G2P Abair source Adjusted word (standardised) Adjusted Abair Rule . a |   | ə | l |   |   | ə → ∅ / v # _ | . a | è | ə | l |   |   |   | . a | ə | ə | l |   |   |   | . a | ᵊ | ə | l |   |   |   | . ach | ɑx | ˈah | l |   |   |   | . acú | ɔku | ˈakˠuː |   | acu | akˠu |   | . adharc | ˈne:rk | ˈeːɾˠkˠ | l |   |   |   | . ag | ə | ˈeɟ | l |   |   | ɟ → ∅ / _ # [+stop] | . ag | ɪg′ | ˈeɟ | l |   |   |   | . againn | ˈεiν′ | ˈəgˠəɴʲ | l |   |   |   | . agamsa | èimsə | ˈəgˠəmˠsˠə | l |   |   |   | . agat | èit | ˈəgˠətˠ | l |   |   |   | . agat | ɛit | ˈəgˠətˠ | l |   |   |   | . agat | ɛjəd | ˈəgˠətˠ | l |   |   |   | . agus | ogəs | ˈagˠəsˠ | l |   |   |   | . agus | ɔgas | ˈagˠəsˠ | l |   |   |   | . agus | ɔges | ˈagˠəsˠ | l |   |   |   | . agus | ɔgəs | ˈagˠəsˠ | l |   |   |   | . aige | ɛg′ə | ˈeɟə | l |   |   |   | . air | er′ʔ | ˈeɾʲ | l |   |   |   | . air | èr′ | ˈeɾʲ | l |   |   |   | . air | ɛr′ | ˈeɾʲ | l |   |   |   | . am | ˈnɑm | ˈamˠ | l |   |   |   | . amach | əˈmax | əˈmˠah | l |   |   |   | . amach | əˈmɑh | əˈmˠah | l |   |   |   | . amach | əˈmɑx | əˈmˠah | l |   |   |   | . an | n | ˈəɴˠ | l |   |   | ə → ∅ / v # _ | . an | n̥ | ˈəɴˠ | l |   |   | ə → ∅ / v # _ | . an | ə | ˈəɴˠ | l |   |   |   | . ann | o̤n | ˈaɴˠ | l |   |   |   | . annsin | n̥ˈʃɪn′ | ˈaˈɴʲʃinʲ |   | ansin | əɴˠˈʃinʲ | ə → ∅ / v # _ | . annsin | ˈʃɪn′ | ˈaˈɴʲʃinʲ |   |   |   |   | . anois | (ə)ˈnɪʃ | əˈɴˠiʃ | l |   |   |   | . aon | e:ˈn | ˈeːɴˠ | l |   |   |   | . ar | ə | ˈeɾʲ | l |   |   |   | . ar | ər | ˈeɾʲ | l |   |   |   | . ar | ɛr | ˈeɾʲ | l |   |   |   | . arais | əˈraʃ | ˈaɾˠəʃ |   | ar ais | ˈeɾʲ ˈaʃ |   | . araist | əˈraʃd′ | ˈaɾˠəʃtʲ |   | ar ais | ˈeɾʲ ˈaʃ |   | . armaí | ˈɑrmʷi | ˈaɾˠəmˠiː |   |   |   |   | . as | ïs | ˈasˠ | l |   |   |   | . astoigh | əˈsdihʔ | ˈasˠtˠə |   | istigh | isˠˈtˠij |   | . astoigh | əˈʃdihʔ | ˈasˠtˠə |   | istigh | isˠˈtˠij |   | . atá | ə | əˈtˠaː | l |   |   |   | . atá | ətɑ: | əˈtˠaː | l |   |   |   | . atá | ˈtɑ: | əˈtˠaː | l |   |   |   | . ba | bo̤ | ˈbˠə | l |   |   |   | . ba é | byje: | ˈbˠə ˈeː | l |   |   |   | . bachtadh | ˈbɑxdu | ˈbˠaɾˠtˠuː |   | bachta | ˈbˠaɾˠtˠə |   | . barraille | ˈbɑrəl′ə | ˈbˠaːˈɾˠaʟʲə |   | bairille | ˈbˠaɾʲʟʲə |   | . barraillí | ˈbɑrəl′i | ˈbˠaːˈɾˠaʟʲiː |   | bairillí | ˈbˠaɾʲəʟʲiː |   | . bascóid | ˈbɑsgɔd′ᶾ | ˈbˠasˠkˠɔdʲ |   | bascaed | ˈbˠasˠkˠedˠ |   | . beachóg | ˈb′ahɔg | ˈbʲahɔgˠ |   |   |   |   | . beag | ˈb′øg | ˈbʲogˠ | l |   |   |   | . bealtaine | ˈb′a:ltɪn′ə | ˈbʲoʟˠtˠənʲə | l |   |   |   | . bhachta | ˈwɑxdə | ˈwaɾˠtˠə | l+m |   |   |   | . bhachtadh | ˈwɑxdu | ˈwaɾˠtˠuː |   | bhachta |   |   | . bhaint | wï′nt | ˈwanʲtʲ | l |   |   |   | . bharraille | ˈwɑrəl′ə | ˈwaːˈɾˠaʟʲə |   | bhairille | ˈwaɾʲʟʲə |   | . bheireadh | vɛr′əd′ | ˈvʲeɾʲuː | l |   |   | &lt;eadh&gt; → ədʲ / _ # pronoun | . bhfaghaidh | ˈwɑ: | ˈweːiː |   | bhfaighidh | ˈwiː |   | . bhfeiceadh | ˈvɛk′u | ˈvʲecuː |   |   |   |   | . bhfosclaidh | ˈwɔsgli | ˈwoˈsˠkˠʟˠeː |   | bhfosclaí | ˈwoˈsˠkˠʟˠiː |   | . bhfuil | ˈwil′ | ˈwilʲ | l |   |   |   | . bhinn | ˈνïν′ | ˈvʲiɴʲ | l |   |   |   | . bhraich | ˈvreihʔ | ˈwɾˠaç | l+m |   |   |   | . bhun | ˈwo̤n | ˈwuɴˠ | l |   |   |   | . bhéadh | vɛuw | ˈvʲeːɣ |   |   |   |   | . bhéarfaidh | verhə | ˈvʲeːɾˠhiː | l |   |   |   | . bhéarfaidh | vèrhə | ˈvʲeːɾˠhiː | l |   |   |   | . bhéarfaidh | vɛ:rhə | ˈvʲeːɾˠhiː | l |   |   |   | . bhéarfaidh | vɛrhə | ˈvʲeːɾˠhiː | l |   |   |   | . bhí | vi: | ˈvʲiː | l |   |   |   | . bhíodh | vi:d′ | ˈvʲiːuː | l |   |   | &lt;odh&gt; → (ə)dʲ / _ # pronoun | . bhíodh | viuw | ˈvʲiːuː | l |   |   |   | . binn | ˈb′ïn′ | ˈbʲiɴʲ | l |   |   |   | . bith | ˈb′i | ˈbʲiː | l |   |   |   | . bladhaire | ˈblᴇir′ə | ˈbˠʟˠeːɾʲə | l |   |   |   | . bocsa | ˈbo̤ks | ˈbˠokˠsˠə |   | bosca | ˈbˠokˠsˠə |   | . bracha | ˈbrɑxə | ˈbˠɾˠahə |   | braiche | ˈbˠɾˠaçə |   | . briste | ˈb′r′ïʃd′ə | ˈbʲɾʲiʃtʲə | l |   |   |   | . bruach | ˈbri:x | ˈbˠɾˠuah | l |   |   |   | . bruach | ˈbryəx | ˈbˠɾˠuah | l |   |   |   | . bróinte | ˈbrɔ:n′t′ə | ˈbˠɾˠoːnʲtʲə |   | brónna | bˠɾˠoːɴˠə |   | . bárr | ˈbɑ:r | ˈbˠaːɾˠ |   | barr | ˈbˠaːɾˠ |   | . caidé | gəˈd′ᶾe: | kˠəˈdʲeː | l |   |   |   | . cailleadh | ˈkal′l′u | ˈkˠaʟʲuː | l |   |   |   | . caithfidh | ˈkaihɪ | ˈkˠahjiː | l |   |   |   | . caithfidh | ˈkɑihi | ˈkˠahjiː | l |   |   |   | . caithfidh | ˈkɑihɪ | ˈkˠahjiː | l |   |   |   | . caithte | ˈko̤t′ᶴə | ˈkˠahtʲə |   | caite | ˈkˠatʲə |   | . ceig | ˈk′èg′ | ˈceɟ |   |   |   |   | . ceól | ˈk′ʲɔ:l | ˈcoːʟˠ |   | ceol | ˈcoːʟˠ |   | . chaith | ˈxɑih | ˈxahj | l |   |   |   | . chaitheamh | ˈxɑhu | ˈxahjuː | l |   |   |   | . cheann | ˈx′o̤n | ˈçiɴˠ | l |   |   |   | . cheig | ˈx′ɛg′ | ˈçeɟ |   |   |   |   | . cheithre | ˈx′ɛr′ə | ˈxeɾʲə | l |   |   |   | . chiadhna | ˈx′iənə | ˈçiəɣɴˠə |   | chéanna | ˈçeːɾˠɴˠə |   | . chiall | ˈx′i:əl | ˈçiaʟˠ | l |   |   |   | . chionn | x′o̤n | ˈçiɴˠ | l+m |   |   |   | . chor | ˈxɔr | ˈxaɾˠ | l |   |   |   | . chuireadh | xo̤r′əd′ | ˈxuɾʲuː | l |   |   | &lt;eadh&gt; → ədʲ / _ # pronoun | . chuireas | ˈxo̤r′əs | ˈxuɾʲəsˠ | l |   |   |   | . chur | ˈxo̤r | ˈxuɾˠ | l |   |   |   | . chéad | ˈx′e(:)d | ˈçeːdˠ | l |   |   |   | . clampaí | ˈklɑmbi | ˈkˠʟˠamˠpˠiː |   |   |   |   | . crapannaí | ˈkrɑpəni | ˈkˠɾˠapˠəɴˠiː |   |   |   |   | . croiceann | ˈkrɛk′ən | ˈkˠɾˠocəɴˠ |   | craiceann | ˈkˠɾˠacəɴˠ |   | . cruacha | ˈkruəx | ˈkˠɾˠuəˈxa |   |   |   |   | . cruachta | ˈkruəxdə | ˈkˠɾˠuəˈɾˠtˠa |   |   |   |   | . cróigeáin | ˈkrɔ:ᵊg′ən′ | ˈkˠɾˠoːɟaːnʲ |   | gróigeáin | ˈgˠɾˠoːɟaːnʲ |   | . cróigfidh | ˈkrɔ:ᵊk′ə | ˈkˠɾˠoːɟiː |   | gróigfidh | ˈgˠɾˠoːɟiː |   | . cubhar | ˈku:r | ˈkˠuwəɾˠ |   | cúr | ˈkˠuːɾˠ |   | . cumhdach | ˈku:dɑx | ˈkˠuːdˠah | l |   |   |   | . cur | ˈko̤r | ˈkˠuɾˠ | l |   |   |   | . cáithte | ˈka:t′ʃə | ˈkˠaːhtʲə |   | cáite | kˠaːtʲə |   | . d’fhásfadh | dɑ:shəd′ | ˈdˠaːsˠuː |   |   |   | &lt;adh&gt; → ədʲ / _ # pronoun | . dabhach | ˈdɔuʷɑx | ˈdˠauh | l |   |   |   | . daoithe | di:ʰə | ˈdˠiːhə |   | di | ˈdˠi |   | . daoithe | dihə | ˈdˠiːhə |   | di | ˈdˠi |   | . dara | ˈdɑrə | ˈdˠaɾˠə | l |   |   |   | . de’n | ɔn | ˈdˠenˠ | l |   |   | d → ∅ / t # _ | . deasach | ˈd′ᶾasɑx | ˈdʲasˠah | l |   |   |   | . den | dɔ | ˈdˠenˠ | l |   |   |   | . den | dɔn | ˈdˠenˠ | l |   |   |   | . dh’fhás | ˈɣɑ:s | ˈɣaːsˠ |   | d’fhás | ˈdˠaːsˠ |   | . dhá | ˈɣɑ: | ˈɣaː | l |   |   |   | . dhéanamh | ˈja:nu | ˈjeːɴˠuː | l |   |   |   | . dhéanfaidh | ja:nhə | ˈɣeːɴˠhiː | l |   |   |   | . dhéin | ˈje:n′ | ˈjeːnʲ | l+m |   |   |   | . do | dɔ | ˈdˠə | l |   |   |   | . domh | du | ˈdˠuː | l |   |   |   | . dorga | ˈdɔrəgə | ˈdˠoˈɾˠgˠa |   | dorú | ˈdˠoɾˠuː |   | . dtaobh | du: | ˈdʲiːw | l |   |   |   | . dtig | ˈd′ɪg′ | ˈdʲiɟ | l |   |   |   | . dtig | ˈd′ᶾɪg′ | ˈdʲiɟ | l |   |   |   | . dtiocfadh | d′ᶾo̤ku | ˈdʲokˠuː | l |   |   |   | . dtiocfadh | d′ᶾo̤ku | ˈdʲokˠuː | l |   |   |   | . dtugadh | do̤gəd′ | ˈdˠugˠuː | l+m |   |   | &lt;adh&gt; → ədʲ / _ # pronoun | . dtéighidh | ˈd′ᶾe:ᵊ | ˈdʲeːjiː |   | dté | ˈdʲeː |   | . dtí | ˈdʒ′i: | ˈdʲiː | l |   |   |   | . dtí | ˈd′ʒi: | ˈdʲiː | l |   |   |   | . dtólamh | ˈdɔ:luw | ˈdˠoːʟˠuː | l+m |   |   |   | . dtólamh | ˈdɔ:ləf′ | ˈdˠoːʟˠuː | l+m |   |   |   | . duine | ˈdɪn′ | ˈdˠinʲə | l |   |   | ə → ∅ / _ # v | . dóigh | dɔ:i | ˈdˠoːj | l |   |   |   | . dóigh | ˈdɔ:i | ˈdˠoːj | l |   |   |   | . dórtadh | ˈdɔ:rtu | ˈdˠoːˈɾˠtˠeː |   | doirteadh | ˈdˠoɾˠtʲuː |   | . eagla | øglə | ˈogˠʟˠə | l |   |   |   | . eile | ˈɛl′i: | ˈelʲə | l |   |   |   | . eile | εl′ə | ˈelʲə | l |   |   |   | . eórna | ˈn′ɔ:rn | ˈoːɾˠɴˠə |   | eorna | ˈoːɾˠɴˠə | ə → ∅ / _ # v | . eórna | ˈn′ɔ:rnə | ˈoːɾˠɴˠə |   |   |   |   | . eórna | ˈn′ɔ:rnə | ˈoːɾˠɴˠə |   | eorna | ˈoːɾˠɴˠə |   | . fad | fɑd | ˈfˠadˠ | l |   |   |   | . faoi | fʷi | ˈfˠiː | l |   |   |   | . faoin | fʷi:n | ˈfˠinʲ | l |   |   |   | . fhad | ad | ˈadˠ | l |   |   |   | . fhad | ˈɑd | ˈadˠ | l |   |   |   | . fhios | ïs | ˈisˠ | l |   |   |   | . fhéil | l′ | ˈeːlʲ | l |   |   |   | . fhód | o:d | ˈoːdˠ | l+m |   |   |   | . fichead | ˈf′ihəd | ˈfʲihjədˠ | l |   |   |   | . fiog | ˈf′øg | ˈfʲigˠ |   |   |   |   | . fuar | ˈfyər | ˈfˠiaɾˠ | l |   |   |   | . fá | fɑ | ˈfˠaː | l |   |   |   | . fágfaidh | ˈfɑ:khə | ˈfˠaːgˠhə | l |   |   |   | . fágfaidh | ˈfɑ:kə | ˈfˠaːgˠhə | l |   |   |   | . fágáil | ˈfɑ:gɑl′ | ˈfˠaːgˠalʲ | l |   |   |   | . fód | ˈfo:d | ˈfˠoːdˠ | l |   |   |   | . gabháil | gɔl′ | ˈgˠolʲ | l |   |   |   | . gcionn | g′o̤n | ˈɟoɴˠ | l |   |   |   | . gclocha | glo̤hə | ˈgˠʟˠahə | l+m |   |   |   | . gconnadae | ˈgo̤ndei | ˈgˠoɴˠədˠeː |   | gcontae | ˈgˠəɴˠˈtˠe |   | . gcruachaidh | ˈgruəxə | ˈgˠɾˠuəˈxeː |   | gcruacha | ˈgˠɾˠuəˈxa |   | . geárradh | ˈg′ɑ:ru | ˈɟaːɾˠuː |   | gearradh | ˈɟaɾˠuː |   | . geárraidh | ˈg′ɑ:ri | ˈɟaːɾˠiː |   | gearra | ˈɟaɾˠə |   | . geárrfaidh | ˈg′ɑ:rhə | ˈɟaːɾˠiː |   | gearrfaidh | ˈɟaɾˠiː |   | . geárrtha | ˈg′ɑ:rhə | ˈɟaːɾˠhə |   | gearrtha | ˈɟaːɾˠˈha |   | . ghabháil | ˈɣɔ(:)l′ | ˈɣolʲ | l |   |   |   | . gheimhridh | ˈjɛvr′i | ˈjivʲɾʲi | l |   |   |   | . gheárradh | ˈjɑ:ru | ˈjaːɾˠuː |   | ghearradh | ˈjaɾˠuː |   | . ghlas | ˈɣlɑs | ˈɣʟˠasˠ | l |   |   |   | . ghoirid | ˈɣo̤r′id′ᶾ | ˈɣoɾʲədʲ |   |   |   |   | . ghrian | ˈjᵊr′iən | ˈɣɾʲiaɴˠ | l |   |   |   | . gloine | ˈglön′ə | ˈgˠʟˠinʲə | l |   |   |   | . go | go | ˈgˠə | l |   |   |   | . go | gɔ | ˈgˠə | l |   |   |   | . go | gə | ˈgˠə | l |   |   |   | . goidé | gəˈd′ᶾe: | ˈgˠədʲeː | l |   |   |   | . grian | ˈg′r′iən | ˈɟɾʲiaɴˠ | l |   |   |   | . géar | ˈg′ɛ:ᵊr | ˈɟeːɾˠ | l |   |   |   | . géarrfaidh | ˈg′ɑ:rhə | ˈɟeːˈɾˠeː |   | gearrfaidh | ˈɟaɾˠiː |   | . h-áirid | ˈha:rid′ᶾ | ˈhaːɾʲədʲ |   | háirithe | ˈhaːɾʲihjə |   | . h-áiteacha | ˈha:n′t′ahə | ˈhaːtʲəhə | h-áiteacha |   |   |   | . h-é | hè | ˈheː | l+m |   |   |   | . huaire | ˈhuər′ə | ˈhuaɾʲə | l |   |   |   | . i |   | ˈi | l |   |   |   | . i | ə | ˈi | l |   |   |   | . iad | iəd | ˈiadˠ | l |   |   |   | . iad | əd | ˈiadˠ | l |   |   |   | . ina | nə | ˈiɴˠə | l |   |   |   | . ina | əνə | ˈiɴˠə | l |   |   |   | . innse | ïν′ʃə | ˈiˈɴʲʃe |   | insint | ˌinʲˈʃinʲtʲ |   | . inntí | ˈɪn′t′i | ˈiˈɴʲtʲiː |   | inti | iɴʲtʲi |   | . ins | n̥s | ˈinʲʃ |   |   |   |   | . ins | n̥s | ˈinʲʃ |   |   |   | ə → ∅ / v # _ | . ins | n̥s | ˈinʲʃ |   | sa | ˈsˠə |   | . ins an | n̥sə | ˈinʲʃ ˈəɴˠ |   |   |   |   | . insa | n̥sə | ˈinʲˈsˠə |   |   |   |   | . insa | n̥sə | ˈinʲˈsˠə |   | sa | ˈsˠə |   | . isteach | əˈʃd′ah | iʃˈtʲah | l |   |   |   | . isteach | əˈʃd′ax | iʃˈtʲah | l |   |   |   | . le | l′ɛ | ˈlʲe | l |   |   |   | . leagfaidh | ˈl′o̤khə | ˈʟʲagˠiː |   |   |   |   | . leat | l′at | ˈlʲatˠ | l |   |   |   | . leis | l′eʃ | ˈlʲiʃ | l |   |   |   | . leis | l′ɛ | ˈlʲiʃ | l |   |   | ʃ → ∅ / _ # ʃ | . leithead | ˈl′ɛhəd | ˈʟʲaihjədˠ | l |   |   |   | . lena | l′ɛnə | ˈlʲeɴˠə | l |   |   |   | . leófa | l′ɔ:fə | ˈʟʲoːfˠə |   | leo | ˈlʲo |   | . lomadh | ˈlo̤mu | ˈʟˠomˠuː | l |   |   |   | . lomta | ˈlo̤mt | ˈʟˠomˠtˠə |   |   |   |   | . lá | ˈlɑ: | ˈʟˠaː | l |   |   |   | . láimhe | ˈlɑ:və | ˈʟˠaːvʲə | l |   |   |   | . lámh | ˈlɑ:w | ˈʟˠaːw | l |   |   |   | . lámha | ˈlɑ:wə | ˈʟˠaːwə | l |   |   |   | . lán | lɑ:n | ˈʟˠaːɴˠ | l |   |   |   | . léithe | l′ɛ:hə | ˈlʲeːhjə | l |   |   |   | . líonadh | ˈl′i:nəd′ | ˈʟʲiːɴˠuː | l |   |   |   | . maith | ˈmɑi | ˈmˠahj | l |   |   |   | . mar | mo̤r | ˈmˠaɾˠ | l |   |   |   | . mar’s | mo̤řš | ˈm_ea_er_ez_e | l |   |   |   | . mar’s | məs | ˈmˠaɾˠsˠ | l |   |   |   | . marbh | ˈmaru | ˈmˠaɾˠəw | l |   |   |   | . mheileadh | vəl′həd′ | ˈvʲelʲuː |   |   |   | &lt;eadh&gt; → ədʲ / _ # pronoun | . mhárta | ˈwɑ:rtə | ˈwaːɾˠtˠə | l+m |   |   |   | . mhóin | ˈwo:n′ | ˈwoːnʲ | l+m |   |   |   | . mhóin | ˈwo:ᵊn′ | ˈwoːnʲ | l+m |   |   |   | . midhe | ˈm′i:ə | ˈmʲiːə |   | mí | ˈmʲiː |   | . má | mɑ | ˈmˠa | l |   |   |   | . mála | ˈmɑ:lə | ˈmˠaːʟˠə | l |   |   |   | . mí | ˈm′i: | ˈmʲiː | l |   |   |   | . móin | mo:n′ | ˈmˠoːnʲ | l |   |   |   | . mónadh | mo:nu | ˈmˠoːɴˠuː | l |   |   |   | . mór | ˈmo:r | ˈmˠoːɾˠ | l |   |   |   | . n | n | nˠ | l |   |   |   | . n | n̥ | nˠ | l |   |   |   | . na | nə | ˈɴˠə | l |   |   |   | . naoi | ˈni: | ˈɴˠiː | l |   |   |   | . ndam | ˈnɑmʷ | ˈɴˠamˠ |   | ndamba | ˈɴˠamˠbˠə |   | . ndéantar | ˈn′a:ntər | ˈnʲeːɴˠtˠəɾˠ | l |   |   |   | . nuair | nuər′ | ˈɴˠuːɾʲ | l |   |   |   | . ná | nɑ: | ˈɴˠaː | l |   |   |   | . ní | n′i: | ˈɴʲiː | l |   |   |   | . níl | ˈn′i:l′ | ˈɴʲiːlʲ | l |   |   |   | . níodh | ˈn′i:wəd′ | ˈnʲiːuː | l |   |   | &lt;odh&gt; → ədʲ / _ # pronoun | . nó | nɑ: | ˈɴˠoː | l |   |   |   | . ocht | ɔxd | ˈaxtˠ | l |   |   |   | . orthaí | ɔrhi | ˈoːɾˠhiː |   | uirthi | ˈaɾˠhjiː |   | . phoitín | ˈfot′in′ | ˈfˠotʲinʲ | l+m |   |   |   | . phoitín | ˈfɔt′in′ | ˈfˠotʲinʲ | l+m |   |   |   | . phortaigh | ˈfɔrti | ˈfˠaɾˠtˠiː | l |   |   |   | . poitín | ˈpɔt′in′ | ˈpˠotʲinʲ | l |   |   |   | . pádraig | ˈpɑ:drik′ | ˈpˠaːdˠɾˠəɟ | l |   |   |   | . rabh | ro | ˈɾˠau |   | raibh | ˈɾˠoːw |   | . rachadh | rɑhu | ˈɾˠahuː | l |   |   |   | . rachadh | rɑhəd′ | ˈɾˠahuː | l |   |   | &lt;adh&gt; → ədʲ / _ # pronoun | . rachaidh | ˈrɑhə | ˈɾˠaːhij | l |   |   |   | . raithte | ˈrat′ʃ | ˈɾˠahtʲə |   | ráite | ˈɾˠaːtʲə | ə → ∅ / _ # v | . rannadh | ˈrɑnhu | ˈɾˠaɴˠuː |   | roinnt | ˈɾˠoɴʲtʲ |   | . rathaidh | n̥ˈrahi | ˈɾˠahiː |   |   |   |   | . rathaidh | ˈrɑhi | ˈɾˠahiː |   | ratha | ˈɾˠahə |   | . riclíní | ˈrïk′l′i:n′i | ˈɾˠiclʲiːnʲiː |   |   |   |   | . rotha | ˈrɔh | ˈɾˠohə |   |   |   |   | . rud | ro̤d | ˈɾˠudˠ | l |   |   |   | . rud | ˈro̤d | ˈɾˠudˠ | l |   |   |   | . réidh | ˈre:i | ˈɾˠeːj | l |   |   |   | . réir | ˈre: | ˈɾˠeːɾʲ | l |   |   |   | . réir | ˈr′e: | ˈɾˠeːɾʲ | l |   |   |   | . sa | sə | ˈsˠə | l |   |   |   | . seachtmhaine | ˈʃaxdɪn′ə | ˈʃaɾˠtˠwənʲə |   | seachtaine | ˈʃaɾˠtˠənʲə |   | . seo | ʃɔ | ˈʃo | l |   |   |   | . shoin | xɪn′ | ˈhoˈinʲ |   | shin | ˈhinʲ |   | . shíolthuigheadh | ˈhiəlhiuw | ˈhiːʟˠhəjuː |   | shíothlaíodh | ˈhiːhʟˠiəɣ |   | . siad | ʃəd | ˈʃiːdˠ | l |   |   |   | . sin | ʃɪn′ | ˈʃinʲ | l |   |   |   | . sin’s | ʃɪn′s | ˈʃinʲʃ |   |   |   |   | . sioc | ˈʃo̤k | ˈʃikˠ | l |   |   |   | . slat | ˈslɑt | ˈsˠʟˠatˠ | l |   |   |   | . sleaghán | ˈʃl′a:n | ˈʃlʲaɣaːɴˠ |   | sleán | ˈʃlʲaːɴˠ |   | . spréidhfidh | ˈsb′r′e:f′ə | ˈsˠpʲɾʲeːjiː |   | spréifidh | ˈsˠpʲɾʲeːiː |   | . spád | ˈsbɑ:d | ˈsˠpˠaːdˠ | l |   |   |   | . spád | ˈsbʷɑ:d | ˈsˠpˠaːdˠ | l |   |   |   | . still | ˈsdïl | ˈʃtʲiʟʲ |   |   |   |   | . stáluighidh | ˈsdɑ:li | ˈsˠtˠaːʟˠəjiː |   | stálaí | ˈsˠtˠaːʟˠiː |   | . suas | ʃuəs | ˈsˠuasˠ | l |   |   |   | . sábháilte | ˈsɑ:wɑl′t′ | ˈsˠaːwaʟʲtʲə | l |   |   |   | . sábháilte | ˈsɑ:wɑl′t′ᶴə | ˈsˠaːwaʟʲtʲə | l |   |   |   | . sé | ʃɛ | ˈʃeː | l |   |   |   | . sí | tɑ:ʃi: | ˈʃiː | l |   |   |   | . sí | ʃi(:) | ˈʃiː | l |   |   |   | . síos | ˈʃi:s | ˈʃiːsˠ | l |   |   |   | . síos | ˈʃiᵊs | ˈʃiːsˠ | l |   |   |   | . t-am | ˈtɑ(:)m | ˈtˠaːmˠ | l |   |   |   | . t-iomlán | ˈt′ᶴo̤mlan | ˈtʲuːmˠʟˠaɴˠ |   |   |   |   | . t-uachtar | ˈtuəxdər | ˈtˠuaxtˠəɾˠ | l+m |   |   |   | . t-uisce | tɪʃg′ə | ˈtˠiʃcə | l |   |   |   | . talamh | ˈtɑlu | ˈtˠoʟˠuː | l |   |   |   | . tamallt | tɑməlt | ˈtˠamˠəʟˠtˠ |   | tamall | ˈtˠamˠəʟˠ |   | . taobh | ti:w | ˈtˠiːw | l |   |   |   | . tarraingt | tɑrən′t′ | ˈtˠaɾˠinʲtʲ | l |   |   |   | . teinidh | ˈt′ʃɪn′i | ˈtʲenʲiː |   | tine |   |   | . thart | hɑrt | ˈhaɾˠtˠ | l |   |   |   | . theacht | haxd | ˈhjaxtˠ | l |   |   |   | . thig | hɪg′ | ˈhjiɟ | l |   |   |   | . thiocfadh | ho̤ku | ˈhjokˠuː | l |   |   |   | . thoirt | ˈho̤rt′ | ˈhaɾˠtʲ | l+m |   |   |   | . thriomuigheadh | ˈx′r′ïmʷied′ | ˈr̪ʲimˠəjuː |   | thriomaíodh | ˈr̪ʲimˠiəɣ |   | . thriomuigheann | ˈx′r′o̤mʷiən | ˈr̪ʲimˠəjəɴˠ |   | thriomaíonn | ˈr̪ʲimˠiəɴˠ |   | . théigheadh | ˈhe:wəd′ | ˈheːjuː |   | théadh | ˈhjeːh |   | . théigheann | ˈhe:ᵊn | ˈheːjəɴˠ |   | théann | ˈheːɴˠ |   | . tionntochaidh | ˈt′ᶴo̤ntahə | ˈtʲiɴˠtˠəhiː |   | tiontóidh | ˈtʲiɴˠtˠɔj |   | . toithe | tihə | ˈtˠohə |   | tithe | ˈtʲihjiː |   | . toithe | ˈtihə | ˈtˠohə |   | tithe | ˈtʲihjiː |   | . tosochaidh | ˈtɔsahə | ˈtˠosˠəhiː |   | tosóidh | ˈtˠosˠɔj |   | . triomochaidh | ˈt′ᶴr′ïmɑhə | ˈtʲɾʲimˠəhiː |   | triomóidh | ˈtʲɾʲimˠɔj |   | . trí | t′ʃr′i: | ˈtʲɾʲiː | l |   |   |   | . tsleagháin | ′t′ʃl′a:n′ | ˈtʲlʲaɣaːnʲ |   | tsleáin | ˈtʲlʲaːnʲ |   | . tuairim | tuər′ɪm′ | ˈtˠuaɾʲimʲ | l |   |   |   | . tusa | ˈtösə | ˈtˠusˠə | l |   |   |   | . tá | ˈtɑ(:) | ˈtˠaː | l |   |   |   | . tír | ˈt′ᶴi:r′ | ˈtʲiːɾʲ | l |   |   |   | . tú | tu(ᵊ) | ˈtˠuː | l |   |   |   | . uair | nuər′ | ˈuaɾʲ | l |   |   |   | . uair | ˈnuər′ | ˈuaɾʲ | l |   |   |   | . uile | ˈnɪl′ə | ˈilʲə | l |   |   |   | . uisce | ɪʃg′ə | ˈiʃcə | l |   |   |   | . well | wɛl′ | ˈweʟʲ |   |   |   |   | . worm | ˈwïr′əm | ˈwoːɾˠəmˠ |   |   |   |   | . á | a | aː | l |   |   |   | . áiteacha | ˈa:n′t′axə | ˈaːtʲəhə |   | áiteanna | ˈaːtʲəɴˠə |   | . éadan | ˈe:ᵊdɑn | ˈeːdˠəɴˠ | l |   |   |   | . éadan | ˈɛ:dɑn | ˈeːdˠəɴˠ | l |   |   |   | . éadan | ˈɛ:ᵊdɑn | ˈeːdˠəɴˠ | l |   |   |   | . í |   | ˈiː | l |   |   |   | . í | i: | ˈiː | l |   |   |   | . ó | ɑ | ˈoː | l |   |   |   | . ó | ɔ | ˈoː | l |   |   |   | . O’Neill, John E. “Irish Texts from South West Donegal.” Zeitschrift Für Celtische Philologie, vol. 33, 1974, doi:10.1515/zcph.1974.33.1.285. &#8617; . |",
            "url": "https://jimregan.github.io/notes/irish/donegal/2021/06/14/irish-texts-from-south-west-donegal-texts-1-2.html",
            "relUrl": "/irish/donegal/2021/06/14/irish-texts-from-south-west-donegal-texts-1-2.html",
            "date": " • Jun 14, 2021"
        }
        
    
  
    
        ,"post202": {
            "title": "Tuairisc scraper pieces",
            "content": "_SITEMAP=&#39;https://tuairisc.ie/sitemap.xml&#39; . import requests from bs4 import BeautifulSoup . def _read_main_sitemap(): output = [] sm = requests.get(_SITEMAP) if sm.status_code != 200: raise Exception(&quot;Failed to read sitemap&quot;) base_soup = BeautifulSoup(sm.text, &#39;lxml&#39;) for submap in base_soup.findAll(&#39;sitemap&#39;): location = submap.find(&#39;loc&#39;).text if &#39;sitemap-pt&#39; in location: output.append(_read_sub_sitemap(location)) return output . def _read_sub_sitemap(url): output = [] sm = requests.get(url) if sm.status_code != 200: raise Exception(&quot;Failed to read sitemap&quot;) base_soup = BeautifulSoup(sm.text, &quot;lxml&quot;) for submap in base_soup.findAll(&quot;url&quot;): output.append(submap.find(&quot;loc&quot;).text) return output . def _fetch_article(url): page = requests.get(url) if page.status_code != 200: raise Exception(&quot;Failed to read page: &quot; + url) return page.text . def _get_article_text(content): base_soup = BeautifulSoup(content, &quot;lxml&quot;) main = base_soup.find(&quot;div&quot;, {&quot;class&quot;: &quot;article--full__content&quot;}) paras = [p.text.strip() for p in main.findAll(&quot;p&quot;) if p.text.strip() != &#39;&#39;] return(paras) . def _get_pub_date(content): base_soup = BeautifulSoup(content, &quot;lxml&quot;) date = base_soup.find(&quot;time&quot;, {&quot;itemprop&quot;: &quot;datePublished&quot;}) return date[&quot;datetime&quot;] . _get_article_text(_fetch_article(&#39;https://tuairisc.ie/nuair-a-thainig-john-hume-go-hollscoil-na-banriona-thuig-me-gur-i-lathair-ceannaire-agus-faidh-a-bhi-me/&#39;)) . _get_pub_date(_fetch_article(&#39;https://tuairisc.ie/nuair-a-thainig-john-hume-go-hollscoil-na-banriona-thuig-me-gur-i-lathair-ceannaire-agus-faidh-a-bhi-me/&#39;)) . &#39;2020-08-04 05:44&#39; .",
            "url": "https://jimregan.github.io/notes/irish/scraper/tuairisc/2021/06/13/tuairisc-scraper.html",
            "relUrl": "/irish/scraper/tuairisc/2021/06/13/tuairisc-scraper.html",
            "date": " • Jun 13, 2021"
        }
        
    
  
    
        ,"post203": {
            "title": "Download w2v-u Swedish model trained on Colab",
            "content": "Original . %%capture !pip install gdown . !gdown https://drive.google.com/uc?id=1-3fYwuDq-l7UpowGtzq3X4Dg-jTrb5jQ !gdown https://drive.google.com/uc?id=1E3LB7rlmk00zhsgYEYFq8y-2Ck6QU-wx . Downloading... From: https://drive.google.com/uc?id=1-3fYwuDq-l7UpowGtzq3X4Dg-jTrb5jQ To: /kaggle/working/checkpoint_last.pt 13.0MB [00:00, 57.6MB/s] Downloading... From: https://drive.google.com/uc?id=1E3LB7rlmk00zhsgYEYFq8y-2Ck6QU-wx To: /kaggle/working/checkpoint_best.pt 13.0MB [00:00, 65.7MB/s] .",
            "url": "https://jimregan.github.io/notes/kaggle/w2vu/2021/06/09/download-w2vu-sv-model-trained-on-colab.html",
            "relUrl": "/kaggle/w2vu/2021/06/09/download-w2vu-sv-model-trained-on-colab.html",
            "date": " • Jun 9, 2021"
        }
        
    
  
    
        ,"post204": {
            "title": "wav2vec-u Common Voice Swedish - GAN training, CPU8",
            "content": "Original here . Preparation . !cp ../input/w2vu-cvsv-checkpoints-cpu7/checkpoint_best.pt . !cp ../input/w2vu-cvsv-checkpoints-cpu7/checkpoint_last.pt . . %%capture !conda install -c pykaldi pykaldi -y . %cd /tmp . !git clone https://github.com/jimregan/fairseq/ --branch issue3581 . !git clone https://github.com/kpu/kenlm . %%capture !apt-get -y install libeigen3-dev liblzma-dev zlib1g-dev libbz2-dev . %%capture %cd /tmp/kenlm !python setup.py install %cd /tmp . import os os.environ[&#39;PATH&#39;] = f&quot;{os.environ[&#39;PATH&#39;]}:/tmp/kenlm/build/bin/&quot; os.environ[&#39;FAIRSEQ_ROOT&#39;] = &#39;/tmp/fairseq&#39; . %cd /tmp/fairseq/ . %%capture !python setup.py install . %cd /tmp/fairseq/ . os.environ[&#39;HYDRA_FULL_ERROR&#39;] = &#39;1&#39; . %%capture !pip install editdistance . GAN . %%writefile rungan.sh PREFIX=w2v_unsup_gan_xp TASK_DATA=/kaggle/input/wav2vec-u-cv-swedish-audio/precompute_pca512_cls128_mean_pooled/ TEXT_DATA=/kaggle/input/wav2vec-u-cv-swedish-text-prep/preppedtext/phones/ KENLM_PATH=/kaggle/input/wav2vec-u-cv-swedish-text-prep/preppedtext/phones/lm.phones.filtered.04.bin PREFIX=$PREFIX fairseq-hydra-train -m --config-dir fairseq/config/model/wav2vecu/gan --config-name w2vu task.data=${TASK_DATA} task.text_data=${TEXT_DATA} task.kenlm_path=${KENLM_PATH} checkpoint.no_epoch_checkpoints=false checkpoint.keep_last_epochs=5 checkpoint.save_dir=/kaggle/working &#39;common.seed=range(0,5)&#39; . !bash rungan.sh .",
            "url": "https://jimregan.github.io/notes/kaggle/wav2vec-u/2021/06/05/wav2vec-u-cv-swedish-gan-cpu8.html",
            "relUrl": "/kaggle/wav2vec-u/2021/06/05/wav2vec-u-cv-swedish-gan-cpu8.html",
            "date": " • Jun 5, 2021"
        }
        
    
  
    
        ,"post205": {
            "title": "CC-Aligned Irish contains porn",
            "content": "I re-ran this notebook and forgot to take the opportunity to see why M2M100 thinks everything is porn. . Now I know. . !wget http://www.statmt.org/cc-aligned/en_XX-ga_IE.tsv.xz . --2021-06-05 18:10:06-- http://www.statmt.org/cc-aligned/en_XX-ga_IE.tsv.xz Resolving www.statmt.org (www.statmt.org)... 129.215.197.184 Connecting to www.statmt.org (www.statmt.org)|129.215.197.184|:80... connected. HTTP request sent, awaiting response... 200 OK Length: 150347648 (143M) [application/x-xz] Saving to: ‘en_XX-ga_IE.tsv.xz’ en_XX-ga_IE.tsv.xz 100%[===================&gt;] 143.38M 128KB/s in 18m 23s 2021-06-05 18:28:30 (133 KB/s) - ‘en_XX-ga_IE.tsv.xz’ saved [150347648/150347648] . !unxz en_XX-ga_IE.tsv.xz . unxz: en_XX-ga_IE.tsv: File exists . !cat en_XX-ga_IE.tsv|grep -a -i brazzers|wc -l . 461 . !cat en_XX-ga_IE.tsv|grep -a -i brazzers|cut -c -120 . brazzers-n.com http://brazzers-n.com/en/tgb/6350-%E0%A6%86%E0%A6%B0%E0%A6%AC%2C+%E0%A6%AC%E0%A7%87%E0%A6%B6%E0%A7%8D%E0% brazzers-n.com http://brazzers-n.com/en/tgb/3981-%E0%A4%AD%E0%A4%B5%E0%A5%8D%E0%A4%AF+%E0%A4%95%E0%A4%BF%E0%A4%B6%E0%A5% brazzers-n.com http://brazzers-n.com/en/tgb/13264-%E0%B0%AA%E0%B0%BE%E0%B0%A0%E0%B0%B6%E0%B0%BE%E0%B0%B2+%E0%B0%AB%E0%B0 brazzers-n.com http://brazzers-n.com/en/tgb/16024-%D0%93%D2%AF%D0%BD+Creampie/ Deep Creampie - BRAZZERS porn Studio. Por brazzers-n.com http://brazzers-n.com/en/tgb/7978-%D0%94%D0%B0%D0%BB%D0%B4+%D0%93%D0%B0%D0%BB%D0%B7%D1%83%D1%83%D0%B3%D0% brazzers-n.com http://brazzers-n.com/en/tgb/6324-CFNM+%D0%A1%D0%B5%D0%BA%D1%81/ CFNM Sex - BRAZZERS porn Studio. Porn cl porndig-n.com http://porndig-n.com/en/bikini Bikini porn video porndig|Menu|Main (current)|Random video|All categories|E hotpornadult.com http://hotpornadult.com/ HotPornAdult - porn in HD|Free porn videos online|Sliding menu|HotPornAdult|Ma brazzers-n.com http://brazzers-n.com/en/tgb/17530-%E0%A6%AA%E0%A7%87%E0%A6%9B%E0%A6%A8+%E0%A6%A5%E0%A7%87%E0%A6%95%E0%A7 ecml.at http://edl.ecml.at/LanguageFun/LanguageQuiz/tabid/1873/language/en-GB/Default.aspx European Day of Languages &gt; L brazzers-n.com http://brazzers-n.com/en/tgb/14265-%D0%A5%D1%83%D1%83%D1%87%D0%B8%D0%BD+Dicks/ Old Dicks - BRAZZERS porn brazzers-n.com http://brazzers-n.com/en/tgb/12184-%D0%95%D0%B2%D1%80%D0%BE+%D0%93%D1%80%D1%83%D0%BF%D0%BF/ Euro Group - brazzers-n.com http://brazzers-n.com/en/tgb/6922-%E0%A6%9C%E0%A6%BE%E0%A6%AA%E0%A6%BE%E0%A6%A8%E0%A6%BF+%E0%A6%A6%E0%A7% foto-semya.ru https://foto-semya.ru/ bohsia doggie telugubrothersistersexvides asa akira hot|bohsia doggie|bohsia doggie lenkino.mobi http://lenkino.mobi/en/mv/1916008-danielle-dynamite-masturbates.html Danielle Dynamite Masturbates|Apostate brazzers-n.com http://brazzers-n.com/en/tgb/16058-%E0%A6%AA%E0%A6%B0%E0%A6%BF%E0%A6%9A%E0%A6%BE%E0%A6%B0%E0%A6%BF%E0%A6% 24video-xxx.com http://24video-xxx.com/en/hairy-pussy Hairy pussy this category contains selected videos in HD quality. brazzers-n.com http://brazzers-n.com/en/tgb/733-Chubby/ Chubby - BRAZZERS porn Studio. Porn clips brazzers Studio and no brazzers-n.com http://brazzers-n.com/en/tgb/9953-%E0%A6%95%E0%A7%81%E0%A6%96%E0%A7%8D%E0%A6%AF%E0%A6%BE%E0%A6%A4/ Infamo brazzers-n.com http://brazzers-n.com/en/mb/3319014-eva.html Eva|Menu|Main (current)|Random video|Chat|All categories|Eng brazzers-n.com http://brazzers-n.com/en/tgb/952-%E0%A6%B2%E0%A6%BE%E0%A6%B2+%E0%A6%B8%E0%A6%AC%E0%A7%81%E0%A6%9C/ Red Gr brazzers-n.com http://brazzers-n.com/en/tgb/10228-Girl+Loves+Anal/ Girl Loves Anal - BRAZZERS porn Studio. Porn clips br hdbox.ws https://hdbox.ws/en/sat-tv-novosti/5092-transpondernye-novosti-sputnikovogo-televideniya-20-fevralya-2018.html hotpornadult.com http://hotpornadult.com/en/tag/ Free porn videos online|Sliding menu|HotPornAdult|Main (current)|Random brazzers-n.com http://brazzers-n.com/en/tgb/12851-%E0%A6%B8%E0%A7%8D%E0%A6%AC%E0%A6%B0%E0%A7%8D%E0%A6%A3%E0%A6%95%E0%A7% pornoload-n.com http://pornoload-n.com/en/tag/431-%C4%90%E1%BB%93/page/7/ Hard Sex - Pornload best website with adult vi brazzers-n.com http://brazzers-n.com/en/vibrator/ Vibrator brazzers|Menu|Main (current)|Random video|Chat|All categories pornoload-n.com http://pornoload-n.com/en/tag/11490-Famous/ Famous - Pornload best website with adult videos and porn cl ruporn-tv.com http://ruporn-tv.com/en/blonde Blonde|Menu|Main (current)|Random|Category|English|Русский|English|A pornk.mobi http://pornk.mobi/en/bikini Bikini porn pornk|Menu|Main (current)|Topics porn|Random video|Chat|English|Ру� eporner-n.com http://eporner-n.com/en/facialized Cum on face _ EPORNER|Menu|Main (current)|All categories|Random|English brazzers-n.com http://brazzers-n.com/en/tgb/16337-%E0%A8%A6%E0%A8%BF%E0%A8%A8/ Daytime - BRAZZERS porn Studio. Porn clip brazzers-n.com http://brazzers-n.com/en/tgb/12184-%E0%A8%AF%E0%A9%82%E0%A8%B0%E0%A9%8B+%E0%A8%97%E0%A8%B0%E0%A9%81%E0%A9 gonzofap.com http://gonzofap.com/en/ Gonzo Fap|English|Afrikaans|العربية|Azərbaycanca|Беларуская|Бъ� pornoload-n.com http://pornoload-n.com/en/hardcore Hardcore|Menu|PornoLoad|Main (current)|Random video|All categories|En oisquipedia.org https://oisquipedia.org/encheu_a_boca_dela_de_porra_0532 Encheu A Boca Dela De Porra - English Porn Vide ruporn-tv.com http://ruporn-tv.com/en/p/6/ Russian porn online watch free video on Ruporn.tv - page 6|Menu|Main (current ecml.at http://edl.ecml.at/LanguageFun/FAQsonsignlanguage/tabid/2741/language/en-GB/Default.aspx European Day of Languag cucek.net http://cucek.net/en/porn-orgasms Porn orgasms|Sliding menu|Cucek.NET|Main (current)|Random video|All categorie ecml.at http://edl.ecml.at/LanguageFun/LanguageFacts/tabid/1859/language/en-GB/Default.aspx European Day of Languages &gt; trahtubetv.com http://trahtubetv.com/en/tag/351-Pounded/ Pounded - Fuck tube. Check out hot pussies. Porn videos for fre brazzers-n.com http://brazzers-n.com/en/tgb/12398-%E0%B9%80%E0%B8%82%E0%B9%88%E0%B8%B2%E0%B8%AA%E0%B8%B9%E0%B8%87%E0%B8% brazzers-n.com http://brazzers-n.com/en/tgb/344-%E0%A6%AB%E0%A6%BF%E0%A6%B8%E0%A6%A8%E0%A7%87%E0%A6%9F/ Fishnet - BRAZZE pornoload-n.com http://pornoload-n.com/en/tag/9763-%D0%97%D0%B2%D1%83%D1%87%D0%B0%D0%BD%D0%B8%D0%B5/ Sounding - Pornload brazzers-n.com http://brazzers-n.com/en/tgb/5075-%E0%A6%95%E0%A7%83%E0%A6%B7%E0%A6%95%E0%A6%A6%E0%A7%87%E0%A6%B0/ Farmer estudiogrum.com https://estudiogrum.com/en/home English Porn Video - Free Porn Videos Xvideos, Pornhub, xnxx - Ladyboy P brazzers-n.com http://brazzers-n.com/en/azeri/ Azeri brazzers|Menu|Main (current)|Random video|Chat|All categories|Engli pornoload-n.com http://pornoload-n.com/en/page/8/ Pornload best website with adult videos and porn clips adult free - pa brazzers-n.com http://brazzers-n.com/en/tgb/23432-%E0%A6%9B%E0%A7%8B%E0%A6%9F+%E0%A6%B2%E0%A6%BE%E0%A6%B2+%E0%A6%9A%E0%A brazzers-n.com http://brazzers-n.com/en/tgb/12940-%E0%A6%AC%E0%A6%A1%E0%A6%BC%E0%A7%8B+%E0%A6%AA%E0%A7%8B%E0%A6%81%E0%A6 hotpornohub.com http://hotpornohub.com/en/next/3/ Cool porn video from hotpornohub.com! - page 3|Sliding menu|HotPornoHu brazzers-n.com http://brazzers-n.com/en/tgb/7808-%E0%A6%97%E0%A6%B0%E0%A6%AE%2C+%E0%A6%AA%E0%A7%80%E0%A6%A8%E0%A6%B8%E0% brazzers-n.com http://brazzers-n.com/en/tgb/12939-%E0%A6%AE%E0%A6%BE%E0%A6%87+%E0%A6%8F%E0%A6%B0/ Huge Titties - BRAZZER brazzers-n.com http://brazzers-n.com/en/tgb/11635-%E0%A6%AA%E0%A6%B0%E0%A6%BF%E0%A6%A3%E0%A6%A4%2C+%E0%A6%AA%E0%A7%8B%E0 erkiss-tv.com http://erkiss-tv.com/en/bikini/ Bikini porn on the phone|Menu|Main (current)|Random|Chat|Category|English| brazzers-n.com http://brazzers-n.com/en/tgb/21088-%D0%9D%D1%83%D0%BB%D0%B8%D0%BC%D0%B6+%D0%A8%D2%AF%D1%82%D1%8D%D1%8D%D0 brazzers-n.com http://brazzers-n.com/en/tgb/12030-%E0%A6%AE%E0%A6%BE%E0%A6%87+%E0%A6%8F%E0%A6%B0+%E0%A6%AE%E0%A6%BE%E0%A brazzers-n.com http://brazzers-n.com/en/tgb/11741-%E0%A6%A8%E0%A6%BF%E0%A6%96%E0%A7%81%E0%A6%81%E0%A6%A4+%E0%A6%B8%E0%A7 xyutv-a.com http://xyutv-a.com/en/tag/2528-%E0%A6%95%E0%A7%81%E0%A6%A4%E0%A7%8D%E0%A6%A4%E0%A6%BE/ Motherfucker - fuck T hotpornadult.com http://hotpornadult.com/en/ HotPornAdult - porn in HD|Free porn videos online|Sliding menu|HotPornAdult trahtubetv.com http://trahtubetv.com/en/mi/9353721-vol.258-typorno.com.html vol.258 typorno.com|Menu|Tractor|Main (curre brazzers-n.com http://brazzers-n.com/en/tgb/8595-%E0%A6%97%E0%A6%B0%E0%A6%AE+%E0%A6%A7%E0%A6%BE%E0%A6%AA/ Hot Step - BRA xnxx-hd.pro http://xnxx-hd.pro/en/tag/4659-%E0%A6%AE%E0%A6%BE/ Busty Mother - Porno HD online in high quality|100% free 24video-net.com http://24video-net.com/en/footwork Footwork|Menu|24video|Main (current)|Random video|All categories|Engl ruporn-tv.com http://ruporn-tv.com/en/tag/1023-%E0%A4%8F%E0%A4%AE%E0%A4%86%E0%A4%88%E0%A4%8F%E0%A4%B2%E0%A4%8F+%E0%A4%AE pornoload-n.com http://pornoload-n.com/en/page/9/ Pornload best website with adult videos and porn clips adult free - pa porndig-n.com http://porndig-n.com/ PornDig: Porn tube video HD online Sex Free porn|Menu|Main (current)|Random video|Al brazzers-n.com http://brazzers-n.com/en/tgb/9-%E0%A6%AC%E0%A6%BE%E0%A6%B8%E0%A7%8D%E0%A6%A4%E0%A6%AC/ Real - BRAZZERS po pornoload-n.com http://pornoload-n.com/en/page/5/ Pornload best website with adult videos and porn clips adult free - pa brazzers-n.com http://brazzers-n.com/en/tgb/17424-%E0%A6%AB%E0%A7%8D%E0%A6%B2%E0%A6%BE%E0%A6%B6+%E0%A6%97%E0%A6%BE%E0%A6 reachporn.com https://www.reachporn.com/ Reach Porn » List Of The Best Porn Sites On The Net|Reach the best porn sites sozrelxxx.com http://sozrelxxx.com/en/c/ The list of all categories|ripe for porn|View all|English|Русский|Englis cucek.net http://cucek.net/en/hardcore Hardcore|Sliding menu|Cucek.NET|Main (current)|Random video|All categories|Englis brazzers-n.com http://brazzers-n.com/en/tgb/5025-%D0%A1%D1%83%D0%B2%D0%B4%D0%B0%D0%BD+%D0%97%D2%AF%D2%AF%D0%BB%D1%82/ Pe brazzers-n.com http://brazzers-n.com/en/tgb/9523-%D0%9D%D1%8E+%D0%94%D0%BE%D0%BC%D0%B0/ Nude House - BRAZZERS porn Studi trahtubetv.com http://trahtubetv.com/en/tag/55-%E0%A6%B8%E0%A7%81%E0%A6%A8%E0%A7%8D%E0%A6%A6%E0%A6%B0%E0%A6%BF+%E0%A6%B8 brazzers-n.com http://brazzers-n.com/en/tgb/19143-%D0%90%D1%80%D0%BC%D0%B5%D0%BD%D0%B8%D0%B9+%D0%9E%D1%85%D0%B8%D0%BD/ A biqle-ru.com http://biqle-ru.com/en/mk/50810-zombie-joi.html Zombie JOI|Menu|Main (current)|Random|Category|English|Ру hdbox.ws https://hdbox.ws/en/sat-tv-novosti/5065-transpondernye-novosti-sputnikovogo-televideniya-30-yanvarya-2018.html ecml.at http://edl.ecml.at/Home/WhyaEuropeanDayofLanguages/tabid/1763/language/en-GB/Default.aspx Why a European Day of brazzers-n.com http://brazzers-n.com/en/tgb/7754-%E0%A6%9F%E0%A6%BE%E0%A6%87%E0%A6%9F+%E0%A6%AF%E0%A7%8B%E0%A6%A8%E0%A6% brazzers-n.com http://brazzers-n.com/en/tgb/12173-%E0%A6%AA%E0%A7%8B%E0%A6%81%E0%A6%A6%2C+%E0%A6%AA%E0%A6%AA/ Ass Pop - brazzers-n.com http://brazzers-n.com/en/tgb/18830-Gaping+%D0%9D%D0%BE%D0%B9%D1%82%D0%BE%D0%BD+Pussy/ Gaping Wet Pussy - brazzers-n.com http://brazzers-n.com/en/tgb/17511-%E0%A6%9A%E0%A6%B0%E0%A6%AE+%E0%A6%B9%E0%A6%BF%E0%A6%B2/ Extreme Heels brazzers-n.com http://brazzers-n.com/en/tgb/15787-%E0%A4%8F%E0%A4%AE%E0%A5%87%E0%A4%9A%E0%A5%8D%E0%A4%AF%E0%A5%8B%E0%A4% xnxx-hd.pro http://xnxx-hd.pro/en/tag/16818-%E0%A4%AC%E0%A4%A1%E0%A4%BC%E0%A5%87+%E0%A4%B8%E0%A5%8D%E0%A4%A4%E0%A4%A8+%E brazzers-n.com http://brazzers-n.com/en/tgb/3373-%D0%A8%D0%B0%D1%80+%D0%91%D0%B8%D0%BA%D0%B8%D0%BD%D0%B8/ Yellow Bikini ruporn-tv.com http://ruporn-tv.com/en/tag/582-Fellatio/ Fellatio - Russian porn online watch free video on Ruporn.tv|Men pornoload-n.com http://pornoload-n.com/en/ch/ Chat|Menu|PornoLoad|Main (current)|Random video|All categories|English|Р� biqle-ru.com http://biqle-ru.com/en/mk/27008-,-brazzers--franceska-james , Brazzers - Franceska James&#39;s anal adventure|M gannuaire.com https://gannuaire.com/en/home Just Porn Xvideos, Free Porn Videos, Free Porn Download, Bb Ladies|DE|EN|CS| brazzers-n.com http://brazzers-n.com/en/tgb/9550-Craziest/ Craziest - BRAZZERS porn Studio. Porn clips brazzers Studio a brazzers-n.com http://brazzers-n.com/en/tgb/3714-POV+Fuck/ POV Fuck - BRAZZERS porn Studio. Porn clips brazzers Studio a affinicasts.com https://affinicasts.com/lexi-luna-bikini-0-1-223 Lexi Luna Bikini - English Porn Video - Free Porn Video ecml.at http://edl.ecml.at/LanguageFun/Celebritiesspeakinglanguages/tabid/3113/language/en-GB/Default.aspx European Day pornoload-n.com http://pornoload-n.com/ Pornload best website with adult videos and porn clips adult free|Menu|PornoLoad brazzers-n.com http://brazzers-n.com/en/hardcore/ Hardcore brazzers|Menu|Main (current)|Random video|Chat|All categories brazzers-n.com http://brazzers-n.com/en/tgb/21948-Big+C%C3%ADocha+M%C3%BAinteoir/ Big Boobs Teacher - BRAZZERS porn Stud brazzers-n.com http://brazzers-n.com/en/tgb/3096-%E0%A6%AD%E0%A6%BE%E0%A6%B2%2C+%E0%A6%AC%E0%A7%8D%E0%A6%B2%E0%A6%9C%E0% brazzers-n.com http://brazzers-n.com/en/celebrity/ Celebrity brazzers|Menu|Main (current)|Random video|Chat|All categori brazzers-n.com http://brazzers-n.com/en/tgb/13598-%E0%A6%AC%E0%A7%8D%E0%A6%B2%E0%A6%9C%E0%A6%AC+%E0%A6%AE%E0%A6%BE%E0%A6 brazzers-n.com http://brazzers-n.com/en/tgb/22448-%E0%A6%AE%E0%A7%81%E0%A6%96+%E0%A6%9A%E0%A6%A1%E0%A6%BC/ Face Slap - B brazzers-n.com http://brazzers-n.com/en/tgb/654-Bachelorette/ Bachelorette - BRAZZERS porn Studio. Porn clips brazzers S brazzers-n.com http://brazzers-n.com/en/tgb/14011-%D0%91%D0%B0%D0%B9%D0%B3%D0%B0%D0%BB%D0%B8%D0%B9%D0%BD+%D3%A8%D1%81%D0 brazzers-n.com http://brazzers-n.com/en/tgb/4224-%E0%A6%B8%E0%A7%87%E0%A6%95%E0%A7%8D%E0%A6%B8+%E0%A6%95%E0%A7%8D%E0%A6% brazzers-n.com http://brazzers-n.com/en/tgb/23569-%E0%A6%9A%E0%A7%81%E0%A6%B2%2C+%E0%A6%AA%E0%A7%8B%E0%A6%81%E0%A6%A6%2C brazzers-n.com http://brazzers-n.com/en/tgb/8670-%D0%AD%D0%BC%D1%87+%D0%A1%D1%83%D0%B2%D0%B8%D0%BB%D0%B0%D0%B3%D1%87/ Do brazzers-n.com http://brazzers-n.com/en/tgb/7986-%D0%91%D0%B0%D1%8F%D1%80%D1%82%D0%B0%D0%B9/ Excited - BRAZZERS porn Stu brazzers-n.com http://brazzers-n.com/en/tgb/6338-%E0%A6%B0%E0%A6%BE%E0%A6%B8%E0%A7%8D%E0%A6%A4%E0%A6%BE%E0%A6%B0+%E0%A6% brazzers-n.com http://brazzers-n.com/en/tgb/17449-%E0%A6%95%E0%A7%8D%E0%A6%AF%E0%A6%BE%E0%A6%AE%E0%A7%87%E0%A6%B0%E0%A6% redtube-n.com http://redtube-n.com/en/tag/ Menu|Main (current)|All categories|Random|English|Русский|English|Azə dojki-n.com http://dojki-n.com/en/nudists/pp/2/ Nudist videos online in hd quality - page 2|Menu|Main (current)|Random v ecml.at http://edl.ecml.at/LanguageFun/Hello/tabid/1876/language/en-GB/Default.aspx European Day of Languages &gt; Language brazzers-n.com http://brazzers-n.com/en/tgb/21973-%E0%A6%8F%E0%A6%95%E0%A6%BE%E0%A6%A7%E0%A6%BF%E0%A6%95+Squirting/ Mult youporn-n.com http://youporn-n.com/en/tis/11242-Brazzers%2C/ Brazzers Ass - Excellent Porn videos, sex movies, XXX Porn, sozrelxxx.com http://sozrelxxx.com/en/blowjob Super Blowjob video in excellent quality online|ripe for porn|Arab|Beach|B brazzers-n.com http://brazzers-n.com/en/tgb/19032-%E0%A6%A1%E0%A7%81%E0%A6%AC/ Dipping - BRAZZERS porn Studio. Porn clip brazzers-n.com http://brazzers-n.com/en/tgb/4846-%E0%A6%AE%E0%A6%BE%E0%A6%A4%E0%A7%8D%E0%A6%B0%E0%A6%BE%E0%A6%A4%E0%A6%B brazzers-n.com http://brazzers-n.com/en/tgb/15098-%2C+%E0%A6%97%E0%A6%AD%E0%A7%80%E0%A6%B0%2C+%E0%A6%AA%E0%A7%8B%E0%A6%8 brazzers-n.com http://brazzers-n.com/en/tgb/9090-%E0%A6%A4%E0%A6%B0%E0%A7%81%E0%A6%A3%2C+%E0%A6%AE%E0%A7%87%E0%A6%AF%E0% brazzers-n.com http://brazzers-n.com/en/tgb/8788-%E0%B0%AA%E0%B1%86%E0%B0%A6%E0%B1%8D%E0%B0%A7+%E0%B0%B0%E0%B1%8A%E0%B0% brazzers-n.com http://brazzers-n.com/en/tgb/32-Glamour/ Glamour - BRAZZERS porn Studio. Porn clips brazzers Studio and n ecml.at http://edl.ecml.at/Participate/Promoteyourevent/tabid/1768/language/en-GB/Default.aspx European Day of Languages brazzers-n.com http://brazzers-n.com/en/tgb/22267-%E0%A6%B9%E0%A7%8B%E0%A6%9F%E0%A7%87%E0%A6%B2+%E0%A6%AB%E0%A7%8D%E0%A6 brazzers-n.com http://brazzers-n.com/en/tgb/17023-%E0%A6%AD%E0%A6%BE%E0%A6%97%E0%A7%8D%E0%A6%AF%E0%A6%AC%E0%A6%BE%E0%A6% vporn-com.com http://vporn-com.com/en/ms/3397020-striptease.html Striptease|Menu|Main (current)|Random video|All categor ecml.at http://edl.ecml.at/Home/Movingintothepolyglotage/tabid/2970/language/en-GB/Default.aspx European Day of Language brazzers-n.com http://brazzers-n.com/en/threesome Threesome brazzers|Menu|Main (current)|Random video|Chat|All categorie brazzers-n.com http://brazzers-n.com/en/tgb/12851-%E0%B0%AD%E0%B0%BE%E0%B0%B0%E0%B1%8D%E0%B0%AF+%E0%B0%87%E0%B0%B0%E0%B1 brazzers-n.com http://brazzers-n.com/en/columbia/ Columbia brazzers|Menu|Main (current)|Random video|Chat|All categories xyutv-a.com http://xyutv-a.com/en/tag/6404-Sexy+Poibl%C3%AD/ Sexy Public - fuck TV PORN VIDEOS ONLINE - WATCH FREE best vporn-com.com http://vporn-com.com/en/tag/3821-%D0%97%D0%B0%D0%BB%D1%83%D1%83+%D0%AD%D0%BC%D1%8D%D0%B3%D1%82%D1%8D%D0%B9 brazzers-n.com http://brazzers-n.com/en/tgb/13598-%2C/ Suck Tits - BRAZZERS porn Studio. Porn clips brazzers Studio and brazzers-n.com http://brazzers-n.com/en/tgb/10582-%E0%A6%B8%E0%A7%87%E0%A6%95%E0%A7%8D%E0%A6%B8%E0%A6%BF%2C+%E0%A6%B8%E0 lenkino.mobi http://lenkino.mobi/en/mv/10405951-spandexporn-michaela.html SpandexPorn Michaela|720 HD video|Adult toys|A online-casino-10.pro http://online-casino-10.pro/ online-casino-10.pro - Free Czech Porn Videos And Amateur Sex Videos|M brazzers-n.com http://brazzers-n.com/en/tgb/21449-%E0%A6%A4%E0%A6%BF%E0%A6%A8%E0%A7%87+%E0%A6%AE%E0%A6%BF%E0%A6%B2%E0%A7 vporn-com.com http://vporn-com.com/en/tag/8471-Fraincis+Cum/ French Cum - porn - Best porn videos and Sex XXX movies, HD brazzers-n.com http://brazzers-n.com/en/tgb/16058-%D9%81%D9%8A+%D8%B3%D9%86+%D8%A7%D9%84%D9%85%D8%B1%D8%A7%D9%87%D9%82%D brazzers-n.com http://brazzers-n.com/en/tgb/13566-%E0%A6%AE%E0%A7%8D%E0%A6%AF%E0%A6%BE%E0%A6%B8%E0%A7%87%E0%A6%9C+%E0%A6 lenkino.mobi http://lenkino.mobi/en/otslaivanie/ Otslaivanie in lenkino|Adult toys|Apostate|Bisexual|Blonde|Bukkake|Cart brazzers-n.com http://brazzers-n.com/en/tgb/14756-%D0%97%D0%B0%D0%BB%D1%83%D1%83+%D0%A1%D0%BE%D0%BD%D0%B8%D1%80%D1%85%D0 pornyfree.com https://pornyfree.com/ Free Porn HD 4k,1080p,720p , Latest Porno Are Here|Skip to content|Follow me on:|We cucek.net http://cucek.net/en/rimjob/ Rimjob|Sliding menu|Cucek.NET|Main (current)|Random video|All categories|English|� brazzers-n.com http://brazzers-n.com/en/tgb/10899-%E0%A6%AC%E0%A6%A1%E0%A6%BC%E0%A7%8B+%E0%A6%AE%E0%A6%BE%E0%A6%87/ Voye ruporn-tv.com http://ruporn-tv.com/en/tag/17899-%2C%2C+%E0%A6%86%E0%A6%AF%E0%A6%BC%E0%A6%A8%E0%A6%BE%2C/ Teen Mirror - R ruporn-tv.com http://ruporn-tv.com/en/erotic/ Erotic|Menu|Main (current)|Random|Category|English|Русский|English| hdbox.ws https://hdbox.ws/en/sat-tv-novosti/4737-transpondernye-novosti-za-08-08-2017.html ﻿ Transponder news for 08.0 24video-xxx.com http://24video-xxx.com/en/tag/11458-R%C3%B8yking+120s/ Smoking 120s - 24video.xxx com porn watch online, brazzers-n.com http://brazzers-n.com/en/tgb/10485-%E0%A6%A6%E0%A7%87%E0%A6%96%E0%A6%BE/ Meet up - BRAZZERS porn Studio. tube8-n.com http://tube8-n.com/en/vibrator Vibrator porn videos|Menu|Main (current)|View all|At random|English|Русс� hotpornohub.com http://hotpornohub.com/en/tag/ Sliding menu|HotPornoHub|Main (current)|Random video|All categories|Engli biqle-ru.com http://biqle-ru.com/en/arab-porn/ Arab porn porn videos|Menu|Main (current)|Random|Category|English|Рус� brazzers-n.com http://brazzers-n.com/en/tgb/19015-%E0%A6%A1%E0%A6%BE%E0%A6%95%E0%A7%8D%E0%A6%A4%E0%A6%BE%E0%A6%B0/ Old D brazzers-n.com http://brazzers-n.com/en/tgb/19771-%E0%A8%B5%E0%A8%BF%E0%A8%86%E0%A8%B9+%E0%A8%A8%E0%A9%82%E0%A9%B0+%E0%A youjizzhd.net https://youjizzhd.net/en/porn-orgasms/ Porn orgasms on youjizz|Menu|Main (current)|Random video|All catego brazzers-n.com http://brazzers-n.com/en/tgb/17716-%E0%A6%AA%E0%A7%8B%E0%A6%81%E0%A6%A6+%E0%A6%97%E0%A7%81%E0%A6%A6+%E0%A ecml.at http://edl.ecml.at/LanguageFun/Selfevaluateyourlanguageskills/tabid/2194/language/en-GB/Default.aspx European Da brazzers-n.com http://brazzers-n.com/en/tgb/20192-%E0%A4%B8%E0%A4%B9+%E0%A4%95%E0%A4%B5%E0%A4%B0+Slut/ Cum Covered Slut brazzers-n.com http://brazzers-n.com/en/tgb/17-%D0%A2%D0%BE%D0%BC+%D0%A5%D1%83%D0%BB%D0%B0%D0%BD/ Big Ass - BRAZZERS por brazzers-n.com http://brazzers-n.com/en/tgb/1256-%D0%9E%D0%BD%D0%BB%D0%B0%D0%B9%D0%BD/ Online - BRAZZERS porn Studio. Po brazzers-n.com http://brazzers-n.com/en/tgb/21088-%E0%A6%A4%E0%A6%BF%E0%A6%A8%E0%A7%87+%E0%A6%AE%E0%A6%BF%E0%A6%B2%E0%A7 brazzers-n.com http://brazzers-n.com/en/tgb/10213-%E0%A6%86%E0%A6%AE%E0%A6%BE%E0%A6%B0+%E0%A6%B8%E0%A7%87%E0%A6%95%E0%A7 brazzers-n.com http://brazzers-n.com/en/tgb/18868-%D0%AD%D1%80%D0%BE%D1%82%D0%B8%D0%BA%D0%B0%D0%BB%D1%8B%D2%9B+%D0%91%D0 brazzers-n.com http://brazzers-n.com/en/tgb/5025-%E0%B9%80%E0%B8%9E%E0%B8%B4%E0%B8%A3%E0%B9%8C%E0%B8%A5%E0%B8%AD%E0%B8%A brazzers-n.com http://brazzers-n.com/en/tgb/5827-%E0%A6%B8%E0%A6%B0%E0%A6%95%E0%A6%BE%E0%A6%B0%E0%A7%80+%E0%A6%AB%E0%A7% vporn-com.com http://vporn-com.com/en/tag/4951-%D0%A5%D0%B0%D1%80+%D2%AE%D1%81%D1%82%D1%8D%D0%B9+%D0%A8%D1%83%D0%BB%D1%8 brazzers-n.com http://brazzers-n.com/en/tgb/12700-%E0%A6%B8%E0%A6%BE%E0%A6%A6%E0%A6%BE+%E0%A6%A6%E0%A7%88%E0%A6%A4%E0%A7 brazzers-n.com http://brazzers-n.com/en/tgb/12414-%E0%A6%B8%E0%A7%81%E0%A6%A8%E0%A7%8D%E0%A6%A6%E0%A6%B0%E0%A6%BF+%E0%A6 trahtubetv.com http://trahtubetv.com/en/mi/9686996-crazy-squealing-orgasm-dachix.com.html Crazy Squealing Orgasm dachix. brazzers-n.com http://brazzers-n.com/en/piercing/ Piercing brazzers|Menu|Main (current)|Random video|Chat|All categories ruporn-tv.com http://ruporn-tv.com/en/tag/2047-%E0%A4%97%E0%A5%81%E0%A4%B2%E0%A4%BE%E0%A4%AE+%E0%A4%AA%E0%A5%8D%E0%A4%B0 lenkino.mobi http://lenkino.mobi/en/tg/6394-%E0%A4%B8%E0%A5%80%E0%A4%96%E0%A4%A8%E0%A5%87/ Learning - Porn videos in HD 24video-xxx.com http://24video-xxx.com/en/c/full/ The list of all categories|To switch the language|Русский|Engli brazzers-n.com http://brazzers-n.com/en/tgb/5954-%D0%A2%D0%BE%D0%BC+%D0%98%D0%BB%D0%B6%D0%B8%D0%B3+Latina/ Big Ass Latin dojki-n.com http://dojki-n.com/en/tag/23086-%D0%98%D1%85+%D0%91%D1%80%D0%B8%D1%82%D0%B0%D0%BD%D0%B8%D0%B9%D0%BD+Sluts/ B brazzers-n.com http://brazzers-n.com/en/tgb/18928-%E0%A4%B6%E0%A4%BF%E0%A4%95%E0%A5%8D%E0%A4%B7%E0%A4%95+%E0%A4%89%E0%A4 trahtubetv.com http://trahtubetv.com/en/bikini Bikini|Menu|Tractor|Main (current)|Random video|All categories|English|Р trahtubetv.com http://trahtubetv.com/en/tag/758-Sciorta/ Skirt - Fuck tube. Check out hot pussies. Porn videos for free| tube8-n.com http://tube8-n.com/en/naked-porn-star Naked porn star porn videos|Menu|Main (current)|View all|At random|Eng cucek.net http://cucek.net/en/mcuc/11219659-scarlett-johansson%2C-john-g%2C-barea-follando-en-el-semad-sexed.su.html Sca brazzers-n.com http://brazzers-n.com/en/tgb/559-%E0%A6%95%E0%A6%BE%E0%A6%B2%E0%A7%8B+%E0%A6%AC%E0%A6%B9%E0%A7%81+%E0%A6% trahtubetv.com http://trahtubetv.com/en/massage Massage|Menu|Tractor|Main (current)|Random video|All categories|English| pornoload-n.com http://pornoload-n.com/en/tag/2615-%E0%A4%B5%E0%A4%BF%E0%A4%B6%E0%A4%BE%E0%A4%B2+%E0%A4%B8%E0%A5%8D%E0%A brazzers-n.com http://brazzers-n.com/en/tgb/12884-%E0%A6%95%E0%A7%8D%E0%A6%B0%E0%A7%80%E0%A6%A4%E0%A6%A6%E0%A6%BE%E0%A6% dojki-n.com http://dojki-n.com/en/tag/16482-%E0%A4%AE%E0%A5%87%E0%A4%B0%E0%A5%87+%E0%A4%B8%E0%A4%AC%E0%A4%B8%E0%A5%87+%E cucek.net http://cucek.net/en/rimjob Rimjob|Sliding menu|Cucek.NET|Main (current)|Random video|All categories|English|Р brazzers-n.com http://brazzers-n.com/en/tgb/20752-%E0%A4%85%E0%A4%9A%E0%A5%8D%E0%A4%9B%E0%A4%BE+%E0%A4%97%E0%A5%8D%E0%A4 trahtubetv.com http://trahtubetv.com/en/tag/12353-Busty+%E0%A4%B8%E0%A4%9A%E0%A4%BF%E0%A4%B5/ Busty Secretary - Fuck tub brazzers-n.com http://brazzers-n.com/en/tgb/5954-Asal+M%C3%B3r+Latina/ Big Ass Latina - BRAZZERS porn Studio. Porn clips pornk.mobi http://pornk.mobi/en/yoga/ Yoga porn pornk|Menu|Main (current)|Topics porn|Random video|Chat|English|Русс brazzers-n.com http://brazzers-n.com/en/tgb/4593-%E0%A6%B2%E0%A6%82+%E0%A6%AA%E0%A6%A6/ Long Legged - BRAZZERS porn Stud bizneswkatalogu.pl http://bizneswkatalogu.pl/en/ Lustful.TV|English|Afrikaans|العربية|Azərbaycanca|Белару� trahtubetv.com http://trahtubetv.com/en/tag/41-%E0%A6%97%E0%A7%81%E0%A6%A6/pi/11/ Pussy - Fuck tube. Check out hot pussi brazzers-n.com http://brazzers-n.com/en/tgb/11039-%E0%A6%A7%E0%A6%B0%E0%A7%8D%E0%A6%B7%E0%A6%A3%2C+%E0%A6%B8%E0%A7%8D%E0 brazzers-n.com http://brazzers-n.com/en/tgb/19357-%E0%A6%85%E0%A6%AA%E0%A7%87%E0%A6%B6%E0%A6%BE%E0%A6%A6%E0%A6%BE%E0%A6% erkiss-tv.com http://erkiss-tv.com/en/canadians/ Canadians porn on phone|Menu|Main (current)|Random|Chat|Category|Englis brazzers-n.com http://brazzers-n.com/en/tgb/8788-%D2%AE%D0%BB%D0%BA%D0%B5%D0%BD+%D0%A1%D0%B8%D1%81%D1%8C%D0%BA%D0%B8+%D0 brazzers-n.com http://brazzers-n.com/en/footwork/pgb/3/ Footwork brazzers - page 3|Menu|Main (current)|Random video|Chat brazzers-n.com http://brazzers-n.com/en/tgb/4872-Public+Fuck/ Public Fuck - BRAZZERS porn Studio. Porn clips brazzers St brazzers-n.com http://brazzers-n.com/en/pgb/3/ BRAZZERS porn Studio. Porn clips brazzers Studio and not only. - page 3|M hdbox.ws https://hdbox.ws/en/wetek-play/414-spisok-kanalov-36e-dlya-resivera-wetek-play-ot-05-11-2015.html Channel list pornk.mobi http://pornk.mobi/en/canadians/ Canadians porn pornk|Menu|Main (current)|Topics porn|Random video|Chat|Englis ruporn-tv.com http://ruporn-tv.com/en/tag/17050-%E0%A4%AC%E0%A4%82%E0%A4%A7%E0%A4%95+%E0%A4%AA%E0%A4%B0%E0%A4%AA%E0%A5%8 brazzers-n.com http://brazzers-n.com/en/tgb/36-%E0%A6%AC%E0%A6%A1%E0%A6%BC%E0%A7%8B+%E0%A6%AE%E0%A6%BE%E0%A6%87/ Big Tit brazzers-n.com http://brazzers-n.com/en/tgb/530-%D0%9D%D2%AF%D2%AF%D1%80+%D0%A5%D1%83%D1%83%D0%B4%D0%B0%D1%81+%D0%A5%D0% brazzers-n.com http://brazzers-n.com/en/tgb/13141-Caliente/ Caliente - BRAZZERS porn Studio. Porn clips brazzers Studio brazzers-n.com http://brazzers-n.com/en/tgb/2896-%E0%A6%B8%E0%A7%8D%E0%A6%A4%E0%A7%8D%E0%A6%B0%E0%A7%80/ Granny Fucks - brazzers-n.com http://brazzers-n.com/en/tgb/2045-Feminization/ Feminization - BRAZZERS porn Studio. Porn clips brazzers cucek.net http://cucek.net/en/mcuc/9325057-cunilingus-fantasti.cc.html Cunilingus fantasti.cc|Sliding menu|Cucek.NET|Mai brazzers-n.com http://brazzers-n.com/en/tgb/7168-%E0%A8%AE%E0%A8%BF%E0%A8%B2%E0%A9%8D%E0%A8%AB%E0%A8%BC+%E0%A8%9A%E0%A8% biqle-ru.com http://biqle-ru.com/en/mk/3350324-vor-der-cam-mastubiert.html Vor der Cam Mastubiert|Menu|Main (current)|Ra brazzers-n.com http://brazzers-n.com/en/tgb/4631-%E0%A6%B6%E0%A7%8D%E0%A6%B0%E0%A7%8B%E0%A6%A3%E0%A7%80%E0%A6%9A%E0%A6%9 x-artvideo.net https://x-artvideo.net/ x-artvideo - X-art Video is a free daily porn tube that offers free porn movies o pornoload-n.com http://pornoload-n.com/en/rimjob Rimjob|Menu|PornoLoad|Main (current)|Random video|All categories|Englis brazzers-n.com http://brazzers-n.com/en/tgb/10241-%E0%A6%AC%E0%A6%A1%E0%A6%BC%E0%A7%8B+%E0%A6%AE%E0%A6%BE%E0%A6%87+%E0%A brazzers-n.com http://brazzers-n.com/en/tgb/12764-%E0%A6%AD%E0%A6%BF%E0%A6%9C%E0%A6%BE%2C+%E0%A6%97%E0%A7%8B%E0%A6%B2%E0 hotpornohub.com http://hotpornohub.com/en/fatties/ Bbw porn videos in excellent quality|Sliding menu|HotPornoHub|Main (c pornk.mobi http://pornk.mobi/en/cheerleaders/ Cheerleaders porn pornk|Menu|Main (current)|Topics porn|Random video|Chat| ruporn-tv.com http://ruporn-tv.com/en/tag/328-%E0%A8%95%E0%A8%AE+++%E0%A8%A4%E0%A9%87+%E0%A8%AA%E0%A8%BF%E0%A8%9B%E0%A9% pornoload-n.com http://pornoload-n.com/en/tag/457-Oifig/page/10/ Office - Pornload best website with adult videos and po brazzers-n.com http://brazzers-n.com/en/tgb/18261-%E0%A6%85%E0%A6%A8%E0%A7%8D%E0%A6%A7%E0%A6%95%E0%A6%BE%E0%A6%B0+%E0%A6 brazzers-n.com http://brazzers-n.com/en/tgb/18869-%E0%A6%89%E0%A6%A4%E0%A7%8D%E0%A6%AF%E0%A6%95%E0%A7%8D%E0%A6%A4+%E0%A6 brazzers-n.com http://brazzers-n.com/en/tgb/3375-%E0%A6%AE%E0%A6%BE%E0%A6%96%E0%A6%A8%E0%A7%87%E0%A6%B0+%E0%A6%AE%E0%A6% brazzers-n.com http://brazzers-n.com/en/tgb/15712-%E0%A4%95%E0%A4%BF%E0%A4%B6%E0%A5%8B%E0%A4%B0+%E0%A4%AC%E0%A4%A1%E0%A4 brazzers-n.com http://brazzers-n.com/en/tgb/4427-%E0%A6%AF%E0%A7%8C%E0%A6%A8/ Sexually - BRAZZERS porn Studio. Porn clip brazzers-n.com http://brazzers-n.com/en/tgb/12398-%E0%A6%B9%E0%A6%BE%E0%A6%81%E0%A6%9F%E0%A7%81+%E0%A6%89%E0%A6%9A%E0%A7 brazzers-n.com http://brazzers-n.com/en/tgb/16614-%E0%A6%B9%E0%A6%BE%E0%A6%B0%E0%A7%8D%E0%A6%A1%2C/ Hard Strapon - BRAZZ brazzers-n.com http://brazzers-n.com/en/bdsm BDSM brazzers|Menu|Main (current)|Random video|Chat|All categories|English| brazzers-n.com http://brazzers-n.com/en/tgb/12601-%E0%A6%AE%E0%A7%81%E0%A6%96%E0%A6%97%E0%A6%A4+%E0%A6%AA%E0%A7%82%E0%A6 brazzers-n.com http://brazzers-n.com/en/tgb/14420-%D0%A1%D0%BE%D0%BB%D0%BE+%D0%94%D1%83%D1%80/ Solo Orgasm - BRAZZERS po brazzers-n.com http://brazzers-n.com/en/tgb/5183-%E0%A6%AA%E0%A7%8D%E0%A6%B0%E0%A6%9A%E0%A6%A3%E0%A7%8D%E0%A6%A1+%E0%A6% brazzers-n.com http://brazzers-n.com/en/tgb/21424-%E0%A6%86%E0%A6%81%E0%A6%9F+%E0%A6%AC%E0%A6%A1%E0%A6%BC%E0%A7%8B+%E0%A lenkino.mobi http://lenkino.mobi/en/anal Anal on lenkino|Anonymous chat !|18 years|Amateurs|Arab porn|Bathroom|Beach|Cum biqle-ru.com http://biqle-ru.com/en/t/1680-%E0%A8%86%E0%A8%AE/ Roughly - Porno HD online in high quality on biqle, witho brazzers-n.com http://brazzers-n.com/en/tgb/20975-%D0%92%D1%82%D0%B5%D1%87%D0%B0/ Escape - BRAZZERS porn Studio. Porn cl brazzers-n.com http://brazzers-n.com/en/tgb/23507-%E0%A6%B2%E0%A7%87%E0%A6%B8%E0%A6%AC%E0%A6%BF%E0%A6%AF%E0%A6%BC%E0%A6% trahtubetv.com http://trahtubetv.com/en/anal/pi/6/ Anal - page 6|Menu|Tractor|Main (current)|Random video|All categories brazzers-n.com http://brazzers-n.com/en/tgb/13264-%E0%A6%B8%E0%A7%8D%E0%A6%95%E0%A7%81%E0%A6%B2%2C/ School Fuck - BRAZZE vporn-com.com http://vporn-com.com/en/latex/ Latex only on anysex|Menu|Main (current)|Random video|All categories|Englis brazzers-n.com http://brazzers-n.com/en/tgb/19829-%E0%A4%97%E0%A5%81%E0%A4%82%E0%A4%A1%E0%A4%BE%2C/ Punk Lesbian - BRAZZ xvideos-a.com http://xvideos-a.com/en/moa/3597716-verronica-tempting-handjob.html Verronica Tempting Handjob|Navigation| brazzers-n.com http://brazzers-n.com/en/tgb/10899-%E0%B0%A4%E0%B0%B0%E0%B1%81%E0%B0%B2%E0%B1%81+%E0%B0%B8%E0%B1%86%E0%B0 ruporn-tv.com http://ruporn-tv.com/en/tag/3298-%E0%A4%B8%E0%A4%B9%E0%A4%AA%E0%A4%BE%E0%A4%A0%E0%A5%80/ Classmate - Russi brazzers-n.com http://brazzers-n.com/en/tgb/12967-%E0%A6%AA%E0%A6%B0%E0%A6%BF%E0%A6%A3%E0%A6%A4+%E0%A6%AE%E0%A7%87%E0%A6 ecml.at http://edl.ecml.at/LanguageFun/Talktome/tabid/1878/language/en-GB/Default.aspx European Day of Languages &gt; Langu brazzers-n.com http://brazzers-n.com/en/tgb/8788-%E0%A6%AC%E0%A6%A1%E0%A6%BC%E0%A7%8B+%E0%A6%AE%E0%A6%BE%E0%A6%87+%E0%A6 brazzers-n.com http://brazzers-n.com/en/tgb/10099-%E0%A6%B8%E0%A7%81%E0%A6%A8%E0%A7%8D%E0%A6%A6%E0%A6%B0%E0%A7%80+%E0%A6 brazzers-n.com http://brazzers-n.com/en/tgb/19789-%E0%A6%95%E0%A6%BE%E0%A6%B2%E0%A7%8B+%E0%A6%95%E0%A6%AE%E0%A7%8D%E0%A6 hdbox.ws https://hdbox.ws/en/sat-tv-novosti/5311-transpondernye-novosti-sputnikovogo-televideniya-11-maya-2018.html ﻿ hotpornohub.com http://hotpornohub.com/en/mov/11135847-closeup-creampie.html closeup Creampie|Sliding menu|HotPornoHub|M ecml.at http://edl.ecml.at/Participate/Materials/tabid/1769/language/en-GB/Default.aspx European Day of Languages &gt; Part hotpornohub.com http://hotpornohub.com/en/fatties Bbw porn videos in excellent quality|Sliding menu|HotPornoHub|Main (cu brazzers-n.com http://brazzers-n.com/en/tgb/15845-%E0%A6%B8%E0%A6%95+%E0%A6%AA%E0%A7%82%E0%A6%9C%E0%A6%BE/ Sock Worship pornoload-n.com http://pornoload-n.com/en/tag/11115-%D0%92+%D0%A8%D0%BA%D0%BE%D0%BB%D0%B5/ At School - Pornload best web pikeals.org https://pikeals.org/en/home English Porn Video - Free Porn Videos Xvideos, Pornhub, xnxx - Snapchat Cosplay| brazzers-n.com http://brazzers-n.com/en/tgb/14315-%E0%A6%B8%E0%A7%8D%E0%A6%A4%E0%A7%8D%E0%A6%B0%E0%A7%80+%E0%A6%9D%E0%A6 brazzers-n.com http://brazzers-n.com/en/tgb/112-%E0%A8%97%E0%A9%B0%E0%A8%A6%E0%A9%87+%E0%A8%A6%E0%A9%80+%E0%A8%9A%E0%A9% erkiss-tv.com http://erkiss-tv.com/en/tag_phone/1586-%E0%A6%AE%E0%A6%BE%E0%A6%B0%E0%A7%8D%E0%A6%9C%E0%A6%A8/ Rubbing - P ecml.at http://edl.ecml.at/Participate/Howtoparticipate/tabid/1766/language/en-GB/Default.aspx European Day of Languages ruporn-tv.com http://ruporn-tv.com/en/tag/381-%E0%A4%AC%E0%A4%BF%E0%A4%B2%E0%A5%8D%E0%A4%B2%E0%A5%80+%E0%A4%95%E0%A4%AE% brazzers-n.com http://brazzers-n.com/en/tgb/18853-%E0%A6%AA%E0%A6%A4%E0%A6%BF%E0%A6%A4+%E0%A6%9C%E0%A6%AE%E0%A6%BF/ Wast brazzers-n.com http://brazzers-n.com/en/tgb/21233-%E0%A6%85%E0%A6%AA%E0%A7%87%E0%A6%B6%E0%A6%BE%E0%A6%A6%E0%A6%BE%E0%A6% ruporn-tv.com http://ruporn-tv.com/en/tag/1494-%E0%A4%96%E0%A5%82%E0%A4%AC%E0%A4%B8%E0%A5%82%E0%A4%B0%E0%A4%A4+%E0%A4%B5 hdbox.ws https://hdbox.ws/en/sat-tv-novosti/3008-transpondernye-novosti-za-07-10-2016.html » Transponder news for 07.10 brazzers-n.com http://brazzers-n.com/en/tgb/10899-%E0%A4%A6%E0%A5%83%E0%A4%B6%E0%A5%8D%E0%A4%AF%E0%A4%B0%E0%A4%A4%E0%A4% brazzers-n.com http://brazzers-n.com/en/tgb/19829-%E0%A6%AC%E0%A6%BE%E0%A6%9C%E0%A7%87+%E0%A6%95%E0%A6%A5%E0%A6%BE%2C/ P brazzers-n.com http://brazzers-n.com/en/tgb/15812-%E0%A6%AC%E0%A7%8D%E0%A6%B0%E0%A6%BF%E0%A6%9F%E0%A6%BF%E0%A6%B6+%E0%A6 fuckedtonight.com http://www.fuckedtonight.com/en/ Free porn @ Fucked Tonight|FuckedTonight|English|Ελληνικά|Gal brazzers-n.com http://brazzers-n.com/en/tgb/4173-%E0%A6%B8%E0%A7%8D%E0%A6%AC%E0%A6%B0%E0%A7%8D%E0%A6%A3%E0%A6%95%E0%A7%8 brazzers-n.com http://brazzers-n.com/en/tgb/21533-%E0%A4%B9%E0%A5%82%E0%A4%95%E0%A4%B0%2C/ Hooker Creampie - BRAZZERS po vporn-com.com http://vporn-com.com/en/tag/458-%D0%94%D0%BE%D1%82%D1%83%D1%83%D1%80+%D1%85%D1%83%D0%B2%D1%86%D0%B0%D1%81/ sozrelxxx.com http://sozrelxxx.com/en/tag/23492-%D3%98%D1%83%D0%B5%D1%81%D2%9B%D0%BE%D0%B9%D0%BB%D1%8B%D2%9B+%D0%96%D0%B brazzers-n.com http://brazzers-n.com/en/tgb/12632-%E0%A6%AC%E0%A6%BE%E0%A6%B9+%E0%A6%AC%E0%A7%83%E0%A6%A6%E0%A7%8D%E0%A6 pornoload-n.com http://pornoload-n.com/en/tag/8784-%E0%A6%86%E0%A6%AC%E0%A6%B9%E0%A6%BE%E0%A6%93%E0%A6%AF%E0%A6%BC%E0%A6 eporner-n.com http://eporner-n.com/en/negros Negros _ EPORNER|Menu|Main (current)|All categories|Random|English|Русс ecml.at http://edl.ecml.at/Participate/Whocanparticipate/tabid/1765/language/en-GB/Default.aspx European Day of Language biqle-ru.com http://biqle-ru.com/en/t/35-%D0%97%D0%B0%D0%BB%D1%83%D1%83/ Young - Porno HD online in high quality on biql ecml.at http://edl.ecml.at/Participate/tabid/1764/language/en-GB/Default.aspx Participate|Home (Basque)|What is it?|Why erkiss-tv.com http://erkiss-tv.com/en/gangbang-gangbang Gangbang gangbang porn on phone|Menu|Main (current)|Random|Chat| pornoload-n.com http://pornoload-n.com/en/tag/255-Big+Dick Big Dick - Pornload best website with adult videos and porn c brazzers-n.com http://brazzers-n.com/en/tgb/16181-%E0%A6%A8%E0%A6%97%E0%A7%8D%E0%A6%A8+%E0%A6%AA%E0%A6%B0%E0%A7%8D%E0%A6 brazzers-n.com http://brazzers-n.com/en/feedback/ Feedback|Menu|Main (current)|Random video|Chat|All categories|English| xyutv-a.com http://xyutv-a.com/en/tag/1773-I+an+linn+Sn%C3%A1mha/ In the Pool - fuck TV PORN VIDEOS ONLINE - WATCH FREE lenkino.mobi http://lenkino.mobi/en/pg/4/ Porn videos in HD quality. This Lenkino porn online! Watch porn for free! - pa nakedgirls.org https://nakedgirls.org/ Naked Girls - Hot Nude Women &amp; Naked Teen Girls Videos|Skip to content|Home|Categ brazzers-n.com http://brazzers-n.com/en/tgb/1600-%E0%A6%8F%E0%A6%B6%E0%A6%BF%E0%A6%AF%E0%A6%BC%E0%A6%BE%E0%A6%A8/ Asian tube8-n.com http://tube8-n.com/en/otslaivanie Otslaivanie porn videos|Menu|Main (current)|View all|At random|English|Р� brazzers-n.com http://brazzers-n.com/en/tgb/7858-%E0%A6%AA%E0%A7%81%E0%A6%B0%E0%A7%81%2C+%E0%A6%86%E0%A6%AC%E0%A6%B2%E0% brazzers-n.com http://brazzers-n.com/en/tgb/16899-%E0%A6%AC%E0%A6%BE%E0%A6%B8%E0%A7%8D%E0%A6%A4%E0%A6%AC+%E0%A6%AA%E0%A7 ecml.at http://edl.ecml.at/Events/PictureGallery2012/tabid/3090/language/en-GB/Default.aspx Picture Gallery 2012|Home (B pornozal-net.com http://pornozal-net.com/en/tag/ Menu|Pornosu Porn|Main (current)|Random|Our categories|English|Русс online-casino-10.pro http://online-casino-10.pro/en/reference/online_services/ online-casino-10.pro - Free Czech Porn Vi dojki-n.com http://dojki-n.com/en/latina Latina videos online in hd quality|Menu|Main (current)|Random video|All categor ruporn-tv.com http://ruporn-tv.com/en/moms Moms|Menu|Main (current)|Random|Category|English|Русский|English|Azər brazzers-n.com http://brazzers-n.com/en/footwork/ Footwork brazzers|Menu|Main (current)|Random video|Chat|All categories ruporn-tv.com http://ruporn-tv.com/en/m/10201287-nackt-im-wald.html Nackt im Wald|Menu|Main (current)|Random|Category|En ruporn-tv.com http://ruporn-tv.com/en/tag/17143-%E0%A4%A1%E0%A5%88%E0%A4%B0%E0%A4%BF%E0%A4%B2/ Darryl - Russian porn onl ruporn-tv.com http://ruporn-tv.com/en/tag/12421-%2C+%E0%A4%95%E0%A4%BE%E0%A4%AE/ MILF Work - Russian porn online watch f fucked-movies.com http://fucked-movies.com/en/ Fucked Movies|English|Afrikaans|العربية|Azərbaycanca|Белару xnxx-hd.pro http://xnxx-hd.pro/en/tag/16818-%E0%A6%AC%E0%A6%A1%E0%A6%BC%E0%A7%8B+%E0%A6%AE%E0%A6%BE%E0%A6%87+%E0%A6%A8%E brazzers-n.com http://brazzers-n.com/en/tgb/18992-%D0%9E%D1%85%D0%B8%D0%BD+%D0%A5%D0%B0%D1%88%D0%B3%D0%B8%D1%80%D1%87/ G biqle-ru.com http://biqle-ru.com/en/closeup Closeup porn videos|Menu|Main (current)|Random|Category|English|Русски brazzers-n.com http://brazzers-n.com/en/tgb/19541-%E0%A6%AC%E0%A6%BE%E0%A6%81%E0%A6%A1%E0%A6%BC%E0%A6%BE%E0%A6%B0+%E0%A6 pornoload-n.com http://pornoload-n.com/en/tag/19078-Melena/ Melena - Pornload best website with adult videos and porn cl brazzers-n.com http://brazzers-n.com/en/tgb/5183-%E0%B0%A8%E0%B0%B2%E0%B1%81%E0%B0%97%E0%B1%81%E0%B0%B0%E0%B1%81+%E0%B0% brazzers-n.com http://brazzers-n.com/en/tgb/7168-%E0%A6%B8%E0%A7%81%E0%A6%A8%E0%A7%8D%E0%A6%A6%E0%A6%B0%E0%A6%BF+%E0%A6% brazzers-n.com http://brazzers-n.com/en/tgb/11752-%E0%A6%9F%E0%A7%8D%E0%A6%AF%E0%A6%BE%E0%A6%95%E0%A7%8D%E0%A6%B8%E0%A6% brazzers-n.com http://brazzers-n.com/en/tgb/6306-%E0%A6%96%E0%A7%81%E0%A6%AC%2C+%E0%A6%B8%E0%A7%87%E0%A6%95%E0%A7%8D%E0% brazzers-n.com http://brazzers-n.com/en/tgb/590-%E0%A6%86%E0%A6%99%E0%A7%81%E0%A6%B2+%E0%A6%97%E0%A7%81%E0%A6%A6/ Finger pornk.mobi http://pornk.mobi/en/strapon/ Strapon porn pornk|Menu|Main (current)|Topics porn|Random video|Chat|English|Р brazzers-n.com http://brazzers-n.com/en/tgb/11643-%E0%A6%B8%E0%A7%8D%E0%A6%A4%E0%A7%8D%E0%A6%B0%E0%A7%80%2C+Cheats+%E0%A vporn-com.com http://vporn-com.com/en/tag/7184-%E0%A6%A1%E0%A6%AC%E0%A6%B2%2C+%E0%A6%B8%E0%A7%8D%E0%A6%9F%E0%A6%BE%E0%A6 lenkino.mobi http://lenkino.mobi/en/pg/6/ Porn videos in HD quality. This Lenkino porn online! Watch porn for free! - pa ecml.at http://edl.ecml.at/Contact/tabid/1519/language/en-GB/Default.aspx European Day of Languages &gt; Contact|Home (Basq brazzers-n.com http://brazzers-n.com/en/tgb/8238-%E0%A6%B0%E0%A6%BE%E0%A6%A4/ Nights - BRAZZERS porn Studio. Porn clips brazzers-n.com http://brazzers-n.com/en/tgb/6150-Hard+Ass+Fuck/ Hard Ass Fuck - BRAZZERS porn Studio. Porn clips brazzer pornoload-n.com http://pornoload-n.com/en/tag/7401-%E0%A8%B5%E0%A9%87%E0%A8%B8%E0%A8%BC%E0%A8%B5%E0%A8%BE+%E0%A8%A6%E0%A brazzers-n.com http://brazzers-n.com/en/tgb/9967-%E0%A6%85%E0%A6%AA%E0%A7%87%E0%A6%B6%E0%A6%BE%E0%A6%A6%E0%A6%BE%E0%A6%B brazzers-n.com http://brazzers-n.com/en/tgb/1545-%E0%A6%AC%E0%A6%BF%E0%A6%A6%E0%A6%BE%E0%A6%B0%E0%A6%A3/ Cleavage - BRAZ lenkino.mobi http://lenkino.mobi/en/tg/19868-%E0%A4%AC%E0%A4%A6%E0%A4%B8%E0%A5%82%E0%A4%B0%E0%A4%A4+%E0%A4%B5%E0%A5%89%E brazzers-n.com http://brazzers-n.com/en/tgb/9369-%E0%A6%AC%E0%A6%BE%E0%A6%81%E0%A6%A1%E0%A6%BC%E0%A6%BE%E0%A6%B0+%E0%A6% brazzers-n.com http://brazzers-n.com/en/tgb/5399-%E0%A6%97%E0%A6%B0%E0%A6%AE%2C+%E0%A6%AA%E0%A6%BE%E0%A6%AF%E0%A6%BC%E0% brazzers-n.com http://brazzers-n.com/en/tgb/13919-%E0%A6%AC%E0%A7%8D%E0%A6%B2%E0%A6%9C%E0%A6%AC+%E0%A6%AA%E0%A6%BE%E0%A6 brazzers-n.com http://brazzers-n.com/en/tgb/18500-%E0%A6%AF%E0%A7%8C%E0%A6%A8%E0%A6%A4%E0%A6%BE+%E0%A6%86%E0%A6%AE%E0%A6 brazzers-n.com http://brazzers-n.com/en/tgb/10664-%E0%A6%97%E0%A7%8B%E0%A6%B2%E0%A6%BE%E0%A6%AA%E0%A7%80+%E0%A6%AA%E0%A7 brazzers-n.com http://brazzers-n.com/en/tgb/4628-%E0%A6%9D%E0%A6%B0%E0%A6%A8%E0%A6%BE+%E0%A6%AE%E0%A6%9C%E0%A6%BE/ Showe 24video-xxx.com http://24video-xxx.com/en/tag/8784-Wetter+M%C3%A4dchen/ Weather Girl - 24video.xxx com porn watch online brazzers-n.com http://brazzers-n.com/en/tgb/18853-%E0%A8%B5%E0%A8%BF%E0%A8%B0%E0%A8%BE%E0%A8%A8/ Wasteland - BRAZZERS po brazzers-n.com http://brazzers-n.com/en/tgb/9408-%E0%A6%95%E0%A6%A6%E0%A6%B0%E0%A7%8D%E0%A6%AF+%E0%A6%AE%E0%A7%81%E0%A6% lenkino.mobi http://lenkino.mobi/en/rimjob/ Rimjob on lenkino|Anonymous chat !|18 years|720 HD video|BDSM|Big Tits|Casti hdbox.ws https://hdbox.ws/en/sat-tv-novosti/3714-transpondernye-novosti-za-23-11-2016.html » Transponder news for 23.11 lenkino.mobi http://lenkino.mobi/en/720-hd-video/ 720 HD video on lenkino|Arab porn|BDSM|Bikini|Bondage|Celebrity|Chines ruporn-tv.com http://ruporn-tv.com/en/moms/ Moms|Menu|Main (current)|Random|Category|English|Русский|English|Azə brazzers-n.com http://brazzers-n.com/en/tgb/21948-%D2%AE%D0%BB%D0%BA%D0%B5%D0%BD+%D0%A1%D0%B8%D1%81%D1%8C%D0%BA%D0%B8+%D brazzers-n.com http://brazzers-n.com/en/mb/5552913-milf,-molto-troia.html Milf, molto Troia|Menu|Main (current)|Random v brazzers-n.com http://brazzers-n.com/en/tgb/3663-%E0%A6%AC%E0%A6%A1%E0%A6%BC+%E0%A6%B8%E0%A7%81%E0%A6%A8%E0%A7%8D%E0%A6% brazzers-n.com http://brazzers-n.com/en/ BRAZZERS porn Studio. Porn clips brazzers Studio and not only.|Menu|Main (curre ruporn-tv.com http://ruporn-tv.com/en/tag/3862-Par+Elske/ Couple Make Love - Russian porn online watch free video on Rup brazzers-n.com http://brazzers-n.com/en/tgb/20235-%D0%A2%D0%BE%D0%BC+%D0%98%D0%BB%D0%B6%D0%B8%D0%B3+Slut/ Big Ass Slut - brazzers-n.com http://brazzers-n.com/en/tgb/583-%E0%A6%87%E0%A6%A4%E0%A6%B0/ Hooker - BRAZZERS porn Studio. Porn clips b brazzers-n.com http://brazzers-n.com/en/tgb/44-%D0%93%D1%83%D1%80%D0%B2%D0%B0%D0%BB%D1%81%D0%B0%D0%BD+%D0%B3%D1%80%D1%83 trahtubetv.com http://trahtubetv.com/en/tag/3351-Te+Altra/ Hot Nurse - Fuck tube. Check out hot pussies. Porn videos for brazzers-n.com http://brazzers-n.com/en/tgb/353-%E0%A6%97%E0%A6%B0%E0%A6%AE+%E0%A6%B8%E0%A7%81%E0%A6%A8%E0%A7%8D%E0%A6%A erkiss-tv.com http://erkiss-tv.com/en/tag_phone/1977-%E0%A6%AC%E0%A6%A1%E0%A6%BC+%E0%A6%AE%E0%A7%8B%E0%A6%B0%E0%A6%97+%E brazzers-n.com http://brazzers-n.com/en/tgb/7870-%E0%A6%B8%E0%A7%81%E0%A6%A8%E0%A7%8D%E0%A6%A6%E0%A6%B0%E0%A6%BF+%E0%A6% vporn-com.com http://vporn-com.com/en/tag/16192-%E0%A6%95%E0%A6%BE%E0%A6%B2%E0%A7%8B+%E0%A6%AA%E0%A7%8D%E0%A6%AF%E0%A6%B ecml.at http://edl.ecml.at/Home/Whatisit/tabid/1760/language/en-GB/Default.aspx What is it?|Home (Basque)|What is it?|Wh 24video-xxx.com http://24video-xxx.com/en/tag/562-%D0%A5%D0%B0%D1%80%2C/ Black and - 24video.xxx com porn watch online, brazzers-n.com http://brazzers-n.com/en/tgb/11849-%E0%A6%A8%E0%A6%BF%E0%A6%9F%E0%A7%8B%E0%A6%B2+%E0%A6%AC%E0%A6%A1%E0%A6 brazzers-n.com http://brazzers-n.com/en/venezuelan/ Venezuelan brazzers|Menu|Main (current)|Random video|Chat|All catego pornoload-n.com http://pornoload-n.com/en/tag/36-%E0%A6%AC%E0%A6%A1%E0%A6%BC%E0%A7%8B+%E0%A6%AE%E0%A6%BE%E0%A6%87/page/4 vuku-cc.com http://vuku-cc.com/en/tag/ Menu|Main (current)|Random video|All categories|English|Русский|English|Az brazzers-n.com http://brazzers-n.com/en/tgb/720-%E0%A6%9F%E0%A6%BE%E0%A6%87%E0%A6%9F+%E0%A6%AD%E0%A6%97+%E0%A6%B0%E0%A6% brazzers-n.com http://brazzers-n.com/en/tgb/11930-%E0%A6%AE%E0%A7%8D%E0%A6%AF%E0%A6%BE%E0%A6%A1%E0%A6%BF%E0%A6%B8%E0%A6% hdbox.ws https://hdbox.ws/en/soft/2288-skachat-plagin-emulyator-oscam-11272-arm-wetek-pod-libreelec-i-openelec.html » D brazzers-n.com http://brazzers-n.com/en/tgb/8193-%E0%A6%AC%E0%A7%83%E0%A6%A6%E0%A7%8D%E0%A6%A7%E0%A6%BE%2C+%E0%A6%AA%E0% brazzers-n.com http://brazzers-n.com/en/tgb/18928-%E0%A6%B6%E0%A6%BF%E0%A6%95%E0%A7%8D%E0%A6%B7%E0%A6%95+%E0%A6%A4%E0%A6 ruporn-tv.com http://ruporn-tv.com/en/tag/12421-MILF+Arbeid/ MILF Work - Russian porn online watch free video on Ruporn. brazzers-n.com http://brazzers-n.com/en/tgb/13249-%E0%A6%95%E0%A6%BF%E0%A6%AD%E0%A6%BE%E0%A6%AC%E0%A7%87+%E0%A6%AC%E0%A7 hdbox.ws https://hdbox.ws/en/sat-tv-novosti/5089-transpondernye-novosti-sputnikovogo-televideniya-17-fevralya-2018.html xvideos-a.com http://xvideos-a.com/en/vibrator/ View Vibrator|Navigation|On the main (current)|Random video|Sections|Eng brazzers-n.com http://brazzers-n.com/en/tgb/18868-%E0%A6%AA%E0%A7%8D%E0%A6%B0%E0%A7%87%E0%A6%AE%E0%A6%AE%E0%A7%82%E0%A6% brazzers-n.com http://brazzers-n.com/en/tgb/20478-%E0%A8%95%E0%A8%BE%E0%A8%B2%E0%A9%87+%E0%A8%85%E0%A8%A7%E0%A8%BF%E0%A8 brazzers-n.com http://brazzers-n.com/en/tgb/424-Tits+N%C3%A1d%C3%BArtha/ Natural Tits - BRAZZERS porn Studio. Porn clips brazzers-n.com http://brazzers-n.com/en/tgb/10968-%E0%A6%B8%E0%A7%87%E0%A6%95%E0%A7%8D%E0%A6%B8%2C+%E0%A6%95%E0%A7%8D%E0 brazzers-n.com http://brazzers-n.com/en/tgb/15712-%E0%A6%AA%E0%A7%8B%E0%A6%81%E0%A6%A6%2C+Big+Dick%2C/ Teen with Big Dic brazzers-n.com http://brazzers-n.com/en/bdsm/ BDSM brazzers|Menu|Main (current)|Random video|Chat|All categories|English brazzers-n.com http://brazzers-n.com/en/tgb/4871-%E0%A6%AA%E0%A7%8D%E0%A6%B0%E0%A7%87%E0%A6%AE+%E0%A6%9F%E0%A6%BE%E0%A6% eporner-n.com http://eporner-n.com/en/fisting Fisting _ EPORNER|Menu|Main (current)|All categories|Random|English|Рус pornoload-n.com http://pornoload-n.com/en/movie/9725122-hairy-monica-2.html Hairy Monica 2|Menu|PornoLoad|Main (current) brazzers-n.com http://brazzers-n.com/en/tgb/19745-%E0%A6%97%E0%A6%B0%E0%A6%AE%2C+%E0%A6%87%E0%A6%A4%E0%A6%BE%E0%A6%B2%E0 brazzers-n.com http://brazzers-n.com/en/tgb/21973-%E0%A8%95%E0%A8%88+Squirting/ Multiple Squirting - BRAZZERS porn Studi lenkino.mobi http://lenkino.mobi/en/tg/2050-%E0%A4%97%E0%A5%81%E0%A4%A6%E0%A4%BE+%E0%A4%AA%E0%A5%8D%E0%A4%AF%E0%A4%BE%E0 brazzers-n.com http://brazzers-n.com/en/tgb/16056-%E0%A6%B9%E0%A6%BF%E0%A6%A8%E0%A7%8D%E0%A6%A6%E0%A6%BF+%E0%A6%97%E0%A6 pornk.mobi http://pornk.mobi/en/negros Negros porn pornk|Menu|Main (current)|Topics porn|Random video|Chat|English|Ру� yaxochu.ru http://yaxochu.ru/en/tag/ Sliding menu|I want...|Main (current)|Category|Random video|English|Русский| pornoload-n.com http://pornoload-n.com/en/massage/ Massage|Menu|PornoLoad|Main (current)|Random video|All categories|Eng brazzers-n.com http://brazzers-n.com/en/tgb/21924-%E0%A6%9C%E0%A6%BE%E0%A6%AA%E0%A6%BE%E0%A6%A8%E0%A6%BF+%E0%A6%B8%E0%A7 brazzers-n.com http://brazzers-n.com/en/mb/11116607-kigurumi.html kigurumi|Menu|Main (current)|Random video|Chat|All cat brazzers-n.com http://brazzers-n.com/en/otslaivanie/ Otslaivanie brazzers|Menu|Main (current)|Random video|Chat|All cate ruporn-tv.com http://ruporn-tv.com/en/tag/1505-Rubia+Folla/ Blonde Fucks - Russian porn online watch free video on Rupor brazzers-n.com http://brazzers-n.com/en/tgb/15787-%D0%A1%D0%BE%D0%BD%D0%B8%D1%80%D1%85%D0%BE%D0%B3%D1%87%D0%B4%D1%8B%D0% brazzers-n.com http://brazzers-n.com/en/tgb/41-%E0%A6%97%E0%A7%81%E0%A6%A6/ Pussy - BRAZZERS porn Studio. Porn clips bra pornk.mobi http://pornk.mobi/en/bikini/ Bikini porn pornk|Menu|Main (current)|Topics porn|Random video|Chat|English|Ру brazzers-n.com http://brazzers-n.com/en/cb/ The list of all categories|Menu|Main (current)|Random video|Chat|All categor brazzers-n.com http://brazzers-n.com/en/tgb/18721-%E0%A6%B9%E0%A6%BE%E0%A6%81%E0%A6%9F%E0%A7%81+%E0%A6%89%E0%A6%9A%E0%A7 xnxx-hd.pro http://xnxx-hd.pro/en/cts/ The list of all categories|100% free porn videos sex content|Search|Main (current brazzers-n.com http://brazzers-n.com/en/tgb/1972-%E0%A6%AC%E0%A6%BF%E0%A6%B0%E0%A6%95%E0%A7%8D%E0%A6%A4+%E0%A6%95%E0%A6% lenkino.mobi http://lenkino.mobi/en/rimjob Rimjob on lenkino|Anonymous chat !|Amateurs|Big Tits|Bisexual|Cartoon adult|C 24video-xxx.com http://24video-xxx.com/en/m/3377548-moms.html Moms|To switch the language|Русский|English|Azərba brazzers-n.com http://brazzers-n.com/en/fisting/ Fisting brazzers|Menu|Main (current)|Random video|Chat|All categories|E dojki-n.com http://dojki-n.com/en/threesome Threesome sex videos online in hd quality|Menu|Main (current)|Random video|A brazzers-n.com http://brazzers-n.com/en/tgb/8579-%E0%A6%86%E0%A6%B6%E0%A7%8D%E0%A6%9A%E0%A6%B0%E0%A7%8D%E0%A6%AF%E0%A6%9 brazzers-n.com http://brazzers-n.com/en/tgb/4203-%E0%A6%AD%E0%A6%BE%E0%A6%97%E0%A7%8D%E0%A6%AF%E0%A6%AC%E0%A6%BE%E0%A6%A ruporn-tv.com http://ruporn-tv.com/en/tag/8058-%E0%A8%B5%E0%A8%BF%E0%A8%86%E0%A8%B9/ Wedding - Russian porn online watch brazzers-n.com http://brazzers-n.com/en/tgb/2703-%E0%A6%95%E0%A6%B0%E0%A7%8D%E0%A6%AE%E0%A6%9A%E0%A6%BE%E0%A6%B0%E0%A7%8 xnxx-hd.pro http://xnxx-hd.pro/en/striptease/ Striptease high quality videos for You.|100% free porn videos sex content| pornoload-n.com http://pornoload-n.com/en/tag/429-Coileach+M%C3%B3r/ Big Cock - Pornload best website with adult videos trahtubetv.com http://trahtubetv.com/en/yoga/ Yoga|Menu|Tractor|Main (current)|Random video|All categories|English|Ру� brazzers-n.com http://brazzers-n.com/en/tgb/9098-%E0%A6%8F%E0%A6%95+%E0%A6%AE%E0%A6%B9%E0%A6%BF%E0%A6%B2%E0%A6%BE+%E0%A6 ruporn-tv.com http://ruporn-tv.com/en/vibrator/p/6/ Vibrator - page 6|Menu|Main (current)|Random|Category|English|Рус brazzers-n.com http://brazzers-n.com/en/tgb/22349-%E0%A6%B8%E0%A7%8D%E0%A6%AC%E0%A6%BE%E0%A6%AE%E0%A7%80/ Teagan - BRAZZ brazzers-n.com http://brazzers-n.com/en/tgb/15966-%E0%A6%AC%E0%A6%BE%E0%A6%B8%E0%A7%8D%E0%A6%A4%E0%A6%AC+%E0%A6%AE%E0%A7 brazzers-n.com http://brazzers-n.com/en/tgb/15712-%D9%81%D9%8A+%D8%B3%D9%86+%D8%A7%D9%84%D9%85%D8%B1%D8%A7%D9%87%D9%82%D brazzers-n.com http://brazzers-n.com/en/tgb/16875-%E0%A6%B0%E0%A6%BE%E0%A6%A4%E0%A7%87%E0%A6%B0+%E0%A6%B8%E0%A6%AE%E0%A6 ecml.at http://edl.ecml.at/LanguageFun/LanguageTreasures/tabid/1533/language/en-GB/Default.aspx Language Treasures|Home brazzers-n.com http://brazzers-n.com/en/tgb/13598-%D0%94%D0%B0%D1%80%D0%BE%D0%B2+%D0%90%D0%BB%D0%BB%D0%B0/ Suck Tits - B vporn-com.com http://vporn-com.com/en/tag/7184-Duplo+Recheado/ Double Stuffed - porn - Best porn videos and Sex XXX movi hotpornohub.com http://hotpornohub.com/en/dildo Dildo porn videos in excellent quality|Sliding menu|HotPornoHub|Main (cu pornoload-n.com http://pornoload-n.com/en/movie/9135781-piss.html piss|Menu|PornoLoad|Main (current)|Random video|All ca ecml.at http://edl.ecml.at/Participate/Materials/Logo/tabid/1526/language/en-GB/Default.aspx Logo|Home|What is it?|Why a dojki-n.com http://dojki-n.com/en/amateurs Amateurs videos online in hd quality|Menu|Main (current)|Random video|All cat ruporn-tv.com http://ruporn-tv.com/en/tag/3499-%D0%97%D1%83%D0%B7%D0%B0%D0%B0%D0%BD+Chubby/ Thick Chubby - Russian porn cucek.net http://cucek.net/en/pg/5/ No Boobs. While there, enjoy selective porn. - page 5|Sliding menu|Cucek.NET|Main (c brazzers-n.com http://brazzers-n.com/en/tgb/20099-%E0%A6%AA%E0%A6%A6%E0%A6%AC%E0%A7%8D%E0%A6%B0%E0%A6%9C%E0%A7%87+%E0%A6 pornoload-n.com http://pornoload-n.com/en/movie/524228-redheaded-moms-crave-orgasm.html Redheaded moms crave orgasm|Menu hdbox.ws https://hdbox.ws/en/sat-tv-novosti/4060-transpondernye-novosti-za-05-01-2017.html » Transponder news for 05.01 online-casino-10.pro http://online-casino-10.pro/en/ FakeTaxi - English Escort Girl Amber Jayne - online-casino-10.pro|M xnxx-hd.pro http://xnxx-hd.pro/en/mvi/54585-hairy-pussy-whores-ufa.html Hairy pussy whores Ufa|100% free porn videos sex lustful.tv http://www.lustful.tv/en/ Free porn @ Lustful TV|LustfulTV|English|Ελληνικά|Galego|ייִדיש|ภ� hotpornadult.com http://hotpornadult.com/en/tag/733-Pullea/ Chubby - HotPornAdult - porn in HD|Free porn videos online|S brazzers-n.com http://brazzers-n.com/en/tgb/4273-%E0%A6%B8%E0%A6%A4%E0%A7%8D%E0%A6%AF+%E0%A6%AC%E0%A6%BE+Dare/ Truth or 24video-net.com http://24video-net.com/en/tag/124-Fucked Fucked - 24video xxx porn watch online, porn videos for free 24 biqle-ru.com http://biqle-ru.com/en/cs/ The list of all categories|Menu|Main (current)|Random|Category|English|Русс� pornk.mobi http://pornk.mobi/en/pcts/full/ The list of all categories|Menu|Main (current)|Topics porn|Random video|Chat| pornoload-n.com http://pornoload-n.com/en/movie/3754286-voyeur-pissing-13.html Voyeur pissing 13|Menu|PornoLoad|Main (cu sozrelxxx.com http://sozrelxxx.com/en/feedback/ Feedback|ripe for porn|Bondage|British|Cartoon adult|Changed|Dildo|Dirty dojki-n.com http://dojki-n.com/en/hairy-pussy Hairy pussy videos online in hd quality|Menu|Main (current)|Random video|A brazzers-n.com http://brazzers-n.com/en/tgb/22723-%E0%A6%95%E0%A6%BE%E0%A6%B2%E0%A7%8B%2C+%E0%A6%B8%E0%A7%81%E0%A6%A8%E0 pornoload-n.com http://pornoload-n.com/en/movie/11258860-turkije.html turkije|Menu|PornoLoad|Main (current)|Random video brazzers-n.com http://brazzers-n.com/en/tgb/2526-%E0%A6%AA%E0%A6%B0%E0%A6%BF%E0%A6%A3%E0%A6%A4%2C+%E0%A6%B8%E0%A7%8D%E0% drtuber-n.com http://drtuber-n.com/en/striptease/ Striptease porn videos DrTuber|Sliding menu|Main (current)|Random vide brazzers-n.com http://brazzers-n.com/en/tgb/17799-%E0%A6%B8%E0%A7%81%E0%A6%A8%E0%A7%8D%E0%A6%A6%E0%A6%B0%E0%A6%BF+%E0%A6 brazzers-n.com http://brazzers-n.com/en/tgb/9965-%E0%A6%B8%E0%A7%81%E0%A6%A8%E0%A7%8D%E0%A6%A6%E0%A6%B0%E0%A6%BF+%E0%A6% hotpornohub.com http://hotpornohub.com/en/next/6/ Cool porn video from hotpornohub.com! - page 6|Sliding menu|HotPornoHu brazzers-n.com http://brazzers-n.com/en/tgb/9050-18%2C+%E0%A6%AA%E0%A7%8B%E0%A6%81%E0%A6%A6%2C/ 18 Anal - BRAZZERS porn brazzers-n.com http://brazzers-n.com/en/tgb/10246-%E0%A6%85%E0%A6%AA%E0%A7%87%E0%A6%B6%E0%A6%BE%E0%A6%A6%E0%A6%BE%E0%A6% trahtubetv.com http://trahtubetv.com/en/blonde Blonde|Menu|Tractor|Main (current)|Random video|All categories|English|Р pornoload-n.com http://pornoload-n.com/en/celebrity/ Celebrity|Menu|PornoLoad|Main (current)|Random video|All categories xnxx-hd.pro http://xnxx-hd.pro/en/tag/16818-%E0%A8%B5%E0%A9%B1%E0%A8%A1%E0%A9%87+%E0%A8%9A%E0%A9%82%E0%A8%9A%E0%A8%95+%E brazzers-n.com http://brazzers-n.com/en/tgb/1212-%E0%A6%AE%E0%A7%87%E0%A6%AF%E0%A6%BC%E0%A7%87%E0%A6%A6%E0%A7%87%E0%A6%B ruporn-tv.com http://ruporn-tv.com/en/tag/7326-T%C3%AB+Par%C3%AB+Gjat%C3%AB+Gjith%C3%AB/ See Thru - Russian porn online 24video-xxx.com http://24video-xxx.com/en/porn-orgasms Porn orgasms this category contains selected videos in HD quality pornk.mobi http://pornk.mobi/en/big-breasts/ Big breast porn pornk|Menu|Main (current)|Topics porn|Random video|Chat|Eng brazzers-n.com http://brazzers-n.com/en/tgb/84-%D0%A2%D0%BE%D0%BC+%D0%9E%D1%85%D0%B8%D0%BD+%D0%A5%D1%83%D0%BB%D0%B0%D0%B ecml.at http://edl.ecml.at/Events/PictureGallery2013/tabid/3122/language/en-GB/Default.aspx European Day of Languages &gt; brazzers-n.com http://brazzers-n.com/en/tgb/4962-%E0%A6%AC%E0%A6%A1%E0%A6%BF%E0%A6%AC%E0%A6%BF%E0%A6%B2%E0%A7%8D%E0%A6%A brazzers-n.com http://brazzers-n.com/en/tgb/3101-%E0%A6%A6%E0%A7%81%E0%A6%B7%E0%A7%8D%E0%A6%9F%E0%A7%81+%E0%A6%85%E0%A6% brazzers-n.com http://brazzers-n.com/en/tgb/20478-%E0%A6%95%E0%A6%BE%E0%A6%B2%E0%A7%8B+%E0%A6%B6%E0%A6%BF%E0%A6%95%E0%A7 xhamster-n.com http://xhamster-n.com/en/otslaivanie/ Otslaivanie free|Sliding menu|Main (current)|Random video|All categ brazzers-n.com http://brazzers-n.com/en/tgb/12973-%E0%A6%AB%E0%A6%BE%E0%A6%B2%E0%A6%BE%2C+%E0%A6%AE%E0%A7%87%E0%A6%B0%E0 brazzers-n.com http://brazzers-n.com/en/tgb/19634-%E0%A6%AE%E0%A6%BE/ Seduced by a Cougar - BRAZZERS porn Studio. Porn c brazzers-n.com http://brazzers-n.com/en/tgb/21794-%E0%A6%AA%E0%A7%8B%E0%A6%81%E0%A6%A6+%E0%A6%96%E0%A7%87%E0%A6%B2%E0%A6 24video-xxx.com http://24video-xxx.com/en/footwork/ The footwork in this category, collected the best video in HD qualit brazzers-n.com http://brazzers-n.com/en/tgb/19378-%E0%A6%B9%E0%A7%8D%E0%A6%AF%E0%A6%BE%E0%A6%B0%E0%A6%BF%E0%A6%B8/ Harri cucek.net http://cucek.net/en/mcuc/10978279-busty-flexibe-babe-fucking-ruporn.tv.html Busty flexibe babe fucking ruporn. brazzers-n.com http://brazzers-n.com/en/tgb/9820-Bavarian/ Bavarian - BRAZZERS porn Studio. Porn clips brazzers Studio a brazzers-n.com http://brazzers-n.com/en/tgb/12297-%E0%A6%AA%E0%A7%8D%E0%A6%B0%E0%A6%BE%E0%A6%95%E0%A7%83%E0%A6%A4%E0%A6% ruporn-tv.com http://ruporn-tv.com/en/tag/255-%E0%A4%AC%E0%A4%BF%E0%A4%97+%E0%A4%A1%E0%A4%BF%E0%A4%95/ Big Dick - Russia vporn-com.com http://vporn-com.com/en/gangbang Gangbang only on anysex|Menu|Main (current)|Random video|All categories|E .",
            "url": "https://jimregan.github.io/notes/badmt/irish/2021/06/05/cc-aligned-irish-porn.html",
            "relUrl": "/badmt/irish/2021/06/05/cc-aligned-irish-porn.html",
            "date": " • Jun 5, 2021"
        }
        
    
  
    
        ,"post206": {
            "title": "Extract CUDA from Kaldi docker image",
            "content": "%cd /tmp . !git clone https://github.com/jjlin/docker-image-extract/ . !docker-image-extract/docker-image-extract kaldiasr/kaldi:gpu-latest . %cd output/ . !find . -name &#39;*cudnn*&#39; -or -name &#39;*cuda*&#39; . !tar cvf /kaggle/working/cuda.tar ./usr/local/cuda-10.0/ ./usr/include/cudnn.h ./usr/include/x86_64-linux-gnu/cudnn_v7.h ./usr/include/linux/cuda.h ./usr/lib/x86_64-linux-gnu/libcudnn* .",
            "url": "https://jimregan.github.io/notes/asr/kaggle/2021/06/04/extract-cuda-from-kaldi-docker.html",
            "relUrl": "/asr/kaggle/2021/06/04/extract-cuda-from-kaldi-docker.html",
            "date": " • Jun 4, 2021"
        }
        
    
  
    
        ,"post207": {
            "title": "Multidict scraper",
            "content": "import requests from bs4 import BeautifulSoup def scrapepage(pageid): page = requests.get(f&#39;https://multidict.net/clilstore/page.php?id={pageid}&#39;) soup = BeautifulSoup(page.text, &#39;html.parser&#39;) body = soup.find(&#39;body&#39;) bodytext = body.find(&#39;div&#39;, {&#39;class&#39;: &#39;body-indent&#39;}) text = [tmp.text for tmp in bodytext.findAll(&#39;p&#39;)] iframe = bodytext.findAll(&#39;iframe&#39;) return iframe[0][&#39;src&#39;], text . print(scrapepage(&#39;8839&#39;)) . headers = { &quot;accept&quot;: &quot;text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9&quot;, &quot;accept-language&quot;: &quot;en-US,en;q=0.9,pl;q=0.8,ga;q=0.7,en-GB;q=0.6&quot;, &quot;cache-control&quot;: &quot;max-age=0&quot;, &quot;content-type&quot;: &quot;application/x-www-form-urlencoded&quot;, &quot;sec-ch-ua&quot;: &quot; &quot; Not A;Brand &quot;;v= &quot;99 &quot;, &quot;Chromium &quot;;v= &quot;90 &quot;, &quot;Google Chrome &quot;;v= &quot;90 &quot;&quot;, &quot;sec-ch-ua-mobile&quot;: &quot;?0&quot;, &quot;sec-fetch-dest&quot;: &quot;document&quot;, &quot;sec-fetch-mode&quot;: &quot;navigate&quot;, &quot;sec-fetch-site&quot;: &quot;same-origin&quot;, &quot;sec-fetch-user&quot;: &quot;?1&quot;, &quot;upgrade-insecure-requests&quot;: &quot;1&quot; } . s = requests.Session() s.headers.update(headers) s.get(&quot;https://multidict.net/clilstore/&quot;) s.headers.update({&#39;referer&#39;: &quot;https://multidict.net/clilstore/&quot;}) x = s.post(&quot;https://multidict.net/clilstore/&quot;, data=&quot;sl=ga&amp;filterForm=1&amp;title=&amp;text=&amp;showAll=showAll&quot;) . listsoup = BeautifulSoup(x.text, &#39;html.parser&#39;) . table = listsoup.find(&#39;table&#39;, {&#39;id&#39;: &#39;main&#39;}) . links = table.findAll(&#39;a&#39;) . def attrstartswith(tag, attr, needle): return tag.attrs and attr in tag.attrs and tag.attrs[attr].startswith(needle) . def collectlinks(links): out = [] for link in links: if attrstartswith(link, &#39;href&#39;, &#39;/cs/&#39;): out.append(link.attrs[&#39;href&#39;][4:]) return out .",
            "url": "https://jimregan.github.io/notes/asr/irish/todo/2021/06/02/multidict-scraper.html",
            "relUrl": "/asr/irish/todo/2021/06/02/multidict-scraper.html",
            "date": " • Jun 2, 2021"
        }
        
    
  
    
        ,"post208": {
            "title": "wav2vec-u Common Voice Swedish - GAN training, CPU1",
            "content": "Original here . Preparation . %%capture !conda install -c pykaldi pykaldi -y . %cd /tmp . /tmp . !git clone https://github.com/jimregan/fairseq/ --branch issue3581 . !git clone https://github.com/kpu/kenlm . %%capture !apt-get -y install libeigen3-dev liblzma-dev zlib1g-dev libbz2-dev . %%capture %cd /tmp/kenlm !python setup.py install %cd /tmp . import os os.environ[&#39;PATH&#39;] = f&quot;{os.environ[&#39;PATH&#39;]}:/tmp/kenlm/build/bin/&quot; os.environ[&#39;FAIRSEQ_ROOT&#39;] = &#39;/tmp/fairseq&#39; . %cd /tmp/fairseq/ . /tmp/fairseq . %%capture !python setup.py install . %cd /tmp/fairseq/ . /tmp/fairseq . os.environ[&#39;HYDRA_FULL_ERROR&#39;] = &#39;1&#39; . %%capture !pip install editdistance . GAN . %%writefile rungan.sh PREFIX=w2v_unsup_gan_xp TASK_DATA=/kaggle/input/wav2vec-u-cv-swedish-audio/precompute_pca512_cls128_mean_pooled/ TEXT_DATA=/kaggle/input/wav2vec-u-cv-swedish-text-prep/preppedtext/phones/ KENLM_PATH=/kaggle/input/wav2vec-u-cv-swedish-text-prep/preppedtext/phones/lm.phones.filtered.04.bin PREFIX=$PREFIX fairseq-hydra-train -m --config-dir fairseq/config/model/wav2vecu/gan --config-name w2vu task.data=${TASK_DATA} task.text_data=${TEXT_DATA} task.kenlm_path=${KENLM_PATH} checkpoint.no_epoch_checkpoints=false checkpoint.keep_last_epochs=20 checkpoint.save_dir=/kaggle/working &#39;common.seed=range(0,5)&#39; . Writing rungan.sh . !bash rungan.sh .",
            "url": "https://jimregan.github.io/notes/kaggle/wav2vec-u/2021/06/01/wav2vec-u-cv-swedish-gan-cpu1.html",
            "relUrl": "/kaggle/wav2vec-u/2021/06/01/wav2vec-u-cv-swedish-gan-cpu1.html",
            "date": " • Jun 1, 2021"
        }
        
    
  
    
        ,"post209": {
            "title": "wav2vec-u CV-sv - GAN",
            "content": "The original attempt on Kaggle won&#39;t run because of an issue with CuDNN, but this notebook runs fine on Colab. . Preparation . !pip install condacolab . Collecting condacolab Downloading https://files.pythonhosted.org/packages/ee/47/6f9fe13087c31aba889c4b09f9beaa558bf216bf9108c9ccef44e6c9dcfe/condacolab-0.1.2-py3-none-any.whl Installing collected packages: condacolab Successfully installed condacolab-0.1.2 . import condacolab condacolab.install() . ⏬ Downloading https://github.com/jaimergp/miniforge/releases/latest/download/Mambaforge-colab-Linux-x86_64.sh... 📦 Installing... 📌 Adjusting configuration... 🩹 Patching environment... ⏲ Done in 0:00:36 🔁 Restarting kernel... . %%capture !conda install -c pykaldi pykaldi -y . !git clone https://github.com/jimregan/fairseq/ --branch issue3581 . Cloning into &#39;fairseq&#39;... remote: Enumerating objects: 28296, done. remote: Total 28296 (delta 0), reused 0 (delta 0), pack-reused 28296 Receiving objects: 100% (28296/28296), 11.77 MiB | 24.69 MiB/s, done. Resolving deltas: 100% (21286/21286), done. . !git clone https://github.com/kpu/kenlm . Cloning into &#39;kenlm&#39;... remote: Enumerating objects: 13824, done. remote: Counting objects: 100% (137/137), done. remote: Compressing objects: 100% (79/79), done. remote: Total 13824 (delta 76), reused 92 (delta 45), pack-reused 13687 Receiving objects: 100% (13824/13824), 5.49 MiB | 20.76 MiB/s, done. Resolving deltas: 100% (7956/7956), done. . %%capture !apt-get -y install libeigen3-dev liblzma-dev zlib1g-dev libbz2-dev . %%capture %cd /content/kenlm !python setup.py install %cd /tmp . import os os.environ[&#39;PATH&#39;] = f&quot;{os.environ[&#39;PATH&#39;]}:/content/kenlm/build/bin/&quot; os.environ[&#39;FAIRSEQ_ROOT&#39;] = &#39;/content/fairseq&#39; . %cd /content/fairseq/ . /content/fairseq . %%capture !python setup.py install . os.environ[&#39;HYDRA_FULL_ERROR&#39;] = &#39;1&#39; . %%capture !pip install editdistance . https://colab.research.google.com/github/corrieann/kaggle/blob/master/kaggle_api_in_colab.ipynb . %%capture !pip install kaggle . from google.colab import files uploaded = files.upload() for fn in uploaded.keys(): print(&#39;User uploaded file &quot;{name}&quot; with length {length} bytes&#39;.format( name=fn, length=len(uploaded[fn]))) # Then move kaggle.json into the folder where the API expects to find it. !mkdir -p ~/.kaggle/ &amp;&amp; mv kaggle.json ~/.kaggle/ &amp;&amp; chmod 600 ~/.kaggle/kaggle.json . Upload widget is only available when the cell has been executed in the current browser session. Please rerun this cell to enable. Saving kaggle.json to kaggle.json User uploaded file &#34;kaggle.json&#34; with length 64 bytes . %cd /content . /content . !kaggle datasets download &quot;jimregan/w2vu-cvsv-prepared-text&quot; . Downloading w2vu-cvsv-prepared-text.zip to /content 75% 13.0M/17.4M [00:00&lt;00:00, 55.1MB/s] 100% 17.4M/17.4M [00:00&lt;00:00, 64.5MB/s] . %%capture !unzip /content/w2vu-cvsv-prepared-text.zip . !kaggle datasets download -d jimregan/w2vu-cvsv-precompute-pca512-cls128-mean-pooled . Downloading w2vu-cvsv-precompute-pca512-cls128-mean-pooled.zip to /content 98% 386M/394M [00:04&lt;00:00, 90.1MB/s] 100% 394M/394M [00:04&lt;00:00, 102MB/s] . %%capture !unzip w2vu-cvsv-precompute-pca512-cls128-mean-pooled.zip . !rm *.zip . GAN . import torch torch.version.cuda . &#39;10.1&#39; . torch.backends.cudnn.version() . 7603 . %cd /content/fairseq . /content/fairseq . from google.colab import drive drive.mount(&#39;/content/drive&#39;) . %%writefile rungan.sh PREFIX=w2v_unsup_gan_xp TASK_DATA=/content/precompute_pca512_cls128_mean_pooled TEXT_DATA=/content/preppedtext/phones/ KENLM_PATH=/content/preppedtext/phones/lm.phones.filtered.04.bin PREFIX=$PREFIX CUDA_LAUNCH_BLOCKING=1 fairseq-hydra-train -m --config-dir fairseq/config/model/wav2vecu/gan --config-name w2vu task.data=${TASK_DATA} task.text_data=${TEXT_DATA} task.kenlm_path=${KENLM_PATH} checkpoint.no_epoch_checkpoints=true checkpoint.save_dir=/content/drive/MyDrive/w2vu &#39;common.seed=range(0,5)&#39; . Writing rungan.sh . !bash rungan.sh . [2021-06-04 00:06:14,189][fairseq.tasks.unpaired_audio_text][INFO] - REF: ɛ n f œ ʂ ə n a d ɵ ʂ ə k t f øː r d eː t s ɔ m h ɛ n d ə p oː ɕ œ r k ɔ n s ɛ t ə n [2021-06-04 00:06:14,192][fairseq.tasks.unpaired_audio_text][INFO] - HYP: oː b iː ʃ œ m ɕ m œ ɕ ɪ ɵ ɕ ɵ m ɵ s ɵ uː ɵ s ɵ ɛ ʂ a tː sx [2021-06-04 00:06:14,198][fairseq.tasks.unpaired_audio_text][INFO] - LM [REF]: -53.44462585449219, 0.05339602260269112 [2021-06-04 00:06:14,198][fairseq.tasks.unpaired_audio_text][INFO] - LM [HYP]: -61.104984283447266, 0.006571721232914821 [2021-06-04 00:06:14,844][valid][INFO] - {&#34;epoch&#34;: 8, &#34;valid_loss&#34;: &#34;0.93&#34;, &#34;valid_ntokens&#34;: &#34;3039.79&#34;, &#34;valid_nsentences&#34;: &#34;144.214&#34;, &#34;valid_lm_score_sum&#34;: &#34;-71760.8&#34;, &#34;valid_num_pred_chars&#34;: &#34;28972&#34;, &#34;valid_vocab_seen_pct&#34;: &#34;0.949477&#34;, &#34;valid_uer&#34;: &#34;92.9812&#34;, &#34;valid_weighted_lm_ppl&#34;: &#34;229.386&#34;, &#34;valid_lm_ppl&#34;: &#34;206.793&#34;, &#34;valid_wps&#34;: &#34;15426&#34;, &#34;valid_wpb&#34;: &#34;3039.8&#34;, &#34;valid_bsz&#34;: &#34;144.2&#34;, &#34;valid_num_updates&#34;: &#34;128&#34;, &#34;valid_best_weighted_lm_ppl&#34;: &#34;189.002&#34;} [2021-06-04 00:06:14,846][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 8 @ 128 updates [2021-06-04 00:06:14,847][fairseq.trainer][INFO] - Saving checkpoint to /content/drive/MyDrive/w2vu/checkpoint8.pt [2021-06-04 00:06:14,911][fairseq.trainer][INFO] - Finished saving checkpoint to /content/drive/MyDrive/w2vu/checkpoint8.pt [2021-06-04 00:06:14,974][fairseq.checkpoint_utils][INFO] - Saved checkpoint /content/drive/MyDrive/w2vu/checkpoint8.pt (epoch 8 @ 128 updates, score 229.38563413598007) (writing took 0.12713056299980963 seconds) .",
            "url": "https://jimregan.github.io/notes/kaggle/colab/wav2vec-u/2021/05/30/wav2vec-u-cv-swedish-gan.html",
            "relUrl": "/kaggle/colab/wav2vec-u/2021/05/30/wav2vec-u-cv-swedish-gan.html",
            "date": " • May 30, 2021"
        }
        
    
  
    
        ,"post210": {
            "title": "Find datives in Unimorph",
            "content": "Unimorph&#39;s Irish extraction from Wiktionary is basically useless: nouns don&#39;t include gender, they extract contexts instead of forms, and only extract the first of multiple contexts; their tagset is bizarre and incomplete regarding Irish. About the only thing it&#39;s even potentially good for is finding the dative forms of nouns (without doing a full wiktionary extraction). . with open(&#39;../input/unimorph-gle/gle&#39;, &#39;r&#39;) as crap: for line in crap.readlines(): if line.strip() == &#39;&#39;: continue parts = line.split(&#39; t&#39;) if len(parts) &lt; 3: print(f&#39;Junk: &lt;{parts[0]}&gt; &lt;{parts[1]}&gt;&#39;) if parts[2] == &#39;N;DAT;SG&#39; and parts[0] != parts[1]: print(f&#39;{parts[0]} t{parts[1]}&#39;) elif parts[2] == &#39;N;DAT;SG;DEF&#39;: form = parts[2].replace(&#39;leis an &#39;, &#39;&#39;) if len(form) &gt; 3 and form[0:2] == &#39;bhf&#39; or form[0:1] == &#39;n-&#39;: if parts[0] != form[2:]: print(f&#39;{parts[0]} t{form[2:]}&#39;) elif len(form) &gt; 2 and form[0:1] in [&#39;mb&#39;, &#39;gc&#39;, &#39;nd&#39;, &#39;ng&#39;, &#39;bp&#39;, &#39;dt&#39;]: if parts[0] != form[1:]: print(f&#39;{parts[0]} t{form[1:]}&#39;) else: continue .",
            "url": "https://jimregan.github.io/notes/irish/unimorph/2021/05/29/find-datives-in-unimorph-gle.html",
            "relUrl": "/irish/unimorph/2021/05/29/find-datives-in-unimorph-gle.html",
            "date": " • May 29, 2021"
        }
        
    
  
    
        ,"post211": {
            "title": "Compiling Kaldi on Kaggle",
            "content": "Original . Kaldi is a bit of a beast to install. I tried to get around it by extracting files from the official docker image: tl;dr, it works fine for the tools that run on CPU, but the GPU-based tools depend on CUDA 10.0, while Kaggle&#39;s GPU images use CUDA 11.0. . I&#39;m building this in /opt to match the docker extraction notebook. . %cd /opt . !git clone https://github.com/kaldi-asr/kaldi . I&#39;m installing cudatoolkit to make sure it&#39;s there, and the same version as the one in the gpu docker image, because issues with that are why I&#39;m compiling this in the first place. You can quite possibly get away with not running this step, but I&#39;m not taking a chance on it. If you are going to re-run this, make sure to check the gpu docker image to match the version for cudatoolkit. . #!conda install cudatoolkit=11.0 -y . !conda install cudatoolkit-dev=11.0 . %%capture !apt-get -y install liblapack-dev sox . First step is to follow the instructions in kaldi/tools . %cd /opt/kaldi/tools . The INSTALL file says to run extras/check_dependencies.sh, fix anything that&#39;s missing, and then run make. It&#39;s unlikely that new dependencies will be added (Kaldi more in maintenance mode than active development), but just in case, uncomment the line in the next cell and run it. . #!./extras/check_dependencies.sh . This is what I was missing from the check_dependencies check: . %%capture !apt-get -y install automake autoconf gfortran subversion . %%capture !make . Next,we need a maths library: . %%capture !extras/install_openblas.sh . Now is the time to build any of the optional dependencies you might want. I want phonetisaurus. . %%capture !bash extras/install_phonetisaurus.sh . I had problems with phonetisaurus-apply from the branch installed by install_phonetisaurus.sh, so I&#39;m replacing it with an updated version from the phonetisaurus repo: . %%writefile /opt/kaldi/tools/phonetisaurus-g2p/src/scripts/phonetisaurus-apply #!/usr/bin/env python # -*- mode: python; coding: utf-8 -*- from __future__ import print_function from __future__ import unicode_literals import os, logging, subprocess, time, re from datetime import datetime from collections import defaultdict import tempfile class G2PModelTester () : &quot;&quot;&quot;G2P Model training wrapper class. Phonetisaurus G2P modeling training wrapper class. This wraps the alignment, joint n-gram training, and ARPA to WFST conversion steps into one command. &quot;&quot;&quot; def __init__ (self, model, **kwargs) : self.model = model self.lexicon_file = kwargs.get (&quot;lexicon&quot;, None) self.nbest = kwargs.get (&quot;nbest&quot;, 1) self.thresh = kwargs.get (&quot;thresh&quot;, 99) self.beam = kwargs.get (&quot;beam&quot;, 10000) self.greedy = kwargs.get (&quot;greedy&quot;, False) self.accumulate = kwargs.get (&quot;accumulate&quot;, False) self.pmass = kwargs.get (&quot;pmass&quot;, 0.0) self.probs = kwargs.get (&quot;probs&quot;, False) self.verbose = kwargs.get (&quot;verbose&quot;, False) self.logger = self.setupLogger () def setupLogger (self) : &quot;&quot;&quot;Setup the logger and logging level. Setup the logger and logging level. We only support verbose and non-verbose mode. Args: verbose (bool): Verbose mode, or not. Returns: Logger: A configured logger instance. &quot;&quot;&quot; level = logging.DEBUG if self.verbose else logging.INFO logging.basicConfig ( level=level, format=&quot; 033[94m%(levelname)s:%(name)s:&quot; &quot;%(asctime)s 033[0m: %(message)s&quot;, datefmt=&quot;%Y-%m-%d %H:%M:%S&quot; ) return logging.getLogger (&quot;phonetisaurus-apply&quot;) def _loadLexicon (self) : &quot;&quot;&quot;Load the lexicon from a file. Load the reference lexicon from a file, and store it in a defaultdict (list). &quot;&quot;&quot; _lexicon = defaultdict (list) if not self.lexicon_file : return _lexicon self.logger.debug (&quot;Loading lexicon from file...&quot;) with open (self.lexicon_file, &quot;r&quot;) as ifp : for line in ifp : # py2py3 compatbility, if sys.version_info[0] &lt; 3: line = line.decode(&quot;utf8&quot;).strip () else: line = line.strip () word, pron = re.split (r&quot; t&quot;, line, 1) _lexicon [word].append (pron) return _lexicon def checkPhonetisaurusConfig (self) : &quot;&quot;&quot;Run some basic checks before training. Run some basic checks regarding the $PATH, environment, and provided data before starting training. Raises: EnvironmentError: raised if binaries are not found. &quot;&quot;&quot; self.logger.debug (&quot;Checking command configuration...&quot;) for program in [&quot;phonetisaurus-g2pfst&quot;] : if not self.which (program) : raise EnvironmentError(&quot;Phonetisaurus command, &#39;{0}&#39;, &quot; &quot;not found in path.&quot;.format (program)) if self.lexicon_file and not os.path.exists (self.lexicon_file) : self.logger.error (&quot;Could not find provided lexicon file.&quot;) sys.exit (1) for key,val in sorted (vars (self).items ()) : self.logger.debug (u&quot;{0}: {1}&quot;.format (key, val)) self.lexicon = self._loadLexicon () return def which (self, program) : &quot;&quot;&quot;Basic &#39;which&#39; implementation for python. Basic &#39;which&#39; implementation for python from stackoverflow: * https://stackoverflow.com/a/377028/6739158 Args: program (str): The program name to search the $PATH for. Returns: path/None: The path to the executable, or None. &quot;&quot;&quot; def is_exe (fpath) : return os.path.isfile (fpath) and os.access (fpath, os.X_OK) fpath, fname = os.path.split (program) if fpath: if is_exe (program): return program else: for path in os.environ[&quot;PATH&quot;].split (os.pathsep) : path = path.strip (&#39;&quot;&#39;) exe_file = os.path.join (path, program) if is_exe (exe_file): return exe_file return None def makeG2PCommand (self, word_list) : &quot;&quot;&quot;Build the G2P command. Build the G2P command from the provided arguments. Returns: list: The command in subprocess list format. &quot;&quot;&quot; command = [ u&quot;phonetisaurus-g2pfst&quot;, u&quot;--model={0}&quot;.format (self.model), u&quot;--nbest={0}&quot;.format (self.nbest), u&quot;--beam={0}&quot;.format (self.beam), u&quot;--thresh={0}&quot;.format (self.thresh), u&quot;--accumulate={0}&quot;.format (str (self.accumulate).lower ()), u&quot;--pmass={0}&quot;.format (self.pmass), u&quot;--nlog_probs={0}&quot;.format (str(not self.probs).lower ()), u&quot;--wordlist={0}&quot;.format (word_list) ] self.logger.debug (u&quot; &quot;.join (command)) return command def runG2PCommand (self, word_list_file) : &quot;&quot;&quot;Generate and run the actual G2P command. Generate and run the actual G2P command. Each synthesized entry will be yielded back on-the-fly via the subprocess stdout readline method. Args: word_list_file (str): The input word list. &quot;&quot;&quot; g2p_command = self.makeG2PCommand (word_list_file) self.logger.debug (&quot;Applying G2P model...&quot;) with open (os.devnull, &quot;w&quot;) as devnull : proc = subprocess.Popen ( g2p_command, stdout=subprocess.PIPE, stderr=devnull if not self.verbose else None ) for line in proc.stdout : parts = re.split (r&quot; t&quot;, line.decode (&quot;utf8&quot;).strip ()) if not len (parts) == 3 : self.logger.warning ( u&quot;No pronunciation for word: &#39;{0}&#39;&quot;.format (parts [0]) ) continue yield parts return def applyG2POnly (self, word_list_file) : &quot;&quot;&quot;Apply the G2P model to a word list. Apply the G2P model to a word list. No filtering or application of a reference lexicon is used here. Args: word_list_file (str): The input word list. &quot;&quot;&quot; for word, score, pron in self.runG2PCommand (word_list_file) : line = u&quot;&quot; if self.verbose : line = u&quot;{0} t{1:.2f} t{2}&quot;.format ( word, float (score), pron ) else : line = u&quot;{0} t{1}&quot;.format (word, pron) # py2py3 compatbility, if sys.version_info[0] &lt; 3: print (line.encode (&quot;utf8&quot;)) else : print (line) return def applyG2PWithLexicon (self, word_list_file) : &quot;&quot;&quot;Apply the G2P model to a word list, combined with lexicon. Apply the G2P model to a word list, but combine this with a reference lexicon. Words for which a reference entry exists will not be sent to the G2P, unless the additional &#39;--greedy&#39; flag is set to True. Args: word_list_file (str): The input word list. &quot;&quot;&quot; target_lexicon = defaultdict (list) tmpwordlist = tempfile.NamedTemporaryFile(mode=&#39;w&#39;, delete=False) #First, find any words in the target list for which we already # have a canonical pronunciation in the reference lexicon. with open (word_list_file, &quot;r&quot;) as ifp : for word in ifp : # py2py3 compatbility, if sys.version_info[0] &lt; 3: word = word.decode (&quot;utf8&quot;).strip () else: word = word.strip () # already in &#39;utf8&#39;. if word in self.lexicon : target_lexicon [word] = [(0.0,pron) for pron in self.lexicon [word]] #In greedy mode we still send words to the G2P, even # if we have canonical entries in the reference lexicon. if self.greedy : print (word.encode (&quot;utf8&quot;), file=tmpwordlist) else : # py2py3 compatbility, if sys.version_info[0] &lt; 3: print (word.encode (&quot;utf8&quot;), file=tmpwordlist) else: print (word, file=tmpwordlist) tmpwordlist.close () #Second, iterate through the G2P output, and filter against # any possible duplicates previously found in the reference lexicon. for word, score, pron in self.runG2PCommand (tmpwordlist.name) : prons = set ([p for s,p in target_lexicon [word]]) if pron in prons : continue target_lexicon [word].append ((score, pron)) #Finally, sort everything that is left and print it. for word in sorted (target_lexicon.keys ()) : for score, pron in target_lexicon [word] : line = u&quot;&quot; if self.verbose : line = u&quot;{0} t{1:.2f} t{2}&quot;.format ( word, float (score), pron ) else : line = u&quot;{0} t{1}&quot;.format (word, pron) # py2py3 compatbility, if sys.version_info[0] &lt; 3: print (line.encode (&quot;utf8&quot;)) else : print (line) os.unlink (tmpwordlist.name) return def ApplyG2PModel (self, word_list_file) : &quot;&quot;&quot;Apply the G2P model to a word list. Apply the G2P model to a word list. Args: word_list_file (str): The input word list. &quot;&quot;&quot; self.checkPhonetisaurusConfig () if not os.path.exists (word_list_file) or not os.path.isfile (word_list_file) : raise IOError(&quot;Word list file not found.&quot;) if len (self.lexicon) == 0 : self.applyG2POnly (word_list_file) else : self.applyG2PWithLexicon (word_list_file) return if __name__ == &quot;__main__&quot; : import sys, argparse example = &quot;{0} --model train/model.fst --word test&quot;.format (sys.argv [0]) parser = argparse.ArgumentParser (description=example) parser.add_argument (&quot;--model&quot;, &quot;-m&quot;, help=&quot;Phonetisaurus G2P fst model.&quot;, required=True) parser.add_argument (&quot;--lexicon&quot;, &quot;-l&quot;, help=&quot;Optional reference lexicon.&quot;, required=False) parser.add_argument (&quot;--nbest&quot;, &quot;-n&quot;, help=&quot;Maximum number of hypotheses &quot; &quot;to produce. Overridden if --pmass is set.&quot;, default=1, type=int) parser.add_argument (&quot;--beam&quot;, &quot;-b&quot;, help=&quot;Search &#39;beam&#39;.&quot;, default=10000, type=int) parser.add_argument (&quot;--thresh&quot;, &quot;-t&quot;, help=&quot;Pruning threshold for n-best.&quot;, default=99.0, type=float) parser.add_argument (&quot;--greedy&quot;, &quot;-g&quot;, help=&quot;Use the G2P even if a &quot; &quot;reference lexicon has been provided.&quot;, default=False, action=&quot;store_true&quot;) parser.add_argument (&quot;--accumulate&quot;, &quot;-a&quot;, help=&quot;Accumulate probabilities &quot; &quot;across unique pronunciations.&quot;, default=False, action=&quot;store_true&quot;) parser.add_argument (&quot;--pmass&quot;, &quot;-p&quot;, help=&quot;Select the maximum number of &quot; &quot;hypotheses summing to P total mass for a word.&quot;, default=0.0, type=float) parser.add_argument (&quot;--probs&quot;, &quot;-pr&quot;, help=&quot;Print exp(-val) &quot; &quot;instead of default -log values.&quot;, default=False, action=&quot;store_true&quot;) parser.add_argument (&quot;--word_list&quot;, &quot;-wl&quot;, help=&quot;Input word or word list to apply &quot; &quot;G2P model to.&quot;, type=str) parser.add_argument (&quot;--verbose&quot;, &quot;-v&quot;, help=&quot;Verbose mode.&quot;, default=False, action=&quot;store_true&quot;) args = parser.parse_args () tester = G2PModelTester ( args.model, **{key:val for key,val in args.__dict__.items () if not key in [&quot;model&quot;,&quot;word_list&quot;]} ) tester.ApplyG2PModel (args.word_list) . %cd /opt/kaldi/src/ . Be sure to uncomment and run the next cell, to make sure nothing&#39;s changed; it&#39;s unlikely that anything will have changed, though. The following cell does configure, make depend, and make, which is all that the current INSTALL says. . . !./configure --shared --use-cuda --mathlib=OPENBLAS !make depend -j 8 !make -j 8 . %cd /opt . Second last step, clean up the object files: . !find /opt/kaldi -type f ( -name &quot;*.o&quot; -o -name &quot;*.la&quot; -o -name &quot;*.a&quot; ) -exec rm {} ; . !tar cvf /kaggle/working/kaldi.tar kaldi/ .",
            "url": "https://jimregan.github.io/notes/kaggle/kaldi/2021/05/28/compile-kaldi.html",
            "relUrl": "/kaggle/kaldi/2021/05/28/compile-kaldi.html",
            "date": " • May 28, 2021"
        }
        
    
  
    
        ,"post212": {
            "title": "Common Voice Swedish - prepare audio",
            "content": "Original here . %cd /tmp . /tmp . %%capture !pip install git+https://github.com/pytorch/fairseq/ . %%capture !git clone https://github.com/pytorch/fairseq/ . %cd fairseq/examples/wav2vec/unsupervised/scripts . /tmp/fairseq/examples/wav2vec/unsupervised/scripts . !mkdir tsv !for i in train test valid; do echo /kaggle/input/wav2vec-u-cv-swedish-vads/wav/$i/common-voice-swedish-16bit-wav/ &gt; tsv/$i.tsv; cat /kaggle/input/fork-of-wav2vec-u-cv-swedish-tsv/$i.tsv|sed &#39;1d&#39; &gt;&gt; tsv/$i.tsv;done !cp /kaggle/input/wav2vec-u-cv-swedish-prep-ltr-phn-wrd/dic* tsv/ !cp /kaggle/input/wav2vec-u-cv-swedish-prep-ltr-phn-wrd/*.wrd tsv/ !cp /kaggle/input/wav2vec-u-cv-swedish-prep-ltr-phn-wrd/*.ltr tsv/ !cp /kaggle/input/wav2vec-u-cv-swedish-prep-ltr-phn-wrd/*.phn tsv/ . %%capture !pip install npy-append-array . !pip install faiss-gpu . %%capture !apt-get -y install zsh . !zsh prepare_audio.sh tsv /kaggle/working /kaggle/input/download-xlsr-53-wav2vec2-model/xlsr_53_56k.pt . using 512 dim for PCA 100%|███████████████████████████████████████| 2331/2331 [01:21&lt;00:00, 28.76it/s] 100%|███████████████████████████████████████| 2019/2019 [01:07&lt;00:00, 29.98it/s] 100%|███████████████████████████████████████| 2027/2027 [01:08&lt;00:00, 29.41it/s] Faiss Specs: [faiss_spec(pca=0, norm=False, n_clus=128, sphere=False, spec_str=&#39;CLUS128&#39;)] 100%|███████████████████████████████████████| 2331/2331 [01:10&lt;00:00, 33.09it/s] (223140, 1024) Processing spec faiss_spec(pca=0, norm=False, n_clus=128, sphere=False, spec_str=&#39;CLUS128&#39;) Computing kmeans Clustering 223140 points in 1024D to 128 clusters, redo 3 times, 50 iterations Preprocessing in 0.17 s Outer iteration 0 / 3 Objective improved: keep new clusters Outer iteration 1 / 3 Objective improved: keep new clusters Outer iteration 2 / 3 Objective improved: keep new clusters Faiss Spec: faiss_spec(pca=0, norm=False, n_clus=128, sphere=False, spec_str=&#39;CLUS128&#39;) Loaded centroids (128, 1024) 100%|███████████████████████████████████████| 2331/2331 [00:58&lt;00:00, 40.05it/s] Faiss Spec: faiss_spec(pca=0, norm=False, n_clus=128, sphere=False, spec_str=&#39;CLUS128&#39;) Loaded centroids (128, 1024) 100%|███████████████████████████████████████| 2019/2019 [00:57&lt;00:00, 35.24it/s] Faiss Spec: faiss_spec(pca=0, norm=False, n_clus=128, sphere=False, spec_str=&#39;CLUS128&#39;) Loaded centroids (128, 1024) 100%|███████████████████████████████████████| 2027/2027 [00:51&lt;00:00, 39.40it/s] Reading features Computing PCA data path: /kaggle/working/train 0%| | 0/1 [00:00&lt;?, ?it/s]apply_pca.py:66: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1603729047590/work/torch/csrc/utils/tensor_numpy.cpp:141.) x = torch.from_numpy(features[start:end]).cuda() 100%|█████████████████████████████████████████████| 1/1 [00:01&lt;00:00, 1.53s/it] data path: /kaggle/working/precompute_pca512/train 100%|██████████████████████████████████████| 2331/2331 [00:05&lt;00:00, 402.56it/s] data path: /kaggle/working/precompute_pca512_cls128_mean/train 0%| | 0/2331 [00:00&lt;?, ?it/s]mean_pool.py:69: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1603729047590/work/torch/csrc/utils/tensor_numpy.cpp:141.) x = torch.from_numpy(feats).cuda() 100%|██████████████████████████████████████| 2331/2331 [00:03&lt;00:00, 692.56it/s] data path: /kaggle/working/valid 0%| | 0/1 [00:00&lt;?, ?it/s]apply_pca.py:66: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1603729047590/work/torch/csrc/utils/tensor_numpy.cpp:141.) x = torch.from_numpy(features[start:end]).cuda() 100%|█████████████████████████████████████████████| 1/1 [00:01&lt;00:00, 1.60s/it] data path: /kaggle/working/precompute_pca512/valid 100%|██████████████████████████████████████| 2019/2019 [00:04&lt;00:00, 447.45it/s] data path: /kaggle/working/precompute_pca512_cls128_mean/valid 0%| | 0/2019 [00:00&lt;?, ?it/s]mean_pool.py:69: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1603729047590/work/torch/csrc/utils/tensor_numpy.cpp:141.) x = torch.from_numpy(feats).cuda() 100%|██████████████████████████████████████| 2019/2019 [00:03&lt;00:00, 592.35it/s] data path: /kaggle/working/test 0%| | 0/1 [00:00&lt;?, ?it/s]apply_pca.py:66: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1603729047590/work/torch/csrc/utils/tensor_numpy.cpp:141.) x = torch.from_numpy(features[start:end]).cuda() 100%|█████████████████████████████████████████████| 1/1 [00:01&lt;00:00, 1.22s/it] data path: /kaggle/working/precompute_pca512/test 100%|██████████████████████████████████████| 2027/2027 [00:05&lt;00:00, 379.47it/s] data path: /kaggle/working/precompute_pca512_cls128_mean/test 0%| | 0/2027 [00:00&lt;?, ?it/s]mean_pool.py:69: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/conda/conda-bld/pytorch_1603729047590/work/torch/csrc/utils/tensor_numpy.cpp:141.) x = torch.from_numpy(feats).cuda() 100%|██████████████████████████████████████| 2027/2027 [00:03&lt;00:00, 569.65it/s] .",
            "url": "https://jimregan.github.io/notes/kaggle/wav2vec-u/2021/05/27/wav2vec-u-cv-swedish-audio.html",
            "relUrl": "/kaggle/wav2vec-u/2021/05/27/wav2vec-u-cv-swedish-audio.html",
            "date": " • May 27, 2021"
        }
        
    
  
    
        ,"post213": {
            "title": "wav2vec-u CV-sv - prepare text",
            "content": "Original here . %cd /opt . /opt . %%capture !tar xvf /kaggle/input/extract-prebuilt-kaldi-from-docker/kaldi.tar . %cd /tmp . /tmp . !git clone https://github.com/pytorch/fairseq/ . %%capture !pip install phonemizer . %%capture !pip install git+https://github.com/pytorch/fairseq/ . %%capture !apt-get -y install espeak . !git clone https://github.com/kpu/kenlm . %%capture !apt-get -y install libeigen3-dev liblzma-dev zlib1g-dev libbz2-dev . %%capture %cd kenlm !mkdir build %cd build !cmake .. !make -j 4 %cd /tmp . import os os.environ[&#39;PATH&#39;] = f&quot;{os.environ[&#39;PATH&#39;]}:/tmp/kenlm/build/bin/&quot; os.environ[&#39;FAIRSEQ_ROOT&#39;] = &#39;/tmp/fairseq&#39; . !cat /kaggle/input/wav2vec-u-cv-swedish-audio/*.wrd | grep -v &#39;^$&#39; | sort| uniq &gt; /kaggle/working/sentences.txt . %cd fairseq/examples/wav2vec/unsupervised . /tmp/fairseq/examples/wav2vec/unsupervised . %%capture !apt-get -y install zsh . !mkdir /kaggle/working/preppedtext . %cd scripts . /tmp/fairseq/examples/wav2vec/unsupervised/scripts . The next part requires a FastText language id model; I don&#39;t know where the 187 language model comes from, but there is a model for 176 languages here . !wget https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin . !cat normalize_and_filter_text.py|sed -e &#39;s/187/176/&#39; &gt; tmp !mv tmp normalize_and_filter_text.py . os.environ[&#39;HYDRA_FULL_ERROR&#39;] = &#39;1&#39; . import os os.environ[&#39;LD_LIBRARY_PATH&#39;] = &#39;/opt/conda/lib:/opt/kaldi/tools/openfst-1.6.7/lib:/opt/kaldi/src/lib&#39; . There are two lines with missing variables in prepare_text.sh - pull request - so replace the file. . While I&#39;m replacing the file: most of the first part of the script is unneeded, as I already have a phonetic dictionary, so I&#39;m using that instead. . With the calls of the preprocess.py script, make sure to check the threshold: there&#39;s a divide by zero if the threshold is set too high. . Config options for kaldi_initializer.py . in_labels: a naming component, for the Kaldi lexicons/fsts (required) | wav2letter_lexicon: path to wav2letter lexicon | out_labels: a naming component, for the Kaldi lexicons/fsts: set to in_label if missing | kaldi_root: path to Kaldi: /opt/kaldi for my kaggle image | fst_dir: path where generated fsts will be saved | data_dir: path to phones data | lm_arpa: path to the lm in ARPA format | blank_symbol: CTC blank symbol (&lt;s&gt; here) | silence_symbol: Kaldi symbol for silence (&lt;SIL&gt; is set for two of the scripts) | . A config file needs to exist for this, even though the options set in it seem to be ignored. . !mkdir /tmp/fairseq/examples/speech_recognition/kaldi/config/ . %%writefile /tmp/fairseq/examples/speech_recognition/kaldi/config/config.yaml kaldi_root: &quot;/opt/kaldi&quot; . Writing /tmp/fairseq/examples/speech_recognition/kaldi/config/config.yaml . %%writefile prepare_text.sh #!/usr/bin/env zsh # Copyright (c) Facebook, Inc. and its affiliates. # # This source code is licensed under the MIT license found in the # LICENSE file in the root directory of this source tree. lg=$1 text_path=$2 target_dir=$3 #ph_lg=${lg:l} #if test &quot;$lg&quot; = &#39;fr&#39;; then # ph_lg=&#39;fr-fr&#39; #elif test &quot;$lg&quot; = &#39;en&#39;; then # ph_lg=&#39;en-us&#39; #elif test &quot;$lg&quot; = &#39;pt&#39;; then # ph_lg=&#39;pt-br&#39; #fi ph_lg=&quot;sv&quot; echo $lg echo $ph_lg echo $text_path echo $target_dir mkdir -p $target_dir #python normalize_and_filter_text.py --lang $lg &lt; $text_path | grep -v &#39; - - -&#39; &gt;! $target_dir/lm.upper.lid.txt #python $FAIRSEQ_ROOT/fairseq_cli/preprocess.py --dataset-impl mmap --trainpref $target_dir/lm.upper.lid.txt --only-source --destdir $target_dir --thresholdsrc 2 --padding-factor 1 --dict-only #cut -f1 -d&#39; &#39; $target_dir/dict.txt | grep -v -x &#39;[[:punct:]]*&#39; | grep -Pv &#39; d d d d d+&#39; &gt;! $target_dir/words.txt cp /kaggle/input/wav2vec-u-cv-swedish-audio/train.wrd $target_dir/lm.upper.lid.txt cut -f1 -d&#39; &#39; /kaggle/input/wav2vec-u-cv-swedish-audio/dict.train &gt;! $target_dir/words.txt #one=$(echo &quot;1&quot; | PHONEMIZER_ESPEAK_PATH=$(which espeak) phonemize -p &#39; &#39; -w &#39;&#39; -l $ph_lg --language-switch remove-flags) #sed &#39;s/$/ 1/&#39; $target_dir/words.txt | PHONEMIZER_ESPEAK_PATH=$(which espeak) phonemize -o $target_dir/phones.txt -p &#39; &#39; -w &#39;&#39; -l $ph_lg -j 70 --language-switch remove-flags cut -f2- -d&#39; &#39; /kaggle/input/wav2vec-u-cv-swedish-audio/dict.train &gt;! $target_dir/phones.txt #echo &quot;one is ${one}&quot; #sed -i &quot;s/${one}$//&quot; $target_dir/phones.txt #paste $target_dir/words.txt $target_dir/phones.txt &gt;! $target_dir/lexicon.lst cp /kaggle/input/wav2vec-u-cv-swedish-audio/dict.train $target_dir/lexicon.lst #python $FAIRSEQ_ROOT/fairseq_cli/preprocess.py --dataset-impl mmap --trainpref $target_dir/phones.txt --only-source --destdir $target_dir/phones --thresholdsrc 1000 --padding-factor 1 --dict-only python $FAIRSEQ_ROOT/fairseq_cli/preprocess.py --dataset-impl mmap --trainpref $target_dir/phones.txt --only-source --destdir $target_dir/phones --thresholdsrc 2 --padding-factor 1 --dict-only python filter_lexicon.py -d $target_dir/phones/dict.txt &lt; $target_dir/lexicon.lst &gt;! $target_dir/lexicon_filtered.lst python phonemize_with_sil.py -s 0.25 --surround --lexicon $target_dir/lexicon_filtered.lst &lt; $target_dir/lm.upper.lid.txt &gt;! $target_dir/phones/lm.phones.filtered.txt cp $target_dir/phones/dict.txt $target_dir/phones/dict.phn.txt echo &quot;&lt;SIL&gt; 0&quot; &gt;&gt; $target_dir/phones/dict.phn.txt python $FAIRSEQ_ROOT/fairseq_cli/preprocess.py --dataset-impl mmap --trainpref $target_dir/phones/lm.phones.filtered.txt --workers 70 --only-source --destdir $target_dir/phones --srcdict $target_dir/phones/dict.phn.txt lmplz -o 4 &lt; $target_dir/lm.upper.lid.txt --discount_fallback --prune 0 0 0 3 &gt;! $target_dir/kenlm.wrd.o40003.arpa build_binary $target_dir/kenlm.wrd.o40003.arpa $target_dir/kenlm.wrd.o40003.bin lg=$lg python $FAIRSEQ_ROOT/examples/speech_recognition/kaldi/kaldi_initializer.py fst_dir=$target_dir/fst/phn_to_words_sil lm_arpa=$target_dir/kenlm.wrd.o40003.arpa wav2letter_lexicon=$target_dir/lexicon_filtered.lst data_dir=$target_dir/phones &quot;blank_symbol=&#39;&lt;SIL&gt;&#39;&quot; &quot;in_labels=&#39;phn&#39;&quot; &quot;kaldi_root=&#39;/opt/kaldi&#39;&quot; lg=$lg python $FAIRSEQ_ROOT/examples/speech_recognition/kaldi/kaldi_initializer.py fst_dir=$target_dir/fst/phn_to_words lm_arpa=$target_dir/kenlm.wrd.o40003.arpa wav2letter_lexicon=$target_dir/lexicon_filtered.lst data_dir=$target_dir/phones &quot;in_labels=&#39;phn&#39;&quot; &quot;kaldi_root=&#39;/opt/kaldi&#39;&quot; lmplz -o 4 &lt; $target_dir/phones/lm.phones.filtered.txt --discount_fallback &gt;! $target_dir/phones/lm.phones.filtered.04.arpa build_binary -s $target_dir/phones/lm.phones.filtered.04.arpa $target_dir/phones/lm.phones.filtered.04.bin lmplz -o 6 &lt; $target_dir/phones/lm.phones.filtered.txt --discount_fallback &gt;! $target_dir/phones/lm.phones.filtered.06.arpa build_binary -s $target_dir/phones/lm.phones.filtered.06.arpa $target_dir/phones/lm.phones.filtered.06.bin lg=$lg python $FAIRSEQ_ROOT/examples/speech_recognition/kaldi/kaldi_initializer.py fst_dir=$target_dir/fst/phn_to_phn_sil lm_arpa=$target_dir/phones/lm.phones.filtered.06.arpa data_dir=$target_dir/phones &quot;blank_symbol=&#39;&lt;SIL&gt;&#39;&quot; &quot;in_labels=&#39;phn&#39;&quot; &quot;kaldi_root=&#39;/opt/kaldi&#39;&quot; . Overwriting prepare_text.sh . add-self-loop-simple.cc attempts to use std::endl with KALDI_LOG, which doesn&#39;t work, so rewrite that (I&#39;m not sure if this actually prevents anything from working, but it is really distracting). . %%writefile /tmp/fairseq/examples/speech_recognition/kaldi/add-self-loop-simple.cc /* * Copyright (c) Facebook, Inc. and its affiliates. * * This source code is licensed under the MIT license found in the * LICENSE file in the root directory of this source tree. */ #include &lt;iostream&gt; #include &quot;fstext/fstext-lib.h&quot; // @manual #include &quot;util/common-utils.h&quot; // @manual /* * This program is to modify a FST without self-loop by: * for each incoming arc with non-eps input symbol, add a self-loop arc * with that non-eps symbol as input and eps as output. * * This is to make sure the resultant FST can do deduplication for repeated * symbols, which is very common in acoustic model * */ namespace { int32 AddSelfLoopsSimple(fst::StdVectorFst* fst) { typedef fst::MutableArcIterator&lt;fst::StdVectorFst&gt; IterType; int32 num_states_before = fst-&gt;NumStates(); fst::MakePrecedingInputSymbolsSame(false, fst); int32 num_states_after = fst-&gt;NumStates(); KALDI_LOG &lt;&lt; &quot;There are &quot; &lt;&lt; num_states_before &lt;&lt; &quot; states in the original FST; &quot; &lt;&lt; &quot; after MakePrecedingInputSymbolsSame, there are &quot; &lt;&lt; num_states_after &lt;&lt; &quot; states &quot;; auto weight_one = fst::StdArc::Weight::One(); int32 num_arc_added = 0; fst::StdArc self_loop_arc; self_loop_arc.weight = weight_one; int32 num_states = fst-&gt;NumStates(); std::vector&lt;std::set&lt;int32&gt;&gt; incoming_non_eps_label_per_state(num_states); for (int32 state = 0; state &lt; num_states; state++) { for (IterType aiter(fst, state); !aiter.Done(); aiter.Next()) { fst::StdArc arc(aiter.Value()); if (arc.ilabel != 0) { incoming_non_eps_label_per_state[arc.nextstate].insert(arc.ilabel); } } } for (int32 state = 0; state &lt; num_states; state++) { if (!incoming_non_eps_label_per_state[state].empty()) { auto&amp; ilabel_set = incoming_non_eps_label_per_state[state]; for (auto it = ilabel_set.begin(); it != ilabel_set.end(); it++) { self_loop_arc.ilabel = *it; self_loop_arc.olabel = 0; self_loop_arc.nextstate = state; fst-&gt;AddArc(state, self_loop_arc); num_arc_added++; } } } return num_arc_added; } void print_usage() { std::cout &lt;&lt; &quot;add-self-loop-simple usage: n&quot; &quot; tadd-self-loop-simple &lt;in-fst&gt; &lt;out-fst&gt; n&quot;; } } // namespace int main(int argc, char** argv) { if (argc != 3) { print_usage(); exit(1); } auto input = argv[1]; auto output = argv[2]; auto fst = fst::ReadFstKaldi(input); auto num_states = fst-&gt;NumStates(); KALDI_LOG &lt;&lt; &quot;Loading FST from &quot; &lt;&lt; input &lt;&lt; &quot; with &quot; &lt;&lt; num_states &lt;&lt; &quot; states.&quot;; int32 num_arc_added = AddSelfLoopsSimple(fst); KALDI_LOG &lt;&lt; &quot;Adding &quot; &lt;&lt; num_arc_added &lt;&lt; &quot; self-loop arcs &quot;; fst::WriteFstKaldi(*fst, std::string(output)); KALDI_LOG &lt;&lt; &quot;Writing FST to &quot; &lt;&lt; output; delete fst; } . Overwriting /tmp/fairseq/examples/speech_recognition/kaldi/add-self-loop-simple.cc . !zsh prepare_text.sh sv /kaggle/working/sentences.txt /kaggle/working/preppedtext . sv sv /kaggle/working/sentences.txt /kaggle/working/preppedtext === 1/5 Counting and sorting n-grams === Reading /kaggle/working/preppedtext/lm.upper.lid.txt -5101520253035404550556065707580859095--100 **************************************************************************************************** Unigram tokens 14359 types 3160 === 2/5 Calculating and sorting adjusted counts === Chain sizes: 1:37920 2:2571431424 3:4821433856 4:7714294272 Statistics: 1 3160 D1=0.722623 D2=1.14413 D3+=1.45956 2 10285 D1=0.848104 D2=1.2466 D3+=1.46191 3 12632 D1=0.943362 D2=1.24166 D3+=1.32723 4 19/11699 D1=0.970399 D2=1.4843 D3+=2.12351 Memory estimate for binary LM: type kB probing 617 assuming -p 1.5 probing 764 assuming -r models -p 1.5 trie 309 without quantization trie 182 assuming -q 8 -b 8 quantization trie 293 assuming -a 22 array pointer compression trie 166 assuming -a 22 -q 8 -b 8 array pointer compression and quantization === 3/5 Calculating and sorting initial probabilities === Chain sizes: 1:37920 2:164560 3:252640 4:456 -5101520253035404550556065707580859095--100 #################################################################################################### === 4/5 Calculating and writing order-interpolated probabilities === Chain sizes: 1:37920 2:164560 3:252640 4:456 -5101520253035404550556065707580859095--100 #################################################################################################### === 5/5 Writing ARPA model === -5101520253035404550556065707580859095--100 **************************************************************************************************** Name:lmplz VmPeak:14925024 kB VmRSS:6488 kB RSSMax:2975268 kB user:0.194576 sys:0.839708 CPU:1.03431 real:1.03864 Reading /kaggle/working/preppedtext/kenlm.wrd.o40003.arpa -5101520253035404550556065707580859095--100 **************************************************************************************************** SUCCESS [2021-05-30 15:50:13,771][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words_sil/kaldi_dict.phn.txt [2021-05-30 15:50:13,771][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words_sil/G_kenlm.wrd.o40003.fst /opt/kaldi/src/lmbin/arpa2fst --disambig-symbol=#0 --write-symbol-table=/kaggle/working/preppedtext/fst/phn_to_words_sil/kaldi_dict.kenlm.wrd.o40003.txt /kaggle/working/preppedtext/kenlm.wrd.o40003.arpa /kaggle/working/preppedtext/fst/phn_to_words_sil/G_kenlm.wrd.o40003.fst LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:94) Reading data section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 1-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 2-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 3-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 4-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:RemoveRedundantStates():arpa-lm-compiler.cc:359) Reduced num-states from 22665 to 12144 [2021-05-30 15:50:13,918][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words_sil/kaldi_lexicon.phn.kenlm.wrd.o40003.txt (in units file: /kaggle/working/preppedtext/fst/phn_to_words_sil/kaldi_dict.phn.txt) [2021-05-30 15:50:14,005][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words_sil/H.phn.fst [2021-05-30 15:50:14,045][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words_sil/L.phn.kenlm.wrd.o40003.fst (in units: /kaggle/working/preppedtext/fst/phn_to_words_sil/kaldi_dict.phn_disambig.txt) [2021-05-30 15:50:14,244][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words_sil/LG.phn.kenlm.wrd.o40003.fst [2021-05-30 15:50:15,269][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words_sil/HLGa.phn.kenlm.wrd.o40003.fst [2021-05-30 15:50:17,600][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words_sil/HLG.phn.kenlm.wrd.o40003.fst [2021-05-30 15:50:26,782][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words/kaldi_dict.phn.txt [2021-05-30 15:50:26,783][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words/G_kenlm.wrd.o40003.fst /opt/kaldi/src/lmbin/arpa2fst --disambig-symbol=#0 --write-symbol-table=/kaggle/working/preppedtext/fst/phn_to_words/kaldi_dict.kenlm.wrd.o40003.txt /kaggle/working/preppedtext/kenlm.wrd.o40003.arpa /kaggle/working/preppedtext/fst/phn_to_words/G_kenlm.wrd.o40003.fst LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:94) Reading data section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 1-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 2-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 3-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 4-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:RemoveRedundantStates():arpa-lm-compiler.cc:359) Reduced num-states from 22665 to 12144 [2021-05-30 15:50:26,992][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words/kaldi_lexicon.phn.kenlm.wrd.o40003.txt (in units file: /kaggle/working/preppedtext/fst/phn_to_words/kaldi_dict.phn.txt) [2021-05-30 15:50:27,047][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words/H.phn.fst [2021-05-30 15:50:27,088][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words/L.phn.kenlm.wrd.o40003.fst (in units: /kaggle/working/preppedtext/fst/phn_to_words/kaldi_dict.phn_disambig.txt) [2021-05-30 15:50:27,281][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words/LG.phn.kenlm.wrd.o40003.fst [2021-05-30 15:50:28,293][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words/HLGa.phn.kenlm.wrd.o40003.fst [2021-05-30 15:50:31,245][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_words/HLG.phn.kenlm.wrd.o40003.fst === 1/5 Counting and sorting n-grams === Reading /kaggle/working/preppedtext/phones/lm.phones.filtered.txt -5101520253035404550556065707580859095--100 **************************************************************************************************** Unigram tokens 63676 types 44 === 2/5 Calculating and sorting adjusted counts === Chain sizes: 1:528 2:2571437824 3:4821446144 4:7714313728 Substituting fallback discounts for order 0: D1=0.5 D2=1 D3+=1.5 Statistics: 1 44 D1=0.5 D2=1 D3+=1.5 2 1053 D1=0.421189 D2=1.06361 D3+=1.49793 3 8534 D1=0.558099 D2=1.17765 D3+=1.45173 4 23058 D1=0.643934 D2=1.15876 D3+=1.53884 Memory estimate for binary LM: type kB probing 631 assuming -p 1.5 probing 687 assuming -r models -p 1.5 trie 203 without quantization trie 88 assuming -q 8 -b 8 quantization trie 196 assuming -a 22 array pointer compression trie 81 assuming -a 22 -q 8 -b 8 array pointer compression and quantization === 3/5 Calculating and sorting initial probabilities === Chain sizes: 1:528 2:16848 3:170680 4:553392 -5101520253035404550556065707580859095--100 #################################################################################################### === 4/5 Calculating and writing order-interpolated probabilities === Chain sizes: 1:528 2:16848 3:170680 4:553392 -5101520253035404550556065707580859095--100 #################################################################################################### === 5/5 Writing ARPA model === -5101520253035404550556065707580859095--100 **************************************************************************************************** Name:lmplz VmPeak:14916784 kB VmRSS:7056 kB RSSMax:2973864 kB user:0.209899 sys:0.716931 CPU:0.926881 real:0.936705 Reading /kaggle/working/preppedtext/phones/lm.phones.filtered.04.arpa -5101520253035404550556065707580859095--100 **************************************************************************************************** SUCCESS === 1/5 Counting and sorting n-grams === Reading /kaggle/working/preppedtext/phones/lm.phones.filtered.txt -5101520253035404550556065707580859095--100 **************************************************************************************************** Unigram tokens 63676 types 44 === 2/5 Calculating and sorting adjusted counts === Chain sizes: 1:528 2:929673728 3:1743138176 4:2789021184 5:4067322624 6:5578042368 Substituting fallback discounts for order 0: D1=0.5 D2=1 D3+=1.5 Statistics: 1 44 D1=0.5 D2=1 D3+=1.5 2 1053 D1=0.421189 D2=1.06361 D3+=1.49793 3 8534 D1=0.558099 D2=1.17765 D3+=1.45173 4 23058 D1=0.704256 D2=1.25425 D3+=1.63465 5 35879 D1=0.821218 D2=1.34714 D3+=1.61281 6 43593 D1=0.834579 D2=1.24241 D3+=1.56972 Memory estimate for binary LM: type kB probing 2373 assuming -p 1.5 probing 2775 assuming -r models -p 1.5 trie 907 without quantization trie 401 assuming -q 8 -b 8 quantization trie 838 assuming -a 22 array pointer compression trie 331 assuming -a 22 -q 8 -b 8 array pointer compression and quantization === 3/5 Calculating and sorting initial probabilities === Chain sizes: 1:528 2:16848 3:170680 4:553392 5:1004612 6:1394976 -5101520253035404550556065707580859095--100 #################################################################################################### === 4/5 Calculating and writing order-interpolated probabilities === Chain sizes: 1:528 2:16848 3:170680 4:553392 5:1004612 6:1394976 -5101520253035404550556065707580859095--100 #################################################################################################### === 5/5 Writing ARPA model === -5101520253035404550556065707580859095--100 **************************************************************************************************** Name:lmplz VmPeak:14949572 kB VmRSS:6500 kB RSSMax:2354520 kB user:0.256512 sys:0.588288 CPU:0.84484 real:0.81585 Reading /kaggle/working/preppedtext/phones/lm.phones.filtered.06.arpa -5101520253035404550556065707580859095--100 **************************************************************************************************** SUCCESS [2021-05-30 15:50:35,812][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_phn_sil/kaldi_dict.phn.txt [2021-05-30 15:50:35,812][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_phn_sil/G_lm.phones.filtered.06.fst /opt/kaldi/src/lmbin/arpa2fst --disambig-symbol=#0 --write-symbol-table=/kaggle/working/preppedtext/fst/phn_to_phn_sil/kaldi_dict.lm.phones.filtered.06.txt /kaggle/working/preppedtext/phones/lm.phones.filtered.06.arpa /kaggle/working/preppedtext/fst/phn_to_phn_sil/G_lm.phones.filtered.06.fst LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:94) Reading data section. LOG (arpa2fst[5.5.0~1-2b62]:HeaderAvailable():arpa-lm-compiler.cc:300) Reverting to slower state tracking because model is large: 6-gram with symbols up to 47 LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 1-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 2-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 3-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 4-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 5-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading 6-grams: section. LOG (arpa2fst[5.5.0~1-2b62]:RemoveRedundantStates():arpa-lm-compiler.cc:359) Reduced num-states from 67529 to 67528 [2021-05-30 15:50:36,696][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_phn_sil/kaldi_lexicon.phn.lm.phones.filtered.06.txt (in units file: /kaggle/working/preppedtext/fst/phn_to_phn_sil/kaldi_dict.phn.txt) [2021-05-30 15:50:36,713][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_phn_sil/H.phn.fst [2021-05-30 15:50:36,754][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_phn_sil/L.phn.lm.phones.filtered.06.fst (in units: /kaggle/working/preppedtext/fst/phn_to_phn_sil/kaldi_dict.phn_disambig.txt) [2021-05-30 15:50:36,802][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_phn_sil/LG.phn.lm.phones.filtered.06.fst [2021-05-30 15:50:37,700][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_phn_sil/HLGa.phn.lm.phones.filtered.06.fst [2021-05-30 15:50:40,759][__main__][INFO] - Creating /kaggle/working/preppedtext/fst/phn_to_phn_sil/HLG.phn.lm.phones.filtered.06.fst .",
            "url": "https://jimregan.github.io/notes/kaggle/wav2vec-u/2021/05/26/wav2vec-u-cv-swedish-text-prep.html",
            "relUrl": "/kaggle/wav2vec-u/2021/05/26/wav2vec-u-cv-swedish-text-prep.html",
            "date": " • May 26, 2021"
        }
        
    
  
    
        ,"post214": {
            "title": "wav2vec-u Common Voice Swedish - prepare ltr/phn/wrd",
            "content": "Original here . In the section Preparation of speech and text data of the readme, it says: . Similar to wav2vec 2.0, data folders contain {train,valid,test}.{tsv,wrd,phn} files, where audio paths are stored in tsv files, and word, letter or phoneme transcriptions are stored in .{wrd,ltr,phn}. The .wrd and .ltr files are outputs of libri_labels.py . %%capture !pip install phonemizer . %%capture !apt-get -y install espeak . %%capture !apt-get -y install zsh . This is just my best guess at what the .wrd files contain - it seems to match up with what libri_labels.py does: given input like . 1272-128104-0000 MISTER QUILTER IS THE APOSTLE OF THE MIDDLE CLASSES AND WE ARE GLAD TO WELCOME HIS GOSPEL . it does &quot; &quot;.join(items[1:]), which is basically the same . !cat /kaggle/input/download-common-voice-swedish/cv-corpus-6.1-2020-12-11/sv-SE/test.tsv | awk -F&#39; t&#39; &#39;{print $3}&#39;|grep -v &#39;^sentence$&#39; | perl -C7 -ane &#39;chomp;$_=lc($_);s/[^ p{L} p{N} p{M}&#39;&quot; &#39;&quot;&#39; -]/ /g;s/ +/ /g;s/ $//;s/^ //;print &quot;$_ n&quot;;&#39; &gt; test.wrd !cat /kaggle/input/download-common-voice-swedish/cv-corpus-6.1-2020-12-11/sv-SE/dev.tsv | awk -F&#39; t&#39; &#39;{print $3}&#39;|grep -v &#39;^sentence$&#39; | perl -C7 -ane &#39;chomp;$_=lc($_);s/[^ p{L} p{N} p{M}&#39;&quot; &#39;&quot;&#39; -]/ /g;s/ +/ /g;s/ $//;s/^ //;print &quot;$_ n&quot;;&#39; &gt; valid.wrd !cat /kaggle/input/download-common-voice-swedish/cv-corpus-6.1-2020-12-11/sv-SE/train.tsv | awk -F&#39; t&#39; &#39;{print $3}&#39;|grep -v &#39;^sentence$&#39; | perl -C7 -ane &#39;chomp;$_=lc($_);s/[^ p{L} p{N} p{M}&#39;&quot; &#39;&quot;&#39; -]/ /g;s/ +/ /g;s/ $//;s/^ //;print &quot;$_ n&quot;;&#39; &gt; train.wrd . for i in [&#39;train&#39;, &#39;test&#39;, &#39;valid&#39;]: with open(f&#39;/kaggle/working/{i}.wrd&#39;, &#39;r&#39;) as inf, open(f&#39;/kaggle/working/{i}.ltr&#39;, &#39;w&#39;) as out: for line in inf.readlines(): print(&quot; &quot;.join(list(line.strip().replace(&quot; &quot;, &quot;|&quot;))) + &quot; |&quot;, file=out) . !head train.ltr . v a d | ä r | d e t | i | e u r o | d u | s k a | v e t a | a t t | d e t | ä r | d u | s o m | h a r | f e l | g å | n e r | p å | k n ä | f ö r s t | m å s t e | j a g | s l å | s ö n d e r | d e n | d ä r | s t o r a | s k r o t h ö g e n | d e t | b l i r | s v å r t | v a d | f ö r | j ä v l a | f r å g a | ä r | d e t | j a g | å t e r v ä n d e r | i n t e | t i l l | s k i t h å l e t | t i t t a | p å | s ö m m a r n a | f e s | d u | p r e c i s | a k t r i s e r | h a r | e t t | b ä s t | f ö r e d a t u m | . There are some warnings about switching, so echo the filename first to known where the errors are . !for i in train test valid; do echo $i.wrd; cat $i.wrd | PHONEMIZER_ESPEAK_PATH=$(which espeak) phonemize -o $i.phn -p &#39; &#39; -w &#39;&#39; -l sv -j 70 --language-switch remove-flags ;done . train.wrd [WARNING] 2 utterances containing language switches on lines 254, 1457 [WARNING] extra phones may appear in the &#34;sv&#34; phoneset [WARNING] language switch flags have been removed (applying &#34;remove-flags&#34; policy) test.wrd [WARNING] 1 utterances containing language switches on lines 81 [WARNING] extra phones may appear in the &#34;sv&#34; phoneset [WARNING] language switch flags have been removed (applying &#34;remove-flags&#34; policy) valid.wrd [WARNING] 1 utterances containing language switches on lines 1831 [WARNING] extra phones may appear in the &#34;sv&#34; phoneset [WARNING] language switch flags have been removed (applying &#34;remove-flags&#34; policy) . !cat test.wrd|awk &#39;BEGIN{ln=1}{if(ln==81){print $0};ln++}&#39; !cat train.wrd|awk &#39;BEGIN{ln=1}{if(ln==254||ln==1457){print $0};ln++}&#39; !cat valid.wrd|awk &#39;BEGIN{ln=1}{if(ln==1831){print $0};ln++}&#39; . det är taskigt och så unik design internet slutade fungera det finns inget internet . !cat test.phn|awk &#39;BEGIN{ln=1}{if(ln==81){print $0};ln++}&#39; !cat train.phn|awk &#39;BEGIN{ln=1}{if(ln==254||ln==1457){print $0};ln++}&#39; !cat valid.phn|awk &#39;BEGIN{ln=1}{if(ln==1831){print $0};ln++}&#39; . d eː t ɛː r t a s k ɪ ɡ t ɔ k s oː ɵ n iː k d ɪ z aɪ n ɪ n t ə n ɛ t s l ʉ t a d ə f ɵ n ɡ eː r a d eː t f ɪ n s ɪ ŋ ə t ɪ n t ə n ɛ t . &quot;design&quot; and &quot;internet&quot; are clearly the English words that are causing the switch in their respective sentences, but I&#39;m not sure what the problem in test.wrd is: &quot;taskigt&quot;? . design /dɛˈsajn/ | internet /ˈɪntɛrnɛt/, /ɪntɛrˈnɛt/ | . !echo taskigt|espeak -v sv --ipa 2&gt; /dev/null . (en)tˈaskɪɡt(sv) . !cat test.phn|sed -e &#39;s/^ //;s/t a s k ɪ ɡ t/t a s k ɪ t/&#39; &gt; tmp !mv tmp test.phn !cat train.phn|sed -e &#39;s/^ //;s/d ɪ z aɪ n/d ɛ s a j n/;s/ɪ n t ə n ɛ t/ɪ n t ɛ r n ɛ t/&#39; &gt; tmp !mv tmp train.phn !cat valid.phn|sed -e &#39;s/^ //;s/ɪ n t ə n ɛ t/ɪ n t ɛ r n ɛ t/&#39; &gt; tmp !mv tmp valid.phn . !for i in train test valid; do cat $i.wrd|tr &#39; &#39; &#39; n&#39;|sort|uniq |grep -v &#39;^internet$&#39;|grep -v &#39;^design$&#39;|grep -v &#39;^taskigt$&#39; &gt; /tmp/$i.wl; cat /tmp/$i.wl | PHONEMIZER_ESPEAK_PATH=$(which espeak) phonemize -o /tmp/$i.wl.phn -p &#39; &#39; -w &#39;&#39; -l sv -j 70 --language-switch remove-flags;paste /tmp/$i.wl /tmp/$i.wl.phn &gt; dict.$i; done !printf &quot;taskigt tt a s k ɪ t n&quot; &gt;&gt; dict.test !printf &quot;design td ɛ s a j n n&quot; &gt;&gt; dict.train !printf &quot;internet tɪ n t ɛ r n ɛ t n&quot; &gt;&gt; dict.train !printf &quot;internet tɪ n t ɛ r n ɛ t n&quot; &gt;&gt; dict.valid . !for i in dic*;do cat $i |sort &gt; tmp;mv tmp $i;done . cat: valid: No such file or directory .",
            "url": "https://jimregan.github.io/notes/kaggle/wav2vec-u/2021/05/26/wav2vec-u-cv-swedish-prep-ltr-phn-wrd.html",
            "relUrl": "/kaggle/wav2vec-u/2021/05/26/wav2vec-u-cv-swedish-prep-ltr-phn-wrd.html",
            "date": " • May 26, 2021"
        }
        
    
  
    
        ,"post215": {
            "title": "Attempt to install Merlin on Kaggle",
            "content": "!git clone https://github.com/CSTR-Edinburgh/merlin . Merlin needs bandmat, but there&#39;s an issue with Python 3.7 and Cython, so build it separately: . %%capture !pip install git+https://github.com/MattShannon/bandmat . %cd merlin . /kaggle/working/merlin . %%capture !pip install -r requirements.txt . %cd tools . /kaggle/working/merlin/tools . %%capture !apt-get -y install csh automake autoconf . !./compile_tools.sh . %cd /kaggle/working/merlin . /kaggle/working/merlin . %cd egs/slt_arctic . /kaggle/working/merlin/egs/slt_arctic . !cat README . About the SLT Arctic corpus The CMU_ARCTIC databases were constructed at the Language Technologies Institute at Carnegie Mellon University as phonetically balanced, US English single speaker databases designed for unit selection speech synthesis research. The databases consist of around 1150 utterances carefully selected from out-of-copyright texts from Project Gutenberg. The databses include US English male (bdl) and female (slt) speakers (both experienced voice talent) as well as other accented speakers. Each subdirectory of this directory contains the scripts for a sequence of experiments. s1: To run slt_arctic_demo with WORLD vocoder. s2: To run slt_arctic_demo with MagPhase vocoder (includes acoustic feature extraction). . %cd s1 . /kaggle/working/merlin/egs/slt_arctic/s1 . !ls . 01_setup.sh RESULTS.md scripts 02_prepare_conf_files.sh conf slt_arctic_full_data 03_train_duration_model.sh experiments slt_arctic_full_data.zip 04_train_acoustic_model.sh merlin_synthesis.sh testrefs 05_run_merlin.sh run_demo.sh README.md run_full_voice.sh . !./01_setup.sh . ################################ Usage: Chose any of the below datasets To run on short data: ./01_setup.sh slt_arctic_demo ./01_setup.sh awb_arctic_demo (or) To run on full data: ./01_setup.sh slt_arctic_full ./01_setup.sh awb_arctic_full ./01_setup.sh bdl_arctic_full ################################ . !./01_setup.sh slt_arctic_full . Step 1: downloading data..... % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 247M 100 247M 0 0 23.1M 0 0:00:10 0:00:10 --:--:-- 26.5M unzipping files...... data is ready! Merlin default voice settings configured in conf/global_settings.cfg setup done...! . !./02_prepare_conf_files.sh . ################################ Usage: ./02_prepare_conf_files.sh &lt;path_to_global_conf_file&gt; default path to global conf file: conf/global_settings.cfg Config files will be prepared based on settings in global conf file ################################ . !cat conf/global_settings.cfg . MerlinDir=/kaggle/working/merlin WorkDir=/kaggle/working/merlin/egs/slt_arctic/s1 Voice=slt_arctic_full Labels=state_align QuestionFile=questions-radio_dnn_416.hed Vocoder=WORLD SamplingFreq=16000 FileIDList=file_id_list_full.scp Train=1000 Valid=66 Test=66 . !./02_prepare_conf_files.sh conf/global_settings.cfg . Step 2: preparing config files for acoustic, duration models... Duration configuration settings stored in conf/duration_slt_arctic_full.conf Acoustic configuration settings stored in conf/acoustic_slt_arctic_full.conf preparing config files for synthesis... Duration configuration settings stored in conf/test_dur_synth_slt_arctic_full.conf Acoustic configuration settings stored in conf/test_synth_slt_arctic_full.conf . !./03_train_duration_model.sh . ################################ Usage: ./03_train_duration_model.sh &lt;path_to_duration_conf_file&gt; Default path to duration conf file: conf/duration_slt_arctic_full.conf ################################ . !./03_train_duration_model.sh conf/duration_slt_arctic_full.conf . Step 3: training duration model... Architecture: x86_64 Distribution: Ubuntu 18.04.5 LTS HOSTNAME=37a070d6fe91 USER= PATH: /opt/conda/bin /usr/local/sbin /usr/local/bin /usr/sbin /usr/bin /sbin /bin LD_LIBRARY_PATH: /opt/conda/lib PYTHONPATH: /kaggle/lib/kagglegym /kaggle/lib PYTHONBIN: python MERLIN_THEANO_FLAGS: cuda.root=/usr/local/8.0 floatX=float32 on_unused_input=ignore No GPU is available! Running on CPU... /opt/conda/lib/python3.7/site-packages/theano/configparser.py:255: UserWarning: Theano does not recognise this flag: cuda.root warnings.warn(f&#34;Theano does not recognise this flag: {key}&#34;) Traceback (most recent call last): File &#34;/kaggle/working/merlin/src/run_merlin.py&#34;, line 74, in &lt;module&gt; from models.deep_rnn import DeepRecurrentNetwork File &#34;/kaggle/working/merlin/src/models/deep_rnn.py&#34;, line 9, in &lt;module&gt; from theano.tensor.shared_randomstreams import RandomStreams ModuleNotFoundError: No module named &#39;theano.tensor.shared_randomstreams&#39; .",
            "url": "https://jimregan.github.io/notes/kaggle/merlin/2021/05/26/merlin-attempt.html",
            "relUrl": "/kaggle/merlin/2021/05/26/merlin-attempt.html",
            "date": " • May 26, 2021"
        }
        
    
  
    
        ,"post216": {
            "title": "wav2vec-u Common Voice Swedish - vad",
            "content": "Original here . %cd /tmp . /tmp . !git clone https://github.com/pytorch/fairseq/ . %cd fairseq/examples/wav2vec/unsupervised . /tmp/fairseq/examples/wav2vec/unsupervised . !git clone https://github.com/zhenghuatan/rVADfast . !cat scripts/vads.py|sed -e &#39;s!/path/to/rVADfast_py_2.0!/tmp/fairseq/examples/wav2vec/unsupervised/rVADfast!&#39; &gt; tmp !mv tmp scripts/vads.py . !for i in train valid test;do cat /kaggle/input/fork-of-wav2vec-u-cv-swedish-tsv/$i.tsv|python scripts/vads.py &gt; /kaggle/working/$i.vads;done . 100%|█████████████████████████████████████| 2331/2331 [1:01:46&lt;00:00, 1.59s/it] 100%|███████████████████████████████████████| 2019/2019 [53:39&lt;00:00, 1.59s/it] 100%|███████████████████████████████████████| 2027/2027 [57:26&lt;00:00, 1.70s/it] . !mkdir /kaggle/working/wav !mkdir /kaggle/working/wav/train !mkdir /kaggle/working/wav/test !mkdir /kaggle/working/wav/valid . !for i in train test valid; do python scripts/remove_silence.py --tsv /kaggle/input/fork-of-wav2vec-u-cv-swedish-tsv/$i.tsv --vads /kaggle/working/$i.vads --out /kaggle/working/wav/$i;done .",
            "url": "https://jimregan.github.io/notes/kaggle/wav2vec-u/2021/05/25/wav2vec-u-cv-swedish-vads.html",
            "relUrl": "/kaggle/wav2vec-u/2021/05/25/wav2vec-u-cv-swedish-vads.html",
            "date": " • May 25, 2021"
        }
        
    
  
    
        ,"post217": {
            "title": "wav2vec-u Common Voice Swedish - prepare tsv",
            "content": "Original here . import soundfile input = { &#39;train&#39;: &#39;/kaggle/input/download-common-voice-swedish/cv-corpus-6.1-2020-12-11/sv-SE/train.tsv&#39;, &#39;test&#39;: &#39;/kaggle/input/download-common-voice-swedish/cv-corpus-6.1-2020-12-11/sv-SE/test.tsv&#39;, &#39;valid&#39;: &#39;/kaggle/input/download-common-voice-swedish/cv-corpus-6.1-2020-12-11/sv-SE/dev.tsv&#39; } for split in input.keys(): with open(input[split], &#39;r&#39;) as tsv: with open(f&#39;/kaggle/working/{split}.tsv&#39;, &#39;w&#39;) as out: print(&#39;/kaggle/input/common-voice-swedish-16bit-wav/&#39;, file=out) for line in tsv.readlines(): data = line.split(&#39; t&#39;) if data[1] == &#39;path&#39;: continue file = data[1] file = file.replace(&#39;.mp3&#39;, &#39;.wav&#39;) path = f&#39;/kaggle/input/common-voice-swedish-16bit-wav/{file}&#39; frames = soundfile.info(path).frames print(&quot;{} t{}&quot;.format(file, frames), file=out) .",
            "url": "https://jimregan.github.io/notes/kaggle/wav2vec-u/2021/05/25/wav2vec-u-cv-swedish-tsv.html",
            "relUrl": "/kaggle/wav2vec-u/2021/05/25/wav2vec-u-cv-swedish-tsv.html",
            "date": " • May 25, 2021"
        }
        
    
  
    
        ,"post218": {
            "title": "Download Common Voice Swedish",
            "content": "Original notebook here . This link won&#39;t work any more, so you&#39;ll need a fresh link from Common Voice Datasets . !wget &#39;https://mozilla-common-voice-datasets.s3.dualstack.us-west-2.amazonaws.com/cv-corpus-6.1-2020-12-11/sv-SE.tar.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;X-Amz-Credential=ASIAQ3GQRTO3KA6TWRBY%2F20210525%2Fus-west-2%2Fs3%2Faws4_request&amp;X-Amz-Date=20210525T103604Z&amp;X-Amz-Expires=43200&amp;X-Amz-Security-Token=FwoGZXIvYXdzEHwaDAOxZbXj8dSCv%2B%2B1%2FyKSBFuQ4WGxxfHEd51rf4QvMe6fipqbY4nXKUe7Hi%2FCoUFR%2BgXEgXjMjzgKih3fiiBllsdJ1w%2BO4dQ6mKmIYdYWwfXWezdctGJ13gGNYRX2RO8EpTEHOcG48Jvc8pF97Wrv4vZ3Kmlo0jf3Y6rKLZ3HHiKbkQBQgCT40vylI0wPZg5pFXZm6o%2B8zXun1NncwAzRtbmsDSuYT0tJ4zLXpzTZhJ0Ln%2F5gZVxPnZv5WleN0sFcYBMsqTnt9hNyaCQFbnQuCv1BfE6m6KBCG8cSc23YN%2FALgcd4EzxvPaIRM%2F0vFjPTHQFuipe3du7u6TW5gJemh0xaJnLczIx7FbmkrWuZ6HXQH77U7S4YQEX3BSLrBhkcIS7QeTv9oZ5D7yfCbRAXc2V2qzVANcAoipgYxP2By0iA0C90t3ggu5YvTwSAnrHxtSDMalsXU6%2BVcEo87VDb2DkOZ9OtpApZdpstX7QXHmC5QdR7Gg7M4aiW9jbZMyAH%2FQAowc2pZHqh%2BrJqySYOLYMWEApqDZ94VaCkuguuXODS25l%2F07IqAaCzT5LO%2FjPyuFBs7nXlDZXZo64295Iu6VDprtvutUvHbxQy6qkiMYT%2Fkt297E%2FsorK9YjNhj17PjtGPx6EW4WZIHLikvpkQ3aEiVN5%2ByLu9sbj8lwdzWnf9mSGp3T5oedv27ARY1SvmWn9uQH1FB6Tet%2ByaM5u1KIBKKJGbs4UGMipKgz7uHdY53WDR2h1mkBlucbyh484Wj%2BldCrqic%2FgIKjqhay57WHKZe2w%3D&amp;X-Amz-Signature=549006bf559d20bba1fbc6523f7b7b02ef8b2b7a68f229b1875bd02336e3c3b6&amp;X-Amz-SignedHeaders=host&#39; -O sv-SE.tar.gz . !tar zxvf sv-SE.tar.gz !rm sv-SE.tar.gz .",
            "url": "https://jimregan.github.io/notes/kaggle/wav2vec-u/2021/05/25/download-common-voice-swedish.html",
            "relUrl": "/kaggle/wav2vec-u/2021/05/25/download-common-voice-swedish.html",
            "date": " • May 25, 2021"
        }
        
    
  
    
        ,"post219": {
            "title": "Convert Common Voice Swedish to 16bit wav",
            "content": "Original here . !for i in ../input/download-common-voice-swedish/cv-corpus-6.1-2020-12-11/sv-SE/clips/*.mp3;do o=$(basename $i &#39;.mp3&#39;); ffmpeg -i &quot;$i&quot; -acodec pcm_s16le -ac 1 -ar 16000 $o.wav;done .",
            "url": "https://jimregan.github.io/notes/kaggle/wav2vec-u/2021/05/25/common-voice-swedish-16bit-wav.html",
            "relUrl": "/kaggle/wav2vec-u/2021/05/25/common-voice-swedish-16bit-wav.html",
            "date": " • May 25, 2021"
        }
        
    
  
    
        ,"post220": {
            "title": "Tuairisc question page scraper",
            "content": "import requests from bs4 import BeautifulSoup . url1 = &#39;https://tuairisc.ie/leamhthuiscint-faoiseamh-agus-saoirse-sa-snamh/&#39; . def _get_url(url): r = requests.get(url) if r.status_code != 200: raise Exception(&quot;Failed to open landing page&quot;) return r.content . def _stop_reading(elem): from bs4.element import NavigableString if isinstance(elem, NavigableString): return False elems = [c for c in elem.children] return len(elems) == 1 and elems[0].name == &#39;h2&#39; and &#39; &#39;.join(elems[0][&#39;class&#39;]) == &#39;heading-banner education__banner&#39; . t1 = _get_url(url1) . soup = BeautifulSoup(t1, &#39;html.parser&#39;) . desc = soup.find(&#39;meta&#39;, {&#39;property&#39;: &#39;og:description&#39;})[&#39;content&#39;] title = soup.find(&#39;meta&#39;, {&#39;property&#39;: &#39;og:title&#39;})[&#39;content&#39;] . article_outer = soup.find(&#39;article&#39;) . article = article_outer.find(&#39;div&#39;, {&#39;itemprop&#39;: &#39;articleBody&#39;}) . def _extract_text(article): from bs4.element import NavigableString paragraphs = [] for i in article.children: if isinstance(i, NavigableString): continue if _stop_reading(i): return paragraphs paragraphs.append(i.text.replace(&#39; xa0&#39;, &#39; &#39;)) . def _extract_questions(article): out = [] for p in article.find(&#39;ol&#39;).findAll(&#39;li&#39;): out.append(p.text) return out . qs = _extract_questions(article) . qs . x.findAll(&#39;li&#39;) .",
            "url": "https://jimregan.github.io/notes/irish/tuairisc/incomplete/2021/05/24/tuairisc-question-page-scraper.html",
            "relUrl": "/irish/tuairisc/incomplete/2021/05/24/tuairisc-question-page-scraper.html",
            "date": " • May 24, 2021"
        }
        
    
  
    
        ,"post221": {
            "title": "Training Kaldi on Kaggle - Data Prep",
            "content": "%cd /opt . /opt . %%capture !tar xvf /kaggle/input/extract-prebuilt-kaldi-from-docker/kaldi.tar . %cd kaldi/egs . /opt/kaldi/egs . !git clone https://github.com/danijel3/ClarinStudioKaldi . Cloning into &#39;ClarinStudioKaldi&#39;... remote: Enumerating objects: 778, done. remote: Counting objects: 100% (3/3), done. remote: Compressing objects: 100% (3/3), done. remote: Total 778 (delta 0), reused 0 (delta 0), pack-reused 775 Receiving objects: 100% (778/778), 35.26 MiB | 19.96 MiB/s, done. Resolving deltas: 100% (262/262), done. . %cd ClarinStudioKaldi . /opt/kaldi/egs/ClarinStudioKaldi . %%capture !conda install -c bioconda perl-perlio-gzip -y . import os os.environ[&#39;LD_LIBRARY_PATH&#39;] = &#39;/opt/conda/lib:/opt/kaldi/tools/openfst-1.6.7/lib:/opt/kaldi/src/lib&#39; . !cat path.sh|sed -e &#39;s/~ /apps/ /opt/&#39; &gt; tmp !mv tmp path.sh . !echo &gt; local_clarin/clarin_pl_clean.sh . !mkdir /kaggle/working/data !ln -s /kaggle/working/data . %%writefile /opt/kaldi/tools/phonetisaurus-g2p/src/scripts/phonetisaurus-apply #!/usr/bin/env python # -*- mode: python; coding: utf-8 -*- from __future__ import print_function from __future__ import unicode_literals import os, logging, subprocess, time, re from datetime import datetime from collections import defaultdict import tempfile class G2PModelTester () : &quot;&quot;&quot;G2P Model training wrapper class. Phonetisaurus G2P modeling training wrapper class. This wraps the alignment, joint n-gram training, and ARPA to WFST conversion steps into one command. &quot;&quot;&quot; def __init__ (self, model, **kwargs) : self.model = model self.lexicon_file = kwargs.get (&quot;lexicon&quot;, None) self.nbest = kwargs.get (&quot;nbest&quot;, 1) self.thresh = kwargs.get (&quot;thresh&quot;, 99) self.beam = kwargs.get (&quot;beam&quot;, 10000) self.greedy = kwargs.get (&quot;greedy&quot;, False) self.accumulate = kwargs.get (&quot;accumulate&quot;, False) self.pmass = kwargs.get (&quot;pmass&quot;, 0.0) self.probs = kwargs.get (&quot;probs&quot;, False) self.verbose = kwargs.get (&quot;verbose&quot;, False) self.logger = self.setupLogger () def setupLogger (self) : &quot;&quot;&quot;Setup the logger and logging level. Setup the logger and logging level. We only support verbose and non-verbose mode. Args: verbose (bool): Verbose mode, or not. Returns: Logger: A configured logger instance. &quot;&quot;&quot; level = logging.DEBUG if self.verbose else logging.INFO logging.basicConfig ( level=level, format=&quot; 033[94m%(levelname)s:%(name)s:&quot; &quot;%(asctime)s 033[0m: %(message)s&quot;, datefmt=&quot;%Y-%m-%d %H:%M:%S&quot; ) return logging.getLogger (&quot;phonetisaurus-apply&quot;) def _loadLexicon (self) : &quot;&quot;&quot;Load the lexicon from a file. Load the reference lexicon from a file, and store it in a defaultdict (list). &quot;&quot;&quot; _lexicon = defaultdict (list) if not self.lexicon_file : return _lexicon self.logger.debug (&quot;Loading lexicon from file...&quot;) with open (self.lexicon_file, &quot;r&quot;) as ifp : for line in ifp : # py2py3 compatbility, if sys.version_info[0] &lt; 3: line = line.decode(&quot;utf8&quot;).strip () else: line = line.strip () word, pron = re.split (r&quot; t&quot;, line, 1) _lexicon [word].append (pron) return _lexicon def checkPhonetisaurusConfig (self) : &quot;&quot;&quot;Run some basic checks before training. Run some basic checks regarding the $PATH, environment, and provided data before starting training. Raises: EnvironmentError: raised if binaries are not found. &quot;&quot;&quot; self.logger.debug (&quot;Checking command configuration...&quot;) for program in [&quot;phonetisaurus-g2pfst&quot;] : if not self.which (program) : raise EnvironmentError(&quot;Phonetisaurus command, &#39;{0}&#39;, &quot; &quot;not found in path.&quot;.format (program)) if self.lexicon_file and not os.path.exists (self.lexicon_file) : self.logger.error (&quot;Could not find provided lexicon file.&quot;) sys.exit (1) for key,val in sorted (vars (self).items ()) : self.logger.debug (u&quot;{0}: {1}&quot;.format (key, val)) self.lexicon = self._loadLexicon () return def which (self, program) : &quot;&quot;&quot;Basic &#39;which&#39; implementation for python. Basic &#39;which&#39; implementation for python from stackoverflow: * https://stackoverflow.com/a/377028/6739158 Args: program (str): The program name to search the $PATH for. Returns: path/None: The path to the executable, or None. &quot;&quot;&quot; def is_exe (fpath) : return os.path.isfile (fpath) and os.access (fpath, os.X_OK) fpath, fname = os.path.split (program) if fpath: if is_exe (program): return program else: for path in os.environ[&quot;PATH&quot;].split (os.pathsep) : path = path.strip (&#39;&quot;&#39;) exe_file = os.path.join (path, program) if is_exe (exe_file): return exe_file return None def makeG2PCommand (self, word_list) : &quot;&quot;&quot;Build the G2P command. Build the G2P command from the provided arguments. Returns: list: The command in subprocess list format. &quot;&quot;&quot; command = [ u&quot;phonetisaurus-g2pfst&quot;, u&quot;--model={0}&quot;.format (self.model), u&quot;--nbest={0}&quot;.format (self.nbest), u&quot;--beam={0}&quot;.format (self.beam), u&quot;--thresh={0}&quot;.format (self.thresh), u&quot;--accumulate={0}&quot;.format (str (self.accumulate).lower ()), u&quot;--pmass={0}&quot;.format (self.pmass), u&quot;--nlog_probs={0}&quot;.format (str(not self.probs).lower ()), u&quot;--wordlist={0}&quot;.format (word_list) ] self.logger.debug (u&quot; &quot;.join (command)) return command def runG2PCommand (self, word_list_file) : &quot;&quot;&quot;Generate and run the actual G2P command. Generate and run the actual G2P command. Each synthesized entry will be yielded back on-the-fly via the subprocess stdout readline method. Args: word_list_file (str): The input word list. &quot;&quot;&quot; g2p_command = self.makeG2PCommand (word_list_file) self.logger.debug (&quot;Applying G2P model...&quot;) with open (os.devnull, &quot;w&quot;) as devnull : proc = subprocess.Popen ( g2p_command, stdout=subprocess.PIPE, stderr=devnull if not self.verbose else None ) for line in proc.stdout : parts = re.split (r&quot; t&quot;, line.decode (&quot;utf8&quot;).strip ()) if not len (parts) == 3 : self.logger.warning ( u&quot;No pronunciation for word: &#39;{0}&#39;&quot;.format (parts [0]) ) continue yield parts return def applyG2POnly (self, word_list_file) : &quot;&quot;&quot;Apply the G2P model to a word list. Apply the G2P model to a word list. No filtering or application of a reference lexicon is used here. Args: word_list_file (str): The input word list. &quot;&quot;&quot; for word, score, pron in self.runG2PCommand (word_list_file) : line = u&quot;&quot; if self.verbose : line = u&quot;{0} t{1:.2f} t{2}&quot;.format ( word, float (score), pron ) else : line = u&quot;{0} t{1}&quot;.format (word, pron) # py2py3 compatbility, if sys.version_info[0] &lt; 3: print (line.encode (&quot;utf8&quot;)) else : print (line) return def applyG2PWithLexicon (self, word_list_file) : &quot;&quot;&quot;Apply the G2P model to a word list, combined with lexicon. Apply the G2P model to a word list, but combine this with a reference lexicon. Words for which a reference entry exists will not be sent to the G2P, unless the additional &#39;--greedy&#39; flag is set to True. Args: word_list_file (str): The input word list. &quot;&quot;&quot; target_lexicon = defaultdict (list) tmpwordlist = tempfile.NamedTemporaryFile(mode=&#39;w&#39;, delete=False) #First, find any words in the target list for which we already # have a canonical pronunciation in the reference lexicon. with open (word_list_file, &quot;r&quot;) as ifp : for word in ifp : # py2py3 compatbility, if sys.version_info[0] &lt; 3: word = word.decode (&quot;utf8&quot;).strip () else: word = word.strip () # already in &#39;utf8&#39;. if word in self.lexicon : target_lexicon [word] = [(0.0,pron) for pron in self.lexicon [word]] #In greedy mode we still send words to the G2P, even # if we have canonical entries in the reference lexicon. if self.greedy : print (word.encode (&quot;utf8&quot;), file=tmpwordlist) else : # py2py3 compatbility, if sys.version_info[0] &lt; 3: print (word.encode (&quot;utf8&quot;), file=tmpwordlist) else: print (word, file=tmpwordlist) tmpwordlist.close () #Second, iterate through the G2P output, and filter against # any possible duplicates previously found in the reference lexicon. for word, score, pron in self.runG2PCommand (tmpwordlist.name) : prons = set ([p for s,p in target_lexicon [word]]) if pron in prons : continue target_lexicon [word].append ((score, pron)) #Finally, sort everything that is left and print it. for word in sorted (target_lexicon.keys ()) : for score, pron in target_lexicon [word] : line = u&quot;&quot; if self.verbose : line = u&quot;{0} t{1:.2f} t{2}&quot;.format ( word, float (score), pron ) else : line = u&quot;{0} t{1}&quot;.format (word, pron) # py2py3 compatbility, if sys.version_info[0] &lt; 3: print (line.encode (&quot;utf8&quot;)) else : print (line) os.unlink (tmpwordlist.name) return def ApplyG2PModel (self, word_list_file) : &quot;&quot;&quot;Apply the G2P model to a word list. Apply the G2P model to a word list. Args: word_list_file (str): The input word list. &quot;&quot;&quot; self.checkPhonetisaurusConfig () if not os.path.exists (word_list_file) or not os.path.isfile (word_list_file) : raise IOError(&quot;Word list file not found.&quot;) if len (self.lexicon) == 0 : self.applyG2POnly (word_list_file) else : self.applyG2PWithLexicon (word_list_file) return if __name__ == &quot;__main__&quot; : import sys, argparse example = &quot;{0} --model train/model.fst --word test&quot;.format (sys.argv [0]) parser = argparse.ArgumentParser (description=example) parser.add_argument (&quot;--model&quot;, &quot;-m&quot;, help=&quot;Phonetisaurus G2P fst model.&quot;, required=True) parser.add_argument (&quot;--lexicon&quot;, &quot;-l&quot;, help=&quot;Optional reference lexicon.&quot;, required=False) parser.add_argument (&quot;--nbest&quot;, &quot;-n&quot;, help=&quot;Maximum number of hypotheses &quot; &quot;to produce. Overridden if --pmass is set.&quot;, default=1, type=int) parser.add_argument (&quot;--beam&quot;, &quot;-b&quot;, help=&quot;Search &#39;beam&#39;.&quot;, default=10000, type=int) parser.add_argument (&quot;--thresh&quot;, &quot;-t&quot;, help=&quot;Pruning threshold for n-best.&quot;, default=99.0, type=float) parser.add_argument (&quot;--greedy&quot;, &quot;-g&quot;, help=&quot;Use the G2P even if a &quot; &quot;reference lexicon has been provided.&quot;, default=False, action=&quot;store_true&quot;) parser.add_argument (&quot;--accumulate&quot;, &quot;-a&quot;, help=&quot;Accumulate probabilities &quot; &quot;across unique pronunciations.&quot;, default=False, action=&quot;store_true&quot;) parser.add_argument (&quot;--pmass&quot;, &quot;-p&quot;, help=&quot;Select the maximum number of &quot; &quot;hypotheses summing to P total mass for a word.&quot;, default=0.0, type=float) parser.add_argument (&quot;--probs&quot;, &quot;-pr&quot;, help=&quot;Print exp(-val) &quot; &quot;instead of default -log values.&quot;, default=False, action=&quot;store_true&quot;) parser.add_argument (&quot;--word_list&quot;, &quot;-wl&quot;, help=&quot;Input word or word list to apply &quot; &quot;G2P model to.&quot;, type=str) parser.add_argument (&quot;--verbose&quot;, &quot;-v&quot;, help=&quot;Verbose mode.&quot;, default=False, action=&quot;store_true&quot;) args = parser.parse_args () tester = G2PModelTester ( args.model, **{key:val for key,val in args.__dict__.items () if not key in [&quot;model&quot;,&quot;word_list&quot;]} ) tester.ApplyG2PModel (args.word_list) . Overwriting /opt/kaldi/tools/phonetisaurus-g2p/src/scripts/phonetisaurus-apply . !chmod a+x /opt/kaldi/tools/phonetisaurus-g2p/src/scripts/phonetisaurus-apply . %%writefile local_clarin/clarin_prepare_dict.sh #!/bin/bash # Copyright 2010-2012 Microsoft Corporation # 2012-2014 Johns Hopkins University (Author: Daniel Povey) # 2015 Guoguo Chen # Modified 2017 Danijel Korzinek # Licensed under the Apache License, Version 2.0 (the &quot;License&quot;); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # THIS CODE IS PROVIDED *AS IS* BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY # KIND, EITHER EXPRESS OR IMPLIED, INCLUDING WITHOUT LIMITATION ANY IMPLIED # WARRANTIES OR CONDITIONS OF TITLE, FITNESS FOR A PARTICULAR PURPOSE, # MERCHANTABLITY OR NON-INFRINGEMENT. # See the Apache 2 License for the specific language governing permissions and # limitations under the License. # Call this script from one level above, e.g. from the s3/ directory. It puts # its output in data/local/. # The parts of the output of this that will be needed are # [in data/local/dict/ ] # lexicon.txt # extra_questions.txt # nonsilence_phones.txt # optional_silence.txt # silence_phones.txt # run this from ../ echo &quot;$0 $@&quot; # Print the command line for logging . utils/parse_options.sh || exit 1; . ./path.sh if [ $# -ne 2 ]; then echo &quot;Usage: ./local/prepare_lang.sh &lt;word_list&gt; &lt;dict_dir&gt;&quot; echo &quot;Creates a folder &lt;dict_dir&gt; with lexicon derived from&quot; echo &quot; word list &lt;word_list&gt;.&quot; exit 1 fi word_list=$1 dir=$2 mkdir -p $dir # Make phones symbol-table (adding in silence and verbal and non-verbal noises at this point). # We are adding suffixes _B, _E, _S for beginning, ending, and singleton phones. # silence phones, one per line. (echo sil) &gt; $dir/silence_phones.txt echo sil &gt; $dir/optional_silence.txt # nonsilence phones; on each line is a list of phones that correspond # really to the same base phone. printf &quot;I nS nZ na nb nd ndZ ndz ndzi ne nen nf ng ni nj nk nl nm nn nni no non np nr ns nsi nt ntS nts ntsi nu nv nw nx nz nzi n&quot; &gt; $dir/nonsilence_phones.txt # A few extra questions that will be added to those obtained by automatically clustering # the &quot;real&quot; phones. These ask about stress; there&#39;s also one for silence. cat $dir/silence_phones.txt| awk &#39;{printf(&quot;%s &quot;, $1);} END{printf &quot; n&quot;;}&#39; &gt; $dir/extra_questions.txt || exit 1; cat $dir/nonsilence_phones.txt | perl -e &#39;while(&lt;&gt;){ foreach $p (split(&quot; &quot;, $_)) { $p =~ m:^([^ d]+)( d*)$: || die &quot;Bad phone $_&quot;; $q{$2} .= &quot;$p &quot;; } } foreach $l (values %q) {print &quot;$l n&quot;;}&#39; &gt;&gt; $dir/extra_questions.txt || exit 1; #Transcribe the wordlist export LD_LIBRARY_PATH=$KALDI_ROOT/tools/openfst/lib export PATH=$PATH:/opt/kaldi/tools/phonetisaurus-g2p/ /opt/kaldi/tools/phonetisaurus-g2p/src/scripts/phonetisaurus-apply --model local_clarin/model.fst --lexicon local_clarin/lexicon.txt --word_list $word_list -p 0.8 &gt; $dir/lexicon_raw_nosil.txt || exit 1 sort -u $dir/lexicon_raw_nosil.txt -o $dir/lexicon_raw_nosil.txt # Add the silences, noises etc. # the sort | uniq is to remove a duplicated pron. # lexicon.txt is without the _B, _E, _S, _I markers. (echo -e &#39;&lt;unk&gt; tsil&#39; ) | cat - $dir/lexicon_raw_nosil.txt | sort -u &gt; $dir/lexicon.txt || exit 1; # Cleanup rm -f $dir/lexiconp.txt rm -f $dir/lexicon_raw_nosil.txt echo &quot;Dictionary preparation succeeded&quot; . Overwriting local_clarin/clarin_prepare_dict.sh . %%writefile local_clarin/clarin_pl_data_prep.sh #!/bin/bash . ./path.sh #you can change this here, if you want it on a different partition, for example AUDIO_DL_PATH=audio if [ ! -d $AUDIO_DL_PATH ] ; then mkdir -p $AUDIO_DL_PATH ; fi pushd $AUDIO_DL_PATH if [ ! -f audio.tar.gz ] ; then echo &quot;Downloading audio from the Clarin-pl website (~4.6GB)...&quot; curl -O http://mowa.clarin-pl.eu/korpusy/audio.tar.gz else echo &quot;File already downloaded! Checking if download is consistent...&quot; curl -O http://mowa.clarin-pl.eu/korpusy/audio.md5sum if ! md5sum -c audio.md5sum ; then echo &quot;Download doesn&#39;t match the one on the server! &quot; echo &quot;Erase the audio.tar.gz file (and audio folder) and run this script again!&quot; exit -1 fi fi if [ ! -d audio ] ; then echo &quot;Extracting files...&quot; tar xf audio.tar.gz else echo &quot;Files already extracted?&quot; echo &quot;Remove the audio dir to extract them again...&quot; fi popd if [ ! -d data ] ; then mkdir data ; fi echo Generating file lists using proper paths... python3 local_clarin/generate_lists.py $AUDIO_DL_PATH/audio data local_clarin echo Generating spk2utt... utils/utt2spk_to_spk2utt.pl data/train/utt2spk &gt; data/train/spk2utt utils/utt2spk_to_spk2utt.pl data/test/utt2spk &gt; data/test/spk2utt utils/utt2spk_to_spk2utt.pl data/dev/utt2spk &gt; data/dev/spk2utt echo Preparing dictionary... if [ ! -d data/local ] ; then mkdir data/local ; fi cut -f2- -d&#39; &#39; &lt; data/train/text | tr &#39; &#39; &#39; n&#39; | sort -u &gt; data/local/train.wlist if [ x&quot;$(which ngram)&quot; != x&quot;&quot; ] then ngram -lm local_clarin/arpa.lm.gz -unk -write-vocab data/local/lm.wlist else perl local_clarin/extract_vocab.pl local_clarin/arpa.lm.gz &gt; data/local/lm.wlist fi tail -n +5 data/local/lm.wlist | cat data/local/train.wlist - | sort -u &gt; data/local/all.wlist if [ ! -f local_clarin/model.fst ] ; then gunzip -c local_clarin/model.fst.gz &gt; local_clarin/model.fst ; fi local_clarin/clarin_prepare_dict.sh data/local/all.wlist data/local/dict_nosp || exit 1 . Overwriting local_clarin/clarin_pl_data_prep.sh . %%writefile runmfcc.sh #!/bin/bash . ./path.sh ## set the paths in this file correctly! # link to scripts from the standard Kaldi distribution # we try to use these as much as possible if [ ! -f $KALDI_ROOT/egs/wsj/s5/conf ] ; then ln -s $KALDI_ROOT/egs/wsj/s5/conf ; fi if [ ! -f $KALDI_ROOT/egs/wsj/s5/local ] ; then ln -s $KALDI_ROOT/egs/wsj/s5/local ; fi if [ ! -f $KALDI_ROOT/egs/wsj/s5/utils ] ; then ln -s $KALDI_ROOT/egs/wsj/s5/utils ; fi if [ ! -f $KALDI_ROOT/egs/wsj/s5/steps ] ; then ln -s $KALDI_ROOT/egs/wsj/s5/steps ; fi # exits script if error occurs anywhere # you might not want to do this for interactive shells. set -e export nj=40 ##number of concurrent processes export nj_test=30 ## number of concurrent processes for test has to be &lt;=30 # This is a shell script, but it&#39;s recommended that you run the commands one by # one by copying and pasting into the shell. #run some initial data preparation (look at the file for more details): local_clarin/clarin_pl_data_prep.sh #prepare the lang directory utils/prepare_lang.sh data/local/dict_nosp &quot;&lt;unk&gt;&quot; data/local/tmp_nosp data/lang_nosp #make G.fst utils/format_lm.sh data/lang_nosp local_clarin/arpa.lm.gz data/local/dict_nosp/lexicon.txt data/lang_nosp_test # Make normalized MFCC features. steps/make_mfcc.sh --nj $nj data/train steps/compute_cmvn_stats.sh data/train steps/make_mfcc.sh --nj $nj data/test steps/compute_cmvn_stats.sh data/test . Writing runmfcc.sh . !bash runmfcc.sh .",
            "url": "https://jimregan.github.io/notes/kaggle/kaldi/2021/05/24/kaldi-clarinstudio-polish-data-prep.html",
            "relUrl": "/kaggle/kaldi/2021/05/24/kaldi-clarinstudio-polish-data-prep.html",
            "date": " • May 24, 2021"
        }
        
    
  
    
        ,"post222": {
            "title": "Kaldi on Kaggle, ClarinStudio PL Mono iters 30-40",
            "content": "%cd /opt . /opt . %%capture !tar xvf /kaggle/input/extract-prebuilt-kaldi-from-docker/kaldi.tar . %cd kaldi/egs . /opt/kaldi/egs . !git clone https://github.com/danijel3/ClarinStudioKaldi . Cloning into &#39;ClarinStudioKaldi&#39;... remote: Enumerating objects: 778, done. remote: Counting objects: 100% (3/3), done. remote: Compressing objects: 100% (3/3), done. remote: Total 778 (delta 0), reused 0 (delta 0), pack-reused 775 Receiving objects: 100% (778/778), 35.26 MiB | 22.14 MiB/s, done. Resolving deltas: 100% (262/262), done. . %cd ClarinStudioKaldi . /opt/kaldi/egs/ClarinStudioKaldi . %%capture !conda install -c bioconda perl-perlio-gzip -y . import os os.environ[&#39;LD_LIBRARY_PATH&#39;] = &#39;/opt/conda/lib:/opt/kaldi/tools/openfst-1.6.7/lib:/opt/kaldi/src/lib&#39; . !cat path.sh|sed -e &#39;s/~ /apps/ /opt/&#39; &gt; tmp !mv tmp path.sh . !echo &gt; local_clarin/clarin_pl_clean.sh . !ln -s ../wsj/s5/steps !ln -s ../wsj/s5/conf !ln -s ../wsj/s5/local !ln -s ../wsj/s5/utils . !cp -r /kaggle/input/kaldi-clarinstudio-polish-train-mono-1-30/data /kaggle/working/ !cp -r /kaggle/input/kaldi-clarinstudio-polish-train-mono-1-30/exp /kaggle/working/ . !ln -s /kaggle/working/exp !ln -s /kaggle/working/data . !find /kaggle/working/exp -name &#39;*.log&#39; -delete . !/opt/kaldi/src/gmmbin/gmm-info --print-args=false exp/mono0/30.mdl | grep gaussians | awk &#39;{print $NF}&#39; . 925 . %%writefile train_mono.sh #!/usr/bin/env bash # Copyright 2012 Johns Hopkins University (Author: Daniel Povey) # 2019 Xiaohui Zhang # Apache 2.0 # Trimmed down from WSJ train_mono.sh, to continue from 30 # Begin configuration section. nj=4 cmd=run.pl scale_opts=&quot;--transition-scale=1.0 --acoustic-scale=0.1 --self-loop-scale=0.1&quot; num_iters=40 # Number of iterations of training max_iter_inc=30 # Last iter to increase #Gauss on. regular_beam=10 # beam used after the first iteration retry_beam=40 totgauss=1000 # Target #Gaussians. careful=false boost_silence=1.0 # Factor by which to boost silence likelihoods in alignment realign_iters=&quot;1 2 3 4 5 6 7 8 9 10 12 14 16 18 20 23 26 29 32 35 38&quot;; config= # name of config file. stage=-4 power=0.25 # End configuration section. echo &quot;$0 $@&quot; # Print the command line for logging if [ -f path.sh ]; then . ./path.sh; fi . parse_options.sh || exit 1; if [ $# != 3 ]; then echo &quot;Usage: steps/train_mono.sh [options] &lt;data-dir&gt; &lt;lang-dir&gt; &lt;exp-dir&gt;&quot; echo &quot; e.g.: steps/train_mono.sh data/train.1k data/lang exp/mono&quot; echo &quot;main options (for others, see top of script file)&quot; echo &quot; --config &lt;config-file&gt; # config containing options&quot; echo &quot; --nj &lt;nj&gt; # number of parallel jobs&quot; echo &quot; --cmd (utils/run.pl|utils/queue.pl &lt;queue opts&gt;) # how to run jobs.&quot; exit 1; fi data=$1 lang=$2 dir=$3 oov_sym=`cat $lang/oov.int` || exit 1; mkdir -p $dir/log echo $nj &gt; $dir/num_jobs sdata=$data/split$nj; [[ -d $sdata &amp;&amp; $data/feats.scp -ot $sdata ]] || split_data.sh $data $nj || exit 1; feats=&quot;ark,s,cs:apply-cmvn $cmvn_opts --utt2spk=ark:$sdata/JOB/utt2spk scp:$sdata/JOB/cmvn.scp scp:$sdata/JOB/feats.scp ark:- | add-deltas $delta_opts ark:- ark:- |&quot; cp $lang/phones.txt $dir || exit 1; numgauss=`gmm-info --print-args=false $dir/0.mdl | grep gaussians | awk &#39;{print $NF}&#39;` incgauss=$[($totgauss-$numgauss)/$max_iter_inc] # per-iter increment for #Gauss # update from last run #numgauss=`gmm-info --print-args=false $dir/30.mdl | grep gaussians | awk &#39;{print $NF}&#39;` #numgauss=925 igauss=1 while [ $igauss -lt 30 ];do numgauss=$[$numgauss+$incgauss]; igauss=$[$igauss+1] done # beam is only set to $initial_beam for first run beam=$regular_beam x=30 while [ $x -lt $num_iters ]; do echo &quot;$0: Pass $x&quot; if [ $stage -le $x ]; then if echo $realign_iters | grep -w $x &gt;/dev/null; then echo &quot;$0: Aligning data&quot; mdl=&quot;gmm-boost-silence --boost=$boost_silence `cat $lang/phones/optional_silence.csl` $dir/$x.mdl - |&quot; $cmd JOB=1:$nj $dir/log/align.$x.JOB.log gmm-align-compiled $scale_opts --beam=$beam --retry-beam=$retry_beam --careful=$careful &quot;$mdl&quot; &quot;ark:gunzip -c $dir/fsts.JOB.gz|&quot; &quot;$feats&quot; &quot;ark,t:|gzip -c &gt;$dir/ali.JOB.gz&quot; || exit 1; fi $cmd JOB=1:$nj $dir/log/acc.$x.JOB.log gmm-acc-stats-ali $dir/$x.mdl &quot;$feats&quot; &quot;ark:gunzip -c $dir/ali.JOB.gz|&quot; $dir/$x.JOB.acc || exit 1; $cmd $dir/log/update.$x.log gmm-est --write-occs=$dir/$[$x+1].occs --mix-up=$numgauss --power=$power $dir/$x.mdl &quot;gmm-sum-accs - $dir/$x.*.acc|&quot; $dir/$[$x+1].mdl || exit 1; rm $dir/$x.mdl $dir/$x.*.acc $dir/$x.occs 2&gt;/dev/null fi if [ $x -le $max_iter_inc ]; then numgauss=$[$numgauss+$incgauss]; fi beam=$regular_beam x=$[$x+1] done ( cd $dir; rm final.{mdl,occs} 2&gt;/dev/null; ln -s $x.mdl final.mdl; ln -s $x.occs final.occs ) steps/diagnostic/analyze_alignments.sh --cmd &quot;$cmd&quot; $lang $dir utils/summarize_warnings.pl $dir/log steps/info/gmm_dir_info.pl $dir echo &quot;$0: Done training monophone system in $dir&quot; exit 0 . Writing train_mono.sh . !bash train_mono.sh --nj 40 data/train data/lang_nosp exp/mono0 .",
            "url": "https://jimregan.github.io/notes/kaldi/kaggle/clarinstudio/2021/05/23/kaldi-clarinstudio-polish-train-mono-30-40.html",
            "relUrl": "/kaldi/kaggle/clarinstudio/2021/05/23/kaldi-clarinstudio-polish-train-mono-30-40.html",
            "date": " • May 23, 2021"
        }
        
    
  
    
        ,"post223": {
            "title": "Run ffmpeg silence detection on Wolne Lektury audio",
            "content": "Original on Kaggle . !for i in ../input/wolne-lektury-audio-zip/*.zip; do unzip $i -d /tmp; for j in /tmp/*.mp3; do base=$(basename &quot;$j&quot; &quot;.mp3&quot;); ffmpeg -i $j -af silencedetect=noise=-30dB:d=0.5 -f null - 2&gt; $base.txt; done; rm /tmp/*.mp3; done .",
            "url": "https://jimregan.github.io/notes/asr/polish/kaggle/2021/05/23/ffmpeg-silence-detection-wolne-lektury.html",
            "relUrl": "/asr/polish/kaggle/2021/05/23/ffmpeg-silence-detection-wolne-lektury.html",
            "date": " • May 23, 2021"
        }
        
    
  
    
        ,"post224": {
            "title": "CoreNLP English model on Kaggle",
            "content": "Original on Kaggle (complete with downloaded model). . !pip install stanza . import stanza stanza.install_corenlp(dir=&quot;corenlp&quot;) . Downloading http://nlp.stanford.edu/software/stanford-corenlp-latest.zip: 100%|██████████| 504M/504M [02:28&lt;00:00, 3.39MB/s] . stanza.download_corenlp_models(model=&#39;english&#39;, version=&#39;4.1.0&#39;, dir=&quot;corenlp&quot;) . Downloading http://nlp.stanford.edu/software/stanford-corenlp-4.1.0-models-english.jar: 100%|██████████| 671M/671M [03:37&lt;00:00, 3.08MB/s] .",
            "url": "https://jimregan.github.io/notes/kaggle/corenlp/english/2021/05/22/stanza-corenlp-english-model.html",
            "relUrl": "/kaggle/corenlp/english/2021/05/22/stanza-corenlp-english-model.html",
            "date": " • May 22, 2021"
        }
        
    
  
    
        ,"post225": {
            "title": "Quiggin to IPA",
            "content": "import icu def transliterator_from_rules(name, rules): fromrules = icu.Transliterator.createFromRules(name, rules) icu.Transliterator.registerInstance(fromrules) return icu.Transliterator.createInstance(name) . quiggin_to_wikipedia = &quot;&quot;&quot; b′ → bʲ; b → bˠ; k′ → c; k → k; ç → ç; d′ → dʲ; d → d̪ˠ; e : → eː; ɛ → ɛ; e → ɛ; ə → ə; αi → əi; αu → əu; α : → aː; α̃ : → aː; æ → a; α → a; f′ → fʲ; f → fˠ; ɡ′ → ɟ; g′ → ɟ; ɡ → ɡ; g → ɡ; ℊ → ɣ; h → h; i : → iː; iə → iə; ï → ɪ; ĩ → ɪ; i → ɪ; y → ɪ; j → j; L′ → l̠ʲ; l′ → lʲ; L → l̪ˠ; l → lˠ; m′ → mʲ; m → mˠ; n′ → nʲ; n → nˠ; N′ → n̠ʲ; N → n̪ˠ; ɲ → ɲ; ŋ → ŋ; o : → oː; ɔ : → oː; ɔ → ɔ; o̤ → ɔ; p′ → pʲ; p → pˠ; r′ → ɾʲ; r → ɾˠ; R → ɾˠ; s → sˠ; ʃ → ʃ; t′ → tʲ; t → t̪ˠ; u : → uː; uə → uə; Ũ → ʊ; U → ʊ; v → vʲ; w̥&#39;`&#39; → w; w̥ → w; w → w; χ → x; &quot;&quot;&quot; . quiggin = transliterator_from_rules(&#39;quiggin&#39;, quiggin_to_wikipedia) . quiggin.transliterate(&quot;ə t′αspəl&quot;) . &#39;ə tʲasˠpˠəlˠ&#39; . sample = &quot;&quot;&quot; ʃαnɔklə. 1. l′eʃ ə Nïl′ə wαduw α χrα̃:v. 2. b′i: ə çiəL hein′ ɛg′ ə Nïl′ə ℊyn′ə αgəs k′iəL ər L′eç ɛg′ ə N′αr vir′ə. 3. N′i: wi:r′ ə mαduw ruə t′αχt′ir′ə N′i: b′α:r Nα ɛ hein′. 4. mαrəguw Nə bα:ʃt′i:, L′ig′ dŨw̥`, L′ik′ə m′ə did′. 5. əs Nα̃:wid′ ə çïrd′ gən ə f′jɔ:l′əm′. 6. ʃi:l′i: N′ t′ɛəN dUw̥ gər b′e: ɛən hein′ ə t′ɛən əs bα:n′ə er′ b′iç. 7. ʃk′ɛəl ə iN′ʃə də χαpəL sə kαpəL ər to:n′ ə Nα:rd′ə. 8. N′i:r′ vĩʃt′ə də f′αdər pɔ:l. 9. tu:s k′αhə k′ɔ:. &quot;&quot;&quot; . print(quiggin.transliterate(sample)) . ʃanˠɔklˠə. 1. lʲɛʃ ə n̪ˠɪlʲə wad̪ˠuw a xɾˠaːvʲ. 2. bʲiː ə çiəl̪ˠ hɛɪnʲ ɛɟ ə n̪ˠɪlʲə ɣɪnʲə aɡəsˠ ciəl̪ˠ əɾˠ l̠ʲɛç ɛɟ ə n̠ʲaɾˠ vʲɪɾʲə. 3. n̠ʲiː wiːɾʲ ə mˠad̪ˠuw ɾˠuə tʲaxtʲɪɾʲə n̠ʲiː bʲaːɾˠ n̪ˠa ɛ hɛɪnʲ. 4. mˠaɾˠəɡuw n̪ˠə bˠaːʃtʲiː, l̠ʲɪɟ d̪ˠʊw, l̠ʲɪcə mʲə d̪ˠɪdʲ. 5. əsˠ n̪ˠaːwɪdʲ ə çɪɾˠdʲ ɡənˠ ə fʲjoːlʲəmʲ. 6. ʃiːlʲiː n̠ʲ tʲɛən̪ˠ d̪ˠʊw ɡəɾˠ bʲeː ɛənˠ hɛɪnʲ ə tʲɛənˠ əsˠ bˠaːnʲə ɛɾʲ bʲɪç. 7. ʃcɛəlˠ ə ɪn̠ʲʃə d̪ˠə xapˠəl̪ˠ sˠə kapˠəl̪ˠ əɾˠ t̪ˠoːnʲ ə n̪ˠaːɾˠdʲə. 8. n̠ʲiːɾʲ vʲɪʃtʲə d̪ˠə fʲad̪ˠəɾˠ pˠoːlˠ. 9. t̪ˠuːsˠ cahə coː. .",
            "url": "https://jimregan.github.io/notes/irish/quiggin/icu/ipa/phonetic/2021/05/21/quiggin-to-ipa.html",
            "relUrl": "/irish/quiggin/icu/ipa/phonetic/2021/05/21/quiggin-to-ipa.html",
            "date": " • May 21, 2021"
        }
        
    
  
    
        ,"post226": {
            "title": "Running rbg2p on Colab",
            "content": "!pip install -q condacolab import condacolab condacolab.install() . ⏬ Downloading https://github.com/jaimergp/miniforge/releases/latest/download/Mambaforge-colab-Linux-x86_64.sh... 📦 Installing... 📌 Adjusting configuration... 🩹 Patching environment... ⏲ Done in 0:00:30 🔁 Restarting kernel... . %%capture !conda install -c conda-forge go go-cgo -y . %%capture !pip install --upgrade setuptools wheel . !go get github.com/sergi/go-diff !go get github.com/stts-se/rbg2p . go: downloading github.com/sergi/go-diff v1.2.0 . !git clone https://github.com/stts-se/rbg2p . Cloning into &#39;rbg2p&#39;... remote: Enumerating objects: 3918, done. remote: Counting objects: 100% (123/123), done. remote: Compressing objects: 100% (85/85), done. remote: Total 3918 (delta 59), reused 77 (delta 29), pack-reused 3795 Receiving objects: 100% (3918/3918), 678.17 KiB | 2.32 MiB/s, done. Resolving deltas: 100% (1233/1233), done. . import os os.environ[&quot;PATH&quot;]=f&#39;{os.environ[&quot;PATH&quot;]}:/root/go/bin&#39; . %cd rbg2p . /content/rbg2p . %%writefile maori.g2p CHARACTER_SET &quot;aeghikmnoprtuwāēīōū&quot; DEFAULT_PHONEME &quot;_&quot; PHONEME_DELIMITER &quot; &quot; wh -&gt; f h -&gt; h k -&gt; k m -&gt; m ng -&gt; ŋ n -&gt; n p -&gt; p r -&gt; ɾ t -&gt; t w -&gt; w au -&gt; au ā -&gt; aː a -&gt; a ē -&gt; ɛː e -&gt; ɛ ī -&gt; iː i -&gt; i ō -&gt; ɔː o -&gt; ɔ ū -&gt; ʉː u -&gt; ʉ g -&gt; ∅ . Writing maori.g2p . !echo kaumātua | go run cmd/g2p/g2p.go ../maori.g2p . 0 ERROR(S) FOR ../maori.g2p 0 WARNING(S) FOR ../maori.g2p ALL 0 TESTS PASSED FOR ../maori.g2p Reading input from stdin... kaumātua k au m aː t ʉ a TOTAL INPUT : 1 ERRORS : 0 TRANSCRIBED : 1 .",
            "url": "https://jimregan.github.io/notes/rbg2p/colab/2021/05/20/running-rbg2p.html",
            "relUrl": "/rbg2p/colab/2021/05/20/running-rbg2p.html",
            "date": " • May 20, 2021"
        }
        
    
  
    
        ,"post227": {
            "title": "Kilkenny vs. Waterford",
            "content": "Comparing Kilkenny Irish with Waterford Irish. . The Kilkenny Irish comes from these tweets: (Google Books says Éigse, vol. 26, p. 35 1) . Cúpla sampla spéisiúil breise: pic.twitter.com/tYckKMrPM7 . &mdash; Corbmacc (@erisceres) May 17, 2021 I’ve marked the clear differences in bold face; differences in transcription (s′/ʃ, ɑː/aː) are not marked, nor are expected differences (⟨ao⟩ → [ai] in Waterford Irish; /r′/ → [ʒ] in Kilkenny Irish). . The Waterford side of the comparison is from Breatnach 2; references as in the index. I chose the first (that matched), except with some common words, where I used the first place I came across them. . ansoin and ansan are clearly different, but Breatnach (t. 20) gives ó shoin (/oː xin′/). . raibh /re/ is a bit of a stretch; Breatnach says this is only before pronouns, and considers it a back-formation from the unstressed form /rə/ (/rev′/ stressed). . /duːr′t′/ for dúirt in Waterford is a little unexpected: the usual rule is r′ → [r] / _ [+dental]. . K. Word K. Phonetic W. Phonetic TIoRCW ref. W. Word . a | ə | ə | t. 349 |   | . acu | əku | əˈku | 163 | aca | . ag | eg′ | eg′ | p. 146 n. 4 |   | . ag | ə | ə | 317 |   | . ag | g′ | g′ | 42 |   | . agus | ɑgəs | agə(s) | 303 |   | . áit | ɑːt′ | aːt′ | 53 |   | . an | ən | ən | 250 |   | . an | ə | ə | t. 339 |   | . an | (ə)n | n | 496 |   | . ag an | g′en | g′en | t. 78 | aige ’n | . anall | ənəul | (ə)ˈnaul | 111 |   | . anchuid | anəˈxid′ | anə + xid′ | 171 + t. 253 | ana- + chuid | . ann | uːn | aun | 110 |   | . anonn | ənuːn | (ə)ˈnaun | 111 |   | . ansoin | ənsin′ | ənson | 320 | annsan | . ar | eʒ | er′ | 42 |   | . bean | b′an | b′an | 44 |   | . bhean | v′an | v′an | 483 |   | . bhfuil | bil′ | bil′ | 399 |   | . bhí | v′iː | v′iː | 21 |   | . broim | brəim′ | brəim′ | 545 |   | . cadé | d′eː | d′eː | 302 | dé | . chuir | xiʒ | xir′ | 28 |   | . chun | xuːn | xuːn | 308 | chún | . cé | k′eː | k′eː | t. 56 | cia | . conas | kunəs | kunəs | 66 | cionnus | . cuir | kir | kir′ | 260 |   | . déin | t′eːn′ | d′eːn′ | 34 |   | . deir | d′er | d′er′ | 303 |   | . duine | din′ə | din′ə | 77 |   | . dúirt | duːrt′ | duːr′t′ | 72 | adubhairt | . éinne | eːŋ′ə | aiŋ′ə | 106 | aonduine | . fadó | fədoː | fəˈdoː | 62 | fad’ ó | . fear | f′ar | f′ar | 44 |   | . feicim | hek′əm′ | f′ek′əm′ | 553 | faicim | . fhios | (ə)s | ə ŋanəs | 231 | i ngan-fhios | . lig | l′ig′ | l′ig′ | 426 | léig | . lámh | lɑː | laː l′ə, laːv′ | p. 134 n. 2 | láimh lé, láimh | . leis | l′es′ | l′eʃ | 39 |   | . mná | mnɑː | məˈnaː | 227 |   | . ní | n′iː | n′iː | p. 67 n. 2 |   | . orthu | orhə | orhə | 57 | ortha | . raibh | re | re | p. 119 n. 6 |   | . réidh | reː | reːg′ | 36 |   | . siar | s′iər | ʃiər | 180 |   | . suí | siː | siː | 24 | suidhe | . sé | s′e | ʃe | t. 305 |   | . scian | s′g′iən | ʃg′iən | 87 |   | . t-ainm | tan′əm′ | an′əm′ | 44 | ainm | . thine | hin′ə | t′in′ə | 26 + 210 | teine | . thá | hɑː | haː | t. 323 | atá | . trí | t′ʒiː | t′siː | 219 |   | . tú | tu | tuː, tə | 134, 80 |   | . Tá droch-chaoi ar mo chóip féin den alt iontach so le R.A. Breathnach.Breatnach (R. A.): Iarsmaí de Ghaeilig Chontae Chill Choinnigh. In Éigse 26 (1992) pp. 21 42. pic.twitter.com/wkIu4EUBpl . &mdash; Sıonnaċ (@SeaghanSionnach) May 19, 2021 Breatnach, R. A., (1992). ‘Iarsmaí de Ghaeilig Chontae Chill Choinnigh’. In Éigse, 26, pp. 21—42. &#8617; . | Breatnach, R. B., (1947). The Irish of Ring, Co. Waterford: A Phonetic Study. Dublin Institute for Advanced Studies. &#8617; . |",
            "url": "https://jimregan.github.io/notes/irish/kilkenny/waterford/2021/05/19/kilkenny-vs-waterford.html",
            "relUrl": "/irish/kilkenny/waterford/2021/05/19/kilkenny-vs-waterford.html",
            "date": " • May 19, 2021"
        }
        
    
  
    
        ,"post228": {
            "title": "Converting Ó Raghallaigh (2010)",
            "content": "This notebook contains a re-implementation of the &quot;global&quot; phonetiser from Brian Ó Raghallaigh&#39;s Ph.D. thesis using rbg2p, along with the &quot;local&quot; phonetiser for Kerry. . The global phonetiser here is essentially the same as the earlier one, except the output phonemes are lowercase, and there are no spaces between output phonemes, to work around some slight limitations of rbg2p. . Brian Ó Raghallaigh (2010). Multi-dialect phonetisation for Irish text-to-speech synthesis: a modular approach. (Doctoral thesis, Trinity College, Dublin), Appendix B.1 . %%writefile oraghallaigh.g2p CHARACTER_SET &quot;aábcdeéfghiíjklmnoópqrstuúvwxyz&#39;-’&quot; DEFAULT_PHONEME &quot;_&quot; PHONEME_DELIMITER &quot;&quot; VAR CONS [bcdfghjklmnpqrstvwxyz] VAR CONSS [bcdfghjklmnpqrstvwxyz]* VAR CONSP [bcdfghjklmnpqrstvwxyz]+ VAR NONSYLLABIC [ábcdfghjklmnópqrstúvwxyz] // broad future/conditional endings VAR BFCE (á|adh|aidh|aidís|aimid|aimis|ainn|as) // slender future/conditional endings VAR SFCE (eá|eadh|idh|idís|imid|imis|inn) VAR FMP [fmp] VAR LNRP [lnr]+ VAR DNLST [dnlst] VAR RDNLR (rd|rn|rl|rr) VAR VOWEL [aáeéiíoóuú] VAR VOWELS [aáeéiíoóuú]* VAR VOWELP [aáeéiíoóuú]+ // left context short broad vowel VAR LCSBV (ea|io|iu|a|o|u) // left context short slender vowel VAR LCSSV (ai|eai|ei|e|iui|i|oi|ui) // left context broad vowel VAR LCBV (adh|ae|ao|aá|ea|eá|eo|éa|io|iu|iú|ío|oó|uío|ua|u|ú) // left context slender vowel VAR LCSV (aei|aidh|ai|aí|aoi|ái|eai|eái|ei|eoi|e|éi|é|iai|iui|iúi|i|í|oi|ói|uai|ui|uí|úi) VAR LCSVS (aei|aidh|ai|aí|aoi|ái|eai|eái|ei|eoi|e|éi|é|iai|iui|iúi|i|í|oi|ói|uai|ui|uí|úi)* // right context slender vowel VAR RCSV (eai|ea|eái|eá|ei|eoi|eo|e|éa|éi|é|iai|ia|io|iui|iu|iúi|iú|i|ío|í) // left context long vowel VAR LCLV (aei|ae|aoi|ao|ái|á|eái|eá|eoi|eó|eo|éi|é|iúi|iú|ío|í|ói|ó|uío|uí|úi|ú) // left context slender long vowel VAR LCSLV (aei|aidh|aoi|ái|eái|eoi|éi|é|iúi|í|ói|uai|uí|úi) ádh -&gt; aa ái -&gt; aa á -&gt; aa abh -&gt; abh adh -&gt; adh / _ # adh -&gt; ai agh -&gt; ai aei -&gt; ee ae -&gt; ee aíodh -&gt; íodh / _ # aío -&gt; aío aí -&gt; ii aidh -&gt; idh / _ # aidh -&gt; ai aigh -&gt; igh / _ # aigh -&gt; ai aithe -&gt; ithe / _ # ai -&gt; ∅ / # CONSS VOWELS (abh|adh|agh|amh|ódh|ogh|omh|umh) _ CONSP ai -&gt; ∅ / # CONSS (obh|odh) _ CONSP ai -&gt; aa / # CONSS _ RDNLR ai -&gt; a / # CONSS _ ai -&gt; @@ / VOWELP CONSP _ ai -&gt; a amh -&gt; amh / _ # amh -&gt; au aoi -&gt; ao ao -&gt; ao a -&gt; ∅ / # CONSS VOWELS (abh|adh|agh|amh|ódh|ogh|omh|umh) _ CONSP a -&gt; ∅ / # CONSS (obh|odh) _ CONSP # addition a -&gt; ∅ / # CONSS VOWELS ogh _ # omh -&gt; OO / (gc|ch|c) _ (ai|a) r a -&gt; aa / # CONSS _ RDNLR a -&gt; a / # CONSS _ a -&gt; @@ / VOWELP CONSP _ a -&gt; a éa -&gt; ee éi -&gt; ee é -&gt; ee eái -&gt; aa eá -&gt; aa eabh -&gt; abh eadh -&gt; adh / _ # eadh -&gt; au eagh -&gt; ai eai -&gt; a eamh -&gt; amh / _ # eamh -&gt; au / # CONSS _ # VOWEL, or VOWELS ?? ea -&gt; ∅ / # CONSS VOWEL igh _ CONSP ea -&gt; aa / # CONSS _ RDNLR ea -&gt; a / # CONSS _ ea -&gt; @@ / VOWELP CONSP _ ea -&gt; a eidh -&gt; eidh eigh -&gt; eigh ei -&gt; ee / # CONSS _ RDNLR # ei -&gt; ee / # CONSS _ RDNLR NONSYLLABIC ei -&gt; e / # CONSS _ ei -&gt; e eódh -&gt; oo eoi -&gt; oo eó -&gt; oo eo -&gt; oo e -&gt; e / # CONSS _ e -&gt; @@ / VOWELP CONSP _ e -&gt; e íodh -&gt; íodh / _ # ío -&gt; ii í -&gt; ii iadh -&gt; i@ iath -&gt; i@ iai -&gt; i@ ia -&gt; i@ idh -&gt; idh igh -&gt; igh io -&gt; io ithe -&gt; ithe / _ # iúi -&gt; uu iú -&gt; uu iubh -&gt; ubh iumh -&gt; uu iui -&gt; uu iu -&gt; u i -&gt; ∅ / # CONSS VOWEL idh _ CONSP # i -&gt; ∅ / # CONSS VOWEL igh _ CONSP i -&gt; @@ / VOWELP CONSP _ i -&gt; I ódh -&gt; ódh / _ # ói -&gt; oo ó -&gt; oo obh -&gt; obh odh -&gt; odh ogh -&gt; ogh oí -&gt; ii oidh -&gt; oidh oigh -&gt; oigh oi -&gt; oo / # CONSS _ RDNLR oi -&gt; @@ / # VOWELP CONSP _ oi -&gt; oi omh -&gt; omh o -&gt; oo / # CONSS _ RDNLR # o -&gt; oo / # CONSS _ RDNLR NONSYLLABIC o -&gt; o / # VOWELP CONSP _ o -&gt; o úi -&gt; uu ú -&gt; uu uath -&gt; u@ uai -&gt; u@ ua -&gt; u@ ubh -&gt; ubh ue -&gt; e ui -&gt; uu / # CONSS _ RDNLR # ui -&gt; uu / # CONSS _ RDNLR NONSYLLABIC ui -&gt; i / # CONSS _ ui -&gt; @@ / VOWELP CONSP _ ui -&gt; ui uío -&gt; ii uí -&gt; ii umh -&gt; uu u -&gt; uu / # CONSS _ RDNLR u -&gt; u / # CONSS _ u -&gt; @@ / VOWELP CONSP _ u -&gt; u bf -&gt; p / _ BFCE # bf -&gt; pj / _ SFCE # bhf -&gt; vj / # _ CONSS RCSV # bhf -&gt; vj / # _ CONSS RCSV NONSYLLABIC bhf -&gt; v / # _ bhf -&gt; f / _ BFCE # bhf -&gt; fj / _ SFCE # bh -&gt; @@ v / # LCSBV LNRP _ bh -&gt; @@ v / NONSYLLABIC LCSBV LNRP _ bh -&gt; @@ vj / # LCSSV LNRP _ bh -&gt; @@ vj / NONSYLLABIC LCSSV LNRP _ bh -&gt; vj / # _ CONSS RCSV # bh -&gt; vj / # _ CONSS RCSV NONSYLLABIC bh -&gt; v / # _ bh -&gt; vj / _ CONSS RCSV # bh -&gt; vj / _ CONSS RCSV NONSYLLABIC bh -&gt; vj / # LCSV CONSP _ bh -&gt; vj / NONSYLLABIC LCSV CONSP _ bh -&gt; vj / # LCSV _ bh -&gt; vj / NONSYLLABIC LCSV _ bh -&gt; v bp -&gt; bj / # _ CONSS RCSV # bp -&gt; bj / # _ CONSS RCSV NONSYLLABIC bp -&gt; b / # _ bth -&gt; p / LCBV CONSS _ bth -&gt; pj / LCSV CONSS _ b -&gt; @@ b / # LCSBV LNRP _ b -&gt; @@ b / NONSYLLABIC LCSBV LNRP _ b -&gt; @@ bj / # LCSSV LNRP _ b -&gt; @@ bj / NONSYLLABIC LCSSV LNRP _ b -&gt; bj / _ CONSS RCSV # b -&gt; bj / _ CONSS RCSV NONSYLLABIC b -&gt; bj / # LCSV CONSP _ b -&gt; bj / NONSYLLABIC LCSV CONSP _ b -&gt; bj / # LCSV _ b -&gt; bj / NONSYLLABIC LCSV _ b -&gt; b cf -&gt; k / _ BFCE # cf -&gt; kj / _ SFCE # chf -&gt; x / _ BFCE # chf -&gt; xj / _ SFCE # ch -&gt; @@ x / # LCSBV LNRP _ ch -&gt; @@ x / NONSYLLABIC LCSBV LNRP _ ch -&gt; @@ xj / # LCSSV LNRP _ ch -&gt; @@ xj / NONSYLLABIC LCSSV LNRP _ ch -&gt; xj / # _ CONSS RCSV # ch -&gt; xj / # _ CONSS RCSV NONSYLLABIC ch -&gt; x / # _ ch -&gt; xj / _ CONSS RCSV # ch -&gt; xj / _ CONSS RCSV NONSYLLABIC ch -&gt; xj / # LCSV CONSP _ ch -&gt; xj / NONSYLLABIC LCSV CONSP _ ch -&gt; xj / # LCSV _ ch -&gt; xj / NONSYLLABIC LCSV _ ch -&gt; x cth -&gt; k / LCBV CONSS _ cth -&gt; kj / LCSV CONSS _ c -&gt; kj / _ CONSS RCSV # c -&gt; kj / _ CONSS RCSV NONSYLLABIC c -&gt; kj / # LCSV CONSP _ c -&gt; kj / NONSYLLABIC LCSV CONSP _ c -&gt; kj / # LCSV _ c -&gt; kj / NONSYLLABIC LCSV _ c -&gt; k df -&gt; t / _ BFCE # df -&gt; tj / _ SFCE # dha -&gt; ∅ / # LCLV _ dha -&gt; ∅ / NONSYLLABIC LCLV _ dh -&gt; gfj / # LCSLV _ dh -&gt; gfj / NONSYLLABIC LCSLV _ dh -&gt; gfj / # CONSS LCSVS _ # dh -&gt; ∅ / # LCLV _ dh -&gt; ∅ / NONSYLLABIC LCLV _ dh -&gt; gfj / # _ CONSS RCSV # dh -&gt; gfj / # _ CONSS RCSV NONSYLLABIC dh -&gt; gf / # _ dh -&gt; gfj / _ CONSS RCSV # dh -&gt; gfj / _ CONSS RCSV NONSYLLABIC dh -&gt; gfj / # LCSV CONSP _ dh -&gt; gfj / NONSYLLABIC LCSV CONSP _ dh -&gt; gfj / # LCSV _ dh -&gt; gfj / NONSYLLABIC LCSV _ dh -&gt; gf dt -&gt; dj / # _ CONSS RCSV # dt -&gt; dj / # _ CONSS RCSV NONSYLLABIC dt -&gt; d / # _ dt -&gt; t / LCBV CONSS _ dt -&gt; tj / LCSV CONSS _ d -&gt; dj / _ CONSS RCSV # d -&gt; dj / _ CONSS RCSV NONSYLLABIC d -&gt; dj / # LCSV CONSP _ d -&gt; dj / NONSYLLABIC LCSV CONSP _ d -&gt; dj / # LCSV _ d -&gt; dj / NONSYLLABIC LCSV _ d -&gt; d fh -&gt; ∅ f -&gt; h / VOWEL _ BFCE # f -&gt; hj / VOWEL _ SFCE # f -&gt; @@ f / # LCSBV LNRP _ f -&gt; @@ f / NONSYLLABIC LCSBV LNRP _ f -&gt; @@ fj / # LCSSV LNRP _ f -&gt; @@ fj / NONSYLLABIC LCSSV LNRP _ f -&gt; fj / _ CONSS RCSV # f -&gt; fj / _ CONSS RCSV NONSYLLABIC f -&gt; fj / # LCSV CONSP _ f -&gt; fj / NONSYLLABIC LCSV CONSP _ f -&gt; fj / # LCSV _ f -&gt; fj / NONSYLLABIC LCSV _ f -&gt; f gc -&gt; gj / # _ CONSS RCSV # gc -&gt; gj / # _ CONSS RCSV NONSYLLABIC gc -&gt; g / # _ gf -&gt; k / _ BFCE # gf -&gt; kj / _ SFCE # gh -&gt; gfj / # _ CONSS RCSV # gh -&gt; gfj / # _ CONSS RCSV NONSYLLABIC gh -&gt; gf / # _ gh -&gt; gfj / # LCSLV _ gh -&gt; gfj / NONSYLLABIC LCSLV _ gh -&gt; gfj / # CONSS LCSVS _ # gh -&gt; ∅ / # LCLV _ gh -&gt; ∅ / NONSYLLABIC LCLV _ gh -&gt; gfj / _ CONSS RCSV # gh -&gt; gfj / _ CONSS RCSV NONSYLLABIC gh -&gt; gfj / # LCSV CONSP _ gh -&gt; gfj / NONSYLLABIC LCSV CONSP _ gh -&gt; gfj / # LCSV _ gh -&gt; gfj / NONSYLLABIC LCSV _ gh -&gt; gf gth -&gt; k / LCBV CONSS _ gth -&gt; kj / LCSV CONSS _ g -&gt; @@ g / # LCSBV LNRP _ g -&gt; @@ g / NONSYLLABIC LCSBV LNRP _ g -&gt; @@ gj / # LCSSV LNRP _ g -&gt; @@ gj / NONSYLLABIC LCSSV LNRP _ g -&gt; gj / _ CONSS RCSV # g -&gt; gj / _ CONSS RCSV NONSYLLABIC g -&gt; gj / # LCSV CONSP _ g -&gt; gj / NONSYLLABIC LCSV CONSP _ g -&gt; gj / # LCSV _ g -&gt; gj / NONSYLLABIC LCSV _ g -&gt; g h -&gt; hj / _ CONSS RCSV # h -&gt; hj / _ CONSS RCSV NONSYLLABIC h -&gt; hj / # LCSV CONSP _ h -&gt; hj / NONSYLLABIC LCSV CONSP _ h -&gt; hj / # LCSV _ h -&gt; hj / NONSYLLABIC LCSV _ h -&gt; h j -&gt; djzj k -&gt; kj / _ CONSS RCSV # k -&gt; kj / _ CONSS RCSV NONSYLLABIC k -&gt; kj / # LCSV CONSP _ k -&gt; kj / NONSYLLABIC LCSV CONSP _ k -&gt; kj / # LCSV _ k -&gt; kj / NONSYLLABIC LCSV _ k -&gt; k llf -&gt; ll_d / _ BFCE # llf -&gt; llj_d / _ SFCE # llth -&gt; ll_d / LCBV CONSS _ llth -&gt; llj_d / LCSV CONSS _ ll -&gt; llj / _ CONSS RCSV # ll -&gt; llj / _ CONSS RCSV NONSYLLABIC ll -&gt; llj / # LCSV CONSP _ ll -&gt; llj / NONSYLLABIC LCSV CONSP _ ll -&gt; llj / # LCSV _ ll -&gt; llj / NONSYLLABIC LCSV _ ll -&gt; ll lf -&gt; ll_d / _ BFCE # lf -&gt; lj_d / _ SFCE # lth -&gt; ll_d / LCBV CONSS _ lth -&gt; lj_d / LCSV CONSS _ l -&gt; lj / _ CONSS RCSV # l -&gt; lj / _ CONSS RCSV NONSYLLABIC l -&gt; lj / # LCSV CONSP _ l -&gt; lj / NONSYLLABIC LCSV CONSP _ l -&gt; lj / # LCSV _ l -&gt; lj / NONSYLLABIC LCSV _ l -&gt; ll mb -&gt; mj / # _ CONSS RCSV # mb -&gt; mj / # _ CONSS RCSV NONSYLLABIC mb -&gt; m / # _ mf -&gt; m_d / _ BFCE # mf -&gt; mj_d / _ SFCE # mhf -&gt; f / _ BFCE # mhf -&gt; fj / _ SFCE # mh -&gt; vj / # _ CONSS RCSV # mh -&gt; vj / # _ CONSS RCSV NONSYLLABIC mh -&gt; v / # _ mh -&gt; @@ v / # LCSBV LNRP _ mh -&gt; @@ v / NONSYLLABIC LCSBV LNRP _ mh -&gt; @@ vj / # LCSSV LNRP _ mh -&gt; @@ vj / NONSYLLABIC LCSSV LNRP _ mh -&gt; vj / _ CONSS RCSV # mh -&gt; vj / _ CONSS RCSV NONSYLLABIC mh -&gt; vj / # LCSV CONSP _ mh -&gt; vj / NONSYLLABIC LCSV CONSP _ mh -&gt; vj / # LCSV _ mh -&gt; vj / NONSYLLABIC LCSV _ mh -&gt; v mth -&gt; m_d / LCBV CONSS _ mth -&gt; mj_d / LCSV CONSS _ m -&gt; @@ m / # LCSBV LNRP _ m -&gt; @@ m / NONSYLLABIC LCSBV LNRP _ m -&gt; @@ mj / # LCSSV LNRP _ m -&gt; @@ mj / NONSYLLABIC LCSSV LNRP _ m -&gt; mj / _ CONSS RCSV # m -&gt; mj / _ CONSS RCSV NONSYLLABIC m -&gt; mj / # LCSV CONSP _ m -&gt; mj / NONSYLLABIC LCSV CONSP _ m -&gt; mj / # LCSV _ m -&gt; mj / NONSYLLABIC LCSV _ m -&gt; m nnf -&gt; nn_d / _ BFCE # nnf -&gt; nnj_d / _ SFCE # nnth -&gt; nn_d / LCBV CONSS _ nnth -&gt; nnj_d / LCSV CONSS _ nn -&gt; nnj / _ CONSS RCSV # nn -&gt; nnj / _ CONSS RCSV NONSYLLABIC nn -&gt; nnj / # LCSV CONSP _ nn -&gt; nnj / NONSYLLABIC LCSV CONSP _ nn -&gt; nnj / # LCSV _ nn -&gt; nnj / NONSYLLABIC LCSV _ nn -&gt; nn n- -&gt; nj / # _ RCSV # n- -&gt; nj / # _ RCSV NONSYLLABIC n- -&gt; nn / # _ nd -&gt; nnj / # _ CONSS RCSV # nd -&gt; nnj / # _ CONSS RCSV NONSYLLABIC nd -&gt; nn / # _ nf -&gt; nn_d / _ BFCE # nf -&gt; nj_d / _ SFCE # ngf -&gt; ng_d / _ BFCE # ngf -&gt; ngj_d / _ SFCE # ngth -&gt; ng_d / LCBV CONSS _ ngth -&gt; ngj_d / LCSV CONSS _ ng -&gt; ngj / # _ CONSS RCSV # ng -&gt; ngj / # _ CONSS RCSV NONSYLLABIC ng -&gt; ng / # _ ng -&gt; nj / # LCSV _ t # ng -&gt; nj / NONSYLLABIC LCSV _ t # ng -&gt; ngj / _ CONSS RCSV # ng -&gt; ngj / _ CONSS RCSV NONSYLLABIC ng -&gt; ngj / # LCSV CONSP _ ng -&gt; ngj / NONSYLLABIC LCSV CONSP _ ng -&gt; ngj / # LCSV _ ng -&gt; ngj / NONSYLLABIC LCSV _ ng -&gt; ng nth -&gt; nn_d / LCBV CONSS _ nth -&gt; nj_d / LCSV CONSS _ n -&gt; ngj / # LCSV _ c n -&gt; ngj / NONSYLLABIC LCSV _ c n -&gt; ng / _ c n -&gt; nj / _ CONSS RCSV # n -&gt; nj / _ CONSS RCSV NONSYLLABIC n -&gt; nj / # LCSV CONSP _ n -&gt; nj / NONSYLLABIC LCSV CONSP _ n -&gt; nj / # LCSV _ n -&gt; nj / NONSYLLABIC LCSV _ n -&gt; nn pf -&gt; p / _ BFCE # pf -&gt; pj / _ SFCE # ph -&gt; fj / # _ CONSS RCSV # ph -&gt; fj / # _ CONSS RCSV NONSYLLABIC ph -&gt; f / # _ ph -&gt; fj / _ CONSS RCSV # ph -&gt; fj / _ CONSS RCSV NONSYLLABIC ph -&gt; fj / # LCSV CONSP _ ph -&gt; fj / NONSYLLABIC LCSV CONSP _ ph -&gt; fj / # LCSV _ ph -&gt; fj / NONSYLLABIC LCSV _ ph -&gt; f pth -&gt; p / LCBV CONSS _ pth -&gt; pj / LCSV CONSS _ p -&gt; pj / _ CONSS RCSV # p -&gt; pj / _ CONSS RCSV NONSYLLABIC p -&gt; pj / # LCSV CONSP _ p -&gt; pj / NONSYLLABIC LCSV CONSP _ p -&gt; pj / # LCSV _ p -&gt; pj / NONSYLLABIC LCSV _ p -&gt; p # really? there&#39;s a &#39;W&#39; in the phoneset q -&gt; k v rrf -&gt; rr_d / _ BFCE # rrf -&gt; rrj_d / _ SFCE # rrth -&gt; rr_d / LCBV CONSS _ rrth -&gt; rrj_d / LCSV CONSS _ rr -&gt; rrj / _ CONSS RCSV # rr -&gt; rrj / _ CONSS RCSV NONSYLLABIC rr -&gt; rrj / # LCSV CONSP _ rr -&gt; rrj / NONSYLLABIC LCSV CONSP _ rr -&gt; rrj / # LCSV _ rr -&gt; rrj / NONSYLLABIC LCSV _ rr -&gt; rr rf -&gt; r_d / _ BFCE # rf -&gt; rj_d / _ SFCE # rth -&gt; r_d / LCBV CONSS _ rth -&gt; rj_d / LCSV CONSS _ r -&gt; r / # s _ r -&gt; r / # _ r -&gt; r / _ DNLST r -&gt; rj / _ CONSS RCSV # r -&gt; rj / _ CONSS RCSV NONSYLLABIC r -&gt; rj / # LCSV CONSP _ r -&gt; rj / NONSYLLABIC LCSV CONSP _ r -&gt; rj / # LCSV _ r -&gt; rj / NONSYLLABIC LCSV _ r -&gt; r sf -&gt; s / _ BFCE # sf -&gt; sj / _ SFCE # shl -&gt; lj_d / _ CONSS RCSV # shl -&gt; lj_d / _ CONSS RCSV NONSYLLABIC shl -&gt; ll_d shm -&gt; mj_d / _ CONSS RCSV # shm -&gt; mj_d / _ CONSS RCSV NONSYLLABIC shm -&gt; m_d shn -&gt; nj_d / _ CONSS RCSV # shn -&gt; nj_d / _ CONSS RCSV NONSYLLABIC shn -&gt; nn_d shr -&gt; rj_d / _ CONSS RCSV # shr -&gt; rj_d / _ CONSS RCSV NONSYLLABIC shr -&gt; r_d sh -&gt; xj / # _ CONSS RCSV # sh -&gt; xj / # _ CONSS RCSV NONSYLLABIC sh -&gt; h / # _ sh -&gt; xj / _ CONSS RCSV # sh -&gt; xj / _ CONSS RCSV NONSYLLABIC sh -&gt; xj / # LCSV CONSP _ sh -&gt; xj / NONSYLLABIC LCSV CONSP _ sh -&gt; xj / # LCSV _ sh -&gt; xj / NONSYLLABIC LCSV _ sh -&gt; h s -&gt; s / # _ r s -&gt; s / # _ FMP CONSS RCSV # s -&gt; s / # _ FMP CONSS RCSV NONSYLLABIC s -&gt; sj / _ CONSS RCSV # s -&gt; sj / _ CONSS RCSV NONSYLLABIC s -&gt; sj / # LCSV CONSP _ s -&gt; sj / NONSYLLABIC LCSV CONSP _ s -&gt; sj / # LCSV _ s -&gt; sj / NONSYLLABIC LCSV _ s -&gt; s t- -&gt; tj / # _ RCSV # t- -&gt; tj / # _ RCSV NONSYLLABIC t- -&gt; t / # _ tf -&gt; t / _ BFCE # tf -&gt; tj / _ SFCE # // &quot;hack for compound boundaries&quot; th -&gt; ∅ / _ CONS h thb -&gt; pj / _ CONSS RCSV # thb -&gt; pj / _ CONSS RCSV NONSYLLABIC thb -&gt; p thc -&gt; kj / _ CONSS RCSV # thc -&gt; kj / _ CONSS RCSV NONSYLLABIC thc -&gt; k thd -&gt; tj / _ CONSS RCSV # thd -&gt; tj / _ CONSS RCSV NONSYLLABIC thd -&gt; t thf -&gt; h / _ BFCE # thf -&gt; xj / _ SFCE # thl -&gt; lj_d / _ CONSS RCSV # thl -&gt; lj_d / _ CONSS RCSV NONSYLLABIC thl -&gt; ll_d thm -&gt; mj_d / _ CONSS RCSV # thm -&gt; mj_d / _ CONSS RCSV NONSYLLABIC thm -&gt; m_d thn -&gt; nj_d / _ CONSS RCSV # thn -&gt; nj_d / _ CONSS RCSV NONSYLLABIC thn -&gt; nn_d thp -&gt; pj / _ CONSS RCSV # thp -&gt; pj / _ CONSS RCSV NONSYLLABIC thp -&gt; p thr -&gt; rj_d / _ CONSS RCSV # thr -&gt; rj_d / _ CONSS RCSV NONSYLLABIC thr -&gt; r_d ths -&gt; sj / _ CONSS RCSV # ths -&gt; sj / _ CONSS RCSV NONSYLLABIC ths -&gt; s tht -&gt; tj / _ CONSS RCSV # tht -&gt; tj / _ CONSS RCSV NONSYLLABIC tht -&gt; t th -&gt; hj / # _ CONSS RCSV # th -&gt; hj / # _ CONSS RCSV NONSYLLABIC th -&gt; h / # _ th -&gt; hj / _ CONSS RCSV # th -&gt; hj / _ CONSS RCSV NONSYLLABIC th -&gt; hj / # LCSV CONSP _ th -&gt; hj / NONSYLLABIC LCSV CONSP _ th -&gt; hj / # LCSV _ th -&gt; hj / NONSYLLABIC LCSV _ th -&gt; h ts -&gt; tj / # _ CONSS RCSV # ts -&gt; tj / # _ CONSS RCSV NONSYLLABIC ts -&gt; t / # _ t -&gt; tj / _ CONSS RCSV # t -&gt; tj / _ CONSS RCSV NONSYLLABIC t -&gt; tj / # LCSV CONSP _ t -&gt; tj / NONSYLLABIC LCSV CONSP _ t -&gt; tj / # LCSV _ t -&gt; tj / NONSYLLABIC LCSV _ t -&gt; t v -&gt; vj / _ CONSS RCSV # v -&gt; vj / _ CONSS RCSV NONSYLLABIC v -&gt; vj / # LCSV CONSP _ v -&gt; vj / NONSYLLABIC LCSV CONSP _ v -&gt; vj / # LCSV _ v -&gt; vj / NONSYLLABIC LCSV _ v -&gt; v w -&gt; v x- -&gt; e kj s x -&gt; zj y -&gt; gfj z -&gt; zj / _ CONSS RCSV # z -&gt; zj / _ CONSS RCSV NONSYLLABIC z -&gt; zj / # LCSV CONSP _ z -&gt; zj / NONSYLLABIC LCSV CONSP _ z -&gt; zj / # LCSV _ z -&gt; zj / NONSYLLABIC LCSV _ z -&gt; z &#39; -&gt; ∅ ’ -&gt; ∅ - -&gt; ∅ TEST ádh -&gt; aa TEST áiseanna -&gt; aa sj @@ nn @@ TEST áthas -&gt; aa h @@ s TEST abhainn -&gt; abh nnj TEST bualadh -&gt; b u@ ll adh TEST sadhbh -&gt; s ai v TEST saghas -&gt; s ai s TEST gaeilge -&gt; g ee lj gj @@ TEST saolaíodh -&gt; s ao ll íodh TEST gardaí -&gt; g aa r d ii TEST dúnfaidh -&gt; d uu nn_d idh TEST aidhm -&gt; ai mj TEST cheadaigh -&gt; xj a d igh TEST aighneas -&gt; ai nj @@ s TEST diúltaithe -&gt; dj uu ll t ithe TEST seabhaic -&gt; sj abh kj TEST feadhain -&gt; fj au nj TEST teaghais -&gt; tj ai sj TEST eamhain -&gt; au nj TEST lobhair -&gt; ll obh rj TEST leódhais -&gt; lj oo sj TEST bodhair -&gt; b odh rj TEST eoghain -&gt; oo nj TEST broghais -&gt; b r ogh sj TEST comhair -&gt; k oo rj TEST ciumhais -&gt; kj uu sj TEST airde -&gt; aa r dj @@ TEST cait -&gt; k a tj TEST sodair -&gt; s o d @@ rj TEST ait -&gt; a tj TEST déanamh -&gt; dj ee nn amh TEST amharc -&gt; au r k TEST gaoil -&gt; g ao lj TEST gaol -&gt; g ao ll TEST seabhac -&gt; sj abh k TEST ceadharlach -&gt; kj au r ll @@ x TEST teaghasán -&gt; tj ai s aa nn TEST lobhar -&gt; ll obh r TEST leódhas -&gt; lj oo s TEST bodhar -&gt; b odh r TEST eoghan -&gt; oo nn TEST bogha -&gt; b ogh TEST comhar -&gt; k oo r TEST dumhach -&gt; d uu x TEST ard -&gt; aa r d TEST cat -&gt; k a t TEST sodar -&gt; s o d @@ r TEST at -&gt; a t TEST éan -&gt; ee nn TEST éiníní -&gt; ee nj ii nj ii TEST é -&gt; ee TEST sheáin -&gt; xj aa nj TEST seán -&gt; sj aa nn TEST seabhac -&gt; sj abh k TEST seinneadh -&gt; sj e nnj adh TEST ceadharlach -&gt; kj au r ll @@ x TEST teaghlach -&gt; tj ai ll @@ x TEST beairic -&gt; bj a rj @@ kj TEST áireamh -&gt; aa rj amh TEST sleamhnán -&gt; sj lj au nn aa nn TEST oighear -&gt; oigh r TEST ceard -&gt; kj aa r d TEST cead -&gt; kj a d TEST áireamhán -&gt; aa rj @@ v aa nn TEST eas -&gt; a s TEST feidhm -&gt; fj eidh mj TEST leigheas -&gt; lj eigh s TEST ceird -&gt; kj ee r dj TEST deis -&gt; dj e sj TEST eitpheil -&gt; e tj fj e lj TEST ceoil -&gt; kj oo lj TEST bainseó -&gt; b a nj sj oo TEST ceol -&gt; kj oo ll TEST uile -&gt; i lj @@ TEST ceannaíodh -&gt; kj a nn íodh TEST síos -&gt; sj ii s TEST sí -&gt; sj ii TEST siadhail -&gt; sj i@ lj TEST sciath -&gt; sj kj i@ TEST riail -&gt; r i@ lj TEST siad -&gt; sj i@ d TEST seinnfidh -&gt; sj e nnj_d idh TEST cheannaigh -&gt; xj a nn igh TEST fios -&gt; fj io s TEST imithe -&gt; i mj ithe TEST siúil -&gt; sj uu lj TEST siúl -&gt; sj uu ll TEST tiubh -&gt; tj ubh TEST ciumhais -&gt; kj uu sj TEST giuirléid -&gt; gj uu r lj ee dj TEST fiuch -&gt; fj u x TEST leighis -&gt; lj eigh sj TEST foighid -&gt; f oigh dj TEST aithris -&gt; a rj_d @@ sj TEST sin -&gt; sj i nj TEST cheannódh -&gt; xj a nn ódh TEST óil -&gt; oo lj TEST ól -&gt; oo ll TEST lobhadh -&gt; ll obh adh TEST todhchaí -&gt; t odh x ii TEST toghadh -&gt; t ogh adh TEST oíche -&gt; ii xj @@ TEST oidhe -&gt; oidh @@ TEST oighear -&gt; oigh r TEST boird -&gt; b oo r dj TEST soir -&gt; s oi rj TEST comhar -&gt; k oo r TEST bord -&gt; b oo r d TEST bos -&gt; b o s TEST súil -&gt; s uu lj TEST súl -&gt; s uu ll TEST uathúil -&gt; u@ uu lj TEST uaine -&gt; u@ nj @@ TEST uan -&gt; u@ nn TEST subh -&gt; s ubh TEST bhuel -&gt; v e ll TEST guird -&gt; g uu r dj TEST cuid -&gt; k i dj TEST uile -&gt; i lj @@ TEST bruíon -&gt; b r ii nn TEST bruíne -&gt; b r ii nj @@ TEST cumhacht -&gt; k uu x t TEST burdún -&gt; b uu r d uu nn TEST cur -&gt; k u r TEST bus -&gt; b u s TEST scuabfaidh -&gt; s k u@ p idh TEST clibfidh -&gt; kj lj i pj idh TEST scuabfadh -&gt; s k u@ p adh TEST clibfeadh -&gt; kj lj i pj adh TEST bhfáinne -&gt; v aa nnj @@ TEST bhfianaise -&gt; vj i@ nn @@ sj @@ TEST scríobhfaidh -&gt; sj kj rj ii f idh TEST díbhfidh -&gt; dj ii fj idh TEST scríobhfadh -&gt; sj kj rj ii f adh TEST díbhfeadh -&gt; dj ii fj adh TEST searbh -&gt; sj a r @@ v TEST seirbhís -&gt; sj e rj @@ vj ii sj TEST bhrostaigh -&gt; v r o s t igh TEST bhris -&gt; vj rj i sj TEST coibhín -&gt; k oi vj ii nj TEST bpáistí -&gt; b aa sj tj ii TEST bpéisteanna -&gt; bj ee sj tj @@ nn @@ TEST scuabtha -&gt; s k u@ p @@ TEST clibthe -&gt; kj lj i pj @@ TEST borb -&gt; b o r @@ b TEST seirbiach -&gt; sj e rj @@ bj i@ x TEST bróna -&gt; b r oo nn @@ TEST brian -&gt; bj rj i@ nn TEST leódhas -&gt; lj oo s TEST t-uisce -&gt; t ui sj kj @@ TEST t-éabhlóidí -&gt; tj ee v ll oo dj ii TEST atfaidh -&gt; a t idh TEST titfidh -&gt; tj i tj idh TEST athdhéanamh -&gt; a gfj ee nn amh TEST meathfadh -&gt; mj a h adh TEST rithfeadh -&gt; r i xj adh TEST bláthra -&gt; b ll aa r_d @@ TEST tharla -&gt; h aa r ll @@ TEST thit -&gt; hj i tj TEST tseachtain -&gt; tj a x t @@ nj TEST tsagairt -&gt; t a g @@ r tj TEST teann -&gt; tj a nn TEST tit -&gt; tj i tj TEST togra -&gt; t o g r @@ TEST sadhbh -&gt; s ai v TEST bhéal -&gt; vj ee ll TEST bhéil -&gt; vj ee lj . %%writefile oraghallaigh-cd.g2p CHARACTER_SET &quot;abcdefghiíjklmnoóprstuvwxz@.012-_&quot; DEFAULT_PHONEME &quot;_&quot; PHONEME_DELIMITER &quot; &quot; VAR BC (p|b|f|v|m_d|m|t_|t|d_|d|ll_d|ll|l_d|l|nn_d|nn|n_d|n|rr_d|r_d|rr|r|s|z|k|g|x|gf|ng_d|ng|h) VAR LLJ (llj|nnj|rrj|mj) VAR LL (ll|nn|rr|m) aa -&gt; aa abh -&gt; au adh -&gt; @ x agh -&gt; ai aío -&gt; i@ amh -&gt; @ v ai -&gt; ai ao -&gt; ee au -&gt; au a -&gt; ai / _ LLJ a -&gt; au / _ LL a -&gt; a ee -&gt; i@ / _ BC ee -&gt; ee eidh -&gt; e gj / _ # eidh -&gt; ai eigh -&gt; ai e -&gt; e idh -&gt; @ gj igh -&gt; @ gj íodh -&gt; i@ x ithe -&gt; @ . 0 h @ i@ -&gt; i@ ii -&gt; ii io -&gt; i i -&gt; ii / _ LLJ # i -&gt; i obh -&gt; au ódh -&gt; oo x odh -&gt; au ogh -&gt; au oidh -&gt; ai oigh -&gt; ai oi -&gt; ii / _ LLJ # oi -&gt; i omh -&gt; au oo -&gt; oo o -&gt; au / _ LL # o -&gt; o ubh -&gt; u v / _ # ubh -&gt; @ v u@ -&gt; u@ ui -&gt; ii / _ LLJ ui -&gt; i uu -&gt; uu u -&gt; u @@ -&gt; @ pj -&gt; pj p -&gt; p bj -&gt; bj b -&gt; b fj -&gt; fj f -&gt; f vj -&gt; vj v -&gt; v w -&gt; w mj_d -&gt; mj_d m_d -&gt; m_d mj -&gt; mj m -&gt; m tjsj -&gt; tjsj djzj -&gt; djzj t_- -&gt; t_- tj -&gt; tj t -&gt; t d_- -&gt; d_- dj -&gt; dj d -&gt; d llj_d -&gt; lj_d ll_d -&gt; l_d llj -&gt; lj ll -&gt; l lj_d -&gt; lj_d l_d -&gt; l_d lj -&gt; lj l -&gt; l nnj_d -&gt; nj_d nn_d -&gt; n_d nnj -&gt; nj nn -&gt; n nj_d -&gt; nj_d n_d -&gt; n_d rrj_d -&gt; rj_d rj_d -&gt; rj_d rr_d -&gt; r_d r_d -&gt; r_d rrj -&gt; rj rj -&gt; rj rr -&gt; r r -&gt; r sj -&gt; sj s -&gt; s zj -&gt; zj z -&gt; z kj -&gt; kj k -&gt; k gj -&gt; gj g -&gt; g xj -&gt; xj x -&gt; x gfj -&gt; ∅ / _ # gfj -&gt; gfj ngj_d -&gt; ngj h ng_d -&gt; ng h ngj -&gt; nj / _ # ngj -&gt; ngj ng -&gt; ng nj -&gt; nj n -&gt; n hj -&gt; h h -&gt; h 0 -&gt; 0 1 -&gt; 1 2 -&gt; 2 . -&gt; . - -&gt; ∅ @ -&gt; ∅ c -&gt; ∅ j -&gt; ∅ í -&gt; ∅ ó -&gt; ∅ _ -&gt; ∅ TEST faas -&gt; f aa s TEST abhnnj -&gt; au nj TEST saghd -&gt; s ai d TEST saíoxt -&gt; s i@ x t TEST djeennamh -&gt; dj ee n @ v TEST taig -&gt; t ai g TEST saoll -&gt; s ee l TEST saulj -&gt; s au lj TEST kallj -&gt; k ai lj TEST krann -&gt; k r au n TEST kad -&gt; k a d TEST eenn -&gt; i@ n TEST sjee -&gt; sj ee TEST beidh -&gt; b e gj TEST fjeidhmj -&gt; fj ai mj TEST ljeighs -&gt; lj ai s TEST djesj -&gt; dj e sj TEST bjrjisjidh -&gt; bj rj i sj @ gj TEST xjannigh -&gt; xj a n @ gj TEST kjanníodh -&gt; kj a n i@ x TEST kjannithe -&gt; kj a n @ h @ TEST i@rr -&gt; i@ r TEST sjiinj -&gt; sj ii nj TEST fjios -&gt; fj i s TEST imj -&gt; ii mj TEST sjinj -&gt; sj i nj TEST llobhr -&gt; l au r TEST kjannódh -&gt; kj a n oo x TEST bodhr -&gt; b au r TEST toghxaann -&gt; t au x aa n TEST oidhrjaxt -&gt; ai rj a x t TEST oighr -&gt; ai r TEST koillj -&gt; k ii lj TEST koillj@@ -&gt; k i lj @ TEST domhnn -&gt; d au n TEST moor -&gt; m oo r TEST poll -&gt; p au l TEST polladh -&gt; p o l @ x TEST ubh@@gaann -&gt; @ v @ g aa n TEST bu@ -&gt; b u@ TEST suimj -&gt; s ii mj TEST kuidj -&gt; k i dj TEST kuur -&gt; k uu r TEST kur -&gt; k u r TEST farjsj@@ngj -&gt; f a rj sj @ nj .",
            "url": "https://jimregan.github.io/notes/irish/g2p/kerry/2021/05/17/o-raghallaigh-thesis-attempt-2-cd.html",
            "relUrl": "/irish/g2p/kerry/2021/05/17/o-raghallaigh-thesis-attempt-2-cd.html",
            "date": " • May 17, 2021"
        }
        
    
  
    
        ,"post229": {
            "title": "Kilkenny Irish example",
            "content": "Scéal beagán i nGaeilig Osraí (Contae Chill Choinnigh). pic.twitter.com/KhG3fd7fkE . &mdash; Corbmacc (@erisceres) May 17, 2021 The picture is nice; transcriptions are better: . v′iː toːrə uːn fədoː ɑgəs v′i anəˈxid′ mnɑː eg′ən toːrə, ɑgəs v′iː s′iəd ə siː eʒ ə loxdə, ən ɑːt′ ə re n toːrə. wel′, l′ig′ din′ə brəim′ ɑgəs n′iː res eg′ eːŋ′ə k′eː l′ig′ ən brəim′ duːrt′ f′ar ə v′iː g′en toːrə ‘wel′’, ə d′er s′e, ‘ən b′an ə l′ig′ ə brəim′ hɑː kəip′ t′ʒiː hin′ə’ ənsin′ xiʒ ən v′an ǝ lɑː s′iər xuːn ə kəip′, ɑgǝs v′iːs əku el′ə (ə)nsin′ ən b′an ə l′ig′ ən brəim′. . Bhí tórramh ann fadó agus bhí anchuid mná ag an tórramh, agus bhí siad ag suí ar an lochta, an áit a raibh an tórramh. Well, lig duine broim agus ní raibh a fhios ag éinne cé lig an broim. Dúirt fear a bhí ag an tórramh ‘Well’, a deir sé, ‘an bean (sic) a lig an broim, thá a caidhp trí thine.’ Ansoin chuir an bhean a lámh siar chun a caidhp, agus bhí a fhios acu uile ansoin an bean a lig an broim. .",
            "url": "https://jimregan.github.io/notes/irish/twitter/kilkenny/2021/05/17/kilkenny-irish.html",
            "relUrl": "/irish/twitter/kilkenny/2021/05/17/kilkenny-irish.html",
            "date": " • May 17, 2021"
        }
        
    
  
    
        ,"post230": {
            "title": "Ó Raghallaigh in ICU",
            "content": "$wb=[^[:L:][:M:]]; $alpha = [abcdefghijklmnopqrstuvwxyz]; $cons = [bcdfghjklmnpqrstvwxyz]; $nonsyllabic = [ábcdfghjklmnópqrstúvwxyz#] # broad future/conditional endings $bfce = [á{adh}{aidh}{aidís}{aimid}{aimis}{ainn}{as}]; # slender future/conditional endings $sfce = [{eá}{eadh}{idh}{idís}{imid}{imis}{inn}]; $l = [{ll}l]; $mn = [mn]; $fmp = [fmp]; $lnr = [lnr]; $lrst = [lrst]; $dnlst = [dnlst]; $dnst = [dnst]; $rdnlr = [{rd}{rn}{rl}{rr}]; $vowel = [aáeéiíoóuú]; # left context short broad vowel $lcsbv = [{ea}{io}{iu}aou]; # left context short slender vowel $lcssv = [{ai}{eai}{ei}e{iui}i{oi}{ui}]; # left context broad vowel $lcbv = [{adh}{ae}{ao}aá{ea}{eá}{eo}{éa}{io}{iu}{iú}{ío}oó{uío}uú]; # right context broad vowel $rcbv = [{aei}{ae}{ai}{aoi}{ao}{a}{ái}á{oi}o{ói}ó{ui}{uío}{uí}u{úi}ú]; # left context slender vowel $lcsv = [{aei}{aidh}{ai}{aí}{aoi}{ái}{eai}{eái}{ei}{eoi}e{éi}é{iai}{iui}{iúi}ií{oi}{ói}{uai}{ui}{uí}{úi}]; # right context slender vowel $rcsv = [{aei}{ea}{eái}{eá}{ei}{eoi}e{éa}{éi}é{iai}{ia}{io}{iui}{iu}{iúi}{iú}i{ío}í]; # left context long vowel $lclv = [{aei}{ae}{aoi}{ao}{ái}{á}{eái}{eá}{eoi}{eó}{eo}{éi}é{iúi}{iú}{ío}í{ói}ó{uío}{uí}{úi}ú]; # left context slender long vowel $lcslv = [{aei}{aidh}{aoi}{ái}{eái}{eoi}{éi}é{iúi}í{ói}{uai}{uí}{úi}]; ádh → AA _; ái → AA _; á → AA _; abh → ABH _; adh } $wb → ADH _; adh → AI _; agh → AI _; aei → EE _; ae → EE _; aíodh } $wb → ÍODH; aío → AÍO _; aí → II _; aidh } $wb → IDH; aidh → AI _; aigh } $wb → IGH; aigh → AI _; aithe } $wb → ITHE; $wb $cons* $vowel* abh { ai } $cons+ → &#39;&#39;; $wb $cons* $vowel* adh { ai } $cons+ → &#39;&#39;; $wb $cons* $vowel* agh { ai } $cons+ → &#39;&#39;; $wb $cons* $vowel* amh { ai } $cons+ → &#39;&#39;; $wb $cons* obh { ai } $cons+ → &#39;&#39;; $wb $cons* $vowel* ódh { ai } $cons+ → &#39;&#39;; $wb $cons* odh { ai } $cons+ → &#39;&#39;; $wb $cons* $vowel* ogh { ai } $cons+ → &#39;&#39;; $wb $cons* $vowel* omh { ai } $cons+ → &#39;&#39;; $wb $cons* $vowel* umh { ai } $cons+ → &#39;&#39;; $wb $cons* { ai } $rdnlr → AA _; $wb $cons* { ai → A _; $vowel+ $cons+ { ai → @@; ai → A; amh { $wb → AMH; amh → AU _; aoi → AO; ao → AO; $wb $cons* $vowel* abh { a } $cons+ → &#39;&#39;; $wb $cons* $vowel* adh { a } $cons+ → &#39;&#39;; $wb $cons* $vowel* agh { a } $cons+ → &#39;&#39;; $wb $cons* $vowel* amh { a } $cons+ → &#39;&#39;; $wb $cons* obh { a } $cons+ → &#39;&#39;; $wb $cons* $vowel* ódh { a } $cons+ → &#39;&#39;; $wb $cons* odh { a } $cons+ → &#39;&#39;; $wb $cons* $vowel* ogh { a } $cons+ → &#39;&#39;; $wb $cons* $vowel* omh { a } $cons+ → &#39;&#39;; $wb $cons* $vowel* umh { a } $cons+ → &#39;&#39;; $wb $cons* { a } $rdnlr → AA _; $wb $cons* { a → A _; $vowel+ $cons+ { a → @ _; a → A _; éa → EE _; éi → EE _; é → EE _; eái → AA _; eá → AA _; eabh → ABH _; eadh } $wb → ADH; eadh → AU _; eagh → AI _; eai → A _; eamh } $wb → AMH; $wb $cons* eamh → AU _; $wb $cons* $vowel igh { ea } $cons+ → &#39;&#39;; . abhainn ABH NNJ bualadh B U@ LL ADH sadhbh S AI V saghas S AI S gaeilge G EE LJ GJ @@ saolaíodh S AO LL ÍODH gardaí G AA R D II dúnfaidh D UU NN_D IDH aidhm AI MJ cheadaigh XJ A D IGH aighneas AI NJ @@ S diúltaithe DJ UU LL T ITHE seabhaic SJ ABH KJ feadhain FJ AU NJ teaghais TJ AI SJ eamhain AU NJ lobhair LL OBH RJ leódhais LJ OO SJ bodhair B ODH RJ eoghain OO NJ broghais B R OGH SJ comhair K OO RJ ciumhais KJ UU SJ airde AA RJ DJ @@ cait K A TJ sodair S O D @@ RJ ait A TJ déanamh DJ EE NN AMH amharc AU R K gaoil G AO LJ gaol G AO L seabhac SJ ABH K ceadharlach KJ AU R LL @@ X teaghasán TJ AI S AA NN lobhar LL OBH R leódhas LL OO S bodhar B ODH R eoghan OO NN bogha B OGH comhar K OO R dumhach D UU X ard AA R D cat K A T sodar S O D @@ R at A T éan EE NN éiníní EE NJ II NJ II é EE .",
            "url": "https://jimregan.github.io/notes/irish/g2p/incomplete/2021/05/16/oraghallaigh-icu.html",
            "relUrl": "/irish/g2p/incomplete/2021/05/16/oraghallaigh-icu.html",
            "date": " • May 16, 2021"
        }
        
    
  
    
        ,"post231": {
            "title": "Converting Ó Raghallaigh (2010)",
            "content": "This notebook contains a re-implementation of the &quot;global&quot; phonetiser from Brian Ó Raghallaigh&#39;s Ph.D. thesis using rbg2p. . Brian Ó Raghallaigh (2010). Multi-dialect phonetisation for Irish text-to-speech synthesis: a modular approach. (Doctoral thesis, Trinity College, Dublin), Appendix B.1 . @phdthesis{oraghallaigh2010multidialect, author = {Brian Ó~Raghallaigh}, title = {Multi-dialect phonetisation for {I}rish text-to-speech synthesis: a modular approach}, school = {Trinity College, Dublin}, year = 2010, address = {Dublin, Ireland}, month = 9, } . The initial run (after small conversion errors were corrected) gave the following set of errors: . FAILED TEST: for &#39;comhair&#39;, expected /K OO RJ/, got /K OMH RJ/ FAILED TEST: for &#39;airde&#39;, expected /AA RJ DJ @@/, got /AA R DJ @@/ FAILED TEST: for &#39;bogha&#39;, expected /B OGH/, got /B OGH @@/ FAILED TEST: for &#39;comhar&#39;, expected /K OO R/, got /K OMH R/ FAILED TEST: for &#39;ceird&#39;, expected /KJ EE RJ DJ/, got /KJ EE R DJ/ FAILED TEST: for &#39;riail&#39;, expected /RJ I@ LJ/, got /R I@ LJ/ FAILED TEST: for &#39;giuirléid&#39;, expected /GJ UU RJ LJ EE DJ/, got /GJ UU R LJ EE DJ/ FAILED TEST: for &#39;boird&#39;, expected /B OO RJ DJ/, got /B OO R DJ/ FAILED TEST: for &#39;bantaboic&#39;, expected /B A NN T @@ B @@ KJ/, got /B A NN T @@ B OI KJ/ FAILED TEST: for &#39;comhar&#39;, expected /K OO R/, got /K OMH R/ FAILED TEST: for &#39;bantaboc&#39;, expected /B A NN T @@ B @@ K/, got /B A NN T @@ B O K/ FAILED TEST: for &#39;guird&#39;, expected /G UU RJ DJ/, got /G UU R DJ/ FAILED TEST: for &#39;bhfianaise&#39;, expected /VJ I@ NN @@ SJ @@/, got /V I@ NN @@ SJ @@/ FAILED TEST: for &#39;leathbhosca&#39;, expected /LJ A V @@ S K @@/, got /LJ A V O S K @@/ FAILED TEST: for &#39;rithfeadh&#39;, expected /RJ I XJ ADH/, got /R I XJ ADH/ FAILED TEST: for &#39;tsagairt&#39;, expected /T A G @@ RJ TJ/, got /T A G @@ R TJ/ 16 OF 168 TESTS FAILED FOR briain.g2p exit status 1 . The most consistent source of errors is slender &#39;r&#39; in environments (word initially, before &#39;d&#39;, etc.) where the rule is that they should be left broad; I corrected the tests (which were intended only as tests of the vowels). . Of the remainder, bogha represents a missing rule, while comhar/comhair does not fit with the given rule, so I added a somewhat lexicalised rule to handle it (and its mutated forms) specifically. . This leaves these words: . FAILED TEST: for &#39;bantaboic&#39;, expected /B A NN T @@ B @@ KJ/, got /B A NN T @@ B OI KJ/ FAILED TEST: for &#39;bantaboc&#39;, expected /B A NN T @@ B @@ K/, got /B A NN T @@ B O K/ FAILED TEST: for &#39;leathbhosca&#39;, expected /LJ A V @@ S K @@/, got /LJ A V O S K @@/ . leathbhosca is a compound, and keeping bhosca as V O S K @@ is correct; otherwise, the rule which for other short vowels converts to schwa is specifically converted to O, so I disabled these rules. . %%writefile oraghallaigh.g2p CHARACTER_SET &quot;aábcdeéfghiíjklmnoópqrstuúvwxyz&#39;-’&quot; DEFAULT_PHONEME &quot;_&quot; PHONEME_DELIMITER &quot; &quot; #VAR ALPHA [abcdefghijklmnopqrstuvwxyz] VAR CONS [bcdfghjklmnpqrstvwxyz] VAR CONSS [bcdfghjklmnpqrstvwxyz]* VAR CONSP [bcdfghjklmnpqrstvwxyz]+ # including &#39;#&#39; doesn&#39;t work, so those rules were duplicated #VAR NONSYLLABIC (á|b|c|d|f|g|h|j|k|l|m|n|ó|p|q|r|s|t|ú|v|w|x|y|z|#) VAR NONSYLLABIC [ábcdfghjklmnópqrstúvwxyz] // broad future/conditional endings VAR BFCE (á|adh|aidh|aidís|aimid|aimis|ainn|as) // slender future/conditional endings VAR SFCE (eá|eadh|idh|idís|imid|imis|inn) #VAR L (ll|l) #VAR MN [mn] VAR FMP [fmp] #VAR LNR [lnr] VAR LNRP [lnr]+ #VAR LRST [lrst] VAR DNLST [dnlst] #VAR DNST [dnst] VAR RDNLR (rd|rn|rl|rr) VAR VOWEL [aáeéiíoóuú] VAR VOWELS [aáeéiíoóuú]* VAR VOWELP [aáeéiíoóuú]+ // left context short broad vowel VAR LCSBV (ea|io|iu|a|o|u) // left context short slender vowel VAR LCSSV (ai|eai|ei|e|iui|i|oi|ui) // left context broad vowel VAR LCBV (adh|ae|ao|aá|ea|eá|eo|éa|io|iu|iú|ío|oó|uío|ua|u|ú) // right context broad vowel #VAR RCBV (aei|ae|ai|aoi|ao|a|ái|á|oi|o|ói|ó|ui|uío|uí|u|úi|ú) // left context slender vowel VAR LCSV (aei|aidh|ai|aí|aoi|ái|eai|eái|ei|eoi|e|éi|é|iai|iui|iúi|i|í|oi|ói|uai|ui|uí|úi) VAR LCSVS (aei|aidh|ai|aí|aoi|ái|eai|eái|ei|eoi|e|éi|é|iai|iui|iúi|i|í|oi|ói|uai|ui|uí|úi)* // right context slender vowel VAR RCSV (eai|ea|eái|eá|ei|eoi|eo|e|éa|éi|é|iai|ia|io|iui|iu|iúi|iú|i|ío|í) // left context long vowel VAR LCLV (aei|ae|aoi|ao|ái|á|eái|eá|eoi|eó|eo|éi|é|iúi|iú|ío|í|ói|ó|uío|uí|úi|ú) // left context slender long vowel VAR LCSLV (aei|aidh|aoi|ái|eái|eoi|éi|é|iúi|í|ói|uai|uí|úi) ádh -&gt; AA ái -&gt; AA á -&gt; AA abh -&gt; ABH adh -&gt; ADH / _ # adh -&gt; AI agh -&gt; AI aei -&gt; EE ae -&gt; EE aíodh -&gt; ÍODH / _ # aío -&gt; AÍO aí -&gt; II aidh -&gt; IDH / _ # aidh -&gt; AI aigh -&gt; IGH / _ # aigh -&gt; AI aithe -&gt; ITHE / _ # ai -&gt; ∅ / # CONSS VOWELS abh _ CONSP ai -&gt; ∅ / # CONSS VOWELS adh _ CONSP ai -&gt; ∅ / # CONSS VOWELS agh _ CONSP ai -&gt; ∅ / # CONSS VOWELS amh _ CONSP ai -&gt; ∅ / # CONSS obh _ CONSP ai -&gt; ∅ / # CONSS VOWELS ódh _ CONSP ai -&gt; ∅ / # CONSS odh _ CONSP ai -&gt; ∅ / # CONSS VOWELS ogh _ CONSP ai -&gt; ∅ / # CONSS VOWELS omh _ CONSP ai -&gt; ∅ / # CONSS VOWELS umh _ CONSP ai -&gt; AA / # CONSS _ RDNLR ai -&gt; A / # CONSS _ ai -&gt; @@ / VOWELP CONSP _ ai -&gt; A amh -&gt; AMH / _ # amh -&gt; AU aoi -&gt; AO ao -&gt; AO a -&gt; ∅ / # CONSS VOWELS abh _ CONSP a -&gt; ∅ / # CONSS VOWELS adh _ CONSP a -&gt; ∅ / # CONSS VOWELS agh _ CONSP a -&gt; ∅ / # CONSS VOWELS amh _ CONSP a -&gt; ∅ / # CONSS obh _ CONSP a -&gt; ∅ / # CONSS VOWELS ódh _ CONSP a -&gt; ∅ / # CONSS odh _ CONSP a -&gt; ∅ / # CONSS VOWELS ogh _ CONSP a -&gt; ∅ / # CONSS VOWELS omh _ CONSP a -&gt; ∅ / # CONSS VOWELS umh _ CONSP # addition a -&gt; ∅ / # CONSS VOWELS ogh _ # omh -&gt; OO / (gc|ch|c) _ (ai|a) r a -&gt; AA / # CONSS _ RDNLR a -&gt; A / # CONSS _ a -&gt; @@ / VOWELP CONSP _ a -&gt; A éa -&gt; EE éi -&gt; EE é -&gt; EE eái -&gt; AA eá -&gt; AA eabh -&gt; ABH eadh -&gt; ADH / _ # eadh -&gt; AU eagh -&gt; AI eai -&gt; A eamh -&gt; AMH / _ # eamh -&gt; AU / # CONSS _ # VOWEL, or VOWELS ?? ea -&gt; ∅ / # CONSS VOWEL igh _ CONSP ea -&gt; AA / # CONSS _ RDNLR ea -&gt; A / # CONSS _ ea -&gt; @@ / VOWELP CONSP _ ea -&gt; A eidh -&gt; EIDH eigh -&gt; EIGH ei -&gt; EE / # CONSS _ RDNLR # ei -&gt; EE / # CONSS _ RDNLR NONSYLLABIC ei -&gt; E / # CONSS _ ei -&gt; E eódh -&gt; OO eoi -&gt; OO eó -&gt; OO eo -&gt; OO e -&gt; E / # CONSS _ e -&gt; @@ / VOWELP CONSP _ e -&gt; E íodh -&gt; ÍODH / _ # ío -&gt; II í -&gt; II iadh -&gt; I@ iath -&gt; I@ iai -&gt; I@ ia -&gt; I@ idh -&gt; IDH igh -&gt; IGH io -&gt; IO ithe -&gt; ITHE / _ # iúi -&gt; UU iú -&gt; UU iubh -&gt; UBH iumh -&gt; UU iui -&gt; UU iu -&gt; U i -&gt; ∅ / # CONSS VOWEL idh _ CONSP # i -&gt; ∅ / # CONSS VOWEL igh _ CONSP i -&gt; @@ / VOWELP CONSP _ i -&gt; I ódh -&gt; ÓDH / _ # ói -&gt; OO ó -&gt; OO obh -&gt; OBH odh -&gt; ODH ogh -&gt; OGH oí -&gt; II oidh -&gt; OIDH oigh -&gt; OIGH oi -&gt; OO / # CONSS _ RDNLR oi -&gt; @@ / # VOWELP CONSP _ oi -&gt; OI omh -&gt; OMH o -&gt; OO / # CONSS _ RDNLR # o -&gt; OO / # CONSS _ RDNLR NONSYLLABIC o -&gt; O / # VOWELP CONSP _ o -&gt; O úi -&gt; UU ú -&gt; UU uath -&gt; U@ uai -&gt; U@ ua -&gt; U@ ubh -&gt; UBH ue -&gt; E ui -&gt; UU / # CONSS _ RDNLR # ui -&gt; UU / # CONSS _ RDNLR NONSYLLABIC ui -&gt; I / # CONSS _ ui -&gt; @@ / VOWELP CONSP _ ui -&gt; UI uío -&gt; II uí -&gt; II umh -&gt; UU u -&gt; UU / # CONSS _ RDNLR u -&gt; U / # CONSS _ u -&gt; @@ / VOWELP CONSP _ u -&gt; U bf -&gt; P / _ BFCE # bf -&gt; PJ / _ SFCE # bhf -&gt; VJ / # _ CONSS RCSV # bhf -&gt; VJ / # _ CONSS RCSV NONSYLLABIC bhf -&gt; V / # _ bhf -&gt; F / _ BFCE # bhf -&gt; FJ / _ SFCE # bh -&gt; @@ V / # LCSBV LNRP _ bh -&gt; @@ V / NONSYLLABIC LCSBV LNRP _ bh -&gt; @@ VJ / # LCSSV LNRP _ bh -&gt; @@ VJ / NONSYLLABIC LCSSV LNRP _ bh -&gt; VJ / # _ CONSS RCSV # bh -&gt; VJ / # _ CONSS RCSV NONSYLLABIC bh -&gt; V / # _ bh -&gt; VJ / _ CONSS RCSV # bh -&gt; VJ / _ CONSS RCSV NONSYLLABIC bh -&gt; VJ / # LCSV CONSP _ bh -&gt; VJ / NONSYLLABIC LCSV CONSP _ bh -&gt; VJ / # LCSV _ bh -&gt; VJ / NONSYLLABIC LCSV _ bh -&gt; V bp -&gt; BJ / # _ CONSS RCSV # bp -&gt; BJ / # _ CONSS RCSV NONSYLLABIC bp -&gt; B / # _ bth -&gt; P / LCBV CONSS _ bth -&gt; PJ / LCSV CONSS _ b -&gt; @@ B / # LCSBV LNRP _ b -&gt; @@ B / NONSYLLABIC LCSBV LNRP _ b -&gt; @@ BJ / # LCSSV LNRP _ b -&gt; @@ BJ / NONSYLLABIC LCSSV LNRP _ b -&gt; BJ / _ CONSS RCSV # b -&gt; BJ / _ CONSS RCSV NONSYLLABIC b -&gt; BJ / # LCSV CONSP _ b -&gt; BJ / NONSYLLABIC LCSV CONSP _ b -&gt; BJ / # LCSV _ b -&gt; BJ / NONSYLLABIC LCSV _ b -&gt; B cf -&gt; K / _ BFCE # cf -&gt; KJ / _ SFCE # chf -&gt; X / _ BFCE # chf -&gt; XJ / _ SFCE # ch -&gt; @@ X / # LCSBV LNRP _ ch -&gt; @@ X / NONSYLLABIC LCSBV LNRP _ ch -&gt; @@ XJ / # LCSSV LNRP _ ch -&gt; @@ XJ / NONSYLLABIC LCSSV LNRP _ ch -&gt; XJ / # _ CONSS RCSV # ch -&gt; XJ / # _ CONSS RCSV NONSYLLABIC ch -&gt; X / # _ ch -&gt; XJ / _ CONSS RCSV # ch -&gt; XJ / _ CONSS RCSV NONSYLLABIC ch -&gt; XJ / # LCSV CONSP _ ch -&gt; XJ / NONSYLLABIC LCSV CONSP _ ch -&gt; XJ / # LCSV _ ch -&gt; XJ / NONSYLLABIC LCSV _ ch -&gt; X cth -&gt; K / LCBV CONSS _ cth -&gt; KJ / LCSV CONSS _ c -&gt; KJ / _ CONSS RCSV # c -&gt; KJ / _ CONSS RCSV NONSYLLABIC c -&gt; KJ / # LCSV CONSP _ c -&gt; KJ / NONSYLLABIC LCSV CONSP _ c -&gt; KJ / # LCSV _ c -&gt; KJ / NONSYLLABIC LCSV _ c -&gt; K df -&gt; T / _ BFCE # df -&gt; TJ / _ SFCE # dha -&gt; ∅ / # LCLV _ dha -&gt; ∅ / NONSYLLABIC LCLV _ dh -&gt; GFJ / # LCSLV _ dh -&gt; GFJ / NONSYLLABIC LCSLV _ dh -&gt; GFJ / # CONSS LCSVS _ # dh -&gt; ∅ / # LCLV _ dh -&gt; ∅ / NONSYLLABIC LCLV _ dh -&gt; GFJ / # _ CONSS RCSV # dh -&gt; GFJ / # _ CONSS RCSV NONSYLLABIC dh -&gt; GF / # _ dh -&gt; GFJ / _ CONSS RCSV # dh -&gt; GFJ / _ CONSS RCSV NONSYLLABIC dh -&gt; GFJ / # LCSV CONSP _ dh -&gt; GFJ / NONSYLLABIC LCSV CONSP _ dh -&gt; GFJ / # LCSV _ dh -&gt; GFJ / NONSYLLABIC LCSV _ dh -&gt; GF dt -&gt; DJ / # _ CONSS RCSV # dt -&gt; DJ / # _ CONSS RCSV NONSYLLABIC dt -&gt; D / # _ dt -&gt; T / LCBV CONSS _ dt -&gt; TJ / LCSV CONSS _ d -&gt; DJ / _ CONSS RCSV # d -&gt; DJ / _ CONSS RCSV NONSYLLABIC d -&gt; DJ / # LCSV CONSP _ d -&gt; DJ / NONSYLLABIC LCSV CONSP _ d -&gt; DJ / # LCSV _ d -&gt; DJ / NONSYLLABIC LCSV _ d -&gt; D fh -&gt; ∅ f -&gt; H / VOWEL _ BFCE # f -&gt; HJ / VOWEL _ SFCE # f -&gt; @@ F / # LCSBV LNRP _ f -&gt; @@ F / NONSYLLABIC LCSBV LNRP _ f -&gt; @@ FJ / # LCSSV LNRP _ f -&gt; @@ FJ / NONSYLLABIC LCSSV LNRP _ f -&gt; FJ / _ CONSS RCSV # f -&gt; FJ / _ CONSS RCSV NONSYLLABIC f -&gt; FJ / # LCSV CONSP _ f -&gt; FJ / NONSYLLABIC LCSV CONSP _ f -&gt; FJ / # LCSV _ f -&gt; FJ / NONSYLLABIC LCSV _ f -&gt; F gc -&gt; GJ / # _ CONSS RCSV # gc -&gt; GJ / # _ CONSS RCSV NONSYLLABIC gc -&gt; G / # _ gf -&gt; K / _ BFCE # gf -&gt; KJ / _ SFCE # gh -&gt; GFJ / # _ CONSS RCSV # gh -&gt; GFJ / # _ CONSS RCSV NONSYLLABIC gh -&gt; GF / # _ gh -&gt; GFJ / # LCSLV _ gh -&gt; GFJ / NONSYLLABIC LCSLV _ gh -&gt; GFJ / # CONSS LCSVS _ # gh -&gt; ∅ / # LCLV _ gh -&gt; ∅ / NONSYLLABIC LCLV _ gh -&gt; GFJ / _ CONSS RCSV # gh -&gt; GFJ / _ CONSS RCSV NONSYLLABIC gh -&gt; GFJ / # LCSV CONSP _ gh -&gt; GFJ / NONSYLLABIC LCSV CONSP _ gh -&gt; GFJ / # LCSV _ gh -&gt; GFJ / NONSYLLABIC LCSV _ gh -&gt; GF gth -&gt; K / LCBV CONSS _ gth -&gt; KJ / LCSV CONSS _ g -&gt; @@ G / # LCSBV LNRP _ g -&gt; @@ G / NONSYLLABIC LCSBV LNRP _ g -&gt; @@ GJ / # LCSSV LNRP _ g -&gt; @@ GJ / NONSYLLABIC LCSSV LNRP _ g -&gt; GJ / _ CONSS RCSV # g -&gt; GJ / _ CONSS RCSV NONSYLLABIC g -&gt; GJ / # LCSV CONSP _ g -&gt; GJ / NONSYLLABIC LCSV CONSP _ g -&gt; GJ / # LCSV _ g -&gt; GJ / NONSYLLABIC LCSV _ g -&gt; G h -&gt; HJ / _ CONSS RCSV # h -&gt; HJ / _ CONSS RCSV NONSYLLABIC h -&gt; HJ / # LCSV CONSP _ h -&gt; HJ / NONSYLLABIC LCSV CONSP _ h -&gt; HJ / # LCSV _ h -&gt; HJ / NONSYLLABIC LCSV _ h -&gt; H j -&gt; DJZJ k -&gt; KJ / _ CONSS RCSV # k -&gt; KJ / _ CONSS RCSV NONSYLLABIC k -&gt; KJ / # LCSV CONSP _ k -&gt; KJ / NONSYLLABIC LCSV CONSP _ k -&gt; KJ / # LCSV _ k -&gt; KJ / NONSYLLABIC LCSV _ k -&gt; K llf -&gt; LL_D / _ BFCE # llf -&gt; LLJ_D / _ SFCE # llth -&gt; LL_D / LCBV CONSS _ llth -&gt; LLJ_D / LCSV CONSS _ ll -&gt; LLJ / _ CONSS RCSV # ll -&gt; LLJ / _ CONSS RCSV NONSYLLABIC ll -&gt; LLJ / # LCSV CONSP _ ll -&gt; LLJ / NONSYLLABIC LCSV CONSP _ ll -&gt; LLJ / # LCSV _ ll -&gt; LLJ / NONSYLLABIC LCSV _ ll -&gt; LL lf -&gt; LL_D / _ BFCE # lf -&gt; LJ_D / _ SFCE # lth -&gt; LL_D / LCBV CONSS _ lth -&gt; LJ_D / LCSV CONSS _ l -&gt; LJ / _ CONSS RCSV # l -&gt; LJ / _ CONSS RCSV NONSYLLABIC l -&gt; LJ / # LCSV CONSP _ l -&gt; LJ / NONSYLLABIC LCSV CONSP _ l -&gt; LJ / # LCSV _ l -&gt; LJ / NONSYLLABIC LCSV _ l -&gt; LL mb -&gt; MJ / # _ CONSS RCSV # mb -&gt; MJ / # _ CONSS RCSV NONSYLLABIC mb -&gt; M / # _ mf -&gt; M_D / _ BFCE # mf -&gt; MJ_D / _ SFCE # mhf -&gt; F / _ BFCE # mhf -&gt; FJ / _ SFCE # mh -&gt; VJ / # _ CONSS RCSV # mh -&gt; VJ / # _ CONSS RCSV NONSYLLABIC mh -&gt; V / # _ mh -&gt; @@ V / # LCSBV LNRP _ mh -&gt; @@ V / NONSYLLABIC LCSBV LNRP _ mh -&gt; @@ VJ / # LCSSV LNRP _ mh -&gt; @@ VJ / NONSYLLABIC LCSSV LNRP _ mh -&gt; VJ / _ CONSS RCSV # mh -&gt; VJ / _ CONSS RCSV NONSYLLABIC mh -&gt; VJ / # LCSV CONSP _ mh -&gt; VJ / NONSYLLABIC LCSV CONSP _ mh -&gt; VJ / # LCSV _ mh -&gt; VJ / NONSYLLABIC LCSV _ mh -&gt; V mth -&gt; M_D / LCBV CONSS _ mth -&gt; MJ_D / LCSV CONSS _ m -&gt; @@ M / # LCSBV LNRP _ m -&gt; @@ M / NONSYLLABIC LCSBV LNRP _ m -&gt; @@ MJ / # LCSSV LNRP _ m -&gt; @@ MJ / NONSYLLABIC LCSSV LNRP _ m -&gt; MJ / _ CONSS RCSV # m -&gt; MJ / _ CONSS RCSV NONSYLLABIC m -&gt; MJ / # LCSV CONSP _ m -&gt; MJ / NONSYLLABIC LCSV CONSP _ m -&gt; MJ / # LCSV _ m -&gt; MJ / NONSYLLABIC LCSV _ m -&gt; M nnf -&gt; NN_D / _ BFCE # nnf -&gt; NNJ_D / _ SFCE # nnth -&gt; NN_D / LCBV CONSS _ nnth -&gt; NNJ_D / LCSV CONSS _ nn -&gt; NNJ / _ CONSS RCSV # nn -&gt; NNJ / _ CONSS RCSV NONSYLLABIC nn -&gt; NNJ / # LCSV CONSP _ nn -&gt; NNJ / NONSYLLABIC LCSV CONSP _ nn -&gt; NNJ / # LCSV _ nn -&gt; NNJ / NONSYLLABIC LCSV _ nn -&gt; NN n- -&gt; NJ / # _ RCSV # n- -&gt; NJ / # _ RCSV NONSYLLABIC n- -&gt; NN / # _ nd -&gt; NNJ / # _ CONSS RCSV # nd -&gt; NNJ / # _ CONSS RCSV NONSYLLABIC nd -&gt; NN / # _ nf -&gt; NN_D / _ BFCE # nf -&gt; NJ_D / _ SFCE # ngf -&gt; NG_D / _ BFCE # ngf -&gt; NGJ_D / _ SFCE # ngth -&gt; NG_D / LCBV CONSS _ ngth -&gt; NGJ_D / LCSV CONSS _ ng -&gt; NGJ / # _ CONSS RCSV # ng -&gt; NGJ / # _ CONSS RCSV NONSYLLABIC ng -&gt; NG / # _ ng -&gt; NJ / # LCSV _ t # ng -&gt; NJ / NONSYLLABIC LCSV _ t # ng -&gt; NGJ / _ CONSS RCSV # ng -&gt; NGJ / _ CONSS RCSV NONSYLLABIC ng -&gt; NGJ / # LCSV CONSP _ ng -&gt; NGJ / NONSYLLABIC LCSV CONSP _ ng -&gt; NGJ / # LCSV _ ng -&gt; NGJ / NONSYLLABIC LCSV _ ng -&gt; NG nth -&gt; NN_D / LCBV CONSS _ nth -&gt; NJ_D / LCSV CONSS _ n -&gt; NGJ / # LCSV _ c n -&gt; NGJ / NONSYLLABIC LCSV _ c n -&gt; NG / _ c n -&gt; NJ / _ CONSS RCSV # n -&gt; NJ / _ CONSS RCSV NONSYLLABIC n -&gt; NJ / # LCSV CONSP _ n -&gt; NJ / NONSYLLABIC LCSV CONSP _ n -&gt; NJ / # LCSV _ n -&gt; NJ / NONSYLLABIC LCSV _ n -&gt; NN pf -&gt; P / _ BFCE # pf -&gt; PJ / _ SFCE # ph -&gt; FJ / # _ CONSS RCSV # ph -&gt; FJ / # _ CONSS RCSV NONSYLLABIC ph -&gt; F / # _ ph -&gt; FJ / _ CONSS RCSV # ph -&gt; FJ / _ CONSS RCSV NONSYLLABIC ph -&gt; FJ / # LCSV CONSP _ ph -&gt; FJ / NONSYLLABIC LCSV CONSP _ ph -&gt; FJ / # LCSV _ ph -&gt; FJ / NONSYLLABIC LCSV _ ph -&gt; F pth -&gt; P / LCBV CONSS _ pth -&gt; PJ / LCSV CONSS _ p -&gt; PJ / _ CONSS RCSV # p -&gt; PJ / _ CONSS RCSV NONSYLLABIC p -&gt; PJ / # LCSV CONSP _ p -&gt; PJ / NONSYLLABIC LCSV CONSP _ p -&gt; PJ / # LCSV _ p -&gt; PJ / NONSYLLABIC LCSV _ p -&gt; P # really? there&#39;s a &#39;W&#39; in the phoneset q -&gt; K V rrf -&gt; RR_D / _ BFCE # rrf -&gt; RRJ_D / _ SFCE # rrth -&gt; RR_D / LCBV CONSS _ rrth -&gt; RRJ_D / LCSV CONSS _ rr -&gt; RRJ / _ CONSS RCSV # rr -&gt; RRJ / _ CONSS RCSV NONSYLLABIC rr -&gt; RRJ / # LCSV CONSP _ rr -&gt; RRJ / NONSYLLABIC LCSV CONSP _ rr -&gt; RRJ / # LCSV _ rr -&gt; RRJ / NONSYLLABIC LCSV _ rr -&gt; RR rf -&gt; R_D / _ BFCE # rf -&gt; RJ_D / _ SFCE # rth -&gt; R_D / LCBV CONSS _ rth -&gt; RJ_D / LCSV CONSS _ r -&gt; R / # s _ r -&gt; R / # _ // This rule blocks tests for airde and ceird r -&gt; R / _ DNLST r -&gt; RJ / _ CONSS RCSV # r -&gt; RJ / _ CONSS RCSV NONSYLLABIC r -&gt; RJ / # LCSV CONSP _ r -&gt; RJ / NONSYLLABIC LCSV CONSP _ r -&gt; RJ / # LCSV _ r -&gt; RJ / NONSYLLABIC LCSV _ r -&gt; R sf -&gt; S / _ BFCE # sf -&gt; SJ / _ SFCE # shl -&gt; LJ_D / _ CONSS RCSV # shl -&gt; LJ_D / _ CONSS RCSV NONSYLLABIC shl -&gt; LL_D shm -&gt; MJ_D / _ CONSS RCSV # shm -&gt; MJ_D / _ CONSS RCSV NONSYLLABIC shm -&gt; M_D shn -&gt; NJ_D / _ CONSS RCSV # shn -&gt; NJ_D / _ CONSS RCSV NONSYLLABIC shn -&gt; NN_D shr -&gt; RJ_D / _ CONSS RCSV # shr -&gt; RJ_D / _ CONSS RCSV NONSYLLABIC shr -&gt; R_D sh -&gt; XJ / # _ CONSS RCSV # sh -&gt; XJ / # _ CONSS RCSV NONSYLLABIC sh -&gt; H / # _ sh -&gt; XJ / _ CONSS RCSV # sh -&gt; XJ / _ CONSS RCSV NONSYLLABIC sh -&gt; XJ / # LCSV CONSP _ sh -&gt; XJ / NONSYLLABIC LCSV CONSP _ sh -&gt; XJ / # LCSV _ sh -&gt; XJ / NONSYLLABIC LCSV _ sh -&gt; H s -&gt; S / # _ r s -&gt; S / # _ FMP CONSS RCSV # s -&gt; S / # _ FMP CONSS RCSV NONSYLLABIC s -&gt; SJ / _ CONSS RCSV # s -&gt; SJ / _ CONSS RCSV NONSYLLABIC s -&gt; SJ / # LCSV CONSP _ s -&gt; SJ / NONSYLLABIC LCSV CONSP _ s -&gt; SJ / # LCSV _ s -&gt; SJ / NONSYLLABIC LCSV _ s -&gt; S t- -&gt; TJ / # _ RCSV # t- -&gt; TJ / # _ RCSV NONSYLLABIC t- -&gt; T / # _ tf -&gt; T / _ BFCE # tf -&gt; TJ / _ SFCE # // &quot;hack for compound boundaries&quot; th -&gt; ∅ / _ CONS h thb -&gt; PJ / _ CONSS RCSV # thb -&gt; PJ / _ CONSS RCSV NONSYLLABIC thb -&gt; P thc -&gt; KJ / _ CONSS RCSV # thc -&gt; KJ / _ CONSS RCSV NONSYLLABIC thc -&gt; K thd -&gt; TJ / _ CONSS RCSV # thd -&gt; TJ / _ CONSS RCSV NONSYLLABIC thd -&gt; T thf -&gt; H / _ BFCE # thf -&gt; XJ / _ SFCE # thl -&gt; LJ_D / _ CONSS RCSV # thl -&gt; LJ_D / _ CONSS RCSV NONSYLLABIC thl -&gt; LL_D thm -&gt; MJ_D / _ CONSS RCSV # thm -&gt; MJ_D / _ CONSS RCSV NONSYLLABIC thm -&gt; M_D thn -&gt; NJ_D / _ CONSS RCSV # thn -&gt; NJ_D / _ CONSS RCSV NONSYLLABIC thn -&gt; NN_D thp -&gt; PJ / _ CONSS RCSV # thp -&gt; PJ / _ CONSS RCSV NONSYLLABIC thp -&gt; P thr -&gt; RJ_D / _ CONSS RCSV # thr -&gt; RJ_D / _ CONSS RCSV NONSYLLABIC thr -&gt; R_D ths -&gt; SJ / _ CONSS RCSV # ths -&gt; SJ / _ CONSS RCSV NONSYLLABIC ths -&gt; S tht -&gt; TJ / _ CONSS RCSV # tht -&gt; TJ / _ CONSS RCSV NONSYLLABIC tht -&gt; T th -&gt; HJ / # _ CONSS RCSV # th -&gt; HJ / # _ CONSS RCSV NONSYLLABIC th -&gt; H / # _ th -&gt; HJ / _ CONSS RCSV # th -&gt; HJ / _ CONSS RCSV NONSYLLABIC th -&gt; HJ / # LCSV CONSP _ th -&gt; HJ / NONSYLLABIC LCSV CONSP _ th -&gt; HJ / # LCSV _ th -&gt; HJ / NONSYLLABIC LCSV _ th -&gt; H ts -&gt; TJ / # _ CONSS RCSV # ts -&gt; TJ / # _ CONSS RCSV NONSYLLABIC ts -&gt; T / # _ t -&gt; TJ / _ CONSS RCSV # t -&gt; TJ / _ CONSS RCSV NONSYLLABIC t -&gt; TJ / # LCSV CONSP _ t -&gt; TJ / NONSYLLABIC LCSV CONSP _ t -&gt; TJ / # LCSV _ t -&gt; TJ / NONSYLLABIC LCSV _ t -&gt; T v -&gt; VJ / _ CONSS RCSV # v -&gt; VJ / _ CONSS RCSV NONSYLLABIC v -&gt; VJ / # LCSV CONSP _ v -&gt; VJ / NONSYLLABIC LCSV CONSP _ v -&gt; VJ / # LCSV _ v -&gt; VJ / NONSYLLABIC LCSV _ v -&gt; V w -&gt; V x- -&gt; E KJ S x -&gt; ZJ y -&gt; GFJ z -&gt; ZJ / _ CONSS RCSV # z -&gt; ZJ / _ CONSS RCSV NONSYLLABIC z -&gt; ZJ / # LCSV CONSP _ z -&gt; ZJ / NONSYLLABIC LCSV CONSP _ z -&gt; ZJ / # LCSV _ z -&gt; ZJ / NONSYLLABIC LCSV _ z -&gt; Z &#39; -&gt; ∅ ’ -&gt; ∅ - -&gt; ∅ TEST ádh -&gt; AA TEST áiseanna -&gt; AA SJ @@ NN @@ TEST áthas -&gt; AA H @@ S TEST abhainn -&gt; ABH NNJ TEST bualadh -&gt; B U@ LL ADH TEST sadhbh -&gt; S AI V TEST saghas -&gt; S AI S TEST gaeilge -&gt; G EE LJ GJ @@ TEST saolaíodh -&gt; S AO LL ÍODH TEST gardaí -&gt; G AA R D II TEST dúnfaidh -&gt; D UU NN_D IDH TEST aidhm -&gt; AI MJ TEST cheadaigh -&gt; XJ A D IGH TEST aighneas -&gt; AI NJ @@ S TEST diúltaithe -&gt; DJ UU LL T ITHE TEST seabhaic -&gt; SJ ABH KJ TEST feadhain -&gt; FJ AU NJ TEST teaghais -&gt; TJ AI SJ TEST eamhain -&gt; AU NJ TEST lobhair -&gt; LL OBH RJ TEST leódhais -&gt; LJ OO SJ TEST bodhair -&gt; B ODH RJ TEST eoghain -&gt; OO NJ TEST broghais -&gt; B R OGH SJ TEST comhair -&gt; K OO RJ TEST ciumhais -&gt; KJ UU SJ # wiktionary has: ˈɑːɾˠdʲə ˈiːɾˠdʲə ˈɑːɾˠdʲə ˈaiɾʲdʲə ˈæːɾˠdʲə ˈʌɾˠdʲə, so rule seems right #TEST airde -&gt; AA RJ DJ @@ TEST airde -&gt; AA R DJ @@ TEST cait -&gt; K A TJ TEST sodair -&gt; S O D @@ RJ TEST ait -&gt; A TJ TEST déanamh -&gt; DJ EE NN AMH TEST amharc -&gt; AU R K TEST gaoil -&gt; G AO LJ TEST gaol -&gt; G AO LL TEST seabhac -&gt; SJ ABH K TEST ceadharlach -&gt; KJ AU R LL @@ X TEST teaghasán -&gt; TJ AI S AA NN TEST lobhar -&gt; LL OBH R TEST leódhas -&gt; LJ OO S TEST bodhar -&gt; B ODH R TEST eoghan -&gt; OO NN TEST bogha -&gt; B OGH TEST comhar -&gt; K OO R TEST dumhach -&gt; D UU X TEST ard -&gt; AA R D TEST cat -&gt; K A T TEST sodar -&gt; S O D @@ R TEST at -&gt; A T TEST éan -&gt; EE NN TEST éiníní -&gt; EE NJ II NJ II TEST é -&gt; EE TEST sheáin -&gt; XJ AA NJ TEST seán -&gt; SJ AA NN TEST seabhac -&gt; SJ ABH K TEST seinneadh -&gt; SJ E NNJ ADH TEST ceadharlach -&gt; KJ AU R LL @@ X TEST teaghlach -&gt; TJ AI LL @@ X TEST beairic -&gt; BJ A RJ @@ KJ TEST áireamh -&gt; AA RJ AMH TEST sleamhnán -&gt; SJ LJ AU NN AA NN TEST oighear -&gt; OIGH R TEST ceard -&gt; KJ AA R D TEST cead -&gt; KJ A D TEST áireamhán -&gt; AA RJ @@ V AA NN TEST eas -&gt; A S TEST feidhm -&gt; FJ EIDH MJ TEST leigheas -&gt; LJ EIGH S # wiktionary gives cəiɾˠdʲ and cɪɾˠdʲ; the rule seems right #TEST ceird -&gt; KJ EE RJ DJ TEST ceird -&gt; KJ EE R DJ TEST deis -&gt; DJ E SJ TEST eitpheil -&gt; E TJ FJ E LJ TEST ceoil -&gt; KJ OO LJ TEST bainseó -&gt; B A NJ SJ OO TEST ceol -&gt; KJ OO LL TEST uile -&gt; I LJ @@ TEST ceannaíodh -&gt; KJ A NN ÍODH TEST síos -&gt; SJ II S TEST sí -&gt; SJ II TEST siadhail -&gt; SJ I@ LJ TEST sciath -&gt; SJ KJ I@ #TEST riail -&gt; RJ I@ LJ TEST riail -&gt; R I@ LJ TEST siad -&gt; SJ I@ D TEST seinnfidh -&gt; SJ E NNJ_D IDH TEST cheannaigh -&gt; XJ A NN IGH TEST fios -&gt; FJ IO S TEST imithe -&gt; I MJ ITHE TEST siúil -&gt; SJ UU LJ TEST siúl -&gt; SJ UU LL TEST tiubh -&gt; TJ UBH TEST ciumhais -&gt; KJ UU SJ #TEST giuirléid -&gt; GJ UU RJ LJ EE DJ TEST giuirléid -&gt; GJ UU R LJ EE DJ TEST fiuch -&gt; FJ U X TEST leighis -&gt; LJ EIGH SJ TEST foighid -&gt; F OIGH DJ TEST aithris -&gt; A RJ_D @@ SJ TEST sin -&gt; SJ I NJ TEST cheannódh -&gt; XJ A NN ÓDH TEST óil -&gt; OO LJ TEST ól -&gt; OO LL TEST lobhadh -&gt; LL OBH ADH TEST todhchaí -&gt; T ODH X II TEST toghadh -&gt; T OGH ADH TEST oíche -&gt; II XJ @@ TEST oidhe -&gt; OIDH @@ TEST oighear -&gt; OIGH R #TEST boird -&gt; B OO RJ DJ TEST boird -&gt; B OO R DJ TEST soir -&gt; S OI RJ TEST comhar -&gt; K OO R TEST bord -&gt; B OO R D TEST bos -&gt; B O S TEST súil -&gt; S UU LJ TEST súl -&gt; S UU LL TEST uathúil -&gt; U@ UU LJ TEST uaine -&gt; U@ NJ @@ TEST uan -&gt; U@ NN TEST subh -&gt; S UBH // not LJ ? TEST bhuel -&gt; V E LL #TEST guird -&gt; G UU RJ DJ TEST guird -&gt; G UU R DJ TEST cuid -&gt; K I DJ TEST uile -&gt; I LJ @@ TEST bruíon -&gt; B R II NN TEST bruíne -&gt; B R II NJ @@ TEST cumhacht -&gt; K UU X T TEST burdún -&gt; B UU R D UU NN TEST cur -&gt; K U R TEST bus -&gt; B U S TEST scuabfaidh -&gt; S K U@ P IDH TEST clibfidh -&gt; KJ LJ I PJ IDH TEST scuabfadh -&gt; S K U@ P ADH TEST clibfeadh -&gt; KJ LJ I PJ ADH TEST bhfáinne -&gt; V AA NNJ @@ TEST bhfianaise -&gt; VJ I@ NN @@ SJ @@ TEST scríobhfaidh -&gt; SJ KJ RJ II F IDH TEST díbhfidh -&gt; DJ II FJ IDH TEST scríobhfadh -&gt; SJ KJ RJ II F ADH TEST díbhfeadh -&gt; DJ II FJ ADH TEST searbh -&gt; SJ A R @@ V TEST seirbhís -&gt; SJ E RJ @@ VJ II SJ TEST bhrostaigh -&gt; V R O S T IGH TEST bhris -&gt; VJ RJ I SJ TEST coibhín -&gt; K OI VJ II NJ TEST bpáistí -&gt; B AA SJ TJ II TEST bpéisteanna -&gt; BJ EE SJ TJ @@ NN @@ TEST scuabtha -&gt; S K U@ P @@ TEST clibthe -&gt; KJ LJ I PJ @@ TEST borb -&gt; B O R @@ B TEST seirbiach -&gt; SJ E RJ @@ BJ I@ X TEST bróna -&gt; B R OO NN @@ TEST brian -&gt; BJ RJ I@ NN TEST leódhas -&gt; LJ OO S TEST t-uisce -&gt; T UI SJ KJ @@ TEST t-éabhlóidí -&gt; TJ EE V LL OO DJ II TEST atfaidh -&gt; A T IDH TEST titfidh -&gt; TJ I TJ IDH TEST athdhéanamh -&gt; A GFJ EE NN AMH TEST meathfadh -&gt; MJ A H ADH #TEST rithfeadh -&gt; RJ I XJ ADH TEST rithfeadh -&gt; R I XJ ADH TEST bláthra -&gt; B LL AA R_D @@ TEST tharla -&gt; H AA R LL @@ TEST thit -&gt; HJ I TJ TEST tseachtain -&gt; TJ A X T @@ NJ #TEST tsagairt -&gt; T A G @@ RJ TJ # wiktionary (sagairt): ˈsˠaɡəɾˠtʲ ˈsˠæɡəɾˠtʲ TEST tsagairt -&gt; T A G @@ R TJ TEST teann -&gt; TJ A NN TEST tit -&gt; TJ I TJ TEST togra -&gt; T O G R @@ TEST sadhbh -&gt; S AI V # disabled; the rule for &#39;o&#39; in an unaccented syllable # does not produce schwa; also, &#39;leathbhosca&#39; is a compound; # the &#39;o&#39; should not be reduced #TEST leathbhosca -&gt; LJ A V @@ S K @@ #TEST bantaboic -&gt; B A NN T @@ B @@ KJ #TEST bantaboc -&gt; B A NN T @@ B @@ K TEST bhéal -&gt; VJ EE LL TEST bhéil -&gt; VJ EE LJ .",
            "url": "https://jimregan.github.io/notes/irish/g2p/2021/05/16/o-raghallaigh-thesis-attempt-1.html",
            "relUrl": "/irish/g2p/2021/05/16/o-raghallaigh-thesis-attempt-1.html",
            "date": " • May 16, 2021"
        }
        
    
  
    
        ,"post232": {
            "title": "Clarin-Studio Polish Train mono 1-30",
            "content": "Original on Kaggle . %cd /opt . %%capture !tar xvf /kaggle/input/extract-prebuilt-kaldi-from-docker/kaldi.tar . %cd kaldi/egs . /opt/kaldi/egs . !git clone https://github.com/danijel3/ClarinStudioKaldi . %cd ClarinStudioKaldi . /opt/kaldi/egs/ClarinStudioKaldi . !conda install -c bioconda perl-perlio-gzip -y . import os #os.environ[&#39;LD_LIBRARY_PATH&#39;] = f&#39;{os.environ[&quot;LD_LIBRARY_PATH&quot;]}:/opt/kaldi/tools/openfst-1.6.7/lib:/opt/kaldi/src/lib&#39; os.environ[&#39;LD_LIBRARY_PATH&#39;] = &#39;/opt/conda/lib:/opt/kaldi/tools/openfst-1.6.7/lib:/opt/kaldi/src/lib&#39; . !cat path.sh|sed -e &#39;s/~ /apps/ /opt/&#39; &gt; tmp !mv tmp path.sh . !echo &gt; local_clarin/clarin_pl_clean.sh . !ln -s ../wsj/s5/steps !ln -s ../wsj/s5/conf !ln -s ../wsj/s5/local !ln -s ../wsj/s5/utils . !cp -r /kaggle/input/kaldi-clarinstudio-polish-data-prep/data /kaggle/working/ . !mkdir /kaggle/working/exp !ln -s /kaggle/working/exp !ln -s /kaggle/working/data . !bash steps/train_mono.sh --nj 40 --num_iters 30 data/train data/lang_nosp exp/mono0 .",
            "url": "https://jimregan.github.io/notes/clarinpl/kaggle/2021/05/16/kaldi-clarinstudio-polish-train-mono-1-30.html",
            "relUrl": "/clarinpl/kaggle/2021/05/16/kaldi-clarinstudio-polish-train-mono-1-30.html",
            "date": " • May 16, 2021"
        }
        
    
  
    
        ,"post233": {
            "title": "Clarin-Studio Polish GMM",
            "content": "Original on Kaggle . %cd /opt . /opt . %%capture !tar xvf /kaggle/input/extract-prebuilt-kaldi-from-docker/kaldi.tar . %cd kaldi/egs . /opt/kaldi/egs . !git clone https://github.com/danijel3/ClarinStudioKaldi . %cd ClarinStudioKaldi . /opt/kaldi/egs/ClarinStudioKaldi . !conda install -c bioconda perl-perlio-gzip -y . import os #os.environ[&#39;LD_LIBRARY_PATH&#39;] = f&#39;{os.environ[&quot;LD_LIBRARY_PATH&quot;]}:/opt/kaldi/tools/openfst-1.6.7/lib:/opt/kaldi/src/lib&#39; os.environ[&#39;LD_LIBRARY_PATH&#39;] = &#39;/opt/conda/lib:/opt/kaldi/tools/openfst-1.6.7/lib:/opt/kaldi/src/lib&#39; . !cat path.sh|sed -e &#39;s/~ /apps/ /opt/&#39; &gt; tmp !mv tmp path.sh . !echo &gt; local_clarin/clarin_pl_clean.sh . !sh run.sh . !mv exp /kaggle/working/ .",
            "url": "https://jimregan.github.io/notes/clarinpl/kaggle/2021/05/15/kaldi-clarinstudio-polish-gmm.html",
            "relUrl": "/clarinpl/kaggle/2021/05/15/kaldi-clarinstudio-polish-gmm.html",
            "date": " • May 15, 2021"
        }
        
    
  
    
        ,"post234": {
            "title": "Extract pre-built Kaldi on Kaggle",
            "content": "Original here . %cd /tmp . /tmp . !git clone https://github.com/jjlin/docker-image-extract/ . !docker-image-extract/docker-image-extract kaldiasr/kaldi:gpu-latest . Getting API token... Getting image manifest for kaldiasr/kaldi:gpu-latest... Fetching and extracting layer 976a760c94fcdd7d105269ae621e8269e7bb25a58c52ae667b4029a6bc7e33cb... Fetching and extracting layer c58992f3c37bb64aeba18910408cda9a7a63e212fe27e95065a8d54130ca5926... Fetching and extracting layer 0ca0e5e7f12e6eb512246aea5579fcb771fe7203bc60944384d5cd7962f87ddb... Fetching and extracting layer f2a274cc00ca5f671b1740c43672dbc96504760cee585e7604029a3fe56854a8... Fetching and extracting layer 708a53113e13a385afdeddfe409f4b7b71e65b1e5cff48ba33906c8803e19808... Fetching and extracting layer 465b2edc87fbc8c5fb06541c382eefd1edbfcac71521273855dbe0841a5aaf4a... Fetching and extracting layer 4189f57a58ef61e7e283534fb6d0dd4b2b818a037d82c0e1a2994cea35b01883... Fetching and extracting layer 35de2d1091bb82248c486931c94f18336d55dfee05d32d549305626c2e54ca82... Fetching and extracting layer 719d77537fdce03bba6ed02fcbc2e4b84d58906af53a95102326d7aa290549bf... Fetching and extracting layer 3745e7bcc1b3b7ef8b9afe38e20019cdd052d2ed5fa6b32f063e693620179f90... Fetching and extracting layer d990bd9da1ddb55d091b2fcc12a80dc7d3b04e1ba14c2e79f6e0ec9f487773fe... Fetching and extracting layer 15f2cb6c17ae91014b292d6db2438f202e2fb2f9527cb6730f5a38f639526641... Fetching and extracting layer d3305c2a9a9794962ae8183ae36e93f656f290fcec1216407bf4f417e09e512b... Image contents extracted into ./output. . %cd output/opt/ . /tmp/output/opt . import os os.environ[&#39;LD_LIBRARY_PATH&#39;] = &#39;/opt/conda/lib:/opt/kaldi/tools/openfst-1.6.7/lib:/opt/kaldi/src/lib&#39; . %pushd kaldi/tools !bash extras/install_phonetisaurus.sh %popd . !tar cvf /kaggle/working/kaldi.tar kaldi/ .",
            "url": "https://jimregan.github.io/notes/kaggle/kaldi/wav2vec-u/2021/05/15/extract-prebuilt-kaldi-from-docker.html",
            "relUrl": "/kaggle/kaldi/wav2vec-u/2021/05/15/extract-prebuilt-kaldi-from-docker.html",
            "date": " • May 15, 2021"
        }
        
    
  
    
        ,"post235": {
            "title": "G2P with MFA",
            "content": "Original on Kaggle . %%capture import os os.chdir(&#39;/tmp&#39;) !wget https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/releases/download/v1.0.1/montreal-forced-aligner_linux.tar.gz !tar zxvf montreal-forced-aligner_linux.tar.gz !ln -s /tmp/montreal-forced-aligner/lib/libpython3.6m.so.1.0 /tmp/montreal-forced-aligner/lib/libpython3.6m.so . os.chdir(&#39;/kaggle/working&#39;) os.environ[&#39;LD_LIBRARY_PATH&#39;] = f&#39;{os.environ[&quot;LD_LIBRARY_PATH&quot;]}:/tmp/montreal-forced-aligner/lib/&#39; os.environ[&#39;PATH&#39;] = f&#39;{os.environ[&quot;PATH&quot;]}:/tmp/montreal-forced-aligner/bin/&#39; . %%capture !apt-get -y install libgfortran3 . !mkdir /tmp/example . The example below is from section 488 (p. 239) of Gaeilge Chorca Dhuibhne by Diarmuid Ó Sé. . The provided transcription is: əs kiːn′ l′əm nə ˈheːn′ɪ v′eh ə bɪn′t′ vuːn er′ . %%writefile /tmp/example/test1.lab is cuimhin liom na haoinne a bheith ag baint mhóna air . Writing /tmp/example/test1.lab . Ibid, Section 488, p. 238 . xuːərˈdiːs ˈgax ɑːt′ . %%writefile /tmp/example/test2.lab chuardaíos gach áit . Writing /tmp/example/test2.lab . MFA insists on having .wav files, which it reads, even though it makes no use of them for G2P . %%capture !apt-get -y install sox . !sox -n -r 16000 -b 16 -c 1 -L /tmp/example/test1.wav trim 0.0 6.000 !sox -n -r 16000 -b 16 -c 1 -L /tmp/example/test2.wav trim 0.0 6.000 . !mfa_generate_dictionary ../input/train-irish-mfa-model-fuaimeanna/g2p-munster.zip /tmp/example/ output . Setting up corpus information... . !cat output . cuimhin k ɪ vˠ nʲ áit ɑː tʲ a ə mhóna vˠ oː n̪ˠ ə bheith vʲ ɛ baint bˠ ɪ nʲ tʲ air a ɾʲ is ɪ ʃ na n̪ˠ ə gach ɡ ə x chuardaíos x uə ɾˠ d̪ˠ iː ʌ sˠ ag a ɡ liom lʲ ʌ mˠ haoinne ɪ nʲ ɛ . Word Pronunciation Alt. Transcript Generated Correct? In context? Rule/Reason . is | əs | əsˠ (~ ɪʃ) | ɪ ʃ | ✔️ | ❌ | Exception: ios but correct before a slender consonant | . cuimhin | kiːn′ | kiːnʲ | k ɪ vˠ nʲ | ❌ | ❌ | Missing grapheme: uimhi | . liom | l′əm | lʲəmˠ (~ lʲʌmˠ) | lʲ ʌ mˠ | ✔️ | ✔️ | (See, e.g., section 291: l′um) | . na | nə | n̪ˠə | n̪ˠ ə | ✔️ | ✔️ | | . haoinne | ˈheːn′ɪ | heːnʲɪ | ɪ nʲ ɛ | ❌ | ❌ | | . a | ə | | ə | ✔️ | ✔️ | | . bheith | v′eh | vʲɛ(h) | vʲ ɛ | ✔️ | ❌ | Section 9: h → ∅ / _ # -V | . ag | ə | ə (~ ɪɟ) | a ɡ | ❌ | ❌ | ɪg′, section 60 | . baint | bɪn′t′ | bˠɪnʲtʲ | bˠ ɪ nʲ tʲ | ✔️ | ✔️ | | . mhóna | vuːn | vˠuːn̪ˠ(ə) | vˠ oː n̪ˠ ə | ✔️ | ❌ | ó → oː ~ uː / _ [+nasal], ə → ∅ / _ # | . air | er′ | eɾʲ | a ɾʲ | ❌ | ❌ | Exception: eir | . chuardaíos | xuːərˈdiːs | xuəɾˠd̪ˠiːsˠ | x uə ɾˠ d̪ˠ iː ʌ sˠ | ❌ | ❌ | Missing grapheme aío | . gach | ˈgax | ɡax (~ ɡəx) | ɡ ə x | ✔️ | ✔️ | See section 810 | . áit | ɑːt′ | ɑːtʲ | ɑː tʲ | ✔️ | ✔️ | | .",
            "url": "https://jimregan.github.io/notes/kaggle/g2p/mfa/2021/05/14/g2p-with-mfa.html",
            "relUrl": "/kaggle/g2p/mfa/2021/05/14/g2p-with-mfa.html",
            "date": " • May 14, 2021"
        }
        
    
  
    
        ,"post236": {
            "title": "Title",
            "content": "Part, the first . Setting up MFA . To create the same data, fork and run this notebook . !mkdir /tmp/m !mkdir /tmp/c !mkdir /tmp/u !cp ../input/scrape-fuaimeanna-private/wav/*s1.wav /tmp/u !cp ../input/scrape-fuaimeanna-private/wav/*s2.wav /tmp/m !cp ../input/scrape-fuaimeanna-private/wav/*s3.wav /tmp/c . %%writefile /tmp/fuaimeanna-write.pl #!/usr/bin/perl use warnings; use strict; use utf8; binmode(STDIN, &quot;:utf8&quot;); binmode(STDOUT, &quot;:utf8&quot;); binmode(STDERR, &quot;:utf8&quot;); my %cr_files = ( &#39;mo shmidiú&#39; =&gt; &#39;mo chuid smidiú&#39;, &#39;mo shmior&#39; =&gt; &#39;mo chuid smior&#39;, &#39;mo shmólach&#39; =&gt; &#39;mo smólach&#39;, &#39;shmachtaigh&#39; =&gt; &#39;smachtaigh&#39;, &#39;shmaoinigh&#39; =&gt; &#39;smaoinigh&#39;, &#39;shmear&#39; =&gt; &#39;smear&#39;, &#39;deamhain&#39; =&gt; &#39;diabhail&#39;, &#39;folach&#39; =&gt; &#39;i bhfolach&#39;, &#39;captaen&#39; =&gt; &#39;caiptín&#39;, &#39;oirthe&#39; =&gt; &#39;feilte&#39;, ); my %empty = ( &#39;/sounds/gob_i3_s3.mp3&#39; =&gt; 1, &#39;/sounds/iioctha_i3_s3.mp3&#39; =&gt; 1, &#39;/sounds/mo_shuiiochaan_i3_s3.mp3&#39; =&gt; 1, &#39;/sounds/riail_i3_s3.mp3&#39; =&gt; 1 ); open(LEXM, &#39;&gt;&gt;&#39;, &#39;/tmp/lexicon-munster.raw&#39;); binmode LEXM, &#39;:utf8&#39;; open(LEXU, &#39;&gt;&gt;&#39;, &#39;/tmp/lexicon-ulster.raw&#39;); binmode LEXU, &#39;:utf8&#39;; open(LEXC, &#39;&gt;&gt;&#39;, &#39;/tmp/lexicon-connaught.raw&#39;); binmode LEXC, &#39;:utf8&#39;; sub write_text { my $file = shift; my $text = shift; open(OUTF, &#39;&gt;&gt;&#39;, $file); binmode OUTF, &#39;:utf8&#39;; print OUTF $text; close OUTF; } sub write_pron { my $file = shift; my $text = shift; my $pron = shift; if ($text eq &#39;ar tí&#39;) { $pron =~ s/ . ˈ / # /g; } $pron =~ s/ [ˈˌ] / /g; $pron =~ s/^[ˈˌ] //g; $pron =~ s/ . / /g; my @words = split/ /, $text; my @prons = split/ # /, $pron; if($#words != $#prons) { print STDERR &quot;ERROR: $file $text $pron n&quot;; } if($#words == 0) { print $file &quot;$text $pron n&quot;; } else { for(my $i = 0; $i &lt;= $#words; $i++) { print $file &quot;$words[$i] $prons[$i] n&quot;; } } } while(&lt;STDIN&gt;) { chomp; my @line = split/ t/; next if($line[0] eq &#39;Orthographic&#39;); my $text = lc($line[0]); next if($line[0] eq &quot;d&#39;fhág&quot;); my $uout = $line[1]; $uout =~ s!/sounds/!!; $uout =~ s/ .mp3$/.txt/; my $cout = $line[3]; $cout =~ s!/sounds/!!; $cout =~ s/ .mp3$/.txt/; my $mout = $line[5]; $mout =~ s!/sounds/!!; $mout =~ s/ .mp3$/.txt/; $uout = &#39;/tmp/u/&#39; . $uout; $cout = &#39;/tmp/c/&#39; . $cout; $mout = &#39;/tmp/m/&#39; . $mout; my $pronu = $line[2]; my $pronc = $line[4]; my $pronm = $line[6]; if($text eq &#39;Gaeilge&#39;) { write_text($uout, &quot;gaeilic&quot;); write_text($cout, &quot;gaeilge&quot;); write_text($mout, &quot;gaelainn&quot;); write_pron( *LEXU, &quot;gaeilic&quot;, $pronu); write_pron( *LEXC, &quot;gaeilge&quot;, $pronc); write_pron( *LEXM, &quot;gaelainn&quot;, $pronm); next; } if($line[0] eq &#39;bocht&#39; || $line[0] eq &#39;teacht&#39; || $line[0] eq &#39;teocht&#39;) { $pronu =~ s/x t̪ˠ/ɾˠ t̪ˠ/; } write_text($uout, $text); write_pron( *LEXU, $text, $pronu); write_text($mout, $text); write_pron( *LEXM, $text, $pronm); if(!exists $empty{$line[3]}) { my $cfix = exists $cr_files{$text} ? $cr_files{$text} : $text; write_text($cout, $cfix); write_pron( *LEXC, $cfix, $pronc); } } . Writing /tmp/fuaimeanna-write.pl . !cat ../input/scrape-fuaimeanna-private/all-fuaimeanna-data.tsv | perl /tmp/fuaimeanna-write.pl . !cat /tmp/lexicon-connaught.raw | sort | uniq &gt; /tmp/lexicon-connaught.txt !cat /tmp/lexicon-ulster.raw | sort | uniq &gt; /tmp/lexicon-ulster.txt !cat /tmp/lexicon-munster.raw | sort | uniq &gt; /tmp/lexicon-munster.txt !cat /tmp/lexicon-connaught.raw /tmp/lexicon-ulster.raw /tmp/lexicon-munster.raw | sort | uniq &gt; /tmp/lexicon-all.txt . !mkdir /tmp/all !cp /tmp/c/* /tmp/all !cp /tmp/m/* /tmp/all !cp /tmp/u/* /tmp/all !mkdir /tmp/mfa-temp . Run MFA . Aha. Was pinned to an old environment. . !conda config --remove channels rapidsai . !conda install montreal-forced-aligner -y -c conda-forge !mfa train -t /tmp/mfa-temp --output_directory /tmp/textgrid-munster /tmp/m /tmp/lexicon-munster.txt ./munster-model !mfa train -t /tmp/mfa-temp --output_directory /tmp/textgrid-ulster /tmp/u /tmp/lexicon-ulster.txt ./ulster-model !mfa train -t /tmp/mfa-temp --output_directory /tmp/textgrid-connaught /tmp/c /tmp/lexicon-connaught.txt ./connaught-model !mfa train -t /tmp/mfa-temp --output_directory /tmp/textgrid-all /tmp/all /tmp/lexicon-all.txt ./all-model !mfa train_g2p -t /tmp/mfa-temp /tmp/lexicon-ulster.txt ./g2p-ulster !mfa train_g2p -t /tmp/mfa-temp /tmp/lexicon-munster.txt ./g2p-munster !mfa train_g2p -t /tmp/mfa-temp /tmp/lexicon-connaught.txt ./g2p-connaught !mfa train_g2p -t /tmp/mfa-temp /tmp/lexicon-all.txt ./g2p-all . Retrieving notices: ...working... done Collecting package metadata (current_repodata.json): | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | done Solving environment: -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | unsuccessful initial attempt using frozen solve. Retrying with flexible solve. Solving environment: -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / unsuccessful attempt using repodata from current_repodata.json, retrying with next repodata source. Collecting package metadata (repodata.json): | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / done Solving environment: | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  done ## Package Plan ## environment location: /opt/conda added / updated specs: - montreal-forced-aligner The following packages will be downloaded: package | build |-- aom-3.5.0 | h27087fc_0 2.7 MB conda-forge audioread-3.0.0 | py310hff52083_1 34 KB conda-forge baumwelch-0.3.7 | hf52228f_4 362 KB conda-forge biopython-1.79 | py310h5764c6d_3 2.7 MB conda-forge click-8.1.4 |unix_pyh707e725_0 83 KB conda-forge cython-0.29.36 | py310hc6cd4ac_0 2.0 MB conda-forge dataclassy-1.0.1 | pyhd8ed1ab_0 31 KB conda-forge dav1d-1.2.1 | hd590300_0 742 KB conda-forge ffmpeg-6.0.0 | gpl_hdbbbd96_103 9.4 MB conda-forge gnutls-3.7.8 | hf3e180e_0 2.2 MB conda-forge greenlet-2.0.2 | py310hc6cd4ac_1 186 KB conda-forge hdbscan-0.8.30 | py310h278f3c1_0 504 KB conda-forge implicit-0.5.2 | py310h013f86e_1 15.6 MB conda-forge joblib-1.3.0 | pyhd8ed1ab_1 216 KB conda-forge kaldi-5.5.1068 | cpu_h05f3a92_1 20.0 MB conda-forge kneed-0.8.3 | pyhd8ed1ab_0 15 KB conda-forge lazy_loader-0.2 | pyhd8ed1ab_0 13 KB conda-forge libass-0.17.1 | hc9aadba_0 123 KB conda-forge libdrm-2.4.114 | h166bdaf_0 298 KB conda-forge libidn2-2.3.4 | h166bdaf_0 157 KB conda-forge liblapacke-3.9.0 |17_linux64_openblas 14 KB conda-forge libllvm14-14.0.6 | hcd5def8_3 29.9 MB conda-forge libpciaccess-0.17 | h166bdaf_0 39 KB conda-forge librosa-0.10.0 | pyhd8ed1ab_1 188 KB conda-forge libtasn1-4.19.0 | h166bdaf_0 114 KB conda-forge libunistring-0.9.10 | h7f98852_0 1.4 MB conda-forge libva-2.19.0 | hd590300_0 183 KB conda-forge libvpx-1.13.0 | hcb278e6_0 964 KB conda-forge llvmlite-0.40.1 | py310h1b8f574_0 2.4 MB conda-forge mad-0.15.1b | h9c3ff4c_1 113 KB conda-forge markdown-it-py-3.0.0 | pyhd8ed1ab_0 63 KB conda-forge mdurl-0.1.0 | pyhd8ed1ab_0 13 KB conda-forge montreal-forced-aligner-2.2.15| pyhd8ed1ab_0 224 KB conda-forge msgpack-python-1.0.5 | py310hdf3cbec_0 83 KB conda-forge nettle-3.8.1 | hc379101_1 1.1 MB conda-forge ngram-1.3.14 | h924138e_2 3.4 MB conda-forge numba-0.57.1 | py310h0f6aa51_0 4.0 MB conda-forge numpy-1.24.4 | py310ha4c1d20_0 6.4 MB conda-forge openfst-1.8.2 | h924138e_2 7.4 MB conda-forge openh264-2.3.1 | hcb278e6_2 702 KB conda-forge p11-kit-0.24.1 | hc5aa10d_0 4.5 MB conda-forge pandas-2.0.3 | py310h7cbd5c2_1 11.7 MB conda-forge patsy-0.5.3 | pyhd8ed1ab_0 189 KB conda-forge pgvector-0.4.4 | he295718_0 41 KB conda-forge pgvector-python-0.1.8 | pyhb2dc1fd_0 13 KB conda-forge postgresql-15.3 | hd458b1d_1 4.9 MB conda-forge praatio-6.0.0 | pyhd8ed1ab_0 60 KB conda-forge psycopg2-2.9.6 | py310h76c1b15_0 170 KB conda-forge pynini-2.1.5 | py310hbf28c38_5 1.5 MB conda-forge pysoundfile-0.12.1 | pyhd8ed1ab_0 27 KB conda-forge python-tzdata-2023.3 | pyhd8ed1ab_0 140 KB conda-forge pytz-2023.3 | pyhd8ed1ab_0 182 KB conda-forge rich-13.4.2 | pyhd8ed1ab_0 179 KB conda-forge rich-click-1.6.1 | pyhd8ed1ab_0 22 KB conda-forge scikit-learn-1.2.2 | py310hf7d194e_2 7.3 MB conda-forge seaborn-0.12.2 | hd8ed1ab_0 6 KB conda-forge seaborn-base-0.12.2 | pyhd8ed1ab_0 226 KB conda-forge sox-14.4.2 | ha5cc309_1018 499 KB conda-forge soxr-0.1.3 | h0b41bf4_3 128 KB conda-forge soxr-python-0.3.5 | py310h278f3c1_0 259 KB conda-forge sqlalchemy-2.0.18 | py310h2372a71_0 2.5 MB conda-forge statsmodels-0.14.0 | py310h278f3c1_1 10.1 MB conda-forge svt-av1-1.6.0 | h59595ed_0 2.5 MB conda-forge threadpoolctl-3.1.0 | pyh8a188c0_0 18 KB conda-forge tzcode-2023c | h0b41bf4_0 67 KB conda-forge x264-1!164.3095 | h166bdaf_2 877 KB conda-forge x265-3.5 | h924138e_3 3.2 MB conda-forge Total: 167.2 MB The following NEW packages will be INSTALLED: aom conda-forge/linux-64::aom-3.5.0-h27087fc_0 audioread conda-forge/linux-64::audioread-3.0.0-py310hff52083_1 baumwelch conda-forge/linux-64::baumwelch-0.3.7-hf52228f_4 biopython conda-forge/linux-64::biopython-1.79-py310h5764c6d_3 click conda-forge/noarch::click-8.1.4-unix_pyh707e725_0 cython conda-forge/linux-64::cython-0.29.36-py310hc6cd4ac_0 dataclassy conda-forge/noarch::dataclassy-1.0.1-pyhd8ed1ab_0 dav1d conda-forge/linux-64::dav1d-1.2.1-hd590300_0 ffmpeg conda-forge/linux-64::ffmpeg-6.0.0-gpl_hdbbbd96_103 gnutls conda-forge/linux-64::gnutls-3.7.8-hf3e180e_0 greenlet conda-forge/linux-64::greenlet-2.0.2-py310hc6cd4ac_1 hdbscan conda-forge/linux-64::hdbscan-0.8.30-py310h278f3c1_0 joblib conda-forge/noarch::joblib-1.3.0-pyhd8ed1ab_1 kaldi conda-forge/linux-64::kaldi-5.5.1068-cpu_h05f3a92_1 kneed conda-forge/noarch::kneed-0.8.3-pyhd8ed1ab_0 lazy_loader conda-forge/noarch::lazy_loader-0.2-pyhd8ed1ab_0 libass conda-forge/linux-64::libass-0.17.1-hc9aadba_0 libdrm conda-forge/linux-64::libdrm-2.4.114-h166bdaf_0 libidn2 conda-forge/linux-64::libidn2-2.3.4-h166bdaf_0 liblapacke conda-forge/linux-64::liblapacke-3.9.0-17_linux64_openblas libllvm14 conda-forge/linux-64::libllvm14-14.0.6-hcd5def8_3 libpciaccess conda-forge/linux-64::libpciaccess-0.17-h166bdaf_0 librosa conda-forge/noarch::librosa-0.10.0-pyhd8ed1ab_1 libtasn1 conda-forge/linux-64::libtasn1-4.19.0-h166bdaf_0 libunistring conda-forge/linux-64::libunistring-0.9.10-h7f98852_0 libva conda-forge/linux-64::libva-2.19.0-hd590300_0 libvpx conda-forge/linux-64::libvpx-1.13.0-hcb278e6_0 llvmlite conda-forge/linux-64::llvmlite-0.40.1-py310h1b8f574_0 mad conda-forge/linux-64::mad-0.15.1b-h9c3ff4c_1 markdown-it-py conda-forge/noarch::markdown-it-py-3.0.0-pyhd8ed1ab_0 mdurl conda-forge/noarch::mdurl-0.1.0-pyhd8ed1ab_0 montreal-forced-a~ conda-forge/noarch::montreal-forced-aligner-2.2.15-pyhd8ed1ab_0 msgpack-python conda-forge/linux-64::msgpack-python-1.0.5-py310hdf3cbec_0 nettle conda-forge/linux-64::nettle-3.8.1-hc379101_1 ngram conda-forge/linux-64::ngram-1.3.14-h924138e_2 numba conda-forge/linux-64::numba-0.57.1-py310h0f6aa51_0 openfst conda-forge/linux-64::openfst-1.8.2-h924138e_2 openh264 conda-forge/linux-64::openh264-2.3.1-hcb278e6_2 p11-kit conda-forge/linux-64::p11-kit-0.24.1-hc5aa10d_0 pandas conda-forge/linux-64::pandas-2.0.3-py310h7cbd5c2_1 patsy conda-forge/noarch::patsy-0.5.3-pyhd8ed1ab_0 pgvector conda-forge/linux-64::pgvector-0.4.4-he295718_0 pgvector-python conda-forge/noarch::pgvector-python-0.1.8-pyhb2dc1fd_0 postgresql conda-forge/linux-64::postgresql-15.3-hd458b1d_1 praatio conda-forge/noarch::praatio-6.0.0-pyhd8ed1ab_0 psycopg2 conda-forge/linux-64::psycopg2-2.9.6-py310h76c1b15_0 pynini conda-forge/linux-64::pynini-2.1.5-py310hbf28c38_5 pysoundfile conda-forge/noarch::pysoundfile-0.12.1-pyhd8ed1ab_0 python-tzdata conda-forge/noarch::python-tzdata-2023.3-pyhd8ed1ab_0 pytz conda-forge/noarch::pytz-2023.3-pyhd8ed1ab_0 rich conda-forge/noarch::rich-13.4.2-pyhd8ed1ab_0 rich-click conda-forge/noarch::rich-click-1.6.1-pyhd8ed1ab_0 scikit-learn conda-forge/linux-64::scikit-learn-1.2.2-py310hf7d194e_2 seaborn conda-forge/noarch::seaborn-0.12.2-hd8ed1ab_0 seaborn-base conda-forge/noarch::seaborn-base-0.12.2-pyhd8ed1ab_0 sox conda-forge/linux-64::sox-14.4.2-ha5cc309_1018 soxr conda-forge/linux-64::soxr-0.1.3-h0b41bf4_3 soxr-python conda-forge/linux-64::soxr-python-0.3.5-py310h278f3c1_0 sqlalchemy conda-forge/linux-64::sqlalchemy-2.0.18-py310h2372a71_0 statsmodels conda-forge/linux-64::statsmodels-0.14.0-py310h278f3c1_1 svt-av1 conda-forge/linux-64::svt-av1-1.6.0-h59595ed_0 threadpoolctl conda-forge/noarch::threadpoolctl-3.1.0-pyh8a188c0_0 tzcode conda-forge/linux-64::tzcode-2023c-h0b41bf4_0 x264 conda-forge/linux-64::x264-1!164.3095-h166bdaf_2 x265 conda-forge/linux-64::x265-3.5-h924138e_3 The following packages will be DOWNGRADED: implicit 0.7.0-py310h552f1b7_6 --&gt; 0.5.2-py310h013f86e_1 numpy 1.25.0-py310ha4c1d20_0 --&gt; 1.24.4-py310ha4c1d20_0 Downloading and Extracting Packages libva-2.19.0 | 183 KB | | 0% nettle-3.8.1 | 1.1 MB | | 0% joblib-1.3.0 | 216 KB | | 0% seaborn-base-0.12.2 | 226 KB | | 0% soxr-0.1.3 | 128 KB | | 0% markdown-it-py-3.0.0 | 63 KB | | 0% baumwelch-0.3.7 | 362 KB | | 0% psycopg2-2.9.6 | 170 KB | | 0% msgpack-python-1.0.5 | 83 KB | | 0% x264-1!164.3095 | 877 KB | | 0% llvmlite-0.40.1 | 2.4 MB | | 0% cython-0.29.36 | 2.0 MB | | 0% dataclassy-1.0.1 | 31 KB | | 0% libpciaccess-0.17 | 39 KB | | 0% libvpx-1.13.0 | 964 KB | | 0% libass-0.17.1 | 123 KB | | 0% rich-click-1.6.1 | 22 KB | | 0% mdurl-0.1.0 | 13 KB | | 0% pysoundfile-0.12.1 | 27 KB | | 0% patsy-0.5.3 | 189 KB | | 0% hdbscan-0.8.30 | 504 KB | | 0% sox-14.4.2 | 499 KB | | 0% libdrm-2.4.114 | 298 KB | | 0% libva-2.19.0 | 183 KB | ###2 | 9% nettle-3.8.1 | 1.1 MB | 5 | 1% joblib-1.3.0 | 216 KB | ##7 | 7% seaborn-base-0.12.2 | 226 KB | ##6 | 7% soxr-0.1.3 | 128 KB | ####6 | 12% markdown-it-py-3.0.0 | 63 KB | #########4 | 25% msgpack-python-1.0.5 | 83 KB | #######1 | 19% nettle-3.8.1 | 1.1 MB | ###############################9 | 86% psycopg2-2.9.6 | 170 KB | ###4 | 9% baumwelch-0.3.7 | 362 KB | #6 | 4% x264-1!164.3095 | 877 KB | 6 | 2% llvmlite-0.40.1 | 2.4 MB | 2 | 1% cython-0.29.36 | 2.0 MB | 2 | 1% libva-2.19.0 | 183 KB | ##################################### | 100% dataclassy-1.0.1 | 31 KB | ###################1 | 52% libvpx-1.13.0 | 964 KB | 6 | 2% libass-0.17.1 | 123 KB | ####8 | 13% rich-click-1.6.1 | 22 KB | ##########################7 | 72% llvmlite-0.40.1 | 2.4 MB | ##################1 | 49% cython-0.29.36 | 2.0 MB | ############################### | 84% mdurl-0.1.0 | 13 KB | ##################################### | 100% pysoundfile-0.12.1 | 27 KB | #####################5 | 58% patsy-0.5.3 | 189 KB | ###1 | 8% sox-14.4.2 | 499 KB | #1 | 3% libdrm-2.4.114 | 298 KB | #9 | 5% ... (more hidden) ... hdbscan-0.8.30 | 504 KB | #1 | 3% seaborn-base-0.12.2 | 226 KB | ##################################### | 100% seaborn-base-0.12.2 | 226 KB | ##################################### | 100% markdown-it-py-3.0.0 | 63 KB | ##################################### | 100% markdown-it-py-3.0.0 | 63 KB | ##################################### | 100% soxr-0.1.3 | 128 KB | ##################################### | 100% soxr-0.1.3 | 128 KB | ##################################### | 100% joblib-1.3.0 | 216 KB | ##################################### | 100% joblib-1.3.0 | 216 KB | ##################################### | 100% msgpack-python-1.0.5 | 83 KB | ##################################### | 100% msgpack-python-1.0.5 | 83 KB | ##################################### | 100% psycopg2-2.9.6 | 170 KB | ##################################### | 100% psycopg2-2.9.6 | 170 KB | ##################################### | 100% baumwelch-0.3.7 | 362 KB | ##################################### | 100% baumwelch-0.3.7 | 362 KB | ##################################### | 100% libpciaccess-0.17 | 39 KB | ##################################### | 100% libpciaccess-0.17 | 39 KB | ##################################### | 100% dataclassy-1.0.1 | 31 KB | ##################################### | 100% dataclassy-1.0.1 | 31 KB | ##################################### | 100% libass-0.17.1 | 123 KB | ##################################### | 100% libass-0.17.1 | 123 KB | ##################################### | 100% rich-click-1.6.1 | 22 KB | ##################################### | 100% rich-click-1.6.1 | 22 KB | ##################################### | 100% mdurl-0.1.0 | 13 KB | ##################################### | 100% x264-1!164.3095 | 877 KB | ##################################### | 100% x264-1!164.3095 | 877 KB | ##################################### | 100% pysoundfile-0.12.1 | 27 KB | ##################################### | 100% pysoundfile-0.12.1 | 27 KB | ##################################### | 100% nettle-3.8.1 | 1.1 MB | ##################################### | 100% libvpx-1.13.0 | 964 KB | ##################################### | 100% libvpx-1.13.0 | 964 KB | ##################################### | 100% patsy-0.5.3 | 189 KB | ##################################### | 100% patsy-0.5.3 | 189 KB | ##################################### | 100% llvmlite-0.40.1 | 2.4 MB | ##################################### | 100% llvmlite-0.40.1 | 2.4 MB | ##################################### | 100% libdrm-2.4.114 | 298 KB | ##################################### | 100% libdrm-2.4.114 | 298 KB | ##################################### | 100% sox-14.4.2 | 499 KB | ##################################### | 100% sox-14.4.2 | 499 KB | ##################################### | 100% hdbscan-0.8.30 | 504 KB | ##################################### | 100% hdbscan-0.8.30 | 504 KB | ##################################### | 100% cython-0.29.36 | 2.0 MB | ##################################### | 100% ... (more hidden) ... ... (more hidden) ... Preparing transaction: / -  | / -  | / done Verifying transaction: | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / done Executing transaction: | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / -  | / done /opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version &gt;=1.16.5 and &lt;1.23.0 is required for this version of SciPy (detected version 1.24.4 warnings.warn(f&#34;A NumPy version &gt;={np_minversion} and &lt;{np_maxversion}&#34; INFO Setting up corpus information... INFO Loading corpus from source files... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 527/100 [ 0:00:00 &lt; 0:00:00 , 3,178 it/s ] INFO Found 1 speaker across 760 files, average number of utterances per speaker: 760.0 INFO Initializing multiprocessing jobs... WARNING Number of jobs was specified as 3, but due to only having 1 speakers, MFA will only use 1 jobs. Use the --single_speaker flag if you would like to split utterances across jobs regardless of their speaker. INFO Normalizing text... 11% ━━━╸━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 82/760 [ 0:00:01 &lt; -:--:-- , ? it/s ] INFO Creating corpus split for feature generation... 0% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1,520 [ 0:00:01 &lt; -:--:-- , ? it/s ] INFO Generating MFCCs... 98% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 744/760 [ 0:00:15 &lt; 0:00:01 , 157 it/s ] INFO Calculating CMVN... INFO Generating final features... 77% ━━━━━━━━━━━━━━━━━━━━━━━╺━━━━━━ 586/760 [ 0:00:01 &lt; 0:00:01 , 1,734 it/s ] INFO Creating corpus split with features... 0% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/760 [ 0:00:01 &lt; -:--:-- , ? it/s ] INFO Filtering utterances for training... INFO Initializing training for monophone... INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Generating initial alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Initialization complete! INFO monophone - Iteration 1 of 40 INFO Generating alignments... 96% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━ 727/760 [ 0:00:02 &lt; 0:00:01 , 635 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:01 &lt; 0:00:01 , 1,971 it/s ] INFO monophone - Iteration 2 of 40 INFO Generating alignments... 91% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━━ 693/760 [ 0:00:02 &lt; 0:00:01 , 741 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:01 &lt; 0:00:01 , 1,906 it/s ] INFO monophone - Iteration 3 of 40 INFO Generating alignments... 97% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 738/760 [ 0:00:02 &lt; 0:00:01 , 731 it/s ] INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,866 it/s ] INFO monophone - Iteration 4 of 40 INFO Generating alignments... 95% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━ 720/760 [ 0:00:02 &lt; 0:00:01 , 784 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:01 &lt; 0:00:01 , 1,842 it/s ] INFO monophone - Iteration 5 of 40 INFO Generating alignments... 93% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 704/760 [ 0:00:02 &lt; 0:00:01 , 774 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:01 &lt; 0:00:01 , 1,869 it/s ] INFO monophone - Iteration 6 of 40 INFO Generating alignments... 95% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━ 722/760 [ 0:00:02 &lt; 0:00:01 , 797 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:01 &lt; 0:00:01 , 1,814 it/s ] INFO monophone - Iteration 7 of 40 INFO Generating alignments... 97% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━ 734/760 [ 0:00:02 &lt; 0:00:01 , 776 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:01 &lt; 0:00:01 , 1,855 it/s ] INFO monophone - Iteration 8 of 40 INFO Generating alignments... 96% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━ 727/760 [ 0:00:02 &lt; 0:00:01 , 797 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:01 &lt; 0:00:01 , 1,626 it/s ] INFO monophone - Iteration 9 of 40 INFO Generating alignments... 93% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 706/760 [ 0:00:02 &lt; 0:00:01 , 765 it/s ] INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,752 it/s ] INFO monophone - Iteration 10 of 40 INFO Generating alignments... 98% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 747/760 [ 0:00:02 &lt; 0:00:01 , 809 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:01 &lt; 0:00:01 , 1,766 it/s ] INFO monophone - Iteration 11 of 40 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:01 &lt; 0:00:01 , 1,754 it/s ] INFO monophone - Iteration 12 of 40 INFO Generating alignments... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━━ 700/760 [ 0:00:02 &lt; 0:00:01 , 769 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:01 &lt; 0:00:01 , 1,732 it/s ] INFO monophone - Iteration 13 of 40 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:01 &lt; 0:00:01 , 1,749 it/s ] INFO monophone - Iteration 14 of 40 INFO Generating alignments... 91% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━━ 689/760 [ 0:00:02 &lt; 0:00:01 , 749 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:01 &lt; 0:00:01 , 1,729 it/s ] INFO monophone - Iteration 15 of 40 INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,671 it/s ] INFO monophone - Iteration 16 of 40 INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 756/760 [ 0:00:02 &lt; 0:00:01 , 742 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:01 &lt; 0:00:01 , 1,674 it/s ] INFO monophone - Iteration 17 of 40 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:01 &lt; 0:00:01 , 1,682 it/s ] INFO monophone - Iteration 18 of 40 INFO Generating alignments... 94% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 711/760 [ 0:00:02 &lt; 0:00:01 , 751 it/s ] INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,565 it/s ] INFO monophone - Iteration 19 of 40 INFO Accumulating statistics... 86% ━━━━━━━━━━━━━━━━━━━━━━━━━╸━━━━ 650/760 [ 0:00:01 &lt; 0:00:01 , 1,540 it/s ] INFO monophone - Iteration 20 of 40 INFO Generating alignments... 96% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━ 728/760 [ 0:00:02 &lt; 0:00:01 , 712 it/s ] INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,616 it/s ] INFO monophone - Iteration 21 of 40 INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,597 it/s ] INFO monophone - Iteration 22 of 40 INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,571 it/s ] INFO monophone - Iteration 23 of 40 INFO Generating alignments... 95% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━ 722/760 [ 0:00:02 &lt; 0:00:01 , 706 it/s ] INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,536 it/s ] INFO monophone - Iteration 24 of 40 INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,564 it/s ] INFO monophone - Iteration 25 of 40 INFO Accumulating statistics... 86% ━━━━━━━━━━━━━━━━━━━━━━━━━╸━━━━ 650/760 [ 0:00:01 &lt; 0:00:01 , 1,494 it/s ] INFO monophone - Iteration 26 of 40 INFO Generating alignments... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 702/760 [ 0:00:02 &lt; 0:00:01 , 686 it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:00 &lt; 0:00:00 , 1,473 it/s ] INFO monophone - Iteration 27 of 40 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:01 &lt; 0:00:01 , 1,450 it/s ] INFO monophone - Iteration 28 of 40 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:01 &lt; 0:00:01 , 1,481 it/s ] INFO monophone - Iteration 29 of 40 INFO Generating alignments... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━━ 697/760 [ 0:00:02 &lt; 0:00:01 , 686 it/s ] INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,460 it/s ] INFO monophone - Iteration 30 of 40 INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,425 it/s ] INFO monophone - Iteration 31 of 40 INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,399 it/s ] INFO monophone - Iteration 32 of 40 INFO Generating alignments... 96% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━ 728/760 [ 0:00:02 &lt; 0:00:01 , 549 it/s ] INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,360 it/s ] INFO monophone - Iteration 33 of 40 INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,402 it/s ] INFO monophone - Iteration 34 of 40 INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,380 it/s ] INFO monophone - Iteration 35 of 40 INFO Generating alignments... 98% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 748/760 [ 0:00:02 &lt; 0:00:01 , 668 it/s ] INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,387 it/s ] INFO monophone - Iteration 36 of 40 INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,394 it/s ] INFO monophone - Iteration 37 of 40 INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,372 it/s ] INFO monophone - Iteration 38 of 40 INFO Generating alignments... 98% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 746/760 [ 0:00:02 &lt; 0:00:01 , 665 it/s ] INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,387 it/s ] INFO monophone - Iteration 39 of 40 INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,403 it/s ] INFO monophone - Iteration 40 of 40 INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,329 it/s ] INFO Training complete! INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Generating alignments... 97% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 740/760 [ 0:00:02 &lt; 0:00:01 , 659 it/s ] INFO Initializing training for triphone... INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Converting alignments... 0% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0/760 [ 0:00:01 &lt; -:--:-- , ? it/s ] INFO Initialization complete! INFO triphone - Iteration 1 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:00 &lt; 0:00:00 , 1,098 it/s ] INFO triphone - Iteration 2 of 35 INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,108 it/s ] INFO triphone - Iteration 3 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:01 &lt; 0:00:01 , 907 it/s ] INFO triphone - Iteration 4 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:02 &lt; 0:00:01 , 670 it/s ] INFO triphone - Iteration 5 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:02 &lt; 0:00:01 , 515 it/s ] INFO triphone - Iteration 6 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:02 &lt; 0:00:01 , 431 it/s ] INFO triphone - Iteration 7 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:03 &lt; 0:00:01 , 326 it/s ] INFO triphone - Iteration 8 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:04 &lt; 0:00:01 , 243 it/s ] INFO triphone - Iteration 9 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:04 &lt; 0:00:01 , 196 it/s ] INFO triphone - Iteration 10 of 35 INFO Generating alignments... 98% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 745/760 [ 0:00:05 &lt; 0:00:01 , 177 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:05 &lt; 0:00:01 , 161 it/s ] INFO triphone - Iteration 11 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:07 &lt; 0:00:01 , 126 it/s ] INFO triphone - Iteration 12 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 138 it/s ] INFO triphone - Iteration 13 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 135 it/s ] INFO triphone - Iteration 14 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 134 it/s ] INFO triphone - Iteration 15 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 133 it/s ] INFO triphone - Iteration 16 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 129 it/s ] INFO triphone - Iteration 17 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 131 it/s ] INFO triphone - Iteration 18 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 129 it/s ] INFO triphone - Iteration 19 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:07 &lt; 0:00:01 , 127 it/s ] INFO triphone - Iteration 20 of 35 INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 753/760 [ 0:00:05 &lt; 0:00:01 , 175 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:07 &lt; 0:00:01 , 127 it/s ] INFO triphone - Iteration 21 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 128 it/s ] INFO triphone - Iteration 22 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:07 &lt; 0:00:01 , 126 it/s ] INFO triphone - Iteration 23 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:07 &lt; 0:00:01 , 125 it/s ] INFO triphone - Iteration 24 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:07 &lt; 0:00:01 , 125 it/s ] INFO triphone - Iteration 25 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:07 &lt; 0:00:01 , 126 it/s ] INFO triphone - Iteration 26 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:07 &lt; 0:00:01 , 124 it/s ] INFO triphone - Iteration 27 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:07 &lt; 0:00:01 , 124 it/s ] INFO triphone - Iteration 28 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:07 &lt; 0:00:01 , 125 it/s ] INFO triphone - Iteration 29 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:07 &lt; 0:00:01 , 125 it/s ] INFO triphone - Iteration 30 of 35 INFO Generating alignments... 98% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 748/760 [ 0:00:05 &lt; 0:00:01 , 174 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:07 &lt; 0:00:01 , 121 it/s ] INFO triphone - Iteration 31 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:07 &lt; 0:00:01 , 126 it/s ] INFO triphone - Iteration 32 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:07 &lt; 0:00:01 , 124 it/s ] INFO triphone - Iteration 33 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:07 &lt; 0:00:01 , 124 it/s ] INFO triphone - Iteration 34 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:07 &lt; 0:00:01 , 123 it/s ] INFO triphone - Iteration 35 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:07 &lt; 0:00:01 , 121 it/s ] INFO Training complete! INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 753/760 [ 0:00:05 &lt; 0:00:01 , 166 it/s ] INFO Initializing training for lda... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Converting alignments... 0% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0/760 [ 0:00:01 &lt; -:--:-- , ? it/s ] INFO Initialization complete! INFO lda - Iteration 1 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:01 &lt; 0:00:01 , 1,786 it/s ] INFO lda - Iteration 2 of 35 INFO Re-calculating LDA... 84% ━━━━━━━━━━━━━━━━━━━━━━━━━╺━━━━ 640/760 [ 0:00:01 &lt; 0:00:01 , 1,899 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:02 &lt; 0:00:01 , 742 it/s ] INFO lda - Iteration 3 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:02 &lt; 0:00:01 , 487 it/s ] INFO lda - Iteration 4 of 35 INFO Re-calculating LDA... 88% ━━━━━━━━━━━━━━━━━━━━━━━━━━╺━━━ 666/760 [ 0:00:01 &lt; 0:00:01 , 1,508 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:03 &lt; 0:00:01 , 350 it/s ] INFO lda - Iteration 5 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:04 &lt; 0:00:01 , 223 it/s ] INFO lda - Iteration 6 of 35 INFO Re-calculating LDA... 86% ━━━━━━━━━━━━━━━━━━━━━━━━━╸━━━━ 650/760 [ 0:00:01 &lt; 0:00:01 , 1,918 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:05 &lt; 0:00:01 , 168 it/s ] INFO lda - Iteration 7 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 146 it/s ] INFO lda - Iteration 8 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 140 it/s ] INFO lda - Iteration 9 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 138 it/s ] INFO lda - Iteration 10 of 35 INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 754/760 [ 0:00:05 &lt; 0:00:01 , 171 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 148 it/s ] INFO lda - Iteration 11 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 151 it/s ] INFO lda - Iteration 12 of 35 INFO Re-calculating LDA... 83% ━━━━━━━━━━━━━━━━━━━━━━━━╸━━━━━ 632/760 [ 0:00:01 &lt; 0:00:01 , 1,870 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 149 it/s ] INFO lda - Iteration 13 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 150 it/s ] INFO lda - Iteration 14 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:05 &lt; 0:00:01 , 154 it/s ] INFO lda - Iteration 15 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 153 it/s ] INFO lda - Iteration 16 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 152 it/s ] INFO lda - Iteration 17 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 153 it/s ] INFO lda - Iteration 18 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 148 it/s ] INFO lda - Iteration 19 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 150 it/s ] INFO lda - Iteration 20 of 35 INFO Generating alignments... 98% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 748/760 [ 0:00:04 &lt; 0:00:01 , 198 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 150 it/s ] INFO lda - Iteration 21 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 150 it/s ] INFO lda - Iteration 22 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 148 it/s ] INFO lda - Iteration 23 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 149 it/s ] INFO lda - Iteration 24 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 147 it/s ] INFO lda - Iteration 25 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 149 it/s ] INFO lda - Iteration 26 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 150 it/s ] INFO lda - Iteration 27 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 146 it/s ] INFO lda - Iteration 28 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 149 it/s ] INFO lda - Iteration 29 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 147 it/s ] INFO lda - Iteration 30 of 35 INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 752/760 [ 0:00:04 &lt; 0:00:01 , 207 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 149 it/s ] INFO lda - Iteration 31 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 142 it/s ] INFO lda - Iteration 32 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:07 &lt; 0:00:01 , 125 it/s ] INFO lda - Iteration 33 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 146 it/s ] INFO lda - Iteration 34 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 145 it/s ] INFO lda - Iteration 35 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 146 it/s ] INFO Training complete! INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 751/760 [ 0:00:05 &lt; 0:00:01 , 183 it/s ] INFO Initializing training for sat... INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Converting alignments... 0% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0/760 [ 0:00:01 &lt; -:--:-- , ? it/s ] INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Initialization complete! INFO sat - Iteration 1 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:01 &lt; 0:00:01 , 1,364 it/s ] INFO sat - Iteration 2 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:01 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:03 &lt; 0:00:01 , 306 it/s ] INFO sat - Iteration 3 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:04 &lt; 0:00:01 , 231 it/s ] INFO sat - Iteration 4 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:05 &lt; 0:00:01 , 167 it/s ] INFO sat - Iteration 5 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 154 it/s ] INFO sat - Iteration 6 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 154 it/s ] INFO sat - Iteration 7 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 149 it/s ] INFO sat - Iteration 8 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 152 it/s ] INFO sat - Iteration 9 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 148 it/s ] INFO sat - Iteration 10 of 35 INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 752/760 [ 0:00:05 &lt; 0:00:01 , 170 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 151 it/s ] INFO sat - Iteration 11 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 138 it/s ] INFO sat - Iteration 12 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 149 it/s ] INFO sat - Iteration 13 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 149 it/s ] INFO sat - Iteration 14 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 148 it/s ] INFO sat - Iteration 15 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 146 it/s ] INFO sat - Iteration 16 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 149 it/s ] INFO sat - Iteration 17 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 147 it/s ] INFO sat - Iteration 18 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 146 it/s ] INFO sat - Iteration 19 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 148 it/s ] INFO sat - Iteration 20 of 35 INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 751/760 [ 0:00:05 &lt; 0:00:01 , 195 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 148 it/s ] INFO sat - Iteration 21 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 148 it/s ] INFO sat - Iteration 22 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 146 it/s ] INFO sat - Iteration 23 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 152 it/s ] INFO sat - Iteration 24 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 144 it/s ] INFO sat - Iteration 25 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 148 it/s ] INFO sat - Iteration 26 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 149 it/s ] INFO sat - Iteration 27 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 144 it/s ] INFO sat - Iteration 28 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 147 it/s ] INFO sat - Iteration 29 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 148 it/s ] INFO sat - Iteration 30 of 35 INFO Generating alignments... 98% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 741/760 [ 0:00:05 &lt; 0:00:01 , 198 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 148 it/s ] INFO sat - Iteration 31 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 143 it/s ] INFO sat - Iteration 32 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 146 it/s ] INFO sat - Iteration 33 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 147 it/s ] INFO sat - Iteration 34 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 143 it/s ] INFO sat - Iteration 35 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 148 it/s ] INFO Creating alignment model for speaker-independent features... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 758/760 [ 0:00:06 &lt; 0:00:01 , 140 it/s ] INFO Training complete! INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 749/760 [ 0:00:05 &lt; 0:00:01 , 205 it/s ] INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:01 &lt; 0:00:00 , ? it/s ] INFO Generating alignments... 98% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 747/760 [ 0:00:04 &lt; 0:00:01 , 204 it/s ] INFO Initializing training for sat_2... INFO Converting alignments... 0% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0/760 [ 0:00:01 &lt; -:--:-- , ? it/s ] INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Initialization complete! INFO sat_2 - Iteration 1 of 35 INFO Accumulating statistics... 79% ━━━━━━━━━━━━━━━━━━━━━━━╸━━━━━━ 600/760 [ 0:00:01 &lt; 0:00:01 , 1,833 it/s ] INFO sat_2 - Iteration 2 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:05 &lt; 0:00:01 , 162 it/s ] INFO sat_2 - Iteration 3 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 153 it/s ] INFO sat_2 - Iteration 4 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:05 &lt; 0:00:01 , 155 it/s ] INFO sat_2 - Iteration 5 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:05 &lt; 0:00:01 , 155 it/s ] INFO sat_2 - Iteration 6 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 142 it/s ] INFO sat_2 - Iteration 7 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 149 it/s ] INFO sat_2 - Iteration 8 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 152 it/s ] INFO sat_2 - Iteration 9 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 154 it/s ] INFO sat_2 - Iteration 10 of 35 INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 749/760 [ 0:00:05 &lt; 0:00:01 , 176 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 143 it/s ] INFO sat_2 - Iteration 11 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 150 it/s ] INFO sat_2 - Iteration 12 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:05 &lt; 0:00:01 , 154 it/s ] INFO sat_2 - Iteration 13 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 149 it/s ] INFO sat_2 - Iteration 14 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 146 it/s ] INFO sat_2 - Iteration 15 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 145 it/s ] INFO sat_2 - Iteration 16 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 150 it/s ] INFO sat_2 - Iteration 17 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 153 it/s ] INFO sat_2 - Iteration 18 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 147 it/s ] INFO sat_2 - Iteration 19 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 147 it/s ] INFO sat_2 - Iteration 20 of 35 INFO Generating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 759/760 [ 0:00:05 &lt; 0:00:01 , 195 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 149 it/s ] INFO sat_2 - Iteration 21 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 150 it/s ] INFO sat_2 - Iteration 22 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 145 it/s ] INFO sat_2 - Iteration 23 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 150 it/s ] INFO sat_2 - Iteration 24 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 145 it/s ] INFO sat_2 - Iteration 25 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 150 it/s ] INFO sat_2 - Iteration 26 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 148 it/s ] INFO sat_2 - Iteration 27 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 150 it/s ] INFO sat_2 - Iteration 28 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 148 it/s ] INFO sat_2 - Iteration 29 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 136 it/s ] INFO sat_2 - Iteration 30 of 35 INFO Generating alignments... 98% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 744/760 [ 0:00:04 &lt; 0:00:01 , 205 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 151 it/s ] INFO sat_2 - Iteration 31 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 149 it/s ] INFO sat_2 - Iteration 32 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 148 it/s ] INFO sat_2 - Iteration 33 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 148 it/s ] INFO sat_2 - Iteration 34 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 151 it/s ] INFO sat_2 - Iteration 35 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 148 it/s ] INFO Creating alignment model for speaker-independent features... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 751/760 [ 0:00:06 &lt; 0:00:01 , 143 it/s ] INFO Training complete! INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 749/760 [ 0:00:04 &lt; 0:00:01 , 204 it/s ] INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:01 &lt; 0:00:00 , ? it/s ] INFO Generating alignments... 98% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 743/760 [ 0:00:04 &lt; 0:00:01 , 197 it/s ] INFO Generating pronunciations... 22% ━━━━━━━╺━━━━━━━━━━━━━━━━━━━━━━━━ 168/760 [ 0:00:01 &lt; 0:00:02 , 398 it/s ] INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 756/760 [ 0:00:04 &lt; 0:00:01 , 201 it/s ] INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:01 &lt; 0:00:00 , ? it/s ] INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 749/760 [ 0:00:04 &lt; 0:00:01 , 199 it/s ] INFO Initializing training for sat_3... INFO Converting alignments... 0% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0/760 [ 0:00:01 &lt; -:--:-- , ? it/s ] INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Initialization complete! INFO sat_3 - Iteration 1 of 35 INFO Accumulating statistics... 79% ━━━━━━━━━━━━━━━━━━━━━━━╸━━━━━━ 600/760 [ 0:00:01 &lt; 0:00:01 , 2,038 it/s ] INFO sat_3 - Iteration 2 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 152 it/s ] INFO sat_3 - Iteration 3 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:05 &lt; 0:00:01 , 155 it/s ] INFO sat_3 - Iteration 4 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 153 it/s ] INFO sat_3 - Iteration 5 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:05 &lt; 0:00:01 , 155 it/s ] INFO sat_3 - Iteration 6 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 154 it/s ] INFO sat_3 - Iteration 7 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 150 it/s ] INFO sat_3 - Iteration 8 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:05 &lt; 0:00:01 , 156 it/s ] INFO sat_3 - Iteration 9 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 151 it/s ] INFO sat_3 - Iteration 10 of 35 INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 753/760 [ 0:00:05 &lt; 0:00:01 , 175 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 151 it/s ] INFO sat_3 - Iteration 11 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 149 it/s ] INFO sat_3 - Iteration 12 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 144 it/s ] INFO sat_3 - Iteration 13 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 150 it/s ] INFO sat_3 - Iteration 14 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 150 it/s ] INFO sat_3 - Iteration 15 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 145 it/s ] INFO sat_3 - Iteration 16 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 149 it/s ] INFO sat_3 - Iteration 17 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 149 it/s ] INFO sat_3 - Iteration 18 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 151 it/s ] INFO sat_3 - Iteration 19 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 145 it/s ] INFO sat_3 - Iteration 20 of 35 INFO Generating alignments... 98% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 744/760 [ 0:00:04 &lt; 0:00:01 , 198 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 151 it/s ] INFO sat_3 - Iteration 21 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 147 it/s ] INFO sat_3 - Iteration 22 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 146 it/s ] INFO sat_3 - Iteration 23 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 149 it/s ] INFO sat_3 - Iteration 24 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 148 it/s ] INFO sat_3 - Iteration 25 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 147 it/s ] INFO sat_3 - Iteration 26 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 148 it/s ] INFO sat_3 - Iteration 27 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 145 it/s ] INFO sat_3 - Iteration 28 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 150 it/s ] INFO sat_3 - Iteration 29 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 147 it/s ] INFO sat_3 - Iteration 30 of 35 INFO Generating alignments... 98% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 741/760 [ 0:00:04 &lt; 0:00:01 , 203 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 146 it/s ] INFO sat_3 - Iteration 31 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 149 it/s ] INFO sat_3 - Iteration 32 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 149 it/s ] INFO sat_3 - Iteration 33 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 139 it/s ] INFO sat_3 - Iteration 34 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 149 it/s ] INFO sat_3 - Iteration 35 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 144 it/s ] INFO Creating alignment model for speaker-independent features... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 756/760 [ 0:00:06 &lt; 0:00:01 , 143 it/s ] INFO Training complete! INFO Exiting training early to save time as the corpus is below the subset size for later training stages INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Generating alignments... 98% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 745/760 [ 0:00:04 &lt; 0:00:01 , 206 it/s ] INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:01 &lt; 0:00:00 , ? it/s ] INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 755/760 [ 0:00:05 &lt; 0:00:01 , 195 it/s ] INFO Accumulating transition stats... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Finished accumulating transition stats! INFO Collecting phone and word alignments from sat_3_ali lattices... 91% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━━ 693/760 [ 0:00:01 &lt; 0:00:01 , 1,056 it/s ] INFO Beginning phone LM training... INFO Collecting training data... 0% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0/760 [ 0:00:01 &lt; -:--:-- , ? it/s ] INFO Training model... INFO Completed training in 1412.3437068462372 seconds! INFO Saved model to munster-model WARNING Alignment analysis not available without using postgresql INFO Exporting sat_3_ali TextGrids to /tmp/textgrid-munster... 98% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 742/760 [ 0:00:04 &lt; 0:00:01 , 333 it/s ] INFO Finished exporting TextGrids to /tmp/textgrid-munster! INFO Done! Everything took 1441.163 seconds /opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version &gt;=1.16.5 and &lt;1.23.0 is required for this version of SciPy (detected version 1.24.4 warnings.warn(f&#34;A NumPy version &gt;={np_minversion} and &lt;{np_maxversion}&#34; INFO Setting up corpus information... INFO Loading corpus from source files... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 702/100 [ 0:00:00 &lt; 0:00:00 , 631 it/s ] INFO Found 1 speaker across 760 files, average number of utterances per speaker: 760.0 INFO Initializing multiprocessing jobs... WARNING Number of jobs was specified as 3, but due to only having 1 speakers, MFA will only use 1 jobs. Use the --single_speaker flag if you would like to split utterances across jobs regardless of their speaker. INFO Normalizing text... 40% ━━━━━━━━━━━━━╺━━━━━━━━━━━━━━━━━━━━ 301/760 [ 0:00:01 &lt; -:--:-- , ? it/s ] INFO Creating corpus split for feature generation... 5% ━╸━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81/1,520 [ 0:00:01 &lt; -:--:-- , ? it/s ] INFO Generating MFCCs... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:08 &lt; 0:00:01 , 134 it/s ] INFO Calculating CMVN... INFO Generating final features... 87% ━━━━━━━━━━━━━━━━━━━━━━━━━╸━━━━ 658/760 [ 0:00:01 &lt; 0:00:01 , 1,818 it/s ] INFO Creating corpus split with features... 64% ━━━━━━━━━━━━━━━━━━━━━╸━━━━━━━━━━━━ 486/760 [ 0:00:01 &lt; -:--:-- , ? it/s ] INFO Filtering utterances for training... INFO Initializing training for monophone... INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Generating initial alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Initialization complete! INFO monophone - Iteration 1 of 40 INFO Generating alignments... 95% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━ 725/760 [ 0:00:02 &lt; 0:00:01 , 586 it/s ] INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,609 it/s ] INFO monophone - Iteration 2 of 40 INFO Generating alignments... 96% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━ 733/760 [ 0:00:02 &lt; 0:00:01 , 602 it/s ] INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,584 it/s ] INFO monophone - Iteration 3 of 40 INFO Generating alignments... 96% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━ 733/760 [ 0:00:02 &lt; 0:00:01 , 651 it/s ] INFO Accumulating statistics... 86% ━━━━━━━━━━━━━━━━━━━━━━━━━╸━━━━ 650/760 [ 0:00:01 &lt; 0:00:01 , 1,517 it/s ] INFO monophone - Iteration 4 of 40 INFO Generating alignments... 98% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 748/760 [ 0:00:02 &lt; 0:00:01 , 667 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:01 &lt; 0:00:01 , 1,476 it/s ] INFO monophone - Iteration 5 of 40 INFO Generating alignments... 94% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━ 714/760 [ 0:00:02 &lt; 0:00:01 , 637 it/s ] INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,521 it/s ] INFO monophone - Iteration 6 of 40 INFO Generating alignments... 95% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━ 720/760 [ 0:00:02 &lt; 0:00:01 , 638 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:01 &lt; 0:00:01 , 1,330 it/s ] INFO monophone - Iteration 7 of 40 INFO Generating alignments... 93% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 708/760 [ 0:00:02 &lt; 0:00:01 , 633 it/s ] INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,450 it/s ] INFO monophone - Iteration 8 of 40 INFO Generating alignments... 96% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━ 729/760 [ 0:00:02 &lt; 0:00:01 , 648 it/s ] INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,445 it/s ] INFO monophone - Iteration 9 of 40 INFO Generating alignments... 93% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 705/760 [ 0:00:02 &lt; 0:00:01 , 624 it/s ] INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,410 it/s ] INFO monophone - Iteration 10 of 40 INFO Generating alignments... 96% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━ 733/760 [ 0:00:02 &lt; 0:00:01 , 590 it/s ] INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,374 it/s ] INFO monophone - Iteration 11 of 40 INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,341 it/s ] INFO monophone - Iteration 12 of 40 INFO Generating alignments... 98% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 744/760 [ 0:00:02 &lt; 0:00:01 , 601 it/s ] INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,354 it/s ] INFO monophone - Iteration 13 of 40 INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,347 it/s ] INFO monophone - Iteration 14 of 40 INFO Generating alignments... 95% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━ 721/760 [ 0:00:02 &lt; 0:00:01 , 589 it/s ] INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,325 it/s ] INFO monophone - Iteration 15 of 40 INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,318 it/s ] INFO monophone - Iteration 16 of 40 INFO Generating alignments... 98% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 748/760 [ 0:00:02 &lt; 0:00:01 , 542 it/s ] INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,278 it/s ] INFO monophone - Iteration 17 of 40 INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,283 it/s ] INFO monophone - Iteration 18 of 40 INFO Generating alignments... 93% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 710/760 [ 0:00:02 &lt; 0:00:01 , 576 it/s ] INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,274 it/s ] INFO monophone - Iteration 19 of 40 INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,244 it/s ] INFO monophone - Iteration 20 of 40 INFO Generating alignments... 95% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━ 724/760 [ 0:00:02 &lt; 0:00:01 , 541 it/s ] INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,227 it/s ] INFO monophone - Iteration 21 of 40 INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,203 it/s ] INFO monophone - Iteration 22 of 40 INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,184 it/s ] INFO monophone - Iteration 23 of 40 INFO Generating alignments... 95% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━ 719/760 [ 0:00:02 &lt; 0:00:01 , 538 it/s ] INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,144 it/s ] INFO monophone - Iteration 24 of 40 INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,182 it/s ] INFO monophone - Iteration 25 of 40 INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,136 it/s ] INFO monophone - Iteration 26 of 40 INFO Generating alignments... 95% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━ 722/760 [ 0:00:02 &lt; 0:00:01 , 541 it/s ] INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,153 it/s ] INFO monophone - Iteration 27 of 40 INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,068 it/s ] INFO monophone - Iteration 28 of 40 INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,081 it/s ] INFO monophone - Iteration 29 of 40 INFO Generating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 758/760 [ 0:00:02 &lt; 0:00:01 , 518 it/s ] INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,085 it/s ] INFO monophone - Iteration 30 of 40 INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,070 it/s ] INFO monophone - Iteration 31 of 40 INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,025 it/s ] INFO monophone - Iteration 32 of 40 INFO Generating alignments... 95% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━ 724/760 [ 0:00:02 &lt; 0:00:01 , 506 it/s ] INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,033 it/s ] INFO monophone - Iteration 33 of 40 INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,048 it/s ] INFO monophone - Iteration 34 of 40 INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,024 it/s ] INFO monophone - Iteration 35 of 40 INFO Generating alignments... 94% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━ 717/760 [ 0:00:02 &lt; 0:00:01 , 497 it/s ] INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,035 it/s ] INFO monophone - Iteration 36 of 40 INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,044 it/s ] INFO monophone - Iteration 37 of 40 INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,043 it/s ] INFO monophone - Iteration 38 of 40 INFO Generating alignments... 96% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━ 730/760 [ 0:00:02 &lt; 0:00:01 , 508 it/s ] INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,049 it/s ] INFO monophone - Iteration 39 of 40 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:00 &lt; 0:00:00 , 1,012 it/s ] INFO monophone - Iteration 40 of 40 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:00 &lt; 0:00:00 , 1,009 it/s ] INFO Training complete! INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Generating alignments... 94% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━ 717/760 [ 0:00:02 &lt; 0:00:01 , 498 it/s ] INFO Initializing training for triphone... INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Converting alignments... 0% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0/760 [ 0:00:01 &lt; -:--:-- , ? it/s ] INFO Initialization complete! INFO triphone - Iteration 1 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:02 &lt; 0:00:01 , 600 it/s ] INFO triphone - Iteration 2 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:02 &lt; 0:00:01 , 580 it/s ] INFO triphone - Iteration 3 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:02 &lt; 0:00:01 , 442 it/s ] INFO triphone - Iteration 4 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:03 &lt; 0:00:01 , 382 it/s ] INFO triphone - Iteration 5 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:03 &lt; 0:00:01 , 313 it/s ] INFO triphone - Iteration 6 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:03 &lt; 0:00:01 , 260 it/s ] INFO triphone - Iteration 7 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:04 &lt; 0:00:01 , 235 it/s ] INFO triphone - Iteration 8 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:04 &lt; 0:00:01 , 204 it/s ] INFO triphone - Iteration 9 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:05 &lt; 0:00:01 , 186 it/s ] INFO triphone - Iteration 10 of 35 INFO Generating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 757/760 [ 0:00:08 &lt; 0:00:01 , 106 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:05 &lt; 0:00:01 , 166 it/s ] INFO triphone - Iteration 11 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 147 it/s ] INFO triphone - Iteration 12 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 130 it/s ] INFO triphone - Iteration 13 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:07 &lt; 0:00:01 , 117 it/s ] INFO triphone - Iteration 14 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:08 &lt; 0:00:01 , 105 it/s ] INFO triphone - Iteration 15 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 93 it/s ] INFO triphone - Iteration 16 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 87 it/s ] INFO triphone - Iteration 17 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 86 it/s ] INFO triphone - Iteration 18 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 87 it/s ] INFO triphone - Iteration 19 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 85 it/s ] INFO triphone - Iteration 20 of 35 INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 754/760 [ 0:00:11 &lt; 0:00:01 , 72 it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:09 &lt; 0:00:00 , 83 it/s ] INFO triphone - Iteration 21 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:09 &lt; 0:00:00 , 83 it/s ] INFO triphone - Iteration 22 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:09 &lt; 0:00:00 , 83 it/s ] INFO triphone - Iteration 23 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:09 &lt; 0:00:00 , 82 it/s ] INFO triphone - Iteration 24 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:09 &lt; 0:00:00 , 83 it/s ] INFO triphone - Iteration 25 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:09 &lt; 0:00:00 , 83 it/s ] INFO triphone - Iteration 26 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:09 &lt; 0:00:00 , 81 it/s ] INFO triphone - Iteration 27 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:09 &lt; 0:00:00 , 83 it/s ] INFO triphone - Iteration 28 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:09 &lt; 0:00:00 , 84 it/s ] INFO triphone - Iteration 29 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:09 &lt; 0:00:00 , 82 it/s ] INFO triphone - Iteration 30 of 35 INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 755/760 [ 0:00:11 &lt; 0:00:01 , 72 it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:09 &lt; 0:00:00 , 84 it/s ] INFO triphone - Iteration 31 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:09 &lt; 0:00:00 , 80 it/s ] INFO triphone - Iteration 32 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:09 &lt; 0:00:00 , 83 it/s ] INFO triphone - Iteration 33 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:09 &lt; 0:00:00 , 82 it/s ] INFO triphone - Iteration 34 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:09 &lt; 0:00:00 , 77 it/s ] INFO triphone - Iteration 35 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:09 &lt; 0:00:00 , 83 it/s ] INFO Training complete! INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 756/760 [ 0:00:11 &lt; 0:00:01 , 72 it/s ] INFO Initializing training for lda... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Converting alignments... 0% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0/760 [ 0:00:01 &lt; -:--:-- , ? it/s ] INFO Initialization complete! INFO lda - Iteration 1 of 35 INFO Accumulating statistics... 86% ━━━━━━━━━━━━━━━━━━━━━━━━━╸━━━━ 650/760 [ 0:00:01 &lt; 0:00:01 , 1,520 it/s ] INFO lda - Iteration 2 of 35 INFO Re-calculating LDA... 87% ━━━━━━━━━━━━━━━━━━━━━━━━━╸━━━━ 658/760 [ 0:00:01 &lt; 0:00:01 , 1,947 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:02 &lt; 0:00:01 , 428 it/s ] INFO lda - Iteration 3 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:03 &lt; 0:00:01 , 327 it/s ] INFO lda - Iteration 4 of 35 INFO Re-calculating LDA... 81% ━━━━━━━━━━━━━━━━━━━━━━━━╺━━━━━ 615/760 [ 0:00:01 &lt; 0:00:01 , 1,837 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:03 &lt; 0:00:01 , 269 it/s ] INFO lda - Iteration 5 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:04 &lt; 0:00:01 , 215 it/s ] INFO lda - Iteration 6 of 35 INFO Re-calculating LDA... 89% ━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━━ 676/760 [ 0:00:01 &lt; 0:00:01 , 2,001 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:05 &lt; 0:00:01 , 172 it/s ] INFO lda - Iteration 7 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 146 it/s ] INFO lda - Iteration 8 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:07 &lt; 0:00:01 , 119 it/s ] INFO lda - Iteration 9 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:08 &lt; 0:00:01 , 105 it/s ] INFO lda - Iteration 10 of 35 INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 753/760 [ 0:00:11 &lt; 0:00:01 , 74 it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:07 &lt; 0:00:00 , 97 it/s ] INFO lda - Iteration 11 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 93 it/s ] INFO lda - Iteration 12 of 35 INFO Re-calculating LDA... 90% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━━ 687/760 [ 0:00:01 &lt; 0:00:01 , 2,039 it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:07 &lt; 0:00:00 , 97 it/s ] INFO lda - Iteration 13 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 94 it/s ] INFO lda - Iteration 14 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 93 it/s ] INFO lda - Iteration 15 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 95 it/s ] INFO lda - Iteration 16 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 93 it/s ] INFO lda - Iteration 17 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 94 it/s ] INFO lda - Iteration 18 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 94 it/s ] INFO lda - Iteration 19 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 93 it/s ] INFO lda - Iteration 20 of 35 INFO Generating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 757/760 [ 0:00:10 &lt; 0:00:01 , 83 it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 92 it/s ] INFO lda - Iteration 21 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 91 it/s ] INFO lda - Iteration 22 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 92 it/s ] INFO lda - Iteration 23 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 93 it/s ] INFO lda - Iteration 24 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 92 it/s ] INFO lda - Iteration 25 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 90 it/s ] INFO lda - Iteration 26 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 90 it/s ] INFO lda - Iteration 27 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 92 it/s ] INFO lda - Iteration 28 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 91 it/s ] INFO lda - Iteration 29 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 92 it/s ] INFO lda - Iteration 30 of 35 INFO Generating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 757/760 [ 0:00:09 &lt; 0:00:01 , 87 it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 93 it/s ] INFO lda - Iteration 31 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 92 it/s ] INFO lda - Iteration 32 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 91 it/s ] INFO lda - Iteration 33 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 91 it/s ] INFO lda - Iteration 34 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 93 it/s ] INFO lda - Iteration 35 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 93 it/s ] INFO Training complete! INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 755/760 [ 0:00:10 &lt; 0:00:01 , 85 it/s ] INFO Initializing training for sat... INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Converting alignments... 0% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0/760 [ 0:00:01 &lt; -:--:-- , ? it/s ] INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Initialization complete! INFO sat - Iteration 1 of 35 INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/760 [ 0:00:01 &lt; 0:00:01 , 1,599 it/s ] INFO sat - Iteration 2 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:04 &lt; 0:00:01 , 252 it/s ] INFO sat - Iteration 3 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:04 &lt; 0:00:01 , 218 it/s ] INFO sat - Iteration 4 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:04 &lt; 0:00:01 , 193 it/s ] INFO sat - Iteration 5 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 153 it/s ] INFO sat - Iteration 6 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:06 &lt; 0:00:01 , 131 it/s ] INFO sat - Iteration 7 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:07 &lt; 0:00:01 , 112 it/s ] INFO sat - Iteration 8 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 96 it/s ] INFO sat - Iteration 9 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:07 &lt; 0:00:00 , 96 it/s ] INFO sat - Iteration 10 of 35 INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 753/760 [ 0:00:11 &lt; 0:00:01 , 74 it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 92 it/s ] INFO sat - Iteration 11 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:08 &lt; 0:00:01 , 96 it/s ] INFO sat - Iteration 12 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 95 it/s ] INFO sat - Iteration 13 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 95 it/s ] INFO sat - Iteration 14 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 93 it/s ] INFO sat - Iteration 15 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 92 it/s ] INFO sat - Iteration 16 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 94 it/s ] INFO sat - Iteration 17 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 92 it/s ] INFO sat - Iteration 18 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 88 it/s ] INFO sat - Iteration 19 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 91 it/s ] INFO sat - Iteration 20 of 35 INFO Generating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 757/760 [ 0:00:10 &lt; 0:00:01 , 84 it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 90 it/s ] INFO sat - Iteration 21 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 91 it/s ] INFO sat - Iteration 22 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 88 it/s ] INFO sat - Iteration 23 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:09 &lt; 0:00:00 , 84 it/s ] INFO sat - Iteration 24 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 92 it/s ] INFO sat - Iteration 25 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 91 it/s ] INFO sat - Iteration 26 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 85 it/s ] INFO sat - Iteration 27 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 92 it/s ] INFO sat - Iteration 28 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 92 it/s ] INFO sat - Iteration 29 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 92 it/s ] INFO sat - Iteration 30 of 35 INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 753/760 [ 0:00:10 &lt; 0:00:01 , 83 it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 93 it/s ] INFO sat - Iteration 31 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 94 it/s ] INFO sat - Iteration 32 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 91 it/s ] INFO sat - Iteration 33 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 90 it/s ] INFO sat - Iteration 34 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 93 it/s ] INFO sat - Iteration 35 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 90 it/s ] INFO Creating alignment model for speaker-independent features... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 85 it/s ] INFO Training complete! INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 755/760 [ 0:00:10 &lt; 0:00:01 , 84 it/s ] INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 754/760 [ 0:00:10 &lt; 0:00:01 , 83 it/s ] INFO Initializing training for sat_2... INFO Converting alignments... 0% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0/760 [ 0:00:01 &lt; -:--:-- , ? it/s ] INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Initialization complete! INFO sat_2 - Iteration 1 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:00 &lt; 0:00:00 , 1,514 it/s ] INFO sat_2 - Iteration 2 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:05 &lt; 0:00:01 , 181 it/s ] INFO sat_2 - Iteration 3 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:08 &lt; 0:00:01 , 101 it/s ] INFO sat_2 - Iteration 4 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:08 &lt; 0:00:01 , 101 it/s ] INFO sat_2 - Iteration 5 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:07 &lt; 0:00:00 , 97 it/s ] INFO sat_2 - Iteration 6 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:07 &lt; 0:00:00 , 96 it/s ] INFO sat_2 - Iteration 7 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 95 it/s ] INFO sat_2 - Iteration 8 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:07 &lt; 0:00:00 , 96 it/s ] INFO sat_2 - Iteration 9 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 96 it/s ] INFO sat_2 - Iteration 10 of 35 INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 754/760 [ 0:00:11 &lt; 0:00:01 , 73 it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 95 it/s ] INFO sat_2 - Iteration 11 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 92 it/s ] INFO sat_2 - Iteration 12 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 91 it/s ] INFO sat_2 - Iteration 13 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 93 it/s ] INFO sat_2 - Iteration 14 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 91 it/s ] INFO sat_2 - Iteration 15 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 92 it/s ] INFO sat_2 - Iteration 16 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 92 it/s ] INFO sat_2 - Iteration 17 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 92 it/s ] INFO sat_2 - Iteration 18 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 91 it/s ] INFO sat_2 - Iteration 19 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 91 it/s ] INFO sat_2 - Iteration 20 of 35 INFO Generating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 758/760 [ 0:00:10 &lt; 0:00:01 , 84 it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 91 it/s ] INFO sat_2 - Iteration 21 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 92 it/s ] INFO sat_2 - Iteration 22 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 91 it/s ] INFO sat_2 - Iteration 23 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 93 it/s ] INFO sat_2 - Iteration 24 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 91 it/s ] INFO sat_2 - Iteration 25 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 93 it/s ] INFO sat_2 - Iteration 26 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 93 it/s ] INFO sat_2 - Iteration 27 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 93 it/s ] INFO sat_2 - Iteration 28 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 89 it/s ] INFO sat_2 - Iteration 29 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 93 it/s ] INFO sat_2 - Iteration 30 of 35 INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 754/760 [ 0:00:10 &lt; 0:00:01 , 85 it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 87 it/s ] INFO sat_2 - Iteration 31 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 91 it/s ] INFO sat_2 - Iteration 32 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 91 it/s ] INFO sat_2 - Iteration 33 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 89 it/s ] INFO sat_2 - Iteration 34 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 90 it/s ] INFO sat_2 - Iteration 35 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 90 it/s ] INFO Creating alignment model for speaker-independent features... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 757/760 [ 0:00:09 &lt; 0:00:01 , 87 it/s ] INFO Training complete! INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Generating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 758/760 [ 0:00:10 &lt; 0:00:01 , 81 it/s ] INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Generating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 759/760 [ 0:00:10 &lt; 0:00:01 , 84 it/s ] INFO Generating pronunciations... 81% ━━━━━━━━━━━━━━━━━━━━━━━━╺━━━━━ 616/760 [ 0:00:01 &lt; 0:00:01 , 1,415 it/s ] INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Generating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 757/760 [ 0:00:10 &lt; 0:00:01 , 82 it/s ] INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 755/760 [ 0:00:10 &lt; 0:00:01 , 82 it/s ] INFO Initializing training for sat_3... INFO Converting alignments... 0% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0/760 [ 0:00:01 &lt; -:--:-- , ? it/s ] INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Initialization complete! INFO sat_3 - Iteration 1 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:00 &lt; 0:00:00 , 1,544 it/s ] INFO sat_3 - Iteration 2 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/760 [ 0:00:07 &lt; 0:00:01 , 122 it/s ] INFO sat_3 - Iteration 3 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:07 &lt; 0:00:00 , 97 it/s ] INFO sat_3 - Iteration 4 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:07 &lt; 0:00:00 , 97 it/s ] INFO sat_3 - Iteration 5 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 95 it/s ] INFO sat_3 - Iteration 6 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 95 it/s ] INFO sat_3 - Iteration 7 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:07 &lt; 0:00:00 , 97 it/s ] INFO sat_3 - Iteration 8 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:07 &lt; 0:00:00 , 96 it/s ] INFO sat_3 - Iteration 9 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 90 it/s ] INFO sat_3 - Iteration 10 of 35 INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 755/760 [ 0:00:11 &lt; 0:00:01 , 72 it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:07 &lt; 0:00:00 , 97 it/s ] INFO sat_3 - Iteration 11 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:07 &lt; 0:00:00 , 96 it/s ] INFO sat_3 - Iteration 12 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 94 it/s ] INFO sat_3 - Iteration 13 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 95 it/s ] INFO sat_3 - Iteration 14 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 94 it/s ] INFO sat_3 - Iteration 15 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 93 it/s ] INFO sat_3 - Iteration 16 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 94 it/s ] INFO sat_3 - Iteration 17 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 87 it/s ] INFO sat_3 - Iteration 18 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 93 it/s ] INFO sat_3 - Iteration 19 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 92 it/s ] INFO sat_3 - Iteration 20 of 35 INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 754/760 [ 0:00:10 &lt; 0:00:01 , 82 it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 92 it/s ] INFO sat_3 - Iteration 21 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 93 it/s ] INFO sat_3 - Iteration 22 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 90 it/s ] INFO sat_3 - Iteration 23 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 91 it/s ] INFO sat_3 - Iteration 24 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 92 it/s ] INFO sat_3 - Iteration 25 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 92 it/s ] INFO sat_3 - Iteration 26 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 91 it/s ] INFO sat_3 - Iteration 27 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 92 it/s ] INFO sat_3 - Iteration 28 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 90 it/s ] INFO sat_3 - Iteration 29 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 90 it/s ] INFO sat_3 - Iteration 30 of 35 INFO Generating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 758/760 [ 0:00:10 &lt; 0:00:01 , 84 it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 90 it/s ] INFO sat_3 - Iteration 31 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 85 it/s ] INFO sat_3 - Iteration 32 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 89 it/s ] INFO sat_3 - Iteration 33 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 91 it/s ] INFO sat_3 - Iteration 34 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 91 it/s ] INFO sat_3 - Iteration 35 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:08 &lt; 0:00:00 , 89 it/s ] INFO Creating alignment model for speaker-independent features... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 758/760 [ 0:00:09 &lt; 0:00:01 , 87 it/s ] INFO Training complete! INFO Exiting training early to save time as the corpus is below the subset size for later training stages INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Generating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:09 &lt; 0:00:00 , 85 it/s ] INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:01 &lt; 0:00:00 , ? it/s ] INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 756/760 [ 0:00:10 &lt; 0:00:01 , 85 it/s ] INFO Accumulating transition stats... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 760/760 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Finished accumulating transition stats! INFO Collecting phone and word alignments from sat_3_ali lattices... 90% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━━ 687/760 [ 0:00:01 &lt; 0:00:01 , 1,094 it/s ] INFO Beginning phone LM training... INFO Collecting training data... 0% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0/760 [ 0:00:01 &lt; -:--:-- , ? it/s ] INFO Training model... INFO Completed training in 2015.4587409496307 seconds! INFO Saved model to ulster-model WARNING Alignment analysis not available without using postgresql INFO Exporting sat_3_ali TextGrids to /tmp/textgrid-ulster... 96% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━ 731/760 [ 0:00:04 &lt; 0:00:01 , 357 it/s ] INFO Finished exporting TextGrids to /tmp/textgrid-ulster! INFO Done! Everything took 2037.755 seconds /opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version &gt;=1.16.5 and &lt;1.23.0 is required for this version of SciPy (detected version 1.24.4 warnings.warn(f&#34;A NumPy version &gt;={np_minversion} and &lt;{np_maxversion}&#34; INFO Setting up corpus information... INFO Loading corpus from source files... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 669/100 [ 0:00:00 &lt; 0:00:00 , 748 it/s ] INFO Found 1 speaker across 756 files, average number of utterances per speaker: 756.0 INFO Initializing multiprocessing jobs... WARNING Number of jobs was specified as 3, but due to only having 1 speakers, MFA will only use 1 jobs. Use the --single_speaker flag if you would like to split utterances across jobs regardless of their speaker. INFO Normalizing text... 85% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━━━━ 644/756 [ 0:00:01 &lt; -:--:-- , ? it/s ] INFO Creating corpus split for feature generation... 3% ╸━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 45/1,512 [ 0:00:01 &lt; -:--:-- , ? it/s ] INFO Generating MFCCs... 98% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 741/756 [ 0:00:06 &lt; 0:00:01 , 164 it/s ] INFO Calculating CMVN... INFO Generating final features... 78% ━━━━━━━━━━━━━━━━━━━━━━━╺━━━━━━ 590/756 [ 0:00:01 &lt; 0:00:01 , 2,449 it/s ] INFO Creating corpus split with features... 66% ━━━━━━━━━━━━━━━━━━━━━━╺━━━━━━━━━━━ 498/756 [ 0:00:01 &lt; -:--:-- , ? it/s ] INFO Filtering utterances for training... INFO Initializing training for monophone... INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 756/756 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Generating initial alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 756/756 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Initialization complete! INFO monophone - Iteration 1 of 40 INFO Generating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 756/756 [ 0:00:01 &lt; 0:00:00 , 730 it/s ] INFO Accumulating statistics... 86% ━━━━━━━━━━━━━━━━━━━━━━━━━╸━━━━ 650/756 [ 0:00:01 &lt; 0:00:01 , 2,085 it/s ] INFO monophone - Iteration 2 of 40 INFO Generating alignments... 97% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━ 730/756 [ 0:00:02 &lt; 0:00:01 , 797 it/s ] INFO Accumulating statistics... 86% ━━━━━━━━━━━━━━━━━━━━━━━━━╸━━━━ 650/756 [ 0:00:01 &lt; 0:00:01 , 2,072 it/s ] INFO monophone - Iteration 3 of 40 INFO Generating alignments... 90% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━━ 682/756 [ 0:00:01 &lt; 0:00:01 , 831 it/s ] INFO Accumulating statistics... 86% ━━━━━━━━━━━━━━━━━━━━━━━━━╸━━━━ 650/756 [ 0:00:01 &lt; 0:00:01 , 2,051 it/s ] INFO monophone - Iteration 4 of 40 INFO Generating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 755/756 [ 0:00:02 &lt; 0:00:01 , 823 it/s ] INFO Accumulating statistics... 79% ━━━━━━━━━━━━━━━━━━━━━━━╸━━━━━━ 600/756 [ 0:00:01 &lt; 0:00:01 , 2,005 it/s ] INFO monophone - Iteration 5 of 40 INFO Generating alignments... 90% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━━ 679/756 [ 0:00:01 &lt; 0:00:01 , 830 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:01 &lt; 0:00:01 , 1,965 it/s ] INFO monophone - Iteration 6 of 40 INFO Generating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 755/756 [ 0:00:02 &lt; 0:00:01 , 820 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:01 &lt; 0:00:01 , 1,930 it/s ] INFO monophone - Iteration 7 of 40 INFO Generating alignments... 91% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━━ 691/756 [ 0:00:01 &lt; 0:00:01 , 843 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:01 &lt; 0:00:01 , 1,896 it/s ] INFO monophone - Iteration 8 of 40 INFO Generating alignments... 95% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━ 718/756 [ 0:00:02 &lt; 0:00:01 , 789 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:01 &lt; 0:00:01 , 1,852 it/s ] INFO monophone - Iteration 9 of 40 INFO Generating alignments... 91% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━━ 688/756 [ 0:00:01 &lt; 0:00:01 , 841 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:01 &lt; 0:00:01 , 1,920 it/s ] INFO monophone - Iteration 10 of 40 INFO Generating alignments... 91% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━━ 685/756 [ 0:00:02 &lt; 0:00:01 , 808 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:01 &lt; 0:00:01 , 1,872 it/s ] INFO monophone - Iteration 11 of 40 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:01 &lt; 0:00:01 , 1,856 it/s ] INFO monophone - Iteration 12 of 40 INFO Generating alignments... 95% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━ 719/756 [ 0:00:02 &lt; 0:00:01 , 779 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:01 &lt; 0:00:01 , 1,862 it/s ] INFO monophone - Iteration 13 of 40 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:01 &lt; 0:00:01 , 1,822 it/s ] INFO monophone - Iteration 14 of 40 INFO Generating alignments... 98% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 743/756 [ 0:00:02 &lt; 0:00:01 , 791 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:01 &lt; 0:00:01 , 1,736 it/s ] INFO monophone - Iteration 15 of 40 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:01 &lt; 0:00:01 , 1,776 it/s ] INFO monophone - Iteration 16 of 40 INFO Generating alignments... 95% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━ 717/756 [ 0:00:02 &lt; 0:00:01 , 780 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:01 &lt; 0:00:01 , 1,758 it/s ] INFO monophone - Iteration 17 of 40 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:01 &lt; 0:00:01 , 1,769 it/s ] INFO monophone - Iteration 18 of 40 INFO Generating alignments... 94% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━ 709/756 [ 0:00:02 &lt; 0:00:01 , 758 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:01 &lt; 0:00:01 , 1,723 it/s ] INFO monophone - Iteration 19 of 40 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:01 &lt; 0:00:01 , 1,709 it/s ] INFO monophone - Iteration 20 of 40 INFO Generating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 755/756 [ 0:00:02 &lt; 0:00:01 , 744 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:01 &lt; 0:00:01 , 1,627 it/s ] INFO monophone - Iteration 21 of 40 INFO Accumulating statistics... 93% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/756 [ 0:00:01 &lt; 0:00:01 , 1,631 it/s ] INFO monophone - Iteration 22 of 40 INFO Accumulating statistics... 93% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/756 [ 0:00:01 &lt; 0:00:01 , 1,611 it/s ] INFO monophone - Iteration 23 of 40 INFO Generating alignments... 91% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━━ 686/756 [ 0:00:02 &lt; 0:00:01 , 743 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:01 &lt; 0:00:01 , 1,652 it/s ] INFO monophone - Iteration 24 of 40 INFO Accumulating statistics... 93% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/756 [ 0:00:01 &lt; 0:00:01 , 1,612 it/s ] INFO monophone - Iteration 25 of 40 INFO Accumulating statistics... 93% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/756 [ 0:00:01 &lt; 0:00:01 , 1,594 it/s ] INFO monophone - Iteration 26 of 40 INFO Generating alignments... 98% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 743/756 [ 0:00:02 &lt; 0:00:01 , 729 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:01 &lt; 0:00:01 , 1,528 it/s ] INFO monophone - Iteration 27 of 40 INFO Accumulating statistics... 93% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/756 [ 0:00:01 &lt; 0:00:01 , 1,551 it/s ] INFO monophone - Iteration 28 of 40 INFO Accumulating statistics... 93% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/756 [ 0:00:01 &lt; 0:00:01 , 1,531 it/s ] INFO monophone - Iteration 29 of 40 INFO Generating alignments... 97% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 736/756 [ 0:00:02 &lt; 0:00:01 , 718 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:01 &lt; 0:00:01 , 1,452 it/s ] INFO monophone - Iteration 30 of 40 INFO Accumulating statistics... 93% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/756 [ 0:00:01 &lt; 0:00:01 , 1,442 it/s ] INFO monophone - Iteration 31 of 40 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:01 &lt; 0:00:01 , 1,446 it/s ] INFO monophone - Iteration 32 of 40 INFO Generating alignments... 94% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━ 711/756 [ 0:00:02 &lt; 0:00:01 , 694 it/s ] INFO Accumulating statistics... 93% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/756 [ 0:00:01 &lt; 0:00:01 , 1,425 it/s ] INFO monophone - Iteration 33 of 40 INFO Accumulating statistics... 93% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/756 [ 0:00:01 &lt; 0:00:01 , 1,421 it/s ] INFO monophone - Iteration 34 of 40 INFO Accumulating statistics... 93% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/756 [ 0:00:01 &lt; 0:00:01 , 1,419 it/s ] INFO monophone - Iteration 35 of 40 INFO Generating alignments... 97% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 733/756 [ 0:00:02 &lt; 0:00:01 , 659 it/s ] INFO Accumulating statistics... 93% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/756 [ 0:00:01 &lt; 0:00:01 , 1,376 it/s ] INFO monophone - Iteration 36 of 40 INFO Accumulating statistics... 93% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/756 [ 0:00:01 &lt; 0:00:01 , 1,425 it/s ] INFO monophone - Iteration 37 of 40 INFO Accumulating statistics... 93% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/756 [ 0:00:01 &lt; 0:00:01 , 1,433 it/s ] INFO monophone - Iteration 38 of 40 INFO Generating alignments... 95% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━ 717/756 [ 0:00:02 &lt; 0:00:01 , 700 it/s ] INFO Accumulating statistics... 93% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/756 [ 0:00:01 &lt; 0:00:01 , 1,399 it/s ] INFO monophone - Iteration 39 of 40 INFO Accumulating statistics... 93% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/756 [ 0:00:01 &lt; 0:00:01 , 1,404 it/s ] INFO monophone - Iteration 40 of 40 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:01 &lt; 0:00:01 , 1,460 it/s ] INFO Training complete! INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 756/756 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Generating alignments... 94% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 707/756 [ 0:00:02 &lt; 0:00:01 , 691 it/s ] INFO Initializing training for triphone... INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 756/756 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Converting alignments... 0% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0/756 [ 0:00:01 &lt; -:--:-- , ? it/s ] INFO Initialization complete! INFO triphone - Iteration 1 of 35 INFO Accumulating statistics... 93% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 700/756 [ 0:00:01 &lt; 0:00:01 , 910 it/s ] INFO triphone - Iteration 2 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:01 &lt; 0:00:01 , 845 it/s ] INFO triphone - Iteration 3 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:02 &lt; 0:00:01 , 658 it/s ] INFO triphone - Iteration 4 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:02 &lt; 0:00:01 , 500 it/s ] INFO triphone - Iteration 5 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:03 &lt; 0:00:01 , 362 it/s ] INFO triphone - Iteration 6 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:03 &lt; 0:00:01 , 288 it/s ] INFO triphone - Iteration 7 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:04 &lt; 0:00:01 , 219 it/s ] INFO triphone - Iteration 8 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:05 &lt; 0:00:01 , 176 it/s ] INFO triphone - Iteration 9 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 151 it/s ] INFO triphone - Iteration 10 of 35 INFO Generating alignments... 98% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 742/756 [ 0:00:05 &lt; 0:00:01 , 178 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 137 it/s ] INFO triphone - Iteration 11 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 138 it/s ] INFO triphone - Iteration 12 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 136 it/s ] INFO triphone - Iteration 13 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 135 it/s ] INFO triphone - Iteration 14 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 134 it/s ] INFO triphone - Iteration 15 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 132 it/s ] INFO triphone - Iteration 16 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 130 it/s ] INFO triphone - Iteration 17 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 130 it/s ] INFO triphone - Iteration 18 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 127 it/s ] INFO triphone - Iteration 19 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 130 it/s ] INFO triphone - Iteration 20 of 35 INFO Generating alignments... 98% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 738/756 [ 0:00:05 &lt; 0:00:01 , 192 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:07 &lt; 0:00:01 , 126 it/s ] INFO triphone - Iteration 21 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 129 it/s ] INFO triphone - Iteration 22 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 129 it/s ] INFO triphone - Iteration 23 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 128 it/s ] INFO triphone - Iteration 24 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:07 &lt; 0:00:01 , 125 it/s ] INFO triphone - Iteration 25 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:07 &lt; 0:00:01 , 126 it/s ] INFO triphone - Iteration 26 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:07 &lt; 0:00:01 , 127 it/s ] INFO triphone - Iteration 27 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 128 it/s ] INFO triphone - Iteration 28 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 128 it/s ] INFO triphone - Iteration 29 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:07 &lt; 0:00:01 , 126 it/s ] INFO triphone - Iteration 30 of 35 INFO Generating alignments... 98% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 740/756 [ 0:00:05 &lt; 0:00:01 , 191 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 127 it/s ] INFO triphone - Iteration 31 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 128 it/s ] INFO triphone - Iteration 32 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 128 it/s ] INFO triphone - Iteration 33 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:07 &lt; 0:00:01 , 126 it/s ] INFO triphone - Iteration 34 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 129 it/s ] INFO triphone - Iteration 35 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 129 it/s ] INFO Training complete! INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 756/756 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Generating alignments... 98% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 743/756 [ 0:00:05 &lt; 0:00:01 , 185 it/s ] INFO Initializing training for lda... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 756/756 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 756/756 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Converting alignments... 0% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0/756 [ 0:00:01 &lt; -:--:-- , ? it/s ] INFO Initialization complete! INFO lda - Iteration 1 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 756/756 [ 0:00:00 &lt; 0:00:00 , 1,969 it/s ] INFO lda - Iteration 2 of 35 INFO Re-calculating LDA... 91% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━━ 690/756 [ 0:00:01 &lt; 0:00:01 , 2,018 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:02 &lt; 0:00:01 , 568 it/s ] INFO lda - Iteration 3 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:03 &lt; 0:00:01 , 387 it/s ] INFO lda - Iteration 4 of 35 INFO Re-calculating LDA... 94% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━ 714/756 [ 0:00:01 &lt; 0:00:01 , 2,131 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:04 &lt; 0:00:01 , 244 it/s ] INFO lda - Iteration 5 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:05 &lt; 0:00:01 , 176 it/s ] INFO lda - Iteration 6 of 35 INFO Re-calculating LDA... 87% ━━━━━━━━━━━━━━━━━━━━━━━━━╸━━━━ 655/756 [ 0:00:01 &lt; 0:00:01 , 1,904 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 148 it/s ] INFO lda - Iteration 7 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 149 it/s ] INFO lda - Iteration 8 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 145 it/s ] INFO lda - Iteration 9 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 146 it/s ] INFO lda - Iteration 10 of 35 INFO Generating alignments... 98% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 744/756 [ 0:00:05 &lt; 0:00:01 , 181 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 143 it/s ] INFO lda - Iteration 11 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 146 it/s ] INFO lda - Iteration 12 of 35 INFO Re-calculating LDA... 96% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━ 724/756 [ 0:00:01 &lt; 0:00:01 , 2,112 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 141 it/s ] INFO lda - Iteration 13 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 145 it/s ] INFO lda - Iteration 14 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 144 it/s ] INFO lda - Iteration 15 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 141 it/s ] INFO lda - Iteration 16 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 144 it/s ] INFO lda - Iteration 17 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 143 it/s ] INFO lda - Iteration 18 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 139 it/s ] INFO lda - Iteration 19 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 143 it/s ] INFO lda - Iteration 20 of 35 INFO Generating alignments... 97% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 737/756 [ 0:00:04 &lt; 0:00:01 , 207 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 145 it/s ] INFO lda - Iteration 21 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 142 it/s ] INFO lda - Iteration 22 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 141 it/s ] INFO lda - Iteration 23 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 143 it/s ] INFO lda - Iteration 24 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 138 it/s ] INFO lda - Iteration 25 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 142 it/s ] INFO lda - Iteration 26 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 135 it/s ] INFO lda - Iteration 27 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 142 it/s ] INFO lda - Iteration 28 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 144 it/s ] INFO lda - Iteration 29 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 144 it/s ] INFO lda - Iteration 30 of 35 INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 745/756 [ 0:00:04 &lt; 0:00:01 , 216 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 143 it/s ] INFO lda - Iteration 31 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 144 it/s ] INFO lda - Iteration 32 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 142 it/s ] INFO lda - Iteration 33 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 138 it/s ] INFO lda - Iteration 34 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 143 it/s ] INFO lda - Iteration 35 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 142 it/s ] INFO Training complete! INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 756/756 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Generating alignments... 98% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 741/756 [ 0:00:04 &lt; 0:00:01 , 216 it/s ] INFO Initializing training for sat... INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Converting alignments... 0% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0/756 [ 0:00:01 &lt; -:--:-- , ? it/s ] INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 756/756 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Initialization complete! INFO sat - Iteration 1 of 35 INFO Accumulating statistics... 86% ━━━━━━━━━━━━━━━━━━━━━━━━━╸━━━━ 650/756 [ 0:00:01 &lt; 0:00:01 , 2,044 it/s ] INFO sat - Iteration 2 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:04 &lt; 0:00:01 , 235 it/s ] INFO sat - Iteration 3 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:05 &lt; 0:00:01 , 175 it/s ] INFO sat - Iteration 4 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:05 &lt; 0:00:01 , 154 it/s ] INFO sat - Iteration 5 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 149 it/s ] INFO sat - Iteration 6 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 144 it/s ] INFO sat - Iteration 7 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 150 it/s ] INFO sat - Iteration 8 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 145 it/s ] INFO sat - Iteration 9 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 136 it/s ] INFO sat - Iteration 10 of 35 INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 752/756 [ 0:00:05 &lt; 0:00:01 , 186 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 143 it/s ] INFO sat - Iteration 11 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 145 it/s ] INFO sat - Iteration 12 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 145 it/s ] INFO sat - Iteration 13 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 142 it/s ] INFO sat - Iteration 14 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 144 it/s ] INFO sat - Iteration 15 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 140 it/s ] INFO sat - Iteration 16 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 143 it/s ] INFO sat - Iteration 17 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 138 it/s ] INFO sat - Iteration 18 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 143 it/s ] INFO sat - Iteration 19 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 139 it/s ] INFO sat - Iteration 20 of 35 INFO Generating alignments... 98% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 744/756 [ 0:00:04 &lt; 0:00:01 , 209 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 139 it/s ] INFO sat - Iteration 21 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 142 it/s ] INFO sat - Iteration 22 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 142 it/s ] INFO sat - Iteration 23 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 142 it/s ] INFO sat - Iteration 24 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 145 it/s ] INFO sat - Iteration 25 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 140 it/s ] INFO sat - Iteration 26 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 141 it/s ] INFO sat - Iteration 27 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 142 it/s ] INFO sat - Iteration 28 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 136 it/s ] INFO sat - Iteration 29 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 140 it/s ] INFO sat - Iteration 30 of 35 INFO Generating alignments... 97% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 736/756 [ 0:00:04 &lt; 0:00:01 , 216 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 139 it/s ] INFO sat - Iteration 31 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 141 it/s ] INFO sat - Iteration 32 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 139 it/s ] INFO sat - Iteration 33 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 134 it/s ] INFO sat - Iteration 34 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 143 it/s ] INFO sat - Iteration 35 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 139 it/s ] INFO Creating alignment model for speaker-independent features... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 748/756 [ 0:00:06 &lt; 0:00:01 , 137 it/s ] INFO Training complete! INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 756/756 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Generating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 754/756 [ 0:00:04 &lt; 0:00:01 , 214 it/s ] INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 747/756 [ 0:00:04 &lt; 0:00:01 , 218 it/s ] INFO Initializing training for sat_2... INFO Converting alignments... 0% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0/756 [ 0:00:01 &lt; -:--:-- , ? it/s ] INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 756/756 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Initialization complete! INFO sat_2 - Iteration 1 of 35 INFO Accumulating statistics... 86% ━━━━━━━━━━━━━━━━━━━━━━━━━╸━━━━ 650/756 [ 0:00:01 &lt; 0:00:01 , 2,018 it/s ] INFO sat_2 - Iteration 2 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 150 it/s ] INFO sat_2 - Iteration 3 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 148 it/s ] INFO sat_2 - Iteration 4 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 152 it/s ] INFO sat_2 - Iteration 5 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 147 it/s ] INFO sat_2 - Iteration 6 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 148 it/s ] INFO sat_2 - Iteration 7 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 145 it/s ] INFO sat_2 - Iteration 8 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 149 it/s ] INFO sat_2 - Iteration 9 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 142 it/s ] INFO sat_2 - Iteration 10 of 35 INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 752/756 [ 0:00:05 &lt; 0:00:01 , 185 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 146 it/s ] INFO sat_2 - Iteration 11 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 147 it/s ] INFO sat_2 - Iteration 12 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 147 it/s ] INFO sat_2 - Iteration 13 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 146 it/s ] INFO sat_2 - Iteration 14 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 144 it/s ] INFO sat_2 - Iteration 15 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 144 it/s ] INFO sat_2 - Iteration 16 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 133 it/s ] INFO sat_2 - Iteration 17 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 145 it/s ] INFO sat_2 - Iteration 18 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 145 it/s ] INFO sat_2 - Iteration 19 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 143 it/s ] INFO sat_2 - Iteration 20 of 35 INFO Generating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 755/756 [ 0:00:04 &lt; 0:00:01 , 213 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 142 it/s ] INFO sat_2 - Iteration 21 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 139 it/s ] INFO sat_2 - Iteration 22 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 144 it/s ] INFO sat_2 - Iteration 23 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 140 it/s ] INFO sat_2 - Iteration 24 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 141 it/s ] INFO sat_2 - Iteration 25 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 140 it/s ] INFO sat_2 - Iteration 26 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 138 it/s ] INFO sat_2 - Iteration 27 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 141 it/s ] INFO sat_2 - Iteration 28 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 140 it/s ] INFO sat_2 - Iteration 29 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 139 it/s ] INFO sat_2 - Iteration 30 of 35 INFO Generating alignments... 98% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 738/756 [ 0:00:04 &lt; 0:00:01 , 208 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 141 it/s ] INFO sat_2 - Iteration 31 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 140 it/s ] INFO sat_2 - Iteration 32 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 142 it/s ] INFO sat_2 - Iteration 33 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 140 it/s ] INFO sat_2 - Iteration 34 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 140 it/s ] INFO sat_2 - Iteration 35 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 141 it/s ] INFO Creating alignment model for speaker-independent features... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 754/756 [ 0:00:06 &lt; 0:00:01 , 131 it/s ] INFO Training complete! INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 756/756 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Generating alignments... 97% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 736/756 [ 0:00:04 &lt; 0:00:01 , 214 it/s ] INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 747/756 [ 0:00:04 &lt; 0:00:01 , 211 it/s ] INFO Generating pronunciations... 13% ━━━━╺━━━━━━━━━━━━━━━━━━━━━━━━━━━ 102/756 [ 0:00:01 &lt; 0:00:03 , 230 it/s ] INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 756/756 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Generating alignments... 98% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 739/756 [ 0:00:04 &lt; 0:00:01 , 209 it/s ] INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 745/756 [ 0:00:04 &lt; 0:00:01 , 209 it/s ] INFO Initializing training for sat_3... INFO Converting alignments... 0% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0/756 [ 0:00:01 &lt; -:--:-- , ? it/s ] INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 756/756 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Initialization complete! INFO sat_3 - Iteration 1 of 35 INFO Accumulating statistics... 79% ━━━━━━━━━━━━━━━━━━━━━━━╸━━━━━━ 600/756 [ 0:00:01 &lt; 0:00:01 , 2,119 it/s ] INFO sat_3 - Iteration 2 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 152 it/s ] INFO sat_3 - Iteration 3 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 152 it/s ] INFO sat_3 - Iteration 4 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 150 it/s ] INFO sat_3 - Iteration 5 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 152 it/s ] INFO sat_3 - Iteration 6 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 148 it/s ] INFO sat_3 - Iteration 7 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 146 it/s ] INFO sat_3 - Iteration 8 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 151 it/s ] INFO sat_3 - Iteration 9 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 150 it/s ] INFO sat_3 - Iteration 10 of 35 INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 745/756 [ 0:00:05 &lt; 0:00:01 , 184 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 146 it/s ] INFO sat_3 - Iteration 11 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 145 it/s ] INFO sat_3 - Iteration 12 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 145 it/s ] INFO sat_3 - Iteration 13 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 148 it/s ] INFO sat_3 - Iteration 14 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 145 it/s ] INFO sat_3 - Iteration 15 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 136 it/s ] INFO sat_3 - Iteration 16 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 139 it/s ] INFO sat_3 - Iteration 17 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 142 it/s ] INFO sat_3 - Iteration 18 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 147 it/s ] INFO sat_3 - Iteration 19 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 144 it/s ] INFO sat_3 - Iteration 20 of 35 INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 746/756 [ 0:00:04 &lt; 0:00:01 , 212 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 130 it/s ] INFO sat_3 - Iteration 21 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 142 it/s ] INFO sat_3 - Iteration 22 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 145 it/s ] INFO sat_3 - Iteration 23 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 143 it/s ] INFO sat_3 - Iteration 24 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 141 it/s ] INFO sat_3 - Iteration 25 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 138 it/s ] INFO sat_3 - Iteration 26 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 143 it/s ] INFO sat_3 - Iteration 27 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 141 it/s ] INFO sat_3 - Iteration 28 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 144 it/s ] INFO sat_3 - Iteration 29 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 142 it/s ] INFO sat_3 - Iteration 30 of 35 INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 752/756 [ 0:00:04 &lt; 0:00:01 , 206 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 137 it/s ] INFO sat_3 - Iteration 31 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 135 it/s ] INFO sat_3 - Iteration 32 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 140 it/s ] INFO sat_3 - Iteration 33 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 141 it/s ] INFO sat_3 - Iteration 34 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 142 it/s ] INFO sat_3 - Iteration 35 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 750/756 [ 0:00:06 &lt; 0:00:01 , 138 it/s ] INFO Creating alignment model for speaker-independent features... 98% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 743/756 [ 0:00:06 &lt; 0:00:01 , 133 it/s ] INFO Training complete! INFO Exiting training early to save time as the corpus is below the subset size for later training stages INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 756/756 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Generating alignments... 98% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 738/756 [ 0:00:04 &lt; 0:00:01 , 208 it/s ] INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Generating alignments... 98% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 741/756 [ 0:00:04 &lt; 0:00:01 , 200 it/s ] INFO Accumulating transition stats... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 756/756 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Finished accumulating transition stats! INFO Collecting phone and word alignments from sat_3_ali lattices... 92% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 698/756 [ 0:00:01 &lt; 0:00:01 , 1,112 it/s ] INFO Beginning phone LM training... INFO Collecting training data... 0% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0/756 [ 0:00:01 &lt; -:--:-- , ? it/s ] INFO Training model... INFO Completed training in 1433.7462072372437 seconds! INFO Saved model to connaught-model WARNING Alignment analysis not available without using postgresql INFO Exporting sat_3_ali TextGrids to /tmp/textgrid-connaught... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 751/756 [ 0:00:04 &lt; 0:00:01 , 308 it/s ] INFO Finished exporting TextGrids to /tmp/textgrid-connaught! INFO Done! Everything took 1455.678 seconds /opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version &gt;=1.16.5 and &lt;1.23.0 is required for this version of SciPy (detected version 1.24.4 warnings.warn(f&#34;A NumPy version &gt;={np_minversion} and &lt;{np_maxversion}&#34; INFO Setting up corpus information... INFO Loading corpus from source files... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,247/100 [ 0:00:00 &lt; 0:00:00 , 795 it/s ] INFO Found 1 speaker across 2276 files, average number of utterances per speaker: 2276.0 INFO Initializing multiprocessing jobs... WARNING Number of jobs was specified as 3, but due to only having 1 speakers, MFA will only use 1 jobs. Use the --single_speaker flag if you would like to split utterances across jobs regardless of their speaker. INFO Normalizing text... 27% ━━━━━━━╸━━━━━━━━━━━━━━━━━━━━━━ 605/2,276 [ 0:00:01 &lt; 0:00:02 , 932 it/s ] INFO Creating corpus split for feature generation... 66% ━━━━━━━━━━━━━━━━╸━━━━━━━━ 3,011/4,552 [ 0:00:01 &lt; 0:00:01 , 29,857 it/s ] INFO Generating MFCCs... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,263/2,276 [ 0:00:16 &lt; 0:00:01 , 168 it/s ] INFO Calculating CMVN... INFO Generating final features... 92% ━━━━━━━━━━━━━━━━━━━━━━━╸━━ 2,083/2,276 [ 0:00:02 &lt; 0:00:01 , 2,133 it/s ] INFO Creating corpus split with features... 2% ╸━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 37/2,276 [ 0:00:01 &lt; -:--:-- , ? it/s ] INFO Filtering utterances for training... INFO Initializing training for monophone... INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:01 &lt; 0:00:00 , ? it/s ] INFO Generating initial alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:01 &lt; 0:00:00 , ? it/s ] INFO Initialization complete! INFO monophone - Iteration 1 of 40 INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,245/2,276 [ 0:00:05 &lt; 0:00:01 , 516 it/s ] INFO Accumulating statistics... 94% ━━━━━━━━━━━━━━━━━━━━━━━━╸━ 2,150/2,276 [ 0:00:02 &lt; 0:00:01 , 1,849 it/s ] INFO monophone - Iteration 2 of 40 INFO Generating alignments... 98% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 2,235/2,276 [ 0:00:04 &lt; 0:00:01 , 609 it/s ] INFO Accumulating statistics... 94% ━━━━━━━━━━━━━━━━━━━━━━━━╸━ 2,150/2,276 [ 0:00:02 &lt; 0:00:01 , 1,863 it/s ] INFO monophone - Iteration 3 of 40 INFO Generating alignments... 98% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 2,232/2,276 [ 0:00:04 &lt; 0:00:01 , 678 it/s ] INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━╸━━ 2,100/2,276 [ 0:00:02 &lt; 0:00:01 , 1,946 it/s ] INFO monophone - Iteration 4 of 40 INFO Generating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,271/2,276 [ 0:00:04 &lt; 0:00:01 , 684 it/s ] INFO Accumulating statistics... 94% ━━━━━━━━━━━━━━━━━━━━━━━━╸━ 2,150/2,276 [ 0:00:02 &lt; 0:00:01 , 1,768 it/s ] INFO monophone - Iteration 5 of 40 INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,262/2,276 [ 0:00:04 &lt; 0:00:01 , 631 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,250/2,276 [ 0:00:02 &lt; 0:00:01 , 1,814 it/s ] INFO monophone - Iteration 6 of 40 INFO Generating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,266/2,276 [ 0:00:04 &lt; 0:00:01 , 688 it/s ] INFO Accumulating statistics... 94% ━━━━━━━━━━━━━━━━━━━━━━━━╸━ 2,150/2,276 [ 0:00:02 &lt; 0:00:01 , 1,720 it/s ] INFO monophone - Iteration 7 of 40 INFO Generating alignments... 97% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 2,208/2,276 [ 0:00:04 &lt; 0:00:01 , 693 it/s ] INFO Accumulating statistics... 94% ━━━━━━━━━━━━━━━━━━━━━━━━╸━ 2,150/2,276 [ 0:00:02 &lt; 0:00:01 , 1,750 it/s ] INFO monophone - Iteration 8 of 40 INFO Generating alignments... 97% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 2,219/2,276 [ 0:00:04 &lt; 0:00:01 , 699 it/s ] INFO Accumulating statistics... 97% ━━━━━━━━━━━━━━━━━━━━━━━━━╺ 2,200/2,276 [ 0:00:02 &lt; 0:00:01 , 1,763 it/s ] INFO monophone - Iteration 9 of 40 INFO Generating alignments... 97% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 2,209/2,276 [ 0:00:04 &lt; 0:00:01 , 677 it/s ] INFO Accumulating statistics... 94% ━━━━━━━━━━━━━━━━━━━━━━━━╸━ 2,150/2,276 [ 0:00:02 &lt; 0:00:01 , 1,764 it/s ] INFO monophone - Iteration 10 of 40 INFO Generating alignments... 98% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,240/2,276 [ 0:00:04 &lt; 0:00:01 , 650 it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:01 &lt; 0:00:00 , 1,690 it/s ] INFO monophone - Iteration 11 of 40 INFO Accumulating statistics... 94% ━━━━━━━━━━━━━━━━━━━━━━━━╸━ 2,150/2,276 [ 0:00:02 &lt; 0:00:01 , 1,646 it/s ] INFO monophone - Iteration 12 of 40 INFO Generating alignments... 97% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 2,213/2,276 [ 0:00:04 &lt; 0:00:01 , 684 it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:01 &lt; 0:00:00 , 1,678 it/s ] INFO monophone - Iteration 13 of 40 INFO Accumulating statistics... 94% ━━━━━━━━━━━━━━━━━━━━━━━━╸━ 2,150/2,276 [ 0:00:02 &lt; 0:00:01 , 1,661 it/s ] INFO monophone - Iteration 14 of 40 INFO Generating alignments... 98% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 2,223/2,276 [ 0:00:04 &lt; 0:00:01 , 657 it/s ] INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━╸━━ 2,100/2,276 [ 0:00:02 &lt; 0:00:01 , 1,654 it/s ] INFO monophone - Iteration 15 of 40 INFO Accumulating statistics... 94% ━━━━━━━━━━━━━━━━━━━━━━━━╸━ 2,150/2,276 [ 0:00:02 &lt; 0:00:01 , 1,661 it/s ] INFO monophone - Iteration 16 of 40 INFO Generating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,274/2,276 [ 0:00:04 &lt; 0:00:01 , 653 it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:01 &lt; 0:00:00 , 1,625 it/s ] INFO monophone - Iteration 17 of 40 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,250/2,276 [ 0:00:02 &lt; 0:00:01 , 1,612 it/s ] INFO monophone - Iteration 18 of 40 INFO Generating alignments... 98% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 2,222/2,276 [ 0:00:05 &lt; 0:00:01 , 542 it/s ] INFO Accumulating statistics... 97% ━━━━━━━━━━━━━━━━━━━━━━━━━╺ 2,200/2,276 [ 0:00:02 &lt; 0:00:01 , 1,700 it/s ] INFO monophone - Iteration 19 of 40 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:01 &lt; 0:00:00 , 1,626 it/s ] INFO monophone - Iteration 20 of 40 INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,260/2,276 [ 0:00:04 &lt; 0:00:01 , 631 it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:01 &lt; 0:00:00 , 1,553 it/s ] INFO monophone - Iteration 21 of 40 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:01 &lt; 0:00:00 , 1,616 it/s ] INFO monophone - Iteration 22 of 40 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,250/2,276 [ 0:00:02 &lt; 0:00:01 , 1,679 it/s ] INFO monophone - Iteration 23 of 40 INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,264/2,276 [ 0:00:04 &lt; 0:00:01 , 628 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,250/2,276 [ 0:00:02 &lt; 0:00:01 , 1,672 it/s ] INFO monophone - Iteration 24 of 40 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,250/2,276 [ 0:00:02 &lt; 0:00:01 , 1,618 it/s ] INFO monophone - Iteration 25 of 40 INFO Accumulating statistics... 94% ━━━━━━━━━━━━━━━━━━━━━━━━╸━ 2,150/2,276 [ 0:00:02 &lt; 0:00:01 , 1,415 it/s ] INFO monophone - Iteration 26 of 40 INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,249/2,276 [ 0:00:04 &lt; 0:00:01 , 594 it/s ] INFO Accumulating statistics... 97% ━━━━━━━━━━━━━━━━━━━━━━━━━╺ 2,200/2,276 [ 0:00:02 &lt; 0:00:01 , 1,500 it/s ] INFO monophone - Iteration 27 of 40 INFO Accumulating statistics... 94% ━━━━━━━━━━━━━━━━━━━━━━━━╸━ 2,150/2,276 [ 0:00:02 &lt; 0:00:01 , 1,470 it/s ] INFO monophone - Iteration 28 of 40 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:01 &lt; 0:00:00 , 1,497 it/s ] INFO monophone - Iteration 29 of 40 INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,258/2,276 [ 0:00:04 &lt; 0:00:01 , 612 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,250/2,276 [ 0:00:02 &lt; 0:00:01 , 1,476 it/s ] INFO monophone - Iteration 30 of 40 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,250/2,276 [ 0:00:02 &lt; 0:00:01 , 1,490 it/s ] INFO monophone - Iteration 31 of 40 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,250/2,276 [ 0:00:02 &lt; 0:00:01 , 1,494 it/s ] INFO monophone - Iteration 32 of 40 INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,264/2,276 [ 0:00:05 &lt; 0:00:01 , 579 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,250/2,276 [ 0:00:02 &lt; 0:00:01 , 1,425 it/s ] INFO monophone - Iteration 33 of 40 INFO Accumulating statistics... 97% ━━━━━━━━━━━━━━━━━━━━━━━━━╺ 2,200/2,276 [ 0:00:02 &lt; 0:00:01 , 1,454 it/s ] INFO monophone - Iteration 34 of 40 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,250/2,276 [ 0:00:02 &lt; 0:00:01 , 1,470 it/s ] INFO monophone - Iteration 35 of 40 INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,257/2,276 [ 0:00:04 &lt; 0:00:01 , 594 it/s ] INFO Accumulating statistics... 97% ━━━━━━━━━━━━━━━━━━━━━━━━━╺ 2,200/2,276 [ 0:00:02 &lt; 0:00:01 , 1,441 it/s ] INFO monophone - Iteration 36 of 40 INFO Accumulating statistics... 97% ━━━━━━━━━━━━━━━━━━━━━━━━━╺ 2,200/2,276 [ 0:00:02 &lt; 0:00:01 , 1,418 it/s ] INFO monophone - Iteration 37 of 40 INFO Accumulating statistics... 97% ━━━━━━━━━━━━━━━━━━━━━━━━━╺ 2,200/2,276 [ 0:00:02 &lt; 0:00:01 , 1,422 it/s ] INFO monophone - Iteration 38 of 40 INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,246/2,276 [ 0:00:04 &lt; 0:00:01 , 607 it/s ] INFO Accumulating statistics... 94% ━━━━━━━━━━━━━━━━━━━━━━━━╸━ 2,150/2,276 [ 0:00:02 &lt; 0:00:01 , 1,476 it/s ] INFO monophone - Iteration 39 of 40 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,250/2,276 [ 0:00:02 &lt; 0:00:01 , 1,363 it/s ] INFO monophone - Iteration 40 of 40 INFO Accumulating statistics... 94% ━━━━━━━━━━━━━━━━━━━━━━━━╸━ 2,150/2,276 [ 0:00:02 &lt; 0:00:01 , 1,448 it/s ] INFO Training complete! INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:01 &lt; 0:00:00 , ? it/s ] INFO Generating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,265/2,276 [ 0:00:05 &lt; 0:00:01 , 577 it/s ] INFO Initializing training for triphone... INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:01 &lt; 0:00:00 , ? it/s ] INFO Converting alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Initialization complete! INFO triphone - Iteration 1 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,250/2,276 [ 0:00:02 &lt; 0:00:01 , 1,432 it/s ] INFO triphone - Iteration 2 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,250/2,276 [ 0:00:02 &lt; 0:00:01 , 1,334 it/s ] INFO triphone - Iteration 3 of 35 INFO Accumulating statistics... 97% ━━━━━━━━━━━━━━━━━━━━━━━━━╺ 2,200/2,276 [ 0:00:02 &lt; 0:00:01 , 1,269 it/s ] INFO triphone - Iteration 4 of 35 INFO Accumulating statistics... 97% ━━━━━━━━━━━━━━━━━━━━━━━━━╺ 2,200/2,276 [ 0:00:03 &lt; 0:00:01 , 1,161 it/s ] INFO triphone - Iteration 5 of 35 INFO Accumulating statistics... 97% ━━━━━━━━━━━━━━━━━━━━━━━━━╺ 2,200/2,276 [ 0:00:03 &lt; 0:00:01 , 1,164 it/s ] INFO triphone - Iteration 6 of 35 INFO Accumulating statistics... 97% ━━━━━━━━━━━━━━━━━━━━━━━━━╺ 2,200/2,276 [ 0:00:03 &lt; 0:00:01 , 1,075 it/s ] INFO triphone - Iteration 7 of 35 INFO Accumulating statistics... 97% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 2,200/2,276 [ 0:00:03 &lt; 0:00:01 , 994 it/s ] INFO triphone - Iteration 8 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,250/2,276 [ 0:00:03 &lt; 0:00:01 , 983 it/s ] INFO triphone - Iteration 9 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,250/2,276 [ 0:00:03 &lt; 0:00:01 , 895 it/s ] INFO triphone - Iteration 10 of 35 INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,257/2,276 [ 0:00:06 &lt; 0:00:01 , 414 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,250/2,276 [ 0:00:03 &lt; 0:00:01 , 838 it/s ] INFO triphone - Iteration 11 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,250/2,276 [ 0:00:04 &lt; 0:00:01 , 756 it/s ] INFO triphone - Iteration 12 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,250/2,276 [ 0:00:04 &lt; 0:00:01 , 648 it/s ] INFO triphone - Iteration 13 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,250/2,276 [ 0:00:05 &lt; 0:00:01 , 568 it/s ] INFO triphone - Iteration 14 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,250/2,276 [ 0:00:05 &lt; 0:00:01 , 466 it/s ] INFO triphone - Iteration 15 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,250/2,276 [ 0:00:07 &lt; 0:00:01 , 381 it/s ] INFO triphone - Iteration 16 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,250/2,276 [ 0:00:07 &lt; 0:00:01 , 333 it/s ] INFO triphone - Iteration 17 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,250/2,276 [ 0:00:09 &lt; 0:00:01 , 282 it/s ] INFO triphone - Iteration 18 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,250/2,276 [ 0:00:09 &lt; 0:00:01 , 256 it/s ] INFO triphone - Iteration 19 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:10 &lt; 0:00:00 , 212 it/s ] INFO triphone - Iteration 20 of 35 INFO Generating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:17 &lt; 0:00:00 , 133 it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:11 &lt; 0:00:00 , 201 it/s ] INFO triphone - Iteration 21 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:12 &lt; 0:00:00 , 183 it/s ] INFO triphone - Iteration 22 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:13 &lt; 0:00:00 , 165 it/s ] INFO triphone - Iteration 23 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:14 &lt; 0:00:00 , 153 it/s ] INFO triphone - Iteration 24 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:16 &lt; 0:00:00 , 141 it/s ] INFO triphone - Iteration 25 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:18 &lt; 0:00:00 , 125 it/s ] INFO triphone - Iteration 26 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:18 &lt; 0:00:00 , 121 it/s ] INFO triphone - Iteration 27 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:20 &lt; 0:00:00 , 114 it/s ] INFO triphone - Iteration 28 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:20 &lt; 0:00:00 , 113 it/s ] INFO triphone - Iteration 29 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:20 &lt; 0:00:00 , 113 it/s ] INFO triphone - Iteration 30 of 35 INFO Generating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,270/2,276 [ 0:00:29 &lt; 0:00:01 , 80 it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:20 &lt; 0:00:00 , 113 it/s ] INFO triphone - Iteration 31 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:20 &lt; 0:00:00 , 114 it/s ] INFO triphone - Iteration 32 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:20 &lt; 0:00:00 , 114 it/s ] INFO triphone - Iteration 33 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:20 &lt; 0:00:00 , 114 it/s ] INFO triphone - Iteration 34 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:19 &lt; 0:00:00 , 115 it/s ] INFO triphone - Iteration 35 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:20 &lt; 0:00:00 , 111 it/s ] INFO Training complete! INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:01 &lt; 0:00:00 , ? it/s ] INFO Generating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,273/2,276 [ 0:00:29 &lt; 0:00:01 , 81 it/s ] INFO Initializing training for lda... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:01 &lt; 0:00:00 , ? it/s ] INFO Converting alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Initialization complete! INFO lda - Iteration 1 of 35 INFO Accumulating statistics... 94% ━━━━━━━━━━━━━━━━━━━━━━━━╸━ 2,150/2,276 [ 0:00:02 &lt; 0:00:01 , 1,795 it/s ] INFO lda - Iteration 2 of 35 INFO Re-calculating LDA... 90% ━━━━━━━━━━━━━━━━━━━━━━━╺━━ 2,050/2,276 [ 0:00:02 &lt; 0:00:01 , 2,412 it/s ] INFO Accumulating statistics... 97% ━━━━━━━━━━━━━━━━━━━━━━━━━╺ 2,200/2,276 [ 0:00:02 &lt; 0:00:01 , 1,246 it/s ] INFO lda - Iteration 3 of 35 INFO Accumulating statistics... 97% ━━━━━━━━━━━━━━━━━━━━━━━━━╺ 2,200/2,276 [ 0:00:02 &lt; 0:00:01 , 1,174 it/s ] INFO lda - Iteration 4 of 35 INFO Re-calculating LDA... 97% ━━━━━━━━━━━━━━━━━━━━━━━━━╺ 2,199/2,276 [ 0:00:02 &lt; 0:00:01 , 2,264 it/s ] INFO Accumulating statistics... 97% ━━━━━━━━━━━━━━━━━━━━━━━━━╺ 2,200/2,276 [ 0:00:03 &lt; 0:00:01 , 1,069 it/s ] INFO lda - Iteration 5 of 35 INFO Accumulating statistics... 97% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 2,200/2,276 [ 0:00:03 &lt; 0:00:01 , 949 it/s ] INFO lda - Iteration 6 of 35 INFO Re-calculating LDA... 96% ━━━━━━━━━━━━━━━━━━━━━━━━╸━ 2,178/2,276 [ 0:00:02 &lt; 0:00:01 , 2,057 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,250/2,276 [ 0:00:03 &lt; 0:00:01 , 879 it/s ] INFO lda - Iteration 7 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,250/2,276 [ 0:00:04 &lt; 0:00:01 , 733 it/s ] INFO lda - Iteration 8 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,250/2,276 [ 0:00:05 &lt; 0:00:01 , 555 it/s ] INFO lda - Iteration 9 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,250/2,276 [ 0:00:06 &lt; 0:00:01 , 412 it/s ] INFO lda - Iteration 10 of 35 INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,261/2,276 [ 0:00:12 &lt; 0:00:01 , 201 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,250/2,276 [ 0:00:08 &lt; 0:00:01 , 323 it/s ] INFO lda - Iteration 11 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,250/2,276 [ 0:00:09 &lt; 0:00:01 , 273 it/s ] INFO lda - Iteration 12 of 35 INFO Re-calculating LDA... 91% ━━━━━━━━━━━━━━━━━━━━━━━╸━━ 2,062/2,276 [ 0:00:02 &lt; 0:00:01 , 2,177 it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:09 &lt; 0:00:00 , 229 it/s ] INFO lda - Iteration 13 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:11 &lt; 0:00:00 , 194 it/s ] INFO lda - Iteration 14 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:13 &lt; 0:00:00 , 165 it/s ] INFO lda - Iteration 15 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:15 &lt; 0:00:00 , 147 it/s ] INFO lda - Iteration 16 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:17 &lt; 0:00:00 , 134 it/s ] INFO lda - Iteration 17 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:19 &lt; 0:00:00 , 117 it/s ] INFO lda - Iteration 18 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:21 &lt; 0:00:00 , 105 it/s ] INFO lda - Iteration 19 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:23 &lt; 0:00:00 , 97 it/s ] INFO lda - Iteration 20 of 35 INFO Generating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,270/2,276 [ 0:00:33 &lt; 0:00:01 , 70 it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:25 &lt; 0:00:00 , 88 it/s ] INFO lda - Iteration 21 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:28 &lt; 0:00:00 , 79 it/s ] INFO lda - Iteration 22 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:33 &lt; 0:00:00 , 68 it/s ] INFO lda - Iteration 23 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:33 &lt; 0:00:00 , 67 it/s ] INFO lda - Iteration 24 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:36 &lt; 0:00:00 , 63 it/s ] INFO lda - Iteration 25 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:42 &lt; 0:00:00 , 53 it/s ] INFO lda - Iteration 26 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:43 &lt; 0:00:00 , 53 it/s ] INFO lda - Iteration 27 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:47 &lt; 0:00:00 , 48 it/s ] INFO lda - Iteration 28 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:47 &lt; 0:00:00 , 48 it/s ] INFO lda - Iteration 29 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:46 &lt; 0:00:00 , 49 it/s ] INFO lda - Iteration 30 of 35 INFO Generating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,272/2,276 [ 0:00:46 &lt; 0:00:01 , 50 it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:48 &lt; 0:00:00 , 47 it/s ] INFO lda - Iteration 31 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:47 &lt; 0:00:00 , 48 it/s ] INFO lda - Iteration 32 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:47 &lt; 0:00:00 , 48 it/s ] INFO lda - Iteration 33 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:47 &lt; 0:00:00 , 48 it/s ] INFO lda - Iteration 34 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:48 &lt; 0:00:00 , 47 it/s ] INFO lda - Iteration 35 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:49 &lt; 0:00:00 , 46 it/s ] INFO Training complete! INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:01 &lt; 0:00:00 , ? it/s ] INFO Generating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,275/2,276 [ 0:00:45 &lt; 0:00:01 , 52 it/s ] INFO Initializing training for sat... INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:01 &lt; 0:00:00 , ? it/s ] INFO Converting alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:01 &lt; 0:00:00 , ? it/s ] INFO Initialization complete! INFO sat - Iteration 1 of 35 INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━╸━━ 2,100/2,276 [ 0:00:02 &lt; 0:00:01 , 1,788 it/s ] INFO sat - Iteration 2 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:02 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:02 &lt; 0:00:00 , 1,086 it/s ] INFO sat - Iteration 3 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,250/2,276 [ 0:00:03 &lt; 0:00:01 , 1,133 it/s ] INFO sat - Iteration 4 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:01 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:02 &lt; 0:00:00 , 1,031 it/s ] INFO sat - Iteration 5 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,250/2,276 [ 0:00:03 &lt; 0:00:01 , 853 it/s ] INFO sat - Iteration 6 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:01 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,250/2,276 [ 0:00:04 &lt; 0:00:01 , 604 it/s ] INFO sat - Iteration 7 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,250/2,276 [ 0:00:05 &lt; 0:00:01 , 478 it/s ] INFO sat - Iteration 8 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,250/2,276 [ 0:00:07 &lt; 0:00:01 , 361 it/s ] INFO sat - Iteration 9 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,250/2,276 [ 0:00:08 &lt; 0:00:01 , 296 it/s ] INFO sat - Iteration 10 of 35 INFO Generating alignments... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,263/2,276 [ 0:00:15 &lt; 0:00:01 , 158 it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,250/2,276 [ 0:00:10 &lt; 0:00:01 , 254 it/s ] INFO sat - Iteration 11 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:10 &lt; 0:00:00 , 211 it/s ] INFO sat - Iteration 12 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:02 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:12 &lt; 0:00:00 , 189 it/s ] INFO sat - Iteration 13 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:13 &lt; 0:00:00 , 163 it/s ] INFO sat - Iteration 14 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:15 &lt; 0:00:00 , 144 it/s ] INFO sat - Iteration 15 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:17 &lt; 0:00:00 , 128 it/s ] INFO sat - Iteration 16 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:19 &lt; 0:00:00 , 120 it/s ] INFO sat - Iteration 17 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:21 &lt; 0:00:00 , 106 it/s ] INFO sat - Iteration 18 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:23 &lt; 0:00:00 , 98 it/s ] INFO sat - Iteration 19 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:26 &lt; 0:00:00 , 87 it/s ] INFO sat - Iteration 20 of 35 INFO Generating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,274/2,276 [ 0:00:35 &lt; 0:00:01 , 67 it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:28 &lt; 0:00:00 , 81 it/s ] INFO sat - Iteration 21 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:30 &lt; 0:00:00 , 76 it/s ] INFO sat - Iteration 22 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:32 &lt; 0:00:00 , 69 it/s ] INFO sat - Iteration 23 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:36 &lt; 0:00:00 , 63 it/s ] INFO sat - Iteration 24 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:38 &lt; 0:00:00 , 59 it/s ] INFO sat - Iteration 25 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:41 &lt; 0:00:00 , 55 it/s ] INFO sat - Iteration 26 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:44 &lt; 0:00:00 , 51 it/s ] INFO sat - Iteration 27 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:49 &lt; 0:00:00 , 46 it/s ] INFO sat - Iteration 28 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:51 &lt; 0:00:00 , 44 it/s ] INFO sat - Iteration 29 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:48 &lt; 0:00:00 , 47 it/s ] INFO sat - Iteration 30 of 35 INFO Generating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,271/2,276 [ 0:00:46 &lt; 0:00:01 , 50 it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:48 &lt; 0:00:00 , 47 it/s ] INFO sat - Iteration 31 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:49 &lt; 0:00:00 , 46 it/s ] INFO sat - Iteration 32 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:49 &lt; 0:00:00 , 46 it/s ] INFO sat - Iteration 33 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:48 &lt; 0:00:00 , 47 it/s ] INFO sat - Iteration 34 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:49 &lt; 0:00:00 , 46 it/s ] INFO sat - Iteration 35 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:48 &lt; 0:00:00 , 47 it/s ] INFO Creating alignment model for speaker-independent features... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:50 &lt; 0:00:00 , 45 it/s ] INFO Training complete! INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:01 &lt; 0:00:00 , ? it/s ] INFO Generating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,275/2,276 [ 0:00:45 &lt; 0:00:01 , 51 it/s ] INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:02 &lt; 0:00:00 , ? it/s ] INFO Generating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,271/2,276 [ 0:00:46 &lt; 0:00:01 , 50 it/s ] INFO Initializing training for sat_2... INFO Converting alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:01 &lt; 0:00:00 , ? it/s ] INFO Initialization complete! INFO sat_2 - Iteration 1 of 35 INFO Accumulating statistics... 92% ━━━━━━━━━━━━━━━━━━━━━━━╸━━ 2,100/2,276 [ 0:00:02 &lt; 0:00:01 , 1,789 it/s ] INFO sat_2 - Iteration 2 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:02 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 97% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 2,200/2,276 [ 0:00:03 &lt; 0:00:01 , 917 it/s ] INFO sat_2 - Iteration 3 of 35 INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,250/2,276 [ 0:00:06 &lt; 0:00:01 , 420 it/s ] INFO sat_2 - Iteration 4 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:01 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,250/2,276 [ 0:00:10 &lt; 0:00:01 , 245 it/s ] INFO sat_2 - Iteration 5 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:14 &lt; 0:00:00 , 156 it/s ] INFO sat_2 - Iteration 6 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:02 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:20 &lt; 0:00:00 , 111 it/s ] INFO sat_2 - Iteration 7 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:27 &lt; 0:00:00 , 84 it/s ] INFO sat_2 - Iteration 8 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:35 &lt; 0:00:00 , 64 it/s ] INFO sat_2 - Iteration 9 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:46 &lt; 0:00:00 , 49 it/s ] INFO sat_2 - Iteration 10 of 35 INFO Generating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,273/2,276 [ 0:00:59 &lt; 0:00:01 , 39 it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:57 &lt; 0:00:00 , 40 it/s ] INFO sat_2 - Iteration 11 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:00 &lt; 0:00:00 , 38 it/s ] INFO sat_2 - Iteration 12 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:01 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:00 &lt; 0:00:00 , 38 it/s ] INFO sat_2 - Iteration 13 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:01 &lt; 0:00:00 , 37 it/s ] INFO sat_2 - Iteration 14 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:02 &lt; 0:00:00 , 37 it/s ] INFO sat_2 - Iteration 15 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:02 &lt; 0:00:00 , 37 it/s ] INFO sat_2 - Iteration 16 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:00 &lt; 0:00:00 , 38 it/s ] INFO sat_2 - Iteration 17 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:02 &lt; 0:00:00 , 37 it/s ] INFO sat_2 - Iteration 18 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:02 &lt; 0:00:00 , 36 it/s ] INFO sat_2 - Iteration 19 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:02 &lt; 0:00:00 , 36 it/s ] INFO sat_2 - Iteration 20 of 35 INFO Generating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:56 &lt; 0:00:00 , 36 it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:03 &lt; 0:00:00 , 36 it/s ] INFO sat_2 - Iteration 21 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:06 &lt; 0:00:00 , 34 it/s ] INFO sat_2 - Iteration 22 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:06 &lt; 0:00:00 , 34 it/s ] INFO sat_2 - Iteration 23 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:03 &lt; 0:00:00 , 36 it/s ] INFO sat_2 - Iteration 24 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:03 &lt; 0:00:00 , 36 it/s ] INFO sat_2 - Iteration 25 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:03 &lt; 0:00:00 , 36 it/s ] INFO sat_2 - Iteration 26 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:04 &lt; 0:00:00 , 35 it/s ] INFO sat_2 - Iteration 27 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:04 &lt; 0:00:00 , 36 it/s ] INFO sat_2 - Iteration 28 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:04 &lt; 0:00:00 , 36 it/s ] INFO sat_2 - Iteration 29 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:02 &lt; 0:00:00 , 37 it/s ] INFO sat_2 - Iteration 30 of 35 INFO Generating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,274/2,276 [ 0:00:53 &lt; 0:00:01 , 43 it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:06 &lt; 0:00:00 , 35 it/s ] INFO sat_2 - Iteration 31 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:06 &lt; 0:00:00 , 35 it/s ] INFO sat_2 - Iteration 32 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:05 &lt; 0:00:00 , 35 it/s ] INFO sat_2 - Iteration 33 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:04 &lt; 0:00:00 , 36 it/s ] INFO sat_2 - Iteration 34 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:05 &lt; 0:00:00 , 35 it/s ] INFO sat_2 - Iteration 35 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:06 &lt; 0:00:00 , 34 it/s ] INFO Creating alignment model for speaker-independent features... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,272/2,276 [ 0:01:08 &lt; 0:00:01 , 34 it/s ] INFO Training complete! INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:01 &lt; 0:00:00 , ? it/s ] INFO Generating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,274/2,276 [ 0:00:52 &lt; 0:00:01 , 44 it/s ] INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:02 &lt; 0:00:00 , ? it/s ] INFO Generating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,274/2,276 [ 0:00:53 &lt; 0:00:01 , 43 it/s ] INFO Generating pronunciations... 95% ━━━━━━━━━━━━━━━━━━━━━━━━╸━ 2,164/2,276 [ 0:00:02 &lt; 0:00:01 , 1,450 it/s ] INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:01 &lt; 0:00:00 , ? it/s ] INFO Generating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,272/2,276 [ 0:00:54 &lt; 0:00:01 , 43 it/s ] INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:02 &lt; 0:00:00 , ? it/s ] INFO Generating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,275/2,276 [ 0:00:54 &lt; 0:00:01 , 43 it/s ] INFO Initializing training for sat_3... INFO Converting alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:01 &lt; 0:00:00 , ? it/s ] INFO Initialization complete! INFO sat_3 - Iteration 1 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:01 &lt; 0:00:00 , 1,724 it/s ] INFO sat_3 - Iteration 2 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:02 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:04 &lt; 0:00:00 , 512 it/s ] INFO sat_3 - Iteration 3 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:16 &lt; 0:00:00 , 140 it/s ] INFO sat_3 - Iteration 4 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:01 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:35 &lt; 0:00:00 , 64 it/s ] INFO sat_3 - Iteration 5 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:59 &lt; 0:00:00 , 39 it/s ] INFO sat_3 - Iteration 6 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:01 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:59 &lt; 0:00:00 , 38 it/s ] INFO sat_3 - Iteration 7 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:01 &lt; 0:00:00 , 37 it/s ] INFO sat_3 - Iteration 8 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:03 &lt; 0:00:00 , 37 it/s ] INFO sat_3 - Iteration 9 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:02 &lt; 0:00:00 , 37 it/s ] INFO sat_3 - Iteration 10 of 35 INFO Generating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,273/2,276 [ 0:01:01 &lt; 0:00:01 , 38 it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:02 &lt; 0:00:00 , 37 it/s ] INFO sat_3 - Iteration 11 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:03 &lt; 0:00:00 , 35 it/s ] INFO sat_3 - Iteration 12 of 35 INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:01 &lt; 0:00:00 , ? it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:02 &lt; 0:00:00 , 37 it/s ] INFO sat_3 - Iteration 13 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:01 &lt; 0:00:00 , 37 it/s ] INFO sat_3 - Iteration 14 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:02 &lt; 0:00:00 , 36 it/s ] INFO sat_3 - Iteration 15 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:02 &lt; 0:00:00 , 37 it/s ] INFO sat_3 - Iteration 16 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:04 &lt; 0:00:00 , 35 it/s ] INFO sat_3 - Iteration 17 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:03 &lt; 0:00:00 , 36 it/s ] INFO sat_3 - Iteration 18 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:03 &lt; 0:00:00 , 36 it/s ] INFO sat_3 - Iteration 19 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:03 &lt; 0:00:00 , 37 it/s ] INFO sat_3 - Iteration 20 of 35 INFO Generating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:52 &lt; 0:00:00 , 43 it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:04 &lt; 0:00:00 , 35 it/s ] INFO sat_3 - Iteration 21 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:05 &lt; 0:00:00 , 35 it/s ] INFO sat_3 - Iteration 22 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:03 &lt; 0:00:00 , 35 it/s ] INFO sat_3 - Iteration 23 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:03 &lt; 0:00:00 , 36 it/s ] INFO sat_3 - Iteration 24 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:04 &lt; 0:00:00 , 35 it/s ] INFO sat_3 - Iteration 25 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:03 &lt; 0:00:00 , 36 it/s ] INFO sat_3 - Iteration 26 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:02 &lt; 0:00:00 , 37 it/s ] INFO sat_3 - Iteration 27 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:02 &lt; 0:00:00 , 37 it/s ] INFO sat_3 - Iteration 28 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:03 &lt; 0:00:00 , 36 it/s ] INFO sat_3 - Iteration 29 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:03 &lt; 0:00:00 , 36 it/s ] INFO sat_3 - Iteration 30 of 35 INFO Generating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,273/2,276 [ 0:00:53 &lt; 0:00:01 , 44 it/s ] INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:02 &lt; 0:00:00 , 36 it/s ] INFO sat_3 - Iteration 31 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:03 &lt; 0:00:00 , 36 it/s ] INFO sat_3 - Iteration 32 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:02 &lt; 0:00:00 , 36 it/s ] INFO sat_3 - Iteration 33 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:03 &lt; 0:00:00 , 36 it/s ] INFO sat_3 - Iteration 34 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:02 &lt; 0:00:00 , 37 it/s ] INFO sat_3 - Iteration 35 of 35 INFO Accumulating statistics... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:01:03 &lt; 0:00:00 , 36 it/s ] INFO Creating alignment model for speaker-independent features... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,274/2,276 [ 0:01:08 &lt; 0:00:01 , 34 it/s ] INFO Training complete! INFO Exiting training early to save time as the corpus is below the subset size for later training stages INFO Compiling training graphs... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:01 &lt; 0:00:00 , ? it/s ] INFO Generating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:53 &lt; 0:00:00 , 43 it/s ] INFO Calculating fMLLR for speaker adaptation... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1/1 [ 0:00:02 &lt; 0:00:00 , ? it/s ] INFO Generating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,275/2,276 [ 0:00:54 &lt; 0:00:01 , 43 it/s ] INFO Accumulating transition stats... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2,276/2,276 [ 0:00:00 &lt; 0:00:00 , ? it/s ] INFO Finished accumulating transition stats! INFO Collecting phone and word alignments from sat_3_ali lattices... 99% ━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,242/2,276 [ 0:00:03 &lt; 0:00:01 , 1,050 it/s ] INFO Beginning phone LM training... INFO Collecting training data... 17% ━━━━━╺━━━━━━━━━━━━━━━━━━━━━━━━━━ 383/2,276 [ 0:00:01 &lt; -:--:-- , ? it/s ] INFO Training model... INFO Completed training in 7754.0635895729065 seconds! INFO Saved model to all-model WARNING Alignment analysis not available without using postgresql INFO Exporting sat_3_ali TextGrids to /tmp/textgrid-all... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 2,267/2,276 [ 0:00:11 &lt; 0:00:01 , 251 it/s ] INFO Finished exporting TextGrids to /tmp/textgrid-all! INFO Done! Everything took 7795.071 seconds /opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version &gt;=1.16.5 and &lt;1.23.0 is required for this version of SciPy (detected version 1.24.4 warnings.warn(f&#34;A NumPy version &gt;={np_minversion} and &lt;{np_maxversion}&#34; INFO Training aligner INFO Calculating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 250/250 [ 0:00:25 &lt; 0:00:00 , 10 it/s ] INFO Best likelihood: -4.57581 INFO Completed computing alignments! INFO Encoding the alignments as FSAs INFO Success! FAR path: /tmp/mfa-temp/lexicon-ulster/train_g2p/lexicon-ulster.far; encoder path: /tmp/mfa-temp/lexicon-ulster/train_g2p/lexicon-ulster.enc INFO Saved model to g2p-ulster INFO Done! Everything took 29.555 seconds /opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version &gt;=1.16.5 and &lt;1.23.0 is required for this version of SciPy (detected version 1.24.4 warnings.warn(f&#34;A NumPy version &gt;={np_minversion} and &lt;{np_maxversion}&#34; INFO Training aligner INFO Calculating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸ 249/250 [ 0:00:23 &lt; 0:00:01 , 11 it/s ] INFO Best likelihood: -4.86911 INFO Completed computing alignments! INFO Encoding the alignments as FSAs INFO Success! FAR path: /tmp/mfa-temp/lexicon-munster/train_g2p/lexicon-munster.far; encoder path: /tmp/mfa-temp/lexicon-munster/train_g2p/lexicon-munster.enc INFO Saved model to g2p-munster INFO Done! Everything took 25.841 seconds /opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version &gt;=1.16.5 and &lt;1.23.0 is required for this version of SciPy (detected version 1.24.4 warnings.warn(f&#34;A NumPy version &gt;={np_minversion} and &lt;{np_maxversion}&#34; INFO Training aligner INFO Calculating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 250/250 [ 0:00:21 &lt; 0:00:00 , 11 it/s ] INFO Best likelihood: -4.7599 INFO Completed computing alignments! INFO Encoding the alignments as FSAs INFO Success! FAR path: /tmp/mfa-temp/lexicon-connaught/train_g2p/lexicon-connaught.far; encoder path: /tmp/mfa-temp/lexicon-connaught/train_g2p/lexicon-connaught.enc INFO Saved model to g2p-connaught INFO Done! Everything took 24.935 seconds /opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version &gt;=1.16.5 and &lt;1.23.0 is required for this version of SciPy (detected version 1.24.4 warnings.warn(f&#34;A NumPy version &gt;={np_minversion} and &lt;{np_maxversion}&#34; INFO Training aligner INFO Calculating alignments... 100% ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 250/250 [ 0:01:03 &lt; 0:00:00 , 4 it/s ] INFO Best likelihood: -5.08084 INFO Completed computing alignments! INFO Encoding the alignments as FSAs INFO Success! FAR path: /tmp/mfa-temp/lexicon-all/train_g2p/lexicon-all.far; encoder path: /tmp/mfa-temp/lexicon-all/train_g2p/lexicon-all.enc INFO Saved model to g2p-all INFO Done! Everything took 67.876 seconds .",
            "url": "https://jimregan.github.io/notes/2021/05/13/train-irish-mfa-model-fuaimeanna.html",
            "relUrl": "/2021/05/13/train-irish-mfa-model-fuaimeanna.html",
            "date": " • May 13, 2021"
        }
        
    
  
    
        ,"post237": {
            "title": "Scrape fuaimeanna.ie",
            "content": "Not-quite original version . %%writefile fuaimeanna.pl #!/usr/bin/perl # License: Apache 2.0 # Scrapes sounds from fuaimeanna.ie # Creates a set of labels in &#39;label/&#39; (which must exist) # along with three files: # run-wget.sh, which downloads the sounds to mp3/ (it creates it) # run-ffmpeg.sh, which converts the sounds in mp3/ to wav files in wav/ # all-fuaimeanna-data.tsv, which contains all of the data use warnings; use strict; use utf8; use URI; use Web::Scraper; use Data::Dumper; binmode(STDOUT, &quot;:utf8&quot;); binmode(STDERR, &quot;:utf8&quot;); open(WGET, &quot;&gt;&quot;, &quot;run-wget.sh&quot;); binmode(WGET, &quot;:utf8&quot;); open(FFMPEG, &quot;&gt;&quot;, &quot;run-ffmpeg.sh&quot;); binmode(FFMPEG, &quot;:utf8&quot;); open(ALL, &quot;&gt;&quot;, &quot;all-fuaimeanna-data.tsv&quot;); binmode(ALL, &quot;:utf8&quot;); my $phones = scraper { process &#39;div[class=&quot;friotal&quot;]&#39;, &#39;sounds[]&#39; =&gt; scraper { process &#39;span[class=&quot;ortho&quot;]&#39;, &#39;orth&#39; =&gt; &#39;TEXT&#39;; process &#39;span[class=&quot;taifead&quot;] span[class=&quot;player&quot;] a audio source&#39;, &#39;sounds[]&#39; =&gt; &#39;@src&#39;; process &#39;span[class=&quot;phonological&quot;]&#39;, &#39;dialects[]&#39; =&gt; scraper { process &#39;a[class=&quot;phoneme&quot;]&#39;, &#39;phonemes[]&#39; =&gt; &#39;TEXT&#39;; }; }; }; if(! -d &quot;label&quot;) { die &quot;Directory &#39;label&#39; does not exist n&quot;; } # write shell headers to output files print WGET &quot;#!/bin/sh n&quot;; print WGET &quot;mkdir mp3 n&quot;; print FFMPEG &quot;#!/bin/sh n&quot;; print FFMPEG &quot;mkdir wav n&quot;; # write .tsv header print ALL &quot;Orthographic t&quot;; print ALL &quot;Audio (Gaoth Dobhair) tIPA (Gaoth Dobhair) t&quot;; print ALL &quot;Audio (Ceathrú Rua) tIPA (Ceathrú Rua) t&quot;; print ALL &quot;Audio (Corca Dhuibhne) tIPA (Corca Dhuibhne) n&quot;; for my $i (1..77) { my $res = $phones-&gt;scrape(URI-&gt;new(&quot;http://www.fuaimeanna.ie/en/Recordings.aspx?Page=$i&quot;)); for my $sound (@{$res-&gt;{&#39;sounds&#39;}}) { my $word = $sound-&gt;{&#39;orth&#39;}; $word =~ s/^&lt;//; $word =~ s/&gt;$//; if($#{$sound-&gt;{&#39;sounds&#39;}} != 2 &amp;&amp; $#{$sound-&gt;{&#39;dialects&#39;}} != 2) { print STDERR &quot;Error reading &lt;$word&gt; on page $i&quot;; } print ALL &quot;$word t&quot;; for my $j (0..2) { my $sound_raw = ${$sound-&gt;{&#39;sounds&#39;}}[$j]; my $phones_raw = join(&#39; &#39;, @{${$sound-&gt;{&#39;dialects&#39;}}[$j]-&gt;{&#39;phonemes&#39;}}); # put everything in a tsv file first, because it doesn&#39;t make sense to hammer their server again print ALL $sound_raw . &quot; t&quot; . $phones_raw; print ALL &quot; t&quot; unless ($j == 2); my $sound_base = $sound_raw; $sound_base =~ s!/sounds/!!; $sound_base =~ s/ .mp3//; my $phones_out = $phones_raw; # discard word boundary $phones_out =~ s/ # / /g; $phones_out =~ s/ .//g; $phones_out =~ s/ˈ//g; $phones_out =~ s/ s+/ /g; $phones_out =~ s/^ //; $phones_out =~ s/ $//; # write the script line print WGET &quot;wget http://www.fuaimeanna.ie$sound_raw -O mp3/$sound_base.mp3 n&quot;; print FFMPEG &quot;ffmpeg -i &quot;mp3/$sound_base.mp3 &quot; -acodec pcm_s16le -ac 1 -ar 16000 wav/$sound_base.wav n&quot;; # write the phones to the label file my $label_file = &quot;label/$sound_base.phones&quot;; open(OUT, &quot;&gt;&quot;, $label_file); binmode(OUT, &quot;:utf8&quot;); print OUT &quot;$phones_out&quot;; close(OUT); } # add a newline to the tsv file print ALL &quot; n&quot;; } } . !mkdir label . %%capture !apt-get -y install libweb-scraper-perl liburi-perl . !chmod a+x fuaimeanna.pl . !./fuaimeanna.pl . %%capture !sh run-wget.sh !sh run-ffmpeg.sh .",
            "url": "https://jimregan.github.io/notes/kaggle/fuaimeanna/scraper/2021/05/13/scrape-fuaimeanna-ie.html",
            "relUrl": "/kaggle/fuaimeanna/scraper/2021/05/13/scrape-fuaimeanna-ie.html",
            "date": " • May 13, 2021"
        }
        
    
  
    
        ,"post238": {
            "title": "CMU Wilderness no longer works",
            "content": "tl;dr - grabbing the audio doesn&#39;t work . !git clone https://github.com/festvox/datasets-CMU_Wilderness . Cloning into &#39;datasets-CMU_Wilderness&#39;... remote: Enumerating objects: 791, done. remote: Total 791 (delta 0), reused 0 (delta 0), pack-reused 791 Receiving objects: 100% (791/791), 91.48 MiB | 11.83 MiB/s, done. Resolving deltas: 100% (32/32), done. . %cd datasets-CMU_Wilderness . /kaggle/working/datasets-CMU_Wilderness . %%capture !yes|apt install sptk html2text sox libncurses-dev . %%capture !bin/do_found make_dependencies . !bin/do_found fast_make_align indices/ABIWBT.tar.gz . /bin/bash: bin/do_found: No such file or directory .",
            "url": "https://jimregan.github.io/notes/kaggle/cmuwilderness/bibleis/2021/05/09/cmu-wilderness-does-not-work.html",
            "relUrl": "/kaggle/cmuwilderness/bibleis/2021/05/09/cmu-wilderness-does-not-work.html",
            "date": " • May 9, 2021"
        }
        
    
  
    
        ,"post239": {
            "title": "Run deepspeech on Wolne Lektury audio (20-000-mil-podmorskiej-zeglugi pt. 1)",
            "content": "Original on Kaggle . !cp ../input/wolne-lektury-deepspeech/*.json . . !pip install deepspeech . deepspeech --model ../input/polish-deepspeech-models/output_graph_pl.pbmm --scorer ../input/polish-deepspeech-models/kenlm_pl.scorer --json --audio ../input/wolne-lektury-deepspeech/20-000-mil-podmorskiej-zeglugi_026_nowa-propozycja-kapitana-nemo.wav &gt; 20-000-mil-podmorskiej-zeglugi_026_nowa-propozycja-kapitana-nemo.json; rm $out $j; done;done . !for i in $(ls ../input/wolne-lektury-deepspeech/*.mp3|grep -v zeglugi_026_nowa-propozycja-kapitana); do base=$(basename &quot;$i&quot; &quot;.mp3&quot;); out=&quot;$base.wav&quot;; ffmpeg -i $i -acodec pcm_s16le -ac 1 -ar 16000 $out; deepspeech --model ../input/polish-deepspeech-models/output_graph_pl.pbmm --scorer ../input/polish-deepspeech-models/kenlm_pl.scorer --json --audio $out &gt; $base.json; rm $out $j; done .",
            "url": "https://jimregan.github.io/notes/asr/polish/kaggle/2021/05/07/deepspeech-wolne-lektury-20-000-mil-podmorskiej-zeglugi-pt-1.html",
            "relUrl": "/asr/polish/kaggle/2021/05/07/deepspeech-wolne-lektury-20-000-mil-podmorskiej-zeglugi-pt-1.html",
            "date": " • May 7, 2021"
        }
        
    
  
    
        ,"post240": {
            "title": "Azure ASR's JSONL output to JSON",
            "content": "import glob import json for i in glob.glob(&#39;../input/mo-sgeal-fein-wikisource-azure-asr-output/*.jsonl&#39;): outf = i.replace(&#39;jsonl&#39;, &#39;json&#39;).split(&#39;/&#39;)[-1] with open(i) as f: curfile = [] for line in f.readlines(): cur = {} json_data = json.loads(line) cur[&#39;start&#39;] = json_data[&#39;Offset&#39;] cur[&#39;duration&#39;] = json_data[&#39;Duration&#39;] cur[&#39;text&#39;] = json_data[&#39;NBest&#39;][0][&#39;Lexical&#39;] curfile.append(cur) with open(outf, &#39;w&#39;) as of: json.dump(curfile, of) .",
            "url": "https://jimregan.github.io/notes/azure/irish/asr/2021/05/04/msf-azure-jsonl-to-json.html",
            "relUrl": "/azure/irish/asr/2021/05/04/msf-azure-jsonl-to-json.html",
            "date": " • May 4, 2021"
        }
        
    
  
    
        ,"post241": {
            "title": "Azure speech recognition for Irish",
            "content": "%%capture !pip install azure-cognitiveservices-speech . %%capture !pip install youtube-dl . %%capture !youtube-dl https://www.youtube.com/watch?v=cfjdfaqWY3Y . %%capture !ffmpeg -i Cúla4 Ar Scoil _ Ábhar - Mata _ Téama - Bia-cfjdfaqWY3Y.mkv -acodec pcm_s16le -ac 1 -ar 16000 cfjdfaqWY3Y.wav . import IPython IPython.display.Audio(&#39;/content/cfjdfaqWY3Y.wav&#39;) . import azure.cognitiveservices.speech as speechsdk . Use either Key1 or Key2 (on Azure Portal, in &quot;Keys and Endpoints&quot; from the menu on the left hand side of the screen). . _SUBS=&#39;&#39; . _LOC=&#39;westeurope&#39; . speech_config = speechsdk.SpeechConfig(region=_LOC, subscription=_SUBS) . audio_input=speechsdk.audio.AudioConfig(filename=&#39;cfjdfaqWY3Y.wav&#39;) . speech_config.speech_recognition_language = &#39;ga-IE&#39; speech_config.request_word_level_timestamps() speech_config.output_format = speechsdk.OutputFormat(1) speech_config.endpoint_id=&#39;https://westeurope.api.cognitive.microsoft.com/sts/v1.0/issuetoken&#39; . speech_config.set_property(speechsdk.PropertyId.Speech_LogFilename, &quot;azure.log&quot;) . # Copyright (c) Microsoft. All rights reserved. # Licensed under the MIT license. See LICENSE.md file in the project root for full license information. import time def speech_recognize_continuous_from_file(speech_config, audio_config): &quot;&quot;&quot;performs continuous speech recognition with input from an audio file&quot;&quot;&quot; speech_config = speech_config audio_config = audio_config speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, language=&#39;ga-IE&#39;, audio_config=audio_config) done = False def stop_cb(evt): &quot;&quot;&quot;callback that signals to stop continuous recognition upon receiving an event `evt`&quot;&quot;&quot; print(&#39;CLOSING on {}&#39;.format(evt)) nonlocal done done = True def cancelled(evt): result = evt.result cancellation_details = result.cancellation_details print(&quot;Speech Recognition canceled: {}&quot;.format(cancellation_details.reason)) if cancellation_details.reason == speechsdk.CancellationReason.Error: print(&quot;Error details: {}&quot;.format(cancellation_details.error_details)) # Connect callbacks to the events fired by the speech recognizer speech_recognizer.recognizing.connect(lambda evt: print(&#39;RECOGNIZING: {}&#39;.format(evt))) speech_recognizer.recognized.connect(lambda evt: print(&#39;RECOGNIZED: {}&#39;.format(evt))) speech_recognizer.session_started.connect(lambda evt: print(&#39;SESSION STARTED: {}&#39;.format(evt))) speech_recognizer.session_stopped.connect(lambda evt: print(&#39;SESSION STOPPED {}&#39;.format(evt))) speech_recognizer.canceled.connect(cancelled) # stop continuous recognition on either session stopped or canceled events speech_recognizer.session_stopped.connect(stop_cb) speech_recognizer.canceled.connect(stop_cb) # Start continuous speech recognition speech_recognizer.start_continuous_recognition() while not done: time.sleep(.5) speech_recognizer.stop_continuous_recognition() . speech_recognize_continuous_from_file(speech_config, audio_input) . Debugging with curl . !curl -v -X POST &quot;https://{_LOC}.api.cognitive.microsoft.com/sts/v1.0/issueToken&quot; -H &quot;Ocp-Apim-Subscription-Key: {_SUBS}&quot; -H &quot;Content-type: application/x-www-form-urlencoded&quot; -H &quot;Content-Length: 0&quot; . _TOK=&#39;&#39; . !curl -v -X POST &quot;https://{_LOC}.stt.speech.microsoft.com/speech/recognition/interactive/cognitiveservices/v1?language=ga-IE&quot; -H &quot;Authorization: Bearer {_TOK}&quot; -H &quot;Transfer-Encoding: chunked&quot; -H &quot;Content-type: audio/wav; codec=audio/pcm; samplerate=16000&quot; --data-binary @cfjdfaqWY3Y.wav . Next step, get at the innards (TODO) . transcript_display_list = [] transcript_ITN_list = [] confidence_list = [] words = [] def parse_azure_result(evt): import json response = json.loads(evt.result.json) transcript_display_list.append(response[&#39;DisplayText&#39;]) confidence_list_temp = [item.get(&#39;Confidence&#39;) for item in response[&#39;NBest&#39;]] max_confidence_index = confidence_list_temp.index(max(confidence_list_temp)) confidence_list.append(response[&#39;NBest&#39;][max_confidence_index][&#39;Confidence&#39;]) transcript_ITN_list.append(response[&#39;NBest&#39;][max_confidence_index][&#39;ITN&#39;]) words.extend(response[&#39;NBest&#39;][max_confidence_index][&#39;Words&#39;]) logger.debug(evt) .",
            "url": "https://jimregan.github.io/notes/azure/irish/asr/2021/05/04/azure-asr-with-irish.html",
            "relUrl": "/azure/irish/asr/2021/05/04/azure-asr-with-irish.html",
            "date": " • May 4, 2021"
        }
        
    
  
    
        ,"post242": {
            "title": "Azure speech recognition for Irish, part 2",
            "content": "%%capture !pip install azure-cognitiveservices-speech !pip install youtube-dl . %%capture !youtube-dl https://www.youtube.com/watch?v=cfjdfaqWY3Y . import azure.cognitiveservices.speech as speechsdk . Use either Key1 or Key2 (on Azure Portal, in &quot;Keys and Endpoints&quot; from the menu on the left hand side of the screen). . _SUBS=input(&#39;put your subscription key here: &#39;) . _LOC=&#39;westeurope&#39; . speech_config = speechsdk.SpeechConfig(region=_LOC, subscription=_SUBS) . !wget https://upload.wikimedia.org/wikipedia/commons/6/60/MSF_chapter_3.ogg https://upload.wikimedia.org/wikipedia/commons/e/ee/MSF_chapter_4.ogg https://upload.wikimedia.org/wikipedia/commons/b/b3/MSF_chapter_5.ogg https://upload.wikimedia.org/wikipedia/commons/2/21/MSF_chapter_6.ogg https://upload.wikimedia.org/wikipedia/commons/7/71/MSF_chapter_7.ogg https://upload.wikimedia.org/wikipedia/commons/d/d5/MSF_chapter_8.ogg . !ffmpeg -i MSF_chapter_5.ogg -acodec pcm_s16le -ac 1 -ar 16000 MSF_chapter_5.wav . speech_config.speech_recognition_language = &#39;ga-IE&#39; speech_config.request_word_level_timestamps() speech_config.output_format = speechsdk.OutputFormat(1) speech_config.endpoint_id=f&#39;https://{_LOC}.api.cognitive.microsoft.com/sts/v1.0/issuetoken&#39; . # Copyright (c) Microsoft. All rights reserved. # Licensed under the MIT license. See LICENSE.md file in the project root for full license information. import time import json def speech_recognize_continuous_from_file(speech_config, filename): &quot;&quot;&quot;performs continuous speech recognition with input from an audio file&quot;&quot;&quot; speech_config = speech_config audio_config = speechsdk.audio.AudioConfig(filename=filename) outfilename = filename.replace(&#39;.wav&#39;, &#39;.json&#39;) outfile = open(outfilename, &#39;a&#39;) speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, language=&#39;ga-IE&#39;, audio_config=audio_config) done = False def stop_cb(evt): &quot;&quot;&quot;callback that signals to stop continuous recognition upon receiving an event `evt`&quot;&quot;&quot; print(&#39;CLOSING on {}&#39;.format(evt)) nonlocal done done = True def cancelled(evt): result = evt.result cancellation_details = result.cancellation_details print(&quot;Speech Recognition canceled: {}&quot;.format(cancellation_details.reason)) if cancellation_details.reason == speechsdk.CancellationReason.Error: print(&quot;Error details: {}&quot;.format(cancellation_details.error_details)) def recognised(evt): response = json.loads(evt.result.json) outfile.write(&#39;{} n&#39;.format(evt.result.json)) # Connect callbacks to the events fired by the speech recognizer speech_recognizer.recognizing.connect(lambda evt: print(&#39;RECOGNIZING: {}&#39;.format(evt))) speech_recognizer.recognized.connect(recognised) speech_recognizer.session_started.connect(lambda evt: print(&#39;SESSION STARTED: {}&#39;.format(evt))) speech_recognizer.session_stopped.connect(lambda evt: print(&#39;SESSION STOPPED {}&#39;.format(evt))) speech_recognizer.canceled.connect(cancelled) # stop continuous recognition on either session stopped or canceled events speech_recognizer.session_stopped.connect(stop_cb) speech_recognizer.canceled.connect(stop_cb) # Start continuous speech recognition speech_recognizer.start_continuous_recognition() while not done: time.sleep(.5) speech_recognizer.stop_continuous_recognition() outfile.close() . for i in &quot;345678&quot;: speech_recognize_continuous_from_file(speech_config, f&#39;MSF_chapter_{i}.wav&#39;) .",
            "url": "https://jimregan.github.io/notes/azure/irish/asr/2021/05/04/azure-asr-with-irish-part2.html",
            "relUrl": "/azure/irish/asr/2021/05/04/azure-asr-with-irish-part2.html",
            "date": " • May 4, 2021"
        }
        
    
  
    
        ,"post243": {
            "title": "Playing with auditok",
            "content": "%%capture !pip install auditok . %%capture !yes|apt install python3-pyaudio . %%capture !pip install youtube-dl . !youtube-dl https://www.youtube.com/watch?v=D44-x6PTd_Q . [youtube] D44-x6PTd_Q: Downloading webpage [youtube] D44-x6PTd_Q: Downloading MPD manifest WARNING: Requested formats are incompatible for merge and will be merged into mkv. [dashsegments] Total fragments: 22 [download] Destination: Sraith Pictiúr - An Ghaeilge Seoid luachmhar-D44-x6PTd_Q.f247.webm [download] 22.7% of ~12.60MiB at 5.49MiB/s ETA 00:13[download] Got server HTTP error: HTTP Error 404: Not Found. Retrying fragment 6 (attempt 1 of 10)... [download] 100% of 15.12MiB in 00:18 [download] Destination: Sraith Pictiúr - An Ghaeilge Seoid luachmhar-D44-x6PTd_Q.f140.m4a [download] 100% of 1.73MiB in 00:00 [ffmpeg] Merging formats into &#34;Sraith Pictiúr - An Ghaeilge Seoid luachmhar-D44-x6PTd_Q.mkv&#34; Deleting original file Sraith Pictiúr - An Ghaeilge Seoid luachmhar-D44-x6PTd_Q.f247.webm (pass -k to keep) Deleting original file Sraith Pictiúr - An Ghaeilge Seoid luachmhar-D44-x6PTd_Q.f140.m4a (pass -k to keep) . import auditok input = &#39;Sraith Pictiúr - An Ghaeilge Seoid luachmhar-D44-x6PTd_Q.mkv&#39; audio_regions = auditok.split( input, min_dur=1, max_dur=10, max_silence=0.9, energy_threshold=20 ) for i, r in enumerate(audio_regions): print(&quot;Region {i}: {r.meta.start:.3f}s -- {r.meta.end:.3f}s&quot;.format(i=i, r=r)) . Region 0: 0.300s -- 6.550s Region 1: 7.450s -- 12.950s Region 2: 13.150s -- 15.700s Region 3: 15.900s -- 19.200s Region 4: 19.350s -- 29.350s Region 5: 29.700s -- 34.200s Region 6: 34.300s -- 38.600s Region 7: 39.000s -- 43.650s Region 8: 43.700s -- 46.550s Region 9: 46.750s -- 49.500s Region 10: 49.550s -- 52.950s Region 11: 53.000s -- 56.050s Region 12: 56.250s -- 59.500s Region 13: 59.700s -- 62.550s Region 14: 63.150s -- 69.600s Region 15: 69.650s -- 73.100s Region 16: 73.400s -- 77.450s Region 17: 77.800s -- 81.150s Region 18: 81.350s -- 89.100s Region 19: 89.500s -- 92.750s Region 20: 92.950s -- 96.250s Region 21: 96.500s -- 99.600s Region 22: 99.850s -- 104.350s Region 23: 104.500s -- 108.050s . regs = auditok.load(input) regs.split_and_plot( min_dur=1, max_dur=10, max_silence=0.9, energy_threshold=20, dpi=600 ) . [AudioRegion(duration=6.250, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=5.500, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=2.550, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.300, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=10.000, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=4.500, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=4.300, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=4.650, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=2.850, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=2.750, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.400, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.050, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.250, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=2.850, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=6.450, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.450, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=4.050, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.350, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=7.750, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.250, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.300, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.100, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=4.500, sampling_rate=44100, sample_width=2, channels=2), AudioRegion(duration=3.550, sampling_rate=44100, sample_width=2, channels=2)] .",
            "url": "https://jimregan.github.io/notes/auditok/2021/05/03/playing-with-auditok.html",
            "relUrl": "/auditok/2021/05/03/playing-with-auditok.html",
            "date": " • May 3, 2021"
        }
        
    
  
    
        ,"post244": {
            "title": "rclone and Sharepoint",
            "content": "%%capture !curl https://rclone.org/install.sh |bash . curl_out=!curl --cookie -i -L &#39;https://uniwersytetlodzki-my.sharepoint.com/:f:/g/personal/pelcra_uni_lodz_pl/EpPehikqGqZJltrAKlVp3k0BOeyzEgBBO_ZwmFC9WaLbWw&#39;|grep &#39;var _spPageContextInfo=&#39; . import json for s in curl_out: if &#39;var _spPageContextInfo=&#39; in s: start = s[s.index(&#39;access_token=&#39;)+len(&#39;access_token=&#39;):] access_token = start[:start.index(&#39;&quot;&#39;)] . _URL=&#39;https://uniwersytetlodzki-my.sharepoint.com/personal/pelcra_uni_lodz_pl/Documents&#39; . _COOKIE=&#39;FedAuth=77u/PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0idXRmLTgiPz48U1A+VjksMGguZnxtZW1iZXJzaGlwfHVybiUzYXNwbyUzYWFub24jNTZiNDAwY2Y5OWYxMjQwYTkyYjRhNWU3ZTkwYjJlNWVlY2Q3MzYyMGJlNmNiMjI4OTllNjhiMWU4Zjc2Nzk4ZCwwIy5mfG1lbWJlcnNoaXB8dXJuJTNhc3BvJTNhYW5vbiM1NmI0MDBjZjk5ZjEyNDBhOTJiNGE1ZTdlOTBiMmU1ZWVjZDczNjIwYmU2Y2IyMjg5OWU2OGIxZThmNzY3OThkLDEzMjY0NDY0NTU3MDAwMDAwMCwwLDEzMjY0NTUwNjU4MDQxOTgzNCwwLjAuMC4wLDI1OCxkZGIyZmM4NS0xYzE4LTRjMmItOTkyYS1lODQxMWJmZmMwZTcsLCw0ODEyYzQ5Zi02MGY0LTIwMDAtZTE0Mi02YzYwM2MyZGE3YzQsNDgxMmM0OWYtNjBmNC0yMDAwLWUxNDItNmM2MDNjMmRhN2M0LDVrVml3YU9rSGtxaWZjbzVzKytYSlEsMCwwLDAsLCwsMjY1MDQ2Nzc0Mzk5OTk5OTk5OSwwLCwsLCwsc0JtSkR4RTZJd3I5VmsraGJHclFSUDhSNzJIUXh2UWlqNDZ6WnFPdXArUVZnVWhkNkVmQWljNUZ1YUYwMEdGUjRFRnhMRUJsRlNTZ3lnNElkTUdSSnpwbGZUT0JGSkw0Tyt4cjRHS01WdjZ1YnhJWTFzMkFWYWpySVgzbXRGWm9zOHkrYjk0SnhPZElibVVxaUJWZzVaZHVTcWxSMnlFdzc0Y3BueERjVHdQU3FVYTk3VG5qOTRWM0s4YkdkUnA1QVVGSGtacjg2Q0YvZVY5R2Y1OGlTd1ZKUWx2VEc5OVByaU9JWE94Umc4N2FZc2ZFTWZzcG9JL05tYlU0cm9sQ1ZnVzVVNUl3NXJlY29PNzkxUXZZbDBlUlZNcXBVSHI0UEdBOVhLaEJVb3I5YTJpMFpQZEhZRE9SQnlVcWtHRDQvb0NXY21JamdGQVhNM2RtTFgwWGJBPT08L1NQPg==; path=/; SameSite=None; secure; HttpOnly&#39; . !rclone config create pelcra webdav url {_URL} webdav-vendor other access_token {access_token} #cookie &quot;{_COOKIE}&quot; . Remote config -- [pelcra] type = webdav url = https://uniwersytetlodzki-my.sharepoint.com/personal/pelcra_uni_lodz_pl/Documents webdav-vendor = other access_token = eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJhdWQiOiIwMDAwMDAwMy0wMDAwLTBmZjEtY2UwMC0wMDAwMDAwMDAwMDAvdW5pd2Vyc3l0ZXRsb2R6a2ktbXkuc2hhcmVwb2ludC5jb21ANjM0NDFhZWYtZGEwZS00Mzk3LWJiN2UtZjlkNDcwNWU5NjNiIiwiaXNzIjoiMDAwMDAwMDMtMDAwMC0wZmYxLWNlMDAtMDAwMDAwMDAwMDAwIiwibmJmIjoxNjIwMjU0MjMwLCJleHAiOjE2MjAyNzU4MzAsImlzbG9vcGJhY2siOiJUcnVlIiwibmFtZWlkIjoiMCMuZnxtZW1iZXJzaGlwfHVybiUzYXNwbyUzYWFub24jNTZiNDAwY2Y5OWYxMjQwYTkyYjRhNWU3ZTkwYjJlNWVlY2Q3MzYyMGJlNmNiMjI4OTllNjhiMWU4Zjc2Nzk4ZCIsIm5paSI6Im1pY3Jvc29mdC5zaGFyZXBvaW50IiwiaXN1c2VyIjoidHJ1ZSIsImNhY2hla2V5IjoiMGguZnxtZW1iZXJzaGlwfHVybiUzYXNwbyUzYWFub24jNTZiNDAwY2Y5OWYxMjQwYTkyYjRhNWU3ZTkwYjJlNWVlY2Q3MzYyMGJlNmNiMjI4OTllNjhiMWU4Zjc2Nzk4ZCIsInR0IjoiMCIsInVzZVBlcnNpc3RlbnRDb29raWUiOiIyIn0.A50UZ17CCLwueDg9UAJx4NY4FM-3p_vRN59OrxDxFz4u0026prooftoken=eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIsIng1dCI6IkcydDJKYzlkMVZ6RkdjdzZUZy02YUhZVXk2VSJ9.eyJhdWQiOiIwMDAwMDAwMy0wMDAwLTBmZjEtY2UwMC0wMDAwMDAwMDAwMDBAKiIsImlzcyI6IjAwMDAwMDAzLTAwMDAtMGZmMS1jZTAwLTAwMDAwMDAwMDAwMEAqIiwibmJmIjoiMTYyMDI0NjgzMCIsImV4cCI6IjE2MjA4NTE2MzAiLCJwcmYiOiJLMUs2Z21oMFNpZDBaL2E0SjJReXpDSVJLMXBTWGlyOXAzcitoM1UwTjZRNWo2UEc2REZPaG5OU2dPU3FwZDRXK1ZpenppSTlCcWc2d2kvSE83Zk9scGhmaE9pU3NLN1p6clFGMUxlOFk3dnJJejdNb1RLQ3Njbjh5cUhvSklVbjFmVFlIcGltb1E0NnJQdVlJV0pJK3UwOXVHTVBpSS9ZcWlCYzhHd0VBTit0bnoyZ2tIcXM3OGhXbGo2Y3dBNzNTckJwTHBTdG53QzZaRXRoUVV1N3l6eGhuRVlXdkNhNUFPdVlWaXRiMndTZWpib0g5QlBCc0puemVEL1ZMUDFqZXh2Qk9DRVpYN25XRjU4SC9Sck1tdWdZb2ZxMGQzZnhlTG56d0RJbDFEYjdqcFc3L20vaURJV1FQRUZScmFmUW1pbFJmYjRSTFUxVFFGWWptVHJmU1E9PSIsImlzdXNlciI6InRydWUifQ.o1x0-K2UNkorQjKyT5o0HXJiOJxHP3vlYscEzjKN2KQHzp95ja3ml5yzqPtSXdCwYxjCdJjWgtAvS5YlQzLBX2Eac8odydBxDa8EHyuVxIa6T-n7dD4R1WHVebyXt62shIP61s_TeiJkwiD0Sl_nPIzqY9zkrKEg_cSe0isEi0mCv6ynYXCWetYpaMdv4ifaGAl5aK7v6zxNKzwVoxBUfEIcJLV8MjdeV1i1Puuinpj69GUispryx7ruDs0g5CLVjOeAk0wwaoTeRzL4y04EKTKdt4UsdeAAXzE1Rby4na3xqDkeewPUCYxZHQL89tGOUcmiwjJKeB7Fos39XIhrRg -- . !rclone ls --use-cookies -vv &#39;pelcra:SHARE/CLARIN/SPOKES/PELCRA_EMO&#39; --dump bodies . 2021/05/05 22:54:48 DEBUG : Using config file from &#34;/root/.config/rclone/rclone.conf&#34; 2021/05/05 22:54:48 DEBUG : rclone: Version &#34;v1.55.1&#34; starting with parameters [&#34;rclone&#34; &#34;ls&#34; &#34;--use-cookies&#34; &#34;-vv&#34; &#34;pelcra:SHARE/CLARIN/SPOKES/PELCRA_EMO&#34; &#34;--dump&#34; &#34;bodies&#34;] 2021/05/05 22:54:48 DEBUG : Creating backend with remote &#34;pelcra:SHARE/CLARIN/SPOKES/PELCRA_EMO&#34; 2021/05/05 22:54:48 DEBUG : You have specified to dump information. Please be noted that the Accept-Encoding as shown may not be correct in the request and the response may not show Content-Encoding if the go standard libraries auto gzip encoding was in effect. In this case the body of the request will be gunzipped before showing it. 2021/05/05 22:54:48 DEBUG : &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 2021/05/05 22:54:48 DEBUG : HTTP REQUEST (req 0xc000596a00) 2021/05/05 22:54:48 DEBUG : PROPFIND /personal/pelcra_uni_lodz_pl/Documents/SHARE/CLARIN/SPOKES/PELCRA_EMO HTTP/1.1 Host: uniwersytetlodzki-my.sharepoint.com User-Agent: rclone/v1.55.1 Depth: 1 Referer: https://uniwersytetlodzki-my.sharepoint.com/personal/pelcra_uni_lodz_pl/Documents/ Accept-Encoding: gzip 2021/05/05 22:54:48 DEBUG : &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; 2021/05/05 22:54:49 DEBUG : &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; 2021/05/05 22:54:49 DEBUG : HTTP RESPONSE (req 0xc000596a00) 2021/05/05 22:54:49 DEBUG : HTTP/2.0 403 Forbidden Content-Length: 13 Content-Type: text/plain; charset=utf-8 Date: Wed, 05 May 2021 22:54:48 GMT Microsoftsharepointteamservices: 16.0.0.21221 Ms-Cv: n8UOqHwAACDhQmsT9SmG6Q.0 P3p: CP=&#34;ALL IND DSP COR ADM CONo CUR CUSo IVAo IVDo PSA PSD TAI TELo OUR SAMo CNT COM INT NAV ONL PHY PRE PUR UNI&#34; Request-Id: a80ec59f-007c-2000-e142-6b13f52986e9 Sprequestguid: a80ec59f-007c-2000-e142-6b13f52986e9 X-Content-Type-Options: nosniff X-Forms_based_auth_required: https://uniwersytetlodzki-my.sharepoint.com/_forms/default.aspx?ReturnUrl=/_layouts/15/error.aspx&amp;Source=%2fpersonal%2fpelcra_uni_lodz_pl%2fDocuments%2fSHARE%2fCLARIN%2fSPOKES%2fPELCRA_EMO X-Forms_based_auth_return_url: https://uniwersytetlodzki-my.sharepoint.com/_layouts/15/error.aspx X-Idcrl_auth_params_v1: IDCRL Type=&#34;BPOSIDCRL&#34;, EndPoint=&#34;/personal/pelcra_uni_lodz_pl/_vti_bin/idcrl.svc/&#34;, RootDomain=&#34;sharepoint.com&#34;, Policy=&#34;MBI&#34; X-Ms-Invokeapp: 1; RequireReadOnly X-Msdavext_error: 917656; Access+denied.+Before+opening+files+in+this+location%2c+you+must+first+browse+to+the+web+site+and+select+the+option+to+login+automatically. X-Msedge-Ref: Ref A: 8A3CC80AA56A42C4A2112F4377B61AA6 Ref B: HK2EDGE0921 Ref C: 2021-05-05T22:54:49Z X-Powered-By: ASP.NET X-Sharepointhealthscore: 3 403 FORBIDDEN 2021/05/05 22:54:49 DEBUG : &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; 2021/05/05 22:54:49 Failed to create file system for &#34;pelcra:SHARE/CLARIN/SPOKES/PELCRA_EMO&#34;: read metadata failed: 403 FORBIDDEN: 403 Forbidden . !rclone ls :http: --http-url &#39;https://uniwersytetlodzki-my.sharepoint.com/:f:/g/personal/pelcra_uni_lodz_pl/EpPehikqGqZJltrAKlVp3k0BOeyzEgBBO_ZwmFC9WaLbWw&#39; --use-cookies -vv . !rclone config dump .",
            "url": "https://jimregan.github.io/notes/rclone/sharepoint/2021/05/02/rclone-and-sharepoint.html",
            "relUrl": "/rclone/sharepoint/2021/05/02/rclone-and-sharepoint.html",
            "date": " • May 2, 2021"
        }
        
    
  
    
        ,"post245": {
            "title": "Ruby kernel on Colab",
            "content": "!apt-get install ruby-dev !sudo apt install libtool libffi-dev ruby ruby-dev make !sudo apt install libzmq3-dev libczmq-dev !gem install ffi-rzmq !gem install specific_install !gem specific_install https://github.com/SciRuby/iruby !iruby register . !jupyter kernelspec list . Available kernels: ruby /root/.local/share/jupyter/kernels/ruby ir /usr/local/share/jupyter/kernels/ir python2 /usr/local/share/jupyter/kernels/python2 python3 /usr/local/share/jupyter/kernels/python3 .",
            "url": "https://jimregan.github.io/notes/colab/misc/2021/05/01/colab-ruby-kernel.html",
            "relUrl": "/colab/misc/2021/05/01/colab-ruby-kernel.html",
            "date": " • May 1, 2021"
        }
        
    
  
    
        ,"post246": {
            "title": "Two speechbrain speech enhancement models",
            "content": "The Colab notebook (with outputs) is here; the models are on the Huggingface hub: mtl-mimic-voicebank and speechbrain/metricgan-plus-voicebank . The first twenty seconds of mtl-mimic-voicebank aren&#39;t great (but they are quieter in the recording); the rest is fantastic. The output from metricgan-plus-voicebank is bad from start to finish. . %%capture !pip install torchaudio speechbrain . !wget http://assets.doegen.ie/sound/MP3_versions/aud_Ul1-LA_1202d1u1.mp3 . import IPython IPython.display.Audio(&#39;aud_Ul1-LA_1202d1u1.mp3&#39;) . import torchaudio from speechbrain.pretrained import SpectralMaskEnhancement enhance_model = SpectralMaskEnhancement.from_hparams( source=&quot;speechbrain/mtl-mimic-voicebank&quot;, savedir=&quot;pretrained_models/mtl-mimic-voicebank&quot;, ) enhanced = enhance_model.enhance_file(&quot;aud_Ul1-LA_1202d1u1.mp3&quot;) # Saving enhanced signal on disk torchaudio.save(&#39;enhanced.wav&#39;, enhanced.unsqueeze(0), 16000) . IPython.display.Audio(&#39;enhanced.wav&#39;) . import torch enhance_model = SpectralMaskEnhancement.from_hparams( source=&quot;speechbrain/metricgan-plus-voicebank&quot;, savedir=&quot;pretrained_models/metricgan-plus-voicebank&quot;, ) noisy = enhance_model.load_audio(&quot;aud_Ul1-LA_1202d1u1.mp3&quot;).unsqueeze(0) # Add relative length tensor enhanced = enhance_model.enhance_batch(noisy, lengths=torch.tensor([1.])) # Saving enhanced signal on disk torchaudio.save(&#39;enhanced2.wav&#39;, enhanced, 16000) . IPython.display.Audio(&#39;enhanced2.wav&#39;) .",
            "url": "https://jimregan.github.io/notes/speechbrain/speech%20enhancement/2021/04/30/speechbrain_speech_enhancements.html",
            "relUrl": "/speechbrain/speech%20enhancement/2021/04/30/speechbrain_speech_enhancements.html",
            "date": " • Apr 30, 2021"
        }
        
    
  
    
        ,"post247": {
            "title": "Polish phonetic comparison",
            "content": "from difflib import SequenceMatcher import icu . plipa = icu.Transliterator.createInstance(&#39;pl-pl_FONIPA&#39;) . The errors in E2E models are quite often phonetic confusions, so we do the opposite of traditional ASR and generate the phonetic representation from the output as a basis for comparison. . def phonetic_check(word1, word2, ignore_spaces=False): &quot;&quot;&quot;Uses ICU&#39;s IPA transliteration to check if words are the same&quot;&quot;&quot; tl1 = plipa.transliterate(word1) if not ignore_spaces else plipa.transliterate(word1.replace(&#39; &#39;, &#39;&#39;)) tl2 = plipa.transliterate(word2) if not ignore_spaces else plipa.transliterate(word2.replace(&#39; &#39;, &#39;&#39;)) return tl1 == tl2 . phonetic_check(&quot;jórz&quot;, &quot;jusz&quot;, False) . True . The Polish y is phonetically a raised schwa; like the schwa in English, it&#39;s often deleted in fast speech. This function returns true if the only differences between the first word and the second is are deletions of y, except at the end of the word (which is typically the plural ending). . def no_igrek(word1, word2): &quot;&quot;&quot;Checks if a word-internal y has been deleted&quot;&quot;&quot; sm = SequenceMatcher(None, word1, word2) for oc in sm.get_opcodes(): if oc[0] == &#39;equal&#39;: continue elif oc[0] == &#39;delete&#39; and word1[oc[1]:oc[2]] != &#39;y&#39;: return False elif oc[0] == &#39;delete&#39; and word1[oc[1]:oc[2]] == &#39;y&#39; and oc[2] == len(word1): return False elif oc[0] == &#39;insert&#39; or oc[0] == &#39;replace&#39;: return False return True . no_igrek(&#39;uniwersytet&#39;, &#39;uniwerstet&#39;) . True . no_igrek(&#39;uniwerstety&#39;, &#39;uniwerstet&#39;) . False . phonetic_alternatives = [ [&#39;u&#39;, &#39;ó&#39;], [&#39;rz&#39;, &#39;ż&#39;] ] def reverse_alts(phonlist): return [ [i[1], i[0]] for i in phonlist ] . sm = SequenceMatcher(None, &quot;już&quot;, &quot;jurz&quot;) for oc in sm.get_opcodes(): print(oc) . (&#39;equal&#39;, 0, 2, 0, 2) (&#39;replace&#39;, 2, 3, 2, 4) . Reads a CTM-like file, returning a list of lists containing the filename, start time, end time, and word. . def read_ctmish(filename): output = [] with open(filename, &#39;r&#39;) as f: for line in f.readlines(): pieces = line.strip().split(&#39; &#39;) if len(pieces) &lt;= 4: continue for piece in pieces[4:]: output.append([pieces[0], pieces[2], pieces[3], piece]) return output . Returns the contents of a plain text file as a list of lists containing the line number and the word, for use in locating mismatches . def read_text(filename): output = [] counter = 0 with open(filename, &#39;r&#39;) as f: for line in f.readlines(): counter += 1 for word in line.strip().split(&#39; &#39;) output.append([counter, word]) return output . ctmish = read_ctmish(&quot;/mnt/c/Users/Jim O &#39;Regan/git/notes/PlgU9JyTLPE.ctm&quot;) . rec_words = [i[3] for i in ctmish] .",
            "url": "https://jimregan.github.io/notes/asr/polish/phonetic/todo/2021/04/29/phonetic-comparison.html",
            "relUrl": "/asr/polish/phonetic/todo/2021/04/29/phonetic-comparison.html",
            "date": " • Apr 29, 2021"
        }
        
    
  
    
        ,"post248": {
            "title": "Doegen recordings scraper",
            "content": "import requests from bs4 import BeautifulSoup import json . _BASE = &#39;https://doegen.ie/counties&#39; def do_get(url): r = requests.get(url, headers = {&#39;User-agent&#39;: &#39;Mozilla/5.0&#39;}) if r.status_code != 200: raise Exception(&quot;Failed to open landing page&quot;) return r.content . soup = BeautifulSoup(do_get(_BASE), &#39;html.parser&#39;) . counties = soup.find(&#39;ul&#39;, {&#39;class&#39;: &#39;vocabindex&#39;}).find_all(&#39;li&#39;) . pages = [] for county in counties: item = {} anchor = county.find(&#39;a&#39;) href = anchor[&#39;href&#39;] item[&#39;link&#39;] = f&#39;https://doegen.ie{href}&#39; if anchor.find(&#39;span&#39;).text.strip() != &#39;(0)&#39;: item[&#39;county&#39;] = anchor.text.split()[1] pages.append(item) . def proc_page(url): result = {} html = do_get(url) soup = BeautifulSoup(html, &#39;html.parser&#39;) main = soup.find(&#39;div&#39;, {&#39;id&#39;: &#39;main&#39;}) content = main.find(&#39;div&#39;, {&#39;class&#39;: &#39;content&#39;}) source = content.find(&#39;source&#39;) if source == None: return {} result[&#39;mp3&#39;] = source[&#39;src&#39;] result[&#39;transcript&#39;] = content.find(&#39;div&#39;, id=&#39;transcript&#39;).text if content.find(&#39;div&#39;, id=&#39;translation&#39;) != None: result[&#39;translation&#39;] = content.find(&#39;div&#39;, id=&#39;translation&#39;).text if content.find(&#39;div&#39;, id=&#39;footnote&#39;) != None: result[&#39;footnote&#39;] = content.find(&#39;div&#39;, id=&#39;footnote&#39;).text result[&#39;recording_metadata&#39;] = content.find(&#39;div&#39;, id=&#39;recording_metadata&#39;).text return result . def proc_county(item): content = do_get(item[&#39;link&#39;]) soup = BeautifulSoup(content, &#39;html.parser&#39;) main = soup.find(&#39;div&#39;, id=&#39;main&#39;) nodes = main.find_all(&#39;div&#39;, {&#39;class&#39;: &#39;node&#39;}) stories = [] for node in nodes: story = {} anchor = node.find(&#39;a&#39;) story[&#39;link&#39;] = f&quot;https://doegen.ie{anchor[&#39;href&#39;]}&quot; story[&#39;content&#39;] = proc_page(story[&#39;link&#39;]) if story[&#39;content&#39;] == {}: continue tags = node.find(&#39;div&#39;, {&#39;class&#39;: &#39;terms&#39;}).find_all(&#39;a&#39;, rel=&#39;tag&#39;) text = anchor.text if &#39; - &#39; in text: tmp = text.split(&#39; - &#39;) if len(tmp) == 2: story[&#39;title&#39;] = tmp[0] story[&#39;speaker_name&#39;] = tmp[1] name_parts = tmp[1].split(&#39; &#39;) first = name_parts[0] for tag in tags: if first in tag.text: story[&#39;speaker_url&#39;] = f&quot;https://doegen.ie{tag[&#39;href&#39;]}&quot; else: story[&#39;raw&#39;] = text else: story[&#39;raw&#39;] = text stories.append(story) item[&#39;stories&#39;] = stories . for page in pages: proc_county(page) . with open(&#39;doegen.json&#39;, &#39;w&#39;) as f: json.dump(pages, f) .",
            "url": "https://jimregan.github.io/notes/irish/scraper/2021/04/29/doegen-scraper.html",
            "relUrl": "/irish/scraper/2021/04/29/doegen-scraper.html",
            "date": " • Apr 29, 2021"
        }
        
    
  
    
        ,"post249": {
            "title": "Praat via parselmouth",
            "content": "import numpy as np import matplotlib.pyplot as plt import seaborn as sns import requests import parselmouth import tempfile . sns.set() # Use seaborn&#39;s default style to make attractive graphs plt.rcParams[&#39;figure.dpi&#39;] = 300 # Show nicely large images in this notebook . def load_from_teanglann(word, dialect): valid_dialects = [&#39;C&#39;, &#39;M&#39;, &#39;U&#39;] if dialect not in valid_dialects and dialect.upper()[0] not in valid_dialects: raise Exception(f&#39;Dialect must be one of &quot;C&quot;, &quot;M&quot; or &quot;U&quot;; got &quot;{dialect}&quot;&#39;) url = f&#39;https://www.teanglann.ie/Can{dialect}/{word}.mp3&#39; r = requests.get(url) if r.status_code != 200: raise Exception(f&#39;Failed to fetch {url}&#39;) file = tempfile.NamedTemporaryFile(mode=&#39;w+b&#39;) file.write(r.content) return file . def draw_spectrogram(spectrogram, dynamic_range=70): X, Y = spectrogram.x_grid(), spectrogram.y_grid() sg_db = 10 * np.log10(spectrogram.values) plt.pcolormesh(X, Y, sg_db, vmin=sg_db.max() - dynamic_range, cmap=&#39;afmhot&#39;) plt.ylim([spectrogram.ymin, spectrogram.ymax]) plt.xlabel(&quot;time [s]&quot;) plt.ylabel(&quot;frequency [Hz]&quot;) def draw_intensity(intensity): plt.plot(intensity.xs(), intensity.values.T, linewidth=3, color=&#39;w&#39;) plt.plot(intensity.xs(), intensity.values.T, linewidth=1) plt.grid(False) plt.ylim(0) plt.ylabel(&quot;intensity [dB]&quot;) . file=load_from_teanglann(&#39;athdhreas&#39;, &#39;U&#39;) snd = parselmouth.Sound(file_path=file.name) intensity = snd.to_intensity() spectrogram = snd.to_spectrogram() plt.figure() draw_spectrogram(spectrogram) plt.twinx() #draw_intensity(intensity) plt.xlim([snd.xmin, snd.xmax]) plt.show() . def draw_pitch(pitch): # Extract selected pitch contour, and # replace unvoiced samples by NaN to not plot pitch_values = pitch.selected_array[&#39;frequency&#39;] pitch_values[pitch_values==0] = np.nan plt.plot(pitch.xs(), pitch_values, &#39;o&#39;, markersize=5, color=&#39;w&#39;) plt.plot(pitch.xs(), pitch_values, &#39;o&#39;, markersize=2) plt.grid(False) plt.ylim(0, pitch.ceiling) plt.ylabel(&quot;fundamental frequency [Hz]&quot;) pitch = snd.to_pitch() # If desired, pre-emphasize the sound fragment before calculating the spectrogram pre_emphasized_snd = snd.copy() pre_emphasized_snd.pre_emphasize() spectrogram = pre_emphasized_snd.to_spectrogram(window_length=0.03, maximum_frequency=8000) plt.figure() draw_spectrogram(spectrogram) plt.twinx() #draw_pitch(pitch) plt.xlim([snd.xmin, snd.xmax]) plt.show() .",
            "url": "https://jimregan.github.io/notes/praat/parselmouth/2021/04/24/parselmouth.html",
            "relUrl": "/praat/parselmouth/2021/04/24/parselmouth.html",
            "date": " • Apr 24, 2021"
        }
        
    
  
    
        ,"post250": {
            "title": "BuNaMo to json",
            "content": "from lxml import etree . class BuNaMoWrongDocument(Exception): &quot;&quot;&quot;Exception raised for wrong document type&quot;&quot;&quot; def __init__(self, expected, got): self.expected = expected self.got = got self.message = f&quot;Expected root element &lt;{self.expected}&gt; but got &lt;{self.got}&gt;&quot; super().__init__(self.message) . Various functions to read one of the types of XML file. The open parts of speech (noun, adjective, verb) can have multiple forms, so those functions return attributes (a dictionary) and forms (a list of dictionaries) separately. . Close parts of speech (possessives and prepositions) are simpler, and most of the attributes are needless, so they return a simple dictionary containing the forms. . def read_adjective(file): tree = etree.parse(file) root = tree.getroot() valid_tags = [&#39;sgNom&#39;, &#39;sgGenMasc&#39;, &#39;sgGenFem&#39;, &#39;plNom&#39;, &#39;graded&#39;, &#39;abstractNoun&#39;, &#39;sgVocMasc&#39;, &#39;sgVocFem&#39;] attribs = {} forms = [] if root.tag != &#39;adjective&#39;: raise BuNaMoWrongDocument(&#39;adjective&#39;, root.tag) attribs[&#39;default&#39;] = root.get(&#39;default&#39;) attribs[&#39;declension&#39;] = root.get(&#39;declension&#39;) attribs[&#39;disambig&#39;] = root.get(&#39;disambig&#39;) attribs[&#39;isPre&#39;] = root.get(&#39;isPre&#39;) for child in root: if child.tag not in valid_tags: raise Exception(&#39;Unexpected tag &#39; + child.tag) tmp = {} tmp[&#39;props&#39;] = child.tag tmp[&#39;form&#39;] = child.get(&#39;default&#39;) forms.append(tmp) return attribs, forms def read_noun(file): tree = etree.parse(file) root = tree.getroot() valid_tags = [&#39;sgNom&#39;, &#39;sgGen&#39;, &#39;plNom&#39;, &#39;plGen&#39;, &#39;count&#39;, &#39;sgDat&#39;] attribs = {} forms = [] if root.tag != &#39;noun&#39;: raise BuNaMoWrongDocument(&#39;noun&#39;, root.tag) attribs[&#39;default&#39;] = root.get(&#39;default&#39;) attribs[&#39;declension&#39;] = root.get(&#39;declension&#39;) attribs[&#39;disambig&#39;] = root.get(&#39;disambig&#39;) attribs[&#39;isProper&#39;] = root.get(&#39;isProper&#39;) attribs[&#39;isDefinite&#39;] = root.get(&#39;isDefinite&#39;) attribs[&#39;allowArticledGenitive&#39;] = root.get(&#39;allowArticledGenitive&#39;) for child in root: if child.tag not in valid_tags: raise Exception(&#39;Unexpected tag &#39; + child.tag) tmp = {} tmp[&#39;props&#39;] = child.tag tmp[&#39;form&#39;] = child.get(&#39;default&#39;) tmp[&#39;gender&#39;] = child.get(&#39;gender&#39;) tmp[&#39;strength&#39;] = child.get(&#39;strength&#39;) forms.append(tmp) return attribs, forms def read_verb(file): tree = etree.parse(file) root = tree.getroot() valid_tags = [&#39;verbalNoun&#39;, &#39;verbalAdjective&#39;, &#39;tenseForm&#39;, &#39;moodForm&#39;] attribs = {} forms = [] if root.tag != &#39;verb&#39;: raise BuNaMoWrongDocument(&#39;verb&#39;, root.tag) attribs[&#39;default&#39;] = root.get(&#39;default&#39;) attribs[&#39;disambig&#39;] = root.get(&#39;disambig&#39;) for child in root: if child.tag not in valid_tags: raise Exception(&#39;Unexpected tag &#39; + child.tag) tmp = {} tmp[&#39;props&#39;] = child.tag tmp[&#39;form&#39;] = child.get(&#39;default&#39;) tmp[&#39;tense&#39;] = child.get(&#39;tense&#39;) tmp[&#39;mood&#39;] = child.get(&#39;mood&#39;) tmp[&#39;dependency&#39;] = child.get(&#39;dependency&#39;) tmp[&#39;person&#39;] = child.get(&#39;person&#39;) forms.append(tmp) return attribs, forms def read_nounphrase(file): tree = etree.parse(file) root = tree.getroot() valid_tags = [&#39;sgNom&#39;, &#39;sgGen&#39;, &#39;plNom&#39;, &#39;plGen&#39;, &#39;sgNomArt&#39;, &#39;sgGenArt&#39;, &#39;plNomArt&#39;, &#39;plGenArt&#39;] attribs = {} forms = [] if root.tag != &#39;nounPhrase&#39;: raise BuNaMoWrongDocument(&#39;nounPhrase&#39;, root.tag) attribs[&#39;default&#39;] = root.get(&#39;default&#39;) attribs[&#39;declension&#39;] = root.get(&#39;declension&#39;) attribs[&#39;disambig&#39;] = root.get(&#39;disambig&#39;) attribs[&#39;isProper&#39;] = root.get(&#39;isProper&#39;) attribs[&#39;isDefinite&#39;] = root.get(&#39;isDefinite&#39;) attribs[&#39;allowArticledGenitive&#39;] = root.get(&#39;allowArticledGenitive&#39;) attribs[&#39;forceNominative&#39;] = root.get(&#39;forceNominative&#39;) for child in root: if child.tag not in valid_tags: raise Exception(&#39;Unexpected tag &#39; + child.tag) tmp = {} tmp[&#39;props&#39;] = child.tag tmp[&#39;form&#39;] = child.get(&#39;default&#39;) tmp[&#39;gender&#39;] = child.get(&#39;gender&#39;) tmp[&#39;strength&#39;] = child.get(&#39;strength&#39;) forms.append(tmp) return attribs, forms def read_possessive(file): tree = etree.parse(file) root = tree.getroot() valid_tags = [&#39;full&#39;, &#39;apos&#39;] attribs = {} forms = [] if root.tag != &#39;possessive&#39;: raise BuNaMoWrongDocument(&#39;possessive&#39;, root.tag) attribs[&#39;default&#39;] = root.get(&#39;default&#39;) attribs[&#39;disambig&#39;] = root.get(&#39;disambig&#39;) attribs[&#39;mutation&#39;] = root.get(&#39;mutation&#39;) for child in root: if child.tag not in valid_tags: raise Exception(&#39;Unexpected tag &#39; + child.tag) if child.tag == &#39;apos&#39;: attribs[&#39;apos&#39;] = child.get(&#39;default&#39;) return attribs def read_preposition(file): tree = etree.parse(file) root = tree.getroot() valid_tags = [&#39;sg1&#39;, &#39;sg2&#39;, &#39;sg3Masc&#39;, &#39;sg3Fem&#39;, &#39;pl1&#39;, &#39;pl2&#39;, &#39;pl3&#39;] attribs = {} forms = [] if root.tag != &#39;preposition&#39;: raise BuNaMoWrongDocument(&#39;preposition&#39;, root.tag) attribs[&#39;default&#39;] = root.get(&#39;default&#39;) for child in root: if child.tag not in valid_tags: raise Exception(&#39;Unexpected tag &#39; + child.tag) attribs[child.tag] = child.get(&#39;default&#39;) return attribs . import glob import json adjectives = {} for x in glob.glob(&#39;../input/bunamo-bunachar-naisiunta-moirfeolaiochta/adjective/*.xml&#39;): fname = x.split(&#39;/&#39;)[-1].replace(&#39;.xml&#39;, &#39;&#39;) attribs, forms = read_adjective(x) tmp = {} tmp[&#39;attributes&#39;] = attribs tmp[&#39;forms&#39;] = forms adjectives[fname] = tmp word = attribs[&#39;default&#39;] with open(&#39;adjectives.json&#39;, &#39;w&#39;) as outfile: json.dump(adjectives, outfile) . nouns = {} for x in glob.glob(&#39;../input/bunamo-bunachar-naisiunta-moirfeolaiochta/noun/*.xml&#39;): fname = x.split(&#39;/&#39;)[-1].replace(&#39;.xml&#39;, &#39;&#39;) attribs, forms = read_noun(x) tmp = {} tmp[&#39;attributes&#39;] = attribs tmp[&#39;forms&#39;] = forms nouns[fname] = tmp word = attribs[&#39;default&#39;] with open(&#39;nouns.json&#39;, &#39;w&#39;) as outfile: json.dump(nouns, outfile) . nounphrases = {} for x in glob.glob(&#39;../input/bunamo-bunachar-naisiunta-moirfeolaiochta/nounPhrase/*.xml&#39;): fname = x.split(&#39;/&#39;)[-1].replace(&#39;.xml&#39;, &#39;&#39;) attribs, forms = read_nounphrase(x) tmp = {} tmp[&#39;attributes&#39;] = attribs tmp[&#39;forms&#39;] = forms nounphrases[fname] = tmp word = attribs[&#39;default&#39;] with open(&#39;nounphrases.json&#39;, &#39;w&#39;) as outfile: json.dump(nounphrases, outfile) . verbs = {} for x in glob.glob(&#39;../input/bunamo-bunachar-naisiunta-moirfeolaiochta/verb/*.xml&#39;): fname = x.split(&#39;/&#39;)[-1].replace(&#39;.xml&#39;, &#39;&#39;) attribs, forms = read_verb(x) tmp = {} tmp[&#39;attributes&#39;] = attribs tmp[&#39;forms&#39;] = forms verbs[fname] = tmp word = attribs[&#39;default&#39;] with open(&#39;verbs.json&#39;, &#39;w&#39;) as outfile: json.dump(verbs, outfile) . preposition = {} for x in glob.glob(&#39;../input/bunamo-bunachar-naisiunta-moirfeolaiochta/preposition/*.xml&#39;): fname = x.split(&#39;/&#39;)[-1].replace(&#39;.xml&#39;, &#39;&#39;) attribs = read_preposition(x) tmp = {} tmp[&#39;attributes&#39;] = attribs preposition[fname] = tmp with open(&#39;prepositions.json&#39;, &#39;w&#39;) as outfile: json.dump(preposition, outfile) . possessive = {} for x in glob.glob(&#39;../input/bunamo-bunachar-naisiunta-moirfeolaiochta/possessive/*.xml&#39;): fname = x.split(&#39;/&#39;)[-1].replace(&#39;.xml&#39;, &#39;&#39;) attribs = read_possessive(x) tmp = {} tmp[&#39;attributes&#39;] = attribs possessive[fname] = tmp with open(&#39;possessives.json&#39;, &#39;w&#39;) as outfile: json.dump(possessive, outfile) . possessive . {&#39;ár_poss&#39;: {&#39;attributes&#39;: {&#39;default&#39;: &#39;ár&#39;, &#39;disambig&#39;: &#39;&#39;, &#39;mutation&#39;: &#39;ecl1&#39;}}, &#39;a_poss_masc&#39;: {&#39;attributes&#39;: {&#39;default&#39;: &#39;a&#39;, &#39;disambig&#39;: &#39;masc&#39;, &#39;mutation&#39;: &#39;len1&#39;}}, &#39;a_poss_fem&#39;: {&#39;attributes&#39;: {&#39;default&#39;: &#39;a&#39;, &#39;disambig&#39;: &#39;fem&#39;, &#39;mutation&#39;: &#39;prefH&#39;}}, &#39;do_poss&#39;: {&#39;attributes&#39;: {&#39;default&#39;: &#39;do&#39;, &#39;disambig&#39;: &#39;&#39;, &#39;mutation&#39;: &#39;len1&#39;, &#39;apos&#39;: &#34;d&#39;&#34;}}, &#39;a_poss_pl&#39;: {&#39;attributes&#39;: {&#39;default&#39;: &#39;a&#39;, &#39;disambig&#39;: &#39;pl&#39;, &#39;mutation&#39;: &#39;ecl1&#39;}}, &#39;mo_poss&#39;: {&#39;attributes&#39;: {&#39;default&#39;: &#39;mo&#39;, &#39;disambig&#39;: &#39;&#39;, &#39;mutation&#39;: &#39;len1&#39;, &#39;apos&#39;: &#34;m&#39;&#34;}}, &#39;bhur_poss&#39;: {&#39;attributes&#39;: {&#39;default&#39;: &#39;bhur&#39;, &#39;disambig&#39;: &#39;&#39;, &#39;mutation&#39;: &#39;ecl1&#39;}}} .",
            "url": "https://jimregan.github.io/notes/irish/bunamo/kaggle/2021/04/24/bunamo-raw-json.html",
            "relUrl": "/irish/bunamo/kaggle/2021/04/24/bunamo-raw-json.html",
            "date": " • Apr 24, 2021"
        }
        
    
  
    
        ,"post251": {
            "title": "Kashubian PDF corpus 1",
            "content": "!wget $(lynx -dump http://skarbnicakaszubska.pl/najo-uczba/|grep pdf|awk &#39;{print $NF}&#39;) . For the most part, the text extracted from the pdfs is fine as is; one of the files has multiple articles, several with translations, making it potentially useful as a parallel corpus. . The text (seems to) come out fine with pdftotext, so I haven&#39;t bothered doing anything else. . !pdftotext -nopgbrk -f 9 -l 10 ZKP_biuletynRJK_2015_internet.pdf - | grep -v &#39;BIU­L E­T IN RADZËZNË KASZËBSCZÉGÒ JÃZËKA 2015&#39;|grep -v &#39;^10&#39;|grep -v &#39;^$&#39; &gt; ZKP_biuletynRJK_2015_internet_1.csb.txt . !pdftotext -nopgbrk -f 11 -l 12 ZKP_biuletynRJK_2015_internet.pdf - | grep -v &#39;BIU­L E­T YN RADY JĘZYKA KASZUBSKIEGO 2015&#39;|grep -v &#39;^12&#39;|grep -v &#39;^$&#39; &gt; ZKP_biuletynRJK_2015_internet_1.pl.txt . !pdftotext -nopgbrk -f 14 -l 20 ZKP_biuletynRJK_2015_internet.pdf - | grep -v &#39;BIU­L E­T IN RADZËZNË KASZËBSCZÉGÒ JÃZËKA 2015&#39;|grep -v &#39;^Pòstanowienia Radzëznë Kaszëbsczégò Jãzëka&#39;|grep -v &#39;^$&#39;|grep -v &#39;^1[5-9]$&#39;|grep -v &#39;^20$&#39; &gt; ZKP_biuletynRJK_2015_internet_wl1.txt . !pdftotext -nopgbrk -f 21 -l 23 ZKP_biuletynRJK_2015_internet.pdf - | grep -v &#39;BIU­L E­T IN RADZËZNË KASZËBSCZÉGÒ JÃZËKA 2015&#39;|grep -v &#39;^Pòstanowienia Radzëznë Kaszëbsczégò Jãzëka&#39;|grep -v &#39;^$&#39;|grep -v &#39;^2[1-9]$&#39; &gt; ZKP_biuletynRJK_2015_internet_wl2.txt . !pdftotext -nopgbrk -f 24 -l 29 ZKP_biuletynRJK_2015_internet.pdf - | grep -v &#39;BIU­L E­T IN RADZËZNË KASZËBSCZÉGÒ JÃZËKA 2015&#39;|grep -v &#39;^Pòstanowienia Radzëznë Kaszëbsczégò Jãzëka&#39;|grep -v &#39;^$&#39;|grep -v &#39;^2[1-9]$&#39; &gt; ZKP_biuletynRJK_2015_internet_wl3.txt . !pdftotext -nopgbrk -f 30 -l 48 ZKP_biuletynRJK_2015_internet.pdf - | grep -v &#39;BIU­L E­T IN RADZËZNË KASZËBSCZÉGÒ JÃZËKA 2015&#39;|grep -v &#39;^Pòstanowienia Radzëznë Kaszëbsczégò Jãzëka&#39;|grep -v &#39;^$&#39;|grep -v &#39;^[34][0-9]$&#39; &gt; ZKP_biuletynRJK_2015_internet_wl4.txt . !pdftotext -nopgbrk -f 49 -l 49 ZKP_biuletynRJK_2015_internet.pdf - | grep -v &#39;BIU­L E­T IN RADZËZNË KASZËBSCZÉGÒ JÃZËKA 2015&#39;|grep -v &#39;^Pòstanowienia Radzëznë Kaszëbsczégò Jãzëka&#39;|grep -v &#39;^$&#39;|grep -v &#39;^[34][0-9]$&#39; &gt; ZKP_biuletynRJK_2015_internet_wl5.txt . !pdftotext -nopgbrk -f 50 -l 65 ZKP_biuletynRJK_2015_internet.pdf - | grep -v &#39;BIU­L E­T IN RADZËZNË KASZËBSCZÉGÒ JÃZËKA 2015&#39;|grep -v &#39;^Pòstanowienia Radzëznë Kaszëbsczégò Jãzëka&#39;|grep -v &#39;^$&#39;|grep -v &#39;^[56][0-9]$&#39; &gt; ZKP_biuletynRJK_2015_internet_wl6.txt . def runner(file, start, end, suffix): base = file.replace(&#39;.pdf&#39;, &#39;&#39;) outfile = f&quot;{base}_{suffix}.txt&quot; !pdftotext -nopgbrk -f {start} -l {end} {file} - | grep -v &#39;BIU­L E­T IN RADZËZNË KASZËBSCZÉGÒ JÃZËKA 2015&#39;|grep -v &#39;BIU­L E­T YN RADY JĘZYKA KASZUBSKIEGO 2015&#39;|grep -v &#39;^Pòstanowienia Radzëznë Kaszëbsczégò Jãzëka&#39;|grep -v &#39;^$&#39;|grep -v &#39;^[0-9][0-9]$&#39;|grep -v &#39;^[1-4][0-9][0-9]$&#39; &gt; {outfile} . runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 68, 74, &#39;wl7&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 75, 77, &#39;wl8&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 78, 83, &#39;wl9&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 84, 102, &#39;wl10&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 103, 103, &#39;wl11&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 104, 119, &#39;wl12&#39;) . runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 122, 128, &#39;csb2&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 129, 132, &#39;csb3&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 133, 144, &#39;csb4&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 145, 151, &#39;csb5&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 153, 161, &#39;csb6&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 162, 166, &#39;csb7&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 168, 178, &#39;csb8&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 179, 185, &#39;csb9&#39;) # it took me this long to remember that there&#39;s a table of contents! runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 186, 197, &#39;csb10&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 198, 204, &#39;csb11&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 205, 211, &#39;csb12&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 212, 220, &#39;csb13&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 222, 228, &#39;pl2&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 229, 237, &#39;plx1&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 238, 241, &#39;pl3&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 242, 248, &#39;plx2&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 249, 254, &#39;plx3&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 255, 266, &#39;pl4&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 267, 274, &#39;pl5&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 275, 283, &#39;pl6&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 284, 289, &#39;pl7&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 290, 300, &#39;plx4&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 301, 313, &#39;pl8&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 314, 320, &#39;pl9&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 5, 8, &#39;toc&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 321, 333, &#39;pl10&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 334, 359, &#39;plx5&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 360, 367, &#39;pl11&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 368, 374, &#39;pl12&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 375, 390, &#39;plx6&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 391, 396, &#39;plx7&#39;) runner(&#39;ZKP_biuletynRJK_2015_internet.pdf&#39;, 397, 404, &#39;pl13&#39;) . Now, the rest . !for i in [0-9N]*.pdf;do pdftotext $i;done . uname=!uname -a if not &#39;LAPTOP-6PFTN7M9&#39; in uname: !rm *.pdf .",
            "url": "https://jimregan.github.io/notes/kashubian/lazyscrape/2021/04/23/najo-uczba-pdfs.html",
            "relUrl": "/kashubian/lazyscrape/2021/04/23/najo-uczba-pdfs.html",
            "date": " • Apr 23, 2021"
        }
        
    
  
    
        ,"post252": {
            "title": "Checking a Kashubian adjective-like declension",
            "content": "def _list_to_check(pos): num = [&#39;sg&#39;, &#39;pl&#39;] gen = [&#39;mp&#39;, &#39;ma&#39;, &#39;mi&#39;, &#39;f&#39;, &#39;nt&#39;] cas = [&#39;nom&#39;, &#39;gen&#39;, &#39;dat&#39;, &#39;acc&#39;, &#39;ins&#39;, &#39;loc&#39;, &#39;voc&#39;] out = [] for n in num: for g in gen: for c in cas: out.append(f&quot;{pos}.{g}.{n}.{c}&quot;) return out . len(_list_to_check(&#39;num.ord&#39;)) . 70 . dredzi = &quot;&quot;&quot; drëdżi drëdżi num.ord.mp|ma|mi.sg.nom|voc drëgô drëdżi num.ord.f.sg.nom|voc drëdżé drëdżi num.ord.nt.sg.nom|acc|voc drëgą drëdżi num.ord.f.sg.acc|ins drëdżi drëdżi num.ord.f.sg.gen|dat|loc drëdżim drëdżi num.ord.mp|ma|mi|nt.sg.loc|ins drëdżé drëdżi num.ord.nt|f|mi|ma.pl.nom|acc|voc drëdżich drëdżi num.ord.nt|f|mi|ma|mp.pl.gen|loc drëdżima drëdżi num.ord.nt|f|mi|ma.pl.ins drëdżégò drëdżi num.ord.nt|mi|ma|mp.sg.gen drëdżégò drëdżi num.ord.ma|mp.sg.acc drëdżémù drëdżi num.ord.nt|mi|ma|mp.sg.dat drëdżi drëdżi num.ord.mp.pl.nom|voc drëdżich drëdżi num.ord.mp.pl.acc drëdżim drëdżi num.ord.nt|f|mi|ma|mp.pl.dat &quot;&quot;&quot; . def _do_expand(stack, todo): onward = [] if not &#39;.&#39; in todo: return [f&#39;{a}.{b}&#39; for a in stack for b in todo.split(&#39;|&#39;)] cur, rest = todo.split(&#39;.&#39;, 1) if stack == []: onward = cur.split(&#39;|&#39;) return _do_expand(onward, rest) else: onward = [f&#39;{a}.{b}&#39; for a in stack for b in cur.split(&#39;|&#39;)] return _do_expand(onward, rest) def expand_compressed(lines): output = [] for i in lines: form, lemma, postag = i.split(&#39; t&#39;) newtags = _do_expand([], postag) output.extend([f&quot;{form} t{lemma} t{itag}&quot; for itag in newtags]) return output . expand_compressed([l for l in dredzi.split(&#39; n&#39;) if l != &#39;&#39;]) . vals = expand_compressed([l for l in dredzi.split(&#39; n&#39;) if l != &#39;&#39;]) . tags = [a.split(&#39; t&#39;)[-1] for a in vals] . for tc in _list_to_check(&#39;num.ord&#39;): if not tc in tags: print(tc) . num.ord.mi.sg.acc num.ord.mp.pl.ins . dredzi = &quot;&quot;&quot; drëdżi drëdżi num.ord.mp|ma|mi.sg.nom|voc drëdżi drëdżi num.ord.mi.sg.acc drëgô drëdżi num.ord.f.sg.nom|voc drëdżé drëdżi num.ord.nt.sg.nom|acc|voc drëgą drëdżi num.ord.f.sg.acc|ins drëdżi drëdżi num.ord.f.sg.gen|dat|loc drëdżim drëdżi num.ord.mp|ma|mi|nt.sg.loc|ins drëdżé drëdżi num.ord.nt|f|mi|ma.pl.nom|acc|voc drëdżich drëdżi num.ord.nt|f|mi|ma|mp.pl.gen|loc drëdżima drëdżi num.ord.nt|f|mi|ma|mp.pl.ins drëdżégò drëdżi num.ord.nt|mi|ma|mp.sg.gen drëdżégò drëdżi num.ord.ma|mp.sg.acc drëdżémù drëdżi num.ord.nt|mi|ma|mp.sg.dat drëdżi drëdżi num.ord.mp.pl.nom|voc drëdżich drëdżi num.ord.mp.pl.acc drëdżim drëdżi num.ord.nt|f|mi|ma|mp.pl.dat &quot;&quot;&quot; .",
            "url": "https://jimregan.github.io/notes/kashubian/declension/2021/04/23/check-kashubian-adjlike.html",
            "relUrl": "/kashubian/declension/2021/04/23/check-kashubian-adjlike.html",
            "date": " • Apr 23, 2021"
        }
        
    
  
    
        ,"post253": {
            "title": "Title",
            "content": "&gt; &quot;Train a model for MFA on Irish data on Kaggle&quot; - toc: false - branch: master - hidden: true - categories: [kaggle, irish, mfa] . Original on [Kaggle](https://www.kaggle.com/jimregan/train-irish-mfa-model) . %%capture import os os.chdir(&#39;/tmp&#39;) !wget https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/releases/download/v1.0.1/montreal-forced-aligner_linux.tar.gz !tar zxvf montreal-forced-aligner_linux.tar.gz !ln -s /tmp/montreal-forced-aligner/lib/libpython3.6m.so.1.0 /tmp/montreal-forced-aligner/lib/libpython3.6m.so . os.chdir(&#39;/kaggle/working&#39;) os.environ[&#39;LD_LIBRARY_PATH&#39;] = f&#39;{os.environ[&quot;LD_LIBRARY_PATH&quot;]}:/tmp/montreal-forced-aligner/lib/&#39; os.environ[&#39;PATH&#39;] = f&#39;{os.environ[&quot;PATH&quot;]}:/tmp/montreal-forced-aligner/bin/&#39; . %%capture !yes|apt install libgfortran3 . !mkdir /tmp/mfa-temp . import json datapath = &#39;../input/living-audio-irish-speech-corpus/living-audio.json&#39; with open(datapath) as jsonf: data = json.load(jsonf) . !mkdir /tmp/living-audio . lexicon_words = set() with open(&#39;../input/living-audio-irish-speech-corpus/lexicon.txt&#39;) as lexicon_file: for line in lexicon_file.readlines(): words = line.split(&#39; &#39;) lexicon_words.add(words[0]) . import shutil missing_words = set() for utt in data: shutil.copyfile(utt[&#39;path&#39;], f&quot;/tmp/living-audio/{utt[&#39;id&#39;]}.wav&quot;) with open(f&quot;/tmp/living-audio/{utt[&#39;id&#39;]}.txt&quot;, &#39;w&#39;) as text: sentence = utt[&#39;sentence&#39;] sentence = sentence.replace(&#39;(&#39;, &#39;&#39;).replace(&#39;)&#39;, &#39;&#39;) words = [] for word in sentence.split(&#39; &#39;): if not word in lexicon_words: missing_words.add(word) if &#39;-&#39; in word: if word.startswith(&#39;n-&#39;) or word.startswith(&#39;t-&#39;): workword = word[2:] workword.replace(&#39;-&#39;, &#39; &#39;) word = word[0:2] + workword else: word = word.replace(&#39;-&#39;, &#39; &#39;) words.append(word) text.write(&#39; &#39;.join(words)) . !mfa_train_and_align -t /tmp/mfa-temp -o ./irish-model /tmp/living-audio ../input/living-audio-irish-speech-corpus/lexicon.txt ./textgrid . Setting up corpus information... Creating dictionary information... Setting up training data... Calculating MFCCs... Calculating CMVN... Number of speakers in corpus: 1, average number of utterances per speaker: 1121.0 b&#39;number of phones 215 nnumber of pdfs 165 nnumber of transition-ids 1470 nnumber of transition-states 675 nfeature dimension 39 nnumber of gaussians 165 n&#39; None b&#39;number of phones 215 nnumber of pdfs 165 nnumber of transition-ids 1470 nnumber of transition-states 675 nfeature dimension 39 nnumber of gaussians 165 n&#39; None Beginning monophone training... 100%|███████████████████████████████████████████| 39/39 [25:35&lt;00:00, 21.13s/it] Initializing triphone training... Beginning triphone training... 100%|███████████████████████████████████████████| 34/34 [19:09&lt;00:00, 16.35s/it] Initializing speaker-adapted triphone training... Beginning speaker-adapted triphone training... 100%|███████████████████████████████████████████| 34/34 [08:55&lt;00:00, 8.33s/it] Saved model to ./irish-model .",
            "url": "https://jimregan.github.io/notes/2021/04/22/train-irish-mfa-model.html",
            "relUrl": "/2021/04/22/train-irish-mfa-model.html",
            "date": " • Apr 22, 2021"
        }
        
    
  
    
        ,"post254": {
            "title": "Kashubian - extract text from tlog",
            "content": "import json with open(&quot;/tmp/csb/kashubian-data.json&quot;, &quot;r&quot;) as read_file: data = json.load(read_file) . for datum in data: file = datum[&#39;audio&#39;].split(&#39;/&#39;)[-1].replace(&#39;.ogg&#39;, &#39;.txt&#39;) with open(f&#39;/tmp/csb/{file}&#39;, &#39;w&#39;) as f: text = &#39; n&#39;.join([a.strip() for a in datum[&#39;text&#39;].split(&#39; n&#39;) if a.strip() != &#39;&#39;]) f.write(text) . import glob for file in glob.glob(&#39;/tmp/csb/*.ogg.wav.tlog&#39;): outfile = file.replace(&#39;.ogg.wav.tlog&#39;, &#39;.rec.txt&#39;) with open(file, &quot;r&quot;) as tlog: data = json.load(tlog) with open(outfile, &quot;w&quot;) as rectxt: for datum in data: rectxt.write(f&quot;{datum[&#39;transcript&#39;]} n&quot;) .",
            "url": "https://jimregan.github.io/notes/asr/kashubian/2021/04/22/kashubian-extract-text-from-tlog.html",
            "relUrl": "/asr/kashubian/2021/04/22/kashubian-extract-text-from-tlog.html",
            "date": " • Apr 22, 2021"
        }
        
    
  
    
        ,"post255": {
            "title": "Training MFA G2P on fuaimeanna.ie",
            "content": "Original on Kaggle . %%capture import os os.chdir(&#39;/tmp&#39;) !wget https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/releases/download/v1.0.1/montreal-forced-aligner_linux.tar.gz !tar zxvf montreal-forced-aligner_linux.tar.gz !ln -s /tmp/montreal-forced-aligner/lib/libpython3.6m.so.1.0 /tmp/montreal-forced-aligner/lib/libpython3.6m.so . os.chdir(&#39;/kaggle/working&#39;) os.environ[&#39;LD_LIBRARY_PATH&#39;] = f&#39;{os.environ[&quot;LD_LIBRARY_PATH&quot;]}:/tmp/montreal-forced-aligner/lib/&#39; . os.environ[&#39;PATH&#39;] = f&#39;{os.environ[&quot;PATH&quot;]}:/tmp/montreal-forced-aligner/bin/&#39; . !mkdir /tmp/mfa-temp . !mfa_train_g2p -t /tmp/mfa-temp ../input/living-audio-irish-speech-corpus/lexicon.txt ./g2p-model . GitRevision: kaldi-6-g64719c Loading input file: /tmp/mfa-temp/g2p-model/input.txt Starting EM... Finished first iter... Iteration: 1 Change: 3.18428 Iteration: 2 Change: 0.068243 Iteration: 3 Change: 0.0359888 Iteration: 4 Change: 0.00983238 Iteration: 5 Change: 0.00348759 Iteration: 6 Change: 0.00150681 Iteration: 7 Change: 0.00084877 Iteration: 8 Change: 0.000713348 Iteration: 9 Change: 0.000318527 Iteration: 10 Change: 0.000238419 Iteration: 11 Change: 0.000259399 Last iteration: GitRevision: kaldi-6-g64719c Initializing... Converting... Saved model to ./g2p-model .",
            "url": "https://jimregan.github.io/notes/kaggle/mfa/fuaimeanna/2021/04/21/train-irish-g2p-model-with-mfa.html",
            "relUrl": "/kaggle/mfa/fuaimeanna/2021/04/21/train-irish-g2p-model-with-mfa.html",
            "date": " • Apr 21, 2021"
        }
        
    
  
    
        ,"post256": {
            "title": "Installing montreal-forced-aligner on kaggle",
            "content": "%%capture !wget https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/releases/download/v1.0.1/montreal-forced-aligner_linux.tar.gz . %%capture !tar zxvf montreal-forced-aligner_linux.tar.gz !rm montreal-forced-aligner_linux.tar.gz . !mv montreal-forced-aligner/bin montreal-forced-aligner/bb . !ln -s montreal-forced-aligner/lib/libpython3.6m.so.1.0 montreal-forced-aligner/lib/libpython3.6m.so .",
            "url": "https://jimregan.github.io/notes/kaggle/itworks/2021/04/20/mfa-on-kaggle.html",
            "relUrl": "/kaggle/itworks/2021/04/20/mfa-on-kaggle.html",
            "date": " • Apr 20, 2021"
        }
        
    
  
    
        ,"post257": {
            "title": "Title",
            "content": "&gt; &quot;[Incomplete]&quot; - toc: false - branch: master - hidden: true - categories: [irish, g2p, icu, incomplete] . import icu . def transliterator_from_rules(name, rules): fromrules = icu.Transliterator.createFromRules(name, rules) icu.Transliterator.registerInstance(fromrules) return icu.Transliterator.createInstance(name) . irishlc_rules = &quot;&quot;&quot; :: NFD; $uvowel=[AEIOU]; $wb=[^[:L:][:M:]]; $wb { ([nt]) } $uvowel → $1 &#39;-&#39;; :: lower; :: NFC; &quot;&quot;&quot; . irishlc = transliterator_from_rules(&#39;irishlc&#39;, irishlc_rules) . ulster_stress_rules = &quot;&quot;&quot; $wb=[^[:L:][:M:]]; $cons = [bcdfghjklmnpqrstvwxyz]; $vowel = [aeiouáéíóú]; $bvowel = [aouáóú{ae}]; $svowel = [eiéí]; :: irishlc; $wb { anois } $wb → an&#39;ˈ&#39;ois; $wb { arís } $wb → air&#39;ˈ&#39;ís; $wb { isteach } $wb → ist&#39;ˈ&#39;each; $wb { istigh } $wb → ist&#39;ˈ&#39;igh; $wb { amach } $wb → am&#39;ˈ&#39;ach; $wb $cons* { ($vowel) → &#39;ˈ&#39;$1; &quot;&quot;&quot; . stress = transliterator_from_rules(&#39;ulster_stress&#39;, ulster_stress_rules) . stress.transliterate(&quot;amach&quot;) . &#39;amˈach&#39; . ulster_g2p_rules = &quot;&quot;&quot; $wb=[^[:L:][:M:]]; $cons = [bcdfghjklmnpqrstvwxyz]; # when we transliterate past the first consonant, # we need to use the transliteration as context $scons = [{bʲ}cç{dʲ}{fʲ}ɟ{mʲ}{ɴʲ}ʃ{tʲ}{vʲ}{GJ}{DJ}{BJ}{MJ}]; $bcons = [{bˠ}{kˠ}x{dˠ}{fˠ}{gˠ}{mˠ}{ɴˠ}{sˠ}{tˠ}w{GH}{DH}{BH}{MH}]; $vowel = [aeiouáéíóú]; $bvowel = [aouáóú{ae}]; $svowel = [eiéí]; $apos = [’ &#39;]; $bfce = [{á}{adh}{aidh}{aidís}{aimid}{aimis}{ainn}{as}]; $sfce = [{eá}{eadh}{idh}{idís}{imid}{imis}{inn}]; $ps = &#39;ˈ&#39;; :: irishlc; :: ulster_stress; $wb { mb $apos? } $cons* ˈ? $bvowel → mˠ; $wb { mb $apos? } $cons* ˈ? $svowel → mʲ; #$bvowel $bcons* { bh → w; #bh } $cons* ˈ? $bvowel → w; #$svowel $scons* { bh → vʲ; #bh } $cons* ˈ? $svowel → vʲ; $bvowel $bcons* { bh → BH; bh } $cons* ˈ? $bvowel → BH; $svowel $scons* { bh → BJ; bh } $cons* ˈ? $svowel → BJ; bf } $bfce $wb → pˠ; bf } $sfce $wb → pʲ; $bvowel $bcons* { b → bˠ; b } $cons* ˈ? $bvowel → bˠ; $svowel $scons* { b → bʲ; b } $cons* ˈ? $svowel → bʲ; # gKim/Khim are things that happen too $wb { gc } $cons* ˈ? $bvowel → gˠ; $wb { gc } $cons* ˈ? $svowel → ɟ; $bvowel $bcons* { ch → x; ch } $cons* ˈ? $bvowel → x; $svowel $scons* { ch → ç; ch } $cons* ˈ? $svowel → ç; $bvowel $bcons* { [ck] → kˠ; [ck] } $cons* ˈ? $bvowel → kˠ; $svowel $scons* { [ck] → c; [ck] } $cons* ˈ? $svowel → c; $wb { nd } $cons* ˈ? $bvowel → ɴˠ; $wb { nd } $cons* ˈ? $svowel → ɴʲ; $wb { dh $apos? } $cons* ˈ? $bvowel → ɣ; $wb { dh $apos? } $cons* ˈ? $svowel → j; # can&#39;t do this here, because the next pass does diphthongs #$bvowel $bcons* { dh → ɣ; #dh } $cons* ˈ? $bvowel → ɣ; #$svowel $scons* { dh → j; #dh } $cons* ˈ? $svowel → j; $bvowel $bcons* { dh → DH; dh } $cons* ˈ? $bvowel → DH; $svowel $scons* { dh → DJ; dh } $cons* ˈ? $svowel → DJ; $wb { d $apos? } $cons* ˈ? $bvowel → dˠ; $wb { d $apos? } $cons* ˈ? $svowel → dʲ; $bvowel $bcons* { d → dˠ; d } $cons* ˈ? $bvowel → dˠ; $svowel $scons* { d → dʲ; d } $cons* ˈ? $svowel → dʲ; j → dʲ ; $wb { bhf } $cons* ˈ? $bvowel → w; $wb { bhf } $cons* ˈ? $svowel → vʲ; fh → ; $bvowel $bcons* { f → fˠ; f } $cons* ˈ? $bvowel → fˠ; $svowel $scons* { f → fʲ; f } $cons* ˈ? $svowel → fʲ; # can&#39;t do this here, because the next pass does diphthongs #$bvowel $bcons* { gh → ɣ; #gh } $cons* ˈ? $bvowel → ɣ; #$svowel $scons* { gh → j; #gh } $cons* ˈ? $svowel → j; $bvowel $bcons* { gh → GH; gh } $cons* ˈ? $bvowel → GH; $svowel $scons* { gh → GJ; gh } $cons* ˈ? $svowel → GJ; $bvowel $bcons* { g → gˠ; g } $cons* ˈ? $bvowel → gˠ; $svowel $scons* { g → ɟ; g } $cons* ˈ? $svowel → ɟ; $wb { l } ˈ? $svowel → ʟʲ; $bvowel $bcons* { ll → ʟˠ; ll } $cons* ˈ? $bvowel → ʟˠ; $svowel $scons* { ll → ʟʲ; ll } $cons* ˈ? $svowel → ʟʲ; $bvowel $bcons* { l → ʟˠ; l } $cons* ˈ? $bvowel → ʟˠ; $svowel $scons* { l → lʲ; l } $cons* ˈ? $svowel → lʲ; #$bvowel $bcons* { mh → w; #mh } $cons* ˈ? $bvowel → w; #$svowel $scons* { mh → vʲ; #mh } $cons* ˈ? $svowel → vʲ; $bvowel $bcons* { mh → MH; mh } $cons* ˈ? $bvowel → MH; $svowel $scons* { mh → MJ; mh } $cons* ˈ? $svowel → MJ; $wb { m $apos? } $cons* ˈ? $bvowel → mˠ; $wb { m $apos? } $cons* ˈ? $svowel → mʲ; $bvowel $bcons* { m → mˠ; m } $cons* ˈ? $bvowel → mˠ; $svowel $scons* { m → mʲ; m } $cons* ˈ? $svowel → mʲ; $wb { bp } $cons* ˈ? $bvowel → bˠ; $wb { bp } $cons* ˈ? $svowel → bʲ; $bvowel $bcons* { ph → fˠ; ph } $cons* ˈ? $bvowel → fˠ; $svowel $scons* { ph → fʲ; ph } $cons* ˈ? $svowel → fʲ; $bvowel $bcons* { p → pˠ; p } $cons* ˈ? $bvowel → pˠ; $svowel $scons* { p → pʲ; p } $cons* ˈ? $svowel → pʲ; $wb { r → ɾˠ; [st]hr } ˈ? $bvowel → r̪ˠ ; [st]hr } ˈ? $svowel → r̪ʲ ; $bvowel $cons* { [st]hr → r̪ˠ; [st]hr } ˈ? $bvowel → r̪ˠ ; $svowel $cons* { [st]hr → r̪ʲ; [st]hr } ˈ? $svowel → r̪ʲ ; $wb { sh } ˈ? [{eá}{eái}{eoi}{eo}{iúi}{iú}] → ç ; [st]h → h ; h → h ; $bvowel $cons* { s → sˠ; s } $cons* ˈ? $bvowel → sˠ; $svowel $cons* { s → ʃ; s } $cons* ˈ? $svowel → ʃ; $bvowel $bcons* { t → tˠ; t } $cons* ˈ? $bvowel → tˠ; $svowel $scons* { t → tʲ; t } $cons* ˈ? $svowel → tʲ; # &#39;oi&#39; can represent either: # * &#39;o&#39; before a slender consonant # * &#39;i&#39; after a broad consonant # &#39;goitse&#39; can be either, I think, but abair says /i/ ([ɪ]) (I&#39;ve only ever heard /o/ ([ʌ])) $wb g $ps { oi } tse $wb → i ; $wb an $ps { oi } s $wb → i ; :: null; e?a DH ai? → eː; $ps { e?a DH → eː; e?a DH → uː; $ps { oi [DG]J → ai; $ps { [ae]i DJ → eː; $ps { a?i GJ → ai; oi [DG]J → ə; ai [DG]J → iː; ei DJ → ə; i DJ → iː; i GJ → ə; o MH } $wb → uː; o MH → oː; $ps { o BH ai? → au; $ps { o [DG]H a? → au; o GH a? → ə; o BH a i? → ə; o DH a → ə; o DH → uː; $ps { ea [MB]H ai → au ; $ps { ea [MB]H a → au ; $ps { ea [MB]H → au ; $ps { a [MB]H ai → au ; $ps { a [MB]H a → au ; $ps { a [MB]H → au ; ea [MB]H ai → ə ; ea [MB]H a → ə ; ea [MB]H → uː ; a [MB]H ai → ə ; a [MB]H a → ə ; a [MB]H → ə ; $ps { ei GH ea → eː; # it seems like abair ought to have this rule, but doesn&#39;t #a GH ai → eː; # instead this happens (agha + i separately) a GH ai → eːə; a GH a → eː; $ps { a GH → eː; ei GH ea → ə; a GH → ə; $ps { eái → aː; $ps { eá → aː; $ps { ái → aː; $ps { á → aː; $ps { aei → eː; $ps { ae → eː; $ps { éi → eː; $ps { é → eː; $ps { uío → iː; $ps { aío → iː; $ps { aí → iː; $ps { uí → iː; $ps { oí → iː; $ps { ío → iː; $ps { aoi → iː; $ps { ao → iː; $ps { í → iː; $ps { eoi → oː; $ps { eó → oː; $ps { eo → oː; $ps { ió → oː; $ps { ói → oː; $ps { ó → oː; eái → a; eá → a; ái → a; á → a; aei → e; ae → e; éi → e; é → e; uío → iə; aío → iə; aí → i; uí → i; oí → i; ío → iə; aoi → i; ao → i; í → i; eoi → ɔ; eó → ɔ; eo → ɔ; ió → ɔ; ói → ɔ; ó → ɔ; $ps { iúi → uː; $ps { úai → uː; $ps { iú → uː; iú } $wb → uː; $ps { úi → uː; $ps { ú → uː; ú } $wb → uː; iúi → u; úai → u; iú → u; úi → u; ú → u; $ps { eai → a ; $ps { ea → a ; $ps { ai → a ; $ps { a → a ; $ps { ei → e ; $ps { ue → e ; $ps { e → e ; eai → ə ; ea → ə ; ai → ə ; a → ə ; ei → ə ; ue → ə ; e → ə ; $ps { oi → o ; $ps { ui → i ; $ps { iu → u ; $ps { u → u ; $ps { io → i ; $ps { i → i ; $wb $ps? { o } [r{ɾˠ}] → oː ; $ps { o → o ; oi → ə ; ui → ə ; iu → ə ; io → ə ; u → ə ; i → ə ; o → ə ; DH → ɣ; DJ → j; GH → ɣ; GJ → j; BH → w; BJ → v; MH → w; MJ → v; $ps → $ps; &quot;&quot;&quot; . ulster_g2p = transliterator_from_rules(&#39;ulster_g2p&#39;, ulster_g2p_rules) . ulster_g2p.transliterate(&quot;scuaibfeá&quot;) . &#39;sˠkˠˈuəpʲa&#39; .",
            "url": "https://jimregan.github.io/notes/2021/04/19/ulster_g2p.html",
            "relUrl": "/2021/04/19/ulster_g2p.html",
            "date": " • Apr 19, 2021"
        }
        
    
  
    
        ,"post258": {
            "title": "Irish lowercase with ICU",
            "content": "import icu . def transliterator_from_rules(name, rules): fromrules = icu.Transliterator.createFromRules(name, rules) icu.Transliterator.registerInstance(fromrules) return icu.Transliterator.createInstance(name) . irishlc_rules = &quot;&quot;&quot; :: NFD; $uvowel=[AEIOU]; $wb=[^[:L:][:M:]]; $wb { ([nt]) } $uvowel → $1 &#39;-&#39;; :: lower; :: NFC; &quot;&quot;&quot; . irishlc = transliterator_from_rules(&#39;irishlc&#39;, irishlc_rules) . irishlc.transliterate(&quot;tá an tUachtarán tar éis a lámh a chur leis&quot;) . &#39;tá an t-uachtarán tar éis a lámh a chur leis&#39; .",
            "url": "https://jimregan.github.io/notes/icu/2021/04/18/irish-lower-with-icu.html",
            "relUrl": "/icu/2021/04/18/irish-lower-with-icu.html",
            "date": " • Apr 18, 2021"
        }
        
    
  
    
        ,"post259": {
            "title": "Clarin-Studio dataset",
            "content": "The datasets are on the hub: jimregan/clarinpl_studio and jimregan/clarinpl_sejmsenat . !wget http://mowa.clarin-pl.eu/korpusy/audio.tar.gz . !tar zxvf audio.tar.gz . !cat /content/audio/SES0001/spk.txt . SPK0001 . !cat /content/audio/SES0001/sent030.txt . gdy maluch już się wypluska wytrzyjcie go dokładnie ręcznikiem posmarujcie jeszcze raz kremem przeciwsłonecznym i ubierzcie w suche u branie . !head /content/SejmSenat/test/wav.scp.orig . !head /content/SejmSenat/test/spk2utt . !head /content/SejmSenat/train/text . !huggingface-cli login . !huggingface-cli repo create clarinpl_studio --type dataset . !rm -rf clarinpl_studio !git clone https://huggingface.co/datasets/jimregan/clarinpl_studio . Cloning into &#39;clarinpl_studio&#39;... remote: Enumerating objects: 6, done. remote: Counting objects: 100% (6/6), done. remote: Compressing objects: 100% (5/5), done. remote: Total 6 (delta 0), reused 0 (delta 0) Unpacking objects: 100% (6/6), done. . !datasets-cli test clarinpl_studio --save_infos --all_configs . Testing builder &#39;clean&#39; (1/1) Downloading and preparing dataset clarin_pl_studio/clean (download: 4.59 GiB, generated: 4.50 MiB, post-processed: Unknown size, total: 4.60 GiB) to /root/.cache/huggingface/datasets/clarin_pl_studio/clean/2.1.0/733df40ff099ad45628c8c755782c0abb5554817218890a3d232ed359122252c... 0 examples [00:00, ? examples/s]2021-04-15 10:43:00.739700: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0 Dataset clarin_pl_studio downloaded and prepared to /root/.cache/huggingface/datasets/clarin_pl_studio/clean/2.1.0/733df40ff099ad45628c8c755782c0abb5554817218890a3d232ed359122252c. Subsequent calls will reuse this data. 100% 3/3 [00:00&lt;00:00, 176.78it/s] Dataset Infos file saved at clarinpl_studio/dataset_infos.json Test successful. . # coding=utf-8 # Copyright 2021 The TensorFlow Datasets Authors and the HuggingFace Datasets Authors. # Copyright 2021 Jim O&#39;Regan # # Licensed under the Apache License, Version 2.0 (the &quot;License&quot;); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an &quot;AS IS&quot; BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. # Lint as: python3 &quot;&quot;&quot;ClarinPL Studio automatic speech recognition dataset.&quot;&quot;&quot; import os import datasets _CITATION = &quot;&quot;&quot; @article{korvzinek2017polish, title={Polish read speech corpus for speech tools and services}, author={Kor{ v{z}}inek, Danijel and Marasek, Krzysztof and Brocki, { L}ukasz and Wo{ l}k, Krzysztof}, journal={arXiv preprint arXiv:1706.00245}, year={2017} } &quot;&quot;&quot; _DESCRIPTION = &quot;&quot;&quot; The corpus consists of 317 speakers recorded in 554 sessions, where each session consists of 20 read sentences and 10 phonetically rich words. The size of the audio portion of the corpus amounts to around 56 hours, with transcriptions containing 356674 words from a vocabulary of size 46361. Note that in order to limit the required storage for preparing this dataset, the audio is stored in the .wav format and is not converted to a float32 array. To convert the audio file to a float32 array, please make use of the `.map()` function as follows: python import soundfile as sf def map_to_array(batch): speech_array, _ = sf.read(batch[&quot;file&quot;]) batch[&quot;speech&quot;] = speech_array return batch dataset = dataset.map(map_to_array, remove_columns=[&quot;file&quot;]) &quot;&quot;&quot; _URL = &quot;https://mowa.clarin-pl.eu/&quot; _DS_URL = &quot;http://mowa.clarin-pl.eu/korpusy/audio.tar.gz&quot; _TRAIN_URL = &quot;https://raw.githubusercontent.com/danijel3/ClarinStudioKaldi/master/local_clarin/train.sessions&quot; _TEST_URL = &quot;https://raw.githubusercontent.com/danijel3/ClarinStudioKaldi/master/local_clarin/test.sessions&quot; _VALID_URL = &quot;https://raw.githubusercontent.com/danijel3/ClarinStudioKaldi/master/local_clarin/dev.sessions&quot; class ClarinPLStudioASRConfig(datasets.BuilderConfig): &quot;&quot;&quot;BuilderConfig for ClarinPLStudioASR.&quot;&quot;&quot; def __init__(self, **kwargs): &quot;&quot;&quot; Args: data_dir: `string`, the path to the folder containing the files in the downloaded .tar citation: `string`, citation for the data set url: `string`, url for information about the data set **kwargs: keyword arguments forwarded to super. &quot;&quot;&quot; super(ClarinPLStudioASRConfig, self).__init__(version=datasets.Version(&quot;2.1.0&quot;, &quot;&quot;), **kwargs) class ClarinPLStudio(datasets.GeneratorBasedBuilder): &quot;&quot;&quot;ClarinPL Studio dataset.&quot;&quot;&quot; BUILDER_CONFIGS = [ ClarinPLStudioASRConfig(name=&quot;clean&quot;, description=&quot;&#39;Clean&#39; speech.&quot;), ] def _info(self): return datasets.DatasetInfo( description=_DESCRIPTION, features=datasets.Features( { &quot;file&quot;: datasets.Value(&quot;string&quot;), &quot;text&quot;: datasets.Value(&quot;string&quot;), &quot;speaker_id&quot;: datasets.Value(&quot;string&quot;), &quot;id&quot;: datasets.Value(&quot;string&quot;), } ), supervised_keys=(&quot;file&quot;, &quot;text&quot;), homepage=_URL, citation=_CITATION, ) def _split_generators(self, dl_manager): def get_sessions(path): sessions = [] with open(path, &#39;r&#39;) as f: for line in f: sessions.append(line.strip()) return sessions archive_path = dl_manager.download_and_extract(_DS_URL) train_sessions_path = dl_manager.download(_TRAIN_URL) test_sessions_path = dl_manager.download(_TEST_URL) valid_sessions_path = dl_manager.download(_VALID_URL) train_sessions = get_sessions(train_sessions_path) test_sessions = get_sessions(test_sessions_path) valid_sessions = get_sessions(valid_sessions_path) archive_path = os.path.join(archive_path, &quot;audio&quot;) return [ datasets.SplitGenerator(name=&quot;train&quot;, gen_kwargs={ &quot;archive_path&quot;: archive_path, &quot;sessions&quot;: train_sessions }), datasets.SplitGenerator(name=&quot;test&quot;, gen_kwargs={ &quot;archive_path&quot;: archive_path, &quot;sessions&quot;: test_sessions }), datasets.SplitGenerator(name=&quot;valid&quot;, gen_kwargs={ &quot;archive_path&quot;: archive_path, &quot;sessions&quot;: valid_sessions }), ] def _generate_examples(self, archive_path, sessions): &quot;&quot;&quot;Generate examples from a ClarinPL Studio archive_path.&quot;&quot;&quot; def get_single_line(path): lines = [] with open(path, &#39;r&#39;, encoding=&quot;utf-8&quot;) as f: for line in f: line = line.strip() lines.append(line) assert(len(lines) == 1) return lines[0] for session in sessions: session_path = os.path.join(archive_path, session) speaker = get_single_line(os.path.join(session_path, &quot;spk.txt&quot;)) text_glob = os.path.join(session_path, &quot;*.txt&quot;) for text_file in sorted(glob.glob(text_glob)): if text_file.endswith(&quot;spk.txt&quot;): continue basename = os.path.basename(text_file) basename = basename.replace(&#39;.txt&#39;, &#39;&#39;) key = f&#39;{session}_{basename}&#39; text = get_single_line(text_file) audio = text_file.replace(&#39;.txt&#39;, &#39;.wav&#39;) example = { &quot;id&quot;: key, &quot;speaker_id&quot;: speaker, &quot;file&quot;: audio, &quot;text&quot;: text, } yield key, example . !pip install datasets . from datasets import load_dataset dataset = load_dataset(&#39;clarinpl_studio.py&#39;) . Downloading and preparing dataset clarin_pl_studio/clean (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/clarin_pl_studio/clean/2.1.0/733df40ff099ad45628c8c755782c0abb5554817218890a3d232ed359122252c... Dataset clarin_pl_studio downloaded and prepared to /root/.cache/huggingface/datasets/clarin_pl_studio/clean/2.1.0/733df40ff099ad45628c8c755782c0abb5554817218890a3d232ed359122252c. Subsequent calls will reuse this data. . dataset . DatasetDict({ train: Dataset({ features: [&#39;file&#39;, &#39;text&#39;, &#39;speaker_id&#39;, &#39;id&#39;], num_rows: 11222 }) test: Dataset({ features: [&#39;file&#39;, &#39;text&#39;, &#39;speaker_id&#39;, &#39;id&#39;], num_rows: 1362 }) valid: Dataset({ features: [&#39;file&#39;, &#39;text&#39;, &#39;speaker_id&#39;, &#39;id&#39;], num_rows: 1229 }) }) . import IPython IPython.display.Audio(dataset[&#39;train&#39;][&#39;file&#39;][2184]) . dataset . DatasetDict({ train: Dataset({ features: [&#39;file&#39;, &#39;text&#39;, &#39;speaker_id&#39;, &#39;id&#39;], num_rows: 6622 }) test: Dataset({ features: [&#39;file&#39;, &#39;text&#39;, &#39;speaker_id&#39;, &#39;id&#39;], num_rows: 130 }) }) . dataset[&#39;train&#39;][0] . {&#39;file&#39;: &#39;/root/.cache/huggingface/datasets/downloads/extracted/333ddc746f2df1e1d19b44986992d4cbe28710fde81d533a220e755ee6c5c519/audio/SES0001/rich001.wav&#39;, &#39;id&#39;: &#39;SES0001_rich001&#39;, &#39;speaker_id&#39;: &#39;SPK0001&#39;, &#39;text&#39;: &#39;drożdże dżip gwożdżenie ozimina wędzarz rdzeń wędzonka ingerować kładzenie jutrzenka&#39;} . !wc -l /root/.cache/huggingface/datasets/downloads/extracted/4143b1d75559b10028c1c7e8800c9ccc05934ca5a8ea15f8f9a92770576a1ee3/SejmSenat/*/text . 130 /root/.cache/huggingface/datasets/downloads/extracted/4143b1d75559b10028c1c7e8800c9ccc05934ca5a8ea15f8f9a92770576a1ee3/SejmSenat/test/text 6622 /root/.cache/huggingface/datasets/downloads/extracted/4143b1d75559b10028c1c7e8800c9ccc05934ca5a8ea15f8f9a92770576a1ee3/SejmSenat/train/text 6752 total . !find /root/.cache/huggingface/datasets/downloads/extracted/4143b1d75559b10028c1c7e8800c9ccc05934ca5a8ea15f8f9a92770576a1ee3/SejmSenat/audio/ -type f|wc . 6752 6752 1159384 . !rm -rf SejmSenat/ .",
            "url": "https://jimregan.github.io/notes/clarinpl/huggingface/2021/04/14/clarin-studio-dataset.html",
            "relUrl": "/clarinpl/huggingface/2021/04/14/clarin-studio-dataset.html",
            "date": " • Apr 14, 2021"
        }
        
    
  
    
        ,"post260": {
            "title": "CC-Aligned Irish contains rubbish",
            "content": "See here. This is probably why M2M100 sucks at Irish. . !wget http://www.statmt.org/cc-aligned/en_XX-ga_IE.tsv.xz . --2021-06-05 17:38:16-- http://www.statmt.org/cc-aligned/en_XX-ga_IE.tsv.xz Resolving www.statmt.org (www.statmt.org)... 129.215.197.184 Connecting to www.statmt.org (www.statmt.org)|129.215.197.184|:80... connected. HTTP request sent, awaiting response... 200 OK Length: 150347648 (143M) [application/x-xz] Saving to: ‘en_XX-ga_IE.tsv.xz’ en_XX-ga_IE.tsv.xz 100%[===================&gt;] 143.38M 139KB/s in 20m 26s 2021-06-05 17:58:43 (120 KB/s) - ‘en_XX-ga_IE.tsv.xz’ saved [150347648/150347648] . !unxz en_XX-ga_IE.tsv.xz . !grep &#39; .ca&#39; en_XX-ga_IE.tsv| cut -c -120 . boutiquestepup.ca https://boutiquestepup.ca/collections/figure-skating-tights Figure skating tights – Boutique Step Up boutiquestepup.ca https://boutiquestepup.ca/collections/crystalized-dress-and-catsuit Figure Skating Dress with Crystals boutiquestepup.ca https://boutiquestepup.ca/collections/mens-skatewear BOYS &amp; MENS FIGURE SKATING WEAR – Boutique Step boutiquestepup.ca https://boutiquestepup.ca/collections/black-figure-skating-dresses Black Figure Skating Dresses, Catsu boutiquestepup.ca https://boutiquestepup.ca/products/new-jerrys-figure-skating-dress-catsuit-unitard-black-lace-made-on- boutiquestepup.ca https://boutiquestepup.ca/ Boutique Step Up|All Departments|GIFT CARDS|AQUATICS &amp; SWIMMING|WOMENS /GIR boutiquestepup.ca https://boutiquestepup.ca/products/new-skating-dress-catsuit-unitard-290-high-neck-made-on-order-youth boutiquestepup.ca https://boutiquestepup.ca/collections/training-racing-swimsuit Training &amp; Racing Swimsuit – Boutique boutiquestepup.ca https://boutiquestepup.ca/collections/skating-catsuit-unitard SKATING CATSUIT- UNITARD – Boutique St boutiquestepup.ca https://boutiquestepup.ca/collections/figure-skates-skating-boots-and-skating-blades Figure Skates, Sk boutiquestepup.ca https://boutiquestepup.ca/collections/dance-shoes Dance Shoes – Boutique Step Up|❅|❆|❅|❆|❅ boutiquestepup.ca https://boutiquestepup.ca/collections/dance-costumes Dance Costumes – Boutique Step Up|All Departmen mp3gain-pro.com http://mp3gain-pro.com/mp3/keywords Keywords « Mp3 Gain PRO official site Mp3 Normalizer|Home|Tags|Keyw boutiquestepup.ca https://boutiquestepup.ca/collections/skating-shorts Skating Shorts – Boutique Step Up|All Departmen boutiquestepup.ca https://boutiquestepup.ca/products/new-jerrys-competition-skating-dress-142-mirror-red-made-on-order N boutiquestepup.ca https://boutiquestepup.ca/collections/jammers Men&#39;s &amp; Boys Swimwear – Boutique Step Up|All Departmen boutiquestepup.ca https://boutiquestepup.ca/products/new-rockerz-figure-skating-guards-skate-guards-mix-match-colors Fig boutiquestepup.ca https://boutiquestepup.ca/collections/practice-gymnastics-leotard-competition-gymnastics-leotard-team- boutiquestepup.ca https://boutiquestepup.ca/collections/figure-skating-skirt FIGURE SKATING SKIRT – Boutique Step Up|A boutiquestepup.ca https://boutiquestepup.ca/collections/aqua-fitness-chlorine-resistant-swimsuit Aqua Fitness Swimsuits boutiquestepup.ca https://boutiquestepup.ca/collections/dance-accessories-tights DANCE ACCESSORIES &amp; TIGHTS – Boutique cantonfair.net https://www.cantonfair.net/category/49-health-industry Trade Shows from Health Industry China|Search|Sear lrmsafety.com https://en.lrmsafety.com/products/3m-11525 3M รุ่น 11525 – บริษัท เหลือง Binary file en_XX-ga_IE.tsv matches .",
            "url": "https://jimregan.github.io/notes/badmt/irish/2021/04/14/cc-aligned-irish.html",
            "relUrl": "/badmt/irish/2021/04/14/cc-aligned-irish.html",
            "date": " • Apr 14, 2021"
        }
        
    
  
    
        ,"post261": {
            "title": "M2M100 sucks at Irish",
            "content": "Huggingface Transformers added the M2M 100 model, I tried it out and tweeted screenshots of the appalling output, so I thought I&#39;d recreate the translations to show they were very real. . !pip install sentencepiece transformers . from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer model = M2M100ForConditionalGeneration.from_pretrained(&quot;facebook/m2m100_418M&quot;) tokenizer = M2M100Tokenizer.from_pretrained(&quot;facebook/m2m100_418M&quot;) . def translate(text, src_lang=&quot;pl&quot;, trg_lang=&quot;ga&quot;): tokenizer.src_lang = src_lang encoded = tokenizer(text, return_tensors=&quot;pt&quot;) generated_tokens = model.generate(**encoded, forced_bos_token_id=tokenizer.get_lang_id(trg_lang)) print(tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)) . So, do massively multilingual MT models trained on massively crawled datasets lead to great output?No pic.twitter.com/SckNGTq09B . &mdash; Jim O&#39;Regan (@jimregan) April 12, 2021 . “One must love one&#39;s wife” . translate(&quot;Trzeba kochać swoją żonę&quot;) . [&#39;Brazzers físeán catagóir Inexperienced, Déagóir Inexperienced&#39;] . pic.twitter.com/4b6DgbbhtE . &mdash; Jim O&#39;Regan (@jimregan) April 12, 2021 . “What are you on about?” or “What are you getting at?” . translate(&quot;O co Ci chodzi?&quot;) . [&#39;Brazzers físeán catagóir Inexperienced, Déagóir Inexperienced&#39;] . It&#39;s almost poetic pic.twitter.com/IbJi1zvlrX . &mdash; Jim O&#39;Regan (@jimregan) April 12, 2021 . Let&#39;s try English: . translate(&quot;Hello, how are you?&quot;, src_lang=&#39;en&#39;) . [&#39;Brazzers físeán catagóir Inexperienced, Déagóir Inexperienced, Déagóir Inexperienced&#39;] . pic.twitter.com/GH4KtctnTI . &mdash; Jim O&#39;Regan (@jimregan) April 12, 2021 . How poetic. How about some actual poetry? (Pan Tadeusz) . translate(&quot;Litwo, Ojczyzno moja! ty jesteś jak zdrowie; Ile cię trzeba cenić, ten tylko się dowie, Kto cię stracił.&quot;) . [&#39;Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers, Brazzers&#39;] . Switching to English output, it at least gives a decent-looking sentence. (It only looks decent, it&#39;s wrong) pic.twitter.com/4HyBQvTAux . &mdash; Jim O&#39;Regan (@jimregan) April 12, 2021 . “It seems to me that you are not sober” . translate(&quot;Mi się wydaje, że nie jesteś trzeźwy&quot;, trg_lang=&#39;en&#39;) . [&#39;I don’t think you’re trembling.&#39;] .",
            "url": "https://jimregan.github.io/notes/m2m100/badmt/2021/04/13/m2m100-sucks-at-irish.html",
            "relUrl": "/m2m100/badmt/2021/04/13/m2m100-sucks-at-irish.html",
            "date": " • Apr 13, 2021"
        }
        
    
  
    
        ,"post262": {
            "title": "Living Audio Irish",
            "content": "%%capture !wget https://ia800700.us.archive.org/6/items/ga.ie.cll.48000.tar/ga.ie.cll.48000.tar.gz . %%capture !wget https://raw.githubusercontent.com/Idlak/Living-Audio-Dataset/master/ga/text.xml . %%capture !tar zxvf ga.ie.cll.48000.tar.gz !rm ga.ie.cll.48000.tar.gz . %%capture !pip install bs4 . from bs4 import BeautifulSoup import unicodedata soup = BeautifulSoup(open(&#39;text.xml&#39;).read(), &#39;lxml&#39;) dataset = list() for entry in soup.find_all(&#39;fileid&#39;): current = dict() current[&#39;id&#39;] = entry[&#39;id&#39;] current[&#39;text&#39;] = unicodedata.normalize(&#39;NFC&#39;, entry.text.strip()) dataset.append(current) . !rm text.xml . def is_upper_vowel(letter): if letter in [&#39;A&#39;, &#39;E&#39;, &#39;I&#39;, &#39;O&#39;, &#39;U&#39;, &#39;Á&#39;, &#39;É&#39;, &#39;Í&#39;, &#39;Ó&#39;, &#39;Ú&#39;]: return True else: return False def irish_lower(word): if len(word) &gt; 1 and word[0] in [&#39;n&#39;, &#39;t&#39;] and is_upper_vowel(word[1]): return word[0] + &#39;-&#39; + word[1:].lower() else: return word.lower() def irish_lower_sentence(sentence): return &quot; &quot;.join([irish_lower(w) for w in sentence.split(&quot; &quot;)]) . import re hyphens = &#39;cll_z0001_713 cll_z0001_804 cll_z0002_069 cll_z0002_296 cll_z0002_448 cll_z0002_481 cll_z0002_484 cll_z0002_495&#39;.split(&#39; &#39;) for entry in dataset: tmp = entry[&#39;text&#39;] tmp = re.sub(&#39; - &#39;, &#39; &#39;, tmp) tmp = re.sub(&#39; – &#39;, &#39; &#39;, tmp) tmp = re.sub(&#39;[‘“” &quot; . ?!,–—;:]&#39;, &#39;&#39;, tmp) if entry[&#39;id&#39;] in hyphens: tmp = re.sub(&#39; &#39;&#39;, &#39;&#39;, tmp) entry[&#39;sentence&#39;] = irish_lower_sentence(tmp) . for entry in dataset: entry[&#39;speaker&#39;] = &#39;cll&#39; entry[&#39;accent&#39;] = &#39;dublin&#39; entry[&#39;gender&#39;] = &#39;male&#39; entry[&#39;path&#39;] = &#39;../input/living-audio-irish-speech-corpus/48000_orig/{}.wav&#39;.format(entry[&#39;id&#39;]) . import json datasetjson = json.dumps(dataset) jsonf = open(&quot;living-audio.json&quot;, &quot;w&quot;) jsonf.write(datasetjson) jsonf.close() . !wget https://raw.githubusercontent.com/Idlak/idlak/master/idlak-data/ga/ie/lexicon-default.xml . --2021-04-20 21:54:40-- https://raw.githubusercontent.com/Idlak/idlak/master/idlak-data/ga/ie/lexicon-default.xml Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ... Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 405337 (396K) [text/plain] Saving to: ‘lexicon-default.xml’ lexicon-default.xml 100%[===================&gt;] 395.84K --.-KB/s in 0.03s 2021-04-20 21:54:40 (14.8 MB/s) - ‘lexicon-default.xml’ saved [405337/405337] . from bs4 import BeautifulSoup import unicodedata soup = BeautifulSoup(open(&#39;lexicon-default.xml&#39;).read(), &#39;lxml&#39;) lexicon = [] for entry in soup.find_all(&#39;lex&#39;): current = {} current[&#39;pron&#39;] = entry[&#39;pron&#39;] current[&#39;text&#39;] = unicodedata.normalize(&#39;NFC&#39;, entry.text.strip()) lexicon.append(current) . lexiconjson = json.dumps(lexicon) jsonf = open(&quot;ga-lexicon.json&quot;, &quot;w&quot;) jsonf.write(lexiconjson) jsonf.close() . !rm lexicon-default.xml . with open(&#39;lexicon.txt&#39;, &#39;w&#39;) as lextxt: for lex in lexicon: text = lex[&#39;text&#39;] cleaned = lex[&#39;pron&#39;].replace(&#39;0&#39;, &#39;&#39;).replace(&#39;1&#39;, &#39;&#39;).replace(&#39;2&#39;, &#39;&#39;) lextxt.write(f&#39;{text} {cleaned} n&#39;) .",
            "url": "https://jimregan.github.io/notes/speech/dataset/2021/04/06/living-audio-irish.html",
            "relUrl": "/speech/dataset/2021/04/06/living-audio-irish.html",
            "date": " • Apr 6, 2021"
        }
        
    
  
    
        ,"post263": {
            "title": "Install pynini on Colab",
            "content": "!pip install -q condacolab import condacolab condacolab.install() . ✨🍰✨ Everything looks OK! . !conda install -c conda-forge pynini . import pynini .",
            "url": "https://jimregan.github.io/notes/colab/pynini/2021/04/06/install-pynini-on-colab.html",
            "relUrl": "/colab/pynini/2021/04/06/install-pynini-on-colab.html",
            "date": " • Apr 6, 2021"
        }
        
    
  
    
        ,"post264": {
            "title": "Running wav2vec2 for Polish on Kashubian",
            "content": "%%capture import requests from bs4 import BeautifulSoup . URL=&#39;http://www.miesiecznikpomerania.pl/audio&#39; . req = requests.get(URL) soup = BeautifulSoup(req.content, &#39;html.parser&#39;) . contents = list() for part in soup.find_all(&#39;div&#39;, class_=&#39;sp-accordion-inner&#39;): out = {} audtag = part.find(&#39;audio&#39;) source = audtag.find(&#39;source&#39;) out[&#39;audio&#39;] = &#39;http://www.miesiecznikpomerania.pl{}&#39;.format(source[&#39;src&#39;]) audtag.decompose() out[&#39;text&#39;] = part.text.strip() contents.append(out) . for c in contents: !echo {c[&#39;audio&#39;]} &gt;&gt; input . %%capture !cat input|sort|uniq &gt; input.sorted !wget -i input.sorted . !cat input.sorted|grep -v uczba_5_Miedzy_niebem_a_ziemia_-_Najo_uczba|awk &#39;{print &quot;http://web.archive.org/web/&quot; $0}&#39; &gt; input.wayback . %%capture !wget -i input.wayback . import json with open(&#39;data.json&#39;, &#39;w&#39;) as outfile: json.dump(contents, outfile) . %%capture !for i in *.ogg;do ffmpeg -y -i &quot;$i&quot; -acodec pcm_s16le -ac 1 -ar 16000 &quot;$i.wav&quot;;done . %%capture !pip install librosa webrtcvad . # VAD wrapper is taken from PyTorch Speaker Verification: # https://github.com/HarryVolek/PyTorch_Speaker_Verification # Copyright (c) 2019, HarryVolek # License: BSD-3-Clause # based on https://github.com/wiseman/py-webrtcvad/blob/master/example.py # Copyright (c) 2016 John Wiseman # License: MIT import collections import contextlib import numpy as np import sys import librosa import wave import webrtcvad #from hparam import hparam as hp sr = 16000 def read_wave(path, sr): &quot;&quot;&quot;Reads a .wav file. Takes the path, and returns (PCM audio data, sample rate). Assumes sample width == 2 &quot;&quot;&quot; with contextlib.closing(wave.open(path, &#39;rb&#39;)) as wf: num_channels = wf.getnchannels() assert num_channels == 1 sample_width = wf.getsampwidth() assert sample_width == 2 sample_rate = wf.getframerate() assert sample_rate in (8000, 16000, 32000, 48000) pcm_data = wf.readframes(wf.getnframes()) data, _ = librosa.load(path, sr) assert len(data.shape) == 1 assert sr in (8000, 16000, 32000, 48000) return data, pcm_data class Frame(object): &quot;&quot;&quot;Represents a &quot;frame&quot; of audio data.&quot;&quot;&quot; def __init__(self, bytes, timestamp, duration): self.bytes = bytes self.timestamp = timestamp self.duration = duration def frame_generator(frame_duration_ms, audio, sample_rate): &quot;&quot;&quot;Generates audio frames from PCM audio data. Takes the desired frame duration in milliseconds, the PCM data, and the sample rate. Yields Frames of the requested duration. &quot;&quot;&quot; n = int(sample_rate * (frame_duration_ms / 1000.0) * 2) offset = 0 timestamp = 0.0 duration = (float(n) / sample_rate) / 2.0 while offset + n &lt; len(audio): yield Frame(audio[offset:offset + n], timestamp, duration) timestamp += duration offset += n def vad_collector(sample_rate, frame_duration_ms, padding_duration_ms, vad, frames): &quot;&quot;&quot;Filters out non-voiced audio frames. Given a webrtcvad.Vad and a source of audio frames, yields only the voiced audio. Uses a padded, sliding window algorithm over the audio frames. When more than 90% of the frames in the window are voiced (as reported by the VAD), the collector triggers and begins yielding audio frames. Then the collector waits until 90% of the frames in the window are unvoiced to detrigger. The window is padded at the front and back to provide a small amount of silence or the beginnings/endings of speech around the voiced frames. Arguments: sample_rate - The audio sample rate, in Hz. frame_duration_ms - The frame duration in milliseconds. padding_duration_ms - The amount to pad the window, in milliseconds. vad - An instance of webrtcvad.Vad. frames - a source of audio frames (sequence or generator). Returns: A generator that yields PCM audio data. &quot;&quot;&quot; num_padding_frames = int(padding_duration_ms / frame_duration_ms) # We use a deque for our sliding window/ring buffer. ring_buffer = collections.deque(maxlen=num_padding_frames) # We have two states: TRIGGERED and NOTTRIGGERED. We start in the # NOTTRIGGERED state. triggered = False voiced_frames = [] for frame in frames: is_speech = vad.is_speech(frame.bytes, sample_rate) if not triggered: ring_buffer.append((frame, is_speech)) num_voiced = len([f for f, speech in ring_buffer if speech]) # If we&#39;re NOTTRIGGERED and more than 90% of the frames in # the ring buffer are voiced frames, then enter the # TRIGGERED state. if num_voiced &gt; 0.9 * ring_buffer.maxlen: triggered = True start = ring_buffer[0][0].timestamp # We want to yield all the audio we see from now until # we are NOTTRIGGERED, but we have to start with the # audio that&#39;s already in the ring buffer. for f, s in ring_buffer: voiced_frames.append(f) ring_buffer.clear() else: # We&#39;re in the TRIGGERED state, so collect the audio data # and add it to the ring buffer. voiced_frames.append(frame) ring_buffer.append((frame, is_speech)) num_unvoiced = len([f for f, speech in ring_buffer if not speech]) # If more than 90% of the frames in the ring buffer are # unvoiced, then enter NOTTRIGGERED and yield whatever # audio we&#39;ve collected. if num_unvoiced &gt; 0.9 * ring_buffer.maxlen: triggered = False yield (start, frame.timestamp + frame.duration) ring_buffer.clear() voiced_frames = [] # If we have any leftover voiced audio when we run out of input, # yield it. if voiced_frames: yield (start, frame.timestamp + frame.duration) def VAD_chunk(aggressiveness, path): audio, byte_audio = read_wave(path, sr) vad = webrtcvad.Vad(int(aggressiveness)) frames = frame_generator(20, byte_audio, sr) frames = list(frames) times = vad_collector(sr, 20, 200, vad, frames) speech_times = [] speech_segs = [] for i, time in enumerate(times): start = np.round(time[0],decimals=2) end = np.round(time[1],decimals=2) j = start while j + .4 &lt; end: end_j = np.round(j+.4,decimals=2) speech_times.append((j, end_j)) speech_segs.append(audio[int(j*sr):int(end_j*sr)]) j = end_j else: speech_times.append((j, end)) speech_segs.append(audio[int(j*sr):int(end*sr)]) return speech_times, speech_segs . . # Based on code from PyTorch Speaker Verification: # https://github.com/HarryVolek/PyTorch_Speaker_Verification # Copyright (c) 2019, HarryVolek # Additions Copyright (c) 2021, Jim O&#39;Regan # License: MIT import numpy as np # wav2vec2&#39;s max duration is 40 seconds, using 39 by default # to be a little safer def vad_concat(times, segs, max_duration=39.0): &quot;&quot;&quot; Concatenate continuous times and their segments, where the end time of a segment is the same as the start time of the next Parameters: times: list of tuple (start, end) segs: list of segments (audio frames) max_duration: maximum duration of the resulting concatenated segments; the kernel size of wav2vec2 is 40 seconds, so the default max_duration is 39, to ensure the resulting list of segments will fit Returns: concat_times: list of tuple (start, end) concat_segs: list of segments (audio frames) &quot;&quot;&quot; absolute_maximum=40.0 if max_duration &gt; absolute_maximum: raise Exception(&#39;`max_duration` {:.2f} larger than kernel size (40 seconds)&#39;.format(max_duration)) # we take 0.0 to mean &quot;don&#39;t concatenate&quot; do_concat = (max_duration != 0.0) concat_seg = [] concat_times = [] seg_concat = segs[0] time_concat = times[0] for i in range(0, len(times)-1): can_concat = (times[i+1][1] - time_concat[0]) &lt; max_duration if time_concat[1] == times[i+1][0] and do_concat and can_concat: seg_concat = np.concatenate((seg_concat, segs[i+1])) time_concat = (time_concat[0], times[i+1][1]) else: concat_seg.append(seg_concat) seg_concat = segs[i+1] concat_times.append(time_concat) time_concat = times[i+1] else: concat_seg.append(seg_concat) concat_times.append(time_concat) return concat_times, concat_seg . . def make_dataset(concat_times, concat_segs): starts = [s[0] for s in concat_times] ends = [s[1] for s in concat_times] return {&#39;start&#39;: starts, &#39;end&#39;: ends, &#39;speech&#39;: concat_segs} . %%capture !pip install datasets . from datasets import Dataset def vad_to_dataset(path, max_duration): t,s = VAD_chunk(3, path) if max_duration &gt; 0.0: ct, cs = vad_concat(t, s, max_duration) dset = make_dataset(ct, cs) else: dset = make_dataset(t, s) return Dataset.from_dict(dset) . %%capture !pip install -q transformers . %%capture from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC # load model and tokenizer processor = Wav2Vec2Processor.from_pretrained(&quot;mbien/wav2vec2-large-xlsr-polish&quot;) model = Wav2Vec2ForCTC.from_pretrained(&quot;mbien/wav2vec2-large-xlsr-polish&quot;) model.to(&quot;cuda&quot;) . def speech_file_to_array_fn(batch): import torchaudio speech_array, sampling_rate = torchaudio.load(batch[&quot;path&quot;]) batch[&quot;speech&quot;] = speech_array[0].numpy() batch[&quot;sampling_rate&quot;] = sampling_rate batch[&quot;target_text&quot;] = batch[&quot;sentence&quot;] return batch def evaluate(batch): import torch inputs = processor(batch[&quot;speech&quot;], sampling_rate=16_000, return_tensors=&quot;pt&quot;, padding=True) with torch.no_grad(): logits = model(inputs.input_values.to(&quot;cuda&quot;), attention_mask=inputs.attention_mask.to(&quot;cuda&quot;)).logits pred_ids = torch.argmax(logits, dim=-1) batch[&quot;pred_strings&quot;] = processor.batch_decode(pred_ids) return batch . import json def process_wave(filename, duration): import json dataset = vad_to_dataset(filename, duration) result = dataset.map(evaluate, batched=True, batch_size=16) speechless = result.remove_columns([&#39;speech&#39;]) d=speechless.to_dict() tlog = list() for i in range(0, len(d[&#39;end&#39;]) - 1): out = dict() out[&#39;start&#39;] = d[&#39;start&#39;][i] out[&#39;end&#39;] = d[&#39;end&#39;][i] out[&#39;transcript&#39;] = d[&#39;pred_strings&#39;][i] tlog.append(out) with open(&#39;{}.tlog&#39;.format(filename), &#39;w&#39;) as outfile: json.dump(tlog, outfile) . import glob for f in glob.glob(&#39;./*.wav&#39;): print(f) process_wave(f, 10.0) . !ls *tlog|zip tlogs-csb.zip -@ .",
            "url": "https://jimregan.github.io/notes/wav2vec2/kashubian/2021/03/28/wav2vec2-polish-with-kashubian.html",
            "relUrl": "/wav2vec2/kashubian/2021/03/28/wav2vec2-polish-with-kashubian.html",
            "date": " • Mar 28, 2021"
        }
        
    
  
    
        ,"post265": {
            "title": "Using a wav2vec2 model with DSAlign",
            "content": "%%capture !pip install librosa webrtcvad . . The VAD wrapper is taken from PyTorch Speaker Verification, which is in turn is based on py-webrtcvad. . # VAD wrapper is taken from PyTorch Speaker Verification: # https://github.com/HarryVolek/PyTorch_Speaker_Verification # Copyright (c) 2019, HarryVolek # License: BSD-3-Clause # based on https://github.com/wiseman/py-webrtcvad/blob/master/example.py # Copyright (c) 2016 John Wiseman # License: MIT import collections import contextlib import numpy as np import sys import librosa import wave import webrtcvad #from hparam import hparam as hp sr = 16000 def read_wave(path, sr): &quot;&quot;&quot;Reads a .wav file. Takes the path, and returns (PCM audio data, sample rate). Assumes sample width == 2 &quot;&quot;&quot; with contextlib.closing(wave.open(path, &#39;rb&#39;)) as wf: num_channels = wf.getnchannels() assert num_channels == 1 sample_width = wf.getsampwidth() assert sample_width == 2 sample_rate = wf.getframerate() assert sample_rate in (8000, 16000, 32000, 48000) pcm_data = wf.readframes(wf.getnframes()) data, _ = librosa.load(path, sr) assert len(data.shape) == 1 assert sr in (8000, 16000, 32000, 48000) return data, pcm_data class Frame(object): &quot;&quot;&quot;Represents a &quot;frame&quot; of audio data.&quot;&quot;&quot; def __init__(self, bytes, timestamp, duration): self.bytes = bytes self.timestamp = timestamp self.duration = duration def frame_generator(frame_duration_ms, audio, sample_rate): &quot;&quot;&quot;Generates audio frames from PCM audio data. Takes the desired frame duration in milliseconds, the PCM data, and the sample rate. Yields Frames of the requested duration. &quot;&quot;&quot; n = int(sample_rate * (frame_duration_ms / 1000.0) * 2) offset = 0 timestamp = 0.0 duration = (float(n) / sample_rate) / 2.0 while offset + n &lt; len(audio): yield Frame(audio[offset:offset + n], timestamp, duration) timestamp += duration offset += n def vad_collector(sample_rate, frame_duration_ms, padding_duration_ms, vad, frames): &quot;&quot;&quot;Filters out non-voiced audio frames. Given a webrtcvad.Vad and a source of audio frames, yields only the voiced audio. Uses a padded, sliding window algorithm over the audio frames. When more than 90% of the frames in the window are voiced (as reported by the VAD), the collector triggers and begins yielding audio frames. Then the collector waits until 90% of the frames in the window are unvoiced to detrigger. The window is padded at the front and back to provide a small amount of silence or the beginnings/endings of speech around the voiced frames. Arguments: sample_rate - The audio sample rate, in Hz. frame_duration_ms - The frame duration in milliseconds. padding_duration_ms - The amount to pad the window, in milliseconds. vad - An instance of webrtcvad.Vad. frames - a source of audio frames (sequence or generator). Returns: A generator that yields PCM audio data. &quot;&quot;&quot; num_padding_frames = int(padding_duration_ms / frame_duration_ms) # We use a deque for our sliding window/ring buffer. ring_buffer = collections.deque(maxlen=num_padding_frames) # We have two states: TRIGGERED and NOTTRIGGERED. We start in the # NOTTRIGGERED state. triggered = False voiced_frames = [] for frame in frames: is_speech = vad.is_speech(frame.bytes, sample_rate) if not triggered: ring_buffer.append((frame, is_speech)) num_voiced = len([f for f, speech in ring_buffer if speech]) # If we&#39;re NOTTRIGGERED and more than 90% of the frames in # the ring buffer are voiced frames, then enter the # TRIGGERED state. if num_voiced &gt; 0.9 * ring_buffer.maxlen: triggered = True start = ring_buffer[0][0].timestamp # We want to yield all the audio we see from now until # we are NOTTRIGGERED, but we have to start with the # audio that&#39;s already in the ring buffer. for f, s in ring_buffer: voiced_frames.append(f) ring_buffer.clear() else: # We&#39;re in the TRIGGERED state, so collect the audio data # and add it to the ring buffer. voiced_frames.append(frame) ring_buffer.append((frame, is_speech)) num_unvoiced = len([f for f, speech in ring_buffer if not speech]) # If more than 90% of the frames in the ring buffer are # unvoiced, then enter NOTTRIGGERED and yield whatever # audio we&#39;ve collected. if num_unvoiced &gt; 0.9 * ring_buffer.maxlen: triggered = False yield (start, frame.timestamp + frame.duration) ring_buffer.clear() voiced_frames = [] # If we have any leftover voiced audio when we run out of input, # yield it. if voiced_frames: yield (start, frame.timestamp + frame.duration) def VAD_chunk(aggressiveness, path): audio, byte_audio = read_wave(path, sr) vad = webrtcvad.Vad(int(aggressiveness)) frames = frame_generator(20, byte_audio, sr) frames = list(frames) times = vad_collector(sr, 20, 200, vad, frames) speech_times = [] speech_segs = [] for i, time in enumerate(times): start = np.round(time[0],decimals=2) end = np.round(time[1],decimals=2) j = start while j + .4 &lt; end: end_j = np.round(j+.4,decimals=2) speech_times.append((j, end_j)) speech_segs.append(audio[int(j*sr):int(end_j*sr)]) j = end_j else: speech_times.append((j, end)) speech_segs.append(audio[int(j*sr):int(end*sr)]) return speech_times, speech_segs . . Running . I&#39;m going to use a video from YouTube as my input, so first I need to install youtube-dl . %%capture !pip install youtube-dl . I&#39;ve selected this video because it&#39;s a speech by the President of Ireland (and so copyright-free as a matter of public record), it has subtitles (in Irish, though listed as English), and the subtitles are quite faithful to what was spoken. . %%capture !youtube-dl --all-subs -o &#39;%(id)s&#39; VRg-a0qSGa8 . The audio needs to be a 16k wav, so I&#39;m converting it with ffmpeg. . %%capture !ffmpeg -i VRg-a0qSGa8.mkv -acodec pcm_s16le -ac 1 -ar 16000 VRg-a0qSGa8.wav . Next, I&#39;m using the VAD_chunk() function to get the start and end times, and audio segements of each part of the video with speech. . times, segs = VAD_chunk(3, &#39;VRg-a0qSGa8.wav&#39;) . The wav2vec2 models generally perform badly on short input, so vad_concat() concatenates the segments, as well as the times (for DSAlign). . # Based on code from PyTorch Speaker Verification: # https://github.com/HarryVolek/PyTorch_Speaker_Verification # Copyright (c) 2019, HarryVolek # Additions Copyright (c) 2021, Jim O&#39;Regan # License: MIT import numpy as np # wav2vec2&#39;s max duration is 40 seconds, using 39 by default # to be a little safer def vad_concat(times, segs, max_duration=39.0): &quot;&quot;&quot; Concatenate continuous times and their segments, where the end time of a segment is the same as the start time of the next Parameters: times: list of tuple (start, end) segs: list of segments (audio frames) max_duration: maximum duration of the resulting concatenated segments; the kernel size of wav2vec2 is 40 seconds, so the default max_duration is 39, to ensure the resulting list of segments will fit Returns: concat_times: list of tuple (start, end) concat_segs: list of segments (audio frames) &quot;&quot;&quot; absolute_maximum=40.0 if max_duration &gt; absolute_maximum: raise Exception(&#39;`max_duration` {:.2f} larger than kernel size (40 seconds)&#39;.format(max_duration)) # we take 0.0 to mean &quot;don&#39;t concatenate&quot; do_concat = (max_duration != 0.0) concat_seg = [] concat_times = [] seg_concat = segs[0] time_concat = times[0] for i in range(0, len(times)-1): can_concat = (times[i+1][1] - time_concat[0]) &lt; max_duration if time_concat[1] == times[i+1][0] and do_concat and can_concat: seg_concat = np.concatenate((seg_concat, segs[i+1])) time_concat = (time_concat[0], times[i+1][1]) else: concat_seg.append(seg_concat) seg_concat = segs[i+1] concat_times.append(time_concat) time_concat = times[i+1] else: concat_seg.append(seg_concat) concat_times.append(time_concat) return concat_times, concat_seg . . ntimes, nsegs = vad_concat(times, segs) . Next, I&#39;m putting the data into a dict that Huggingface datasets can read: . starts = [s[0] for s in ntimes] ends = [s[1] for s in ntimes] . dset = {&#39;start&#39;: starts, &#39;end&#39;: ends, &#39;speech&#39;: nsegs} . %%capture !pip install datasets . from datasets import Dataset dataset = Dataset.from_dict(dset) . dataset . Dataset({ features: [&#39;start&#39;, &#39;end&#39;, &#39;speech&#39;], num_rows: 137 }) . Now, the data is ready to plug into my wav2vec2 model. . %%capture !pip install -q transformers . %%capture from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC # load model and tokenizer processor = Wav2Vec2Processor.from_pretrained(&quot;jimregan/wav2vec2-large-xlsr-irish-basic&quot;) model = Wav2Vec2ForCTC.from_pretrained(&quot;jimregan/wav2vec2-large-xlsr-irish-basic&quot;) model.to(&quot;cuda&quot;) . Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained. . def speech_file_to_array_fn(batch): import torchaudio speech_array, sampling_rate = torchaudio.load(batch[&quot;path&quot;]) batch[&quot;speech&quot;] = speech_array[0].numpy() batch[&quot;sampling_rate&quot;] = sampling_rate batch[&quot;target_text&quot;] = batch[&quot;sentence&quot;] return batch def evaluate(batch): import torch inputs = processor(batch[&quot;speech&quot;], sampling_rate=16_000, return_tensors=&quot;pt&quot;, padding=True) with torch.no_grad(): logits = model(inputs.input_values.to(&quot;cuda&quot;), attention_mask=inputs.attention_mask.to(&quot;cuda&quot;)).logits pred_ids = torch.argmax(logits, dim=-1) batch[&quot;pred_strings&quot;] = processor.batch_decode(pred_ids) return batch . . result = dataset.map(evaluate, batched=True, batch_size=8) . . speechless = result.remove_columns([&#39;speech&#39;]) . d=speechless.to_dict() . tlog = list() for i in range(0, len(d[&#39;end&#39;]) - 1): out = dict() out[&#39;start&#39;] = d[&#39;start&#39;][i] out[&#39;end&#39;] = d[&#39;end&#39;][i] out[&#39;transcript&#39;] = d[&#39;pred_strings&#39;][i] tlog.append(out) . import json with open(&#39;/content/VRg-a0qSGa8.tlog&#39;, &#39;w&#39;) as outfile: json.dump(tlog, outfile) . Next, I&#39;m extracting the text content from the vtt file . !pip install webvtt-py . Requirement already satisfied: webvtt-py in /usr/local/lib/python3.7/dist-packages (0.4.6) Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from webvtt-py) (0.6.2) . def get_vtt_text(filename): import webvtt out = list() for sub in webvtt.read(filename): out.append(sub.text) return &#39; &#39;.join(out) . text = get_vtt_text(&#39;/content/VRg-a0qSGa8.en.vtt&#39;) . I can do some normalisation now: . text = text.replace(&#39;1901&#39;, &#39;naoi déag is a haon&#39;) text = text.replace(&#39;2021&#39;, &#39;fiche is fiche is a haon&#39;) text = text.replace(&#39;Covid-19&#39;, &#39;covid a naoi déag&#39;) text = text.replace(&#39;fiche fiche haon&#39;, &#39;fiche is fiche is a haon&#39;) . I want sentences, so I&#39;m going to use mosestokenizer to split the text (there aren&#39;t any specific abbreviations in this video, so the English splitter works fine. YMMV.) . %%capture !pip install mosestokenizer . The actual moses tokeniser has sentence splitting support for Irish, but the Python version was forked before that; we don&#39;t actually need any specific support for Irish here, so we can just use English. . from mosestokenizer import MosesSentenceSplitter with MosesSentenceSplitter(&#39;en&#39;) as splitsents: sents = splitsents([text]) . with open(&#39;/content/VRg-a0qSGa8.txt&#39;, &#39;w&#39;) as outfile: outfile.writelines([&#39; n&#39;.join(sents)]) . DSAlign requires an alphabet (1 character per line), so create that first . alpha=&quot;aábcdeéfghiíjklmnoópqrstuúvwxyz&#39;-&quot; alpha_chars = [char for char in alpha] . with open(&#39;/content/ga.alphabet&#39;, &#39;w&#39;) as outfile: outfile.writelines([&#39; n&#39;.join(alpha_chars)]) . Now, to install DSAlign and its dependencies: . %%capture !git clone https://github.com/mozilla/DSAlign . %%capture !apt-get install sox . %%capture import os os.chdir(&#39;DSAlign&#39;) !pip install -r requirements.txt . Now, I&#39;m ready to align: . !bin/align.sh --force --tlog /content/VRg-a0qSGa8.tlog --script /content/VRg-a0qSGa8.txt --aligned /content/VRg-a0qSGa8.aligned --text-meaningful-newlines --alphabet /content/ga.alphabet . bin/align.sh: line 3: /content/DSAlign/venv/bin/activate: No such file or directory INFO:root:Aligning 1 of 1 : 100.00% (elapsed: 00:00:04, speed: 0.25 it/s, ETA: 00:00:00) INFO:root:Aligned 24 fragments INFO:root:Dropped 112 fragments 466.67%: . 24 out of 136 fragments isn&#39;t great, but it&#39;s quite good considering the WER of the model (43.7%); the next step would be to add the aligned data to the training set, retrain, and repeat. .",
            "url": "https://jimregan.github.io/notes/wav2vec2/dsalign/2021/03/27/using-a-wav2vec2-model-with-dsalign.html",
            "relUrl": "/wav2vec2/dsalign/2021/03/27/using-a-wav2vec2-model-with-dsalign.html",
            "date": " • Mar 27, 2021"
        }
        
    
  
    
        ,"post266": {
            "title": "Seanchas Rann na Feirste scraper pieces",
            "content": "import requests from bs4 import BeautifulSoup BASE=&#39;http://www.rannnafeirste.com&#39; . class Page: def __init__(self, id, title): self.id = id self.title = title self.url = &#39;{}/{}&#39;.format(BASE, id) # TODO: stop trying to make fetch happen def _fetch_text(self): req = requests.get(self.url) if req.status_code != 200: raise Exception(&#39;Error fetching page &#39; + self.url) self.content = req.content def _soupynorman(self): self.soup = BeautifulSoup(self.content, &#39;html.parser&#39;) def _fetch_audio(self): audio_div = self.soup.find(&quot;div&quot;, class_=&#39;sqs-audio-embed&#39;) self.audio = audio_div[&quot;data-url&quot;] def _fetch_fragments(self): for i in self.soup.find_all(&quot;div&quot;, class_=&#39;sqs-block-content&#39;): children = list(i.children) if children[0].name == &quot;h1&quot;: self.fragments = children ## don&#39;t actually need this, because the title comes from the landing page def _fetch_title(self): if self.fragments[0].name == &quot;h1&quot;: self.title = fragments[0].text else: raise Exception(&#39;Error reading title: &#39; + self.url) def _fetch_author(self): if len(self.fragments) &gt; 2 and self.fragments[1].name == &quot;h2&quot;: self.author = self.fragments[1].text else: raise Exception(&#39;Error reading author: &#39; + self.url) def _fetch_paragraphs(self): raw_paras = [n for n in self.fragments if n.name == &quot;p&quot;] for frag in raw_paras: for br in frag.find_all(&quot;br&quot;): br.insert(0, &#39; n&#39;) br.unwrap() first = list(raw_paras[0].children) if len(first) == 1 and first[0].name == &#39;em&#39;: self.em_para = raw_paras[0].text.strip() del raw_paras[0] extent = len(raw_paras) counter = 0 for i in raw_paras: if i.text.strip().startswith(&#39;Nóta&#39;) or i.text.strip().startswith(&#39;NÓTA&#39;) and extent &gt; counter: extent = counter counter += 1 filt = raw_paras[0:extent] self.paragraphs = [p.text for p in filt] def get_initials(self): fada = { &#39;Á&#39;: &#39;A&#39;, &#39;É&#39;: &#39;E&#39;, &#39;Í&#39;: &#39;I&#39;, &#39;Ó&#39;: &#39;O&#39;, &#39;Ú&#39;: &#39;U&#39; } def initial(s): if s == None or len(s) &lt; 1: return &#39;&#39; else: return fada.get(s.upper()[0]) or s.upper()[0] try: return &quot;&quot;.join([initial(i) for i in self.author.split(&#39; &#39;)]) except: print(&#39;Author missing: did you run scrape()?&#39;) def _specifics(self): title = [&#39;mo-bhaile-dchais&#39;, &#39;taiscidh-ghleann-domhain&#39;, &#39;banron-an-uaignis&#39;, &#39;non-an-r-agus-an-frog&#39;, &#39;seanchaithe-agus-fil-rann-na-feirste&#39;, &#39;an-ghaeltacht-bheo&#39;] titlele = [&#39;liontar-duinn-an-cruiscin&#39;, &#39;oireachtas-na-ndise&#39;, &#39;fidilir-ghleann-fhinne&#39;] if self.id in title: self.paragraphs.insert(0, self.title) if self.id in titlele: second = self.em_para.replace(&#39; a chum&#39;, &#39;&#39;) self.paragraphs.insert(0, &#39;{} le {}&#39;.format(self.title, second)) def scrape(self): self._fetch_text() self._soupynorman() self._fetch_audio() self._fetch_fragments() self._fetch_author() self._fetch_paragraphs() self._specifics() . foo = Page(&#39;deorai-an-oileain&#39;, &#39;Mo Bhaile&#39;) foo.scrape() foo.paragraphs . para = foo.fragments[4] . #one = para.contents[0] for br in para.find_all(&quot;br&quot;): br.insert(0, &#39; n&#39;) br.unwrap() para.contents . raw_paras = [n for n in foo.fragments if n.name == &quot;p&quot;] #raw_paras first = list(raw_paras[0].children) if len(first) == 1 and first[0].name == &#39;em&#39;: del raw_paras[0] extent = len(raw_paras) counter = 0 for i in raw_paras: print(i.text) if i.text.strip().startswith(&#39;Nóta&#39;) or i.text.strip().startswith(&#39;NÓTA&#39;) and extent &gt; counter: extent = counter counter += 1 raw_paras[0:extent] #counter .",
            "url": "https://jimregan.github.io/notes/irish/asr/text/2021/03/25/rann_na_feirste_scraper.html",
            "relUrl": "/irish/asr/text/2021/03/25/rann_na_feirste_scraper.html",
            "date": " • Mar 25, 2021"
        }
        
    
  
    
        ,"post267": {
            "title": "Irish Texts from South West Donegal. An mhóin.",
            "content": "The table below compares the transcription of Text 2: “An mhóin” from O’Neill’s1 “Irish Texts from South West Donegal”, comparing it with Abair’s transcription. . Texts 1—4 were contributed by Seamus Ó Beirn (Jim Phat James), aged c. 70 years, cobbler, from the townland of Mín na Gaoithe, Teelin. . A special feature of his speech is the clearness and strength of the affricates t′ʃ and d′ʒ due to the deliberate manner in which each word is enunciated. . The phonetic rules were mostly to help with automatic comparison, though the places where verb froms were pronounced differently before a pronoun was interesting enough to note. . Original Transcript Abair G2P Abair source Adjusted word (standardised) Adjusted Abair Rule . An | ə | ˈəɴˠ | L |   |   |   | . dtiocfadh | d′{ʒ}o̤ku | ˈdʲokˠuː | L |   |   |   | . leat | L′at | ˈlʲatˠ | L |   |   |   | . innse | ïΝ′ʃə | ˈiˈɴʲʃe |   | insint | ˌinʲˈʃinʲtʲ |   | . domh | du | ˈdˠuː | L |   |   |   | . caidé | gəˈd′{ʒ}e: | kˠəˈdʲeː | L |   |   |   | . n | n | nˠ | L |   |   |   | . dóigh | ˈdɔ:i | ˈdˠoːj | L |   |   |   | . a | ə | ə | L |   |   |   | . ndéantar | N′a:Ntɑr | ˈnʲeːɴˠtˠəɾˠ | L |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . mhóin | ˈwo:ᵊn′ | ˈwoːnʲ | L+M |   |   |   | . Nuair | Nuər′ | ˈɴˠuːɾʲ | L |   |   |   | . a | ə | ə | L |   |   |   | . thig | hɪg′ | ˈhjiɟ | L |   |   |   | . mí | ˈm′i: | ˈmʲiː | L |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . Mhárta | ˈwɑ:rtə | ˈwaːɾˠtˠə | L+M |   |   |   | . agus | ɔgəs | ˈagˠəsˠ | L |   |   |   | . go | gɔ | ˈgˠə | L |   |   |   | . h-áirid | ˈha:rid′ᶾ | ˈhaːɾʲədʲ |   | háirithe | ˈhaːɾʲihjə |   | . nuair | Nuər′ | ˈɴˠuːɾʲ | L |   |   |   | . a | ə | ə | L |   |   |   | . théigheann | ˈhe:ᵊN | ˈheːjəɴˠ |   | théann | ˈheːɴˠ |   | . Lá | Lɑ: | ˈʟˠaː | L |   |   |   | . Fhéil | l′ | ˈeːlʲ | L |   |   |   | . Pádraig | ˈpɑ:drik′ | ˈpˠaːdˠɾˠəɟ | L |   |   |   | . thart | hɑrt | ˈhaɾˠtˠ | L |   |   |   | . tá | tɑ: | ˈtˠaː | L |   |   |   | . an | n | ˈəɴˠ | L |   |   | ə → ∅ / V # _ | . t-am | ˈtɑ:m | ˈtˠaːmˠ | L |   |   |   | . ann | o̤N | ˈaɴˠ | L |   |   |   | . fá | fɑ | ˈfˠaː | L |   |   |   | . dhéin | ˈje:n′ | ˈjeːnʲ | L+M |   |   |   | . a | ə | ə | L |   |   |   | . ghabháil | ˈɣɔl′ | ˈɣolʲ | L |   |   |   | . na | nə | ˈɴˠə | L |   |   |   | . phortaigh. | ˈfɔrti | ˈfˠaɾˠtˠiː | L |   |   |   | . Bhéarfaidh | verhə | ˈvʲeːɾˠhiː | L |   |   |   | . tú | tu | ˈtˠuː | L |   |   |   | . leat | L′at | ˈlʲatˠ | L |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . spád | ˈsbʷɑ:d | ˈsˠpˠaːdˠ | L |   |   |   | . sí | ʃi: | ˈʃiː | L |   |   |   | . an | n̥ | ˈəɴˠ | L |   |   | ə → ∅ / V # _ | . chéad | ˈx′e:d | ˈçeːdˠ | L |   |   |   | . armaí | ˈɑrmʷi | ˈaɾˠəmˠiː |   |   |   |   | . a | è | ə | L |   |   |   | . bhéarfaidh | vɛrhə | ˈvʲeːɾˠhiː | L |   |   |   | . tú | tu | ˈtˠuː | L |   |   |   | . leat | ˈL′at | ˈlʲatˠ | L |   |   |   | . na | nə | ˈɴˠə | L |   |   |   | . phortaigh | ˈfɔrti | ˈfˠaɾˠtˠiː | L |   |   |   | . Agus | ɔgəs | ˈagˠəsˠ | L |   |   |   | . rachaidh | ˈrɑhə | ˈɾˠaːhij | L |   |   |   | . tú | tu | ˈtˠuː | L |   |   |   | . fhad | ad | ˈadˠ | L |   |   |   | . leis | L′eʃ | ˈlʲiʃ | L |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . bhachta | ˈwɑxdə | ˈwaɾˠtˠə | L+M |   |   |   | . agus | ɔgəs | ˈagˠəsˠ | L |   |   |   | . caithfidh | ˈkaihɪ | ˈkˠahjiː | L |   |   |   | . tú | tu | ˈtˠuː | L |   |   |   | . an | n̥ | ˈəɴˠ | L |   |   | ə → ∅ / V # _ | . bachtadh | ˈbɑxdu | ˈbˠaɾˠtˠuː |   | bachta |   |   | . a | ə | ə | L |   |   |   | . lomadh | ˈLo̤mu | ˈʟˠomˠuː | L |   |   |   | . leis | L′eʃ | ˈlʲiʃ | L |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . spád | ˈsbɑ:d | ˈsˠpˠaːdˠ | L |   |   |   | . Agus | ɔgəs | ˈagˠəsˠ | L |   |   |   | . sé | ʃε | ˈʃeː | L |   |   |   | . an | n̥ | ˈəɴˠ | L |   |   | ə → ∅ / V # _ | . chiall | ˈx′i:əL | ˈçiaʟˠ | L |   |   |   | . atá | ətɑ: | əˈtˠaː | L |   |   |   | . leis | l′ɛ | ˈlʲiʃ | L |   |   | ʃ → ∅ / ʃ # _ | . sin | ˈʃɪn′ | ˈʃinʲ | L |   |   |   | . an | n̥ | ˈəɴˠ | L |   |   |   | . croiceann | ˈkrɛk′əN | ˈkˠɾˠocəɴˠ |   | craiceann | ˈkˠɾˠacəɴˠ |   | . a | ə | ə | L |   |   |   | . bhaint | wï′Nt | ˈwanʲtʲ | L |   |   |   | . de’n | ɔn | ˈdˠenˠ | L |   |   | d → ∅ / t # _ | . talamh | ˈtɑlu | ˈtˠoʟˠuː | L |   |   |   | . go | go | ˈgˠə | L |   |   |   | . dtéighidh | ˈd′ᶾe:ᵊ | ˈdʲeːjiː |   | dté | ˈdʲeː |   | . tú | tu | ˈtˠuː | L |   |   |   | . síos | ˈʃi:s | ˈʃiːsˠ | L |   |   |   | . fhad | ɑd | ˈadˠ | L |   |   |   | . leis | L′eʃ | ˈlʲiʃ | L |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . mhóin. | ˈwo:n′ | ˈwoːnʲ | L+M |   |   |   | . Tá | tɑ: | ˈtˠaː | L |   |   |   | . an | n̥ | ˈəɴˠ | L |   |   | ə → ∅ / V # _ | . t-uachtar | ˈtuəxdər | ˈtˠuaxtˠəɾˠ | L+M |   |   |   | . marbh | ˈmaru | ˈmˠaɾˠəw | L |   |   |   | . ag | ɪg′ | ˈeɟ | L |   |   |   | . sioc | ˈʃo̤k | ˈʃikˠ | L |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . Gheimhridh | ˈjɛvr′i | ˈjivʲɾʲi | L |   |   |   | . agus | ɔgəs | ˈagˠəsˠ | L |   |   |   | . caithfidh | ˈkɑihɪ | ˈkˠahjiː | L |   |   |   | . tú | tu | ˈtˠuː | L |   |   |   | . ghabháil | ɣɔl′ | ˈɣolʲ | L |   |   |   | . síos | ˈʃiᵊs | ˈʃiːsˠ | L |   |   |   | . go | gɔ | ˈgˠə | L |   |   |   | . dtí | ˈd′ʒi: | ˈdʲiː | L |   |   |   | . go | gɔ | ˈgˠə | L |   |   |   | . bhfaghaidh | ˈwɑ: | ˈweːiː |   | bhfaighidh | ˈwiː |   | . tú | tu | ˈtˠuː | L |   |   |   | . an | n̥ | ˈəɴˠ | L |   |   |   | . mhóin | ˈwo:ᵊn′ | ˈwoːnʲ | L+M |   |   |   | . Leagfaidh | ˈL′o̤khə | ˈʟʲagˠiː |   |   |   |   | . tú | tu | ˈtˠuː | L |   |   |   | . an | n̥ | ˈəɴˠ | L |   |   |   | . dorga | ˈdɔrəgə | ˈdˠoˈɾˠgˠa |   | dorú | ˈdˠoɾˠuː |   | . ar | ɛr | ˈeɾʲ | L |   |   |   | . éadan | ˈe:ᵊdɑn | ˈeːdˠəɴˠ | L |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . bhachta | ˈwɑxdə | ˈwaɾˠtˠə | L+M |   |   |   | . agus | ɔgəs | ˈagˠəsˠ | L |   |   |   | . bhéarfaidh | vèrhə | ˈvʲeːɾˠhiː | L |   |   |   | . tú | tu | ˈtˠuː | L |   |   |   | . slat | ˈslɑt | ˈsˠʟˠatˠ | L |   |   |   | . ar | ɛr | ˈeɾʲ | L |   |   |   | . leithead | ˈL′ɛhəd | ˈʟʲaihjədˠ | L |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . bhachtadh | ˈwɑxdu | ˈwaɾˠtˠuː |   |   |   |   | . ó | ɑ | ˈoː | L |   |   |   | . bhun | ˈwo̤n | ˈwuɴˠ | L |   |   |   | . go | gɔ | ˈgˠə | L |   |   |   | . bárr | ˈbɑ:R | ˈbˠaːɾˠ |   | barr | ˈbˠaːɾˠ |   | . Nuair | Nuər′ | ˈɴˠuːɾʲ | L |   |   |   | . atá | ətɑ: | əˈtˠaː | L |   |   |   | . an | n̥ | ˈəɴˠ | L |   |   |   | . bachtadh | ˈbɑxdu | ˈbˠaɾˠtˠuː |   |   |   |   | . lomta | ˈLo̤mt | ˈʟˠomˠtˠə |   |   |   |   | . agat | èit | ˈəgˠətˠ | L |   |   |   | . annsin | n̥ˈʃɪn′ | ˈaˈɴʲʃinʲ |   | ansin | əɴˠʃinʲ |   | . bhéarfaidh | vɛ:rhə | ˈvʲeːɾˠhiː | L |   |   |   | . tú | tu | ˈtˠuː | L |   |   |   | . leat | L′at | ˈlʲatˠ | L |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . spád | ˈsbʷɑ:d | ˈsˠpˠaːdˠ | L |   |   |   | . araist | əˈraʃd′ | ˈaɾˠəʃtʲ |   | ar ais |   |   | . agus | ogəs | ˈagˠəsˠ | L |   |   |   | . géarrfaidh | ˈg′ɑ:Rhə | ˈɟeːˈɾˠeː |   | gearrfaidh | ˈɟaɾˠiː |   | . tú | tu | ˈtˠuː | L |   |   |   | . le | l′ɛ | ˈlʲe | L |   |   |   | . éadan | ˈɛ:dɑn | ˈeːdˠəɴˠ | L |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . bhachtadh | ˈwɑxdu | ˈwaɾˠtˠuː |   |   |   |   | . ar | ɛr | ˈeɾʲ | L |   |   |   | . fhad | ˈɑd | ˈadˠ | L |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . bhachtadh | ˈwɑxdu | ˈwaɾˠtˠuː |   |   |   |   | . leis | L′eʃ | ˈlʲiʃ | L |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . spád | ˈsbɑ:d | ˈsˠpˠaːdˠ | L |   |   |   | . Tá | tɑ: | ˈtˠaː | L |   |   |   | . tú | tu | ˈtˠuː | L |   |   |   | . ag | ə | ˈeɟ | L |   |   |   | . gabháil | gɔl′ | ˈgˠolʲ | L |   |   |   | . a | ə | ə | L |   |   |   | . gheárradh | ˈjɑ:Ru | ˈjaːɾˠuː |   | ghearradh |   |   | . le | l′ɛ | ˈlʲe | L |   |   |   | . sleaghán | ˈʃL′a:n | ˈʃlʲaɣaːɴˠ |   | sleán | ˈʃlʲaːɴˠ |   | . má | mɑ | ˈmˠa | L |   |   |   | . tá | tɑ: | ˈtˠaː | L |   |   |   | . tú | tu | ˈtˠuː | L |   |   |   | . deasach | ˈd′ᶾasɑx | ˈdʲasˠah | L |   |   |   | . agus | ɔgəs | ˈagˠəsˠ | L |   |   |   | . ag | ə | ˈeɟ | L |   |   |   | . gabháil | ˈgɔl′ | ˈgˠolʲ | L |   |   |   | . a | ə | ə | L |   |   |   | . chur | xo̤r | ˈxuɾˠ | L |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . mhóin | ˈwo:n′ | ˈwoːnʲ | L+M |   |   |   | . ar | ɛr | ˈeɾʲ | L |   |   |   | . bruach | ˈbryəx | ˈbˠɾˠuah | L |   |   |   | . Caithfidh | ˈkɑihi | ˈkˠahjiː | L |   |   |   | . tú | tu | ˈtˠuː | L |   |   |   | . geárradh | ˈg′ɑ:Ru | ˈɟaːɾˠuː |   | gearradh | ˈɟaɾˠuː |   | . leis | L′eʃ | ˈlʲiʃ | L |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . spád | ˈsbɑ:d | ˈsˠpˠaːdˠ | L |   |   |   | . le | l′ε | ˈlʲe | L |   |   |   | . éadan | ˈe:ᵊdɑn | ˈeːdˠəɴˠ | L |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . bhachtadh | ˈwɑxdu | ˈwaɾˠtˠuː |   |   |   |   | . mar | mo̤r | ˈmˠaɾˠ | L |   |   |   | . go | gɔ | ˈgˠə | L |   |   |   | . bhfuil | wɪl′ | ˈwilʲ | L |   |   |   | . binn | ˈb′ïN′ | ˈbʲiɴʲ | L |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . tsleagháin | ′t′ʃL′a:n′ | ˈtʲlʲaɣaːnʲ |   | tsleáin | ˈtʲlʲaːnʲ |   | . i |   | ˈi | L |   |   |   | . dtólamh | ˈdɔ:luw | ˈdˠoːʟˠuː | L+M |   |   |   | . ag | ə | ˈeɟ | L |   |   |   | . fágáil | ˈfɑ:gɑl′ | ˈfˠaːgˠalʲ | L |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . bhachtadh | ˈwɑxdu | ˈwaɾˠtˠuː |   |   |   |   | . nuair | Nuər′ | ˈɴˠuːɾʲ | L |   |   |   | . atá | ətɑ: | əˈtˠaː | L |   |   |   | . tusa | ˈtösə | ˈtˠusˠə | L |   |   |   | . ag | ə | ˈeɟ | L |   |   |   | . cur | ko̤r | ˈkˠuɾˠ | L |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . mhóin | ˈwo:n′ | ˈwoːnʲ | L+M |   |   |   | . ar | εr | ˈeɾʲ | L |   |   |   | . bruach | ˈbri:x | ˈbˠɾˠuah | L |   |   |   | . Ach | ɑx | ˈah | L |   |   |   | . tá | tɑ: | ˈtˠaː | L |   |   |   | . áiteacha | ˈa:N′t′axə | ˈaːtʲəhə |   | áiteanna | ˈaːtʲəɴˠə |   | . agus | ɔgəs | ˈagˠəsˠ | L |   |   |   | . ní | N′i: | ˈɴʲiː | L |   |   |   | . h-é | hè | ˈheː | L+M |   |   |   | . sin | ˈʃɪn′ | ˈʃinʲ | L |   |   |   | . mar’s | mo̤řš | ˈm_ea_er_ez_e | L |   |   |   | . geárraidh | ˈg′ɑ:Ri | ˈɟaːɾˠiː |   | gearra | ˈɟaɾˠə |   | . siad | ʃəd | ˈʃiːdˠ | L |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . mhóin | ˈwo:n′ | ˈwoːnʲ | L+M |   |   |   | . ar | ə | ˈeɾʲ | L |   |   |   | . chor | xɔr | ˈxaɾˠ | L |   |   |   | . ar | ə | ˈeɾʲ | L |   |   |   | . bith | ˈb′i | ˈbʲiː | L |   |   |   | . síos | ʃi:s | ˈʃiːsˠ | L |   |   |   | . i |   | ˈi | L |   |   |   | . gConnadae | ˈgo̤Ndei | ˈgˠoɴˠədˠeː |   | gContae | ˈgˠəɴˠˈtˠe |   | . na | Nə | ˈɴˠə | L |   |   |   | . Midhe | ˈm′i:ə | ˈmʲiːə |   | Mí | ˈmʲiː |   | . agus | ɔgəs | ˈagˠəsˠ | L |   |   |   | . na | Nə | ˈɴˠə | L |   |   |   | . h-áiteacha | ˈha:N′t′ahə | ˈhaːtʲəhə | h-áiteacha |   |   |   | . sin | ˈʃɪn′ | ˈʃinʲ | L |   |   |   | . Ach | ɑx | ˈah | L |   |   |   | . seo | ʃɔ | ˈʃo | L |   |   |   | . mar’s | mo̤řš | ˈm_ea_er_ez_e | L |   |   |   | . geárraidh | ˈg′ɑ:Ri | ˈɟaːɾˠiː |   | gearra | ˈɟaɾˠə |   | . siad | ʃəd | ˈʃiːdˠ | L |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . mhóin | ˈwo:n′ | ˈwoːnʲ | L+M |   |   |   | . insa | n̥sə | ˈinʲˈsˠə |   | sa | ˈsˠə |   | . tír | ˈt′ᶴi:r′ | ˈtʲiːɾʲ | L |   |   |   | . seo | ʃɔ | ˈʃo | L |   |   |   | . Tosochaidh | ˈtɔsahə | ˈtˠosˠəhiː |   | Tosóidh | ˈtˠosˠɔj |   | . tú | tu | ˈtˠuː | L |   |   |   | . a |   | ə | L |   |   |   | . gheárradh | ˈjɑ:Ru | ˈjaːɾˠuː |   | ghearradh | ˈjaɾˠuː |   | . agus | ɔgəs | ˈagˠəsˠ | L |   |   |   | . níl | ˈN′i:l′ | ˈɴʲiːlʲ | L |   |   |   | . tú | tu | ˈtˠuː | L |   |   |   | . ag | ə | ˈeɟ | L |   |   |   | . cailleadh | ˈkaL′L′u | ˈkˠaʟʲuː | L |   |   |   | . aon | e:ˈN | ˈeːɴˠ | L |   |   |   | . fhód | o:d | ˈoːdˠ | L+M |   |   |   | . tá | tɑ: | ˈtˠaː | L |   |   |   | . tú | tu | ˈtˠuː | L |   |   |   | . ag | ə | ˈeɟ | L |   |   |   | . cur | ko̤r | ˈkˠuɾˠ | L |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . uile | ˈNɪl′ə | ˈilʲə | L |   |   |   | . cheann | ˈx′o̤N | ˈçiɴˠ | L |   |   |   | . isteach | ə′ʃd′ax | iʃˈtʲah | L |   |   |   | . ar | ɛr | ˈeɾʲ | L |   |   |   | . bruach | ˈbri:x | ˈbˠɾˠuah | L |   |   |   | . Agus | ɔgəs | ˈagˠəsˠ | L |   |   |   | . nuair | Nuər′ | ˈɴˠuːɾʲ | L |   |   |   | . atá | ətɑ: | əˈtˠaː | L |   |   |   | . an | n | ˈəɴˠ | L |   |   |   | . fód | ˈfo:d | ˈfˠoːdˠ | L |   |   |   | . sin | ʃɪn′ | ˈʃinʲ | L |   |   |   | . geárrtha | ˈg′ɑ:Rh | ˈɟaːɾˠhə |   | gearrtha | ˈɟaːɾˠˈha |   | . agat | ɛit | ˈəgˠətˠ | L |   |   |   | . geárrfaidh | ˈg′ɑ:Rhə | ˈɟaːɾˠiː |   | gearrfaidh | ˈɟaɾˠiː |   | . tú | tu | ˈtˠuː | L |   |   |   | . an | n̥ | ˈəɴˠ | L |   |   |   | . dara | ˈdɑrə | ˈdˠaɾˠə | L |   |   |   | . fód | ˈfo:d | ˈfˠoːdˠ | L |   |   |   | . ar | ɛr | ˈeɾʲ | L |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . dóigh | dɔ:i | ˈdˠoːj | L |   |   |   | . chiadhna | ˈx′iəNə | ˈçiəɣɴˠə |   | chéanna | ˈçeːɾˠɴˠə |   | . Well | wɛL′ | ˈweʟʲ |   |   |   |   | . má | mɑ | ˈmˠa | L |   |   |   | . tá | tɑ: | ˈtˠaː | L |   |   |   | . bachtadh | ˈbɑxdu | ˈbˠaɾˠtˠuː |   | bachta | ˈbˠaɾˠtˠə |   | . mór | ˈmo:r | ˈmˠoːɾˠ | L |   |   |   | . agat | èit | ˈəgˠətˠ | L |   |   |   | . fá | fɑ | ˈfˠaː | L |   |   |   | . dhéin | ˈje:n′ | ˈjeːnʲ | L+M |   |   |   | . a |   | ə | L |   |   |   | . dtig | ˈd′ᶾɪg′ | ˈdʲiɟ | L |   |   |   | . leat | ˈL′at | ˈlʲatˠ | L |   |   |   | . móin | mo:n′ | ˈmˠoːnʲ | L |   |   |   | . a | ə | ə | L |   |   |   | . rannadh | ˈrɑNhu | ˈɾˠaɴˠuː |   | roinnt | ˈɾˠoɴʲtʲ |   | . air | èr′ | ˈeɾʲ | L |   |   |   | . Anois | Nɪʃ | əˈɴˠiʃ | L |   |   |   | . tionntochaidh | ˈt′ᶴo̤Ntahə | ˈtʲiɴˠtˠəhiː |   | tiontóidh | ˈtʲiɴˠtˠɔj |   | . tú | tu | ˈtˠuː | L |   |   |   | . ar | ɛr | ˈeɾʲ | L |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . bhachtadh | ˈwɑxdu | ˈwaɾˠtˠuː |   | bhachta |   |   | . agus | ɔgəs | ˈagˠəsˠ | L |   |   |   | . bhéarfaidh | vɛrhə | ˈvʲeːɾˠhiː | L |   |   |   | . tú | tu | ˈtˠuː | L |   |   |   | . an | n̥ | ˈəɴˠ | L |   |   |   | . bhinn | ˈνïΝ′ | ˈvʲiɴʲ | L |   |   |   | . le | l′ε | ˈlʲe | L |   |   |   | . éadan | ˈɛ:ᵊdɑn | ˈeːdˠəɴˠ | L |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . bhachtadh | ˈwɑxdu | ˈwaɾˠtˠuː |   | bhachta |   |   | . Agus | ɔgəs | ˈagˠəsˠ | L |   |   |   | . rachaidh | rɑhə | ˈɾˠaːhij | L |   |   |   | . tú | tu | ˈtˠuː | L |   |   |   | . a | ə | ə | L |   |   |   | . chaitheamh | ˈxɑhu | ˈxahjuː | L |   |   |   | . amach | əˈmɑh | əˈmˠah | L |   |   |   | . as | ïs | ˈasˠ | L |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . bhachtadh | ˈwɑxdu | ˈwaɾˠtˠuː |   | bhachta |   |   | . ná | nɑ: | ˈɴˠaː | L |   |   |   | . go | gɔ | ˈgˠə | L |   |   |   | . rabh | ro | ˈɾˠau |   | raibh | ˈɾˠoːw |   | . an | n̥ | ˈəɴˠ | L |   |   |   | . bachtadh | ˈbɑxdu | ˈbˠaɾˠtˠuː |   | bachta | ˈbˠaɾˠtˠə |   | . geárrtha | ˈg′ɑ:Rhə | ˈɟaːɾˠhə |   | gearrtha | ˈɟaːɾˠˈha |   | . Nuair | Nuər′ | ˈɴˠuːɾʲ | L |   |   |   | . atá | ətɑ: | əˈtˠaː | L |   |   |   | . an | n̥ | ˈəɴˠ | L |   |   |   | . bachtadh | ˈbɑxdu | ˈbˠaɾˠtˠuː |   | bachta | ˈbˠaɾˠtˠə |   | . geárrtha | ˈg′ɑ:Rhə | ˈɟaːɾˠhə |   | gearrtha | ˈɟaːɾˠˈha |   | . annsin | n̥ˈʃɪn′ | ˈaˈɴʲʃinʲ |   | ansin |   |   | . agat | èit | ˈəgˠətˠ | L |   |   |   | . bhéarfaidh | vɛrhə | ˈvʲeːɾˠhiː | L |   |   |   | . tú | tu | ˈtˠuː | L |   |   |   | . leat | L′at | ˈlʲatˠ | L |   |   |   | . bascóid | ˈbɑsgɔd′ᶾ | ˈbˠasˠkˠɔdʲ |   | bascaed | ˈbˠasˠkˠedˠ |   | . ná | nɑ: | ˈɴˠaː | L |   |   |   | . tá | tɑ: | ˈtˠaː | L |   |   |   | . rud | ro̤D | ˈɾˠudˠ | L |   |   |   | . againn | ˈεiΝ′ | ˈəgˠəɴʲ | L |   |   |   | . sa | sə | ˈsˠə | L |   |   |   | . tír | ˈt′ᶴi:r′ | ˈtʲiːɾʲ | L |   |   |   | . seo | ʃɔ | ˈʃo | L |   |   |   | . a | ə | ə | L |   |   |   | . bhfuil | wɪl′ | ˈwilʲ | L |   |   |   | . rotha | ˈrɔh | ˈɾˠohə |   |   |   |   | . air | er′ʔ | ˈeɾʲ | L |   |   |   | . agus | ɔgəs | ˈagˠəsˠ | L |   |   |   | . dhá | ˈɣɑ: | ˈɣaː | L |   |   |   | . lámh | ˈLɑ:w | ˈʟˠaːw | L |   |   |   | . amach | əˈmɑh | əˈmˠah | L |   |   |   | . as | ïs | ˈasˠ | L |   |   |   | . agus | ɔgəs | ˈagˠəsˠ | L |   |   |   | . bocsa | ˈbo̤ks | ˈbˠokˠsˠə |   | bosca | ˈbˠokˠsˠə |   | . air | ɛr′ | ˈeɾʲ | L |   |   |   | . a | ə | ə | L |   |   |   | . chuireas | ˈxo̤r′əs | ˈxuɾʲəsˠ | L |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . mhóin | ˈwo:n′ | ˈwoːnʲ | L+M |   |   |   | . amach | əˈmɑx | əˈmˠah | L |   |   |   | . Sin | ʃɪn′ | ˈʃinʲ | L |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . dóigh | ˈdɔ:i | ˈdˠoːj | L |   |   |   | . a | ᵊ | ə | L |   |   |   | . ndéantar | ˈN′a:Ntər | ˈnʲeːɴˠtˠəɾˠ | L |   |   |   | . Tá | tɑ | ˈtˠaː | L |   |   |   | . an | n̥ | ˈəɴˠ | L |   |   |   | . bruach | ˈbri:x | ˈbˠɾˠuah | L |   |   |   | . mónadh | mo:nu | ˈmˠoːɴˠuː | L |   |   |   | . sin | ˈʃɪn′ | ˈʃinʲ | L |   |   |   | . agat | ɛit | ˈəgˠətˠ | L |   |   |   | . le | l′ε | ˈlʲe | L |   |   |   | . cur | ˈko̤r | ˈkˠuɾˠ | L |   |   |   | . amach | əˈmax | əˈmˠah | L |   |   |   | . agus | ɔgəs | ˈagˠəsˠ | L |   |   |   | . anois | əˈnɪʃ | əˈɴˠiʃ | L |   |   |   | . fágfaidh | ˈfɑ:khə | ˈfˠaːgˠhə | L |   |   |   | . tú | tu | ˈtˠuː | L |   |   |   | . annsin | n̥ˈʃin′ | ˈaˈɴʲʃinʲ |   | ansin | əɴˠˈʃinʲ |   | . í | i: | ˈiː | L |   |   |   | . mar | mo̤r | ˈmˠaɾˠ | L |   |   |   | . atá | ˈtɑ: | əˈtˠaː | L |   |   |   | . sí | ʃi: | ˈʃiː | L |   |   |   | . nó | nɑ: | ˈɴˠoː | L |   |   |   | . go | gɔ | ˈgˠə | L |   |   |   | . dtí | ˈdʒ′i: | ˈdʲiː | L |   |   |   | . go | gɔ | ˈgˠə | L |   |   |   | . dtig | ˈd′ɪg′ | ˈdʲiɟ | L |   |   |   | . grian | ˈg′r′iən | ˈɟɾʲiaɴˠ | L |   |   |   | . orthaí | ɔrhi | ˈoːɾˠhiː |   | uirthi | ˈaɾˠhjiː |   | . i | ə | ˈi | L |   |   |   | . mí | m′i: | ˈmʲiː | L |   |   |   | . na | Nə | ˈɴˠə | L |   |   |   | . Bealtaine | ˈb′a:Ltɪn′ə | ˈbʲoʟˠtˠənʲə | L |   |   |   | . Agus | ɔgəs | ˈagˠəsˠ | L |   |   |   | . tá | tɑ: | ˈtˠaː | L |   |   |   | . sí | ʃi | ˈʃiː | L |   |   |   | . caithte | ˈko̤t′ᶴə | ˈkˠahtʲə |   | caite | ˈkˠatʲə |   | . ina | Nə | ˈiɴˠə | L |   |   |   | . crapannaí | ˈkrɑpəNi | ˈkˠɾˠapˠəɴˠiː |   |   |   |   | . agat | ɛit | ˈəgˠətˠ | L |   |   |   | . go | gɔ | ˈgˠə | L |   |   |   | . dtí | ˈd′ʒi: | ˈdʲiː | L |   |   |   | . go | go | ˈgˠə | L |   |   |   | . bhfosclaidh | ˈwɔsgli | ˈwoˈsˠkˠʟˠeː |   | bhfosclaí | ˈwoˈsˠkˠʟˠiː |   | . an | n̥ | ˈəɴˠ | L |   |   |   | . ghrian | ˈjᵊr′iən | ˈɣɾʲiaɴˠ | L |   |   |   | . rud | ro̤D | ˈɾˠudˠ | L |   |   |   | . beag | ˈb′øG | ˈbʲogˠ | L |   |   |   | . agus | ɔgəs | ˈagˠəsˠ | L |   |   |   | . spréidhfidh | ˈsb′r′e:f′ə | ˈsˠpʲɾʲeːjiː |   | spréifidh | ˈsˠpʲɾʲeːiː |   | . tú | tu | ˈtˠuː | L |   |   |   | . le | l′ε | ˈlʲe | L |   |   |   | . do | dɔ | ˈdˠə | L |   |   |   | . lámha | ˈLɑ:wə | ˈʟˠaːwə | L |   |   |   | . annsin | n̥ˈʃɪn′ | ˈaˈɴʲʃinʲ |   | ansin | əɴˠˈʃinʲ |   | . í | i: | ˈiː | L |   |   |   | . Fágfaidh | ˈfɑ:kə | ˈfˠaːgˠhə | L |   |   |   | . tú | tuᵊ | ˈtˠuː | L |   |   |   | . anois | ˈnɪʃ | əˈɴˠiʃ | L |   |   |   | . tamallt | tɑməLt | ˈtˠamˠəʟˠtˠ |   | tamall | ˈtˠamˠəʟˠ |   | . eile | ˈɛl′i: | ˈelʲə | L |   |   |   | . í |   | ˈiː | L |   |   |   | . agus | ɔgas | ˈagˠəsˠ | L |   |   |   | . nuair | Nuər′ | ˈɴˠuːɾʲ | L |   |   |   | . a | ə | ə | L |   |   |   | . thriomuigheann | ˈx′r′o̤mʷiəN | ˈr̪ʲimˠəjəɴˠ |   | thriomaíonn | ˈr̪ʲimˠiəɴˠ |   | . an | ə | ˈəɴˠ | L |   |   |   | . uair | ˈNuər′ | ˈuaɾʲ | L |   |   |   | . suas | ʃuəs | ˈsˠuasˠ | L |   |   |   | . faoi | fʷi | ˈfˠiː | L |   |   |   | . chionn | x′o̤N | ˈçiɴˠ | L+M |   |   |   | . seachtmhaine | ˈʃaxdɪn′ə | ˈʃaɾˠtˠwənʲə |   | seachtaine | ˈʃaɾˠtˠənʲə |   | . ná | nɑ: | ˈɴˠaː | L |   |   |   | . mar | mo̤r | ˈmˠaɾˠ | L |   |   |   | . sin | ˈʃɪn′ | ˈʃinʲ | L |   |   |   | . rachaidh | rɑhə | ˈɾˠaːhij | L |   |   |   | . tú | tu | ˈtˠuː | L |   |   |   | . fhad | ɑd | ˈadˠ | L |   |   |   | . léithe | L′ɛ:hə | ˈlʲeːhjə | L |   |   |   | . arais | əˈraʃ | ˈaɾˠəʃ |   | ar ais | ˈeɾʲ ˈaʃ |   | . agus | ɔgəs | ˈagˠəsˠ | L |   |   |   | . cróigfidh | ˈkrɔ:ᵊk′ə | ˈkˠɾˠoːɟiː |   | gróigfidh | ˈgˠɾˠoːɟiː |   | . tú | tu | ˈtˠuː | L |   |   |   | . í | i: | ˈiː | L |   |   |   | . Fágfaidh | ˈfɑ:kə | ˈfˠaːgˠhə | L |   |   |   | . tú | tu | ˈtˠuː | L |   |   |   | . ins | n̥s | ˈinʲʃ |   | sa | ˈsˠə |   | . na | Nə | ˈɴˠə | L |   |   |   | . cróigeáin | ˈkrɔ:ᵊg′ən′ | ˈkˠɾˠoːɟaːnʲ |   | gróigeáin | ˈgˠɾˠoːɟaːnʲ |   | . anois | əˈnɪʃ | əˈɴˠiʃ | L |   |   |   | . í | i: | ˈiː | L |   |   |   | . tamallt | tɑməLt | ˈtˠamˠəʟˠtˠ |   | tamall | ˈtˠamˠəʟˠ |   | . eile | εl′ə | ˈelʲə | L |   |   |   | . agus | ɔgəs | ˈagˠəsˠ | L |   |   |   | . dhéanfaidh | ja:nhə | ˈɣeːɴˠhiː | L |   |   |   | . tú | tu | ˈtˠuː | L |   |   |   | . anois | əˈnɪʃ | əˈɴˠiʃ | L |   |   |   | . clampaí | ˈklɑmbi | ˈkˠʟˠamˠpˠiː |   |   |   |   | . daoithe | dihə | ˈdˠiːhə |   | di | ˈdˠi |   | . Nuair | Nuər′ | ˈɴˠuːɾʲ | L |   |   |   | . atá | ə | əˈtˠaː | L |   |   |   | . sí | tɑ:ʃi: | ˈʃiː | L |   |   |   | . ins | n̥s | ˈinʲʃ |   | sa | ˈsˠə |   | . na | Nə | ˈɴˠə | L |   |   |   | . clampaí | ˈklɑmbi | ˈkˠʟˠamˠpˠiː |   |   |   |   | . tamallt | tɑməLt | ˈtˠamˠəʟˠtˠ |   | tamall | ˈtˠamˠəʟˠ |   | . agat | èit | ˈəgˠətˠ | L |   |   |   | . á | a | aː | L |   |   |   | . réir | ˈr′e: | ˈɾˠeːɾʲ | L |   |   |   | . sin | ʃɪn′ | ˈʃinʲ | L |   |   |   | . mar’s | məs | ˈmˠaɾˠsˠ | L |   |   |   | . tá | tɑ: | ˈtˠaː | L |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . uair | ˈNuər′ | ˈuaɾʲ | L |   |   |   | . briste | ˈb′r′ïʃd′ə | ˈbʲɾʲiʃtʲə | L |   |   |   | . caithfidh | kaihɪ | ˈkˠahjiː | L |   |   |   | . tú | tu | ˈtˠuː | L |   |   |   | . riclíní | ˈrïk′l′i:n′i | ˈɾˠiclʲiːnʲiː |   |   |   |   | . a | ə | ə | L |   |   |   | . dhéanamh | ˈja:nu | ˈjeːɴˠuː | L |   |   |   | . daoithe | di:ʰə | ˈdˠiːhə |   | di | ˈdˠi |   | . Ach | ɑx | ˈah | L |   |   |   | . má | mɑ | ˈmˠa | L |   |   |   | . tá | tɑ: | ˈtˠaː | L |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . uair | Nuər′ | ˈuaɾʲ | L |   |   |   | . maith | ˈmɑi | ˈmˠahj | L |   |   |   | . triomochaidh | ˈt′ᶴr′ïmɑhə | ˈtʲɾʲimˠəhiː |   | triomóidh | ˈtʲɾʲimˠɔj |   | . sí | ʃi: | ˈʃiː | L |   |   |   | . ins | n̥s | ˈinʲʃ |   | sa | ˈsˠə |   | . na | Nə | ˈɴˠə | L |   |   |   | . clampaí | ˈklɑmbi | ˈkˠʟˠamˠpˠiː |   |   |   |   | . go | gə | ˈgˠə | L |   |   |   | . gcruachaidh | ˈgruəxə | ˈgˠɾˠuəˈxeː |   | gcruacha | ˈgˠɾˠuəˈxa |   | . tú | tu | ˈtˠuː | L |   |   |   | . í | i: | ˈiː | L |   |   |   | . Nuair | Nuər′ | ˈɴˠuːɾʲ | L |   |   |   | . atá | ətɑ: | əˈtˠaː | L |   |   |   | . sí | ʃi: | ˈʃiː | L |   |   |   | . cruachta | ˈkruəxdə | ˈkˠɾˠuəˈɾˠtˠa |   |   |   |   | . annsin | n̥ˈʃɪn′ | ˈaˈɴʲʃinʲ |   |   |   |   | . agat | ɛjəd | ˈəgˠətˠ | L |   |   |   | . fágfaidh | ˈfɑ:kə | ˈfˠaːgˠhə | L |   |   |   | . tú | tu | ˈtˠuː | L |   |   |   | . ins | n̥s | ˈinʲʃ |   |   |   |   | . na | Nə | ˈɴˠə | L |   |   |   | . cruacha | ˈkruəx | ˈkˠɾˠuəˈxa |   |   |   |   | . í | i: | ˈiː | L |   |   |   | . go | gɔ | ˈgˠə | L |   |   |   | . stáluighidh | ˈsdɑ:li | ˈsˠtˠaːʟˠəjiː |   | stálaí | ˈsˠtˠaːʟˠiː |   | . sí | ʃi: | ˈʃiː | L |   |   |   | . Agus | ɔgəs | ˈagˠəsˠ | L |   |   |   | . tá | ˈtɑ: | ˈtˠaː | L |   |   |   | . sí | ʃi: | ˈʃiː | L |   |   |   | . agat | èit | ˈəgˠətˠ | L |   |   |   | . sábháilte | ˈsɑ:wɑL′t′ᶴə | ˈsˠaːwaʟʲtʲə | L |   |   |   | . annsin | n̥ˈʃɪn′ | ˈaˈɴʲʃinʲ |   |   |   |   | . O’Neill, John E. “Irish Texts from South West Donegal.” Zeitschrift Für Celtische Philologie, vol. 33, 1974, doi:10.1515/zcph.1974.33.1.285. &#8617; . |",
            "url": "https://jimregan.github.io/notes/irish/donegal/2021/01/25/irish-texts-from-south-west-donegal-text-2-an-mhoin.html",
            "relUrl": "/irish/donegal/2021/01/25/irish-texts-from-south-west-donegal-text-2-an-mhoin.html",
            "date": " • Jan 25, 2021"
        }
        
    
  
    
        ,"post268": {
            "title": "Irish Texts from South West Donegal. Poitín.",
            "content": "The table below compares the transcription of Text 1: “Poitín” from O’Neill’s1 “Irish Texts from South West Donegal”, comparing it with Abair’s transcription. . Texts 1—4 were contributed by Seamus Ó Beirn (Jim Phat James), aged c. 70 years, cobbler, from the townland of Mín na Gaoithe, Teelin. . A special feature of his speech is the clearness and strength of the affricates t′ʃ and d′ʒ due to the deliberate manner in which each word is enunciated. . The phonetic rules were mostly to help with automatic comparison, though the places where verb froms were pronounced differently before a pronoun was interesting enough to note. . Original Transcript Abair G2P Abair source Adjusted word (standardised) Adjusted Abair Rule . An | ə | ˈəɴˠ | L |   |   |   | . dtiocfadh | d′ᶾo̤ku | ˈdʲokˠuː | L |   |   |   | . leat | L′at | ˈlʲatˠ | L |   |   |   | . innse | ïΝ′ʃə | ˈiˈɴʲʃe |   | insint | ˌinʲˈʃinʲtʲ |   | . domh | du | ˈdˠuː | L |   |   |   | . goidé | gəˈd′ᶾe: | ˈgˠədʲeː | L |   |   |   | . n | n̥ | nˠ | L |   |   |   | . dóigh | dɔ:i | ˈdˠoːj | L |   |   |   | . a | ə | ə | L |   |   |   | . ndéantar | N′a:Ntɑr | ˈnʲeːɴˠtˠəɾˠ | L |   |   |   | . poitín | ˈpɔt′in′ | ˈpˠotʲinʲ | L |   |   |   | . Well | wɛL′ | ˈweʟʲ |   |   |   |   | . sé | ʃε | ˈʃeː | L |   |   |   | . a |   | ə | L |   |   | ə → ∅ / V # _ | . bhfuil | ˈwil′ | ˈwilʲ | L |   |   |   | . fhios | ïs | ˈisˠ | L |   |   |   | . agamsa | èimsə | ˈəgˠəmˠsˠə | L |   |   |   | . fá | fɑ | ˈfˠaː | L |   |   |   | . dtaobh | du: | ˈdʲiːw | L |   |   |   | . den | dɔn | ˈdˠenˠ | L |   |   |   | . phoitín | ˈfot′in′ | ˈfˠotʲinʲ | L+M |   |   |   | . fad | fɑd | ˈfˠadˠ | L |   |   |   | . ó | ɔ | ˈoː | L |   |   |   | . shoin | xɪn′ | ˈhoˈinʲ |   | shin | ˈhinʲ |   | . nuair | Nuər′ | ˈɴˠuːɾʲ | L |   |   |   | . a | ə | ə | L |   |   |   | . níodh | ˈN′i:wəd′ | ˈnʲiːuː | L |   |   | &lt;odh&gt; → ədʲ / _ # PRONOUN | . siad | ʃəd | ˈʃiːdˠ | L |   |   |   | . as | ïs | ˈasˠ | L |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . eórna | ˈN′ɔ:rN | ˈoːɾˠɴˠə |   | eorna | ˈoːɾˠɴˠə | ə → ∅ / _ # V | . í | i: | ˈiː | L |   |   |   | . Nuair | Nuər′ | ˈɴˠuːɾʲ | L |   |   |   | . a | ə | ə | L |   |   |   | . bhéadh | vɛuw | ˈvʲeːɣ |   |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . eórna | ˈN′ɔ:rNə | ˈoːɾˠɴˠə |   |   |   |   | . sábháilte | ˈsɑ:wɑL′t′ | ˈsˠaːwaʟʲtʲə | L |   |   |   | . acú | ɔku | ˈakˠuː |   |   |   |   | . cáithte | ˈka:t′ʃə | ˈkˠaːhtʲə |   | cáite | kˠaːtʲə |   | . astoigh | əˈsdihʔ | ˈasˠtˠə |   | istigh | isˠˈtˠij |   | . ina | əΝə | ˈiɴˠə | L |   |   |   | . mála | ˈmɑ:lə | ˈmˠaːʟˠə | L |   |   |   | . bheireadh | vɛr′əd′ | ˈvʲeɾʲuː | L |   |   | &lt;eadh&gt; → ədʲ / _ # PRONOUN | . siad | ʃəd | ˈʃiːdˠ | L |   |   |   | . leófa | L′ɔ:fə | ˈʟʲoːfˠə |   | leo | ˈlʲo |   | . tuairim | tuər′ɪm′ | ˈtˠuaɾʲimʲ | L |   |   |   | . ar | ər | ˈeɾʲ | L |   |   |   | . ocht | ɔxd | ˈaxtˠ | L |   |   |   | . gclocha | glo̤hə | ˈgˠʟˠahə | L+M |   |   |   | . den | dɔ | ˈdˠenˠ | L |   |   |   | . eórna | ˈN′ɔ:rNə | ˈoːɾˠɴˠə |   | eorna | ˈoːɾˠɴˠə |   | . sin | ʃɪn′ | ˈʃinʲ | L |   |   |   | . agus | ɔgəs | ˈagˠəsˠ | L |   |   |   | . chuireadh | xo̤r′əd′ | ˈxuɾʲuː | L |   |   | &lt;eadh&gt; → ədʲ / _ # PRONOUN | . siad | ʃəd | ˈʃiːdˠ | L |   |   |   | . isteach | əˈʃd′ax | iʃˈtʲah | L |   |   |   | . ina | əΝə | ˈiɴˠə | L |   |   |   | . ndam | ˈNɑMʷ | ˈɴˠamˠ |   | ndamba | ˈɴˠamˠbˠə |   | . í | i: | ˈiː | L |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . rud | ro̤D | ˈɾˠudˠ | L |   |   |   | . a | ə | ə | L |   |   |   | . dtugadh | do̤gəd′ | ˈdˠugˠuː | L+M |   |   | &lt;adh&gt; → ədʲ / _ # PRONOUN | . siad | ʃəd | ˈʃiːdˠ | L |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . bachtadh | ˈbɑxdu | ˈbˠaɾˠtˠuː |   | bachta | ˈbˠaɾˠtˠə |   | . air | ɛr′ | ˈeɾʲ | L |   |   |   | . Nuair | Nuər′ | ˈɴˠuːɾʲ | L |   |   |   | . a | ə | ə | L |   |   |   | . bhíodh | vi:d′ | ˈvʲiːuː | L |   |   | &lt;odh&gt; → ədʲ / _ # PRONOUN | . sí | ʃi: | ˈʃiː | L |   |   |   | . naoi | ˈNi: | ˈɴˠiː | L |   |   |   | . lá | ˈLɑ: | ˈʟˠaː | L |   |   |   | . annsin | n̥ˈʃɪn′ | ˈaˈɴʲʃinʲ |   |   |   |   | . d’fhásfadh | dɑ:shəd′ | ˈdˠaːsˠuː |   |   |   | &lt;adh&gt; → ədʲ / _ # PRONOUN | . sí | ʃi: | ˈʃiː | L |   |   |   | . géar | ˈg′ɛ:ᵊr | ˈɟeːɾˠ | L |   |   |   | . agus | ɔgəs | ˈagˠəsˠ | L |   |   |   | . rachadh | rɑhəd′ | ˈɾˠahuː | L |   |   | &lt;adh&gt; → ədʲ / _ # PRONOUN | . sí | ʃi: | ˈʃiː | L |   |   |   | . a |   | ə | L |   |   | ə → ∅ / V # _ | . dh’fhás | ˈɣɑ:s | ˈɣaːsˠ |   | d’fhás | ˈdˠaːsˠ |   | . agus | ɔgəs | ˈagˠəsˠ | L |   |   |   | . ba é | byje: | ˈbˠə ˈeː |   |   |   |   | . sin | ʃɪn′ | ˈʃinʲ | L |   |   |   | . an | əˈ | ˈəɴˠ | L |   |   |   | . t-am | tɑM | ˈtˠaːmˠ | L |   |   |   | . acú | ɔku | ˈakˠuː |   |   |   |   | . lena | l′ɛnə | ˈlʲeɴˠə | L |   |   |   | . tarraingt | tɑRəN′t′ | ˈtˠaɾˠinʲtʲ | L |   |   |   | . amach | əˈmɑx | əˈmˠah | L |   |   |   | . Agus | ɔgəs | ˈagˠəsˠ | L |   |   |   | . ins an | n̥sə | ˈinʲʃ ˈəɴˠ |   |   |   |   | . am | ˈNɑM | ˈamˠ | L |   |   |   | . sin | ʃɪn′ | ˈʃinʲ | L |   |   |   | . bhí | vi: | ˈvʲiː | L |   |   |   | . na | Nə | ˈɴˠə | L |   |   |   | . toithe | tihə | ˈtˠohə |   | tithe | ˈtʲihjiː |   | . bracha | ˈbrɑxə | ˈbˠɾˠahə |   | braiche | ˈbˠɾˠaçə |   | . faoin | fʷi:n | ˈfˠinʲ | L |   |   |   | . talamh | ˈtɑlu | ˈtˠoʟˠuː | L |   |   |   | . ar | ɛr | ˈeɾʲ | L |   |   |   | . eagla | øGlə | ˈogˠʟˠə | L |   |   |   | . go | gɔ | ˈgˠə | L |   |   |   | . bhfeiceadh | ˈvɛk′u | ˈvʲecuː |   |   |   |   | . duine | ˈdɪn′ | ˈdˠinʲə | L |   |   | ə → ∅ / _ # V | . ar | ɛr | ˈeɾʲ | L |   |   |   | . bith | b′i | ˈbʲiː | L |   |   |   | . iad | iəd | ˈiadˠ | L |   |   |   | . Agus | ɔgəs | ˈagˠəsˠ | L |   |   |   | . ins | n̥s | ˈinʲʃ |   |   |   |   | . na | Nə | ˈɴˠə | L |   |   |   | . toithe | ˈtihə | ˈtˠohə |   | tithe | ˈtʲihjiː |   | . bracha | ˈbrɑxə | ˈbˠɾˠahə |   | braiche | ˈbˠɾˠaçə |   | . thriomuigheadh | ˈx′r′ïmʷied′ | ˈr̪ʲimˠəjuː |   | thriomaíodh | ˈr̪ʲimˠiəɣ |   | . siad | ʃəd | ˈʃiːdˠ | L |   |   |   | . araist | əˈraʃd′ | ˈaɾˠəʃtʲ |   |   |   |   | . í | i: | ˈiː | L |   |   |   | . Annsin | n̥ˈʃɪn′ | ˈaˈɴʲʃinʲ |   |   |   | ə → ∅ / V # _ | . mheileadh | vəl′həd′ | ˈvʲelʲuː |   |   |   | &lt;eadh&gt; → ədʲ / _ # PRONOUN | . siad | ʃəd | ˈʃiːdˠ | L |   |   |   | . í | i: | ˈiː | L |   |   |   | . le | l′ɛ | ˈlʲe | L |   |   |   | . bróinte | ˈbrɔ:N′t′ə | ˈbˠɾˠoːnʲtʲə |   | brónna | bˠɾˠoːɴˠə |   | . láimhe | ˈLɑ:və | ˈʟˠaːvʲə | L |   |   |   | . Bhí | vi: | ˈvʲiː | L |   |   |   | . na | Nə | ˈɴˠə | L |   |   |   | . barraillí | ˈbɑRəL′i | ˈbˠaːˈɾˠaʟʲiː |   | bairillí | ˈbˠaɾʲəʟʲiː |   | . acú | ɔku | ˈakˠuː |   | acu | akˠu |   | . annsin | n̥ˈʃɪn′ | ˈaˈɴʲʃinʲ |   | ansin | əɴˠʃinʲ | ə → ∅ / V # _ | . agus | ɔges | ˈagˠəsˠ | L |   |   |   | . líonadh | ˈL′i:nəd′ | ˈʟʲiːɴˠuː | L |   |   |   | . siad | ʃəd | ˈʃiːdˠ | L |   |   |   | . lán | Lɑ:n | ˈʟˠaːɴˠ | L |   |   |   | . uisce | ɪʃg′ə | ˈiʃcə | L |   |   |   | . an | n̥ | ˈəɴˠ | L |   |   | ə → ∅ / V # _ | . barraille | ˈbɑRəL′ə | ˈbˠaːˈɾˠaʟʲə |   | bairille | ˈbˠaɾʲʟʲə |   | . Chuireadh | xo̤r′əd′ | ˈxuɾʲuː | L |   |   | &lt;eadh&gt; → ədʲ / _ # PRONOUN | . siad | ʃəd | ˈʃiːdˠ | L |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . bhraich | ˈvreihʔ | ˈwɾˠaç | L+M |   |   |   | . isteach | əˈʃd′ax | iʃˈtʲah | L |   |   |   | . insa | n̥sə | ˈinʲˈsˠə |   | sa | ˈsˠə |   | . bharraille | ˈwɑRəL′ə | ˈwaːˈɾˠaʟʲə |   | bhairille | ˈwaɾʲʟʲə |   | . agus | ɔgəs | ˈagˠəsˠ | L |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . ghabháil | ˈɣɔ:l′ | ˈɣolʲ | L |   |   |   | . annsin | n̥ˈʃɪn′ | ˈaɴʲʃinʲ |   | ansin | əɴˠʃinʲ |   | . Chuireadh | xo̤r′əd′ | ˈxuɾʲuː | L |   |   | &lt;eadh&gt; → ədʲ / _ # PRONOUN | . siad | ʃəd | ˈʃiːdˠ | L |   |   |   | . cumhdach | ˈku:dɑx | ˈkˠuːdˠah | L |   |   |   | . ar | ɛr | ˈeɾʲ | L |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . bharraille | ˈwɑRəL′ə | ˈwaːˈɾˠaʟʲə |   | bhairille | ˈwaɾʲʟʲə |   | . agus | ɔgəs | ˈagˠəsˠ | L |   |   |   | . ba | bo̤ | ˈbˠə | L |   |   |   | . ghoirid | ˈɣo̤r′id′ᶾ | ˈɣoɾʲədʲ |   |   |   |   | . i | ə | ˈi | L |   |   |   | . gcionn | g′o̤N | ˈɟoɴˠ | L |   |   |   | . cheithre | ˈx′ɛr′ə | ˈxeɾʲə | L |   |   |   | . huaire | ˈhuər′ə | ˈhuaɾʲə | L |   |   |   | . fichead | ˈf′ihəd | ˈfʲihjədˠ | L |   |   |   | . thiocfadh | ho̤ku | ˈhjokˠuː | L |   |   |   | . an | n̥ | ˈəɴˠ | L |   |   | ə → ∅ / V # _ | . cubhar | ˈku:r | ˈkˠuwəɾˠ |   | cúr | ˈkˠuːɾˠ |   | . a | ə | ə | L |   |   |   | . theacht | haxd | ˈhjaxtˠ | L |   |   |   | . ar | ɛr | ˈeɾʲ | L |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . bharraille | ˈwɑRəL′ə | ˈwaːˈɾˠaʟʲə |   | bhairille | ˈwaɾʲʟʲə |   | . agus | ɔgəs | ˈagˠəsˠ | L |   |   |   | . bhí | vi: | ˈvʲiː | L |   |   |   | . an | n | ˈəɴˠ | L |   |   | ə → ∅ / V # _ | . ceol | ˈk′ʲɔ:l | ˈcoːʟˠ | L |   |   |   | . aige | ɛg′ə | ˈeɟə | L |   |   |   | . mar | mo̤r | ˈmˠaɾˠ | L |   |   |   | . ceól | ˈk′ʲɔ:l | ˈcoːʟˠ |   | ceol | ˈcoːʟˠ |   | . beachóg | ˈb′ahɔg | ˈbʲahɔgˠ |   |   |   |   | . Nuair | Nuər′ | ˈɴˠuːɾʲ | L |   |   |   | . a | ə | ə | L |   |   |   | . bhíodh | vi:d′ | ˈvʲiːuː | L |   |   | &lt;odh&gt; → ədʲ / _ # PRONOUN | . sé | ʃɛ | ˈʃeː | L |   |   |   | . naoi | ˈNi: | ˈɴˠiː | L |   |   |   | . lá | ˈLɑ: | ˈʟˠaː | L |   |   |   | . shíolthuigheadh | ˈhiəlhiuw | ˈhiːʟˠhəjuː |   | shíothlaíodh | ˈhiːhʟˠiəɣ |   | . an | ə | ˈəɴˠ | L |   |   |   | . t-iomlán | ˈt′ᶴo̤mlan | ˈtʲuːmˠʟˠaɴˠ |   |   |   |   | . síos | ʃi:s | ˈʃiːsˠ | L |   |   |   | . ins | n̥s | ˈinʲʃ |   |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . bharraille | ˈwɑRəL′ə | ˈwaːˈɾˠaʟʲə |   |   |   |   | . araist | əˈraʃd′ | ˈaɾˠəʃtʲ |   |   |   |   | . agus | ɔgəs | ˈagˠəsˠ | L |   |   |   | . ba é | byje: | ˈbˠə ˈeː | L |   |   |   | . sin | ʃɪn′ | ˈʃinʲ | L |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . t-am | ˈtɑM | ˈtˠaːmˠ | L |   |   |   | . acú | ɔku | ˈakˠuː |   |   |   |   | . lena | l′ɛnə | ˈlʲeɴˠə | L |   |   |   | . chur | ˈxo̤r | ˈxuɾˠ | L |   |   |   | . sa | sə | ˈsˠə | L |   |   |   | . still | ˈsdïl | ˈʃtʲiʟʲ |   |   |   |   | . Bhí | vi: | ˈvʲiː | L |   |   |   | . sí | ʃi: | ˈʃiː | L |   |   |   | . réidh | ˈre:i | ˈɾˠeːj | L |   |   |   | . fá | fɑ | ˈfˠaː | L |   |   |   | . dhéin | ˈje:n′ | ˈjeːnʲ | L+M |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . still | ˈsdïl | ˈʃtʲiʟʲ |   |   |   |   | . Chuireadh | xo̤r′əd′ | ˈxuɾʲuː | L |   |   | &lt;eadh&gt; → ədʲ / _ # PRONOUN | . siad | ʃəd | ˈʃiːdˠ | L |   |   |   | . isteach | əˈʃd′ah | iʃˈtʲah | L |   |   |   | . insa | n̥sə | ˈinʲˈsˠə |   |   |   |   | . still | ˈsdïl | ˈʃtʲiʟʲ |   |   |   |   | . í | i: | ˈiː | L |   |   |   | . agus | ɔgəs | ˈagˠəsˠ | L |   |   |   | . bhí | vi: | ˈvʲiː | L |   |   |   | . dabhach | ˈdɔuʷɑx | ˈdˠauh | L |   |   |   | . acú | ɔku | ˈakˠuː |   |   |   |   | . agus | ɔgəs | ˈagˠəsˠ | L |   |   |   | . rud | ˈro̤D | ˈɾˠudˠ | L |   |   |   | . a | ə | ə | L |   |   |   | . dtugadh | do̤gəd′ | ˈdˠugˠuː | L+M |   |   | &lt;adh&gt; → ədʲ / _ # PRONOUN | . siad | ʃəd | ˈʃiːdˠ | L |   |   |   | . worm | ˈwïr′əm | ˈwoːɾˠəmˠ |   |   |   |   | . air | ɛr′ | ˈeɾʲ | L |   |   |   | . a | ə | ə | L |   |   |   | . rabh | roˈ | ˈɾˠau |   | raibh | ˈɾˠoːw |   | . trí | t′ʃr′i: | ˈtʲɾʲiː | L |   |   |   | . chor | ˈxɔr | ˈxaɾˠ | L |   |   |   | . inntí | ˈɪN′t′i | ˈiˈɴʲtʲiː |   | inti | iɴʲtʲi |   | . Agus | ɔgəs | ˈagˠəsˠ | L |   |   |   | . bhí | vi: | ˈvʲiː | L |   |   |   | . an | n̥ | ˈəɴˠ | L |   |   | ə → ∅ / V # _ | . worm | ˈwïr′əm | ˈwoːɾˠəmˠ |   |   |   |   | . astoigh | əˈʃdihʔ | ˈasˠtˠə |   | istigh | isˠˈtˠij |   | . sa | sə | ˈsˠə | L |   |   |   | . dabhach | ˈdɔuʷɑx | ˈdˠauh | L |   |   |   | . agus | ɔgəs | ˈagˠəsˠ | L |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . t-uisce | tɪʃg′ə | ˈtˠiʃcə | L |   |   |   | . fuar | ˈfyər | ˈfˠiaɾˠ | L |   |   |   | . ag | ə | ˈeɟ | L |   |   | ɟ → ∅ / _ # [+stop] | . dórtadh | ˈdɔ:rtu | ˈdˠoːˈɾˠtˠeː |   | doirteadh | ˈdˠoɾˠtʲuː |   | . orthaí | ɔrhi | ˈoːɾˠhiː |   | uirthi | ˈaɾˠhjiː |   | . Agus | ɔgəs | ˈagˠəsˠ | L |   |   |   | . ar | ɛr | ˈeɾʲ | L |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . taobh | ti:w | ˈtˠiːw | L |   |   |   | . eile | εl′ə | ˈelʲə | L |   |   |   | . den | dɔn | ˈdˠenˠ | L |   |   |   | . worm | ˈwïr′əm | ˈwoːɾˠəmˠ |   |   |   |   | . bhí | vi: | ˈvʲiː | L |   |   |   | . an | n̥ | ˈəɴˠ | L |   |   | ə → ∅ / V # _ | . ceig | ˈk′èG′ | ˈceɟ |   |   |   |   | . agus | ɔgəs | ˈagˠəsˠ | L |   |   |   | . ar | ər | ˈeɾʲ | L |   |   |   | . tuairim | tuər′ɪm′ | ˈtˠuaɾʲimʲ | L |   |   |   | . ar | ɛr | ˈeɾʲ | L |   |   |   | . thoirt | ˈho̤Rt′ | ˈhaɾˠtʲ | L+M |   |   |   | . fiog | ˈf′øG | ˈfʲigˠ |   |   |   |   | . ghlas | ˈɣlɑs | ˈɣʟˠasˠ | L |   |   |   | . rachadh | rɑhu | ˈɾˠahuː | L |   |   |   | . an | n̥ | ˈəɴˠ | L |   |   | ə → ∅ / V # _ | . poitín | ˈpɔt′in′ | ˈpˠotʲinʲ | L |   |   |   | . isteach | əˈʃd′ah | iʃˈtʲah | L |   |   |   | . insa | n̥sə | ˈinʲˈsˠə |   |   |   |   | . cheig | ˈx′ɛG′ | ˈçeɟ |   |   |   |   | . amach | əˈmɑh | əˈmˠah | L |   |   |   | . as | ïs | ˈasˠ | L |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . worm | ˈwïr′əm | ˈwoːɾˠəmˠ |   |   |   |   | . Annsin | n̥ˈʃɪn′ | ˈaˈɴʲʃinʲ |   |   |   |   | . nuair | Nuər′ | ˈɴˠuːɾʲ | L |   |   |   | . a | ə | ə | L |   |   |   | . bhíodh | viuw | ˈvʲiːuː | L |   |   |   | . an | n̥ | ˈəɴˠ | L |   |   |   | . chéad | ˈx′ed | ˈçeːdˠ | L |   |   |   | . rathaidh | ˈrɑhi | ˈɾˠahiː |   | ratha | ˈɾˠahə |   | . raithte | ˈrat′ʃ | ˈɾˠahtʲə |   | ráite | ˈɾˠaːtʲə | ə → ∅ / _ # V | . acú | ɔku | ˈakˠuː |   |   |   |   | . chuireadh | xo̤r′əd′ | ˈxuɾʲuː | L |   |   | &lt;eadh&gt; → ədʲ / _ # PRONOUN | . siad | ʃəd | ˈʃiːdˠ | L |   |   |   | . isteach | əˈʃd′ah | iʃˈtʲah | L |   |   |   | . araist | əˈraʃd′ | ˈaɾˠəʃtʲ |   |   |   |   | . í | i: | ˈiː | L |   |   |   | . ins | n̥s | ˈinʲʃ |   |   |   | ə → ∅ / V # _ | . an | ə | ˈəɴˠ | L |   |   |   | . still | ˈsdïl | ˈʃtʲiʟʲ |   |   |   |   | . agus | ɔgəs | ˈagˠəsˠ | L |   |   |   | . níodh | ˈN′i:wəd′ | ˈnʲiːuː | L |   |   | &lt;odh&gt; → ədʲ / _ # PRONOUN | . siad | ʃəd | ˈʃiːdˠ | L |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . dara | ˈdɑrə | ˈdˠaɾˠə | L |   |   |   | . rathaidh | n̥ˈrahi | ˈɾˠahiː |   |   |   |   | . annsin | ˈʃɪn′ | ˈaˈɴʲʃinʲ |   |   |   |   | . Bhíodh | viuw | ˈvʲiːuː | L |   |   |   | . gloine | ˈglön′ə | ˈgˠʟˠinʲə | L |   |   |   | . acú | ɔku | ˈakˠuː |   |   |   |   | . a | ə | ə | L |   |   |   | . dtugadh | do̤gəd′ | ˈdˠugˠuː | L+M |   |   | &lt;adh&gt; → ədʲ / _ # PRONOUN | . siad | ʃəd | ˈʃiːdˠ | L |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . adharc | ˈNe:rk | ˈeːɾˠkˠ | L |   |   |   | . air | ɛr′ | ˈeɾʲ | L |   |   |   | . agus | ɔgəs | ˈagˠəsˠ | L |   |   |   | . á | a | aː | L |   |   |   | . réir | ˈre: | ˈɾˠeːɾʲ | L |   |   |   | . sin’s | ʃɪn′s | ˈʃinʲʃ |   |   |   |   | . bhíodh | vi:d′ | ˈvʲiːuː | L |   |   |   | . siad | ʃəd | ˈʃiːdˠ | L |   |   |   | . ag | ə | ˈeɟ | L |   |   |   | . rathaidh | ˈrɑhi | ˈɾˠahiː |   |   |   |   | . an | n̥ | ˈəɴˠ | L |   |   | ə → ∅ / V # _ | . phoitín | ˈfɔt′in′ | ˈfˠotʲinʲ | L+M |   |   |   | . chuireadh | xo̤r′əd′ | ˈxuɾʲuː | L |   |   | &lt;eadh&gt; → ədʲ / _ # PRONOUN | . siad | ʃəd | ˈʃiːdˠ | L |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . adharc | ˈNe:rk | ˈeːɾˠkˠ | L |   |   |   | . isteach | əˈʃd′ax | iʃˈtʲah | L |   |   |   | . faoin | fʷi:n | ˈfˠinʲ | L |   |   |   | . phoitín | ˈfɔt′in′ | ˈfˠotʲinʲ | L+M |   |   |   | . agus | ɔgəs | ˈagˠəsˠ | L |   |   |   | . chaith | ˈxɑih | ˈxahj | L |   |   |   | . iad | əd | ˈiadˠ | L |   |   |   | . insa | n̥sə | ˈinʲˈsˠə |   |   |   |   | . teinidh | ˈt′ʃɪn′i | ˈtʲenʲiː |   |   |   |   | . í | i: | ˈiː | L |   |   |   | . Agus | ɔgəs | ˈagˠəsˠ | L |   |   |   | . nuair | Nuər′ | ˈɴˠuːɾʲ | L |   |   |   | . a | ə | ə | L |   |   |   | . thiocfadh | ho̤ku | ˈhjokˠuː | L |   |   |   | . an | n̥ | ˈəɴˠ | L |   |   | ə → ∅ / V # _ | . bladhaire | ˈblᴇir′ə | ˈbˠʟˠeːɾʲə | L |   |   |   | . bhí | vi: | ˈvʲiː | L |   |   |   | . sé | ʃɛ | ˈʃeː | L |   |   |   | . i |   | ˈi | L |   |   |   | . dtólamh | ˈdɔ:ləf′ | ˈdˠoːʟˠuː | L+M |   |   |   | . ar | ɛr | ˈeɾʲ | L |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . phoitín | ˈfɔt′in′ | ˈfˠotʲinʲ | L+M |   |   |   | . Agus | ɔgəs | ˈagˠəsˠ | L |   |   |   | . nuair | Nuər′ | ˈɴˠuːɾʲ | L |   |   |   | . a | ə | ə | L |   |   |   | . théigheadh | ˈhe:wəd′ | ˈheːjuː |   | théadh | ˈhjeːh | &lt;eadh&gt; → ədʲ / _ # PRONOUN | . sí | ʃi: | ˈʃiː | L |   |   |   | . a |   | ə | L |   |   | ə → ∅ / V # _ | . chur | xo̤r | ˈxuɾˠ | L |   |   |   | . an | ə | ˈəɴˠ | L |   |   |   | . teinidh | ˈt′ʃɪn′i | ˈtʲenʲiː |   | tine |   |   | . as | ïs | ˈasˠ | L |   |   |   | . bhí | vi: | ˈvʲiː | L |   |   |   | . an | n̥ | ˈəɴˠ | L |   |   | ə → ∅ / V # _ | . poitín | ˈpɔt′in′ | ˈpˠotʲinʲ | L |   |   |   | . acú | ɔku | ˈakˠuː |   |   |   |   | . O’Neill, John E. “Irish Texts from South West Donegal.” Zeitschrift Für Celtische Philologie, vol. 33, 1974, doi:10.1515/zcph.1974.33.1.285. &#8617; . |",
            "url": "https://jimregan.github.io/notes/irish/donegal/2021/01/24/irish-texts-from-south-west-donegal-text-1-poitin.html",
            "relUrl": "/irish/donegal/2021/01/24/irish-texts-from-south-west-donegal-text-1-poitin.html",
            "date": " • Jan 24, 2021"
        }
        
    
  
    
        ,"post269": {
            "title": "Iníon an cheannaí",
            "content": "Tá tamall fad anois a bhí fear ina chónaí i mbaile mór Chorcaí. Fear saibhir agus ceannaí farraige ab ea é. Do bhíodh loingeas ag teacht thar lár chúige. Do bhí aon iníon amháin aige gurb é an ainm a bhí uirthi Máire Bhán. Do shíl sí an ainm sin mar ní raibh sí sa bhaile mhór aon chailín comh deas comh maorga léi. Ní raibh éinne clainne aige ina muintir ach í agus do mhéadaigh sin urraim agus grá na ndaoine don iníon óg so. . Ba ghnáthach léi captaen óg loinge teacht ar cuairt go tigh an cheannaí go minic agus bhíodh sé an-cheanúil ar Mháire bhán. Bhí Máire ag titim i ngrá leis i gan fhios di féin. Nuair a imíodh sé ón gcuan bhíodh uaigneas agus díomá an domhain uirthi ach ní bhíodh fhios aici cad é an fáth. Ní raibh aon fhear óg uasal timpeall ná go raibh é tnúth le Máire Bhán i dháil le pósadh ach ní raibh aon mhaith dena bheith á lorg. Ní phósadh sí aon fhear ach a captaen óg. Níor mhaith lena muintir í (a) thabhairt le pósadh dósan. Do b’fhearr leo í a bheith ina gcóngar féin. D’fhan Máire blianta gan pósadh. Deireadh sí ina haigne féin “dá bheadh m’athair bás bheadh sé ar mo chumas mo reogha fear a phósadh.” .",
            "url": "https://jimregan.github.io/notes/irish/2021/01/16/in%C3%ADon-an-cheanna%C3%AD.html",
            "relUrl": "/irish/2021/01/16/in%C3%ADon-an-cheanna%C3%AD.html",
            "date": " • Jan 16, 2021"
        }
        
    
  
    
        ,"post270": {
            "title": "Dinneen, p. 34",
            "content": "ainmheas, -a and -ta, m., disrespect. . ainmheasartha, indec. a., unmeasured, immoderate, intemperate. . ainmheasarthacht, -a, f., immoderateness, excess, intemperance. . ainmheisneach, -nigh and -nighe, m. and f., rashness, hesitancy, weakness, state of discouragement (m. in M.). . ainmheon, a., busy (Clare). . ainmhian, -mhéine, pl. -a, and -ta, dpl. ainmhianaibh (Kea.), f., lust, concupiscence, passion; ainmhianta na colna, the concupiscence of the flesh. . ainmhianach, -aighe, a., passionate, lustful, sensual. . ainmhidhe, g. id., pl. ainmhinte and ainmhidhthe, m., a brute, an animal. . ainmhidheach, -dhighe, a., brutish, beastly. . ainmhidheacht, -a, f., brutality. . ainmhín, -e, a., rough, passionate. . ainmhíne, g. id., f., roughness, coarseness, passionateness. . ainmneach, -nighe, a., famous, illustrious. . ainmneamhail, -mhla, a., famous. . ainmnighim, -iughadh, v. tr., I name, assign. . ainmnighthe, p. a., named, specified; go ha., namely. . ainmniughadh, -ighthe, m., act of naming, denomination, dedication. . ainnir (ainnear), -nire, pl. id., f., a maiden; is í &#39;na hainnir bhig, while she was a young maiden. . ainreacht (ainriocht), -a, pl. id., m., evil plight. . ainriachtanach, -aighe, a., necessitous, poor, miserable. . ainriachtanas, -ais, m., extreme danger, great misery or necessity. . ainriochtach, -aighe, a., pitiable. See riocht. . ainscian, -cine, pl. -ceanna, f., a large knife; fury, extravagance; a furious or wild person. . ainscianach, -aighe, a., furious, extravagant. . ainscianta, indecl. a., furious, extravagant. . ainshearc, g. -eirce and -earca, f., hatred. . ainshearc, m. and f., excessive love. . ainshearcach, -aighe, a., unloving, merciless, cruel. . ainsheascair, -e, a., troublous, uneasy, uncomfortable. . ainspioraid, -e, -idhe, f., an evil spirit; the devil. . ainshrianta, a., unbridled, debauched. . ainshriantacht, -a., f., libertinism, debauchery, unbridled passion. . ainteann, -einne, a., very violent, oppressive, severe; braced up, very stiff, very stout. . ainteas, -a, m., great heat, inflammation, wrath. . ainteasach, -aighe, a., hot, feverish. . ainteasaidhe, indec. a., sultry, warm (of weather). . ainteastach, -aigh, pl. id., m., a false witness; “ainteastach bréag,” a base asserter of lies (Kea.); “innisin scéal ainteastach do bhí fuathmhar dó” (id.). . ainteastach, -aighe, a., falsely testified. . aintighearna, g. id., pl., -idhe, m., a tyrant, an oppressor. . aintighearnacht, -a, f., tyranny, oppression. . aipche, g. id., f., maturity (from abaidh, ripe). . aipidh, see abaid. . air, prep., on, upon, etc.; more generally written ar, which see. . air, prep, pr., m., upon him or it. See ar, prep. . airc, -e, f., greed, voracity; géar-airc (O&#39;Ra.) want, hardship (Don.). . airc, in phr. gheall sé na huirc is na hairc dam, he promised me the world and all. . airc, -e, -eacha, f., a chest, a coffer; an ark. . airc, in various meanings, as a lizard, etc. See earc and arc. .",
            "url": "https://jimregan.github.io/notes/irish/dinneen/2021/01/09/dinneen-p-34.html",
            "relUrl": "/irish/dinneen/2021/01/09/dinneen-p-34.html",
            "date": " • Jan 9, 2021"
        }
        
    
  
    
        ,"post271": {
            "title": "Teanglann pronunciations",
            "content": "Link Ulster Connacht Munster Ulster (Abair IPA) Connacht (Abair IPA) Munster (Abair IPA) Speaker Ulster Speaker Connacht Speaker Munster . ádhúil | ˈauəlʲ | ˈɑːuːlʲ | ɑːˈuːlʲ | ˈaːuːlʲ | ˈɑːɣuːlʲ | ɑːˈɣuːl |   |   |   | . adhmad | ˈɑmˠədˠ | ˈɑmˠədˠ |   | ˈeːmˠədˠ | ˈaimˠədˠ | ˈaimˠədˠ | =ocht |   |   | . adhmad | ˈeːmˠədˠ | ˈɑmˠədˠ |   |   |   |   |   |   |   | . ocht | ˈokˠtˠ |   |   | ˈaxtˠ | ˈoxtˠ | ˈoxtˠ |   |   |   | . seachtain | ˈʃɑxtˠənʲ | ˈʃɑxtˠənʲ | ˈʃɑxtˠənʲ | ˈʃaɾˠtˠənʲ | ˈʃaxtˠənʲ | ˈʃaxtˠənʲ | =ocht |   |   | . Seachtain | ˈʃɑkˠtˠənʲ | ˈʃɑxtˠənʲ | ˈʃɑxtˠənʲ |   |   |   |   |   | =seachtódú | . seacht | ˈʃɑtˠ 1 | ˈʃɑxtˠ | ˈʃɑxtˠ | ˈʃaxtˠ | ˈʃaxtˠ | ˈʃaxtˠ |   |   |   | . seachtó | ˈʃɑhbˠə | ˈʃɑxtˠoː | ˈʃɑxtˠoː | ˈʃaɾˠtˠoː | ˈʃaxtˠuː | ʃaxˈtˠoː |   | =seachtain | =seachtain | . seachtódú | ˈʃɑxtˠodˠuː | ˈʃɑxtˠuːdˠuː | ˈʃɑxtˠoːdˠuː | ˈʃaɾˠtˠodˠuː | ˈʃaxtˠoːdˠuː | ʃaxˈtˠoːdˠuː |   |   |   | . ochtó | ˈoxtˠwa | ˈoxtˠoː | ˈoxtˠoː | ˈaxtˠoː | ˈoxtˠuː | oxˈtˠoː |   |   |   | . srónach |   |   | ˈʃɾˠoːnˠəx | ˈsˠɾˠoːɴˠah | ˈsˠɾˠoːɴˠəx | ˈsˠɾˠoːnˠəx |   |   |   | . teorainn | ˈtʲoːˈɾˠaɴʲ | ˈtʲoːɾˠəɴʲ | ˈtʲoːɾˠə 2 | ˈtʲoːɾˠəɴʲ | ˈtʲoːˈɾˠaɴʲ | ˈtʲoːɾˠənʲ |   |   |   | . sram | ˈsˠɾˠɑmˠ | ˈsˠɾˠɑmˠ | ˈsˠɾˠɑmˠ | ˈsˠɾˠamˠ | ˈsˠɾˠamˠ | ˈsˠɾˠamˠ |   |   |   | . seachtar | ˈʃɑtˠəɾˠ |   |   | ˈʃaɾˠtˠəɾˠ | ˈʃaxtˠəɾˠ | ˈʃaxtˠəɾˠ | =seacht |   |   | . seachtar | ˈʃɑtˠə |   |   |   |   |   | =seacht |   |   | . cathlán | ˈkˠaʟ̥ˠaɴˠ | ˈkˠaʟˠɑːɴˠ | kˠɑˈl̥ˠɑːnˠ | ˈkˠahʟˠaɴˠ | ˈkˠahʟˠɑːɴˠ | kˠaˈhlˠɑːnˠ |   |   |   | . Or ˈʃɑhtˠ ? &#8617; . | teora &#8617; . |",
            "url": "https://jimregan.github.io/notes/irish/teanglann/2020/11/25/teanglann-pronunciations.html",
            "relUrl": "/irish/teanglann/2020/11/25/teanglann-pronunciations.html",
            "date": " • Nov 25, 2020"
        }
        
    
  
    
        ,"post272": {
            "title": "Teanglann compound pronunciations",
            "content": "Word Compound Ulster Connacht Munster Ulster (Abair IPA) Connacht (Abair IPA) Munster (Abair IPA) Speaker Ulster Speaker Connacht Speaker Munster . tuathghríosóir | tuath+ghríosóir | ˈtˠuahəˈɾʲiːsˠəɾʲ | ˈtˠuˈʝiːsˠoːɾʲ | ˈtˠuəʝɾʲiːˈsˠoːɾʲ | ˈtˠuajɾʲisˠoɾʲ | ˈtˠuəˈjɾʲiːsˠoːɾʲ | ˈtˠuəjɾʲiːˈsˠoːɾʲ |   |   |   | . leathréal | leath+réal | ˈʟʲaɾ̥ˠeːʟˠ |   |   | ˈʟʲaˈɾˠeːʟˠ | ˈʟʲaˈɾˠeːʟˠ | ˈlʲaˈɾˠeːlˠ |   |   |   | . leathnóta | leath+nóta | ˈʟʲaˌɴ̥ˠoːtˠə |   |   | ˈʟʲaˈɴˠoːtˠə | ˈʟʲaˈɴˠoːtˠə | ˈlʲaˈnˠoːtˠə |   |   |   | . leathghealach | leath+ghealach | ˈʟʲaˈçɑʟˠəx |   | ˈlʲaʝaˈlˠɑx | ˈʟʲaˈjaʟˠəh | ˈʟʲaˈjaʟˠəx | ˈlʲajəˈlˠax |   |   |   | . leathchiorcal | leath+chiorcal | ˈʟʲaˈçoɾˠkˠəʟˠ | ˈʟʲaˈçoɾˠkˠəʟˠ |   | ˈʟʲaˈçiɾˠkˠəʟˠ | ˈʟʲaˈçiɾˠkˠəʟˠ | ˈlʲaˈçiɾˠkˠəʟˠ |   |   |   | . iathghlas | iath+ghlas | iəxʟˠasˠ | ˈiəɣʟˠasˠ | iəˈɣlˠɑsˠ | ˈiəhɣʟˠəsˠ | ˈiəhɣʟˠəsˠ | ˈiəhɣlˠəsˠ |   |   |   | . leathard | leath+ard | ˈʟʲehaɾˠd | ˈʟʲaˈɑːɾˠdˠ | ˈlʲaˈhɑːɾˠdˠ | ˈʟʲaˈaɾˠdˠ | ˈʟʲaˈɑːɾˠdˠ | ˈlʲaˈɑːɾˠdˠ |   |   |   | . leathardaithe | leath+ardaithe | ˈʟʲaˈaɾˠdˠiːhə | ˈʟʲaˈɑːɾˠdˠiː | ˈlʲaˈɑːɾˠdˠəhə | ˈʟʲaˈaɾˠdˠəhə | ˈʟʲaˈaɾˠdˠəhə | ˈlʲaˈaɾˠdˠəhə | =leathard | =leathard | =leathard | . leathfhocal | leath+fhocal |   |   |   | ˈʟʲaˈhokˠəʟˠ | ˈʟʲaˈokˠəʟˠ | ˈlʲaˈokˠəlˠ |   |   |   | . leathshlí | leath+shlí | ˈʟʲaˈl̥ʲiː | ʟʲaˈl̥ʲiː | ˈlʲaˈl̥ʲiː | ˈʟʲaˈhlʲi | ˈʟʲaˈl̪ʲiː | ˈlʲaˈʃlʲiː |   |   |   | . dlúthdhiosca | dlúth+dhiosca |   |   |   | ˈdˠʟˠuːˈjisˠkˠə | ˈdˠʟˠuːjisˠkˠə | ˈdˠlˠuːˈjisˠkˠə |   |   |   | . dlúthshaothair | dlúth+shaothair | ˈdˠʟˠuːhiːhəɾʲ | ˈdˠʟˠuːhiːhəɾʲ |   | ˈdˠʟˠuːˈhiːhəɾʲ | ˈdˠʟˠuːˈhiːhəɾʲ | ˈdˠlˠuːˈheːhəɾ |   |   |   | . dlúthfhostaíochta | dlúth+fhostaíochta | ˈdˠʟˠuːˈosˠtˠiəktˠə |   |   | ˈdˠʟˠuːˈoˈsˠtˠiːɾˠtˠə | ˈdˠʟˠuːˈoˈsˠtˠiːxtˠə | ˈdˠlˠuːosˠˈtˠiəxtˠə | =ocht |   |   | . scáthlínigh | scáth+línigh | ˈsˠkˠaːl̥ʲiːnʲiː | ˈsˠkˠɑːlʲiːnʲə | sˠkˠɑːˈlʲiːnʲiɟ | ˈsˠkˠaːhlʲiːnʲə | ˈsˠkˠɑːhlʲiːnʲə | sˠkˠɑːˈhlʲiːnʲiɟ |   |   |   | . liathghorm | liath+ghorm |   |   |   | ˈʟʲiəˈɣoɾˠəmˠ | ˈʟʲiəˈɣoɾˠəmˠ | lʲiəɣoɾˠəmˠ |   |   |   | . atheisiúint | ath+eisiúint |   |   |   | ˈaˈeʃuɴʲtʲ | ˈaˈeʃuːnʲtʲ | ˈaeˈʃuːnʲtʲ |   |   |   | . atheisigh | ath+eisigh | ˈaˈheʃiː |   |   | ˈaˈeʃiː | ˈaˈeʃə | ˈaˈeʃiɟ |   |   |   | . atheagrú | ath+eagrú | ˈaˈhagˠɾˠuː |   | aˌhagˠˈɾˠuː | ˈaˈagˠɾˠuː | ˈaˈagˠɾˠuː | ˈaˌagˠəˈɾˠuː |   |   |   | . athdhréacht | ath+dhréacht | ˈaˈɾ̥ʲeːxtˠ | ˈaˈɾʲeːxtˠ | ɑˈʝɾʲeːxtˠ | ˈaˈjɾʲeːxtˠ | ˈaˈjɾʲeːxtˠ | ˈaˈjɾʲeːxtˠ |   |   |   | . athdhreas | ath+dhreas | ˈaˈhjɾʲasˠ | ˈaɾʲasˠ | ɑˈɾ̥ʲasˠ | ˈaˈjɾʲasˠ | ˈaˈjɾʲasˠ | ˈaˈjɾʲasˠ |   |   |   | . athdhreasaigh | ath+dhreasaigh | ˈaiˈɾʲasˠiː | ˈaˈvʲasˠə | aˈhjasˠiɟ 1 | ˈaˈjɾʲasˠiː | ˈaˈjɾʲasˠə | ˈaˈjɾʲasˠiɟ |   |   | =atheagraigh | . atheagraigh | ath+eagraigh | ˈaˈhagˠɾˠiː | ˈaˈhagˠɾˠə | ˈaˈhagˠɾˠiɟ | ˈaˈagˠɾˠiː | ˈaˈagˠɾˠə | ˈaˈagˠəɾˠiɟ |   |   |   | . athfheistigh | ath+fheistigh |   |   |   | ˈaˈeʃtʲiː | ˈaˈeʃtʲə | ˈaˈeʃtʲiɟ |   |   |   | . athdheisigh | ath+dheisigh | ˈahˈjeʃiː |   | ɑˈjeʃiɟ | ˈaˈjeʃə | ˈaˈjeʃə | ˈaˈjeʃiɟ |   |   |   | . athdhíol | ath+dhíol | ˈahˈjiːʟˠ | ˈajiːʟˠ | aˈjiəlˠ | ˈaˈjiːʟˠ | ˈaˈjiːʟˠ | ˈaˈjiəlˠ |   |   |   | . athdhírigh | ath+dhírigh | ˈahjiːɾʲiː |   | aˈiːɾʲiɟ | ˈaˈjiːɾʲiː | ˈaˈjiːɾʲə | ˈaˈjiːɾʲiɟ |   |   |   | . athimir | ath+imir |   |   | aˈhimʲəɾʲ | ˈaˈimʲəɾʲ | ˈaˈimʲəɾʲ | ˈaˈimʲəɾʲ |   |   |   | . athláimhe | ath+láimhe |   |   | aˈlˠɑːvʲə 2 | ˈaˈʟˠaːvʲə | ˈaˌʟˠɑːvʲə | ˈaˈlˠɑːvʲə |   |   | =athdhíol | . athleabaigh | ath+leabaigh | ˈaˈʟ̥ʲabˠiː |   | ɑˈlʲɑbˠiɟ | ˈaˈʟʲabˠiː | ˈaˈʟʲabˠə | ˈaˈlʲabˠiɟ |   |   |   | . athmhaoinigh | ath+mhaoinigh | ˈaˈhwiːnʲiː |   | aˈvˠiːnʲiɟ | ˈaˈwiːnʲiː | ˈaˈwiːnʲə | ˈaˈwiːnʲiɟ |   |   |   | . athghin | ath+ghin | ˈaçinʲ | ˈajinʲ | ɑˈçjinʲ | ˈaˈjinʲ | ˈaˈjinʲədʲəx | ˈaˈjinʲ |   |   |   | . saincheaptha | sain+cheaptha | ˈsˠanʲˈçapˠə | ˈsˠanʲˈçapˠiː | ˈsˠanʲˈçapəˠhə | ˈsˠanʲˈçapˠhə | ˈsˠanʲˈçapˠə | ˈsˠanʲˈçapˠhə |   |   |   | . uathoibreán | uath+oibreán | u:ˈibʲɾʲaɴˠ | ˈuˈəibʲɾʲɑːɴˠ | ˈuːiˈbʲɾʲɑːnˠ | ˈuahˈobʲɾʲaɴˠ | ˈuəˈobʲɾʲɑːɴˠ | ˈuəoˈbʲɾʲɑːnˠ |   |   |   | . uathfheidhmeach | uath+fheidhmeach | ˈu:ˈaimʲah |   | u:ˈaimʲəx | ˈuahˈaimʲah | ˈuəˈaimʲəx | ˈuəˈaimʲəx | =uathoibreán | =uathoibreán | =uathoibreán | . uasghrádú | uas+ghrádú |   |   | uəsˠˈɾˠɑːdˠu | ˈuəsˠˈɣɾˠaːdˠuː | ˈuəsˠˈɣɾˠɑːdˠuː | ˈuəsˠɣɾˠɑːˈdˠu |   |   |   | . sraithadhmad | sraith+adhmad | ˈsˠɾˠaˈhjemˠədˠ | ˈsˠɾˠɑˈɑ:mˠədˠ | sˠɾˠɑˈaimˠədˠ | ˈsˠɾˠaiˈhjeːmˠədˠ | ˈsˠɾˠahəmˠədˠ | ˈsˠɾˠahəmˠədˠ |   |   |   | . sraithchomórtas | sraith+chomórtas | ˈsˠɾˠaiˈhomˠoɾˠtˠəsˠ | ˈsˠɾˠɑˌxomˠoːɾˠtˠəsˠ | ˈsˠɾˠaxəˈmˠoːɾˠtˠəsˠ | ˈsˠɾˠaˈhomˠoɾˠtˠəsˠ | ˈsˠɾˠaˌxomˠoːɾˠtˠəsˠ | ˌsˠɾˠahxəˈmˠoːɾˠtˠəsˠ |   |   |   | . sramshúileach | sram+shúileach | ˈsˠɾˠɑmˠˈhuːlʲə | ˈsˠɾˠɑmˠˈhuːlʲəx | ˈsˠɾˠɑmˠˈhuːlʲəx | ˈsˠɾˠamˠhuːlʲəh | ˈsˠɾˠamˠhuːlʲəx | sˠɾˠamˠˈhuːlʲəx |   |   | ! | . Same speaker as ‘atheagraigh’; no accent on ‘ath’ here, but there is there (Ó Sé, pt 830) &#8617; . | Ó Sé, pt. 830 (p. 471): “Bionn suiomh na béime de réir riail bhéime an chomhfhocail nuair atá guta fada i dtús an fhocail” &#8617; . |",
            "url": "https://jimregan.github.io/notes/irish/teanglann/2020/11/25/teanglann-compound-pronunciations.html",
            "relUrl": "/irish/teanglann/2020/11/25/teanglann-compound-pronunciations.html",
            "date": " • Nov 25, 2020"
        }
        
    
  
    
        ,"post273": {
            "title": "Evernote web clips, 16/10/2020",
            "content": "High or low? Comparing high and low-variability phonetic training in adult and child second language learners . Introducing LexTALE: A quick and valid Lexical Test for Advanced Learners of English . A Tutorial on Extracting Formants in Praat . A Dive Into GhostNet with PyTorch and TensorFlow .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/praat/2020/10/16/evernote-links.html",
            "relUrl": "/evernote/web%20clip/praat/2020/10/16/evernote-links.html",
            "date": " • Oct 16, 2020"
        }
        
    
  
    
        ,"post274": {
            "title": "Evernote web clips, 5/10/2020",
            "content": "How to use multiple keywords in Pocketsphinx continuous mode . Richer Sentence Embeddings using Sentence-BERT — Part I . Examples of synthesizing sounds with Praat VocalTract area functions . Recommendations for Real-Time Speech MRI .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2020/10/05/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2020/10/05/evernote-links.html",
            "date": " • Oct 5, 2020"
        }
        
    
  
    
        ,"post275": {
            "title": "Evernote web clips, 29/9/2020",
            "content": "Poor Man’s BERT - Exploring layer pruning . Computing MFCCs voice recognition features on ARM systems . Beginner’s guide to Speech Analysis . Yes you should understand backprop . Long Form Question Answering with ELI5 and Wikipedia . A Framework For Contrastive Self-Supervised Learning And Designing A New Approach . DeepSpeech-Polyglot-PL - Google Drive . Speech Recognition — ASR Model Training .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2020/09/29/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2020/09/29/evernote-links.html",
            "date": " • Sep 29, 2020"
        }
        
    
  
    
        ,"post276": {
            "title": "Training spaCy on IDT",
            "content": "!git clone https://github.com/UniversalDependencies/UD_Irish-IDT . Cloning into &#39;UD_Irish-IDT&#39;... remote: Enumerating objects: 32, done. remote: Counting objects: 100% (32/32), done. remote: Compressing objects: 100% (23/23), done. remote: Total 328 (delta 14), reused 25 (delta 9), pack-reused 296 Receiving objects: 100% (328/328), 3.63 MiB | 12.73 MiB/s, done. Resolving deltas: 100% (182/182), done. . !mkdir idt-json . !python -m spacy convert /content/UD_Irish-IDT/ga_idt-ud-train.conllu /content/idt-json . ✔ Generated output file (2019 documents): /content/idt-json/ga_idt-ud-train.json . !python -m spacy convert /content/UD_Irish-IDT/ga_idt-ud-dev.conllu /content/idt-json . ✔ Generated output file (451 documents): /content/idt-json/ga_idt-ud-dev.json . !wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ga.300.vec.gz !python -m spacy init-model ga /content/ga_vectors_cc --vectors-loc cc.ga.300.vec.gz . --2020-09-14 17:16:11-- https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ga.300.vec.gz Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.75.142, 104.22.74.142, ... Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 184422000 (176M) [binary/octet-stream] Saving to: ‘cc.ga.300.vec.gz’ cc.ga.300.vec.gz 100%[===================&gt;] 175.88M 44.2MB/s in 4.0s 2020-09-14 17:16:16 (43.8 MB/s) - ‘cc.ga.300.vec.gz’ saved [184422000/184422000] ✔ Successfully created model 316836it [00:27, 11398.56it/s] ✔ Loaded vectors from cc.ga.300.vec.gz ✔ Sucessfully compiled vocab 317041 entries, 316836 vectors . WikiANN is currently only available through Google Drive . from google.colab import drive drive.mount(&#39;/gdrive&#39;) . Mounted at /gdrive . !cp /gdrive/My Drive/ga.tar.gz . . !tar zxvf ga.tar.gz . README.txt wikiann-ga.bio . !wget http://downloads.dbpedia.org/links/resources/wikidatadump/2017-07-07/enwiki/20170701/enwiki-20170701-interlanguage-links_wikidataorg.ttl . --2020-09-14 17:15:11-- http://downloads.dbpedia.org/links/resources/wikidatadump/2017-07-07/enwiki/20170701/enwiki-20170701-interlanguage-links_wikidataorg.ttl Resolving downloads.dbpedia.org (downloads.dbpedia.org)... 139.18.16.66 Connecting to downloads.dbpedia.org (downloads.dbpedia.org)|139.18.16.66|:80... connected. HTTP request sent, awaiting response... 200 OK Length: 1020894244 (974M) [text/turtle] Saving to: ‘enwiki-20170701-interlanguage-links_wikidataorg.ttl’ enwiki-20170701-int 100%[===================&gt;] 973.60M 18.7MB/s in 54s 2020-09-14 17:16:05 (18.1 MB/s) - ‘enwiki-20170701-interlanguage-links_wikidataorg.ttl’ saved [1020894244/1020894244] . !cat wikiann-ga.bio | awk &#39;(NF == 7){print $6}&#39;|sort|uniq|while read i;do grep &quot;/$i&gt;&quot; enwiki-20170701-interlanguage-links_wikidataorg.ttl &gt;&gt; filtered;done . !pip install danlp . Collecting danlp Downloading https://files.pythonhosted.org/packages/3c/79/96d0d3f3634ce75787d408383fa81cdd854552e27e4e279a985b511a6d88/danlp-0.0.9-py3-none-any.whl Collecting pyconll Downloading https://files.pythonhosted.org/packages/2c/6e/c325d0db05ac1b8d45645de903e4ba691d419e861c915c3d4ebfcaf8ac25/pyconll-2.2.1-py3-none-any.whl Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from danlp) (4.41.1) Requirement already satisfied: tweepy in /usr/local/lib/python3.6/dist-packages (from danlp) (3.6.0) Requirement already satisfied: requests&gt;=2.21 in /usr/local/lib/python3.6/dist-packages (from pyconll-&gt;danlp) (2.23.0) Requirement already satisfied: six&gt;=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy-&gt;danlp) (1.15.0) Requirement already satisfied: PySocks&gt;=1.5.7 in /usr/local/lib/python3.6/dist-packages (from tweepy-&gt;danlp) (1.7.1) Requirement already satisfied: requests-oauthlib&gt;=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy-&gt;danlp) (1.3.0) Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests&gt;=2.21-&gt;pyconll-&gt;danlp) (2020.6.20) Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.6/dist-packages (from requests&gt;=2.21-&gt;pyconll-&gt;danlp) (2.10) Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests&gt;=2.21-&gt;pyconll-&gt;danlp) (1.24.3) Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests&gt;=2.21-&gt;pyconll-&gt;danlp) (3.0.4) Requirement already satisfied: oauthlib&gt;=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib&gt;=0.7.0-&gt;tweepy-&gt;danlp) (3.1.0) Installing collected packages: pyconll, danlp Successfully installed danlp-0.0.9 pyconll-2.2.1 . import danlp.datasets.wiki_ann wa = danlp.datasets.wiki_ann._convert_wikiann_to_iob(&#39;wikiann-ga.bio&#39;, &#39;wikiann-ga.ner&#39;) . !head out . Colm _ _ B-PER Ó _ _ I-PER Ruairc _ _ I-PER Seosamh _ _ B-PER Ó _ _ I-PER Cainín _ _ I-PER Dónal _ _ B-PER Ó _ _ I-PER . !python -m spacy convert -n 10 wikiann-ga.ner /content/idt-json/ . ℹ Auto-detected token-per-line NER format ℹ Grouping every 10 sentences into a document. ✔ Generated output file (757 documents): /content/idt-json/wikiann-ga.json . !rm -rf models !mkdir models !python -m spacy train -v /content/ga_vectors_cc -p &#39;tagger,parser,ner&#39; ga models idt-json/ga_idt-ud-train.json idt-json/ga_idt-ud-dev.json . Training pipeline: [&#39;tagger&#39;, &#39;parser&#39;] Starting with blank model &#39;ga&#39; Loading vector from model &#39;/content/ga_vectors_cc&#39; Counting training words (limit=0) /usr/lib/python3.6/runpy.py:193: UserWarning: [W022] Training a new part-of-speech tagger using a model with no lemmatization rules or data. This means that the trained model may not be able to lemmatize correctly. If this is intentional or the language you&#39;re using doesn&#39;t have lemmatization data, you can ignore this warning by setting SPACY_WARNING_IGNORE=W022. If this is surprising, make sure you have the spacy-lookups-data package installed. &#34;__main__&#34;, mod_spec) Itn Tag Loss Tag % Dep Loss UAS LAS Token % CPU WPS -- - - 1 14058.829 90.650 43482.222 74.804 56.787 100.000 11293 2 6188.294 92.810 34097.493 79.836 66.009 100.000 11461 3 4475.949 93.400 30061.441 81.314 69.572 100.000 11930 4 3549.242 93.530 27752.841 82.784 71.759 100.000 11719 5 2916.639 93.570 25861.771 83.066 72.401 100.000 11616 6 2438.355 93.550 24533.545 83.133 72.726 100.000 12227 7 2084.913 93.500 22901.218 83.281 73.043 100.000 11842 8 1845.607 93.610 21836.129 83.516 73.346 100.000 12094 9 1698.212 93.630 20626.109 83.555 73.507 100.000 11907 10 1406.626 93.570 19251.761 83.712 73.978 100.000 11926 11 1366.677 93.620 18882.570 83.896 74.128 100.000 12023 12 1209.500 93.610 17836.598 83.968 74.177 100.000 11924 13 1140.886 93.640 17341.624 84.098 74.375 100.000 11522 14 1043.542 93.670 16748.375 83.992 74.292 100.000 11766 15 926.876 93.700 15727.938 84.183 74.572 100.000 11931 16 848.805 93.680 15002.112 84.059 74.427 100.000 11750 17 857.415 93.760 14686.168 84.075 74.465 100.000 11724 18 775.277 93.750 14028.872 84.091 74.603 100.000 11890 19 651.078 93.680 13698.526 84.215 74.794 100.000 11932 20 672.552 93.670 13036.999 84.356 74.879 100.000 11724 21 590.244 93.670 12162.862 84.468 75.048 100.000 11851 22 593.722 93.680 12494.905 84.441 75.122 100.000 11910 23 582.541 93.660 12110.757 84.351 75.032 100.000 11544 24 514.448 93.690 11635.750 84.232 74.879 100.000 11984 25 491.457 93.640 10942.966 84.226 74.816 100.000 12106 26 521.324 93.660 10958.952 84.232 74.779 100.000 12112 27 507.717 93.650 10907.860 84.255 74.790 100.000 11754 28 485.186 93.660 10149.477 84.143 74.666 100.000 11411 29 507.038 93.720 10331.116 84.165 74.644 100.000 11740 30 477.966 93.700 9649.121 84.300 74.891 100.000 11300 ✔ Saved model to output directory models/model-final ✔ Created best model models/model-best . !mkdir modelout !python -m spacy package --meta meta.json /content/models/model-best modelout . ✔ Loaded meta.json from file meta.json ✔ Successfully created package &#39;ga_idt_lg-1.0.0&#39; modelout/ga_idt_lg-1.0.0 To build the package, run `python setup.py sdist` in this directory. . import os os.chdir(&#39;/content/modelout/ga_idt_lg-1.0.0&#39;) !python setup.py sdist . running sdist running egg_info creating ga_idt_lg.egg-info writing ga_idt_lg.egg-info/PKG-INFO writing dependency_links to ga_idt_lg.egg-info/dependency_links.txt writing requirements to ga_idt_lg.egg-info/requires.txt writing top-level names to ga_idt_lg.egg-info/top_level.txt writing manifest file &#39;ga_idt_lg.egg-info/SOURCES.txt&#39; reading manifest file &#39;ga_idt_lg.egg-info/SOURCES.txt&#39; reading manifest template &#39;MANIFEST.in&#39; writing manifest file &#39;ga_idt_lg.egg-info/SOURCES.txt&#39; warning: sdist: standard file not found: should have one of README, README.rst, README.txt, README.md running check creating ga_idt_lg-1.0.0 creating ga_idt_lg-1.0.0/ga_idt_lg creating ga_idt_lg-1.0.0/ga_idt_lg.egg-info creating ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0 creating ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/parser creating ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/tagger creating ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/vocab copying files to ga_idt_lg-1.0.0... copying MANIFEST.in -&gt; ga_idt_lg-1.0.0 copying meta.json -&gt; ga_idt_lg-1.0.0 copying setup.py -&gt; ga_idt_lg-1.0.0 copying ga_idt_lg/__init__.py -&gt; ga_idt_lg-1.0.0/ga_idt_lg copying ga_idt_lg/meta.json -&gt; ga_idt_lg-1.0.0/ga_idt_lg copying ga_idt_lg.egg-info/PKG-INFO -&gt; ga_idt_lg-1.0.0/ga_idt_lg.egg-info copying ga_idt_lg.egg-info/SOURCES.txt -&gt; ga_idt_lg-1.0.0/ga_idt_lg.egg-info copying ga_idt_lg.egg-info/dependency_links.txt -&gt; ga_idt_lg-1.0.0/ga_idt_lg.egg-info copying ga_idt_lg.egg-info/not-zip-safe -&gt; ga_idt_lg-1.0.0/ga_idt_lg.egg-info copying ga_idt_lg.egg-info/requires.txt -&gt; ga_idt_lg-1.0.0/ga_idt_lg.egg-info copying ga_idt_lg.egg-info/top_level.txt -&gt; ga_idt_lg-1.0.0/ga_idt_lg.egg-info copying ga_idt_lg/ga_idt_lg-1.0.0/meta.json -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0 copying ga_idt_lg/ga_idt_lg-1.0.0/tokenizer -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0 copying ga_idt_lg/ga_idt_lg-1.0.0/parser/cfg -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/parser copying ga_idt_lg/ga_idt_lg-1.0.0/parser/model -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/parser copying ga_idt_lg/ga_idt_lg-1.0.0/parser/moves -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/parser copying ga_idt_lg/ga_idt_lg-1.0.0/tagger/cfg -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/tagger copying ga_idt_lg/ga_idt_lg-1.0.0/tagger/model -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/tagger copying ga_idt_lg/ga_idt_lg-1.0.0/tagger/tag_map -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/tagger copying ga_idt_lg/ga_idt_lg-1.0.0/vocab/key2row -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/vocab copying ga_idt_lg/ga_idt_lg-1.0.0/vocab/lexemes.bin -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/vocab copying ga_idt_lg/ga_idt_lg-1.0.0/vocab/strings.json -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/vocab copying ga_idt_lg/ga_idt_lg-1.0.0/vocab/vectors -&gt; ga_idt_lg-1.0.0/ga_idt_lg/ga_idt_lg-1.0.0/vocab Writing ga_idt_lg-1.0.0/setup.cfg creating dist Creating tar archive removing &#39;ga_idt_lg-1.0.0&#39; (and everything under it) . !cat /content/models/model-best/meta.json . { &#34;lang&#34;:&#34;ga&#34;, &#34;name&#34;:&#34;model&#34;, &#34;version&#34;:&#34;0.0.0&#34;, &#34;spacy_version&#34;:&#34;&gt;=2.2.4&#34;, &#34;description&#34;:&#34;&#34;, &#34;author&#34;:&#34;&#34;, &#34;email&#34;:&#34;&#34;, &#34;url&#34;:&#34;&#34;, &#34;license&#34;:&#34;&#34;, &#34;vectors&#34;:{ &#34;width&#34;:300, &#34;vectors&#34;:316836, &#34;keys&#34;:316836, &#34;name&#34;:&#34;ga_model.vectors&#34; }, &#34;pipeline&#34;:[ &#34;tagger&#34;, &#34;parser&#34; ], &#34;factories&#34;:{ &#34;tagger&#34;:&#34;tagger&#34;, &#34;parser&#34;:&#34;parser&#34; }, &#34;labels&#34;:{ &#34;tagger&#34;:[ &#34;!&#34;, &#34;.&#34;, &#34;...&#34;, &#34;?&#34;, &#34;Abr&#34;, &#34;Ad&#34;, &#34;Adj&#34;, &#34;Art&#34;, &#34;CM&#34;, &#34;CU&#34;, &#34;Cmp&#34;, &#34;Cmpd&#34;, &#34;CmpdNoGen&#34;, &#34;Comp&#34;, &#34;Cond&#34;, &#34;Coord&#34;, &#34;Cop&#34;, &#34;Cp&#34;, &#34;Deg&#34;, &#34;Dem&#34;, &#34;Det&#34;, &#34;Dir&#34;, &#34;Foreign&#34;, &#34;FutInd&#34;, &#34;Gn&#34;, &#34;Idf&#34;, &#34;Imper&#34;, &#34;Inf&#34;, &#34;Item&#34;, &#34;Itj&#34;, &#34;Its&#34;, &#34;Loc&#34;, &#34;Nm&#34;, &#34;Noun&#34;, &#34;Num&#34;, &#34;PastImp&#34;, &#34;PastInd&#34;, &#34;Pat&#34;, &#34;Pers&#34;, &#34;Poss&#34;, &#34;Prep&#34;, &#34;PresImp&#34;, &#34;PresInd&#34;, &#34;PresSubj&#34;, &#34;Pron&#34;, &#34;Punct&#34;, &#34;Q&#34;, &#34;Ref&#34;, &#34;Rel&#34;, &#34;Simp&#34;, &#34;Subord&#34;, &#34;Subst&#34;, &#34;Sup&#34;, &#34;Temp&#34;, &#34;Unknown&#34;, &#34;VD&#34;, &#34;VI&#34;, &#34;VT&#34;, &#34;VTI&#34;, &#34;Vb&#34;, &#34;Voc&#34;, &#34;Web&#34;, &#34;_SP&#34;, &#34;cionn&#34; ], &#34;parser&#34;:[ &#34;ROOT&#34;, &#34;acl:relcl&#34;, &#34;advcl&#34;, &#34;advmod&#34;, &#34;amod&#34;, &#34;appos&#34;, &#34;case&#34;, &#34;cc&#34;, &#34;ccomp&#34;, &#34;compound&#34;, &#34;conj&#34;, &#34;cop&#34;, &#34;csubj:cleft&#34;, &#34;csubj:cop&#34;, &#34;dep&#34;, &#34;det&#34;, &#34;fixed&#34;, &#34;flat&#34;, &#34;flat:name&#34;, &#34;mark&#34;, &#34;mark:prt&#34;, &#34;nmod&#34;, &#34;nmod:poss&#34;, &#34;nsubj&#34;, &#34;nummod&#34;, &#34;obj&#34;, &#34;obl&#34;, &#34;obl:prep&#34;, &#34;obl:tmod&#34;, &#34;parataxis&#34;, &#34;punct&#34;, &#34;xcomp&#34;, &#34;xcomp:pred&#34; ] }, &#34;accuracy&#34;:{ &#34;tags_acc&#34;:92.23, &#34;token_acc&#34;:100.0, &#34;las&#34;:68.3640850205, &#34;uas&#34;:80.5899837362, &#34;las_per_type&#34;:{ &#34;nummod&#34;:{ &#34;p&#34;:70.0, &#34;r&#34;:61.5384615385, &#34;f&#34;:65.4970760234 }, &#34;root&#34;:{ &#34;p&#34;:88.0266075388, &#34;r&#34;:88.0266075388, &#34;f&#34;:88.0266075388 }, &#34;case&#34;:{ &#34;p&#34;:88.8535031847, &#34;r&#34;:91.7763157895, &#34;f&#34;:90.2912621359 }, &#34;obl&#34;:{ &#34;p&#34;:47.0031545741, &#34;r&#34;:54.9815498155, &#34;f&#34;:50.6802721088 }, &#34;mark:prt&#34;:{ &#34;p&#34;:71.1538461538, &#34;r&#34;:81.9620253165, &#34;f&#34;:76.1764705882 }, &#34;ccomp&#34;:{ &#34;p&#34;:40.2777777778, &#34;r&#34;:47.5409836066, &#34;f&#34;:43.6090225564 }, &#34;nsubj&#34;:{ &#34;p&#34;:75.1824817518, &#34;r&#34;:79.7213622291, &#34;f&#34;:77.3854244929 }, &#34;obj&#34;:{ &#34;p&#34;:55.5555555556, &#34;r&#34;:49.2957746479, &#34;f&#34;:52.2388059701 }, &#34;nmod&#34;:{ &#34;p&#34;:52.912142152, &#34;r&#34;:54.8618219038, &#34;f&#34;:53.8693467337 }, &#34;mark&#34;:{ &#34;p&#34;:82.7715355805, &#34;r&#34;:72.6973684211, &#34;f&#34;:77.408056042 }, &#34;xcomp&#34;:{ &#34;p&#34;:60.4743083004, &#34;r&#34;:65.3846153846, &#34;f&#34;:62.8336755647 }, &#34;acl:relcl&#34;:{ &#34;p&#34;:47.2602739726, &#34;r&#34;:53.488372093, &#34;f&#34;:50.1818181818 }, &#34;xcomp:pred&#34;:{ &#34;p&#34;:44.0476190476, &#34;r&#34;:59.6774193548, &#34;f&#34;:50.6849315068 }, &#34;amod&#34;:{ &#34;p&#34;:57.5438596491, &#34;r&#34;:54.3046357616, &#34;f&#34;:55.8773424191 }, &#34;det&#34;:{ &#34;p&#34;:92.8480204342, &#34;r&#34;:94.0491591203, &#34;f&#34;:93.4447300771 }, &#34;csubj:cleft&#34;:{ &#34;p&#34;:47.2222222222, &#34;r&#34;:27.4193548387, &#34;f&#34;:34.693877551 }, &#34;obl:prep&#34;:{ &#34;p&#34;:77.6041666667, &#34;r&#34;:65.6387665198, &#34;f&#34;:71.1217183771 }, &#34;advcl&#34;:{ &#34;p&#34;:54.4, &#34;r&#34;:49.2753623188, &#34;f&#34;:51.711026616 }, &#34;parataxis&#34;:{ &#34;p&#34;:42.4242424242, &#34;r&#34;:27.4509803922, &#34;f&#34;:33.3333333333 }, &#34;nmod:poss&#34;:{ &#34;p&#34;:73.4939759036, &#34;r&#34;:75.3086419753, &#34;f&#34;:74.3902439024 }, &#34;cc&#34;:{ &#34;p&#34;:78.9473684211, &#34;r&#34;:79.5454545455, &#34;f&#34;:79.2452830189 }, &#34;conj&#34;:{ &#34;p&#34;:42.7609427609, &#34;r&#34;:42.0529801325, &#34;f&#34;:42.4040066778 }, &#34;dep&#34;:{ &#34;p&#34;:0.0, &#34;r&#34;:0.0, &#34;f&#34;:0.0 }, &#34;compound&#34;:{ &#34;p&#34;:75.0, &#34;r&#34;:26.0869565217, &#34;f&#34;:38.7096774194 }, &#34;flat&#34;:{ &#34;p&#34;:64.1025641026, &#34;r&#34;:64.9350649351, &#34;f&#34;:64.5161290323 }, &#34;cop&#34;:{ &#34;p&#34;:69.3251533742, &#34;r&#34;:70.625, &#34;f&#34;:69.9690402477 }, &#34;flat:name&#34;:{ &#34;p&#34;:63.4782608696, &#34;r&#34;:51.4084507042, &#34;f&#34;:56.8093385214 }, &#34;obl:tmod&#34;:{ &#34;p&#34;:66.6666666667, &#34;r&#34;:2.7397260274, &#34;f&#34;:5.2631578947 }, &#34;advmod&#34;:{ &#34;p&#34;:66.2745098039, &#34;r&#34;:65.0, &#34;f&#34;:65.6310679612 }, &#34;appos&#34;:{ &#34;p&#34;:21.9512195122, &#34;r&#34;:20.9302325581, &#34;f&#34;:21.4285714286 }, &#34;flat:foreign&#34;:{ &#34;p&#34;:0.0, &#34;r&#34;:0.0, &#34;f&#34;:0.0 }, &#34;fixed&#34;:{ &#34;p&#34;:74.7663551402, &#34;r&#34;:61.0687022901, &#34;f&#34;:67.2268907563 }, &#34;csubj:cop&#34;:{ &#34;p&#34;:62.5, &#34;r&#34;:55.5555555556, &#34;f&#34;:58.8235294118 }, &#34;discourse&#34;:{ &#34;p&#34;:0.0, &#34;r&#34;:0.0, &#34;f&#34;:0.0 }, &#34;case:voc&#34;:{ &#34;p&#34;:0.0, &#34;r&#34;:0.0, &#34;f&#34;:0.0 }, &#34;vocative&#34;:{ &#34;p&#34;:0.0, &#34;r&#34;:0.0, &#34;f&#34;:0.0 } } }, &#34;speed&#34;:{ &#34;cpu&#34;:13038.7132631094, &#34;gpu&#34;:null, &#34;nwords&#34;:10000 } } . import os os.chdir(&#39;/content&#39;) !rm -rf modelout !mkdir modelout !rm meta.json . !cat meta.json . { &#34;name&#34;: &#34;ga_idt_sm&#34;, &#34;lang&#34;: &#34;ga&#34;, &#34;version&#34;: &#34;1.0.0&#34;, &#34;spacy_version&#34;: &#34;&gt;=2.0.0,&lt;3.0.0&#34;, &#34;description&#34;: &#34;Irish model for spaCy trained on IDT&#34;, &#34;author&#34;: &#34;Jim O&#39;Regan&#34;, &#34;email&#34;: &#34;jaoregan@tcd.ie&#34;, &#34;license&#34;: &#34;CC BY-SA 3.0&#34;, &#34;pipeline&#34;: [&#34;tagger&#34;, &#34;parser&#34;, &#34;ner&#34;] } .",
            "url": "https://jimregan.github.io/notes/spacy/idt/2020/09/14/train-spacy-idt.html",
            "relUrl": "/spacy/idt/2020/09/14/train-spacy-idt.html",
            "date": " • Sep 14, 2020"
        }
        
    
  
    
        ,"post277": {
            "title": "Evernote web clips, 30/8/2020",
            "content": "Language-Agnostic BERT Sentence Embedding . End-to-End Automatic Pronunciation Error Detection Based on Improved Hybrid CTC/Attention Architecture . Festival Speech Synthesis System - 13 Lexicons . awslabs/mlm-scoring .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2020/08/30/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2020/08/30/evernote-links.html",
            "date": " • Aug 30, 2020"
        }
        
    
  
    
        ,"post278": {
            "title": "Javascript hoops",
            "content": "!git clone https://github.com/jimregan/coco-ssd-ga . Cloning into &#39;coco-ssd-ga&#39;... remote: Enumerating objects: 55, done. remote: Counting objects: 100% (55/55), done. remote: Compressing objects: 100% (38/38), done. remote: Total 55 (delta 17), reused 48 (delta 14), pack-reused 0 Unpacking objects: 100% (55/55), done. . import os os.chdir(&#39;coco-ssd-ga&#39;) . !npm install -g yarn rimraf browserify typescript ts-node @tensorflow/tfjs-core @tensorflow/tfjs-converter . &gt; yarn@1.22.10 preinstall /tools/node/lib/node_modules/yarn &gt; :; (node ./preinstall.js &gt; /dev/null 2&gt;&amp;1 || true) /tools/node/bin/browserify -&gt; /tools/node/lib/node_modules/browserify/bin/cmd.js /tools/node/bin/rimraf -&gt; /tools/node/lib/node_modules/rimraf/bin.js /tools/node/bin/ts-node -&gt; /tools/node/lib/node_modules/ts-node/dist/bin.js /tools/node/bin/ts-script -&gt; /tools/node/lib/node_modules/ts-node/dist/bin-script-deprecated.js /tools/node/bin/ts-node-script -&gt; /tools/node/lib/node_modules/ts-node/dist/bin-script.js /tools/node/bin/ts-node-transpile-only -&gt; /tools/node/lib/node_modules/ts-node/dist/bin-transpile.js /tools/node/bin/tsc -&gt; /tools/node/lib/node_modules/typescript/bin/tsc /tools/node/bin/tsserver -&gt; /tools/node/lib/node_modules/typescript/bin/tsserver /tools/node/bin/yarn -&gt; /tools/node/lib/node_modules/yarn/bin/yarn.js /tools/node/bin/yarnpkg -&gt; /tools/node/lib/node_modules/yarn/bin/yarn.js + rimraf@3.0.2 + yarn@1.22.10 + browserify@17.0.0 + ts-node@9.1.1 + @tensorflow/tfjs-converter@3.5.0 + @tensorflow/tfjs-core@3.5.0 + typescript@4.2.4 added 203 packages from 137 contributors in 12.754s . !npm install . npm WARN deprecated fsevents@2.1.3: &#34;Please update to latest v2.3 or v2.2&#34; npm WARN deprecated core-js@2.6.12: core-js@&lt;3 is no longer maintained and not recommended for usage due to the number of issues. Please, upgrade your dependencies to the actual version of core-js@3. &gt; core-js@2.6.12 postinstall /content/coco-ssd-ga/node_modules/core-js &gt; node -e &#34;try{require(&#39;./postinstall&#39;)}catch(e){}&#34; Thank you for using core-js ( https://github.com/zloirock/core-js ) for polyfilling JavaScript standard library! The project needs your help! Please consider supporting of core-js on Open Collective or Patreon: &gt; https://opencollective.com/core-js &gt; https://www.patreon.com/zloirock Also, the author of core-js ( https://github.com/zloirock ) is looking for a good job -) npm notice created a lockfile as package-lock.json. You should commit this file. npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@~2.1.2 (node_modules/rollup/node_modules/fsevents): npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@2.1.3: wanted {&#34;os&#34;:&#34;darwin&#34;,&#34;arch&#34;:&#34;any&#34;} (current: {&#34;os&#34;:&#34;linux&#34;,&#34;arch&#34;:&#34;x64&#34;}) npm WARN @rollup/plugin-typescript@3.1.1 requires a peer of rollup@^1.20.0 but none is installed. You must install peer dependencies yourself. added 196 packages from 157 contributors and audited 197 packages in 10.534s 10 packages are looking for funding run `npm fund` for details found 0 vulnerabilities ╭────────────────────────────────────────────────────────────────╮ │ │ │ New major version of npm available! 6.14.8 → 7.11.1 │ │ Changelog: https://github.com/npm/cli/releases/tag/v7.11.1 │ │ Run npm install -g npm to update! │ │ │ ╰────────────────────────────────────────────────────────────────╯ . !yarn build . yarn run v1.22.10 $ rimraf dist &amp;&amp; tsc Done in 6.76s. . !npm install yalc . npm WARN @rollup/plugin-typescript@3.1.1 requires a peer of rollup@^1.20.0 but none is installed. You must install peer dependencies yourself. npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@2.1.3 (node_modules/fsevents): npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@2.1.3: wanted {&#34;os&#34;:&#34;darwin&#34;,&#34;arch&#34;:&#34;any&#34;} (current: {&#34;os&#34;:&#34;linux&#34;,&#34;arch&#34;:&#34;x64&#34;}) + yalc@1.0.0-pre.51 updated 1 package and audited 197 packages in 2.25s 8 packages are looking for funding run `npm fund` for details found 0 vulnerabilities . !npm install -g cross-env . /tools/node/bin/cross-env -&gt; /tools/node/lib/node_modules/cross-env/src/bin/cross-env.js /tools/node/bin/cross-env-shell -&gt; /tools/node/lib/node_modules/cross-env/src/bin/cross-env-shell.js + cross-env@7.0.3 added 7 packages from 5 contributors in 0.789s . !npm install -g @tensorflow/tfjs-core @tensorflow/tfjs-converter rollup yalc !npm install --save install !yarn run publish-local . . /tools/node/bin/rollup -&gt; /tools/node/lib/node_modules/rollup/dist/bin/rollup /tools/node/bin/yalc -&gt; /tools/node/lib/node_modules/yalc/src/yalc.js npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@~2.3.1 (node_modules/rollup/node_modules/fsevents): npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@2.3.2: wanted {&#34;os&#34;:&#34;darwin&#34;,&#34;arch&#34;:&#34;any&#34;} (current: {&#34;os&#34;:&#34;linux&#34;,&#34;arch&#34;:&#34;x64&#34;}) + rollup@2.45.2 + yalc@1.0.0-pre.51 + @tensorflow/tfjs-core@3.5.0 + @tensorflow/tfjs-converter@3.5.0 updated 4 packages in 3.883s npm WARN @rollup/plugin-typescript@3.1.1 requires a peer of rollup@^1.20.0 but none is installed. You must install peer dependencies yourself. npm WARN optional SKIPPING OPTIONAL DEPENDENCY: fsevents@2.1.3 (node_modules/fsevents): npm WARN notsup SKIPPING OPTIONAL DEPENDENCY: Unsupported platform for fsevents@2.1.3: wanted {&#34;os&#34;:&#34;darwin&#34;,&#34;arch&#34;:&#34;any&#34;} (current: {&#34;os&#34;:&#34;linux&#34;,&#34;arch&#34;:&#34;x64&#34;}) + install@0.13.0 added 1 package from 1 contributor and audited 198 packages in 1.647s 10 packages are looking for funding run `npm fund` for details found 0 vulnerabilities yarn run v1.22.10 $ yarn build &amp;&amp; rollup -c &amp;&amp; yalc push . $ rimraf dist &amp;&amp; tsc src/index.ts → dist/coco-ssd.node.js... created dist/coco-ssd.node.js in 8.9s coco-ssd-ga@2.1.0 published in store. Done in 16.51s. . !npm install -g browserify . /tools/node/bin/browserify -&gt; /tools/node/lib/node_modules/browserify/bin/cmd.js + browserify@17.0.0 updated 1 package in 4.871s . !npm i minify -g . /tools/node/bin/minify -&gt; /tools/node/lib/node_modules/minify/bin/minify.js + minify@7.0.1 added 26 packages from 52 contributors in 1.951s . !browserify /content/coco-ssd-ga/dist/coco-ssd.node.js --s cocoGa -o /content/coco-ssd-ga/dist/coco-ssd.browser.js . !minify /content/coco-ssd-ga/dist/coco-ssd.browser.js &gt; /content/coco-ssd-ga/dist/coco-ssd.min.js .",
            "url": "https://jimregan.github.io/notes/web/coco-ssd/2020/08/12/coco-ssd-ga.html",
            "relUrl": "/web/coco-ssd/2020/08/12/coco-ssd-ga.html",
            "date": " • Aug 12, 2020"
        }
        
    
  
    
        ,"post279": {
            "title": "Evernote web clips, 9/8/2020",
            "content": "LM Rescoring . any example on lattice rescoring for large language model . Lattice re-scoring during manual editing for automatic error correction of ASR transcripts . Neural Network Language Modeling with Letter-Based Features and Importance Sampling . Tutorial - RiveScript.com . An Overview of Multi-Task Learning in Speech Recognition . aalto-speech/subword-kaldi Properly handle position-dependent phones in a subword lexicon FST . wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2020/08/09/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2020/08/09/evernote-links.html",
            "date": " • Aug 9, 2020"
        }
        
    
  
    
        ,"post280": {
            "title": "Evernote web clips, 8/7/2020",
            "content": "Muskerry pronunciation . Dive into Deep Learning . One LEGO at a Time - Explaining the Math of how Neural Networks Learn with Implementation from Scratch . MULTI-LINGUAL AUTOMATIC PHONEME CLUSTERING . Closleabhair: 13 Irish language audiobooks you can listen to for free online . Measuring Unsupervised Acoustic Clustering through Phoneme Pair Merge-and-Split Tests . The General Ideas of Word Embeddings .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2020/07/08/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2020/07/08/evernote-links.html",
            "date": " • Jul 8, 2020"
        }
        
    
  
    
        ,"post281": {
            "title": "Boat parts",
            "content": "en pron. pl . mast |   | maszt | . jib |   | fok | . mainsail |   | grot | . forestay |   | forsztag | . foremast |   | fokmaszt | . shroud |   | wanta | . tack |   | hals | . clew |   | róg szotowy | . stern |   | rufa | . bow |   | dziób | . hull |   | kadłub | . tiller |   | rumpel | . boom |   | bom | . gunwale | (/ˈɡʌnəl/ - ganl) | reling | . board |   | pokład | . rudder |   | ster | . halyard |   | fał (halliard) | . head |   | lik górny | . leech |   | lik wolny | . luff |   | lik przedni | . foot |   | lik dolny | . boatswain | /ˈbəʊsn̩/ (bosn) | bosman | . coxswain |   | sternik | .",
            "url": "https://jimregan.github.io/notes/english%20teaching/pruszk%C3%B3w/2020/06/10/boat-parts.html",
            "relUrl": "/english%20teaching/pruszk%C3%B3w/2020/06/10/boat-parts.html",
            "date": " • Jun 10, 2020"
        }
        
    
  
    
        ,"post282": {
            "title": "Interesting links, 16/3/2020",
            "content": "Pocketsphinx.js - Speech Recognition in JavaScript and WebAssembly . RiveScript - Artificial Intelligence Scripting Language . andi611/Mockingjay-Speech-Representation Official Implementation of Mockingjay in Pytorch . grtzsohalf/Audio-Phonetic-and-Semantic-Embedding . Phonetic-and-Semantic Embedding of Spoken Words with Applications in Spoken Content Retrieval . Tesseract.js – pure Javascript port of the popular Tesseract OCR engine. . microsoft/Recognizers-Text Microsoft.Recognizers.Text provides recognition and resolution of numbers, units, and date/time expressed in multiple languages .",
            "url": "https://jimregan.github.io/notes/links/2020/03/16/misc-links.html",
            "relUrl": "/links/2020/03/16/misc-links.html",
            "date": " • Mar 16, 2020"
        }
        
    
  
    
        ,"post283": {
            "title": "Evernote web clips, 15/3/2020",
            "content": "Open Challenge for Correcting Errors of Speech Recognition Systems . Understanding RNNs . Unsupervised Pre-training for Speech Recognition wav2vec . Podchraoltaí Gaeilge . Universal Phone Recognition with a Multilingual Allophone System . Re-Scoring Word Lattices from Automatic Speech Recognition System Based on Manual Error Corrections . ASR Context-Sensitive Error Correction Based on Microsoft N-Gram Dataset . Results of the IMPACT project .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2020/03/15/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2020/03/15/evernote-links.html",
            "date": " • Mar 15, 2020"
        }
        
    
  
    
        ,"post284": {
            "title": "ClarinPL SpeechTools links",
            "content": "ForcedAlign/run.sh . ./steps/make_mfcc.sh --nj 1 data ./steps/compute_cmvn_stats.sh data ./local_utils/prepare_dict.sh data dict ./utils/prepare_lang.sh dict &quot;&lt;unk&gt;&quot; tmp lang ./steps/align_fmllr.sh --nj 1 --beam ${beam} --retry-beam ${retry_beam} data lang tri3b_mmi ali ./steps/get_train_ctm.sh data lang ali ./local_utils/get_phoneme_ctm.sh data lang ali awk &#39;$0=&quot;@&quot;$0&#39; ali/phonectm | cat ali/ctm - | sort -r -k3n &gt; $out . ForcedAlign/run_eaf.sh . if $phones ; then ./local_utils/get_phoneme_ctm.sh --use-segments false data lang ali python3 local_utils/ctm2eaf.py --phones-ctm ali/phonectm ali/ctm data/seg2tier ${eaf_in} ${eaf_out} else python3 local_utils/ctm2eaf.py ali/ctm data/seg2tier ${eaf_in} ${eaf_out} fi . ForcedAlign/run_segments.sh . SegmentAlign/run.sh . misc/transcribe_word_list.sh . misc/train_g2p.sh . SpeechActivityDetection/run.sh .",
            "url": "https://jimregan.github.io/notes/kaldi/2020/03/07/kaldi-pl-scripts.html",
            "relUrl": "/kaldi/2020/03/07/kaldi-pl-scripts.html",
            "date": " • Mar 7, 2020"
        }
        
    
  
    
        ,"post285": {
            "title": "Séadna, Caibidil a hAon",
            "content": "SÉADNA. . CAIBIDIL A hAON. . Cois na tine. Peig, Nóra, Gobnait, Síle bheag, agus Cáit Ní Bhuachalla. . Nóra.—A Pheig, inis scéal dúinn. . Peig.—B’ait liom san! Inis féin scéal. . Gobnait.—Níl aon mhaith inti, a Pheig. B’fhearr linn do scéalsa. . Síle.—Dein, a Pheig, agus beimid an-shocair. . Peig.—Nach maith nár fhanais socair aréir, nuair a bhí “Madra na nOcht gCos” agam dá insint! . Síle.—Mar sin ní stadfadh Cáit Ní Bhuachalla ach am priocadh. . Cáit.—Thugais d’éitheach! Ní rabhas-sa ad phriocadh, a chaillichín! . Gobnait.—Ná bac í féin, a Cháit. Ní raibh éinne á priocadh ach í á ligeant uirthi. . Síle.—Do bhí, is dóin; agus mura mbeadh go raibh, ní liúfainn. . Nóra.—Abair le Peig ná liúfair anois, a Shíle, agus ‘neosaidh sí scéal dúinn. . Síle.—Ní liúfad, a Pheig, pé rud a imeoidh orm. . Peig.—Más ea, suigh anso i m’aice, i dtreo ná féadfaidh éinne thú phriocadh a gan fhios dom. . Cáit.—Bíodh geall go bpriocfaidh an cat í. A thoice bhig, bheadh scéal breá againn mura mbeadh tú féin agus do chuid liúirí. . Gobnait.—Éist, a Cháit, nó cuirfir ag gol í, agus beimid gan scéal. Má curtar fearg ar Pheig ní ‘neosaidh sí aon scéal anocht. Sea anois, a Pheig, tá gach éinne ciúin ag brath ar scéal uait. . Peig.—Bhí fear ann fadó agus is é ainm a bhí air ná Séadna. Gréasaí ab ea é. Bhí tigh beag deas cluthar aige ag bun cnoic, ar thaobh na fothana. Bhí cathaoir shúgáin aige do dhein sé féin dó féin, agus ba ghnáth leis suí inti um thráthnóna, nuair a bhíodh obair an lae críochnaithe, agus nuair a shuíodh sé inti bhíodh sé ar a shástacht. Bhí mealbhóg mine aige ar crochadh in aice na tine, agus anois agus arís chuireadh sé a lámh inti agus thógadh sé lán a dhoirn den mhin, agus bhíodh sé á cogaint ar a shuaimhneas. Bhí crann úll ag fás ar an dtaobh amuigh de dhoras aige, agus nuair a bhíodh tart air ó bheith ag cogaint na mine, chuireadh sé lámh sa chrann san agus thógadh sé ceann desna húllaibh, agus d’itheadh sé é. . Síle.—Ó, a thiarcais, a Pheig, nár dheas é! . Peig.—Cé acu an chathaoir nó an mhin nó an t‑úll ba dheas? . Síle.—An t‑úll, gan amhras! . Cáit.—B’fhearr liomsa an mhin. Ní bhainfeadh an t‑úll an t‑ocras de dhuine. . Gobnait.—B’fhearr liomsa an chathaoir, agus chuirfinn Peig ina suí inti, ag insint na scéal. . Peig.—Is maith chun plámáis thú, a Ghobnait. . Gobnait.—Is fearr chun na scéal tusa, a Pheig. Conas d’imigh le Séadna? . Peig.—Lá dá raibh sé ag déanamh bróg, thug sé fé ndeara ná raibh a thuilleadh leathair aige, ná a thuilleadh snáithe, ná a thuilleadh céarach. Bhí an taoibhín déanach suas agus an greim déanach curtha, agus níorbh fholáir dó dul agus ábhar do sholáthar sula bhféadfadh sé a thuilleadh bróg a dhéanamh. Do ghluais sé ar maidin, agus bhí trí scillinge ina phóca, agus ní raibh sé ach míle ón dtigh nuair a bhuail duine bocht uime, a d’iaraidh déirce. . “Tabhair dhom déirc ar son an tSlánaitheora agus le h‑anaman na marbh, agus tar cheann do shláinte,” arsan duine bocht. . Thug Séadna scilling dó, agus ansan ní raibh aige ach dhá scilling. Dúirt sé leis féin go mb’fhéidir go ndéanfadh an dá scilling a ghnó. Ní raibh sé ach míle eile ó bhaile nuair a bhuail bean bhocht uime agus í cos-nochtaithe. . “Tabhair dhom cúnamh éigin,” ar sise, “ar son an tSlánaitheora, agus le hanaman do mharbh, agus tar cheann do shláinte.” . Do ghlac trua dhí é, agus thug sé scilling di, agus d’imigh sí. Do bhí aon scilling amháin ansan aige, ach do chomáin sé leis, ag brath air go mbuailfeadh seans éigin uime a chuirfeadh ar a chumas a ghnó a dhéanamh. Níorbh fhada gur casadh air leanbh agus é ag gol le fuacht agus le hocras. “Ar son an tSlánaitheora,” arsan leanbh, “tabhair dhom rud éigin le n‑ithe.” . Bhí tigh ósta i ngar dóibh, agus do chuaigh Séadna isteach ann, agus cheannaigh sé bríc aráin agus thug sé chun an linbh é. Nuair a fuair an leanbh an t‑arán d’athraigh a dhealbh. D’fhás sé suas in‑airde, agus do las solas iontach ina shúilibh agus ina cheannachaibh, i dtreo go dtáinig scanradh ar Shéanna. . Síle.—Dia linn! a Pheig, is dócha gur thit Séadna bocht i laige. . Peig.—Níor thit; ach más ea, ba dhícheall dó. Chomh luath agus d’fhéad sé labhairt, dúirt sé:– . “Cad é an saghas duine thusa?” Agus is é freagra a fuair sé:— . “A Shéanna, tá Dia buíoch díot. Aingeal is ea mise. Is mé an tríú h‑aingeal gur thugais déirc dó inniu ar son an tSlánaitheora. Agus anois tá trí ghuí agat le fáil ó Dhia na glóire. Iar ar Dhia aon trí ghuí is toil leat, agus gheobhair iad. Ach tá aon chomhairle amháin agamsa le tabhairt duit.—Ná dearúd an Trócaire.” . “Agus an ndeirir liom go bhfaighead mo ghuí?” arsa Séadna. . “Deirim, gan amhras,” arsan t‑aingeal. . “Tá go maith,” arsa Séadna. “Tá cathaoir bheag dheas súgáin agam sa bhaile, agus an uile dhailtín a thagann isteach, ní foláir leis suí inti. An chéad duine eile a shuífidh inti, ach mé féin, go gceanglaí sé inti!” . “Faire, faire, a Shéanna,” arsan t‑aingeal; “sin guí breá imithe gan tairbhe. Tá dhá cheann eile agat, agus ná dearúd an Trócaire.” . “Tá,” arsa Séadna, “mealbhóigín mine agam sa bhaile, agus an uile dhailtín a thagann isteach, ní foláir leis a dhorn a shá inti. An chéad duine eile a chuirfidh lámh sa mhealbhóig sin, ach mé féin, go gceanglaí sé inti, féach!” . “Ó, a Shéanna, a Shéanna, níl fasc agat,” arsan t‑aingeal. “Níl agat anois ach aon ghuí amháin eile. Iar Trócaire Dé do d’anam.” . “Ó, is fíor dhuit,” arsa Séadna, “ba dhóbair dom é dhearúd. Tá crann beag úll agam i leataoibh mo dhorais, agus an uile dhailtín a thagann an treo, ní foláir leis a lámh do chur in airde agus úll do stathadh agus do bhreith leis. An chéad duine eile, ach mé féin, a chuirfidh lámh sa chrann san, go gceanglaí sé ann!—Ó! a dhaoine!” ar seisean, ag scairteadh ar gháirí, “nach agam a bheidh an spórt orthu!” . Nuair a tháinig sé as na trithíbh, d’fhéach sé suas agus bhí an t‑aingeal imithe. Dhein sé a mhachnamh air féin ar feadh tamaill mhaith. Fé dheireadh thiar thall, dúirt sé leis féin: “Féach anois, níl aon amadán in Éirinn is mó ná mé! Dá mbeadh triúr ceangailte agam um an dtaca so, duine sa chathaoir, duine sa mhealbhóig, agus duine sa chrann, cad é an mhaith a dhéanfadh san domsa agus mé i bhfad ó bhaile, gan bia, gan deoch, gan airgead?” . Ní túisce a bhí an méid sin cainte ráite aige ná a thug sé fé ndeara os a chomhair amach, sa n‑áit ina raibh an t‑aingeal, fear fada caol dubh, agus é ag glinniúint air, agus tine chreasa ag teacht as a dhá shúil ina spréachaibh nimhe. Bhí dhá adhairc air mar bheadh ar phocán gabhair; agus meigeall fada liathghorm garbh air, eireaball mar a bheadh ar mhadra rua, agus crúb ar chois leis mar chrúb thairbh. Do leath a bhéal agus a dhá shúil ar Shéanna, agus do stad a chaint. I gceann tamaill do labhair an Fear Dubh. . “A Shéanna,” ar seisean, “ní gá dhuit aon eagla do bheith ort romhamsa. Nílim ar tí do dhíobhála. Ba mhian liom tairbhe éigin a dhéanamh duit, dá nglacfá mo chomhairle. Do chloiseas thú, anois beag, á rá go rabhais gan bia, gan deoch, gan airgead. Thabharfainnse airgead do dhóthain duit ar aon choinníoll bheag amháin.” . “Agus greadadh tré lár do scairt!” arsa Séadna, agus tháinig a chaint dó; “ná féadfá an méid sin do rá gan duine do mhilleadh led’ chuid glinniúna, pé hé thú féin?” . “Is cuma dhuit cé hé mé, ach bhéarfad an oiread airgid duit anois agus cheannóidh an oiread leathair agus choimeádfaidh ag obair thú go ceann trí mbliain ndéag, ar an gcoinníoll seo—go dtiocfair liom an uair sin.” . “Agus má réidhtighim leat, cá raghmaoíd an uair sin?” . “Cá beag duit an cheist sin do chur nuair a bheidh an leathar ídithe agus bheimid ag gluaiseacht?” . “Táir géarchúiseach. Bíodh agat. Feiceam an t‑airgead.” . “Táirse géarchúiseach. Féach!”—do chuir an Fear Dubh a lámh ina phóca agus tharraing sé amach sparán mór, agus as an sparán do lig sé amach ar a bhais carn beag d’ór bhreá bhuí. . “Féach!” ar seisean, agus shín sé a lámh agus chuir sé an carn de phíosaíbh gleoite gléineacha suas fé shúilibh Shéanna bhoicht. Do shín Séadna a dhá láimh, agus do leathadar a dhá ladhar chun an óir. . “Go réidh!” arsan Fear Dubh, ag tarrang an óir chuige isteach. “Níl an margadh déanta fós.” . “Bíodh ina mhargadh,” arsa Séadna. . “Gan teip?” arsan Fear Dubh. . “Gan teip,” arsa Séadna. . “Dar bhrí na mionn?” arsan Fear Dubh. . “Dar bhrí na mionn,” arsa Séadna. .",
            "url": "https://jimregan.github.io/notes/irish/seadna/2020/02/15/seadna-caibidil-a-haon.html",
            "relUrl": "/irish/seadna/2020/02/15/seadna-caibidil-a-haon.html",
            "date": " • Feb 15, 2020"
        }
        
    
  
    
        ,"post286": {
            "title": "Evernote web clips, 10/1/2020",
            "content": "PDF - www.ilrweb.ie . Kaldi Tutorial . How to get timestamps of an audio file using pre-trained model with Kaldi . kaldi/create_segments_from_ctm.pl . kaldi/run_unk_model.sh . Create shared versions of get_ctm_conf.sh, add get_ctm_conf… . Added a new lexicon learning (adaptation) recipe for tedlium . Output-Gate Projected Gated Recurrent Unit for Speech Recognition . Improvements to multi_en tdnn-opgru/lstm recipes #2824 . Fix a typo in steps/dict/learn_lexicon_bayesian.sh #3288 . simple-g2p/run_simpleG2P.sh . Backstitch: Counteracting Finite-Sample Bias via Negative Steps . Acoustic data-driven lexicon learning based on a greedy pronunciation selection framework . Evaluating Natural Language Understanding Services for Conversational Question Answering Systems . [ASR Independent Hybrid Recurrent Neural Network Based Error Correction for Dialog System Applications | Request PDF](https://www.researchgate.net/publication/302498352_ASR_Independent_Hybrid_Recurrent_Neural_Network_Based_Error_Correction_for_Dialog_System_Applications) | . Improving Performance of End-to-End ASR on Numeric Sequences . REFORMER: THE EFFICIENT TRANSFORMER . Reformer: The Efficient Transformer - Pastebin.com . Fix issue in copy_lat_dir.sh affecting combine_lat_dirs.sh . kaldi/compute-gop.cc at b0f6bcb76824fc7ce0dbf8ecaba3467273bba1c7 . Make compute-gop work with missing alignments . Add layer for attention with bypass by danpovey . Incremental determinization . Handwriting recognition and language modeling with MXNet Gluon .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2020/01/10/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2020/01/10/evernote-links.html",
            "date": " • Jan 10, 2020"
        }
        
    
  
    
        ,"post287": {
            "title": "Evernote web clips, 9/1/2020",
            "content": "Luik 1 - Gospel of Luke in Ulster-Scots . Acoustic data-driven lexicon learning based on a greedy pronunciation selection framework . The Illustrated BERT, ELMo, and co. . A Visual Guide to Using BERT for the First Time . Zwroty angielskie przydatne u fryzjera .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2020/01/09/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2020/01/09/evernote-links.html",
            "date": " • Jan 9, 2020"
        }
        
    
  
    
        ,"post288": {
            "title": "Evernote web clips, 30/12/2019",
            "content": "Lesson 1: Deep Learning 2019 - Image classification . Arrayfire Getting Started . flashlight/examples . gulp21/languagetool-neural-network . Neural Network Rules - Development - LanguageTool Forum . Java Regex - Java Regular Expressions . PDF - www.speech.cs.cmu.edu . gf5353/deploytools . Books · Léamh – Learn Early Modern Irish . Deep Lip Reading . Add Chime 6 baseline system #3755 . Minority language resources: a guide - How to get fluent, with Dr Popkins . facebookresearch/detectron2 . PyTorch 1.3 adds mobile, privacy, quantization, and named tensors . Learning from Past Mistakes: Improving Automatic Speech Recognition Output via Noisy-Clean Phrase Context Modeling . Statistical Error Correction Methods for Domain-Specific ASR Systems . A simple module consistently outperforms self-attention and Transformer model on main NMT datasets with SoTA performance . Google’s Explainable AI service sheds light on how machine learning models make decisions . EdgeSpeechNets: Highly Efficient Deep Neural Networks for Speech Recognition on the Edge . Google AI technique reduces speech recognition errors by 29% . ASR Context-Sensitive Error Correction Based on Microsoft N-Gram Dataset . Automatic Speech Recognition Errors Detection and Correction: A Review . Creating and using ground truth OCR sample data for Finnish historical newspapers and journals . NBoost: Boost Elasticsearch Search Relevance by 80% with BERT : MachineLearning . CMU Sphinx Use Needleman-Wunsch algorithm to get results. . openslr.org Crowdsourced high-quality Basque speech data set . Added tri3b and chain training for Aurora4 #3638 . A Visual Guide to Using BERT for the First Time . Mathematics for Machine Learning . The Illustrated Word2vec . The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning) . Is múinteoir Gaeilge mé… . Gramadach - Blag Gaeilge SMPPS . Goodness of Pronunciation (GOP) #3703 . Talking Head Anime from a Single Image : MachineLearning . GELU better than RELU? : MachineLearning . [How to write vectorized code | ArrayFire](http://arrayfire.com/how-to-write-vectorized-code/) | . Post-Editing Error Correction Algorithm For Speech Recognition using Bing Spelling Suggestion . A spelling correction model for end-to-end speech recognition . Novelist Cormac McCarthy’s tips on how to write a great science paper . How to do Unsupervised Clustering with Keras . Contrastive Predictive Coding Based Feature for Automatic Speaker Verification . Representation Learning with Contrastive Predictive Coding . Maven – Maven on Windows .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2019/12/30/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2019/12/30/evernote-links.html",
            "date": " • Dec 30, 2019"
        }
        
    
  
    
        ,"post289": {
            "title": "Evernote web clips, 22/12/2019",
            "content": "KPWr . Marian :: MTM2017 Tutorial - Part 2 . Training and Adapting Multilingual NMT for Less-resourced and Morphologically Rich Languages . An Exploration of Neural Sequence-to-Sequence Architectures for Automatic Post-Editing .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2019/12/22/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2019/12/22/evernote-links.html",
            "date": " • Dec 22, 2019"
        }
        
    
  
    
        ,"post290": {
            "title": "Evernote web clips, 15/12/2019",
            "content": "Controlling Text Generation with Plug and Play Language Models . How To Code Modern Neural Networks Using Python and NumPy . Distilling knowledge from Neural Networks to build smaller and faster models .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2019/12/15/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2019/12/15/evernote-links.html",
            "date": " • Dec 15, 2019"
        }
        
    
  
    
        ,"post291": {
            "title": "Trick or Treat",
            "content": "Trick or treat is an American custom, but it has its origins in earlier customs: “guising”, which was practiced in Scotland and Ireland; and “souling”, which was practiced in Britain and Ireland, but is more usually associated with England. . In “guising”, children wore costumes (or “guises”), and went from door to door, much like with trick or treat. The main difference was that children who went guising had to perform something - a joke, a song, or a poem - to receive a treat. . “Souling” involved people going in groups, offering to pray for the souls of family members of the people they visited: for this, they would receive a “soul cake”. . “Trick or treat” is usually just something that people say - these days, people don’t usually expect to have to play a trick - but in the 1990s, egging (throwing raw eggs) and TP-ing (throwing an opened roll of toilet paper, to “decorate” the house) were common “tricks”. .",
            "url": "https://jimregan.github.io/notes/english%20teaching/pruszk%C3%B3w/2019/10/31/trick-or-treat.html",
            "relUrl": "/english%20teaching/pruszk%C3%B3w/2019/10/31/trick-or-treat.html",
            "date": " • Oct 31, 2019"
        }
        
    
  
    
        ,"post292": {
            "title": "Harry Potter quiz",
            "content": "1. What is Harry’s full address? . (The Cupboard under the stairs, 2 Privet Drive) . 2. What did Harry get for Christmas? . (The invisibility cloak) . 3. What did Harry get at the end of the movie? . (A photo album) . 4. What was the number of Harry’s vault at Gringott’s . 687 . 5. What was spelled on Harry’s birthday cake? . Happee birthdae Harry . 6. Who taught Defence Against the Dark Arts? . Quirrell . 7. How many times did McGonagall appear as a cat? . Twice . 8. What is the name of the wizard’s bank? . Gringott’s . 9. What was the number of the vault Hagrid went to at Gringott’s? . 713 . 10. What did Neville receive in the mail? . A rememberall . 11. What is the name of Harry’s aunt? . Petunia . 12. What is the name of the ball that wins a game of quidditch? . The Golden Snitch . 13. What is the name of Hagrid’s dog . Fang/Kieł . 14. What is the name of the dog guarding the trap door? . Fluffy . 15. What was the name of Hagrid’s dragon? . Norbert . 16. How many points did Neville receive at the end of the movie? . 10 . 17. What was the name of the centaur? . Firenze . 18. Where was the snake at the start of the movie from? . Burma . 19. Where is Ron’s brother studying dragons? . Romania . 20. What kind of dragon did Hagrid have? . A Norwegian Ridgeback . 21. How old was Harry when he found out he is a wizard? . 11 . 22. What flavour of Every Flavour Beans did Dumbledore eat in the hospital? . Ear wax . 23. Who was the wizard on the Chocolate Frog card that Harry opened on the train? . Dumbledore . 24. What is at the core of Harry’s wand? . Phoenix feather .",
            "url": "https://jimregan.github.io/notes/english%20teaching/siemczyno/2019/07/28/hp-quiz.html",
            "relUrl": "/english%20teaching/siemczyno/2019/07/28/hp-quiz.html",
            "date": " • Jul 28, 2019"
        }
        
    
  
    
        ,"post293": {
            "title": "Treasure Island, Chapter 1 vocab",
            "content": "year of grace: year in the Christian era; year A.D. . Cove: an inlet, usually with high cliffs that can protect ships from the wind . Capstan: machine for putting force on ropes, usually on a ship . Grog: rum and water . “sittyated” - situated . “mought” - might . berth - bunk for sleeping (usually on a ship); also, room for movement: to give someone a wide berth means to avoid them . keep a weather eye open - be alert (a weather eye was a tool for predicting the weather) . assizes - court hearing . be quit of - be rid of in modern English . rheumatics - rheumatism .",
            "url": "https://jimregan.github.io/notes/english%20teaching/pruszk%C3%B3w/2019/06/03/treasure-island-chapter-1.html",
            "relUrl": "/english%20teaching/pruszk%C3%B3w/2019/06/03/treasure-island-chapter-1.html",
            "date": " • Jun 3, 2019"
        }
        
    
  
    
        ,"post294": {
            "title": "Snatch vocabulary",
            "content": "Bust a cap in his ass: African-American slang. “Bust a cap” means to shoot (a cap can be a small explosive used to set off a larger explosive, especially in mining, so in slang, it’s a bullet); one’s ass can be used as an emphatic replacement for a pronoun: “my ass is tired”, “he has to drag his ass to work”. Possibly from work one’s ass off (to work to the point of fatigue). . Yardie: a Jamaican (“yard” in Jamaican Creole means “home”); more specifically, a member of a Jamaican gang . Goody gumdrops (or goody goody gumdrops): childish expression of happiness, usually sarcastic when used by adults. . Pisshead: person who regularly gets drunk. “Piss” can be used to mean alcohol (“We’re going on the piss” = “we’re going drinking”); -head can be used to form a noun (usually derogatory) for a person who’s dedicated to something: a pothead likes to smoke marijuana (“pot”), a metalhead listens to heavy metal; it can also be added to other insults to imply stupidity (blockhead, shithead). . Look like curry to a pisshead: curry is an extremely popular post-pub food in Britain, so this is irresistible food. . Porky pies: rhyming slang for lies. Usually shortened to porkies. .",
            "url": "https://jimregan.github.io/notes/english%20teaching/pruszk%C3%B3w/2019/06/03/snatch-vocab.html",
            "relUrl": "/english%20teaching/pruszk%C3%B3w/2019/06/03/snatch-vocab.html",
            "date": " • Jun 3, 2019"
        }
        
    
  
    
        ,"post295": {
            "title": "Title",
            "content": "https://dumps.wikimedia.org/enwiktionary/ . !wget https://dumps.wikimedia.org/enwiktionary/20190501/enwiktionary-20190501-pages-articles-multistream.xml.bz2 . %%writefile extract-enwiktionary-ipa.pl #!/usr/bin/perl use warnings; use strict; use utf8; binmode(STDIN, &quot;:utf8&quot;); binmode(STDOUT, &quot;:utf8&quot;); binmode(STDERR, &quot;:utf8&quot;); my $title = &#39;&#39;; my $polish_seen = 0; while(&lt;&gt;) { if(/&lt;title&gt;([^&lt;]*)&lt; /title&gt;/) { $title = trim($1); $polish_seen = 0; } elsif(/== *Polish *==/) { $polish_seen = 1; } elsif(/== *([^=]*)==/) { if($1 !~ /polish/i) { $polish_seen = 0; } } elsif(/ { {IPA |([^}]*) } }/) { my $inner = $1; if($inner =~ / |/) { my @parts = split/ |/, $inner; if($#parts != 1) { if($inner =~ /lang=pl$|lang=pl |/) { for my $part (@parts) { next if($part =~ /^lang=pl$/); print &quot;$title t$part n&quot;; } } else { next; } } else { my $pron = ($parts[0] =~ /lang=/) ? $parts[1] : $parts[0]; my $lang = ($parts[0] =~ /lang=/) ? $parts[0] : $parts[1]; if($lang =~ /=pl$/) { print &quot;$title t$pron n&quot;; } else { next; } } } elsif($polish_seen) { print &quot;CHECK: t$title $inner n&quot;; } else { next; } $polish_seen = 0; } else { next; } } sub trim { my $var = shift; $var =~ s/^ *//; $var =~ s/ *$//; $var; } . !bzcat enwiktionary-20190501-pages-articles-multistream.xml.bz2|perl extract-enwiktionary-ipa.pl &gt; wikt-ipa.txt .",
            "url": "https://jimregan.github.io/notes/2019/05/19/get-polish-ipa-from-enwiktionary.html",
            "relUrl": "/2019/05/19/get-polish-ipa-from-enwiktionary.html",
            "date": " • May 19, 2019"
        }
        
    
  
    
        ,"post296": {
            "title": "Evernote web clips, 29/3/2019",
            "content": "Multilingual Speech Recognition With A Single End-To-End Model . Memory, attention, sequences . natsuhh / SWC . Building Kaldi on Windows: Part 1 . Yes you should understand backprop . The M-AILABS Speech Dataset – caito .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2019/03/29/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2019/03/29/evernote-links.html",
            "date": " • Mar 29, 2019"
        }
        
    
  
    
        ,"post297": {
            "title": "Interesting links, 29/1/2019",
            "content": "FstContrib . OpenGrm Libraries . OpenGrm Thrax Grammar Compiler . OpenGrm Thrax tools . mjansche/tts-tutorial . google/sparrowhawk . google/language-resources . Free Linguistic Environment – a grammar engineering platform for LFG. git . dcavar/treebankparsersa – This is a tool that reads treebank files and generates a probabilistic grammar for use in FLE. . Practical Instructions for Working with LFG . Grammar Development with LFG and XLE . S --&gt; NP: (^ SUBJ)=! (! CASE)=NOM; VP: ^=!. &quot;indicate comments&quot; VP --&gt; V: ^=!; &quot;head&quot; (NP: (^ OBJ)=! &quot;() = optionality&quot; (! CASE)=ACC) PP*: ! $ (^ ADJUNCT). &quot;$ = set, * = Kleene star&quot; . astorfi/TensorFlow-World – Simple and ready-to-use tutorials for TensorFlow .",
            "url": "https://jimregan.github.io/notes/links/2019/01/29/misc-links.html",
            "relUrl": "/links/2019/01/29/misc-links.html",
            "date": " • Jan 29, 2019"
        }
        
    
  
    
        ,"post298": {
            "title": "Evernote web clips, 11/4/2018",
            "content": "The Annotated Transformer . General Information . explosion/sense2vec .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2018/04/11/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2018/04/11/evernote-links.html",
            "date": " • Apr 11, 2018"
        }
        
    
  
    
        ,"post299": {
            "title": "Evernote web clips, 23/3/2018",
            "content": "Gangster’s paradise: how organised crime took over Russia . WIP: Segmenting long erroneous recordings by vimalmanohar . vimalmanohar/kaldi . vimalmanohar/kaldi . vimalmanohar/kaldi . vimalmanohar/kaldi . vimalmanohar/kaldi . vimalmanohar/kaldi . vimalmanohar/kaldi . vimalmanohar/kaldi . Modeling Relational Data with Graph Convolutional Networks . RodenLuo/Smith-Waterman-in-Perl . Untitled note . Plucene-Plugin-Analyzer-MetaphoneAnalyzer-1.02 - Metaphone analyzer - metacpan.org . Find What You Want with Plucene . Machine Learning 10-701/15-781: Lectures . Top Machine Learning MOOCs and Online Lectures: A Comprehensive Survey . tcsai/data-mining . Add the diphone alignment system by akreal . Add diphones acoustic model and dictionary by akreal . akreal/diphones . Add modernized vystadial_cz recipe . Pretrained models . GSByeon/multi-speaker-tacotron-tensorflow . How to build a three-layer neural network from scratch . Prerequisites and Prework . voicy-ai/DialogStateTracking . RasaHQ/rasa_nlu . Question answering with TensorFlow . English gold standard recipe — Ossian 1.3 documentation . Implementation of Gradient Descent in TensorFlow using tf.gradients . tensorflow/tensor2tensor . AI::FANN - search.cpan.org . [Machine learning in Perl | Sergey Kolychev [blogs.perl.org]](http://blogs.perl.org/users/sergey_kolychev/2017/02/machine-learning-in-perl.html) | . AN TRIAIL le Máiréad Ní Ghráda . Anna Heussaff ag léamh as SÁRÚ . deepmipt/DeepPavlov . CMU-Perceptual-Computing-Lab/openpose . dlib C++ Library - train_shape_predictor_ex.cpp . Real-Time Face Pose Estimation . astorfi/lip-reading-deeplearning . facebookresearch/TensorComprehensions . facebookresearch/StarSpace . facebookresearch/MUSE . facebookresearch/InferSent . facebookresearch/tdfbanks . facebookresearch/loop . fastai/numerical-linear-algebra . zackchase/mxnet-slides . zackchase/mxnet-the-straight-dope . zackchase/mxnet-the-straight-dope . aalto-speech/finnish-parliament-scripts . tudarmstadt-lt/kaldi-tuda-de . cltk/lapos . Speech::Recognizer::SPX - search.cpan.org . opencv/opencv_contrib . Dynamic word embeddings for evolving semantic discovery . Machine Learning Top 10 Open Source Projects (v.Mar 2018) . Bliain an Áir (Year of Slaughter) – Irish Famine of 1740-1741 . Phn2vec Embeddings . syhw/speech_embeddings . Pointer Networks . ikostrikov/TensorFlow-Pointer-Networks . atom/flight-manual.atom.io . tsee/p5-ML-TensorFlow . How To Write Your Own Tensorflow in C++ . MycroftAI/padatious . Pocketsphinx.js - Speech Recognition in JavaScript and WebAssembly . MycroftAI/padatious . Conv Nets: A Modular Perspective . Attention and Augmented Recurrent Neural Networks . Understanding LSTM Networks . UFLDL Recommended Readings . tiny-dnn/tiny-dnn . zotroneneis/machine_learning_basics . mozilla/TTS . uclmr/inferbeddings . Rayhane-mamah/Tacotron-2 . sdkcarlos/artyom.js . kan-bayashi/PytorchWaveNetVocoder . Rayhane-mamah/Tacotron-2 . Kyubyong/cross_vc . k2kobayashi/sprocket . timothycrosley/jiphy . pyjs/pyjs . uwgraphics/Leap . A-Jacobson/tacotron2 . The Books and the Pilgrimage of the Polish Nation . Adversarial Sets for Regularising Neural Link Predictors . Compiling Deep Learning Models to WebGL with TVM . NNVM Compiler: Open Compiler for AI Frameworks . Tool for segmenting long audio files with erroneous transcripts · Issue #869 · kaldi-asr/kaldi . resonance-audio/resonance-audio . Implementation - Rust By Example . Starting to Corrode . KeyMe Releases Two Machine Learning Models - KeyMe Blog . PDF - arxiv.org . Community Interaction and Conflict on the Web . Transfer Your Font Style with GANs . PolEval 2017 :: Tasks . Introduction to Gaussian Processes . Bad Speech Synthesis Made Simple . Are the hyper-realistic results of Tacotron-2 and Wavenet not reproducible? • r/MachineLearning . KPWr . PDF - static.googleusercontent.com . a-nagrani/VGGVox . Visual Geometry Group: VoxCeleb dataset . Transfer learning wsj-rm by pegahgh · Pull Request #1633 · kaldi-asr/kaldi . Semi-supervised training on Fisher English by vimalmanohar · Pull Request #2140 · kaldi-asr/kaldi . DNN-based speaker embedding - Google Groups . End-to-end speech recognition - Google Groups . [Machine learning in Perl | Sergey Kolychev [blogs.perl.org]](http://blogs.perl.org/users/sergey_kolychev/2017/02/machine-learning-in-perl.html) | . salesforce/nonauto-nmt . salesforce/awd-lstm-lm . An Analysis of Neural Language Modeling at Multiple Scales . facebookresearch/tdfbanks . tensorflow/tensorflow . fomorians/highway-cnn . Highway Networks with TensorFlow – Jim Fleming – Medium . deltamachine/naive-automatic-postediting . Added lexnet_nc model. · tensorflow/models@1f37153 . [Understanding Deep Learning through Neuron Deletion | DeepMind](https://deepmind.com/blog/understanding-deep-learning-through-neuron-deletion/) | . kaldi-asr/kaldi . facebookresearch/tdfbanks . PDF - arxiv.org . Corpus building for data-driven TTS systems . apohllo/pjn . Time alignments off by a factor of 3 when using nnet3-align-compiled - Google Groups . One best hypothesis Lattice to CTM - Google Groups . zackchase/ddc . ethanfetaya/NRI . C++ gradients: Fractional*Pool, Soft{Plus,Sign} by kbsriram · Pull Request #17331 · tensorflow/tensorflow .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2018/03/23/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2018/03/23/evernote-links.html",
            "date": " • Mar 23, 2018"
        }
        
    
  
    
        ,"post300": {
            "title": "Evernote web clips, 22/3/2018",
            "content": "Language Transfer of Audio Word2Vec: Learning Audio Segment Representations without Target Language Data . Peering into Neural Networks—How Sequence Models View State of the Union Speeches from Three U.S. Presidents . Annotation Artifacts in Natural Language Inference Data . CMU Sphinx Frequently Asked Questions . How to use an Existing DNN Recognizer for Decoding in Kaldi . Exploring the Boost Graph Library . How to build a deep learning model in 15 minutes . Requests for Research . Gradient Descent in a Nutshell .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2018/03/22/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2018/03/22/evernote-links.html",
            "date": " • Mar 22, 2018"
        }
        
    
  
    
        ,"post301": {
            "title": "Evernote web clips, 14/2/2018",
            "content": "Create a working compiler with the LLVM framework, Part 1 . Create a working compiler with the LLVM framework, Part 2 .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/llvm/2018/02/14/evernote-links.html",
            "relUrl": "/evernote/web%20clip/llvm/2018/02/14/evernote-links.html",
            "date": " • Feb 14, 2018"
        }
        
    
  
    
        ,"post302": {
            "title": "Evernote web clips, 16/1/2018",
            "content": "Fast Inference for Neural Vocoders . The 10 Deep Learning Methods AI Practitioners Need to Apply . Adapting the default acoustic model . What most people don’t understand about AI and the the state of machine learning . Recent Advances in Recurrent Neural Networks . Deep Learning: A Critical Appraisal . mozilla/DeepSpeech document-init-from-frozen-model . Building Speech Applications Using CMU Sphinx and Related Resources .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2018/01/16/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2018/01/16/evernote-links.html",
            "date": " • Jan 16, 2018"
        }
        
    
  
    
        ,"post303": {
            "title": "Evernote web clips, 5/12/2016",
            "content": "[Readings | ÚFAL](https://ufal.mff.cuni.cz/milan-straka/readings) | .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2016/12/05/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2016/12/05/evernote-links.html",
            "date": " • Dec 5, 2016"
        }
        
    
  
    
        ,"post304": {
            "title": "Evernote web clips, 11/7/2016",
            "content": "User:Krvoje/Foma script for testing finite-state disambiguation - Apertium . Facebook will soon introduce a new Multilingual composer that automatically translates posts .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2016/07/11/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2016/07/11/evernote-links.html",
            "date": " • Jul 11, 2016"
        }
        
    
  
    
        ,"post305": {
            "title": "Evernote web clips, 4/4/2016",
            "content": "Formant-controlled HMM-based Speech Synthesis .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/tts/2016/04/04/evernote-links.html",
            "relUrl": "/evernote/web%20clip/tts/2016/04/04/evernote-links.html",
            "date": " • Apr 4, 2016"
        }
        
    
  
    
        ,"post306": {
            "title": "Evernote web clips, 25/3/2016",
            "content": "SpeCT - The Speech Corpus Toolkit for Praat .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/praat/2016/03/25/evernote-links.html",
            "relUrl": "/evernote/web%20clip/praat/2016/03/25/evernote-links.html",
            "date": " • Mar 25, 2016"
        }
        
    
  
    
        ,"post307": {
            "title": "Evernote web clips, 19/3/2016",
            "content": "Train your own image classifier with Inception in TensorFlow .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2016/03/19/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2016/03/19/evernote-links.html",
            "date": " • Mar 19, 2016"
        }
        
    
  
    
        ,"post308": {
            "title": "Evernote web clips, 17/3/2016",
            "content": "Train your own image classifier with Inception in TensorFlow . TensorFlow for Poets .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2016/03/17/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2016/03/17/evernote-links.html",
            "date": " • Mar 17, 2016"
        }
        
    
  
    
        ,"post309": {
            "title": "signal processing definitions",
            "content": "periodic - traces same path . aperiodic - doesn’t . cycle - shape that repeats . period - time cycle takes to repeat . Hertz - cycles per second .",
            "url": "https://jimregan.github.io/notes/evernote/2016/01/31/signal-processing-defn.html",
            "relUrl": "/evernote/2016/01/31/signal-processing-defn.html",
            "date": " • Jan 31, 2016"
        }
        
    
  
    
        ,"post310": {
            "title": "node",
            "content": "Node . class Node {      char ch = START;      List&lt;Node&gt; = List.newArrayList();      void add (String str) {           if (str.length() == 0)                return;           char chNew = str.charAt(0);           for (Node n : nodes) {                if (n.ch == chNew) {                     n.add (str.substring(1));                     return;                }           Node newNode = new Node();           newNode.ch = chNew;           new Node.add(str.substring(1));           nodes.add(newNode);      }      String toRegexp() {           StringBuilder .",
            "url": "https://jimregan.github.io/notes/evernote/incomplete/2016/01/31/node.html",
            "relUrl": "/evernote/incomplete/2016/01/31/node.html",
            "date": " • Jan 31, 2016"
        }
        
    
  
    
        ,"post311": {
            "title": "LuaJ / Scribunto",
            "content": "LuaJ / Scribunto . LuaJ Field Access / function calls . LuaValue globals = JsePlatform.standardGlobals(); LuaValue sqrt = globals.get(&quot;math&quot;).get(&quot;sqrt&quot;); LuaValue print = globals.get(&quot;print&quot;); LuaValue d = sqrt.call(a); print.call(LuaValue.valueOf(&quot;sqrt(5):&quot;), a); . varargs / multiple returns . use invoke(Varargs) or invokemethod(LuaValue, Varargs) . LuaValue modf = globals.get(&quot;math&quot;).get(&quot;modf&quot;); Varargs r = modf.invoke(d); print.call(r.arg(1), r.arg(2)); . To load / run script: LoadState . LoadState.load(new FileInputStream(&quot;main.lua&quot;), &quot;main.lua&quot;, globals).call(); . or require . globals.get(&quot;require&quot;).call(LuaValue.valueOf(&quot;main&quot;)) . preinit tables: . listOf(LuaValue[]) - for unnamed elements | tableOf (LuaValue[]) - for named | tableOf(LuaValue[], LuaValue[], Varargs) - mixture | . LuaJ - date not implemented . if (format[0] == &#39;!&#39;) {      calendar = Calendar.getInstance(TimeZone.getTimeZone(&quot;GMT&quot;); } else {      calendar = Cak,getInst(TimeZone.getDefault()); } . also adjust format . DST: TimeZone tz = TimeZone.getDefault();      bool.isdst = tz.useDaylightTime(); function setTTL ($ttl) {      $args = func_get_args();      $this-&gt;checkNumber(&#39;setTTL&#39;, $args, 0);      $frame = $this-&gt;getFrameById(&#39;current&#39;);      if (is_callable(array($frame, &#39;setTTL&#39;))) {           $frame-&gt;setTTL($ttl); // ??      } } . Scribunto . Module: Bananas . local p = {} function p.hello(frame)      return &quot;Hello world&quot; end return p . other page: . {{#invoke:Bananas|hello}} .",
            "url": "https://jimregan.github.io/notes/evernote/2016/01/30/luaj-scribunto.html",
            "relUrl": "/evernote/2016/01/30/luaj-scribunto.html",
            "date": " • Jan 30, 2016"
        }
        
    
  
    
        ,"post312": {
            "title": "Evernote web clips, 27/1/2016",
            "content": "A cross-language vowel normalisation procedure . An Aspectual Classification of Polish Verbs .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2016/01/27/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2016/01/27/evernote-links.html",
            "date": " • Jan 27, 2016"
        }
        
    
  
    
        ,"post313": {
            "title": "Evernote web clips, 16/1/2016",
            "content": "generate-bidix-templates.py . Hiberno-English Vowel System: Drogheda English . Tonal Alignment in Three Varieties of Hiberno-English . Hiberno-English Question Intonation: the Case of Drogheda English .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2016/01/16/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2016/01/16/evernote-links.html",
            "date": " • Jan 16, 2016"
        }
        
    
  
    
        ,"post314": {
            "title": "Evernote web clips, 1/12/2015",
            "content": "Unsupervised estimation of the human vocal tract length over sentence level utterances .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/12/01/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/12/01/evernote-links.html",
            "date": " • Dec 1, 2015"
        }
        
    
  
    
        ,"post315": {
            "title": "Evernote web clips, 29/11/2015",
            "content": "The invisible minority: revisiting the debate on foreign-accented speakers and upward mobility in the workplace. . Accents in the workplace: their effects during a job interview. . PLURILINGUALISM – PRIORITY IN PROMOTING EQUALITY OF CHANCES. . Challenges of multilingualism in the EU. . Piecing together the workplace multilingualism jigsaw puzzle .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/11/29/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/11/29/evernote-links.html",
            "date": " • Nov 29, 2015"
        }
        
    
  
    
        ,"post316": {
            "title": "Evernote web clips, 17/11/2015",
            "content": "[Swesaurus | Språkbanken](http://spraakbanken.gu.se/eng/resource/swesaurus) | . [SALDO’s morphology | Språkbanken](http://spraakbanken.gu.se/eng/resource/saldom) | . [LWT | Språkbanken](http://spraakbanken.gu.se/eng/resource/lwt) | . [LWT-PWN | Språkbanken](http://spraakbanken.gu.se/eng/resource/lwt-pwn) | . An Engineer’s Guide to GEMM .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/11/17/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/11/17/evernote-links.html",
            "date": " • Nov 17, 2015"
        }
        
    
  
    
        ,"post317": {
            "title": "Evernote web clips, 28/10/2015",
            "content": "Guidelines for developing NIF-based NLP services . The Stanford NLP (Natural Language Processing) Group . Guidelines for Linked Data corpus creation using NIF . [Torch | The power of Spatial Transformer Networks](http://torch.ch/blog/2015/09/07/spatial_transformers.html) | .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/10/28/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/10/28/evernote-links.html",
            "date": " • Oct 28, 2015"
        }
        
    
  
    
        ,"post318": {
            "title": "Dependency analysis",
            "content": "Irish stuff .       . d’ | do | do+Part+Vb+@&gt;V | . ól | ól | ól+Verb+VTI+Vow+PastInd+Len+@FMV | . mé | mé | mé+Pron+Pers+1P+Sg+@SUBJ | .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/10/26/irish-dependency.html",
            "relUrl": "/evernote/web%20clip/2015/10/26/irish-dependency.html",
            "date": " • Oct 26, 2015"
        }
        
    
  
    
        ,"post319": {
            "title": "Evernote web clips, 6/9/2015",
            "content": "Phoneme Recognition . btrask/stronglink .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/09/06/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/09/06/evernote-links.html",
            "date": " • Sep 6, 2015"
        }
        
    
  
    
        ,"post320": {
            "title": "Evernote web clips, 3/9/2015",
            "content": "Wikidata/Wikidata-Toolkit . NASARI . [Transition-Based Dependency Parsing with Stack Long Short-Term Memory | GitXiv](http://gitxiv.com/posts/qEQvDP8eidkAsGcPQ/transition-based-dependency-parsing-with-stack-long-short) | .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/09/03/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/09/03/evernote-links.html",
            "date": " • Sep 3, 2015"
        }
        
    
  
    
        ,"post321": {
            "title": "Evernote web clips, 12/8/2015",
            "content": "Parsing S-Expressions in Scala . Function Memoization in Scala . Clang Plugins — Clang 3.8 documentation .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/08/12/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/08/12/evernote-links.html",
            "date": " • Aug 12, 2015"
        }
        
    
  
    
        ,"post322": {
            "title": "Evernote web clips, 12/6/2015",
            "content": "I have now converged on a stable recipe for deep neural net training Kaldi.… . Start of parser . Untitled note . karpathy/gist:7bae8033dcf5ca2630ba . Use of exp in the Reparametrization · Issue #3 · y0ast/VAE-Torch . chrisnatale / IHTAI / wiki / Home — Bitbucket . littleowen/Conceptor . duguyue100/conceptors .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/06/12/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/06/12/evernote-links.html",
            "date": " • Jun 12, 2015"
        }
        
    
  
    
        ,"post323": {
            "title": "Evernote web clips, 4/6/2015",
            "content": "Četnost jmen a příjmení - Ministerstvo vnitra České republiky . NomesLex-PT 01 in English - DMIR Group at INESC-ID . [Sansa Stark | Reaction Images](http://knowyourmeme.com/photos/588075-reaction-images) | . OpenCL alternatives for CUDA Linear Algebra Libraries . What are important points about deep learning applied to speech recognition, for a business audience? - Quora . Deep Learning, NLP, and Representations . From Machine Learning to Machine Reasoning . Learning Continuous Phrase Representations for Translation Modeling . Hinton’s Dark Knowledge . High-Performance OCR for Printed English and Fraktur using LSTM Networks . C3D: Generic Features for Video Analysis . dlwh/epic . Senna . Natural Language Processing (almost) from Scratch . Conv Nets: A Modular Perspective . Understanding Convolutions . Visualizing Representations: Deep Learning and Human Beings .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/06/04/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/06/04/evernote-links.html",
            "date": " • Jun 4, 2015"
        }
        
    
  
    
        ,"post324": {
            "title": "Evernote web clips, 2015-06-03",
            "content": "cubicdaiya/dtl . facebook/Stack-RNN . An Introduction to Conditional Random Fields . Using word2vec for different NLP tasks • /r/MachineLearning . gensim: topic modelling for humans . erickrf/nlpnet . SENNA . Natural Language Processing (almost) from Scratch . The Agency . Demystifying LSTM Neural Networks . A good source to learn Recurrent Neural Nets and Long Short Term Memory Nets? • /r/MachineLearning . An illustrated introduction to the t-SNE algorithm - O&#39;Reilly Media . Feeding an image to a RNN or dealing with images of different dimensions? • /r/MachineLearning .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/06/03/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/06/03/evernote-links.html",
            "date": " • Jun 3, 2015"
        }
        
    
  
    
        ,"post325": {
            "title": "Evernote web clips, 31/5/2015",
            "content": "pyklatt - An advanced Python implementation of a Klatt synthesizer . Untitled note . Formant Estimation with LPC Coefficients . proteusvacuum/KlattSynth .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/05/31/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/05/31/evernote-links.html",
            "date": " • May 31, 2015"
        }
        
    
  
    
        ,"post326": {
            "title": "Evernote notes, TTS",
            "content": "Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups . Multi-distribution deep belief network for speech synthesis . Modeling spectral envelopes using restricted Boltzmann machines for statistical parametric speech synthesis . Speech recognition with deep recurrent neural networks . Hybrid speech recognition with Deep Bidirectional LSTM . Connectionist temporal classification: labelling un-segmented sequence data with recurrent neural networks . mohammadpz/CTC-Connectionist-Temporal-Classification . Feature engineering in context-dependent deep neural networks for conversational speech transcription . A Novel Approach to On-Line Handwriting Recognition Based on Bidirectional Long Short-Term Memory Networks .",
            "url": "https://jimregan.github.io/notes/evernote/tts/asr/2015/05/30/tts-evernote.html",
            "relUrl": "/evernote/tts/asr/2015/05/30/tts-evernote.html",
            "date": " • May 30, 2015"
        }
        
    
  
    
        ,"post327": {
            "title": "Evernote web clips, 30/5/2015",
            "content": "Modeling spectral envelopes using restricted Boltzmann machines for statistical parametric speech synthesis . Multi-distribution deep belief network for speech synthesis . Deep Neural Networks for Acoustic Modeling in Speech Recognition . Grapheme-based Synthesizer . glecorve/rnnlm2wfst . Statistical Parametric Speech Synthesis Using Deep Neural Networks . NEURAL MACHINE TRANSLATION BY JOINTLY LEARNING TO ALIGN AND TRANSLATE . Combining a vector space representation of linguistic context with a deep neural network for text-to-speech synthesis . TTS Synthesis with Bidirectional LSTM based Recurrent Neural Networks . Implementation of Neural Turing Machines • /r/MachineLearning . Sequence to Sequence Learning with Neural Networks . Discriminative models, not discriminative training . kastnerkyle/test_ctc.py . glecorve/rnnlm2wfst . DEEP NEURAL NETWORK (DNN) FOR TTS SYNTHESIS - Microsoft Research .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/05/30/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/05/30/evernote-links.html",
            "date": " • May 30, 2015"
        }
        
    
  
    
        ,"post328": {
            "title": "Evernote web clips, 29/5/2015",
            "content": "aalto-speech/AaltoASR . nouiz/lisa_emotiw . dpkingma/nips14-ssl . stanfordnlp/treelstm . CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers . mattpap/IScala . brian473/neural_rl . dcodeIO/ByteBuffer.js .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/05/29/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/05/29/evernote-links.html",
            "date": " • May 29, 2015"
        }
        
    
  
    
        ,"post329": {
            "title": "Simple lttoolbox transducer",
            "content": "hexdump /tmp/test2.bin 0000000 1a 40 61 40 62 40 63 40 64 40 65 40 66 40 67 40 0000010 68 40 69 40 6a 40 6b 40 6c 40 6d 40 6e 40 6f 40 0000020 70 40 71 40 72 40 73 40 74 40 75 40 76 40 77 40 0000030 78 40 79 40 7a 01 01 40 6e 08 01 01 01 40 74 01 0000040 00 40 67 40 67 40 70 40 70 40 63 40 63 40 62 40 0000050 62 40 73 40 73 02 12 40 69 40 6e 40 63 40 6f 40 0000060 40 40 69 40 6e 40 63 40 6f 40 6e 40 64 40 69 40 0000070 74 40 69 40 6f 40 6e 40 61 40 6c 00 01 05 06 01 0000080 05 01 01 06 01 01 07 01 01 01 01 01 02 01 00 0d 0000090 40 6d 40 61 40 69 40 6e 40 40 40 73 40 74 40 61 00000a0 40 6e 40 64 40 61 40 72 40 64 00 01 05 06 01 03 00000b0 01 01 04 01 01 04 01 01 01 01 01 02 01 00      00000be . ^Z@a@b@c@d@e@f@g@h@i@j@k@l@m@n@o@p@q@r@s@t@u@v@w@x@y@z ^A^A@^A^A^A@t^A^@@g@g@p@p@c@c@b@b@s@s^B^R@i@n@c@o@@@i @n@c@o@n@d@i@t@i@o@n@a@l^@^A^E^F^A^E^A^A^F^A^A^G^A^A ^A^A^A^B^A^@^M@m@a@i@n@@@s@t@a@n@d@a@r@d^@^A^E^F^A^C ^A^A^D^A^A^D^A^A^A^A^A^B^A^@ . $ lt-print /tmp/test2.bin 0     1     b     b     1     2     a     a     2     3     r     r     3     4     ε     s     4     5     ε     &lt;n&gt;     5 -- 0     1     f     f     1     2     o     o     2     3     o     o     3     4     ε     s     4     5     ε     &lt;n&gt;     5 . ^@ ^A^E^F^A^E^A^A^F^A^A^G^A^A^A^A^A^B^A ^@ ^M . $ cat /tmp/test.dix . &lt;dictionary&gt;   &lt;alphabet&gt;abcdefghijklmnopqrstuvwxyz&lt;/alphabet&gt;   &lt;sdefs&gt;     &lt;sdef n=&quot;n&quot;/&gt;   &lt;/sdefs&gt;   &lt;pardefs&gt;     &lt;pardef n=&quot;one&quot;&gt;       &lt;e&gt;&lt;p&gt;&lt;l&gt;&lt;/l&gt;&lt;r&gt;s&lt;s n=&quot;n&quot;/&gt;&lt;/r&gt;&lt;/p&gt;&lt;/e&gt;     &lt;/pardef&gt;   &lt;/pardefs&gt;   &lt;section id=&quot;main&quot; type=&quot;standard&quot;&gt;     &lt;e&gt;&lt;i&gt;foo&lt;/i&gt;&lt;par n=&quot;one&quot;/&gt;&lt;/e&gt;   &lt;/section&gt;   &lt;section id=&quot;inco&quot; type=&quot;inconditional&quot;&gt;     &lt;e&gt;&lt;i&gt;bar&lt;/i&gt;&lt;par n=&quot;one&quot;/&gt;&lt;/e&gt;   &lt;/section&gt; &lt;/dictionary&gt; .",
            "url": "https://jimregan.github.io/notes/evernote/2015/05/28/simple-lttoolbox-transducer.html",
            "relUrl": "/evernote/2015/05/28/simple-lttoolbox-transducer.html",
            "date": " • May 28, 2015"
        }
        
    
  
    
        ,"post330": {
            "title": "neural notes",
            "content": "Weakly Supervised Memory Networks . Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks . wojzaremba/lstm . Reinforcement Learning Neural Turing Machines . kaishengtai/torch-ntm . stanfordnlp/treelstm . Neural Machine Translation by Jointly Learning to Align and Translate . lisa-groundhog/GroundHog . rsennrich/nplm . shawntan/neural-turing-machines, implementation of neural turing machines, gcgibson/NTM . Learning to Execute . Sequence to Sequence Learning with Neural Networks .",
            "url": "https://jimregan.github.io/notes/evernote/2015/05/28/neural-notes-evernote-links.html",
            "relUrl": "/evernote/2015/05/28/neural-notes-evernote-links.html",
            "date": " • May 28, 2015"
        }
        
    
  
    
        ,"post331": {
            "title": "Evernote web clips, 27/5/2015",
            "content": "The Unreasonable Effectiveness of Recurrent Neural Networks . fchollet/keras . Implementation of Neural Turing Machines • /r/MachineLearning . [Keras: Theano-Based Deep Learning Library | Hacker News](https://news.ycombinator.com/item?id=9283105) | . INL/BlackLab . INL/BlackLab . INL/BlackLab . Circular_buffer example - 1.58.0 . Neural Machine Translation by Jointly Learning to Align and Translate .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/05/27/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/05/27/evernote-links.html",
            "date": " • May 27, 2015"
        }
        
    
  
    
        ,"post332": {
            "title": "Evernote web clips, 1/3/2015",
            "content": "SAMPA for Polish . Which GPU(s) to Get for Deep Learning: My Experience and Advice for Using GPUs in Deep Learning .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/03/01/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/03/01/evernote-links.html",
            "date": " • Mar 1, 2015"
        }
        
    
  
    
        ,"post333": {
            "title": "Evernote web clips, 19/5/2015",
            "content": "TrainingTesseract3 . Cédric Verstraeten . Introduction to Artificial Neural Networks Part 2 - Learning . Pauls Online Notes : Calculus III - Partial Derivatives . Medieval Unicode Font Initiative - Wikipedia, the free encyclopedia .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/02/19/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/02/19/evernote-links.html",
            "date": " • Feb 19, 2015"
        }
        
    
  
    
        ,"post334": {
            "title": "Evernote web clips, 15/2/2015",
            "content": "Finger Trees - Andrew Gibiansky . Machine Learning: Neural Networks - Andrew Gibiansky . Machine Learning: the Basics - Andrew Gibiansky . Creating Language Kernels for IPython - Andrew Gibiansky . Convolutional Neural Networks - Andrew Gibiansky . K Nearest Neighbors: Simplest Machine Learning - Andrew Gibiansky . Hessian Free Optimization - Andrew Gibiansky . Fully Connected Neural Network Algorithms - Andrew Gibiansky . Convolutional Neural Networks - Andrew Gibiansky . Homophony Groups in Haskell - Andrew Gibiansky . Gradient Descent Typeclasses in Haskell - Andrew Gibiansky . Cool Linear Algebra: Singular Value Decomposition - Andrew Gibiansky . Recurrent Neural Networks - Andrew Gibiansky . Speech Recognition with Neural Networks - Andrew Gibiansky . Sequence Transduction with Recurrent Neural Networks . Speech Recognition with Neural Networks - Andrew Gibiansky .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/02/15/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/02/15/evernote-links.html",
            "date": " • Feb 15, 2015"
        }
        
    
  
    
        ,"post335": {
            "title": "Evernote web clips, 8/2/2015",
            "content": "SuDoKu Grabber with OpenCV: Recognizing digits - AI Shack . SuDoKu Grabber with OpenCV: Extracting digits - AI Shack . SuDoKu Grabber with OpenCV: Extracting the grid - AI Shack . SuDoKu Grabber with OpenCV: The Plot - AI Shack . Caffe: Add TRec unit . Caffe: Load weights from multiple caffemodels . On Academia… « muellis blog . Running the code with Ocelot - Udacity .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/02/08/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/02/08/evernote-links.html",
            "date": " • Feb 8, 2015"
        }
        
    
  
    
        ,"post336": {
            "title": "Evernote web clips, 6/2/2015",
            "content": "Android: Simple Shape Recognition using OpenCV, JavaCV . SuDoKu Grabber with OpenCV: Grid detection - AI Shack . [The D2RQ Mapping Language | The D2RQ Platform](http://d2rq.org/d2rq-language#example-join) | . d2rp example . Metacademy - Deep learning from the bottom up . How to detect simple geometric shapes using OpenCV . [Note to self: Compiling C++ programs using libraries installed with homebrew | The NonConditional Beast](http://nonconditional.com/2013/10/note-to-self-compiling-programs-using-boost-installed-with-homebrew/) | . Deep Learning via Semi-Supervised Embedding . Representation Learning: A Review and New Perspectives . Recursive Autoencoder with Theano - Google Groups .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/02/06/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/02/06/evernote-links.html",
            "date": " • Feb 6, 2015"
        }
        
    
  
    
        ,"post337": {
            "title": "Evernote web clips, 15/1/2015",
            "content": "[School of Shred: Paul Gilbert on the Art and Science of Playing Lead Guitar - Page 3 | Guitar World](http://www.guitarworld.com/school-shred-paul-gilbert-teaches-isightful-lesson-art-and-science-lead-guitar-playing?page=0,2) | . [School of Shred: Paul Gilbert on the Art and Science of Playing Lead Guitar - Page 2 | Guitar World](http://www.guitarworld.com/school-shred-paul-gilbert-teaches-isightful-lesson-art-and-science-lead-guitar-playing?page=0,1) | . [School of Shred: Paul Gilbert on the Art and Science of Playing Lead Guitar | Guitar World](http://www.guitarworld.com/school-shred-paul-gilbert-teaches-isightful-lesson-art-and-science-lead-guitar-playing) | . Drop 2 Chords &amp; Voicings For Guitar . Guitar Chalk Sessions: A Clean Guide to Understanding Seventh Chords . . Dlaczego słownik nie stoi na straży czystości języka? - Wielki słownik od kuchni . GDSSecurity/Docker-Secure-Deployment-Guidelines . Creating and publishing a node.js module - Quick Left . Felix’s Node.js Beginners Guide .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/01/15/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/01/15/evernote-links.html",
            "date": " • Jan 15, 2015"
        }
        
    
  
    
        ,"post338": {
            "title": "Evernote web clips, 14/1/2015",
            "content": "Constructing Deterministic Finite-State Automata in Recurrent Neural Networks . Finite-state computation in analog neural networks: steps towards biologically plausible models? . Comparing two acquisition systems for automatically building an English–Croatian parallel corpus from multilingual websites . Quality Estimation for Synthetic Parallel Data Generation . Abu-MaTran at WMT 2014 Translation Task: Two-step Data Selection and RBMT-Style Synthetic Rules . [Custom Runners | Cloud9 User Documentation](https://docs.c9.io/custom_runners.html) | . [Jazz Guitar Corner: Jazz Guitar Chord Exercises — with Tab and Audio | Guitar World](http://www.guitarworld.com/jazz-guitar-corner-jazz-guitar-chord-exercises-tab-and-audio) | . To Fall in Love With Anyone, Do This - NYTimes.com . Here Are the 36 Questions That Will Allegedly Make You Fall in Love . No. 37: Big Wedding or Small? - NYTimes.com . How to Get Read on Medium — Medium . The Grumpy Programmer: October 2014 . Scripting Languages You May Not Know - Dice News .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/01/14/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/01/14/evernote-links.html",
            "date": " • Jan 14, 2015"
        }
        
    
  
    
        ,"post339": {
            "title": "Evernote web clips, 12/1/2015",
            "content": "Text in Russian: Saint Petersburg . Text in Russian: The coldest town on Earth . Text in Russian: Banya / Russian Sauna . Text in Russian: Russian bear .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/russian/2015/01/12/evernote-links.html",
            "relUrl": "/evernote/web%20clip/russian/2015/01/12/evernote-links.html",
            "date": " • Jan 12, 2015"
        }
        
    
  
    
        ,"post340": {
            "title": "Evernote web clips, 8/1/2015",
            "content": "Wikimedia Blog » Blog Archive » Scaling Wikidata: success means making the pie bigger . [The 88 movies we’re most excited about in 2015 | Film | The Guardian](http://www.theguardian.com/film/2015/jan/06/2015-key-movies-films-year-ahead) | . azakai: HOWTO: Port a C/C++ Library to JavaScript (xml.js) . Getting Started With Emscripten · jallwine/emscripten_test Wiki . wiki.dbpedia.org : meetings / Dublin 2015 . [What reviewers write, and what they (really) mean | Peter Simons - Academia.edu](https://www.academia.edu/9468277/What_reviewers_write_and_what_they_really_mean) | .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/01/08/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/01/08/evernote-links.html",
            "date": " • Jan 8, 2015"
        }
        
    
  
    
        ,"post341": {
            "title": "Evernote web clips, 1/1/2015",
            "content": "Word Embeddings For Fashion — Technology on Heels with Lyst Engineering . Neat Algorithms - Paxos - Will You Harry Me . Radim Řehůřek : Word2vec Tutorial . Life Lessons From Highly Successful People - Business Insider .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2015/01/01/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2015/01/01/evernote-links.html",
            "date": " • Jan 1, 2015"
        }
        
    
  
    
        ,"post342": {
            "title": "Evernote web clips, 29/12/2014",
            "content": "A Faster Scrabble Move Generation Algorithm . [Gaddag Data Structure – A Way To Quickly Find Scrabble Words | NullWords Blog](http://nullwords.wordpress.com/2013/02/27/gaddag-data-structure/) | . [Jacky Tian | Blog](http://blog.xjtian.com/post/50516439182/a-smarter-scrabble-ai-part-1-lexical) | . GADDAG.java .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/gaddag/scrabble/2014/12/29/evernote-links.html",
            "relUrl": "/evernote/web%20clip/gaddag/scrabble/2014/12/29/evernote-links.html",
            "date": " • Dec 29, 2014"
        }
        
    
  
    
        ,"post343": {
            "title": "Evernote web clips, 28/12/2014",
            "content": "Distilling the Knowledge in a Neural Network . Implementation of Lucas-Kanade tracker in cpp . lk_track.py . SLAM for Dummies . Nikita Zhiltsov / Никита Жильцов: My Visiting Project at Emory University: Entity Search over Linked Data . Chapter 10. Code case study: parsing a binary data format .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/12/28/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/12/28/evernote-links.html",
            "date": " • Dec 28, 2014"
        }
        
    
  
    
        ,"post344": {
            "title": "Evernote, 21/12/2014",
            "content": "phash.cc . #include &lt;iostream&gt; #include &lt;string&gt; #include &lt;pHash.h&gt; #define PROPS_URL &quot;&lt;http://...&gt;&quot; int main (int argc, char** argv) {      ulong64 hash = 0;      string name;      while(std::getline(std::cin, name))      {           ph_dct_imagehash(name.c_str(), hash);           std::cout &lt;&lt; &quot;&lt;http://&quot; &lt;&lt; name &lt;&lt; &quot;&gt; &quot;;           std::cout &lt;&lt; PROPS_URL;           std::cout &lt;&lt; &quot; &quot;&quot; &lt;&lt; hash &lt;&lt; &quot; &quot; .&quot; &lt;&lt; endl;           hash = 0;      }      return 0; } .",
            "url": "https://jimregan.github.io/notes/evernote/phash/2014/12/21/phash.html",
            "relUrl": "/evernote/phash/2014/12/21/phash.html",
            "date": " • Dec 21, 2014"
        }
        
    
  
    
        ,"post345": {
            "title": "Evernote web clips, 18/12/2014",
            "content": "Fun mosaic effect with Go . Cultural Studies and Modern Languages: an Introduction — University of Bristol — FutureLearn . Introduction to Dutch — University of Groningen — FutureLearn .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/12/18/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/12/18/evernote-links.html",
            "date": " • Dec 18, 2014"
        }
        
    
  
    
        ,"post346": {
            "title": "Evernote web clips, 13/12/2014",
            "content": "Rich feature hierarchies for accurate object detection and semantic segmentation . AUDFPRINT - Audio fingerprint database creation + query . [Using Docker to Encapsulate Complicated Program is Successful | Internet Archive Blogs](http://blog.archive.org/2014/11/14/docker-to-encapsulate-complicated-program-successful/) | .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/12/13/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/12/13/evernote-links.html",
            "date": " • Dec 13, 2014"
        }
        
    
  
    
        ,"post347": {
            "title": "Evernote web clips, 12/12/2014",
            "content": "Addressing the Rare Word Problem in Neural Machine Translation . presslabs/gitfs . gitfs/Vagrantfile at master · PressLabs/gitfs . [From word2vec to doc2vec: an approach driven by Chinese restaurant process | Kifi Engineering Blog](https://web.archive.org/web/20160309231845/http://eng.kifi.com/from-word2vec-to-doc2vec-an-approach-driven-by-chinese-restaurant-process/) | . word2vec Explained: deriving Mikolov et al.’s negative-sampling word-embedding method . gensim: models.word2vec – Deep learning with word2vec . Sequence to Sequence Learning with Neural Networks . Distributed Representations of Sentences and Documents . Writing and transliterating Swahili in Arabic script with Andika! . [Fast Randomized SVD | Blog | Research at Facebook](https://research.facebook.com/blog/294071574113354/fast-randomized-svd/) | . [Question Answering with Subgraph Embeddings | Publications | Research at Facebook](https://research.facebook.com/publications/1473550739586509/question-answering-with-subgraph-embeddings/) | . [C3D: Generic Features for Video Analysis | Blog | Research at Facebook](https://research.facebook.com/blog/736987489723834/c3d-generic-features-for-video-analysis/) | . Machine Learning: The High-Interest Credit Card of Technical Debt . The Psychology of Color in Marketing and Branding . GloVe: Global Vectors for Word Representation . Distributing the Singular Value Decomposition with Spark – Databricks . Spark/mllib SVD example . How do I turn off the unlimited whitespace in IntelliJ editor? - Stack Overflow .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/12/12/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/12/12/evernote-links.html",
            "date": " • Dec 12, 2014"
        }
        
    
  
    
        ,"post348": {
            "title": "Evernote web clips, 6/11/2014",
            "content": "KALDI: Decision tree internals . Recurrent Neural Network Language Models . Deeplearning4j - Open-source, distributed deep learning for the JVM . Hac - A Java class library for hierarchical agglomerative clustering . Tangle: API Reference . Blazing fast AST generation using boost::spirit . Deep Learning, NLP, and Representations . Parse::RecDescent - search.cpan.org . An Introduction to the Boost Spirit Parser framework - CodeProject .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/11/06/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/11/06/evernote-links.html",
            "date": " • Nov 6, 2014"
        }
        
    
  
    
        ,"post349": {
            "title": "Evernote web clips, 2/11/2014",
            "content": "www.boddie.org.uk/david - Impression Documents and Tools . Spectrum +3 CP/M Plus manual . Reverse engineering the Quark Xpress file format .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/11/02/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/11/02/evernote-links.html",
            "date": " • Nov 2, 2014"
        }
        
    
  
    
        ,"post350": {
            "title": "Evernote web clips, 30/10/2014",
            "content": "Training Acoustic Model For CMUSphinx - CMUSphinx Wiki . [Russian Audiobook Morphology-Based Model | CMU Sphinx - Speech Recognition Toolkit](https://cmusphinx.github.io/2011/09/russian-audiobook-morphology-based-model/) | .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/10/30/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/10/30/evernote-links.html",
            "date": " • Oct 30, 2014"
        }
        
    
  
    
        ,"post351": {
            "title": "Evernote web clips, 28/10/2014",
            "content": "Pagestream . Impression Document Description Format .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/10/28/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/10/28/evernote-links.html",
            "date": " • Oct 28, 2014"
        }
        
    
  
    
        ,"post352": {
            "title": "Evernote web clips, 27/10/2014",
            "content": "LibriVox . OpenGRM.org . Lecture 6: OpenFST . OpenFst: src/include/fst/concat.h Source File . Tutorial for OpenFST and PyFST . OpenFST: Part II. Library Use and Design . The Problem With Positive Thinking - NYTimes.com . ConcatDoc &lt; FST &lt; TWiki . espeak ttsengine.cpp . /sources/flite/sapi/FliteTTSEngineObj/FliteTTSEngineObj.cpp . TTS Engine Vendor Porting Guide (SAPI 5.3) . XML TTS Tutorial (SAPI 5.3) . Overview of SAPI Grammar: Solitaire Example (SAPI 5.3) . Helper SpConvertStreamFormatEnum (SAPI 5.3) .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/10/27/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/10/27/evernote-links.html",
            "date": " • Oct 27, 2014"
        }
        
    
  
    
        ,"post353": {
            "title": "Evernote web clips, 17/10/2014",
            "content": "Changing Bits: Lucene’s TokenStreams are actually graphs! . Appendix:Lower Sorbian nouns - Wiktionary . [How to Write a Spelling Corrector | Felipe Farinon](http://scarvenger.wordpress.com/2007/12/11/how-to-write-a-spelling-corrector/) | .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/10/17/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/10/17/evernote-links.html",
            "date": " • Oct 17, 2014"
        }
        
    
  
    
        ,"post354": {
            "title": "Evernote web clips, 7/9/2014",
            "content": "command center: The byte order fallacy . nnFileFormat - tesseract-ocr-extradocs - Extra documentation about Tesseract OCR - Google Project Hosting . Distributed systems theory for the distributed systems engineer : Paper Trail .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/09/07/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/09/07/evernote-links.html",
            "date": " • Sep 7, 2014"
        }
        
    
  
    
        ,"post355": {
            "title": "Evernote web clips, 1/9/2014",
            "content": "HfstTwolC &lt; KitWiki &lt; TWiki . koskenni/pytwolc . CA : Two-Level Rule Compiler - Xerox XRCE .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/09/01/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/09/01/evernote-links.html",
            "date": " • Sep 1, 2014"
        }
        
    
  
    
        ,"post356": {
            "title": "Evernote web clips, 8/8/2014",
            "content": "vptree.hs . Convert Between std::string and std::wstring, UTF-8 and UTF-16 - CodeProject . Google Fonts Uncial Antiqua . Appendix:Scots irregular verbs .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/08/08/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/08/08/evernote-links.html",
            "date": " • Aug 8, 2014"
        }
        
    
  
    
        ,"post357": {
            "title": "Evernote web clips, 2/8/2014",
            "content": "LLVM Tutorial . robovm/robovm . BlueRiverInteractive/robovm-ios-bindings . parslet -Get Started . A Gentle Introduction to IO Streams in C++ . Implementing a JIT Compiler with Haskell and LLVM . . As Yet Untitled — Git: Grafting repositories . hivex - Windows Registry &quot;hive&quot; extraction library .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/08/02/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/08/02/evernote-links.html",
            "date": " • Aug 2, 2014"
        }
        
    
  
    
        ,"post358": {
            "title": "Lolita vocabulary",
            "content": "etiolate make pale . coeval of the same age, from the same time . palliative serving to mitigate . fascinum ivory phallus . somatic relating to the body of an organism . tiddle fondle . axillary of or pertaining to the axilla or armpit . russet reddish-brown . voluptas pleasure . frétillement wriggling . tant pis too bad, never mind . Il était malin, celui qui a inventé ce truc-là He was clever, whoever invented this thing . grue prostitute .",
            "url": "https://jimregan.github.io/notes/evernote/2014/07/23/lolita-vocab-evernote-links.html",
            "relUrl": "/evernote/2014/07/23/lolita-vocab-evernote-links.html",
            "date": " • Jul 23, 2014"
        }
        
    
  
    
        ,"post359": {
            "title": "Evernote web clips, 23/7/2014",
            "content": "PL101: Create your own programming language . PL101: Create your own programming language . PL101: Create your own programming language . PL101: Create your own programming language . PL101: Create your own programming language . PL101: Create your own programming language . PL101: Create your own programming language . PL101: Create your own programming language . Parsoid - MediaWiki . Parsoid/MediaWiki DOM spec - MediaWiki .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/07/23/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/07/23/evernote-links.html",
            "date": " • Jul 23, 2014"
        }
        
    
  
    
        ,"post360": {
            "title": "Evernote web clips, 22/7/2014",
            "content": "The End of the Russian Fairy Tale . Rosja idzie w zaparte: fałszywi eksperci i informacje w rządowych mediach . Koniec rosyjskiej bajki. Wkrótce wszystko stanie się jasne . Separatyści wpuścili ekspertów na miejsce katastrofy. Na Ukrainę lecą policjanci z Australii . Ukraina . . Basic Binding using RoboVM and libGDXSeven Armed Squid . [Caffe | MNIST Tutorial](http://caffe.berkeleyvision.org/gathered/examples/mnist.html) | . [article | Perl 5 to Perl 6](http://perlgeek.de/en/article/5-to-6) | . Reading: It&#39;s All Good: Lolita . gocircuit/escher . simple_example.cc .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/07/22/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/07/22/evernote-links.html",
            "date": " • Jul 22, 2014"
        }
        
    
  
    
        ,"post361": {
            "title": "Evernote web clips, 16/7/2014",
            "content": "Public API Specification - NIF 2.0 . PDFBox text extraction . PDFBox create . Getting Started with Xtext . latex_equations.md .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/07/16/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/07/16/evernote-links.html",
            "date": " • Jul 16, 2014"
        }
        
    
  
    
        ,"post362": {
            "title": "Evernote web clips, 13/7/2014",
            "content": "[5 Essential Jazz Guitar Soloing Patterns | The Jazz Guitar Blog](http://www.jazzguitar.be/blog/5-essential-jazz-guitar-soloing-patterns/) | . Jazz Guitar Chord Theory Part 1 . [Guitar Scales | The Altered Scale For Guitar](https://www.jazzguitar.be/blog/altered-scale-for-guitar/) | . [17 Essential Jazz Guitar Chords For Beginners | Chord Chart](http://www.jazzguitar.be/blog/17-essential-jazz-guitar-chords-beginners/) | . [Gypsy Jazz Guitar | Django Reinhardt Arpeggios, Tricks &amp; Licks](https://www.jazzguitar.be/blog/django-reinhardt/) | . Exotic Guitar Scales .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/07/13/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/07/13/evernote-links.html",
            "date": " • Jul 13, 2014"
        }
        
    
  
    
        ,"post363": {
            "title": "Evernote web clips, 10/7/2014",
            "content": "Folder2IndexApp.java . APIExample . sven efftinge’s blog: 5 simple steps to Fowler’s DSL with Xtext 2.0 . Elastic Bunch Graph Matching - Scholarpedia . Polish » I4D - IVONA 4 Developers . Enclosing the public domain: The restriction of public domain books in a digital environment .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/07/10/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/07/10/evernote-links.html",
            "date": " • Jul 10, 2014"
        }
        
    
  
    
        ,"post364": {
            "title": "Evernote web clips, 28/4/2014",
            "content": "Ania Dąbrowska - Jej zapach . Ania Dąbrowska - Przy sąsiednim stoliku .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/04/28/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/04/28/evernote-links.html",
            "date": " • Apr 28, 2014"
        }
        
    
  
    
        ,"post365": {
            "title": "Evernote web clips, 26/4/2014",
            "content": "LuaJ add lua function in Java - Stack Overflow . lua - Force an integer type in luajava - Stack Overflow . nltk.probability.FreqDist . [public:gaussian_mixture_models_em_algorithm_-demo](https://web.archive.org/web/20160911013157/http://juergenwiki.de/work/wiki/doku.php?id=public:gaussian_mixture_models_em_algorithm-_demo) . c++ - OpenCV: color extraction based on Gaussian mixture model - Stack Overflow . ~sepisoad/vala-totrials/ValaTutorials : contents of io/gio_based/simple_text_file_reading/main.vala at revision 22 .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/04/26/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/04/26/evernote-links.html",
            "date": " • Apr 26, 2014"
        }
        
    
  
    
        ,"post366": {
            "title": "Evernote web clips, 25/4/2014",
            "content": "Image Recoloring using Gaussian Mixture Model and Expectation Maximization . _gpc.py . _gpr.py . 1.7 Gaussian Processes — scikit-learn 0.14 documentation .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/04/25/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/04/25/evernote-links.html",
            "date": " • Apr 25, 2014"
        }
        
    
  
    
        ,"post367": {
            "title": "Evernote web clips, 24/4/2014",
            "content": "Neural networks and deep learning . java - How can I pass objects to an exposed luaj function? - Stack Overflow .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/04/24/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/04/24/evernote-links.html",
            "date": " • Apr 24, 2014"
        }
        
    
  
    
        ,"post368": {
            "title": "Evernote web clips, 23/4/2014",
            "content": "The Science of Scientific Writing » American Scientist . File Exchange - MATLAB Central . A Gentle Introduction to Infrared Photography - Part 1 — Twelve-Tone Infrared Photography . Infrared basics for digital photographers . FLIR Tools Software for Use with FLIR Infrared Cameras and Thermal Imagers . Open Source Thermal Imaging . IRINFO - Understanding Proprietary Infrared Image Files .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/04/23/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/04/23/evernote-links.html",
            "date": " • Apr 23, 2014"
        }
        
    
  
    
        ,"post369": {
            "title": "jsoup Evernote web clips, 21/4/2014",
            "content": "Use selector-syntax to find elements: jsoup Java HTML parser . Use DOM methods to navigate a document: jsoup Java HTML parser . jsoup Java HTML Parser, with best of DOM, CSS, and jquery . Working with URLs: jsoup Java HTML parser . Extract attributes, text, and HTML from elements . Example program: list links: jsoup Java HTML parser . Set attribute values: jsoup Java HTML parser . Jsoup.clean without adding html entities - Stack Overflow . jsoup: Java HTML Parser . Whitelist (jsoup 1.7.4-SNAPSHOT API) . How To Parse HTML in JAVA -JSOUP Examples .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/jsoup/2014/04/21/jsoup-evernote-links.html",
            "relUrl": "/evernote/web%20clip/jsoup/2014/04/21/jsoup-evernote-links.html",
            "date": " • Apr 21, 2014"
        }
        
    
  
    
        ,"post370": {
            "title": "Evernote web clips, 21/4/2014",
            "content": "LOCOCONZ-PAS.txt . hypercard.org - Open Source HyperCard-related stuff . q_c.txt . dkpro-jwpl . TemplateNameExtractor.java . MicroDesign 3 page (.MDP) and area (.MDA) file specifications . LocoScript 1 file format .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2014/04/21/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2014/04/21/evernote-links.html",
            "date": " • Apr 21, 2014"
        }
        
    
  
    
        ,"post371": {
            "title": "lttoolbox oneOrMore",
            "content": "oneOrMore . This is code from lttoolbox, licence GPL 2 . void Transducer::oneOrMore(int const epsilon_tag) {   joinFinals(epsilon_tag);   int state = newState();   linkStates(state, initial, epsilon_tag);   initial = state;   state = newState();   linkStates(*finals.begin(), state, epsilon_tag);   finals.clear();   finals.insert(state);   linkStates(state, initial, epsilon_tag); } void Transducer::joinFinals(int const epsilon_tag) {   if(finals.size() &gt; 1)   {     int state = newState();     for(set&lt;int&gt;::iterator it = finals.begin(), limit = finals.end();         it != limit; it++)     {       linkStates(*it, state, epsilon_tag);     }     finals.clear();     finals.insert(state);   }   else if(finals.size() == 0)   {     wcerr &lt;&lt; L&quot;Error: empty set of final states&quot; &lt;&lt;endl;     exit(EXIT_FAILURE);   } } void Transducer::linkStates(int const source, int const destino,                    int const etiqueta) {   if(transitions.find(source) != transitions.end() &amp;&amp;      transitions.find(destino) != transitions.end())   {     // new code     pair&lt;multimap&lt;int, int&gt;::iterator, multimap&lt;int, int&gt;::iterator&gt; range;     range = transitions[source].equal_range(etiqueta);     for(;range.first != range.second; range.first++)     {       if(range.first-&gt;first == etiqueta &amp;&amp; range.first-&gt;second == destino)       {         return;       }     }     // end of new code     transitions[source].insert(pair&lt;int, int&gt;(etiqueta, destino));   }   else   {     wcerr &lt;&lt; L&quot;Error: Trying to link nonexistent states (&quot; &lt;&lt; source;     wcerr &lt;&lt; L&quot;, &quot; &lt;&lt; destino &lt;&lt; L&quot;, &quot; &lt;&lt; etiqueta &lt;&lt; L&quot;)&quot; &lt;&lt; endl;     exit(EXIT_FAILURE);   } } .",
            "url": "https://jimregan.github.io/notes/evernote/lttoolbox/2014/03/23/one-or-more.html",
            "relUrl": "/evernote/lttoolbox/2014/03/23/one-or-more.html",
            "date": " • Mar 23, 2014"
        }
        
    
  
    
        ,"post372": {
            "title": "Evernote web clips, 22/6/2013",
            "content": "Quick notes on how to use RapidXML . rapid xml example . Archive of Formal Proofs .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2013/06/22/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2013/06/22/evernote-links.html",
            "date": " • Jun 22, 2013"
        }
        
    
  
    
        ,"post373": {
            "title": "Evernote web clips, 12/2/2013",
            "content": "IBM Model 1 . IBM Model 1 defines the probability of a sentence $s_1^J$, with length $J$, being translated to a sentence $t_1^I$, with length $I$, with the alignment $a_1^J$ as: . $Pr(t,a|s) = frac{ epsilon}{(J+1)^{I}} prod_{j=1}^{J}{tr(t_j|s_{a(j)})}$ . ASM/AAM . LeungMalikFilterBank .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2013/02/12/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2013/02/12/evernote-links.html",
            "date": " • Feb 12, 2013"
        }
        
    
  
    
        ,"post374": {
            "title": "Evernote web clips, 28/1/2013",
            "content": "mysql&gt; SELECT COUNT(DISTINCT p.product_id) AS total FROM oc_product p LEFT JOIN oc_product_description pd ON (p.product_id = pd.product_id) LEFT JOIN oc_product_to_store p2s ON (p.product_id = p2s.product_id) LEFT JOIN oc_product_to_category p2c ON (p.product_id = p2c.product_id) WHERE pd.language_id = &#39;1&#39; AND p.status = &#39;1&#39; AND p.date_available &lt;= NOW() AND p2s.store_id = &#39;0&#39; AND (p2c.category_id = &#39;2101&#39;); +-+ | total | +-+ |    19 | +-+ 1 row in set (15.58 sec) . Keynote DTD . keynote-apxl.html .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2013/01/28/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2013/01/28/evernote-links.html",
            "date": " • Jan 28, 2013"
        }
        
    
  
    
        ,"post375": {
            "title": "Evernote web clips, 2012-09-17",
            "content": "[How to clear font caches in Leopard | Macworld](http://www.macworld.com/article/1139383/fontcacheclear.html) | . If you want to remove the font cache for all users, use this command, and provide your admin password when asked: sudo atsutil databases -remove . Once you’ve cleared the caches, you should stop and restart the ATS server with these commands: . $ atsutil server -shutdown . $ atsutil server -ping . OpenIMAJ DoubleKMeans .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2012/09/17/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2012/09/17/evernote-links.html",
            "date": " • Sep 17, 2012"
        }
        
    
  
    
        ,"post376": {
            "title": "Evernote web clips, 16/9/2012",
            "content": "[Home | Natural Language Processing Laboratory](http://web.archive.org/web/20110907050907/http://nlp.sbu.ac.ir/site) | . [Multilingual Central Repository | adimen.si.ehu.es](http://adimen.si.ehu.es/web/MCR) | . MultiWordNet - Related works . MLSN: Download . Japanese Wordnet . FinnWordNet: Download files - Department of General Linguistics . Estonian Wordnet . Thai WordNet license . Sanskrit WordNet . Slovenská terminologická databáza .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/wordnet/2012/09/16/evernote-links.html",
            "relUrl": "/evernote/web%20clip/wordnet/2012/09/16/evernote-links.html",
            "date": " • Sep 16, 2012"
        }
        
    
  
    
        ,"post377": {
            "title": "SUMO relations",
            "content": "SUMO relations .     . equivalenceRelation  | = | . subsumingRelation  | + | . instanceRelation | @ | . antiSubsumingRelation | [ | . antiEquivalenceRelation | : | .",
            "url": "https://jimregan.github.io/notes/evernote/sumo/2012/09/10/sumo-relations.html",
            "relUrl": "/evernote/sumo/2012/09/10/sumo-relations.html",
            "date": " • Sep 10, 2012"
        }
        
    
  
    
        ,"post378": {
            "title": "Linking lexical resources and ontologies on the semantic web with lemon",
            "content": "@inproceedings{McCrae:2011:LLR:2008892.2008914, author = {McCrae, John and Spohr, Dennis and Cimiano, Philipp}, title = {Linking lexical resources and ontologies on the semantic web with lemon}, booktitle = {Proceedings of the 8th extended semantic web conference on The semantic web: research and applications - Volume Part I}, series = {ESWC&#39;11}, year = {2011}, isbn = {978-3-642-21033-4}, location = {Heraklion, Crete, Greece}, pages = {245--259}, numpages = {15}, url = {http://dl.acm.org/citation.cfm?id=2008892.2008914}, acmid = {2008914}, publisher = {Springer-Verlag}, address = {Berlin, Heidelberg}, } .",
            "url": "https://jimregan.github.io/notes/evernote/2012/08/17/lemon-citation.html",
            "relUrl": "/evernote/2012/08/17/lemon-citation.html",
            "date": " • Aug 17, 2012"
        }
        
    
  
    
        ,"post379": {
            "title": "ImageTerrier command",
            "content": "ImageTerrier command . /usr/bin/java -Xshare:off -Xmx6G -Djava.awt.headless=true -XX:-UseGCOverheadLimit -Dbundle.size=1000 -Dmemory.reserved=400000000 -cp /Users/jim/Downloads/ImageTerrierTools-3.0.1-jar-with-dependencies.jar org.imageterrier.basictools.BasicIndexer -o idx -qt RANDOM -p BYTE -k 100000 -t POSITION -pm SPATIAL_SCALE_ORI -nb 8,8,8,8 -mins 0.0,0.0,0.0,-3.14157 -maxs 1000.0,1000.0,150.0,3.14157 . .",
            "url": "https://jimregan.github.io/notes/evernote/imageterrier/2012/06/12/imageterrier-command-evernote-links.html",
            "relUrl": "/evernote/imageterrier/2012/06/12/imageterrier-command-evernote-links.html",
            "date": " • Jun 12, 2012"
        }
        
    
  
    
        ,"post380": {
            "title": "Evernote web clips, 12/6/2012",
            "content": "Tesseract iterator . tess.SetImage(...); tess.Recognize(0); tesseract::ResultIterator* ri = tess.GetIterator(); tesseract::ChoiceIterator* ci; if(ri != 0) { do { const char* symbol = ri-&gt;GetUTF8Text(tesseract::RIL_SYMBOL); if(symbol != 0) { float conf = ri-&gt;Confidence(tesseract::RIL_SYMBOL); std::cout &lt;&lt; &quot; tnext symbol: &quot; &lt;&lt; symbol &lt;&lt; &quot; tconf: &quot; &lt;&lt; conf &lt;&lt; &quot; n&quot;; const tesseract::ResultIterator itr = *ri; ci = new tesseract::ChoiceIterator(itr); do { const char* choice = ci-&gt;GetUTF8Text(); std::cout &lt;&lt; &quot; t t&quot; &lt;&lt; choice &lt;&lt; &quot; conf: &quot; &lt;&lt; ci-&gt;Confidence() &lt;&lt; &quot; n&quot;; } while(ci-&gt;Next()); delete ci; } delete[] symbol; } while((ri-&gt;Next(tesseract::RIL_SYMBOL))); } . System/36-Compatible RPG II User’s Guide and Reference .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/rpg/tesseract/2012/06/12/evernote-links.html",
            "relUrl": "/evernote/web%20clip/rpg/tesseract/2012/06/12/evernote-links.html",
            "date": " • Jun 12, 2012"
        }
        
    
  
    
        ,"post381": {
            "title": "Evernote web clips, 21/5/2012",
            "content": "How to write a Paper or Presentation . 10 Scala One Liners to Impress Your Friends . VP_tree.py .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2012/05/21/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2012/05/21/evernote-links.html",
            "date": " • May 21, 2012"
        }
        
    
  
    
        ,"post382": {
            "title": "Evernote web clips, 19/5/2012",
            "content": "10 CoffeeScript One Liners to Impress Your Friends . Processing real world HTML as if it were XML in scala . SSTable and Log Structured Storage: LevelDB . User:Rednaxela/kD-Tree - RoboWiki . bytefish/libfacerec .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2012/05/19/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2012/05/19/evernote-links.html",
            "date": " • May 19, 2012"
        }
        
    
  
    
        ,"post383": {
            "title": "Evernote web clips, 18/5/2012",
            "content": "CMU Sphinx: Long audio aligner for foreign languages . A Tour of Scala: Sequence Comprehensions . ScalaNLP . VP trees: A data structure for finding stuff fast . Reading XML using Groovy’s XmlSlurper wayback . R2R Framework – Translating RDF data from the Web to a target vocabulary . eldur/jwbf . TOPIC MODELING FOR WIKIPEDIA LINK DISAMBIGUATION .",
            "url": "https://jimregan.github.io/notes/evernote/web%20clip/2012/05/18/evernote-links.html",
            "relUrl": "/evernote/web%20clip/2012/05/18/evernote-links.html",
            "date": " • May 18, 2012"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://jimregan.github.io/notes/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  

  

  

  

  

  
  

  
      ,"page16": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://jimregan.github.io/notes/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}