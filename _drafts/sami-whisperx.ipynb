{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1763968",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import ctranslate2\n",
    "cnv = ctranslate2.converters.TransformersConverter(\"NbAiLab/whisper-large-sme\")\n",
    "cnv.convert(\"/data/whisper-large-sme\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e896697a",
   "metadata": {},
   "source": [
    "\n",
    "`whisperx --model_dir /data/whisper-large-sme --model large-v2 --align_model GetmanY1/wav2vec2-large-sami-22k  /data/9980064.mp3`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543a867d",
   "metadata": {},
   "source": [
    "```\n",
    "root@0c16ebf3d7d9:/workspace# whisperx --model /data/whisper-large-sme  --align_model GetmanY1/wav2vec2-large-sami-22k  /data/program_eamilbmotit_ii_oaidnu_bel_20251120_1532000148_a96.m4a \n",
    "/opt/conda/lib/python3.11/site-packages/pyannote/audio/core/io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
    "  torchaudio.list_audio_backends()\n",
    "/opt/conda/lib/python3.11/site-packages/speechbrain/utils/torch_audio_backend.py:57: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
    "  available_backends = torchaudio.list_audio_backends()\n",
    "tokenizer.json: 2.48MB [00:00, 42.4MB/s]\n",
    "2025-11-24 14:51:58 - whisperx.asr - INFO - No language specified, language will be detected for each audio file (increases inference time)\n",
    "2025-11-24 14:51:58 - whisperx.vads.pyannote - INFO - Performing voice activity detection using Pyannote...\n",
    "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.5.6. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../opt/conda/lib/python3.11/site-packages/whisperx/assets/pytorch_model.bin`\n",
    "/opt/conda/lib/python3.11/site-packages/pyannote/audio/core/io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
    "  torchaudio.list_audio_backends()\n",
    "Model was trained with pyannote.audio 0.0.1, yours is 3.4.0. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
    "Model was trained with torch 1.10.0+cu102, yours is 2.8.0+cu128. Bad things might happen unless you revert torch to 1.x.\n",
    "2025-11-24 14:51:58 - whisperx.transcribe - INFO - Performing transcription...\n",
    "/opt/conda/lib/python3.11/site-packages/pyannote/audio/utils/reproducibility.py:74: ReproducibilityWarning: TensorFloat-32 (TF32) has been disabled as it might lead to reproducibility issues and lower accuracy.\n",
    "It can be re-enabled by calling\n",
    "   >>> import torch\n",
    "   >>> torch.backends.cuda.matmul.allow_tf32 = True\n",
    "   >>> torch.backends.cudnn.allow_tf32 = True\n",
    "See https://github.com/pyannote/pyannote-audio/issues/1370 for more details.\n",
    "\n",
    "  warnings.warn(\n",
    "2025-11-24 14:51:59 - whisperx.asr - INFO - Detected language: fi (1.00) in first 30s of audio\n",
    "Transcript: [0.031 --> 26.845] dál gal dat čoahkemis beláŋŋas lea leamašan eanet ságat eamit álmmoga birra go goassege ovdal okta gii lea mátkkoštán Garasovvonis gitta Brasiliái lea sámi ráđđi ságadoalli PERSON gii dadjá gávtti gesuha ollu fuomášumiid\n",
    "Transcript: [26.845 --> 49.508] go Ruoŧa radio doaimmaheaddji lulli Amerihkás deaivvadit PERSON de son muitalii ahte háliidii loktet dálkkadat rievdadeamiid ja váikkuhusaid boazodollui ovdamearkka dihte go muohta maŋŋel lea buot juohke jagiid\n",
    "Transcript: [49.643 --> 68.358] muhto son dovdá ahte ii oktage guldal sin go dalle gáhtát eai boađe eamit almmot prográmmaide ja son dovdá iežas beahttun\n",
    "Transcript: [68.358 --> 94.075] Eami álmogiid ovttasteaddjit leat čoahkkimis juohkejuvvon čieža regiivnni ma ovttas galget sobadit makkár ášši galget leat mielde dálkkádat čoahkkima loahppadokkimentii Lea váttis bargu dadjat nuhtiid muhto okta ášši lea ovtta oaivilis ja dat lea ahte eami álmogat galget leat ossuin ja jierahuvvut ovdal go álggahii proseavtta mat váikojit sidjiide ja sin eatnamiid\n",
    "Transcript: [94.345 --> 109.955] dat lea grøndrifta de lea vindklasbargga de lea skukskjøplinga skuksaverkninga dálvvi Noraldit frem til de mii eat de lean vel førahan de informeren sámi tyskera mii elii eret eret de go de sáhttá manin dat orret dalle álttii leat dálvalit\n",
    "Transcript: [109.955 --> 131.504] Olloeami álmogiin lea ruvkedoallu govttáš danne go hárvánas minerálaid gáibádus lea lasihuvvon ja dát minerálaat gávdnojit dávjá sin eatnamiin PERSON dadjá ahte son ii leat vuostá leat ruoná ovttaideapmi muhto ahte galgá maid geahččalit máhčahit ja ođđasit geavahit minerálaid\n",
    "Transcript: [131.74 --> 149.948] ja ahte man vel de konsumera son miige fárpmá mans lenge greierit dan ahte og for sin egen de láhtin ahte eláhii dan fornyjaseame son tá mobiil telefovdnii skohter ala biillara og klæder og ahte man forholdos ehpet dii de man oro lottiin go lean ii be lean ge\n",
    "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at GetmanY1/wav2vec2-large-sami-22k and are newly initialized: ['lm_head.bias', 'lm_head.weight']\n",
    "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
    "2025-11-24 14:52:05 - whisperx.transcribe - INFO - New language found (fi)! Previous was (en), loading new alignment model for new language...\n",
    "/opt/conda/lib/python3.11/site-packages/transformers/configuration_utils.py:335: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
    "  warnings.warn(\n",
    "2025-11-24 14:52:07 - whisperx.transcribe - INFO - Performing alignment...\n",
    "Traceback (most recent call last):\n",
    "  File \"/opt/conda/bin/whisperx\", line 8, in <module>\n",
    "    sys.exit(cli())\n",
    "             ^^^^^\n",
    "  File \"/opt/conda/lib/python3.11/site-packages/whisperx/__main__.py\", line 98, in cli\n",
    "    transcribe_task(args, parser)\n",
    "  File \"/opt/conda/lib/python3.11/site-packages/whisperx/transcribe.py\", line 189, in transcribe_task\n",
    "    result: AlignedTranscriptionResult = align(\n",
    "                                         ^^^^^^\n",
    "  File \"/opt/conda/lib/python3.11/site-packages/whisperx/alignment.py\", line 275, in align\n",
    "    trellis = get_trellis(emission, tokens, blank_id)\n",
    "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "  File \"/opt/conda/lib/python3.11/site-packages/whisperx/alignment.py\", line 410, in get_trellis\n",
    "    trellis[t, :-1] + get_wildcard_emission(emission[t], tokens[1:], blank_id),\n",
    "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "  File \"/opt/conda/lib/python3.11/site-packages/whisperx/alignment.py\", line 435, in get_wildcard_emission\n",
    "    regular_scores = frame_emission[tokens.clamp(min=0).long()]  # clamp to avoid -1 index\n",
    "                     ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "IndexError: index 34 is out of bounds for dimension 0 with size 34\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
