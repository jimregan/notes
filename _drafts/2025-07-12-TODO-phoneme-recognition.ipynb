{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b204068b",
   "metadata": {},
   "source": [
    "Yes â€” you're thinking of the **multilingual wav2vec 2.0 phoneme recognizer**, likely from the **XLSR** series (`xlsr_53_56k.pt`) or from **SUPERB-style benchmarks**. These are excellent for comparison and serve as a **more directly competitive baseline** than Allosaurus, especially since:\n",
    "\n",
    "* They use the **same architecture** (wav2vec 2.0)\n",
    "* Include **Swedish** among supported languages (via Common Voice or VoxPopuli)\n",
    "* Are trained to predict phoneme sequences â€” either via fine-tuning or CTC\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”Ž Likely Reference Models\n",
    "\n",
    "### 1. **XLSR-53**\n",
    "\n",
    "* Trained on 53 languages\n",
    "* Often used in downstream phoneme or ASR fine-tuning\n",
    "* Common checkpoints: `xlsr_53_56k.pt`, `xlsr_53_100k.pt`\n",
    "* Phoneme labels typically derived from forced alignment (e.g., BABEL, CV)\n",
    "\n",
    "### 2. **SUPERB Benchmarks**\n",
    "\n",
    "* Many phoneme recognition results use multilingual wav2vec2 backbones\n",
    "* Common format: fine-tune for framewise phoneme prediction or CTC\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Why This Is a Good Baseline\n",
    "\n",
    "| Your Model                     | XLSR-Based Baseline                    |\n",
    "| ------------------------------ | -------------------------------------- |\n",
    "| Trained on Waxholm (Swedish)   | Trained on multilingual data           |\n",
    "| Outputs phonetic words         | Outputs flat phoneme sequence          |\n",
    "| Designed for dialect variation | Not dialect-aware or language-specific |\n",
    "| Integrated into full lexicon   | Standalone recognizer                  |\n",
    "\n",
    "> Comparing to XLSR-style phoneme models gives you a **head-to-head**: same architecture, different training strategy.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§ª How to Use for Comparison\n",
    "\n",
    "### 1. **Download a model checkpoint**\n",
    "\n",
    "If using Fairseq:\n",
    "\n",
    "```bash\n",
    "wget https://dl.fbaipublicfiles.com/fairseq/wav2vec/xlsr_53_56k.pt\n",
    "```\n",
    "\n",
    "### 2. **Fine-tune it on your phoneme data (optional)**\n",
    "\n",
    "Or evaluate as-is if it's a usable phoneme decoder (some require downstream finetuning).\n",
    "\n",
    "### 3. **Use consistent decoding**\n",
    "\n",
    "* Apply same phoneme decoding / CTC decoder as you do for your model\n",
    "* Evaluate:\n",
    "\n",
    "  * PER\n",
    "  * Segment-level accuracy\n",
    "  * Prosodic or dialectal coverage\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“Š Suggested Comparison Table\n",
    "\n",
    "| Model            | PER (%) | Phonetic Word Match | Notes                         |\n",
    "| ---------------- | ------- | ------------------- | ----------------------------- |\n",
    "| Your model       | 21.3    | 72.5%               | Swedish, word-segmented       |\n",
    "| XLSR-53 baseline | 30.2    | 58.7%               | Multilingual, no segmentation |\n",
    "| Allosaurus       | 34.7    | 52.1%               | Symbol set mismatch           |\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Action Steps\n",
    "\n",
    "| Task                                      | Time Estimate | Description                    |\n",
    "| ----------------------------------------- | ------------- | ------------------------------ |\n",
    "| \\[ ] Download XLSR checkpoint             | 5 min         | From Fairseq or HuggingFace    |\n",
    "| \\[ ] Run inference on test audio          | 30 min        | Via Fairseq or direct script   |\n",
    "| \\[ ] Align output with phonetic reference | 30 min        | Match to phonetic words or IPA |\n",
    "| \\[ ] Evaluate                             | 30 min        | Compute PER, analyze errors    |\n",
    "\n",
    "---\n",
    "\n",
    "Would you like:\n",
    "\n",
    "* A minimal evaluation script for `xlsr_53_56k.pt` in Fairseq?\n",
    "* Help decoding its output into phones (and mapping to your IPA set)?\n",
    "* A suggestion on how to handle dialectal forms it might miss?\n",
    "\n",
    "Let me know how deep you want to go with this comparison.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f46d2fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
