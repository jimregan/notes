(1) X
https://twitter.com/ChristophMolnar/status/1745731602682982675?t=LHKlCc79AHUE94jlWGyfHw&s=09

what_are_embeddings/notebooks/fig_4_bert.ipynb at main ¬∑ veekaybee/what_are_embeddings
https://github.com/veekaybee/what_are_embeddings/blob/main/notebooks/fig_4_bert.ipynb

BetterExplained ‚Äì Math lessons that click
https://betterexplained.com/

roboflow/supervision: We write your reusable computer vision tools. üíú
https://github.com/roboflow/supervision

Code LoRA from Scratch
https://lightning.ai/lightning-ai/studios/code-lora-from-scratch?view=public&section=all

text_search/examples/libriheavy at master ¬∑ k2-fsa/text_search
https://github.com/k2-fsa/text_search/tree/master/examples/libriheavy

MambaByte/mambabyte/model.py at main ¬∑ kyegomez/MambaByte
https://github.com/kyegomez/MambaByte/blob/main/mambabyte/model.py

hustvl/Vim: Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model
https://github.com/hustvl/Vim

makeMoE: Implement a Sparse Mixture of Experts Language Model from Scratch
https://huggingface.co/blog/AviSoori1x/makemoe-from-scratch

[2305.19435] AdANNS: A Framework for Adaptive Semantic Search
https://arxiv.org/abs/2305.19435

2211.09949.pdf
https://arxiv.org/pdf/2211.09949.pdf

[2401.16658] OWSM v3.1: Better and Faster Open Whisper-Style Speech Models based on E-Branchformer
https://arxiv.org/abs/2401.16658

A complete practical grammar of the Hungarian language; with exercises, selections from the best authors, and vocabularies, to which is added a Historical sketch of Hungarian literature by J Csink - PDF Drive
https://www.pdfdrive.com/a-complete-practical-grammar-of-the-hungarian-language-with-exercises-selections-from-the-best-authors-and-vocabularies-to-which-is-added-a-historical-sketch-of-hungarian-literature-d157292500.html

[2402.00282] PAM: Prompting Audio-Language Models for Audio Quality Assessment
https://arxiv.org/abs/2402.00282

[2401.18059] RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval
https://arxiv.org/abs/2401.18059

Lesson - Mondly
https://app.mondly.com/home/5/lessons/505

OWSM v3.1: Better and Faster Open Whisper-Style Speech Models based on E-Branchformer
https://arxiv.org/html/2401.16658v1

Audio Flamingo: A Novel Audio Language Model with Few-Shot Learning and Dialogue Abilities
https://arxiv.org/pdf/2402.01831.pdf

CLAP/msclap/models/mapper.py at main ¬∑ microsoft/CLAP
https://github.com/microsoft/CLAP/blob/main/msclap/models/mapper.py

Commits ¬∑ NVIDIA/NeMo
https://github.com/NVIDIA/NeMo/commits/main/?after=9940ec60058f644662809a6787ba1b7c464567ad+34

Replace CLIP Image Encoder with LanguageBind Image Encoder [Video-NeVA] by PannuMuthu ¬∑ Pull Request #8300 ¬∑ NVIDIA/NeMo
https://github.com/NVIDIA/NeMo/pull/8300/commits/a3d9cc7198962780cb7922fd733802a3507e3ad9#diff-07b087ee21d99449fa5be968321007e0bfe109f0a97f5420d0b34b430dcc88fb

enable nmt to use beam search by mengruwNv ¬∑ Pull Request #8287 ¬∑ NVIDIA/NeMo
https://github.com/NVIDIA/NeMo/pull/8287

Attention encoder-decoder models for multiple speech-to-text tasks ‚Ä¶ ¬∑ NVIDIA/NeMo@d10726d
https://github.com/NVIDIA/NeMo/commit/d10726da72f74eb5a95056843d1f9e2562a5051c

Pin lhotse version to 1.19.2 (#8291) ¬∑ NVIDIA/NeMo@f6e6485
https://github.com/NVIDIA/NeMo/commit/f6e64859174920e6a7fb26c4308cbe4c1d44206e

Mixtral to NeMo conversion script. (#8155) ¬∑ NVIDIA/NeMo@13c1db4
https://github.com/NVIDIA/NeMo/commit/13c1db4ffdaa3b2125ce6e66c93509a39d55b2cf

switch to mcore dataset [with FIM support] (#8149) ¬∑ NVIDIA/NeMo@a93589d
https://github.com/NVIDIA/NeMo/commit/a93589d80472bfbf949b0e65758b106eeaa7ac80

NeMo/nemo/collections/common/data/dataset.py at 2c2c3ccde2f1269a0e30f9b54dac0b0d569bae51 ¬∑ NVIDIA/NeMo
https://github.com/NVIDIA/NeMo/blob/2c2c3ccde2f1269a0e30f9b54dac0b0d569bae51/nemo/collections/common/data/dataset.py

lhotse/lhotse/recipes/switchboard.py at master ¬∑ lhotse-speech/lhotse
https://github.com/lhotse-speech/lhotse/blob/master/lhotse/recipes/switchboard.py

lhotse/lhotse/recipes/timit.py at master ¬∑ lhotse-speech/lhotse
https://github.com/lhotse-speech/lhotse/blob/master/lhotse/recipes/timit.py

lhotse/lhotse/recipes/nsc.py at master ¬∑ lhotse-speech/lhotse
https://github.com/lhotse-speech/lhotse/blob/master/lhotse/recipes/nsc.py

lhotse/lhotse/recipes/mls.py at master ¬∑ lhotse-speech/lhotse
https://github.com/lhotse-speech/lhotse/blob/master/lhotse/recipes/mls.py

lhotse/lhotse/recipes/dipco.py at master ¬∑ lhotse-speech/lhotse
https://github.com/lhotse-speech/lhotse/blob/master/lhotse/recipes/dipco.py

Course information for doctoral students | EECS internal pages
https://intra.kth.se/en/eecs/forskarutbildning/courses

NY FO-TRAK
https://intra.kth.se/polopoly_fs/1.1298221.1700743075!/FO-TRAK%20EECS.pdf

NVIDIA GPU Compute Test Suite Collection - OpenBenchmarking.org
https://openbenchmarking.org/suite/pts/nvidia-gpu-compute

Interspeech thing for ParlaCLARIN - Online LaTeX Editor Overleaf
https://www.overleaf.com/project/65b12a434befd9098dbef6a9

ParlaCLARIN IV Workshop on Creating, Analysing, and Increasing Accessibility of Parliamentary Corpora | CLARIN ERIC
https://www.clarin.eu/ParlaCLARIN-IV

SIGUL 2024 - SIGUL
https://www.sigul.eu/event/sigul-2024/

SIGUL-2024_Call-for-Papers.pdf
https://sigul-2024.ilc.cnr.it/wp-content/uploads/2023/12/SIGUL-2024_Call-for-Papers.pdf

Call For Papers ‚Äì Interspeech 2024
https://interspeech2024.org/call-for-papers/

Phonological rules ‚Äî Montreal Forced Aligner 3.0.0 documentation
https://montreal-forced-aligner.readthedocs.io/en/latest/user_guide/implementations/phonological_rules.html

Large-Scale Contrastive Language-Audio Pretraining with Feature Fusion and Keyword-to-Caption Augmentation | IEEE Conference Publication | IEEE Xplore
https://ieeexplore.ieee.org/document/10095969

Text-to-audio retrieval via large-scale contrastive learning - Google Search
https://www.google.com/search?q=Text-to-audio+retrieval+via+large-scale+contrastive+learning&rlz=1C5GCEM_enSE990SE991&sourceid=chrome&ie=UTF-8

CLAP/src/laion_clap/clap_module/pann_model.py at main ¬∑ LAION-AI/CLAP
https://github.com/LAION-AI/CLAP/blob/main/src/laion_clap/clap_module/pann_model.py

Large-scale Contrastive Language-Audio Petraining
https://retrocirce.github.io/appendix/

audioset_tagging_cnn/scripts/0_inference.sh at master ¬∑ qiuqiangkong/audioset_tagging_cnn
https://github.com/qiuqiangkong/audioset_tagging_cnn/blob/master/scripts/0_inference.sh

(1) Philipp Schmid on X: "Can a 2B LLM outperform Mistral 7B or Llama 13B? Creators of the popular Ultrafeedback dataset released MiniCPM, a 2.4B parameter model claiming performance close to Mistral 7B, Llama 2 13B, or Falcon 40B. ü§Øü§î As part of the release, the researchers released a detailed‚Ä¶" / X
https://twitter.com/_philschmid/status/1755268463457657263

MiniCPM: Unveiling the Potential of End-side Large Language Models
https://shengdinghu.notion.site/MiniCPM-Unveiling-the-Potential-of-End-side-Large-Language-Models-d4d3a8c426424654a4e80e42a711cb20

OpenBMB/MiniCPM: MiniCPM-2B: An end-side LLM outperforms Llama2-13B.
https://github.com/OpenBMB/MiniCPM

General-Model-License/ÈÄöÁî®Ê®°ÂûãËÆ∏ÂèØÂçèËÆÆ-Êù•Ê∫êËØ¥Êòé-ÂÆ£‰º†ÈôêÂà∂-ÂïÜ‰∏öÊéàÊùÉ.md at main ¬∑ OpenBMB/General-Model-License
https://github.com/OpenBMB/General-Model-License/blob/main/%E9%80%9A%E7%94%A8%E6%A8%A1%E5%9E%8B%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE-%E6%9D%A5%E6%BA%90%E8%AF%B4%E6%98%8E-%E5%AE%A3%E4%BC%A0%E9%99%90%E5%88%B6-%E5%95%86%E4%B8%9A%E6%8E%88%E6%9D%83.md

[2402.03944] IMUSIC: IMU-based Facial Expression Capture
https://arxiv.org/abs/2402.03944

state-spaces/mamba
https://github.com/state-spaces/mamba?tab=readme-ov-file

state-spaces/s4: Structured state space sequence models
https://github.com/state-spaces/s4?tab=readme-ov-file

s4/src/dataloaders at main ¬∑ state-spaces/s4
https://github.com/state-spaces/s4/tree/main/src/dataloaders

(1) Cory Doctorow @pluralistic@mamot.fr on X: "There's a strain of anti-anti-monopolist that insists that they're not *pro*-monopoly - they're just *realists* who understand that global gigacorporations are too big to fail, too big to jail, and that governments can't hope to rein them in. 1/ https://t.co/nx0lM4lKWu" / X
https://twitter.com/doctorow/status/1754999901073903739

Duty-free shop - Wikipedia
https://en.wikipedia.org/wiki/Duty-free_shop#1947%E2%80%931990:_duty_free_establishment

System prompt - Pastebin.com
https://pastebin.com/vnxJ7kQk

metavoiceio/metavoice-1B-v0.1 ¬∑ Hugging Face
https://huggingface.co/metavoiceio/metavoice-1B-v0.1

huggingface.co
https://huggingface.co/spaces/mrfakename/MetaVoice-1B-v0.1/blob/main/app.py

metavoiceio/metavoice-src: AI for human-level speech intelligence
https://github.com/metavoiceio/metavoice-src

metavoice-src/fam/llm/model.py at main ¬∑ metavoiceio/metavoice-src
https://github.com/metavoiceio/metavoice-src/blob/main/fam/llm/model.py

neonbjb/tortoise-tts: A multi-voice TTS system trained with an emphasis on quality
https://github.com/neonbjb/tortoise-tts

TTS by MetaVoice
https://ttsdemo.themetavoice.xyz/

(1) LangChain on X: "RAG From Scratch: Video series focused on understanding the RAG landscape RAG is central for LLM application development, connecting LLMs to external data sources. But, the pace of innovation and new approaches makes it challenging to keep up. We're launching a new video‚Ä¶ https://t.co/963lOnVLcP" / X
https://twitter.com/LangChainAI/status/1754915914796216654

RAG From Scratch: Part 1 (Overview) - YouTube
https://www.youtube.com/watch?v=wd7TZ4w1mSw

rag-from-scratch/rag_from_scratch_1_to_4.ipynb at main ¬∑ langchain-ai/rag-from-scratch
https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_1_to_4.ipynb

whisperX/whisperx/alignment.py at main ¬∑ m-bain/whisperX
https://github.com/m-bain/whisperX/blob/main/whisperx/alignment.py

whisper/data at main ¬∑ openai/whisper
https://github.com/openai/whisper/tree/main/data

whisper v3 - Google Search
https://www.google.com/search?q=whisper+v3&rlz=1C5GCEM_enSE990SE991&oq=whisper+v3&gs_lcrp=EgZjaHJvbWUyCQgAEEUYORiABDIHCAEQABiABDIHCAIQABiABDIHCAMQABiABDIHCAQQABiABDIHCAUQABiABDIGCAYQRRg9MgYIBxBFGD3SAQgzNzQzajBqN6gCALACAA&sourceid=chrome&ie=UTF-8

openai/whisper-large-v3 ¬∑ Hugging Face
https://huggingface.co/openai/whisper-large-v3

Ego-Exo4D
https://ego-exo4d-data.org/?utm_source=twitter&utm_medium=organic_social&utm_campaign=fair10&utm_content=video

Efficient Linear Model Merging for LLMs
https://lightning.ai/lightning-ai/studios/efficient-linear-model-merging-for-llms

Fast Timing-Conditioned Latent Audio Diffusion
https://arxiv.org/pdf/2402.04825.pdf

Stability-AI/stable-audio-tools: Generative models for conditional audio generation
https://github.com/Stability-AI/stable-audio-tools

(1) Home / X
https://twitter.com/home

[2309.08030] AV2Wav: Diffusion-Based Re-synthesis from Continuous Self-supervised Features for Audio-Visual Speech Enhancement
https://arxiv.org/abs/2309.08030

2309.08030.pdf
https://arxiv.org/pdf/2309.08030.pdf

nvidia/canary-1b ¬∑ Hugging Face
https://huggingface.co/nvidia/canary-1b

Meta Research
https://github.com/orgs/facebookresearch/repositories

facebookresearch/Pearl: A Production-ready Reinforcement Learning AI Agent Library brought by the Applied Reinforcement Learning team at Meta.
https://github.com/facebookresearch/Pearl?tab=readme-ov-file

Pearl/pearl/policy_learners/sequential_decision_making/deep_q_learning.py at main ¬∑ facebookresearch/Pearl
https://github.com/facebookresearch/Pearl/blob/main/pearl/policy_learners/sequential_decision_making/deep_q_learning.py

Pearl/pearl at main ¬∑ facebookresearch/Pearl
https://github.com/facebookresearch/Pearl/tree/main/pearl

facebookresearch/ConvNeXt-V2: Code release for ConvNeXt V2 model
https://github.com/facebookresearch/ConvNeXt-V2

facebookresearch/projectaria_tools: projectaria_tools is an C++/Python open-source toolkit to interact with Project Aria data
https://github.com/facebookresearch/projectaria_tools

facebookresearch/ConvNeXt-V2: Code release for ConvNeXt V2 model
https://github.com/facebookresearch/ConvNeXt-V2

facebookresearch/d2go: D2Go is a toolkit for efficient deep learning
https://github.com/facebookresearch/d2go

xformers/xformers/components/positional_embedding/sine.py at main ¬∑ facebookresearch/xformers
https://github.com/facebookresearch/xformers/blob/main/xformers/components/positional_embedding/sine.py

Commits ¬∑ facebookresearch/fairseq
https://github.com/facebookresearch/fairseq/commits/main/

fairseq/examples/mms at 3f0f20f2d12403629224347664b3e75c13b2c8e0 ¬∑ facebookresearch/fairseq
https://github.com/facebookresearch/fairseq/tree/3f0f20f2d12403629224347664b3e75c13b2c8e0/examples/mms

Fine-Tune MMS Adapter Models for low-resource ASR
https://huggingface.co/blog/mms_adapters

Update MMS README.md (#5202) ¬∑ facebookresearch/fairseq@91c364b
https://github.com/facebookresearch/fairseq/commit/91c364b7ceef8032099363cb10ba19a85b050c1c

MMS TTS Colab Notebook (#5165) ¬∑ facebookresearch/fairseq@ae59bd6
https://github.com/facebookresearch/fairseq/commit/ae59bd6d04871f6174351ad46c90992e1dca7ac7

[MMS] Add a tutorial on CC LM decoding for ASR model (#5160) ¬∑ facebookresearch/fairseq@35641fb
https://github.com/facebookresearch/fairseq/commit/35641fb41e5e7bd49e48df37e8aab2fbac673012

vumichien/AV-HuBERT ¬∑ Hugging Face
https://huggingface.co/vumichien/AV-HuBERT

facebook/mms-1b-fl102 ¬∑ Hugging Face
https://huggingface.co/facebook/mms-1b-fl102#supported-languages

(2) Home / X
https://twitter.com/home


