Christoph Molnar on X: "I just found a great introduction to embedding. The book is comprehensive yet short. Historical encoding tools, neural nets, and production - all covered. Fantastic job by @vboykis. Thanks for making it free to read! Looking forward to diving in. https://t.co/uFwaSjaysn https://t.co/SKl2ExOJaw" / X
https://twitter.com/ChristophMolnar/status/1745731602682982675?t=LHKlCc79AHUE94jlWGyfHw&s=09

what_are_embeddings/notebooks/fig_4_bert.ipynb at main ¬∑ veekaybee/what_are_embeddings
https://github.com/veekaybee/what_are_embeddings/blob/main/notebooks/fig_4_bert.ipynb

BetterExplained ‚Äì Math lessons that click
https://betterexplained.com/

roboflow/supervision: We write your reusable computer vision tools. üíú
https://github.com/roboflow/supervision

Code LoRA from Scratch
https://lightning.ai/lightning-ai/studios/code-lora-from-scratch?view=public&section=all

text_search/examples/libriheavy at master ¬∑ k2-fsa/text_search
https://github.com/k2-fsa/text_search/tree/master/examples/libriheavy

MambaByte/mambabyte/model.py at main ¬∑ kyegomez/MambaByte
https://github.com/kyegomez/MambaByte/blob/main/mambabyte/model.py

hustvl/Vim: Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model
https://github.com/hustvl/Vim

makeMoE: Implement a Sparse Mixture of Experts Language Model from Scratch
https://huggingface.co/blog/AviSoori1x/makemoe-from-scratch

[2305.19435] AdANNS: A Framework for Adaptive Semantic Search
https://arxiv.org/abs/2305.19435

2211.09949.pdf
https://arxiv.org/pdf/2211.09949.pdf

[2401.16658] OWSM v3.1: Better and Faster Open Whisper-Style Speech Models based on E-Branchformer
https://arxiv.org/abs/2401.16658

A complete practical grammar of the Hungarian language; with exercises, selections from the best authors, and vocabularies, to which is added a Historical sketch of Hungarian literature by J Csink - PDF Drive
https://www.pdfdrive.com/a-complete-practical-grammar-of-the-hungarian-language-with-exercises-selections-from-the-best-authors-and-vocabularies-to-which-is-added-a-historical-sketch-of-hungarian-literature-d157292500.html

[2402.00282] PAM: Prompting Audio-Language Models for Audio Quality Assessment
https://arxiv.org/abs/2402.00282

[2401.18059] RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval
https://arxiv.org/abs/2401.18059

Lesson - Mondly
https://app.mondly.com/home/5/lessons/505

OWSM v3.1: Better and Faster Open Whisper-Style Speech Models based on E-Branchformer
https://arxiv.org/html/2401.16658v1

Audio Flamingo: A Novel Audio Language Model with Few-Shot Learning and Dialogue Abilities
https://arxiv.org/pdf/2402.01831.pdf

CLAP/msclap/models/mapper.py at main ¬∑ microsoft/CLAP
https://github.com/microsoft/CLAP/blob/main/msclap/models/mapper.py

Commits ¬∑ NVIDIA/NeMo
https://github.com/NVIDIA/NeMo/commits/main/?after=9940ec60058f644662809a6787ba1b7c464567ad+34

Replace CLIP Image Encoder with LanguageBind Image Encoder [Video-NeVA] by PannuMuthu ¬∑ Pull Request #8300 ¬∑ NVIDIA/NeMo
https://github.com/NVIDIA/NeMo/pull/8300/commits/a3d9cc7198962780cb7922fd733802a3507e3ad9#diff-07b087ee21d99449fa5be968321007e0bfe109f0a97f5420d0b34b430dcc88fb

enable nmt to use beam search by mengruwNv ¬∑ Pull Request #8287 ¬∑ NVIDIA/NeMo
https://github.com/NVIDIA/NeMo/pull/8287

Attention encoder-decoder models for multiple speech-to-text tasks ‚Ä¶ ¬∑ NVIDIA/NeMo@d10726d
https://github.com/NVIDIA/NeMo/commit/d10726da72f74eb5a95056843d1f9e2562a5051c

Pin lhotse version to 1.19.2 (#8291) ¬∑ NVIDIA/NeMo@f6e6485
https://github.com/NVIDIA/NeMo/commit/f6e64859174920e6a7fb26c4308cbe4c1d44206e

Mixtral to NeMo conversion script. (#8155) ¬∑ NVIDIA/NeMo@13c1db4
https://github.com/NVIDIA/NeMo/commit/13c1db4ffdaa3b2125ce6e66c93509a39d55b2cf

switch to mcore dataset [with FIM support] (#8149) ¬∑ NVIDIA/NeMo@a93589d
https://github.com/NVIDIA/NeMo/commit/a93589d80472bfbf949b0e65758b106eeaa7ac80

NeMo/nemo/collections/common/data/dataset.py at 2c2c3ccde2f1269a0e30f9b54dac0b0d569bae51 ¬∑ NVIDIA/NeMo
https://github.com/NVIDIA/NeMo/blob/2c2c3ccde2f1269a0e30f9b54dac0b0d569bae51/nemo/collections/common/data/dataset.py

lhotse/lhotse/recipes/switchboard.py at master ¬∑ lhotse-speech/lhotse
https://github.com/lhotse-speech/lhotse/blob/master/lhotse/recipes/switchboard.py

lhotse/lhotse/recipes/timit.py at master ¬∑ lhotse-speech/lhotse
https://github.com/lhotse-speech/lhotse/blob/master/lhotse/recipes/timit.py

lhotse/lhotse/recipes/nsc.py at master ¬∑ lhotse-speech/lhotse
https://github.com/lhotse-speech/lhotse/blob/master/lhotse/recipes/nsc.py

lhotse/lhotse/recipes/mls.py at master ¬∑ lhotse-speech/lhotse
https://github.com/lhotse-speech/lhotse/blob/master/lhotse/recipes/mls.py

lhotse/lhotse/recipes/dipco.py at master ¬∑ lhotse-speech/lhotse
https://github.com/lhotse-speech/lhotse/blob/master/lhotse/recipes/dipco.py

Course information for doctoral students | EECS internal pages
https://intra.kth.se/en/eecs/forskarutbildning/courses

NY FO-TRAK
https://intra.kth.se/polopoly_fs/1.1298221.1700743075!/FO-TRAK%20EECS.pdf

NVIDIA GPU Compute Test Suite Collection - OpenBenchmarking.org
https://openbenchmarking.org/suite/pts/nvidia-gpu-compute

Interspeech thing for ParlaCLARIN - Online LaTeX Editor Overleaf
https://www.overleaf.com/project/65b12a434befd9098dbef6a9

ParlaCLARIN IV Workshop on Creating, Analysing, and Increasing Accessibility of Parliamentary Corpora | CLARIN ERIC
https://www.clarin.eu/ParlaCLARIN-IV

SIGUL 2024 - SIGUL
https://www.sigul.eu/event/sigul-2024/

SIGUL-2024_Call-for-Papers.pdf
https://sigul-2024.ilc.cnr.it/wp-content/uploads/2023/12/SIGUL-2024_Call-for-Papers.pdf

Call For Papers ‚Äì Interspeech 2024
https://interspeech2024.org/call-for-papers/

Phonological rules ‚Äî Montreal Forced Aligner 3.0.0 documentation
https://montreal-forced-aligner.readthedocs.io/en/latest/user_guide/implementations/phonological_rules.html

Large-Scale Contrastive Language-Audio Pretraining with Feature Fusion and Keyword-to-Caption Augmentation | IEEE Conference Publication | IEEE Xplore
https://ieeexplore.ieee.org/document/10095969

Text-to-audio retrieval via large-scale contrastive learning - Google Search
https://www.google.com/search?q=Text-to-audio+retrieval+via+large-scale+contrastive+learning&rlz=1C5GCEM_enSE990SE991&sourceid=chrome&ie=UTF-8

CLAP/src/laion_clap/clap_module/pann_model.py at main ¬∑ LAION-AI/CLAP
https://github.com/LAION-AI/CLAP/blob/main/src/laion_clap/clap_module/pann_model.py

Large-scale Contrastive Language-Audio Petraining
https://retrocirce.github.io/appendix/

audioset_tagging_cnn/scripts/0_inference.sh at master ¬∑ qiuqiangkong/audioset_tagging_cnn
https://github.com/qiuqiangkong/audioset_tagging_cnn/blob/master/scripts/0_inference.sh

(1) Philipp Schmid on X: "Can a 2B LLM outperform Mistral 7B or Llama 13B? Creators of the popular Ultrafeedback dataset released MiniCPM, a 2.4B parameter model claiming performance close to Mistral 7B, Llama 2 13B, or Falcon 40B. ü§Øü§î As part of the release, the researchers released a detailed‚Ä¶" / X
https://twitter.com/_philschmid/status/1755268463457657263

MiniCPM: Unveiling the Potential of End-side Large Language Models
https://shengdinghu.notion.site/MiniCPM-Unveiling-the-Potential-of-End-side-Large-Language-Models-d4d3a8c426424654a4e80e42a711cb20

OpenBMB/MiniCPM: MiniCPM-2B: An end-side LLM outperforms Llama2-13B.
https://github.com/OpenBMB/MiniCPM

General-Model-License/ÈÄöÁî®Ê®°ÂûãËÆ∏ÂèØÂçèËÆÆ-Êù•Ê∫êËØ¥Êòé-ÂÆ£‰º†ÈôêÂà∂-ÂïÜ‰∏öÊéàÊùÉ.md at main ¬∑ OpenBMB/General-Model-License
https://github.com/OpenBMB/General-Model-License/blob/main/%E9%80%9A%E7%94%A8%E6%A8%A1%E5%9E%8B%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE-%E6%9D%A5%E6%BA%90%E8%AF%B4%E6%98%8E-%E5%AE%A3%E4%BC%A0%E9%99%90%E5%88%B6-%E5%95%86%E4%B8%9A%E6%8E%88%E6%9D%83.md

[2402.03944] IMUSIC: IMU-based Facial Expression Capture
https://arxiv.org/abs/2402.03944

state-spaces/mamba
https://github.com/state-spaces/mamba?tab=readme-ov-file

state-spaces/s4: Structured state space sequence models
https://github.com/state-spaces/s4?tab=readme-ov-file

s4/src/dataloaders at main ¬∑ state-spaces/s4
https://github.com/state-spaces/s4/tree/main/src/dataloaders

(1) Cory Doctorow @pluralistic@mamot.fr on X: "There's a strain of anti-anti-monopolist that insists that they're not *pro*-monopoly - they're just *realists* who understand that global gigacorporations are too big to fail, too big to jail, and that governments can't hope to rein them in. 1/ https://t.co/nx0lM4lKWu" / X
https://twitter.com/doctorow/status/1754999901073903739

Duty-free shop - Wikipedia
https://en.wikipedia.org/wiki/Duty-free_shop#1947%E2%80%931990:_duty_free_establishment

System prompt - Pastebin.com
https://pastebin.com/vnxJ7kQk

metavoiceio/metavoice-1B-v0.1 ¬∑ Hugging Face
https://huggingface.co/metavoiceio/metavoice-1B-v0.1

huggingface.co
https://huggingface.co/spaces/mrfakename/MetaVoice-1B-v0.1/blob/main/app.py

metavoiceio/metavoice-src: AI for human-level speech intelligence
https://github.com/metavoiceio/metavoice-src

metavoice-src/fam/llm/model.py at main ¬∑ metavoiceio/metavoice-src
https://github.com/metavoiceio/metavoice-src/blob/main/fam/llm/model.py

neonbjb/tortoise-tts: A multi-voice TTS system trained with an emphasis on quality
https://github.com/neonbjb/tortoise-tts

TTS by MetaVoice
https://ttsdemo.themetavoice.xyz/

(1) LangChain on X: "RAG From Scratch: Video series focused on understanding the RAG landscape RAG is central for LLM application development, connecting LLMs to external data sources. But, the pace of innovation and new approaches makes it challenging to keep up. We're launching a new video‚Ä¶ https://t.co/963lOnVLcP" / X
https://twitter.com/LangChainAI/status/1754915914796216654

RAG From Scratch: Part 1 (Overview) - YouTube
https://www.youtube.com/watch?v=wd7TZ4w1mSw

rag-from-scratch/rag_from_scratch_1_to_4.ipynb at main ¬∑ langchain-ai/rag-from-scratch
https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_1_to_4.ipynb

whisperX/whisperx/alignment.py at main ¬∑ m-bain/whisperX
https://github.com/m-bain/whisperX/blob/main/whisperx/alignment.py

whisper/data at main ¬∑ openai/whisper
https://github.com/openai/whisper/tree/main/data

whisper v3 - Google Search
https://www.google.com/search?q=whisper+v3&rlz=1C5GCEM_enSE990SE991&oq=whisper+v3&gs_lcrp=EgZjaHJvbWUyCQgAEEUYORiABDIHCAEQABiABDIHCAIQABiABDIHCAMQABiABDIHCAQQABiABDIHCAUQABiABDIGCAYQRRg9MgYIBxBFGD3SAQgzNzQzajBqN6gCALACAA&sourceid=chrome&ie=UTF-8

openai/whisper-large-v3 ¬∑ Hugging Face
https://huggingface.co/openai/whisper-large-v3

Ego-Exo4D
https://ego-exo4d-data.org/?utm_source=twitter&utm_medium=organic_social&utm_campaign=fair10&utm_content=video

Efficient Linear Model Merging for LLMs
https://lightning.ai/lightning-ai/studios/efficient-linear-model-merging-for-llms

Fast Timing-Conditioned Latent Audio Diffusion
https://arxiv.org/pdf/2402.04825.pdf

Stability-AI/stable-audio-tools: Generative models for conditional audio generation
https://github.com/Stability-AI/stable-audio-tools

Home / X
https://twitter.com/home

2312.04533.pdf
https://arxiv.org/pdf/2312.04533.pdf

Dream2Real: Zero-Shot 3D Object Rearrangement with Vision-Language Models
https://www.robot-learning.uk/dream2real

nvidia/canary-1b ¬∑ Hugging Face
https://huggingface.co/nvidia/canary-1b

Pull requests ¬∑ NVIDIA/NeMo
https://github.com/NVIDIA/NeMo/pulls

Attention encoder-decoder models for multiple speech-to-text tasks ‚Ä¶ ¬∑ NVIDIA/NeMo@d10726d
https://github.com/NVIDIA/NeMo/commit/d10726da72f74eb5a95056843d1f9e2562a5051c#diff-17e7ee0546f6ee8af2cee82466fcb96a72f5a80c24939d2c008e0d82ef7fad4c

Mixtral to NeMo conversion script. (#8155) ¬∑ NVIDIA/NeMo@13c1db4
https://github.com/NVIDIA/NeMo/commit/13c1db4ffdaa3b2125ce6e66c93509a39d55b2cf

Pull requests ¬∑ NVIDIA/NeMo
https://github.com/NVIDIA/NeMo/pulls

Update MM Dataprep Tutorial by cuichenx ¬∑ Pull Request #8373 ¬∑ NVIDIA/NeMo
https://github.com/NVIDIA/NeMo/pull/8373/files

TTS SpeechLLM models by blisc ¬∑ Pull Request #8364 ¬∑ NVIDIA/NeMo
https://github.com/NVIDIA/NeMo/pull/8364

TTS SpeechLLM models by blisc ¬∑ Pull Request #8364 ¬∑ NVIDIA/NeMo
https://github.com/NVIDIA/NeMo/pull/8364/files#diff-18b3a37d06f50d34d9fed38c1b7235ee17b124fe098f9fe55119a9b8e1eb3d4d

Irish TN by jimregan ¬∑ Pull Request #71 ¬∑ NVIDIA/NeMo-text-processing
https://github.com/NVIDIA/NeMo-text-processing/pull/71#issuecomment-1920340902

Meta Research
https://github.com/orgs/facebookresearch/repositories

facebookresearch/Pearl: A Production-ready Reinforcement Learning AI Agent Library brought by the Applied Reinforcement Learning team at Meta.
https://github.com/facebookresearch/Pearl?tab=readme-ov-file

Pearl/pearl/policy_learners/sequential_decision_making/deep_q_learning.py at main ¬∑ facebookresearch/Pearl
https://github.com/facebookresearch/Pearl/blob/main/pearl/policy_learners/sequential_decision_making/deep_q_learning.py

Pearl/pearl at main ¬∑ facebookresearch/Pearl
https://github.com/facebookresearch/Pearl/tree/main/pearl

facebookresearch/ConvNeXt-V2: Code release for ConvNeXt V2 model
https://github.com/facebookresearch/ConvNeXt-V2

facebookresearch/projectaria_tools: projectaria_tools is an C++/Python open-source toolkit to interact with Project Aria data
https://github.com/facebookresearch/projectaria_tools

facebookresearch/ConvNeXt-V2: Code release for ConvNeXt V2 model
https://github.com/facebookresearch/ConvNeXt-V2

facebookresearch/d2go: D2Go is a toolkit for efficient deep learning
https://github.com/facebookresearch/d2go

xformers/xformers/components/positional_embedding/sine.py at main ¬∑ facebookresearch/xformers
https://github.com/facebookresearch/xformers/blob/main/xformers/components/positional_embedding/sine.py

Commits ¬∑ facebookresearch/fairseq
https://github.com/facebookresearch/fairseq/commits/main/

fairseq/examples/mms at 3f0f20f2d12403629224347664b3e75c13b2c8e0 ¬∑ facebookresearch/fairseq
https://github.com/facebookresearch/fairseq/tree/3f0f20f2d12403629224347664b3e75c13b2c8e0/examples/mms

Fine-Tune MMS Adapter Models for low-resource ASR
https://huggingface.co/blog/mms_adapters

Update MMS README.md (#5202) ¬∑ facebookresearch/fairseq@91c364b
https://github.com/facebookresearch/fairseq/commit/91c364b7ceef8032099363cb10ba19a85b050c1c

MMS TTS Colab Notebook (#5165) ¬∑ facebookresearch/fairseq@ae59bd6
https://github.com/facebookresearch/fairseq/commit/ae59bd6d04871f6174351ad46c90992e1dca7ac7

[MMS] Add a tutorial on CC LM decoding for ASR model (#5160) ¬∑ facebookresearch/fairseq@35641fb
https://github.com/facebookresearch/fairseq/commit/35641fb41e5e7bd49e48df37e8aab2fbac673012

vumichien/AV-HuBERT ¬∑ Hugging Face
https://huggingface.co/vumichien/AV-HuBERT

facebook/mms-1b-fl102 ¬∑ Hugging Face
https://huggingface.co/facebook/mms-1b-fl102#supported-languages

MMS
https://huggingface.co/docs/transformers/model_doc/mms

Dream2Real: Zero-Shot 3D Object Rearrangement with Vision-Language Models
https://www.robot-learning.uk/dream2real

Automatic Speech Recognition (ASR) ‚Äî NVIDIA NeMo
https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/main/asr/intro.html#asr-tutorial-notebooks

NeMo/tutorials/asr/ASR_with_NeMo.ipynb at main ¬∑ NVIDIA/NeMo
https://github.com/NVIDIA/NeMo/blob/main/tutorials/asr/ASR_with_NeMo.ipynb

Datasets ‚Äî NVIDIA NeMo
https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/main/asr/datasets.html#preparing-custom-asr-data

Models ‚Äî NVIDIA NeMo
https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/main/asr/models.html#hybrid-asr-tts-model

2003.07705.pdf
https://arxiv.org/pdf/2003.07705.pdf

NeMo/nemo/collections/asr/modules/rnnt.py at main ¬∑ NVIDIA/NeMo
https://github.com/NVIDIA/NeMo/blob/main/nemo/collections/asr/modules/rnnt.py

Pull requests ¬∑ espnet/espnet
https://github.com/espnet/espnet/pulls

[WIP] Support external dataset library by Masao-Someki ¬∑ Pull Request #5584 ¬∑ espnet/espnet
https://github.com/espnet/espnet/pull/5584/files#diff-d73b19c9038190fcca9e673c1523b18eb579c3b5ed08a802ddf26c347db48edd

Add causal LM for ASR2 by akreal ¬∑ Pull Request #5514 ¬∑ espnet/espnet
https://github.com/espnet/espnet/pull/5514

[WIP] Implement wav2gloss by juice500ml ¬∑ Pull Request #5449 ¬∑ espnet/espnet
https://github.com/espnet/espnet/pull/5449/files#diff-12ce31487cc7e7842d534c8f04eb1fdb34187ffc9a4cc4fa36a0f98549aae5ad

espnet/egs2/googlei18n_lowresource/tts1/conf/tuning/train_gst+xvector_tacotron2.yaml at c9bbf80aa8879dcfebf49304ac2ffb659fb9ca16 ¬∑ espnet/espnet
https://github.com/espnet/espnet/blob/c9bbf80aa8879dcfebf49304ac2ffb659fb9ca16/egs2/googlei18n_lowresource/tts1/conf/tuning/train_gst%2Bxvector_tacotron2.yaml

croissant/python/mlcroissant at main ¬∑ mlcommons/croissant
https://github.com/mlcommons/croissant/tree/main/python/mlcroissant

r-three/phatgoose: Code for PHATGOOSE introduced in "Learning to Route Among Specialized Experts for Zero-Shot Generalization"
https://github.com/r-three/phatgoose

Home / X
https://twitter.com/home

unilm/e5 at master ¬∑ microsoft/unilm
https://github.com/microsoft/unilm/tree/master/e5

microsoft/unilm: Large-scale Self-supervised Pre-training Across Tasks, Languages, and Modalities
https://github.com/microsoft/unilm?tab=readme-ov-file

unilm/infoxlm at master ¬∑ microsoft/unilm
https://github.com/microsoft/unilm/tree/master/infoxlm

vall-e - Google Search
https://www.google.com/search?q=vall-e&rlz=1C5GCEM_enSE990SE991&oq=VALL-E&gs_lcrp=EgZjaHJvbWUqBwgAEAAYgAQyBwgAEAAYgAQyDAgBEAAYQxiABBiKBTIMCAIQABhDGIAEGIoFMgwIAxAAGEMYgAQYigUyDAgEEAAYQxiABBiKBTIGCAUQRRg9MgYIBhBFGDwyBggHEEUYPNIBBzMyNmowajSoAgCwAgA&sourceid=chrome&ie=UTF-8#ip=1

VALL-E download | SourceForge.net
https://sourceforge.net/projects/vall-e.mirror/

vall-e/valle/modules/embedding.py at main ¬∑ lifeiteng/vall-e
https://github.com/lifeiteng/vall-e/blob/main/valle/modules/embedding.py

unilm/wavlm at master ¬∑ microsoft/unilm
https://github.com/microsoft/unilm/tree/master/wavlm

[2402.05755] SpiRit-LM: Interleaved Spoken and Written Language Model
https://arxiv.org/abs/2402.05755

CTC forced alignment API tutorial ‚Äî Torchaudio 2.2.0.dev20240210 documentation
https://pytorch.org/audio/main/tutorials/ctc_forced_alignment_api_tutorial.html

BAAI-DCAI/Bunny: A family of lightweight multimodal models.
https://github.com/BAAI-DCAI/Bunny

Top 5 linguist hacks for language learners - YouTube
https://www.youtube.com/watch?v=KbMSc5btyuA

A bes√∫g√≥ | 1. r√©sz | SkyShowtime Magyarorsz√°g - YouTube
https://www.youtube.com/watch?v=Nip8K47UvdE&t=2263s

paraszt - Wiktionary, the free dictionary
https://en.wiktionary.org/wiki/paraszt

Panelshow
https://www.reddit.com/r/panelshow/

Reddit - Dive into anything
https://www.reddit.com/r/panelshow/wiki/taskmaster/#wiki_kongen_befaler_.28taskmaster_norway.29

Kongen_Befaler_S09_E02.mkv - Google Drive
https://drive.google.com/file/d/1kFiwxgAhEzn2msRoclVzpfI6BK0afWp5/view

Category:Hungarian-language dubs | The Dubbing Database | Fandom
https://dubdb.fandom.com/wiki/Category:Hungarian-language_dubs

Peppa Malac | A Nagy Beteg | Rajzfilmek - YouTube
https://www.youtube.com/watch?v=a68sy55RBe4

Peppa Malac | Az √°lruha | Rajzfilmek - YouTube
https://www.youtube.com/watch?v=Em5Vj_ar8xY

Peppa Pig - Dressing Up (full episode) - YouTube
https://www.youtube.com/watch?v=mqxNuaK2uZE

multilingual t5 - Google Search
https://www.google.com/search?q=multilingual+t5&sca_esv=a5cf8bc1fdafc68d&rlz=1C5GCEM_enSE990SE991&sxsrf=ACQVn0-twJbpgAwxmJi11wkIsOdI9vrQUQ%3A1707594034738&ei=MtHHZaXXLMStwPAPye2GwAk&ved=0ahUKEwiluPG-w6GEAxXEFhAIHcm2AZgQ4dUDCBA&uact=5&oq=multilingual+t5&gs_lp=Egxnd3Mtd2l6LXNlcnAiD211bHRpbGluZ3VhbCB0NTIFEAAYgAQyCxAAGIAEGIoFGJECMgYQABgWGB4yChAAGIAEGBQYhwIyBhAAGBYYHjIGEAAYFhgeMgYQABgWGB5IxSlQ6ghY5SNwA3gBkAEAmAF9oAGUCaoBBDEzLjK4AQPIAQD4AQHCAgoQABhHGNYEGLADwgINEAAYgAQYigUYQxiwA8ICDhAAGOQCGNYEGLAD2AEBwgIZEC4YgAQYigUYQxjHARjRAxjIAxiwA9gBAsICFhAuGIAEGIoFGEMY1AIYyAMYsAPYAQLCAhMQLhiABBiKBRhDGMgDGLAD2AECwgIEECMYJ8ICChAuGIAEGIoFGCfCAgoQIxiABBiKBRgnwgIKEAAYgAQYigUYQ8ICCxAuGIAEGMcBGNEDwgIFEC4YgATCAgsQLhiABBjHARivAeIDBBgAIEGIBgGQBhO6BgYIARABGAm6BgYIAhABGAg&sclient=gws-wiz-serp#ip=1

multilingual-t5/multilingual_t5/tasks.py at master ¬∑ google-research/multilingual-t5
https://github.com/google-research/multilingual-t5/blob/master/multilingual_t5/tasks.py

Going Global ‚ÄîHow to Multi-Task in Multiple Languages with the mT5 Transformer | by Thilina Rajapakse | Towards Data Science
https://towardsdatascience.com/going-global-how-to-multi-task-in-multiple-languages-with-the-mt5-transformer-892617cd890c

mT6: Multilingual Pretrained Text-to-Text Transformer with Translation Pairs
https://aclanthology.org/2021.emnlp-main.125.pdf

FLAN-T5 Tutorial: Guide and Fine-Tuning | DataCamp
https://www.datacamp.com/tutorial/flan-t5-tutorial

north sami corpus - Google Search
https://www.google.com/search?q=north+sami+corpus&rlz=1C5GCEM_enSE990SE991&oq=north+sami+corpus&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIHCAEQIRigATIHCAIQIRigAdIBCDQ5MzRqMGo0qAIAsAIA&sourceid=chrome&ie=UTF-8#ip=1

SIKOR North Saami corpus - Arctic Language Technology
https://dataverse.no/dataset.xhtml;jsessionid=4655f41072c706e121d2598ad1cc?persistentId=doi%3A10.18710%2F8AK7KZ&version=&q=&fileTypeGroupFacet=&fileAccess=Public&fileTag=&fileSortField=size&fileSortOrder=

Northern S√°mi - Wikipedia
https://en.wikipedia.org/wiki/Northern_S%C3%A1mi

UniversalDependencies/UD_North_Sami-Giella: North S√°mi data.
https://github.com/UniversalDependencies/UD_North_Sami-Giella

Northern Saami interactive text corpus
https://giellatekno.uit.no/text.en.html

SIKOR North Saami free corpus
https://repo.clarino.uib.no/xmlui/handle/11509/100

Welcome to Giellatekno, the Research group for Saami language technology
https://giellatekno.uit.no/index.eng.html

Translation memories | GiellaLT Documentation
https://giellalt.github.io/tm/TranslationMemories.html

biggies - Revision 4825: /trunk/mt/omegat/sma-nob/glossary
https://gtsvn.uit.no/biggies/trunk/mt/omegat/sma-nob/glossary/

Downloads
https://wortschatz.uni-leipzig.de/en/download

cisnlp/simalign: Obtain Word Alignments using Pretrained Language Models (e.g., mBERT)
https://github.com/cisnlp/simalign


