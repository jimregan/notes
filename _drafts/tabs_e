(1) Christoph Molnar on X: "I just found a great introduction to embedding. The book is comprehensive yet short. Historical encoding tools, neural nets, and production - all covered. Fantastic job by @vboykis. Thanks for making it free to read! Looking forward to diving in. https://t.co/uFwaSjaysn https://t.co/SKl2ExOJaw" / X
https://twitter.com/ChristophMolnar/status/1745731602682982675?t=LHKlCc79AHUE94jlWGyfHw&s=09

what_are_embeddings/notebooks/fig_4_bert.ipynb at main ¬∑ veekaybee/what_are_embeddings
https://github.com/veekaybee/what_are_embeddings/blob/main/notebooks/fig_4_bert.ipynb

BetterExplained ‚Äì Math lessons that click
https://betterexplained.com/

roboflow/supervision: We write your reusable computer vision tools. üíú
https://github.com/roboflow/supervision

Code LoRA from Scratch
https://lightning.ai/lightning-ai/studios/code-lora-from-scratch?view=public&section=all

text_search/examples/libriheavy at master ¬∑ k2-fsa/text_search
https://github.com/k2-fsa/text_search/tree/master/examples/libriheavy

MambaByte/mambabyte/model.py at main ¬∑ kyegomez/MambaByte
https://github.com/kyegomez/MambaByte/blob/main/mambabyte/model.py

hustvl/Vim: Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model
https://github.com/hustvl/Vim

makeMoE: Implement a Sparse Mixture of Experts Language Model from Scratch
https://huggingface.co/blog/AviSoori1x/makemoe-from-scratch

[2305.19435] AdANNS: A Framework for Adaptive Semantic Search
https://arxiv.org/abs/2305.19435

2211.09949.pdf
https://arxiv.org/pdf/2211.09949.pdf

[2401.16658] OWSM v3.1: Better and Faster Open Whisper-Style Speech Models based on E-Branchformer
https://arxiv.org/abs/2401.16658

A complete practical grammar of the Hungarian language; with exercises, selections from the best authors, and vocabularies, to which is added a Historical sketch of Hungarian literature by J Csink - PDF Drive
https://www.pdfdrive.com/a-complete-practical-grammar-of-the-hungarian-language-with-exercises-selections-from-the-best-authors-and-vocabularies-to-which-is-added-a-historical-sketch-of-hungarian-literature-d157292500.html

[2402.00282] PAM: Prompting Audio-Language Models for Audio Quality Assessment
https://arxiv.org/abs/2402.00282

[2401.18059] RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval
https://arxiv.org/abs/2401.18059

Lesson - Mondly
https://app.mondly.com/home/5/lessons/505

OWSM v3.1: Better and Faster Open Whisper-Style Speech Models based on E-Branchformer
https://arxiv.org/html/2401.16658v1

Audio Flamingo: A Novel Audio Language Model with Few-Shot Learning and Dialogue Abilities
https://arxiv.org/pdf/2402.01831.pdf

CLAP/msclap/models/mapper.py at main ¬∑ microsoft/CLAP
https://github.com/microsoft/CLAP/blob/main/msclap/models/mapper.py

Commits ¬∑ NVIDIA/NeMo
https://github.com/NVIDIA/NeMo/commits/main/?after=9940ec60058f644662809a6787ba1b7c464567ad+34

Replace CLIP Image Encoder with LanguageBind Image Encoder [Video-NeVA] by PannuMuthu ¬∑ Pull Request #8300 ¬∑ NVIDIA/NeMo
https://github.com/NVIDIA/NeMo/pull/8300/commits/a3d9cc7198962780cb7922fd733802a3507e3ad9#diff-07b087ee21d99449fa5be968321007e0bfe109f0a97f5420d0b34b430dcc88fb

enable nmt to use beam search by mengruwNv ¬∑ Pull Request #8287 ¬∑ NVIDIA/NeMo
https://github.com/NVIDIA/NeMo/pull/8287

Attention encoder-decoder models for multiple speech-to-text tasks ‚Ä¶ ¬∑ NVIDIA/NeMo@d10726d
https://github.com/NVIDIA/NeMo/commit/d10726da72f74eb5a95056843d1f9e2562a5051c

Pin lhotse version to 1.19.2 (#8291) ¬∑ NVIDIA/NeMo@f6e6485
https://github.com/NVIDIA/NeMo/commit/f6e64859174920e6a7fb26c4308cbe4c1d44206e

Mixtral to NeMo conversion script. (#8155) ¬∑ NVIDIA/NeMo@13c1db4
https://github.com/NVIDIA/NeMo/commit/13c1db4ffdaa3b2125ce6e66c93509a39d55b2cf

switch to mcore dataset [with FIM support] (#8149) ¬∑ NVIDIA/NeMo@a93589d
https://github.com/NVIDIA/NeMo/commit/a93589d80472bfbf949b0e65758b106eeaa7ac80

NeMo/nemo/collections/common/data/dataset.py at 2c2c3ccde2f1269a0e30f9b54dac0b0d569bae51 ¬∑ NVIDIA/NeMo
https://github.com/NVIDIA/NeMo/blob/2c2c3ccde2f1269a0e30f9b54dac0b0d569bae51/nemo/collections/common/data/dataset.py

lhotse/lhotse/recipes/switchboard.py at master ¬∑ lhotse-speech/lhotse
https://github.com/lhotse-speech/lhotse/blob/master/lhotse/recipes/switchboard.py

lhotse/lhotse/recipes/timit.py at master ¬∑ lhotse-speech/lhotse
https://github.com/lhotse-speech/lhotse/blob/master/lhotse/recipes/timit.py

lhotse/lhotse/recipes/nsc.py at master ¬∑ lhotse-speech/lhotse
https://github.com/lhotse-speech/lhotse/blob/master/lhotse/recipes/nsc.py

lhotse/lhotse/recipes/mls.py at master ¬∑ lhotse-speech/lhotse
https://github.com/lhotse-speech/lhotse/blob/master/lhotse/recipes/mls.py

lhotse/lhotse/recipes/dipco.py at master ¬∑ lhotse-speech/lhotse
https://github.com/lhotse-speech/lhotse/blob/master/lhotse/recipes/dipco.py

Course information for doctoral students | EECS internal pages
https://intra.kth.se/en/eecs/forskarutbildning/courses

NY FO-TRAK
https://intra.kth.se/polopoly_fs/1.1298221.1700743075!/FO-TRAK%20EECS.pdf

NVIDIA GPU Compute Test Suite Collection - OpenBenchmarking.org
https://openbenchmarking.org/suite/pts/nvidia-gpu-compute

Interspeech thing for ParlaCLARIN - Online LaTeX Editor Overleaf
https://www.overleaf.com/project/65b12a434befd9098dbef6a9

ParlaCLARIN IV Workshop on Creating, Analysing, and Increasing Accessibility of Parliamentary Corpora | CLARIN ERIC
https://www.clarin.eu/ParlaCLARIN-IV

SIGUL 2024 - SIGUL
https://www.sigul.eu/event/sigul-2024/

SIGUL-2024_Call-for-Papers.pdf
https://sigul-2024.ilc.cnr.it/wp-content/uploads/2023/12/SIGUL-2024_Call-for-Papers.pdf

Call For Papers ‚Äì Interspeech 2024
https://interspeech2024.org/call-for-papers/

Phonological rules ‚Äî Montreal Forced Aligner 3.0.0 documentation
https://montreal-forced-aligner.readthedocs.io/en/latest/user_guide/implementations/phonological_rules.html

Large-Scale Contrastive Language-Audio Pretraining with Feature Fusion and Keyword-to-Caption Augmentation | IEEE Conference Publication | IEEE Xplore
https://ieeexplore.ieee.org/document/10095969

Text-to-audio retrieval via large-scale contrastive learning - Google Search
https://www.google.com/search?q=Text-to-audio+retrieval+via+large-scale+contrastive+learning&rlz=1C5GCEM_enSE990SE991&sourceid=chrome&ie=UTF-8

CLAP/src/laion_clap/clap_module/pann_model.py at main ¬∑ LAION-AI/CLAP
https://github.com/LAION-AI/CLAP/blob/main/src/laion_clap/clap_module/pann_model.py

Large-scale Contrastive Language-Audio Petraining
https://retrocirce.github.io/appendix/

audioset_tagging_cnn/scripts/0_inference.sh at master ¬∑ qiuqiangkong/audioset_tagging_cnn
https://github.com/qiuqiangkong/audioset_tagging_cnn/blob/master/scripts/0_inference.sh

(1) Philipp Schmid on X: "Can a 2B LLM outperform Mistral 7B or Llama 13B? Creators of the popular Ultrafeedback dataset released MiniCPM, a 2.4B parameter model claiming performance close to Mistral 7B, Llama 2 13B, or Falcon 40B. ü§Øü§î As part of the release, the researchers released a detailed‚Ä¶" / X
https://twitter.com/_philschmid/status/1755268463457657263

MiniCPM: Unveiling the Potential of End-side Large Language Models
https://shengdinghu.notion.site/MiniCPM-Unveiling-the-Potential-of-End-side-Large-Language-Models-d4d3a8c426424654a4e80e42a711cb20

OpenBMB/MiniCPM: MiniCPM-2B: An end-side LLM outperforms Llama2-13B.
https://github.com/OpenBMB/MiniCPM

General-Model-License/ÈÄöÁî®Ê®°ÂûãËÆ∏ÂèØÂçèËÆÆ-Êù•Ê∫êËØ¥Êòé-ÂÆ£‰º†ÈôêÂà∂-ÂïÜ‰∏öÊéàÊùÉ.md at main ¬∑ OpenBMB/General-Model-License
https://github.com/OpenBMB/General-Model-License/blob/main/%E9%80%9A%E7%94%A8%E6%A8%A1%E5%9E%8B%E8%AE%B8%E5%8F%AF%E5%8D%8F%E8%AE%AE-%E6%9D%A5%E6%BA%90%E8%AF%B4%E6%98%8E-%E5%AE%A3%E4%BC%A0%E9%99%90%E5%88%B6-%E5%95%86%E4%B8%9A%E6%8E%88%E6%9D%83.md

[2402.03944] IMUSIC: IMU-based Facial Expression Capture
https://arxiv.org/abs/2402.03944

state-spaces/mamba
https://github.com/state-spaces/mamba?tab=readme-ov-file

state-spaces/s4: Structured state space sequence models
https://github.com/state-spaces/s4?tab=readme-ov-file

s4/src/dataloaders at main ¬∑ state-spaces/s4
https://github.com/state-spaces/s4/tree/main/src/dataloaders

(1) Cory Doctorow @pluralistic@mamot.fr on X: "There's a strain of anti-anti-monopolist that insists that they're not *pro*-monopoly - they're just *realists* who understand that global gigacorporations are too big to fail, too big to jail, and that governments can't hope to rein them in. 1/ https://t.co/nx0lM4lKWu" / X
https://twitter.com/doctorow/status/1754999901073903739

Duty-free shop - Wikipedia
https://en.wikipedia.org/wiki/Duty-free_shop#1947%E2%80%931990:_duty_free_establishment

System prompt - Pastebin.com
https://pastebin.com/vnxJ7kQk

metavoiceio/metavoice-1B-v0.1 ¬∑ Hugging Face
https://huggingface.co/metavoiceio/metavoice-1B-v0.1

huggingface.co
https://huggingface.co/spaces/mrfakename/MetaVoice-1B-v0.1/blob/main/app.py

metavoiceio/metavoice-src: AI for human-level speech intelligence
https://github.com/metavoiceio/metavoice-src

metavoice-src/fam/llm/model.py at main ¬∑ metavoiceio/metavoice-src
https://github.com/metavoiceio/metavoice-src/blob/main/fam/llm/model.py

neonbjb/tortoise-tts: A multi-voice TTS system trained with an emphasis on quality
https://github.com/neonbjb/tortoise-tts

TTS by MetaVoice
https://ttsdemo.themetavoice.xyz/

(1) LangChain on X: "RAG From Scratch: Video series focused on understanding the RAG landscape RAG is central for LLM application development, connecting LLMs to external data sources. But, the pace of innovation and new approaches makes it challenging to keep up. We're launching a new video‚Ä¶ https://t.co/963lOnVLcP" / X
https://twitter.com/LangChainAI/status/1754915914796216654

RAG From Scratch: Part 1 (Overview) - YouTube
https://www.youtube.com/watch?v=wd7TZ4w1mSw

YouTube
https://www.youtube.com/

Do Pressures Points Work for Self Defense? - YouTube
https://www.youtube.com/watch?v=ZGjpDmDy11M

Top TV Shows Premiering in February 2024 | Rotten Tomatoes TV - YouTube
https://www.youtube.com/watch?v=nwa5ogg-QeY

rag-from-scratch/rag_from_scratch_1_to_4.ipynb at main ¬∑ langchain-ai/rag-from-scratch
https://github.com/langchain-ai/rag-from-scratch/blob/main/rag_from_scratch_1_to_4.ipynb

whisperX/whisperx/alignment.py at main ¬∑ m-bain/whisperX
https://github.com/m-bain/whisperX/blob/main/whisperx/alignment.py

whisper/data at main ¬∑ openai/whisper
https://github.com/openai/whisper/tree/main/data

whisper v3 - Google Search
https://www.google.com/search?q=whisper+v3&rlz=1C5GCEM_enSE990SE991&oq=whisper+v3&gs_lcrp=EgZjaHJvbWUyCQgAEEUYORiABDIHCAEQABiABDIHCAIQABiABDIHCAMQABiABDIHCAQQABiABDIHCAUQABiABDIGCAYQRRg9MgYIBxBFGD3SAQgzNzQzajBqN6gCALACAA&sourceid=chrome&ie=UTF-8

openai/whisper-large-v3 ¬∑ Hugging Face
https://huggingface.co/openai/whisper-large-v3

Ego-Exo4D
https://ego-exo4d-data.org/?utm_source=twitter&utm_medium=organic_social&utm_campaign=fair10&utm_content=video

Efficient Linear Model Merging for LLMs
https://lightning.ai/lightning-ai/studios/efficient-linear-model-merging-for-llms

Fast Timing-Conditioned Latent Audio Diffusion
https://arxiv.org/pdf/2402.04825.pdf

Stability-AI/stable-audio-tools: Generative models for conditional audio generation
https://github.com/Stability-AI/stable-audio-tools

(1) AK on X: "LGM Large Multi-View Gaussian Model for High-Resolution 3D Content Creation paper page: https://t.co/IyOG6jv9xb 3D content creation has achieved significant progress in terms of both quality and speed. Although current feed-forward models can produce 3D objects in seconds,‚Ä¶ https://t.co/goc3UePfww" / X
https://twitter.com/_akhaliq/status/1755462708105781269

2402.05054.pdf
https://arxiv.org/pdf/2402.05054.pdf

k2-fsa/sherpa-onnx: Speech-to-text, text-to-speech, and speaker recongition using next-gen Kaldi with onnxruntime without Internet connection. Support embedded systems, Android, iOS, Raspberry Pi, x86_64 servers, websocket server/client, C/C++, Python, Kotlin, C#, Go, NodeJS, Java, Swift
https://github.com/k2-fsa/sherpa-onnx

‚ÄòEnshittification‚Äô is coming for absolutely everything
https://www.ft.com/content/6fb1602d-a08b-4a8c-bac0-047b7d64aba5?shareType=nongift

‚ÄòEnshittification‚Äô is coming for absolutely everything
https://www.ft.com/content/6fb1602d-a08b-4a8c-bac0-047b7d64aba5?shareType=nongift


