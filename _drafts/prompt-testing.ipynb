{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.76.0-py3-none-any.whl (661 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.2/661.2 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /Users/joregan/opt/anaconda3/envs/nst-tts/lib/python3.10/site-packages (from openai) (3.6.2)\n",
      "Collecting distro<2,>=1.7.0\n",
      "  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Collecting httpx<1,>=0.23.0\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting typing-extensions<5,>=4.11\n",
      "  Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sniffio in /Users/joregan/opt/anaconda3/envs/nst-tts/lib/python3.10/site-packages (from openai) (1.3.0)\n",
      "Collecting pydantic<3,>=1.9.0\n",
      "  Downloading pydantic-2.11.3-py3-none-any.whl (443 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.6/443.6 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jiter<1,>=0.4.0\n",
      "  Downloading jiter-0.9.0-cp310-cp310-macosx_10_12_x86_64.whl (314 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.5/314.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>4 in /Users/joregan/opt/anaconda3/envs/nst-tts/lib/python3.10/site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/joregan/opt/anaconda3/envs/nst-tts/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in /Users/joregan/opt/anaconda3/envs/nst-tts/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2023.5.7)\n",
      "Collecting httpcore==1.*\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting h11>=0.16\n",
      "  Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Collecting pydantic-core==2.33.1\n",
      "  Downloading pydantic_core-2.33.1-cp310-cp310-macosx_10_12_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting annotated-types>=0.6.0\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting typing-inspection>=0.4.0\n",
      "  Downloading typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: typing-extensions, jiter, h11, distro, annotated-types, typing-inspection, pydantic-core, httpcore, pydantic, httpx, openai\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.5.0\n",
      "    Uninstalling typing_extensions-4.5.0:\n",
      "      Successfully uninstalled typing_extensions-4.5.0\n",
      "Successfully installed annotated-types-0.7.0 distro-1.9.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 jiter-0.9.0 openai-1.76.0 pydantic-2.11.3 pydantic-core-2.33.1 typing-extensions-4.13.2 typing-inspection-0.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "JSONPATH = Path(\"/Users/joregan/Playing/hsi/annotations/final_resolved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKIPPABLES = [\"room\"]\n",
    "\n",
    "def process_item(item):\n",
    "    utt_key = \"utterance_type\"\n",
    "    if not utt_key in item[\"high_level\"]:\n",
    "        utt_key = \"topic_name\"\n",
    "    if item[\"high_level\"][utt_key] == \"conversation_generic\":\n",
    "        return {}\n",
    "    current = item[\"high_level\"][\"current_topic\"]\n",
    "    if current in SKIPPABLES:\n",
    "        return {}\n",
    "    snippet = item[\"snippet\"]\n",
    "    return {\n",
    "        \"topic:\": current,\n",
    "        \"snippet\": snippet\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "alldata = []\n",
    "\n",
    "for jsonfile in JSONPATH.glob(\"*.json\"):\n",
    "    stem = jsonfile.stem\n",
    "    parts = stem.split(\"_\")\n",
    "    person = parts[1]\n",
    "    room = parts[3]\n",
    "\n",
    "    with open(jsonfile) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    output = {\n",
    "        \"person\": person,\n",
    "        \"room\": room,\n",
    "        \"items\": []\n",
    "    }\n",
    "    for item in data.keys():\n",
    "        processed = process_item(data[item])\n",
    "        if processed and processed != {}:\n",
    "            output[\"items\"].append(processed)\n",
    "    alldata.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/tmp/hsi.json\", \"w\") as f:\n",
    "    json.dump(alldata, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = alldata[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = f\"\"\"\n",
    "Below is some data from a conversation. The data is in JSON format.\n",
    "The data contains a list of items, each with a topic and a snippet. The topic is the subject of the conversation, and the snippet is a short excerpt from the conversation.\n",
    "Continue the conversation by writing a new snippet that is relevant to the topic. The new snippet should contain a reference to the topic and should be a natural continuation of the conversation.\n",
    "The new snippet should be in the same format as the original snippets, and should be a short paragraph of text, of between 10 and 50 words.\n",
    "There should only be one reference to the topic in the new snippet. It should be a natural part of the conversation, and should not be forced or awkward. It should be marked in boldface using markdown syntax. Only the determiner should be marked; boldface is marked by a single asterisk.\n",
    "The reference to the topic should be suitable for instructing a person to point at it in a conversation. It can be a noun phrase, or a pronoun, but it should be clear and unambiguous. If the reference is a noun phrase, it should include a determiner, such as \"this\" or \"that\". If the reference is a pronoun, it should be clear what it refers to.\n",
    "If another topic is mentioned in the new snippet and the spatial relationship is very clear, it is ok to reuse that spatial reference.\n",
    "Create as many new snippets as there are items in the data.\n",
    "```json\n",
    "{test}\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                { \"type\": \"text\", \"text\": PROMPT },\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-BRGKBf83FizBn2cuY40CfosbbuwGm', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='```json\\n{\\'topic:\\': \\'Book_28\\', \\'snippet\\': \"Yeah, I noticed **that novel** when I came in, and it seemed interesting. It must belong to someone who really enjoys detective stories, don\\'t you think?\"}\\n```', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1745837307, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_90122d973c', usage=CompletionUsage(completion_tokens=52, prompt_tokens=1029, total_tokens=1081, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_text = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n{\\'topic:\\': \\'Book_28\\', \\'snippet\\': \"Yeah, I noticed **that novel** when I came in, and it seemed interesting. It must belong to someone who really enjoys detective stories, don\\'t you think?\"}\\n```'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_response(response_text):\n",
    "    response_text = response_text.replace(\"```json\", \"\")\n",
    "    response_text = response_text.replace(\"```\", \"\")\n",
    "    response_text = response_text.strip()\n",
    "    # response_text = response_text.replace(\"'\", '\"')\n",
    "    # try:\n",
    "    #     return json.loads(response_text)\n",
    "    # except json.JSONDecodeError:\n",
    "    #     print(response_text)\n",
    "    data = eval(response_text)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic:': 'Book_28',\n",
       " 'snippet': \"Yeah, I noticed **that novel** when I came in, and it seemed interesting. It must belong to someone who really enjoys detective stories, don't you think?\"}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_response(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                { \"type\": \"text\", \"text\": PROMPT },\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-BRGSLwcAubUqXJVqMYgh5T77PwpTP', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='```json\\n[\\n    {\"topic:\": \"furniture\", \"snippet\": \"I\\'ll rearrange the chairs today, so **this setup** feels more welcoming.\"},\\n    {\"topic:\": \"furniture\", \"snippet\": \"Perhaps moving **that table** near the window would brighten up the room.\"},\\n    {\"topic:\": \"furniture\", \"snippet\": \"You know, **those stools** would be perfect at the kitchen counter.\"},\\n    {\"topic:\": \"furniture\", \"snippet\": \"Let\\'s think about where **this bench** could go; maybe the hallway?\"},\\n    {\"topic:\": \"Television_f9d000b1\", \"snippet\": \"Maybe we could move **the TV** to the opposite wall for a cozier setup.\"},\\n    {\"topic:\": \"Dog_Statue_1\", \"snippet\": \"I checked around, and **the statue** seems perfectly fine now.\"},\\n    {\"topic:\": \"Dog_Statue_1\", \"snippet\": \"I\\'d love to know how **that piece** first caught your eye.\"},\\n    {\"topic:\": \"Dog_Statue_1\", \"snippet\": \"And I was thinking, maybe **this statue** deserves a spot in the garden.\"},\\n    {\"topic:\": \"Tennis_Racquet_4\", \"snippet\": \"I think **this racquet** needs a new grip before the next match.\"},\\n    {\"topic:\": \"Laptop_4\", \"snippet\": \"I found **the charger**, so now you can use it wherever you like.\"},\\n    {\"topic:\": \"Laptop_4\", \"snippet\": \"Sure, just let me know if **this laptop** starts acting up again.\"},\\n    {\"topic:\": \"Laptop_4\", \"snippet\": \"I\\'m happy holding onto **this one** until you\\'re sure you need it.\"},\\n    {\"topic:\": \"KeyChain_76c05fe6\", \"snippet\": \"Can you show me how **these keys** fit into everything?\"},\\n    {\"topic:\": \"Newspaper_990192bf\", \"snippet\": \"If you want, we could swap **this newspaper** for a new one.\"},\\n    {\"topic:\": \"Newspaper_990192bf\", \"snippet\": \"I heard they changed the layout in **the papers**, right?\"},\\n    {\"topic:\": \"Newspaper_990192bf\", \"snippet\": \"I\\'ve been thinking of subscribing to **them** for a while now.\"},\\n    {\"topic:\": \"Box_7d6b3e2c\", \"snippet\": \"I wonder if **that box** has any old photos we can look through.\"},\\n    {\"topic:\": \"Book_17\", \"snippet\": \"I might borrow **this novel** once you\\'re done with it.\"},\\n    {\"topic:\": \"Book_17\", \"snippet\": \"Noticed that **another book** fits well with the decor too.\"},\\n    {\"topic:\": \"Book_17\", \"snippet\": \"I can’t wait to hear your thoughts on **the story** when you finish.\"},\\n    {\"topic:\": \"furniture\", \"snippet\": \"After settling **this room**, moving the furniture outside may be next.\"},\\n    {\"topic:\": \"painting\", \"snippet\": \"I think that moving **these paintings** has changed the room\\'s atmosphere.\"},\\n    {\"topic:\": \"painting\", \"snippet\": \"And if we frame **that piece**, the entire collection will truly shine.\"},\\n    {\"topic:\": \"garbage bin\", \"snippet\": \"It might be a good idea to move **the bin** outside, near the sidewalk.\"},\\n    {\"topic:\": \"Book_28\", \"snippet\": \"Or perhaps **that novel** could be a fun read during the weekend.\"}\\n]\\n```', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1745837813, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_90122d973c', usage=CompletionUsage(completion_tokens=792, prompt_tokens=1060, total_tokens=1852, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_text = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'topic:': 'furniture',\n",
       "  'snippet': \"I'll rearrange the chairs today, so **this setup** feels more welcoming.\"},\n",
       " {'topic:': 'furniture',\n",
       "  'snippet': 'Perhaps moving **that table** near the window would brighten up the room.'},\n",
       " {'topic:': 'furniture',\n",
       "  'snippet': 'You know, **those stools** would be perfect at the kitchen counter.'},\n",
       " {'topic:': 'furniture',\n",
       "  'snippet': \"Let's think about where **this bench** could go; maybe the hallway?\"},\n",
       " {'topic:': 'Television_f9d000b1',\n",
       "  'snippet': 'Maybe we could move **the TV** to the opposite wall for a cozier setup.'},\n",
       " {'topic:': 'Dog_Statue_1',\n",
       "  'snippet': 'I checked around, and **the statue** seems perfectly fine now.'},\n",
       " {'topic:': 'Dog_Statue_1',\n",
       "  'snippet': \"I'd love to know how **that piece** first caught your eye.\"},\n",
       " {'topic:': 'Dog_Statue_1',\n",
       "  'snippet': 'And I was thinking, maybe **this statue** deserves a spot in the garden.'},\n",
       " {'topic:': 'Tennis_Racquet_4',\n",
       "  'snippet': 'I think **this racquet** needs a new grip before the next match.'},\n",
       " {'topic:': 'Laptop_4',\n",
       "  'snippet': 'I found **the charger**, so now you can use it wherever you like.'},\n",
       " {'topic:': 'Laptop_4',\n",
       "  'snippet': 'Sure, just let me know if **this laptop** starts acting up again.'},\n",
       " {'topic:': 'Laptop_4',\n",
       "  'snippet': \"I'm happy holding onto **this one** until you're sure you need it.\"},\n",
       " {'topic:': 'KeyChain_76c05fe6',\n",
       "  'snippet': 'Can you show me how **these keys** fit into everything?'},\n",
       " {'topic:': 'Newspaper_990192bf',\n",
       "  'snippet': 'If you want, we could swap **this newspaper** for a new one.'},\n",
       " {'topic:': 'Newspaper_990192bf',\n",
       "  'snippet': 'I heard they changed the layout in **the papers**, right?'},\n",
       " {'topic:': 'Newspaper_990192bf',\n",
       "  'snippet': \"I've been thinking of subscribing to **them** for a while now.\"},\n",
       " {'topic:': 'Box_7d6b3e2c',\n",
       "  'snippet': 'I wonder if **that box** has any old photos we can look through.'},\n",
       " {'topic:': 'Book_17',\n",
       "  'snippet': \"I might borrow **this novel** once you're done with it.\"},\n",
       " {'topic:': 'Book_17',\n",
       "  'snippet': 'Noticed that **another book** fits well with the decor too.'},\n",
       " {'topic:': 'Book_17',\n",
       "  'snippet': 'I can’t wait to hear your thoughts on **the story** when you finish.'},\n",
       " {'topic:': 'furniture',\n",
       "  'snippet': 'After settling **this room**, moving the furniture outside may be next.'},\n",
       " {'topic:': 'painting',\n",
       "  'snippet': \"I think that moving **these paintings** has changed the room's atmosphere.\"},\n",
       " {'topic:': 'painting',\n",
       "  'snippet': 'And if we frame **that piece**, the entire collection will truly shine.'},\n",
       " {'topic:': 'garbage bin',\n",
       "  'snippet': 'It might be a good idea to move **the bin** outside, near the sidewalk.'},\n",
       " {'topic:': 'Book_28',\n",
       "  'snippet': 'Or perhaps **that novel** could be a fun read during the weekend.'}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_response(response_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nst-tts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
