{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.76.0-py3-none-any.whl (661 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.2/661.2 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /Users/joregan/opt/anaconda3/envs/nst-tts/lib/python3.10/site-packages (from openai) (3.6.2)\n",
      "Collecting distro<2,>=1.7.0\n",
      "  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Collecting httpx<1,>=0.23.0\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting typing-extensions<5,>=4.11\n",
      "  Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sniffio in /Users/joregan/opt/anaconda3/envs/nst-tts/lib/python3.10/site-packages (from openai) (1.3.0)\n",
      "Collecting pydantic<3,>=1.9.0\n",
      "  Downloading pydantic-2.11.3-py3-none-any.whl (443 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.6/443.6 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jiter<1,>=0.4.0\n",
      "  Downloading jiter-0.9.0-cp310-cp310-macosx_10_12_x86_64.whl (314 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.5/314.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>4 in /Users/joregan/opt/anaconda3/envs/nst-tts/lib/python3.10/site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/joregan/opt/anaconda3/envs/nst-tts/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in /Users/joregan/opt/anaconda3/envs/nst-tts/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2023.5.7)\n",
      "Collecting httpcore==1.*\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting h11>=0.16\n",
      "  Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Collecting pydantic-core==2.33.1\n",
      "  Downloading pydantic_core-2.33.1-cp310-cp310-macosx_10_12_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting annotated-types>=0.6.0\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting typing-inspection>=0.4.0\n",
      "  Downloading typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: typing-extensions, jiter, h11, distro, annotated-types, typing-inspection, pydantic-core, httpcore, pydantic, httpx, openai\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.5.0\n",
      "    Uninstalling typing_extensions-4.5.0:\n",
      "      Successfully uninstalled typing_extensions-4.5.0\n",
      "Successfully installed annotated-types-0.7.0 distro-1.9.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 jiter-0.9.0 openai-1.76.0 pydantic-2.11.3 pydantic-core-2.33.1 typing-extensions-4.13.2 typing-inspection-0.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "JSONPATH = Path(\"/Users/joregan/Playing/hsi/annotations/final_resolved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKIPPABLES = [\"room\"]\n",
    "\n",
    "def process_item(item):\n",
    "    utt_key = \"utterance_type\"\n",
    "    if not utt_key in item[\"high_level\"]:\n",
    "        utt_key = \"topic_name\"\n",
    "    if item[\"high_level\"][utt_key] == \"conversation_generic\":\n",
    "        return {}\n",
    "    current = item[\"high_level\"][\"current_topic\"]\n",
    "    if current in SKIPPABLES:\n",
    "        return {}\n",
    "    snippet = item[\"snippet\"]\n",
    "    return {\n",
    "        \"topic:\": current,\n",
    "        \"snippet\": snippet\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "alldata = []\n",
    "\n",
    "for jsonfile in JSONPATH.glob(\"*.json\"):\n",
    "    stem = jsonfile.stem\n",
    "    parts = stem.split(\"_\")\n",
    "    person = parts[1]\n",
    "    room = parts[3]\n",
    "\n",
    "    with open(jsonfile) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    output = {\n",
    "        \"person\": person,\n",
    "        \"room\": room,\n",
    "        \"items\": []\n",
    "    }\n",
    "    for item in data.keys():\n",
    "        processed = process_item(data[item])\n",
    "        if processed and processed != {}:\n",
    "            output[\"items\"].append(processed)\n",
    "    alldata.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/tmp/hsi.json\", \"w\") as f:\n",
    "    json.dump(alldata, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = alldata[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = f\"\"\"\n",
    "Below is some data from a conversation. The data is in JSON format.\n",
    "The data contains a list of items, each with a topic and a snippet. The topic is the subject of the conversation, and the snippet is a short excerpt from the conversation.\n",
    "Continue the conversation by writing a new snippet that is relevant to the topic. The new snippet should contain a reference to the topic and should be a natural continuation of the conversation.\n",
    "The new snippet should be in the same format as the original snippets, and should be a short paragraph of text, of between 10 and 50 words.\n",
    "There should only be one reference to the topic in the new snippet. It should be a natural part of the conversation, and should not be forced or awkward. It should be marked in boldface using markdown syntax.\n",
    "The reference to the topic should be suitable for instructing a person to point at it in a conversation. It can be a noun phrase, or a pronoun, but it should be clear and unambiguous. If the reference is a noun phrase, it should include a determiner, such as \"this\" or \"that\". If the reference is a pronoun, it should be clear what it refers to.\n",
    "If another topic is mentioned in the new snippet and the spatial relationship is very clear, it is ok to reuse that spatial reference.\n",
    "```json\n",
    "{test}\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                { \"type\": \"text\", \"text\": PROMPT },\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-BRGKBf83FizBn2cuY40CfosbbuwGm', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='```json\\n{\\'topic:\\': \\'Book_28\\', \\'snippet\\': \"Yeah, I noticed **that novel** when I came in, and it seemed interesting. It must belong to someone who really enjoys detective stories, don\\'t you think?\"}\\n```', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1745837307, model='gpt-4o-2024-08-06', object='chat.completion', service_tier='default', system_fingerprint='fp_90122d973c', usage=CompletionUsage(completion_tokens=52, prompt_tokens=1029, total_tokens=1081, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_text = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'```json\\n{\\'topic:\\': \\'Book_28\\', \\'snippet\\': \"Yeah, I noticed **that novel** when I came in, and it seemed interesting. It must belong to someone who really enjoys detective stories, don\\'t you think?\"}\\n```'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_response(response_text):\n",
    "    response_text = response_text.replace(\"```json\", \"\")\n",
    "    response_text = response_text.replace(\"```\", \"\")\n",
    "    response_text = response_text.strip()\n",
    "    response_text = response_text.replace(\"'\", '\"')\n",
    "    try:\n",
    "        return json.loads(response_text)\n",
    "    except json.JSONDecodeError:\n",
    "        print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"topic:\": \"Book_28\", \"snippet\": \"Yeah, I noticed **that novel** when I came in, and it seemed interesting. It must belong to someone who really enjoys detective stories, don\"t you think?\"}\n"
     ]
    }
   ],
   "source": [
    "clean_response(response_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nst-tts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
