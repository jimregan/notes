{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"\n",
    "But then if you want to to remove some of the pieces, I think ah the the two ah pieces, the one the red one and the brown one there, eh those are the one down there.\n",
    "Mhm.\n",
    "Mm.\n",
    "Hmm.\n",
    "It's like a base. Ehm. They mm they are too flat I think for for the rest the rest are more like vertical pieces and those are super horizontal pieces then it's not um... It's not working for the place I think.\n",
    "Um yeah they are a little bit creepy but I mean it's it's a matter of uh choice i- if you don't like them you can actually remove them I think that that would be totally fine even maybe you can actually put some of these pieces there and then you can maybe have books here.\n",
    "But I don't think so. I think it looks nice. It's a nice division and it it gives you a nice view of the... I mean, it's a cen- it's a focus point that then leads you to the... to the green garden, yes.\n",
    "Uh so yeah, but but yeah, I mean, sometimes, eh whenever it's not, I mean, eh there is not that much light, I take them out in the balcony.\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "audio_dir = \"/home/joregan/hsi/audio\"\n",
    "json_dir = \"/tmp/whisperx-json\"\n",
    "whisper_model = \"large-v2\"\n",
    "align_model = \"facebook/wav2vec2-large-robust-ft-swbd-300h\"\n",
    "prompt = \"\"\n",
    "\n",
    "compute_type = \"float16\"\n",
    "batch_size = 16\n",
    "\n",
    "vad_onset = 0.500\n",
    "vad_offset = 0.363\n",
    "chunk_size = 30\n",
    "\n",
    "faster_whisper_threads = 4\n",
    "\n",
    "interpolate_method = \"nearest\"\n",
    "\n",
    "skip_files = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\"\n",
    "else:\n",
    "    DEVICE = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not prompt or prompt == \"\":\n",
    "    prompt = PROMPT\n",
    "skip_files = skip_files.split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_asr_options =  {\n",
    "    \"beam_size\": 5,\n",
    "    \"best_of\": 5,\n",
    "    \"patience\": 1,\n",
    "    \"length_penalty\": 1,\n",
    "    \"repetition_penalty\": 1,\n",
    "    \"no_repeat_ngram_size\": 0,\n",
    "    \"temperatures\": [0.0, 0.2, 0.4, 0.6, 0.8, 1.0],\n",
    "    \"compression_ratio_threshold\": 2.4,\n",
    "    \"log_prob_threshold\": -1.0,\n",
    "    \"no_speech_threshold\": 0.6,\n",
    "    \"condition_on_previous_text\": False,\n",
    "    \"prompt_reset_on_temperature\": 0.5,\n",
    "    \"initial_prompt\": None,\n",
    "    \"prefix\": None,\n",
    "    \"suppress_blank\": True,\n",
    "    \"suppress_tokens\": [-1],\n",
    "    \"without_timestamps\": True,\n",
    "    \"max_initial_timestamp\": 0.0,\n",
    "    \"word_timestamps\": False,\n",
    "    \"prepend_punctuations\": \"\\\"'“¿([{-\",\n",
    "    \"append_punctuations\": \"\\\"'.。,，!！?？:：”)]}、\",\n",
    "    \"suppress_numerals\": False,\n",
    "    \"max_new_tokens\": None,\n",
    "    \"clip_timestamps\": None,\n",
    "    \"hallucination_silence_threshold\": None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import gc\n",
    "import whisperx\n",
    "\n",
    "results = []\n",
    "tmp_results = []\n",
    "\n",
    "model = whisperx.load_model(whisper_model, device=DEVICE, compute_type=compute_type, language=\"en\", asr_options=default_asr_options, vad_options={\"vad_onset\": vad_onset, \"vad_offset\": vad_offset}, task=\"transcribe\", threads=faster_whisper_threads)\n",
    "\n",
    "for wavfile in Path(audio_dir).glob(\"*.wav\"):\n",
    "    if wavfile.name in skip_files or wavfile.stem in skip_files:\n",
    "        continue\n",
    "    audio_path = str(wavfile)\n",
    "    audio = whisperx.load_audio(audio_path)\n",
    "    result = model.transcribe(audio, batch_size=batch_size, chunk_size=chunk_size, print_progress=True)\n",
    "    results.append((result, audio_path))\n",
    "\n",
    "\n",
    "del model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "align_model, align_metadata = whisperx.load_align_model(\"en\", DEVICE, model_name=align_model)\n",
    "\n",
    "tmp_results = results\n",
    "results = []\n",
    "for result, audio_path in tmp_results:\n",
    "    if len(tmp_results) > 1:\n",
    "        input_audio = audio_path\n",
    "    else:\n",
    "        # lazily load audio from part 1\n",
    "        input_audio = audio\n",
    "\n",
    "    if align_model is not None and len(result[\"segments\"]) > 0:\n",
    "        if result.get(\"language\", \"en\") != align_metadata[\"language\"]:\n",
    "            # load new language\n",
    "            print(\"Error: found something other than English\", audio_path)\n",
    "        print(\">>Performing alignment...\")\n",
    "        result = whisperx.align(result[\"segments\"], align_model, align_metadata, input_audio, DEVICE, interpolate_method=interpolate_method, return_char_alignments=False, print_progress=True)\n",
    "\n",
    "    results.append((result, audio_path))\n",
    "\n",
    "# Unload align model\n",
    "del align_model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json_path = Path(json_dir)\n",
    "if not json_path.is_dir():\n",
    "    json_path.mkdir()\n",
    "\n",
    "for result, audio_path in results:\n",
    "    audio_stem = Path(audio_path).stem\n",
    "    json_file = json_path / f\"{audio_stem}.json\"\n",
    "    with open(str(json_file), \"w\") as outfile:\n",
    "        json.dump(result, outfile, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
