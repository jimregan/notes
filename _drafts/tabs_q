CVPR 2022 Author Kit - Online LaTeX Editor Overleaf
https://www.overleaf.com/project/680b5d858fd7186fb6b63068

CVPR_2022_Author_Kit (2).pdf
file:///Users/joregan/Downloads/CVPR_2022_Author_Kit%20(2).pdf

hungarian-algorithm/hungarian_algorithm/algorithm.py at master ¬∑ benchaplin/hungarian-algorithm
https://github.com/benchaplin/hungarian-algorithm/blob/master/hungarian_algorithm/algorithm.py

Generating Diverse and Natural 3D Human Motions from Texts
https://ericguo5513.github.io/text-to-motion/

EricGuo5513/HumanML3D: HumanML3D: A large and diverse 3d human motion-language dataset.
https://github.com/EricGuo5513/HumanML3D?tab=readme-ov-file

Action2Motion: Conditioned Generation of 3D Human Motions
https://ericguo5513.github.io/action-to-motion/#data

F5-TTS/src/f5_tts/infer/utils_infer.py at main ¬∑ SWivid/F5-TTS
https://github.com/SWivid/F5-TTS/blob/main/src/f5_tts/infer/utils_infer.py#L293

whisperX/whisperx/transcribe.py at main ¬∑ m-bain/whisperX
https://github.com/m-bain/whisperX/blob/main/whisperx/transcribe.py#L141

Incorporating Spatial Awareness in Data-Driven Gesture Generation for Virtual Agents
https://dl.acm.org/doi/pdf/10.1145/3652988.3673936

3_meta_files - Google Drive
https://drive.google.com/drive/u/4/folders/1ZWfIIgy30asG5scrYMh6ny_T8ofEiOSb

Torchvision NMS Error Fix
https://chatgpt.com/c/680f7f6f-ca38-8011-910c-566daeebe01b

inference-cli.py ¬∑ mrfakename/E2-F5-TTS at main
https://huggingface.co/spaces/mrfakename/E2-F5-TTS/blob/main/inference-cli.py

raw.githubusercontent.com/SWivid/F5-TTS/refs/heads/main/src/f5_tts/infer/infer_cli.py
https://raw.githubusercontent.com/SWivid/F5-TTS/refs/heads/main/src/f5_tts/infer/infer_cli.py

Modify script for batch synthesis
https://chatgpt.com/c/680f9bb8-c1dc-8011-9ed1-4002f80b1e52

The command to pass specific gpu ids to docker run command needs gpu ids in quotes ¬∑ Issue #11010 ¬∑ docker/docs
https://github.com/docker/docs/issues/11010

GroundingGPT/lego/serve/cli.py at main ¬∑ lzw-lzw/GroundingGPT
https://github.com/lzw-lzw/GroundingGPT/blob/main/lego/serve/cli.py

lzw-lzw/GroundingGPT: [ACL 2024] GroundingGPT: Language-Enhanced Multi-modal Grounding Model
https://github.com/lzw-lzw/GroundingGPT?tab=readme-ov-file

lzw-lzw/GroundingGPT: [ACL 2024] GroundingGPT: Language-Enhanced Multi-modal Grounding Model
https://github.com/lzw-lzw/GroundingGPT

Clarifying Demonstrative Usage
https://chatgpt.com/c/680fb4d1-2e94-8011-afb4-19eae4d1bbee

Grounding gpt by jimregan ¬∑ Pull Request #3 ¬∑ jimregan/dockerfiles
https://github.com/jimregan/dockerfiles/pull/3

Loop by jimregan ¬∑ Pull Request #5 ¬∑ jimregan/dockerfiles
https://github.com/jimregan/dockerfiles/pull/3

Exophoric Reference Correction
https://chatgpt.com/c/680fd19d-096c-8011-b01f-3a4a2f269dd8

Irish Pronunciation Database: foighne
https://www.teanglann.ie/en/fuaim/foighne

tmux list sessions - Google Search
https://www.google.com/search?q=tmux+list+sessions&rlz=1C5GCCM_en&oq=tmux+lis&gs_lcrp=EgZjaHJvbWUqBwgAEAAYgAQyBwgAEAAYgAQyBggBEEUYOTIHCAIQABiABDIHCAMQABiABDIHCAQQABiABDIHCAUQABiABDIHCAYQABiABDIHCAcQABiABDIHCAgQABiABDIHCAkQABiABNIBCDIwNjdqMGo3qAIAsAIA&sourceid=chrome&ie=UTF-8

m-bain/whisperX: WhisperX: Automatic Speech Recognition with Word-level Timestamps (& Diarization)
https://github.com/m-bain/whisperX

munkres ‚Äî Munkres implementation for Python
https://software.clapper.org/munkres/

yhw-yhw/TalkSHOW: This is the official repository for TalkSHOW: Generating Holistic 3D Human Motion from Speech [CVPR2023].
https://github.com/yhw-yhw/TalkSHOW/tree/main

Generating Holistic 3D Human Motion from Speech
https://www.computer.org/csdl/proceedings-article/cvpr/2023/012900a469/1POUpiEzI3K

CrowdMoGen: Zero-Shot Text-Driven Collective Motion Generation
https://arxiv.org/html/2407.06188v1#bib.bib45

CVPR 2021 Open Access Repository
https://openaccess.thecvf.com/content/CVPR2021/html/Punnakkal_BABEL_Bodies_Action_and_Behavior_With_English_Labels_CVPR_2021_paper.html

jihoonerd/Robust-Motion-In-betweening: üìñ Paper: Robust Motion In-betweening üèÉ
https://github.com/jihoonerd/Robust-Motion-In-betweening

The KIT Motion-Language Dataset | Big Data
https://www.liebertpub.com/doi/abs/10.1089/big.2016.0028

1607.03827
https://arxiv.org/pdf/1607.03827

EricGuo5513/HumanML3D: HumanML3D: A large and diverse 3d human motion-language dataset.
https://github.com/EricGuo5513/HumanML3D

CBT Steps Overview
https://chatgpt.com/c/67e93d80-421c-8011-8747-7294f0cf4cbb

KIT Motion-Language Dataset
https://motion-annotation.humanoids.kit.edu/dataset/

KIT Whole-Body Human Motion Database
https://motion-database.humanoids.kit.edu/list/datasets/

Carnegie Mellon University - CMU Graphics Lab - motion capture library
https://mocap.cs.cmu.edu/

MMMCore: Main Page
https://sw.pages.h2t.iar.kit.edu/mmm/core/index.html

Software / Master Motor Map / Core ¬∑ GitLab
https://git.h2t.iar.kit.edu/sw/mmm/core

Generating Diverse and Natural 3D Human Motions from Texts
https://ericguo5513.github.io/text-to-motion/

Prime Video: Kneecap
https://www.primevideo.com/region/eu/detail/0Q4COZS04SY6XSG1J5EEINF2X1/ref=atv_sr_fle_c_srce7a38_1_1_1?pageTypeId=B0DPTP4LHZ&workflowType=Commerce-TVOD&qid=1746010927906&pageTypeIdSource=ASIN&sr=1-1

yhw-yhw/TalkSHOW: This is the official repository for TalkSHOW: Generating Holistic 3D Human Motion from Speech [CVPR2023].
https://github.com/yhw-yhw/TalkSHOW?tab=readme-ov-file

TALKSHOW
https://talkshow.is.tue.mpg.de/

pyrender/examples/models at master ¬∑ mmatl/pyrender
https://github.com/mmatl/pyrender/tree/master/examples/models

EvelynFan/FaceFormer: [CVPR 2022] FaceFormer: Speech-Driven 3D Facial Animation with Transformers
https://github.com/EvelynFan/FaceFormer

Aaa - Google Drive
https://drive.google.com/drive/u/0/folders/1q2CGIniYAY8skB-40aTEyHYkCrPim34p

yhw-yhw/TalkSHOW: This is the official repository for TalkSHOW: Generating Holistic 3D Human Motion from Speech [CVPR2023].
https://github.com/yhw-yhw/TalkSHOW?tab=readme-ov-file

2212.04420
https://arxiv.org/pdf/2212.04420

camenduru/BEAT: A Large-Scale Semantic and Emotional Multi-Modal Dataset for Conversational Gestures Synthesis [ECCV 2022]
https://github.com/camenduru/BEAT?tab=readme-ov-file

EMAGE
https://pantomatrix.github.io/EMAGE/

2401.00374
https://arxiv.org/pdf/2401.00374

EMAGE_ZIP - Google Drive
https://drive.google.com/drive/folders/1ukbifhHc85qWTzspEgvAxCXwn9mK4ifr

EMAGE_ZIP - Google Drive
https://drive.google.com/drive/folders/1ukbifhHc85qWTzspEgvAxCXwn9mK4ifr

BEAT: A Large-Scale Semantic and Emotional Multi-Modal Dataset for Conversational Gestures Synthesis
https://pantomatrix.github.io/BEAT/

EricGuo5513/HumanML3D: HumanML3D: A large and diverse 3d human motion-language dataset.
https://github.com/EricGuo5513/HumanML3D?tab=readme-ov-file

[2303.14613] GestureDiffuCLIP: Gesture Diffusion Model with CLIP Latents
https://arxiv.org/abs/2303.14613

[2401.06071] GroundingGPT:Language Enhanced Multi-modal Grounding Model
https://arxiv.org/abs/2401.06071

[1712.05474] AI2-THOR: An Interactive 3D Environment for Visual AI
https://arxiv.org/abs/1712.05474

EMAGE
https://pantomatrix.github.io/EMAGE/

Talking With Hands 16.2M: A Large-Scale Dataset of Synchronized Body-Finger Motion and Audio for Conversational Motion Analysis and Synthesis
https://openaccess.thecvf.com/content_ICCV_2019/papers/Lee_Talking_With_Hands_16.2M_A_Large-Scale_Dataset_of_Synchronized_Body-Finger_ICCV_2019_paper.pdf

[2410.06885] F5-TTS: A Fairytaler that Fakes Fluent and Faithful Speech with Flow Matching
https://arxiv.org/abs/2410.06885

SWivid/F5-TTS: Official code for "F5-TTS: A Fairytaler that Fakes Fluent and Faithful Speech with Flow Matching"
https://github.com/SWivid/F5-TTS

[2312.16051] Inter-X: Towards Versatile Human-Human Interaction Analysis
https://arxiv.org/abs/2312.16051

ChatGPT
https://chatgpt.com/

[2310.08580] OmniControl: Control Any Joint at Any Time for Human Motion Generation
https://arxiv.org/abs/2310.08580

OmniControl/environment.yml at main ¬∑ neu-vi/OmniControl
https://github.com/neu-vi/OmniControl/blob/main/environment.yml

neu-vi/OmniControl: OmniControl: Control Any Joint at Any Time for Human Motion Generation, ICLR 2024
https://github.com/neu-vi/OmniControl/tree/main?tab=readme-ov-file

OmniControl/eval_omnicontrol.sh at main ¬∑ neu-vi/OmniControl
https://github.com/neu-vi/OmniControl/blob/main/eval_omnicontrol.sh

EricGuo5513/HumanML3D: HumanML3D: A large and diverse 3d human motion-language dataset.
https://github.com/EricGuo5513/HumanML3D

EricGuo5513/HumanML3D: HumanML3D: A large and diverse 3d human motion-language dataset.
https://github.com/EricGuo5513/HumanML3D

openai/guided-diffusion
https://github.com/openai/guided-diffusion

sigal-raab/MoDi: Unconditional Motion Synthesis from Diverse Data
https://github.com/sigal-raab/MoDi

wangsen1312/joints2smpl: fit smpl parameters model using 3D joints
https://github.com/wangsen1312/joints2smpl

Mathux/ACTOR: Official Pytorch implementation of the paper "Action-Conditioned 3D Human Motion Synthesis with Transformer VAE", ICCV 2021
https://github.com/Mathux/ACTOR

EricGuo5513/text-to-motion: Official implementation for "Generating Diverse and Natural 3D Human Motions from Texts (CVPR2022)."
https://github.com/EricGuo5513/text-to-motion

GuyTevet/MotionCLIP: Official Pytorch implementation of the paper "MotionCLIP: Exposing Human Motion Generation to CLIP Space"
https://github.com/GuyTevet/MotionCLIP

ChenFengYe/motion-latent-diffusion: [CVPR 2023] Executing your Commands via Motion Diffusion in Latent Space, a fast and high-quality motion diffusion model
https://github.com/ChenFengYe/motion-latent-diffusion

Mathux/TEMOS: Official PyTorch implementation of the paper "TEMOS: Generating diverse human motions from textual descriptions", ECCV 2022 (Oral)
https://github.com/Mathux/TEMOS

GuyTevet/motion-diffusion-model: The official PyTorch implementation of the paper "Human Motion Diffusion Model"
https://github.com/GuyTevet/motion-diffusion-model

Mathux/ACTOR: Official Pytorch implementation of the paper "Action-Conditioned 3D Human Motion Synthesis with Transformer VAE", ICCV 2021
https://github.com/Mathux/ACTOR

how to use conda install environment.yml package? ¬∑ Issue #3417 ¬∑ conda/conda
https://github.com/conda/conda/issues/3417


