2023.sigtyp-1.20.pdf
https://aclanthology.org/2023.sigtyp-1.20.pdf

Submitted to INTERSPEECH
https://arxiv.org/pdf/2305.13629.pdf

Submitted to INTERSPEECH
https://arxiv.org/pdf/2305.14546.pdf

Submitted to INTERSPEECH
https://arxiv.org/pdf/2305.12459.pdf

2305.10763.pdf
https://arxiv.org/pdf/2305.10763.pdf

Submitted to INTERSPEECH
https://arxiv.org/pdf/2305.05084.pdf

THE HARPY SPEECH RECOGNITION SYSTEM
https://stacks.stanford.edu/file/druid:rq916rn6924/rq916rn6924.pdf

A brief history of speech recognition | Sonix
https://sonix.ai/history-of-speech-recognition#:~:text=In%201952%2C%20Bell%20Laboratories%20designed,could%20recognize%20sound%20and%20speech.

azu_etd_17345_sip1_m.pdf
https://repository.arizona.edu/bitstream/handle/10150/634249/azu_etd_17345_sip1_m.pdf?sequence=1

ADA013808.pdf
https://apps.dtic.mil/sti/pdfs/ADA013808.pdf

IEEE Xplore Full-Text PDF:
https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6031408

azu_etd_17345_sip1_m.pdf
https://repository.arizona.edu/bitstream/handle/10150/634249/azu_etd_17345_sip1_m.pdf?sequence=1

htkbook.pdf
https://www.danielpovey.com/files/htkbook.pdf

conformer/README.md at main ¬∑ sooftware/conformer ¬∑ GitHub
https://github.com/sooftware/conformer/blob/main/README.md

openspeech-team/openspeech: Open-Source Toolkit for End-to-End Speech Recognition leveraging PyTorch-Lightning and Hydra.
https://github.com/openspeech-team/openspeech

2206.00888.pdf
https://arxiv.org/pdf/2206.00888.pdf

2005.03191.pdf
https://arxiv.org/pdf/2005.03191.pdf

ContextNet ‚Äî Openspeech v0.3.0 documentation
https://openspeech-team.github.io/openspeech/architectures/ContextNet.html

openspeech/model.py at main ¬∑ openspeech-team/openspeech ¬∑ GitHub
https://github.com/openspeech-team/openspeech/blob/main/openspeech/models/squeezeformer/model.py

2005.08100.pdf
https://arxiv.org/pdf/2005.08100.pdf

Sequence-to-Sequence Speech Recognition with Time-Depth Separable Convolutions
https://www.isca-speech.org/archive_v0/Interspeech_2019/pdfs/2460.pdf

add description for g2p.py ¬∑ Takaaki-Saeki/zm-text-tts@e3ca681
https://github.com/Takaaki-Saeki/zm-text-tts/commit/e3ca6811992dd88169761b26b5b9e87cbfa2dd38

Translatotron 3: Speech to Speech Translation with Monolingual Data
https://google-research.github.io/lingvo-lab/translatotron3/

jbeskow/tuben: Tube model of vocal tract - resonance frequency estimation
https://github.com/jbeskow/tuben

gestdiff_eval/makevids.py at master ¬∑ jbeskow/gestdiff_eval ¬∑ GitHub
https://github.com/jbeskow/gestdiff_eval/blob/master/sg23/makevids.py

jbeskow/lrc2vid
https://github.com/jbeskow/lrc2vid

The Illustrated Transformer ‚Äì Jay Alammar ‚Äì Visualizing machine learning one concept at a time.
https://jalammar.github.io/illustrated-transformer/

The Illustrated Transformer ‚Äì Jay Alammar ‚Äì Visualizing machine learning one concept at a time.
https://jalammar.github.io/illustrated-transformer/

The Annotated Transformer
http://nlp.seas.harvard.edu/annotated-transformer/

enhuiz/vall-e: An unofficial PyTorch implementation of the audio LM VALL-E
https://github.com/enhuiz/vall-e

facebookresearch/encodec: State-of-the-art deep learning based audio codec supporting both mono 24 kHz audio and stereo 48 kHz audio.
https://github.com/facebookresearch/encodec

encodec/encodec/msstftd.py at main ¬∑ facebookresearch/encodec ¬∑ GitHub
https://github.com/facebookresearch/encodec/blob/main/encodec/msstftd.py

SoundStorm: Efficient Parallel Audio Generation
https://arxiv.org/pdf/2305.09636.pdf

language/language at master ¬∑ google-research/language ¬∑ GitHub
https://github.com/google-research/language/tree/master/language

google-research/language-table: Suite of human-collected datasets and a multi-task continuous control benchmark for open vocabulary visuolinguomotor learning.
https://github.com/google-research/language-table

jimregan/wolnelektury-speech-corpus at w2v2-json
https://github.com/jimregan/wolnelektury-speech-corpus/tree/w2v2-json

Diverged main by jimregan ¬∑ Pull Request #45 ¬∑ jimregan/wolnelektury-speech-corpus
https://github.com/jimregan/wolnelektury-speech-corpus/pull/45/commits/237d70989d84b649dca095e90c3e18d9748647aa

Huy Ha on Twitter: "How can we put robotics on the same scaling trend as large language models while not compromising on rich low-level manipulation and control? https://t.co/2ZG5N4hp6L" / X
https://twitter.com/haqhuy/status/1684967184517275655

RT-2: New model translates vision and language into action
https://www.deepmind.com/blog/rt-2-new-model-translates-vision-and-language-into-action

Michael Pyrczüåª on Twitter: "Many people struggle to understand #Bayesian updating! So I made this super cool #Python @matplotlib #educational, interactive dashboard. Given a positive test, '+', what is the probability that the an 'Event' is happening? Change the probability of the event, P(Event), true‚Ä¶ https://t.co/emiQNzux4S" / X
https://twitter.com/GeostatsGuy/status/1684920034542411776

PaLI: Scaling Language-Image Learning in 100+ Languages ‚Äì Google Research Blog
https://ai.googleblog.com/2022/09/pali-scaling-language-image-learning-in.html

google/mt5-small at main
https://huggingface.co/google/mt5-small/tree/main

google (Google)
https://huggingface.co/google

google/matcha-base ¬∑ Hugging Face
https://huggingface.co/google/matcha-base

google/matcha-chart2text-pew ¬∑ Hugging Face
https://huggingface.co/google/matcha-chart2text-pew

google/flan-t5-xxl ¬∑ Hugging Face
https://huggingface.co/google/flan-t5-xxl

google/matcha-plotqa-v2 ¬∑ Hugging Face
https://huggingface.co/google/matcha-plotqa-v2

google/fleurs ¬∑ Datasets at Hugging Face
https://huggingface.co/datasets/google/fleurs/viewer/ga_ie/train

google/umt5-base ¬∑ Hugging Face
https://huggingface.co/google/umt5-base

google/pix2struct-widget-captioning-base ¬∑ Hugging Face
https://huggingface.co/google/pix2struct-widget-captioning-base

google/flan-ul2 ¬∑ Hugging Face
https://huggingface.co/google/flan-ul2

swda ¬∑ Datasets at Hugging Face
https://huggingface.co/datasets/swda

cgpotts/swda: Switchboard Dialog Act Corpus with Penn Treebank links
https://github.com/cgpotts/swda

calhoun.pdf
https://web.stanford.edu/~jurafsky/calhoun.pdf

Meta Research
https://github.com/orgs/facebookresearch/repositories?type=all

facebookresearch/EasyComDataset: The Easy Communications (EasyCom) dataset is a world-first dataset designed to help mitigate the *cocktail party effect* from an augmented-reality (AR) -motivated multi-sensor egocentric world view.
https://github.com/facebookresearch/EasyComDataset

facebookresearch/Ego4d: Ego4d dataset repository. Download the dataset, visualize, extract features & example usage of the dataset
https://github.com/facebookresearch/Ego4d

facebookresearch/segment-anything: The repository provides code for running inference with the SegmentAnything Model (SAM), links for downloading the trained model checkpoints, and example notebooks that show how to use the model.
https://github.com/facebookresearch/segment-anything

fairseq/fairseq at main ¬∑ facebookresearch/fairseq
https://github.com/facebookresearch/fairseq/tree/main/fairseq

jimregan (Jim O'Regan)
https://huggingface.co/jimregan

nst_swedish_tts.py ¬∑ jimregan/nst_swedish_tts at main
https://huggingface.co/datasets/jimregan/nst_swedish_tts/blob/main/nst_swedish_tts.py

Switchboard-1 Release 2 - Linguistic Data Consortium
https://catalog.ldc.upenn.edu/LDC97S62

We-All-Have-A-Secret.jpg (728√ó728)
https://funfactsfordays.com/wp-content/uploads/2023/05/We-All-Have-A-Secret.jpg

Dreaming Tulpa ü•ìüëë on Twitter: "Voice cloning is getting scary. HierVST is zero-shot voice transfer system without any text transcripts. That means it is able to transfer the voice style of a target speaker to a source speaker without any training data from the target speaker. https://t.co/Qc7oC4YDFC https://t.co/iUTITJcTsv" / X
https://twitter.com/dreamingtulpa/status/1686649903525584896

HierVST Demo
https://hiervst.github.io/

mshukor/UnIVAL: Official implementation of UnIVAL: Unified Model for Image, Video, Audio and Language Tasks.
https://github.com/mshukor/UnIVAL#datasets-and-checkpoints

UnIVAL
https://unival-model.github.io/

ASRfromScratch.ipynb - Colaboratory
https://colab.research.google.com/drive/1aFgzrUv3udM_gNJNUoLaHIm78QHtxdIz?usp=sharing#scrollTo=b3tnXnrWc2My

K2 interface for speechbrain by geoph9 ¬∑ Pull Request #2065 ¬∑ speechbrain/speechbrain
https://github.com/speechbrain/speechbrain/pull/2065/commits/111f6d672982b6ef6a31cf990744bb2ba683703a

Pull requests ¬∑ speechbrain/speechbrain
https://github.com/speechbrain/speechbrain/pulls?page=2&q=is%3Apr+is%3Aopen

ResNet speaker recognition by underdogliu ¬∑ Pull Request #2090 ¬∑ speechbrain/speechbrain
https://github.com/speechbrain/speechbrain/pull/2090

[WIP] Gpt2 finetuning by poonehmousavi ¬∑ Pull Request #2086 ¬∑ speechbrain/speechbrain
https://github.com/speechbrain/speechbrain/pull/2086/files

budzianowski/multiwoz: Source code for end-to-end dialogue model from the MultiWOZ paper (Budzianowski et al. 2018, EMNLP)
https://github.com/budzianowski/multiwoz

salesforce/DialogStudio: DialogStudio: Towards Richest and Most Diverse Unified Dataset Collection and Instruction-Aware Models for Conversational AI
https://github.com/salesforce/DialogStudio

Pull requests ¬∑ speechbrain/speechbrain
https://github.com/speechbrain/speechbrain/pulls?page=2&q=is%3Apr+is%3Aclosed

Implementation of the Branchformer (code from Samsung AI Cambridge) by TParcollet ¬∑ Pull Request #1992 ¬∑ speechbrain/speechbrain
https://github.com/speechbrain/speechbrain/pull/1992/files#diff-6f92976b49672b44341bd28893103f39c3059bb99c702a881e39d15e229f5e07

Conformer Transducer Librispeech (Contribution from Samsung AI Cambridge) by TParcollet ¬∑ Pull Request #1782 ¬∑ speechbrain/speechbrain
https://github.com/speechbrain/speechbrain/pull/1782

HyperConformer by florianmai ¬∑ Pull Request #1905 ¬∑ speechbrain/speechbrain
https://github.com/speechbrain/speechbrain/pull/1905

Integrating Pruned Fast RNNT with Transducer + new recipe for mTEDx dataset by Anwarvic ¬∑ Pull Request #1465 ¬∑ speechbrain/speechbrain
https://github.com/speechbrain/speechbrain/pull/1465

k2-fsa/fast_rnnt: A torch implementation of a recursion which turns out to be useful for RNN-T.
https://github.com/k2-fsa/fast_rnnt/tree/master

Add `cspell` by calvinballing ¬∑ Pull Request #1353 ¬∑ speechbrain/speechbrain
https://github.com/speechbrain/speechbrain/pull/1353

[WIP] Support for full-inference recipe tests by mravanelli ¬∑ Pull Request #2091 ¬∑ speechbrain/speechbrain
https://github.com/speechbrain/speechbrain/pull/2091

add documentation for HF API testing by TParcollet ¬∑ Pull Request #2089 ¬∑ speechbrain/speechbrain
https://github.com/speechbrain/speechbrain/pull/2089

speechbrain/recipes at develop ¬∑ speechbrain/speechbrain
https://github.com/speechbrain/speechbrain/tree/develop/recipes

speechbrain/recipes/TIMIT/timit_prepare.py at develop ¬∑ speechbrain/speechbrain
https://github.com/speechbrain/speechbrain/blob/develop/recipes/TIMIT/timit_prepare.py

speechbrain/recipes/IWSLT22_lowresource at develop ¬∑ speechbrain/speechbrain
https://github.com/speechbrain/speechbrain/tree/develop/recipes/IWSLT22_lowresource

speechbrain/recipes/CommonVoice at develop ¬∑ speechbrain/speechbrain
https://github.com/speechbrain/speechbrain/tree/develop/recipes/CommonVoice

librispeech ¬∑ speechbrain/speechbrain@15f77dd
https://github.com/speechbrain/speechbrain/commit/15f77dd4efd15da62f0c749dbcaa64308af51e03

ResNet speaker recognition by underdogliu ¬∑ Pull Request #2090 ¬∑ speechbrain/speechbrain
https://github.com/speechbrain/speechbrain/pull/2090

Bayesian ASR by lucadellalib ¬∑ Pull Request #1864 ¬∑ speechbrain/speechbrain
https://github.com/speechbrain/speechbrain/pull/1864

[WIP] FlexFormer with new dynamic mixing by MartinKocour ¬∑ Pull Request #1816 ¬∑ speechbrain/speechbrain
https://github.com/speechbrain/speechbrain/pull/1816

threshold SpeakerRecognition by joshipunitram ¬∑ Pull Request #1767 ¬∑ speechbrain/speechbrain
https://github.com/speechbrain/speechbrain/pull/1767

OpenNMT/CTranslate2: Fast inference engine for Transformer models
https://github.com/OpenNMT/CTranslate2

Fairseq ‚Äî CTranslate2 3.17.1 documentation
https://opennmt.net/CTranslate2/guides/fairseq.html

OpenNMT/OpenNMT-py: Open Source Neural Machine Translation and (Large) Language Models in PyTorch
https://github.com/OpenNMT/OpenNMT-py

Messenger
https://www.messenger.com/t/100000439761967

Home / X
https://twitter.com/home

Gpt-ouijia-board-/README.md at main ¬∑ jconorgrogan/Gpt-ouijia-board-
https://github.com/jconorgrogan/Gpt-ouijia-board-/blob/main/README.md

Audio samples from "Learning to speak fluently in a foreign language: Multilingual speech synthesis and cross-language voice cloning"
https://google.github.io/tacotron/publications/multilingual/

deterministic-algorithms-lab/Cross-Lingual-Voice-Cloning: Tacotron 2 - PyTorch implementation with faster-than-realtime inference modified to enable cross lingual voice cloning.
https://github.com/deterministic-algorithms-lab/Cross-Lingual-Voice-Cloning

Taskmaster PT S02 E01 (with English subtitles) : r/panelshows
https://www.reddit.com/r/panelshows/comments/14ov6w1/taskmaster_pt_s02_e01_with_english_subtitles/

Taskmaster_PT_S02_E01.mkv - Google Drive
https://drive.google.com/file/d/1a4Ds80P3pnfOsTC6f7t2Ra7E_Djum337/view

Paper page - MC-JEPA: A Joint-Embedding Predictive Architecture for Self-Supervised Learning of Motion and Content Features
https://huggingface.co/papers/2307.12698?s=09

mozilla/DSAlign: DeepSpeech based forced alignment tool
https://github.com/mozilla/DSAlign

NeMo-text-processing/nemo_text_processing/text_normalization/ga/taggers at irish-tn2 ¬∑ jimregan/NeMo-text-processing
https://github.com/jimregan/NeMo-text-processing/tree/irish-tn2/nemo_text_processing/text_normalization/ga/taggers

NeMo-text-processing/nemo_text_processing/text_normalization/ga/taggers/fraction.py at irish-tn2 ¬∑ jimregan/NeMo-text-processing
https://github.com/jimregan/NeMo-text-processing/blob/irish-tn2/nemo_text_processing/text_normalization/ga/taggers/fraction.py

asr-augmentation/src/cpt/run_wav2vec2_pretraining_no_trainer.py at main ¬∑ Bartelds/asr-augmentation
https://github.com/Bartelds/asr-augmentation/blob/main/src/cpt/run_wav2vec2_pretraining_no_trainer.py

bartelds/gos-demo ¬∑ Datasets at Hugging Face
https://huggingface.co/datasets/bartelds/gos-demo/viewer/bartelds--gos-demo/train

2207.02971.pdf
https://arxiv.org/pdf/2207.02971.pdf

2108.09084.pdf
https://arxiv.org/pdf/2108.09084.pdf

Fastformer/Fastformer.ipynb at main ¬∑ wuch15/Fastformer
https://github.com/wuch15/Fastformer/blob/main/Fastformer.ipynb

text processing - Show all the file up to the match - Unix & Linux Stack Exchange
https://unix.stackexchange.com/questions/11305/show-all-the-file-up-to-the-match

apple lasagna - Google Search
https://www.google.com/search?q=apple+lasagna&rlz=1C5GCEM_enSE990SE991&oq=apple+lasa&gs_lcrp=EgZjaHJvbWUqCggAEAAY4wIYgAQyCggAEAAY4wIYgAQyBwgBEC4YgAQyBwgCEAAYgAQyBggDEEUYOTIICAQQABgWGB4yCAgFEAAYFhgeMggIBhAAGBYYHjIICAcQABgWGB4yCAgIEAAYFhgeMggICRAAGBYYHtIBCDM3NjJqMGo5qAIAsAIA&sourceid=chrome&ie=UTF-8

Plain Hungarian (@plainhungarian) ‚Ä¢ Instagram photos and videos
https://www.instagram.com/plainhungarian/

Instagram
https://www.instagram.com/

Desh Raj on Twitter: "10 years ago, WFST-based methods were the norm for speech processing (think, Kaldi). Since then, end-to-end models have become quite the rage --- they are simple, do not require much domain expertise, and you can train a PyTorch model for a new task over a weekend. ‚ö°Ô∏è 1/n" / X
https://twitter.com/rdesh26/status/1687387338542809088

src/corpora/multilingual_librispeech.jl ¬∑ main ¬∑ FAST / SpeechCorpora.jl ¬∑ GitLab
https://gitlab.lisn.upsaclay.fr/fast/speechcorpora.jl/-/blob/main/src/corpora/multilingual_librispeech.jl

Final: Automatic design of conversational models from observation of human-to-human conversation - YouTube
https://www.youtube.com/watch?v=QS5zXkpXV3Q&t=2832s

JSALT Workshop Programme - JSALT2023
https://jsalt2023.univ-lemans.fr/en/jsalt-workshop-programme.html

Ss - Google Drive
https://drive.google.com/drive/u/1/folders/152z06OaUyBO0CsfgtOc8kaEECd2Ht-zT

Jim O'Regan | Flickr
https://www.flickr.com/photos/jimregan/?

icefall/egs at master ¬∑ k2-fsa/icefall
https://github.com/k2-fsa/icefall/tree/master/egs

k2-fsa/icefall
https://github.com/k2-fsa/icefall

k2-fsa/k2: FSA/FST algorithms, differentiable, with PyTorch compatibility.
https://github.com/k2-fsa/k2

snowfall/egs/librispeech/asr/simple_v1 at master ¬∑ k2-fsa/snowfall
https://github.com/k2-fsa/snowfall/tree/master/egs/librispeech/asr/simple_v1

snowfall/egs/librispeech/asr/simple_v1/mmi_mbr_decode.py at master ¬∑ k2-fsa/snowfall
https://github.com/k2-fsa/snowfall/blob/master/egs/librispeech/asr/simple_v1/mmi_mbr_decode.py

icefall/icefall at master ¬∑ k2-fsa/icefall
https://github.com/k2-fsa/icefall/tree/master/icefall

icefall/icefall/mmi_graph_compiler.py at master ¬∑ k2-fsa/icefall
https://github.com/k2-fsa/icefall/blob/master/icefall/mmi_graph_compiler.py

icefall/egs/timit/ASR at master ¬∑ k2-fsa/icefall
https://github.com/k2-fsa/icefall/tree/master/egs/timit/ASR

Non Streaming ASR ‚Äî icefall 0.1 documentation
https://icefall.readthedocs.io/en/latest/recipes/Non-streaming-ASR/index.html

TDNN-LSTM-CTC ‚Äî icefall 0.1 documentation
https://icefall.readthedocs.io/en/latest/recipes/Non-streaming-ASR/timit/tdnn_lstm_ctc.html

icefall-asr-timit-pretrained-tdnn-lstm-ctc-usage.ipynb - Colaboratory
https://colab.research.google.com/drive/1Hs9DA4V96uapw_30uNp32OMJgkuR5VVd#scrollTo=puZt_92gtSIt

audio/torchaudio/csrc/forced_align at main ¬∑ pytorch/audio
https://github.com/pytorch/audio/tree/main/torchaudio/csrc/forced_align

Refactor wav2vec2 pipeline misc helper functions (#3527) ¬∑ pytorch/audio@09aabcc
https://github.com/pytorch/audio/commit/09aabcc16e8d5a2c0180a2ac3dc3d507b9dc65b2

lhotse-speech/lhotse: Tools for handling speech data in machine learning projects.
https://github.com/lhotse-speech/lhotse

Distillation with HuBERT ‚Äî icefall 0.1 documentation
https://icefall.readthedocs.io/en/latest/recipes/Non-streaming-ASR/librispeech/distillation.html

[2211.00508] Predicting Multi-Codebook Vector Quantization Indexes for Knowledge Distillation
https://arxiv.org/abs/2211.00508

Shallow fusion for Transducer ‚Äî icefall 0.1 documentation
https://icefall.readthedocs.io/en/latest/decoding-with-langugage-models/shallow-fusion.html

icefall/docker/torch1.13.0-cuda11.6.dockerfile at master ¬∑ k2-fsa/icefall
https://github.com/k2-fsa/icefall/blob/master/docker/torch1.13.0-cuda11.6.dockerfile

icefall/egs/spgispeech/ASR/pruned_transducer_stateless2/asr_datamodule.py at master ¬∑ k2-fsa/icefall
https://github.com/k2-fsa/icefall/blob/master/egs/spgispeech/ASR/pruned_transducer_stateless2/asr_datamodule.py

icefall/egs/ptb/LM/local/sort_lm_training_data.py at master ¬∑ k2-fsa/icefall
https://github.com/k2-fsa/icefall/blob/master/egs/ptb/LM/local/sort_lm_training_data.py

icefall/egs/must_c/ST at master ¬∑ k2-fsa/icefall
https://github.com/k2-fsa/icefall/tree/master/egs/must_c/ST

icefall/egs/libricss/SURT at master ¬∑ k2-fsa/icefall
https://github.com/k2-fsa/icefall/tree/master/egs/libricss/SURT

desh2608/icefall-asr-tedlium3-zipformer ¬∑ Hugging Face
https://huggingface.co/desh2608/icefall-asr-tedlium3-zipformer

Forced Alignment with Wav2Vec2 ‚Äî Torchaudio 2.0.1 documentation
https://pytorch.org/audio/stable/tutorials/forced_alignment_tutorial.html

Stockholm, Stockholm, Sweden Weather Forecast and Conditions - The Weather Channel | Weather.com
https://weather.com/weather/today/l/59.33,18.07?par=google

Stockholm Culture Festival in mid-August
https://www.visitnordic.com/en/attraction/stockholm-culture-festival

Drottningholm Palace Park | Visit Drottningholm Palace Park in Sweden
https://www.visitnordic.com/en/attraction/drottningholm-palace-park

Drottningholm Palace - Residence of the Royal Swedish Family
https://www.visitnordic.com/en/attraction/drottningholm-palace

Kulturfestivalen¬†‚Äì Program
https://kulturfestivalen.stockholm.se/program/

Kulturfestivalen - Monsterhjulet
https://kulturfestivalen.stockholm.se/programpunkt/monsterhjulet-med-fabula-storytelling/

Andrej Karpathy on Twitter: ""How is LLaMa.cpp possible?" great post by @finbarrtimbers https://t.co/yF43inlY87 llama.cpp surprised many people (myself included) with how quickly you can run large LLMs on small computers, e.g. 7B runs @ ~16 tok/s on a MacBook. Wait don't you need supercomputers to work‚Ä¶ https://t.co/EIp9iPkZ6x" / X
https://twitter.com/karpathy/status/1691571869051445433

Release 2.5.2 ¬∑ xenova/transformers.js
https://github.com/xenova/transformers.js/releases/tag/2.5.2

Tips for Writing NLP Papers. Over the years I‚Äôve developed a certain‚Ä¶ | by Vered Shwartz | Aug, 2023 | Medium
https://medium.com/@vered1986/tips-for-writing-nlp-papers-9c729a2f9e1f

Focl√≥ir Gaeilge‚ÄìB√©arla (√ì D√≥naill): orla
https://www.teanglann.ie/en/fgb/orla

SIGGRAPH 2023 Papers
https://kesen.realtimerendering.com/sig2023.html


