Amphion/models/tts/jets/alignments.py at main Â· open-mmlab/Amphion
https://github.com/open-mmlab/Amphion/blob/main/models/tts/jets/alignments.py

jets/espnet2/gan_tts/jets/alignments.py at main Â· imdanboy/jets
https://github.com/imdanboy/jets/blob/main/espnet2/gan_tts/jets/alignments.py

ggml/examples/yolo/yolov3-tiny.cpp at master Â· ggerganov/ggml
https://github.com/ggerganov/ggml/blob/master/examples/yolo/yolov3-tiny.cpp

Introduction to ggml
https://huggingface.co/blog/introduction-to-ggml

ggml : r/LocalLLaMA
https://www.reddit.com/r/LocalLLaMA/comments/12vo2rn/ggml/

Dataset release for EMNLP 2023 paper on reasoning with spatial preposâ€¦ Â· google-research/language@815bfe6
https://github.com/google-research/language/commit/815bfe68235d740c8d152330b7f05409921d7f9d

google-research/lasertagger
https://github.com/google-research/lasertagger?tab=readme-ov-file

1909.01187
https://arxiv.org/pdf/1909.01187

google-research-datasets/wiki-split: One million English sentences, each split into two sentences that together preserve the original meaning, extracted from Wikipedia edits.
https://github.com/google-research-datasets/wiki-split

google-research/structured-additive-IR
https://github.com/google-research/structured-additive-IR

Convert trained Keras models (.h5) to ONNX format. | by Ethan Sergy | Medium
https://medium.com/@sergyoubi/convert-trained-keras-models-h5-to-onnx-format-e25819bbf5dd

octra/libs/annotation/src/lib/annotjson.ts at 0449311377d6960e4cd23326acb7fbcefaded718 Â· IPS-LMU/octra
https://github.com/IPS-LMU/octra/blob/0449311377d6960e4cd23326acb7fbcefaded718/libs/annotation/src/lib/annotjson.ts

OCTRA app configuration Â· IPS-LMU/octra Wiki
https://github.com/IPS-LMU/octra/wiki/OCTRA-app-configuration

whisper.cpp/models at master Â· ggerganov/whisper.cpp
https://github.com/ggerganov/whisper.cpp/tree/master/models

whisper.cpp/models/convert-whisper-to-coreml.py at master Â· ggerganov/whisper.cpp
https://github.com/ggerganov/whisper.cpp/blob/master/models/convert-whisper-to-coreml.py

whisper.cpp/include/whisper.h at master Â· ggerganov/whisper.cpp
https://github.com/ggerganov/whisper.cpp/blob/master/include/whisper.h

huggingface/transformers: ðŸ¤— Transformers: State-of-the-art Machine Learning for Pytorch, TensorFlow, and JAX.
https://github.com/huggingface/transformers

transformers/src/transformers/models/wav2vec2/modeling_wav2vec2.py at main Â· huggingface/transformers
https://github.com/huggingface/transformers/blob/main/src/transformers/models/wav2vec2/modeling_wav2vec2.py

transformers/src/transformers/models/audio_spectrogram_transformer/modeling_audio_spectrogram_transformer.py at main Â· huggingface/transformers
https://github.com/huggingface/transformers/blob/main/src/transformers/models/audio_spectrogram_transformer/modeling_audio_spectrogram_transformer.py

transformers/src/transformers/models/t5 at main Â· huggingface/transformers
https://github.com/huggingface/transformers/tree/main/src/transformers/models/t5

transformers/src/transformers/models/byt5 at main Â· huggingface/transformers
https://github.com/huggingface/transformers/tree/main/src/transformers/models/byt5

transformers/src/transformers/models/wav2vec2_phoneme at main Â· huggingface/transformers
https://github.com/huggingface/transformers/tree/main/src/transformers/models/wav2vec2_phoneme

transformers/src/transformers/models/wav2vec2_bert/modeling_wav2vec2_bert.py at main Â· huggingface/transformers
https://github.com/huggingface/transformers/blob/main/src/transformers/models/wav2vec2_bert/modeling_wav2vec2_bert.py

transformers/src/transformers/models/wav2vec2_bert/modeling_wav2vec2_bert.py at main Â· huggingface/transformers
https://github.com/huggingface/transformers/blob/main/src/transformers/models/wav2vec2_bert/modeling_wav2vec2_bert.py

Models - Hugging Face
https://huggingface.co/models?other=base_model:finetune:facebook%2Fw2v-bert-2.0&p=3&sort=trending

Fine-Tune W2V2-Bert for low-resource ASR with ðŸ¤— Transformers
https://huggingface.co/blog/fine-tune-w2v2-bert

whisper.cpp/grammars/chess.gbnf at master Â· ggerganov/whisper.cpp
https://github.com/ggerganov/whisper.cpp/blob/master/grammars/chess.gbnf

pyf98/owsm_ctc_v3.1_1B Â· Hugging Face
https://huggingface.co/pyf98/owsm_ctc_v3.1_1B

ffmpeg subtitles and audio to video - Google Search
https://www.google.com/search?q=ffmpeg+subtitles+and+audio+to+video&rlz=1C5GCCM_en&oq=ffmpeg+subtitles+and+audio+to+video&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIHCAEQIRigATIHCAIQIRigAdIBCDkyNDdqMGo0qAIAsAIB&sourceid=chrome&ie=UTF-8

libass/libass: libass is a portable subtitle renderer for the ASS/SSA (Advanced Substation Alpha/Substation Alpha) subtitle format.
https://github.com/libass/libass?tab=readme-ov-file

Trying to use pocketsphinx to word align | notes
https://jimregan.github.io/notes/pocketsphinx/hsi/alignment/2024/10/06/pocketsphinx-align.html

x.com/ArxivSound/status/1835892798479798403
https://x.com/ArxivSound/status/1835892798479798403

2409.09543
https://arxiv.org/pdf/2409.09543

BUTSpeechFIT/TS-ASR-Whisper
https://github.com/BUTSpeechFIT/TS-ASR-Whisper

2406.12998
https://arxiv.org/pdf/2406.12998

SPARC
https://berkeley-speech-group.github.io/sparc-demo/

Vocal Tract Visualization github - Google Search
https://www.google.com/search?q=Vocal+Tract+Visualization+github&sca_esv=e936ada1b37f2909&rlz=1C5GCCM_en&sxsrf=ADLYWII1SVq2A9LsldLgrGGXvoWsXWXrFw%3A1730392828978&ei=_LIjZ5GoO-q9wPAPqsLi0AQ&ved=0ahUKEwiRlpLPh7mJAxXqHhAIHSqhGEoQ4dUDCBA&uact=5&oq=Vocal+Tract+Visualization+github&gs_lp=Egxnd3Mtd2l6LXNlcnAiIFZvY2FsIFRyYWN0IFZpc3VhbGl6YXRpb24gZ2l0aHViMgUQIRigAUjODFBlWJ8KcAF4AZABAJgBa6ABwASqAQM2LjG4AQPIAQD4AQGYAgigAt0EwgIKEAAYsAMY1gQYR8ICCBAAGIAEGKIEwgIHECEYoAEYCpgDAIgGAZAGCJIHAzcuMaAHhg4&sclient=gws-wiz-serp

megseekosh/vocal_tract_vowel: Triple vowel formant tracker, compute vocal tract length from formant measurements
https://github.com/megseekosh/vocal_tract_vowel?tab=readme-ov-file#acoustic-measurements

zakaton/Pink-Trombone: A programmable version of Neil Thapen's Pink Trombone
https://github.com/zakaton/Pink-Trombone

HidekiKawahara/SparkNG: MATLAB real-time/interactive speech tools. This series is obsolete. SP3ARK is the up-to-date series (will be).
https://github.com/HidekiKawahara/SparkNG

Voice-Lab/VoiceLab: Automated Reproducible Acoustical Analysis
https://github.com/Voice-Lab/VoiceLab

Web-based-vocoder/web-based-vocoder.github.io: This repository contains a simple vocoder that works with live input. The vocoder uses LPC coefficients to do voice transformations and/or visualization of the vocal tract in real-time. The output signal is synthesized with an overlap and add routine. The description of the project is organized in chapters. This demo works only with Chrome (the only browswer that supports Audio Worklets right now?)
https://github.com/Web-based-vocoder/web-based-vocoder.github.io?tab=readme-ov-file

VocalTractLab
https://www.vocaltractlab.de/index.php?page=vocaltractlab-download

Web-based-vocoder
https://github.com/Web-based-vocoder

Speech-Articulatory-Coding/sparc/block.py at main Â· Berkeley-Speech-Group/Speech-Articulatory-Coding
https://github.com/Berkeley-Speech-Group/Speech-Articulatory-Coding/blob/main/sparc/block.py

interactiveaudiolab/penn: Pitch Estimating Neural Networks (PENN)
https://github.com/interactiveaudiolab/penn

maxrmorrison/torchcrepe: Pytorch implementation of the CREPE pitch tracker
https://github.com/maxrmorrison/torchcrepe?tab=readme-ov-file

microsoft/MMdnn: MMdnn is a set of tools to help users inter-operate among different deep learning frameworks. E.g. model conversion and visualization. Convert models between Caffe, Keras, MXNet, Tensorflow, CNTK, PyTorch Onnx and CoreML.
https://github.com/microsoft/MMdnn?tab=readme-ov-file#conversion

Speech-Articulatory-Coding/setup.py at main Â· Berkeley-Speech-Group/Speech-Articulatory-Coding
https://github.com/Berkeley-Speech-Group/Speech-Articulatory-Coding/blob/main/setup.py

ml-explore/mlx: MLX: An array framework for Apple silicon
https://github.com/ml-explore/mlx?tab=readme-ov-file

ml-explore/mlx-examples: Examples in the MLX framework
https://github.com/ml-explore/mlx-examples

mlx Â· GitHub Topics
https://github.com/topics/mlx

abeleinin/Metal-Puzzles: Solve Puzzles. Learn Metal ðŸ¤˜
https://github.com/abeleinin/Metal-Puzzles?tab=readme-ov-file

Custom Metal Kernels â€” MLX 0.19.2 documentation
https://ml-explore.github.io/mlx/build/html/dev/custom_metal_kernels.html

(1) Awni Hannun on X: "RFP: request for port @srush_nlp GPU puzzles to Metal with MLX custom_kernels: https://t.co/ji2YRKEYJ5 Would be a great way to learn Metal / Apple GPU programming." / X
https://x.com/awnihannun/status/1833376670063202536

Memory management â€” Numba 0+untagged.871.g53e976f.dirty documentation
https://numba.readthedocs.io/en/stable/cuda/memory.html

srush/Tensor-Puzzles: Solve puzzles. Improve your pytorch.
https://github.com/srush/Tensor-Puzzles

Use soundfile instead of torchaudio. Â· lucasnewman/f5-tts-mlx@ca45c85
https://github.com/lucasnewman/f5-tts-mlx/commit/ca45c85ebbd3e503d291c2dade8e3fb2f03f2464

lucasnewman (lucasnewman) / Repositories
https://github.com/lucasnewman?tab=repositories

lucasnewman/descript-mlx: Implementation of the Descript Audio Codec in MLX
https://github.com/lucasnewman/descript-mlx

lucidrains/voicebox-pytorch: Implementation of Voicebox, new SOTA Text-to-speech network from MetaAI, in Pytorch
https://github.com/lucidrains/voicebox-pytorch?tab=readme-ov-file

e2-tts-pytorch/e2_tts_pytorch/e2_tts.py at main Â· lucidrains/e2-tts-pytorch
https://github.com/lucidrains/e2-tts-pytorch/blob/main/e2_tts_pytorch/e2_tts.py

lucasnewman (Lucas Newman)
https://github.com/lucasnewman

2107.10342
https://arxiv.org/pdf/2107.10342

2211.07292
https://arxiv.org/pdf/2211.07292

lucasnewman/spear-tts-pytorch: Implementation of Spear-TTS - multi-speaker text-to-speech attention network, in Pytorch
https://github.com/lucasnewman/spear-tts-pytorch?tab=readme-ov-file

Add trainers for the pretraining and backtranslation tasks by lucasnewman Â· Pull Request #4 Â· lucidrains/spear-tts-pytorch
https://github.com/lucidrains/spear-tts-pytorch/pull/4/files

lucasnewman (Lucas Newman)
https://github.com/lucasnewman

lucidrains (lucidrains) / Repositories
https://github.com/lucidrains?tab=repositories

lucidrains/nGPT-pytorch: Quick implementation of nGPT, learning entirely on the hypersphere, from NvidiaAI
https://github.com/lucidrains/nGPT-pytorch

lvsm-pytorch/lvsm_pytorch/lvsm.py at main Â· lucidrains/lvsm-pytorch
https://github.com/lucidrains/lvsm-pytorch/blob/main/lvsm_pytorch/lvsm.py

tree_attention/tree_shard_test.py at main Â· Zyphra/tree_attention
https://github.com/Zyphra/tree_attention/blob/main/tree_shard_test.py

spline-based-transformer/spline_based_transformer/spline_based_transformer.py at main Â· lucidrains/spline-based-transformer
https://github.com/lucidrains/spline-based-transformer/blob/main/spline_based_transformer/spline_based_transformer.py

lucidrains/x-transformers: A concise but complete full-attention transformer with a set of promising experimental features from various papers
https://github.com/lucidrains/x-transformers

lucidrains/audiolm-pytorch: Implementation of AudioLM, a SOTA Language Modeling Approach to Audio Generation out of Google Research, in Pytorch
https://github.com/lucidrains/audiolm-pytorch

WhenAvailable - Free Group Scheduling Tool
https://whenavailable.com/reply?sid=T5cX0Vw8yXpblq875eCX&invite=JLyX8fZXobdADtSgFqew

Phonetic transcription with HuggingFace | notes
https://jimregan.github.io/notes/phonetic/espeak/wav2vec2/huggingface/timestamps/2022/10/18/wav2vec2-phonetic-transcription.html

Getting timestamps on long audio | notes
https://jimregan.github.io/notes/long%20audio/wav2vec2/huggingface/timestamps/2022/03/08/getting-timestamps-on-long-audio-with-wav2vec2-and-huggingface.html

jimregan/wav2vec2-xls-r-300m-phoneme-timit Â· Hugging Face
https://huggingface.co/jimregan/wav2vec2-xls-r-300m-phoneme-timit

2410.22179
https://arxiv.org/pdf/2410.22179

Panelshow
https://www.reddit.com/r/panelshow/

Have I Got News For You S68E05 - Jo Brand, Nabil Abdulrashid and Tom Peck : r/panelshow
https://www.reddit.com/r/panelshow/comments/1ghh5vl/have_i_got_news_for_you_s68e05_jo_brand_nabil/

Getting timestamps on long audio | notes
https://jimregan.github.io/notes/long%20audio/wav2vec2/huggingface/timestamps/2022/03/08/getting-timestamps-on-long-audio-with-wav2vec2-and-huggingface.html

Phoneme Recognition with Wav2Vec2
https://www.kaggle.com/code/jimregan/phoneme-recognition-with-wav2vec2/notebook

DARPA TIMIT Acoustic-Phonetic Continuous Speech
https://www.kaggle.com/datasets/mfekadu/darpa-timit-acousticphonetic-continuous-speech

philipperemy/timit: The DARPA TIMIT Acoustic-Phonetic Continuous Speech Corpus.
https://github.com/philipperemy/timit

Extract a dictionary from MFA-aligned TextGrids | notes
https://jimregan.github.io/notes/textgrid/mfa/2021/10/15/extract-dictionary-from-mfa-textgrids.html

neuralcoref/neuralcoref/neuralcoref.pyx at master Â· huggingface/neuralcoref
https://github.com/huggingface/neuralcoref/blob/master/neuralcoref/neuralcoref.pyx

llama.cpp/examples/llava/README.md at master Â· ggerganov/llama.cpp
https://github.com/ggerganov/llama.cpp/blob/master/examples/llava/README.md

Overview Â· spaCy Universe
https://spacy.io/universe

Coreferee Â· spaCy Universe
https://spacy.io/universe/project/coreferee

2024-11-07-set-up-neuralcoref.ipynb - Colab
https://colab.research.google.com/drive/1MY5A-f3Nhj35ww4m_V-aXou6Dh6D7rkq#scrollTo=yKOYV_spC6PK

Set up neuralcoref | notes
https://jimregan.github.io/notes/neuralcoref/spacy/2024/11/07/set-up-neuralcoref.html

resuscitative, adj. meanings, etymology and more | Oxford English Dictionary
https://www.oed.com/dictionary/resuscitative_adj

jimregan/notes
https://github.com/jimregan/notes?tab=readme-ov-file

Using Matcha with a private repo | notes
https://jimregan.github.io/notes/matcha/english/private/hsi/2024/10/26/matcha-private-repo.html

Get data from Folkets Swedish-English | notes
https://jimregan.github.io/notes/folkets/swedish/pronunciation/2024/10/12/folkets.html

jupyter notebook persistence - Google Search
https://www.google.com/search?q=jupyter+notebook+persistence&rlz=1C5GCCM_en&oq=jupyter+persisten&gs_lcrp=EgZjaHJvbWUqCAgBEAAYFhgeMgYIABBFGDkyCAgBEAAYFhgeMg0IAhAAGIYDGIAEGIoFMg0IAxAAGIYDGIAEGIoFMg0IBBAAGIYDGIAEGIoFMg0IBRAAGIYDGIAEGIoFMg0IBhAAGIYDGIAEGIoFMgoIBxAAGIAEGKIEMgoICBAAGIAEGKIE0gEINDg3MGowajeoAgCwAgA&sourceid=chrome&ie=UTF-8

discourse.jupyter.org
https://discourse.jupyter.org/t/saving-state-or-sessions-in-jupyter-notebooks/3907

Persist â€” A JupyterLab Extension for Persistent Interactions
https://vdl.sci.utah.edu/blog/2024/05/29/persist/

Quickstart Tutorial | Persist
https://vdl.sci.utah.edu/persist/docs/getting-started/simple-tutorial

Example Gallery â€” Vega-Altair 5.5.0dev documentation
https://altair-viz.github.io/gallery/index.html#example-gallery

A High-Level Grammar of Interactive Graphics | Vega-Lite
https://vega.github.io/vega-lite/

yifanwu/b2: Bridging Code and Interactive Visualization in Computational Notebooks
https://github.com/yifanwu/b2?tab=readme-ov-file

yifanwu/midas-exp-pub
https://github.com/yifanwu/midas-exp-pub

agenda.infn.it
https://agenda.infn.it/event/31005/contributions/167438/attachments/96417/133850/Minio_jupyter_persistence.pdf

Blog/Audio normalization with FFmpeg - Forza's ramblings
https://wiki.tnonline.net/w/Blog/Audio_normalization_with_FFmpeg

Encountered a 404 error
https://sox.sourceforge.net/sox.html

Any way to make the volume the same across all video files? : r/PleX
https://www.reddit.com/r/PleX/comments/hg9een/any_way_to_make_the_volume_the_same_across_all/

AudioVolume â€“ FFmpeg
https://trac.ffmpeg.org/wiki/AudioVolume

slhck/ffmpeg-normalize: Audio Normalization for Python/ffmpeg
https://github.com/slhck/ffmpeg-normalize?tab=readme-ov-file#should-i-use-this-to-normalize-my-music-collection

audio - ffmpeg loudnorm 2pass in single line - Super User
https://superuser.com/questions/1312811/ffmpeg-loudnorm-2pass-in-single-line

slhck/ffmpeg-normalize: Audio Normalization for Python/ffmpeg
https://github.com/slhck/ffmpeg-normalize?tab=readme-ov-file

ffmpeg-normalize/ffmpeg_normalize/_ffmpeg_normalize.py at master Â· slhck/ffmpeg-normalize
https://github.com/slhck/ffmpeg-normalize/blob/master/ffmpeg_normalize/_ffmpeg_normalize.py

normalize audio of a directory ffmpeg - Google Search
https://www.google.com/search?q=normalize+audio+of+a+directory+ffmpeg&rlz=1C5GCCM_en&oq=normalize+audio+of+a+direc&gs_lcrp=EgZjaHJvbWUqCQgBECEYChigATIGCAAQRRg5MgkIARAhGAoYoAEyCQgCECEYChigATIJCAMQIRgKGKAB0gEINzU4NGowajeoAgCwAgA&sourceid=chrome&ie=UTF-8

Normalize a whole folder : r/audioengineering
https://www.reddit.com/r/audioengineering/comments/gsyiz3/normalize_a_whole_folder/

generate subtitles with word highlighting python - Google Search
https://www.google.com/search?q=generate+subtitles+with+word+highlighting+python&rlz=1C5GCCM_en&oq=generate+subtitles+with+word+highlighting+python&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIHCAEQIRigATIHCAIQIRigAdIBCTE3MTMwajBqN6gCALACAA&sourceid=chrome&ie=UTF-8

Add subtitles permanently to a video using Python and Moviepy - YouTube
https://www.youtube.com/watch?v=Zbze7zs8Kyk

The Power of Single-Word Subtitles | by @dl4senses | Medium
https://medium.com/@didierlacroix/the-power-of-single-word-subtitles-662f8c3891bd

AngelFolio
https://www.angel1254.com/blog/posts/word-by-word-captions

nattofriends/python-ass: A library for parsing and manipulating Advanced SubStation Alpha subtitle files.
https://github.com/nattofriends/python-ass

swedish names hedda - Google Search
https://www.google.com/search?q=swedish+names+hedda&rlz=1C5GCCM_en&oq=swedish+names+hedda&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIHCAEQIRigATIHCAIQIRigATIHCAMQIRigATIHCAQQIRigATIHCAUQIRifBTIHCAYQIRifBTIHCAcQIRifBTIHCAgQIRifBTIHCAkQIRifBdIBCDM4MDBqMGo3qAIAsAIA&sourceid=chrome&ie=UTF-8

Inbox â€¢ Direct
https://www.instagram.com/direct/t/102052201197290/

jimregan (Jim Oâ€™Regan)
https://github.com/jimregan

Scene gesture - Google Docs
https://docs.google.com/document/d/1mjH0ib1AATU8PI3USTOyi0ZqnPk97FTJKSPnPOjG8ac/edit?tab=t.0#heading=h.dtslf9oeuul1

Spatial Gesture - a Hugging Face Space by annadeichler
https://huggingface.co/spaces/annadeichler/spatial-gesture

annadeichler/spatial-gesture at main
https://huggingface.co/spaces/annadeichler/spatial-gesture/tree/main/Build

annadeichler (Anna Deichler)
https://huggingface.co/annadeichler

time in california - Google Search
https://www.google.com/search?q=time+in+california&rlz=1C5GCCM_en&oq=time+in+cali&gs_lcrp=EgZjaHJvbWUqDAgAECMYJxiABBiKBTIMCAAQIxgnGIAEGIoFMgYIARBFGDkyBwgCEAAYgAQyBwgDEAAYgAQyBwgEEAAYgAQyBwgFEAAYgAQyBwgGEAAYgAQyBwgHEAAYgAQyBwgIEAAYgAQyCQgJEAAYChiABNIBCDE4MjhqMGo3qAIAsAIA&sourceid=chrome&ie=UTF-8

GuyTevet/MotionCLIP: Official Pytorch implementation of the paper "MotionCLIP: Exposing Human Motion Generation to CLIP Space"
https://github.com/GuyTevet/MotionCLIP

Tags | notes
https://jimregan.github.io/notes/categories/#ctc

Download CÃºla4 ar Scoil video | notes
https://jimregan.github.io/notes/irish/dataset/cula4/2021/08/21/download-cula4-ar-scoil-video.html

CÃºla4 - YouTube
https://www.youtube.com/@Cula4

CÃºla4 - YouTube
https://www.youtube.com/@Cula4/videos

An bhfaca tÃº mo ShÃ©amuisÃ­n? | Rannta agus AmhrÃ¡in le Niamh - YouTube
https://www.youtube.com/watch?v=o4OBazWZ4Kk

json.load() i Python - GeeksforGeeks
https://www.geeksforgeeks.org/json-load-in-python/

ERROR: Output extension mp4 does not support PCM audio. Please choose a suitable audio codec with the -c:a option - Google Search
https://www.google.com/search?q=ERROR%3A+Output+extension+mp4+does+not+support+PCM+audio.+Please+choose+a+suitable+audio+codec+with+the+-c%3Aa+option&rlz=1C5GCCM_en&oq=ERROR%3A+Output+extension+mp4+does+not+support+PCM+audio.+Please+choose+a+suitable+audio+codec+with+the+-c%3Aa+option&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIGCAEQRRg60gEHMTMxajBqN6gCALACAA&sourceid=chrome&ie=UTF-8

Aria Data Tools | Aria Data Tools
https://facebookresearch.github.io/Aria_data_tools/

Project Aria Open Tools | Project Aria
https://www.projectaria.com/tools/

facebookresearch/projectaria_tools: projectaria_tools is an C++/Python open-source toolkit to interact with Project Aria data
https://github.com/facebookresearch/projectaria_tools

Meta Research
https://github.com/facebookresearch

facebookresearch/spot-sim2real: Spot Sim2Real Infrastructure
https://github.com/facebookresearch/spot-sim2real?tab=readme-ov-file

spot-sim2real/ros_tcp/install_ros_bridge_server.sh at main Â· facebookresearch/spot-sim2real
https://github.com/facebookresearch/spot-sim2real/blob/main/ros_tcp/install_ros_bridge_server.sh

spot-sim2real/README.md at main Â· facebookresearch/spot-sim2real
https://github.com/facebookresearch/spot-sim2real/blob/main/README.md#rotating_light-running-emergency-stop

2409.12737
https://arxiv.org/pdf/2409.12737


