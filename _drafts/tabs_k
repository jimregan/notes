Amphion/models/tts/jets/alignments.py at main Â· open-mmlab/Amphion
https://github.com/open-mmlab/Amphion/blob/main/models/tts/jets/alignments.py

IPS-LMU/octra: OCTRA is a web-application for the orthographic transcription of audio files.
https://github.com/IPS-LMU/octra

espnet/owsm_ctc_v3.1_1B Â· Hugging Face
https://huggingface.co/espnet/owsm_ctc_v3.1_1B

Berkeley-Speech-Group/Speech-Articulatory-Coding
https://github.com/Berkeley-Speech-Group/Speech-Articulatory-Coding

interactiveaudiolab/penn: Pitch Estimating Neural Networks (PENN)
https://github.com/interactiveaudiolab/penn

maxrmorrison/torchcrepe: Pytorch implementation of the CREPE pitch tracker
https://github.com/maxrmorrison/torchcrepe?tab=readme-ov-file

microsoft/MMdnn: MMdnn is a set of tools to help users inter-operate among different deep learning frameworks. E.g. model conversion and visualization. Convert models between Caffe, Keras, MXNet, Tensorflow, CNTK, PyTorch Onnx and CoreML.
https://github.com/microsoft/MMdnn?tab=readme-ov-file

Pull requests Â· microsoft/MMdnn
https://github.com/microsoft/MMdnn/pulls?page=2&q=is%3Apr+is%3Aclosed

1. Add tf slim resnet_v1_101 model into examples. Â· microsoft/MMdnn@4e05f1c
https://github.com/Microsoft/MMdnn/commit/4e05f1c669583d488c966526d56e956b8f71daf7

coding speech through vocal tract kinematics - Google Search
https://www.google.com/search?q=coding+speech+through+vocal+tract+kinematics&rlz=1C5GCCM_en&oq=Coding+Speech+through+Vocal+Tract+Kinematics&gs_lcrp=EgZjaHJvbWUqBwgAEAAYgAQyBwgAEAAYgAQyDQgBEAAYhgMYgAQYigUyDQgCEAAYhgMYgAQYigUyDQgDEAAYhgMYgAQYigUyCggEEAAYgAQYogQyCggFEAAYgAQYogTSAQc0OTRqMGo0qAIAsAIB&sourceid=chrome&ie=UTF-8

Vocal Tract Visualization github - Google Search
https://www.google.com/search?q=Vocal+Tract+Visualization+github&sca_esv=e936ada1b37f2909&rlz=1C5GCCM_en&sxsrf=ADLYWII1SVq2A9LsldLgrGGXvoWsXWXrFw%3A1730392828978&ei=_LIjZ5GoO-q9wPAPqsLi0AQ&ved=0ahUKEwiRlpLPh7mJAxXqHhAIHSqhGEoQ4dUDCBA&uact=5&oq=Vocal+Tract+Visualization+github&gs_lp=Egxnd3Mtd2l6LXNlcnAiIFZvY2FsIFRyYWN0IFZpc3VhbGl6YXRpb24gZ2l0aHViMgUQIRigAUjODFBlWJ8KcAF4AZABAJgBa6ABwASqAQM2LjG4AQPIAQD4AQGYAgigAt0EwgIKEAAYsAMY1gQYR8ICCBAAGIAEGKIEwgIHECEYoAEYCpgDAIgGAZAGCJIHAzcuMaAHhg4&sclient=gws-wiz-serp

zakaton/Pink-Trombone: A programmable version of Neil Thapen's Pink Trombone
https://github.com/zakaton/Pink-Trombone

SparkNG/LICENSE.txt at master Â· HidekiKawahara/SparkNG
https://github.com/HidekiKawahara/SparkNG/blob/master/LICENSE.txt

VocalTractLab
https://www.vocaltractlab.de/index.php?page=vocaltractlab-download

Web-based-vocoder
https://github.com/Web-based-vocoder

Speech-Articulatory-Coding/sparc/block.py at main Â· Berkeley-Speech-Group/Speech-Articulatory-Coding
https://github.com/Berkeley-Speech-Group/Speech-Articulatory-Coding/blob/main/sparc/block.py

interactiveaudiolab/penn: Pitch Estimating Neural Networks (PENN)
https://github.com/interactiveaudiolab/penn

maxrmorrison/torchcrepe: Pytorch implementation of the CREPE pitch tracker
https://github.com/maxrmorrison/torchcrepe?tab=readme-ov-file

microsoft/MMdnn: MMdnn is a set of tools to help users inter-operate among different deep learning frameworks. E.g. model conversion and visualization. Convert models between Caffe, Keras, MXNet, Tensorflow, CNTK, PyTorch Onnx and CoreML.
https://github.com/microsoft/MMdnn?tab=readme-ov-file#conversion

Speech-Articulatory-Coding/setup.py at main Â· Berkeley-Speech-Group/Speech-Articulatory-Coding
https://github.com/Berkeley-Speech-Group/Speech-Articulatory-Coding/blob/main/setup.py

ml-explore/mlx: MLX: An array framework for Apple silicon
https://github.com/ml-explore/mlx?tab=readme-ov-file

[2306.06546] High-Fidelity Audio Compression with Improved RVQGAN
https://arxiv.org/abs/2306.06546

lucidrains/e2-tts-pytorch: Implementation of E2-TTS, "Embarrassingly Easy Fully Non-Autoregressive Zero-Shot TTS", in Pytorch
https://github.com/lucidrains/e2-tts-pytorch

e2-tts-pytorch/e2_tts_pytorch/e2_tts.py at main Â· lucidrains/e2-tts-pytorch
https://github.com/lucidrains/e2-tts-pytorch/blob/main/e2_tts_pytorch/e2_tts.py

lucasnewman (Lucas Newman)
https://github.com/lucasnewman

2107.10342
https://arxiv.org/pdf/2107.10342

2211.07292
https://arxiv.org/pdf/2211.07292

lucasnewman/spear-tts-pytorch: Implementation of Spear-TTS - multi-speaker text-to-speech attention network, in Pytorch
https://github.com/lucasnewman/spear-tts-pytorch?tab=readme-ov-file

Add trainers for the pretraining and backtranslation tasks by lucasnewman Â· Pull Request #4 Â· lucidrains/spear-tts-pytorch
https://github.com/lucidrains/spear-tts-pytorch/pull/4/files

lucasnewman (Lucas Newman)
https://github.com/lucasnewman

lucidrains (lucidrains) / Repositories
https://github.com/lucidrains?tab=repositories

lucidrains/nGPT-pytorch: Quick implementation of nGPT, learning entirely on the hypersphere, from NvidiaAI
https://github.com/lucidrains/nGPT-pytorch

lvsm-pytorch/lvsm_pytorch/lvsm.py at main Â· lucidrains/lvsm-pytorch
https://github.com/lucidrains/lvsm-pytorch/blob/main/lvsm_pytorch/lvsm.py

tree_attention/tree_shard_test.py at main Â· Zyphra/tree_attention
https://github.com/Zyphra/tree_attention/blob/main/tree_shard_test.py

spline-based-transformer/spline_based_transformer/spline_based_transformer.py at main Â· lucidrains/spline-based-transformer
https://github.com/lucidrains/spline-based-transformer/blob/main/spline_based_transformer/spline_based_transformer.py

lucidrains/x-transformers: A concise but complete full-attention transformer with a set of promising experimental features from various papers
https://github.com/lucidrains/x-transformers

lucidrains/audiolm-pytorch: Implementation of AudioLM, a SOTA Language Modeling Approach to Audio Generation out of Google Research, in Pytorch
https://github.com/lucidrains/audiolm-pytorch

WhenAvailable - Free Group Scheduling Tool
https://whenavailable.com/reply?sid=T5cX0Vw8yXpblq875eCX&invite=JLyX8fZXobdADtSgFqew

Phonetic transcription with HuggingFace | notes
https://jimregan.github.io/notes/phonetic/espeak/wav2vec2/huggingface/timestamps/2022/10/18/wav2vec2-phonetic-transcription.html

Getting timestamps on long audio | notes
https://jimregan.github.io/notes/long%20audio/wav2vec2/huggingface/timestamps/2022/03/08/getting-timestamps-on-long-audio-with-wav2vec2-and-huggingface.html

jimregan/wav2vec2-xls-r-300m-phoneme-timit Â· Hugging Face
https://huggingface.co/jimregan/wav2vec2-xls-r-300m-phoneme-timit

2410.22179
https://arxiv.org/pdf/2410.22179

Panelshow
https://www.reddit.com/r/panelshow/

Have I Got News For You S68E05 - Jo Brand, Nabil Abdulrashid and Tom Peck : r/panelshow
https://www.reddit.com/r/panelshow/comments/1ghh5vl/have_i_got_news_for_you_s68e05_jo_brand_nabil/

Getting timestamps on long audio | notes
https://jimregan.github.io/notes/long%20audio/wav2vec2/huggingface/timestamps/2022/03/08/getting-timestamps-on-long-audio-with-wav2vec2-and-huggingface.html

Phoneme Recognition with Wav2Vec2
https://www.kaggle.com/code/jimregan/phoneme-recognition-with-wav2vec2/notebook

DARPA TIMIT Acoustic-Phonetic Continuous Speech
https://www.kaggle.com/datasets/mfekadu/darpa-timit-acousticphonetic-continuous-speech

philipperemy/timit: The DARPA TIMIT Acoustic-Phonetic Continuous Speech Corpus.
https://github.com/philipperemy/timit

Extract a dictionary from MFA-aligned TextGrids | notes
https://jimregan.github.io/notes/textgrid/mfa/2021/10/15/extract-dictionary-from-mfa-textgrids.html

neuralcoref/neuralcoref/neuralcoref.pyx at master Â· huggingface/neuralcoref
https://github.com/huggingface/neuralcoref/blob/master/neuralcoref/neuralcoref.pyx

llama.cpp/examples/llava/README.md at master Â· ggerganov/llama.cpp
https://github.com/ggerganov/llama.cpp/blob/master/examples/llava/README.md

Overview Â· spaCy Universe
https://spacy.io/universe

Coreferee Â· spaCy Universe
https://spacy.io/universe/project/coreferee

2024-11-07-set-up-neuralcoref.ipynb - Colab
https://colab.research.google.com/drive/1MY5A-f3Nhj35ww4m_V-aXou6Dh6D7rkq#scrollTo=yKOYV_spC6PK

Set up neuralcoref | notes
https://jimregan.github.io/notes/neuralcoref/spacy/2024/11/07/set-up-neuralcoref.html

resuscitative, adj. meanings, etymology and more | Oxford English Dictionary
https://www.oed.com/dictionary/resuscitative_adj

jimregan/notes
https://github.com/jimregan/notes?tab=readme-ov-file

Using Matcha with a private repo | notes
https://jimregan.github.io/notes/matcha/english/private/hsi/2024/10/26/matcha-private-repo.html

Get data from Folkets Swedish-English | notes
https://jimregan.github.io/notes/folkets/swedish/pronunciation/2024/10/12/folkets.html

jupyter notebook persistence - Google Search
https://www.google.com/search?q=jupyter+notebook+persistence&rlz=1C5GCCM_en&oq=jupyter+persisten&gs_lcrp=EgZjaHJvbWUqCAgBEAAYFhgeMgYIABBFGDkyCAgBEAAYFhgeMg0IAhAAGIYDGIAEGIoFMg0IAxAAGIYDGIAEGIoFMg0IBBAAGIYDGIAEGIoFMg0IBRAAGIYDGIAEGIoFMg0IBhAAGIYDGIAEGIoFMgoIBxAAGIAEGKIEMgoICBAAGIAEGKIE0gEINDg3MGowajeoAgCwAgA&sourceid=chrome&ie=UTF-8

discourse.jupyter.org
https://discourse.jupyter.org/t/saving-state-or-sessions-in-jupyter-notebooks/3907

Persist â€” A JupyterLab Extension for Persistent Interactions
https://vdl.sci.utah.edu/blog/2024/05/29/persist/

Quickstart Tutorial | Persist
https://vdl.sci.utah.edu/persist/docs/getting-started/simple-tutorial

Example Gallery â€” Vega-Altair 5.5.0dev documentation
https://altair-viz.github.io/gallery/index.html#example-gallery

A High-Level Grammar of Interactive Graphics | Vega-Lite
https://vega.github.io/vega-lite/

yifanwu/b2: Bridging Code and Interactive Visualization in Computational Notebooks
https://github.com/yifanwu/b2?tab=readme-ov-file

yifanwu/midas-exp-pub
https://github.com/yifanwu/midas-exp-pub

agenda.infn.it
https://agenda.infn.it/event/31005/contributions/167438/attachments/96417/133850/Minio_jupyter_persistence.pdf

Blog/Audio normalization with FFmpeg - Forza's ramblings
https://wiki.tnonline.net/w/Blog/Audio_normalization_with_FFmpeg

Encountered a 404 error
https://sox.sourceforge.net/sox.html

Any way to make the volume the same across all video files? : r/PleX
https://www.reddit.com/r/PleX/comments/hg9een/any_way_to_make_the_volume_the_same_across_all/

AudioVolume â€“ FFmpeg
https://trac.ffmpeg.org/wiki/AudioVolume

slhck/ffmpeg-normalize: Audio Normalization for Python/ffmpeg
https://github.com/slhck/ffmpeg-normalize?tab=readme-ov-file#should-i-use-this-to-normalize-my-music-collection

audio - ffmpeg loudnorm 2pass in single line - Super User
https://superuser.com/questions/1312811/ffmpeg-loudnorm-2pass-in-single-line

slhck/ffmpeg-normalize: Audio Normalization for Python/ffmpeg
https://github.com/slhck/ffmpeg-normalize?tab=readme-ov-file

ffmpeg-normalize/ffmpeg_normalize/_ffmpeg_normalize.py at master Â· slhck/ffmpeg-normalize
https://github.com/slhck/ffmpeg-normalize/blob/master/ffmpeg_normalize/_ffmpeg_normalize.py

normalize audio of a directory ffmpeg - Google Search
https://www.google.com/search?q=normalize+audio+of+a+directory+ffmpeg&rlz=1C5GCCM_en&oq=normalize+audio+of+a+direc&gs_lcrp=EgZjaHJvbWUqCQgBECEYChigATIGCAAQRRg5MgkIARAhGAoYoAEyCQgCECEYChigATIJCAMQIRgKGKAB0gEINzU4NGowajeoAgCwAgA&sourceid=chrome&ie=UTF-8

Normalize a whole folder : r/audioengineering
https://www.reddit.com/r/audioengineering/comments/gsyiz3/normalize_a_whole_folder/

generate subtitles with word highlighting python - Google Search
https://www.google.com/search?q=generate+subtitles+with+word+highlighting+python&rlz=1C5GCCM_en&oq=generate+subtitles+with+word+highlighting+python&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIHCAEQIRigATIHCAIQIRigAdIBCTE3MTMwajBqN6gCALACAA&sourceid=chrome&ie=UTF-8

Add subtitles permanently to a video using Python and Moviepy - YouTube
https://www.youtube.com/watch?v=Zbze7zs8Kyk

The Power of Single-Word Subtitles | by @dl4senses | Medium
https://medium.com/@didierlacroix/the-power-of-single-word-subtitles-662f8c3891bd

AngelFolio
https://www.angel1254.com/blog/posts/word-by-word-captions

nattofriends/python-ass: A library for parsing and manipulating Advanced SubStation Alpha subtitle files.
https://github.com/nattofriends/python-ass

swedish names hedda - Google Search
https://www.google.com/search?q=swedish+names+hedda&rlz=1C5GCCM_en&oq=swedish+names+hedda&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIHCAEQIRigATIHCAIQIRigATIHCAMQIRigATIHCAQQIRigATIHCAUQIRifBTIHCAYQIRifBTIHCAcQIRifBTIHCAgQIRifBTIHCAkQIRifBdIBCDM4MDBqMGo3qAIAsAIA&sourceid=chrome&ie=UTF-8

GuyTevet/MotionCLIP: Official Pytorch implementation of the paper "MotionCLIP: Exposing Human Motion Generation to CLIP Space"
https://github.com/GuyTevet/MotionCLIP

Aria Data Tools | Aria Data Tools
https://facebookresearch.github.io/Aria_data_tools/

Project Aria Open Tools | Project Aria
https://www.projectaria.com/tools/

facebookresearch/projectaria_tools: projectaria_tools is an C++/Python open-source toolkit to interact with Project Aria data
https://github.com/facebookresearch/projectaria_tools

Meta Research
https://github.com/facebookresearch

facebookresearch/spot-sim2real: Spot Sim2Real Infrastructure
https://github.com/facebookresearch/spot-sim2real?tab=readme-ov-file

spot-sim2real/ros_tcp/install_ros_bridge_server.sh at main Â· facebookresearch/spot-sim2real
https://github.com/facebookresearch/spot-sim2real/blob/main/ros_tcp/install_ros_bridge_server.sh

spot-sim2real/README.md at main Â· facebookresearch/spot-sim2real
https://github.com/facebookresearch/spot-sim2real/blob/main/README.md#rotating_light-running-emergency-stop

2409.12737
https://arxiv.org/pdf/2409.12737

NoDaLiDa Baltic-HLT 2025 Conference Reviewers | OpenReview
https://openreview.net/group?id=NoDaLiDa/Baltic-HLT/2025/Conference/Reviewers#assigned-submissions

Does Preprocessing Matter? An Analysis of Acoustic Feature Importance in Deep Learning for Dialect Classification | OpenReview
https://openreview.net/forum?id=0qvJmxBprH&noteId=0qvJmxBprH&invitationId=NoDaLiDa/Baltic-HLT/2025/Conference/Submission5/-/Official_Review&referrer=%5BReviewers%20Console%5D(%2Fgroup%3Fid%3DNoDaLiDa%2FBaltic-HLT%2F2025%2FConference%2FReviewers%23assigned-submissions)

Assessed and Annotated Vowel Lengths in Spoken Icelandic Sentences for L1 and L2 Speakers: A Resource for Pronunciation Training | OpenReview
https://openreview.net/forum?id=nYfa4bPDIX&referrer=%5BReviewers%20Console%5D(%2Fgroup%3Fid%3DNoDaLiDa%2FBaltic-HLT%2F2025%2FConference%2FReviewers%23assigned-submissions)

pdf
https://openreview.net/pdf?id=0qvJmxBprH

Dialect Identification of Spoken North SÃ¡mi Language Varieties Using Prosodic Features - University of Helsinki
https://researchportal.helsinki.fi/en/publications/dialect-identification-of-spoken-north-s%C3%A1mi-language-varieties-us

ISCA Archive - Dialect Identification of Spoken North SÃ¡mi Language Varieties Using Prosodic Features
https://www.isca-archive.org/speechprosody_2020/kakouros20_speechprosody.html#

Submitted to INTERSPEECH
https://arxiv.org/pdf/2305.11864

The 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024) - ACL Anthology
https://aclanthology.org/events/lrec-2024/

The 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024) - ACL Anthology
https://aclanthology.org/events/lrec-2024/#2024lrec-main

Corpus Creation and Automatic Alignment of Historical Dutch Dialect Speech
https://aclanthology.org/2024.lrec-main.357.pdf

NB Uttale: A Norwegian Pronunciation Lexicon with Dialect Variation
https://aclanthology.org/2024.lrec-main.1056.pdf

nb_uttale/data/input/rules_v1.py at v1 Â· Sprakbanken/nb_uttale
https://github.com/Sprakbanken/nb_uttale/blob/v1/data/input/rules_v1.py

Phonotactic Complexity across Dialects
https://aclanthology.org/2024.lrec-main.1115.pdf

Proceedings of the 5th RaPID Workshop
https://demo.spraakbanken.gu.se/svedk/pbl/RAPID5-2024-Proceedings.pdf

cmu-llab/phonotactic-complexity-across-dialects: "Phonotactic Complexity across Dialects" (LREC-Coling 2024)
https://github.com/cmu-llab/phonotactic-complexity-across-dialects

SSSB
https://sssb.se/

Sprakbanken/nb_uttale at v1
https://github.com/Sprakbanken/nb_uttale/tree/v1

jerry maguire gif help me help you - Google Search
https://www.google.com/search?q=jerry+maguire+gif+help+me+help+you&rlz=1C5GCCM_en&oq=jerry+maguire+gif+help&gs_lcrp=EgZjaHJvbWUqBwgAEAAYgAQyBwgAEAAYgAQyBggBEEUYOTIICAIQABgWGB4yCggDEAAYgAQYogQyCggEEAAYgAQYogQyCggFEAAYgAQYogQyCggGEAAYgAQYogTSAQg0NTcxajBqN6gCALACAA&sourceid=chrome&ie=UTF-8#vhid=wOqHIlxNY1h53M&vssid=_S41EZ7-4FKzVwPAPzdnb-Q0_55

YARN | Help me Help you | Jerry Maguire (1996) | Video gifs by quotes | c5e62915 | ç´—
https://memes.yarn.co/yarn-clip/c5e62915-a837-4af3-a487-682c51a7b25d/gif

Comparative adjectives in Hungarian: -abb [HungarianReference.com > Grammar > Adjectives > Comparative: -abb]
http://www.hungarianreference.com/Adjectives/Comparative-bb.aspx#google_vignette

Berkeley-Speech-Group/Speech-Articulatory-Coding
https://github.com/Berkeley-Speech-Group/Speech-Articulatory-Coding

Berkeley-Speech-Group
https://github.com/Berkeley-Speech-Group

Berkeley-Speech-Group/sylber: Sylber: Syllabic Embedding Representation of Speech from Raw Audio
https://github.com/Berkeley-Speech-Group/sylber

[2410.07168] Sylber: Syllabic Embedding Representation of Speech from Raw Audio
https://arxiv.org/abs/2410.07168

PWVD-Pitch-Tracker/ppt.py at main Â· Berkeley-Speech-Group/PWVD-Pitch-Tracker
https://github.com/Berkeley-Speech-Group/PWVD-Pitch-Tracker/blob/main/ppt.py

Berkeley-Speech-Group/audio_ml_workshop_2023: A tutorial for working with self-supervised representations and audio data
https://github.com/Berkeley-Speech-Group/audio_ml_workshop_2023

Berkeley-Speech-Group/SSDM
https://github.com/Berkeley-Speech-Group/SSDM

Jim O'Regan | Flickr
https://www.flickr.com/photos/jimregan/

Vaibhav (VB) Srivastav on X: "Smol TTS keeps getting better! Introducing OuteTTS v0.2 - 500M parameters, multilingual with voice cloning! ðŸ”¥ &gt; Multilingual - English, Chinese, Korean &amp; Japanese &gt; Cross platform inference w/ llama.cpp &gt; Zero-shot voice cloning &gt; Trained on 5 Billion audio tokens &gt; Qwen 2.5 https://t.co/N4c4Ukfrhz" / X
https://x.com/reach_vb/status/1861160122325610900

OuteAI (OuteAI)
https://huggingface.co/OuteAI

OuteAI/OuteTTS-0.1-350M Â· Hugging Face
https://huggingface.co/OuteAI/OuteTTS-0.1-350M

jishengpeng/WavTokenizer: SOTA discrete acoustic codec models with 40 tokens per second for audio language modeling
https://github.com/jishengpeng/WavTokenizer


