YouTube
https://www.youtube.com/

Ylvis cleaning up after drunken party in total darkness (Eng subs) - YouTube
https://www.youtube.com/watch?v=dm9ICOCFULE

Ylvis - Get to know BÃ¥rd - Thai massage - IKMY 09.02.2016 (Eng subs) - YouTube
https://www.youtube.com/watch?v=pNsLT2f3wTQ

Lamia - Wikipedia
https://en.wikipedia.org/wiki/Lamia#Modern_age

ageron/handson-ml2: A series of Jupyter notebooks that walk you through the fundamentals of Machine Learning and Deep Learning in Python using Scikit-Learn, Keras and TensorFlow 2.
https://github.com/ageron/handson-ml2

handson-ml/14_recurrent_neural_networks.ipynb at master Â· ageron/handson-ml
https://github.com/ageron/handson-ml/blob/master/14_recurrent_neural_networks.ipynb

handson-ml/01_the_machine_learning_landscape.ipynb at master Â· ageron/handson-ml
https://github.com/ageron/handson-ml/blob/master/01_the_machine_learning_landscape.ipynb

handson-ml/02_end_to_end_machine_learning_project.ipynb at master Â· ageron/handson-ml
https://github.com/ageron/handson-ml/blob/master/02_end_to_end_machine_learning_project.ipynb

handson-ml/04_training_linear_models.ipynb at master Â· ageron/handson-ml
https://github.com/ageron/handson-ml/blob/master/04_training_linear_models.ipynb

handson-ml2/tools_numpy.ipynb at bad4df148a8118eaaadcc1a9629856e6f1155aff Â· ageron/handson-ml2
https://github.com/ageron/handson-ml2/blob/bad4df148a8118eaaadcc1a9629856e6f1155aff//tools_numpy.ipynb

handson-ml2/math_differential_calculus.ipynb at master Â· ageron/handson-ml2
https://github.com/ageron/handson-ml2/blob/master/math_differential_calculus.ipynb

The Fires of Heaven | A Wheel of Time Wiki | Fandom
https://wot.fandom.com/wiki/The_Fires_of_Heaven

The Fires of Heaven/Chapter 10 | A Wheel of Time Wiki | Fandom
https://wot.fandom.com/wiki/The_Fires_of_Heaven/Chapter_10

Linear algebra with Transformers â€“ Paper Explained - YouTube
https://www.youtube.com/watch?v=dqKM1Mbt0pU

Positional embeddings in transformers EXPLAINED | Demystifying positional encodings. - YouTube
https://www.youtube.com/watch?v=1biZfFLPRSY

Adding vs. concatenating positional embeddings & Learned positional encodings - YouTube
https://www.youtube.com/watch?v=M2ToEXF6Olw

FNet: Mixing Tokens with Fourier Transforms â€“ Paper Explained - YouTube
https://www.youtube.com/watch?v=j7pWPdGEfMA

2105.03824.pdf
https://arxiv.org/pdf/2105.03824.pdf

google-research/models.py at master Â· google-research/google-research
https://github.com/google-research/google-research/blob/master/f_net/models.py

FNet
https://huggingface.co/docs/transformers/model_doc/fnet

huggingface/transformers: ðŸ¤— Transformers: State-of-the-art Machine Learning for Pytorch, TensorFlow, and JAX.
https://github.com/huggingface/transformers

Commits Â· huggingface/transformers
https://github.com/huggingface/transformers/commits/master?after=8ce133063120683018b214fe10d1449e4c2401da+104&branch=master

Handle PyTorch to Flax conversion of 1D convolutions (#15519) Â· huggingface/transformers@854a0d5
https://github.com/huggingface/transformers/commit/854a0d526c7a3b958a790e92272ac798ca3831f5

Fic docstring of ASR pipeline (#15481) Â· huggingface/transformers@13297ac
https://github.com/huggingface/transformers/commit/13297ac71cb45241c7de6b9716ae48f523a824f7

[Wav2Vec2ProcessorWithLM] add alpha & beta to batch decode & decode (â€¦ Â· huggingface/transformers@d718c0c
https://github.com/huggingface/transformers/commit/d718c0c3a887bcab6acc151b3654bf9f46e61d62

Update modeling_wav2vec2.py (#15423) Â· huggingface/transformers@125a288
https://github.com/huggingface/transformers/commit/125a2882b4997f8ad37beadb8a025114f0f0e1a0

Issues with custom dataset in Wav2Vec2 Â· Issue #15366 Â· huggingface/transformers
https://github.com/huggingface/transformers/issues/15366

NbAiLab/NPSC Â· Datasets at Hugging Face
https://huggingface.co/datasets/NbAiLab/NPSC

transformers/run_speech_recognition_ctc_bnb.py at f624249d8b49c50e507077d801062c7fb58797e9 Â· huggingface/transformers
https://github.com/huggingface/transformers/blob/f624249d8b49c50e507077d801062c7fb58797e9/examples/research_projects/robust-speech-event/run_speech_recognition_ctc_bnb.py

huggingface/transformers: ðŸ¤— Transformers: State-of-the-art Machine Learning for Pytorch, TensorFlow, and JAX.
https://github.com/huggingface/transformers

Add XGLM models (#14876) Â· huggingface/transformers@d25e25e
https://github.com/huggingface/transformers/commit/d25e25ee2b63ebfcd099deb689a5a7272574a10f

[DocTests Speech] Add doc tests for all speech models (#15031) Â· huggingface/transformers@9f831bd
https://github.com/huggingface/transformers/commit/9f831bdeaf965acca6c6097dfffb1364f4416c17

[PyTorch-nightly-test] Fix Wav2Vec2 LM & Phoneme tests (#15272) Â· huggingface/transformers@b7cb126
https://github.com/huggingface/transformers/commit/b7cb126ccce4d5ac1abb44a27b4644c08ff42430

[Wav2Vec2ProcessorWithLM] improve multi processing (#15247) Â· huggingface/transformers@80af104
https://github.com/huggingface/transformers/commit/80af1048cf34d4cff54c13c99d3abfd4e9b3f4eb

transformers/README.md at 11afb709ec85b1f2ad6e40b84c980e24de7f6bfb Â· huggingface/transformers
https://github.com/huggingface/transformers/blob/11afb709ec85b1f2ad6e40b84c980e24de7f6bfb/examples/research_projects/robust-speech-event/README.md

facebookresearch/bitsandbytes: Library for 8-bit optimizers and quantization routines.
https://github.com/facebookresearch/bitsandbytes

Load a Dataset in Streaming mode â€” datasets 1.11.0 documentation
https://huggingface.co/docs/datasets/dataset_streaming.html

Background â€” fsspec 2022.01.0+2.g00b8123.dirty documentation
https://filesystem-spec.readthedocs.io/en/latest/intro.html

Resources | SprÃ¥kbanken Text
https://spraakbanken.gu.se/en/resources?s=&language=&page=0


