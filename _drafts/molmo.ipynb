{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[From RoboSpatial](https://github.com/chanhee-luke/RoboSpatial-Eval/blob/master/models.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from transformers import GenerationConfig\n",
    "\n",
    "def generate_answer(image_path, question, model, processor, **kwargs):\n",
    "    inputs = processor.process(\n",
    "        images=[Image.open(image_path)],\n",
    "        text=question\n",
    "    )\n",
    "\n",
    "    # Move inputs to the correct device and make a batch of size 1\n",
    "    inputs = {k: v.to(model.device).unsqueeze(0) for k, v in inputs.items()}\n",
    "\n",
    "    # Create a GenerationConfig and update it with any additional kwargs\n",
    "    generation_config = GenerationConfig(max_new_tokens=200, stop_strings=\"<|endoftext|>\")\n",
    "    for key, value in kwargs.items():\n",
    "        setattr(generation_config, key, value)\n",
    "\n",
    "    # Generate output\n",
    "    output = model.generate_from_batch(\n",
    "        inputs,\n",
    "        generation_config,\n",
    "        tokenizer=processor.tokenizer\n",
    "    )\n",
    "\n",
    "    # Extract generated tokens and decode them to text\n",
    "    generated_tokens = output[0, inputs['input_ids'].size(1):]\n",
    "    generated_text = processor.tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "\n",
    "    return generated_text\n",
    "\n",
    "model = kwargs[\"model\"]\n",
    "processor = kwargs[\"processor\"]\n",
    "# Remove model and processor from kwargs to avoid conflicts\n",
    "generation_kwargs = {k: v for k, v in kwargs.items() if k not in [\"model\", \"processor\"]}\n",
    "generated_text = generate_answer(image_path, question, model, processor, **generation_kwargs)\n",
    "return generated_text"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
