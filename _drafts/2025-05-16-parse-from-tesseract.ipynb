{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gq4eL7Xj9psB"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install stanza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PHI6wzlqAk3t"
      },
      "outputs": [],
      "source": [
        "import urllib.parse, urllib.request, json, sys\n",
        "import stanza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "a-aFOYu_AoGu"
      },
      "outputs": [],
      "source": [
        "STD_API = \"https://cadhan.com/api/intergaelic/3.0\"\n",
        "\n",
        "def standardise(text: str, lang: str = \"ga\"):\n",
        "    \"\"\"Return a list of (orig_tok, std_tok) pairs from Intergaelic.\"\"\"\n",
        "    data   = urllib.parse.urlencode({\"foinse\": lang, \"teacs\": text}).encode()\n",
        "    hdrs   = {\"Content-Type\": \"application/x-www-form-urlencoded\",\n",
        "              \"Accept\":        \"application/json\"}\n",
        "    req    = urllib.request.Request(STD_API, data, hdrs)\n",
        "    with urllib.request.urlopen(req) as resp:\n",
        "        return json.loads(resp.read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "a1WtCT_ZArRt"
      },
      "outputs": [],
      "source": [
        "stanza.download(\"ga\", processors=\"tokenize,pos,lemma,depparse\", verbose=False)\n",
        "\n",
        "nlp = stanza.Pipeline(\n",
        "    lang=\"ga\",\n",
        "    processors=\"tokenize,pos,lemma,depparse\",\n",
        "    # Let Stanza decide sentences & tokens\n",
        "    tokenize_pretokenized=True,\n",
        "    no_ssplit=True,\n",
        "    verbose=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "knN_HAk5Auzx"
      },
      "outputs": [],
      "source": [
        "from itertools import groupby\n",
        "from typing import List, Tuple\n",
        "\n",
        "def _split_std(std: str, orig: str) -> List[str]:\n",
        "    \"\"\"Return the token(s) that should feed Stanza for this pair.\"\"\"\n",
        "    if not std.strip():\n",
        "        return [orig]\n",
        "    return std.split()\n",
        "\n",
        "def _sentences_from_pairs(pairs: List[Tuple[str, str]]):\n",
        "    \"\"\"Very light sentence splitter: keep everything up to . ! ?\"\"\"\n",
        "    sent, buf = [], []\n",
        "    for i, (orig, std) in enumerate(pairs):\n",
        "        parts = _split_std(std, orig)\n",
        "        for j, part in enumerate(parts):\n",
        "            buf.append((i, j, len(parts), orig, part))\n",
        "            if part in {\".\", \"!\", \"?\"}:\n",
        "                sent.append(buf);  buf = []\n",
        "    if buf:\n",
        "        sent.append(buf)\n",
        "    return sent\n",
        "\n",
        "def project_with_stanza(raw_text: str, lang: str = \"ga\") -> str:\n",
        "    pairs  = standardise(raw_text, lang)\n",
        "\n",
        "    sents  = _sentences_from_pairs(pairs)\n",
        "    pretok = [[m[4] for m in sent] for sent in sents]\n",
        "\n",
        "    doc = nlp(pretok)\n",
        "\n",
        "    conllu_lines = []\n",
        "    for sid, (sent_map, sent_doc) in enumerate(zip(sents, doc.sentences), 1):\n",
        "        raw_slice = [m[3] for m in sent_map if m[1] == 0]\n",
        "        std_slice = [m[4] for m in sent_map]\n",
        "        conllu_lines += [\n",
        "            f\"# sent_id = {sid}\",\n",
        "            f\"# text = {' '.join(raw_slice)}\",\n",
        "            f\"# text_standard = {' '.join(std_slice)}\",\n",
        "        ]\n",
        "\n",
        "        # token lines\n",
        "        widx = 0\n",
        "        tid  = 1\n",
        "        for m in sent_map:\n",
        "            orig_i, sub_i, n_sub, orig_tok, std_tok = m\n",
        "            word = sent_doc.words[widx]\n",
        "\n",
        "            if sub_i == 0 and n_sub > 1:\n",
        "                conllu_lines.append(f\"{tid}-{tid+n_sub-1}\\t{orig_tok}\\t_\\t_\\t_\\t_\\t_\\t_\\t_\\t_\")\n",
        "\n",
        "            form = orig_tok if n_sub == 1 else std_tok\n",
        "\n",
        "            conllu_lines.append(\"\\t\".join([\n",
        "                str(tid),\n",
        "                form,\n",
        "                word.lemma or \"_\",\n",
        "                word.upos  or \"_\",\n",
        "                word.xpos  or \"_\",\n",
        "                word.feats or \"_\",\n",
        "                str(word.head) if word.head else \"_\",\n",
        "                word.deprel or \"_\",\n",
        "                \"_\",\n",
        "                \"_\",\n",
        "            ]))\n",
        "\n",
        "            widx += 1\n",
        "            tid  += 1\n",
        "        conllu_lines.append(\"\")\n",
        "\n",
        "    return \"\\n\".join(conllu_lines)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Bjso2N2Z8SQh"
      },
      "outputs": [],
      "source": [
        "PAGE = \"\"\"Maidin amháin, chuaigh gamal as Gúra amach chun\n",
        "connadh a bhailiú. Shiúil sé leis thar an machaire gur tháinig\n",
        "sé go dtí crann mór ológ cois abhann.\n",
        "\n",
        "Dhreap sé an crann agus shuigh sé faoi ar an ngéag ba mhó ar\n",
        "an gcrann. Nuair a bhraith sé ar a shocracht ar an ngéag,\n",
        "thosaigh sé á bualadh le tua.\n",
        "\n",
        "Ghabh an sagart thar bráid. D'fhéach sé in airde agus labhair\n",
        "leis an ngamal:\n",
        "\n",
        "\"A dheartháirín ó, cad atá ar bun agat?\" ar sé os ard. \"Ní mar\n",
        "sin a ghearrtar adhmad!\"\n",
        "\n",
        "\"Níl aon bhealach eile ann, a Athair,\" arsa an gamal.\n",
        "\"Caithfear an tua a ardú agus é a bhualadh anuas ar an\n",
        "adhmad!\"\n",
        "\n",
        "\"Ach tá tú i do shuí ar an ngéag atá á gearradh agat! Brisfidh\n",
        "an ghéag, agus nuair a bhrisfidh titfidh tusa go talamh agus\n",
        "marófar thú,” arsa an sagart.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "IKupmgct-b-Q"
      },
      "outputs": [],
      "source": [
        "paras = [x.replace(\"\\n\", \" \") for x in PAGE.split(\"\\n\\n\")]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_fngHpD-lSn",
        "outputId": "6260c241-15bb-4fa7-cbbc-a46c6b60db84"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Maidin amháin, chuaigh gamal as Gúra amach chun connadh a bhailiú. Shiúil sé leis thar an machaire gur tháinig sé go dtí crann mór ológ cois abhann.',\n",
              " 'Dhreap sé an crann agus shuigh sé faoi ar an ngéag ba mhó ar an gcrann. Nuair a bhraith sé ar a shocracht ar an ngéag, thosaigh sé á bualadh le tua.',\n",
              " \"Ghabh an sagart thar bráid. D'fhéach sé in airde agus labhair leis an ngamal:\",\n",
              " '\"A dheartháirín ó, cad atá ar bun agat?\" ar sé os ard. \"Ní mar sin a ghearrtar adhmad!\"',\n",
              " '\"Níl aon bhealach eile ann, a Athair,\" arsa an gamal. \"Caithfear an tua a ardú agus é a bhualadh anuas ar an adhmad!\"',\n",
              " '\"Ach tá tú i do shuí ar an ngéag atá á gearradh agat! Brisfidh an ghéag, agus nuair a bhrisfidh titfidh tusa go talamh agus marófar thú,” arsa an sagart. ']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "paras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tYWPdPb286bi"
      },
      "outputs": [],
      "source": [
        "nlp_tok = stanza.Pipeline(\n",
        "    lang=\"ga\",\n",
        "    processors=\"tokenize,pos,lemma,depparse\",\n",
        "    tokenize_pretokenized=False,\n",
        "    verbose=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "aLotbbK19BRq"
      },
      "outputs": [],
      "source": [
        "pp = project_with_stanza(\"E-, ‘firing range’ a mbíonns acub agus é seo agus é siúd.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qaebm2iUEWe7",
        "outputId": "961e3838-0830-4c4e-d63c-25ee7a44bba2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# sent_id = 1\n",
            "# text = E - , ‘ firing range ’ a mbíonns acub agus é seo agus é siúd .\n",
            "# text_standard = É - , ‘ firing range ’ a mbíonn acu agus é seo agus é siúd .\n",
            "1\tE\té\tPRON\tPers\tGender=Masc|Number=Sing|Person=3\t_\troot\t_\t_\n",
            "2\t-\t-\tPUNCT\t.\t_\t4\tpunct\t_\t_\n",
            "3\t,\t,\tPUNCT\tPunct\t_\t4\tpunct\t_\t_\n",
            "4\t‘\t‘\tX\tForeign\tForeign=Yes\t1\tparataxis\t_\t_\n",
            "5\tfiring\tfiring\tX\tForeign\tForeign=Yes\t4\tflat:foreign\t_\t_\n",
            "6\trange\trange\tX\tForeign\tForeign=Yes\t4\tflat:foreign\t_\t_\n",
            "7\t’\t’\tPUNCT\tPunct\t_\t9\tpunct\t_\t_\n",
            "8\ta\ta\tPART\tVb\tForm=Indirect|PartType=Vb|PronType=Rel\t9\tmark:prt\t_\t_\n",
            "9\tmbíonns\tbí\tVERB\tPresImp\tAspect=Hab|Form=Ecl|Mood=Ind|Tense=Pres\t4\tacl:relcl\t_\t_\n",
            "10\tacub\tag\tADP\tPrep\tNumber=Plur|Person=3\t9\tobl:prep\t_\t_\n",
            "11\tagus\tagus\tCCONJ\tCoord\t_\t12\tcc\t_\t_\n",
            "12\té\té\tPRON\tPers\tGender=Masc|Number=Sing|Person=3\t1\tconj\t_\t_\n",
            "13\tseo\tseo\tPRON\tDem\tPronType=Dem\t12\tdet\t_\t_\n",
            "14\tagus\tagus\tSCONJ\tSubord\t_\t15\tmark\t_\t_\n",
            "15\té\té\tPRON\tPers\tGender=Masc|Number=Sing|Person=3\t12\tconj\t_\t_\n",
            "16\tsiúd\tsiúd\tPRON\tDem\tPronType=Dem\t15\tdet\t_\t_\n",
            "17\t.\t.\tPUNCT\t.\t_\t1\tpunct\t_\t_\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(pp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FVf_cOHH3NP",
        "outputId": "411d5ac6-4327-483d-c9ec-4949e9a96da9"
      },
      "outputs": [],
      "source": [
        "lines = \"{:C}\".format(nlp_tok(raw)).split(\"\\n\")\n",
        "print(\"\\n\".join(lines))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYDAYg3OJrJG",
        "outputId": "be56da38-887d-4621-d499-2d1b4f9b5d3e"
      },
      "outputs": [],
      "source": [
        "!pip install pytesseract opencv-python-headless"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIK_8uwOJztG",
        "outputId": "f64a62f5-c9d3-4514-9c3c-910710e6605a"
      },
      "outputs": [],
      "source": [
        "!sudo apt install tesseract-ocr tesseract-ocr-gle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "fLBCzBqRP0j6"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def read_image_from_url(url):\n",
        "    response = requests.get(url)\n",
        "    image_array = np.frombuffer(response.content, np.uint8)\n",
        "    image = cv2.imdecode(image_array, cv2.IMREAD_COLOR)\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "OKgDKshVK-U9"
      },
      "outputs": [],
      "source": [
        "import pytesseract\n",
        "import cv2\n",
        "\n",
        "def extract_text_from_bbox(image_path, bbox, lang=\"gle\"):\n",
        "    image = cv2.imread(image_path)\n",
        "\n",
        "    # Extract the region of interest\n",
        "    x1, y1, x2, y2 = bbox\n",
        "    roi = image[y1:y2, x1:x2]\n",
        "\n",
        "    # Convert the ROI to grayscale\n",
        "    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    text = pytesseract.image_to_string(gray, lang=lang)\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "7Vfq6LamP5Ps"
      },
      "outputs": [],
      "source": [
        "import pytesseract\n",
        "import cv2\n",
        "from IPython.display import display, Image\n",
        "import io\n",
        "\n",
        "def extract_text_from_bbox_and_url(url, bbox, lang=\"gle\"):\n",
        "    image = read_image_from_url(url)\n",
        "\n",
        "    # Extract the region of interest\n",
        "    x1, y1, x2, y2 = bbox\n",
        "    roi = image[y1:y2, x1:x2]\n",
        "\n",
        "    # Convert the ROI to grayscale\n",
        "    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    _, buffer = cv2.imencode('.png', roi)\n",
        "    io_buf = io.BytesIO(buffer)\n",
        "    display(Image(io_buf.getvalue()))\n",
        "\n",
        "    text = pytesseract.image_to_string(gray, lang=lang)\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "bFb-zLtyLQe0"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def get_image_selector_from_url(url, selector):\n",
        "    req = requests.get(url)\n",
        "    assert req.status_code == 200, f\"Failed to fetch {url}\"\n",
        "    soup = BeautifulSoup(req.text, 'html.parser')\n",
        "    element = soup.select_one(selector)\n",
        "    if element:\n",
        "        return element['src']\n",
        "    else:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "vVI6NWufdgIh"
      },
      "outputs": [],
      "source": [
        "def get_image_from_data(url, selector, bbox_text):\n",
        "    bbox = [int(x) for x in bbox_text.split(\" \")]\n",
        "    img = get_image_selector_from_url(url, selector)\n",
        "    return extract_text_from_bbox_and_url(img, bbox)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "id": "quVuJ55fLzgR",
        "outputId": "9dc113d9-c5f1-403a-eb72-d59875031333"
      },
      "outputs": [],
      "source": [
        "b = get_image_from_data(\"https://www.leighleat.com/pages/1803\", \"#ajax-page-container > div > div:nth-child(2) > img\", \"297 681 725 742\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aU90T5bL9cO",
        "outputId": "14a5b699-0523-4f24-8d24-02c96bfd064f"
      },
      "outputs": [],
      "source": [
        "lines = \"{:C}\".format(nlp_tok(b)).split(\"\\n\")\n",
        "print(\"\\n\".join(lines))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJT7a_K5bYh9",
        "outputId": "e918fda1-c6f8-490c-8055-b72d4f755a5c"
      },
      "outputs": [],
      "source": [
        "cor = \"Nuair a thagann Brídín abhaile, ordaíonn a mamaí di í féin a ghlanadh.\"\n",
        "lines = \"{:C}\".format(nlp_tok(cor)).split(\"\\n\")\n",
        "print(\"\\n\".join(lines))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "stanza",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
