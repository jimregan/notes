{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33de041e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "LANG_MAP = {\n",
    "    \"air.\": \"Old Irish\",\n",
    "    \"mir.\": \"Middle Irish\",\n",
    "    \"nir.\": \"Modern Irish\",\n",
    "    \"aengl.\": \"Old English\",\n",
    "    \"mengl.\": \"Middle English\",\n",
    "    \"anord.\": \"Old Norse\",\n",
    "    \"aisl.\": \"Old Icelandic\",\n",
    "    \"aschott.\": \"Old Scots\",\n",
    "    \"lat.\": \"Latin\",\n",
    "    \"kymr.\": \"Welsh\",\n",
    "    \"korn.\": \"Cornish\",\n",
    "    \"bret.\": \"Breton\",\n",
    "    \"span.\": \"Spanish\",\n",
    "    \"afranz.\": \"Old French\",\n",
    "}\n",
    "\n",
    "WORK_MAP = {\n",
    "    \"Molloy\": \"Molloy\",\n",
    "    \"Keat.\": \"Keating\",\n",
    "    \"O’R.\": \"O’Reilly\",\n",
    "    \"O'R.\": \"O’Reilly\",\n",
    "    \"O’Clery\": \"O’Clery\",\n",
    "    \"O'Clery\": \"O’Clery\",\n",
    "    \"Atk.\": \"Atkinson\",\n",
    "    \"Bk. of Deer\": \"Book of Deer\",\n",
    "    \"Book of Deer\": \"Book of Deer\",\n",
    "    \"Joyce\": \"Joyce\",\n",
    "}\n",
    "\n",
    "ROMAN_RE = r\"(?:I|II|III|IV|V|VI|VII|VIII|IX|X)\"\n",
    "\n",
    "def split_top_level_semicolons(text: str) -> List[str]:\n",
    "    parts, buf, depth = [], [], 0\n",
    "    for ch in text:\n",
    "        if ch == '(':\n",
    "            depth += 1\n",
    "        elif ch == ')':\n",
    "            depth = max(0, depth - 1)\n",
    "        if ch == ';' and depth == 0:\n",
    "            chunk = ''.join(buf).strip()\n",
    "            if chunk:\n",
    "                parts.append(chunk)\n",
    "            buf = []\n",
    "        else:\n",
    "            buf.append(ch)\n",
    "    last = ''.join(buf).strip()\n",
    "    if last:\n",
    "        parts.append(last)\n",
    "    return parts\n",
    "\n",
    "def parse_neben(chunk: str) -> List[str]:\n",
    "    alts = re.findall(r\"neben\\s+''([^']+)''\", chunk)\n",
    "    return alts\n",
    "\n",
    "def parse_phonetic_head(chunk: str) -> Optional[List[str]]:\n",
    "    m = re.search(r\"^''([^']+)''\", chunk.strip())\n",
    "    if not m:\n",
    "        return None\n",
    "    return [p for p in m.group(1).split() if p]\n",
    "\n",
    "def parse_gloss(chunk: str) -> Optional[str]:\n",
    "    m = re.search(r\"„([^“]+)“\", chunk)\n",
    "    return m.group(1).strip() if m else None\n",
    "\n",
    "def parse_gender(chunk: str) -> Optional[str]:\n",
    "    m = re.search(r\"\\b([mfn])\\.\\b\", chunk)\n",
    "    if not m: return None\n",
    "    return {\"m\": \"masculine\", \"f\": \"feminine\", \"n\": \"neuter\"}[m.group(1)]\n",
    "\n",
    "def parse_vgl_crossrefs(chunk: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Handles: (vgl. II 251, 15), (vgl. II 251, 15. 266, 5), (vgl. I 263)\n",
    "    Returns list of {volume,page[,line]}\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for par in re.findall(r\"\\(([^)]*vgl\\.[^)]*)\\)\", chunk):\n",
    "        s = par\n",
    "        vgl_m = re.search(r\"vgl\\.\\s*(.*)$\", s)\n",
    "        if not vgl_m: \n",
    "            continue\n",
    "        tail = vgl_m.group(1).strip()\n",
    "\n",
    "        tokens = [t for t in re.split(r\"[,\\.\\s]+\", tail) if t]\n",
    "        cur_vol = None\n",
    "        i = 0\n",
    "        while i < len(tokens):\n",
    "            tok = tokens[i]\n",
    "            if re.fullmatch(ROMAN_RE, tok):\n",
    "                cur_vol = tok\n",
    "                i += 1\n",
    "                continue\n",
    "            if tok.isdigit():\n",
    "                page = tok\n",
    "                line = None\n",
    "\n",
    "                if i + 1 < len(tokens) and tokens[i+1].isdigit():\n",
    "                    line = tokens[i+1]\n",
    "                    i += 1\n",
    "                if cur_vol:\n",
    "                    entry = {\"volume\": cur_vol, \"page\": page}\n",
    "                    if line: entry[\"line\"] = line\n",
    "                    out.append(entry)\n",
    "                i += 1\n",
    "                continue\n",
    "            i += 1\n",
    "    return out\n",
    "\n",
    "def parse_etymology(chunk: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Collects historical stages like: air. bél; mir. bláth; aengl. bróc; anord. brókr\n",
    "    Splits multiple forms after the same label (e.g. 'air. biaid bieid').\n",
    "    \"\"\"\n",
    "    out = []\n",
    "\n",
    "    labels = sorted(LANG_MAP.keys(), key=len, reverse=True)\n",
    "    pattern = r\"\\b(\" + \"|\".join(map(re.escape, labels)) + r\")\\s+([^;,()]+)\"\n",
    "    for abbr, forms_blob in re.findall(pattern, chunk):\n",
    "        forms = [f.strip() for f in forms_blob.split() if f.strip()]\n",
    "        for f in forms:\n",
    "            f = f.rstrip(\".,:;\")\n",
    "            if f:\n",
    "                out.append({\"language\": LANG_MAP[abbr], \"form\": f})\n",
    "    return out\n",
    "\n",
    "def parse_sources(chunk: str) -> List[Dict[str, object]]:\n",
    "    \"\"\"\n",
    "    Captures easy modern source references:\n",
    "      - 'Molloy 49: áthúil' → {work:\"Molloy\", page:\"49\", forms:[\"áthúil\"]}\n",
    "      - 'Keat. breódhaim, breóghaim' → {work:\"Keating\", forms:[...]}\n",
    "      - 'O’R.' → {work:\"O’Reilly\"} (form optional)\n",
    "      - '(Bk. of Deer)' → {work:\"Book of Deer\"}\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for m in re.finditer(r\"\\b(Molloy)\\s+(\\d+)(?::\\s*([^);]+))?\", chunk):\n",
    "        work = WORK_MAP[m.group(1)]\n",
    "        page = m.group(2)\n",
    "        forms = []\n",
    "        if m.group(3):\n",
    "            forms = [f.strip() for f in re.split(r\",\\s*\", m.group(3).strip()) if f.strip()]\n",
    "        entry = {\"work\": work, \"page\": page}\n",
    "        if forms: entry[\"forms\"] = forms\n",
    "        out.append(entry)\n",
    "\n",
    "    for key, label in WORK_MAP.items():\n",
    "        if key == \"Molloy\":  # already handled\n",
    "            continue\n",
    "\n",
    "        for m in re.finditer(r\"(?:\\(|\\b)\"+re.escape(key)+r\"(?:\\)|\\b)(?::\\s*([^);]+))?\", chunk):\n",
    "            forms_blob = m.group(1)\n",
    "            entry = {\"work\": label}\n",
    "            if forms_blob:\n",
    "                forms = [f.strip() for f in re.split(r\",\\s*\", forms_blob.strip()) if f.strip()]\n",
    "                if forms: entry[\"forms\"] = forms\n",
    "\n",
    "            if entry not in out:\n",
    "                out.append(entry)\n",
    "    return out\n",
    "\n",
    "def extract_easy_entries(volume: str, page: str, section: str, page_text: str) -> List[Dict[str, object]]:\n",
    "    \"\"\"\n",
    "    Minimal-but-useful pass:\n",
    "      - returns a list of dicts with `volume`, `page`, `raw`\n",
    "      - plus: phonetic, alongside (from 'neben'), gloss, gender, see_section, etymology, source_refs\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    page_text = page_text.replace(\"&nbsp;\", \" \")\n",
    "    for raw in split_top_level_semicolons(page_text):\n",
    "        item = {\n",
    "            \"volume\": volume,\n",
    "            \"page\": page,\n",
    "            \"section\": section,\n",
    "            \"raw\": raw.strip()\n",
    "        }\n",
    "        head = parse_phonetic_head(raw)\n",
    "        if head: item[\"phonetic\"] = head\n",
    "        alts = parse_neben(raw)\n",
    "        if alts:\n",
    "            item[\"alongside\"] = alts[0] if len(alts) == 1 else alts\n",
    "        gloss = parse_gloss(raw)\n",
    "        if gloss: item[\"gloss\"] = gloss\n",
    "        gender = parse_gender(raw)\n",
    "        if gender: item[\"gender\"] = gender\n",
    "        refs = parse_vgl_crossrefs(raw)\n",
    "        if refs: item[\"see_section\"] = refs\n",
    "        ety = parse_etymology(raw)\n",
    "        if ety: item[\"etymology\"] = ety\n",
    "        src = parse_sources(raw)\n",
    "        if src: item[\"source_refs\"] = src\n",
    "        results.append(item)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "78043115",
   "metadata": {},
   "outputs": [],
   "source": [
    "P4 = \"\"\"''āŕlikn̥'' „leihen, verleihen“ (vgl. II 254, 36), air. airliciud; ''bir'' „spitze“, air. bir; ''bišəx'' „besserung“, mir. bisech; ''bitālcə'' „branntwein“, mir. bitáill, afranz. vitaille; ''pŕiāl'' „brühe“ (vgl. II 264, 28), mengl. frien; ''bŕisk'' „brüchig“, mir. brisc; ''bŕišĭm'' „breche“, air. brissim; ''ȷiȷ'' „brustzitze“, mir. did; ''efiǵə'' „bureau“ mir. oifficc, lat. officium; ''fiŕ'', gen. sing. und nom. plur. zu ''fȧr'' „mann“, air. fir; ''fihə'' (neben ''fī fi'') „zwanzig“, air. fiche; ''fihəd'' „zwanzig“ (neben ''fīd''), air. fichet; ''fihĭm'' „webe“, mir. figim; ''fiĺĭm'' „wende mich“, air. fillim; ''filə'' „dichter“, air. fili; ''fin̄'' „blond“ (neben ''fĭūn̄''), air. find; ''fis'' „wissen“, air. fiss; ''ǵliḱ'' „schlau“, air. glicc; ''iməxt'' „fortgehn“, air. imthecht; ''imləkān'' „nabel“, mir. imlecán; ''imørkə'' „überschuss“, mir. imarcraid; ''imū'' „mancher“, air. immde (vgl. II 277, 16); ''ińəx'' „einschlag“, mir. innech; ''impī'' „bitte“, mir. impide; ''ińń̥'' „gehirn“, air. inchind; ''ińūn'' „amboss“, mir. indeóin, air. indéin (''ińūn'' „zwiebel“ s. §&nbsp;65); ''inəd'' „stätte“, mir. inad; ''iniš'' „insel“, air. inis; ''inīn'' „tochter“, air. ingen; ''is'' „ist“, air. iss; ''ḱinə'' „geschlecht“, mir. ciniud; ''ḱintəx'' „schuldig“ air. cintach; ''ḱitəx ḱitōg'' „link, linkisch“, kymr. chwith; ''ḱlišĭm'' „verfehle“, mir. clissim; ''ḱlišcə'' „geschickt, gewandt“, mir. cliste; ''ḱŕis'' „wollgürtel“ (vgl. II 176), air. criss; ''mil'' „honig“, air. mil; ''spŕid'' „geist“, air. spirud spiurt; ''šib'' „ihr, euch“, air. sib; ''šin'' „jener“, air. sin; ''sinə'' „zitze“, mir. sine; ''cimpl̥̄'' „um – herum“, air. timchell; ''cin̄əs'' „krankheit“, mir. tinnes (vgl. ''cīn'' §&nbsp;9).\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "788966ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = []\n",
    "for e in extract_easy_entries(\"I\", page=\"12\", section=\"13\", page_text=P4):\n",
    "    entries.append(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5f04055e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumerate_entries(entries: List[Dict[str, object]], start: int = 1) -> None:\n",
    "    for i, entry in enumerate(entries):\n",
    "        entry[\"id\"] = f\"{entry['volume']}_{entry['section']}_{i + start}\"\n",
    "enumerate_entries(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f2590d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def write_json(path = \"/private/tmp/irish-attested-pronunciations/finck/raw/\", data = [], section = \"4\"):\n",
    "    with open(f\"{path}/section{section}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        import json\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8e2b892b",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_json(data=entries, section=\"13\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nst-tts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
