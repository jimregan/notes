{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "33de041e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "LANG_MAP = {\n",
    "    \"air.\": \"Old Irish\",\n",
    "    \"mir.\": \"Middle Irish\",\n",
    "    \"nir.\": \"Modern Irish\",\n",
    "    \"aengl.\": \"Old English\",\n",
    "    \"mengl.\": \"Middle English\",\n",
    "    \"anord.\": \"Old Norse\",\n",
    "    \"aisl.\": \"Old Icelandic\",\n",
    "    \"aschott.\": \"Old Scots\",\n",
    "    \"lat.\": \"Latin\",\n",
    "    \"kymr.\": \"Welsh\",\n",
    "    \"korn.\": \"Cornish\",\n",
    "    \"bret.\": \"Breton\",\n",
    "    \"span.\": \"Spanish\",\n",
    "    \"afranz.\": \"Old French\",\n",
    "}\n",
    "\n",
    "WORK_MAP = {\n",
    "    \"Molloy\": \"Molloy\",\n",
    "    \"Keat.\": \"Keating\",\n",
    "    \"Oâ€™R.\": \"Oâ€™Reilly\",\n",
    "    \"O'R.\": \"Oâ€™Reilly\",\n",
    "    \"Oâ€™Clery\": \"Oâ€™Clery\",\n",
    "    \"O'Clery\": \"Oâ€™Clery\",\n",
    "    \"Atk.\": \"Atkinson\",\n",
    "    \"Bk. of Deer\": \"Book of Deer\",\n",
    "    \"Book of Deer\": \"Book of Deer\",\n",
    "    \"Joyce\": \"Joyce\",\n",
    "}\n",
    "\n",
    "ROMAN_RE = r\"(?:I|II|III|IV|V|VI|VII|VIII|IX|X)\"\n",
    "\n",
    "def split_top_level_semicolons(text: str) -> List[str]:\n",
    "    parts, buf, depth = [], [], 0\n",
    "    for ch in text:\n",
    "        if ch == '(':\n",
    "            depth += 1\n",
    "        elif ch == ')':\n",
    "            depth = max(0, depth - 1)\n",
    "        if ch == ';' and depth == 0:\n",
    "            chunk = ''.join(buf).strip()\n",
    "            if chunk:\n",
    "                parts.append(chunk)\n",
    "            buf = []\n",
    "        else:\n",
    "            buf.append(ch)\n",
    "    last = ''.join(buf).strip()\n",
    "    if last:\n",
    "        parts.append(last)\n",
    "    return parts\n",
    "\n",
    "def parse_neben(chunk: str) -> List[str]:\n",
    "    alts = re.findall(r\"neben\\s+''([^']+)''\", chunk)\n",
    "    return alts\n",
    "\n",
    "def parse_phonetic_head(chunk: str) -> Optional[List[str]]:\n",
    "    m = re.search(r\"^''([^']+)''\", chunk.strip())\n",
    "    if not m:\n",
    "        return None\n",
    "    return [p for p in m.group(1).split() if p]\n",
    "\n",
    "def parse_gloss(chunk: str) -> Optional[str]:\n",
    "    m = re.search(r\"â€([^â€œ]+)â€œ\", chunk)\n",
    "    return m.group(1).strip() if m else None\n",
    "\n",
    "def parse_gender(chunk: str) -> Optional[str]:\n",
    "    m = re.search(r\"\\b([mfn])\\.\\b\", chunk)\n",
    "    if not m: return None\n",
    "    return {\"m\": \"masculine\", \"f\": \"feminine\", \"n\": \"neuter\"}[m.group(1)]\n",
    "\n",
    "def parse_vgl_crossrefs(chunk: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Handles: (vgl. II 251, 15), (vgl. II 251, 15. 266, 5), (vgl. I 263)\n",
    "    Returns list of {volume,page[,line]}\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for par in re.findall(r\"\\(([^)]*vgl\\.[^)]*)\\)\", chunk):\n",
    "        s = par\n",
    "        vgl_m = re.search(r\"vgl\\.\\s*(.*)$\", s)\n",
    "        if not vgl_m: \n",
    "            continue\n",
    "        tail = vgl_m.group(1).strip()\n",
    "\n",
    "        tokens = [t for t in re.split(r\"[,\\.\\s]+\", tail) if t]\n",
    "        cur_vol = None\n",
    "        i = 0\n",
    "        while i < len(tokens):\n",
    "            tok = tokens[i]\n",
    "            if re.fullmatch(ROMAN_RE, tok):\n",
    "                cur_vol = tok\n",
    "                i += 1\n",
    "                continue\n",
    "            if tok.isdigit():\n",
    "                page = tok\n",
    "                line = None\n",
    "\n",
    "                if i + 1 < len(tokens) and tokens[i+1].isdigit():\n",
    "                    line = tokens[i+1]\n",
    "                    i += 1\n",
    "                if cur_vol:\n",
    "                    entry = {\"volume\": cur_vol, \"page\": page}\n",
    "                    if line: entry[\"line\"] = line\n",
    "                    out.append(entry)\n",
    "                i += 1\n",
    "                continue\n",
    "            i += 1\n",
    "    return out\n",
    "\n",
    "def parse_etymology(chunk: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Collects historical stages like: air. bÃ©l; mir. blÃ¡th; aengl. brÃ³c; anord. brÃ³kr\n",
    "    Splits multiple forms after the same label (e.g. 'air. biaid bieid').\n",
    "    \"\"\"\n",
    "    out = []\n",
    "\n",
    "    labels = sorted(LANG_MAP.keys(), key=len, reverse=True)\n",
    "    pattern = r\"\\b(\" + \"|\".join(map(re.escape, labels)) + r\")\\s+([^;,()]+)\"\n",
    "    for abbr, forms_blob in re.findall(pattern, chunk):\n",
    "        forms = [f.strip() for f in forms_blob.split() if f.strip()]\n",
    "        for f in forms:\n",
    "            f = f.rstrip(\".,:;\")\n",
    "            if f:\n",
    "                out.append({\"language\": LANG_MAP[abbr], \"form\": f})\n",
    "    return out\n",
    "\n",
    "def parse_sources(chunk: str) -> List[Dict[str, object]]:\n",
    "    \"\"\"\n",
    "    Captures easy modern source references:\n",
    "      - 'Molloy 49: Ã¡thÃºil' â†’ {work:\"Molloy\", page:\"49\", forms:[\"Ã¡thÃºil\"]}\n",
    "      - 'Keat. breÃ³dhaim, breÃ³ghaim' â†’ {work:\"Keating\", forms:[...]}\n",
    "      - 'Oâ€™R.' â†’ {work:\"Oâ€™Reilly\"} (form optional)\n",
    "      - '(Bk. of Deer)' â†’ {work:\"Book of Deer\"}\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for m in re.finditer(r\"\\b(Molloy)\\s+(\\d+)(?::\\s*([^);]+))?\", chunk):\n",
    "        work = WORK_MAP[m.group(1)]\n",
    "        page = m.group(2)\n",
    "        forms = []\n",
    "        if m.group(3):\n",
    "            forms = [f.strip() for f in re.split(r\",\\s*\", m.group(3).strip()) if f.strip()]\n",
    "        entry = {\"work\": work, \"page\": page}\n",
    "        if forms: entry[\"forms\"] = forms\n",
    "        out.append(entry)\n",
    "\n",
    "    for key, label in WORK_MAP.items():\n",
    "        if key == \"Molloy\":  # already handled\n",
    "            continue\n",
    "\n",
    "        for m in re.finditer(r\"(?:\\(|\\b)\"+re.escape(key)+r\"(?:\\)|\\b)(?::\\s*([^);]+))?\", chunk):\n",
    "            forms_blob = m.group(1)\n",
    "            entry = {\"work\": label}\n",
    "            if forms_blob:\n",
    "                forms = [f.strip() for f in re.split(r\",\\s*\", forms_blob.strip()) if f.strip()]\n",
    "                if forms: entry[\"forms\"] = forms\n",
    "\n",
    "            if entry not in out:\n",
    "                out.append(entry)\n",
    "    return out\n",
    "\n",
    "def extract_easy_entries(volume: str, page: str, section: str, page_text: str) -> List[Dict[str, object]]:\n",
    "    \"\"\"\n",
    "    Minimal-but-useful pass:\n",
    "      - returns a list of dicts with `volume`, `page`, `raw`\n",
    "      - plus: phonetic, alongside (from 'neben'), gloss, gender, see_section, etymology, source_refs\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    page_text = page_text.replace(\"&nbsp;\", \" \")\n",
    "    for raw in split_top_level_semicolons(page_text):\n",
    "        item = {\n",
    "            \"volume\": volume,\n",
    "            \"page\": page,\n",
    "            \"section\": section,\n",
    "            \"raw\": raw.strip()\n",
    "        }\n",
    "        head = parse_phonetic_head(raw)\n",
    "        if head: item[\"phonetic\"] = head\n",
    "        alts = parse_neben(raw)\n",
    "        if alts:\n",
    "            item[\"alongside\"] = alts[0] if len(alts) == 1 else alts\n",
    "        gloss = parse_gloss(raw)\n",
    "        if gloss: item[\"gloss\"] = gloss\n",
    "        gender = parse_gender(raw)\n",
    "        if gender: item[\"gender\"] = gender\n",
    "        refs = parse_vgl_crossrefs(raw)\n",
    "        if refs: item[\"see_section\"] = refs\n",
    "        ety = parse_etymology(raw)\n",
    "        if ety: item[\"etymology\"] = ety\n",
    "        src = parse_sources(raw)\n",
    "        if src: item[\"source_refs\"] = src\n",
    "        results.append(item)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "78043115",
   "metadata": {},
   "outputs": [],
   "source": [
    "P4 = \"\"\"''glÈ³'' â€rufen, wecken, auffordern, krÃ¤henâ€œ (Molloy 35: gluighe), mir. glÃ³ed glÃ¡ed, davon ''glÈ³x glÄ“x'' (zu ''Ä“'' statt ''È³'' vgl. ''Ä“n'' â€einâ€œ, air. Ã³in Ã³en; ''gÄ“l'' â€irlÃ¤nderâ€œ, mir. gÃ³edel; ''bÄ“Å¡'' â€vorliebeâ€œ, mir. baes; ''galÄ“rÉ™x'' â€seifeâ€œ, gallaoireach (Molloy 26), gallaoileach [Oâ€™R.]); ''plÄ“sk'' â€hirnschaleâ€œ, plaosg, Oâ€™R.; ''glÈ³Ä­m glÈ³xÄ­m'' â€rufeâ€œ etc., mir. gloidim; ''gnÄx'' â€Ã¼blichâ€œ (Molloy 46: gnÃ¡ch), mir. gnÃ¡thach; ''gnÅ'' (''gnÅ«'' ist seltener zweigipflig) â€geschÃ¤ftâ€œ, gnÃ³, Oâ€™R.; ''gauÄ­m gÅÄ­m'' â€nehme, empfange, greifeâ€œ air. gabaim; ''grÄ'' â€liebeâ€œ, mir. grÃ¡d; ''grÅ'' (vgl. II 275, 8) â€eisenstangeâ€œ, grÃ³dh, Oâ€™R., engl. crow-[bar]? (zu ''g'' statt ''k'' vgl. ''pus'' â€lippeâ€œ, mir. bus; ''gax'' â€jederâ€œ, gach, air. cach cech;\"\"\"\n",
    "P4 = \"\"\"''Ä“n'' â€einâ€œ, air. Ã³in Ã³en; ''gÄ“l'' â€irlÃ¤nderâ€œ, mir. gÃ³edel; ''bÄ“Å¡'' â€vorliebeâ€œ, mir. baes; ''galÄ“rÉ™x'' â€seifeâ€œ, gallaoireach (Molloy 26), gallaoileach (Oâ€™R.)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "788966ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = []\n",
    "for e in extract_easy_entries(\"I\", page=\"5\", section=\"4\", page_text=P4):\n",
    "    entries.append(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5f04055e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumerate_entries(entries: List[Dict[str, object]], start: int = 70) -> None:\n",
    "    for i, entry in enumerate(entries):\n",
    "        entry[\"id\"] = f\"{entry['volume']}_{entry['section']}_{i + start}\"\n",
    "enumerate_entries(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f2590d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def write_json(path = \"/private/tmp/irish-attested-pronunciations/finck/raw/\", data = [], section = \"4\"):\n",
    "    with open(f\"{path}/section{section}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        import json\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8e2b892b",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_json(data=entries, section=\"4c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1693d64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "italics = \"ğ˜¢ğ˜£ğ˜¤ğ˜¥ğ˜¦ğ˜§ğ˜¨ğ˜©ğ˜ªğ˜«ğ˜¬ğ˜­ğ˜®ğ˜¯ğ˜°ğ˜±ğ˜²ğ˜³ğ˜´ğ˜µğ˜¶ğ˜·ğ˜¸ğ˜¹ğ˜ºğ˜»\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nst-tts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
