{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rann na Feirste scraper.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "roq1h3eE4yHJ"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "BASE='http://www.rannnafeirste.com'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mXGux1o4kE4"
      },
      "source": [
        "class Page:\n",
        "\tdef __init__(self, id, title):\n",
        "\t\tself.id = id\n",
        "\t\tself.title = title\n",
        "\t\tself.url = '{}/{}'.format(BASE, id)\n",
        "\n",
        "\t# TODO: stop trying to make fetch happen\n",
        "\tdef _fetch_text(self):\n",
        "\t\treq = requests.get(self.url)\n",
        "\t\tif req.status_code != 200:\n",
        "\t\t\traise Exception('Error fetching page ' + self.url)\n",
        "\t\tself.content = req.content\n",
        "\tdef _soupynorman(self):\n",
        "\t\tself.soup = BeautifulSoup(self.content, 'html.parser')\n",
        "\tdef _fetch_audio(self):\n",
        "\t\taudio_div = self.soup.find(\"div\", class_='sqs-audio-embed')\n",
        "\t\tself.audio = audio_div[\"data-url\"]\n",
        "\tdef _fetch_fragments(self):\n",
        "\t\tfor i in self.soup.find_all(\"div\", class_='sqs-block-content'):\n",
        "\t\t\tchildren = list(i.children)\n",
        "\t\t\tif children[0].name == \"h1\":\n",
        "\t\t\t\tself.fragments = children\n",
        "\t## don't actually need this, because the title comes from the landing page\n",
        "\tdef _fetch_title(self):\n",
        "\t\tif self.fragments[0].name == \"h1\":\n",
        "\t\t\tself.title = fragments[0].text\n",
        "\t\telse:\n",
        "\t\t\traise Exception('Error reading title: ' + self.url)\n",
        "\tdef _fetch_author(self):\n",
        "\t\tif len(self.fragments) > 2 and self.fragments[1].name == \"h2\":\n",
        "\t\t\tself.author = self.fragments[1].text\n",
        "\t\telse:\n",
        "\t\t\traise Exception('Error reading author: ' + self.url)\n",
        "\tdef _fetch_paragraphs(self):\n",
        "\t\traw_paras = [n for n in self.fragments if n.name == \"p\"]\n",
        "\t\tfor frag in raw_paras:\n",
        "\t\t\tfor br in frag.find_all(\"br\"):\n",
        "\t\t\t\tbr.insert(0, '\\n')\n",
        "\t\t\t\tbr.unwrap()\n",
        "\t\tfirst = list(raw_paras[0].children)\n",
        "\t\tif len(first) == 1 and first[0].name == 'em':\n",
        "\t\t\t\tself.em_para = raw_paras[0].text.strip()\n",
        "\t\t\t\tdel raw_paras[0]\n",
        "\t\textent = len(raw_paras)\n",
        "\t\tcounter = 0\n",
        "\t\tfor i in raw_paras:\n",
        "\t\t\t\tif i.text.strip().startswith('Nóta') or i.text.strip().startswith('NÓTA') and extent > counter:\n",
        "\t\t\t\t\t\textent = counter\n",
        "\t\t\t\tcounter += 1\n",
        "\t\tfilt = raw_paras[0:extent]\n",
        "\t\tself.paragraphs = [p.text for p in filt]\n",
        "\tdef get_initials(self):\n",
        "\t\tfada = {\n",
        "\t\t\t'Á': 'A',\n",
        "\t\t\t'É': 'E',\n",
        "\t\t\t'Í': 'I',\n",
        "\t\t\t'Ó': 'O',\n",
        "\t\t\t'Ú': 'U'\n",
        "\t\t}\n",
        "\t\tdef initial(s):\n",
        "\t\t\tif s == None or len(s) < 1:\n",
        "\t\t\t\treturn ''\n",
        "\t\t\telse:\n",
        "\t\t\t\treturn fada.get(s.upper()[0]) or s.upper()[0]\n",
        "\t\ttry:\n",
        "\t\t\treturn \"\".join([initial(i) for i in self.author.split(' ')])\n",
        "\t\texcept:\n",
        "\t\t\tprint('Author missing: did you run scrape()?')\n",
        "\n",
        "\tdef _specifics(self):\n",
        "\t\ttitle = ['mo-bhaile-dchais', 'taiscidh-ghleann-domhain', 'banron-an-uaignis', 'non-an-r-agus-an-frog', 'seanchaithe-agus-fil-rann-na-feirste', 'an-ghaeltacht-bheo']\n",
        "\t\ttitlele = ['liontar-duinn-an-cruiscin', 'oireachtas-na-ndise', 'fidilir-ghleann-fhinne']\n",
        "\n",
        "\t\tif self.id in title:\n",
        "\t\t\tself.paragraphs.insert(0, self.title)\n",
        "\n",
        "\t\tif self.id in titlele:\n",
        "\t\t\tsecond = self.em_para.replace(' a chum', '')\n",
        "\t\t\tself.paragraphs.insert(0, '{} le {}'.format(self.title, second))\n",
        "\n",
        "\tdef scrape(self):\n",
        "\t\tself._fetch_text()\n",
        "\t\tself._soupynorman()\n",
        "\t\tself._fetch_audio()\n",
        "\t\tself._fetch_fragments()\n",
        "\t\tself._fetch_author()\n",
        "\t\tself._fetch_paragraphs()\n",
        "\t\tself._specifics()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5xz7Ua844AA"
      },
      "source": [
        "foo = Page('deorai-an-oileain', 'Mo Bhaile')\n",
        "foo.scrape()\n",
        "foo.paragraphs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCf4i30d5yf7"
      },
      "source": [
        "para = foo.fragments[4]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixl0be1WHQxr"
      },
      "source": [
        "#for c in para.content:\n",
        "#one = para.contents[0]\n",
        "for br in para.find_all(\"br\"):\n",
        "  br.insert(0, '\\n')\n",
        "  br.unwrap()\n",
        "\n",
        "para.contents"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_LAoM8E8PdL"
      },
      "source": [
        "raw_paras = [n for n in foo.fragments if n.name == \"p\"]\n",
        "#raw_paras\n",
        "first = list(raw_paras[0].children)\n",
        "if len(first) == 1 and first[0].name == 'em':\n",
        "  del raw_paras[0]\n",
        "extent = len(raw_paras)\n",
        "counter = 0\n",
        "for i in raw_paras:\n",
        "  print(i.text)\n",
        "  if i.text.strip().startswith('Nóta') or i.text.strip().startswith('NÓTA') and extent > counter:\n",
        "    extent = counter\n",
        "  counter += 1\n",
        "raw_paras[0:extent]\n",
        "#counter"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}