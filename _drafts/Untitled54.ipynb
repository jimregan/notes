{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "gq4eL7Xj9psB",
        "outputId": "a96c58d5-996b-4270-f95f-63eafd606279"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting stanza\n",
            "  Downloading stanza-1.10.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting emoji (from stanza)\n",
            "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from stanza) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=3.15.0 in /usr/local/lib/python3.11/dist-packages (from stanza) (5.29.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from stanza) (2.32.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from stanza) (3.4.2)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from stanza) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from stanza) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (4.13.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.3.0->stanza)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.3.0->stanza)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.3.0->stanza)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.3.0->stanza)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.3.0->stanza)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.3.0->stanza)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.3.0->stanza)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.3.0->stanza)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.3.0->stanza)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.3.0->stanza)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.3.0->stanza) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.3.0->stanza) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->stanza) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->stanza) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->stanza) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->stanza) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.3.0->stanza) (3.0.2)\n",
            "Downloading stanza-1.10.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, emoji, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stanza\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed emoji-2.14.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 stanza-1.10.1\n"
          ]
        }
      ],
      "source": [
        "%%capture\n",
        "!pip install stanza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHI6wzlqAk3t"
      },
      "outputs": [],
      "source": [
        "import urllib.parse, urllib.request, json, sys\n",
        "import stanza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-aFOYu_AoGu"
      },
      "outputs": [],
      "source": [
        "STD_API = \"https://cadhan.com/api/intergaelic/3.0\"\n",
        "\n",
        "def standardise(text: str, lang: str = \"ga\"):\n",
        "    \"\"\"Return a list of (orig_tok, std_tok) pairs from Intergaelic.\"\"\"\n",
        "    data   = urllib.parse.urlencode({\"foinse\": lang, \"teacs\": text}).encode()\n",
        "    hdrs   = {\"Content-Type\": \"application/x-www-form-urlencoded\",\n",
        "              \"Accept\":        \"application/json\"}\n",
        "    req    = urllib.request.Request(STD_API, data, hdrs)\n",
        "    with urllib.request.urlopen(req) as resp:\n",
        "        return json.loads(resp.read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1WtCT_ZArRt"
      },
      "outputs": [],
      "source": [
        "stanza.download(\"ga\", processors=\"tokenize,pos,lemma,depparse\", verbose=False)\n",
        "\n",
        "nlp = stanza.Pipeline(\n",
        "    lang=\"ga\",\n",
        "    processors=\"tokenize,pos,lemma,depparse\",\n",
        "    # Let Stanza decide sentences & tokens\n",
        "    tokenize_pretokenized=False,\n",
        "    verbose=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knN_HAk5Auzx"
      },
      "outputs": [],
      "source": [
        "# Cell ▸ robust projection with multi‑word support\n",
        "# -----------------------------------------------\n",
        "from itertools import groupby\n",
        "from typing import List, Tuple\n",
        "\n",
        "def _split_std(std: str, orig: str) -> List[str]:\n",
        "    \"\"\"Return the token(s) that should feed Stanza for this pair.\"\"\"\n",
        "    if not std.strip():                         # e.g. Do → \"\"  → keep 'Do'\n",
        "        return [orig]\n",
        "    return std.split()                          # may yield 1‑N tokens\n",
        "\n",
        "def _sentences_from_pairs(pairs: List[Tuple[str, str]]):\n",
        "    \"\"\"Very light sentence splitter: keep everything up to . ! ?\"\"\"\n",
        "    sent, buf = [], []\n",
        "    for i, (orig, std) in enumerate(pairs):\n",
        "        parts = _split_std(std, orig)\n",
        "        for j, part in enumerate(parts):\n",
        "            buf.append((i, j, len(parts), orig, part))  # mapping entry\n",
        "            if part in {\".\", \"!\", \"?\"}:\n",
        "                sent.append(buf);  buf = []\n",
        "    if buf:\n",
        "        sent.append(buf)\n",
        "    return sent                                       # [[mapping …], …]\n",
        "\n",
        "def project_with_stanza(raw_text: str, lang: str = \"ga\") -> str:\n",
        "    # 1 ── standardise -------------------------------------------------------\n",
        "    pairs  = standardise(raw_text, lang)             # [(orig, std), …]\n",
        "\n",
        "    # 2 ── build *pre‑tokenised* input & a mapping table ---------------------\n",
        "    sents  = _sentences_from_pairs(pairs)            # list‑of‑sentences\n",
        "    pretok = [[m[4] for m in sent] for sent in sents]  # token strings only\n",
        "\n",
        "    # 3 ── parse with Stanza *pretok* mode -----------------------------------\n",
        "    doc = nlp(pretok)                                # same shape as `sents`\n",
        "\n",
        "    # 4 ── project back, keeping multi‑word tokens ---------------------------\n",
        "    conllu_lines = []\n",
        "    for sid, (sent_map, sent_doc) in enumerate(zip(sents, doc.sentences), 1):\n",
        "        # comment lines\n",
        "        raw_slice = [m[3]           for m in sent_map if m[1] == 0]     # first sub‑token per orig\n",
        "        std_slice = [m[4]           for m in sent_map]                  # every sub‑token\n",
        "        conllu_lines += [\n",
        "            f\"# sent_id = {sid}\",\n",
        "            f\"# text = {' '.join(raw_slice)}\",\n",
        "            f\"# text_standard = {' '.join(std_slice)}\",\n",
        "        ]\n",
        "\n",
        "        # token lines\n",
        "        widx = 0                                     # index in sent_doc.words\n",
        "        tid  = 1                                     # running token ID in CONLL‑U\n",
        "        for m in sent_map:\n",
        "            orig_i, sub_i, n_sub, orig_tok, std_tok = m\n",
        "            word = sent_doc.words[widx]\n",
        "\n",
        "            if sub_i == 0 and n_sub > 1:             # multi‑word‑token header\n",
        "                conllu_lines.append(f\"{tid}-{tid+n_sub-1}\\t{orig_tok}\\t_\\t_\\t_\\t_\\t_\\t_\\t_\\t_\")\n",
        "\n",
        "            # choose FORM for the sub‑token\n",
        "            form = orig_tok if n_sub == 1 else std_tok\n",
        "\n",
        "            conllu_lines.append(\"\\t\".join([\n",
        "                str(tid),\n",
        "                form,\n",
        "                word.lemma or \"_\",\n",
        "                word.upos  or \"_\",\n",
        "                word.xpos  or \"_\",\n",
        "                word.feats or \"_\",\n",
        "                str(word.head) if word.head else \"_\",\n",
        "                word.deprel or \"_\",\n",
        "                \"_\",\n",
        "                \"_\",\n",
        "            ]))\n",
        "\n",
        "            widx += 1\n",
        "            tid  += 1\n",
        "        conllu_lines.append(\"\")                      # blank line between sents\n",
        "\n",
        "    return \"\\n\".join(conllu_lines)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ei2TN5Xy-gkI"
      },
      "outputs": [],
      "source": [
        "def run_parse(raw_text):\n",
        "    pairs      = standardise(raw_text, \"ga\")\n",
        "    sentences  = naive_sentences(pairs)\n",
        "    doc        = parse_standardised(sentences)\n",
        "    conllu_out = project(doc, sentences)\n",
        "    print(conllu_out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-I4bPGxj-qru",
        "outputId": "105bd2aa-92da-4edd-d617-a48692b7c210"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# sent_id = 1\n",
            "# text = Áindrías an Ime .\n",
            "1\tÁindrías\tAindrias\tPROPN\tNoun\tDefinite=Def|Gender=Masc|Number=Sing\t_\troot\t_\t_\n",
            "2\tan\tan\tDET\tArt\tDefinite=Def|Number=Sing|PronType=Art\t3\tdet\t_\t_\n",
            "3\tIme\time\tNOUN\tNoun\tCase=Nom|Definite=Def|Gender=Masc|Number=Sing\t1\tnmod\t_\t_\n",
            "4\t.\t.\tPUNCT\t.\t_\t1\tpunct\t_\t_\n",
            "\n"
          ]
        }
      ],
      "source": [
        "run_parse(\"Áindrías an Ime.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMtPVsZZ_Ma1",
        "outputId": "e57c48e3-2c24-4eee-9c67-c99ecaf874f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# sent_id = 1\n",
            "# text = Bhí Áindrías an Ime na chomhnaidhe i mBaile ui Mún i nGleann an Bhaile Dhuibh .\n",
            "1\tBhí\tbí\tVERB\tPastInd\tForm=Len|Mood=Ind|Tense=Past\t_\troot\t_\t_\n",
            "2\tÁindrías\tAindrias\tPROPN\tNoun\tDefinite=Def|Gender=Masc|Number=Sing\t1\tnsubj\t_\t_\n",
            "3\tan\tan\tDET\tArt\tDefinite=Def|Number=Sing|PronType=Art\t4\tdet\t_\t_\n",
            "4\tIme\time\tNOUN\tNoun\tCase=Nom|Definite=Def|Gender=Masc|Number=Sing\t2\tnmod\t_\t_\n",
            "5\tna\ti\tADP\tPoss\tGender=Masc|Number=Sing|Person=3|Poss=Yes\t6\tcase\t_\t_\n",
            "6\tchomhnaidhe\tcónaí\tNOUN\tNoun\tCase=Nom|Definite=Def|Form=Len|Gender=Masc|Number=Sing\t1\txcomp:pred\t_\t_\n",
            "7\ti\ti\tADP\tSimp\t_\t8\tcase\t_\t_\n",
            "8\tmBaile\tBaile\tPROPN\tNoun\tCase=Nom|Definite=Def|Form=Ecl|Gender=Masc|Number=Sing\t6\tnmod\t_\t_\n",
            "9\tui\tuí\tPART\tPat\tPartType=Pat\t8\tflat\t_\t_\n",
            "10\tMún\tMún\tPROPN\tNoun\tCase=Gen|Definite=Def|Gender=Masc|Number=Sing\t8\tflat:name\t_\t_\n",
            "11\ti\ti\tADP\tSimp\t_\t12\tcase\t_\t_\n",
            "12\tnGleann\tgleann\tNOUN\tNoun\tCase=Nom|Definite=Def|Form=Ecl|Gender=Masc|Number=Sing\t1\tobl\t_\t_\n",
            "13\tan\tan\tDET\tArt\tCase=Gen|Definite=Def|Gender=Masc|Number=Sing|PronType=Art\t14\tdet\t_\t_\n",
            "14\tBhaile\tbaile\tNOUN\tNoun\tCase=Gen|Definite=Def|Form=Len|Gender=Masc|Number=Sing\t12\tnmod\t_\t_\n",
            "15\tDhuibh\tDuibh\tPROPN\tNoun\tCase=Gen|Definite=Def|Form=Len|Gender=Masc|Number=Sing\t14\tflat\t_\t_\n",
            "16\t.\t.\tPUNCT\t.\t_\t1\tpunct\t_\t_\n",
            "\n"
          ]
        }
      ],
      "source": [
        "run_parse(\"Bhí Áindrías an Ime na chomhnaidhe i mBaile ui Mún i nGleann an Bhaile Dhuibh.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deZchysp_xB0",
        "outputId": "8758019f-1f0b-4f25-9725-425c4254824f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# sent_id = 1\n",
            "# text = Bu leis Baile ui Mún , áit fiche bó ⁊ tarbh leobhtha .\n",
            "1\tBu\tis\tAUX\tCop\tTense=Past|VerbForm=Cop\t3\tcop\t_\t_\n",
            "2\tleis\tle\tADP\tSimp\t_\t3\tcase\t_\t_\n",
            "3\tBaile\tBaile\tPROPN\tNoun\tDefinite=Def|Gender=Masc|Number=Sing\t_\troot\t_\t_\n",
            "4\tui\tuí\tPART\tPat\tPartType=Pat\t3\tflat:name\t_\t_\n",
            "5\tMún\tMún\tPROPN\tNoun\tCase=Gen|Definite=Def|Gender=Masc|Number=Sing\t4\tflat:name\t_\t_\n",
            "6\t,\t,\tPUNCT\tPunct\t_\t7\tpunct\t_\t_\n",
            "7\táit\táit\tNOUN\tNoun\tCase=Nom|Gender=Fem|Number=Sing\t3\tappos\t_\t_\n",
            "8\tfiche\tfiche\tNUM\tNum\tNumType=Card\t9\tnummod\t_\t_\n",
            "9\tbó\tbó\tNOUN\tNoun\tCase=Nom|Gender=Fem|Number=Sing\t7\tnmod\t_\t_\n",
            "10\t⁊\t⁊\tADP\tSimp\t_\t11\tcase\t_\t_\n",
            "11\ttarbh\ttarbh\tNOUN\tNoun\tCase=Nom|Gender=Masc|Number=Sing\t7\tnmod\t_\t_\n",
            "12\tleobhtha\tle\tADP\tPrep\tNumber=Plur|Person=3\t3\tobl:prep\t_\t_\n",
            "13\t.\t.\tPUNCT\t.\t_\t3\tpunct\t_\t_\n",
            "\n"
          ]
        }
      ],
      "source": [
        "run_parse(\"Bu leis Baile ui Mún, áit fiche bó ⁊ tarbh leobhtha.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2R8NRyfoA2TW",
        "outputId": "77baef5a-d96c-43d3-e5cf-7b8644e51ee6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# sent_id = 1\n",
            "# text = Do bhíodh longphort ag na Lochlannaigh anseo .\n",
            "# text_standard = Bhíodh longfort ag na Lochlannaigh anseo .\n",
            "1\tDo bhíodh\tbí\tVERB\tPastImp\tAspect=Imp|Form=Len|Tense=Past\t_\troot\t_\t_\n",
            "2\tlongphort\tlongfort\tNOUN\tNoun\tCase=Nom|Gender=Masc|Number=Sing\t1\tnsubj\t_\t_\n",
            "3\tag\tag\tADP\tSimp\t_\t5\tcase\t_\t_\n",
            "4\tna\tan\tDET\tArt\tDefinite=Def|Number=Plur|PronType=Art\t5\tdet\t_\t_\n",
            "5\tLochlannaigh\tlochlannach\tNOUN\tNoun\tCase=Nom|Definite=Def|Gender=Masc|Number=Plur\t1\tobl\t_\t_\n",
            "6\tanseo\tanseo\tADV\tLoc\t_\t1\tadvmod\t_\t_\n",
            "7\t.\t.\tPUNCT\t.\t_\t1\tpunct\t_\t_\n",
            "\n",
            "# sent_id = 2\n",
            "# text = D'éirigh an t-árd-rí .\n",
            "# text_standard = D'éirigh an t-ard-rí .\n",
            "1\tD'éirigh\tdo\tPART\tVb\tPartType=Vb\t2\tmark:prt\t_\t_\n",
            "2\tan\téirigh\tVERB\tVI\tMood=Ind|Tense=Past\t_\troot\t_\t_\n",
            "3\tt-árd-rí\tan\tDET\tArt\tDefinite=Def|Number=Sing|PronType=Art\t4\tdet\t_\t_\n",
            "4\t.\tarda\tNOUN\tNoun\tCase=Nom|Definite=Def|Gender=Masc|Number=Sing\t2\tnsubj\t_\t_\n",
            "5\t.\t.\tPUNCT\t.\t_\t2\tpunct\t_\t_\n",
            "\n"
          ]
        }
      ],
      "source": [
        "sample = \"Do bhíodh longphort ag na Lochlannaigh anseo. D’éirigh an t‑árd‑rí.\"\n",
        "print(project_with_stanza(sample))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}