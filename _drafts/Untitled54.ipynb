{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gq4eL7Xj9psB"
      },
      "outputs": [],
      "source": [
        "!pip install stanza"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.parse, urllib.request, json, sys\n",
        "import stanza"
      ],
      "metadata": {
        "id": "PHI6wzlqAk3t"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "STD_API = \"https://cadhan.com/api/intergaelic/3.0\"\n",
        "\n",
        "def standardise(text: str, lang: str = \"ga\"):\n",
        "    \"\"\"Return a list of (orig_tok, std_tok) pairs from Intergaelic.\"\"\"\n",
        "    data   = urllib.parse.urlencode({\"foinse\": lang, \"teacs\": text}).encode()\n",
        "    hdrs   = {\"Content-Type\": \"application/x-www-form-urlencoded\",\n",
        "              \"Accept\":        \"application/json\"}\n",
        "    req    = urllib.request.Request(STD_API, data, hdrs)\n",
        "    with urllib.request.urlopen(req) as resp:\n",
        "        return json.loads(resp.read())"
      ],
      "metadata": {
        "id": "a-aFOYu_AoGu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stanza.download(\"ga\", processors=\"tokenize,pos,lemma,depparse\", verbose=False)\n",
        "\n",
        "nlp = stanza.Pipeline(\n",
        "    lang=\"ga\",\n",
        "    processors=\"tokenize,pos,lemma,depparse\",\n",
        "    # Let Stanza decide sentences & tokens\n",
        "    tokenize_pretokenized=False,\n",
        "    verbose=False\n",
        ")"
      ],
      "metadata": {
        "id": "a1WtCT_ZArRt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def project_with_stanza(raw_text: str, lang: str = \"ga\") -> str:\n",
        "    pairs        = standardise(raw_text, lang)\n",
        "    std_tokens   = [std for _orig, std in pairs]\n",
        "    std_text     = \" \".join(std_tokens)        # one long string for Stanza\n",
        "    doc          = nlp(std_text)               # Stanza finds sentences\n",
        "\n",
        "    # Walk through Stanza words in order and align with the pairs list\n",
        "    idx          = 0\n",
        "    conllu_lines = []\n",
        "    for sent_id, sent in enumerate(doc.sentences, 1):\n",
        "        conllu_lines.append(f\"# sent_id = {sent_id}\")\n",
        "        # Build the original sentence text for the comment line\n",
        "        orig_sentence = \" \".join(pairs[i][0] for i in range(idx, idx+len(sent.words)))\n",
        "        conllu_lines.append(f\"# text = {orig_sentence}\")\n",
        "\n",
        "        for wid, word in enumerate(sent.words, 1):\n",
        "            orig_tok, std_tok = pairs[idx]\n",
        "            if std_tok != word.text:           # rare but possible mismatch\n",
        "                print(f\"⚠️  token mismatch: “{std_tok}” vs “{word.text}” (will keep Stanza)\")\n",
        "            conllu_lines.append(\"\\t\".join([\n",
        "                str(wid),\n",
        "                orig_tok,                       # FORM  = original spelling\n",
        "                word.lemma or \"_\",              # LEMMA = Stanza\n",
        "                word.upos  or \"_\",\n",
        "                word.xpos  or \"_\",\n",
        "                word.feats or \"_\",\n",
        "                str(word.head) if word.head else \"_\",\n",
        "                word.deprel or \"_\",\n",
        "                \"_\",\n",
        "                \"_\",\n",
        "            ]))\n",
        "            idx += 1\n",
        "        conllu_lines.append(\"\")                # blank line between sentences\n",
        "    return \"\\n\".join(conllu_lines)"
      ],
      "metadata": {
        "id": "knN_HAk5Auzx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_parse(raw_text):\n",
        "    pairs      = standardise(raw_text, \"ga\")\n",
        "    sentences  = naive_sentences(pairs)\n",
        "    doc        = parse_standardised(sentences)\n",
        "    conllu_out = project(doc, sentences)\n",
        "    print(conllu_out)\n"
      ],
      "metadata": {
        "id": "ei2TN5Xy-gkI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_parse(\"Áindrías an Ime.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-I4bPGxj-qru",
        "outputId": "105bd2aa-92da-4edd-d617-a48692b7c210"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# sent_id = 1\n",
            "# text = Áindrías an Ime .\n",
            "1\tÁindrías\tAindrias\tPROPN\tNoun\tDefinite=Def|Gender=Masc|Number=Sing\t_\troot\t_\t_\n",
            "2\tan\tan\tDET\tArt\tDefinite=Def|Number=Sing|PronType=Art\t3\tdet\t_\t_\n",
            "3\tIme\time\tNOUN\tNoun\tCase=Nom|Definite=Def|Gender=Masc|Number=Sing\t1\tnmod\t_\t_\n",
            "4\t.\t.\tPUNCT\t.\t_\t1\tpunct\t_\t_\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_parse(\"Bhí Áindrías an Ime na chomhnaidhe i mBaile ui Mún i nGleann an Bhaile Dhuibh.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMtPVsZZ_Ma1",
        "outputId": "e57c48e3-2c24-4eee-9c67-c99ecaf874f3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# sent_id = 1\n",
            "# text = Bhí Áindrías an Ime na chomhnaidhe i mBaile ui Mún i nGleann an Bhaile Dhuibh .\n",
            "1\tBhí\tbí\tVERB\tPastInd\tForm=Len|Mood=Ind|Tense=Past\t_\troot\t_\t_\n",
            "2\tÁindrías\tAindrias\tPROPN\tNoun\tDefinite=Def|Gender=Masc|Number=Sing\t1\tnsubj\t_\t_\n",
            "3\tan\tan\tDET\tArt\tDefinite=Def|Number=Sing|PronType=Art\t4\tdet\t_\t_\n",
            "4\tIme\time\tNOUN\tNoun\tCase=Nom|Definite=Def|Gender=Masc|Number=Sing\t2\tnmod\t_\t_\n",
            "5\tna\ti\tADP\tPoss\tGender=Masc|Number=Sing|Person=3|Poss=Yes\t6\tcase\t_\t_\n",
            "6\tchomhnaidhe\tcónaí\tNOUN\tNoun\tCase=Nom|Definite=Def|Form=Len|Gender=Masc|Number=Sing\t1\txcomp:pred\t_\t_\n",
            "7\ti\ti\tADP\tSimp\t_\t8\tcase\t_\t_\n",
            "8\tmBaile\tBaile\tPROPN\tNoun\tCase=Nom|Definite=Def|Form=Ecl|Gender=Masc|Number=Sing\t6\tnmod\t_\t_\n",
            "9\tui\tuí\tPART\tPat\tPartType=Pat\t8\tflat\t_\t_\n",
            "10\tMún\tMún\tPROPN\tNoun\tCase=Gen|Definite=Def|Gender=Masc|Number=Sing\t8\tflat:name\t_\t_\n",
            "11\ti\ti\tADP\tSimp\t_\t12\tcase\t_\t_\n",
            "12\tnGleann\tgleann\tNOUN\tNoun\tCase=Nom|Definite=Def|Form=Ecl|Gender=Masc|Number=Sing\t1\tobl\t_\t_\n",
            "13\tan\tan\tDET\tArt\tCase=Gen|Definite=Def|Gender=Masc|Number=Sing|PronType=Art\t14\tdet\t_\t_\n",
            "14\tBhaile\tbaile\tNOUN\tNoun\tCase=Gen|Definite=Def|Form=Len|Gender=Masc|Number=Sing\t12\tnmod\t_\t_\n",
            "15\tDhuibh\tDuibh\tPROPN\tNoun\tCase=Gen|Definite=Def|Form=Len|Gender=Masc|Number=Sing\t14\tflat\t_\t_\n",
            "16\t.\t.\tPUNCT\t.\t_\t1\tpunct\t_\t_\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_parse(\"Bu leis Baile ui Mún, áit fiche bó ⁊ tarbh leobhtha.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deZchysp_xB0",
        "outputId": "8758019f-1f0b-4f25-9725-425c4254824f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# sent_id = 1\n",
            "# text = Bu leis Baile ui Mún , áit fiche bó ⁊ tarbh leobhtha .\n",
            "1\tBu\tis\tAUX\tCop\tTense=Past|VerbForm=Cop\t3\tcop\t_\t_\n",
            "2\tleis\tle\tADP\tSimp\t_\t3\tcase\t_\t_\n",
            "3\tBaile\tBaile\tPROPN\tNoun\tDefinite=Def|Gender=Masc|Number=Sing\t_\troot\t_\t_\n",
            "4\tui\tuí\tPART\tPat\tPartType=Pat\t3\tflat:name\t_\t_\n",
            "5\tMún\tMún\tPROPN\tNoun\tCase=Gen|Definite=Def|Gender=Masc|Number=Sing\t4\tflat:name\t_\t_\n",
            "6\t,\t,\tPUNCT\tPunct\t_\t7\tpunct\t_\t_\n",
            "7\táit\táit\tNOUN\tNoun\tCase=Nom|Gender=Fem|Number=Sing\t3\tappos\t_\t_\n",
            "8\tfiche\tfiche\tNUM\tNum\tNumType=Card\t9\tnummod\t_\t_\n",
            "9\tbó\tbó\tNOUN\tNoun\tCase=Nom|Gender=Fem|Number=Sing\t7\tnmod\t_\t_\n",
            "10\t⁊\t⁊\tADP\tSimp\t_\t11\tcase\t_\t_\n",
            "11\ttarbh\ttarbh\tNOUN\tNoun\tCase=Nom|Gender=Masc|Number=Sing\t7\tnmod\t_\t_\n",
            "12\tleobhtha\tle\tADP\tPrep\tNumber=Plur|Person=3\t3\tobl:prep\t_\t_\n",
            "13\t.\t.\tPUNCT\t.\t_\t3\tpunct\t_\t_\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = \"Do bhíodh longphort ag na Lochlannaigh anseo. D’éirigh an t‑árd‑rí.\"\n",
        "print(project_with_stanza(sample))\n"
      ],
      "metadata": {
        "id": "2R8NRyfoA2TW",
        "outputId": "fcd7ecc0-8b4d-49f0-b193-622ed0cc28b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-6e81996f9773>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Do bhíodh longphort ag na Lochlannaigh anseo. D’éirigh an t‑árd‑rí.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_with_stanza\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-1e93631498c4>\u001b[0m in \u001b[0;36mproject_with_stanza\u001b[0;34m(raw_text, lang)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mconllu_lines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"# sent_id = {sent_id}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# Build the original sentence text for the comment line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0morig_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mconllu_lines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"# text = {orig_sentence}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-1e93631498c4>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mconllu_lines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"# sent_id = {sent_id}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# Build the original sentence text for the comment line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0morig_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mconllu_lines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"# text = {orig_sentence}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    }
  ]
}