{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gq4eL7Xj9psB"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install stanza"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.parse, urllib.request, json, sys\n",
        "import stanza"
      ],
      "metadata": {
        "id": "PHI6wzlqAk3t"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "STD_API = \"https://cadhan.com/api/intergaelic/3.0\"\n",
        "\n",
        "def standardise(text: str, lang: str = \"ga\"):\n",
        "    \"\"\"Return a list of (orig_tok, std_tok) pairs from Intergaelic.\"\"\"\n",
        "    data   = urllib.parse.urlencode({\"foinse\": lang, \"teacs\": text}).encode()\n",
        "    hdrs   = {\"Content-Type\": \"application/x-www-form-urlencoded\",\n",
        "              \"Accept\":        \"application/json\"}\n",
        "    req    = urllib.request.Request(STD_API, data, hdrs)\n",
        "    with urllib.request.urlopen(req) as resp:\n",
        "        return json.loads(resp.read())"
      ],
      "metadata": {
        "id": "a-aFOYu_AoGu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stanza.download(\"ga\", processors=\"tokenize,pos,lemma,depparse\", verbose=False)\n",
        "\n",
        "nlp = stanza.Pipeline(\n",
        "    lang=\"ga\",\n",
        "    processors=\"tokenize,pos,lemma,depparse\",\n",
        "    # Let Stanza decide sentences & tokens\n",
        "    tokenize_pretokenized=True,\n",
        "    no_ssplit=True,\n",
        "    verbose=False\n",
        ")"
      ],
      "metadata": {
        "id": "a1WtCT_ZArRt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell ▸ robust projection with multi‑word support\n",
        "# -----------------------------------------------\n",
        "from itertools import groupby\n",
        "from typing import List, Tuple\n",
        "\n",
        "def _split_std(std: str, orig: str) -> List[str]:\n",
        "    \"\"\"Return the token(s) that should feed Stanza for this pair.\"\"\"\n",
        "    if not std.strip():                         # e.g. Do → \"\"  → keep 'Do'\n",
        "        return [orig]\n",
        "    return std.split()                          # may yield 1‑N tokens\n",
        "\n",
        "def _sentences_from_pairs(pairs: List[Tuple[str, str]]):\n",
        "    \"\"\"Very light sentence splitter: keep everything up to . ! ?\"\"\"\n",
        "    sent, buf = [], []\n",
        "    for i, (orig, std) in enumerate(pairs):\n",
        "        parts = _split_std(std, orig)\n",
        "        for j, part in enumerate(parts):\n",
        "            buf.append((i, j, len(parts), orig, part))  # mapping entry\n",
        "            if part in {\".\", \"!\", \"?\"}:\n",
        "                sent.append(buf);  buf = []\n",
        "    if buf:\n",
        "        sent.append(buf)\n",
        "    return sent                                       # [[mapping …], …]\n",
        "\n",
        "def project_with_stanza(raw_text: str, lang: str = \"ga\") -> str:\n",
        "    # 1 ── standardise -------------------------------------------------------\n",
        "    pairs  = standardise(raw_text, lang)             # [(orig, std), …]\n",
        "\n",
        "    # 2 ── build *pre‑tokenised* input & a mapping table ---------------------\n",
        "    sents  = _sentences_from_pairs(pairs)            # list‑of‑sentences\n",
        "    pretok = [[m[4] for m in sent] for sent in sents]  # token strings only\n",
        "\n",
        "    # 3 ── parse with Stanza *pretok* mode -----------------------------------\n",
        "    doc = nlp(pretok)                                # same shape as `sents`\n",
        "\n",
        "    # 4 ── project back, keeping multi‑word tokens ---------------------------\n",
        "    conllu_lines = []\n",
        "    for sid, (sent_map, sent_doc) in enumerate(zip(sents, doc.sentences), 1):\n",
        "        # comment lines\n",
        "        raw_slice = [m[3]           for m in sent_map if m[1] == 0]     # first sub‑token per orig\n",
        "        std_slice = [m[4]           for m in sent_map]                  # every sub‑token\n",
        "        conllu_lines += [\n",
        "            f\"# sent_id = {sid}\",\n",
        "            f\"# text = {' '.join(raw_slice)}\",\n",
        "            f\"# text_standard = {' '.join(std_slice)}\",\n",
        "        ]\n",
        "\n",
        "        # token lines\n",
        "        widx = 0                                     # index in sent_doc.words\n",
        "        tid  = 1                                     # running token ID in CONLL‑U\n",
        "        for m in sent_map:\n",
        "            orig_i, sub_i, n_sub, orig_tok, std_tok = m\n",
        "            word = sent_doc.words[widx]\n",
        "\n",
        "            if sub_i == 0 and n_sub > 1:             # multi‑word‑token header\n",
        "                conllu_lines.append(f\"{tid}-{tid+n_sub-1}\\t{orig_tok}\\t_\\t_\\t_\\t_\\t_\\t_\\t_\\t_\")\n",
        "\n",
        "            # choose FORM for the sub‑token\n",
        "            form = orig_tok if n_sub == 1 else std_tok\n",
        "\n",
        "            conllu_lines.append(\"\\t\".join([\n",
        "                str(tid),\n",
        "                form,\n",
        "                word.lemma or \"_\",\n",
        "                word.upos  or \"_\",\n",
        "                word.xpos  or \"_\",\n",
        "                word.feats or \"_\",\n",
        "                str(word.head) if word.head else \"_\",\n",
        "                word.deprel or \"_\",\n",
        "                \"_\",\n",
        "                \"_\",\n",
        "            ]))\n",
        "\n",
        "            widx += 1\n",
        "            tid  += 1\n",
        "        conllu_lines.append(\"\")                      # blank line between sents\n",
        "\n",
        "    return \"\\n\".join(conllu_lines)\n"
      ],
      "metadata": {
        "id": "knN_HAk5Auzx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_parse(raw_text):\n",
        "    pairs      = standardise(raw_text, \"ga\")\n",
        "    sentences  = naive_sentences(pairs)\n",
        "    doc        = parse_standardised(sentences)\n",
        "    conllu_out = project(doc, sentences)\n",
        "    print(conllu_out)\n"
      ],
      "metadata": {
        "id": "ei2TN5Xy-gkI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(project_with_stanza(\"Áindrías an Ime.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-I4bPGxj-qru",
        "outputId": "eb168871-3fd0-413b-d82e-b2a64c9ad456"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# sent_id = 1\n",
            "# text = Áindrías an Ime .\n",
            "# text_standard = Aindrias an Ime .\n",
            "1\tÁindrías\tAindrias\tPROPN\tNoun\tDefinite=Def|Gender=Masc|Number=Sing\t_\troot\t_\t_\n",
            "2\tan\tan\tDET\tArt\tDefinite=Def|Number=Sing|PronType=Art\t3\tdet\t_\t_\n",
            "3\tIme\time\tNOUN\tNoun\tCase=Nom|Definite=Def|Gender=Masc|Number=Sing\t1\tnmod\t_\t_\n",
            "4\t.\t.\tPUNCT\t.\t_\t1\tpunct\t_\t_\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(project_with_stanza(\"áit an ime.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1OjyfETtTT4",
        "outputId": "7b70a250-255f-4b61-dba6-62025502e1e7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# sent_id = 1\n",
            "# text = áit an ime .\n",
            "# text_standard = áit an ime .\n",
            "1\táit\táit\tNOUN\tNoun\tCase=Nom|Definite=Def|Gender=Fem|Number=Sing\t_\troot\t_\t_\n",
            "2\tan\tan\tDET\tArt\tCase=Gen|Definite=Def|Gender=Masc|Number=Sing|PronType=Art\t3\tdet\t_\t_\n",
            "3\time\time\tNOUN\tNoun\tCase=Gen|Definite=Def|Gender=Masc|Number=Sing\t1\tnmod\t_\t_\n",
            "4\t.\t.\tPUNCT\t.\t_\t1\tpunct\t_\t_\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(project_with_stanza(\"Bhí Áindrías an ime na chomhnaidhe i mBaile ui Mún i nGleann an Bhaile Dhuibh.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMtPVsZZ_Ma1",
        "outputId": "8b765a2b-60ae-4dba-8b5c-03cbb6fbec72"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# sent_id = 1\n",
            "# text = Bhí Áindrías an ime na chomhnaidhe i mBaile ui Mún i nGleann an Bhaile Dhuibh .\n",
            "# text_standard = Bhí Aindrias an ime ina chónaí i mBaile uí Mún i nGleann an Bhaile Dhuibh .\n",
            "1\tBhí\tbí\tVERB\tPastInd\tForm=Len|Mood=Ind|Tense=Past\t_\troot\t_\t_\n",
            "2\tÁindrías\tAindrias\tPROPN\tNoun\tDefinite=Def|Gender=Masc|Number=Sing\t1\tnsubj\t_\t_\n",
            "3\tan\tan\tDET\tArt\tDefinite=Def|Number=Sing|PronType=Art\t4\tdet\t_\t_\n",
            "4\time\time\tNOUN\tNoun\tCase=Nom|Definite=Def|Gender=Masc|Number=Sing\t2\tnmod\t_\t_\n",
            "5\tna\ti\tADP\tPoss\tGender=Masc|Number=Sing|Person=3|Poss=Yes\t6\tcase\t_\t_\n",
            "6\tchomhnaidhe\tcónaí\tNOUN\tNoun\tCase=Nom|Definite=Def|Form=Len|Gender=Masc|Number=Sing\t1\txcomp:pred\t_\t_\n",
            "7\ti\ti\tADP\tSimp\t_\t8\tcase\t_\t_\n",
            "8\tmBaile\tBaile\tPROPN\tNoun\tCase=Nom|Definite=Def|Form=Ecl|Gender=Masc|Number=Sing\t6\tnmod\t_\t_\n",
            "9\tui\tuí\tPART\tPat\tPartType=Pat\t8\tflat\t_\t_\n",
            "10\tMún\tMún\tPROPN\tNoun\tCase=Gen|Definite=Def|Gender=Masc|Number=Sing\t8\tflat:name\t_\t_\n",
            "11\ti\ti\tADP\tSimp\t_\t12\tcase\t_\t_\n",
            "12\tnGleann\tgleann\tNOUN\tNoun\tCase=Nom|Definite=Def|Form=Ecl|Gender=Masc|Number=Sing\t1\tobl\t_\t_\n",
            "13\tan\tan\tDET\tArt\tCase=Gen|Definite=Def|Gender=Masc|Number=Sing|PronType=Art\t14\tdet\t_\t_\n",
            "14\tBhaile\tbaile\tNOUN\tNoun\tCase=Gen|Definite=Def|Form=Len|Gender=Masc|Number=Sing\t12\tnmod\t_\t_\n",
            "15\tDhuibh\tDuibh\tPROPN\tNoun\tCase=Gen|Definite=Def|Form=Len|Gender=Masc|Number=Sing\t14\tflat\t_\t_\n",
            "16\t.\t.\tPUNCT\t.\t_\t1\tpunct\t_\t_\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_parse(\"Bu leis Baile ui Mún, áit fiche bó ⁊ tarbh leobhtha.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deZchysp_xB0",
        "outputId": "8758019f-1f0b-4f25-9725-425c4254824f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# sent_id = 1\n",
            "# text = Bu leis Baile ui Mún , áit fiche bó ⁊ tarbh leobhtha .\n",
            "1\tBu\tis\tAUX\tCop\tTense=Past|VerbForm=Cop\t3\tcop\t_\t_\n",
            "2\tleis\tle\tADP\tSimp\t_\t3\tcase\t_\t_\n",
            "3\tBaile\tBaile\tPROPN\tNoun\tDefinite=Def|Gender=Masc|Number=Sing\t_\troot\t_\t_\n",
            "4\tui\tuí\tPART\tPat\tPartType=Pat\t3\tflat:name\t_\t_\n",
            "5\tMún\tMún\tPROPN\tNoun\tCase=Gen|Definite=Def|Gender=Masc|Number=Sing\t4\tflat:name\t_\t_\n",
            "6\t,\t,\tPUNCT\tPunct\t_\t7\tpunct\t_\t_\n",
            "7\táit\táit\tNOUN\tNoun\tCase=Nom|Gender=Fem|Number=Sing\t3\tappos\t_\t_\n",
            "8\tfiche\tfiche\tNUM\tNum\tNumType=Card\t9\tnummod\t_\t_\n",
            "9\tbó\tbó\tNOUN\tNoun\tCase=Nom|Gender=Fem|Number=Sing\t7\tnmod\t_\t_\n",
            "10\t⁊\t⁊\tADP\tSimp\t_\t11\tcase\t_\t_\n",
            "11\ttarbh\ttarbh\tNOUN\tNoun\tCase=Nom|Gender=Masc|Number=Sing\t7\tnmod\t_\t_\n",
            "12\tleobhtha\tle\tADP\tPrep\tNumber=Plur|Person=3\t3\tobl:prep\t_\t_\n",
            "13\t.\t.\tPUNCT\t.\t_\t3\tpunct\t_\t_\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = \"Do bhíodh longphort ag na Lochlannaigh anseo. D’éirigh an t‑árd‑rí.\"\n",
        "print(project_with_stanza(\"Bu leis Baile ui Mún, áit fiche bó agus tarbh leobhtha.\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2R8NRyfoA2TW",
        "outputId": "d11c4e57-b538-4f10-8144-dc214946bbf2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# sent_id = 1\n",
            "# text = Bu leis Baile ui Mún , áit fiche bó agus tarbh leobhtha .\n",
            "# text_standard = Ba leis Baile uí Mún , áit fiche bó agus tarbh leo .\n",
            "1\tBu\tis\tAUX\tCop\tTense=Past|VerbForm=Cop\t3\tcop\t_\t_\n",
            "2\tleis\tle\tADP\tSimp\t_\t3\tcase\t_\t_\n",
            "3\tBaile\tBaile\tPROPN\tNoun\tDefinite=Def|Gender=Masc|Number=Sing\t_\troot\t_\t_\n",
            "4\tui\tuí\tPART\tPat\tPartType=Pat\t3\tflat:name\t_\t_\n",
            "5\tMún\tMún\tPROPN\tNoun\tCase=Gen|Definite=Def|Gender=Masc|Number=Sing\t4\tflat:name\t_\t_\n",
            "6\t,\t,\tPUNCT\tPunct\t_\t7\tpunct\t_\t_\n",
            "7\táit\táit\tNOUN\tNoun\tCase=Nom|Gender=Fem|Number=Sing\t3\tappos\t_\t_\n",
            "8\tfiche\tfiche\tNUM\tNum\tNumType=Card\t9\tnummod\t_\t_\n",
            "9\tbó\tbó\tNOUN\tNoun\tCase=Nom|Gender=Fem|Number=Sing\t7\tnmod\t_\t_\n",
            "10\tagus\tagus\tCCONJ\tCoord\t_\t11\tcc\t_\t_\n",
            "11\ttarbh\ttarbh\tNOUN\tNoun\tCase=Nom|Gender=Masc|Number=Sing\t3\tconj\t_\t_\n",
            "12\tleobhtha\tle\tADP\tPrep\tNumber=Plur|Person=3\t11\tobl:prep\t_\t_\n",
            "13\t.\t.\tPUNCT\t.\t_\t3\tpunct\t_\t_\n",
            "\n"
          ]
        }
      ]
    }
  ]
}