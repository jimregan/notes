{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "dictfile = \"/Users/joregan/Documents/MFA/pretrained_models/dictionary/hsi_english_us_arpa.dict\"\n",
    "tgfiles = \"/Users/joregan/Playing/hsi_ctmedit/textgrid/\"\n",
    "outdict = \"/tmp/added.dict\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP = {\n",
    "    \"JH\": \"Y\",\n",
    "    \"W\": \"V\",\n",
    "    \"V\": \"B\",\n",
    "    \"B\": \"V\"\n",
    "}\n",
    "\n",
    "TRAP_BATH = [\"S\", \"F\", \"TH\", \"N\", \"V\", \"Z\", \"SH\", \"M\", \"L\", \"DH\"]\n",
    "\n",
    "# everything but 'ER'\n",
    "PURE_VOWELS = [\n",
    "    \"AA\",\n",
    "    \"AE\",\n",
    "    \"AH\",\n",
    "    \"AO\",\n",
    "    \"AW\",\n",
    "    \"AY\",\n",
    "    \"EH\",\n",
    "    \"EY\",\n",
    "    \"IH\",\n",
    "    \"IY\",\n",
    "    \"OW\",\n",
    "    \"OY\",\n",
    "    \"UH\",\n",
    "    \"UW\"\n",
    "]\n",
    "\n",
    "\n",
    "def is_vowel(phone):\n",
    "    if phone[-1:] in [\"0\", \"1\", \"2\"]:\n",
    "        phone = phone[:-1]\n",
    "    return phone in PURE_VOWELS\n",
    "\n",
    "\n",
    "def expand_inner(text):\n",
    "    phones = text.split(\" \")\n",
    "    outphones = []\n",
    "    if len(phones) >= 2 and phones[0] == \"S\" and phones[1] in [\"T\", \"P\", \"M\"]:\n",
    "        outphones.append([\"EH0\", \"\"])\n",
    "    i = 0\n",
    "    next_opt = False\n",
    "    for i in range(len(phones)):\n",
    "        cur = [phones[i]]\n",
    "        if next_opt:\n",
    "            cur.append(\"\")\n",
    "            next_opt = False\n",
    "        if phones[i] in EXP:\n",
    "            cur.append(EXP[phones[i]])\n",
    "        if i < len(phones) - 1 and phones[i] in [\"S\", \"N\"] and phones[i+1] == \"T\":\n",
    "            next_opt = True\n",
    "        if i < len(phones) - 1 and phones[i].startswith(\"AE\") and phones[i+1] in TRAP_BATH:\n",
    "            cur.append(\"AA\" + phones[i][-1])\n",
    "        if i < len(phones) - 1 and phones[i].startswith(\"AA\") and phones[i+1] == \"R\":\n",
    "            cur.append(\"AE\" + phones[i][-1])\n",
    "        if phones[i].startswith(\"ER\"):\n",
    "            emph = phones[i][-1]\n",
    "            cur.append(\"EH\" + emph)\n",
    "            cur.append(\"AH\" + emph)\n",
    "        if i < len(phones) - 1 and is_vowel(phones[i]) and phones[i+1] == \"R\":\n",
    "            next_opt = True\n",
    "\n",
    "        outphones.append(cur)\n",
    "    return outphones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def expand(text):\n",
    "    return [list(x) for x in itertools.product(*expand_inner(text))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = {}\n",
    "with open(dictfile) as df:\n",
    "    for line in df.readlines():\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        if not parts[0] in entries:\n",
    "            entries[parts[0]] = []\n",
    "        entries[parts[0]].append(parts[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from praatio import textgrid\n",
    "import re\n",
    "\n",
    "def norm(text):\n",
    "    words = text.split(\" \")\n",
    "    words = [w.strip(\"\\\",.;:?!\").upper() for w in words if not w.startswith(\"[\")]\n",
    "    return words\n",
    "\n",
    "\n",
    "seen_words = []\n",
    "missing = []\n",
    "new_entries = set()\n",
    "\n",
    "for textgridfile in Path(tgfiles).glob(\"*.[Tt]ext[Gg]rid\"):\n",
    "    tg = textgrid.openTextgrid(textgridfile, includeEmptyIntervals=False)\n",
    "\n",
    "    if len(tg.tierNames) == 1:\n",
    "        tier = tg.getTier(tg.tierNames[0])\n",
    "    elif \"whisperx\" in tg.tierNames:\n",
    "        tier = tg.getTier(\"whisperx\")\n",
    "    elif \"utterances\" in tg.tierNames:\n",
    "        tier = tg.getTier(\"utterances\")\n",
    "    elif \"words\" in tg.tierNames:\n",
    "        tier = tg.getTier(\"words\")\n",
    "    else:\n",
    "        print(\"Be careful: file\", textgridfile, \"has none of the expected tier names\")\n",
    "\n",
    "    for interval in tier.entries:\n",
    "        start = interval[0]\n",
    "        end = interval[1]\n",
    "        text = interval[2]\n",
    "\n",
    "        m = re.match(\"^\\[[^]]+\\]$\", text)\n",
    "        if m:\n",
    "            continue\n",
    "        \n",
    "        for word in norm(text):\n",
    "            word = word.lower()\n",
    "            if word in seen_words:\n",
    "                continue\n",
    "            if not word in entries:\n",
    "                missing.append(word)\n",
    "                continue\n",
    "            if word.endswith(\"-\"):\n",
    "                continue\n",
    "            for pron in entries[word]:\n",
    "                for expanded in expand(pron):\n",
    "                    # filter existing pronunciations!\n",
    "                    joined = ' '.join(expanded)\n",
    "                    joined = re.sub(\"  +\", \" \", joined.strip())\n",
    "                    if not joined in entries[word]:\n",
    "                        new_entries.add(f\"{word}\\t{joined}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JH AH1 S T', 'JH AH1 S', 'Y AH1 S T', 'Y AH1 S']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\" \".join(x).strip() for x in expand(\"JH AH1 S T\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(outdict, \"w\") as outf:\n",
    "    for i in sorted(new_entries):\n",
    "        outf.write(i + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'',\n",
       " 'a-',\n",
       " 'ab-',\n",
       " 'al-',\n",
       " 'an-',\n",
       " 'ano-',\n",
       " 'ash-',\n",
       " 'av-',\n",
       " 'bi-',\n",
       " 'bl-',\n",
       " 'bu-',\n",
       " 'cen-',\n",
       " 'ch-',\n",
       " 'computational',\n",
       " 'con-',\n",
       " 'cont-',\n",
       " 'd-',\n",
       " 'deflates',\n",
       " 'di-',\n",
       " 'do-',\n",
       " 'e-',\n",
       " 'emails',\n",
       " 'g-',\n",
       " \"grandparents'\",\n",
       " 'great-grandmother',\n",
       " 'h-',\n",
       " 'ha-',\n",
       " 'hi-',\n",
       " 'high-tech',\n",
       " 'int-',\n",
       " 'internship',\n",
       " 'key-',\n",
       " 'kind-',\n",
       " 'l-shape',\n",
       " 'lan-',\n",
       " 'le-',\n",
       " 'li-',\n",
       " 'm-',\n",
       " 'may-',\n",
       " 'mol-',\n",
       " 'n-',\n",
       " 'nn',\n",
       " 'outs-',\n",
       " 'pa-',\n",
       " 'pc',\n",
       " 'plushies',\n",
       " 'pop-up',\n",
       " 'r-',\n",
       " 'real-',\n",
       " 's-',\n",
       " 'sh-',\n",
       " 'some-',\n",
       " 'sta-',\n",
       " 'superpowers',\n",
       " 't-',\n",
       " 't-pose',\n",
       " 'ta-',\n",
       " 'th-',\n",
       " 'tha-',\n",
       " 'the-',\n",
       " 'this-',\n",
       " 'three-',\n",
       " 'tr-',\n",
       " 'tromsÃ¸',\n",
       " \"tv's\",\n",
       " 'u-',\n",
       " 'unrespectful',\n",
       " 'v-',\n",
       " 'vi-',\n",
       " 'w-',\n",
       " 'we-',\n",
       " 'wh-',\n",
       " 'whe-',\n",
       " 'work-',\n",
       " 'wuh',\n",
       " 'y-'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(missing)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
