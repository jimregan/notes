{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "dictfile = \"/Users/joregan/Documents/MFA/pretrained_models/dictionary/hsi_english_us_arpa.dict\"\n",
    "tgfiles = \"/Users/joregan/Playing/hsi_ctmedit/textgrid/\"\n",
    "outdict = \"/tmp/added.dict\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP = {\n",
    "    \"JH\": \"Y\",\n",
    "    \"W\": \"V\",\n",
    "    \"V\": \"B\",\n",
    "    \"B\": \"V\"\n",
    "}\n",
    "\n",
    "TRAP_BATH = [\"S\", \"F\", \"TH\", \"N\", \"V\", \"Z\", \"SH\", \"M\", \"L\", \"DH\"]\n",
    "\n",
    "def expand_inner(text):\n",
    "    phones = text.split(\" \")\n",
    "    outphones = []\n",
    "    if len(phones) >= 2 and phones[0] == \"S\" and phones[1] in [\"T\", \"P\", \"M\"]:\n",
    "        outphones.append([\"EH0\", \"\"])\n",
    "    i = 0\n",
    "    next_opt = False\n",
    "    for i in range(len(phones)):\n",
    "        cur = [phones[i]]\n",
    "        if next_opt:\n",
    "            cur.append(\"\")\n",
    "            next_opt = False\n",
    "        if phones[i] in EXP:\n",
    "            cur.append(EXP[phones[i]])\n",
    "        if i < len(phones) - 1 and phones[i] in [\"S\", \"N\"] and phones[i+1] == \"T\":\n",
    "            next_opt = True\n",
    "        if i < len(phones) - 1 and phones[i].startswith(\"AE\") and phones[i+1] in TRAP_BATH:\n",
    "            cur.append(\"AA\" + phones[i][-1])\n",
    "        if i < len(phones) - 1 and phones[i].startswith(\"AA\") and phones[i+1] == \"R\":\n",
    "            cur.append(\"AE\" + phones[i][-1])\n",
    "\n",
    "        outphones.append(cur)\n",
    "    return outphones            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def expand(text):\n",
    "    return [list(x) for x in expand_inner(text)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = {}\n",
    "with open(dictfile) as df:\n",
    "    for line in df.readlines():\n",
    "        parts = line.split(\"\\t\")\n",
    "        if not parts[0] in entries:\n",
    "            entries[parts[0]] = []\n",
    "        entries[parts[0]].append(parts[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from praatio import textgrid\n",
    "import re\n",
    "\n",
    "def norm(text):\n",
    "    words = text.split(\" \")\n",
    "    words = [w.strip(\"\\\",.;:?!\").upper() for w in words if not w.startswith(\"[\")]\n",
    "    return words\n",
    "\n",
    "\n",
    "seen_words = []\n",
    "missing = []\n",
    "new_entries = set()\n",
    "\n",
    "for textgridfile in Path(tgfiles).glob(\"*.[Tt]ext[Gg]rid\"):\n",
    "    tg = textgrid.openTextgrid(textgridfile, includeEmptyIntervals=False)\n",
    "\n",
    "    if len(tg.tierNames) == 1:\n",
    "        tier = tg.getTier(tg.tierNames[0])\n",
    "    elif \"whisperx\" in tg.tierNames:\n",
    "        tier = tg.getTier(\"whisperx\")\n",
    "    elif \"utterances\" in tg.tierNames:\n",
    "        tier = tg.getTier(\"utterances\")\n",
    "    elif \"words\" in tg.tierNames:\n",
    "        tier = tg.getTier(\"words\")\n",
    "    else:\n",
    "        print(\"Be careful: file\", textgridfile, \"has none of the expected tier names\")\n",
    "\n",
    "    for interval in tier.entries:\n",
    "        start = interval[0]\n",
    "        end = interval[1]\n",
    "        text = interval[2]\n",
    "\n",
    "        m = re.match(\"^\\[[^]]+\\]$\", text)\n",
    "        if m:\n",
    "            continue\n",
    "        \n",
    "        for word in norm(text):\n",
    "            if word in seen_words:\n",
    "                continue\n",
    "            if not word in entries:\n",
    "                missing.append(word)\n",
    "                continue\n",
    "            for pron in entries[word]:\n",
    "                for expanded in expand(pron):\n",
    "                    # filter existing pronunciations!\n",
    "                    new_entries.add(f\"{word}\\t{' '.join(expanded)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
