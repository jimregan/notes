\documentclass{article}
\usepackage{graphicx} % Required for inserting images

\title{Speech Recognition: Key Breakthroughs and Foundations}
\author{Jim O'Regan}
\date{May 2023}

\begin{document}

\maketitle

\section{Introduction}

Artificial intelligence and related fields are almost as old as computing itself. The idea of automatic speech recognition (ASR) has been a long-standing challenge in artificial intelligence, with early inspirations coming from the notion that computers could be "thinking machines." Early work in AI included code-breaking machines at Bletchley Park during World War II, which influenced early machine translation attempts, treating language as a type of code to be deciphered.

Speech is a natural mode of human communication, requiring no training, making ASR a key goal in AI. ASR allows for hands-free and efficient input, benefiting accessibility applications and enabling interaction in scenarios where typing is impractical. Despite its intuitive appeal, ASR has faced significant challenges, including variability in speech, noise, and computational complexity.

This chapter explores key breakthroughs in ASR, from early template-matching methods to modern deep learning-based approaches. Additionally, we discuss the foundational *source-filter model* of speech production, which underpins many feature extraction techniques used in ASR.

\section{The Source-Filter Model and Feature Extraction}

One of the most influential models in speech processing is the *source-filter model*, formulated by Gunnar Fant in 1960 \cite{fant1960}. This model describes speech production as a two-stage process:
\begin{itemize}
    \item A sound source (e.g., vocal cord vibration for voiced sounds, turbulence for fricatives).
    \item A vocal tract filter that shapes the raw source sound into phonemes.
\end{itemize}

\subsection{Influence on Formant Analysis and MFCCs}

The *source-filter model* has had a profound influence on **formant analysis** and **Mel-Frequency Cepstral Coefficients (MFCCs)**, two essential techniques in speech processing.

\subsubsection{Formant Analysis}
Formants are resonant frequencies in the vocal tract that characterize different vowel sounds. The source-filter model explains how these frequencies arise due to the shape and length of the vocal tract, making **formant tracking** a crucial technique in phonetic analysis and speech recognition. 

Formants are typically estimated using techniques such as **Linear Predictive Coding (LPC)** \cite{markel1976} and **Short-Time Fourier Transform (STFT)** \cite{oppenheim1999discrete}. Formant frequencies have been widely used in speech applications, including speaker identification, vowel classification, and forensic voice analysis \cite{titze1994principles}.

\subsubsection{Mel-Frequency Cepstral Coefficients (MFCCs)}
MFCCs are one of the most widely used feature extraction methods in ASR. Their design is inspired by the **source-filter model** in several ways:
\begin{itemize}
    \item The vocal tract acts as a filter, shaping speech sounds. MFCCs capture the spectral envelope, which corresponds to this filtering effect.
    \item The Mel scale, used in MFCC computation, mimics the human ear’s sensitivity to different frequency ranges \cite{stevens1937scale}.
    \item The **discrete cosine transform (DCT)** applied in MFCC extraction removes correlation between frequency components, similar to how the source-filter model separates the excitation source from vocal tract resonances \cite{mermelstein1976}.
\end{itemize}

MFCCs remain a standard in ASR despite deep learning models increasingly learning features directly from raw waveforms \cite{baevski2020wav2vec}.

\section{Breakthroughs in Speech Recognition}

\subsection{Early Template-Based Systems (1950s–1970s)}
Early ASR systems were based on *template matching*, where stored examples of spoken words were compared against input speech. Notable early systems include:
\begin{itemize}
    \item Bell Labs' "Audrey" (1952) – recognized spoken digits but was speaker-dependent \cite{davis52digits}.
    \item IBM's "Shoebox" (1961) – a calculator controlled by voice commands.
    \item The CMU HARPY system (1976) – introduced beam search and phoneme-based modeling \cite{lowerre1976harpy}.
\end{itemize}

\subsection{Hidden Markov Models and Statistical ASR (1980s–2000s)}
The adoption of *Hidden Markov Models (HMMs)* revolutionized ASR by introducing probabilistic modeling. Notable advances include:
\begin{itemize}
    \item The DRAGON system (1975) – introduced stochastic models for speech \cite{baker1975stochastic}.
    \item IBM's HMM-based speech recognizer (1980s) \cite{jelinek76csr}.
    \item The widespread use of triphone-based modeling \cite{schwartz85triphone}.
    \item Introduction of **Gaussian Mixture Models (GMMs)** to improve acoustic modeling.
    \item Advancements in **n-gram language models** for better contextual recognition.
\end{itemize}

\subsection{Deep Learning-Based ASR (2010s–Present)}
In recent years, deep learning has driven major advances in ASR. Key developments include:
\begin{itemize}
    \item *Connectionist Temporal Classification (CTC)* \cite{graves2006} – enabled sequence-to-sequence training without explicit alignment.
    \item *Attention-based models* – allowed for better context modeling but suffered from latency issues \cite{bahdanau2016}.
    \item *Transducer models* – improved efficiency and real-time performance \cite{graves2012}.
    \item *End-to-End ASR* (e.g., Whisper by OpenAI) – eliminated the need for explicit phoneme modeling and language models \cite{radford2022whisper}.
    \item *Self-Supervised Learning* (e.g., wav2vec, HuBERT) – improved ASR performance with limited labeled data \cite{baevski2020wav2vec}.
\end{itemize}

\bibliographystyle{IEEEtran}
\bibliography{mybib}

\end{document}

