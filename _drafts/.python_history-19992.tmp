import json
with open("[download] Downloading video 9 of 23
[youtube] zr3Ofv-1H_4: Downloading webpage
[youtube] zr3Ofv-1H_4: Downloading MPD manifest
[download] Destination: zr3Ofv-1H_4.mp4
with open("H4C320170201SfU8") as jsonfile:
	json.load(jsonfile)
with open("H4C320170201SfU8") as jsonfile:
	api=json.load(jsonfile)
api
api['videodata']
api['videodata']['streams']
api['videodata'][0]['streams']
api['videodata'][0]['streams'][0]
api['videodata'][0]['streams']['files']
api['videodata'][0]['streams']['files'][0]
for video_link in api['videodata'][0]['streams']['files'][0]:
	if video_link['name'] == 'Hög kvalitet':
		url = video_link['url']
for video_link in api['videodata'][0]['streams']['files']:
	if video_link['name'] == 'Hög kvalitet':
		url = video_link['url']
 api['videodata'][0]['streams']['files'][0]
api['videodata'][0]['streams']['files'][0]
api['videodata'][0]['streams']['files'][0]['bandwidth']
api['videodata'][0]['streams']['files'][0]['bandwidth'][0]
for video_link in api['videodata'][0]['streams']['files'][0]['bandwidth']:
	if video_link['name'] == 'Hög kvalitet':
		url = video_link['url']
url
for video_link in api['videodata'][0]['streams']['files'][0]['bandwidth']:
	if video_link['name'] == 'Hög kvalitet':
		url = video_link['downloadurl']
url
len(api['videodata'][0])
len(api['videodata'])
4 == True
5 == 5 > 1
5 == 5 > 2
5 == 5 > 7
(5 == 5) > 7
5 == (5 > 7)
(5 == 5) > 1
5 == (5 > 1)
5 == 4 > 1
from datasets import load_dataset
timit = load_dataset("timit_asr")
from datasets import load_dataset
timit = load_dataset("timit_asr")
timit
timit["train"][0]["audio"]
import ffmpeg
import json
import requests
cc_by = []
other = []
retry = []
seen = []
lic = '"Creative Commons Attribution licence (reuse allowed)"'
def inner(cur_id):
    if cur_id in seen:
        return
    req = requests.get(f"https://www.youtube.com/watch?v={cur_id}")
    if req.status_code != 200:
        retry.append(cur_id)
    if lic in req.text:
        cc_by.append(cur_id)
    else:
        other.append(cur_id)
    seen.append(cur_id)
with open("pl_videos.json") as pl_videos:
    for line in pl_videos.readlines():
        line_data = json.loads(line.strip())
        inner(line_data['id'])
with open("uploads.json") as pl_videos:
    for line in pl_videos.readlines():
        line_data = json.loads(line.strip())
with open("pl_videos.json") as pl_videos:
    for line in pl_videos.readlines():
        line_data = json.loads(line.strip())
        inner(line_data['id'])
with open("uploads.json") as pl_videos:
    for line in pl_videos.readlines():
        line_data = json.loads(line.strip())
        inner(line_data['id'])
with open('proc.json', 'w') as outfile:
    json.dump({'cc-by': cc_by, 'other': other, 'retry': retry}, outfile)
lic = 'Creative Commons Attribution licence (reuse allowed)'
line_data = []
with open("pl_videos.json") as pl_videos:
    for line in pl_videos.readlines():
        line_data = json.loads(line.strip())
        inner(line_data['id'])
line_data
from pathlib import Path
for i in Path(".").glob("*.info.json"):
	print(i)
from pathlib import Path
import json
for i in Path(".").glob("*.info.json"):
	data = json.load(i)
for i in Path(".").glob("*.info.json"):
	data = json.load(str(i))
for i in Path(".").glob("*.info.json"):
	with open(i) as f:
		data = json.load(f)
data
data["license"]
CC_BY = 'Creative Commons Attribution license (reuse allowed)'
for i in Path(".").glob("*.info.json"):
	with open(i) as f:
		data = json.load(f)
		if "license" in data and data["license"] == CC_BY:
			print(i)
cc_by_ids = []
for i in Path(".").glob("*.info.json"):
    with open(i) as f:
        data = json.load(f)
        if "license" in data and data["license"] == CC_BY:
            cc_by_ids.append(i.replace(".info.json", ""))
            cc_by_ids.append(str(i).replace(".info.json", ""))
cc_by_ids = []
for i in Path(".").glob("*.info.json"):
    with open(i) as f:
        data = json.load(f)
        if "license" in data and data["license"] == CC_BY:
            cc_by_ids.append(str(i).replace(".info.json", ""))
cc_by_ids
with open("cc-by-ids.txt", "w") as out:
	for vid in cc_by_ids:
		out.write(vid + "\n")
with open("cc-by-ids.txt", "w") as outf:
	for vid in cc_by_ids:
		outf.write(vid + "\n")
print(len(cc_by_ids))
import datasets
datasets.load_dataset('timit_asr', data_dir='/sbtal/TIMIT/')
import datasets
datasets.load_dataset('timit_asr', data_dir='/sbtal/TIMIT/')
timit = datasets.load_dataset('timit_asr', data_dir='/sbtal/TIMIT/')
timit['train'][0]
timit['train'][0]['phonetic_detail'
timit['train'][0]['phonetic_detail']
from transformers import pipeline
_SWE_MODEL = "KBLab/wav2vec2-large-voxrex-swedish"
file = "/tmp/2442101120000160421_759s.wav"
output = pipe(file, chunk_length_s=10, return_timestamps="word")
pipe = pipeline(model=_SWE_MODEL)
output = pipe(file, chunk_length_s=10, return_timestamps="word")
output
output["chunks"]
output["chunks"][1]["text"]
#output["chunks"][1]["text"] = "så".upper()
"så".upper()
output["chunks"][1]["text"] = "så".upper()
output
output["text"].replace("saag", "så")
for chunk in output["chunks"]:
	print(chunk["timestamp"])
for chunk in output["chunks"]:
	old_ts = chunk["timestamp"]
	chunk["timestamp"] = (old_ts[0] + 759, old_ts[1] + 759)
output
#for chunk in output["chunks
with open("/tmp/2442101120000160421_759s.ctm", "w") as of:
	for chunk in output["chunks"]:
		of.write(f'2442101120000160421 1 {chunk["timestamp"][0]} {chunk["timestamp"][1] - chunk["timestamp"][0]} {chunk["text"].lower()} 1.0\n")
		of.write(f'2442101120000160421 1 {chunk["timestamp"][0]} {chunk["timestamp"][1] - chunk["timestamp"][0]} {chunk["text"].lower()} 1.0\n')
with open("/tmp/2442101120000160421_759s.ctm", "w") as of:
	for chunk in output["chunks"]:
		of.write(f'2442101120000160421 1 {chunk["timestamp"][0]} {chunk["timestamp"][1] - chunk["timestamp"][0]} {chunk["text"].lower()} 1.0\n")
with open("/tmp/2442101120000160421_759s.ctm", "w") as of:
	for chunk in output["chunks"]:
		of.write(f'2442101120000160421 1 {chunk["timestamp"][0]} {chunk["timestamp"][1] - chunk["timestamp"][0]} {chunk["text"].lower()} 1.0\n')
with open("/tmp/2442101120000160421_759s.ctm", "w") as of:
	for chunk in output["chunks"]:
		of.write(f'2442101120000160421 1 {chunk["timestamp"][0] + 0.3} {chunk["timestamp"][1] - chunk["timestamp"][0]} {chunk["text"].lower()} 1.0\n')
input = "En-au-sick_as_a_dog.ogg"
from transformers import pipeline
model = "jonatasgrosman/wav2vec2-large-xlsr-53-english"
pipe = pipeline(model=model)
output = pipe(input, chunk_length_s=10, return_timestamps="word")
output
import json
json.dump(output)
json.dumps(output)
import torchaudio
arr, smaple_rate = ta.load("example.wav")
import torchaudio as ta
arr, smaple_rate = ta.load("example.wav")
arr
smaple_rate
import torchaudio as ta
arr, smaple_rate = ta.load("example.wav", normalization=None)
ta.load("example.wav", normalization=None)
rs = ta.transforms.Resample(24000, 16000, resampling_method='sinc_interpolation')
rs
arr2 = rs(arr)
arr, smaple_rate = ta.load("example.wav", normalization=None)
arr, smaple_rate = ta.load("example.wav")
arr2 = rs(arr)
arr2
md = ta.info("example.wav")
md
print(md)
import wavfile
import wave
ifile = wave.open("example.wav")
ifile
samples = ifile.getnframes()
audio = ifile.readframes(samples)
import numpy
audio
len(audio)
arr, smaple_rate = ta.load("example.wav")
len(arr)
len(arr[0])
arr[0][1000]
arr[0][2000]
