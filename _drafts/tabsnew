Whatâ€™s new
chrome://whats-new/

twitter.com/_akhaliq/status/1742757369895960950?t=D1u9nDfYdG91VqmGcwvFBA&s=09
https://twitter.com/_akhaliq/status/1742757369895960950?t=D1u9nDfYdG91VqmGcwvFBA&s=09

(1) DJ on X: "I created my YouTube series on Reinforcement Learning because I saw it applied profitably at Lyft. It was a counterexample to the stigma: "RL is only good for scenarios where a perfect simulator can be accessed endlessly. It's general-but-slow trial-and-error." There's truthâ€¦ https://t.co/wowDxJaUWy" / X
https://twitter.com/DuaneJRich/status/1742777245821989224?t=NaPM_jFTb4boJXgU99EknA&s=09

(1) Vaibhav (VB) Srivastav on X: "Parakeet RNNT &amp; CTC models top the Open ASR Leaderboard! ðŸ‘‘ Brought to you by @NVIDIAAI and @suno_ai_, parakeet beats Whisper and regains its first place. The models are released under a commercially permissive license! ðŸ¥³ The models inherit the same FastConformerâ€¦ https://t.co/jF96yecZ1t" / X
https://twitter.com/reach_vb/status/1742261240141918684?t=PM9B52XZuQQKxsN4NEpuBg&s=09

bclavie/RAGatouille
https://github.com/bclavie/RAGatouille

(1) Benjamin ClaviÃ© on X: "The RAG wave is here to stay, but in practice, it's hard to retrieve the right docs w/ embdings, &amp; better IR models are hard to use! Let's fix that: Introducing ðŸª¤RAGatouille, a lib to train&amp;use SotA retrieval model, ColBERT, in just a few lines of code! https://t.co/VRHiGQl0Xv https://t.co/0EpOfV6UWn" / X
https://twitter.com/bclavie/status/1742950315278672040?t=jvJ5amVnF7IObVB2NVFhMA&s=09

colbert-ir/colbertv2.0 Â· Hugging Face
https://huggingface.co/colbert-ir/colbertv2.0

Omar Khattab on X: "Progress on dense retrievers is saturating. The best retrievers in 2024 will apply new forms of late interaction, i.e. scalable attention-like scoring for multi-vector embeddings. AðŸ§µon late interaction, how it works efficiently, and why/where it's been shown to improve quality https://t.co/2XG33TtM9R" / X
https://twitter.com/lateinteraction/status/1736804963760976092?t=7i9W4jKMslYpN1_GljPjJg&s=09

[2401.02412] LLM Augmented LLMs: Expanding Capabilities through Composition
https://arxiv.org/abs/2401.02412

(1) Jerry Liu on X: "Everyone building RAG uses dense embedding retrieval, but simply doing cosine distance doesnâ€™t always capture fine-grained similarity. Thatâ€™s why SOTA retrieval like ColBERT models are so important; these new architectures are fast but more powerful than pure dense retrieval.â€¦ https://t.co/W2RPBBxml4" / X
https://twitter.com/jerryjliu0/status/1743077679258320925?t=brOCUV_BppsrhGeXsDl7IQ&s=09

[2310.20360] Mathematical Introduction to Deep Learning: Methods, Implementations, and Theory
https://arxiv.org/abs/2310.20360

[2401.02412] LLM Augmented LLMs: Expanding Capabilities through Composition
https://arxiv.org/abs/2401.02412

2312.16218.pdf
https://arxiv.org/pdf/2312.16218.pdf

Phi-2: The surprising power of small language models - Microsoft Research
https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/

mlx-examples/llms/speculative_decoding/model.py at main Â· ml-explore/mlx-examples
https://github.com/ml-explore/mlx-examples/blob/main/llms/speculative_decoding/model.py

mlx-examples/lora/lora.py at main Â· ml-explore/mlx-examples
https://github.com/ml-explore/mlx-examples/blob/main/lora/lora.py

Download file | iLovePDF
https://www.ilovepdf.com/download/6v98sc93s750gzm6z06fdr3ny1wdf1vvf2gzA0wt89vmA1j4b6Ar5Akcv0tdAyjplkqh3t4fw372b0jwshf0cgs8f0s8j3lqyy8rA90bwrnnnyt3d79yyjl285yq5q406Adw8rm0y8868hf8fb44fzn7r73kzdfv4503tAfsw1d34jtrh19l6lln3pz7l18rnc7jv60Axjhx7/2o

A Hackers' Guide to Language Models - YouTube
https://www.youtube.com/watch?v=jkrNMKz9pWU

Multi Class Speech Classification - Online LaTeX Editor Overleaf
https://www.overleaf.com/project/65ba3c1cc694432568e8607d

veeresht/CommPy: Digital Communication with Python
https://github.com/veeresht/CommPy

2310.07707.pdf
https://arxiv.org/pdf/2310.07707.pdf

2307.00162.pdf
https://arxiv.org/pdf/2307.00162.pdf

ankitapasad/layerwise-analysis: Layer-wise analysis of self-supervised pre-trained speech representations
https://github.com/ankitapasad/layerwise-analysis

[2401.17632] What Do Self-Supervised Speech and Speaker Models Learn? New Findings From a Cross Model Layer-Wise Analysis
https://arxiv.org/abs/2401.17632

ytsvetko/qvec: Intrinsic evaluation of word vectors
https://github.com/ytsvetko/qvec

RAIVNLab/MatFormer-OLMo: Code repository for the public reproduction of the language modelling experiments on "MatFormer: Nested Transformer for Elastic Inference"
https://github.com/RAIVNLab/MatFormer-OLMo?tab=readme-ov-file

scenic/scenic/projects/matvit/layers.py at main Â· google-research/scenic
https://github.com/google-research/scenic/blob/main/scenic/projects/matvit/layers.py

Word differences Between 9 different country! Germanic,Romance,East Asia (Shocking Similarity!) - YouTube
https://www.youtube.com/watch?v=S5ydJRC-jTw

Panelshow
https://www.reddit.com/r/panelshow/

BÃ¤st i Test (Taskmaster Sweden) S08E04 [w/ Eng subs] : r/panelshow
https://www.reddit.com/r/panelshow/comments/1ahhwp2/b%C3%A4st_i_test_taskmaster_sweden_s08e04_w_eng_subs/

What Metaâ€™s Fediverse Plans Mean for Threads Users | WIRED
http://web.archive.org/web/20240202135258/https://www.wired.com/story/meta-threads-fediverse-interoperability-rachel-lambert-interview/

Home / X
https://twitter.com/home


