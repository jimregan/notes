{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048cf437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from transformers import pipeline\n",
    "_SWE_MODEL = \"KBLab/wav2vec2-large-voxrex-swedish\"\n",
    "pipe = pipeline(model=_SWE_MODEL)\n",
    "loc = Path(\"/home/joregan/christina-audio/\")\n",
    "for file in loc.glob(\"**/*.mp3\"):\n",
    "    output = pipe(str(file), chunk_length_s=10, return_timestamps=\"word\")\n",
    "    outname = loc / f\"{file.stem}.json\"\n",
    "    with open(outname, \"w\") as of:\n",
    "        json.dump(output, of)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738fb22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "import json\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "model_id = \"KBLab/kb-whisper-large\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, use_safetensors=True, cache_dir=\"cache\"\n",
    ")\n",
    "model.to(device)\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\"automatic-speech-recognition\", model=model, tokenizer=processor.tokenizer, feature_extractor=processor.feature_extractor, torch_dtype=torch_dtype, device=device)\n",
    "\n",
    "for file in loc.glob(\"**/*.mp3\"):\n",
    "    res = pipe(str(file), chunk_length_s=30, generate_kwargs={\"task\": \"transcribe\", \"language\": \"sv\"})\n",
    "    outname = loc / f\"{file.stem}.whisper.json\"\n",
    "    with open(outname, \"w\") as of:\n",
    "       json.dump(res, of)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
