[2203.17113] Pre-Training Transformer Decoder for End-to-End ASR Model with Unpaired Speech Data
https://arxiv.org/abs/2203.17113

MLSLP2021_paper_15.pdf
https://homepages.inf.ed.ac.uk/htang2/sigml/mlslp2021/MLSLP2021_paper_15.pdf

Untitled26.ipynb - Colaboratory
https://colab.research.google.com/drive/1I_DQp1qf4qmg52Pyrz53VoTvUe-1CA90#scrollTo=1hhLcpDziPDB

Add a TF in-graph tokenizer for BERT (#17701) ¬∑ huggingface/transformers@ee0d001 ¬∑ GitHub
https://github.com/huggingface/transformers/commit/ee0d001de71f0da892f86caa3cf2387020ec9696

add MobileNetV2 model by hollance ¬∑ Pull Request #17845 ¬∑ huggingface/transformers ¬∑ GitHub
https://github.com/huggingface/transformers/pull/17845

[WIP] Adding Omnivore Model to HF by AnugunjNaman ¬∑ Pull Request #17772 ¬∑ huggingface/transformers
https://github.com/huggingface/transformers/pull/17772

Layoutlmv2 tesseractconfig by kelvinAI ¬∑ Pull Request #17733 ¬∑ huggingface/transformers
https://github.com/huggingface/transformers/pull/17733

transformers/src/transformers/models at main ¬∑ huggingface/transformers
https://github.com/huggingface/transformers/tree/main/src/transformers/models

transformers/src/transformers/models/wav2vec2 at main ¬∑ huggingface/transformers
https://github.com/huggingface/transformers/tree/main/src/transformers/models/wav2vec2

transformers/feature_extraction_wav2vec2.py at main ¬∑ huggingface/transformers
https://github.com/huggingface/transformers/blob/main/src/transformers/models/wav2vec2/feature_extraction_wav2vec2.py

transformers/modeling_wav2vec2.py at main ¬∑ huggingface/transformers
https://github.com/huggingface/transformers/blob/main/src/transformers/models/wav2vec2/modeling_wav2vec2.py

pyannote/embedding ¬∑ Hugging Face
https://huggingface.co/pyannote/embedding

wav2vec huggingface extract features - Google Search
https://www.google.com/search?q=wav2vec+huggingface+extract+features&rlz=1C5GCEM_enSE990SE991&oq=wav2vec+huggingface+extract+features&aqs=chrome..69i57j33i160l4.8365j0j7&sourceid=chrome&ie=UTF-8

Feature Extractor
https://huggingface.co/docs/transformers/main_classes/feature_extractor

Fine-Tune Wav2Vec2 for English ASR in Hugging Face with ü§ó Transformers
https://huggingface.co/blog/fine-tune-wav2vec2-english

LeBenchmark/wav2vec2-FR-3K-large ¬∑ Hugging Face
https://huggingface.co/LeBenchmark/wav2vec2-FR-3K-large

transformers.models.wav2vec2.feature_extraction_wav2vec2 ‚Äî transformers 4.7.0 documentation
https://huggingface.co/transformers/v4.7.0/_modules/transformers/models/wav2vec2/feature_extraction_wav2vec2.html

Speech2Text2
https://huggingface.co/docs/transformers/model_doc/speech_to_text_2

Making automatic speech recognition work on large files with Wav2Vec2 in ü§ó Transformers
https://huggingface.co/blog/asr-chunking

jusato (jusato) ¬∑ GitHub
https://github.com/jusato

323_Paper.pdf
https://confcats-event-sessions.s3.amazonaws.com/lrec22/papers/final/323/323_Paper.pdf

tatianapassali (Passali Tatiana) ¬∑ GitHub
https://github.com/tatianapassali

Hi, I‚Äôm Dr. Yanjun Gao (È´òËâ≥Áè∫). - Yanjun Gao
https://serenayj.github.io/

1041_Paper.pdf
https://confcats-event-sessions.s3.amazonaws.com/lrec22/papers/final/1041/1041_Paper.pdf

687_Paper.pdf
https://confcats-event-sessions.s3.amazonaws.com/lrec22/papers/final/687/687_Paper.pdf

dppsi.pdf
https://cs.slu.edu/~scannell/pub/dppsi.pdf

UD_Irish-Cadhan/ga_cadhan-ud-test.conllu at dev ¬∑ UniversalDependencies/UD_Irish-Cadhan ¬∑ GitHub
https://github.com/UniversalDependencies/UD_Irish-Cadhan/blob/dev/ga_cadhan-ud-test.conllu

GitHub - kscanne/gbb: Sonra√≠ traen√°la/t√°st√°la NLP
https://github.com/kscanne/gbb

gesticulator/features2bvh.py at master ¬∑ Svito-zar/gesticulator ¬∑ GitHub
https://github.com/Svito-zar/gesticulator/blob/master/gesticulator/data_processing/features2bvh.py

GitHub - probabilisticai/probai-2022: Materials of the Nordic Probabilistic AI School 2022.
https://github.com/probabilisticai/probai-2022

(1268) Probabilistic AI - YouTube
https://www.youtube.com/channel/UCcMwNzhpePJE3xzOP_3pqsw/videos

GitHub - adapter-hub/adapter-transformers: Huggingface Transformers + Adapters = ‚ù§Ô∏è
https://github.com/adapter-hub/adapter-transformers

GitHub - salesforce/awd-lstm-lm: LSTM and QRNN Language Model Toolkit for PyTorch
https://github.com/salesforce/awd-lstm-lm

1911.03588.pdf
https://arxiv.org/pdf/1911.03588.pdf

GitHub - guillefix/transflower-lightning: multimodal transformer
https://github.com/guillefix/transflower-lightning

[2106.13871] Transflower: probabilistic autoregressive dance generation with multimodal attention
https://arxiv.org/abs/2106.13871

(1266) Transflower: Probabilistic autoregressive dance generation with multimodal attention - YouTube
https://www.youtube.com/watch?v=uBnCePehA-Y

GitHub - MetaGenAI/multimodal-transflower: multimodal probabilistic autoregressive models
https://github.com/MetaGenAI/multimodal-transflower

GitHub - guillefix/transflower-lightning: multimodal transformer
https://github.com/guillefix/transflower-lightning

GitHub - microsoft/SpeechT5: Unified-Modal Encoder-Decoder Pre-Training for Spoken Language Processing
https://github.com/microsoft/SpeechT5

2203.17113.pdf
https://arxiv.org/pdf/2203.17113.pdf

2110.07205.pdf
https://arxiv.org/pdf/2110.07205.pdf

[2202.03218] Efficient Adapter Transfer of Self-Supervised Speech Models for Automatic Speech Recognition
https://arxiv.org/abs/2202.03218

Model Downloader and other automation tools ‚Äî OpenVINO‚Ñ¢ documentation ‚Äî Version(latest)
https://docs.openvino.ai/latest/omz_tools_downloader.html#doxid-omz-tools-downloader

Microsoft's SpeechT5 for Spoken Language Processing (ASR, TTS, ST...) ¬∑ Issue #17569 ¬∑ huggingface/transformers
https://github.com/huggingface/transformers/issues/17569

Getting Started on Mobile
https://www.notion.so/Getting-Started-on-Mobile-b0d26442a36a4ab191cfc35a1e66c5c3

Model training T5 Speech
https://ivory-tiger-5be.notion.site/Model-training-T5-Speech-af1553dd188143968648cc8fb6305cf2

Speech T5 Swedish - Colaboratory
https://colab.research.google.com/drive/1vqg91NDM4397rPzydYDLlFdugfNjfJLF?usp=sharing#scrollTo=2FsqEMt5j69L

importerror cannot import name 'metrics' from 'fairseq' (unknown location) - Google Search
https://www.google.com/search?q=importerror+cannot+import+name+%27metrics%27+from+%27fairseq%27+(unknown+location)&rlz=1C5GCEM_enSE990SE991&oq=cannot+import+metrics+from+fairseq&aqs=chrome.1.69i57j0i22i30.6726j0j4&sourceid=chrome&ie=UTF-8

Installing Fairseq from source on Colab fails ( ImportError: cannot import name <> from 'fairseq' (unknown location) ¬∑ Issue #4121 ¬∑ facebookresearch/fairseq
https://github.com/facebookresearch/fairseq/issues/4121

Home / Twitter
https://twitter.com/home

Adapting Speech Recognition to Your Domain | Cobalt
https://www.cobaltspeech.com/blog/2019/11/18/adapting-models-to-your-domain

Publications ‚Äî Richard Socher
https://www.socher.org/publications

(99+) A Primer in BERTology: What we know about how BERT works | Ra S - Academia.edu
https://www.academia.edu/42343971/A_Primer_in_BERTology_What_we_know_about_how_BERT_works

google-research/adapter-bert
https://github.com/google-research/adapter-bert

2004.04290.pdf
https://arxiv.org/pdf/2004.04290.pdf

sv-SE - Google Drive
https://drive.google.com/drive/folders/1iBfsj3Wr8H_qHfkuEgTBa9FikHQvmG7h

SpeechT5/SpeechT5/speecht5/criterions at main ¬∑ microsoft/SpeechT5 ¬∑ GitHub
https://github.com/microsoft/SpeechT5/tree/main/SpeechT5/speecht5/criterions

SpeechT5/SpeechT5/speecht5/data at main ¬∑ microsoft/SpeechT5
https://github.com/microsoft/SpeechT5/tree/main/SpeechT5/speecht5/data

SpeechT5/SpeechT5/speecht5/models at main ¬∑ microsoft/SpeechT5
https://github.com/microsoft/SpeechT5/tree/main/SpeechT5/speecht5/models

SpeechT5/SpeechT5/speecht5/tasks at main ¬∑ microsoft/SpeechT5
https://github.com/microsoft/SpeechT5/tree/main/SpeechT5/speecht5/tasks

microsoft/SpeechT5: Unified-Modal Encoder-Decoder Pre-Training for Spoken Language Processing
https://github.com/microsoft/SpeechT5

SpeechT5/multihead_attention.py at main ¬∑ microsoft/SpeechT5
https://github.com/microsoft/SpeechT5/blob/main/YiTrans/yitrans_iwslt22/modules/multihead_attention.py

SpeechT5/SpeechT5 at main ¬∑ microsoft/SpeechT5
https://github.com/microsoft/SpeechT5/tree/main/SpeechT5

SpeechT5/Speech2C at main ¬∑ microsoft/SpeechT5 ¬∑ GitHub
https://github.com/microsoft/SpeechT5/tree/main/Speech2C

add reading from zip audio to hubert dataset and scripts (#3403) ¬∑ facebookresearch/fairseq@5528b6a ¬∑ GitHub
https://github.com/facebookresearch/fairseq/commit/5528b6a38224404d80b900609463fd6864fd115a

include wav2vec-u 2.0 (#2826) ¬∑ facebookresearch/fairseq@a0ceabc ¬∑ GitHub
https://github.com/facebookresearch/fairseq/commit/a0ceabc287e26f64517fadb13a54c83b71e8e469

SpeechT5/speecht5.py at main ¬∑ microsoft/SpeechT5 ¬∑ GitHub
https://github.com/microsoft/SpeechT5/blob/main/SpeechT5/speecht5/tasks/speecht5.py#L289

SpeechT5/speecht5.py at main ¬∑ microsoft/SpeechT5 ¬∑ GitHub
https://github.com/microsoft/SpeechT5/blob/main/SpeechT5/speecht5/tasks/speecht5.py#L289

Difficulties loading pre-trained weights! ¬∑ Issue #5 ¬∑ microsoft/SpeechT5 ¬∑ GitHub
https://github.com/microsoft/SpeechT5/issues/5

SpeechT5/SpeechT5 at main ¬∑ microsoft/SpeechT5 ¬∑ GitHub
https://github.com/microsoft/SpeechT5/tree/main/SpeechT5#load-pre-trained-models

how to pre-train on a custom dataset ? ¬∑ Issue #1 ¬∑ microsoft/SpeechT5 ¬∑ GitHub
https://github.com/microsoft/SpeechT5/issues/1

SpeechT5/speaker_decoder_postnet.py at 1ad69dfc7f8e8ff89aee28de80fb607f1d4cbf22 ¬∑ microsoft/SpeechT5 ¬∑ GitHub
https://github.com/microsoft/SpeechT5/blob/1ad69dfc7f8e8ff89aee28de80fb607f1d4cbf22/SpeechT5/speecht5/models/modules/speaker_decoder_postnet.py

SpeechT5/decoder.py at 1ad69dfc7f8e8ff89aee28de80fb607f1d4cbf22 ¬∑ microsoft/SpeechT5 ¬∑ GitHub
https://github.com/microsoft/SpeechT5/blob/1ad69dfc7f8e8ff89aee28de80fb607f1d4cbf22/SpeechT5/speecht5/models/modules/decoder.py

Does the quantizer is used when fine-tune the pretrained backbone for the downstream task ? ¬∑ Issue #6 ¬∑ microsoft/SpeechT5 ¬∑ GitHub
https://github.com/microsoft/SpeechT5/issues/6

transformers/src/transformers/models/data2vec at 264128cb9dbd83b666666945fd2fea0662135911 ¬∑ huggingface/transformers ¬∑ GitHub
https://github.com/huggingface/transformers/tree/264128cb9dbd83b666666945fd2fea0662135911/src/transformers/models/data2vec

[SegFormer] TensorFlow port by sayakpaul ¬∑ Pull Request #17910 ¬∑ huggingface/transformers ¬∑ GitHub
https://github.com/huggingface/transformers/pull/17910

[WIP] Adding LID (Language Identification) Head for M-CTC-T Model by cwkeam ¬∑ Pull Request #17671 ¬∑ huggingface/transformers ¬∑ GitHub
https://github.com/huggingface/transformers/pull/17671

Add Google's Trillson Audio Classification Model by vumichien ¬∑ Pull Request #17387 ¬∑ huggingface/transformers
https://github.com/huggingface/transformers/pull/17387/commits/53c5b70b57b9ec96b2c1dee6d6933c7b2991fda6

[Speech Model] Add Emformer by anton-l ¬∑ Pull Request #17302 ¬∑ huggingface/transformers
https://github.com/huggingface/transformers/pull/17302/files

Sequence-to-sequence learning with Transducers - Loren Lugosch
https://lorenlugosch.github.io/posts/2020/11/transducer/

2010.10504.pdf
https://arxiv.org/pdf/2010.10504.pdf

Online ASR with Emformer RNN-T ‚Äî Torchaudio nightly documentation
https://pytorch.org/audio/main/tutorials/online_asr_tutorial.html

add wav2vec2_alignment by arijitx ¬∑ Pull Request #16782 ¬∑ huggingface/transformers
https://github.com/huggingface/transformers/pull/16782

Add fairseq FastSpeech2 by jaketae ¬∑ Pull Request #15773 ¬∑ huggingface/transformers
https://github.com/huggingface/transformers/pull/15773

Commits ¬∑ huggingface/transformers
https://github.com/huggingface/transformers/commits/main?after=051311ff66e7b23bfcfc42bc514c969517323ce9+34&branch=main&qualified_name=refs%2Fheads%2Fmain

Pull requests ¬∑ huggingface/transformers
https://github.com/huggingface/transformers/pulls?page=4&q=is%3Apr+is%3Aopen

[Speech Model] Add Emformer by anton-l ¬∑ Pull Request #17302 ¬∑ huggingface/transformers
https://github.com/huggingface/transformers/pull/17302

fix: data2vec-vision Onnx ready-made configuration. (#18427) ¬∑ huggingface/transformers@fe78573
https://github.com/huggingface/transformers/commit/fe785730dcbf3390aa07f667e8d3c4b02d6638e0

audio/emformer.py at main ¬∑ pytorch/audio
https://github.com/pytorch/audio/blob/main/torchaudio/models/emformer.py

Nic ≈õmiesznego ‚Äì Wikipedia, wolna encyklopedia
https://pl.wikipedia.org/wiki/Nic_%C5%9Bmiesznego

Ma≈Çgorzata Werner - FDB
https://fdb.pl/osoba/26723-malgorzata-werner

Ma≈Çgorzata Werner nic smiesznego - Google Search
https://www.google.com/imgres?imgurl=https%3A%2F%2Focdn.eu%2Fpulscms-transforms%2F1%2F6T6k9kpTURBXy9jOTYwNzEwZGFjZTRmNzY1MTljODFkNTg0ZjU3YTMxOS5qcGeTlQMAAM0CwM0BjJMFzQEEzICTBc0BBMyAgqEwAaExAQ&imgrefurl=https%3A%2F%2Fwww.fakt.pl%2Fmalgorzata-werner&tbnid=MknYzIYMmAr1gM&vet=12ahUKEwjHvaCgrsT5AhVTHMAKHbg6AhIQMygcegUIARCXAQ..i&docid=pc6R8PZp1VIWBM&w=260&h=128&q=Ma%C5%82gorzata%20Werner%20nic%20smiesznego&ved=2ahUKEwjHvaCgrsT5AhVTHMAKHbg6AhIQMygcegUIARCXAQ

Agnieszka Wagner ‚Äì Wikipedia, wolna encyklopedia
https://pl.wikipedia.org/wiki/Agnieszka_Wagner

shivammehta007/Neural-HMM: Neural HMMs are all you need (for high-quality attention-free TTS)
https://github.com/shivammehta007/Neural-HMM

VILORUM - Translation in English - bab.la
https://en.bab.la/dictionary/swedish-english/vilorum

AlphaCephei on Twitter: "We published Tuda german model from https://t.co/4xPzWgW6fw https://t.co/7mdkimirTj it is big (4.4G) and slightly more accurate than Vosk on audiobooks and well covers CV test 9.48 (Tuda-de test), 25.82 (podcast) 4.97 (cv-test) 11.01 (mls) 35.20 (mtedx)" / Twitter
https://twitter.com/alphacep/status/1557445857762578434?cxt=HBwWhMC8zbCwlJ0rAAAA&cn=ZmxleGlibGVfcmVjcw%3D%3D&refsrc=email

https://alphacephei.com/vosk/models/vosk-model-de-tuda-0.6-900k.zip
https://t.co/7mdkimirTj

uhh-lt/kaldi-tuda-de: Scripts for training general-purpose large vocabulary German acoustic models for ASR with Kaldi.
https://github.com/uhh-lt/kaldi-tuda-de#Newest-pretrained-models

STCP
https://www.stcp.pt/en/itinerarium/

Recordings Database - Faith Comes By Hearing
https://www.faithcomesbyhearing.com/audio-bible-resources/recordings-database

Mark 1 | Bible.is
https://live.bible.is/bible/ABIWBT/MRK/1?audio_type=audio

Speaker Diarization ‚Äî NVIDIA NeMo
https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/asr/speaker_diarization/intro.html

Models ‚Äî NVIDIA NeMo
https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/asr/speech_classification/models.html#marblenet-model

Ponte da Arr√°bida w Porto - wspinaczka na most i jedyna taka panorama
https://www.facetikuchnia.com.pl/ponte-da-arrabida-porto/

Ticket-Voucher
https://www.livrarialello.pt/en/store/ticket-voucher#ticketvoucher

Spiritus Porto - Spiritus Tickets and Dates 2022
https://spiritusporto.seetickets.com/tour/spiritus/list/1?startDate=27-08-2022&endDate=27-08-2022

About | Spiritus
https://www.spiritusporto.com/en/sobre

GitHub - perfall/Edyson: Flask-based web framework for visualisation and explorative listening of audio.
https://github.com/perfall/Edyson

International Phonetic Alphabet - Wikipedia
https://en.wikipedia.org/wiki/International_Phonetic_Alphabet

Graph Visualization Tools - Developer Guides
https://neo4j.com/developer/tools-graph-visualization/

TillTal ‚Äì Making spoken cultural heritage accessible for research | KTH
https://www.kth.se/is/tmh/speech-communication/tilltal-making-spoken-cultural-heritage-accessible-for-research-1.694166

Using AI to decode speech from brain activity
https://ai.facebook.com/blog/ai-speech-brain-activity/

icefall/beam_search.py at master ¬∑ k2-fsa/icefall ¬∑ GitHub
https://github.com/k2-fsa/icefall/blob/master/egs/librispeech/ASR/pruned_transducer_stateless/beam_search.py

Pull requests ¬∑ k2-fsa/icefall ¬∑ GitHub
https://github.com/k2-fsa/icefall/pulls

huggingface wav2vec "gtn" - Google Search
https://www.google.com/search?rlz=1C5GCEM_enSE990SE991&sxsrf=ALiCzsabXMoq2w0CN7lmZzqS8DHVtzXZDg:1662118369820&q=huggingface+wav2vec+%22gtn%22&sa=X&ved=2ahUKEwj6xYe4gfb5AhXCmIsKHXt-BPMQ5t4CegQIHxAB&biw=1440&bih=709&dpr=2

OthmaneJ/distil-wav2vec2 ¬∑ Hugging Face
https://huggingface.co/OthmaneJ/distil-wav2vec2

Wav2Vec2Phoneme
https://huggingface.co/docs/transformers/model_doc/wav2vec2_phoneme

https://mobile.twitter.com/vineelk/with_replies
https://mobile.twitter.com/vineelk/with_replies

"beam search" "k2 fsa" - Google Search
https://www.google.com/search?q=%22beam+search%22+%22k2+fsa%22&rlz=1C5GCEM_enSE990SE991&oq=%22beam+search%22+%22k2+fsa%22&aqs=chrome..69i57j33i160.6713j0j7&sourceid=chrome&ie=UTF-8

GitHub - k2-fsa/icefall
https://github.com/k2-fsa/icefall

GitHub - k2-fsa/icefall
https://github.com/k2-fsa/icefall/

Automatic Speech Recognition - a Hugging Face Space by k2-fsa
https://huggingface.co/spaces/k2-fsa/automatic-speech-recognition

Stateless Transducer ‚Äî icefall 0.1 documentation
https://icefall.readthedocs.io/en/latest/recipes/aishell/stateless_transducer.html

optimized_transducer/test_compute_transducer_loss.py at master ¬∑ csukuangfj/optimized_transducer ¬∑ GitHub
https://github.com/csukuangfj/optimized_transducer/blob/master/optimized_transducer/python/tests/test_compute_transducer_loss.py

Recurrent Neural Aligner: An Encoder-Decoder Neural Network Model for Sequence to Sequence Mapping
https://www.isca-speech.org/archive_v0/Interspeech_2017/pdfs/1705.PDF

icefall/egs/alimeeting/ASR at master ¬∑ k2-fsa/icefall ¬∑ GitHub
https://github.com/k2-fsa/icefall/tree/master/egs/alimeeting/ASR

2203.15614.pdf
https://arxiv.org/pdf/2203.15614.pdf

python/k2-fsa/snowfall/egs/gigaspeech/asr/simple_v1/mmi_att_transformer_decode.py Example
https://programtalk.com/vs4/python/k2-fsa/snowfall/egs/gigaspeech/asr/simple_v1/mmi_att_transformer_decode.py/

LITHME
https://lithme.eu/

WG2 ‚Äì LITHME
https://lithme.eu/working-groups/wg2/

WG3 ‚Äì LITHME
https://lithme.eu/working-groups/wg3/

Katarzyna Maria Bagi≈Ñska | Facebook
https://www.facebook.com/katarzyna.m.baginska/about

How to Recognize Mental Abuse, and Why It‚Äôs Not Your Fault
https://www.betterup.com/blog/mental-abuse

Is Emotional Self-Harm a Thing? Signs of Mental Self-Injury | HealthyPlace
https://www.healthyplace.com/blogs/speakingoutaboutselfinjury/2020/6/is-emotional-self-harm-a-thing-signs-of-mental-self-injury

Self-Harm as Violence: When Victim and Perpetrator Are One - Women and Violence - NCBI Bookshelf
https://www.ncbi.nlm.nih.gov/books/NBK349101/

Emotional Abuse: What It Is and Signs to Watch For
https://www.healthline.com/health/signs-of-mental-abuse

TMH Monday lunch meeting protocols Apr 2019‚Äì - Google Docs
https://docs.google.com/document/d/1R53CwfrIrSiXrgLc0s7m-DZHrz9OPYp-V_c-ve97l0w/edit#

CLARIN Annual Conference 2022 | CLARIN ERIC
https://www.clarin.eu/event/2022/clarin-annual-conference-2022#registration

PhD Students Session at CLARIN 2022 | CLARIN ERIC
https://www.clarin.eu/content/phd-students-session-clarin-2022

CLARIN Annual Conference 2022 | CLARIN ERIC
https://www.clarin.eu/event/2022/clarin-annual-conference-2022

Programme CLARIN Annual Conference 2022 | CLARIN ERIC
https://www.clarin.eu/content/programme-clarin-annual-conference-2022

sl ¬∑ Streamlit
http://130.237.67.68:8501/

Untitled document - Google Docs
https://docs.google.com/document/d/1ueG2cFWSKaeP7QayN4T8nz9d-mK2vUG1vCX9pwTJlRw/edit

riksdagen ¬∑ GitHub Topics ¬∑ GitHub
https://github.com/topics/riksdagen

parlaclarin xml - Google Search
https://www.google.com/search?q=parlaclarin+xml&rlz=1C5GCEM_enSE990SE991&oq=parlaclarin+xml&aqs=chrome..69i57j33i160l4.3650j0j7&sourceid=chrome&ie=UTF-8

CLARIN Annual Conference 2022 Registration
https://docs.google.com/forms/u/0/d/e/1FAIpQLScDbIi4CEpOMnLGE4XccanyfXTjRM3_r4S5bYMMTZ5EufzInQ/formResponse

OSF | MASC-MEG
https://osf.io/ag3kj/


