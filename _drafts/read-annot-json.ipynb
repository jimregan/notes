{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "EG = \"/Users/joregan/Playing/merged_annotations/hsi_4_0717_209_002.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(EG) as inf:\n",
    "    data = json.load(inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE = \"\"\"\n",
    "{\n",
    "  \"2\": {\n",
    "    \"general\": {\n",
    "      \"id\": 2,\n",
    "      \"start\": 5.970287890159987,\n",
    "      \"end\": 9.551266621561616\n",
    "    },\n",
    "    \"high_level\": {\n",
    "      \"topic_name\": \"reference_real\",\n",
    "      \"current_topic\": \"vase\",\n",
    "      \"topic_change\": false,\n",
    "      \"topic_duration_id\": 0,\n",
    "      \"spatial_reference\": \"fourth vase\",\n",
    "      \"referenced_object\": [\n",
    "        \"vase\"\n",
    "      ]\n",
    "    },\n",
    "    \"low_level\": {\n",
    "      \"resolved_references\": {\n",
    "        \"the fourth vase\": \"vase\",\n",
    "        \"it\": \"vase\"\n",
    "      },\n",
    "      \"spatial_relationships\": [],\n",
    "      \"resolved_adverbs\": []\n",
    "    },\n",
    "    \"snippet\": \"But I'm wondering about the fourth vase. Where is it? Did you break it?\"\n",
    "  }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```json\n",
    "      \"resolved_references_indices\": {\n",
    "        \"it\": [2, 4]\n",
    "      }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tsv(filename):\n",
    "    data = []\n",
    "    with open(filename) as inf:\n",
    "        for line in inf.readlines():\n",
    "            parts = line.strip().split(\"\\t\")\n",
    "            data.append({\n",
    "                \"start\": float(parts[0]),\n",
    "                \"end\": float(parts[1]),\n",
    "                \"word\": parts[2]\n",
    "            })\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_tsv_data(data, start, end):\n",
    "    ret = []\n",
    "    for datum in data:\n",
    "        if type(datum[\"start\"]) is str:\n",
    "            datum[\"start\"] = float(datum[\"start\"])\n",
    "        if type(datum[\"end\"]) is str:\n",
    "            datum[\"end\"] = float(datum[\"end\"])\n",
    "        if datum[\"start\"] >= start and datum[\"end\"] <= end:\n",
    "            ret.append(datum)\n",
    "        elif datum[\"end\"] > end:\n",
    "            return ret\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    return \" \".join([x.lower().strip(\".,;?!\") for x in text.split(\" \")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "TSVS = Path(\"/Users/joregan/Playing/hsi/word_annotations/\")\n",
    "JSON = Path(\"/Users/joregan/Playing/merged_annotations/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices(needle, haystack, checkpos=True):\n",
    "    ret = []\n",
    "    nwords = [x.lower().strip(\",?.;:\") for x in needle.split(\" \")]\n",
    "    hwords = [x.lower().strip(\",?.;:\") for x in haystack.split(\" \")]\n",
    "    nwordspos = nwords[:-1] + [f\"{nwords[-1]}'s\"]\n",
    "    nlen = len(nwords)\n",
    "\n",
    "    for i in range(len(hwords)):\n",
    "        if hwords[i:i+nlen] == nwords:\n",
    "            ret.append((i, i+nlen))\n",
    "        elif checkpos and hwords[i:i+nlen] == nwordspos:\n",
    "            ret.append((i, i+nlen))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tsv_for_segment(segment, tsv_data):\n",
    "    assert \"general\" in segment, \"Missing key 'general'\"\n",
    "    assert \"start\" in segment[\"general\"], \"Missing key 'start'\"\n",
    "    assert \"end\" in segment[\"general\"], \"Missing key 'end'\"\n",
    "\n",
    "    start = segment[\"general\"][\"start\"]\n",
    "    end = segment[\"general\"][\"end\"]\n",
    "\n",
    "    tsv = slice_tsv_data(tsv_data, start, end)\n",
    "    tsv_words = \" \".join([x[\"word\"] for x in tsv])\n",
    "\n",
    "    if segment[\"snippet\"] != tsv_words:\n",
    "        cleaned_snippet = clean_text(segment[\"snippet\"])\n",
    "        cleaned_text = clean_text(tsv_words)\n",
    "\n",
    "        if cleaned_snippet not in cleaned_text:\n",
    "            print(\"üôÄ mismatch:\", \"üñáÔ∏è\", segment[\"snippet\"], \"üéß\", tsv_words, cleaned_text.find(cleaned_snippet))\n",
    "            return []\n",
    "        else:\n",
    "            idxes = get_indices(cleaned_snippet, cleaned_text)\n",
    "            assert len(idxes) == 1\n",
    "            tsv = tsv[idxes[0][0]:idxes[0][1]]\n",
    "            tsv_words = \" \".join([x[\"word\"] for x in tsv])\n",
    "            cleaned_text = clean_text(tsv_words)\n",
    "            assert cleaned_snippet == cleaned_text, f\"üñáÔ∏è {cleaned_snippet} üéß {cleaned_text}\"\n",
    "    return tsv\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seg in data:\n",
    "    print(get_tsv_for_segment(data[seg], ttsv))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nst-tts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
