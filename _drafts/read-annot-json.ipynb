{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "EG = \"/Users/joregan/Playing/merged_annotations/hsi_4_0717_209_002.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(EG) as inf:\n",
    "    data = json.load(inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE = \"\"\"\n",
    "{\n",
    "  \"2\": {\n",
    "    \"general\": {\n",
    "      \"id\": 2,\n",
    "      \"start\": 5.970287890159987,\n",
    "      \"end\": 9.551266621561616\n",
    "    },\n",
    "    \"high_level\": {\n",
    "      \"topic_name\": \"reference_real\",\n",
    "      \"current_topic\": \"vase\",\n",
    "      \"topic_change\": false,\n",
    "      \"topic_duration_id\": 0,\n",
    "      \"spatial_reference\": \"fourth vase\",\n",
    "      \"referenced_object\": [\n",
    "        \"vase\"\n",
    "      ]\n",
    "    },\n",
    "    \"low_level\": {\n",
    "      \"resolved_references\": {\n",
    "        \"the fourth vase\": \"vase\",\n",
    "        \"it\": \"vase\"\n",
    "      },\n",
    "      \"spatial_relationships\": [],\n",
    "      \"resolved_adverbs\": []\n",
    "    },\n",
    "    \"snippet\": \"But I'm wondering about the fourth vase. Where is it? Did you break it?\"\n",
    "  }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```json\n",
    "      \"resolved_references_indices\": {\n",
    "        \"it\": [2, 4]\n",
    "      }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tsv(filename):\n",
    "    data = []\n",
    "    with open(filename) as inf:\n",
    "        for line in inf.readlines():\n",
    "            parts = line.strip().split(\"\\t\")\n",
    "            data.append({\n",
    "                \"start\": float(parts[0]),\n",
    "                \"end\": float(parts[1]),\n",
    "                \"word\": parts[2]\n",
    "            })\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_tsv_data(data, start, end):\n",
    "    ret = []\n",
    "    for datum in data:\n",
    "        if type(datum[\"start\"]) is str:\n",
    "            datum[\"start\"] = float(datum[\"start\"])\n",
    "        if type(datum[\"end\"]) is str:\n",
    "            datum[\"end\"] = float(datum[\"end\"])\n",
    "        if datum[\"start\"] >= start and datum[\"end\"] <= end:\n",
    "            ret.append(datum)\n",
    "        elif datum[\"end\"] > end:\n",
    "            return ret\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    return \" \".join([x.lower().strip(\".,;?!\") for x in text.split(\" \")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "TSVS = Path(\"/Users/joregan/Playing/hsi/word_annotations/\")\n",
    "JSON = Path(\"/Users/joregan/Playing/merged_annotations/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices(needle, haystack, checkpos=True):\n",
    "    ret = []\n",
    "    nwords = [x.lower().strip(\",?.;:\") for x in needle.split(\" \")]\n",
    "    hwords = [x.lower().strip(\",?.;:\") for x in haystack.split(\" \")]\n",
    "    nwordspos = nwords[:-1] + [f\"{nwords[-1]}'s\"]\n",
    "    nlen = len(nwords)\n",
    "\n",
    "    for i in range(len(hwords)):\n",
    "        if hwords[i:i+nlen] == nwords:\n",
    "            ret.append((i, i+nlen))\n",
    "        elif checkpos and hwords[i:i+nlen] == nwordspos:\n",
    "            ret.append((i, i+nlen))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tsv_for_segment(segment, tsv_data):\n",
    "    assert \"general\" in segment, \"Missing key 'general'\"\n",
    "    assert \"start\" in segment[\"general\"], \"Missing key 'start'\"\n",
    "    assert \"end\" in segment[\"general\"], \"Missing key 'end'\"\n",
    "\n",
    "    start = segment[\"general\"][\"start\"]\n",
    "    end = segment[\"general\"][\"end\"]\n",
    "\n",
    "    tsv = slice_tsv_data(tsv_data, start, end)\n",
    "    tsv_words = \" \".join([x[\"word\"] for x in tsv])\n",
    "\n",
    "    if segment[\"snippet\"] != tsv_words:\n",
    "        cleaned_snippet = clean_text(segment[\"snippet\"])\n",
    "        cleaned_text = clean_text(tsv_words)\n",
    "\n",
    "        if cleaned_snippet not in cleaned_text:\n",
    "            print(\"ğŸ™€ mismatch:\", \"ğŸ–‡ï¸\", segment[\"snippet\"], \"ğŸ§\", tsv_words, cleaned_text.find(cleaned_snippet))\n",
    "            return []\n",
    "        else:\n",
    "            idxes = get_indices(cleaned_snippet, cleaned_text)\n",
    "            assert len(idxes) == 1\n",
    "            tsv = tsv[idxes[0][0]:idxes[0][1]]\n",
    "            tsv_words = \" \".join([x[\"word\"] for x in tsv])\n",
    "            cleaned_text = clean_text(tsv_words)\n",
    "            assert cleaned_snippet == cleaned_text, f\"ğŸ–‡ï¸ {cleaned_snippet} ğŸ§ {cleaned_text}\"\n",
    "    return tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_skippable(segment, strict=True):\n",
    "    skippables = [\"conversation_generic\"]\n",
    "    if strict:\n",
    "        skippables += [\"reference_imaginary\"]\n",
    "    if segment[\"high_level\"][\"topic_name\"] == \"reference_unreal\":\n",
    "        segment[\"high_level\"][\"topic_name\"] = \"reference_imaginary\"\n",
    "    if segment[\"high_level\"][\"topic_name\"] in skippables:\n",
    "        return True\n",
    "    elif segment[\"low_level\"][\"resolved_references\"] == {}:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# that weird waste bin [(1, 5)]\n",
    "# that [(1, 2), (8, 9)]\n",
    "def skip_overlapped_index(a, b):\n",
    "    if a[0] >= b[0] and a[1] <= b[1]:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "assert skip_overlapped_index((1, 2), (1, 5)) == True\n",
    "assert skip_overlapped_index((1, 5), (1, 2)) == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_manual_index(indices, manual):\n",
    "    ret = []\n",
    "    for index in indices:\n",
    "        if index[0] in manual:\n",
    "            ret.append(index)\n",
    "    return ret\n",
    "\n",
    "assert prune_manual_index([(1, 3), (5, 7)], [1]) == [(1, 3)]\n",
    "assert prune_manual_index([(1, 3), (5, 7)], [1, 5]) == [(1, 3), (5, 7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_segment(segment, tsv_data):\n",
    "    if is_skippable(segment):\n",
    "        return\n",
    "    tsv = get_tsv_for_segment(segment, tsv_data)\n",
    "    references = segment[\"low_level\"][\"resolved_references\"]\n",
    "    manual_idx = segment[\"low_level\"].get(\"resolved_references_indices\", {})\n",
    "\n",
    "    # these are ordered. Kinda.\n",
    "    indices = {}\n",
    "    for ref in references:\n",
    "        indices[ref] = get_indices(ref, segment[\"snippet\"])\n",
    "        print(\"1\", ref, indices[ref])\n",
    "        if ref in manual_idx:\n",
    "            indices[ref] = prune_manual_index(indices[ref], manual_idx[ref])\n",
    "        # for index in indices:\n",
    "        #     print(ref, index, tsv[index[0]:index[1]])\n",
    "        print(\"2\", ref, indices[ref])\n",
    "\n",
    "    # print(references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "None\n",
      "1\n",
      "None\n",
      "2\n",
      "None\n",
      "3\n",
      "None\n",
      "4\n",
      "None\n",
      "5\n",
      "1 See-through [(0, 1)]\n",
      "2 See-through [(0, 1)]\n",
      "1 blue [(1, 2)]\n",
      "2 blue [(1, 2)]\n",
      "1 green [(2, 3)]\n",
      "2 green [(2, 3)]\n",
      "None\n",
      "6\n",
      "None\n",
      "7\n",
      "None\n",
      "8\n",
      "None\n",
      "9\n",
      "1 that weird waste bin [(1, 5)]\n",
      "2 that weird waste bin [(1, 5)]\n",
      "1 that [(1, 2), (8, 9)]\n",
      "2 that [(1, 2), (8, 9)]\n",
      "None\n",
      "10\n",
      "1 that [(3, 4)]\n",
      "2 that [(3, 4)]\n",
      "1 it [(12, 13)]\n",
      "2 it [(12, 13)]\n",
      "None\n",
      "11\n",
      "1 it [(2, 3)]\n",
      "2 it [(2, 3)]\n",
      "None\n",
      "12\n",
      "1 the desk [(8, 10)]\n",
      "2 the desk [(8, 10)]\n",
      "1 it [(11, 12), (15, 16)]\n",
      "2 it [(11, 12), (15, 16)]\n",
      "None\n",
      "13\n",
      "None\n",
      "14\n",
      "None\n",
      "15\n",
      "1 the table [(16, 18)]\n",
      "2 the table [(16, 18)]\n",
      "None\n",
      "16\n",
      "1 it [(3, 4)]\n",
      "2 it [(3, 4)]\n",
      "None\n",
      "17\n",
      "None\n",
      "18\n",
      "1 it [(13, 14)]\n",
      "2 it [(13, 14)]\n",
      "None\n",
      "19\n",
      "None\n",
      "20\n",
      "1 the couches [(2, 4)]\n",
      "2 the couches [(2, 4)]\n",
      "None\n",
      "21\n",
      "None\n",
      "22\n",
      "1 them [(3, 4)]\n",
      "2 them [(3, 4)]\n",
      "None\n",
      "23\n",
      "None\n",
      "24\n",
      "None\n",
      "25\n",
      "1 the windows [(0, 2)]\n",
      "2 the windows [(0, 2)]\n",
      "None\n",
      "26\n",
      "None\n",
      "27\n",
      "None\n",
      "28\n",
      "None\n",
      "29\n",
      "1 them [(4, 5)]\n",
      "2 them [(4, 5)]\n",
      "None\n",
      "30\n",
      "None\n",
      "31\n",
      "None\n",
      "32\n",
      "None\n",
      "33\n",
      "None\n",
      "34\n",
      "1 the fireplace [(4, 6)]\n",
      "2 the fireplace [(4, 6)]\n",
      "None\n",
      "35\n",
      "None\n",
      "36\n",
      "None\n",
      "37\n",
      "None\n",
      "38\n",
      "None\n",
      "39\n",
      "1 it [(4, 5)]\n",
      "2 it [(4, 5)]\n",
      "None\n",
      "40\n",
      "None\n",
      "41\n",
      "None\n",
      "42\n",
      "1 it [(4, 5)]\n",
      "2 it [(4, 5)]\n",
      "None\n",
      "43\n",
      "None\n",
      "44\n",
      "None\n",
      "45\n",
      "None\n",
      "46\n",
      "1 the lights [(2, 4)]\n",
      "2 the lights [(2, 4)]\n",
      "None\n",
      "47\n",
      "1 the TV [(3, 5)]\n",
      "2 the TV [(3, 5)]\n",
      "None\n",
      "48\n",
      "1 the TV [(3, 5)]\n",
      "2 the TV [(3, 5)]\n",
      "None\n",
      "49\n",
      "1 it [(5, 6), (14, 15)]\n",
      "2 it [(5, 6), (14, 15)]\n",
      "None\n",
      "50\n",
      "1 the TV [(3, 5)]\n",
      "2 the TV [(3, 5)]\n",
      "None\n",
      "51\n",
      "None\n",
      "52\n",
      "None\n",
      "53\n",
      "None\n",
      "54\n",
      "1 this lamp [(1, 3)]\n",
      "2 this lamp [(1, 3)]\n",
      "None\n",
      "55\n",
      "None\n",
      "56\n",
      "None\n",
      "57\n",
      "1 it [(0, 1), (2, 3), (10, 11)]\n",
      "2 it [(2, 3), (10, 11)]\n",
      "None\n",
      "58\n",
      "None\n",
      "59\n",
      "1 it [(5, 6)]\n",
      "2 it [(5, 6)]\n",
      "None\n",
      "60\n",
      "None\n",
      "61\n",
      "None\n",
      "62\n",
      "None\n",
      "63\n",
      "1 it [(0, 1)]\n",
      "2 it [(0, 1)]\n",
      "None\n",
      "64\n",
      "1 my plant [(8, 10)]\n",
      "2 my plant [(8, 10)]\n",
      "None\n",
      "65\n",
      "None\n",
      "66\n",
      "None\n",
      "67\n",
      "1 it [(7, 8)]\n",
      "2 it [(7, 8)]\n",
      "None\n",
      "68\n",
      "None\n",
      "69\n",
      "1 the yellow painting [(5, 8)]\n",
      "2 the yellow painting [(5, 8)]\n",
      "None\n",
      "70\n",
      "None\n",
      "71\n",
      "None\n",
      "72\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for seg in data:\n",
    "    print(seg)\n",
    "    print(process_segment(data[seg], ttsv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'general': {'id': 57, 'start': 216.59330501354725, 'end': 219.9003740473728},\n",
       " 'high_level': {'topic_name': 'reference_real',\n",
       "  'current_topic': 'lamp',\n",
       "  'topic_change': False,\n",
       "  'topic_duration_id': 3,\n",
       "  'spatial_reference': '',\n",
       "  'referenced_object': ['lamp']},\n",
       " 'low_level': {'resolved_references': {'it': 'lamp'},\n",
       "  'spatial_relationships': [],\n",
       "  'resolved_adverbs': [],\n",
       "  'resolved_references_indices': {'it': [2, 10]}},\n",
       " 'snippet': \"It's like, it looks weird. Did you do something with it?\"}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"57\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nst-tts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
