2023.sigtyp-1.20.pdf
https://aclanthology.org/2023.sigtyp-1.20.pdf

Self-Supervised Accent Learning for Under-Resourced Accents Using Native Language Data | IEEE Conference Publication | IEEE Xplore
https://ieeexplore.ieee.org/abstract/document/10096854

Submitted to INTERSPEECH
https://arxiv.org/pdf/2305.13629.pdf

Submitted to INTERSPEECH
https://arxiv.org/pdf/2305.14546.pdf

Submitted to INTERSPEECH
https://arxiv.org/pdf/2305.12459.pdf

2305.10763.pdf
https://arxiv.org/pdf/2305.10763.pdf

Submitted to INTERSPEECH
https://arxiv.org/pdf/2305.05084.pdf

THE HARPY SPEECH RECOGNITION SYSTEM
https://stacks.stanford.edu/file/druid:rq916rn6924/rq916rn6924.pdf

A brief history of speech recognition | Sonix
https://sonix.ai/history-of-speech-recognition#:~:text=In%201952%2C%20Bell%20Laboratories%20designed,could%20recognize%20sound%20and%20speech.

azu_etd_17345_sip1_m.pdf
https://repository.arizona.edu/bitstream/handle/10150/634249/azu_etd_17345_sip1_m.pdf?sequence=1

ADA013808.pdf
https://apps.dtic.mil/sti/pdfs/ADA013808.pdf

IEEE Xplore Full-Text PDF:
https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6031408

azu_etd_17345_sip1_m.pdf
https://repository.arizona.edu/bitstream/handle/10150/634249/azu_etd_17345_sip1_m.pdf?sequence=1

htkbook.pdf
https://www.danielpovey.com/files/htkbook.pdf

conformer/README.md at main · sooftware/conformer · GitHub
https://github.com/sooftware/conformer/blob/main/README.md

openspeech-team/openspeech: Open-Source Toolkit for End-to-End Speech Recognition leveraging PyTorch-Lightning and Hydra.
https://github.com/openspeech-team/openspeech

parlance/ctcdecode: PyTorch CTC Decoder bindings
https://github.com/parlance/ctcdecode

1ytic/warp-rnnt: CUDA-Warp RNN-Transducer
https://github.com/1ytic/warp-rnnt

Commits · awni/transducer
https://github.com/awni/transducer/commits/master?after=e90c6f45f10ccb404befddb0a99463fa6cb2e753+34&branch=master&qualified_name=refs%2Fheads%2Fmaster

[1211.3711] Sequence Transduction with Recurrent Neural Networks
https://arxiv.org/abs/1211.3711

use gemm for logsumexp · awni/transducer@fba5f8d
https://github.com/awni/transducer/commit/fba5f8d17cece5bde651f40858bba3ca041da7cd

transducer/transducer.c at cda55c0eb20a699ad0c04cc643bcfc1cbfd4856a · awni/transducer · GitHub
https://github.com/awni/transducer/blob/cda55c0eb20a699ad0c04cc643bcfc1cbfd4856a/src/transducer.c

awni (awni) / Repositories
https://github.com/awni?tab=repositories

awni/awni.github.io: Machine-Learning Blog
https://github.com/awni/awni.github.io

Awni Hannun
https://awnihannun.com/

awni/speech: A PyTorch Implementation of End-to-End Models for Speech-to-Text
https://github.com/awni/speech

awni/transducer: A Fast Sequence Transducer Implementation with PyTorch Bindings
https://github.com/awni/transducer

awni/automata_ml: An Introduction to Weighted Automata in Machine Learning
https://github.com/awni/automata_ml

differentiation_with_automata.pdf
https://awnihannun.com/writing/automata_ml/differentiation_with_automata.pdf

2206.00888.pdf
https://arxiv.org/pdf/2206.00888.pdf

2005.03191.pdf
https://arxiv.org/pdf/2005.03191.pdf

ContextNet — Openspeech v0.3.0 documentation
https://openspeech-team.github.io/openspeech/architectures/ContextNet.html

openspeech/model.py at main · openspeech-team/openspeech · GitHub
https://github.com/openspeech-team/openspeech/blob/main/openspeech/models/squeezeformer/model.py

2005.08100.pdf
https://arxiv.org/pdf/2005.08100.pdf

Sequence-to-Sequence Speech Recognition with Time-Depth Separable Convolutions
https://www.isca-speech.org/archive_v0/Interspeech_2019/pdfs/2460.pdf

add description for g2p.py · Takaaki-Saeki/zm-text-tts@e3ca681
https://github.com/Takaaki-Saeki/zm-text-tts/commit/e3ca6811992dd88169761b26b5b9e87cbfa2dd38

Translatotron 3: Speech to Speech Translation with Monolingual Data
https://google-research.github.io/lingvo-lab/translatotron3/

Google Colaboratory
https://github.com/googlecolab

googlecolab/colab-widgets
https://github.com/googlecolab/colab-widgets

googlecolab/colabtools: Python libraries for Google Colaboratory
https://github.com/googlecolab/colabtools

Google Colaboratory
https://github.com/googlecolab

googlecolab/colab-widgets
https://github.com/googlecolab/colab-widgets

googlecolab/colab-cdn-widget-manager
https://github.com/googlecolab/colab-cdn-widget-manager

googlecolab/colab-widgets
https://github.com/googlecolab/colab-widgets

googlecolab/tswidgets
https://github.com/googlecolab/tswidgets

colabtools/notebooks at main · googlecolab/colabtools · GitHub
https://github.com/googlecolab/colabtools/tree/main/notebooks

colabtools/packages/outputframe at main · googlecolab/colabtools · GitHub
https://github.com/googlecolab/colabtools/tree/main/packages/outputframe

advanced_outputs.ipynb - Colaboratory
https://colab.research.google.com/notebooks/snippets/advanced_outputs.ipynb

xiph/LPCNet: Efficient neural speech synthesis
https://github.com/xiph/LPCNet

phoible/dev: PHOIBLE data and development.
https://github.com/phoible/dev

PHOIBLE 2.0 -
https://phoible.org/conventions

bible-corpus/bibles at master · christos-c/bible-corpus · GitHub
https://github.com/christos-c/bible-corpus/tree/master/bibles

tuben/formantsynt.py at main · jbeskow/tuben · GitHub
https://github.com/jbeskow/tuben/blob/main/formantsynt.py

gestdiff_eval/makevids.py at master · jbeskow/gestdiff_eval · GitHub
https://github.com/jbeskow/gestdiff_eval/blob/master/sg23/makevids.py

jbeskow/lrc2vid
https://github.com/jbeskow/lrc2vid

jupyter notebook - Ipywidgets with Google Colaboratory - Stack Overflow
https://stackoverflow.com/questions/47269168/ipywidgets-with-google-colaboratory

Support installation of custom widgets. · Issue #498 · googlecolab/colabtools
https://github.com/googlecolab/colabtools/issues/498

Building a Custom Widget - Email widget — Jupyter Widgets 7.7.2 documentation
https://ipywidgets.readthedocs.io/en/7.x/examples/Widget%20Custom.html

Aniruddha Deb – The Properly Illustrated Transformer
https://aniruddhadeb.com/articles/2023/properly-illustrated-transformer.html

The Illustrated Transformer – Jay Alammar – Visualizing machine learning one concept at a time.
https://jalammar.github.io/illustrated-transformer/

The Annotated Transformer
http://nlp.seas.harvard.edu/annotated-transformer/

enhuiz/vall-e: An unofficial PyTorch implementation of the audio LM VALL-E
https://github.com/enhuiz/vall-e

facebookresearch/encodec: State-of-the-art deep learning based audio codec supporting both mono 24 kHz audio and stereo 48 kHz audio.
https://github.com/facebookresearch/encodec

neonbjb/tortoise-tts: A multi-voice TTS system trained with an emphasis on quality
https://github.com/neonbjb/tortoise-tts

CoDi: Generate Anything from Anything All At Once through Composable Diffusion
https://codi-gen.github.io/

i-Code/i-Code-V3 at main · microsoft/i-Code · GitHub
https://github.com/microsoft/i-Code/tree/main/i-Code-V3

haoheliu/AudioLDM: AudioLDM: Generate speech, sound effects, music and beyond, with text.
https://github.com/haoheliu/AudioLDM

diffusers/src/diffusers/models at main · huggingface/diffusers · GitHub
https://github.com/huggingface/diffusers/tree/main/src/diffusers/models

diffusers/autoencoder_kl.py at main · huggingface/diffusers · GitHub
https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/autoencoder_kl.py

diffusers/vae.py at main · huggingface/diffusers · GitHub
https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/vae.py

Automatic Generation of Subtitles for Videos of the Government of La Rioja | SpringerLink
https://link.springer.com/chapter/10.1007/978-3-031-34020-8_30

2305.16107.pdf
https://arxiv.org/pdf/2305.16107.pdf

Submitted to INTERSPEECH
https://arxiv.org/pdf/2305.13629.pdf

Professor Lei Xie, Northwestern Polytechnical University
http://lxie.nwpu-aslp.org/

wiki.nwpu-aslp.org
http://wiki.nwpu-aslp.org/

西工大音频语音与语言处理研究组
http://www.npu-aslp.org/english

TencentGameMate/chinese_speech_pretrain: chinese speech pretrained models
https://github.com/TencentGameMate/chinese_speech_pretrain

wenet-e2e/wenet: Production First and Production Ready End-to-End Speech Recognition Toolkit
https://github.com/wenet-e2e/wenet

thuhcsi/VAENAR-TTS: The official implementation of VAENAR-TTS, a VAE based non-autoregressive TTS model.
https://github.com/thuhcsi/VAENAR-TTS

keonlee9420/Expressive-FastSpeech2: PyTorch Implementation of Non-autoregressive Expressive (emotional, conversational) TTS based on FastSpeech2, supporting English, Korean, and your own languages.
https://github.com/keonlee9420/Expressive-FastSpeech2

[2305.18096] Improving Textless Spoken Language Understanding with Discrete Units as Intermediate Target
https://arxiv.org/abs/2305.18096

[2305.17732] StyleS2ST: Zero-shot Style Transfer for Direct Speech-to-speech Translation
https://arxiv.org/abs/2305.17732

CoDi: Generate Anything from Anything All At Once through Composable Diffusion
https://codi-gen.github.io/

Add i-Code-V3 (CoDi) inference pipeline and examples by zinengtang · Pull Request #50 · microsoft/i-Code
https://github.com/microsoft/i-Code/pull/50/files#diff-e2073ad989d3cde5a5ce1368b4925feba65104f1e25f6085fdbaa070676a7043

ZinengTang/CoDi · Hugging Face
https://huggingface.co/ZinengTang/CoDi


