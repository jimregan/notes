{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "_TUT3ZmAkUWD"
      },
      "outputs": [],
      "source": [
        "input_textgrid = \"/content/alcott-male-kobietki_001_rozdzial-i-pielgrzymki.textgrid\" # @param {\"type\":\"string\"}\n",
        "input_json = \"/content/alcott-male-kobietki_001_rozdzial-i-pielgrzymki.json\" # @param {\"type\":\"string\"}\n",
        "pronounce_as_tsv = \"/content/pronounce-as.tsv\" # @param {\"type\":\"string\"}\n",
        "language = \"pl\" # @param [\"pl\", \"en\", \"sv\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%pip install praatio"
      ],
      "metadata": {
        "id": "80w6mV8fkl0K"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%pip install piper_phonemize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6hcmz5EOolm",
        "outputId": "943d8251-744d-4855-e099-5a1576b8d92d"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting piper_phonemize\n",
            "  Downloading piper_phonemize-1.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (282 bytes)\n",
            "Downloading piper_phonemize-1.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (25.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.0/25.0 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: piper_phonemize\n",
            "Successfully installed piper_phonemize-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "STRIP_PUNCTUATION = {\n",
        "    \"pl\": \",;:!?—…„”\\\"“.«»*()[]‘/\\\\\",\n",
        "    \"en\": \",;:!?—…„”\\\"“.«»*()[]‘/\\\\\",\n",
        "}"
      ],
      "metadata": {
        "id": "CQIulkYCPMgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read huggingface json\n",
        "import json\n",
        "\n",
        "def read_huggingface_json(input_json):\n",
        "    with open(input_json, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    words = []\n",
        "    for chunk in data[\"chunks\"]:\n",
        "        words.append((chunk[\"timestamp\"][0], chunk[\"timestamp\"][1], chunk[\"text\"]))\n",
        "    return words"
      ],
      "metadata": {
        "id": "ue_gA9c2kqfV"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read pronounce-as data\n",
        "def read_pronounce_as(pronounce_as_tsv):\n",
        "    pronounce_as = {}\n",
        "    with open(pronounce_as_tsv, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            line = line.strip().split('\\t')\n",
        "            word = line[0].lower()\n",
        "            if not word in pronounce_as:\n",
        "                pronounce_as[word] = set()\n",
        "            pronounce_as[word].add(line[1])\n",
        "    if len(pronounce_as) == 0:\n",
        "        return None\n",
        "    return pronounce_as"
      ],
      "metadata": {
        "id": "3_3IXZjjn8kz"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read praat utterances\n",
        "from praatio import textgrid\n",
        "\n",
        "def read_praat_utterances(input_textgrid):\n",
        "    utterances = []\n",
        "    tg = textgrid.openTextgrid(input_textgrid, includeEmptyIntervals=False)\n",
        "\n",
        "    for tmp_tier in tg.tiers:\n",
        "        if tmp_tier.name == \"utterances\":\n",
        "            tier = tmp_tier\n",
        "            break\n",
        "\n",
        "    for interval in tier.entries:\n",
        "        if interval.label.strip() == \"\":\n",
        "            continue\n",
        "        utterances.append((interval.start, interval.end, interval.label))\n",
        "    return utterances"
      ],
      "metadata": {
        "id": "e6xXXl_eqL5c"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "utterances = read_praat_utterances(input_textgrid)\n",
        "words = read_huggingface_json(input_json)\n",
        "pronounce_as = read_pronounce_as(pronounce_as_tsv)"
      ],
      "metadata": {
        "id": "8WAcce3Arazh"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_by_start = {x[0]: x for x in words}\n",
        "words_by_end = {x[1]: x for x in words}"
      ],
      "metadata": {
        "id": "CpT3vu1SsZ0i"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def group_words_by_utterances(words, utterances):\n",
        "\n",
        "    collected = []\n",
        "    new_utterances = []\n",
        "    for utterance in utterances:\n",
        "        start = utterance[0]\n",
        "        end = utterance[1]\n",
        "\n",
        "        ut_dict = {\n",
        "            \"start\": utterance[0],\n",
        "            \"end\": utterance[1],\n",
        "            \"text\": utterance[2],\n",
        "            \"words\": []\n",
        "        }\n",
        "        for word in words:\n",
        "            if word[0] < start:\n",
        "                if word[1] > start:\n",
        "                    ut_dict[\"maybe_start\"] = word\n",
        "                continue\n",
        "            elif word[1] > end:\n",
        "                if word[0] < end:\n",
        "                    ut_dict[\"maybe_end\"] = word\n",
        "                break\n",
        "            elif word[0] >= start and word[1] <= end:\n",
        "                ut_dict[\"words\"].append(word)\n",
        "                collected.append(word)\n",
        "            else:\n",
        "                print(word)\n",
        "        new_utterances.append(ut_dict)\n",
        "\n",
        "    not_collected = []\n",
        "    for word in words:\n",
        "        if word not in collected:\n",
        "            not_collected.append(word)\n",
        "\n",
        "    return new_utterances, not_collected"
      ],
      "metadata": {
        "id": "OeGjX1DEshAx"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grouped, uncollected = group_words_by_utterances(words, utterances)"
      ],
      "metadata": {
        "id": "SrO-JcaPuSnl"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_normalised_words(text):\n",
        "    text = text.lower()\n",
        "    words = [word.strip(STRIP_PUNCTUATION[language]) for word in text.split()]\n",
        "    words = [x for x in words if x != \"\"]\n",
        "    return words\n"
      ],
      "metadata": {
        "id": "3bk7KP98xhal"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for item in grouped:\n",
        "    item[\"normalised_words\"] = get_normalised_words(item[\"text\"])"
      ],
      "metadata": {
        "id": "V_OeVNwfyscW"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "leftover = ''\n",
        "for item in grouped:\n",
        "    w2v_words = [x[2] for x in item[\"words\"]]\n",
        "    if leftover != \"\":\n",
        "        w2v_words = [leftover] + w2v_words\n",
        "        item[\"maybe_start_word\"] = leftover\n",
        "        leftover = ''\n",
        "    elif \"maybe_start\" in item:\n",
        "        if item[\"maybe_start\"][2].endswith(item[\"normalised_words\"][0]):\n",
        "            w2v_words = [item[\"normalised_words\"][0]] + w2v_words\n",
        "            item[\"maybe_start_word\"] = item[\"normalised_words\"][0]\n",
        "    if \"maybe_end\" in item:\n",
        "        if item[\"maybe_end\"][2].startswith(item[\"normalised_words\"][-1]):\n",
        "            item[\"maybe_end_word\"] = item[\"normalised_words\"][-1]\n",
        "            w2v_words = w2v_words + [item[\"normalised_words\"][-1]]\n",
        "            leftover = item[\"maybe_end\"][2][len(item[\"maybe_end_word\"]):]\n",
        "    if w2v_words == item[\"normalised_words\"]:\n",
        "        item[\"ok\"] = True"
      ],
      "metadata": {
        "id": "4IjgHGfF0PWP"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from difflib import SequenceMatcher\n",
        "\n",
        "# run a sequence matcher, but filter for the common\n",
        "# case of a difference in spacing.\n",
        "# Also, extract the relevant pieces.\n",
        "def filter_smatcher(ref, hyp):\n",
        "    items = []\n",
        "\n",
        "    s = SequenceMatcher(None, ref, hyp)\n",
        "    for opcode in s.get_opcodes():\n",
        "        if opcode[0] == 'equal':\n",
        "            items.append((\"OK\", ref[opcode[1]:opcode[2]]))\n",
        "        elif opcode[0] == 'insert':\n",
        "            items.append((\"INSERT\", hyp[opcode[3]:opcode[4]]))\n",
        "        elif opcode[0] == 'delete':\n",
        "            items.append((\"DELETE\", ref[opcode[1]:opcode[2]]))\n",
        "        elif opcode[0] == 'replace':\n",
        "            left = ref[opcode[1]:opcode[2]]\n",
        "            right = hyp[opcode[3]:opcode[4]]\n",
        "            if \"\".join(left) == \"\".join(right):\n",
        "                items.append((\"OK\", left))\n",
        "            else:\n",
        "                items.append((\"REPLACE\", left, right))\n",
        "    return items"
      ],
      "metadata": {
        "id": "lWe8i1Vn9gpc"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_filter_smatcher(item):\n",
        "    a = item[\"normalised_words\"]\n",
        "    b = [x[2] for x in item[\"words\"]]\n",
        "    if \"maybe_start_word\" in item:\n",
        "        b = [item[\"maybe_start_word\"]] + b\n",
        "    if \"maybe_end_word\" in item:\n",
        "        b = b + [item[\"maybe_end_word\"]]\n",
        "    return filter_smatcher(a, b)"
      ],
      "metadata": {
        "id": "yrvEa8GUAnzF"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CHECKED_STARTS = [\n",
        "    1148.4643,\n",
        "    1165.464,\n",
        "    1089.572,\n",
        "    1050.643,\n",
        "    1009.3364,\n",
        "    1039.4474,\n",
        "    1262.991,\n",
        "    5.4285,\n",
        "    10.4302,\n",
        "    28.4102,\n",
        "    229.2161,\n",
        "    260.7154,\n",
        "    302.2812,\n",
        "    1121.9926,\n",
        "    1225.599,\n",
        "    1401.72,\n",
        "    1064.1156,\n",
        "    1222.379,\n",
        "    760.1107,\n",
        "    801.1269,\n",
        "    156.831,\n",
        "    1356.0282,\n",
        "    1445.424,\n",
        "    1458.4299,\n",
        "    1462.4391,\n",
        "    1481.8289,\n",
        "    1491.5354,\n",
        "    1423.2975,\n",
        "    1407.9742,\n",
        "    58.7359,\n",
        "    67.4604,\n",
        "    191.8702,\n",
        "    209.3544,\n",
        "    233.9202,\n",
        "    630.2735,\n",
        "    269.192,\n",
        "    608.6451,\n",
        "    554.6953,\n",
        "    539.9961,\n",
        "    626.63,\n",
        "    306.1663,\n",
        "    681.7677,\n",
        "]"
      ],
      "metadata": {
        "id": "bN6Fv8qUMLuF"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import piper_phonemize\n",
        "\n",
        "def run_piper(text, accents = False):\n",
        "    ret = piper_phonemize.phonemize_espeak(text=text, voice=language)\n",
        "    if not accents:\n",
        "        ACCENTS = [\"ˈ\", \"ˌ\"]\n",
        "        ret = [x for y in ret for x in y if x not in ACCENTS]\n",
        "    return ret\n",
        "\n",
        "def check_phonemised(a, b):\n",
        "    if len(a) == len(b) == 1:\n",
        "        a_phn = run_piper(text=a[0])\n",
        "        b_phn = run_piper(text=b[0])\n",
        "        return a_phn == b_phn\n",
        "\n",
        "    a_phn_list = run_piper(text=\" \".join(a))\n",
        "    b_phn_list = run_piper(text=\" \".join(b))\n",
        "    a_phn_nospace = run_piper(text=\"\".join(a))\n",
        "    b_phn_nospace = run_piper(text=\"\".join(b))\n",
        "\n",
        "    return a_phn_list == b_phn_list or a_phn_nospace == b_phn_nospace\n"
      ],
      "metadata": {
        "id": "U-WzPfD6PsT7"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_phonemised([\"stym\"], [\"z\", \"tym\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKSLlcN8UiQf",
        "outputId": "9ed2c8db-889a-412d-f2f0-24286a4017c2"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['s', 't', 'ɨ', 'm'] ['s', ' ', 't', 'ɨ', 'm'] ['s', 't', 'ɨ', 'm'] ['s', 't', 'ɨ', 'm']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_counts(diffs):\n",
        "    counts = {\n",
        "        \"OK\": 0,\n",
        "        \"INSERT\": 0,\n",
        "        \"DELETE\": 0,\n",
        "        \"REPLACE\": 0\n",
        "    }\n",
        "    for diff in diffs:\n",
        "        counts[diff[0]] += 1\n",
        "    return counts"
      ],
      "metadata": {
        "id": "ejUuRqRmROOO"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def counts_ok(counts):\n",
        "    return counts[\"INSERT\"] == 0 and counts[\"DELETE\"] == 0 and counts[\"REPLACE\"] == 0"
      ],
      "metadata": {
        "id": "_o4Itai6RldK"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for item in grouped:\n",
        "    item_printed = False\n",
        "    if item[\"start\"] in CHECKED_STARTS:\n",
        "        item[\"ok\"] = True\n",
        "    if \"ok\" in item and item[\"ok\"]:\n",
        "        continue\n",
        "    diffs = run_filter_smatcher(item)\n",
        "    counts = get_counts(diffs)\n",
        "    for diff in diffs:\n",
        "        if diff[0] == \"OK\":\n",
        "            continue\n",
        "        if diff[0] == \"REPLACE\":\n",
        "            if check_phonemised(diff[1], diff[2]):\n",
        "                counts[\"REPLACE\"] -= 1\n",
        "                if counts_ok(counts):\n",
        "                    item[\"ok\"] = True\n",
        "                    break\n",
        "            if not item_printed:\n",
        "                print(item[\"start\"], item[\"text\"])\n",
        "                item_printed = True\n",
        "            print(diff[1], diff[2])\n",
        "        if diff[0] == \"INSERT\":\n",
        "            if not item_printed:\n",
        "                print(item[\"start\"], \"INS\", item[\"text\"])\n",
        "                item_printed = True\n",
        "            print(diff[1])\n",
        "        if diff[0] == \"DELETE\":\n",
        "            if not item_printed:\n",
        "                print(item[\"start\"], \"DEL\", item[\"text\"])\n",
        "                item_printed = True\n",
        "            print(diff[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OK5l34j-BIX5",
        "outputId": "e4bf0eee-e10a-4526-fc29-d091f6798d61"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "280.0684 DEL — Ona używa takich gminnych słów — zauważyła Amelka, rzucając gromiące spojrzenie na długą postać rozciągniętą na dywanie.\n",
            "['na', 'dywanie']\n",
            "296.4915 DEL — Dlatego też gwiżdżę.\n",
            "['gwiżdżę']\n",
            "298.7279 DEL — Nic cierpię ordynarnych, nieeleganckich dziewcząt.\n",
            "['nic', 'cierpię']\n",
            "343.9231 — Nie jestem! I jeżeli upinanie włosów czyni mnie doroślejszą, to będę nosiła warkocze do dwudziestu lat! — zawołała, zrzucając siatkę i rozwieszając ciemnoblond grzywę.\n",
            "['mnie'] ['nie']\n",
            "['ciemnoblond', 'grzywę'] ['ciemno', 'bląd']\n",
            "356.1204 — Nie cierpię tej myśli, że dorosnę, zostanę panną March, będę nosić długie suknie i wyglądać tak sztywno jak aster chiński.\n",
            "['march'] ['marcz']\n",
            "['suknie'] ['sukni']\n",
            "391.3708 Lecz nie ma na to rady; staraj się więc poprzestać na odgrywaniu roli naszego brata — rzekła Eliza, głaszcząc szorstkie włosy na głowie wspartej o jej kolana, rączką przyjemną w dotknięciu, pomimo zmywania talerzy i okurzania sprzętów.\n",
            "['okurzania'] ['odkórzenia']\n",
            "420.096 Lubię twoje dobre maniery i wykwintne wysławianie się, gdy nie próbujesz być elegancka, ale twoje niedorzeczne wyrazy stawiam na równi z gminnymi słowami Ludki.\n",
            "['wykwintne'] ['wykwitne']\n",
            "['wyrazy'] ['wyraze']\n",
            "['równi'] ['równie']\n",
            "['gminnymi'] ['gmiennymi']\n",
            "451.755 Ponieważ młode czytelniczki lubią wiedzieć, „jak kto wygląda”, skorzystamy z tej chwili, żeby dać lekki szkic tych czterech dziewczynek, siedzących o szarej godzinie z robotą na drutach, podczas gdy śnieg grudniowy pada cicho na dworze, a ogień trzeszczy wesoło na kominku.\n",
            "['trzeszczy'] ['trzeszcz']\n",
            "469.3168 Był to miły pokój, pomimo spłowiałego dywanu i bardzo prostych mebli; wisiało bowiem na ścianach parę dobrych obrazów, na półkach było dużo książek, w oknach kwitły hiacynty i cierniki i napełniała go przyjemna atmosfera domowego spokoju.\n",
            "['półkach'] ['pułkach']\n",
            "['kwitły', 'hiacynty'] ['kwitłych', 'jacenty']\n",
            "501.9019 Piętnastoletnia Ludka była bardzo wysoka, szczupła i smagła; zawsze jej zawadzały długie kończyny i nie wiedziała, co z nimi robić.\n",
            "['nimi'] ['niemi']\n",
            "509.9198 Miała stanowcze usta, komiczny nos, bystre, szare oczy, które zdawały się wszystko widzieć i bywały to gwałtowne, to śmiejące się, to zamyślone.\n",
            "['stanowcze'] ['stanowczo']\n",
            "527.9309 Ramiona miała szerokie, ręce i nogi duże, ubrani wisiało na niej bez wdzięku i we wszystkim miała niezgrabną minę dziewczynki, która prędko wyrasta na kobietę i jest z tego niezadowolona.\n",
            "['ubrani'] ['ubranie']\n",
            "['i']\n",
            "['z']\n",
            "574.551 Była ta dzieweczka kształtna, biała jak śnieg, z niebieskimi oczami i z główką w złocistych loczkach.\n",
            "['ta'] ['to']\n",
            "638.6914 — Odkąd papa wyjechał, ja jestem jedynym mężczyzną w naszej rodzinie i sama zaopatrzę ją w pantofle, bo odjeżdżając, powierzył ją moim szczególnym staraniom.\n",
            "['zaopatrzę'] ['zaopatrzy']\n",
            "672.479 — Ja najpiękniejsze pantofle, jakie tylko znajdę! — wykrzyknęła Ludka.\n",
            "['pantofle', 'jakie'] ['pantofleje', 'kie']\n",
            "704.1571 DEL — Tak się lękałam, ile razy przyszła na mnie kolej usiąść w fotelu z koroną na głowie, a wyście mnie obstępowały z podarkami i całusami.\n",
            "['i']\n",
            "773.1373 — Nic na to nie poradzę; nigdy nie widziałam, jak się mdleje, a nie mam ochoty zsinieć, sczernieć i paść na wznak, jak ty.\n",
            "['mdleje'] ['dlaje']\n",
            "['zsinieć', 'sczernieć'] ['ssinieć', 'zczernieć']\n",
            "846.2798 Odtąd szło gładziej, bo Don Pedro wyzywał świat jednym tchem w dwustronicowej mowie, czarownica Agara z olśniewającym efektem odśpiewała uroczyste zaklęcie nad patelnią smażących się grzanek, Rodryg zerwał swe więzy z prawdziwie męską siłą, a Hugo, dziko krzycząc „ha! ha!”, skończył życie w mękach trucizny i wyrzutów sumienia.\n",
            "['dwustronicowej'] ['dwu', 'stronnicowej']\n",
            "['smażących'] ['smarzących']\n",
            "['rodryg'] ['rodryk']\n",
            "['wyrzutów'] ['wyrzutw']\n",
            "870.2156 — Pierwszy raz tak się nam udało — rzekła Małgorzata, gdy zmarły złoczyńca usiadł i rozcierał sobie łokcie.\n",
            "['usiadł'] ['siadł']\n",
            "890.6886 — Niezupełnie — odparła skromnie Ludka — wprawdzie klątwa czarownicy i liryczna tragedia to ładne rzeczy, ale chciałabym spróbować Makbeta, gdybyśmy miały klapę w podłodze dla Banka.\n",
            "['makbeta'] ['macbeta']\n",
            "905.291 „Czy sztylet widzę przed sobą?” — wyrzekła, przewracając oczyma i dysząc jak pewna artystka, którą widziała na scenie.\n",
            "['czy', 'sztylet'] ['tylet']\n",
            "925.8849 — Cieszy mnie to, żeście tak wesołe! — odezwał się ożywiony głos we drzwiach, a publiczność i aktorzy obrócili się, by powitać wysoką panią z matczyną twarzą i z tak miłym wyrazem twarzy, jak gdyby każdego pytała: „Czy mogę ci być pomocna?”\n",
            "['we'] ['w']\n",
            "942.2354 Nie była to szczególnie piękna osoba, ale matki zawsze się podobają swoim dzieciom; dziewczętom zdawało się też, że jej szary płaszczyk i niemodny kapelusik okrywają najwspanialszą kobietę na świecie.\n",
            "['dziewczętom'] ['dziewczętą']\n",
            "967.5726 Ludwisiu, zdajesz się na śmierć zmęczona.\n",
            "['ludwisiu'] ['ludwisiuł']\n",
            "970.4827 Dziecię, chodź mnie pocałować.\n",
            "['chodź'] ['chód']\n",
            "973.7509 Zadając te matczyne pytania, pani March zdjęła z siebie przemokłe rzeczy, włożyła ogrzane pantofle i usiadłszy w fotelu, wzięła Amelkę na kolana, ciesząc się na najmilszą godzinę w swym pracowitym dniu.\n",
            "['te', 'matczyne'] ['tematyczyne']\n",
            "['march'] ['marcz']\n",
            "['ogrzane'] ['ograne']\n",
            "986.4572 Dziewczęta krzątały się; każda chciała jej oddać jakąś przysługę i zapewnić wygodę.\n",
            "['każda'] ['każde']\n",
            "992.128 DEL Małgosia przygotowała stół do herbaty; Ludka przyniosła drewna i ustawiła krzesła, wylewając i przewracając z hałasem wszystko, czego tknęła; Eliza cicho i gorliwie kręciła się między pokojem a kuchnią, Amelka zaś wydawała im rozkazy, siedząc sama z założonymi rękami.\n",
            "['z']\n",
            "['eliza'] ['liza']\n",
            "1080.0939 — Jakżebym chciała pójść na dobosza, wivan, jakże się to nazywa? Albo na sanitariuszkę, żeby być razem i czuwać nad nim! — zawołała Ludka.\n",
            "['wivan'] ['wi', 'wan']\n",
            "['sanitariuszkę'] ['sanitariuszka']\n",
            "1141.727 Pan March niewiele wspominał o trudach i niebezpieczeństwach, ani nawet o tęsknocie do kraju, z którą musiał walczyć.\n",
            "['march'] ['marcz']\n",
            "1202.215 W tym miejscu wszystkie rozczuliły się; Ludka nie wstydziła się wielkiej łzy, która jej spadła na nos; Amelka zaś, nie zważając, że psuje sobie loki, ukryła twarzyczkę na ramieniu matki i z łkaniem rzekła:\n",
            "['wielkiej'] ['wielkie']\n",
            "1252.0336 Eliza, nic nie mówiąc, obtarła oczy niebieską skarpetką i zaczęła czym prędzej obracać drutami, aby bez straty czasu pełnić obowiązek znajdujący się najbliżej.\n",
            "['eliza'] ['liza']\n",
            "1272.0337 Pani March przerwała milczenie, panujące po słowach Ludwisi, mówiąc swym wesołym głosem:\n",
            "['march'] ['marcz']\n",
            "1300.3975 — Jakież to było zabawne, zwłaszcza kiedyśmy się wybierały na lwy, na walkę z Apollionem i z wilkołakami, które znajdowały się w dolinie — rzekła Ludka.\n",
            "['apollionem'] ['apolionem']\n",
            "1309.3591 — Lubiłam miejsce, gdzieśmy zdejmowały brzemiona i ciskały ze schodów — odezwała się Małgosia.\n",
            "['zdejmowały', 'brzemiona'] ['zajmowały', 'brzemione']\n",
            "1314.8694 — A dla mnie najlepsza chwila była, kiedyśmy wychodziły, śpiewając z radości wśród promieni słońca, na płaski dach, gdzie były kwiaty, krzewy i inne ładne rzeczy — powiedziała Eliza z uśmiechem, jak gdyby te lube czasy powróciły dla niej.\n",
            "['wychodziły'] ['wychodziłe']\n",
            "['lube'] ['luby']\n",
            "1349.428 — Nie jesteśmy na to nigdy za duże, moja droga, bo w ten czy w inny sposób zawsze się w to bawimy.\n",
            "['duże'] ['duża']\n",
            "1379.2916 — Mamo, ale gdzie są naprawdę nasze brzemiona? — spytała Amelka, biorąca rzeczy bardzo ściśle.\n",
            "['amelka'] ['ameryka']\n",
            "1428.4878 Więc co mamy teraz robić? — zapytała Ludka, uradowana myślą, że coś romantycznego osłodzi jej nudne obowiązki.\n",
            "['jej', 'nudne'] ['i', 'nudny']\n",
            "1435.9828 DEL — Zajrzyjcie pod poduszki w poranek Bożego Narodzenia, to znajdziecie książki, które wam posłużą za przewodników — odpowiedziała pani March.\n",
            "['march']\n"
          ]
        }
      ]
    }
  ]
}