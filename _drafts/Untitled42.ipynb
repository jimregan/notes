{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "_TUT3ZmAkUWD"
      },
      "outputs": [],
      "source": [
        "input_textgrid = \"/content/alcott-male-kobietki_001_rozdzial-i-pielgrzymki.textgrid\" # @param {\"type\":\"string\"}\n",
        "input_json = \"/content/alcott-male-kobietki_001_rozdzial-i-pielgrzymki.json\" # @param {\"type\":\"string\"}\n",
        "pronounce_as_tsv = \"/content/pronounce-as.tsv\" # @param {\"type\":\"string\"}\n",
        "language = \"pl\" # @param [\"pl\", \"en\", \"sv\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%pip install praatio"
      ],
      "metadata": {
        "id": "80w6mV8fkl0K"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%pip install piper_phonemize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6hcmz5EOolm",
        "outputId": "943d8251-744d-4855-e099-5a1576b8d92d"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting piper_phonemize\n",
            "  Downloading piper_phonemize-1.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (282 bytes)\n",
            "Downloading piper_phonemize-1.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (25.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.0/25.0 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: piper_phonemize\n",
            "Successfully installed piper_phonemize-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "STRIP_PUNCTUATION = {\n",
        "    \"pl\": \",;:!?—…„”\\\"“.«»*()[]‘/\\\\\",\n",
        "    \"en\": \",;:!?—…„”\\\"“.«»*()[]‘/\\\\\",\n",
        "}"
      ],
      "metadata": {
        "id": "CQIulkYCPMgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read huggingface json\n",
        "import json\n",
        "\n",
        "def read_huggingface_json(input_json):\n",
        "    with open(input_json, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    words = []\n",
        "    for chunk in data[\"chunks\"]:\n",
        "        words.append((chunk[\"timestamp\"][0], chunk[\"timestamp\"][1], chunk[\"text\"]))\n",
        "    return words"
      ],
      "metadata": {
        "id": "ue_gA9c2kqfV"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read pronounce-as data\n",
        "def read_pronounce_as(pronounce_as_tsv):\n",
        "    pronounce_as = {}\n",
        "    with open(pronounce_as_tsv, 'r') as f:\n",
        "        for line in f.readlines():\n",
        "            line = line.strip().split('\\t')\n",
        "            word = line[0].lower()\n",
        "            if not word in pronounce_as:\n",
        "                pronounce_as[word] = set()\n",
        "            pronounce_as[word].add(line[1])\n",
        "    if len(pronounce_as) == 0:\n",
        "        return None\n",
        "    return pronounce_as"
      ],
      "metadata": {
        "id": "3_3IXZjjn8kz"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read praat utterances\n",
        "from praatio import textgrid\n",
        "\n",
        "def read_praat_utterances(input_textgrid):\n",
        "    utterances = []\n",
        "    tg = textgrid.openTextgrid(input_textgrid, includeEmptyIntervals=False)\n",
        "\n",
        "    for tmp_tier in tg.tiers:\n",
        "        if tmp_tier.name == \"utterances\":\n",
        "            tier = tmp_tier\n",
        "            break\n",
        "\n",
        "    for interval in tier.entries:\n",
        "        if interval.label.strip() == \"\":\n",
        "            continue\n",
        "        utterances.append((interval.start, interval.end, interval.label))\n",
        "    return utterances"
      ],
      "metadata": {
        "id": "e6xXXl_eqL5c"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "utterances = read_praat_utterances(input_textgrid)\n",
        "words = read_huggingface_json(input_json)\n",
        "pronounce_as = read_pronounce_as(pronounce_as_tsv)"
      ],
      "metadata": {
        "id": "8WAcce3Arazh"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_by_start = {x[0]: x for x in words}\n",
        "words_by_end = {x[1]: x for x in words}"
      ],
      "metadata": {
        "id": "CpT3vu1SsZ0i"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def group_words_by_utterances(words, utterances):\n",
        "\n",
        "    collected = []\n",
        "    new_utterances = []\n",
        "    for utterance in utterances:\n",
        "        start = utterance[0]\n",
        "        end = utterance[1]\n",
        "\n",
        "        ut_dict = {\n",
        "            \"start\": utterance[0],\n",
        "            \"end\": utterance[1],\n",
        "            \"text\": utterance[2],\n",
        "            \"words\": []\n",
        "        }\n",
        "        for word in words:\n",
        "            if word[0] < start:\n",
        "                if word[1] > start:\n",
        "                    ut_dict[\"maybe_start\"] = word\n",
        "                continue\n",
        "            elif word[1] > end:\n",
        "                if word[0] < end:\n",
        "                    ut_dict[\"maybe_end\"] = word\n",
        "                break\n",
        "            elif word[0] >= start and word[1] <= end:\n",
        "                ut_dict[\"words\"].append(word)\n",
        "                collected.append(word)\n",
        "            else:\n",
        "                print(word)\n",
        "        new_utterances.append(ut_dict)\n",
        "\n",
        "    not_collected = []\n",
        "    for word in words:\n",
        "        if word not in collected:\n",
        "            not_collected.append(word)\n",
        "\n",
        "    return new_utterances, not_collected"
      ],
      "metadata": {
        "id": "OeGjX1DEshAx"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grouped, uncollected = group_words_by_utterances(words, utterances)"
      ],
      "metadata": {
        "id": "SrO-JcaPuSnl"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_normalised_words(text):\n",
        "    text = text.lower()\n",
        "    words = [word.strip(STRIP_PUNCTUATION[language]) for word in text.split()]\n",
        "    words = [x for x in words if x != \"\"]\n",
        "    return words\n"
      ],
      "metadata": {
        "id": "3bk7KP98xhal"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for item in grouped:\n",
        "    item[\"normalised_words\"] = get_normalised_words(item[\"text\"])"
      ],
      "metadata": {
        "id": "V_OeVNwfyscW"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "leftover = ''\n",
        "for item in grouped:\n",
        "    w2v_words = [x[2] for x in item[\"words\"]]\n",
        "    if leftover != \"\":\n",
        "        w2v_words = [leftover] + w2v_words\n",
        "        item[\"maybe_start_word\"] = leftover\n",
        "        leftover = ''\n",
        "    elif \"maybe_start\" in item:\n",
        "        if item[\"maybe_start\"][2].endswith(item[\"normalised_words\"][0]):\n",
        "            w2v_words = [item[\"normalised_words\"][0]] + w2v_words\n",
        "            item[\"maybe_start_word\"] = item[\"normalised_words\"][0]\n",
        "    if \"maybe_end\" in item:\n",
        "        if item[\"maybe_end\"][2].startswith(item[\"normalised_words\"][-1]):\n",
        "            item[\"maybe_end_word\"] = item[\"normalised_words\"][-1]\n",
        "            w2v_words = w2v_words + [item[\"normalised_words\"][-1]]\n",
        "            leftover = item[\"maybe_end\"][2][len(item[\"maybe_end_word\"]):]\n",
        "    if w2v_words == item[\"normalised_words\"]:\n",
        "        item[\"ok\"] = True"
      ],
      "metadata": {
        "id": "4IjgHGfF0PWP"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from difflib import SequenceMatcher\n",
        "\n",
        "# run a sequence matcher, but filter for the common\n",
        "# case of a difference in spacing.\n",
        "# Also, extract the relevant pieces.\n",
        "def filter_smatcher(ref, hyp):\n",
        "    items = []\n",
        "\n",
        "    s = SequenceMatcher(None, ref, hyp)\n",
        "    for opcode in s.get_opcodes():\n",
        "        if opcode[0] == 'equal':\n",
        "            items.append((\"OK\", ref[opcode[1]:opcode[2]]))\n",
        "        elif opcode[0] == 'insert':\n",
        "            items.append((\"INSERT\", hyp[opcode[3]:opcode[4]]))\n",
        "        elif opcode[0] == 'delete':\n",
        "            items.append((\"DELETE\", ref[opcode[1]:opcode[2]]))\n",
        "        elif opcode[0] == 'replace':\n",
        "            left = ref[opcode[1]:opcode[2]]\n",
        "            right = hyp[opcode[3]:opcode[4]]\n",
        "            if \"\".join(left) == \"\".join(right):\n",
        "                items.append((\"OK\", left))\n",
        "            else:\n",
        "                items.append((\"REPLACE\", left, right))\n",
        "    return items"
      ],
      "metadata": {
        "id": "lWe8i1Vn9gpc"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_filter_smatcher(item):\n",
        "    a = item[\"normalised_words\"]\n",
        "    b = [x[2] for x in item[\"words\"]]\n",
        "    if \"maybe_start_word\" in item:\n",
        "        b = [item[\"maybe_start_word\"]] + b\n",
        "    if \"maybe_end_word\" in item:\n",
        "        b = b + [item[\"maybe_end_word\"]]\n",
        "    return filter_smatcher(a, b)"
      ],
      "metadata": {
        "id": "yrvEa8GUAnzF"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CHECKED_STARTS = [\n",
        "    1148.4643,\n",
        "    1165.464,\n",
        "    1089.572,\n",
        "    1050.643,\n",
        "    1009.3364,\n",
        "    1039.4474,\n",
        "    1262.991,\n",
        "    5.4285,\n",
        "    10.4302,\n",
        "    28.4102,\n",
        "    229.2161,\n",
        "    260.7154,\n",
        "    302.2812,\n",
        "    1121.9926,\n",
        "    1225.599,\n",
        "    1401.72,\n",
        "    1064.1156\n",
        "]"
      ],
      "metadata": {
        "id": "bN6Fv8qUMLuF"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import piper_phonemize\n",
        "\n",
        "def check_phonemised(a, b):\n",
        "    if len(a) == len(b) == 1:\n",
        "        a_phn = piper_phonemize.phonemize_espeak(text=a[0], voice=language)\n",
        "        b_phn = piper_phonemize.phonemize_espeak(text=b[0], voice=language)\n",
        "        return a_phn == b_phn\n",
        "    a_phn_list = piper_phonemize.phonemize_espeak(text=\" \".join(a), voice=language)\n",
        "    b_phn_list = piper_phonemize.phonemize_espeak(text=\" \".join(b), voice=language)\n",
        "    a_phn_nospace = piper_phonemize.phonemize_espeak(text=\"\".join(a), voice=language)\n",
        "    b_phn_nospace = piper_phonemize.phonemize_espeak(text=\"\".join(b), voice=language)\n",
        "    return a_phn_list == b_phn_list or a_phn_nospace == b_phn_nospace\n"
      ],
      "metadata": {
        "id": "U-WzPfD6PsT7"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_counts(diffs):\n",
        "    counts = {\n",
        "        \"OK\": 0,\n",
        "        \"INSERT\": 0,\n",
        "        \"DELETE\": 0,\n",
        "        \"REPLACE\": 0\n",
        "    }\n",
        "    for diff in diffs:\n",
        "        counts[diff[0]] += 1\n",
        "    return counts"
      ],
      "metadata": {
        "id": "ejUuRqRmROOO"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def counts_ok(counts):\n",
        "    return counts[\"INSERT\"] == 0 and counts[\"DELETE\"] == 0 and counts[\"REPLACE\"] == 0"
      ],
      "metadata": {
        "id": "_o4Itai6RldK"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for item in grouped:\n",
        "    item_printed = False\n",
        "    if item[\"start\"] in CHECKED_STARTS:\n",
        "        item[\"ok\"] = True\n",
        "    if \"ok\" in item and item[\"ok\"]:\n",
        "        continue\n",
        "    diffs = run_filter_smatcher(item)\n",
        "    counts = get_counts(diffs)\n",
        "    for diff in diffs:\n",
        "        if diff[0] == \"OK\":\n",
        "            continue\n",
        "        if diff[0] == \"REPLACE\":\n",
        "            if check_phonemised(diff[1], diff[2]):\n",
        "                counts[\"REPLACE\"] -= 1\n",
        "                if counts_ok(counts):\n",
        "                    item[\"ok\"] = True\n",
        "                    break\n",
        "        if diff[0] == \"INSERT\":\n",
        "            if not item_printed:\n",
        "                print(item[\"start\"], item[\"text\"])\n",
        "                item_printed = True\n",
        "            print(diff[1], diff[2])"
      ],
      "metadata": {
        "id": "OK5l34j-BIX5"
      },
      "execution_count": 149,
      "outputs": []
    }
  ]
}