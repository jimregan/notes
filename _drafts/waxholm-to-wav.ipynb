{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smp_probe(filename: str) -> bool:\n",
    "    with open(filename, \"rb\") as f:\n",
    "        return f.read(9) == b\"file=samp\"\n",
    "\n",
    "\n",
    "def smp_headers(filename: str):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        f.seek(0)\n",
    "        raw_headers = f.read(1024)\n",
    "        raw_headers = raw_headers.rstrip(b'\\x00')\n",
    "        asc_headers = raw_headers.decode(\"ascii\")\n",
    "        asc_headers.rstrip('\\x00')\n",
    "        tmp = [a for a in asc_headers.split(\"\\r\\n\")]\n",
    "        back = -1\n",
    "        while abs(back) > len(tmp) + 1:\n",
    "            if tmp[back] == '=':\n",
    "                break\n",
    "            back -= 1\n",
    "        tmp = tmp[0:back-1]\n",
    "        return dict(a.split(\"=\") for a in tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = \"/Users/joregan/Playing/waxholm/scenes_formatted/fp2060/fp2060.11.04.smp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(example, \"rb\") as egf:\n",
    "    egf.seek(0)\n",
    "    blah = egf.read(1024)\n",
    "    a = egf.tell()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_args(\n",
    "        save_dir,\n",
    "        tensorboard_logdir,\n",
    "        data,\n",
    "        w2v_path,\n",
    "        empty_cache_freq=0,\n",
    "        best_checkpoint_metric=\"uer\",  # UER is a character error rate, oddly named\n",
    "        n_gpu=None,\n",
    "        lr=5e-05,\n",
    "        max_update=12000,\n",
    "        warmup_updates=4000,\n",
    "        hold_updates=4000,\n",
    "        decay_updates=4000,\n",
    "        freeze_updates=2000,  # Freeze all but the output layer\n",
    "        validate_after_updates=1000,\n",
    "        validate_interval=1,\n",
    "        valid_subset=\"valid\",\n",
    "        max_tokens=MAX_TOKENS,   # per device. 1250000 fills up the rtx2080 11GB\n",
    "        max_tokens_per_minibatch=6400000,\n",
    "        mask_prob=0.65,\n",
    "        mask_channel_length=64,\n",
    "        mask_channel_prob=0.25,\n",
    "        update_freq=None,\n",
    "        layerdrop=0.1,  # Unconfirmed but I think it's layerdrop/hidden_dropout for fairseq -> huggingface\n",
    "        final_lr_scale=0.05,\n",
    "        final_dropout=0.1,\n",
    "        dropout=0.1,\n",
    "        activation_dropout=0.1,\n",
    "        attention_dropout=0.1,\n",
    "        random_seed=5728395,\n",
    "        adam_epsilon=1e-08,\n",
    "        adam_betas=(0.9, 0.98),\n",
    "        weight_decay=0.0\n",
    "):\n",
    "    # This is pretty clunky, but still less clunky than bash imo\n",
    "    n_gpu = n_gpu or torch.cuda.device_count() or 1\n",
    "    update_freq = update_freq or math.ceil(max_tokens_per_minibatch / max_tokens / n_gpu)\n",
    "    args_string = f\"\"\"\n",
    "      {data}\n",
    "      --fp16\n",
    "      --save-dir {save_dir}\n",
    "      --tensorboard-logdir {tensorboard_logdir}\n",
    "      --distributed-world-size {n_gpu}\n",
    "      --empty-cache-freq {empty_cache_freq}\n",
    "      --max-sample-size {max_tokens}\n",
    "      --max-tokens {max_tokens}\n",
    "      --max-tokens-valid {max_tokens}\n",
    "      --update-freq [{update_freq}]\n",
    "      --post-process letter\n",
    "      --valid-subset {valid_subset}\n",
    "      --no-epoch-checkpoints\n",
    "      --best-checkpoint-metric {best_checkpoint_metric}\n",
    "      --num-workers 1\n",
    "      --max-update {max_update}\n",
    "      --sentence-avg\n",
    "      --task audio_pretraining\n",
    "      --arch wav2vec_ctc\n",
    "      --w2v-path {w2v_path}\n",
    "      --labels ltr\n",
    "      --weight-decay {weight_decay}\n",
    "      --apply-mask\n",
    "      --mask-selection static\n",
    "      --mask-other 0\n",
    "      --mask-length 10\n",
    "      --mask-prob {mask_prob}\n",
    "      --mask-channel-selection static\n",
    "      --mask-channel-other 0\n",
    "      --mask-channel-length {mask_channel_length}\n",
    "      --mask-channel-prob {mask_channel_prob}\n",
    "      --zero-infinity\n",
    "      --feature-grad-mult 0.0\n",
    "      --freeze-finetune-updates {freeze_updates}\n",
    "      --validate-after-updates {validate_after_updates}\n",
    "      --validate-interval {validate_interval}\n",
    "      --optimizer adam\n",
    "      --adam-betas {adam_betas}\n",
    "      --adam-eps {adam_epsilon}\n",
    "      --lr {lr}\n",
    "      --lr-scheduler tri_stage\n",
    "      --warmup-steps {warmup_updates}\n",
    "      --hold-steps {hold_updates}\n",
    "      --decay-steps {decay_updates}\n",
    "      --final-lr-scale {final_lr_scale}\n",
    "      --final-dropout {final_dropout}\n",
    "      --dropout {dropout}\n",
    "      --layerdrop {layerdrop}\n",
    "      --activation-dropout {activation_dropout}\n",
    "      --criterion ctc\n",
    "      --attention-dropout {attention_dropout}\n",
    "      --seed {random_seed}\n",
    "      --log-format json\n",
    "      --log-interval 50\n",
    "      --ddp-backend no_c10d\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dd927b719e572b496e2474453a2ada7f45c90bda9f6c95960374c767a23741c2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('psst')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
