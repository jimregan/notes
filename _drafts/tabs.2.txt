G2P neural - Google Docs
https://docs.google.com/document/d/1RzaqocPs4YLgwP-XX9O60MPG5yJScbQuMDtUt9Ro4Sc/edit

Untitled document - Google Docs
https://docs.google.com/document/d/1aNi_OPVV4vak2ylG35ePr0sd3inOUlIEeVPZk9Vr8Ok/edit

Untitled18.ipynb - Colaboratory
https://colab.research.google.com/drive/1s7DrEd9N_zQC7vyyq6NNC-HQTw6IVbiJ#scrollTo=PpqWzcykc0K_

SIGMORPHON - Special Interest Group on Computational Morphology and Phonology
https://sigmorphon.github.io/

sigmorphon/2021-task1: Second SIGMORPHON Shared Task on Grapheme-to-Phoneme Conversions
https://github.com/sigmorphon/2021-task1

segments/tokenizer.py at master · cldf/segments
https://github.com/cldf/segments/blob/master/src/segments/tokenizer.py

2020/task1/baselines/encoder-decoder at master · sigmorphon/2020
https://github.com/sigmorphon/2020/tree/master/task1/baselines/encoder-decoder

2021-task1/transducer.py at main · sigmorphon/2021-task1
https://github.com/sigmorphon/2021-task1/blob/main/baseline/trans/transducer.py

Making a Point: Pointer-Generator Transformers for Disjoint Vocabularies
https://aclanthology.org/2020.aacl-srw.13.pdf

The CoNLL–SIGMORPHON 2018 Shared Task: Universal Morphological Reinflection - ACL Anthology
https://aclanthology.org/K18-3001/

Tacotron2-Nvidia/bash.bashrc at master · smehta/Tacotron2-Nvidia
https://gits-15.sys.kth.se/smehta/Tacotron2-Nvidia/blob/master/bash.bashrc

Character level models? · Issue #4090 · huggingface/transformers
https://github.com/huggingface/transformers/issues/4090

lucidrains/reformer-pytorch: Reformer, the efficient Transformer, in Pytorch
https://github.com/lucidrains/reformer-pytorch

lucidrains (Phil Wang) / Repositories
https://github.com/lucidrains?tab=repositories

lucidrains/nuwa-pytorch: Implementation of NÜWA, state of the art attention network for text to video synthesis, in Pytorch
https://github.com/lucidrains/nuwa-pytorch

lucidrains/point-transformer-pytorch: Implementation of the Point Transformer layer, in Pytorch
https://github.com/lucidrains/point-transformer-pytorch

x-transformers/x_transformers.py at main · lucidrains/x-transformers
https://github.com/lucidrains/x-transformers/blob/main/x_transformers/x_transformers.py

triton-transformer/softmax.py at main · lucidrains/triton-transformer
https://github.com/lucidrains/triton-transformer/blob/main/triton_transformer/softmax.py

Installation — Triton documentation
https://triton-lang.org/getting-started/installation.html

lucidrains/rela-transformer: Implementation of a Transformer using ReLA (Rectified Linear Attention) from https://arxiv.org/abs/2104.07012
https://github.com/lucidrains/rela-transformer

1907.01470.pdf
https://arxiv.org/pdf/1907.01470.pdf

Hierarchical Mixtures Of Experts And The Em Algorithm - Neural Networks, 1993. IJCNN '93-Nagoya. Proceedings of 1993 International Joint Conference on
https://www.cs.toronto.edu/~hinton/absps/hme.pdf

2020/README.md at master · sigmorphon/2020
https://github.com/sigmorphon/2020/blob/master/task1/README.md

The SIGMORPHON 2020 Shared Task on Multilingual Grapheme-to-Phoneme Conversion
https://aclanthology.org/2020.sigmorphon-1.2.pdf

Low-Resource G2P and P2G Conversion with Synthetic Training Data
https://aclanthology.org/2020.sigmorphon-1.12.pdf

letter-to-phoneme/m2m-aligner: Automatically exported from code.google.com/p/m2m-aligner
https://github.com/letter-to-phoneme/m2m-aligner

Google Code Archive - Long-term storage for Google Code Project Hosting.
https://code.google.com/archive/p/directl-p/

letter-to-phoneme/directl-p: Automatically exported from code.google.com/p/directl-p
https://github.com/letter-to-phoneme/directl-p

Add CharacterBERT model [WIP] by helboukkouri · Pull Request #10053 · huggingface/transformers
https://github.com/huggingface/transformers/pull/10053

Commits · huggingface/transformers
https://github.com/huggingface/transformers/commits/master

Add the SEW and SEW-D speech models by anton-l · Pull Request #13962 · huggingface/transformers
https://github.com/huggingface/transformers/pull/13962

asappresearch/sew
https://github.com/asappresearch/sew/

helboukkouri/character-bert: Main repository for "CharacterBERT: Reconciling ELMo and BERT for Word-Level Open-Vocabulary Representations From Characters"
https://github.com/helboukkouri/character-bert

helboukkouri/character-bert-pretraining: Code for pre-training CharacterBERT models (as well as BERT models).
https://github.com/helboukkouri/character-bert-pretraining

[2108.10447] One TTS Alignment To Rule Them All
https://arxiv.org/abs/2108.10447

NeMo/aligner.py at 046fad0f8fa72ce67d0f7718a048f3be82526402 · NVIDIA/NeMo
https://github.com/NVIDIA/NeMo/blob/046fad0f8fa72ce67d0f7718a048f3be82526402/examples/tts/aligner.py

NVIDIA/flowtron: Flowtron is an auto-regressive flow-based generative network for text to speech synthesis with control over speech variation and style transfer
https://github.com/NVIDIA/flowtron

2103.15060.pdf
https://arxiv.org/pdf/2103.15060.pdf

shamanez/BERT-like-is-All-You-Need: The code for our INTERSPEECH 2020 paper - Jointly Fine-Tuning "BERT-like'" Self Supervised Models to Improve Multimodal Speech Emotion Recognition
https://github.com/shamanez/BERT-like-is-All-You-Need

PnG BERT: Augmented BERT on Phonemes and Graphemes for Neural TTS | DeepAI
https://deepai.org/publication/png-bert-augmented-bert-on-phonemes-and-graphemes-for-neural-tts

JetRunner/BERT-of-Theseus: ⛵️The official PyTorch implementation for "BERT-of-Theseus: Compressing BERT by Progressive Module Replacing" (EMNLP 2020).
https://github.com/JetRunner/BERT-of-Theseus

Synthesis reading group paper list - Google Kalkylark
https://docs.google.com/spreadsheets/d/1OVdpLulHkEX_Kulz6G3OzzrP-mkPmfI6nNoPBjxJsMw/edit#gid=1226758484

1910.11997.pdf
https://arxiv.org/pdf/1910.11997.pdf

ls - How to get the total duration of all video files in current folder and sub-directories - Unix & Linux Stack Exchange
https://unix.stackexchange.com/questions/587646/how-to-get-the-total-duration-of-all-video-files-in-current-folder-and-sub-direc
