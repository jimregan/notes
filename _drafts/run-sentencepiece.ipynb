{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in /Users/joregan/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (0.1.96)\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.0.0-py3-none-any.whl (325 kB)\n",
      "\u001b[K     |████████████████████████████████| 325 kB 8.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /Users/joregan/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from datasets) (3.8.1)\n",
      "Collecting pyarrow>=5.0.0\n",
      "  Downloading pyarrow-7.0.0-cp38-cp38-macosx_10_13_x86_64.whl (20.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 20.2 MB 8.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /Users/joregan/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/joregan/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from datasets) (1.21.2)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.0.0-cp38-cp38-macosx_10_9_x86_64.whl (34 kB)\n",
      "Collecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: pandas in /Users/joregan/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from datasets) (1.4.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/joregan/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from datasets) (4.62.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/joregan/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from datasets) (2.27.1)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.12.2-py38-none-any.whl (128 kB)\n",
      "\u001b[K     |████████████████████████████████| 128 kB 18.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /Users/joregan/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /Users/joregan/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from datasets) (2022.1.0)\n",
      "Collecting dill\n",
      "  Using cached dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/joregan/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n",
      "Requirement already satisfied: pyyaml in /Users/joregan/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
      "Requirement already satisfied: filelock in /Users/joregan/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.4.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/joregan/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from packaging->datasets) (3.0.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/joregan/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/joregan/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/joregan/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2.0.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/joregan/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/joregan/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/joregan/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/joregan/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/joregan/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/joregan/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from aiohttp->datasets) (1.7.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/joregan/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/joregan/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/joregan/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/joregan/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: dill, xxhash, responses, pyarrow, multiprocess, datasets\n",
      "Successfully installed datasets-2.0.0 dill-0.3.4 multiprocess-0.70.12.2 pyarrow-7.0.0 responses-0.18.0 xxhash-3.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_ngraphs = \"ch sch sh si sj sk skj ssi ssj stj ti\".split(\" \")\n",
    "j_digraphs = \"dj gj hj lj\".split(\" \")\n",
    "tj_digraphs = \"kj tj\".split(\" \")\n",
    "retroflex_digraphs = \"rd rl rn rs rt\".split(\" \")\n",
    "assimilations = \"fv dt\".split(\" \")\n",
    "diphthongs = \"au eu\".split(\" \")\n",
    "other = \"ng gn ck\".split(\" \")\n",
    "doublings = [f\"{a}{a}\" for a in \"bcdfglmnpqrstvz\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngraphs = sj_ngraphs + j_digraphs + tj_digraphs + retroflex_digraphs + assimilations + diphthongs + doublings + other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset common_voice (/Users/joregan/.cache/huggingface/datasets/common_voice/sv-SE/6.1.0/d3d5467c15716a2699f2ea3710fdc8bed7c20ae8ed66c248185735a0695dcc3b)\n",
      "100%|██████████| 6/6 [00:00<00:00, 127.24it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"common_voice\", \"sv-SE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = set()\n",
    "_ALPHA = \"abcdefghijklmnopqrstuvwxyzåäöéABCDEFGHIJKLMNOPQRSTUVWXYZÅÄÖ\"\n",
    "skipped = set()\n",
    "for sentence in dataset[\"train\"][\"sentence\"]:\n",
    "    chars = []\n",
    "    i = 0\n",
    "    end = len(sentence)\n",
    "    while i < end:\n",
    "        if sentence[i] in \".,!?\\\"\":\n",
    "            skipped.add(sentence[i])\n",
    "        elif sentence[i] == \":\" or sentence[i] == \"-\":\n",
    "            if (i + 1) < end and sentence[i+1] in _ALPHA:\n",
    "                chars.append(sentence[i])\n",
    "            else:\n",
    "                skipped.add(sentence[i])\n",
    "        else:\n",
    "            chars.append(sentence[i])\n",
    "        i += 1\n",
    "    jnd = \"\".join(chars)\n",
    "    sentences.add(jnd.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"cv-text.txt\", \"w\") as f:\n",
    "    for sent in sentences:\n",
    "        f.write(sent + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: cv-text.txt\n",
      "  input_format: \n",
      "  model_prefix: swedish1k\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 1000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: cv-text.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 2329 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=73874\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.9729% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=27\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.999729\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 2329 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 7180 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 2329\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 3157\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 3157 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=2974 obj=9.61491 num_tokens=6167 num_tokens/piece=2.07364\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=2615 obj=8.4955 num_tokens=6250 num_tokens/piece=2.39006\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=1959 obj=8.61981 num_tokens=6861 num_tokens/piece=3.5023\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=1954 obj=8.52871 num_tokens=6887 num_tokens/piece=3.52456\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=1465 obj=8.9205 num_tokens=7851 num_tokens/piece=5.35904\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=1465 obj=8.82118 num_tokens=7863 num_tokens/piece=5.36724\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=1100 obj=9.3069 num_tokens=8927 num_tokens/piece=8.11545\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=1100 obj=9.21039 num_tokens=8931 num_tokens/piece=8.11909\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: swedish1k.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: swedish1k.vocab\n"
     ]
    }
   ],
   "source": [
    "spm.SentencePieceTrainer.train(input=\"cv-text.txt\", model_prefix=\"swedish1k\", vocab_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: cv-text.txt\n",
      "  input_format: \n",
      "  model_prefix: swedish1k_aug\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 1000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  user_defined_symbols: ch\n",
      "  user_defined_symbols: sch\n",
      "  user_defined_symbols: sh\n",
      "  user_defined_symbols: si\n",
      "  user_defined_symbols: sj\n",
      "  user_defined_symbols: sk\n",
      "  user_defined_symbols: skj\n",
      "  user_defined_symbols: ssi\n",
      "  user_defined_symbols: ssj\n",
      "  user_defined_symbols: stj\n",
      "  user_defined_symbols: ti\n",
      "  user_defined_symbols: dj\n",
      "  user_defined_symbols: gj\n",
      "  user_defined_symbols: hj\n",
      "  user_defined_symbols: lj\n",
      "  user_defined_symbols: kj\n",
      "  user_defined_symbols: tj\n",
      "  user_defined_symbols: rd\n",
      "  user_defined_symbols: rl\n",
      "  user_defined_symbols: rn\n",
      "  user_defined_symbols: rs\n",
      "  user_defined_symbols: rt\n",
      "  user_defined_symbols: fv\n",
      "  user_defined_symbols: dt\n",
      "  user_defined_symbols: au\n",
      "  user_defined_symbols: eu\n",
      "  user_defined_symbols: bb\n",
      "  user_defined_symbols: cc\n",
      "  user_defined_symbols: dd\n",
      "  user_defined_symbols: ff\n",
      "  user_defined_symbols: gg\n",
      "  user_defined_symbols: ll\n",
      "  user_defined_symbols: mm\n",
      "  user_defined_symbols: nn\n",
      "  user_defined_symbols: pp\n",
      "  user_defined_symbols: qq\n",
      "  user_defined_symbols: rr\n",
      "  user_defined_symbols: ss\n",
      "  user_defined_symbols: tt\n",
      "  user_defined_symbols: vv\n",
      "  user_defined_symbols: zz\n",
      "  user_defined_symbols: ng\n",
      "  user_defined_symbols: gn\n",
      "  user_defined_symbols: ck\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: cv-text.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 2329 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: ch\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: sch\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: sh\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: si\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: sj\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: sk\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: skj\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: ssi\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: ssj\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: stj\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: ti\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: dj\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: gj\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: hj\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: lj\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: kj\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: tj\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: rd\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: rl\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: rn\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: rs\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: rt\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: fv\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: dt\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: au\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: eu\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: bb\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: cc\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: dd\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: ff\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: gg\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: ll\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: mm\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: nn\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: pp\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: qq\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: rr\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: ss\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: tt\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: vv\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: zz\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: ng\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: gn\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: ck\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=69112\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.9711% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=27\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.999711\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 2329 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 4063 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 2329\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 3062\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 3062 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=2102 obj=16.2578 num_tokens=8417 num_tokens/piece=4.00428\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=1831 obj=15.8322 num_tokens=8566 num_tokens/piece=4.67832\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=1372 obj=15.7379 num_tokens=9056 num_tokens/piece=6.60058\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=1369 obj=15.7253 num_tokens=9127 num_tokens/piece=6.66691\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=1099 obj=15.8864 num_tokens=9623 num_tokens/piece=8.75614\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=1098 obj=15.8711 num_tokens=9699 num_tokens/piece=8.83333\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: swedish1k_aug.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: swedish1k_aug.vocab\n"
     ]
    }
   ],
   "source": [
    "spm.SentencePieceTrainer.train(input=\"cv-text.txt\", model_prefix=\"swedish1k_aug\", vocab_size=1000, user_defined_symbols=ngraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁arm',\n",
       " 'é',\n",
       " 'n',\n",
       " '▁skicka',\n",
       " 'de',\n",
       " '▁hem',\n",
       " '▁honom',\n",
       " '▁efter',\n",
       " 's',\n",
       " 'om',\n",
       " '▁han',\n",
       " '▁fungera',\n",
       " 'de',\n",
       " '▁dålig',\n",
       " 't',\n",
       " '▁social',\n",
       " 't']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "sp = spm.SentencePieceProcessor(model_file=\"swedish1k.model\")\n",
    "sp2 = spm.SentencePieceProcessor(model_file=\"swedish1k_aug.model\")\n",
    "sp.encode(\"armén skickade hem honom eftersom han fungerade dåligt socialt\", out_type=str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁arm',\n",
       " 'é',\n",
       " 'n',\n",
       " '▁',\n",
       " 'sk',\n",
       " 'i',\n",
       " 'ck',\n",
       " 'ade',\n",
       " '▁hem',\n",
       " '▁honom',\n",
       " '▁efter',\n",
       " 'som',\n",
       " '▁han',\n",
       " '▁fu',\n",
       " 'ng',\n",
       " 'erade',\n",
       " '▁dåligt',\n",
       " '▁social',\n",
       " 't']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp2.encode(\"armén skickade hem honom eftersom han fungerade dåligt socialt\", out_type=str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: cv-text.txt\n",
      "  input_format: \n",
      "  model_prefix: swedish1kbpe\n",
      "  model_type: BPE\n",
      "  vocab_size: 1000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: cv-text.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 2329 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=73874\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.9729% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=27\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.999729\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 2329 sentences.\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 2329\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 3157\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=1841 min_freq=1\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=580 size=20 all=1050 active=1022 piece=▁b\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=329 size=40 all=1376 active=1348 piece=▁inte\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=184 size=60 all=1801 active=1773 piece=▁st\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=114 size=80 all=2120 active=2092 piece=äl\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=86 size=100 all=2524 active=2496 piece=▁e\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=85 min_freq=5\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=72 size=120 all=2812 active=1280 piece=ur\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=61 size=140 all=3032 active=1500 piece=▁komm\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=50 size=160 all=3239 active=1707 piece=▁när\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=43 size=180 all=3512 active=1980 piece=▁hel\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=38 size=200 all=3696 active=2164 piece=▁oss\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=38 min_freq=5\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=34 size=220 all=3795 active=1100 piece=▁sm\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=30 size=240 all=4009 active=1314 piece=▁ig\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=27 size=260 all=4171 active=1476 piece=is\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=24 size=280 all=4283 active=1588 piece=get\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=22 size=300 all=4440 active=1745 piece=lar\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=22 min_freq=5\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=21 size=320 all=4543 active=1083 piece=▁mitt\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=20 size=340 all=4624 active=1164 piece=▁varför\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=18 size=360 all=4693 active=1233 piece=ill\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=17 size=380 all=4799 active=1339 piece=äst\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=16 size=400 all=4877 active=1417 piece=▁låt\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=16 min_freq=4\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=15 size=420 all=5019 active=1139 piece=▁vem\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14 size=440 all=5131 active=1251 piece=ånga\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=13 size=460 all=5208 active=1328 piece=ull\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12 size=480 all=5288 active=1408 piece=org\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12 size=500 all=5369 active=1489 piece=▁snar\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=12 min_freq=4\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11 size=520 all=5476 active=1106 piece=aden\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11 size=540 all=5514 active=1144 piece=▁började\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10 size=560 all=5625 active=1255 piece=▁kar\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10 size=580 all=5663 active=1293 piece=▁kväll\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9 size=600 all=5747 active=1377 piece=▁kn\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=9 min_freq=3\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9 size=620 all=5794 active=1043 piece=▁sti\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9 size=640 all=5815 active=1064 piece=▁tycker\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8 size=660 all=5909 active=1158 piece=ten\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8 size=680 all=5976 active=1225 piece=▁led\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8 size=700 all=6008 active=1257 piece=▁stod\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=8 min_freq=3\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7 size=720 all=6023 active=1016 piece=uv\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7 size=740 all=6093 active=1086 piece=▁sö\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7 size=760 all=6156 active=1149 piece=▁sam\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7 size=780 all=6173 active=1166 piece=ammans\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7 size=800 all=6168 active=1161 piece=▁vilken\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=6 min_freq=3\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=820 all=6277 active=1110 piece=▁al\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=840 all=6324 active=1157 piece=tast\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=860 all=6361 active=1194 piece=innor\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=880 all=6384 active=1217 piece=▁bygga\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=900 all=6383 active=1216 piece=▁gammal\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=6 min_freq=2\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=920 all=6375 active=993 piece=hå\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=940 all=6465 active=1083 piece=tat\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=960 all=6523 active=1141 piece=nars\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: swedish1kbpe.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: swedish1kbpe.vocab\n"
     ]
    }
   ],
   "source": [
    "spm.SentencePieceTrainer.train(input=\"cv-text.txt\", model_prefix=\"swedish1kbpe\", vocab_size=1000, model_type=\"bpe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: cv-text.txt\n",
      "  input_format: \n",
      "  model_prefix: swedish1kbpe_aug\n",
      "  model_type: BPE\n",
      "  vocab_size: 1000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  user_defined_symbols: ch\n",
      "  user_defined_symbols: sch\n",
      "  user_defined_symbols: sh\n",
      "  user_defined_symbols: si\n",
      "  user_defined_symbols: sj\n",
      "  user_defined_symbols: sk\n",
      "  user_defined_symbols: skj\n",
      "  user_defined_symbols: ssi\n",
      "  user_defined_symbols: ssj\n",
      "  user_defined_symbols: stj\n",
      "  user_defined_symbols: ti\n",
      "  user_defined_symbols: dj\n",
      "  user_defined_symbols: gj\n",
      "  user_defined_symbols: hj\n",
      "  user_defined_symbols: lj\n",
      "  user_defined_symbols: kj\n",
      "  user_defined_symbols: tj\n",
      "  user_defined_symbols: rd\n",
      "  user_defined_symbols: rl\n",
      "  user_defined_symbols: rn\n",
      "  user_defined_symbols: rs\n",
      "  user_defined_symbols: rt\n",
      "  user_defined_symbols: fv\n",
      "  user_defined_symbols: dt\n",
      "  user_defined_symbols: au\n",
      "  user_defined_symbols: eu\n",
      "  user_defined_symbols: bb\n",
      "  user_defined_symbols: cc\n",
      "  user_defined_symbols: dd\n",
      "  user_defined_symbols: ff\n",
      "  user_defined_symbols: gg\n",
      "  user_defined_symbols: ll\n",
      "  user_defined_symbols: mm\n",
      "  user_defined_symbols: nn\n",
      "  user_defined_symbols: pp\n",
      "  user_defined_symbols: qq\n",
      "  user_defined_symbols: rr\n",
      "  user_defined_symbols: ss\n",
      "  user_defined_symbols: tt\n",
      "  user_defined_symbols: vv\n",
      "  user_defined_symbols: zz\n",
      "  user_defined_symbols: ng\n",
      "  user_defined_symbols: gn\n",
      "  user_defined_symbols: ck\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: cv-text.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 2329 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: ch\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: sch\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: sh\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: si\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: sj\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: sk\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: skj\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: ssi\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: ssj\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: stj\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: ti\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: dj\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: gj\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: hj\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: lj\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: kj\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: tj\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: rd\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: rl\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: rn\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: rs\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: rt\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: fv\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: dt\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: au\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: eu\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: bb\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: cc\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: dd\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: ff\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: gg\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: ll\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: mm\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: nn\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: pp\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: qq\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: rr\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: ss\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: tt\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: vv\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: zz\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: ng\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: gn\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: ck\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=69112\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.9711% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=27\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.999711\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 2329 sentences.\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 2329\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 3062\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=1835 min_freq=1\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=520 size=20 all=851 active=823 piece=▁o\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=255 size=40 all=1145 active=1117 piece=on\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=129 size=60 all=1485 active=1457 piece=▁som\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=86 size=80 all=1736 active=1708 piece=▁av\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=69 size=100 all=1928 active=1900 piece=▁gör\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=68 min_freq=3\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=55 size=120 all=2112 active=1184 piece=re\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=42 size=140 all=2377 active=1449 piece=der\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=38 size=160 all=2476 active=1548 piece=▁vara\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=33 size=180 all=2588 active=1660 piece=ken\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=29 size=200 all=2703 active=1775 piece=▁vän\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=29 min_freq=3\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=25 size=220 all=2805 active=1094 piece=▁å\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=23 size=240 all=2886 active=1175 piece=▁un\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=21 size=260 all=2985 active=1274 piece=▁ser\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=19 size=280 all=3064 active=1353 piece=▁fo\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=18 size=300 all=3125 active=1414 piece=▁mä\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=18 min_freq=3\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=17 size=320 all=3159 active=1034 piece=▁varit\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=15 size=340 all=3255 active=1130 piece=▁mot\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14 size=360 all=3354 active=1229 piece=▁låg\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12 size=380 all=3407 active=1282 piece=je\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=12 size=400 all=3480 active=1355 piece=▁några\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=12 min_freq=2\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11 size=420 all=3592 active=1113 piece=▁läm\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=10 size=440 all=3627 active=1148 piece=▁äta\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9 size=460 all=3683 active=1204 piece=▁sy\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=9 size=480 all=3710 active=1231 piece=▁slut\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8 size=500 all=3784 active=1305 piece=ten\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=8 min_freq=2\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8 size=520 all=3830 active=1040 piece=▁mar\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8 size=540 all=3836 active=1046 piece=▁vänta\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7 size=560 all=3881 active=1091 piece=tal\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7 size=580 all=3919 active=1129 piece=▁bak\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=7 size=600 all=3932 active=1142 piece=▁klar\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=7 min_freq=2\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=620 all=3932 active=999 piece=jä\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=640 all=3986 active=1053 piece=kter\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=660 all=4009 active=1076 piece=▁enda\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6 size=680 all=4008 active=1075 piece=▁företag\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=700 all=4055 active=1122 piece=men\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=5 min_freq=2\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=720 all=4104 active=1043 piece=▁ry\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=740 all=4125 active=1064 piece=▁hit\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=760 all=4143 active=1082 piece=▁begå\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5 size=780 all=4135 active=1074 piece=▁omkri\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=800 all=4154 active=1093 piece=mp\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=4 min_freq=2\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=820 all=4199 active=1039 piece=ora\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=840 all=4228 active=1068 piece=drag\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=860 all=4249 active=1089 piece=▁död\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=880 all=4260 active=1100 piece=▁smi\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=900 all=4272 active=1112 piece=▁kast\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=4 min_freq=1\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4 size=920 all=4272 active=999 piece=▁förut\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: swedish1kbpe_aug.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: swedish1kbpe_aug.vocab\n"
     ]
    }
   ],
   "source": [
    "spm.SentencePieceTrainer.train(input=\"cv-text.txt\", model_prefix=\"swedish1kbpe_aug\", vocab_size=1000, model_type=\"bpe\", user_defined_symbols=ngraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁ar',\n",
       " 'm',\n",
       " 'é',\n",
       " 'n',\n",
       " '▁',\n",
       " 'sk',\n",
       " 'i',\n",
       " 'ck',\n",
       " 'ade',\n",
       " '▁hem',\n",
       " '▁honom',\n",
       " '▁efte',\n",
       " 'rs',\n",
       " 'om',\n",
       " '▁han',\n",
       " '▁fu',\n",
       " 'ng',\n",
       " 'erade',\n",
       " '▁då',\n",
       " 'ligt',\n",
       " '▁so',\n",
       " 'ci',\n",
       " 'alt']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp3 = spm.SentencePieceProcessor(model_file=\"swedish1kbpe_aug.model\")\n",
    "sp3.encode(\"armén skickade hem honom eftersom han fungerade dåligt socialt\", out_type=str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tokenizers in /Users/joregan/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (0.11.6)\n",
      "Requirement already satisfied: protobuf in /Users/joregan/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages (3.19.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install tokenizers protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import SentencePieceUnigramTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "You're trying to run a `Unigram` model but you're file was trained with a different algorithm",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/joregan/Playing/notes/_drafts/run-sentencepiece.ipynb Cell 17'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/joregan/Playing/notes/_drafts/run-sentencepiece.ipynb#ch0000017?line=0'>1</a>\u001b[0m tok1 \u001b[39m=\u001b[39m SentencePieceUnigramTokenizer\u001b[39m.\u001b[39mfrom_spm(\u001b[39m\"\u001b[39m\u001b[39mswedish1k.model\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/joregan/Playing/notes/_drafts/run-sentencepiece.ipynb#ch0000017?line=1'>2</a>\u001b[0m tok2 \u001b[39m=\u001b[39m SentencePieceUnigramTokenizer\u001b[39m.\u001b[39mfrom_spm(\u001b[39m\"\u001b[39m\u001b[39mswedish1k_aug.model\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/joregan/Playing/notes/_drafts/run-sentencepiece.ipynb#ch0000017?line=2'>3</a>\u001b[0m tok3 \u001b[39m=\u001b[39m SentencePieceUnigramTokenizer\u001b[39m.\u001b[39;49mfrom_spm(\u001b[39m\"\u001b[39;49m\u001b[39mswedish1kbpe.model\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/joregan/Playing/notes/_drafts/run-sentencepiece.ipynb#ch0000017?line=3'>4</a>\u001b[0m tok4 \u001b[39m=\u001b[39m SentencePieceUnigramTokenizer\u001b[39m.\u001b[39mfrom_spm(\u001b[39m\"\u001b[39m\u001b[39mswedish1kbpe_aug.model\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages/tokenizers/implementations/sentencepiece_unigram.py:135\u001b[0m, in \u001b[0;36mSentencePieceUnigramTokenizer.from_spm\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages/tokenizers/implementations/sentencepiece_unigram.py?line=132'>133</a>\u001b[0m model_type \u001b[39m=\u001b[39m m\u001b[39m.\u001b[39mtrainer_spec\u001b[39m.\u001b[39mmodel_type\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages/tokenizers/implementations/sentencepiece_unigram.py?line=133'>134</a>\u001b[0m \u001b[39mif\u001b[39;00m model_type \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> <a href='file:///~/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages/tokenizers/implementations/sentencepiece_unigram.py?line=134'>135</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages/tokenizers/implementations/sentencepiece_unigram.py?line=135'>136</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou\u001b[39m\u001b[39m'\u001b[39m\u001b[39mre trying to run a `Unigram` model but you\u001b[39m\u001b[39m'\u001b[39m\u001b[39mre file was trained with a different algorithm\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages/tokenizers/implementations/sentencepiece_unigram.py?line=136'>137</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages/tokenizers/implementations/sentencepiece_unigram.py?line=138'>139</a>\u001b[0m replacement \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m▁\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///~/opt/anaconda3/envs/pytorch_env/lib/python3.8/site-packages/tokenizers/implementations/sentencepiece_unigram.py?line=139'>140</a>\u001b[0m add_prefix_space \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mException\u001b[0m: You're trying to run a `Unigram` model but you're file was trained with a different algorithm"
     ]
    }
   ],
   "source": [
    "tok1 = SentencePieceUnigramTokenizer.from_spm(\"swedish1k.model\")\n",
    "tok2 = SentencePieceUnigramTokenizer.from_spm(\"swedish1k_aug.model\")\n",
    "tok3 = SentencePieceUnigramTokenizer.from_spm(\"swedish1kbpe.model\")\n",
    "tok4 = SentencePieceUnigramTokenizer.from_spm(\"swedish1kbpe_aug.model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2/unigram.json']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok1.save_model(\"tok1\")\n",
    "tok2.save_model(\"tok2\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7a4cadf7f6c4a04eb0c3890146b6c9b435f49945caf51e54d888e6c2304c7653"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('pyannote': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
