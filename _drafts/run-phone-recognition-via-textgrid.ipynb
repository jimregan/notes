{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "textgrid_dir = \"/home/joregan/textgrids\"\n",
    "wav_dir = \"/home/joregan/hsi/audio/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "textgrid_path = Path(textgrid_dir)\n",
    "wav_path = Path(wav_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from praatio import textgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def noise_event(text):\n",
    "    m = re.match(\"^\\[([^\\]]+)\\]$\", text)\n",
    "    return (m is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tier_entries(textgrid, tiername=\"utterances\"):\n",
    "    entries = []\n",
    "\n",
    "    tier = textgrid.getTier(tiername)\n",
    "    for entry in tier.entries:\n",
    "        text = entry.label\n",
    "        if text.strip() == \"\":\n",
    "            continue\n",
    "        if not noise_event(text.strip()):\n",
    "            entries.append({\n",
    "                \"start\": entry.start,\n",
    "                \"end\": entry.end,\n",
    "                \"text\": entry.label\n",
    "            })\n",
    "    return entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_espeak(text):\n",
    "    phon = !echo \"{text}\" | espeak-ng -v en-us --ipa -q\n",
    "    return (\" \".join(phon)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def espeakify_entries(entries):\n",
    "    for entry in entries:\n",
    "        entry[\"espeak\"] = run_espeak(entry[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def entries_add_audio(wavfile, entries):\n",
    "    audio = AudioSegment.from_file(wavfile)\n",
    "    assert audio.channels == 1, \"More than 1 channel\"\n",
    "    dtype = getattr(np, \"int{:d}\".format(audio.sample_width * 8))\n",
    "\n",
    "    for entry in entries:\n",
    "        start = int(entry[\"start\"] * 1000)\n",
    "        end = int(entry[\"end\"] * 1000)\n",
    "        selection = audio[start:end]\n",
    "        selection = selection.set_frame_rate(16000)\n",
    "        array = np.array(selection.get_array_of_samples())\n",
    "        array = array.astype(\"float32\")\n",
    "        array /= np.iinfo(dtype).max\n",
    "        entry[\"audio\"] = array.squeeze()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joregan/miniconda3/envs/hf_new/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor, AutoModelForCTC, Wav2Vec2Processor\n",
    "import torch\n",
    "from itertools import groupby\n",
    "\n",
    "def decode_phonemes(\n",
    "    ids: torch.Tensor, processor: Wav2Vec2Processor, ignore_stress: bool = False\n",
    ") -> str:\n",
    "    \"\"\"CTC-like decoding. First removes consecutive duplicates, then removes special tokens.\"\"\"\n",
    "    # removes consecutive duplicates\n",
    "    ids = [id_ for id_, _ in groupby(ids)]\n",
    "\n",
    "    special_token_ids = processor.tokenizer.all_special_ids + [\n",
    "        processor.tokenizer.word_delimiter_token_id\n",
    "    ]\n",
    "    # converts id to token, skipping special tokens\n",
    "    phonemes = [processor.decode(id_) for id_ in ids if id_ not in special_token_ids]\n",
    "\n",
    "    # joins phonemes\n",
    "    prediction = \" \".join(phonemes)\n",
    "\n",
    "    # whether to ignore IPA stress marks\n",
    "    if ignore_stress == True:\n",
    "        prediction = prediction.replace(\"ˈ\", \"\").replace(\"ˌ\", \"\")\n",
    "\n",
    "    return prediction\n",
    "\n",
    "checkpoint = \"bookbot/wav2vec2-ljspeech-gruut\"\n",
    "\n",
    "model = AutoModelForCTC.from_pretrained(checkpoint)\n",
    "processor = AutoProcessor.from_pretrained(checkpoint)\n",
    "sr = processor.feature_extractor.sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = []\n",
    "for tgfile in textgrid_path.glob(\"*.[Tt]ext[Gg]rid\"):\n",
    "    wavname = f\"{tgfile.stem}.wav\"\n",
    "    tg = textgrid.openTextgrid(tgfile, False)\n",
    "    entries = get_tier_entries(tg)\n",
    "    espeakify_entries(entries)\n",
    "    entries_add_audio(str(wav_path / wavname), entries)\n",
    "    print(entries)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "wavname = \"/home/joregan/hsi/audio/hsi_7_0719_222_002_inter.wav\"\n",
    "tgfile = \"/home/joregan/textgrids/hsi_7_0719_222_002_inter.TextGrid\"\n",
    "tg = textgrid.openTextgrid(tgfile, False)\n",
    "entries = get_tier_entries(tg)\n",
    "espeakify_entries(entries)\n",
    "entries_add_audio(wavname, entries)\n",
    "entry_ds = Dataset.from_list(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor(entry_ds[\"audio\"], sampling_rate=16_000, return_tensors=\"pt\", padding=True)\n",
    "with torch.no_grad():\n",
    "    logits = model(inputs[\"input_values\"]).logits\n",
    "\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "for i in range(len(entries)):\n",
    "    entries[i][\"prediction\"] = decode_phonemes(predicted_ids[i], processor, ignore_stress=True)\n",
    "\n",
    "entries"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
