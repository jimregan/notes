{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "textgrid_dir = \"/home/joregan/textgrid\"\n",
    "wav_dir = \"/home/joregan/hsi/audio/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "textgrid_path = Path(textgrid_dir)\n",
    "wav_path = Path(wav_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from praatio import textgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def noise_event(text):\n",
    "    m = re.match(\"^\\[([^\\]]+)\\]$\", text)\n",
    "    return (m is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tier_entries(textgrid, tiername=\"utterances\"):\n",
    "    entries = []\n",
    "\n",
    "    tier = textgrid.getTier(tiername)\n",
    "    for entry in tier.entries:\n",
    "        text = entry.label\n",
    "        if text.strip() == \"\":\n",
    "            continue\n",
    "        if not noise_event(text.strip()):\n",
    "            entries.append({\n",
    "                \"start\": entry.start,\n",
    "                \"end\": entry.end,\n",
    "                \"text\": entry.label\n",
    "            })\n",
    "    return entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_espeak(text):\n",
    "    phon = !echo \"{text}\" | espeak-ng -v en-us --ipa -q\n",
    "    return (\" \".join(phon)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def espeakify_entries(entries):\n",
    "    for entry in entries:\n",
    "        entry[\"espeak\"] = run_espeak(entry[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def entries_add_audio(wavfile, entries):\n",
    "    audio = AudioSegment.from_file(wavfile)\n",
    "    dtype = getattr(np, \"int{:d}\".format(audio.sample_width * 8))\n",
    "\n",
    "    for entry in entries:\n",
    "        start = int(entry[\"start\"] * 1000)\n",
    "        end = int(entry[\"end\"] * 1000)\n",
    "        selection = audio[start:end]\n",
    "        entry[\"audio\"] = {\n",
    "            \"array\": np.ndarray((int(selection.frame_count()), selection.channels), buffer=selection.raw_data, dtype=dtype),\n",
    "            \"sampling_rate\": audio.frame_rate\n",
    "        }\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joregan/miniconda3/envs/hf_new/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor, AutoModelForCTC, Wav2Vec2Processor\n",
    "import torch\n",
    "from itertools import groupby\n",
    "\n",
    "def decode_phonemes(\n",
    "    ids: torch.Tensor, processor: Wav2Vec2Processor, ignore_stress: bool = False\n",
    ") -> str:\n",
    "    \"\"\"CTC-like decoding. First removes consecutive duplicates, then removes special tokens.\"\"\"\n",
    "    # removes consecutive duplicates\n",
    "    ids = [id_ for id_, _ in groupby(ids)]\n",
    "\n",
    "    special_token_ids = processor.tokenizer.all_special_ids + [\n",
    "        processor.tokenizer.word_delimiter_token_id\n",
    "    ]\n",
    "    # converts id to token, skipping special tokens\n",
    "    phonemes = [processor.decode(id_) for id_ in ids if id_ not in special_token_ids]\n",
    "\n",
    "    # joins phonemes\n",
    "    prediction = \" \".join(phonemes)\n",
    "\n",
    "    # whether to ignore IPA stress marks\n",
    "    if ignore_stress == True:\n",
    "        prediction = prediction.replace(\"ˈ\", \"\").replace(\"ˌ\", \"\")\n",
    "\n",
    "    return prediction\n",
    "\n",
    "checkpoint = \"bookbot/wav2vec2-ljspeech-gruut\"\n",
    "\n",
    "model = AutoModelForCTC.from_pretrained(checkpoint)\n",
    "processor = AutoProcessor.from_pretrained(checkpoint)\n",
    "sr = processor.feature_extractor.sampling_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tgfile in textgrid_path.glob(\"*.[Tt]ext[Gg]rid\"):\n",
    "    wavname = f\"{tgfile.stem}.wav\"\n",
    "    tg = textgrid.openTextgrid(tgfile, False)\n",
    "    entries = get_tier_entries(tgfile)\n",
    "    espeakify_entries(entries)\n",
    "    entries_add_audio(entries)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
