{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXVeDoCDuygV"
      },
      "source": [
        "# Convert NST pronunciation lexicons to JSON\n",
        "\n",
        "> Converting the pronunciation to IPA along the way\n",
        "\n",
        "- toc: false\n",
        "- badges: true\n",
        "- branch: master\n",
        "- categories: [nst, swedish, danish, norwegian, pronunciation, icu]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on [this]({% post_url 2022-01-12-convert-nst-lexicon %})"
      ],
      "metadata": {
        "id": "fqV9Qg1_u1_V"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BciPhQ9ZuygX"
      },
      "source": [
        "> Set up field reading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gYNezo5RuygX"
      },
      "outputs": [],
      "source": [
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ePIjxejcuygX",
        "outputId": "23eb04eb-c097-4e6d-e2ed-d763d922761c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyicu\n",
            "  Downloading pyicu-2.15.3.tar.gz (267 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/267.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m266.2/267.6 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.6/267.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pyicu\n",
            "  Building wheel for pyicu (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyicu: filename=pyicu-2.15.3-cp312-cp312-linux_x86_64.whl size=2720028 sha256=b231b9f44f3d4ba70ffc531143d89b6982bb5b0cdaf66027e87635f754e73654\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/11/aa/9777ed706b79bd6fbe41492e7a8dbbf0699e91e0173f7be151\n",
            "Successfully built pyicu\n",
            "Installing collected packages: pyicu\n",
            "Successfully installed pyicu-2.15.3\n"
          ]
        }
      ],
      "source": [
        "!pip install pyicu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wmKR7IZ4uygY"
      },
      "outputs": [],
      "source": [
        "field_names = [\n",
        "    \"orthography\",\n",
        "    \"extended_pos\",\n",
        "    \"morphology\",\n",
        "    \"decomp\",\n",
        "    \"decpos\",\n",
        "    \"source\",\n",
        "    \"language_code\",\n",
        "    \"garbage\",\n",
        "    \"domain\",\n",
        "    \"abbr_acr\",\n",
        "    \"expansion\",\n",
        "    \"transliteration1\",\n",
        "    \"certainty_trans_1\",\n",
        "    \"status_trans_1\",\n",
        "    \"language_code_trans_1\",\n",
        "    \"transliteration2\",\n",
        "    \"certainty_trans_2\",\n",
        "    \"status_trans_2\",\n",
        "    \"language_code_trans_2\",\n",
        "    \"transliteration3\",\n",
        "    \"certainty_trans_3\",\n",
        "    \"status_trans_3\",\n",
        "    \"language_code_trans_3\",\n",
        "    \"transliteration4\",\n",
        "    \"certainty_trans_4\",\n",
        "    \"status_trans_4\",\n",
        "    \"language_code_trans_4\",\n",
        "    \"auto_gen_variants\",\n",
        "    \"set_id\",\n",
        "    \"set_name\",\n",
        "    \"style_status\",\n",
        "    \"inflector_role\",\n",
        "    \"lemma\",\n",
        "    \"inflection_rule\",\n",
        "    \"morph_label\",\n",
        "    \"compounder_code\",\n",
        "    \"semantic_info\",\n",
        "    \"available_field1\",\n",
        "    \"available_field2\",\n",
        "    \"available_field3\",\n",
        "    \"available_field4\",\n",
        "    \"available_field5\",\n",
        "    \"available_field6\",\n",
        "    \"available_field7\",\n",
        "    \"available_field8\",\n",
        "    \"available_field9\",\n",
        "    \"frequency\",\n",
        "    \"original_orthography\",\n",
        "    \"comment_field\",\n",
        "    \"update_info\",\n",
        "    \"unique_id\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Dbm7d8MuygY"
      },
      "source": [
        "> Get data\n",
        "\n",
        "1.   [Swedish](https://www.nb.no/sprakbanken/en/resource-catalogue/oai-nb-no-sbr-22/)\n",
        "2.   [Danish](https://www.nb.no/sprakbanken/en/resource-catalogue/oai-nb-no-sbr-26/)\n",
        "3.   [Norwegian](https://www.nb.no/sprakbanken/en/resource-catalogue/oai-nb-no-sbr-23/) (Bokmål)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MaG-oqcWuygY",
        "outputId": "05bf36c8-d9dc-45cf-928f-473a594b206b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-24 15:07:18--  https://www.nb.no/sbfil/leksikalske_databaser/leksikon/sv.leksikon.tar.gz\n",
            "Resolving www.nb.no (www.nb.no)... 158.39.129.53, 2001:700:f01:1071::53\n",
            "Connecting to www.nb.no (www.nb.no)|158.39.129.53|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 22041470 (21M) [application/octet-stream]\n",
            "Saving to: ‘/tmp/sv.leksikon.tar.gz’\n",
            "\n",
            "/tmp/sv.leksikon.ta 100%[===================>]  21.02M  8.60MB/s    in 2.4s    \n",
            "\n",
            "2025-10-24 15:07:22 (8.60 MB/s) - ‘/tmp/sv.leksikon.tar.gz’ saved [22041470/22041470]\n",
            "\n",
            "--2025-10-24 15:07:22--  https://www.nb.no/sbfil/leksikalske_databaser/leksikon/da_leksikon.tar.gz\n",
            "Resolving www.nb.no (www.nb.no)... 158.39.129.53, 2001:700:f01:1071::53\n",
            "Connecting to www.nb.no (www.nb.no)|158.39.129.53|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5731447 (5.5M) [application/octet-stream]\n",
            "Saving to: ‘/tmp/da_leksikon.tar.gz’\n",
            "\n",
            "/tmp/da_leksikon.ta 100%[===================>]   5.47M  3.91MB/s    in 1.4s    \n",
            "\n",
            "2025-10-24 15:07:24 (3.91 MB/s) - ‘/tmp/da_leksikon.tar.gz’ saved [5731447/5731447]\n",
            "\n",
            "--2025-10-24 15:07:25--  https://www.nb.no/sbfil/leksikalske_databaser/leksikon/no.leksikon.tar.gz\n",
            "Resolving www.nb.no (www.nb.no)... 158.39.129.53, 2001:700:f01:1071::53\n",
            "Connecting to www.nb.no (www.nb.no)|158.39.129.53|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 24214255 (23M) [application/octet-stream]\n",
            "Saving to: ‘/tmp/no.leksikon.tar.gz’\n",
            "\n",
            "/tmp/no.leksikon.ta 100%[===================>]  23.09M  7.58MB/s    in 3.0s    \n",
            "\n",
            "2025-10-24 15:07:28 (7.58 MB/s) - ‘/tmp/no.leksikon.tar.gz’ saved [24214255/24214255]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.nb.no/sbfil/leksikalske_databaser/leksikon/sv.leksikon.tar.gz -O /tmp/sv.leksikon.tar.gz\n",
        "!wget https://www.nb.no/sbfil/leksikalske_databaser/leksikon/da_leksikon.tar.gz -O /tmp/da_leksikon.tar.gz\n",
        "!wget https://www.nb.no/sbfil/leksikalske_databaser/leksikon/no.leksikon.tar.gz -O /tmp/no.leksikon.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Zend2MUMuygZ"
      },
      "outputs": [],
      "source": [
        "import tarfile\n",
        "\n",
        "data = {}\n",
        "\n",
        "with tarfile.open(\"/tmp/sv.leksikon.tar.gz\") as tar:\n",
        "    f = tar.extractfile(\"NST svensk leksikon/swe030224NST.pron/swe030224NST.pron\")\n",
        "    prondata = f.read()\n",
        "    data[\"sv\"] = prondata.decode('latin1')\n",
        "with tarfile.open(\"/tmp/no.leksikon.tar.gz\") as tar:\n",
        "    f = tar.extractfile(\"NSTs norske leksikon/nor030224NST.pron/nor030224NST.pron\")\n",
        "    prondata = f.read()\n",
        "    data[\"no\"] = prondata.decode('latin1')\n",
        "with tarfile.open(\"/tmp/da_leksikon.tar.gz\") as tar:\n",
        "    f = tar.extractfile(\"dan030224NST.pron/dan030224NST.pron\")\n",
        "    prondata = f.read()\n",
        "    data[\"da\"] = prondata.decode('latin1')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dH5Cj74cuygZ"
      },
      "source": [
        "> Set up transliterator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "lvw_4IaWuygZ",
        "outputId": "f93bbdd8-b771-4e82-c3b1-ce3ee9b39032",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:2: SyntaxWarning: invalid escape sequence '\\`'\n",
            "<>:2: SyntaxWarning: invalid escape sequence '\\`'\n",
            "/tmp/ipython-input-4250576132.py:2: SyntaxWarning: invalid escape sequence '\\`'\n",
            "  n\\` → ɳ ;\n"
          ]
        }
      ],
      "source": [
        "TRANSLIT_SV = \"\"\"\n",
        "n\\` → ɳ ;\n",
        "s\\` → ʂ ;\n",
        "l\\` → ɭ ;\n",
        "t\\` → ʈ ;\n",
        "d\\` → ɖ ;\n",
        "A → ɑ ;\n",
        "O → ɔ ;\n",
        "I → ɪ ;\n",
        "E \\* U → e \\u2040 ʊ ;\n",
        "E → ɛ ;\n",
        "U → ʊ ;\n",
        "Y → ʏ ;\n",
        "2 → ø ;\n",
        "9 → ø ;\n",
        "u 0 → ɵ ;\n",
        "N → ŋ ;\n",
        "'\"\"' → ² ;\n",
        "'\"' → ˈ ;\n",
        "\\% → ˌ ;\n",
        "\\: → ː ;\n",
        "\\$ → \\. ;\n",
        "g → ɡ ;\n",
        "s \\\\\\' → ɕ ;\n",
        "x \\\\\\\\ → ɧ ;\n",
        "\\* → \\u2040 ;\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NST_TRANSLIT = r\"\"\"\n",
        "::XSampa-IPA;\n",
        "\n",
        "\\$ → \\. ;\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "KKIFZY8txrf0"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5iQnIzjKuyga"
      },
      "outputs": [],
      "source": [
        "import icu\n",
        "def transliterator_from_rules(name, rules):\n",
        "    fromrules = icu.Transliterator.createFromRules(name, rules)\n",
        "    icu.Transliterator.registerInstance(fromrules)\n",
        "    return icu.Transliterator.createInstance(name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "swelex_trans = transliterator_from_rules(\"swelex_trans\", TRANSLIT_SV)"
      ],
      "metadata": {
        "id": "P2kHownoy2_O"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "6CTbJcWluyga"
      },
      "outputs": [],
      "source": [
        "nstlex_trans = transliterator_from_rules(\"nst_trans\", NST_TRANSLIT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "K7h8JMVPuyga"
      },
      "outputs": [],
      "source": [
        "assert swelex_trans.transliterate('\"\"bA:n`s`$%ma$man') == \"²bɑːɳʂ.ˌma.man\"\n",
        "assert swelex_trans.transliterate('\"b9r$mIN$ham') == \"ˈbør.mɪŋ.ham\"\n",
        "assert swelex_trans.transliterate('\"bI$rU') == \"ˈbɪ.rʊ\"\n",
        "assert swelex_trans.transliterate('\"\"bIsp$%go:$d`en') == \"²bɪsp.ˌɡoː.ɖen\"\n",
        "\n",
        "assert swelex_trans.transliterate('\"x\\\\A:l') == \"ˈɧɑːl\"\n",
        "assert swelex_trans.transliterate(\"\\\"s'u:$lens\") == \"ˈɕuː.lens\"\n",
        "assert swelex_trans.transliterate('a$\"lE*U$te$n`a') == 'a.ˈle⁀ʊ.te.ɳa'\n",
        "assert swelex_trans.transliterate('\"fu0l') == 'ˈfɵl'"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oV5uab9GzkRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "nQShHf4zuyga"
      },
      "outputs": [],
      "source": [
        "def collapse_available_fields(data):\n",
        "    output = []\n",
        "    for i in range(1, 10):\n",
        "        if data[f\"available_field{i}\"] != \"\":\n",
        "            output.append(data[f\"available_field{i}\"])\n",
        "        del data[f\"available_field{i}\"]\n",
        "    data[\"available_fields\"] = output\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "5br0w2pnuyga"
      },
      "outputs": [],
      "source": [
        "def collapse_transliterations(data, transliterator):\n",
        "    output = []\n",
        "    for i in range(1, 5):\n",
        "        if data[f\"transliteration{i}\"] != \"\":\n",
        "            tmp = {}\n",
        "            tmp[\"transliteration\"] = data[f\"transliteration{i}\"]\n",
        "            tmp[\"ipa\"] = transliterator.transliterate(data[f\"transliteration{i}\"])\n",
        "            tmp[\"certainty\"] = data[f\"certainty_trans_{i}\"]\n",
        "            tmp[\"status\"] = data[f\"status_trans_{i}\"]\n",
        "            tmp[\"language_code\"] = data[f\"language_code_trans_{i}\"]\n",
        "            output.append(tmp)\n",
        "        del data[f\"transliteration{i}\"]\n",
        "        del data[f\"certainty_trans_{i}\"]\n",
        "        del data[f\"status_trans_{i}\"]\n",
        "        del data[f\"language_code_trans_{i}\"]\n",
        "    data[\"transliterations\"] = output\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "4siNZIpkuyga"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import io\n",
        "with open(\"svlex.json\", \"w\") as outf:\n",
        "    swelexf = io.StringIO(data[\"sv\"])\n",
        "    swelex = csv.DictReader(swelexf, delimiter=';', fieldnames=field_names, quoting=csv.QUOTE_NONE)\n",
        "    for row in swelex:\n",
        "        row[\"decomp\"] = [f for f in row[\"decomp\"].split(\"+\") if f != \"\"]\n",
        "        row = collapse_available_fields(row)\n",
        "        row = collapse_transliterations(row, swelex_trans)\n",
        "        jsonstr = json.dumps(row)\n",
        "        outf.write(jsonstr + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for lang in [\"da\", \"no\"]:\n",
        "    with open(f\"{lang}lex.json\", \"w\") as outf:\n",
        "        swelexf = io.StringIO(data[lang])\n",
        "        swelex = csv.DictReader(swelexf, delimiter=';', fieldnames=field_names, quoting=csv.QUOTE_NONE)\n",
        "        for row in swelex:\n",
        "            row[\"decomp\"] = [f for f in row[\"decomp\"].split(\"+\") if f != \"\"]\n",
        "            row = collapse_available_fields(row)\n",
        "            row = collapse_transliterations(row, nstlex_trans)\n",
        "            jsonstr = json.dumps(row)\n",
        "            outf.write(jsonstr + \"\\n\")"
      ],
      "metadata": {
        "id": "n633RJLt0G50",
        "outputId": "66031056-f2fd-4bcb-a2ed-f92388ab4065",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Error",
          "evalue": "new-line character seen in unquoted field - do you need to open the file with newline=''?",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2574853759.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mswelexf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mswelex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mswelexf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfieldnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfield_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquoting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQUOTE_NONE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mswelex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"decomp\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"decomp\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"+\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollapse_available_fields\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/csv.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;31m# Used only for its side effect.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfieldnames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline_num\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mError\u001b[0m: new-line character seen in unquoted field - do you need to open the file with newline=''?"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ctcseg",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "04f1aebeda7ca92f6170d2806fa3f3c0cbb14da723fd908a9af630117dfe1004"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}