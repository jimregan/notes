Job started on deepspeech at Thu Aug  7 14:37:25 CEST 2025
Using GPU(s): 0
local/chain/run_tdnn.sh --train-set train --gmm tri4a
local/chain/run_ivector_common.sh: computing a subset of data to train the diagonal UBM.
utils/data/subset_data_dir.sh: reducing #utt from 306257 to 76564
local/chain/run_ivector_common.sh: computing a PCA transform from the data.
steps/online/nnet2/get_pca_transform.sh --cmd run.pl --splice-opts --left-context=3 --right-context=3 --max-utts 10000 --subsample 2 exp/chain/diag_ubm/train_subset exp/chain/pca_transform
Done estimating PCA transform in exp/chain/pca_transform
local/chain/run_ivector_common.sh: training the diagonal UBM.
steps/online/nnet2/train_diag_ubm.sh --cmd run.pl --nj 10 --num-frames 700000 --num-threads 8 exp/chain/diag_ubm/train_subset 512 exp/chain/pca_transform exp/chain/diag_ubm
steps/online/nnet2/train_diag_ubm.sh: Directory exp/chain/diag_ubm already exists. Backing up diagonal UBM in exp/chain/diag_ubm/backup.YdW
steps/online/nnet2/train_diag_ubm.sh: initializing model from E-M in memory, 
steps/online/nnet2/train_diag_ubm.sh: starting from 256 Gaussians, reaching 512;
steps/online/nnet2/train_diag_ubm.sh: for 20 iterations, using at most 700000 frames of data
Getting Gaussian-selection info
steps/online/nnet2/train_diag_ubm.sh: will train for 4 iterations, in parallel over
steps/online/nnet2/train_diag_ubm.sh: 10 machines, parallelized with 'run.pl'
steps/online/nnet2/train_diag_ubm.sh: Training pass 0
steps/online/nnet2/train_diag_ubm.sh: Training pass 1
steps/online/nnet2/train_diag_ubm.sh: Training pass 2
