{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":270049783,"sourceType":"kernelVersion"}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!apt-get -qq update\n!apt-get -qq install -y hunspell git libhunspell-dev","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T22:40:08.658153Z","iopub.execute_input":"2025-10-22T22:40:08.658479Z","iopub.status.idle":"2025-10-22T22:40:18.215454Z","shell.execute_reply.started":"2025-10-22T22:40:08.658448Z","shell.execute_reply":"2025-10-22T22:40:18.214167Z"}},"outputs":[{"name":"stdout","text":"W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\nSelecting previously unselected package libhunspell-dev:amd64.\n(Reading database ... 128735 files and directories currently installed.)\nPreparing to unpack .../libhunspell-dev_1.7.0-4build1_amd64.deb ...\nUnpacking libhunspell-dev:amd64 (1.7.0-4build1) ...\nSetting up libhunspell-dev:amd64 (1.7.0-4build1) ...\nProcessing triggers for man-db (2.10.2-1) ...\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"!pip install hunspell","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T22:40:28.460080Z","iopub.execute_input":"2025-10-22T22:40:28.460360Z","iopub.status.idle":"2025-10-22T22:40:34.734239Z","shell.execute_reply.started":"2025-10-22T22:40:28.460339Z","shell.execute_reply":"2025-10-22T22:40:34.732667Z"}},"outputs":[{"name":"stdout","text":"Collecting hunspell\n  Using cached hunspell-0.5.5.tar.gz (34 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nBuilding wheels for collected packages: hunspell\n  Building wheel for hunspell (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for hunspell: filename=hunspell-0.5.5-cp311-cp311-linux_x86_64.whl size=66312 sha256=0b5000b26d6eb6e89d8cdd3e49a07e82d1beb9073da82a0aa180dad86c80c24c\n  Stored in directory: /root/.cache/pip/wheels/0b/41/b3/14ebfe8dfb3116e3f1ab55ff0db766d1ef033b6842ccc67e24\nSuccessfully built hunspell\nInstalling collected packages: hunspell\nSuccessfully installed hunspell-0.5.5\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"!echo $PWD/dictionaries/dictionaries","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T22:37:25.069802Z","iopub.execute_input":"2025-10-22T22:37:25.070125Z","iopub.status.idle":"2025-10-22T22:37:25.193273Z","shell.execute_reply.started":"2025-10-22T22:37:25.070099Z","shell.execute_reply":"2025-10-22T22:37:25.192455Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/dictionaries/dictionaries\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"!git clone https://github.com/wooorm/dictionaries\n!pwd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T22:41:41.478172Z","iopub.execute_input":"2025-10-22T22:41:41.478471Z","iopub.status.idle":"2025-10-22T22:41:41.726056Z","shell.execute_reply.started":"2025-10-22T22:41:41.478447Z","shell.execute_reply":"2025-10-22T22:41:41.725042Z"}},"outputs":[{"name":"stdout","text":"fatal: destination path 'dictionaries' already exists and is not an empty directory.\n/kaggle/working\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"import os, re, hunspell, pandas as pd\nfrom collections import defaultdict\n\nFILE_DIR = \"/kaggle/input/split-braxen-by-language\"\nDICT_ROOT = \"/kaggle/working/dictionaries/dictionaries\"\nOUT_TSV = \"hunspell_results.tsv\"\n\nMIN_ENTRIES = 1000\nSKIP_CODES = {\"afr\",\"asi\",\"aus\",\"sla\",\"mix\",\"fisa\"}\n\nCODE2DICT = {\n    \"swe\": [\"sv\"],\n    \"nor\": [\"nb\",\"nn\"],\n    \"dan\": [\"da\"],\n    \"isl\": [\"is\"],\n    \"fin\": [\"fi\"],\n    \"est\": [\"et\"],\n    \"lat\": [\"la\"],\n    \"lav\": [\"lv\"],\n    \"lit\": [\"lt\"],\n    \"pol\": [\"pl\"],\n    \"cze\": [\"cs\"],\n    \"slk\": [\"sk\"],\n    \"slv\": [\"sl\"],\n    \"hrv\": [\"hr\"],\n    \"srp\": [\"sr-Latn\"],\n    \"bos\": [\"bs\"],\n    \"mkd\": [\"mk\"],\n    \"bul\": [\"bg\"],\n    \"ukr\": [\"uk\"],\n    \"rus\": [\"ru\"],\n    \"deu\": [\"de\"],\n    \"nld\": [\"nl\"],\n    \"eng\": [\"en\",\"en-GB\",\"en-CA\"],\n    \"fre\": [\"fr\"],\n    \"ita\": [\"it\"],\n    \"spa\": [\"es\"],\n    \"por\": [\"pt\",\"pt-PT\"],\n    \"rom\": [\"ro\"],\n    \"hun\": [\"hu\"],\n    \"tur\": [\"tr\"],\n    \"gre\": [\"el\"],\n}\n\nWORD_RE = re.compile(r\"[^\\W\\d_][\\w’'\\-\\u2011\\u2013\\u2014]*\", re.UNICODE)\n\ndef tokenize(text):\n    return WORD_RE.findall(text)\n\ndef read_text(path):\n    with open(path, \"rb\") as f:\n        data = f.read()\n    try:\n        return data.decode(\"utf-8\")\n    except UnicodeDecodeError:\n        return data.decode(\"utf-8\", errors=\"ignore\")\n\ndef file_code(path):\n    base = os.path.basename(path)\n    return base[len(\"braxen-\"):-4]\n\ndef load_hunspell(dict_codes):\n    aff, dic = None, None\n    for code in dict_codes:\n        base = os.path.join(DICT_ROOT, code, code)\n        if os.path.exists(base + \".aff\") and os.path.exists(base + \".dic\"):\n            return hunspell.HunSpell(base + \".dic\", base + \".aff\")\n    return None\n\nfiles = [os.path.join(FILE_DIR, f) for f in os.listdir(FILE_DIR)\n         if f.startswith(\"braxen-\") and f.endswith(\".txt\")]\n\nrows = []\nfor path in files:\n    code = file_code(path)\n    if code in SKIP_CODES:\n        continue\n    words = set(tokenize(read_text(path)))\n    if len(words) < MIN_ENTRIES:\n        continue\n\n    dict_codes = CODE2DICT.get(code)\n    if not dict_codes:\n        print(f\"Skipping {code} — no dictionary mapping.\")\n        continue\n\n    hobj = load_hunspell(dict_codes)\n    if not hobj:\n        print(f\"Skipping {code} — dictionary not found in {DICT_ROOT}.\")\n        continue\n\n    print(f\"Checking {code} ({len(words)} words) ...\")\n\n    for w in sorted(words):\n        if not w:\n            continue\n        if all(ord(ch) < 128 for ch in w) and len(w) < 2:\n            continue\n        # ø/ö quirk normalization\n        wcheck = w.replace(\"ö\",\"ø\").replace(\"Ö\",\"Ø\") if code in {\"nor\",\"dan\"} else w\n        ok = hobj.spell(wcheck)\n        if ok:\n            rows.append((code, w, \"OK\", \"\"))\n        else:\n            sugs = \", \".join(hobj.suggest(wcheck))\n            rows.append((code, w, \"MISS\", sugs))\n\ndf = pd.DataFrame(rows, columns=[\"file_code\",\"word\",\"status\",\"suggestions\"])\ndf.to_csv(OUT_TSV, sep=\"\\t\", index=False, encoding=\"utf-8\")\n\nprint(f\"Wrote {OUT_TSV} with {len(df)} rows\")\ndf.head(30)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-22T22:48:14.803811Z","iopub.execute_input":"2025-10-22T22:48:14.804441Z","iopub.status.idle":"2025-10-22T22:48:14.876813Z","shell.execute_reply.started":"2025-10-22T22:48:14.804412Z","shell.execute_reply":"2025-10-22T22:48:14.875620Z"}},"outputs":[{"name":"stdout","text":"Skipping ara — no dictionary mapping.\nERROR: no dictionary found. Tried:\n   /kaggle/working/dictionaries/dictionaries/fr/fr.aff — MISSING\n   /kaggle/working/dictionaries/dictionaries/fr/fr.dic — MISSING\nChecking fre (5533 words) ...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_41/2697242004.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;31m# ø/ö quirk normalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mwcheck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ö\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"ø\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ö\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Ø\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"nor\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"dan\"\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwcheck\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mok\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mrows\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"OK\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'spell'"],"ename":"AttributeError","evalue":"'tuple' object has no attribute 'spell'","output_type":"error"}],"execution_count":27},{"cell_type":"code","source":"# 1) set the repo root correctly (this is your actual path)\nDICT_ROOT = \"/kaggle/working/dictionaries/dictionaries\"\n\n# 2) include lat->la in the mapping (and any other missing ones)\nCODE2DICT = {\n    \"lat\": [\"la\"],             # Latin -> la\n    \"swe\": [\"sv\"],\n    \"nor\": [\"nb\",\"nn\"],\n    \"dan\": [\"da\"],\n    \"isl\": [\"is\"],\n    \"fin\": [\"fi\"],\n    \"est\": [\"et\"],\n    \"lav\": [\"lv\"],\n    \"lit\": [\"lt\"],\n    \"pol\": [\"pl\"],\n    \"cze\": [\"cs\"],\n    \"slk\": [\"sk\"],\n    \"slv\": [\"sl\"],\n    \"hrv\": [\"hr\"],\n    \"srp\": [\"sr-Latn\"],\n    \"bos\": [\"bs\"],\n    \"mkd\": [\"mk\"],\n    \"bul\": [\"bg\"],\n    \"ukr\": [\"uk\"],\n    \"rus\": [\"ru\"],\n    \"deu\": [\"de\"],\n    \"nld\": [\"nl\"], \"dut\": [\"nl\"],\n    \"eng\": [\"en\",\"en-GB\",\"en-CA\",\"en-AU\",\"en-ZA\"],\n    \"fre\": [\"fr\"],\n    \"ita\": [\"it\"],\n    \"spa\": [\"es\",\"es-MX\"],\n    \"por\": [\"pt\",\"pt-PT\"],\n    \"rom\": [\"ro\"],\n    \"hun\": [\"hu\"],\n    \"tur\": [\"tr\"],\n    \"gre\": [\"el\"],\n}\n\nimport os, hunspell\n\ndef _dict_paths_for(code):\n    \"\"\"Return list of (aff, dic) pairs to try for a given wooorm code.\"\"\"\n    base = os.path.join(DICT_ROOT, code, code)\n    return [(base + \".aff\", base + \".dic\")]\n\ndef load_hunspell(dict_codes):\n    \"\"\"Try each candidate code; return first usable HunSpell object + which code was used.\"\"\"\n    for code in dict_codes:\n        for aff, dic in _dict_paths_for(code):\n            if os.path.exists(aff) and os.path.exists(dic):\n                return hunspell.HunSpell(dic, aff), code\n    # helpful debug: show which paths we tried\n    tried = [p for c in dict_codes for p in [os.path.join(DICT_ROOT, c, c + \".aff\"),\n                                             os.path.join(DICT_ROOT, c, c + \".dic\")]]\n    print(\"ERROR: no dictionary found. Tried:\")\n    for t in tried:\n        print(\"  \", t, \"—\", \"OK\" if os.path.exists(t) else \"MISSING\")\n    return None, None\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T22:42:35.079108Z","iopub.execute_input":"2025-10-22T22:42:35.079674Z","iopub.status.idle":"2025-10-22T22:42:35.207686Z","shell.execute_reply.started":"2025-10-22T22:42:35.079646Z","shell.execute_reply":"2025-10-22T22:42:35.206197Z"}},"outputs":[{"name":"stdout","text":"dictionaries  hunspell_results.tsv\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"!cat hunspell_results.tsv","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-22T22:42:48.923387Z","iopub.execute_input":"2025-10-22T22:42:48.924201Z","iopub.status.idle":"2025-10-22T22:42:49.051138Z","shell.execute_reply.started":"2025-10-22T22:42:48.924166Z","shell.execute_reply":"2025-10-22T22:42:49.050130Z"}},"outputs":[{"name":"stdout","text":"file_code\tword\tstatus\tsuggestions\n","output_type":"stream"}],"execution_count":24}]}