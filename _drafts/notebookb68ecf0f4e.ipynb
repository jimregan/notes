{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a20f95e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T16:06:26.929315Z",
     "iopub.status.busy": "2025-11-08T16:06:26.928920Z",
     "iopub.status.idle": "2025-11-08T16:06:51.071906Z",
     "shell.execute_reply": "2025-11-08T16:06:51.069965Z"
    },
    "papermill": {
     "duration": 24.151399,
     "end_time": "2025-11-08T16:06:51.074679",
     "exception": false,
     "start_time": "2025-11-08T16:06:26.923280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\r\n",
      "Preconfiguring packages ...\r\n",
      "Selecting previously unselected package libtext-iconv-perl.\r\n",
      "(Reading database ... 128639 files and directories currently installed.)\r\n",
      "Preparing to unpack .../0-libtext-iconv-perl_1.7-7build3_amd64.deb ...\r\n",
      "Unpacking libtext-iconv-perl (1.7-7build3) ...\r\n",
      "Selecting previously unselected package dictionaries-common.\r\n",
      "Preparing to unpack .../1-dictionaries-common_1.28.14_all.deb ...\r\n",
      "Adding 'diversion of /usr/share/dict/words to /usr/share/dict/words.pre-dictionaries-common by dictionaries-common'\r\n",
      "Unpacking dictionaries-common (1.28.14) ...\r\n",
      "Selecting previously unselected package hunspell-en-us.\r\n",
      "Preparing to unpack .../2-hunspell-en-us_1%3a2020.12.07-2_all.deb ...\r\n",
      "Unpacking hunspell-en-us (1:2020.12.07-2) ...\r\n",
      "Selecting previously unselected package libhunspell-1.7-0:amd64.\r\n",
      "Preparing to unpack .../3-libhunspell-1.7-0_1.7.0-4build1_amd64.deb ...\r\n",
      "Unpacking libhunspell-1.7-0:amd64 (1.7.0-4build1) ...\r\n",
      "Selecting previously unselected package hunspell.\r\n",
      "Preparing to unpack .../4-hunspell_1.7.0-4build1_amd64.deb ...\r\n",
      "Unpacking hunspell (1.7.0-4build1) ...\r\n",
      "Selecting previously unselected package libhunspell-dev:amd64.\r\n",
      "Preparing to unpack .../5-libhunspell-dev_1.7.0-4build1_amd64.deb ...\r\n",
      "Unpacking libhunspell-dev:amd64 (1.7.0-4build1) ...\r\n",
      "Setting up libtext-iconv-perl (1.7-7build3) ...\r\n",
      "Setting up dictionaries-common (1.28.14) ...\r\n",
      "Setting up hunspell-en-us (1:2020.12.07-2) ...\r\n",
      "Setting up libhunspell-1.7-0:amd64 (1.7.0-4build1) ...\r\n",
      "Setting up libhunspell-dev:amd64 (1.7.0-4build1) ...\r\n",
      "Setting up hunspell (1.7.0-4build1) ...\r\n",
      "Processing triggers for man-db (2.10.2-1) ...\r\n",
      "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\r\n",
      "\r\n",
      "Processing triggers for dictionaries-common (1.28.14) ...\r\n"
     ]
    }
   ],
   "source": [
    "!apt-get -qq update\n",
    "!apt-get -qq install -y hunspell git libhunspell-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e077a20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T16:06:51.087199Z",
     "iopub.status.busy": "2025-11-08T16:06:51.086471Z",
     "iopub.status.idle": "2025-11-08T16:07:02.957211Z",
     "shell.execute_reply": "2025-11-08T16:07:02.955632Z"
    },
    "papermill": {
     "duration": 11.880108,
     "end_time": "2025-11-08T16:07:02.960075",
     "exception": false,
     "start_time": "2025-11-08T16:06:51.079967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hunspell\r\n",
      "  Downloading hunspell-0.5.5.tar.gz (34 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Building wheels for collected packages: hunspell\r\n",
      "  Building wheel for hunspell (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for hunspell: filename=hunspell-0.5.5-cp311-cp311-linux_x86_64.whl size=66309 sha256=b3033f2b5e344b091a8a0e70f30582a9b62399dd9f19e1b0ab4d170f0075c8ce\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/0b/41/b3/14ebfe8dfb3116e3f1ab55ff0db766d1ef033b6842ccc67e24\r\n",
      "Successfully built hunspell\r\n",
      "Installing collected packages: hunspell\r\n",
      "Successfully installed hunspell-0.5.5\r\n"
     ]
    }
   ],
   "source": [
    "!pip install hunspell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5e4691a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T16:07:02.971329Z",
     "iopub.status.busy": "2025-11-08T16:07:02.970865Z",
     "iopub.status.idle": "2025-11-08T16:07:03.096142Z",
     "shell.execute_reply": "2025-11-08T16:07:03.094404Z"
    },
    "papermill": {
     "duration": 0.133762,
     "end_time": "2025-11-08T16:07:03.098370",
     "exception": false,
     "start_time": "2025-11-08T16:07:02.964608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/dictionaries/dictionaries\r\n"
     ]
    }
   ],
   "source": [
    "!echo $PWD/dictionaries/dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "534684b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-08T16:07:03.109579Z",
     "iopub.status.busy": "2025-11-08T16:07:03.109122Z",
     "iopub.status.idle": "2025-11-08T16:07:14.742629Z",
     "shell.execute_reply": "2025-11-08T16:07:14.741344Z"
    },
    "papermill": {
     "duration": 11.641737,
     "end_time": "2025-11-08T16:07:14.744836",
     "exception": false,
     "start_time": "2025-11-08T16:07:03.103099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'dictionaries'...\r\n",
      "remote: Enumerating objects: 11042, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (1506/1506), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (213/213), done.\u001b[K\r\n",
      "remote: Total 11042 (delta 1318), reused 1303 (delta 1293), pack-reused 9536 (from 1)\u001b[K\r\n",
      "Receiving objects: 100% (11042/11042), 101.83 MiB | 18.31 MiB/s, done.\r\n",
      "Resolving deltas: 100% (9492/9492), done.\r\n",
      "Updating files: 100% (570/570), done.\r\n",
      "/kaggle/working\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/wooorm/dictionaries\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6deb0d1f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-08T16:07:14.765460Z",
     "iopub.status.busy": "2025-11-08T16:07:14.764595Z",
     "iopub.status.idle": "2025-11-09T02:09:05.583736Z",
     "shell.execute_reply": "2025-11-09T02:09:05.581546Z"
    },
    "papermill": {
     "duration": 36110.833086,
     "end_time": "2025-11-09T02:09:05.587990",
     "exception": false,
     "start_time": "2025-11-08T16:07:14.754904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cze: 371 tokens via cs\n",
      "dan: 1904 tokens via da\n",
      "eng: 19700 tokens via en\n",
      "skip fin: dict not found for ['fi']\n",
      "fre: 5465 tokens via fr\n",
      "gre: 817 tokens via el\n",
      "hun: 361 tokens via hu\n",
      "ita: 3051 tokens via it\n",
      "lat: 3753 tokens via la\n",
      "nob: 3763 tokens via nb\n",
      "pol: 707 tokens via pl\n",
      "por: 440 tokens via pt\n",
      "rus: 1321 tokens via ru\n",
      "spa: 2405 tokens via es\n",
      "swe: 707415 tokens via sv\n",
      "tur: 762 tokens via tr\n",
      "ukr: 106 tokens via uk\n",
      "Wrote hunspell_results.tsv with 752,322 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_code</th>\n",
       "      <th>word</th>\n",
       "      <th>status</th>\n",
       "      <th>suggestions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cze</td>\n",
       "      <td>Adamkova</td>\n",
       "      <td>OK</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cze</td>\n",
       "      <td>Allertova</td>\n",
       "      <td>MISS</td>\n",
       "      <td>Albertova, Gallertová, Albertov, Tolerovat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cze</td>\n",
       "      <td>Babiš</td>\n",
       "      <td>OK</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cze</td>\n",
       "      <td>Balazova</td>\n",
       "      <td>MISS</td>\n",
       "      <td>Balasova, Balažova, Balažová, Balážova, Balážo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cze</td>\n",
       "      <td>Banik</td>\n",
       "      <td>OK</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cze</td>\n",
       "      <td>Banska</td>\n",
       "      <td>MISS</td>\n",
       "      <td>Bánská, Banka, Baska, Blanska, Banika, Baníka,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cze</td>\n",
       "      <td>Baranka</td>\n",
       "      <td>OK</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cze</td>\n",
       "      <td>Bartecko</td>\n",
       "      <td>MISS</td>\n",
       "      <td>Bartečko, Barteckou, Bartesko, Bartecký, Barte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cze</td>\n",
       "      <td>Bartok</td>\n",
       "      <td>OK</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cze</td>\n",
       "      <td>Bartosak</td>\n",
       "      <td>MISS</td>\n",
       "      <td>Bartošák, Barto sak, Barto-sak, Bartok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cze</td>\n",
       "      <td>Batovska</td>\n",
       "      <td>MISS</td>\n",
       "      <td>Bátovská, Bítovska, Baťovská</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cze</td>\n",
       "      <td>Bejlek</td>\n",
       "      <td>OK</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cze</td>\n",
       "      <td>Benice</td>\n",
       "      <td>OK</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cze</td>\n",
       "      <td>Bezpecnostni</td>\n",
       "      <td>MISS</td>\n",
       "      <td>Bezpečnostní</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cze</td>\n",
       "      <td>Bittová</td>\n",
       "      <td>OK</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cze</td>\n",
       "      <td>Blazíková</td>\n",
       "      <td>MISS</td>\n",
       "      <td>Blažíkova, Blažíková, Bazíková, Blaníková, Bla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cze</td>\n",
       "      <td>Boleslav</td>\n",
       "      <td>OK</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cze</td>\n",
       "      <td>Boril</td>\n",
       "      <td>MISS</td>\n",
       "      <td>Bořil, Borli, Borik, Borl, Briol, Borel, Bortl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cze</td>\n",
       "      <td>Borivoj</td>\n",
       "      <td>MISS</td>\n",
       "      <td>Bořivoj, Borisov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cze</td>\n",
       "      <td>Bouzkova</td>\n",
       "      <td>OK</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   file_code          word status  \\\n",
       "0        cze      Adamkova     OK   \n",
       "1        cze     Allertova   MISS   \n",
       "2        cze         Babiš     OK   \n",
       "3        cze      Balazova   MISS   \n",
       "4        cze         Banik     OK   \n",
       "5        cze        Banska   MISS   \n",
       "6        cze       Baranka     OK   \n",
       "7        cze      Bartecko   MISS   \n",
       "8        cze        Bartok     OK   \n",
       "9        cze      Bartosak   MISS   \n",
       "10       cze      Batovska   MISS   \n",
       "11       cze        Bejlek     OK   \n",
       "12       cze        Benice     OK   \n",
       "13       cze  Bezpecnostni   MISS   \n",
       "14       cze       Bittová     OK   \n",
       "15       cze     Blazíková   MISS   \n",
       "16       cze      Boleslav     OK   \n",
       "17       cze         Boril   MISS   \n",
       "18       cze       Borivoj   MISS   \n",
       "19       cze      Bouzkova     OK   \n",
       "\n",
       "                                          suggestions  \n",
       "0                                                      \n",
       "1          Albertova, Gallertová, Albertov, Tolerovat  \n",
       "2                                                      \n",
       "3   Balasova, Balažova, Balažová, Balážova, Balážo...  \n",
       "4                                                      \n",
       "5   Bánská, Banka, Baska, Blanska, Banika, Baníka,...  \n",
       "6                                                      \n",
       "7   Bartečko, Barteckou, Bartesko, Bartecký, Barte...  \n",
       "8                                                      \n",
       "9              Bartošák, Barto sak, Barto-sak, Bartok  \n",
       "10                       Bátovská, Bítovska, Baťovská  \n",
       "11                                                     \n",
       "12                                                     \n",
       "13                                       Bezpečnostní  \n",
       "14                                                     \n",
       "15  Blažíkova, Blažíková, Bazíková, Blaníková, Bla...  \n",
       "16                                                     \n",
       "17  Bořil, Borli, Borik, Borl, Briol, Borel, Bortl...  \n",
       "18                                   Bořivoj, Borisov  \n",
       "19                                                     "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, re, glob, pandas as pd, hunspell\n",
    "\n",
    "FILE_DIR = \"/kaggle/input/split-braxen-by-language\"\n",
    "DICT_ROOT = \"/kaggle/working/dictionaries/dictionaries\"  # as you showed\n",
    "OUT_TSV = \"hunspell_results.tsv\"\n",
    "MIN_ENTRIES = 100\n",
    "SKIP_CODES = {\"afr\",\"asi\",\"aus\",\"sla\",\"mix\",\"fisa\"}\n",
    "\n",
    "# find index.aff/index.dic pairs under your DICT_ROOT\n",
    "pairs = {}\n",
    "for aff in glob.glob(os.path.join(DICT_ROOT, \"*\", \"index.aff\")):\n",
    "    d = os.path.dirname(aff)\n",
    "    dic = os.path.join(d, \"index.dic\")\n",
    "    code = os.path.basename(d)\n",
    "    if os.path.isfile(dic):\n",
    "        pairs[code] = (dic, aff)\n",
    "\n",
    "CODE2DICT = {\n",
    "    \"lat\":[\"la\"],\n",
    "    \"swe\":[\"sv\"],\n",
    "    \"nob\":[\"nb\"],\n",
    "    \"nno\":[\"nn\"],\n",
    "    \"dan\":[\"da\"],\n",
    "    \"isl\":[\"is\"],\n",
    "    \"fin\":[\"fi\"],\n",
    "    \"est\":[\"et\"],\n",
    "    \"lav\":[\"lv\"],\n",
    "    \"lit\":[\"lt\"],\n",
    "    \"pol\":[\"pl\"],\n",
    "    \"cze\":[\"cs\"],\n",
    "    \"slk\":[\"sk\"],\n",
    "    \"slv\":[\"sl\"],\n",
    "    \"hrv\":[\"hr\"],\n",
    "    \"srp\":[\"sr-Latn\"],\n",
    "    \"bos\":[\"bs\"],\n",
    "    \"mkd\":[\"mk\"],\n",
    "    \"bul\":[\"bg\"],\n",
    "    \"ukr\":[\"uk\"],\n",
    "    \"rus\":[\"ru\"],\n",
    "    \"deu\":[\"de\"],\n",
    "    \"nld\":[\"nl\",\"dut\"],\n",
    "    \"eng\":[\"en\",\"en-GB\",\"en-CA\",\"en-AU\",\"en-ZA\"],\n",
    "    \"fre\":[\"fr\"],\n",
    "    \"ita\":[\"it\"],\n",
    "    \"spa\":[\"es\",\"es-MX\",\"es-AR\",\"es-CL\",\"es-ES\"],\n",
    "    \"por\":[\"pt\",\"pt-PT\"],\n",
    "    \"rom\":[\"ro\"],\n",
    "    \"hun\":[\"hu\"],\n",
    "    \"tur\":[\"tr\"],\n",
    "    \"gre\":[\"el\"],\n",
    "}\n",
    "\n",
    "def read_text(p):\n",
    "    b = open(p,\"rb\").read()\n",
    "    try: return b.decode(\"utf-8\")\n",
    "    except UnicodeDecodeError: return b.decode(\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "def get_words(text):\n",
    "    output = []\n",
    "    for line in text.split(\"\\n\"):\n",
    "        parts = line.split(\"\\t\")\n",
    "        output.append(parts[0])\n",
    "    return output\n",
    "\n",
    "def file_code(p):\n",
    "    b = os.path.basename(p)\n",
    "    return b[len(\"braxen-\"):-4] if b.startswith(\"braxen-\") else b\n",
    "\n",
    "def load_hs(dict_codes):\n",
    "    for c in dict_codes:\n",
    "        if c in pairs:\n",
    "            dic, aff = pairs[c]\n",
    "            return hunspell.HunSpell(dic, aff), c\n",
    "    return None, None\n",
    "\n",
    "files = [os.path.join(FILE_DIR, f) for f in os.listdir(FILE_DIR) if f.startswith(\"braxen-\") and f.endswith(\".txt\")]\n",
    "\n",
    "file_words, file_sizes = {}, {}\n",
    "for p in files:\n",
    "    ws = set(get_words(read_text(p)))\n",
    "    file_words[p] = ws\n",
    "    file_sizes[p] = len(ws)\n",
    "\n",
    "candidates = []\n",
    "for p, n in file_sizes.items():\n",
    "    code = file_code(p)\n",
    "    if n >= MIN_ENTRIES and code not in SKIP_CODES and code in CODE2DICT:\n",
    "        candidates.append(p)\n",
    "\n",
    "rows = []\n",
    "for p in sorted(candidates):\n",
    "    code = file_code(p)\n",
    "    hs, used = load_hs(CODE2DICT[code])\n",
    "    if not hs:\n",
    "        print(f\"skip {code}: dict not found for {CODE2DICT[code]}\")\n",
    "        continue\n",
    "    words = sorted(file_words[p])\n",
    "    print(f\"{code}: {len(words)} tokens via {used}\")\n",
    "    for w in words:\n",
    "        if not w: \n",
    "            continue\n",
    "        if all(ord(ch) < 128 for ch in w) and len(w) < 2:\n",
    "            continue\n",
    "        wcheck = w.replace(\"ö\",\"ø\").replace(\"Ö\",\"Ø\") if code in {\"nor\",\"dan\"} else w\n",
    "        if hs.spell(wcheck):\n",
    "            rows.append((code, w, \"OK\", \"\"))\n",
    "        else:\n",
    "            sugs = \", \".join(hs.suggest(wcheck))\n",
    "            rows.append((code, w, \"MISS\", sugs))\n",
    "\n",
    "df = pd.DataFrame(rows, columns=[\"file_code\",\"word\",\"status\",\"suggestions\"])\n",
    "df.to_csv(OUT_TSV, sep=\"\\t\", index=False, encoding=\"utf-8\")\n",
    "print(f\"Wrote {OUT_TSV} with {len(df):,} rows\")\n",
    "df.head(20)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 270049783,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 36166.07912,
   "end_time": "2025-11-09T02:09:07.137008",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-08T16:06:21.057888",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
