{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20363319",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-22T23:14:25.727855Z",
     "iopub.status.busy": "2025-10-22T23:14:25.727177Z",
     "iopub.status.idle": "2025-10-22T23:14:44.636026Z",
     "shell.execute_reply": "2025-10-22T23:14:44.634879Z"
    },
    "papermill": {
     "duration": 18.915154,
     "end_time": "2025-10-22T23:14:44.637974",
     "exception": false,
     "start_time": "2025-10-22T23:14:25.722820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\r\n",
      "Preconfiguring packages ...\r\n",
      "Selecting previously unselected package libtext-iconv-perl.\r\n",
      "(Reading database ... 128639 files and directories currently installed.)\r\n",
      "Preparing to unpack .../0-libtext-iconv-perl_1.7-7build3_amd64.deb ...\r\n",
      "Unpacking libtext-iconv-perl (1.7-7build3) ...\r\n",
      "Selecting previously unselected package dictionaries-common.\r\n",
      "Preparing to unpack .../1-dictionaries-common_1.28.14_all.deb ...\r\n",
      "Adding 'diversion of /usr/share/dict/words to /usr/share/dict/words.pre-dictionaries-common by dictionaries-common'\r\n",
      "Unpacking dictionaries-common (1.28.14) ...\r\n",
      "Selecting previously unselected package hunspell-en-us.\r\n",
      "Preparing to unpack .../2-hunspell-en-us_1%3a2020.12.07-2_all.deb ...\r\n",
      "Unpacking hunspell-en-us (1:2020.12.07-2) ...\r\n",
      "Selecting previously unselected package libhunspell-1.7-0:amd64.\r\n",
      "Preparing to unpack .../3-libhunspell-1.7-0_1.7.0-4build1_amd64.deb ...\r\n",
      "Unpacking libhunspell-1.7-0:amd64 (1.7.0-4build1) ...\r\n",
      "Selecting previously unselected package hunspell.\r\n",
      "Preparing to unpack .../4-hunspell_1.7.0-4build1_amd64.deb ...\r\n",
      "Unpacking hunspell (1.7.0-4build1) ...\r\n",
      "Selecting previously unselected package libhunspell-dev:amd64.\r\n",
      "Preparing to unpack .../5-libhunspell-dev_1.7.0-4build1_amd64.deb ...\r\n",
      "Unpacking libhunspell-dev:amd64 (1.7.0-4build1) ...\r\n",
      "Setting up libtext-iconv-perl (1.7-7build3) ...\r\n",
      "Setting up dictionaries-common (1.28.14) ...\r\n",
      "Setting up hunspell-en-us (1:2020.12.07-2) ...\r\n",
      "Setting up libhunspell-1.7-0:amd64 (1.7.0-4build1) ...\r\n",
      "Setting up libhunspell-dev:amd64 (1.7.0-4build1) ...\r\n",
      "Setting up hunspell (1.7.0-4build1) ...\r\n",
      "Processing triggers for man-db (2.10.2-1) ...\r\n",
      "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\r\n",
      "\r\n",
      "Processing triggers for dictionaries-common (1.28.14) ...\r\n"
     ]
    }
   ],
   "source": [
    "!apt-get -qq update\n",
    "!apt-get -qq install -y hunspell git libhunspell-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f7f3532",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-22T23:14:44.647043Z",
     "iopub.status.busy": "2025-10-22T23:14:44.646659Z",
     "iopub.status.idle": "2025-10-22T23:14:54.334029Z",
     "shell.execute_reply": "2025-10-22T23:14:54.332782Z"
    },
    "papermill": {
     "duration": 9.693909,
     "end_time": "2025-10-22T23:14:54.335952",
     "exception": false,
     "start_time": "2025-10-22T23:14:44.642043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hunspell\r\n",
      "  Downloading hunspell-0.5.5.tar.gz (34 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Building wheels for collected packages: hunspell\r\n",
      "  Building wheel for hunspell (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for hunspell: filename=hunspell-0.5.5-cp311-cp311-linux_x86_64.whl size=66310 sha256=36b63a5622a67b1a16dacb58abbdb6c394c270a334c2dd1903522815066843d4\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/0b/41/b3/14ebfe8dfb3116e3f1ab55ff0db766d1ef033b6842ccc67e24\r\n",
      "Successfully built hunspell\r\n",
      "Installing collected packages: hunspell\r\n",
      "Successfully installed hunspell-0.5.5\r\n"
     ]
    }
   ],
   "source": [
    "!pip install hunspell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86e4c42c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-22T23:14:54.345854Z",
     "iopub.status.busy": "2025-10-22T23:14:54.344905Z",
     "iopub.status.idle": "2025-10-22T23:14:54.463831Z",
     "shell.execute_reply": "2025-10-22T23:14:54.462709Z"
    },
    "papermill": {
     "duration": 0.125812,
     "end_time": "2025-10-22T23:14:54.465670",
     "exception": false,
     "start_time": "2025-10-22T23:14:54.339858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/dictionaries/dictionaries\r\n"
     ]
    }
   ],
   "source": [
    "!echo $PWD/dictionaries/dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aed6eaf2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-22T23:14:54.475377Z",
     "iopub.status.busy": "2025-10-22T23:14:54.474464Z",
     "iopub.status.idle": "2025-10-22T23:15:05.417504Z",
     "shell.execute_reply": "2025-10-22T23:15:05.416024Z"
    },
    "papermill": {
     "duration": 10.950291,
     "end_time": "2025-10-22T23:15:05.419762",
     "exception": false,
     "start_time": "2025-10-22T23:14:54.469471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'dictionaries'...\r\n",
      "remote: Enumerating objects: 11042, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (1620/1620), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (289/289), done.\u001b[K\r\n",
      "remote: Total 11042 (delta 1366), reused 1341 (delta 1331), pack-reused 9422 (from 1)\u001b[K\r\n",
      "Receiving objects: 100% (11042/11042), 100.32 MiB | 19.38 MiB/s, done.\r\n",
      "Resolving deltas: 100% (9445/9445), done.\r\n",
      "Updating files: 100% (570/570), done.\r\n",
      "/kaggle/working\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/wooorm/dictionaries\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f93b9bf9",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-22T23:15:05.438981Z",
     "iopub.status.busy": "2025-10-22T23:15:05.438639Z",
     "iopub.status.idle": "2025-10-23T07:33:44.041236Z",
     "shell.execute_reply": "2025-10-23T07:33:44.039564Z"
    },
    "papermill": {
     "duration": 29918.633625,
     "end_time": "2025-10-23T07:33:44.062185",
     "exception": false,
     "start_time": "2025-10-22T23:15:05.428560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dan: 1941 tokens via da\n",
      "eng: 19790 tokens via en\n",
      "skip fin: dict not found for ['fi']\n",
      "fre: 5533 tokens via fr\n",
      "ita: 3093 tokens via it\n",
      "lat: 3808 tokens via la\n",
      "rus: 1362 tokens via ru\n",
      "spa: 2450 tokens via es\n",
      "swe: 704331 tokens via sv\n",
      "Wrote hunspell_results.tsv with 742,080 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_code</th>\n",
       "      <th>word</th>\n",
       "      <th>status</th>\n",
       "      <th>suggestions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dan</td>\n",
       "      <td>Aabech</td>\n",
       "      <td>MISS</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dan</td>\n",
       "      <td>Aabo</td>\n",
       "      <td>OK</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dan</td>\n",
       "      <td>Aaes</td>\n",
       "      <td>MISS</td>\n",
       "      <td>Aaens, Aase, Aars, Aas, Aes, Aases, Alaes, Aak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dan</td>\n",
       "      <td>Aage</td>\n",
       "      <td>OK</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dan</td>\n",
       "      <td>Aalbæk</td>\n",
       "      <td>OK</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dan</td>\n",
       "      <td>Aamann</td>\n",
       "      <td>MISS</td>\n",
       "      <td>Aamand, Asmann, Hamann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dan</td>\n",
       "      <td>Aamanns</td>\n",
       "      <td>MISS</td>\n",
       "      <td>Aamands, Asmanns, Hamanns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dan</td>\n",
       "      <td>Aarke</td>\n",
       "      <td>MISS</td>\n",
       "      <td>Aake, Arke, Barke, Harke, Aarøe, Marke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dan</td>\n",
       "      <td>Aarsleff</td>\n",
       "      <td>MISS</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dan</td>\n",
       "      <td>Adsersen</td>\n",
       "      <td>OK</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dan</td>\n",
       "      <td>Aelling</td>\n",
       "      <td>MISS</td>\n",
       "      <td>Aalling, Alling, Selling, Belling, Telling, Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dan</td>\n",
       "      <td>Aftenvagten</td>\n",
       "      <td>OK</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>dan</td>\n",
       "      <td>Amagermanden</td>\n",
       "      <td>OK</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dan</td>\n",
       "      <td>Amagers</td>\n",
       "      <td>OK</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>dan</td>\n",
       "      <td>Amleth</td>\n",
       "      <td>MISS</td>\n",
       "      <td>Hamlet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dan</td>\n",
       "      <td>Ancher</td>\n",
       "      <td>OK</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>dan</td>\n",
       "      <td>Anchers</td>\n",
       "      <td>OK</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>dan</td>\n",
       "      <td>Andkjaer</td>\n",
       "      <td>MISS</td>\n",
       "      <td>Andkjær</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>dan</td>\n",
       "      <td>Andkjær</td>\n",
       "      <td>OK</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>dan</td>\n",
       "      <td>Ankjærgaard</td>\n",
       "      <td>MISS</td>\n",
       "      <td>Kjærgaard, Kjærsgaard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   file_code          word status  \\\n",
       "0        dan        Aabech   MISS   \n",
       "1        dan          Aabo     OK   \n",
       "2        dan          Aaes   MISS   \n",
       "3        dan          Aage     OK   \n",
       "4        dan        Aalbæk     OK   \n",
       "5        dan        Aamann   MISS   \n",
       "6        dan       Aamanns   MISS   \n",
       "7        dan         Aarke   MISS   \n",
       "8        dan      Aarsleff   MISS   \n",
       "9        dan      Adsersen     OK   \n",
       "10       dan       Aelling   MISS   \n",
       "11       dan   Aftenvagten     OK   \n",
       "12       dan  Amagermanden     OK   \n",
       "13       dan       Amagers     OK   \n",
       "14       dan        Amleth   MISS   \n",
       "15       dan        Ancher     OK   \n",
       "16       dan       Anchers     OK   \n",
       "17       dan      Andkjaer   MISS   \n",
       "18       dan       Andkjær     OK   \n",
       "19       dan   Ankjærgaard   MISS   \n",
       "\n",
       "                                          suggestions  \n",
       "0                                                      \n",
       "1                                                      \n",
       "2   Aaens, Aase, Aars, Aas, Aes, Aases, Alaes, Aak...  \n",
       "3                                                      \n",
       "4                                                      \n",
       "5                              Aamand, Asmann, Hamann  \n",
       "6                           Aamands, Asmanns, Hamanns  \n",
       "7              Aake, Arke, Barke, Harke, Aarøe, Marke  \n",
       "8                                                      \n",
       "9                                                      \n",
       "10  Aalling, Alling, Selling, Belling, Telling, Re...  \n",
       "11                                                     \n",
       "12                                                     \n",
       "13                                                     \n",
       "14                                             Hamlet  \n",
       "15                                                     \n",
       "16                                                     \n",
       "17                                            Andkjær  \n",
       "18                                                     \n",
       "19                              Kjærgaard, Kjærsgaard  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, re, glob, pandas as pd, hunspell\n",
    "\n",
    "FILE_DIR = \"/kaggle/input/split-braxen-by-language\"\n",
    "DICT_ROOT = \"/kaggle/working/dictionaries/dictionaries\"  # as you showed\n",
    "OUT_TSV = \"hunspell_results.tsv\"\n",
    "MIN_ENTRIES = 1000\n",
    "SKIP_CODES = {\"afr\",\"asi\",\"aus\",\"sla\",\"mix\",\"fisa\"}\n",
    "\n",
    "# find index.aff/index.dic pairs under your DICT_ROOT\n",
    "pairs = {}\n",
    "for aff in glob.glob(os.path.join(DICT_ROOT, \"*\", \"index.aff\")):\n",
    "    d = os.path.dirname(aff)\n",
    "    dic = os.path.join(d, \"index.dic\")\n",
    "    code = os.path.basename(d)\n",
    "    if os.path.isfile(dic):\n",
    "        pairs[code] = (dic, aff)\n",
    "\n",
    "CODE2DICT = {\n",
    "    \"lat\":[\"la\"],\n",
    "    \"swe\":[\"sv\"],\n",
    "    \"nor\":[\"nb\",\"nn\"],\n",
    "    \"dan\":[\"da\"],\n",
    "    \"isl\":[\"is\"],\n",
    "    \"fin\":[\"fi\"],\n",
    "    \"est\":[\"et\"],\n",
    "    \"lav\":[\"lv\"],\n",
    "    \"lit\":[\"lt\"],\n",
    "    \"pol\":[\"pl\"],\n",
    "    \"cze\":[\"cs\"],\n",
    "    \"slk\":[\"sk\"],\n",
    "    \"slv\":[\"sl\"],\n",
    "    \"hrv\":[\"hr\"],\n",
    "    \"srp\":[\"sr-Latn\"],\n",
    "    \"bos\":[\"bs\"],\n",
    "    \"mkd\":[\"mk\"],\n",
    "    \"bul\":[\"bg\"],\n",
    "    \"ukr\":[\"uk\"],\n",
    "    \"rus\":[\"ru\"],\n",
    "    \"deu\":[\"de\"],\n",
    "    \"nld\":[\"nl\",\"dut\"],\n",
    "    \"eng\":[\"en\",\"en-GB\",\"en-CA\",\"en-AU\",\"en-ZA\"],\n",
    "    \"fre\":[\"fr\"],\n",
    "    \"ita\":[\"it\"],\n",
    "    \"spa\":[\"es\",\"es-MX\",\"es-AR\",\"es-CL\",\"es-ES\"],\n",
    "    \"por\":[\"pt\",\"pt-PT\"],\n",
    "    \"rom\":[\"ro\"],\n",
    "    \"hun\":[\"hu\"],\n",
    "    \"tur\":[\"tr\"],\n",
    "    \"gre\":[\"el\"],\n",
    "}\n",
    "\n",
    "WORD_RE = re.compile(r\"[^\\W\\d_][\\w’'\\-\\u2011\\u2013\\u2014]*\", re.UNICODE)\n",
    "def tokenize(t): return WORD_RE.findall(t)\n",
    "def read_text(p):\n",
    "    b = open(p,\"rb\").read()\n",
    "    try: return b.decode(\"utf-8\")\n",
    "    except UnicodeDecodeError: return b.decode(\"utf-8\", errors=\"ignore\")\n",
    "def file_code(p):\n",
    "    b = os.path.basename(p)\n",
    "    return b[len(\"braxen-\"):-4] if b.startswith(\"braxen-\") else b\n",
    "\n",
    "def load_hs(dict_codes):\n",
    "    for c in dict_codes:\n",
    "        if c in pairs:\n",
    "            dic, aff = pairs[c]\n",
    "            return hunspell.HunSpell(dic, aff), c\n",
    "    return None, None\n",
    "\n",
    "files = [os.path.join(FILE_DIR, f) for f in os.listdir(FILE_DIR) if f.startswith(\"braxen-\") and f.endswith(\".txt\")]\n",
    "\n",
    "file_words, file_sizes = {}, {}\n",
    "for p in files:\n",
    "    ws = set(tokenize(read_text(p)))\n",
    "    file_words[p] = ws\n",
    "    file_sizes[p] = len(ws)\n",
    "\n",
    "candidates = []\n",
    "for p, n in file_sizes.items():\n",
    "    code = file_code(p)\n",
    "    if n >= MIN_ENTRIES and code not in SKIP_CODES and code in CODE2DICT:\n",
    "        candidates.append(p)\n",
    "\n",
    "rows = []\n",
    "for p in sorted(candidates):\n",
    "    code = file_code(p)\n",
    "    hs, used = load_hs(CODE2DICT[code])\n",
    "    if not hs:\n",
    "        print(f\"skip {code}: dict not found for {CODE2DICT[code]}\")\n",
    "        continue\n",
    "    words = sorted(file_words[p])\n",
    "    print(f\"{code}: {len(words)} tokens via {used}\")\n",
    "    for w in words:\n",
    "        if not w: \n",
    "            continue\n",
    "        if all(ord(ch) < 128 for ch in w) and len(w) < 2:\n",
    "            continue\n",
    "        wcheck = w.replace(\"ö\",\"ø\").replace(\"Ö\",\"Ø\") if code in {\"nor\",\"dan\"} else w\n",
    "        if hs.spell(wcheck):\n",
    "            rows.append((code, w, \"OK\", \"\"))\n",
    "        else:\n",
    "            sugs = \", \".join(hs.suggest(wcheck))\n",
    "            rows.append((code, w, \"MISS\", sugs))\n",
    "\n",
    "df = pd.DataFrame(rows, columns=[\"file_code\",\"word\",\"status\",\"suggestions\"])\n",
    "df.to_csv(OUT_TSV, sep=\"\\t\", index=False, encoding=\"utf-8\")\n",
    "print(f\"Wrote {OUT_TSV} with {len(df):,} rows\")\n",
    "df.head(20)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 270049783,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 29964.037178,
   "end_time": "2025-10-23T07:33:45.201910",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-22T23:14:21.164732",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
