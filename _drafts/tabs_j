Label Studio
http://localhost:8080/projects/6/data?tab=5

Getting started ‚Äî API Reference | Label Studio
https://api.labelstud.io/api-reference/introduction/getting-started

kyutai-labs/moshi
https://github.com/kyutai-labs/moshi?tab=readme-ov-file

Moshi.pdf
https://kyutai.org/Moshi.pdf

Label Studio
http://130.237.3.107:8080/projects/1/data

130.237.3.107
http://130.237.3.107:8080/projects/5/data?tab=5&task=72

Label Studio
http://130.237.3.107:8080/projects/8/data?tab=8&task=117

Label Studio
http://130.237.3.107:8080/projects/8/data?tab=8&task=110

Label Studio
http://130.237.3.107:8080/projects/5/data

Label Studio
http://130.237.3.107:8080/projects/6/data?tab=6

Label Studio API
https://labelstud.io/api

TAFFC2457417.pdf
https://sail.usc.edu/publications/files/eyben-preprinttaffc-2015.pdf

descriptinc/descript-audio-codec: State-of-the-art audio codec with 90x compression factor. Supports 44.1kHz, 24kHz, and 16kHz mono/stereo audio.
https://github.com/descriptinc/descript-audio-codec?tab=readme-ov-file

phonlab-tcd/cula4-cruinniu-na-nog-2021
https://github.com/phonlab-tcd/cula4-cruinniu-na-nog-2021?tab=readme-ov-file

phonlab-tcd/caint-ros-muc-im2-scans
https://github.com/phonlab-tcd/caint-ros-muc-im2-scans/

sgeilini_na_finne/html at main ¬∑ phonlab-tcd/sgeilini_na_finne
https://github.com/phonlab-tcd/sgeilini_na_finne/tree/main/html

cjhutto/vaderSentiment: VADER Sentiment Analysis. VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media, and works well on texts from other domains.
https://github.com/cjhutto/vaderSentiment

Models - Hugging Face
https://huggingface.co/models?other=speech-emotion-recognition

WavLM SER Multi Baseline Odyssey2024 - a Hugging Face Space by 3loi
https://huggingface.co/spaces/3loi/WavLM-SER-Multi-Baseline-Odyssey2024

3loi/SER-Odyssey-Baseline-WavLM-Dominance ¬∑ Hugging Face
https://huggingface.co/3loi/SER-Odyssey-Baseline-WavLM-Dominance

dkounadis/wav2small ¬∑ Hugging Face
https://huggingface.co/dkounadis/wav2small

3loi/SER-Odyssey-Baseline-WavLM-Valence ¬∑ Hugging Face
https://huggingface.co/3loi/SER-Odyssey-Baseline-WavLM-Valence

CAiRE/SER-wav2vec2-large-xlsr-53-eng-zho-adults ¬∑ Hugging Face
https://huggingface.co/CAiRE/SER-wav2vec2-large-xlsr-53-eng-zho-adults

thegenerativegeneration/emotion2vec_base_finetuned ¬∑ Hugging Face
https://huggingface.co/thegenerativegeneration/emotion2vec_base_finetuned

FarhadMadadzade/wav2vec2-large-xlsr-53-english-ser-cosine ¬∑ Hugging Face
https://huggingface.co/FarhadMadadzade/wav2vec2-large-xlsr-53-english-ser-cosine

m3hrdadfi/ser ¬∑ Hugging Face
https://huggingface.co/m3hrdadfi/ser

google-t5/t5-base ¬∑ Hugging Face
https://huggingface.co/google-t5/t5-base

1611.04558
https://arxiv.org/pdf/1611.04558

shivammehta25/Match-TTSG
https://github.com/shivammehta25/Match-TTSG

shivammehta25/Matcha-TTS: [ICASSP 2024] üçµ Matcha-TTS: A fast TTS architecture with conditional flow matching
https://github.com/shivammehta25/Matcha-TTS

Matcha-TTS: A fast TTS architecture with conditional flow matching | Matcha-TTS
https://shivammehta25.github.io/Matcha-TTS/

shivammehta25/Matcha-TTS: [ICASSP 2024] üçµ Matcha-TTS: A fast TTS architecture with conditional flow matching
https://github.com/shivammehta25/Matcha-TTS

phonlab-tcd repositories
https://github.com/orgs/phonlab-tcd/repositories?page=2

lara/Aesop/An_Bhean_agus_An_Madra_Rua/corpus/An_Bhean_agus_An_Madra_Rua.txt at master ¬∑ phonlab-tcd/lara
https://github.com/phonlab-tcd/lara/blob/master/Aesop/An_Bhean_agus_An_Madra_Rua/corpus/An_Bhean_agus_An_Madra_Rua.txt

gramadoir-ts/src at main ¬∑ phonlab-tcd/gramadoir-ts
https://github.com/phonlab-tcd/gramadoir-ts/tree/main/src

snc_2023/hts_label_mono/SNC_Gearrscealta_an_Phiarsaigh_0001.lab at main ¬∑ phonlab-tcd/snc_2023
https://github.com/phonlab-tcd/snc_2023/blob/main/hts_label_mono/SNC_Gearrscealta_an_Phiarsaigh_0001.lab

phonlab-tcd/mfa_alignments
https://github.com/phonlab-tcd/mfa_alignments

phonlab-tcd/mfa_models
https://github.com/phonlab-tcd/mfa_models

Moshi.pdf
https://kyutai.org/Moshi.pdf

xinjli/allosaurus: Allosaurus is a pretrained universal phone recognizer for more than 2000 languages
https://github.com/xinjli/allosaurus

1.6. Nearest Neighbors ‚Äî scikit-learn 1.5.2 documentation
https://scikit-learn.org/stable/modules/neighbors.html

ISCA Archive
https://www.isca-archive.org/interspeech_2024/index.html

kang24b_interspeech.pdf
https://www.isca-archive.org/interspeech_2024/kang24b_interspeech.pdf

StevenVdEeckt/unsupervised-ocl-for-asr: Supplementary material to the paper "Unsupervised Online Continual Learning for Automatic Speech Recognition", accepted for Interspeech 2024.
https://github.com/StevenVdEeckt/unsupervised-ocl-for-asr

prabhu24_interspeech.pdf
https://www.isca-archive.org/interspeech_2024/prabhu24_interspeech.pdf

ISCA Archive - Contextual Interactive Evaluation of TTS Models in Dialogue Systems
https://www.isca-archive.org/interspeech_2024/wang24t_interspeech.html

lameris24_interspeech.pdf
https://www.isca-archive.org/interspeech_2024/lameris24_interspeech.pdf

tannander24_interspeech.pdf
https://www.isca-archive.org/interspeech_2024/tannander24_interspeech.pdf

yang24_interspeech.pdf
https://www.isca-archive.org/interspeech_2024/yang24_interspeech.pdf

iooops/G2PA
https://github.com/iooops/G2PA

G2PA/train_aligner.sh at main ¬∑ iooops/G2PA
https://github.com/iooops/G2PA/blob/main/train_aligner.sh

G2PA/hubert_extractor.py at main ¬∑ iooops/G2PA
https://github.com/iooops/G2PA/blob/main/hubert_extractor.py

kakaobrain/g2pm: A Neural Grapheme-to-Phoneme Conversion Package for Mandarin Chinese Based on a New Open Benchmark Dataset
https://github.com/kakaobrain/g2pm

TencentGameMate/chinese-hubert-base ¬∑ Hugging Face
https://huggingface.co/TencentGameMate/chinese-hubert-base

chinese_speech_pretrain/hubert_kmeans at master ¬∑ TencentGameMate/chinese_speech_pretrain
https://github.com/TencentGameMate/chinese_speech_pretrain/tree/master/hubert_kmeans

unsupervised-ocl-for-asr/models/conf/training at main ¬∑ StevenVdEeckt/unsupervised-ocl-for-asr
https://github.com/StevenVdEeckt/unsupervised-ocl-for-asr/tree/main/models/conf/training

fine tune t5 multiple new tasks - Google Search
https://www.google.com/search?q=fine+tune+t5+multiple+new+tasks&rlz=1C5GCEM_enSE990SE991&oq=fine+tune+t5+multiple+new+tasks&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIKCAEQABiABBiiBDIKCAIQABiABBiiBDIKCAMQABiABBiiBNIBCDYzNzBqMGo3qAIAsAIA&sourceid=chrome&ie=UTF-8

A Full Guide to Finetuning T5 for Text2Text and Building a Demo with Streamlit | by Fabio Chiusano | NLPlanet | Medium
https://medium.com/nlplanet/a-full-guide-to-finetuning-t5-for-text2text-and-building-a-demo-with-streamlit-c72009631887

Project Runeberg
https://runeberg.org/

Books by Hedin, Sven Anders (sorted by popularity) - Project Gutenberg
https://www.gutenberg.org/ebooks/author/9475

About Project Runeberg
https://runeberg.org/admin/

Scanned by Nasjonalbiblioteket (About Project Runeberg)
https://runeberg.org/admin/scannb.html

modernisation of swedish texts - Google Search
https://www.google.com/search?q=modernisation+of+swedish+texts&rlz=1C5GCEM_enSE990SE991&oq=modernisation+of+swedish+texts&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIKCAEQABiABBiiBDIKCAIQABiABBiiBDIKCAMQABiABBiiBNIBCDYxNDFqMGo3qAIAsAIA&sourceid=chrome&ie=UTF-8

The AI tool quickly became good at Swedish - Uppsala University
https://www.uu.se/en/news/2023/2023-05-10-the-ai-tool-quickly-became-good-at-swedish

An SMT Approach to Automatic Annotation of Historical Text
https://ep.liu.se/ecp/087/005/ecp1387005.pdf

(PDF) Normalisation of historical text using context-sensitive weighted Levenshtein distance and compound splitting | Eva Pettersson - Academia.edu
https://www.academia.edu/57154394/Normalisation_of_historical_text_using_context_sensitive_weighted_Levenshtein_distance_and_compound_splitting

(PDF) Normalisation of historical text using context-sensitive weighted Levenshtein distance and compound splitting | Eva Pettersson - Academia.edu
https://www.academia.edu/57154394/Normalisation_of_historical_text_using_context_sensitive_weighted_Levenshtein_distance_and_compound_splitting

SUC 3.0 | The Language Bank Text
https://spraakbanken.gu.se/resurser/suc3#:~:text=Stockholm%2DUme%C3%A5%2Dkorpus%20(SUC,och%20texter%20med%20olika%20stilniv%C3%A5er.

Alice‚Äôs √§fventyr i sagolandet sida 1 faksimil | Litteraturbanken
https://litteraturbanken.se/f%C3%B6rfattare/DodgsonCL/titlar/Alices%C3%84fventyr/sida/1/faksimil

Alice's √§ventyr i sagolandet
https://runeberg.org/aliceisago/

2 (Alice's √§ventyr i sagolandet)
https://runeberg.org/aliceisago/0016.html

Alice's Adventures in Wonderland/Chapter 01 - Wikisource
https://sv.wikisource.org/wiki/Alices_%C3%A4ventyr_i_underlandet/Kapitel_01

the little prince - Google Search
https://www.google.com/search?q=the+little+prince&rlz=1C5GCEM_enSE990SE991&oq=the+little+prince&gs_lcrp=EgZjaHJvbWUqBwgAEAAYjwIyBwgAEAAYjwIyEAgBEC4YkQIY1AIYgAQYigUyEAgCEC4YkQIY1AIYgAQYigUyDQgDEAAYkQIYgAQYigUyBwgEEAAYgAQyBwgFEAAYgAQyCggGEC4Y1AIYgAQyCggHEC4Y1AIYgAQyBwgIEAAYgAQyBwgJEAAYgATSAQg0NjE5ajBqN6gCALACAA&sourceid=chrome&ie=UTF-8

fadedpage.com
https://www.fadedpage.com/

Browse By Language: Swedish | Project Gutenberg
https://www.gutenberg.org/browse/languages/sv

Browse By Author: E | Project Gutenberg
https://www.gutenberg.org/browse/authors/e#a45725

Havsboken by Anna Lenah Elgstr√∂m | Project Gutenberg
https://www.gutenberg.org/ebooks/48269

Browse By Author: C | Project Gutenberg
https://www.gutenberg.org/browse/authors/c#a2029

Minna Canth - Wikipedia
https://en.wikipedia.org/wiki/Minna_Canth

The Project Gutenberg eBook of Arbetets Herrav√§lde, by Andrew Carnegie
https://www.gutenberg.org/cache/epub/9951/pg9951-images.html

LibriVox
https://librivox.org/the-empire-of-business-by-andrew-carnegie/

File:The empire of business (IA empireofbusiness00carn).pdf - Wikimedia Commons
https://commons.wikimedia.org/wiki/File:The_empire_of_business_(IA_empireofbusiness00carn).pdf

showlab/Show-o: Repository for Show-o, One Single Transformer to Unify Multimodal Understanding and Generation.
https://github.com/showlab/Show-o?tab=readme-ov-file

hub.docker.com/r/kaldiasr/kaldi
https://hub.docker.com/r/kaldiasr/kaldi

Added jsgf/fsg tags extraction by CarloBenussi ¬∑ Pull Request #84 ¬∑ cmusphinx/pocketsphinx
https://github.com/cmusphinx/pocketsphinx/pull/84

Long Audio Alignment Overview ‚Äì CMUSphinx Open Source Speech Recognition
https://cmusphinx.github.io/wiki/longaudioalignment/

ReadAlongs/SoundSwallower: An even smaller speech recognizer / force aligner
https://github.com/ReadAlongs/SoundSwallower?tab=readme-ov-file

g2p/g2p/mappings/langs/crm at main ¬∑ roedoejet/g2p
https://github.com/roedoejet/g2p/tree/main/g2p/mappings/langs/crm

dhdaines/playa: PLAYA is a LAYout Analyzer üèñÔ∏è
https://github.com/dhdaines/playa

cmusphinx/pocketsphinx: A small speech recognizer
https://github.com/cmusphinx/pocketsphinx

soundswallower package ‚Äî SoundSwallower 0.3 documentation
https://soundswallower.readthedocs.io/en/latest/soundswallower.html

ReadAlongs/Studio: Audiobook alignment for Indigenous languages
https://github.com/ReadAlongs/Studio

The Web App - ReadAlong-Studio
https://readalongs.github.io/Studio/latest/web-app/

ReadAlong-Studio for Interactive Storytelling
https://readalong-studio.mothertongues.org/#/editor

ReadAlong-Studio for Interactive Storytelling
https://readalong-studio.mothertongues.org/#/

drmfinlay/pyjsgf: JSpeech Grammar Format (JSGF) compiler, matcher and parser package for Python.
https://github.com/drmfinlay/pyjsgf/tree/master

pyctcdecode/pyctcdecode/decoder.py at main ¬∑ kensho-technologies/pyctcdecode
https://github.com/kensho-technologies/pyctcdecode/blob/main/pyctcdecode/decoder.py

whisper turbo - Google Search
https://www.google.com/search?q=whisper+turbo&rlz=1C5GCEM_enSE990SE991&oq=whisper+turbo&gs_lcrp=EgZjaHJvbWUyCQgAEEUYORiABDIHCAEQABiABDIICAIQABgWGB4yCAgDEAAYFhgeMggIBBAAGBYYHjIGCAUQRRg8MgYIBhBFGDwyBggHEEUYPNIBCDI3MzVqMGo3qAIAsAIA&sourceid=chrome&ie=UTF-8

owsm huggingface - Google Search
https://www.google.com/search?q=owsm+huggingface&rlz=1C5GCEM_enSE990SE991&oq=owsm+huggingface&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIKCAEQABiABBiiBDIKCAIQABiABBiiBDIKCAMQABiABBiiBDIKCAQQABiABBiiBDIKCAUQABiABBiiBDIGCAYQRRg80gEIMzY4NmowajeoAgCwAgA&sourceid=chrome&ie=UTF-8

espnet/owsm_v3 ¬∑ Hugging Face
https://huggingface.co/espnet/owsm_v3

espnet (ESPnet)
https://huggingface.co/espnet

espnet/jesus_dramas ¬∑ Datasets at Hugging Face
https://huggingface.co/datasets/espnet/jesus_dramas

WAVLab | XEUS - Towards Robust Speech Representation Learning for Thousands of Languages
https://www.wavlab.org/activities/2024/xeus/

espnet (ESPnet)
https://huggingface.co/espnet

espnet/speechlm_tts_ls_giga_mlsen_amuse_speech_delay ¬∑ Hugging Face
https://huggingface.co/espnet/speechlm_tts_ls_giga_mlsen_amuse_speech_delay

espnet/owsm_v3.1_ebf ¬∑ Hugging Face
https://huggingface.co/espnet/owsm_v3.1_ebf

WAVLab | Open Whisper-style Speech Models (OWSM)
https://www.wavlab.org/activities/2024/owsm/

pyf98/owsm_ctc_v3.1_1B ¬∑ Hugging Face
https://huggingface.co/pyf98/owsm_ctc_v3.1_1B

cdn-lfs-us-1.hf.co/repos/b5/2e/b52e705d124d88d2372fc369dd1ea41196024ce5901541af6376a94973d029bf/5478f1a0454b62146ffc9370a2bb45c2473bfba087c5ebcc8ddb7819aafb6b1f?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27meta.yaml%3B+filename%3D"meta.yaml"%3B&response-content-type=text%2Fyaml&Expires=1728042128&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyODA0MjEyOH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2I1LzJlL2I1MmU3MDVkMTI0ZDg4ZDIzNzJmYzM2OWRkMWVhNDExOTYwMjRjZTU5MDE1NDFhZjYzNzZhOTQ5NzNkMDI5YmYvNTQ3OGYxYTA0NTRiNjIxNDZmZmM5MzcwYTJiYjQ1YzI0NzNiZmJhMDg3YzVlYmNjOGRkYjc4MTlhYWZiNmIxZj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=kR0Xl9RdFzZzi0NrItjxwvG3PaSnrfl2WzWStpx9-NnV4Uks5ugsbZ-e2zXeHCiVu4AnVp5AuUZscl-6hzOU1~GmBOc5JuoSVWRd-ZCWGVQTGZmpTuG5iHqRXQhsGsyiqnRF1KtTMLpBcgYmraEy73Xvd0lJEdbpG3mmYIA0dlvosFBmVbVFr9jZV2w6W8Lpg1PYciKS~eNOPUwYZ-OMHru8UAriMm9jqzNA6y9Oz-puUSf-QtbLiGWb8TP7zJYFocvrGF~ANVTmk65TV3Zx9-8iFMpmMlfWBOtPkxAgozJcOauZFMIbucHgEB7LeBPSRIZT1vsSh~CXU0Hyf1I61g__&Key-Pair-Id=K24J24Z295AEI9
https://cdn-lfs-us-1.hf.co/repos/b5/2e/b52e705d124d88d2372fc369dd1ea41196024ce5901541af6376a94973d029bf/5478f1a0454b62146ffc9370a2bb45c2473bfba087c5ebcc8ddb7819aafb6b1f?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27meta.yaml%3B+filename%3D%22meta.yaml%22%3B&response-content-type=text%2Fyaml&Expires=1728042128&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyODA0MjEyOH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2I1LzJlL2I1MmU3MDVkMTI0ZDg4ZDIzNzJmYzM2OWRkMWVhNDExOTYwMjRjZTU5MDE1NDFhZjYzNzZhOTQ5NzNkMDI5YmYvNTQ3OGYxYTA0NTRiNjIxNDZmZmM5MzcwYTJiYjQ1YzI0NzNiZmJhMDg3YzVlYmNjOGRkYjc4MTlhYWZiNmIxZj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=kR0Xl9RdFzZzi0NrItjxwvG3PaSnrfl2WzWStpx9-NnV4Uks5ugsbZ-e2zXeHCiVu4AnVp5AuUZscl-6hzOU1%7EGmBOc5JuoSVWRd-ZCWGVQTGZmpTuG5iHqRXQhsGsyiqnRF1KtTMLpBcgYmraEy73Xvd0lJEdbpG3mmYIA0dlvosFBmVbVFr9jZV2w6W8Lpg1PYciKS%7EeNOPUwYZ-OMHru8UAriMm9jqzNA6y9Oz-puUSf-QtbLiGWb8TP7zJYFocvrGF%7EANVTmk65TV3Zx9-8iFMpmMlfWBOtPkxAgozJcOauZFMIbucHgEB7LeBPSRIZT1vsSh%7ECXU0Hyf1I61g__&Key-Pair-Id=K24J24Z295AEI9

Pull requests ¬∑ speechbrain/speechbrain
https://github.com/speechbrain/speechbrain/pulls

speechbrain/recipes/LJSpeech/ljspeech_prepare.py at develop ¬∑ speechbrain/speechbrain
https://github.com/speechbrain/speechbrain/blob/develop/recipes/LJSpeech/ljspeech_prepare.py

benchmarks/benchmarks/MOABB at main ¬∑ speechbrain/benchmarks
https://github.com/speechbrain/benchmarks/tree/main/benchmarks/MOABB

Tokotron: Tokenized TTS by flexthink ¬∑ Pull Request #2696 ¬∑ speechbrain/speechbrain
https://github.com/speechbrain/speechbrain/pull/2696/files

WIP streaming ASR guide/tutorial by asumagic ¬∑ Pull Request #2700 ¬∑ speechbrain/speechbrain
https://github.com/speechbrain/speechbrain/pull/2700

Voice analysis functions by pplantinga ¬∑ Pull Request #2689 ¬∑ speechbrain/speechbrain
https://github.com/speechbrain/speechbrain/pull/2689

‚ú® Add SNAC by julien-blanchon ¬∑ Pull Request #2568 ¬∑ speechbrain/speechbrain
https://github.com/speechbrain/speechbrain/pull/2568

Add recipe for audio/speech LLM (ltu-as with llama3) by BenoitWang ¬∑ Pull Request #2550 ¬∑ speechbrain/speechbrain
https://github.com/speechbrain/speechbrain/pull/2550

Chaanks/speechbrain: A PyTorch-based Speech Toolkit
https://github.com/Chaanks/speechbrain?tab=readme-ov-file

speechbrain.k2_integration.lattice_decoder module ‚Äî SpeechBrain 0.5.0 documentation
https://speechbrain.readthedocs.io/en/latest/API/speechbrain.k2_integration.lattice_decoder.html

1612.02695
https://arxiv.org/pdf/1612.02695

k2.ipynb - Colab
https://colab.research.google.com/drive/1qbHUhNZUX7AYEpqnZyf29Lrz2IPHBGlX?usp=sharing

voice-activity-detection.ipynb - Colab
https://colab.research.google.com/github/speechbrain/speechbrain/blob/develop/docs/tutorials/tasks/voice-activity-detection.ipynb#scrollTo=SSOeT58mQM1m

showlab/Show-o: Repository for Show-o, One Single Transformer to Unify Multimodal Understanding and Generation.
https://github.com/showlab/Show-o?tab=readme-ov-file

speechbrain/vad-crdnn-libriparty ¬∑ Hugging Face
https://huggingface.co/speechbrain/vad-crdnn-libriparty

Hidden traces of humanity: what AI images reveal about our world | Art | The Guardian
https://www.theguardian.com/news/2024/oct/01/hidden-traces-of-humanity-what-ai-images-reveal-about-our-world?utm_source=instagramstories&utm_campaign=aiimages

speechbrain "rescoring" - Google Search
https://www.google.com/search?q=speechbrain+%22rescoring%22&sca_esv=2f8623b159e229b7&sca_upv=1&rlz=1C5GCEM_enSE990SE991&sxsrf=ADLYWIKPa2ype23aJAb4qclSLgrVEVzmgA%3A1727787381464&ei=dfH7ZorzG5PWwPAPlN3h8QY&ved=0ahUKEwjKgfrIne2IAxUTKxAIHZRuOG4Q4dUDCA8&uact=5&oq=speechbrain+%22rescoring%22&gs_lp=Egxnd3Mtd2l6LXNlcnAiF3NwZWVjaGJyYWluICJyZXNjb3JpbmciMgUQIRigAUiAFVCCDFiPEnABeAGQAQCYAVigAaIBqgEBMrgBA8gBAPgBAZgCA6ACrAHCAgoQABiwAxjWBBhHwgIEECMYJ8ICCBAAGIAEGKIEmAMAiAYBkAYIkgcBM6AH2gQ&sclient=gws-wiz-serp

Releases ¬∑ speechbrain/speechbrain
https://github.com/speechbrain/speechbrain/releases

Google Translate
https://translate.google.com/?sl=auto&tl=en&text=japp%20jo%2C%20h%C3%B6r%20av%20sig%20(eller%20jag%2C%20men%20min%20gissning%20%C3%A4r%20jim)%0A%0Amedel%3A%20ni%20f%C3%A5r%20siffran%20av%20mig%20idag.%20it-st%C3%B6d%20fungerar%20f%C3%B6r%20tillf%C3%A4llet%20j%C3%A4ttebra%20p%C3%A5%20kth%20j%C3%A4mf%C3%B6rt%20med%20ekonomi-st%C3%B6d%2C%20och%20du%20kan%20gussa%20vad%20det%20betyder.%0A%0Akommer%20det%20jag%20vet%20under%20eftermiddagen%20eller%20i%20v%C3%A4rsta%20fall%20imorgon%2C%20jag%20%C3%A4r%20ute%20mesta%20delen%20av%20dagen%20idag.%20och%20%C3%A4r%20det%20n%C3%A5got%20jag%20beh%C3%B6ver%20fr%C3%A5n%20ekonomi-st%C3%B6d%20(%C3%A4r%20inte%20klar%20p%C3%A5%20vilka%20siffror%20jag%20har)%20s%C3%A5%20ber%C3%A4ttar%20jag%20iaf%20det.&op=translate

huggingface/parler-tts: Inference and training library for high-quality TTS models.
https://github.com/huggingface/parler-tts?tab=readme-ov-file#training

scripts_and_notebooks/Finetuning_Parler_TTS_v1_on_a_single_speaker_dataset.ipynb at main ¬∑ ylacombe/scripts_and_notebooks
https://github.com/ylacombe/scripts_and_notebooks/blob/main/Finetuning_Parler_TTS_v1_on_a_single_speaker_dataset.ipynb

@reach-vb on Hugging Face: "What an eventful day in Open Source LLMs today: Mistral released Codestral‚Ä¶"
https://huggingface.co/posts/reach-vb/328638870427201

mistralai/Mamba-Codestral-7B-v0.1 ¬∑ Hugging Face
https://huggingface.co/mistralai/Mamba-Codestral-7B-v0.1

HuggingFaceTB/SmolLM-135M ¬∑ Hugging Face
https://huggingface.co/HuggingFaceTB/SmolLM-135M

huggingface/dataspeech
https://github.com/huggingface/dataspeech?tab=readme-ov-file#how-do-i-use-datasets-that-i-have-with-this-repository

rhasspy/piper-voices ¬∑ Hugging Face
https://huggingface.co/rhasspy/piper-voices

rhasspy/piper: A fast, local neural text to speech system
https://github.com/rhasspy/piper?tab=readme-ov-file

piper/notebooks/pretrained_models.json at master ¬∑ rhasspy/piper
https://github.com/rhasspy/piper/blob/master/notebooks/pretrained_models.json

rhasspy/voice-datasets at main
https://huggingface.co/datasets/rhasspy/voice-datasets/tree/main

piper/TRAINING.md at master ¬∑ rhasspy/piper
https://github.com/rhasspy/piper/blob/master/TRAINING.md

piper gosia.zip - Google Search
https://www.google.com/search?q=piper+gosia.zip&rlz=1C5GCEM_enSE990SE991&oq=piper+gosia.zip&gs_lcrp=EgZjaHJvbWUyBggAEEUYOdIBCDQ1MjBqMGo3qAIAsAIA&sourceid=chrome&ie=UTF-8

MODEL_CARD ¬∑ csukuangfj/vits-piper-pl_PL-gosia-medium at main
https://huggingface.co/csukuangfj/vits-piper-pl_PL-gosia-medium/blob/main/MODEL_CARD

openslr.org
https://www.openslr.org/resources.php

openslr.org
https://www.openslr.org/83/

github.com
https://github.com/googlei18n/language-resources/issues

Santa Barbara Corpus of Spoken American English | Department of Linguistics - UC Santa Barbara
https://www.linguistics.ucsb.edu/research/santa-barbara-corpus

openslr.org
https://www.openslr.org/152/

openslr.org
https://www.openslr.org/148/

openslr.org
https://www.openslr.org/147/

openslr.org
https://www.openslr.org/142/

czyzi0/luna-speech-dataset ¬∑ Datasets at Hugging Face
https://huggingface.co/datasets/czyzi0/luna-speech-dataset/viewer/default/train?p=1

Korpus nagra≈Ñ pr√≥bek mowy do cel√≥w budowy modeli akustycznych dla automatycznego rozpoznawania mowy w jƒôzyku polskim, cz. 8 - AZON
https://zasobynauki.pl/zasoby/korpus-nagran-probek-mowy-do-celow-budowy-modeli-akustycznych-dla-automatycznego-rozpoznawania-mowy,56412/

openslr.org
https://www.openslr.org/146/

openslr.org
https://www.openslr.org/139/

openslr.org
https://www.openslr.org/136/

openslr.org
https://www.openslr.org/98/

torchaudio.datasets ‚Äî Torchaudio 2.4.0 documentation
https://pytorch.org/audio/stable/datasets.html

torch.hub ‚Äî PyTorch 2.4 documentation
https://pytorch.org/docs/stable/hub.html

Matcha-TTS/matcha/utils/rich_utils.py at main ¬∑ jimregan/Matcha-TTS
https://github.com/jimregan/Matcha-TTS/blob/main/matcha/utils/rich_utils.py

Matcha-TTS/matcha/utils/get_durations_from_trained_model.py at 77804265f877b0c42f13cfdece6541dde7838090 ¬∑ shivammehta25/Matcha-TTS
https://github.com/shivammehta25/Matcha-TTS/blob/77804265f877b0c42f13cfdece6541dde7838090/matcha/utils/get_durations_from_trained_model.py

hf-hub-lightning/examples/hf_hub_lightning_demo.ipynb at main ¬∑ nateraw/hf-hub-lightning
https://github.com/nateraw/hf-hub-lightning/blob/main/examples/hf_hub_lightning_demo.ipynb

Working with ".webm" files ¬∑ Issue #1723 ¬∑ pytorch/audio
https://github.com/pytorch/audio/issues/1723

python - Error in librosa.load('path.webm') RuntimeError: File contains data in an unknown format - Stack Overflow
https://stackoverflow.com/questions/73029952/error-in-librosa-loadpath-webm-runtimeerror-file-contains-data-in-an-unknow

sox_utils ‚Äî Torchaudio 2.5.0.dev20241001 documentation
https://pytorch.org/audio/main/generated/torchaudio.utils.sox_utils.html#torchaudio.utils.sox_utils.list_read_formats

ffmpeg_utils ‚Äî Torchaudio 2.5.0.dev20241001 documentation
https://pytorch.org/audio/main/generated/torchaudio.utils.ffmpeg_utils.html#torchaudio.utils.ffmpeg_utils.get_audio_decoders

sox_utils ‚Äî Torchaudio 2.5.0.dev20241001 documentation
https://pytorch.org/audio/main/generated/torchaudio.utils.sox_utils.html

PEP 263 ‚Äì Defining Python Source Code Encodings | peps.python.org
https://peps.python.org/pep-0263/

the motivation for inserting blank IDs between the input IPA-ids? ¬∑ Issue #94 ¬∑ shivammehta25/Matcha-TTS
https://github.com/shivammehta25/Matcha-TTS/issues/94

Dataset download/conversion by jimregan ¬∑ Pull Request #99 ¬∑ shivammehta25/Matcha-TTS
https://github.com/shivammehta25/Matcha-TTS/pull/99

AttributeError: module 'gradio' has no attribute 'Box' ¬∑ Issue #6815 ¬∑ gradio-app/gradio
https://github.com/gradio-app/gradio/issues/6815

Compare to VoiceFlow TTS ¬∑ Issue #66 ¬∑ shivammehta25/Matcha-TTS
https://github.com/shivammehta25/Matcha-TTS/issues/66

Matcha-TTS app error: symbol_id = _symbol_to_id[symbol] KeyError: '(' ¬∑ Issue #89 ¬∑ shivammehta25/Matcha-TTS
https://github.com/shivammehta25/Matcha-TTS/issues/89

Is there any experiment on Chinese data set. ¬∑ Issue #91 ¬∑ shivammehta25/Matcha-TTS
https://github.com/shivammehta25/Matcha-TTS/issues/91

save changes ¬∑ UlutSoftLLC/MamtilTTS@9c7460b
https://github.com/UlutSoftLLC/MamtilTTS/commit/9c7460b8d98995e3c6544c68d8a512350da15700#diff-7648f5f4cce4bf01d02de43f8c5f6f2130b787baece0cf6338210496d8bdfcdc

projecte-aina/matxa-tts-cat-multiaccent ¬∑ Hugging Face
https://huggingface.co/projecte-aina/matxa-tts-cat-multiaccent

projecte-aina/matxa-alvocat-tts-ca at main
https://huggingface.co/spaces/projecte-aina/matxa-alvocat-tts-ca/tree/main

Commits ¬∑ langtech-bsc/Matcha-TTS
https://github.com/langtech-bsc/Matcha-TTS/commits/multilang/

add config file for multilanguage experiment ¬∑ langtech-bsc/Matcha-TTS@450b990
https://github.com/langtech-bsc/Matcha-TTS/commit/450b99003619a6bde06b1f54d8a18c4a3d4537e0

add config file for multilanguage experiment ¬∑ langtech-bsc/Matcha-TTS@450b990
https://github.com/langtech-bsc/Matcha-TTS/commit/450b99003619a6bde06b1f54d8a18c4a3d4537e0#diff-b335630551682c19a781afebcf4d07bf978fb1f8ac04c6bf87428ed5106870f5R27

add inference script ¬∑ langtech-bsc/Matcha-TTS@4d3558d
https://github.com/langtech-bsc/Matcha-TTS/commit/4d3558d45bfd7e8207b6eca16dc53668e20d0b52

Commits ¬∑ langtech-bsc/Matcha-TTS
https://github.com/langtech-bsc/Matcha-TTS/commits/vocos

Commits ¬∑ langtech-bsc/Matcha-TTS
https://github.com/langtech-bsc/Matcha-TTS/commits/dev-cat-hf/

class method functions added to initialize matcha from HF model and c‚Ä¶ ¬∑ langtech-bsc/Matcha-TTS@4885b89
https://github.com/langtech-bsc/Matcha-TTS/commit/4885b8927a94afd692598dd868619c293b0ca0aa

Language Technologies Unit - BSC
https://github.com/langtech-bsc

Update cleaners.py ¬∑ langtech-bsc/Matcha-TTS@b2e6e1e
https://github.com/langtech-bsc/Matcha-TTS/commit/b2e6e1e87e1522753fdb5994671b8d3f25a1f115#diff-6b63d39c98fd1bc31e7d1dddd182dd3e91cd9682fd577f9c97add5ceeb4336aaR109

Update process_text on cli.py with catalan cleaners ¬∑ langtech-bsc/Matcha-TTS@e4d15b6
https://github.com/langtech-bsc/Matcha-TTS/commit/e4d15b681ea263462617e8c394b4bdb492ca8388

Hi-Fi-CAPTAIN | Releases | Advanced Speech Translation Research and Development Promotion Center | ASTREC | UCRI | NICT
https://ast-astrec.nict.go.jp/en/release/hi-fi-captain/

skirdey/voicerestore: VoiceRestore: Flow-Matching Transformers for Universal Speech Restoration
https://github.com/skirdey/voicerestore?tab=readme-ov-file

jadechoghari/VoiceRestore at main
https://huggingface.co/jadechoghari/VoiceRestore/tree/main

shivammehta25 (Shivam Mehta)
https://github.com/shivammehta25

shivammehta25/Matcha-TTS: [ICASSP 2024] üçµ Matcha-TTS: A fast TTS architecture with conditional flow matching
https://github.com/shivammehta25/Matcha-TTS#train-with-your-own-dataset

shivammehta25/CVPRHumogen
https://github.com/shivammehta25/CVPRHumogen

shivammehta25/Diff-TTSG: Diff-TTSG: Denoising probabilistic integrated speech and gesture synthesis
https://github.com/shivammehta25/Diff-TTSG

Matcha-TTS/matcha/utils/get_durations_from_trained_model.py at main ¬∑ shivammehta25/Matcha-TTS
https://github.com/shivammehta25/Matcha-TTS/blob/main/matcha/utils/get_durations_from_trained_model.py

Indian Language TTS Japanese Information - OSDN
https://osdn.net/projects/sfnet_tts-indianlang/

VCTK
https://datashare.ed.ac.uk/handle/10283/2950

datashare.ed.ac.uk/bitstream/handle/10283/3443/README.txt?sequence=1&isAllowed=y
https://datashare.ed.ac.uk/bitstream/handle/10283/3443/README.txt?sequence=1&isAllowed=y

microsoft/MS-SNSD: The Microsoft Scalable Noisy Speech Dataset (MS-SNSD) is a noisy speech dataset that can scale to arbitrary sizes depending on the number of speakers, noise types, and Speech to Noise Ratio (SNR) levels desired.
https://github.com/microsoft/MS-SNSD?tab=readme-ov-file

Noisy speech database for training speech enhancement algorithms and TTS models
https://datashare.ed.ac.uk/handle/10283/2791

datashare.ed.ac.uk/bitstream/handle/10283/343/readme_acted_clear_speech.txt?sequence=1&isAllowed=y
https://datashare.ed.ac.uk/bitstream/handle/10283/343/readme_acted_clear_speech.txt?sequence=1&isAllowed=y

How to calculate the MD5 checksum of a file in Python? - Stack Overflow
https://stackoverflow.com/questions/16874598/how-to-calculate-the-md5-checksum-of-a-file-in-python

shivammehta25/Matcha-TTS: [ICASSP 2024] üçµ Matcha-TTS: A fast TTS architecture with conditional flow matching
https://github.com/shivammehta25/Matcha-TTS

text-normalization/txt_files/expand_Connemara.txt at main ¬∑ phonlab-tcd/text-normalization
https://github.com/phonlab-tcd/text-normalization/blob/main/txt_files/expand_Connemara.txt

espeak-ng/dictsource/ga_rules at master ¬∑ espeak-ng/espeak-ng
https://github.com/espeak-ng/espeak-ng/blob/master/dictsource/ga_rules

Match-TTSG/match_ttsg/utils/audio.py at main ¬∑ shivammehta25/Match-TTSG
https://github.com/shivammehta25/Match-TTSG/blob/main/match_ttsg/utils/audio.py

An E2E-ASR-Based Iteratively-Trained Timestamp Estimator | IEEE Journals & Magazine | IEEE Xplore
https://ieeexplore.ieee.org/document/9829287

2306.11473
https://arxiv.org/pdf/2306.11473

Contextualization of ASR with LLM Using Phonetic Retrieval-Based Augmentation - Apple Machine Learning Research
https://machinelearning.apple.com/research/asr-contextualization

[2409.15353] Contextualization of ASR with LLM using phonetic retrieval-based augmentation
https://arxiv.org/abs/2409.15353

Personalization of CTC-based End-to-End Speech Recognition Using Pronunciation-Driven Subword Tokenization - Apple Machine Learning Research
https://machinelearning.apple.com/research/ctc-based

Matcha-TTS/matcha/models/components/text_encoder.py at main ¬∑ shivammehta25/Matcha-TTS
https://github.com/shivammehta25/Matcha-TTS/blob/main/matcha/models/components/text_encoder.py

Match-TTSG/match_ttsg/models/components/text_encoder.py at main ¬∑ shivammehta25/Match-TTSG
https://github.com/shivammehta25/Match-TTSG/blob/main/match_ttsg/models/components/text_encoder.py

skeleton rotation dual quaternion - Google Search
https://www.google.com/search?q=skeleton+rotation+dual+quaternion&rlz=1C5GCEM_enSE990SE991&oq=skeleton+rotation+dual+quaternion&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIHCAEQIRigATIHCAIQIRigATIHCAMQIRifBTIHCAQQIRifBTIHCAUQIRifBTIHCAYQIRifBTIHCAcQIRifBTIHCAgQIRifBdIBCTEwMzU2ajBqN6gCALACAA&sourceid=chrome&ie=UTF-8

ishmeetkohli/dualQuaternionSkinning: Skeletal Animation with Dual Quaternion Skinning and Linear Blend Skinning
https://github.com/ishmeetkohli/dualQuaternionSkinning

YunjinPark/awesome_talking_face_generation
https://github.com/YunjinPark/awesome_talking_face_generation?tab=readme-ov-file

GeneFacePlusPlus/Dockerfile.genface at main ¬∑ yerfor/GeneFacePlusPlus
https://github.com/yerfor/GeneFacePlusPlus/blob/main/Dockerfile.genface

github.com
https://github.com/Doubiiu/CodeTalker

open-mmlab/mmpose: OpenMMLab Pose Estimation Toolbox and Benchmark.
https://github.com/open-mmlab/mmpose?tab=readme-ov-file

mmpose/projects/just_dance at main ¬∑ open-mmlab/mmpose
https://github.com/open-mmlab/mmpose/tree/main/projects/just_dance

mmpose/projects/yolox_pose at main ¬∑ open-mmlab/mmpose
https://github.com/open-mmlab/mmpose/tree/main/projects/yolox_pose

open-mmlab/mmdetection: OpenMMLab Detection Toolbox and Benchmark
https://github.com/open-mmlab/mmdetection

Dataset Annotation and Format Conversion ‚Äî MMPose 1.3.2 documentation
https://mmpose.readthedocs.io/en/latest/user_guides/dataset_tools.html

open-mmlab/mmpose: OpenMMLab Pose Estimation Toolbox and Benchmark.
https://github.com/open-mmlab/mmpose?tab=readme-ov-file

mmpose/projects/rtmpose3d/rtmpose3d/pose_estimator.py at main ¬∑ open-mmlab/mmpose
https://github.com/open-mmlab/mmpose/blob/main/projects/rtmpose3d/rtmpose3d/pose_estimator.py

Openpose Alternatives and Reviews
https://www.libhunt.com/r/openpose

Mediapipe Alternatives and Reviews
https://www.libhunt.com/r/mediapipe

Freemocap Alternatives and Reviews
https://www.libhunt.com/r/freemocap

KevinLTT/video2bvh: Extracts human motion in video and save it as bvh mocap file.
https://github.com/KevinLTT/video2bvh

3d pose estimation from video - Google Search
https://www.google.com/search?q=3d+pose+estimation+from+video&rlz=1C5GCEM_enSE990SE991&oq=3d+pose+estimation+from+video&gs_lcrp=EgZjaHJvbWUyDwgAEEUYORiRAhiABBiKBTIICAEQABgWGB4yCAgCEAAYFhgeMg0IAxAAGIYDGIAEGIoFMg0IBBAAGIYDGIAEGIoFMg0IBRAAGIYDGIAEGIoFMgoIBhAAGIAEGKIEMgoIBxAAGIAEGKIEMgoICBAAGIAEGKIEMgoICRAAGIAEGKIE0gEIODcwMWowajeoAgCwAgA&sourceid=chrome&ie=UTF-8

OpenMMLab
https://github.com/open-mmlab

open-mmlab/Amphion: Amphion (/√¶mÀàfa…™…ôn/) is a toolkit for Audio, Music, and Speech Generation. Its purpose is to support reproducible research and help junior researchers and engineers get started in the field of audio, music, and speech generation research and development.
https://github.com/open-mmlab/Amphion

open-mmlab/mmpose: OpenMMLab Pose Estimation Toolbox and Benchmark.
https://github.com/open-mmlab/mmpose?tab=readme-ov-file

Implement New Models ‚Äî MMPose 1.3.2 documentation
https://mmpose.readthedocs.io/en/latest/advanced_guides/implement_new_models.html

Demos ‚Äî MMPose 1.3.2 documentation
https://mmpose.readthedocs.io/en/latest/demos.html

Label Studio
http://130.237.3.107:8080/projects/5/data?tab=5&task=71

X-LANCE/VoiceFlow-TTS: [ICASSP 2024] This is the official code for "VoiceFlow: Efficient Text-to-Speech with Rectified Flow Matching"
https://github.com/X-LANCE/VoiceFlow-TTS?tab=readme-ov-file

X-LANCE/UniCATS-CTX-vec2wav: [AAAI 2024] Code for CTX-vec2wav in UniCATS
https://github.com/X-LANCE/UniCATS-CTX-vec2wav

2005.11129
https://arxiv.org/pdf/2005.11129

Revai/reverb-diarization-v2 ¬∑ Hugging Face
https://huggingface.co/Revai/reverb-diarization-v2

reverb/asr/wenet/bin/recognize_wav.py at main ¬∑ revdotcom/reverb
https://github.com/revdotcom/reverb/blob/main/asr/wenet/bin/recognize_wav.py

wenet/examples/openasr2021/s0 at main ¬∑ wenet-e2e/wenet
https://github.com/wenet-e2e/wenet/tree/main/examples/openasr2021/s0

Revai/reverb-asr at main
https://huggingface.co/Revai/reverb-asr/tree/main

revdotcom/reverb: Open source inference code for Rev's model
https://github.com/revdotcom/reverb

Reverb ASR Demo - a Hugging Face Space by Revai
https://huggingface.co/spaces/Revai/reverb-asr-demo

fstalign/docs/NLP-Format.md at develop ¬∑ revdotcom/fstalign
https://github.com/revdotcom/fstalign/blob/develop/docs//NLP-Format.md#wer-tag-sidecar

speech-datasets/earnings22/README.md at main ¬∑ revdotcom/speech-datasets
https://github.com/revdotcom/speech-datasets/blob/main/earnings22/README.md

words2num/words2num/lang_EN_US.py at master ¬∑ revdotcom/words2num
https://github.com/revdotcom/words2num/blob/master/words2num/lang_EN_US.py

wenet-e2e/WenetSpeech: A 10000+ hours dataset for Chinese speech recognition
https://github.com/wenet-e2e/WenetSpeech

wenet/wenet/transformer/search.py at main ¬∑ wenet-e2e/wenet
https://github.com/wenet-e2e/wenet/blob/main/wenet/transformer/search.py

hlt-mt/mosel: Collection of Open Source Speech Data
https://github.com/hlt-mt/mosel?tab=readme-ov-file

EU Parliament Speech corpus
https://clarin-pl.eu/dspace/handle/11321/821

Blog ‚Äì PINC Project
https://pincproject2020.wordpress.com/blog/

sphinx4/sphinx4-core/src/main/java/edu/cmu/sphinx/jsgf at master ¬∑ cmusphinx/sphinx4
https://github.com/cmusphinx/sphinx4/tree/master/sphinx4-core/src/main/java/edu/cmu/sphinx/jsgf

cmusphinx/sphinxbase
https://github.com/cmusphinx/sphinxbase

abus-aikorea/voice-pro: The best gradio web-ui for ai transcription, translation and TTS. Automatic subtitle creation using faster whisper. Easy one click installation. Fully portable.
https://github.com/abus-aikorea/voice-pro?tab=readme-ov-file

facebookresearch/demucs: Code for the paper Hybrid Spectrogram and Waveform Source Separation
https://github.com/facebookresearch/demucs?tab=readme-ov-file

Demucs v3 Has been fully added to the UVR GUI! ¬∑ Issue #334 ¬∑ facebookresearch/demucs
https://github.com/facebookresearch/demucs/issues/334

Anjok07/ultimatevocalremovergui: GUI for a Vocal Remover that uses Deep Neural Networks.
https://github.com/Anjok07/ultimatevocalremovergui#installation

pocketsphinx ¬∑ PyPI
https://pypi.org/project/pocketsphinx/

pocketsphinx/examples/simple.py at master ¬∑ cmusphinx/pocketsphinx
https://github.com/cmusphinx/pocketsphinx/blob/master/examples/simple.py

Main pocketsphinx package ‚Äî PocketSphinx 5.0.3 documentation
https://pocketsphinx.readthedocs.io/en/latest/pocketsphinx.html#pocketsphinx.FsgModel

weather stockholm - Google Search
https://www.google.com/search?q=weather+stockholm&rlz=1C5GCEM_enSE990SE991&oq=weather+stoc&gs_lcrp=EgZjaHJvbWUqDAgAECMYJxiABBiKBTIMCAAQIxgnGIAEGIoFMgYIARBFGDkyDAgCECMYJxiABBiKBTIHCAMQABiABDIHCAQQABiABDIGCAUQRRg8MgYIBhBFGDwyBggHEEUYPNIBCDE3NzRqMGo3qAIAsAIA&sourceid=chrome&ie=UTF-8

pocketsphinx python fsg - Google Search
https://www.google.com/search?q=pocketsphinx+python+fsg&rlz=1C5GCEM_enSE990SE991&oq=pocketsphinx&gs_lcrp=EgZjaHJvbWUqBggAEEUYOzIGCAAQRRg7MgYIARBFGDkyBggCEEUYQDIGCAMQRRg8MgYIBBBFGDwyBggFEEUYPDIGCAYQRRg8MgYIBxBFGDzSAQgxNTk1ajBqN6gCALACAA&sourceid=chrome&ie=UTF-8

Pocketsphinx for Pronunication Evaluation ‚Äì CMUSphinx Open Source Speech Recognition
https://cmusphinx.github.io/wiki/pocketsphinx_pronunciation_evaluation/

JSpeech Grammar Format
https://www.w3.org/TR/2000/NOTE-jsgf-20000605/

jsgf openfst - Google Search
https://www.google.com/search?q=jsgf+openfst&rlz=1C5GCEM_enSE990SE991&oq=jsgf+openfst&gs_lcrp=EgZjaHJvbWUyBggAEEUYOdIBCDM2NTBqMGo3qAIAsAIA&sourceid=chrome&ie=UTF-8

jsgf2fst/jsgf2fst/jsgf2fst.py at master ¬∑ synesthesiam/jsgf2fst
https://github.com/synesthesiam/jsgf2fst/blob/master/jsgf2fst/jsgf2fst.py

danesprite
https://danesprite/pyjsgf

Can Kaldi decode in the JSGFGrammar way like sphinx?
https://groups.google.com/g/kaldi-help/c/9r6mea7aJVc

Geeky Stuff: Decoding graph construction in Kaldi: A visual walkthrough
https://vpanayotov.blogspot.com/2012/06/kaldi-decoding-graph-construction.html

huggingface transformers cache - Google Search
https://www.google.com/search?q=huggingface+transformers+cache&rlz=1C5GCEM_enSE990SE991&oq=huggingface+transformers+cache&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIHCAEQABiABDIICAIQABgWGB4yCAgDEAAYFhgeMggIBBAAGBYYHjINCAUQABiGAxiABBiKBTINCAYQABiGAxiABBiKBTIKCAcQABiABBiiBDIKCAgQABiABBiiBDIKCAkQABiABBiiBNIBCTEwNzkwajBqN6gCALACAA&sourceid=chrome&ie=UTF-8

Cache management
https://huggingface.co/docs/datasets/en/cache

OscarVanL/LibriTTS-British-Accents: A subset of the popular LibriTTS dataset with subsets for English, Scottish, Welsh, and Irish accents.
https://github.com/OscarVanL/LibriTTS-British-Accents?tab=readme-ov-file

LibriTTS-British-Accents/SPEAKERS_ENGLISH.txt at master ¬∑ OscarVanL/LibriTTS-British-Accents
https://github.com/OscarVanL/LibriTTS-British-Accents/blob/master/SPEAKERS_ENGLISH.txt

Accents Table - Librivox wiki
https://wiki.librivox.org/index.php/Accents_Table

Other British Readers on LibriVox | RuthieG's CataBlog
https://golding.wordpress.com/home/other-british-readers-on-librivox/

Git LFS data quota exceeded ¬∑ Issue #1 ¬∑ OscarVanL/LibriTTS-British-Accents
https://github.com/OscarVanL/LibriTTS-British-Accents/issues/1

LLaVa
https://huggingface.co/docs/transformers/en/model_doc/llava

haotian-liu/LLaVA: [NeurIPS'23 Oral] Visual Instruction Tuning (LLaVA) built towards GPT-4V level capabilities and beyond.
https://github.com/haotian-liu/LLaVA?tab=readme-ov-file

LLaVA/docs/MODEL_ZOO.md at main ¬∑ haotian-liu/LLaVA
https://github.com/haotian-liu/LLaVA/blob/main/docs/MODEL_ZOO.md

liuhaotian/llava-v1.6-34b at main
https://huggingface.co/liuhaotian/llava-v1.6-34b/tree/main

README.md ¬∑ liuhaotian/llava-v1.6-vicuna-7b at main
https://huggingface.co/liuhaotian/llava-v1.6-vicuna-7b/blob/main/README.md

README.md ¬∑ liuhaotian/llava-v1.6-mistral-7b at main
https://huggingface.co/liuhaotian/llava-v1.6-mistral-7b/blob/main/README.md

facebookresearch/dino: PyTorch code for Vision Transformers training with the Self-Supervised learning method DINO
https://github.com/facebookresearch/dino

Models - Hugging Face
https://huggingface.co/models?other=dino

llama.cpp/examples/llava/README.md at master ¬∑ ggerganov/llama.cpp
https://github.com/ggerganov/llama.cpp/blob/master/examples/llava/README.md

Best llava architecture models - a cmp-nct Collection
https://huggingface.co/collections/cmp-nct/best-llava-architecture-models-656cc7273dbac3a83d241e79

xtuner/llava-llama-3-8b-v1_1-hf ¬∑ Hugging Face
https://huggingface.co/xtuner/llava-llama-3-8b-v1_1-hf

white lie crossed fingers polish - Google Search
https://www.google.com/search?q=white+lie+crossed+fingers+polish&rlz=1C5GCEM_enSE990SE991&oq=white+lie+crossed+fingers+polish&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIHCAEQIRigAdIBCTEyNDI0ajBqNKgCALACAQ&sourceid=chrome&ie=UTF-8

Crossed fingers - Wikipedia
https://en.wikipedia.org/wiki/Crossed_fingers

cross one's fingers - Wiktionary, the free dictionary
https://en.wiktionary.org/wiki/cross_one%27s_fingers

cross one's fingers - Wiktionary
https://sv.wiktionary.org/wiki/cross_one%27s_fingers

pit√§√§ peukkua - Wiktionary, the free dictionary
https://en.wiktionary.org/wiki/pit%C3%A4%C3%A4_peukkua#Finnish

shivammehta25/Matcha-TTS: [ICASSP 2024] üçµ Matcha-TTS: A fast TTS architecture with conditional flow matching
https://github.com/shivammehta25/Matcha-TTS

Transformers.js
https://huggingface.co/docs/transformers.js/en/index

huggingface/optimum: üöÄ Accelerate training and inference of ü§ó Transformers and ü§ó Diffusers with easy to use hardware optimization tools
https://github.com/huggingface/optimum#onnx--onnx-runtime

ONNX Runtime | Home
https://onnxruntime.ai/

transformers.js/examples/text-to-speech-client/src/worker.js at main ¬∑ xenova/transformers.js
https://github.com/xenova/transformers.js/blob/main/examples/text-to-speech-client/src/worker.js

transformers.js/src/models.js at main ¬∑ xenova/transformers.js
https://github.com/xenova/transformers.js/blob/main/src/models.js#L2185

WavLMForAudioFrameClassification - Google Search
https://www.google.com/search?q=WavLMForAudioFrameClassification&rlz=1C5GCEM_enSE990SE991&oq=WavLMForAudioFrameClassification&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIKCAEQABiABBiiBDIKCAIQABiABBiiBDIKCAMQABiABBiiBDIKCAQQABiABBiiBDIKCAUQABiABBiiBNIBBzQxMmowajeoAgCwAgA&sourceid=chrome&ie=UTF-8

Finetuning AudioFrameClassification model ¬∑ Issue #17509 ¬∑ huggingface/transformers
https://github.com/huggingface/transformers/issues/17509

transformers/src/transformers/models/wavlm/modeling_wavlm.py at main ¬∑ huggingface/transformers
https://github.com/huggingface/transformers/blob/main/src/transformers/models/wavlm/modeling_wavlm.py

microsoft/wavlm-base-plus-sd ¬∑ Hugging Face
https://huggingface.co/microsoft/wavlm-base-plus-sd

Models - Hugging Face
https://huggingface.co/models?other=wavlm&p=1&sort=trending

lgris/WavLM-large-CORAA-pt ¬∑ Hugging Face
https://huggingface.co/lgris/WavLM-large-CORAA-pt

microsoft/wavlm-base-sv ¬∑ Hugging Face
https://huggingface.co/microsoft/wavlm-base-sv

wrice/wavlm-large-timit-punctuation ¬∑ Hugging Face
https://huggingface.co/wrice/wavlm-large-timit-punctuation

jonatasgrosman/exp_w2v2t_sv-se_wavlm_s132 ¬∑ Hugging Face
https://huggingface.co/jonatasgrosman/exp_w2v2t_sv-se_wavlm_s132

UniSpeech/LICENSE at main ¬∑ microsoft/UniSpeech
https://github.com/microsoft/UniSpeech/blob/main/LICENSE

wavlm adapt languag - Google Search
https://www.google.com/search?q=wavlm+adapt+languag&rlz=1C5GCEM_enSE990SE991&oq=wavlm+adapt+languag&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIJCAEQIRgKGKABMgkIAhAhGAoYoAEyCQgDECEYChigAdIBCDU3MDNqMGo3qAIAsAIA&sourceid=chrome&ie=UTF-8

[2405.04485] Adapting WavLM for Speech Emotion Recognition
https://arxiv.org/abs/2405.04485

sinhat98/adapter-wavlm
https://github.com/sinhat98/adapter-wavlm

WavLm Complete Guide
https://blog.unrealspeech.com/wavlm-complete-guide/

504 Gateway Time-out
https://fxis.ai/edu/how-to-implement-the-wavlm-model-a-beginners-guide/

unilm/wavlm/README.md at master ¬∑ microsoft/unilm
https://github.com/microsoft/unilm/blob/master/wavlm/README.md

tuben github - Google Search
https://www.google.com/search?q=tuben+github&rlz=1C5GCEM_enSE990SE991&oq=tuben+github&gs_lcrp=EgZjaHJvbWUyBggAEEUYOdIBCDM5NTlqMGo3qAIAsAIA&sourceid=chrome&ie=UTF-8

shun60s/Vocal-Tube-Model: a very simple vocal tract model, few tube model. generate vowel sound by it
https://github.com/shun60s/Vocal-Tube-Model?tab=readme-ov-file

shun60s/vocal-tract-tube-model-list: repositories table related to vocal tract tube model.
https://github.com/shun60s/vocal-tract-tube-model-list/?tab=readme-ov-file

shun60s/Tube-Model-GUI: A GUI to control three tube resonance model via tkinter.
https://github.com/shun60s/Tube-Model-GUI

vase - Wiktionary, the free dictionary
https://en.wiktionary.org/wiki/vase#English

YouTube
https://www.youtube.com/

The Biceps Training Revolution (MUCH Better Exercises Explained) - YouTube
https://www.youtube.com/watch?v=hoAczB-xAYk

Brendan O'Brien Interview: The Unsung Hero Of Rock Music - YouTube
https://www.youtube.com/watch?v=FfoOvO6Xguw&t=33s

Phoneme Recognition (caveat emptor) ‚Äì CMUSphinx Open Source Speech Recognition
https://cmusphinx.github.io/wiki/phonemerecognition/

Pull requests ¬∑ cmusphinx/pocketsphinx
https://github.com/cmusphinx/pocketsphinx/pulls?q=is%3Apr+is%3Aclosed

pocketsphinx/src/ps_config.c at master ¬∑ cmusphinx/pocketsphinx
https://github.com/cmusphinx/pocketsphinx/blob/master/src/ps_config.c#L53

how to train sentences inside model ¬∑ Issue #225 ¬∑ cmusphinx/pocketsphinx
https://github.com/cmusphinx/pocketsphinx/issues/225

Nobel Peace Prize - Wikipedia
https://en.wikipedia.org/wiki/Nobel_Peace_Prize

Configuration parameters ‚Äî PocketSphinx 5.0.3 documentation
https://pocketsphinx.readthedocs.io/en/latest/config_params.html

Main pocketsphinx package ‚Äî PocketSphinx 5.0.3 documentation
https://pocketsphinx.readthedocs.io/en/latest/pocketsphinx.html

Code search results
https://github.com/search?q=repo%3Acmusphinx%2Fpocketsphinx%20allphone&type=code

pocketsphinx/cython/_pocketsphinx.pyx at 7d375e136d2c6fa4f4c024f19526b3cbc056e8f6 ¬∑ cmusphinx/pocketsphinx
https://github.com/cmusphinx/pocketsphinx/blob/7d375e136d2c6fa4f4c024f19526b3cbc056e8f6/cython/_pocketsphinx.pyx#L1391

pocketsphinx/docs/source/config_params.rst at 7d375e136d2c6fa4f4c024f19526b3cbc056e8f6 ¬∑ cmusphinx/pocketsphinx
https://github.com/cmusphinx/pocketsphinx/blob/7d375e136d2c6fa4f4c024f19526b3cbc056e8f6/docs/source/config_params.rst#L27

pocketsphinx/doxygen/pocketsphinx.1 at 7d375e136d2c6fa4f4c024f19526b3cbc056e8f6 ¬∑ cmusphinx/pocketsphinx
https://github.com/cmusphinx/pocketsphinx/blob/7d375e136d2c6fa4f4c024f19526b3cbc056e8f6/doxygen/pocketsphinx.1#L121

pocketsphinx/src/config_macro.h at 7d375e136d2c6fa4f4c024f19526b3cbc056e8f6 ¬∑ cmusphinx/pocketsphinx
https://github.com/cmusphinx/pocketsphinx/blob/7d375e136d2c6fa4f4c024f19526b3cbc056e8f6/src/config_macro.h#L242

pocketsphinx/test/unit/test_allphone.c at 7d375e136d2c6fa4f4c024f19526b3cbc056e8f6 ¬∑ cmusphinx/pocketsphinx
https://github.com/cmusphinx/pocketsphinx/blob/7d375e136d2c6fa4f4c024f19526b3cbc056e8f6/test/unit/test_allphone.c#L19

pocketsphinx/cython/test/phoneme_test.py at 7d375e136d2c6fa4f4c024f19526b3cbc056e8f6 ¬∑ cmusphinx/pocketsphinx
https://github.com/cmusphinx/pocketsphinx/blob/7d375e136d2c6fa4f4c024f19526b3cbc056e8f6/cython/test/phoneme_test.py#L13

pocketsphinx/cython/test/pypocketsphinx_test.py at 7d375e136d2c6fa4f4c024f19526b3cbc056e8f6 ¬∑ cmusphinx/pocketsphinx
https://github.com/cmusphinx/pocketsphinx/blob/7d375e136d2c6fa4f4c024f19526b3cbc056e8f6/cython/test/pypocketsphinx_test.py#L169


