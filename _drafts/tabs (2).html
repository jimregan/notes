<html><head></head><body><a href="https://github.com/bytedance/SALMONN?tab=readme-ov-file">bytedance/SALMONN: SALMONN: Speech Audio Language Music Open Neural Network</a><br/><a href="https://github.com/bytedance/SALMONN/blob/main/video_salmonn/README.md">SALMONN/video_salmonn/README.md at main ¬∑ bytedance/SALMONN</a><br/><a href="https://huggingface.co/tsinghua-ee/Video-SALMONN">tsinghua-ee/Video-SALMONN ¬∑ Hugging Face</a><br/><a href="https://www.nb.no/sbfil/dok/nst_taledat_se.pdf">nst_taledat_se.pdf</a><br/><a href="https://github.com/JaidedAI/EasyOCR?tab=readme-ov-file">JaidedAI/EasyOCR: Ready-to-use OCR with 80+ supported languages and all popular writing scripts including Latin, Chinese, Arabic, Devanagari, Cyrillic and etc.</a><br/><a href="https://github.com/clovaai/deep-text-recognition-benchmark">clovaai/deep-text-recognition-benchmark: Text recognition (optical character recognition) with deep learning methods, ICCV 2019</a><br/><a href="https://github.com/JaidedAI/EasyOCR/tree/master/trainer">EasyOCR/trainer at master ¬∑ JaidedAI/EasyOCR ¬∑ GitHub</a><br/><a href="https://github.com/JaidedAI/EasyOCR/blob/master/trainer/trainer.ipynb">EasyOCR/trainer/trainer.ipynb at master ¬∑ JaidedAI/EasyOCR ¬∑ GitHub</a><br/><a href="https://github.com/JaidedAI/EasyOCR/blob/master/trainer/config_files/en_filtered_config.yaml">EasyOCR/trainer/config_files/en_filtered_config.yaml at master ¬∑ JaidedAI/EasyOCR ¬∑ GitHub</a><br/><a href="https://x.com/AdeenaY8/status/1803006922674557108">Adina Yakup on X: "Open-Sora 1.2 is outüî• Open-Sora is an initiative dedicated to efficiently producing high-quality video in open-source way , released by @HPCAITech üëè Model: https://t.co/9gJB6iLGLC Demo: https://t.co/npE3DeXbFo ‚ú® Video compression network ‚ú®Rectifie-flow training ‚ú®More data" / X</a><br/><a href="https://x.com/xiaolonw/status/1810387662060269668">(2) Xiaolong Wang on X: "Cannot believe this finally happened! Over the last 1.5 years, we have been developing a new LLM architecture, with linear complexity and expressive hidden states, for long-context modeling. The following plots show our model trained from Books scale better (from 125M to 1.3B) https://t.co/Ku0oi8vqvX" / X</a><br/><a href="https://www.sscardapane.it/assets/alice/Alice_book_volume_1.pdf">Alice_book_volume_1.pdf</a><br/><a href="https://research.google/blog/spoken-question-answering-and-speech-continuation-using-a-spectrogram-powered-llm/">Spoken question answering and speech continuation using a spectrogram-powered LL</a><br/><a href="https://github.com/lucidrains?tab=repositories">lucidrains (lucidrains) / Repositories</a><br/><a href="https://github.com/lucidrains/PEER-pytorch/blob/main/PEER_pytorch/PEER.py">PEER-pytorch/PEER_pytorch/PEER.py at main ¬∑ lucidrains/PEER-pytorch</a><br/><a href="https://github.com/lucidrains/byol-pytorch">lucidrains/byol-pytorch: Usable Implementation of "Bootstrap Your Own Latent" self-supervised learning, from Deepmind, in Pytorch</a><br/><a href="https://github.com/lucidrains/ring-attention-pytorch">lucidrains/ring-attention-pytorch: Implementation of üíç Ring Attention, from Liu et al. at Berkeley AI, in Pytorch</a><br/><a href="https://github.com/lucidrains/meshgpt-pytorch">lucidrains/meshgpt-pytorch: Implementation of MeshGPT, SOTA Mesh generation using Attention, in Pytorch</a><br/><a href="https://github.com/lucidrains/e2-tts-pytorch">lucidrains/e2-tts-pytorch: Implementation of E2-TTS, "Embarrassingly Easy Fully Non-Autoregressive Zero-Shot TTS", in Pytorch</a><br/><a href="https://arxiv.org/pdf/2312.02902">2312.02902</a><br/><a href="https://www.feynmanlectures.caltech.edu/I_43.html">The Feynman Lectures on Physics Vol. I Ch. 43: Diffusion</a><br/><a href="https://numpy.org/doc/stable/user/basics.indexing.html">numpy.org</a><br/><a href="https://numpy.org/doc/stable/user/basics.broadcasting.html">Broadcasting ‚Äî NumPy v2.0 Manual</a><br/><a href="https://einops.rocks/">Einops</a><br/><a href="https://openreview.net/pdf?id=oapKSVM2bcj">pdf</a><br/><a href="https://github.com/arogozhnikov/einops/blob/master/docs/1-einops-basics.ipynb">einops/docs/1-einops-basics.ipynb at master ¬∑ arogozhnikov/einops ¬∑ GitHub</a><br/><a href="https://github.com/arogozhnikov/einops/blob/master/docs/3-einmix-layer.ipynb">einops/docs/3-einmix-layer.ipynb at master ¬∑ arogozhnikov/einops ¬∑ GitHub</a><br/><a href="https://rockt.github.io/2018/04/30/einsum">Tim Rockt√§schel</a><br/><a href="https://pytorch.org/blog/tensor-comprehensions/">Tensor Comprehensions in PyTorch | PyTorch</a><br/><a href="https://facebookresearch.github.io/TensorComprehensions/introduction.html">What is Tensor Comprehensions? ‚Äî Tensor Comprehensions v0.1.1 documentation</a><br/><a href="https://github.com/facebookresearch/TensorComprehensions/blob/master/tc/core/cuda/cuda_libraries.h#L67">TensorComprehensions/tc/core/cuda/cuda_libraries.h at master ¬∑ facebookresearch/TensorComprehensions ¬∑ GitHub</a><br/><a href="https://theaisummer.com/einsum-attention/">Understanding einsum for Deep learning: implement a transformer with multi-head self-attention from scratch | AI Summer</a><br/><a href="https://github.com/arogozhnikov/einops/blob/master/docs/2-einops-for-deep-learning.ipynb">einops/docs/2-einops-for-deep-learning.ipynb at master ¬∑ arogozhnikov/einops ¬∑ GitHub</a><br/><a href="https://www.google.com/search?q=tensor+comprehension+pytorch&sca_esv=2f3821052c9136cf&sca_upv=1&rlz=1C5GCEM_enSE990SE991&biw=1440&bih=721&sxsrf=ADLYWIIIY4CFWtcoSfPqkmpdPvDIqql8rg%3A1720537602473&ei=AlKNZpu9HICTwPAP2dS_KA&oq=tensor+comprehensions+&gs_lp=Egxnd3Mtd2l6LXNlcnAiFnRlbnNvciBjb21wcmVoZW5zaW9ucyAqAggBMgYQABgWGB4yBhAAGBYYHjILEAAYgAQYhgMYigUyCxAAGIAEGIYDGIoFMgsQABiABBiGAxiKBTILEAAYgAQYhgMYigUyCBAAGIAEGKIEMggQABiABBiiBDIIEAAYgAQYogQyCBAAGIAEGKIESMIRUCFYIXABeAGQAQCYAXSgAXSqAQMwLjG4AQPIAQD4AQGYAgKgAn3CAgoQABiwAxjWBBhHmAMAiAYBkAYFkgcDMS4xoAfrBg&sclient=gws-wiz-serp">tensor comprehension pytorch - Google Search</a><br/><a href="https://github.com/facebookresearch/TensorComprehensions">GitHub - facebookresearch/TensorComprehensions: A domain specific language to express machine learning workloads.</a><br/><a href="https://github.com/HazyResearch/flash-fft-conv">GitHub - HazyResearch/flash-fft-conv: FlashFFTConv: Efficient Convolutions for Long Sequences with Tensor Cores</a><br/><a href="https://github.com/PolyAI-LDN/pheme">GitHub - PolyAI-LDN/pheme</a><br/><a href="https://github.com/PolyAI-LDN/pheme">GitHub - PolyAI-LDN/pheme</a><br/><a href="https://huggingface.co/fnlp/SpeechTokenizer">fnlp/SpeechTokenizer ¬∑ Hugging Face</a><br/><a href="https://github.com/0nutation/SpeechGPT">0nutation/SpeechGPT: SpeechGPT Series: Speech Large Language Models</a><br/><a href="https://github.com/0nutation/USLM/blob/main/models/uslm.py">USLM/models/uslm.py at main ¬∑ 0nutation/USLM</a><br/><a href="https://github.com/0nutation/SpeechGPT?tab=readme-ov-file">0nutation/SpeechGPT: SpeechGPT Series: Speech Large Language Models</a><br/><a href="https://github.com/ZhangXInFD/soundstorm-speechtokenizer?tab=readme-ov-file">ZhangXInFD/soundstorm-speechtokenizer: Implementation of SoundStorm built upon SpeechTokenizer.</a><br/><a href="https://huggingface.co/spaces/PolyAI/pheme">Pheme - a Hugging Face Space by PolyAI</a><br/><a href="https://github.com/facebookresearch/seamless_communication/commit/6073b25982ecc4dcd2971dd52ebbfeadf12016bc">Segment audio with Silero VAD and pipeline with Transcriber (#406) ¬∑ facebookresearch/seamless_communication@6073b25</a><br/><a href="https://sverigesradio.se/kanaler">Channels | Swedish Radio</a><br/><a href="https://sverigesradio.se/tabla.aspx?programid=211">P4 Kristianstad | Swedens radio</a><br/><a href="https://stackoverflow.com/questions/51292027/how-to-schedule-a-task-in-asyncio-so-it-runs-at-a-certain-date">python - How to schedule a task in asyncio so it runs at a certain date? - Stack Overflow</a><br/><a href="https://genai-handbook.github.io/">GenAI Handbook</a><br/><a href="https://www.youtube.com/watch?v=9vKqVkMQHKk&list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr&index=4">The paradox of the derivative | Chapter 2, Essence of calculus - YouTube</a><br/><a href="https://www.youtube.com/watch?v=kYB8IZa5AuE&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab&index=4">Linear transformations and matrices | Chapter 3, Essence of linear algebra - YouTube</a><br/><a href="https://www.youtube.com/watch?v=9vKqVkMQHKk&list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr&index=4">The paradox of the derivative | Chapter 2, Essence of calculus - YouTube</a><br/><a href="https://github.com/mlabonne/llm-course?tab=readme-ov-file">mlabonne/llm-course: Course to get into Large Language Models (LLMs) with roadmaps and Colab notebooks.</a><br/><a href="https://mlabonne.github.io/blog/posts/2022-06-07-Decoding_strategies.html">Maxime Labonne - Decoding Strategies in Large Language Models</a><br/><a href="https://www.youtube.com/watch?v=fNk_zzaMoSs&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab">Vectors | Chapter 1, Essence of linear algebra - YouTube</a><br/><a href="https://grew.fr/">Grew</a><br/><a href="https://huggingface.co/blog/finetune-florence2">Fine-tuning Florence-2 - Microsoft's Cutting-edge Vision Language Models</a><br/><a href="https://colab.research.google.com/github/google/learned_optimization/blob/main/docs/notebooks/Part1_Introduction.ipynb#scrollTo=6dab76c7">Part1_Introduction.ipynb - Colab</a><br/><a href="https://jax.readthedocs.io/en/latest/notebooks/thinking_in_jax.html">How to think in JAX ‚Äî JAX documentation</a><br/><a href="https://www.youtube.com/watch?v=iZm4w3GVCi8&list=PL0cq-CiC5QhuyQQ-Qi5Qr5e5Rbzrn7beY&index=3">W2. Matrix Multiplication - AI by Hand ‚úçÔ∏è with Mohsena - YouTube</a><br/><a href="https://aibyhand.substack.com/p/18-can-you-calculate-soras-diffusion">18. Sora's Diffusion Transformer (DiT) - by Tom Yeh</a><br/><a href="https://www.linkedin.com/posts/tom-yeh_ai-by-hand-vol-1-activity-7172975421850943488-UZHo">Tom Yeh on LinkedIn: AI by Hand ‚úçÔ∏è Vol 1. | 217 comments</a><br/><a href="https://huggingface.co/papers/2407.11793">Paper page - Click-Gaussian: Interactive Segmentation to Any 3D Gaussians</a><br/><a href="https://www.patreon.com/collection/31641?view=expanded">Short stories with audio | Collection from Hungarian with Sziszi | 17 posts | Patreon</a><br/><a href="https://x.com/AISafetyMemes/status/1814180255713890636">(2) AI Notkilleveryoneism Memes ‚è∏Ô∏è on X: "Ukranian YouTuber discovers dozens of clones of her promoting Chinese and Russian propaganda Each clone has a different backstory and pretends to be a real person "She has my voice, my face, and speaks fluent Mandarin." https://t.co/y4DVI3LaMw" / X</a><br/><a href="https://x.com/_akhaliq/status/1813755223590285662">(2) AK on X: "Snap presents VD3D Taming Large Video Diffusion Transformers for 3D Camera Control Modern text-to-video synthesis models demonstrate coherent, photorealistic generation of complex videos from a text description. However, most existing models lack fine-grained control over https://t.co/QgaoSDZ9w5" / X</a><br/><a href="https://huggingface.co/microsoft/Phi-3-mini-128k-instruct">microsoft/Phi-3-mini-128k-instruct ¬∑ Hugging Face</a><br/><a href="https://huggingface.co/EleutherAI/pythia-6.9b">EleutherAI/pythia-6.9b ¬∑ Hugging Face</a><br/><a href="https://github.com/mistralai/mistral-finetune">github.com</a><br/><a href="https://huggingface.co/liuhaotian/llava-v1.6-mistral-7b">liuhaotian/llava-v1.6-mistral-7b ¬∑ Hugging Face</a><br/><a href="https://github.com/phonlab-tcd/text-normalization/blob/main/python_version/normalise.py">text-normalization/python_version/normalise.py at main ¬∑ phonlab-tcd/text-normalization</a><br/><a href="https://github.com/huggingface/transformers/pulls?page=2&q=is%3Apr+is%3Aopen">Pull requests ¬∑ huggingface/transformers</a><br/><a href="https://github.com/ggerganov/llama.cpp/tree/master?tab=readme-ov-file">ggerganov/llama.cpp: LLM inference in C/C++</a><br/><a href="https://github.com/facebookresearch/seamless_communication/blob/main/ggml/examples/unity/unity.cpp">seamless_communication/ggml/examples/unity/unity.cpp at main ¬∑ facebookresearch/seamless_communication</a><br/><a href="https://github.com/facebookresearch/seamless_communication/blob/main/docs/m4t/unity2_aligner_README.md">seamless_communication/docs/m4t/unity2_aligner_README.md at main ¬∑ facebookresearch/seamless_communication</a><br/><a href="https://github.com/facebookresearch/seamless_communication/blob/main/docs/expressive/README.md">seamless_communication/docs/expressive/README.md at main ¬∑ facebookresearch/seamless_communication</a><br/><a href="https://github.com/facebookresearch/stopes/blob/main/stopes/pipelines/bitext/shard_and_shuffle.py">stopes/stopes/pipelines/bitext/shard_and_shuffle.py at main ¬∑ facebookresearch/stopes</a><br/><a href="https://github.com/phonlab-tcd/expo-irish-synthesis/tree/main">phonlab-tcd/expo-irish-synthesis</a><br/><a href="https://github.com/rhasspy/piper/blob/master/TRAINING.md">piper/TRAINING.md at master ¬∑ rhasspy/piper</a><br/><a href="https://www.youtube.com/watch?v=LQLj0uHAOQA">How I Learn To Speak Foreign Languages Without Talking To People - YouTube</a><br/><a href="https://gloss.dliflc.edu/">Global Language Online Support System</a><br/><a href="https://www.google.com/search?sca_esv=1fd16e8debd1a7ec&sca_upv=1&rlz=1C5GCEM_enSE990SE991&sxsrf=ADLYWIKJ5V-vo5P75mOpHtno94i7UVIe-g:1721393888355&q=comprehensible+input+hungarian&tbm=vid&source=lnms&fbs=AEQNm0Aa4sjWe7Rqy32pFwRj0UkWd8nbOJfsBGGB5IQQO6L3J_86uWOeqwdnV0yaSF-x2joQcoZ-0Q2Udkt2zEybT7Hdf5FBKg6QdtJ_mF8k5Wx_fK47VnnH0hqC26evHUklzukhRGDp8I9R6sObxD5rXV9iKTeMw0OsLcinUtCw7tu06Z-vfaM&sa=X&ved=2ahUKEwiEne_5k7OHAxXpQVUIHaSGMmcQ0pQJegQIFhAB&biw=1440&bih=721&dpr=2">comprehensible input hungarian - Google Search</a><br/><a href="https://docs.google.com/spreadsheets/d/1dSsHOMkZn6zrh2KQZG-SOlttDll7Rjhv17J4Y_IM3v8/edit?gid=0#gid=0">SGS24_recordings - Google Sheets</a><br/><a href="https://drive.google.com/drive/folders/1BkysYWOzvxeoQzoDvvxmpCXMdRL8Scf4">Series 26 - Google Drive</a><br/><a href="https://pytorch.org/docs/stable/generated/torch.nn.CTCLoss.html">CTCLoss ‚Äî PyTorch 2.4 documentation</a><br/><a href="https://www.youtube.com/watch?v=mAq3DWgWSsw">Egy BIZARR r√©gi rekl√°m! ü§¶üñ•Ô∏è - YouTube</a><br/><a href="https://www.youtube.com/watch?v=REXiMp1sNuA">Êú±ÊòéÂÖÉÊïôÊéàÁöÑÂ§™‰πôÊ∏∏ÈæôÊã≥ - YouTube</a><br/><a href="https://www.youtube.com/watch?v=YTGdIh96Oig">Smashing Pumpkins' Billy Corgan Picks 11 Greatest Heavy-Metal Bands - YouTube</a><br/><a href="https://mail.google.com/mail/u/0/#inbox">mail.google.com</a><br/><a href="https://docs.google.com/spreadsheets/d/1dSsHOMkZn6zrh2KQZG-SOlttDll7Rjhv17J4Y_IM3v8/edit?gid=0#gid=0">SGS24_recordings - Google Sheets</a><br/><a href="https://github.com/shivammehta25/Diff-TTSG/tree/main/pymo">Diff-TTSG/pymo at main ¬∑ shivammehta25/Diff-TTSG</a><br/><a href="https://github.com/m-bain/whisperX/blob/main/whisperx/alignment.py">whisperX/whisperx/alignment.py at main ¬∑ m-bain/whisperX</a><br/><a href="https://pytorch.org/audio/main/generated/torchaudio.pipelines.WAV2VEC2_ASR_LARGE_LV60K_960H.html">WAV2VEC2_ASR_LARGE_LV60K_960H ‚Äî Torchaudio 2.4.0.dev20240628 documentation</a><br/><a href="https://www.youtube.com/watch?v=XK2O-gCEN5A">Watch this to learn ANY Martial Arts Form - YouTube</a><br/><a href="https://www.youtube.com/watch?v=TU_PnLSD0vA">City Nights Transcription ( Allan Holdsworth ) - YouTube</a><br/><a href="https://www.youtube.com/watch?v=H1BpS4mlsfk">Ryan Reynolds Makes His Grand Entrance Riding a Deadpool Float on The Tonight Show - YouTube</a><br/><a href="https://www.youtube.com/watch?v=5I5_8l_mSBs">Exercise Scientist Critiques Floyd Mayweather's Training - YouTube</a><br/><a href="https://www.youtube.com/watch?v=3f78TWKiLlI">'The Boys' Cast Answer The Web's Most Searched Questions | WIRED - YouTube</a><br/><a href="https://github.com/pytransitions/transitions">pytransitions/transitions: A lightweight, object-oriented finite state machine implementation in Python with many extensions</a><br/><a href="https://github.com/alphacep/vosk-api/blob/master/python/vosk/transcriber/transcriber.py">vosk-api/python/vosk/transcriber/transcriber.py at master ¬∑ alphacep/vosk-api</a><br/><a href="https://github.com/daanzu/kaldi-active-grammar/issues/33">Fine Tuning ¬∑ Issue #33 ¬∑ daanzu/kaldi-active-grammar</a><br/><a href="https://huggingface.co/speechbrain/sepformer-wham">speechbrain/sepformer-wham ¬∑ Hugging Face</a><br/><a href="https://montreal-forced-aligner.readthedocs.io/en/latest/user_guide/corpus_creation/diarize_speakers.html">Speaker diarization (mfa diarize_speakers) ‚Äî Montreal Forced Aligner 3.0.0 documentation</a><br/><a href="https://docs.google.com/document/d/1iDIQA2Ee2RkCni0-Db2CWwTjf5i_c9_vUkk6F54wrGk/edit">HSI dataset preparation - Google Docs</a><br/><a href="https://github.com/shivammehta25/Match-TTSG/commits/stoc_preds/">Commits ¬∑ shivammehta25/Match-TTSG</a><br/><a href="https://github.com/shivammehta25/Match-TTSG/blob/main/configs/train.yaml">Match-TTSG/configs/train.yaml at main ¬∑ shivammehta25/Match-TTSG</a><br/><a href="https://github.com/shivammehta25/Match-TTSG/commit/c4b7170c8bd9ee1daf00e2a3719e2806e574ba1c">Adding possibility to load checkpoint with different speaker numbers ¬∑ shivammehta25/Match-TTSG@c4b7170</a><br/><a href="https://github.com/shivammehta25/Match-TTSG/commit/31eb8dcd56386188e722c6f19700d39535f6eecb">Adding fine tuning experiment ¬∑ shivammehta25/Match-TTSG@31eb8dc</a><br/><a href="https://github.com/alphacep/vosk-api/blob/master/python/example/colab/vosk.ipynb">vosk-api/python/example/colab/vosk.ipynb at master ¬∑ alphacep/vosk-api</a><br/><a href="https://github.com/omimo/PyMO">omimo/PyMO: A library for machine learning research on motion capture data</a><br/><a href="https://github.com/20tab/bvh-python">20tab/bvh-python: Python module for parsing BVH (Biovision hierarchical data) mocap files</a><br/><a href="https://pypi.org/project/bvhtoolbox/">bvhtoolbox ¬∑ PyPI</a><br/><a href="https://www.google.com/search?q=bvh+to+expmap&rlz=1C5GCEM_enSE990SE991&oq=bvh+to+expmap&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIJCAEQIRgKGKABMgkIAhAhGAoYoAHSAQgyOTAwajBqN6gCALACAA&sourceid=chrome&ie=UTF-8">bvh to expmap - Google Search</a><br/><a href="https://github.com/Svito-zar/gesticulator/blob/master/gesticulator/data_processing/bvh2features.py">gesticulator/gesticulator/data_processing/bvh2features.py at master ¬∑ Svito-zar/gesticulator</a><br/><a href="https://github.com/simonalexanderson/PyMO/commit/fab408634cb937a60dbe8dbfb5ae9813e39063af">major modifications to increase processing speed, fix exp_map discont‚Ä¶ ¬∑ simonalexanderson/PyMO@fab4086</a><br/><a href="https://github.com/omimo/MocapJS">omimo/MocapJS: A motion capture library for Three.js: Playing | Streaming | VR</a><br/><a href="https://github.com/omimo/DragDiffusion">omimo/DragDiffusion: [CVPR2024] Official code for DragDiffusion</a><br/><a href="https://www.cs.cmu.edu/~spiff/moedit99/expmap.pdf">Microsoft Word - jgt-final.doc</a><br/><a href="https://github.com/Svito-zar/gesticulator?tab=readme-ov-file">Svito-zar/gesticulator: The official implementation for ICMI 2020 Best Paper Award "Gesticulator: A framework for semantically-aware speech-driven gesture generation"</a><br/><a href="https://svito-zar.github.io/papers/Gesticulator_ICMI_2020.pdf">Gesticulator: A framework for semantically-aware speech-driven gesture generation</a><br/><a href="https://github.com/omimo/PyMO/blob/master/pymo/preprocessing.py">PyMO/pymo/preprocessing.py at master ¬∑ omimo/PyMO</a><br/><a href="https://github.com/OlafHaag/bvh-toolbox/blob/main/src/bvhtoolbox/manipulate/renamejoints.py">bvh-toolbox/src/bvhtoolbox/manipulate/renamejoints.py at main ¬∑ OlafHaag/bvh-toolbox</a><br/><a href="https://github.com/noisetorch/NoiseTorch">noisetorch/NoiseTorch: Real-time microphone noise suppression on Linux.</a><br/><a href="https://github.com/Rikorose/DeepFilterNet">Rikorose/DeepFilterNet: Noise supression using deep filtering</a><br/><a href="https://github.com/GestureGeneration/Speech_driven_gesture_generation_with_autoencoder/blob/master/motion_repr_learning/ae/utils/utils.py">Speech_driven_gesture_generation_with_autoencoder/motion_repr_learning/ae/utils/utils.py at master ¬∑ GestureGeneration/Speech_driven_gesture_generation_with_autoencoder</a><br/><a href="https://www.instagram.com/direct/t/102052201197290/">Inbox ‚Ä¢ Direct</a><br/><a href="https://www.instagram.com/">Instagram</a><br/><a href="https://github.com/nateraw/hf-hub-lightning">nateraw/hf-hub-lightning: A PyTorch Lightning Callback for pushing models to the Hugging Face Hub ü§ó‚ö°Ô∏è</a><br/><a href="https://www.youtube.com/shorts/BwswwSzMCM0">This Video Deserves an Oscar - YouTube</a><br/><a href="https://arxiv.org/pdf/2306.09417">Diff-TTSG: Denoising probabilistic integrated speech and gesture synthesis</a><br/><a href="https://ieeexplore.ieee.org/document/8683846">Casting to Corpus: Segmenting and Selecting Spontaneous Dialogue for Tts with a Cnn-lstm Speaker-dependent Breath Detector | IEEE Conference Publication | IEEE Xplore</a><br/><a href="https://thinkcomputers.org/thinkcomputers-podcast-411/">ThinkComputers Podcast #411 - Fractal Design Mood, NVIDIA, AI Motherboards & More! | ThinkComputers.org</a><br/><a href="https://github.com/BirgerMoell/tmh/blob/master/tmh/breath_detection/breath2corpus_step0_TrainBreathAnalysisModel.py">tmh/tmh/breath_detection/breath2corpus_step0_TrainBreathAnalysisModel.py at master ¬∑ BirgerMoell/tmh</a><br/><a href="https://github.com/BirgerMoell/tmh/tree/master/tmh/breath_detection/support_scripts">tmh/tmh/breath_detection/support_scripts at master ¬∑ BirgerMoell/tmh</a><br/><a href="https://github.com/BirgerMoell/tmh/blob/master/tmh/beskow/phonemap.py">tmh/tmh/beskow/phonemap.py at master ¬∑ BirgerMoell/tmh</a><br/><a href="https://github.com/BirgerMoell/tmh/blob/master/tmh/breath_detection/breath2corpus_step0_TrainBreathAnalysisModel.py">tmh/tmh/breath_detection/breath2corpus_step0_TrainBreathAnalysisModel.py at master ¬∑ BirgerMoell/tmh</a><br/><a href="https://chatgpt.com/c/3705f395-aeff-485f-bd16-09f10e28aa0e">Keras to PyTorch Conversion</a><br/><a href="https://stackoverflow.com/questions/43371438/how-to-inspect-h5-file-in-python">matlab - How to inspect .h5 file in Python - Stack Overflow</a><br/><a href="https://github.com/Kyubyong/name2nat/blob/master/train.py">name2nat/train.py at master ¬∑ Kyubyong/name2nat</a><br/><a href="https://github.com/evaszekely/ambiguous/blob/main/batch_mingle_nudge_sgr_eval.ipynb">ambiguous/batch_mingle_nudge_sgr_eval.ipynb at main ¬∑ evaszekely/ambiguous</a><br/><a href="https://aclanthology.org/2020.lrec-1.782.pdf">Augmented Prompt Selection for Evaluation of Spontaneous Speech Synthesis</a><br/><a href="https://github.com/orgs/sprakbankental/repositories?type=all&page=3">sprakbankental repositories</a><br/><a href="https://github.com/sprakbankental/ttsdata/blob/develop/sve.ibm.talesyntese/sw_pcms/scripts/mf/sw_all">ttsdata/sve.ibm.talesyntese/sw_pcms/scripts/mf/sw_all at develop ¬∑ sprakbankental/ttsdata</a><br/><a href="https://www.isca-archive.org/ssw_2023/wang23_ssw.pdf">wang23_ssw.pdf</a><br/><a href="https://pypi.org/project/opencv-python/">opencv-python ¬∑ PyPI</a><br/><a href="https://github.com/domschl/HuggingFaceGuidedTourForMac?tab=readme-ov-file">domschl/HuggingFaceGuidedTourForMac: A guided tour on how to use HuggingFace large language models on Macs with Apple Silicon</a><br/><a href="https://github.com/ml-explore/">ml-explore</a><br/><a href="https://github.com/ml-explore/mlx-examples/blob/main/whisper/convert.py">mlx-examples/whisper/convert.py at main ¬∑ ml-explore/mlx-examples</a><br/><a href="https://www.google.com/search?q=apple+mlx+wav2vec&sca_esv=06c8e48f77199bf5&sca_upv=1&rlz=1C5GCEM_enSE990SE991&sxsrf=ADLYWILmC9jUlN5ojC_XcLQPdVhOS3P0lA%3A1722382734206&ei=jnmpZpaiDMKawPAPwZ382AY&ved=0ahUKEwiWoajY98-HAxVCDRAIHcEOH2sQ4dUDCA8&uact=5&oq=apple+mlx+wav2vec&gs_lp=Egxnd3Mtd2l6LXNlcnAiEWFwcGxlIG1seCB3YXYydmVjSIkNULQGWPELcAF4AJABAJgBjAGgAe0FqgEDMC42uAEDyAEA-AEBmAIDoAL5AcICCxAAGIAEGLADGKIEwgIKECEYoAEYwwQYCpgDAIgGAZAGBJIHAzEuMqAH0gk&sclient=gws-wiz-serp">apple mlx wav2vec - Google Search</a><br/><a href="https://github.com/matlab-deep-learning/wav2vec-2.0/blob/main/speech_to_text_using_wav2vec.mlx">wav2vec-2.0/speech_to_text_using_wav2vec.mlx at main ¬∑ matlab-deep-learning/wav2vec-2.0</a><br/><a href="https://www.mathworks.com/matlabcentral/fileexchange/103525-wav2vec-2-0">wav2vec-2.0 - File Exchange - MATLAB Central</a><br/><a href="https://demystifyml.co/wav2vec-20-model-for-cross-lingual-phoneme-recognition">Wav2Vec 2.0 Model for Cross-Lingual Phoneme Recognition</a><br/><a href="https://github.com/tlikhomanenko/tlikhomanenko">tlikhomanenko/tlikhomanenko: About Me</a><br/><a href="https://github.com/huggingface/transformers/blob/main/src/transformers/models/t5/modeling_t5.py#L67">transformers/src/transformers/models/t5/modeling_t5.py at main ¬∑ huggingface/transformers</a><br/><a href="https://github.com/huggingface/transformers/blob/main/src/transformers/models/t5/modeling_t5.py#L67">transformers/src/transformers/models/t5/modeling_t5.py at main ¬∑ huggingface/transformers</a><br/><a href="https://huggingface.co/jimregan/wav2vec2-xls-r-300m-phoneme-timit/blob/main/vocab.json">vocab.json ¬∑ jimregan/wav2vec2-xls-r-300m-phoneme-timit at main</a><br/><a href="https://www.kaggle.com/code/jimregan/phoneme-recognition-with-wav2vec2/edit/run/165873018">Phoneme Recognition with Wav2Vec2 | Kaggle</a><br/><a href="https://github.com/timmahrt/pysle/blob/main/pysle/utilities/search.py">pysle/pysle/utilities/search.py at main ¬∑ timmahrt/pysle</a><br/><a href="https://github.com/uiuc-sst/g2ps/blob/master/English-US/English-US_segments.csv">g2ps/English-US/English-US_segments.csv at master ¬∑ uiuc-sst/g2ps</a><br/><a href="https://github.com/uiuc-sst/g2ps?tab=readme-ov-file">uiuc-sst/g2ps: Data and code for grapheme-to-phoneme transducers in lots of languages</a><br/><a href="https://x.com/home">(1) Home / X</a><br/><a href="https://www.ladbible.com/news/sport/olympics-imane-khelif-boxing-angela-carini-285074-20240801">Reason Olympic boxer who failed gender eligibility test is able to compete as opponent abandons fight after just 46 seconds</a><br/><a href="https://www.theguardian.com/world/article/2024/aug/01/funeral-for-hamas-political-leader-haniyeh-held-in-tehran-amid-security-fears?utm_source=instagramstories&utm_campaign=hezbollahchiefnewphase">Hezbollah chief says conflict with Israel is in ‚Äònew phase‚Äô after assassinations | Hezbollah | The Guardian</a><br/><a href="https://www.instagram.com/dorotachwedorowicz_official/">DOROTA CHWEDOROWICZ (@dorotachwedorowicz_official) ‚Ä¢ Instagram photos and videos</a><br/><a href="https://x.com/jimregan/status/1381637685413081089">(1) Jim O'Regan on X: "So, do massively multilingual MT models trained on massively crawled datasets lead to great output? No https://t.co/SckNGTq09B" / X</a><br/><a href="https://x.com/home">Home / X</a><br/><a href="https://x.com/InternetH0F/status/1819055743221334463">(1) internet hall of fame on X: "Police officer purposely slams on brakes to get biker to crash into him on the highway üò≥ https://t.co/HhUNxu2DE4" / X</a><br/><a href="https://github.com/internetarchive/warcprox">internetarchive/warcprox: WARC writing MITM HTTP/S proxy</a><br/><a href="https://github.com/odie5533/WarcProxy">odie5533/WarcProxy: Saves proxied HTTP traffic to a WARC file.</a><br/><a href="https://pywb.readthedocs.io/en/develop/manual/usage.html">Usage ‚Äî pywb 2.0 documentation</a><br/><a href="https://conifer.rhizome.org/">Conifer | Homepage</a><br/><a href="https://github.com/webrecorder/warcio?tab=readme-ov-file">webrecorder/warcio: Streaming WARC/ARC library for fast web archive IO</a><br/><a href="https://www.instagram.com/">Instagram</a><br/><a href="https://www.instagram.com/klara_butler/">kl√°ra (@klara_butler) ‚Ä¢ Instagram photos and videos</a><br/><a href="https://www.instagram.com/bambi.ofc/">bambiszon (@bambi.ofc) ‚Ä¢ Instagram photos and videos</a><br/><a href="https://www.instagram.com/mrs.lillyy/">PAULINA STOJANOWSKA (@mrs.lillyy) ‚Ä¢ Instagram photos and videos</a><br/><a href="https://www.google.com/search?q=breath+group+segmentation+github&rlz=1C5GCEM_enSE990SE991&oq=breath+group+seg&gs_lcrp=EgZjaHJvbWUqBwgBECEYoAEyBggAEEUYOTIHCAEQIRigATIHCAIQIRigATIHCAMQIRigAdIBCDU4MDRqMGo5qAIAsAIB&sourceid=chrome&ie=UTF-8">breath group segmentation github - Google Search</a><br/><a href="https://kth.diva-portal.org/smash/get/diva2:1475054/FULLTEXT01.pdf">Breathing and Speech Planning in Spontaneous Speech Synthesis</a><br/><a href="https://github.com/lowerquality/gentle">lowerquality/gentle: gentle forced aligner</a><br/><a href="https://arxiv.org/pdf/2402.00288">Frame-Wise Breath Detection with Self-Training: An Exploration of Enhancing Breath Naturalness in Text-to-Speech</a><br/><a href="http://localhost:8765/transcriptions/6b090921/">localhost:8765/transcriptions/6b090921/</a><br/><a href="https://www.instagram.com/">Instagram</a><br/><a href="https://www.instagram.com/thurlesfarmersmarket/">Thurles Farmers Market (@thurlesfarmersmarket) ‚Ä¢ Instagram photos and videos</a><br/><a href="https://www.instagram.com/kara_becker/">Kara Becker (@kara_becker) ‚Ä¢ Instagram photos and videos</a><br/><a href="https://en.wikisource.org/wiki/Dubliners/An_Encounter">Dubliners/An Encounter - Wikisource, the free online library</a><br/><a href="https://www.google.com/search?q=convert+keras+h5+model+to+pytorch&rlz=1C5GCEM_enSE990SE991&oq=convert+keras+h5+model+to+pytorch&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIGCAEQRRg80gEIODQ2OGowajeoAgCwAgA&sourceid=chrome&ie=UTF-8">convert keras h5 model to pytorch - Google Search</a><br/><a href="https://codeconverter.io/convert/keras-to-pytorch">Transitioning from Keras to PyTorch: A Comprehensive Guide | Convert your code to any language or framework effortlessly.</a><br/><a href="https://github.com/keras-team/keras/issues/10417">Loading saved model fails with ValueError You are trying to load a weight file containing 1 layers into a model with 0 layers ¬∑ Issue #10417 ¬∑ keras-team/keras</a><br/><a href="https://stackoverflow.com/questions/68002742/converted-model-from-keras-h5-to-pytorch-fully-connected-layer-mismatch">Converted model from keras h5 to pytorch - fully connected layer mismatch - Stack Overflow</a><br/><a href="https://chatgpt.com/c/3705f395-aeff-485f-bd16-09f10e28aa0e">Keras to PyTorch Conversion</a><br/><a href="https://montreal-forced-aligner.readthedocs.io/en/latest/user_guide/workflows/alignment.html">Align with an acoustic model (mfa align) ‚Äî Montreal Forced Aligner 3.0.0 documentation</a><br/><a href="https://montreal-forced-aligner.readthedocs.io/en/latest/user_guide/implementations/fine_tune.html#fine-tune-alignments">Fine-tuning alignments ‚Äî Montreal Forced Aligner 3.0.0 documentation</a><br/><a href="https://librivox.org/dubliners-by-james-joyce/">LibriVox</a><br/><a href="https://en.wikipedia.org/wiki/Dubliners">Dubliners - Wikipedia</a><br/><a href="https://www.google.com/search?q=mfa+align+from+textgrid&rlz=1C5GCEM_enSE990SE991&oq=mfa+align+from+textgrid&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIHCAEQIRigATIHCAIQIRigAdIBCDU4NjdqMGo3qAIAsAIA&sourceid=chrome&ie=UTF-8">mfa align from textgrid - Google Search</a><br/><a href="https://eleanorchodroff.com/tutorial/montreal-forced-aligner.html">3 Montreal Forced Aligner | Corpus Phonetics Tutorial</a><br/><a href="https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/blob/78e481d2b3708957f3f6ac2b4d089bac798ad757/montreal_forced_aligner/tokenization/simple.py#L15">Montreal-Forced-Aligner/montreal_forced_aligner/tokenization/simple.py at 78e481d2b3708957f3f6ac2b4d089bac798ad757 ¬∑ MontrealCorpusTools/Montreal-Forced-Aligner</a><br/><a href="https://jmckinstry3.medium.com/alignment-attention-and-textgrids-5d4bc749c333">Alignment, Attention, and TextGrids | by John McKinstry | Medium</a><br/><a href="https://github.com/Jackson-Kang/MFARunner/blob/main/dataset/emotiontts.py">MFARunner/dataset/emotiontts.py at main ¬∑ Jackson-Kang/MFARunner</a><br/><a href="https://montreal-forced-aligner.readthedocs.io/en/latest/user_guide/corpus_structure.html">Corpus formats and structure ‚Äî Montreal Forced Aligner 3.0.0 documentation</a><br/><a href="https://montreal-forced-aligner.readthedocs.io/en/latest/user_guide/troubleshooting.html">Troubleshooting ‚Äî Montreal Forced Aligner 3.0.0 documentation</a><br/><a href="https://montreal-forced-aligner.readthedocs.io/en/latest/user_guide/workflows/alignment.html#align-one">Align with an acoustic model (mfa align) ‚Äî Montreal Forced Aligner 3.0.0 documentation</a><br/><a href="https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/blob/78e481d2b3708957f3f6ac2b4d089bac798ad757/docs/source/user_guide/configuration/index.rst#L31">Montreal-Forced-Aligner/docs/source/user_guide/configuration/index.rst at 78e481d2b3708957f3f6ac2b4d089bac798ad757 ¬∑ MontrealCorpusTools/Montreal-Forced-Aligner</a><br/><a href="https://www.instagram.com/direct/t/100169274717717/">Inbox ‚Ä¢ Direct</a><br/><a href="https://wikisource.org/wiki/Mo_Sg%C3%A9al_F%C3%A9in/1">Mo Sc√©al F√©in/1 - Wikisource</a><br/><a href="https://wikisource.org/wiki/File:MSF_chapter_1.ogg">File:MSF chapter 1.ogg - Wikisource</a><br/><a href="https://wikisource.org/wiki/Author:Peadar_Ua_Laoghaire">Author:Peadar Ua Laoghaire - Wikisource</a><br/><a href="https://www.google.com/search?q=Chionn+tS%C3%A1ile&rlz=1C5GCEM_enSE990SE991&oq=Chionn+tS%C3%A1ile&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIICAEQABgWGB4yCAgCEAAYFhgeMggIAxAAGBYYHjIKCAQQABiABBiiBDIKCAUQABiABBiiBDIKCAYQABiABBiiBDIKCAcQABiABBiiBDIKCAgQABiiBBiJBdIBBzk2NWowajeoAgCwAgA&sourceid=chrome&ie=UTF-8">Chionn tS√°ile - Google Search</a><br/><a href="https://raw.githubusercontent.com/jimregan/irish-asr-data/master/audacity/MSF_chapter_1.aud">raw.githubusercontent.com/jimregan/irish-asr-data/master/audacity/MSF_chapter_1.aud</a><br/><a href="https://github.com/jimregan/sjoestedt-jonval-description">jimregan/sjoestedt-jonval-description</a><br/><a href="https://www.google.com/search?q=site%3Aen.wiktionary.org+%C3%A9ag%C3%B3ra">site:en.wiktionary.org √©ag√≥ra - Google Search</a><br/><a href="https://www.teanglann.ie/en/gram/mairbhe">Irish Grammar Database: mairbhe</a><br/><a href="https://en.wiktionary.org/wiki/maraigh">maraigh - Wiktionary, the free dictionary</a><br/><a href="https://chatgpt.com/c/bbefe036-7aa4-4792-8767-794411f8a46d">Retarget BVH Arm Direction</a><br/><a href="https://github.com/20tab/bvh-python">20tab/bvh-python: Python module for parsing BVH (Biovision hierarchical data) mocap files</a><br/><a href="https://github.com/esdalmaijer/PyGaze/blob/master/pygaze/libsound.py">PyGaze/pygaze/libsound.py at master ¬∑ esdalmaijer/PyGaze</a><br/><a href="https://www.google.com/search?q=RightEyeRotationWorldZ&rlz=1C5GCEM_enSE990SE991&oq=RightEyeRotationWorldZ&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIKCAEQABiABBiiBNIBBzYwNmowajeoAgCwAgA&sourceid=chrome&ie=UTF-8">RightEyeRotationWorldZ - Google Search</a><br/><a href="https://docs.scipy.org/doc/scipy/tutorial/spatial.html">Spatial data structures and algorithms (scipy.spatial) ‚Äî SciPy v1.14.0 Manual</a><br/><a href="https://www.google.com/search?q=mocap+python&rlz=1C5GCEM_enSE990SE991&oq=mocap+python&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIICAEQABgWGB4yDQgCEAAYhgMYgAQYigUyCggDEAAYgAQYogQyCggEEAAYgAQYogQyBggFEEUYPDIGCAYQRRg80gEIMjQyM2owajeoAgCwAgA&sourceid=chrome&ie=UTF-8">mocap python - Google Search</a><br/><a href="https://github.com/mkjung99/mocaplib">mkjung99/mocaplib: MoCapLib: Library for MoCap data processing and analysis</a><br/><a href="https://www.google.com/search?q=manipulate+bvh+swap+arms&sca_esv=0a6ab453dca08831&sca_upv=1&rlz=1C5GCEM_enSE990SE991&sxsrf=ADLYWIJEpbP_3y3yO_2eWt15-vsH8DvwAg%3A1722900963513&ei=42GxZq2BH7a3wPAP74aMkQM&ved=0ahUKEwjt_qafgt-HAxW2GxAIHW8DIzIQ4dUDCBA&uact=5&oq=manipulate+bvh+swap+arms&gs_lp=Egxnd3Mtd2l6LXNlcnAiGG1hbmlwdWxhdGUgYnZoIHN3YXAgYXJtc0jVB1DPBFjPBHACeACQAQCYAX6gAX6qAQMwLjG4AQPIAQD4AQGYAgKgAgbCAg4QABiABBiwAxiGAxiKBcICCxAAGIAEGLADGKIEmAMAiAYBkAYGkgcBMqAHTA&sclient=gws-wiz-serp">manipulate bvh swap arms - Google Search</a><br/><a href="https://blenderartists.org/t/bvh-retargeting/499923">bvh "retargeting"? - Support / Animation and Rigging - Blender Artists Community</a><br/><a href="https://www.reddit.com/r/Python/comments/16ar0dx/opensource_markerless_motion_capture_with/">Open-source markerless motion capture with webcams...one year of learning to program : r/Python</a><br/><a href="https://github.com/mprib/caliscope">mprib/caliscope: Multicamera Calibration + Pose Estimation --> Open Source Motion Capture</a><br/><a href="https://www.google.com/search?q=gaze+tracker+output&rlz=1C5GCEM_enSE990SE991&oq=gaze+tracker+output&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIGCAEQRRhAMgYIAhBFGEDSAQgzMDk5ajFqN6gCALACAA&sourceid=chrome&ie=UTF-8">gaze tracker output - Google Search</a><br/><a href="https://developer.blender.org/docs/release_notes/4.0/animation_rigging/">Animation & Rigging - Blender Developer Documentation</a><br/><a href="https://www.google.com/search?q=listen+denoise+action&rlz=1C5GCEM_enSE990SE991&oq=listen+denoise&gs_lcrp=EgZjaHJvbWUqBwgAEAAYgAQyBwgAEAAYgAQyBggBEEUYOTIICAIQABgWGB4yDQgDEAAYhgMYgAQYigUyDQgEEAAYhgMYgAQYigUyDQgFEAAYhgMYgAQYigUyDQgGEAAYhgMYgAQYigUyBggHEEUYPNIBCDQwODFqMWo3qAIAsAIA&sourceid=chrome&ie=UTF-8">listen denoise action - Google Search</a><br/><a href="https://onlinelibrary.wiley.com/doi/10.1111/cgf.13946">Style‚ÄêControllable Speech‚ÄêDriven Gesture Synthesis Using Normalising Flows - Alexanderson - 2020 - Computer Graphics Forum - Wiley Online Library</a><br/><a href="https://github.com/simonalexanderson/ListenDenoiseAction">simonalexanderson/ListenDenoiseAction: Code to reproduce the results for our SIGGRAPH 2023 paper "Listen Denoise Action"</a><br/><a href="https://raw.githubusercontent.com/simonalexanderson/ListenDenoiseAction/main/pymo/preprocessing.py">raw.githubusercontent.com/simonalexanderson/ListenDenoiseAction/main/pymo/preprocessing.py</a><br/><a href="https://github.com/ulmewennberg/tisa">ulmewennberg/tisa</a><br/><a href="https://www.google.com/search?q=vscode+merge+plugins&rlz=1C5GCEM_enSE990SE991&oq=vscode+merge+plugins&gs_lcrp=EgZjaHJvbWUyBggAEEUYOdIBCDU5OTZqMGo3qAIAsAIA&sourceid=chrome&ie=UTF-8">vscode merge plugins - Google Search</a><br/><a href="https://blog.soltysiak.it/en/2017/08/how-to-use-git-patch-system-to-apply-changes-into-another-folder-structure/">How to use git patch system to apply changes into another folder ‚Äì Soltys Blog</a><br/><a href="https://github.com/simonalexanderson/PyMO/commits/master/">Commits ¬∑ simonalexanderson/PyMO</a><br/><a href="https://github.com/simonalexanderson/PyMO/commit/af9acdaf61d4e4a960655328441262e40ad7d7ce">demos to convert bvh to joint angle features and back ¬∑ simonalexanderson/PyMO@af9acda</a><br/><a href="https://github.com/simonalexanderson/PyMO/commit/506c4fd4627af1c93ce4437d2f4b8f1555d867e1">modified copy to deepcopy ¬∑ simonalexanderson/PyMO@506c4fd</a><br/><a href="https://github.com/simonalexanderson/PyMO/commit/ca2f8c07a013399d909d580c75e356f37a31d295">added rotation order, frame_rate, import start-stop etc ¬∑ simonalexanderson/PyMO@ca2f8c0</a><br/><a href="https://github.com/simonalexanderson/PyMO/commit/fab408634cb937a60dbe8dbfb5ae9813e39063af">major modifications to increase processing speed, fix exp_map discont‚Ä¶ ¬∑ simonalexanderson/PyMO@fab4086</a><br/><a href="https://github.com/simonalexanderson/PyMO/commit/9a4569b111c84d463c890f7f0f94649b3573124c">included frame_rate and rotation order ¬∑ simonalexanderson/PyMO@9a4569b</a><br/><a href="https://github.com/simonalexanderson/PyMO/commit/7ded878b2761ee2eb76650a438d5c3e437efbf7e">Update README.md ¬∑ simonalexanderson/PyMO@7ded878</a><br/><a href="https://github.com/simonalexanderson/PyMO/commit/b6f7a696da2daafb855c26cb453b85c6883bba94">Updated readme ¬∑ simonalexanderson/PyMO@b6f7a69</a><br/><a href="https://github.com/simonalexanderson/PyMO/commit/d746d1a2326f17f6aebd0b1a303cc4e104dc7980">Updated readme ¬∑ simonalexanderson/PyMO@d746d1a</a><br/><a href="https://github.com/simonalexanderson/PyMO/commit/54c3c255896026011d7334d5efc9b1c2ad77dad0">removed redundant depandency to transforms3d ¬∑ simonalexanderson/PyMO@54c3c25</a><br/><a href="https://github.com/simonalexanderson/PyMO/commit/0a9141747d6f25d369830ff612b4ef0374deb6e1">Update README.md ¬∑ simonalexanderson/PyMO@0a91417</a><br/><a href="https://github.com/simonalexanderson/PyMO/tree/master/pymo">PyMO/pymo at master ¬∑ simonalexanderson/PyMO</a><br/><a href="https://github.com/simonalexanderson/PyMO/blob/master/pymo/preprocessing.py">PyMO/pymo/preprocessing.py at master ¬∑ simonalexanderson/PyMO</a><br/><a href="https://www.instagram.com/">Instagram</a><br/><a href="https://www.flickr.com/photos/jimregan/">Jim O'Regan | Flickr</a><br/><a href="https://en.wiktionary.org/wiki/ro-mh%C3%B2r">ro-mh√≤r - Wiktionary, the free dictionary</a><br/><a href="https://en.wiktionary.org/w/index.php?title=eiseaml%C3%A1ir&action=edit&section=4">Editing eiseaml√°ir (section) - Wiktionary, the free dictionary</a><br/><a href="https://en.wikisource.org/wiki/A_Dialect_of_Donegal/The_Vowel_System#s80">A Dialect of Donegal/The Vowel System - Wikisource, the free online library</a><br/><a href="https://en.wikisource.org/wiki/A_Dialect_of_Donegal/The_Vowel_System">A Dialect of Donegal/The Vowel System - Wikisource, the free online library</a><br/><a href="https://en.wikisource.org/wiki/A_Dialect_of_Donegal/The_Vowel_System#s114">A Dialect of Donegal/The Vowel System - Wikisource, the free online library</a><br/><a href="https://fr.wikisource.org/wiki/Phon%C3%A9tique_d%E2%80%99un_parler_irlandais_de_Kerry">Phon√©tique d‚Äôun parler irlandais de Kerry - Wikisource</a><br/><a href="https://fr.wikisource.org/wiki/Description_d%E2%80%99un_parler_irlandais_de_Kerry/2-1">Description d‚Äôun parler irlandais de Kerry/2-1 - Wikisource</a><br/><a href="https://jimregan.github.io/notes/categories/#sjoestedt">Tags | notes</a><br/><a href="https://jimregan.github.io/notes/irish/sjoestedt/phonetique/2024/08/06/sjoestedt_phonetique.html">Sjoestedt-Jonval Phon√©tique | notes</a><br/><a href="https://corkirish.wordpress.com/wp-content/uploads/2018/11/dictionary.pdf">dictionary.pdf</a><br/><a href="https://wezfurlong.org/wezterm/config/lua/wezterm.serde/index.html">module: wezterm.serde - Wez's Terminal Emulator</a><br/><a href="https://wezfurlong.org/wezterm/cli/general.html">CLI Reference - Wez's Terminal Emulator</a><br/><a href="https://github.com/neovim/neovim/blob/master/INSTALL.md">neovim/INSTALL.md at master ¬∑ neovim/neovim</a><br/><a href="https://github.com/neovim/neovim/wiki/Related-projects#plugins">Related projects ¬∑ neovim/neovim Wiki</a><br/><a href="https://github.com/vscode-neovim/vscode-neovim">vscode-neovim/vscode-neovim: Vim mode for VSCode, powered by Neovim</a><br/><a href="https://github.com/carlocab/tmux-nvr?tab=readme-ov-file">carlocab/tmux-nvr: A tmux plugin for using session-specific Neovim instances with neovim-remote</a><br/><a href="https://github.com/tmux-plugins/tpm?tab=readme-ov-file">tmux-plugins/tpm: Tmux Plugin Manager</a><br/><a href="https://github.com/tmux-plugins/list?tab=readme-ov-file">tmux-plugins/list: A list of tmux plugins.</a><br/><a href="https://github.com/wfxr/tmux-fzf-url">wfxr/tmux-fzf-url: üöÄ Quickly open urls on your terminal screen!</a><br/><a href="https://github.com/balta2ar/brotab">balta2ar/brotab: Control your browser's tabs from the command line</a><br/><a href="https://github.com/tmux-plugins/tmux-continuum?tab=readme-ov-file">tmux-plugins/tmux-continuum: Continuous saving of tmux environment. Automatic restore when tmux is started. Automatic tmux start when computer is turned on.</a><br/><a href="https://github.com/tmux-plugins/tmux-resurrect">tmux-plugins/tmux-resurrect: Persists tmux environment across system restarts.</a><br/><a href="https://github.com/tmux-plugins/tpm">tmux-plugins/tpm: Tmux Plugin Manager</a><br/><a href="https://github.com/tmux-plugins/tmux-resurrect?tab=readme-ov-file">tmux-plugins/tmux-resurrect: Persists tmux environment across system restarts.</a><br/><a href="https://github.com/tmux-plugins/tmux-yank?tab=readme-ov-file">tmux-plugins/tmux-yank: Tmux plugin for copying to system clipboard. Works on OSX, Linux and Cygwin.</a><br/><a href="https://github.com/tmux-plugins/tpm">tmux-plugins/tpm: Tmux Plugin Manager</a><br/><a href="https://github.com/ohmyzsh/ohmyzsh/wiki/Plugins">Plugins ¬∑ ohmyzsh/ohmyzsh Wiki</a><br/><a href="https://github.com/mbrubeck/compleat?tab=readme-ov-file">mbrubeck/compleat: Generate command-line completions using a simple DSL.</a><br/><a href="https://wezfurlong.org/wezterm/index.html">WezTerm - Wez's Terminal Emulator</a><br/><a href="https://wezfurlong.org/wezterm/features.html#available-features">Features - Wez's Terminal Emulator</a><br/><a href="https://wezfurlong.org/wezterm/multiplexing.html#multiplexing">Multiplexing - Wez's Terminal Emulator</a><br/><a href="https://wezfurlong.org/wezterm/quickselect.html">Quick Select Mode - Wez's Terminal Emulator</a><br/><a href="https://wezfurlong.org/wezterm/multiplexing.html#multiplexing">Multiplexing - Wez's Terminal Emulator</a><br/><a href="https://www.reddit.com/r/neovim/comments/16kjpxn/wezterm_or_tmuxalacritty/">Wezterm or Tmux/Alacritty : r/neovim</a><br/><a href="https://github.com/nteract/papermill#executing-a-notebook">nteract/papermill: üìö Parameterize, execute, and analyze notebooks</a><br/><a href="https://papermill.readthedocs.io/en/latest/">Home - papermill 2.4.0 documentation</a><br/><a href="https://papermill.readthedocs.io/en/latest/installation.html#installing-in-notebook-language-bindings">Installation - papermill 2.4.0 documentation</a><br/><a href="https://papermill.readthedocs.io/en/latest/usage-cli.html">Command Line Interface - papermill 2.4.0 documentation</a><br/><a href="https://papermill.readthedocs.io/en/latest/reference/index.html">Reference - papermill 2.4.0 documentation</a><br/><a href="https://papermill.readthedocs.io/en/latest/reference/papermill-translators.html#translators">Language Translators - papermill 2.4.0 documentation</a><br/><a href="https://papermill.readthedocs.io/en/latest/reference/papermill-workflow.html#module-papermill.engines">Workflow - papermill 2.4.0 documentation</a><br/><a href="https://github.com/rjdoubleu/Colab-Papermill-Patch/blob/master/Colab-Papermill-Driver.ipynb">Colab-Papermill-Patch/Colab-Papermill-Driver.ipynb at master ¬∑ rjdoubleu/Colab-Papermill-Patch</a><br/><a href="https://github.com/davidbrochart/nbterm">davidbrochart/nbterm: Jupyter Notebooks in the terminal.</a><br/><a href="https://github.com/simonalexanderson/StyleGestures/tree/master/data_processing">StyleGestures/data_processing at master ¬∑ simonalexanderson/StyleGestures</a><br/><a href="https://github.com/simonalexanderson/StyleGestures/tree/master/data_processing/pymo">StyleGestures/data_processing/pymo at master ¬∑ simonalexanderson/StyleGestures</a><br/><a href="https://github.com/simonalexanderson/StyleGestures/commit/d02a883f72ee78105d6d923c1f60f1075759501e">changed rotation framework ¬∑ simonalexanderson/StyleGestures@d02a883</a><br/><a href="https://github.com/simonalexanderson/StyleGestures/commit/cdb8e32538798cb68e5e4e9a59d34e5535919178">changed rotation framework ¬∑ simonalexanderson/StyleGestures@cdb8e32</a><br/><a href="https://github.com/simonalexanderson/StyleGestures/blob/master/data_processing/motion_features.py">StyleGestures/data_processing/motion_features.py at master ¬∑ simonalexanderson/StyleGestures</a><br/><a href="https://github.com/simonalexanderson?tab=repositories">simonalexanderson (simonalexanderson) / Repositories</a><br/><a href="https://github.com/simonalexanderson/StyleGestures">simonalexanderson/StyleGestures</a><br/><a href="https://github.com/simonalexanderson/ListenDenoiseAction">simonalexanderson/ListenDenoiseAction: Code to reproduce the results for our SIGGRAPH 2023 paper "Listen Denoise Action"</a><br/><a href="https://github.com/simonalexanderson/MoGlow">simonalexanderson/MoGlow</a><br/><a href="https://github.com/simonalexanderson/StyleGestures">simonalexanderson/StyleGestures</a><br/><a href="https://github.com/simonalexanderson/StyleGestures/commit/bd906cf7d140972262920ed8774407e9dbd2a875">Update links to gesture data ¬∑ simonalexanderson/StyleGestures@bd906cf</a><br/><a href="https://github.com/simonalexanderson/StyleGestures/blob/master/data_processing/pymo/Quaternions.py">StyleGestures/data_processing/pymo/Quaternions.py at master ¬∑ simonalexanderson/StyleGestures</a><br/><a href="https://github.com/simonalexanderson/StyleGestures/commit/023af476d7d062ddf517c724f23771c9734f49d1">changed rotation framework ¬∑ simonalexanderson/StyleGestures@023af47</a><br/><a href="https://github.com/peterhinch/micropython-samples/blob/master/quaternion/quat.py">micropython-samples/quaternion/quat.py at master ¬∑ peterhinch/micropython-samples</a><br/><a href="https://github.com/moble/quaternion/blob/main/src/quaternion.c">quaternion/src/quaternion.c at main ¬∑ moble/quaternion</a><br/><a href="https://github.com/martinling/numpy_quaternion">martinling/numpy_quaternion: Prototype Quaternion dtype support for Numpy - see https://github.com/moble/quaternion for maintained version</a><br/><a href="https://github.com/moble/quaternionic/blob/main/quaternionic/interpolation.py">quaternionic/quaternionic/interpolation.py at main ¬∑ moble/quaternionic</a><br/><a href="https://www.google.com/search?q=python+quaternion+class&rlz=1C5GCEM_enSE990SE991&oq=python+quaternion+class&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIKCAEQABiABBiiBDIKCAIQABiABBiiBDIKCAMQABiABBiiBNIBCDU1MjhqMGo3qAIAsAIA&sourceid=chrome&ie=UTF-8">python quaternion class - Google Search</a><br/><a href="https://github.com/KieranWynn/pyquaternion">KieranWynn/pyquaternion: A fully featured, pythonic library for representing and using quaternions</a><br/><a href="https://kieranwynn.github.io/pyquaternion/#conjugation">pyquaternion</a><br/><a href="https://github.com/KieranWynn/pyquaternion/commits/master/">Commits ¬∑ KieranWynn/pyquaternion</a><br/><a href="https://github.com/nagyrajmund?tab=repositories">nagyrajmund (nagyrajmund) / Repositories</a><br/><a href="https://github.com/Svito-zar/gesticulator/blob/master/gesticulator/visualization/pymo/rotation_tools.py">gesticulator/gesticulator/visualization/pymo/rotation_tools.py at master ¬∑ Svito-zar/gesticulator</a><br/><a href="https://github.com/jonepatr?tab=repositories">jonepatr (jonepatr) / Repositories</a><br/><a href="https://github.com/jonepatr/affordance?tab=readme-ov-file">jonepatr/affordance: The code repository for the Affordance++ master thesis</a><br/><a href="https://github.com/vrpn/vrpn/blob/master/README.Legal">vrpn/README.Legal at master ¬∑ vrpn/vrpn</a><br/><a href="https://github.com/jonepatr/lets_face_it">jonepatr/lets_face_it: This is the official implementation for IVA'20 Best Paper Award paper "Let's Face It: Probabilistic Multi-modal Interlocutor-aware Generation of Facial Gestures in Dyadic Settings"</a><br/><a href="https://github.com/orgs/facebookresearch/repositories?page=2">facebookresearch repositories</a><br/><a href="https://github.com/facebookresearch/fvcore/blob/main/fvcore/nn/smooth_l1_loss.py">fvcore/fvcore/nn/smooth_l1_loss.py at main ¬∑ facebookresearch/fvcore</a><br/><a href="https://github.com/facebookresearch/Pearl">facebookresearch/Pearl: A Production-ready Reinforcement Learning AI Agent Library brought by the Applied Reinforcement Learning team at Meta.</a><br/><a href="https://github.com/facebookresearch/hand_tracking_toolkit/blob/main/hand_tracking_toolkit/hand_models/mano_hand_model.py">hand_tracking_toolkit/hand_tracking_toolkit/hand_models/mano_hand_model.py at main ¬∑ facebookresearch/hand_tracking_toolkit</a><br/><a href="https://colab.research.google.com/drive/1e8Ta7b5z1loIEfDI3pstW_AXZOMAX-_f#scrollTo=HojPLGFEyKj9">sonar_speech_encoder_training_example.ipynb - Colab</a><br/><a href="https://huggingface.co/facebook/blaser-2.0-qe">facebook/blaser-2.0-qe ¬∑ Hugging Face</a><br/><a href="https://github.com/facebookresearch/SONAR/blob/main/sonar/cards/text_sonar_finetuned_decoder.yaml">SONAR/sonar/cards/text_sonar_finetuned_decoder.yaml at main ¬∑ facebookresearch/SONAR</a><br/><a href="https://github.com/facebookresearch/generative-recommenders">facebookresearch/generative-recommenders: Repository hosting code used to reproduce results in "Actions Speak Louder than Words: Trillion-Parameter Sequential Transducers for Generative Recommendations" (https://arxiv.org/abs/2402.17152).</a><br/><a href="https://github.com/facebookresearch/spot-sim2real">facebookresearch/spot-sim2real: Spot Sim2Real Infrastructure</a><br/><a href="https://github.com/facebookresearch/habitat-sim">facebookresearch/habitat-sim: A flexible, high-performance 3D simulator for Embodied AI research.</a><br/><a href="https://github.com/facebookresearch/pytorch3d?tab=readme-ov-file">facebookresearch/pytorch3d: PyTorch3D is FAIR's library of reusable components for deep learning with 3D data</a><br/><a href="https://github.com/Daniil-Osokin/lightweight-human-pose-estimation.pytorch">Daniil-Osokin/lightweight-human-pose-estimation.pytorch: Fast and accurate human pose estimation in PyTorch. Contains implementation of "Real-time 2D Multi-Person Pose Estimation on CPU: Lightweight OpenPose" paper.</a><br/><a href="https://github.com/ai4r/Gesture-Generation-from-Trimodal-Context">ai4r/Gesture-Generation-from-Trimodal-Context: Speech Gesture Generation from the Trimodal Context of Text, Audio, and Speaker Identity (SIGGRAPH Asia 2020)</a><br/><a href="https://github.com/simonalexanderson/StyleGestures">simonalexanderson/StyleGestures</a><br/><a href="https://github.com/ghenter/trim_bvh/blob/master/trim_bvh.py">trim_bvh/trim_bvh.py at master ¬∑ ghenter/trim_bvh</a><br/><a href="https://github.com/liu-nlp/dl4nlp/blob/main/website/modules/module0/Introduction_to_PyTorch.ipynb">dl4nlp/website/modules/module0/Introduction_to_PyTorch.ipynb at main ¬∑ liu-nlp/dl4nlp</a><br/><a href="https://github.com/nagyrajmund/gesturebot/commit/33bdb2a6c49106073c7aeb4761058ac011cb9f44#diff-42c340b52cd5dc5121f34f132daed9ce5f07f0de50648d0ed2d163e14e4eec0e">Release the gesture generation component. ¬∑ nagyrajmund/gesturebot@33bdb2a</a><br/><a href="https://github.com/GestureGeneration/Speech_driven_gesture_generation_with_autoencoder/pulls?q=is%3Apr+is%3Aclosed">Pull requests ¬∑ GestureGeneration/Speech_driven_gesture_generation_with_autoencoder</a><br/><a href="https://github.com/GestureGeneration/Speech_driven_gesture_generation_with_autoencoder/blob/GENEA_2020/data_processing/pymo/features.py">Speech_driven_gesture_generation_with_autoencoder/data_processing/pymo/features.py at GENEA_2020 ¬∑ GestureGeneration/Speech_driven_gesture_generation_with_autoencoder</a><br/><a href="https://github.com/GestureGeneration/Speech_driven_gesture_generation_with_autoencoder/tree/master/data_processing">Speech_driven_gesture_generation_with_autoencoder/data_processing at master ¬∑ GestureGeneration/Speech_driven_gesture_generation_with_autoencoder</a><br/><a href="https://www.google.com/search?q=python+wiktionary+parser&rlz=1C5GCEM_enSE990SE991&oq=python+wiktionary+parser&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIICAEQABgWGB4yCggCEAAYgAQYogQyCggDEAAYgAQYogTSAQg0MTY2ajBqN6gCALACAA&sourceid=chrome&ie=UTF-8">python wiktionary parser - Google Search</a><br/><a href="https://github.com/alessandrome/pywiktionary">alessandrome/pywiktionary: Python Wiktionary Parser for different languages. Check README fo supported languages</a><br/><a href="https://github.com/tatuylonen/wiktextract/blob/master/README.md">wiktextract/README.md at master ¬∑ tatuylonen/wiktextract</a><br/><a href="https://github.com/tatuylonen/wikitextprocessor/">tatuylonen/wikitextprocessor: Python package for WikiMedia dump processing (Wiktionary, Wikipedia etc). Wikitext parsing, template expansion, Lua module execution. For data extraction, bulk syntax checking, error detection, and offline formatting.</a><br/><a href="https://github.com/tatuylonen/wiktextract?tab=readme-ov-file">tatuylonen/wiktextract: Wiktionary dump file parser and multilingual data extractor</a><br/><a href="https://github.com/tatuylonen/wikitextprocessor/blob/main/tests/animal.txt">wikitextprocessor/tests/animal.txt at main ¬∑ tatuylonen/wikitextprocessor</a><br/><a href="https://github.com/tatuylonen/wiktextract/tree/master/src/wiktextract/extractor">wiktextract/src/wiktextract/extractor at master ¬∑ tatuylonen/wiktextract</a><br/><a href="https://github.com/suyashb95/WiktionaryParser">suyashb95/WiktionaryParser: A Python Wiktionary Parser</a><br/><a href="https://github.com/suyashb95/WiktionaryParser/blob/master/wiktionaryparser/core.py">WiktionaryParser/wiktionaryparser/core.py at master ¬∑ suyashb95/WiktionaryParser</a><br/><a href="https://www.instagram.com/">Instagram</a><br/><a href="https://www.instagram.com/e_heni_0810">Hiroshi (@e_heni_0810) ‚Ä¢ Instagram photos and videos</a><br/><a href="https://github.com/wikimedia/pywikibot">wikimedia/pywikibot: A Python library that interfaces with the MediaWiki API. This is a mirror from gerrit.wikimedia.org. Do not submit any patches here. See https://www.mediawiki.org/wiki/Developer_account for contributing.</a><br/><a href="https://en.wiktionary.org/wiki/aithn%C3%ADm">aithn√≠m - Wiktionary, the free dictionary</a><br/><a href="https://en.wiktionary.org/wiki/bhfuil">bhfuil - Wiktionary, the free dictionary</a><br/><a href="https://www.teanglann.ie/ga/fuaim/sruth%c3%a1n">Bunachar Foghra√≠ochta: sruth√°n</a><br/><a href="https://www.instagram.com/">Instagram</a><br/><a href="chrome://newtab/">New Tab</a><br/><a href="https://en.wiktionary.org/wiki/sr%C3%B3nach#Irish">sr√≥nach - Wiktionary, the free dictionary</a><br/><a href="https://www.rte.ie/news/">News | Latest Breaking News Stories & Headlines | RT√â</a><br/><a href="https://www.rte.ie/sport/paris-2024/2024/0810/1464416-paris-2024-day-16-and-closing-ceremony-updates/">Live: Paris 2024: Day 16 and closing ceremony updates</a><br/><a href="https://www.bbc.com/sport">BBC Sport - Scores, Fixtures, News - Live Sport</a><br/><a href="https://www.youtube.com/channel/UCW6-BQWFA70Dyyc7ZpZ9Xlg">BBC Sport - YouTube</a><br/><a href="https://www.youtube.com/watch?v=Yy3tmbgSM4U">Could you lift as much as Team GB's Emily Campbell? | Paris 2024 Olympics | BBC Sport - YouTube</a><br/><a href="https://www.youtube.com/@TG4TV/videos">TG4 - YouTube</a><br/><a href="https://www.youtube.com/@SportTG4/videos">Sp√≥rt TG4 - YouTube</a><br/><a href="https://www.youtube.com/watch?v=KdLtIhu39OE">T√©acs Taistil | Travel to Palermo, Sicily le TG4‚úàÔ∏è - YouTube</a><br/><a href="https://www.youtube.com/watch?v=pmMUCv4HfD8">T√©acs Taistil | Travel to Stockholm, Sweden with TG4 ‚úàÔ∏è - YouTube</a><br/><a href="https://www.google.com/search?q=kaninhop+stockholm&rlz=1C5GCEM_enSE990SE991&oq=kaninhop+stock&gs_lcrp=EgZjaHJvbWUqCAgBEAAYFhgeMgYIABBFGDkyCAgBEAAYFhgeMgoIAhAAGKIEGIkF0gEINjM2MGowajSoAgCwAgE&sourceid=chrome&ie=UTF-8">kaninhop stockholm - Google Search</a><br/><a href="https://www.quora.com/What-are-some-unusual-fun-things-to-do-in-Stockholm">What are some unusual fun things to do in Stockholm? - Quora</a><br/><a href="https://www.instagram.com/">Instagram</a><br/><a href="https://wezfurlong.org/wezterm/multiplexing.html#connecting">Multiplexing - Wez's Terminal Emulator</a><br/><a href="https://wezfurlong.org/wezterm/config/files.html#configuration-files">Configuration - Wez's Terminal Emulator</a><br/><a href="https://wezfurlong.org/wezterm/cli/general.html">CLI Reference - Wez's Terminal Emulator</a><br/><a href="https://wezfurlong.org/wezterm/escape-sequences.html#printable-codepoints">Escape Sequences - Wez's Terminal Emulator</a><br/><a href="https://wezfurlong.org/wezterm/install/linux.html#installing-on-linux-using-appimage">Linux - Wez's Terminal Emulator</a><br/><a href="https://www.instagram.com/">Instagram</a><br/><a href="https://gist.github.com/jimregan">jimregan‚Äôs gists</a><br/><a href="https://github.com/jimregan/sync-asr/pull/55/files">[failed experiment] whisperx reverse diarisation by jimregan ¬∑ Pull Request #55 ¬∑ jimregan/sync-asr</a><br/><a href="https://github.com/jimregan/sync-asr/pull/55">[failed experiment] whisperx reverse diarisation by jimregan ¬∑ Pull Request #55 ¬∑ jimregan/sync-asr</a><br/><a href="https://github.com/jimregan/sync-asr/pull/57">[sbt22] Phonetic by jimregan ¬∑ Pull Request #57 ¬∑ jimregan/sync-asr</a><br/><a href="https://www.instagram.com/">Instagram</a><br/><a href="https://github.com/m-bain/whisperX/blob/main/whisperx/alignment.py">whisperX/whisperx/alignment.py at main ¬∑ m-bain/whisperX</a><br/><a href="https://www.google.com/search?q=wezterm+tmux&rlz=1C5GCEM_enSE990SE991&oq=wezterm+tmu&gs_lcrp=EgZjaHJvbWUqDggAEEUYJxg7GIAEGIoFMg4IABBFGCcYOxiABBiKBTIGCAEQRRg5MgcIAhAAGIAEMgcIAxAAGIAEMgcIBBAAGIAEMggIBRAAGBYYHjIICAYQABgWGB4yBggHEEUYPNIBCDMxOTJqMGo3qAIAsAIA&sourceid=chrome&ie=UTF-8">wezterm tmux - Google Search</a><br/><a href="https://www.florianbellmann.com/blog/switch-from-tmux-to-wezterm">How to switch from Tmux to WezTerm | Florian Bellmann | Be curious, explore and meditate.</a><br/><a href="https://www.florianbellmann.com/blog/switch-from-tmux-to-wezterm#wezterm-meets-neovim">How to switch from Tmux to WezTerm | Florian Bellmann | Be curious, explore and meditate.</a><br/><a href="https://github.com/alacritty/alacritty">alacritty/alacritty: A cross-platform, OpenGL terminal emulator.</a><br/><a href="https://alacritty.org/">Alacritty - A cross-platform, OpenGL terminal emulator</a><br/><a href="https://kavigihan.medium.com/efficient-terminal-setup-with-alacritty-and-tmux-65a321091434">Efficient terminal setup with alacritty and tmux | by Kavishka Gihan | Medium</a><br/><a href="https://www.google.com/search?q=disney+castle&rlz=1C5GCEM_enSE990SE991&oq=disney+castle&gs_lcrp=EgZjaHJvbWUyCQgAEEUYORiABDIHCAEQABiABDIHCAIQABiABDIHCAMQABiABDIHCAQQABiABDIHCAUQABiABDIHCAYQABiABDIHCAcQABiABDIHCAgQABiABDIHCAkQABiPAtIBCDI0ODNqMGo3qAIAsAIA&sourceid=chrome&ie=UTF-8">disney castle - Google Search</a><br/><a href="https://sltc2024.github.io/">SLTC 2024 | Swedish Language Technology Conference (SLTC) 2024</a><br/><a href="https://github.com/m-bain/whisperX">m-bain/whisperX: WhisperX: Automatic Speech Recognition with Word-level Timestamps (& Diarization)</a><br/><a href="https://www.instagram.com/">Instagram</a><br/><a href="https://www.instagram.com/">Instagram</a><br/><a href="https://www.youtube.com/">YouTube</a><br/><a href="https://www.youtube.com/watch?v=09s9OoHqpV4">Can Karate Work in MMA? - YouTube</a><br/><a href="https://www.youtube.com/">YouTube</a><br/><a href="https://www.youtube.com/shorts/iMcLRAxT4aw">Gary Oldman tells Harrison Ford story - YouTube</a><br/><a href="https://www.youtube.com/shorts/X2lSeyy8UC4">The fastest guitar solo I've ever written - YouTube</a><br/><a href="https://www.youtube.com/watch?v=aOUI-GskZxs">A Rammstein Snow White?! Opera Singers analyze "Sonne" and show you what it's truly about! - YouTube</a><br/><a href="https://github.com/nteract/papermill">nteract/papermill: üìö Parameterize, execute, and analyze notebooks</a><br/><a href="https://www.instagram.com/">Instagram</a><br/><a href="https://www.google.com/search?q=segment+speech+for+tts&rlz=1C5GCEM_enSE990SE991&oq=segment+speech+for+tts&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIHCAEQIRigAdIBCDUwODBqMGo3qAIAsAIA&sourceid=chrome&ie=UTF-8">segment speech for tts - Google Search</a><br/><a href="https://link.springer.com/chapter/10.1007/978-3-030-27947-9_31">LSTM-Based Speech Segmentation for TTS Synthesis | SpringerLink</a><br/><a href="https://www.researchgate.net/profile/Boris-Lobanov-2/publication/274715346_Speech_Corpus_Phonetic_Segmentation_for_TTS_Synthesis/links/55279eae0cf229e6d6362fd7/Speech-Corpus-Phonetic-Segmentation-for-TTS-Synthesis.pdf">SPECOM'2007</a><br/><a href="https://www.google.com/search?q=adjust+asr+output+to+silence+boundaries&rlz=1C5GCEM_enSE990SE991&oq=adjust+asr+output+to+silence+boundaries&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIHCAEQIRigATIHCAIQIRigAdIBCDk2OThqMGo3qAIAsAIA&sourceid=chrome&ie=UTF-8">adjust asr output to silence boundaries - Google Search</a><br/><a href="https://patents.google.com/patent/US8364485B2/en">US8364485B2 - Method for automatically identifying sentence boundaries in noisy conversational data - Google Patents</a><br/><a href="https://medium.com/@xriteshsharmax/speaker-diarization-using-whisper-asr-and-pyannote-f0141c85d59a">Speaker diarization using Whisper ASR and Pyannote | by Ritesh | Medium</a><br/><a href="https://www.geeksforgeeks.org/partial-functions-python/">Partial Functions in Python - GeeksforGeeks</a><br/><a href="https://numba.pydata.org/numba-doc/dev/reference/numpysupported.html">Supported NumPy features ‚Äî Numba 0.52.0.dev0+274.g626b40e-py3.7-linux-x86_64.egg documentation</a><br/><a href="https://isamu-website.medium.com/understanding-the-triton-tutorials-part-1-6191b59ba4c">Understanding the Triton Tutorials Part 1 | by Isamu Isozaki | Medium</a><br/><a href="https://chatgpt.com/c/0ea353db-7e91-4b11-8f19-e3d57361571b">Refactor ZCR Calculation</a><br/><a href="https://www.instagram.com/">Instagram</a><br/><a href="https://www.youtube.com/watch?v=N-2Ahuz23O4">Katy Perry Rates British And American Food | Snack Wars - YouTube</a><br/><a href="https://en.wikipedia.org/wiki/The_Instigators">The Instigators - Wikipedia</a><br/><a href="https://en.wikipedia.org/wiki/Dark_Matter_(2024_TV_series)">Dark Matter (2024 TV series) - Wikipedia</a><br/><a href="https://stackoverflow.com/questions/38015319/how-to-create-a-numpy-array-from-a-pydub-audiosegment">python - How to create a numpy array from a pydub AudioSegment? - Stack Overflow</a><br/><a href="https://github.com/pyannote/pyannote-audio/blob/develop/pyannote/audio/core/model.py">pyannote-audio/pyannote/audio/core/model.py at develop ¬∑ pyannote/pyannote-audio</a><br/><a href="https://lightning.ai/docs/pytorch/stable/tutorials.html">PyTorch Lightning Tutorials ‚Äî PyTorch Lightning 2.4.0 documentation</a><br/><a href="https://lightning.ai/docs/pytorch/stable/notebooks/course_UvA-DL/01-introduction-to-pytorch.html">Tutorial 1: Introduction to PyTorch ‚Äî PyTorch Lightning 2.4.0 documentation</a><br/><a href="https://www.youtube.com/watch?v=wnKZZgFQY-E">Tutorial 2: Introduction to PyTorch (Part 1) - YouTube</a><br/><a href="https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial2/Introduction_to_PyTorch.html">Tutorial 2: Introduction to PyTorch ‚Äî UvA DL Notebooks v1.2 documentation</a><br/><a href="https://colab.research.google.com/github/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/tutorial2/Introduction_to_PyTorch.ipynb">Introduction_to_PyTorch.ipynb - Colab</a><br/><a href="https://chatgpt.com/c/7efada33-4d03-44b2-b423-ac5066a85264">ChatGPT</a><br/><a href="https://numpy.org/doc/stable/reference/generated/numpy.reshape.html">numpy.reshape ‚Äî NumPy v2.0 Manual</a><br/><a href="https://stackoverflow.com/questions/4661557/pil-rotate-image-colors-bgr-rgb">python - PIL rotate image colors (BGR -> RGB) - Stack Overflow</a><br/><a href="https://numpy.org/doc/stable/reference/generated/numpy.floor.html">numpy.floor ‚Äî NumPy v2.0 Manual</a><br/><a href="https://arxiv.org/abs/2408.06292">[2408.06292] The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery</a><br/><a href="https://arxiv.org/pdf/2408.06292">2408.06292</a><br/><a href="https://github.com/SakanaAI/AI-Scientist">SakanaAI/AI-Scientist: The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery üßë‚Äçüî¨</a><br/><a href="https://github.com/gregversteeg/NPEET/blob/master/npeet/entropy_estimators.py">NPEET/npeet/entropy_estimators.py at master ¬∑ gregversteeg/NPEET</a><br/><a href="https://colab.research.google.com/drive/1IELcBvmJYya0s3m98ngdO8LUPKTa8WI2#scrollTo=z6hcmz5EOolm">Untitled42.ipynb - Colab</a><br/><a href="https://github.com/threeplanetssoftware/apple_cloud_notes_parser">threeplanetssoftware/apple_cloud_notes_parser: Parser for Apple Notes data stored on the Cloud as seen on Apple handsets</a><br/><a href="https://www.nodalida-bhlt2025.eu/call-for-papers">NoDaLiDa/Baltic-HLT 2025 - Call for papers</a><br/><a href="https://www.youtube.com/watch?v=djSKp_pwmOA">The Crow (2024) Official Trailer - Bill Skarsg√•rd, FKA twigs, Danny Huston - YouTube</a><br/><a href="https://www.youtube.com/watch?v=djSKp_pwmOA">The Crow (2024) Official Trailer - Bill Skarsg√•rd, FKA twigs, Danny Huston - YouTube</a><br/><a href="https://www.flickr.com/photos/jimregan/53923054428/in/dateposted/">53108652202_27b842565b_k | Jim O'Regan | Flickr</a><br/><a href="https://www.instagram.com/">Instagram</a><br/><a href="https://www.theguardian.com/technology/article/2024/aug/14/jk-rowling-and-elon-musk-named-in-imane-khelif-cyberbullying-lawsuit?utm_source=instagramstories&utm_campaign=cyberbullyinginsta">JK Rowling and Elon Musk named in Imane Khelif cyberbullying lawsuit | France | The Guardian</a><br/><a href="https://drive.google.com/drive/u/0/folders/1A87uy5EnuCovo2xInruefXuUGM8hH15s">Aab - Google Drive</a><br/><a href="https://github.com/daschablume/g2p_correction/commit/1de1b773fc96851bbe2ed42934f4b17adf8ed3a8">deleted a class property because it is unused and uses old code which‚Ä¶ ¬∑ daschablume/g2p_correction@1de1b77</a><br/><a href="https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/blob/main/montreal_forced_aligner/g2p/phonetisaurus_trainer.py">Montreal-Forced-Aligner/montreal_forced_aligner/g2p/phonetisaurus_trainer.py at main ¬∑ MontrealCorpusTools/Montreal-Forced-Aligner</a><br/><a href="https://github.com/google/language-resources/commits/master/">Commits ¬∑ google/language-resources</a><br/><a href="https://github.com/MODU-FTNC/google-language-resources/commits/master/">Commits ¬∑ MODU-FTNC/google-language-resources</a><br/><a href="https://github.com/google/language-resources/blob/master/festus/runtime/compact.h">language-resources/festus/runtime/compact.h at master ¬∑ google/language-resources</a><br/><a href="https://github.com/search?q=repo%3Agoogle%2Flanguage-resources++language%3AStarlark&type=code">Code search results</a><br/><a href="https://chatgpt.com/c/1cd6a8fb-f5ca-4111-b2a9-ec4ea21794c4">ChatGPT</a><br/><a href="https://www.opengrm.org/twiki/bin/view/GRM/PyniniDocs">PyniniDocs < GRM < TWiki</a><br/><a href="https://www.openfst.org/twiki/bin/view/GRM/WebIndex">WebIndex < GRM < TWiki</a><br/><a href="https://www.openfst.org/twiki/bin/view/GRM/BaumWelch">BaumWelch < GRM < TWiki</a><br/><a href="https://opengrm.org/doxygen/baumwelch/html/train_8h_source.html">BaumWelch: /home/openfst/src/grm/baumwelch/baumwelch-0.3.9/src/include/baumwelch/train.h Source File</a><br/><a href="https://www.google.com/search?q=pynini+tutorial&rlz=1C5GCEM_enSE990SE991&oq=pynini+tutorial&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIKCAEQABiABBiiBNIBCDM2NTdqMGo0qAIAsAIB&sourceid=chrome&ie=UTF-8">pynini tutorial - Google Search</a><br/><a href="https://www.ldc.upenn.edu/sites/www.ldc.upenn.edu/files/kbg2019.pdf">A tutorial on finite-state text processing</a><br/><a href="https://www.oreilly.com/content/how-to-get-superior-text-processing-in-python-with-pynini/">How to get superior text processing in Python with Pynini ‚Äì O‚ÄôReilly</a><br/><a href="https://colab.research.google.com/drive/1K6bmCurPR7LhxDKD--L-7P90gafmdFav?usp=sharing">Lab03_2022.ipynb - Colab</a><br/><a href="https://github.com/NVIDIA/NeMo-text-processing/blob/main/tutorials/WFST_Tutorial.ipynb">NeMo-text-processing/tutorials/WFST_Tutorial.ipynb at main ¬∑ NVIDIA/NeMo-text-processing</a><br/><a href="https://www.openfst.org/twiki/bin/view/GRM/Pynini">Pynini < GRM < TWiki</a><br/><a href="https://www.openfst.org/twiki/bin/view/GRM/SFstBackground">SFstBackground < GRM < TWiki</a><br/><a href="https://www.instagram.com/">Instagram</a><br/><a href="https://translate.google.com/?sl=auto&tl=en&text=Jag%20kontaktar%20dig%20om%20resa%20och%20eventuellt%20hotellrum%20i%20samband%20med%20Nationella%20spr%C3%A5kbankens%20h%C3%B6stworkshop%20i%20Uppsala%20torsdagen%20den%2024%20oktober%2C%20d%C3%A4r%20du%20%C3%A4r%20en%20av%20talarna.%0ANationella%20spr%C3%A5kbanken%20st%C3%A5r%20f%C3%B6r%20kostnaderna%20f%C3%B6r%20din%20resa%20tur%20och%20retur.%20Likas%C3%A5%20hotell%C3%B6vernattning%2C%20om%20det%20beh%C3%B6vs.%20%20F%C3%B6r%20enkelhetens%20skull%20bokas%20helst%20resorna%20av%20G%C3%B6teborgs%20universitet%20(via%20mig).%0ADu%20f%C3%A5r%20g%C3%A4rna%20skicka%20avreseort%20och%20%C3%B6nskade%20restider%2C%20s%C3%A5%20tar%20jag%20fram%20ett%20f%C3%B6rslag%20innan%20bokning.%0A%20%0AProgrammet%20f%C3%B6r%20dagen%20hittar%20du%20nedan%20och%20p%C3%A5%20denna%20webbsidan%3A%0Ahttps%3A%2F%2Fxn--sprkbanken-35a.se%2Fhostworkshop%0A%20%0AV%C3%A4lkommen%20att%20h%C3%B6ra%20av%20dig%20om%20du%20har%20fr%C3%A5gor.%0A%20&op=translate">Google Translate</a><br/><a href="https://xn--sprkbanken-35a.se/hostworkshop">H√∂stworkshop | Spr√•kbanken</a><br/><a href="https://www.sj.se/sok-resa/valj-biljettyp/Uppsala%20Central/Stockholm%20Central/2024-08-15/utresa">V√§lj biljettyp f√∂r utresa - SJ</a><br/><a href="https://www.facebook.com/">www.facebook.com</a><br/><a href="https://mixbutton.com/mixing-articles/music-note-to-frequency-chart/">Music Note Frequency Chart - Music Frequency Chart | MixButton</a><br/><a href="https://www.instagram.com/">Stories ‚Ä¢ Instagram</a><br/><a href="https://www.youtube.com/">YouTube</a><br/><a href="https://www.youtube.com/watch?v=eSjdYkqY5WI">The Beastie Boys Expose The Truth About Gold Records | Conan O'Brien Needs A Friend - YouTube</a><br/><a href="https://kulturfestivalen.stockholm.se/programpunkt/teddybears/">Kulturfestivalen - Teddybears</a><br/><a href="https://www.youtube.com/watch?v=s5SA6L722kI">Teddybears - Cobrastyle (feat. Mad Cobra) [Official Video] - YouTube</a><br/><a href="https://www.instagram.com/direct/t/117353749660233/">Inbox ‚Ä¢ Direct</a><br/><a href="https://www.youtube.com/watch?v=DyOtTMCKTPg">The Science-Backed Shortcut to Boulder Shoulders ‚Äì It‚Äôs Insane! - YouTube</a><br/><a href="https://www.google.com/search?q=gajla+swedish&sca_esv=9ea59d307d2a2909&sca_upv=1&rlz=1C5GCEM_enSE990SE991&sxsrf=ADLYWIK06OlAfXqRdBNUZZvwq_TNhBgD2w%3A1723909315367&ei=w8TAZrf8FZ2uwPAPhpDugQc&ved=0ahUKEwj36ffSrvyHAxUdFxAIHQaIO3AQ4dUDCA8&uact=5&oq=gajla+swedish&gs_lp=Egxnd3Mtd2l6LXNlcnAaAhgCIg1nYWpsYSBzd2VkaXNoMgUQIRigATIFECEYoAFIww9QP1jpC3ABeACQAQCYAYgBoAHBBaoBAzcuMbgBA8gBAPgBAZgCCaAC5wXCAg0QABiABBiwAxhDGIoFwgIIEAAYgAQYsAPCAgoQABiABBiwAxgKwgIQEC4YgAQYsAMYyAMYCtgBAcICFBAuGIAEGLADGMcBGMgDGK8B2AEBwgIXEC4YgAQYsAMYxwEYmAUYyAMYrwHYAQHCAg4QLhiABBiwAxjIA9gBAcICBxAuGIAEGArCAgcQABiABBgKwgIQEC4YgAQYqAMYChiaAxiLA8ICChAAGIAEGAoYiwPCAh8QLhiABBimAxjHARiYBRioAxiZBRgKGIsDGJ4FGK8BwgIiEC4YgAQYChiXBRjcBBjeBBjgBBj0AxjxAxj1Axj2A9gBAsICCBAAGBYYChgewgILEAAYFhgKGIsDGB7CAgkQABgWGIsDGB7CAhQQLhjwAxijAxgWGKgDGAoYiwMYHsICBhAAGBYYHsICCBAAGIAEGKIEwgIHECEYoAEYCpgDAIgGAZAGE7oGBggBEAEYCLoGBggCEAEYFJIHAzguMaAHqi8&sclient=gws-wiz-serp">gajla swedish - Google Search</a><br/><a href="https://www.youtube.com/watch?v=gZztPMkV9pQ">I Tried To Expose BJJ - YouTube</a><br/><a href="https://www.youtube.com/watch?v=QhTwTfQrx5s">The Secret of Kung Fu POWER - YouTube</a><br/><a href="https://www.instagram.com/direct/t/110437113687820/">Inbox ‚Ä¢ Direct</a><br/><a href="https://www.youtube.com/watch?v=w-pOpSsDcIc">Can Karate Beat Wing Chun in a Street Fight - YouTube</a><br/><a href="https://biljettshop.se/sv/amon-amarth-fyrishov-uppsala-29-augusti/?gad_source=1&gclid=Cj0KCQjwt4a2BhD6ARIsALgH7DpINiBJ6ryUicSTCMb59-Ng4G011GFA3I1uf5JZV07Nl_nNcTiFjoEaAhw6EALw_wcB">Tickets for Amon Amarth - Heidrun Over Sweden + The Halo Effect + Insomnium Fyrishov (ON SALE) 2024-08-29 18:00 | BiljettShop.se</a><br/><a href="https://www.instagram.com/direct/t/110437113687820/">Inbox ‚Ä¢ Direct</a><br/><a href="https://www.instagram.com/direct/inbox/">(1) Inbox ‚Ä¢ Direct</a><br/><a href="https://github.com/sprakbankental/edyson">sprakbankental/edyson</a><br/><a href="https://github.com/perfall?tab=repositories">perfall (perfall) / Repositories</a><br/><a href="https://github.com/perfall/Edyson/blob/master/python/audio_processing.py">Edyson/python/audio_processing.py at master ¬∑ perfall/Edyson</a><br/><a href="https://cst.dk/DHN2019Pro/papers/11_2018-dhn-fallgrenmmae-final.pdf">Microsoft Word - 2018-dhn-mmae_ZM.docm</a><br/><a href="https://www.audeering.com/opensmile/">openSMILE 3.0 - audEERING</a><br/><a href="https://github.com/audeering/opensmile/pulls?q=is%3Apr+is%3Aclosed">Pull requests ¬∑ audeering/opensmile</a><br/><a href="https://pytorch.org/tutorials/beginner/audio_preprocessing_tutorial.html#comparing-against-librosa">Audio manipulation with torchaudio ‚Äî PyTorch Tutorials 1.10.0+cu102 documentation</a><br/><a href="https://github.com/pytorch/audio/blob/main/src/torio/io/_streaming_media_decoder.py">audio/src/torio/io/_streaming_media_decoder.py at main ¬∑ pytorch/audio</a><br/><a href="https://www.youtube.com/watch?v=_qQK8o20Qtk">8 Out of 10 Cats Does Countdown - Series 26 Episode 05 - YouTube</a><br/><a href="https://www.youtube.com/watch?v=HpFaEdcMlMI">UGLY KID JOE Live at Bloodstock 2023 - Lemmy Tribute ft. Andreas Kisser - YouTube</a><br/><a href="https://www.youtube.com/@ozmartian2">ozmartian - YouTube</a><br/><a href="https://www.youtube.com/watch?v=Geiw3uL_GEM">Jimmy Carr's I Literally Just Told You - Series 04 Episode 05 - YouTube</a><br/><a href="https://www.youtube.com/watch?v=G0jxMy8DmOg&t=19s">Jimmy Carr's I Literally Just Told You - Series 04 Episode 04 - YouTube</a><br/><a href="https://www.instagram.com/direct/t/104511860951810/">Inbox ‚Ä¢ Direct</a><br/><a href="https://liziliao.github.io/papers/2021sigir_mmconv.pdf">MMConv: An Environment for Multimodal Conversational Search across Multiple Domains</a><br/><a href="https://eleanorchodroff.com/tutorial/montreal-forced-aligner.html">3 Montreal Forced Aligner | Corpus Phonetics Tutorial</a><br/><a href="https://montreal-forced-aligner.readthedocs.io/en/latest/user_guide/configuration/global.html">Global Options ‚Äî Montreal Forced Aligner 3.0.0 documentation</a><br/><a href="https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/blob/78e481d2b3708957f3f6ac2b4d089bac798ad757/montreal_forced_aligner/alignment/base.py#L129">Montreal-Forced-Aligner/montreal_forced_aligner/alignment/base.py at 78e481d2b3708957f3f6ac2b4d089bac798ad757 ¬∑ MontrealCorpusTools/Montreal-Forced-Aligner</a><br/><a href="https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/blob/78e481d2b3708957f3f6ac2b4d089bac798ad757/montreal_forced_aligner/transcription/multiprocessing.py#L325">Montreal-Forced-Aligner/montreal_forced_aligner/transcription/multiprocessing.py at 78e481d2b3708957f3f6ac2b4d089bac798ad757 ¬∑ MontrealCorpusTools/Montreal-Forced-Aligner</a><br/><a href="https://cohenpr-xpf.github.io/XPF/Convert-to-IPA.html">Convert to IPA</a><br/><a href="https://github.com/dmort27/epitran">dmort27/epitran: A tool for transcribing orthographic text as IPA (International Phonetic Alphabet)</a><br/><a href="https://montreal-forced-aligner.readthedocs.io/en/latest/user_guide/workflows/train_acoustic_model.html">Train a new acoustic model (mfa train) ‚Äî Montreal Forced Aligner 3.0.0 documentation</a><br/><a href="https://montreal-forced-aligner.readthedocs.io/en/latest/user_guide/implementations/phonological_rules.html">Phonological rules ‚Äî Montreal Forced Aligner 3.0.0 documentation</a><br/><a href="https://raw.githubusercontent.com/MontrealCorpusTools/mfa-models/main/config/acoustic/rules/english_arpa.yaml">raw.githubusercontent.com/MontrealCorpusTools/mfa-models/main/config/acoustic/rules/english_arpa.yaml</a><br/><a href="https://github.com/mlml/autovot/tree/master?tab=readme-ov-file#textgridformat">mlml/autovot: Trainable algorithm for automatic measurement of voice onset time</a><br/><a href="https://www.instagram.com/direct/t/5060418777378294/">Inbox ‚Ä¢ Direct</a><br/><a href="https://nbviewer.org/github/timmahrt/praatIO/blob/main/tutorials/tutorial1_intro_to_praatio.ipynb#modifying_tgs_tiers">Jupyter Notebook Viewer</a><br/><a href="https://montreal-forced-aligner.readthedocs.io/en/latest/user_guide/workflows/train_acoustic_model.html">Train a new acoustic model (mfa train) ‚Äî Montreal Forced Aligner 3.0.0 documentation</a><br/><a href="https://montreal-forced-aligner.readthedocs.io/en/latest/user_guide/glossary.html#term-Acoustic-models">Glossary ‚Äî Montreal Forced Aligner 3.0.0 documentation</a><br/><a href="https://montreal-forced-aligner.readthedocs.io/en/latest/user_guide/implementations/phonological_rules.html">Phonological rules ‚Äî Montreal Forced Aligner 3.0.0 documentation</a><br/><a href="https://github.com/MontrealCorpusTools/mfa-models/tree/main/config/acoustic/rules">mfa-models/config/acoustic/rules at main ¬∑ MontrealCorpusTools/mfa-models</a><br/><a href="https://github.com/MontrealCorpusTools/mfa-models/tree/main/config/acoustic/rules">mfa-models/config/acoustic/rules at main ¬∑ MontrealCorpusTools/mfa-models</a><br/><a href="https://www.google.com/search?q=mfa+phonological+rules&rlz=1C5GCEM_enSE990SE991&oq=mfa+phonological+rules&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIKCAEQABiABBiiBDIKCAIQABiABBiiBDIKCAMQABiABBiiBDIKCAQQABiABBiiBDIKCAUQABiABBiiBNIBCDQ4NjhqMGo3qAIAsAIA&sourceid=chrome&ie=UTF-8">mfa phonological rules - Google Search</a><br/><a href="https://github.com/search?q=repo%3AMontrealCorpusTools%2FMontreal-Forced-Aligner+rules&type=code&p=2">Code search results</a><br/><a href="https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/blob/78e481d2b3708957f3f6ac2b4d089bac798ad757/montreal_forced_aligner/models.py#L469">Montreal-Forced-Aligner/montreal_forced_aligner/models.py at 78e481d2b3708957f3f6ac2b4d089bac798ad757 ¬∑ MontrealCorpusTools/Montreal-Forced-Aligner</a><br/><a href="https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/blob/78e481d2b3708957f3f6ac2b4d089bac798ad757/docs/source/changelog/index.md?plain=1#L15">Montreal-Forced-Aligner/docs/source/changelog/index.md at 78e481d2b3708957f3f6ac2b4d089bac798ad757 ¬∑ MontrealCorpusTools/Montreal-Forced-Aligner</a><br/><a href="https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/blob/78e481d2b3708957f3f6ac2b4d089bac798ad757/montreal_forced_aligner/command_line/validate.py#L78">Montreal-Forced-Aligner/montreal_forced_aligner/command_line/validate.py at 78e481d2b3708957f3f6ac2b4d089bac798ad757 ¬∑ MontrealCorpusTools/Montreal-Forced-Aligner</a><br/><a href="https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/blob/78e481d2b3708957f3f6ac2b4d089bac798ad757/docs/source/user_guide/implementations/phone_groups.md?plain=1#L149">Montreal-Forced-Aligner/docs/source/user_guide/implementations/phone_groups.md at 78e481d2b3708957f3f6ac2b4d089bac798ad757 ¬∑ MontrealCorpusTools/Montreal-Forced-Aligner</a><br/><a href="https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/blob/78e481d2b3708957f3f6ac2b4d089bac798ad757/montreal_forced_aligner/command_line/train_acoustic_model.py#L78">Montreal-Forced-Aligner/montreal_forced_aligner/command_line/train_acoustic_model.py at 78e481d2b3708957f3f6ac2b4d089bac798ad757 ¬∑ MontrealCorpusTools/Montreal-Forced-Aligner</a><br/><a href="https://www.google.com/search?q=montreal+forced+aligner+use+%22phonological+rules%22&sca_esv=aba662b5e5ded398&sca_upv=1&rlz=1C5GCEM_enSE990SE991&sxsrf=ADLYWIKCb8CCmuePXkAb9qUAkOItBTwqwA%3A1724163054244&ei=7qPEZvbGDryHwPAP6auE-AM&ved=0ahUKEwj29Yfz34OIAxW8AxAIHekVAT8Q4dUDCA8&uact=5&oq=montreal+forced+aligner+use+%22phonological+rules%22&gs_lp=Egxnd3Mtd2l6LXNlcnAiMG1vbnRyZWFsIGZvcmNlZCBhbGlnbmVyIHVzZSAicGhvbm9sb2dpY2FsIHJ1bGVzIjIIEAAYgAQYogQyCBAAGIAEGKIEMggQABiABBiiBDIIEAAYgAQYogQyCBAAGIAEGKIESIMaUNYEWMwVcAF4AZABAJgBqwOgAb8FqgEHMC4yLjQtMbgBA8gBAPgBAZgCBKAC0AXCAgoQABiwAxjWBBhHwgIFECEYoAGYAwCIBgGQBgiSBwcxLjIuNC0xoAewCQ&sclient=gws-wiz-serp">montreal forced aligner use "phonological rules" - Google Search</a><br/><a href="https://montreal-forced-aligner.readthedocs.io/en/latest/search.html?q=rules">Search - Montreal Forced Aligner 3.0.0 documentation</a><br/><a href="https://montreal-forced-aligner.readthedocs.io/en/latest/reference/database/generated/montreal_forced_aligner.db.RuleApplication.html">RuleApplication ‚Äî Montreal Forced Aligner 3.0.0 documentation</a><br/><a href="https://montreal-forced-aligner.readthedocs.io/en/latest/user_guide/workflows/train_acoustic_model.html#pronunciation-modeling">Train a new acoustic model (mfa train) ‚Äî Montreal Forced Aligner 3.0.0 documentation</a><br/><a href="https://montreal-forced-aligner.readthedocs.io/en/latest/user_guide/corpus_creation/training_dictionary.html#training-dictionary">Add probabilities to a dictionary (mfa train_dictionary) ‚Äî Montreal Forced Aligner 3.0.0 documentation</a><br/><a href="https://montreal-forced-aligner.readthedocs.io/en/latest/user_guide/corpus_creation/transcribing.html">Transcribe audio files (mfa transcribe) ‚Äî Montreal Forced Aligner 3.0.0 documentation</a><br/><a href="https://montreal-forced-aligner.readthedocs.io/en/latest/user_guide/corpus_creation/create_segments.html">Segment transcribed files (mfa segment) ‚Äî Montreal Forced Aligner 3.0.0 documentation</a><br/><a href="https://translate.google.com/?sl=auto&tl=en&text=Lelki%20f%C3%A1jdalom%2C%20b%C3%A1nat%2C%20szomor%C3%BAs%C3%A1g%2C%20lehangolts%C3%A1g%20kifejez%C3%A9s%C3%A9re.&op=translate">Google Translate</a><br/><a href="https://www.arcanum.com/hu/online-kiadvanyok/Lexikonok-a-magyar-nyelv-ertelmezo-szotara-1BE8B/j-32DF3/jaj-32E14/">oh | Interpretive dictionary of the Hungarian language | Handbook</a><br/><a href="https://en.wiktionary.org/wiki/jaj">jaj - Wiktionary, the free dictionary</a><br/><a href="https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/blob/main/montreal_forced_aligner/acoustic_modeling/base.py">Montreal-Forced-Aligner/montreal_forced_aligner/acoustic_modeling/base.py at main ¬∑ MontrealCorpusTools/Montreal-Forced-Aligner</a><br/><a href="https://translate.google.com/?sl=auto&tl=en&text=Nu%20%C3%A4r%20det%20snart%20dags%20f%C3%B6r%20Spr%C3%A5kbankens%20%C3%A5rliga%20personalm%C3%B6te%2C%20vi%20ser%20fram%20emot%20att%20ses!%0A%0AM%C3%B6tet%20%C3%A4ger%20rum%20den%2021%E2%80%9323%20augusti%202024%20p%C3%A5%20Siggesta%20g%C3%A5rd%2C%20V%C3%A4rmd%C3%B6%20-%20vi%20har%20lyckats%20boka%20hela%20st%C3%A4llet%20och%20de%20%C3%A4r%20redo%20f%C3%B6r%20v%C3%A5r%20invasion!%0A%0ADet%20%C3%B6vergripande%20temat%20%C3%A4r%20som%20sagt%20fram%C3%A5tblickande%20p%C3%A5%20den%20nya%20finansieringsomg%C3%A5ngen%202025%E2%80%932028.%20D%C3%A5%20speciellt%20Swe-CLARIN-verksamheten%2C%20som%20kommer%20att%20organiseras%20formellt%20som%20en%20fj%C3%A4rde%20avdelning%20inom%20Spr%C3%A5kbanken.%0A%0A%0A%0ANedan%20f%C3%B6ljer%20lite%20praktisk%20information.%20%0A%0A%0AVi%20f%C3%B6rs%C3%B6ker%20%C3%A4ven%20kontinuerligt%20uppdatera%20infon%20p%C3%A5%20sprakbanken.se%2Fpersonalm%C3%B6te2024%0A%0ATransport%0ADu%20som%20anm%C3%A4lt%20dig%20till%20en%20plats%20i%20bussen%20ser%20till%20att%20vara%20p%C3%A5%20plats%20p%C3%A5%20Cityterminalen%20kl12%3A35%20(gatenummer%20anges%20p%C3%A5%20avg%C3%A5ngsskylten).%0ADu%20som%20kommer%20med%20t%C3%A5get%20fr%C3%A5n%20G%C3%B6teborg%20g%C3%A5r%20helt%20enkelt%20raka%20v%C3%A4gen%20till%20Cityterminalen%20(f%C3%B6lj%20skyltning)%20utan%20stress%2C%20bussen%20kommer%20inte%20att%20avg%C3%A5%20utan%20dig!%0A%0AAvf%C3%A4rd%20f%C3%B6r%20hemresan%20%C3%A4r%20klockan%2013.%20Resan%20tar%20normalt%20ca%2050%20minuter%20Siggesta%20g%C3%A5rd%20-%20Cityterminalen.%20Tyv%C3%A4rr%20finns%20det%20risk%20f%C3%B6r%20trafikstockning%20den%20tiden%20p%C3%A5%20en%20fredag%2C%20s%C3%A5%20ta%20h%C3%B6jd%20f%C3%B6r%20det%20om%20du%20ska%20vidare%20fr%C3%A5n%20Cityterminalen!%20%0A%0ADu%20som%20reser%20kollektivt%20v%C3%A4ljer%20buss%20437%20eller%20439%20fr%C3%A5n%20Slussen%2C%20station%20Siggesta%E2%80%9D.%20(Bussen%20stannar%20alldeles%20intill%20g%C3%A5rden).%20Planera%20din%20resa%20medsl.se%2C%20ibland%20kr%C3%A4vs%20byten!%0A%0ADu%20som%20bilar%20hittar%20v%C3%A4ganvisningar%20p%C3%A5%20Siggestas%20hemsida.%0ADu%20parkerar%20utan%20kostnad.%20Vid%20ankomst%3A%20parkera%20bilen%20p%C3%A5%20n%C3%A5gon%20av%20g%C3%A5rdens%20h%C3%A4nvisade%20parkeringsplatser%20och%20h%C3%A4mta%20sedan%20ut%20ett%20parkeringstillst%C3%A5nd%20i%20receptionen%2C%20som%20ska%20l%C3%A4ggas%20i%20bilen.%20Fyra%20laddningsstationer%20finns%20precis%20utanf%C3%B6r%20hotellets%20entr%C3%A9.%0A%0ABra%20att%20veta%20p%C3%A5%20plats%0AFrukost%20serveras%20klockan%2007.00%E2%80%9309.00%20i%20loungen.%0AWifi-l%C3%B6sen%20i%20konferenssalen%3A%20konferens2020%20%0AEn%20karta%20%C3%B6ver%20g%C3%A5rdsomr%C3%A5det%20hittar%20du%20h%C3%A4r.%0A%0APROGRAM%0ADag%201%0A14.00%0ASamling%20och%20inledande%20lunch%0A15.00%0ATidigare%20personaldagar%20och%20%C3%A5rets%20schema%0A16.00%0AGruppdiskussion%20I%20%0A16.45%0AEftermiddagsfika%0A17.15%0AGruppdiskussion%20II%20%0A18.00%0AAvslutande%20samling%0A19.00%0AMiddag%0A%0ADag%202%0A9.00%0ASamling%0A9.15%0AGruppdiskussion%20III%0A10.30%0AF%C3%B6rmiddagsfika%0A11.00%0A12.00%20SweClarin%20%3D%3E%20Spr%C3%A5kbanken%20CLARIN%0A12.00%0A13.00%20Lunch%0A13.00%0AClarin-presentationer%20I%0A15.15%0AEftermiddagsfika%0A15.45%0AClarin-presentationer%20II%0A18.00%0APrist%C3%A4vling%0A19.00%0A3-r%C3%A4tters%20middag%20med%20prisutdelning%0A%0ADag%203%0A9.00%0AUppf%C3%B6ljning%20av%20diskussioner%20och%20presentationer%0A10.30%0AF%C3%B6rmiddagsfika%0A11.00%0ASammanfattning%2C%20fram%C3%A5tblick%2C%20avrundning%0A11.30%0AAvslutande%20lunch%0ACirka%2013.00%3A%20avf%C3%A4rd%20med%20buss%20(f%C3%B6r%20de%20som%20anm%C3%A4lt%20sig)%0A%0AV%C3%A4l%20m%C3%B6tt%20p%C3%A5%20onsdag!&op=translate">Google Translate</a><br/><a href="https://montreal-forced-aligner.readthedocs.io/en/latest/user_guide/implementations/phonological_rules.html">Phonological rules ‚Äî Montreal Forced Aligner 3.0.0 documentation</a><br/><a href="https://github.com/search?q=repo%3AMontrealCorpusTools%2FMontreal-Forced-Aligner%20phonological&type=code">Code search results</a><br/><a href="https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/blob/78e481d2b3708957f3f6ac2b4d089bac798ad757/montreal_forced_aligner/dictionary/multispeaker.py#L1030">Montreal-Forced-Aligner/montreal_forced_aligner/dictionary/multispeaker.py at 78e481d2b3708957f3f6ac2b4d089bac798ad757 ¬∑ MontrealCorpusTools/Montreal-Forced-Aligner</a><br/><a href="https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/blob/78e481d2b3708957f3f6ac2b4d089bac798ad757/montreal_forced_aligner/data.py#L114">Montreal-Forced-Aligner/montreal_forced_aligner/data.py at 78e481d2b3708957f3f6ac2b4d089bac798ad757 ¬∑ MontrealCorpusTools/Montreal-Forced-Aligner</a><br/><a href="https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/blob/78e481d2b3708957f3f6ac2b4d089bac798ad757/docs/source/user_guide/workflows/train_acoustic_model.rst#L36">Montreal-Forced-Aligner/docs/source/user_guide/workflows/train_acoustic_model.rst at 78e481d2b3708957f3f6ac2b4d089bac798ad757 ¬∑ MontrealCorpusTools/Montreal-Forced-Aligner</a><br/><a href="http://www.festvox.org/cmu_arctic/">Festvox: CMU_ARCTIC¬†Databases</a><br/><a href="http://www.festvox.org/cmu_arctic/cmuarctic.data">festvox.org/cmu_arctic/cmuarctic.data</a><br/><a href="https://github.com/Plachtaa/VALL-E-X">Plachtaa/VALL-E-X: An open source implementation of Microsoft's VALL-E X zero-shot TTS model. Demo is available in https://plachtaa.github.io</a><br/><a href="https://www.instagram.com/">Instagram</a><br/><a href="https://translate.google.com/?sl=auto&tl=en&text=Vid%20gruppdiskussionerna%20kan%20det%20vara%20bra%20att%20%C3%A4ven%20ha%20tillhands%20den%20nu%20bifogade%20organisationsskissen%20f%C3%B6r%20Spr%C3%A5kbanken%202025%E2%80%932028.%20Jag%20ska%20ber%C3%A4tta%20mer%20om%20den%20under%20dagens%20f%C3%B6rsta%20session.%0A%0A&op=translate">Google Translate</a><br/><a href="https://drive.google.com/drive/u/0/my-drive">My Drive - Google Drive</a><br/><a href="https://docs.google.com/document/d/1H25NL__I3NVB9J3jnDVqU9pC4OF1hrCHK2c1O8GNapo/edit">Untitled document - Google Docs</a><br/><a href="https://translate.google.com/?sl=auto&tl=en&text=fr%C3%A5gor%20f%C3%B6r%20%C3%A5rets%20gruppdiskussioner%0AVi%20forts%C3%A4tter%20p%C3%A5%20temat%20integration%20och%20f%C3%B6ljer%20upp%20fjol%C3%A5rets%20diskussioner.%20Som%20utg%C3%A5ngspunkt%20finns%20de%20uts%C3%A4nda%20diskussionssammanfattningarna.%20Mot%20bakgrund%20av%20dessa%2C%20diskutera%20en%20eller%20flera%20av%20f%C3%B6ljande%20fr%C3%A5gor%3A%0AFormulera%20i%20vilken%20utstr%C3%A4ckning%20du%2Fdin%20grupp%20har%20f%C3%B6rverkligat%20n%C3%A5gra%20av%20f%C3%B6rslagen%20fr%C3%A5n%20f%C3%B6rra%20g%C3%A5ngen.%20Om%20det%20har%20skett%20%E2%80%9Di%20tysthet%E2%80%9D%2C%20hur%20skulle%20det%20kunna%20kommuniceras%20till%20omv%C3%A4rlden%3F%0AHur%20kan%20Spr%C3%A5kbanken%20bli%20%C3%A4nnu%20mer%20integrerad%20som%20nationell%20forskningsinfrastruktur%2C%20allts%C3%A5%20in%C3%A5t%20och%20ut%C3%A5t%20upptr%C3%A4da%20och%20framst%C3%A5%20som%20en%20och%20samma%20organisation%3F%0AI%20samband%20med%20att%20CLARIN-verksamheten%20nu%20blir%20en%20fj%C3%A4rde%20Spr%C3%A5kbanksavdelning%2C%20beh%C3%B6ver%20vi%20st%C3%A4rka%20v%C3%A5r%20europeiska%20synlighet%20och%20hur%20g%C3%B6r%20vi%20det%20i%20s%C3%A5%20fall%3F%0A%0Aarbetsg%C3%A5ng%0AGruppindelning%20(samma%20b%C3%A5da%20dagarna)%20och%20fjol%C3%A5rets%20diskussionssammanfattningar%20som%20underlag%20har%20skickats%20ut.%0AUtse%20en%20antecknare%20i%20varje%20grupp%20(kan%20f%C3%B6rst%C3%A5s%20vara%20olika%20idag%20och%20imorgon)%2C%20som%20kortfattat%20skriver%20ner%20gruppdiskussionernas%20huvudpunkter%20och%20huvudslutsatser.%0ASkicka%20diskussionsanteckningarna%20till%20mig%20efter%20morgondagens%20diskussionssession%20(s%C3%A5%20kan%20jag%20f%C3%B6rbereda%20en%20inledning%20till%20den%20uppf%C3%B6ljande%20diskussionen%20p%C3%A5%20fredag%20morgon).&op=translate">Google Translate</a><br/><a href="https://translate.google.com/?sl=auto&tl=en&text=Gemensamma%20data(repositorier)%2C%20federerade%2C%20och%20resurser.%0AHar%20diskuterats%20p%C3%A5%20SBX%3A%20Hur%20ska%20vi%20organisera%20v%C3%A5ra%20resurser%3F%20B%C3%A4ttre%20att%20ha%20SBX%20resurser%20som%20Clarin-%0Aresurser%3F%20Haft%20retreat%20om%20metadata.%0ABeh%C3%B6vs%20nog%20n%C3%A5gon%20som%20har%20det%20som%20prim%C3%A4ruppgift.%20Vi%20saknar%20pengar%20till%20detta%3F%0AKan%20ju%20b%C3%B6rja%20med%20en%20gemensam%20plats%20f%C3%B6r%20all%20v%C3%A5r%20data.%0AProblem%20med%20r%C3%A4ttigheter%2C%20ex%20skrapade%20nyheter%20och%20bloggar.%20Kan%20l%C3%B6sas%20med%20meningsomkastning.%0AJuridisk%20gr%C3%A5zon.%0AJuridiska%20problem%20kan%20l%C3%B6sas%20gemensamt%20med%20gemensamma%20resurser.%0AM%C3%A5l%20kan%20vara%20gemensam%20portal%20mot%20federerade%20prim%C3%A4rdata.%0AKan%20andra%20SB%20ocks%C3%A5%20anv%C3%A4nda%20sig%20av%20SBX%3As%20repo%2FAPI%20f%C3%B6r%20resurser%20(s%C3%B6kbara%20p%C3%A5%20spraakbanken.gu.se).&op=translate">Google Translate</a><br/><a href="https://spraakbanken.gu.se/">The language bank Text | The Language Bank Text</a><br/><a href="https://github.com/orgs/spraakbanken/repositories?type=all">spraakbanken repositories</a><br/><a href="https://github.com/spraakbanken/swegram-v2">spraakbanken/swegram-v2: SWEGRAM: Annotation and Analysis of English and Swedish Texts</a><br/><a href="https://github.com/spraakbanken/metadata/blob/main/yaml/lexicon/poligraph.yaml">metadata/yaml/lexicon/poligraph.yaml at main ¬∑ spraakbanken/metadata</a><br/><a href="https://spraakbanken.gu.se/en/resources">Language resources | Spr√•kbanken Text</a><br/><a href="https://spraakbanken.gu.se/en/resources/aspac">ASPAC | Spr√•kbanken Text</a><br/><a href="https://spraakbanken.gu.se/resurser/standsriksdagen-riksdagsbeslut">Stadsriksdagen: Riksdag decisions | The Language Bank Text</a><br/><a href="https://spraakbanken.gu.se/resurser/standsriksdagen-riksdagsakter">Bicameral Riksdag: Riksdag acts | The Language Bank Text</a><br/><a href="https://spraakbanken.gu.se/resurser/standsriksdagen-bondestandet">Stadsriksdagen: The Peasant Estate | The Language Bank Text</a><br/><a href="https://github.com/tarepan/vocos-official">tarepan/vocos-official: Vocos: Closing the gap between time-domain and Fourier-based neural vocoders for high-quality audio synthesis</a><br/><a href="https://huggingface.co/jimregan/wav2vec-awb">jimregan/wav2vec-awb ¬∑ Hugging Face</a><br/><a href="https://github.com/facebookresearch/fairseq/tree/ce6c9eeae163ac04b79539c78e74f292f29eaa18/examples/wav2vec#pre-trained-models">fairseq/examples/wav2vec at ce6c9eeae163ac04b79539c78e74f292f29eaa18 ¬∑ facebookresearch/fairseq</a><br/><a href="https://github.com/rdadlaney/Audio-Denoiser-CNN">rdadlaney/Audio-Denoiser-CNN</a><br/><a href="https://www.mathworks.com/help/deeplearning/ug/denoise-speech-using-deep-learning-networks.html">Denoise Speech Using Deep Learning Networks - MATLAB & Simulink</a><br/><a href="https://paperswithcode.com/task/audio-denoising/latest">Audio Denoising | Papers With Code</a><br/><a href="https://github.com/mosheman5/DNP/blob/master/pyramidnet.py">DNP/pyramidnet.py at master ¬∑ mosheman5/DNP</a><br/><a href="https://immohann.github.io/Portfolio/Denoiser.pdf">Denoiser.pdf</a><br/><a href="https://www.analyticsvidhya.com/blog/2022/03/audio-denoiser-a-speech-enhancement-deep-learning-model/">Audio Denoiser: A Speech Enhancement Deep Learning Model</a><br/><a href="https://github.com/EncoraDigital/SAB-cnn-audio-denoiser">EncoraDigital/SAB-cnn-audio-denoiser: Tensorflow 2.0 implementation of the paper: A Fully Convolutional Neural Network for Speech Enhancement</a><br/><a href="https://www.lalal.ai/voice-cleaner/">AI Voice Cleaner & Background Noise Remover | LALAL.AI</a><br/><a href="https://www.lalal.ai/tools-and-api/">Tools & API | LALAL.AI</a><br/><a href="https://github.com/AppleHolic/source_separation?tab=readme-ov-file">AppleHolic/source_separation: Deep learning based speech source separation using Pytorch</a><br/><a href="https://colab.research.google.com/github/Appleholic/source_separation/blob/master/assets/Source_Separation_first_notebook.ipynb#scrollTo=6B0qjk_i3HmD">Source Separation first notebook.ipynb - Colab</a><br/><a href="https://gearspace.com/board/low-end-theory/673757-removing-clicks-pops-bad-cable-sounds-audio.html">Removing Clicks/Pops/Bad Cable sounds from Audio? - Gearspace</a><br/><a href="https://emastered.com/blog/remove-clicks-pops-from-audio">How to Remove Clicks and Pops from Audio</a><br/><a href="https://manual.audacityteam.org/man/spectral_selection.html">Spectral Selection and Editing - Audacity Manual</a><br/><a href="https://multimedia.easeus.com/ai-article/click-removal-audacity.html">Remove Clicks/Pops/Mouth Noises in Audacity [Step-by-Step Guide]</a><br/><a href="https://forum.audacityteam.org/t/updated-de-clicker-and-new-de-esser-for-speech/34283/3">Updated De-Clicker and new De-esser for speech - Programming and Development / New Plug-Ins - Audacity Forum</a><br/><a href="https://www.google.com/search?q=set+chrome+to+autoreject+notifications&rlz=1C5GCEM_enSE990SE991&oq=set+chrome+to+autoreject+notifications&gs_lcrp=EgZjaHJvbWUyCwgAEEUYChg5GKABMgYIARBFGEDSAQg2ODA1ajFqN6gCALACAA&sourceid=chrome&ie=UTF-8">set chrome to autoreject notifications - Google Search</a><br/><a href="https://www.google.com/search?q=audacity+mac+add+nyquist&rlz=1C5GCEM_enSE990SE991&oq=audacity+mac+add+nyq&gs_lcrp=EgZjaHJvbWUqBwgBECEYoAEyBggAEEUYOTIHCAEQIRigATIHCAIQIRigAdIBCDgzNDlqMWo0qAIAsAIB&sourceid=chrome&ie=UTF-8#fpstate=ive&vld=cid:d93646a9,vid:BMZ5gwkn2uo,st:11">audacity mac add nyquist - Google Search</a><br/><a href="https://manual.audacityteam.org/man/normalize.html#Remove_any_DC_offset">Normalize - Audacity Manual</a><br/><a href="https://www.google.com/search?q=fix+clipping+audio&rlz=1C5GCEM_enSE990SE991&oq=fix+clipping&gs_lcrp=EgZjaHJvbWUqBwgAEAAYgAQyBwgAEAAYgAQyBggBEEUYOTIMCAIQABgUGIcCGIAEMgcIAxAAGIAEMgcIBBAAGIAEMgcIBRAAGIAEMgcIBhAAGIAEMgcIBxAAGIAEMgcICBAAGIAEMg0ICRAAGIYDGIAEGIoF0gEINTQyOGoxajeoAgCwAgA&sourceid=chrome&ie=UTF-8">fix clipping audio - Google Search</a><br/><a href="https://www.reddit.com/r/audioengineering/comments/15hjcdy/is_there_a_way_to_fix_blownclipped_audio/">Is there a way to fix blown/clipped audio? : r/audioengineering</a><br/><a href="https://www.google.com/search?q=open+source+audio+fix+clipping&rlz=1C5GCEM_enSE990SE991&oq=open+source+audio+fix+clipping&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIGCAEQRRhAMgYIAhBFGEAyBggDEEUYQNIBCTEwMTg4ajFqNKgCALACAQ&sourceid=chrome&ie=UTF-8">open source audio fix clipping - Google Search</a><br/><a href="https://www.reddit.com/r/audioengineering/comments/15hjcdy/is_there_a_way_to_fix_blownclipped_audio/">Is there a way to fix blown/clipped audio? : r/audioengineering</a><br/><a href="https://github.com/godotengine/godot/issues/22016">Audio clipping / static / interference on rapid intervals of sound (fixed in `master`) ¬∑ Issue #22016 ¬∑ godotengine/godot</a><br/><a href="https://multimedia.easeus.com/ai-article/how-to-fix-distorted-audio-in-audacity.html">How to Fix Distorted Audio in Audacity [7 Newest Ways] üõ†Ô∏è</a><br/><a href="https://www.izotope.com/en/products/rx.html?srsltid=AfmBOopKcy3LhypEvko-RgWPOPIm6QnHEilfZmD9EM09ZdBra7j8qZi3">RX 11 Background Noise Removal & Audio Cleanup Software | iZotope</a><br/><a href="https://manual.audacityteam.org/man/spectral_selection.html">Spectral Selection and Editing - Audacity Manual</a><br/><a href="https://github.com/kenders2000/distortionDetection">kenders2000/distortionDetection: C++ Program to detect Clipping and other overload based nonlinear distortions in Wav Files</a><br/><a href="https://www.google.com/search?q=linux+wav+fix+clipping&rlz=1C5GCEM_enSE990SE991&oq=linux+wav+fix+clipping&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIHCAEQIRigATIHCAIQIRigAdIBCDg5NzdqMWo3qAIAsAIA&sourceid=chrome&ie=UTF-8">linux wav fix clipping - Google Search</a><br/><a href="https://sourceforge.net/p/isse/code/ci/master/tree/">ISSE / code / [451aa4]</a><br/><a href="https://www.reddit.com/r/audioengineering/comments/qh1cyn/looking_for_advice_on_repairing_hard_clipping/">Looking for advice on repairing hard clipping / audio distortion in a .wav file? : r/audioengineering</a><br/><a href="https://www.instagram.com/">Instagram</a><br/><a href="https://www.instagram.com/medusamoon9/reels/">Luna üåô (@medusamoon9) ‚Ä¢ Instagram photos and videos</a><br/><a href="https://github.com/jiaaro/pydub/blob/master/API.markdown">pydub/API.markdown at master ¬∑ jiaaro/pydub</a><br/><a href="https://www.google.com/search?q=fairseq+finetune+wav2vec2+no+dev&sca_esv=59944d6273687f66&sca_upv=1&rlz=1C5GCEM_enSE990SE991&sxsrf=ADLYWIIrwVAfSzHQJIfjgzh3qJ15R67pTg%3A1724440449212&ei=gd_IZqfNDLn-wPAPuNq-8QY&oq=fairseq+finetune+w&gs_lp=Egxnd3Mtd2l6LXNlcnAiEmZhaXJzZXEgZmluZXR1bmUgdyoCCAAyBBAjGCcyBhAAGBYYHjIIEAAYgAQYogQyCBAAGIAEGKIEMggQABiABBiiBDIIEAAYgAQYogQyCBAAGIAEGKIESMQUUI0BWPoCcAF4AJABAJgBVqAB1wGqAQEzuAEDyAEA-AEBmAIDoAKzAcICBxAjGLADGCfCAgoQABiwAxjWBBhHmAMAiAYBkAYEkgcBM6AHyQ0&sclient=gws-wiz-serp">fairseq finetune wav2vec2 no dev - Google Search</a><br/><a href="https://github.com/facebookresearch/fairseq/issues/2685">No decrease of wer when fine tuning wav2vec 2.0 ¬∑ Issue #2685 ¬∑ facebookresearch/fairseq</a><br/><a href="https://huggingface.co/spaces/OFA-Sys/OFA-Generic_Interface/blob/main/fairseq/examples/wav2vec/README.md">fairseq/examples/wav2vec/README.md ¬∑ OFA-Sys/OFA-Generic_Interface at main</a><br/><a href="https://www.youtube.com/watch?v=T-mb7fX4gdk">The Big Fat Quiz of Telly - YouTube</a><br/><a href="https://www.youtube.com/watch?v=GvzAdb8j-00">How Death Metal Legends Learned to Scream - YouTube</a><br/><a href="https://arxiv.org/pdf/2305.10790">2305.10790</a><br/><a href="https://github.com/cmusphinx/pocketsphinx">cmusphinx/pocketsphinx: A small speech recognizer</a><br/><a href="https://cmusphinx.github.io/wiki/phonemerecognition/">Phoneme Recognition (caveat emptor) ‚Äì CMUSphinx Open Source Speech Recognition</a><br/><a href="https://www.instagram.com/direct/t/110437113687820/">Inbox ‚Ä¢ Direct</a><br/><a href="https://kth-my.sharepoint.com/:p:/g/personal/ghe_ug_kth_se/EUU-iBpVNYNFtQ5WqXsJ8BQBB8Mggqc5lcouokIKj2cghQ?e=kHPdKM">ghenter_syndata4genai_talk.pptx</a><br/><a href="https://kth-my.sharepoint.com/:p:/r/personal/smehta_ug_kth_se/_layouts/15/Doc.aspx?sourcedoc=%7BC340542E-AD8B-4800-8F22-9FEB9420FE28%7D&file=MAGI-Poster.pptx&action=edit&mobileredirect=true">MAGI-Poster.pptx</a><br/><a href="https://arxiv.org/pdf/2404.19622">2404.19622</a><br/><a href="https://chatgpt.com/c/a3e71cd2-5412-4378-b199-1b67398e36ea">ChatGPT</a><br/><a href="https://kth-my.sharepoint.com/">Start - OneDrive</a><br/><a href="https://kth-my.sharepoint.com/:p:/r/personal/ghe_ug_kth_se/_layouts/15/Doc.aspx?sourcedoc=%7B1A883E45-3555-4583-B50E-56A97B09F014%7D&file=ghenter_syndata4genai_talk.pptx&action=edit&mobileredirect=true&DefaultItemOpen=1&web=1">ghenter_syndata4genai_talk.pptx</a><br/><a href="https://openreview.net/group?id=STLC/2024/Conference&referrer=%5BHomepage%5D(%2F)#tab-recent-activity">STLC 2024 Conference | OpenReview</a><br/><a href="https://sltc2024.github.io/cfp">Call for Papers | Swedish Language Technology Conference (SLTC) 2024</a><br/><a href="https://www.google.com/maps/dir/59.3483841,18.0747254/Link%C3%B6ping/@58.8742986,15.5330958,8z/data=!3m1!4b1!4m10!4m9!1m1!4e1!1m5!1m1!1s0x46596e719a049f95:0x400fef341e48e70!2m2!1d15.6213728!2d58.410807!3e3?entry=ttu&g_ep=EgoyMDI0MDgyMS4wIKXMDSoASAFQAw%3D%3D">Your location to Link√∂ping - Google Maps</a><br/><a href="https://docs.google.com/document/d/1R53CwfrIrSiXrgLc0s7m-DZHrz9OPYp-V_c-ve97l0w/edit">TMH Monday lunch meeting protocols Apr 2019‚Äì - Google Docs</a><br/><a href="https://github.com/daschablume/g2p_correction/">daschablume/g2p_correction: Web-application for grapheme-to-phoneme correction using user feedback</a><br/><a href="https://www.google.com/search?q=powerpoint+animate+text+box+change&rlz=1C5GCEM_enSE990SE991&oq=powerpoint+animate+text+box+change&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIHCAEQIRigATIHCAIQIRigATIHCAMQIRigATIHCAQQIRigAdIBCDg4MjRqMWo3qAIAsAIA&sourceid=chrome&ie=UTF-8">powerpoint animate text box change - Google Search</a><br/><a href="https://github.com/jimregan/g2p_correction/tree/main">jimregan/g2p_correction: Web-application for grapheme-to-phoneme correction using user feedback</a><br/><a href="https://www.kth.se/form/66cc4c94f48d4dd146c78b9e">KTH | Karaoke night - 6th of September</a><br/><a href="chrome://newtab/">New Tab</a><br/><a href="https://arxiv.org/pdf/2408.13040">2408.13040</a><br/><a href="https://arxiv.org/pdf/2408.12982">2408.12982</a><br/><a href="https://arxiv.org/pdf/2408.13106">2408.13106</a><br/><a href="https://arxiv.org/pdf/2408.13119">2408.13119</a><br/><a href="https://arxiv.org/pdf/2408.13201">2408.13201</a><br/><a href="https://github.com/utter-project/mHuBERT-147-scripts?tab=readme-ov-file">utter-project/mHuBERT-147-scripts: Collection of scripts from mHuBERT-147.</a><br/><a href="https://huggingface.co/collections/utter-project/mhubert-147-models-665f1c1dea9a5601a1bfc905">mHuBERT-147 models - a utter-project Collection</a><br/><a href="https://github.com/clovaai/ClovaCall">clovaai/ClovaCall: ClovaCall dataset and Pytorch LAS baseline code (Interspeech 2020)</a><br/><a href="https://github.com/NVIDIA/NeMo/pull/10154">Support for FastConformer-CTC models in Diarization+ASR with timestamps by KunalDhawan ¬∑ Pull Request #10154 ¬∑ NVIDIA/NeMo</a><br/><a href="https://github.com/NVIDIA/NeMo/pull/10209">[NeMo-UX] Turn on TP and PP communication overlapping by JimmyZhang12 ¬∑ Pull Request #10209 ¬∑ NVIDIA/NeMo</a><br/><a href="https://github.com/NVIDIA/NeMo/pull/10207">Chchien s2st by zhehuaichen ¬∑ Pull Request #10207 ¬∑ NVIDIA/NeMo</a><br/><a href="https://github.com/shivammehta25/Matcha-TTS/blob/main/matcha/utils/get_durations_from_trained_model.py">Matcha-TTS/matcha/utils/get_durations_from_trained_model.py at main ¬∑ shivammehta25/Matcha-TTS</a><br/><a href="https://www.google.com/search?q=piper_phonemizer&rlz=1C5GCEM_enSE990SE991&oq=piper_phonemizer&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIGCAEQRRg8MgYIAhBFGD3SAQc0NjdqMGo3qAIAsAIA&sourceid=chrome&ie=UTF-8">piper_phonemizer - Google Search</a><br/><a href="https://www.google.com/search?q=cuda+12.3+crash+multi+gpu&sca_esv=861bfe30a48f43f8&sca_upv=1&rlz=1C5GCEM_enSE990SE991&sxsrf=ADLYWIKVFbNx8lDvAjtP7w9kAPEgpPDqWQ%3A1724681192442&ei=6IvMZsXVGuujwPAP0_Ou0AQ&ved=0ahUKEwjF6c2O6pKIAxXrERAIHdO5C0oQ4dUDCA8&uact=5&oq=cuda+12.3+crash+multi+gpu&gs_lp=Egxnd3Mtd2l6LXNlcnAaAhgCIhljdWRhIDEyLjMgY3Jhc2ggbXVsdGkgZ3B1MgUQIRigAUjzMFDcBljkLnACeACQAQCYAYABoAGfEKoBBDIzLjO4AQPIAQD4AQGYAhygAvMQwgIOEAAYgAQYsAMYhgMYigXCAgsQABiABBiwAxiiBMICChAjGIAEGCcYigXCAgQQIxgnwgILEAAYgAQYkQIYigXCAgoQABiABBhDGIoFwgIFEAAYgATCAgsQLhiABBjRAxjHAcICDhAuGIAEGMcBGI4FGK8BwgIKEAAYgAQYFBiHAsICCBAAGIAEGIsDwgIGEAAYFhgewgIEECEYFcICBRAhGJ8FwgIHECEYoAEYCpgDAOIDBRIBMSBAiAYBkAYKkgcEMjQuNKAHi4sB&sclient=gws-wiz-serp">cuda 12.3 crash multi gpu - Google Search</a><br/><a href="https://www.reddit.com/r/linux_gaming/comments/17atub2/say_hello_to_nvidia_driver_5452306_beta/">Say hello to Nvidia driver 545.23.06 BETA : r/linux_gaming</a><br/><a href="https://www.google.com/search?q=cuda+12.3+crash+multi+gpu&rlz=1C5GCEM_enSE990SE991&oq=cuda+&gs_lcrp=EgZjaHJvbWUqCAgAEEUYJxg7MggIABBFGCcYOzIGCAEQRRg5Mg4IAhBFGCcYOxiABBiKBTIHCAMQABiABDIHCAQQABiABDIGCAUQRRg9MgYIBhBFGDwyBggHEEUYPNIBCDEzODFqMWo0qAIAsAIB&sourceid=chrome&ie=UTF-8">cuda 12.3 crash multi gpu - Google Search</a><br/><a href="https://github.com/milvus-io/milvus/issues/33390">[Bug]: Use Multi GPU, milvus 2.3.x 2.4.x will crash ¬∑ Issue #33390 ¬∑ milvus-io/milvus</a><br/><a href="https://stackoverflow.com/questions/76963311/llama-cpp-python-not-using-nvidia-gpu-cuda">llama-cpp-python not using NVIDIA GPU CUDA - Stack Overflow</a><br/><a href="https://docs.nvidia.com/cuda/archive/12.4.0/cuda-toolkit-release-notes/#resolved-issues">1. CUDA 12.4 Release Notes ‚Äî Release Notes 12.4 documentation</a><br/><a href="https://discussion.fedoraproject.org/t/nvidia-linux-x86-64-545-29-06/97657">NVIDIA-Linux-x86_64-545.29.06 - Fedora Discussion</a><br/><a href="https://github.com/davisking/dlib/issues/2905">[Bug]: Training randomly crashes with cuda_error: invalid device function ¬∑ Issue #2905 ¬∑ davisking/dlib</a><br/><a href="https://forum.blackmagicdesign.com/viewtopic.php?f=21&t=46198">Blackmagic Forum ‚Ä¢ View topic - Resolve 12.3.2 keeps crashing?</a><br/><a href="https://forums.opensuse.org/t/cuda-12-broken-on-my-system-possibly-nvidia-open-kernel-module/172535">CUDA 12 broken on my system (possibly NVIDIA open kernel module?) - English / Hardware - openSUSE Forums</a><br/><a href="https://discuss.pytorch.org/t/multi-gpu-2080-ti-training-crashes-pc/52032/7">Multi GPU (2080 ti) training crashes PC - distributed - PyTorch Forums</a><br/><a href="http://wili.cc/blog/gpu-burn.html">Multi-GPU CUDA stress test</a><br/><a href="https://github.com/NVIDIA/nccl-tests?tab=readme-ov-file">NVIDIA/nccl-tests: NCCL Tests</a><br/><a href="https://github.com/NVIDIA/nccl/tree/master/src/transport">nccl/src/transport at master ¬∑ NVIDIA/nccl</a><br/><a href="https://docs.nvidia.com/cuda/archive/12.3.0/cuda-toolkit-release-notes/index.html#resolved-issues">1. CUDA 12.3 Release Notes ‚Äî Release Notes 12.3 documentation</a><br/><a href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/">CUDA Installation Guide for Linux</a><br/><a href="https://docs.nvidia.com/deeplearning/nccl/install-guide/index.html#debian">Installation Guide :: NVIDIA Deep Learning NCCL Documentation</a><br/><a href="https://github.com/ajitrajasekharan/multi_gpu_test">ajitrajasekharan/multi_gpu_test: Scripts to set up an nvidia GPU machine (ubuntu)</a><br/><a href="https://askubuntu.com/questions/1523475/nvidia-driver-545-suddenly-stopped-working-for-ubuntu-22-04-4-lts">Nvidia driver 545 suddenly stopped working for Ubuntu 22.04.4 LTS - Ask Ubuntu</a><br/><a href="https://ubuntu.com/server/docs/nvidia-drivers-installation">NVIDIA drivers installation | Ubuntu</a><br/><a href="https://stackoverflow.com/questions/43022843/nvidia-nvml-driver-library-version-mismatch">cuda - Nvidia NVML Driver/library version mismatch - Stack Overflow</a><br/><a href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#ubuntu">CUDA Installation Guide for Linux</a><br/><a href="https://www.reddit.com/r/pop_os/comments/17yz3sd/nvidia_dpkg_help/">nvidia dpkg help : r/pop_os</a><br/><a href="https://www.youtube.com/watch?v=BMuXzKVY8vQ">Julia Louis-Dreyfus‚Äô favorite joke from Veep | What Now? with Trevor Noah ‚Äî Watch Free on Spotify - YouTube</a><br/><a href="https://github.com/jiaaro/pydub/blob/master/API.markdown">pydub/API.markdown at master ¬∑ jiaaro/pydub</a><br/><a href="https://www.cursor.com/">Cursor</a><br/><a href="https://x.com/home">x.com/home</a><br/><a href="https://github.com/Kyubyong/g2p/blob/master/g2p_en/g2p.py">g2p/g2p_en/g2p.py at master ¬∑ Kyubyong/g2p</a><br/><a href="https://www.nltk.org/api/nltk.corpus.reader.html#nltk.corpus.reader.CMUDictCorpusReader.dict">NLTK :: nltk.corpus.reader package</a><br/><a href="https://www.nltk.org/_modules/nltk/corpus/reader/cmudict.html">NLTK :: nltk.corpus.reader.cmudict</a><br/><a href="https://montreal-forced-aligner.readthedocs.io/en/latest/user_guide/implementations/phonological_rules.html">Phonological rules ‚Äî Montreal Forced Aligner 3.0.0 documentation</a><br/><a href="https://github.com/MontrealCorpusTools/mfa-models/tree/main/config/acoustic/rules">mfa-models/config/acoustic/rules at main ¬∑ MontrealCorpusTools/mfa-models</a><br/><a href="https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/blob/78e481d2b3708957f3f6ac2b4d089bac798ad757/tests/test_acoustic_modeling.py#L9">Montreal-Forced-Aligner/tests/test_acoustic_modeling.py at 78e481d2b3708957f3f6ac2b4d089bac798ad757 ¬∑ MontrealCorpusTools/Montreal-Forced-Aligner</a><br/><a href="https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/blob/78e481d2b3708957f3f6ac2b4d089bac798ad757/montreal_forced_aligner/dictionary/multispeaker.py#L1030">Montreal-Forced-Aligner/montreal_forced_aligner/dictionary/multispeaker.py at 78e481d2b3708957f3f6ac2b4d089bac798ad757 ¬∑ MontrealCorpusTools/Montreal-Forced-Aligner</a><br/><a href="https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/blob/78e481d2b3708957f3f6ac2b4d089bac798ad757/montreal_forced_aligner/db.py#L796">Montreal-Forced-Aligner/montreal_forced_aligner/db.py at 78e481d2b3708957f3f6ac2b4d089bac798ad757 ¬∑ MontrealCorpusTools/Montreal-Forced-Aligner</a><br/><a href="https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/blob/78e481d2b3708957f3f6ac2b4d089bac798ad757/montreal_forced_aligner/data.py#L114">Montreal-Forced-Aligner/montreal_forced_aligner/data.py at 78e481d2b3708957f3f6ac2b4d089bac798ad757 ¬∑ MontrealCorpusTools/Montreal-Forced-Aligner</a><br/><a href="https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/blob/78e481d2b3708957f3f6ac2b4d089bac798ad757/montreal_forced_aligner/command_line/train_acoustic_model.py#L80">Montreal-Forced-Aligner/montreal_forced_aligner/command_line/train_acoustic_model.py at 78e481d2b3708957f3f6ac2b4d089bac798ad757 ¬∑ MontrealCorpusTools/Montreal-Forced-Aligner</a><br/><a href="https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/blob/78e481d2b3708957f3f6ac2b4d089bac798ad757/montreal_forced_aligner/corpus/acoustic_corpus.py#L1114">Montreal-Forced-Aligner/montreal_forced_aligner/corpus/acoustic_corpus.py at 78e481d2b3708957f3f6ac2b4d089bac798ad757 ¬∑ MontrealCorpusTools/Montreal-Forced-Aligner</a><br/><a href="https://github.com/roedoejet/g2p/blob/main/g2p/constants.py">g2p/g2p/constants.py at main ¬∑ roedoejet/g2p</a><br/><a href="https://github.com/roedoejet/g2p/blob/main/g2p/mappings/langs/sal/sal_apa_to_ipa.csv">g2p/g2p/mappings/langs/sal/sal_apa_to_ipa.csv at main ¬∑ roedoejet/g2p</a><br/><a href="https://blog.mothertongues.org/g2p-basic-mappings-local/">G2P Part 3: Make a basic mapping with g2p | Mother Tongues Blog</a><br/><a href="https://dhdaines.github.io/alignment-demo/">Speech to text alignment demo</a><br/><a href="https://github.com/facebook/Ax">facebook/Ax: Adaptive Experimentation Platform</a><br/><a href="https://github.com/csalt-research/salsa/commit/ef06f0d9ff28e3e8f866af5810ca77f63c86ac58">adding salsa code ¬∑ csalt-research/salsa@ef06f0d</a><br/><a href="https://github.com/Lightning-AI/litgpt/commits/main/README.md?after=f655f01b19d32fcf7f7d3fd8b68b25b904c825e4+104">History for README.md - Lightning-AI/litgpt</a><br/><a href="https://github.com/Lightning-AI/litgpt/commits/main/pyproject.toml?after=f655f01b19d32fcf7f7d3fd8b68b25b904c825e4+34">History for pyproject.toml - Lightning-AI/litgpt</a><br/><a href="https://github.com/Lightning-AI/litgpt/commits/b3b7fdc81c2ea1daed52950b66c953fc75ae0c71/setup.py">History for setup.py - Lightning-AI/litgpt</a><br/><a href="https://github.com/Lightning-AI/litgpt/commit/a6059b2eb8eaf46985af7a0cc6348736a46aa818">StableLM Zephyr 3B (#801) ¬∑ Lightning-AI/litgpt@a6059b2</a><br/><a href="https://huggingface.co/mistralai/Mathstral-7B-v0.1">mistralai/Mathstral-7B-v0.1 ¬∑ Hugging Face</a><br/><a href="https://www.dropbox.com/scl/fi/5xhmityps82xwaiq46s3o/2499.mp4?rlkey=k60qmg6n27au1spnpzt2d5t9g&e=1&dl=0">2499.mp4</a><br/><a href="https://github.com/Srijith-rkr/Whispering-LLaMA/tree/main/lit_llama">Whispering-LLaMA/lit_llama at main ¬∑ Srijith-rkr/Whispering-LLaMA</a><br/><a href="https://github.com/Lightning-AI/lit-llama">Lightning-AI/lit-llama: Implementation of the LLaMA language model based on nanoGPT. Supports flash attention, Int8 and GPTQ 4bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed.</a><br/><a href="https://github.com/search?q=repo%3AMontrealCorpusTools%2FMontreal-Forced-Aligner+phonological&type=issues">Issue search results</a><br/><a href="https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/issues/810">Have some way to model stress in Japanese MFA ¬∑ Issue #810 ¬∑ MontrealCorpusTools/Montreal-Forced-Aligner</a><br/><a href="https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/issues/813">When to use G2P models? When to use acoustic models? ¬∑ Issue #813 ¬∑ MontrealCorpusTools/Montreal-Forced-Aligner</a><br/><a href="https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/issues/745">QUESTION: Clarification on training a new model with phone groups and phonological rules ¬∑ Issue #745 ¬∑ MontrealCorpusTools/Montreal-Forced-Aligner</a><br/><a href="https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/issues/770">[BUG] --g2p_model_path option of align_one command is not working ¬∑ Issue #770 ¬∑ MontrealCorpusTools/Montreal-Forced-Aligner</a><br/><a href="https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/pull/773/files">Various bug fixes by mmcauliffe ¬∑ Pull Request #773 ¬∑ MontrealCorpusTools/Montreal-Forced-Aligner</a><br/><a href="https://stackoverflow.com/questions/533905/how-to-get-the-cartesian-product-of-multiple-lists">python - How to get the Cartesian product of multiple lists - Stack Overflow</a><br/><a href="https://stackoverflow.com/questions/14032521/python-data-structure-sort-list-alphabetically">Python data structure sort list alphabetically - Stack Overflow</a><br/><a href="https://www.instagram.com/">Instagram</a><br/><a href="https://www.nodalida-bhlt2025.eu/call-for-papers">NoDaLiDa/Baltic-HLT 2025 - Call for papers</a><br/><a href="https://en.wiktionary.org/wiki/book#English">book - Wiktionary, the free dictionary</a><br/><a href="https://github.com/m-bain/whisperX/blob/main/whisperx/alignment.py">whisperX/whisperx/alignment.py at main ¬∑ m-bain/whisperX</a><br/><a href="https://pytorch.org/audio/stable/generated/torchaudio.pipelines.WAV2VEC2_ASR_BASE_960H.html">WAV2VEC2_ASR_BASE_960H ‚Äî Torchaudio 2.4.0 documentation</a><br/><a href="https://huggingface.co/facebook/wav2vec2-base-960h/blob/main/vocab.json">vocab.json ¬∑ facebook/wav2vec2-base-960h at main</a><br/><a href="https://github.com/facebookresearch/fairseq/blob/main/examples/wav2vec/README.md">fairseq/examples/wav2vec/README.md at main ¬∑ facebookresearch/fairseq</a><br/><a href="https://kth-my.sharepoint.com/:p:/r/personal/ghe_ug_kth_se/_layouts/15/Doc.aspx?sourcedoc=%7B1A883E45-3555-4583-B50E-56A97B09F014%7D&file=ghenter_syndata4genai_talk.pptx&action=edit&mobileredirect=true">ghenter_syndata4genai_talk.pptx</a><br/><a href="https://www.google.com/search?q=speech+recognition+for+spontaneous+speech&rlz=1C5GCEM_enSE990SE991&oq=speech+recognition+for+spontaneous+speech&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIHCAEQIRigAdIBCDkzMDlqMWo3qAIAsAIA&sourceid=chrome&ie=UTF-8">speech recognition for spontaneous speech - Google Search</a><br/><a href="https://www.mdpi.com/2078-2489/14/2/137">Information | Free Full-Text | Reconsidering Read and Spontaneous Speech: Causal Perspectives on the Generation of Training Data for Automatic Speech Recognition</a><br/><a href="https://www.isca-archive.org/interspeech_2022/horii22_interspeech.pdf">horii22_interspeech.pdf</a><br/><a href="https://catalog.ldc.upenn.edu/LDC2004T19">Fisher English Training Speech Part 1 Transcripts - Linguistic Data Consortium</a><br/><a href="https://www.google.com/search?q=whisperx+phonetic&rlz=1C5GCEM_enSE990SE991&oq=whisperx+phonetic&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIHCAEQIRigATIHCAIQIRigATIHCAMQIRigAdIBCDI2MzZqMWo3qAIAsAIA&sourceid=chrome&ie=UTF-8">whisperx phonetic - Google Search</a><br/><a href="https://github.com/m-bain/whisperX/issues/762">Detecting Syllable / Phonetic Timestamps ¬∑ Issue #762 ¬∑ m-bain/whisperX</a><br/><a href="https://github.com/Shahabks/my-voice-analysis">Shahabks/my-voice-analysis: My-Voice Analysis is a Python library for the analysis of voice (simultaneous speech, high entropy) without the need of a transcription. It breaks utterances and detects syllable boundaries, fundamental frequency contours, and formants.</a><br/><a href="https://www.google.com/search?q=fairseq+finetune+wav2vec2&rlz=1C5GCEM_enSE990SE991&oq=fairseq+finetune+wav2vec2&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIGCAEQRRg70gEINTA5MWoxajeoAgCwAgA&sourceid=chrome&ie=UTF-8">fairseq finetune wav2vec2 - Google Search</a><br/><a href="https://github.com/facebookresearch/fairseq/issues/2922">How to fine-tune wav2vec 2.0 with TIMIT ¬∑ Issue #2922 ¬∑ facebookresearch/fairseq</a><br/><a href="https://www.cs.ru.nl/bachelors-theses/2022/Thomas_Kolb___1027332___Fine-tuning_Wav2vec2.0_on_caption_data.pdf">Thomas_Kolb___1027332___Fine-tuning_Wav2vec2.0_on_caption_data.pdf</a><br/><a href="https://pytorch.org/audio/main/generated/torchaudio.models.wav2vec2.utils.import_fairseq_model.html">torchaudio.models.wav2vec2.utils.import_fairseq_model ‚Äî Torchaudio 2.5.0.dev20240829 documentation</a><br/><a href="https://huggingface.co/facebook/wav2vec2-lv-60-espeak-cv-ft">facebook/wav2vec2-lv-60-espeak-cv-ft ¬∑ Hugging Face</a><br/><a href="https://huggingface.co/models?other=phoneme-recognition">Models - Hugging Face</a><br/><a href="https://arxiv.org/abs/2109.11680">[2109.11680] Simple and Effective Zero-shot Cross-lingual Phoneme Recognition</a><br/><a href="https://github.com/facebookresearch/fairseq/tree/main/examples/wav2vec">fairseq/examples/wav2vec at main ¬∑ facebookresearch/fairseq</a><br/><a href="https://arxiv.org/abs/2006.13979">[2006.13979] Unsupervised Cross-lingual Representation Learning for Speech Recognition</a><br/><a href="https://github.com/m-bain/whisperX/blob/main/whisperx/utils.py#L399">whisperX/whisperx/utils.py at main ¬∑ m-bain/whisperX</a><br/><a href="https://github.com/m-bain/whisperX/tree/main">m-bain/whisperX: WhisperX: Automatic Speech Recognition with Word-level Timestamps (& Diarization)</a><br/><a href="https://github.com/m-bain/whisperX/blob/main/whisperx/transcribe.py">whisperX/whisperx/transcribe.py at main ¬∑ m-bain/whisperX</a><br/><a href="https://github.com/m-bain/whisperX/blob/main/whisperx/alignment.py">whisperX/whisperx/alignment.py at main ¬∑ m-bain/whisperX</a><br/><a href="https://github.com/m-bain/whisperX/tree/main?tab=readme-ov-file">m-bain/whisperX: WhisperX: Automatic Speech Recognition with Word-level Timestamps (& Diarization)</a><br/><a href="https://hub.docker.com/r/pytorch/pytorch">pytorch/pytorch - Docker Image | Docker Hub</a><br/><a href="https://huggingface.co/pyf98/owsm_ctc_v3.1_1B">pyf98/owsm_ctc_v3.1_1B ¬∑ Hugging Face</a><br/><a href="https://github.com/pyf98/espnet/tree/owsm-ctc">pyf98/espnet at owsm-ctc</a><br/><a href="https://github.com/pyf98/espnet/tree/owsm-ctc">pyf98/espnet at owsm-ctc</a><br/><a href="https://github.com/pyf98/espnet">pyf98/espnet: End-to-End Speech Processing Toolkit</a><br/><a href="https://github.com/lumaku/ctc-segmentation">lumaku/ctc-segmentation: Segment an audio file and obtain utterance alignments. (Python package)</a><br/><a href="https://jimregan.github.io/notes/">notes | Things I know I‚Äôll forget</a><br/><a href="https://jimregan.github.io/notes/whisperx/diarisation/hsi/2024/07/26/whisperx-reverse-diarisation.html">WhisperX using diarisation instead of VAD | notes</a><br/><a href="https://github.com/jimregan/notes">jimregan/notes</a><br/><a href="https://github.com/alphacep/whisper-prompts?tab=readme-ov-file">alphacep/whisper-prompts: OpenAI Whisper Prompt Examples</a><br/><a href="https://cookbook.openai.com/examples/whisper_prompting_guide">Whisper prompting guide | OpenAI Cookbook</a><br/><a href="https://github.com/openai/whisper/discussions/117">prompt vs prefix in DecodingOptions ¬∑ openai/whisper ¬∑ Discussion #117</a><br/><a href="https://arxiv.org/abs/2305.11095">[2305.11095] Prompting the Hidden Talent of Web-Scale Speech Models for Zero-Shot Task Generalization</a><br/><a href="https://github.com/jasonppy/PromptingWhisper">jasonppy/PromptingWhisper: Promting Whisper for Audio-Visual Speech Recognition, Code-Switched Speech Recognition, and Zero-Shot Speech Translation</a><br/><a href="https://github.com/ga642381/Speech-Prompts-Adapters">ga642381/Speech-Prompts-Adapters: This Repository surveys the paper focusing on Prompting and Adapters for Speech Processing.</a><br/><a href="https://docs.google.com/document/d/1PJGdc8GqXt2lkMCyXwWzPSn6W83NYqkwT6QqHlqKyE4/edit#heading=h.z4ypn9xegmdx">MM-conv dataset analysis - Google Docs</a><br/><a href="https://www.google.com/search?q=alcove+in+swedish&sca_esv=f03d7cceb14fcf1a&sca_upv=1&rlz=1C5GCEM_enSE990SE991&sxsrf=ADLYWIIh-LU4ZCaek2M05K41Aj8ydZsCIQ%3A1724942782314&ei=vonQZsrsEru6wPAP062agAg&ved=0ahUKEwjKw7DOuJqIAxU7HRAIHdOWBoAQ4dUDCA8&uact=5&oq=alcove+in+swedish&gs_lp=Egxnd3Mtd2l6LXNlcnAaAhgCIhFhbGNvdmUgaW4gc3dlZGlzaDIIEAAYFhgeGA8yCxAAGIAEGIYDGIoFMgsQABiABBiGAxiKBTILEAAYgAQYhgMYigUyCxAAGIAEGIYDGIoFMggQABiABBiiBDIIEAAYgAQYogQyCBAAGIAEGKIEMggQABiABBiiBEikD1CFAVjCDXABeAGQAQCYAZwCoAHXDKoBBTUuMi40uAEDyAEA-AEBmAIMoALpDMICChAAGLADGNYEGEfCAg0QABiABBiwAxhDGIoFwgIKEAAYgAQYQxiKBcICBRAAGIAEwgIIEAAYgAQYiwPCAgsQLhiABBjHARivAcICERAAGIAEGJECGPgFGIoFGIsDwgIOEAAYgAQYkQIYigUYiwPCAgsQABiABBiRAhiKBcICBhAAGBYYHsICCRAAGBYYiwMYHsICCxAAGBYYiwMYHhgPmAMAiAYBkAYKkgcFNi4yLjSgB-hE&sclient=gws-wiz-serp">alcove in swedish - Google Search</a><br/><a href="https://github.com/openai/whisper/discussions/478">Getting the top few transcription results ¬∑ openai/whisper ¬∑ Discussion #478</a><br/><a href="https://colab.research.google.com/drive/1MVcZioMz7cc1wnRdxPG-_uebKtAdf8-5#scrollTo=BjkFQSzmZeMn">Untitled43.ipynb - Colab</a><br/><a href="https://github.com/kylebgorman/pynini/blob/master/pynini/examples/case.py">pynini/pynini/examples/case.py at master ¬∑ kylebgorman/pynini</a><br/><a href="https://www.opengrm.org/twiki/bin/view/GRM/Pynini">Pynini < GRM < TWiki</a><br/><a href="https://github.com/kylebgorman/pynini/tree/master/pywrapfst">pynini/pywrapfst at master ¬∑ kylebgorman/pynini</a><br/><a href="https://github.com/kylebgorman/pynini/tree/master/pynini">pynini/pynini at master ¬∑ kylebgorman/pynini</a><br/><a href="https://www.google.com/search?q=pynini-notebook+pip&rlz=1C5GCEM_enSE990SE991&oq=pynini-notebook+pip&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIHCAEQIRigATIHCAIQIRigATIHCAMQIRigAdIBCDE2MzZqMGo3qAIAsAIA&sourceid=chrome&ie=UTF-8">pynini-notebook pip - Google Search</a><br/><a href="https://github.com/dan-wells/kiss-aligner/blob/main/egs/learngaelic_litir/local/split_and_number_sentences.py">kiss-aligner/egs/learngaelic_litir/local/split_and_number_sentences.py at main ¬∑ dan-wells/kiss-aligner</a><br/><a href="https://eleanorchodroff.com/tutorial/kaldi/forced-alignment.html">Kaldi Tutorial</a><br/><a href="https://github.com/dan-wells/kiss-aligner">dan-wells/kiss-aligner: Simple Kaldi recipe for forced alignment</a><br/><a href="https://www.eleanorchodroff.com/tutorial/kaldi/forced-alignment.html#extract-alignment">Kaldi Tutorial</a><br/><a href="https://www.eleanorchodroff.com/tutorial/kaldi/forced-alignment.html#prepare-alignment-files">Kaldi Tutorial</a><br/><a href="https://groups.io/g/Praat-Users-List/topic/101618569">Praat-Users-List@groups.io | Detect 'inhalation' or breathing?</a><br/><a href="chrome://newtab/">New Tab</a><br/><a href="https://x.com/e51dc715a5/status/1829154032516292819">(4) Hall of Lore on X: "If the name of the masked people in Rh√ªn translates to ‚Äòpeople of the device/machine‚Äô, they could work as an interesting parallel to what‚Äôs going on in Eregion in Season 2 (given that Sauron has already been active in the East). #TROPspoilers (from Letter 131) https://t.co/rZOSGfBSFM" / X</a><br/><a href="https://github.com/ydqmkkx/Respiro-en/blob/main/demo.ipynb">Respiro-en/demo.ipynb at main ¬∑ ydqmkkx/Respiro-en</a><br/><a href="https://huggingface.co/pyannote/speech-separation-ami-1.0">pyannote/speech-separation-ami-1.0 ¬∑ Hugging Face</a><br/><a href="https://huggingface.co/pyannote/overlapped-speech-detection">pyannote/overlapped-speech-detection ¬∑ Hugging Face</a><br/><a href="https://huggingface.co/pyannote/voice-activity-detection">pyannote/voice-activity-detection ¬∑ Hugging Face</a><br/><a href="https://github.com/qiujiali/lattice-rescore/blob/main/utils/kaldi2htk_lattice.sh">lattice-rescore/utils/kaldi2htk_lattice.sh at main ¬∑ qiujiali/lattice-rescore</a><br/><a href="https://github.com/openai/whisper/discussions/478">Getting the top few transcription results ¬∑ openai/whisper ¬∑ Discussion #478</a><br/><a href="https://huggingface.co/novateur/WavTokenizer">novateur/WavTokenizer ¬∑ Hugging Face</a><br/><a href="https://github.com/jishengpeng/WavTokenizer">jishengpeng/WavTokenizer: SOTA discrete acoustic codec models with 40 tokens per second for audio language modeling</a><br/><a href="https://arxiv.org/pdf/2408.16532">2408.16532</a><br/><a href="https://www.thebyronsociety.com/byron-and-le-mal-du-siecle/">Byron and Le mal du si√®cle - the byron society</a><br/><a href="https://www.songsterr.com/a/wsa/scorpions-the-sails-of-charon-tab-s52956">The Sails Of Charon Tab by Scorpions | Songsterr Tabs with Rhythm</a><br/><a href="https://www.youtube.com/watch?v=mz-uPBFXRNM">‚ÄúOh f*** off!‚Äù ü§¨üòÇ Ryan Reynolds and Hugh Jackman on how Deadpool & Wolverine almost didn't happen - YouTube</a><br/><a href="https://github.com/gtn-org/gtn/pulls?q=is%3Apr+is%3Aclosed">Pull requests ¬∑ gtn-org/gtn</a><br/><a href="https://github.com/gtn-org/gtn/pull/30/files#diff-6dce77377da27d99ba79f2ec657e3e5292fef31f2943f137af8e102031b2f707">needleman wunsch and smith waterman example in python with gtn by awni ¬∑ Pull Request #30 ¬∑ gtn-org/gtn</a><br/><a href="https://github.com/gtn-org/gtn/blob/master/bindings/python/examples/pytorch_loss.py">gtn/bindings/python/examples/pytorch_loss.py at master ¬∑ gtn-org/gtn</a><br/><a href="https://github.com/revdotcom/fstalign/blob/develop/docs/NLP-Format.md">fstalign/docs/NLP-Format.md at develop ¬∑ revdotcom/fstalign</a><br/><a href="https://anaconda.org/conda-forge/openfst">Openfst | Anaconda.org</a><br/><a href="https://x.com/home">Home / X</a><br/><a href="https://github.com/AdolfVonKleist/Phonetisaurus?tab=readme-ov-file">AdolfVonKleist/Phonetisaurus: Phonetisaurus G2P</a><br/><a href="https://github.com/AdolfVonKleist/phonetisaurus-downloads">AdolfVonKleist/phonetisaurus-downloads: Models, packages and other binary files and distributions related to Phonetisaurus.</a><br/><a href="https://github.com/AdolfVonKleist/Phonetisaurus/pull/27/files">Several changes to the build system by giuliopaci ¬∑ Pull Request #27 ¬∑ AdolfVonKleist/Phonetisaurus</a><br/><a href="https://montreal-forced-aligner.readthedocs.io/en/latest/user_guide/workflows/g2p_train.html">Train a new G2P model (mfa train_g2p) ‚Äî Montreal Forced Aligner 3.0.0 documentation</a><br/><a href="https://github.com/google-research/google-research/commits/master/?after=bfa1a6eaaac2bbde8ab6a376de6974233b7456c1+34">Commits ¬∑ google-research/google-research</a><br/><a href="https://github.com/google-research/google-research/commit/95d0f9aff38007fc9bcedabf8b8b4e65c65d00a7">Rename FAX to DrJAX. ¬∑ google-research/google-research@95d0f9a</a><br/><a href="https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/blob/main/montreal_forced_aligner/g2p/phonetisaurus_trainer.py">Montreal-Forced-Aligner/montreal_forced_aligner/g2p/phonetisaurus_trainer.py at main ¬∑ MontrealCorpusTools/Montreal-Forced-Aligner</a><br/><a href="https://github.com/Svito-zar/gesticulator/issues/18">What is the reason to do Euler_Angle to Expressional_Map conversion? ¬∑ Issue #18 ¬∑ Svito-zar/gesticulator</a><br/><a href="https://orbi.uliege.be/bitstream/2268/306081/1/Todesco%20J%20and%20Bruls%202O202%20Highly%20accurate%20differentiation%20of%20the%20exponential%20map%20and%20its%20tangent%20operator%20%28Author%20postprint%29.pdf">Todesco J and Bruls 2O202 Highly accurate differentiation of the exponential map and its tangent operator (Author postprint).pdf</a><br/><a href="https://github.com/qxcv/pose-prediction/blob/master/expmap.py">pose-prediction/expmap.py at master ¬∑ qxcv/pose-prediction</a><br/><a href="https://github.com/daschablume/g2p_correction">daschablume/g2p_correction: Web-application for grapheme-to-phoneme correction using user feedback</a><br/><a href="http://www.andre-gaschler.com/rotationconverter/">3D Rotation Converter</a><br/><a href="https://www.google.com/search?q=%22exponential+map%22+transform+to+target+cordinates&rlz=1C5GCEM_enSE990SE991&oq=%22exponential+map%22+transform+to+target+cordinates&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIJCAEQIRgKGKABMgkIAhAhGAoYoAHSAQkxMDk3NmowajeoAgCwAgA&sourceid=chrome&ie=UTF-8">"exponential map" transform to target cordinates - Google Search</a><br/><a href="https://danieltakeshi.github.io/2018/01/11/twists-and-exponential-coordinates/">Twists and Exponential Coordinates</a><br/><a href="https://thenumb.at/Exponential-Rotations/">Exponentially Better Rotations</a><br/><a href="http://yoonhada.com/?p=1419&ckattempt=1">Exponentially Better Rotations ‚Äì yoonhada</a><br/><a href="https://github.com/rousseau/dynMRI/blob/master/motion_estimation/Exponential_map.py">dynMRI/motion_estimation/Exponential_map.py at master ¬∑ rousseau/dynMRI</a><br/><a href="https://www.google.com/search?q=pytorch+motion&sca_esv=db73fa7fbeeadfbb&sca_upv=1&rlz=1C5GCEM_enSE990SE991&sxsrf=ADLYWIKmDKK_6GCpiDNFbguBqu51uGLfEQ%3A1725141227582&ei=65DTZvqaI8PLwPAPn-2K6Ao&ved=0ahUKEwi6vLrwm6CIAxXDJRAIHZ-2Aq0Q4dUDCBA&uact=5&oq=pytorch+motion&gs_lp=Egxnd3Mtd2l6LXNlcnAiDnB5dG9yY2ggbW90aW9uMgQQABgeMgQQABgeMgYQABgIGB4yBhAAGAgYHjIGEAAYCBgeMgsQABiABBiGAxiKBTILEAAYgAQYhgMYigUyCxAAGIAEGIYDGIoFMggQABiABBiiBDIIEAAYgAQYogRIwhdQqxJY3xRwAXgBkAEAmAFsoAGlAaoBAzEuMbgBA8gBAPgBAZgCA6ACsgHCAgoQABiwAxjWBBhHwgIGEAAYDRgewgIIEAAYCBgNGB6YAwCIBgGQBgeSBwMyLjGgB5oN&sclient=gws-wiz-serp">pytorch motion - Google Search</a><br/><a href="https://github.com/GuyTevet/motion-diffusion-model?tab=readme-ov-file">GuyTevet/motion-diffusion-model: The official PyTorch implementation of the paper "Human Motion Diffusion Model"</a><br/><a href="https://guytevet.github.io/mas-page/">MAS: Multi-view Ancestral Sampling for 3D motion generation using 2D diffusion</a><br/><a href="https://github.com/roykapon/MAS/blob/main/model/smpl.py">MAS/model/smpl.py at main ¬∑ roykapon/MAS</a><br/><a href="https://github.com/Mathux/ACTOR">Mathux/ACTOR: Official Pytorch implementation of the paper "Action-Conditioned 3D Human Motion Synthesis with Transformer VAE", ICCV 2021</a><br/><a href="https://pytorch3d.org/docs/why_pytorch3d.html">why_pytorch3d ¬∑ PyTorch3D</a><br/><a href="https://pytorch3d.org/tutorials/render_densepose">PyTorch3D ¬∑ A library for deep learning with 3D data</a><br/><a href="https://github.com/search?q=repo%3Afacebookresearch%2Fpytorch3d%20expmap&type=code">Code search results</a><br/><a href="https://github.com/facebookresearch/pytorch3d/pull/1478">Delegating crop_bbox to FrameData by salaxieb ¬∑ Pull Request #1478 ¬∑ facebookresearch/pytorch3d</a><br/><a href="https://github.com/search?q=repo%3Afacebookresearch%2Fpytorch3d+exp_map&type=code">Code search results</a><br/><a href="https://github.com/facebookresearch/pytorch3d/blob/05cbea115acbbcbea77999c03d55155b23479991/docs/tutorials/bundle_adjustment.ipynb#L44">pytorch3d/docs/tutorials/bundle_adjustment.ipynb at 05cbea115acbbcbea77999c03d55155b23479991 ¬∑ facebookresearch/pytorch3d</a><br/><a href="https://github.com/facebookresearch/pytorch3d/pulls?q=is%3Apr+is%3Aclosed">Pull requests ¬∑ facebookresearch/pytorch3d</a><br/><a href="https://github.com/facebookresearch/pytorch3d/pull/1478/files">Delegating crop_bbox to FrameData by salaxieb ¬∑ Pull Request #1478 ¬∑ facebookresearch/pytorch3d</a><br/><a href="https://github.com/facebookresearch/pytorch3d/pull/1801">Allow indexing for classes inheriting Transform3d by ListIndexOutOfRange ¬∑ Pull Request #1801 ¬∑ facebookresearch/pytorch3d</a><br/><a href="https://github.com/facebookresearch/pytorch3d/pull/1606">checkin pytorch nerf tutorial branch by andrewldesousa ¬∑ Pull Request #1606 ¬∑ facebookresearch/pytorch3d</a><br/><a href="https://github.com/vchoutas/torch-mesh-isect?tab=readme-ov-file">vchoutas/torch-mesh-isect</a><br/><a href="https://github.com/facebookresearch/detectron2/blob/main/MODEL_ZOO.md">detectron2/MODEL_ZOO.md at main ¬∑ facebookresearch/detectron2</a><br/><a href="https://github.com/mattloper/chumpy/blob/master/chumpy/ch_ops.py">chumpy/chumpy/ch_ops.py at master ¬∑ mattloper/chumpy</a><br/><a href="https://pypi.org/project/bvhio/">bvhio ¬∑ PyPI</a><br/><a href="https://github.com/Wasserwecken/spatial-transform">Wasserwecken/spatial-transform: Transform hierarchies in 3D space</a><br/><a href="https://github.com/topics/bvh-files">bvh-files ¬∑ GitHub Topics</a><br/><a href="https://github.com/Wasserwecken/bvhio">Wasserwecken/bvhio: Read, write, edit and create .bvh files with hierarchical 3D transforms</a><br/><a href="https://github.com/omimo/PyMO/forks?include=active&page=1&period=5y&sort_by=stargazer_counts">Forks ¬∑ omimo/PyMO</a><br/><a href="https://github.com/simonalexanderson/PyMO?tab=readme-ov-file">simonalexanderson/PyMO: A library for machine learning research on motion capture data</a><br/><a href="https://github.com/simonalexanderson/PyMO/blob/master/pymo/parsers.py#L216">PyMO/pymo/parsers.py at master ¬∑ simonalexanderson/PyMO</a><br/><a href="https://github.com/ElijahAhianyo/PyMO">ElijahAhianyo/PyMO: A library for machine learning research on motion capture data</a><br/><a href="https://github.com/airium/PyMO">airium/PyMO: A library for machine learning research on motion capture data</a><br/><a href="https://stackoverflow.com/questions/62052409/how-to-locate-timestamps-of-a-subset-of-a-video">python - How to Locate Timestamps of a Subset of a Video - Stack Overflow</a><br/><a href="https://github.com/omimo/PyMO/blob/master/pymo/viz_tools.py">PyMO/pymo/viz_tools.py at master ¬∑ omimo/PyMO</a><br/><a href="https://omid.al/projects/pymo/">PyMO: Motion Capture Library</a><br/><a href="https://github.com/shivammehta25/Match-TTSG/blob/main/pymo/viz_tools.py">Match-TTSG/pymo/viz_tools.py at main ¬∑ shivammehta25/Match-TTSG</a><br/><a href="https://www.instagram.com/">Instagram</a><br/><a href="https://www.google.com/search?q=bvh+to+mp4&rlz=1C5GCEM_enSE990SE991&oq=bvh+to+mp4&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIICAEQABgWGB4yDQgCEAAYhgMYgAQYigUyDQgDEAAYhgMYgAQYigUyDQgEEAAYhgMYgAQYigUyCggFEAAYgAQYogQyCggGEAAYgAQYogQyCggHEAAYgAQYogQyCggIEAAYgAQYogTSAQgyMDU0ajFqN6gCALACAA&sourceid=chrome&ie=UTF-8">bvh to mp4 - Google Search</a><br/><a href="https://github.com/BartMoyaers/BvhToDeepMimic">BartMoyaers/BvhToDeepMimic: Convert .bvh files (Biovision Hierarchy) to DeepMimic format.</a><br/><a href="https://pypi.org/project/bvhtoolbox/">bvhtoolbox ¬∑ PyPI</a><br/><a href="https://github.com/orgs/genea-workshop/repositories?type=all">genea-workshop repositories</a><br/><a href="https://github.com/genea-workshop/genea_visualizer/blob/master/celery-queue/blender_render.py">genea_visualizer/celery-queue/blender_render.py at master ¬∑ genea-workshop/genea_visualizer</a><br/><a href="https://github.com/genea-workshop/2024">genea-workshop/2024: For the GENEA Workshop 2024 pages</a><br/><a href="https://github.com/genea-workshop/leaderboard">genea-workshop/leaderboard</a><br/><a href="https://github.com/genea-workshop/2023_ivi_baseline/blob/main/pymo/viz_tools.py">2023_ivi_baseline/pymo/viz_tools.py at main ¬∑ genea-workshop/2023_ivi_baseline</a><br/><a href="https://github.com/genea-workshop/genea_numerical_evaluations/blob/2022/hellinger_distance.py">genea_numerical_evaluations/hellinger_distance.py at 2022 ¬∑ genea-workshop/genea_numerical_evaluations</a><br/><a href="https://github.com/genea-workshop/Speech_driven_gesture_generation_with_autoencoder/blob/master/data_processing/alt_prosody.py">Speech_driven_gesture_generation_with_autoencoder/data_processing/alt_prosody.py at master ¬∑ genea-workshop/Speech_driven_gesture_generation_with_autoencoder</a><br/><a href="https://www.opengrm.org/twiki/bin/view/GRM/Pynini">Pynini < GRM < TWiki</a><br/><a href="https://www.opengrm.org/twiki/bin/view/GRM/PyniniDocs">PyniniDocs < GRM < TWiki</a><br/><a href="https://www.opengrm.org/twiki/bin/view/GRM/PyniniDocs">PyniniDocs < GRM < TWiki</a><br/><a href="file:///Users/joregan/Downloads/Gorman,%20Kyle%20(author)_Sproat,%20Richard%20(author)%20-%20Finite-State%20Text%20Processing%20(2022,%20Springer%20International%20Publishing)%20[10.1007_978-3-031-02179-4]%20-%20libgen.li.pdf">Gorman, Kyle (author)_Sproat, Richard (author) - Finite-State Text Processing (2022, Springer International Publishing) [10.1007_978-3-031-02179-4] - libgen.li.pdf</a><br/><a href="https://www.tvguide.co.uk/">TV Listings | TV Guide</a><br/><a href="https://www.instagram.com/direct/t/110437113687820/">Inbox ‚Ä¢ Direct</a><br/><a href="https://www.google.com/search?q=github+render_mp4&rlz=1C5GCEM_enSE990SE991&oq=github+render_mp4&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIGCAEQRRhA0gEIMTE4MWoxajmoAgCwAgE&sourceid=chrome&ie=UTF-8">github render_mp4 - Google Search</a><br/><a href="https://github.com/orgs/jupyterlab/repositories?type=all&page=2">jupyterlab repositories</a><br/><a href="https://github.com/jupyterlab/jupyter-renderers">jupyterlab/jupyter-renderers: Renderers and renderer extensions for JupyterLab</a><br/><a href="https://github.com/jupyterlab/jupyter-collaboration?tab=readme-ov-file">jupyterlab/jupyter-collaboration: A Jupyter Server Extension Providing Support for Y Documents</a><br/><a href="https://github.com/jupyterlab/lumino?tab=readme-ov-file">jupyterlab/lumino: Lumino is a library for building interactive web applications</a><br/><a href="https://github.com/jimregan/g2p_correction/tree/main">jimregan/g2p_correction: Web-application for grapheme-to-phoneme correction using user feedback</a><br/><a href="https://www.google.com/search?q=pynini+ubuntu&rlz=1C5GCEM_enSE990SE991&oq=pynini+ubuntu&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIHCAEQIRigAdIBCDQ1NzJqMWo3qAIAsAIA&sourceid=chrome&ie=UTF-8">pynini ubuntu - Google Search</a><br/><a href="https://github.com/kylebgorman/pynini/issues/16">Installation issues ¬∑ Issue #16 ¬∑ kylebgorman/pynini</a><br/><a href="https://github.com/funderburkjim/pynini-learn/blob/master/ejf07/edit_transducer.py">pynini-learn/ejf07/edit_transducer.py at master ¬∑ funderburkjim/pynini-learn</a><br/><a href="https://chatgpt.com/c/b306b080-518c-40f3-82af-fe78b34316bf">Getting Started with Pynini</a><br/><a href="https://curation.clarin.eu/linkchecker/CLARINO_provider_National_Library_of_Norway">Curation Dashboard</a><br/><a href="https://www.nb.no/sprakbanken/en/resource-catalogue/oai-nb-no-sbr-56/">NST Swedish ASR Database (16 kHz) - reorganized - Spr√•kbanken</a><br/><a href="https://www.nb.no/sbfil/talegjenkjenning/16kHz_2020/se_2020/se-16khz_reorganized.pdf">se-16khz_reorganized.pdf</a><br/><a href="https://www.google.com/search?q=NST+Swedish+tts&rlz=1C5GCEM_enSE990SE991&oq=NST+Swedish+tts&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIHCAEQIRigAdIBCDI0ODVqMGo3qAIAsAIA&sourceid=chrome&ie=UTF-8">NST Swedish tts - Google Search</a><br/><a href="https://www.google.com/search?q=sve.ibm.talesyntese.tar.gz&rlz=1C5GCEM_enSE990SE991&oq=sve.ibm.talesyntese.tar.gz&gs_lcrp=EgZjaHJvbWUyBggAEEUYOdIBBzU3M2owajSoAgCwAgE&sourceid=chrome&ie=UTF-8">sve.ibm.talesyntese.tar.gz - Google Search</a><br/><a href="https://www.nb.no/sbfil/dok/nst_taledat_se.pdf">nst_taledat_se.pdf</a><br/><a href="https://www.nb.no/sprakbanken/en/resource-catalogue/oai-nb-no-sbr-18/">Page not found - Spr√•kbanken</a><br/><a href="https://huggingface.co/KBLab/piper-tts-nst-swedish">KBLab/piper-tts-nst-swedish ¬∑ Hugging Face</a><br/><a href="https://www.songsterr.com/a/wsa/toto-hold-the-line-tab-s20390">Hold The Line Tab by Toto | Songsterr Tabs with Rhythm</a><br/><a href="https://www.instagram.com/reel/C-9ETKKR_jo/">‚≠í Gracie Pleschourt ‚≠í Dating Coach For Men | 4 flirty texts that will give her butterfliesüì≤ #datingadviceformen #datingcoachformen #datingtipsformen | Instagram</a><br/><a href="https://www.instagram.com/reel/C-gKZ8Fyw3R/">‚≠í Gracie Pleschourt ‚≠í Dating Coach For Men | Here are 4 signs that she‚Äôs flirting with youüòè #datingadviceformen #datingtipsformen #datingcoachformen | Instagram</a><br/><a href="https://www.instagram.com/reel/C-RXxHAsctM/">‚≠í Gracie Pleschourt ‚≠í Dating Coach For Men | Here are 3 signs that she likes you but won‚Äôt admit it‚Ä¶ #datingtipsformen #datingadviceformen #datingcoachformen | Instagram</a><br/><a href="https://github.com/MarvinLvn/voice-type-classifier?tab=readme-ov-file">MarvinLvn/voice-type-classifier: A deep learning model for classifying audio frames into [SPEECH, KCHI, CHI, MAL, FEM] classes.</a><br/><a href="https://arxiv.org/pdf/2005.12656">2005.12656</a><br/><a href="https://github.com/jimregan/language-resources/blob/master/af/textnorm/classifier/money.grm">language-resources/af/textnorm/classifier/money.grm at master ¬∑ jimregan/language-resources</a><br/><a href="https://github.com/NVIDIA/NeMo-text-processing">NVIDIA/NeMo-text-processing: NeMo text processing for ASR and TTS</a><br/><a href="https://docs.nvidia.com/nemo-framework/user-guide/latest/nemotoolkit/nlp/text_normalization/wfst/wfst_text_normalization.html">Text (Inverse) Normalization ‚Äî NVIDIA NeMo Framework User Guide latest documentation</a><br/><a href="https://github.com/parthsarthi03/raptor/blob/master/requirements.txt">raptor/requirements.txt at master ¬∑ parthsarthi03/raptor</a><br/><a href="https://arxiv.org/pdf/2401.18059">2401.18059</a><br/><a href="https://umap-learn.readthedocs.io/en/latest/supervised.html">UMAP for Supervised Dimension Reduction and Metric Learning ‚Äî umap 0.5 documentation</a><br/><a href="https://github.com/jpetazzo/pipework">jpetazzo/pipework: Software-Defined Networking tools for LXC (LinuX Containers)</a><br/><a href="https://github.com/bbc/react-transcript-editor/blob/master/packages/stt-adapters/index.js">react-transcript-editor/packages/stt-adapters/index.js at master ¬∑ bbc/react-transcript-editor</a><br/><a href="https://www.google.com/search?q=Bvh+render+python+github&sca_esv=c7a01837b1eb8e0f&sca_upv=1&rlz=1C5GCEM_enSE990SE991&sxsrf=ADLYWIKyJrDI70WoDZ21RztNnnondnwtxQ:1725446945077&ei=ITvYZv75A6fEwPAPu8mMkAw&start=10&sa=N&sstk=AagrsujKjCfy8Pu_99VNNcTYgWaSp8QuAuuGRzYv34i9UwgIHDo_67tI-wZk_ZH871dkinnB78isEIVRoRmVce2-jREFraYL4aJmdw&ved=2ahUKEwi-jvXhjqmIAxUnIhAIHbskA8IQ8NMDegQIBxAW&biw=1440&bih=737&dpr=2">Bvh render python github - Google Search</a><br/><a href="https://github.com/20tab/bvh-python">20tab/bvh-python: Python module for parsing BVH (Biovision hierarchical data) mocap files</a><br/><a href="https://github.com/alinen/bvh-python/blob/main/bvh.py">bvh-python/bvh.py at main ¬∑ alinen/bvh-python</a><br/><a href="https://github.com/20tab/bvh-python">20tab/bvh-python: Python module for parsing BVH (Biovision hierarchical data) mocap files</a><br/><a href="https://github.com/rltonoli/bvhsdk?tab=readme-ov-file">rltonoli/bvhsdk</a><br/><a href="https://bvhsdk.readthedocs.io/en/latest/bvhsdk.html#module-bvhsdk.anim">bvh ‚Äî bvhsdk 0.1.0 documentation</a><br/><a href="https://github.com/GuyTevet/motion-diffusion-model/blob/main/visualize/joints2smpl/README.md">motion-diffusion-model/visualize/joints2smpl/README.md at main ¬∑ GuyTevet/motion-diffusion-model</a><br/><a href="https://github.com/alinen/bvh-python/blob/main/bvhvisualize.py">bvh-python/bvhvisualize.py at main ¬∑ alinen/bvh-python</a><br/><a href="https://github.com/OlafHaag/bvh-toolbox/blob/main/src/bvhtoolbox/bvhtree.py">bvh-toolbox/src/bvhtoolbox/bvhtree.py at main ¬∑ OlafHaag/bvh-toolbox</a><br/><a href="https://github.com/KevinLTT/video2bvh?tab=readme-ov-file">KevinLTT/video2bvh: Extracts human motion in video and save it as bvh mocap file.</a><br/><a href="https://github.com/mmatl/pyrender">mmatl/pyrender: Easy-to-use glTF 2.0-compliant OpenGL renderer for visualization of 3D scenes.</a><br/><a href="https://www.google.com/search?q=render+bvh+python+github&rlz=1C5GCEM_enSE990SE991&oq=render+bvh+python+github&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIGCAEQRRg80gEJMTM0MzdqMWo3qAIAsAIA&sourceid=chrome&ie=UTF-8">render bvh python github - Google Search</a><br/><a href="https://github.com/google-research/mint/blob/main/mint/core/model_builder.py">mint/mint/core/model_builder.py at main ¬∑ google-research/mint</a><br/><a href="https://github.com/nefeliandreou/PoseRepresentation/blob/master/src/bvh/rotation2xyz.py">PoseRepresentation/src/bvh/rotation2xyz.py at master ¬∑ nefeliandreou/PoseRepresentation</a><br/><a href="https://github.com/papagina/Auto_Conditioned_RNN_motion/tree/master/code">Auto_Conditioned_RNN_motion/code at master ¬∑ papagina/Auto_Conditioned_RNN_motion</a><br/><a href="https://github.com/nefeliandreou/PoseRepresentation/blob/master/src/common/skeleton.py">PoseRepresentation/src/common/skeleton.py at master ¬∑ nefeliandreou/PoseRepresentation</a><br/><a href="https://github.com/Achllle/dual_quaternions/blob/master/src/dual_quaternions/dual_quaternions.py">dual_quaternions/src/dual_quaternions/dual_quaternions.py at master ¬∑ Achllle/dual_quaternions</a><br/><a href="https://github.com/facebookresearch/QuaterNet/blob/main/common/quaternion.py">QuaterNet/common/quaternion.py at main ¬∑ facebookresearch/QuaterNet</a><br/><a href="https://github.com/facebookresearch/differentiable-robot-model/blob/main/differentiable_robot_model/spatial_vector_algebra.py">differentiable-robot-model/differentiable_robot_model/spatial_vector_algebra.py at main ¬∑ facebookresearch/differentiable-robot-model</a><br/><a href="https://www.google.com/search?q=python+render+bvh+github&sca_esv=c7a01837b1eb8e0f&sca_upv=1&rlz=1C5GCEM_enSE990SE991&biw=1440&bih=737&sxsrf=ADLYWIK0yxUxKHDDU_sa_AGVEGqHpk1W2Q%3A1725445434896&ei=OjXYZsi0NuCjwPAPnf2TEQ&ved=0ahUKEwjIueeRiamIAxXgERAIHZ3-JAI4FBDh1QMIEA&uact=5&oq=python+render+bvh+github&gs_lp=Egxnd3Mtd2l6LXNlcnAiGHB5dGhvbiByZW5kZXIgYnZoIGdpdGh1YjIFECEYnwVIxxBQSVilDnABeAGQAQCYAb4BoAGQBaoBAzYuMbgBA8gBAPgBAZgCCKACpAXCAgoQABiwAxjWBBhHwgIFECEYoAHCAgcQIRigARgKmAMAiAYBkAYIkgcDNy4xoAemEg&sclient=gws-wiz-serp">python render bvh github - Google Search</a><br/><a href="https://github.com/Wasserwecken/bvhio/blob/main/README.md">bvhio/README.md at main ¬∑ Wasserwecken/bvhio</a><br/><a href="https://github.com/Wasserwecken/spatial-transform">Wasserwecken/spatial-transform: Transform hierarchies in 3D space</a><br/><a href="https://github.com/UM-ARM-Lab/pytorch_kinematics?tab=readme-ov-file">UM-ARM-Lab/pytorch_kinematics: Robot kinematics implemented in pytorch</a><br/><a href="https://github.com/UM-ARM-Lab/pytorch_volumetric/tree/master/src/pytorch_volumetric">pytorch_volumetric/src/pytorch_volumetric at master ¬∑ UM-ARM-Lab/pytorch_volumetric</a><br/><a href="https://github.com/johnkerl/miller/blob/main/pkg/terminals/regtest/regtester.go">miller/pkg/terminals/regtest/regtester.go at main ¬∑ johnkerl/miller</a><br/><a href="https://miller.readthedocs.io/en/6.12.0/">Miller 6.12.0 Documentation</a><br/><a href="https://codeconverter.io/convert/keras-to-pytorch">Transitioning from Keras to PyTorch: A Comprehensive Guide | Convert your code to any language or framework effortlessly.</a><br/><a href="https://discuss.pytorch.org/t/how-to-convert-keras-model-to-pytorch-and-run-inference-in-c-correctly/93451">How to convert keras model to Pytorch, and run inference in C++ correctly? - C++ - PyTorch Forums</a><br/><a href="https://www.youtube.com/watch?v=itdon3ZxRHI">"Do It For Only 60 Seconds" | Behavioural Scientist Paul McKeena - YouTube</a><br/><a href="https://github.com/BirgerMoell/tmh/tree/master/tmh/breath_detection">tmh/tmh/breath_detection at master ¬∑ BirgerMoell/tmh</a><br/><a href="https://github.com/BirgerMoell/tmh/blob/master/tmh/breath_detection/support_scripts/helpers.py">tmh/tmh/breath_detection/support_scripts/helpers.py at master ¬∑ BirgerMoell/tmh</a><br/><a href="https://fr.wikisource.org/wiki/L%E2%80%99Accent_dans_le_ga%C3%ABlique_du_Munster">L‚ÄôAccent dans le ga√´lique du Munster - Wikisource</a><br/><a href="https://arxiv.org/pdf/2406.05401v1">Should you use a probabilistic duration model in TTS? Probably!Especially for spontaneous speech</a><br/><a href="https://github.com/BirgerMoell/tmh/blob/master/tmh/breath_detection/support_scripts/helpers.py#L9">tmh/tmh/breath_detection/support_scripts/helpers.py at master ¬∑ BirgerMoell/tmh</a><br/><a href="https://github.com/BirgerMoell/tmh/blob/master/tmh/breath_detection/breath2corpus_step3_CreateUtterances.py">tmh/tmh/breath_detection/breath2corpus_step3_CreateUtterances.py at master ¬∑ BirgerMoell/tmh</a><br/><a href="https://raw.githubusercontent.com/BirgerMoell/tmh/master/tmh/breath_detection/breath2corpus_step0_TrainBreathAnalysisModel.py">raw.githubusercontent.com/BirgerMoell/tmh/master/tmh/breath_detection/breath2corpus_step0_TrainBreathAnalysisModel.py</a><br/><a href="https://www.youtube.com/watch?v=T5ZfLJCP6EQ">True Confessions with Jenna Ortega and Catherine O'Hara | The Tonight Show Starring Jimmy Fallon - YouTube</a><br/><a href="https://www.youtube.com/watch?v=nhSmXbQzAHY">Can you learn TWO languages at the SAME TIME? - YouTube</a><br/><a href="https://github.com/MontrealCorpusTools/Montreal-Forced-Aligner/blob/78e481d2b3708957f3f6ac2b4d089bac798ad757/montreal_forced_aligner/transcription/multiprocessing.py#L325">Montreal-Forced-Aligner/montreal_forced_aligner/transcription/multiprocessing.py at 78e481d2b3708957f3f6ac2b4d089bac798ad757 ¬∑ MontrealCorpusTools/Montreal-Forced-Aligner</a><br/><a href="https://github.com/facebookresearch/fairseq2">facebookresearch/fairseq2: FAIR Sequence Modeling Toolkit 2</a><br/><a href="https://thehiddenbay.com/search/the%20last%20leg/1/99/0">The Pirate Bay - The galaxy's most resilient bittorrent site</a><br/><a href="https://github.com/chaimleib/intervaltree/blob/master/HACKING.md">intervaltree/HACKING.md at master ¬∑ chaimleib/intervaltree</a><br/><a href="https://github.com/daschablume/g2p_correction">daschablume/g2p_correction: Web-application for grapheme-to-phoneme correction using user feedback</a><br/><a href="https://www.google.com/search?q=wav2vec2+huggingface+pyannote&rlz=1C5GCEM_enSE990SE991&oq=wav2vec2+huggingface+pyannote&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIKCAEQABiABBiiBDIKCAIQABiABBiiBDIKCAMQABiABBiiBDIKCAQQABiABBiiBDIKCAUQABiABBiiBNIBCTExMjE2ajBqN6gCALACAA&sourceid=chrome&ie=UTF-8">wav2vec2 huggingface pyannote - Google Search</a><br/><a href="https://huggingface.co/models?license=license:apache-2.0&other=automatic-speech-recognition&p=2&sort=trending">Models - Hugging Face</a><br/><a href="https://huggingface.co/jonatasgrosman/wav2vec2-large-english">jonatasgrosman/wav2vec2-large-english ¬∑ Hugging Face</a><br/><a href="https://huggingface.co/models?language=en&license=license:apache-2.0&other=whisper&p=4&sort=trending">Models - Hugging Face</a><br/><a href="https://huggingface.co/NathanRoll/psst-medium-en">NathanRoll/psst-medium-en ¬∑ Hugging Face</a><br/><a href="https://huggingface.co/models?search=phoneme">Models - Hugging Face</a><br/><a href="https://huggingface.co/Cnam-LMSSC/vibravox-phonemes-tokenizer/tree/main">Cnam-LMSSC/vibravox-phonemes-tokenizer at main</a><br/><a href="https://huggingface.co/ct-vikramanantha/phoneme-scorer-v2-wav2vec2">ct-vikramanantha/phoneme-scorer-v2-wav2vec2 ¬∑ Hugging Face</a><br/><a href="https://huggingface.co/bookbot">bookbot (Bookbot)</a><br/><a href="https://huggingface.co/datasets/bookbot/OpenBible_Swahili">bookbot/OpenBible_Swahili ¬∑ Datasets at Hugging Face</a><br/><a href="https://huggingface.co/datasets/bookbot/cmudict-0.7b">bookbot/cmudict-0.7b ¬∑ Datasets at Hugging Face</a><br/><a href="https://huggingface.co/bookbot/wav2vec2-ljspeech-gruut">bookbot/wav2vec2-ljspeech-gruut ¬∑ Hugging Face</a><br/><a href="https://huggingface.co/datasets/bookbot/ljspeech_phonemes">bookbot/ljspeech_phonemes ¬∑ Datasets at Hugging Face</a><br/><a href="https://huggingface.co/Splend1dchan/phoneme-bart-base/tree/main">Splend1dchan/phoneme-bart-base at main</a><br/><a href="https://huggingface.co/huchenxu/timit_phoneme">huchenxu/timit_phoneme ¬∑ Hugging Face</a><br/><a href="https://groups.inf.ed.ac.uk/ami/corpus/">AMI Corpus</a><br/><a href="https://groups.inf.ed.ac.uk/ami/download/">AMI Corpus Download</a><br/><a href="https://huggingface.co/datasets/edinburghcstr/ami?row=3">edinburghcstr/ami ¬∑ Datasets at Hugging Face</a><br/><a href="https://huggingface.co/models?dataset=dataset:esb/datasets">Models - Hugging Face</a><br/><a href="https://www.google.com/search?q=huggingface+whisper+finetune+ami&rlz=1C5GCEM_enSE990SE991&oq=huggingface+whisper+finetune+ami&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIJCAEQIRgKGKABMgkIAhAhGAoYoAEyBggDECEYFdIBCDg1NjVqMGo0qAIAsAIB&sourceid=chrome&ie=UTF-8">huggingface whisper finetune ami - Google Search</a><br/><a href="https://huggingface.co/blog/fine-tune-whisper">Fine-Tune Whisper For Multilingual ASR with ü§ó Transformers</a><br/><a href="https://huggingface.co/datasets/babelbox/babelbox_voice/blob/main/babelbox_voice.py">babelbox_voice.py ¬∑ babelbox/babelbox_voice at main</a><br/><a href="https://huggingface.co/datasets/NbAiLab/NPSC">NbAiLab/NPSC ¬∑ Datasets at Hugging Face</a><br/><a href="https://huggingface.co/magnustragardh/whisper-tiny-en-minds14">magnustragardh/whisper-tiny-en-minds14 ¬∑ Hugging Face</a><br/><a href="https://huggingface.co/aadel4/kid-whisper-medium-en-myst_cslu">aadel4/kid-whisper-medium-en-myst_cslu ¬∑ Hugging Face</a><br/><a href="https://huggingface.co/NbAiLab/wav2vec2-large-voxrex-npsc-nynorsk">NbAiLab/wav2vec2-large-voxrex-npsc-nynorsk ¬∑ Hugging Face</a><br/><a href="https://huggingface.co/NbAiLab/wav2vec2-xlsr-300M-NPSC-LM/blob/main/run_speech_recognition_ctc.py">run_speech_recognition_ctc.py ¬∑ NbAiLab/wav2vec2-xlsr-300M-NPSC-LM at main</a><br/><a href="https://huggingface.co/KBLab">KBLab (National Library of Sweden / KBLab)</a><br/><a href="https://huggingface.co/datasets/KBLab/rixvox">KBLab/rixvox ¬∑ Datasets at Hugging Face</a><br/><a href="https://github.com/kb-labb/rixvox/blob/main/scripts/align_transcript_pytorch.py">rixvox/scripts/align_transcript_pytorch.py at main ¬∑ kb-labb/rixvox</a><br/><a href="https://github.com/kb-labb/emotional-headlines/blob/main/modelling/zero-shot-ekman-emotion-classification.ipynb">emotional-headlines/modelling/zero-shot-ekman-emotion-classification.ipynb at main ¬∑ kb-labb/emotional-headlines</a><br/><a href="https://huggingface.co/KBLab/piper-tts-nst-swedish/blob/main/config.json">config.json ¬∑ KBLab/piper-tts-nst-swedish at main</a><br/><a href="https://huggingface.co/NbAiLab/salmon-whisper-large-smj-lr7e-5">NbAiLab/salmon-whisper-large-smj-lr7e-5 ¬∑ Hugging Face</a><br/><a href="https://huggingface.co/NbAiLab/salmon-whisper-medium-smj">NbAiLab/salmon-whisper-medium-smj ¬∑ Hugging Face</a><br/><a href="https://huggingface.co/NbAiLab/whisper-small-smj-test">NbAiLab/whisper-small-smj-test ¬∑ Hugging Face</a><br/><a href="https://huggingface.co/NbAiLab/whisper-large-sme/tree/main">NbAiLab/whisper-large-sme at main</a><br/><a href="https://huggingface.co/NbAiLab/whisper-large-sme/blob/main/convert_to_openai.py">convert_to_openai.py ¬∑ NbAiLab/whisper-large-sme at main</a><br/><a href="https://huggingface.co/datasets/NbAiLab/nrk-sapmi-podcasts">NbAiLab/nrk-sapmi-podcasts ¬∑ Datasets at Hugging Face</a><br/><a href="https://huggingface.co/datasets/NbAiLab/salmon-asr-smj/tree/main">NbAiLab/salmon-asr-smj at main</a><br/><a href="https://github.com/pariajm/joint-disfluency-detector-and-parser">pariajm/joint-disfluency-detector-and-parser: Improving Disfluency Detection by Self-Training a Self-Attentive Model</a><br/><a href="https://huggingface.co/learn/audio-course/en/chapter6/fine-tuning">Fine-tuning SpeechT5 - Hugging Face Audio Course</a><br/><a href="https://www.youtube.com/watch?v=UXM9d_SYPKQ">THE BEST KARATE STYLE (EXPLANATION) ‚Äî Jesse Enkamp - YouTube</a><br/><a href="https://www.youtube.com/watch?v=P6by6LBfo6g">HOW TO STRIKE WITH MAXIMUM POWER - Training with Michael J White - YouTube</a><br/><a href="https://www.google.com/search?q=montreal+forced+aligner+align+phonemes&rlz=1C5GCEM_enSE990SE991&oq=montreal+forced+aligner+align+phonemes&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIHCAEQIRigAdIBCTEyMDU3ajBqN6gCALACAA&sourceid=chrome&ie=UTF-8">montreal forced aligner align phonemes - Google Search</a><br/><a href="https://www.youtube.com/@nadirapovey4919">Nadira Povey - YouTube</a><br/><a href="https://www.youtube.com/watch?v=_zBJVN5lxEg">#67 K2fsa: Training Advice for Beginners - YouTube</a><br/><a href="https://ipa.typeit.org/full/">Type IPA phonetic symbols - online keyboard (all languages)</a><br/><a href="https://www.youtube.com/watch?v=RBpITzRAQUQ">Mastodon Fallen Torches Guitar Lesson ft/ Bill Kelliher & Uncle Ben Eller! - YouTube</a><br/><a href="https://www.google.com/search?q=montreal+forced+aligner+align+phoneme+sequence&rlz=1C5GCEM_enSE990SE991&oq=montreal+forced+aligner+align+phoneme+sequence&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIHCAEQIRigAdIBCDk0MTJqMGo3qAIAsAIA&sourceid=chrome&ie=UTF-8">montreal forced aligner align phoneme sequence - Google Search</a><br/><a href="https://rhasspy.github.io/gruut/">gruut ‚Äî gruut documentation</a><br/><a href="https://github.com/rhasspy/num2words/blob/master/num2words/lang_UK.py">num2words/num2words/lang_UK.py at master ¬∑ rhasspy/num2words</a><br/><a href="https://rhasspy.github.io/gruut/#g2p-models">gruut ‚Äî gruut documentation</a><br/><a href="https://github.com/rhasspy/gruut-ipa/blob/master/gruut_ipa/data/nl/phonemes.txt">gruut-ipa/gruut_ipa/data/nl/phonemes.txt at master ¬∑ rhasspy/gruut-ipa</a><br/><a href="https://www.instagram.com/direct/t/110437113687820/">Inbox ‚Ä¢ Direct</a><br/><a href="https://x.com/home">Home / X</a><br/><a href="https://x.com/Alphafox78/status/1833143572163592297">AlphaFoùïè on X: "This guy realized she was in trouble and played along to get this stalker to leave. Crazy. üòÆ https://t.co/xdJcoNQTUo" / X</a><br/><a href="https://www.google.com/search?q=espeak+ipa+only&rlz=1C5GCEM_enSE990SE991&oq=espeak+ipa+only&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIHCAEQIRigATIHCAIQIRigAdIBCDI2MDRqMGo3qAIAsAIA&sourceid=chrome&ie=UTF-8">espeak ipa only - Google Search</a><br/><a href="https://github.com/trending/c++">Trending C++ repositories on GitHub today</a><br/><a href="https://github.com/facebook/react-native">facebook/react-native: A framework for building native applications using React</a><br/><a href="https://reactnative.dev/docs/components-and-apis#others">Core Components and APIs ¬∑ React Native</a><br/><a href="https://github.com/google-ai-edge/mediapipe?tab=readme-ov-file">google-ai-edge/mediapipe: Cross-platform, customizable ML solutions for live and streaming media.</a><br/><a href="https://developers.googleblog.com/en/signall-sdk-sign-language-interface-using-mediapipe-is-now-available-for-developers/">SignAll SDK: Sign language interface using MediaPipe is now available for developers - Google Developers Blog</a><br/><a href="https://developers.googleblog.com/en/mediapipe-knift-template-based-feature-matching/">MediaPipe KNIFT: Template-based feature matching - Google Developers Blog</a><br/><a href="https://arxiv.org/pdf/1503.03832">1503.03832</a><br/><a href="https://drive.google.com/file/d/1RCdA83a8JDV3ZPS-mtpsV8mTj3r0F9s-/view">Model Card Content - KNIFT (public).pdf - Google Drive</a><br/><a href="https://developers.googleblog.com/en/bringing-artworks-to-life-with-ar/">Bringing artworks to life with AR - Google Developers Blog</a><br/><a href="https://ai.google.dev/edge/mediapipe/solutions/guide">MediaPipe Solutions guide ¬†|¬† Google AI Edge ¬†|¬† Google AI for Developers</a><br/><a href="https://github.com/UZ-SLAMLab/ORB_SLAM3">UZ-SLAMLab/ORB_SLAM3: ORB-SLAM3: An Accurate Open-Source Library for Visual, Visual-Inertial and Multi-Map SLAM</a><br/><a href="https://github.com/TrinityCore/TrinityCore">TrinityCore/TrinityCore: TrinityCore Open Source MMO Framework (master = 11.0.2.56513, 3.3.5 = 3.3.5a.12340, wotlk_classic = 3.4.3.54261, cata classic = 4.4.0.55262)</a><br/><a href="https://github.com/hiroi-sora/Umi-OCR/blob/main/README_en.md">Umi-OCR/README_en.md at main ¬∑ hiroi-sora/Umi-OCR</a><br/><a href="https://github.com/MrForExample/ComfyUI-3D-Pack/blob/main/Gen_3D_Modules/Unique3D/mesh_reconstruction/func.py">ComfyUI-3D-Pack/Gen_3D_Modules/Unique3D/mesh_reconstruction/func.py at main ¬∑ MrForExample/ComfyUI-3D-Pack</a><br/><a href="https://github.com/Profactor/continuous-remeshing/tree/main/core">continuous-remeshing/core at main ¬∑ Profactor/continuous-remeshing</a><br/><a href="https://www.bubblestranslation.com/the-worst-marketing-translation-errors-ever/">The Worst Marketing Translation Errors Ever Made</a><br/><a href="https://www.bubblestranslation.com/once-upon-a-time-the-greatest-works-of-translated-fiction/">Once Upon a Time ‚Äì The Greatest Works of Translated Fiction</a><br/><a href="https://translatebyhumans.com/6-marketing-translation-fails-that-cost-millions/">6 Marketing Translation Fails That Cost Millions! - Translate By Humans‚Ñ¢</a><br/><a href="https://www.google.com/search?q=vits+alignment&rlz=1C5GCEM_enSE990SE991&oq=vits+alignment&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIHCAEQIRigATIHCAIQIRigATIHCAMQIRigAdIBCDM4MDBqMGo3qAIAsAIA&sourceid=chrome&ie=UTF-8">vits alignment - Google Search</a><br/><a href="https://github.com/coqui-ai/TTS/discussions/1969">Alignment starts misaligning while fine-tuning VITS model ¬∑ coqui-ai/TTS ¬∑ Discussion #1969</a><br/><a href="https://k2-fsa.github.io/icefall/huggingface/pretrained-models.html">Pre-trained models ‚Äî icefall 0.1 documentation</a><br/><a href="https://huggingface.co/models?p=6&sort=trending&search=icefall">Models - Hugging Face</a><br/><a href="https://colab.research.google.com/drive/1Hs9DA4V96uapw_30uNp32OMJgkuR5VVd#scrollTo=puZt_92gtSIt">icefall-asr-timit-pretrained-tdnn-lstm-ctc-usage.ipynb - Colab</a><br/><a href="https://github.com/k2-fsa/k2?tab=readme-ov-file">k2-fsa/k2: FSA/FST algorithms, differentiable, with PyTorch compatibility.</a><br/><a href="https://github.com/k2-fsa/libriheavy/blob/master/scripts/extract_and_normalize_transcript.py">libriheavy/scripts/extract_and_normalize_transcript.py at master ¬∑ k2-fsa/libriheavy</a><br/><a href="https://github.com/gradio-app/gradio/issues/5321">Proposal: enhancements and redesign of `Audio` ¬∑ Issue #5321 ¬∑ gradio-app/gradio</a><br/><a href="https://www.gradio.app/guides/real-time-speech-recognition">Real Time Speech Recognition</a><br/><a href="https://www.gradio.app/docs/gradio/audio">Gradio Audio Docs</a><br/><a href="https://github.com/WGBH-MLA/transcript-editor?tab=readme-ov-file">WGBH-MLA/transcript-editor: Web-based tool for correcting speech-to-text generated transcripts.</a><br/><a href="https://fixitplus.americanarchive.org/page/toc">FIX IT +</a><br/><a href="https://github.com/WGBH-MLA/AAPB2/blob/master/app/models/transcript_file.rb">AAPB2/app/models/transcript_file.rb at master ¬∑ WGBH-MLA/AAPB2</a><br/><a href="https://github.com/WGBH-MLA/transcript-editor/tree/master/scripts">transcript-editor/scripts at master ¬∑ WGBH-MLA/transcript-editor</a><br/><a href="https://github.com/vllm-project/vllm/issues/6017">[New Model]: facebook/seamless-m4t-v2-large ¬∑ Issue #6017 ¬∑ vllm-project/vllm</a><br/><a href="https://github.com/huggingface/transformers/blob/e65502951593a76844e872fee9c56b805598538a/src/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py#L4319">transformers/src/transformers/models/seamless_m4t_v2/modeling_seamless_m4t_v2.py at e65502951593a76844e872fee9c56b805598538a ¬∑ huggingface/transformers</a><br/><a href="https://github.com/facebookresearch/seamless_communication/blob/main/ggml/examples/common-ggml.cpp">github.com</a><br/><a href="https://github.com/huggingface/transformers/blob/main/docs/source/en/model_doc/seamless_m4t_v2.md">github.com</a><br/><a href="https://github.com/revdotcom/fstalign/blob/develop/docs/Usage.md">github.com</a><br/><a href="https://github.com/revdotcom/fstalign/blob/develop/docs//NLP-Format.md#wer-tag-sidecar">fstalign/docs/NLP-Format.md at develop ¬∑ revdotcom/fstalign</a><br/><a href="https://github.com/ydqmkkx/Respiro-en/blob/main/demo.ipynb">github.com</a><br/><a href="https://www.instagram.com/">instagram.com</a><br/><a href="https://www.google.com/search?q=fairseq-hydra-train&rlz=1C5GCEM_enSE990SE991&oq=fairseq-hydra-train&gs_lcrp=EgZjaHJvbWUyBggAEEUYOdIBBzE2NGowajeoAgCwAgA&sourceid=chrome&ie=UTF-8">fairseq-hydra-train - Google Search</a><br/><a href="https://github.com/facebookresearch/fairseq?tab=readme-ov-file">facebookresearch/fairseq: Facebook AI Research Sequence-to-Sequence Toolkit written in Python.</a><br/><a href="https://github.com/facebookresearch/fairseq/blob/main/examples/mms/README.md">fairseq/examples/mms/README.md at main ¬∑ facebookresearch/fairseq</a><br/><a href="https://github.com/facebookresearch/fairseq/tree/main/examples/audio_nlp/nlu">fairseq/examples/audio_nlp/nlu at main ¬∑ facebookresearch/fairseq</a><br/><a href="https://github.com/facebookresearch/fairseq/blob/main/docs/hydra_integration.md">fairseq/docs/hydra_integration.md at main ¬∑ facebookresearch/fairseq</a><br/><a href="https://evgeniia.tokarch.uk/blog/extending-fairseq-incomplete-guide/">Evgeniia Tokarchuk | Extending Fairseq: Incomplete Guide</a><br/><a href="https://www.youtube.com/">YouTube</a><br/><a href="https://www.youtube.com/watch?v=ryC47ZjCgu4">An Corp√°n sa Trunc, Cathal √ì S√°ndair - YouTube</a><br/><a href="https://www.youtube.com/">YouTube</a><br/><a href="https://www.youtube.com/">YouTube</a><br/><a href="https://www.youtube.com/watch?v=QmKz-wgwI0w">I Tried Chinese Weapon Forms - YouTube</a><br/><a href="https://improbable.com/2024/09/12/announcing-the-2024-ig-nobel-prize-winners/">Announcing the 2024 Ig Nobel Prize winners</a><br/><a href="https://improbable.com/ig/winners/#ig2024">Past Ig Winners</a><br/><a href="https://improbable.com/ig/winners/#ig2024">Past Ig Winners</a><br/><a href="https://academic.oup.com/jas/article/1939/1/80/4771774">Factors Involved in the Ejection of Milk | Journal of Animal Science | Oxford Academic</a><br/><a href="https://pdf.sciencedirectassets.com/279785/1-s2.0-S0022030241X79628/1-s2.0-S0022030241954061/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEPD%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJGMEQCIGGauHekM%2FGjWKp2mYqQI0FUoaezHgstm2G1Ua%2BqE0erAiASQoCOLwyxGzQSEYZ6noK2YfakAkfhkVBtTrFAnIwa1CqzBQgpEAUaDDA1OTAwMzU0Njg2NSIMzLAq1vg7tVu1AF9cKpAFBgNgf3keKbB8J9US4hkHeDrzh0mTL%2FIuoHf7ztPotec87W69FdltRftODqUrSJ4yjmkmPffEhUDKm2WVJLQNSCgziIktcaz5rTGapDnFOeGZstym%2B%2Fht%2FPN6UA6%2BnLhRMrX0hS9IvNtWHRZQ3fRIocVnp4fdn6EbKsFXsunnmVyso6nh2PD6sd%2FqArJrlviv1ob1DqNv4D8vq6VTgLKRXxzEuu0Jcrkh7M3MekZ6Jg%2FFuJOhOiSBEYyDd%2BjtZROQUTbmzTHSYLBwctsswfeVOum06d%2B7rB6MWlVBls2fMid0pMI9IaveidsU0CZOAIAhGrQg9rrfSsnmQ%2B5g3LnnNCdFQoVpVT%2Fw8874nX0omKi2t6tPneardqwWEiqwZliaH9iAMZd87PSQPzf3rnBK19aFMwqbNsGpDQc%2B6BFogHPBGaL4RuJBuVe2eQnI99AN7PZ6nlyJo9H2ygkIXUf8yL4Wu8FjE%2B9gZBFL3yJElACejVjlmP6GWyutK%2BGA4utAwuGFF%2FKIBQaoQKCHN1fx1qhROZXSAK8OdxxpG2IR%2BWjQRl0T43Y36zg2H2dfTsyZ4yGnnRJX4exQqZQ6tzxN2ze%2F%2FqXxzRwtqgH7rmREN382EQYK%2F18wvj30eFwOhXD4izeGtbS1F6ae1hWZt4z1d%2FE%2B0mEEOmafJnmkGHwCaq95m3XA3Z7nBk99FK6qdqPL6lAw9Ll3aZ3bovx4Q5Xt%2BqnMY4FNqev%2F%2By5ewr2AtTPU8iw9mmYJObocQIqy8WCBrM956UlZko4Q38%2B9eIV5pPiRc6stxm6z0EEC6tGK949AZnY7%2BkSMbGn3iSBfIrIhUHVpxZfZQ1tXTyhILE%2FxvcMT8%2BjfW0S17Cty5MffHukw%2F%2BKktwY6sgE%2FwngiYDbIZ4qUtOfc1Gx%2F7ZzYadufnd4xoQxK3WEl3ao2T5Evr0nMPE7j9BXe6ohxKY3sf3zYOxThKVyqbfisQ8pGKeop4RXy7MSXgeJKfIFtHZDOnCbxQzOmZqa7TahFANBJQrmIdtbCqq38G%2BXYYeki%2FjaLpnxEPMnQ89U6Eu6VSgFcUfYffGNkBPrgPFTtgL%2B31qL%2F39MFtsGF0vz5btWcs9MtRDaHIlkrmtD4b9vH&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20240917T083618Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTY7GXTLL3G%2F20240917%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=9601f4db80b8d8664b99caed796f562132624976553b5f45b48d9d5db0981443&hash=41151b44e8d21d2a7ea503ff17b3e1d5d125f35444114c4d3a8d9e9107522fc3&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S0022030241954061&tid=spdf-61c26356-2416-4a54-a9c9-5034313b2a15&sid=02b482c590bb0144808b4cc1864fa5c1bafcgxrqb&type=client&tsoh=d3d3LnNjaWVuY2VkaXJlY3QuY29t&ua=09005f0252550050595e5b&rr=8c47c4904bc895de&cc=se">Factors Involved in the Ejection of Milk*</a><br/><a href="https://en.wikipedia.org/wiki/ReCAPTCHA">reCAPTCHA - Wikipedia</a><br/><a href="https://en.wikipedia.org/wiki/ESP_game">ESP game - Wikipedia</a><br/><a href="https://www.cs.cmu.edu/~biglou/">Luis von Ahn</a><br/><a href="https://en.wikipedia.org/wiki/Switchboard_Telephone_Speech_Corpus">Switchboard Telephone Speech Corpus - Wikipedia</a><br/><a href="https://convokit.cornell.edu/documentation/switchboard.html">Switchboard Dialog Act Corpus ‚Äî convokit 3.0.0 documentation</a><br/><a href="https://catalog.ldc.upenn.edu/LDC97S62">Switchboard-1 Release 2 - Linguistic Data Consortium</a><br/><a href="https://www.researchgate.net/figure/Hand-picked-example-of-topic-transition-in-the-Switchboard-corpus_fig1_356631780">Hand-picked example of topic transition in the Switchboard corpus | Download Scientific Diagram</a><br/><a href="https://mmpose.readthedocs.io/en/latest/installation.html">Installation ‚Äî MMPose 1.3.2 documentation</a><br/><a href="https://github.com/open-mmlab/mmengine">open-mmlab/mmengine: OpenMMLab Foundational Library for Training Deep Learning Models</a><br/><a href="https://github.com/open-mmlab/mmcv/tree/2.x">open-mmlab/mmcv at 2.x</a><br/><a href="https://github.com/open-mmlab/mim">open-mmlab/mim: MIM Installs OpenMMLab Packages</a><br/><a href="https://www.google.com/search?q=bvh+visualizer+python&rlz=1C5GCEM_enSE990SE991&oq=bvh+visualizer+python&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIHCAEQIRigAdIBCDQ1NzBqMGo0qAIAsAIB&sourceid=chrome&ie=UTF-8">bvh visualizer python - Google Search</a><br/><a href="https://github.com/TemugeB/Python_BVH_viewer/blob/main/parser.py">Python_BVH_viewer/parser.py at main ¬∑ TemugeB/Python_BVH_viewer</a><br/><a href="https://github.com/topics/bvh-files">bvh-files ¬∑ GitHub Topics</a><br/><a href="https://github.com/Wasserwecken/bvhio/tree/main/bvhio">bvhio/bvhio at main ¬∑ Wasserwecken/bvhio</a><br/><a href="https://github.com/Zuzu-Typ/PyGLM">Zuzu-Typ/PyGLM: Fast OpenGL Mathematics (GLM) for Python</a><br/><a href="https://github.com/Wasserwecken/spatial-transform">Wasserwecken/spatial-transform: Transform hierarchies in 3D space</a><br/><a href="https://github.com/ebadier/MotionBuilder-Tools">ebadier/MotionBuilder-Tools: C++ tools for Motion Builder</a><br/><a href="https://omid.al/projects/pymo/">PyMO: Motion Capture Library</a><br/><a href="https://mmpose.readthedocs.io/en/latest/user_guides/dataset_tools.html">Dataset Annotation and Format Conversion ‚Äî MMPose 1.3.2 documentation</a><br/><a href="https://github.com/HumanSignal/label-studio?tab=readme-ov-file">HumanSignal/label-studio: Label Studio is a multi-type data labeling and annotation tool with standardized output format</a><br/><a href="https://github.com/HumanSignal/label-studio-transformers/tree/master/models">label-studio-transformers/models at master ¬∑ HumanSignal/label-studio-transformers</a><br/><a href="https://labelstud.io/guide/quick_start">Label Studio Documentation ‚Äî Quick start guide for Label Studio</a><br/><a href="https://labelstud.io/blog/zero-to-one-getting-started-with-label-studio/">Zero to One: Getting Started with Label Studio | Label Studio</a><br/><a href="https://labelstud.io/guide/tasks#Basic-Label-Studio-JSON-format">Label Studio Documentation ‚Äî Import Data into Label Studio</a><br/><a href="https://labelstud.io/guide/ml_tutorials">Label Studio Documentation ‚Äî Machine Learning Example Tutorials</a><br/><a href="https://labelstud.io/tutorials/interactive_substring_matching">Label Studio Documentation ‚Äî Interactive substring matching for NER tasks</a><br/><a href="https://github.com/HumanSignal/label-studio-ml-backend/blob/master/label_studio_ml/examples/interactive_substring_matching/model.py">label-studio-ml-backend/label_studio_ml/examples/interactive_substring_matching/model.py at master ¬∑ HumanSignal/label-studio-ml-backend</a><br/><a href="https://labelstud.io/guide/predictions.html">Label Studio Documentation ‚Äî Import pre-annotated data into Label Studio</a><br/><a href="https://www.google.com/search?q=handweker&rlz=1C5GCEM_enSE990SE991&oq=handweker&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIJCAEQABgKGIAEMgkIAhAAGAoYgAQyCQgDEAAYChiABDIJCAQQABgKGIAEMg8IBRAuGAoYrwEYxwEYgAQyCQgGEAAYChiABDIPCAcQLhgKGK8BGMcBGIAEMgkICBAAGAoYgAQyCQgJEAAYChiABNIBCDQ0NjRqMGo3qAIAsAIA&sourceid=chrome&ie=UTF-8">handweker - Google Search</a><br/><a href="https://www.google.com/search?q=bvh+to+mp4&sca_esv=72aaa3890415b76e&sca_upv=1&rlz=1C5GCEM_enSE990SE991&sxsrf=ADLYWII0PdxOQYgcPboEZshPlRFxB2tL5w:1726580758818&ei=FojpZv3MMZvKwPAPoNfOuAc&start=30&sa=N&sstk=Aagrsugf-F6lHHsL82308l5AgdoSZahzYPXvJmG3SFQ3nC23KWVUkxvgWbclfKwV9QJcqDQlZCwX8a1ykAq6T6tVXGDxDuanr2Qs-ATAzPKYrgetW2J7kIWdN7K-MrjWByLiUERrQP4U7Hgawby_5ohdbrxpYIdOwrQ&ved=2ahUKEwj9r7jGjsqIAxUbJRAIHaCrE3c4FBDw0wN6BAgFEBc&biw=1440&bih=734&dpr=2">bvh to mp4 - Google Search</a><br/><a href="https://github.com/BartMoyaers/BvhToDeepMimic?tab=readme-ov-file">BartMoyaers/BvhToDeepMimic: Convert .bvh files (Biovision Hierarchy) to DeepMimic format.</a><br/><a href="https://github.com/xbpeng/DeepMimic?tab=readme-ov-file">xbpeng/DeepMimic: Motion imitation with deep reinforcement learning.</a><br/><a href="https://github.com/EricVoll/amp_motion_conversion/blob/master/src/run.py">amp_motion_conversion/src/run.py at master ¬∑ EricVoll/amp_motion_conversion</a><br/><a href="https://raw.githubusercontent.com/herzig/BVHImporter/gh-pages/BVHImport.js">raw.githubusercontent.com/herzig/BVHImporter/gh-pages/BVHImport.js</a><br/><a href="https://threejs.org/examples/?q=loader#webgl_loader_bvh">three.js examples</a><br/><a href="view-source:https://threejs.org/examples/?q=loader#webgl_loader_bvh">view-source:https://threejs.org/examples/?q=loader#webgl_loader_bvh</a><br/><a href="https://github.com/mrdoob/three.js/blob/2208e8126a7c251fcfa95f3bdc752c22c8c6511c/examples/jsm/Addons.js">three.js/examples/jsm/Addons.js at 2208e8126a7c251fcfa95f3bdc752c22c8c6511c ¬∑ mrdoob/three.js</a><br/><a href="https://pypi.org/project/bvhtoolbox/">bvhtoolbox ¬∑ PyPI</a><br/><a href="https://github.com/jupyter-widgets/pythreejs">jupyter-widgets/pythreejs: A Jupyter - Three.js bridge</a><br/><a href="https://pythreejs.readthedocs.io/en/stable/">pythreejs ‚Äî pythreejs 2.4.1 documentation</a><br/><a href="https://www.google.com/search?q=bvh+visualizer+python&rlz=1C5GCEM_enSE990SE991&oq=bvh+&gs_lcrp=EgZjaHJvbWUqCAgBEEUYJxg7Mg4IABBFGCcYOxiABBiKBTIICAEQRRgnGDsyBggCEEUYOTIGCAMQRRg7Mg0IBBAuGK8BGMcBGIAEMgYIBRBFGDwyBggGEEUYPDIGCAcQRRg80gEIMjkxMmowajeoAgCwAgA&sourceid=chrome&ie=UTF-8">bvh visualizer python - Google Search</a><br/><a href="https://temugeb.github.io/repository.html">Temuge's webpage</a><br/><a href="https://github.com/TemugeB/bodypose3d">TemugeB/bodypose3d: Real time 3D body pose estimation with Mediapipe</a><br/><a href="https://github.com/TemugeB/joint_angles_calculate">TemugeB/joint_angles_calculate: Calculate the joint angles of a body pose</a><br/><a href="https://github.com/TemugeB/handpose3d">TemugeB/handpose3d: Real time 3D hand pose estimation using MediaPipe</a><br/><a href="https://www.google.com/search?q=pymo+write+mp4+bvh&sca_esv=825e01edc18a56f7&sca_upv=1&rlz=1C5GCEM_enSE990SE991&sxsrf=ADLYWIITGl8UTZ4b_BFwU-1cBY_ICTI9xw%3A1726586778127&ei=mp_pZpa2B_6swPAP3o6J6QI&ved=0ahUKEwiW69X8pMqIAxV-FhAIHV5HIi0Q4dUDCA8&uact=5&oq=pymo+write+mp4+bvh&gs_lp=Egxnd3Mtd2l6LXNlcnAiEnB5bW8gd3JpdGUgbXA0IGJ2aDIFECEYoAEyBRAhGKABMgUQIRigATIFECEYoAFIkQ5QyQFYxApwAXgBkAEAmAFpoAHkAqoBAzMuMbgBA8gBAPgBAZgCBaAC-ALCAgoQABiwAxjWBBhHwgIFECEYnwWYAwCIBgGQBgaSBwM0LjGgB7cO&sclient=gws-wiz-serp">pymo write mp4 bvh - Google Search</a><br/><a href="https://github.com/simonalexanderson/PyMO/blob/master/pymo/preprocessing.py">PyMO/pymo/preprocessing.py at master ¬∑ simonalexanderson/PyMO</a><br/><a href="https://github.com/shivammehta25/Match-TTSG/blob/main/pymo/viz_tools.py">Match-TTSG/pymo/viz_tools.py at main ¬∑ shivammehta25/Match-TTSG</a><br/><a href="https://github.com/shivammehta25/Match-TTSG/blob/main/pymo/rotation_tools.py">Match-TTSG/pymo/rotation_tools.py at main ¬∑ shivammehta25/Match-TTSG</a><br/><a href="https://github.com/matthew-brett/transforms3d/blob/main/transforms3d/affines.py">transforms3d/transforms3d/affines.py at main ¬∑ matthew-brett/transforms3d</a><br/><a href="https://www.sympy.org/en/index.html">SymPy</a><br/><a href="https://www.sagemath.org/">SageMath - Open-Source Mathematical Software System</a><br/><a href="https://github.com/shivammehta25/Match-TTSG/blob/main/pymo/preprocessing_style_gestures.py">Match-TTSG/pymo/preprocessing_style_gestures.py at main ¬∑ shivammehta25/Match-TTSG</a><br/><a href="https://github.com/shivammehta25/Match-TTSG/blob/main/pymo/preprocessing_refpose_featureselector.py">Match-TTSG/pymo/preprocessing_refpose_featureselector.py at main ¬∑ shivammehta25/Match-TTSG</a><br/><a href="https://github.com/shivammehta25/Match-TTSG/blob/main/pymo/preprocessing.py">Match-TTSG/pymo/preprocessing.py at main ¬∑ shivammehta25/Match-TTSG</a><br/><a href="https://github.com/shivammehta25/Match-TTSG/blob/main/pymo/parsers_new.py">Match-TTSG/pymo/parsers_new.py at main ¬∑ shivammehta25/Match-TTSG</a><br/><a href="https://github.com/shivammehta25/Match-TTSG/blob/main/pymo/data_new.py">Match-TTSG/pymo/data_new.py at main ¬∑ shivammehta25/Match-TTSG</a><br/><a href="https://www.google.com/search?q=pytorch+3d&rlz=1C5GCEM_enSE990SE991&oq=pytorch+3d&gs_lcrp=EgZjaHJvbWUyCQgAEEUYORiABDIHCAEQABiABDIHCAIQABiABDIHCAMQABiABDIHCAQQABiABDIGCAUQRRg8MgYIBhBFGDwyBggHEEUYPNIBCDE4MjdqMGo3qAIAsAIA&sourceid=chrome&ie=UTF-8">pytorch 3d - Google Search</a><br/><a href="https://github.com/search?q=repo%3Afacebookresearch%2Fpytorch3d+skeleton&type=commits">Commit search results</a><br/><a href="https://pytorch3d.org/">PyTorch3D ¬∑ A library for deep learning with 3D data</a><br/><a href="https://github.com/facebookresearch/pytorch3d/pull/1574/files#diff-addf0eaf87268bd10317ed100e09154ae13ff08ffffbc5b8e66e0eef94c5f5da">Implement multitexture obj high precision by justinhchae ¬∑ Pull Request #1574 ¬∑ facebookresearch/pytorch3d</a><br/><a href="https://github.com/facebookresearch/pytorch3d/blob/main/pytorch3d/transforms/rotation_conversions.py">pytorch3d/pytorch3d/transforms/rotation_conversions.py at main ¬∑ facebookresearch/pytorch3d</a><br/><a href="https://github.com/facebookresearch/pytorch3d/issues/1782">can you bump support conda environment to later python and cuda 12? ¬∑ Issue #1782 ¬∑ facebookresearch/pytorch3d</a><br/><a href="https://github.com/facebookresearch/pytorch3d/issues/1754">No module named 'pytorch3d.structures' ¬∑ Issue #1754 ¬∑ facebookresearch/pytorch3d</a><br/><a href="https://github.com/facebookresearch/pytorch3d/commit/9d279ba5431bbe9554220bec60f5bce963b060a9">Skeleton of ShapeNetCore class ¬∑ facebookresearch/pytorch3d@9d279ba</a><br/><a href="https://github.com/nefeliandreou/PoseRepresentation/blob/master/src/extenddb.py">PoseRepresentation/src/extenddb.py at master ¬∑ nefeliandreou/PoseRepresentation</a><br/><a href="https://github.com/nefeliandreou/PoseRepresentation/blob/master/src/loadbvh.py">PoseRepresentation/src/loadbvh.py at master ¬∑ nefeliandreou/PoseRepresentation</a><br/><a href="https://github.com/facebookresearch/QuaterNet">facebookresearch/QuaterNet: Proposes neural networks that can generate animation of virtual characters for different actions.</a><br/><a href="https://github.com/dariopavllo?tab=repositories">dariopavllo (dariopavllo) / Repositories</a><br/><a href="https://github.com/google-research/nerf-from-image">google-research/nerf-from-image: Shape, Pose, and Appearance from a Single Image via Bootstrapped Radiance Field Inversion</a><br/><a href="https://github.com/dariopavllo/textured-3d-gan?tab=readme-ov-file">dariopavllo/textured-3d-gan: Learning Generative Models of Textured 3D Meshes from Real-World Images, ICCV 2021</a><br/><a href="https://github.com/dariopavllo/convmesh">dariopavllo/convmesh: Code for "Convolutional Generation of Textured 3D Meshes", NeurIPS 2020</a><br/><a href="https://github.com/papagina/Auto_Conditioned_RNN_motion/blob/master/code/read_bvh_hierarchy.py">Auto_Conditioned_RNN_motion/code/read_bvh_hierarchy.py at master ¬∑ papagina/Auto_Conditioned_RNN_motion</a><br/><a href="https://github.com/nefeliandreou/PoseRepresentation/tree/master/src/common">PoseRepresentation/src/common at master ¬∑ nefeliandreou/PoseRepresentation</a><br/><a href="https://github.com/nefeliandreou/PoseRepresentation/blob/master/src/common/skeleton.py">PoseRepresentation/src/common/skeleton.py at master ¬∑ nefeliandreou/PoseRepresentation</a><br/><a href="https://github.com/nefeliandreou/PoseRepresentation/blob/master/src/eval.py">PoseRepresentation/src/eval.py at master ¬∑ nefeliandreou/PoseRepresentation</a><br/><a href="https://github.com/DK-Jang/human_motion_manifold/blob/master/skeleton.py">human_motion_manifold/skeleton.py at master ¬∑ DK-Jang/human_motion_manifold</a><br/><a href="https://github.com/UPC-ViRVIG/pymotion/issues/6">Having issues with fk operator and converting the results back for saving ¬∑ Issue #6 ¬∑ UPC-ViRVIG/pymotion</a><br/><a href="https://github.com/Wasserwecken/bvhio/blob/main/bvhio/lib/hierarchy/Joint.py">bvhio/bvhio/lib/hierarchy/Joint.py at main ¬∑ Wasserwecken/bvhio</a><br/><a href="https://stackoverflow.com/questions/41694329/docker-run-override-entrypoint-with-shell-script-which-accepts-arguments">Docker run override entrypoint with shell script which accepts arguments - Stack Overflow</a><br/><a href="undefined"></a><br/></body></html>