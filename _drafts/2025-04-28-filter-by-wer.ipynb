{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Re-)run Hugarian algorithm\n",
    "\n",
    "> \"Because it stops after a few hundred\"\n",
    "\n",
    "- branch: master\n",
    "- hidden: true\n",
    "- categories: [hsi, munkres]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/tmp/procced2.1.json\") as inf:\n",
    "    a = json.load(inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered1 = [x for x in a if not \"discarded\" in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "already_done = []\n",
    "with open(\"/tmp/assignment_short.csv\") as tsvf:\n",
    "    for line in tsvf:\n",
    "        line = line.strip()\n",
    "        if line.startswith(\"syntitem\"):\n",
    "            continue\n",
    "        if not line:\n",
    "            continue\n",
    "        already_done.append(line.split(\",\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = [x for x in filtered1 if not x[\"fileid\"] in already_done]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(423, 1412, 989)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered), len(filtered1), len(already_done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "L = np.load('bvh_pt_lengths.npy',allow_pickle=True)\n",
    "framerate = 120\n",
    "point_length = {}\n",
    "for thing in L:\n",
    "    item = list(thing.keys())[0].split('/')[-1]\n",
    "    item = item.replace('.bvh','')\n",
    "    point_length[item] = list(thing.values())[0]/framerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_length = {}\n",
    "for item in filtered:\n",
    "    synth_length[item[\"fileid\"]] = item[\"duration\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get Anna's names from my list\n",
    "synth_pre = {}\n",
    "synth_post = {}\n",
    "synth_data = {}\n",
    "synth_times = []\n",
    "\n",
    "for item in filtered:\n",
    "    fileid = item[\"fileid\"]\n",
    "    dem_start = float(item[\"determiner_start\"])\n",
    "    dem_end = float(item[\"determiner_end\"])\n",
    "    duration = float(item[\"duration\"])\n",
    "\n",
    "    synth_pre[fileid] = dem_start\n",
    "    synth_post[fileid] = dem_end - dem_start\n",
    "    synth_data[fileid] = (dem_start, duration)\n",
    "    synth_times.append((duration, dem_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1147\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "def find_demonstrative_index(expression, demonstratives):\n",
    "    words = expression.split(' ')\n",
    "    # Iterate over each word to find if it matches any of the demonstratives\n",
    "    for i, word in enumerate(words):\n",
    "        if word in demonstratives:\n",
    "            return i  # Return the index of the first matching demonstrative\n",
    "    return -1  # Return -1 if no demonstratives are found\n",
    "demonstratives = ['this','that','one','those','these','there','here']\n",
    "\n",
    "files = glob('/tmp/tsv_pt_segments/*.tsv')\n",
    "print(len(files))\n",
    "words_to_exclude = ['left', 'right', 'middle', 'back']\n",
    "files = [f for f in files if not any(word in f for word in words_to_exclude)]\n",
    "pt_times = []\n",
    "pt_names = []\n",
    "pt_pre = {}\n",
    "pt_post = {}\n",
    "pt_data = {}\n",
    "for fn in files:\n",
    "    temp_list = []\n",
    "    item = fn.split('/')[-1].split('.tsv')[0]\n",
    "    with open(fn) as f:\n",
    "        with open(fn) as f:\n",
    "            for line in f:\n",
    "                t0, t1, wrd = line.strip().split('\\t')\n",
    "                t0, t1 = float(t0), float(t1)\n",
    "                temp_list.append([t0, t1, wrd])\n",
    "        df = pd.DataFrame(temp_list, columns=['t0','t1','wrd'])\n",
    "        expr = ' '.join(df['wrd'])\n",
    "        index  = find_demonstrative_index(expr, demonstratives)\n",
    "        dem_time = df['t0'].iloc[index]\n",
    "        total_time = point_length[item]\n",
    "        pt_times.append((total_time, dem_time))\n",
    "        pt_names.append(item)\n",
    "        pt_pre[item] = dem_time\n",
    "        pt_post[item] = point_length[item] - pt_pre[item]\n",
    "        pt_data[item] = (dem_time,total_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.576       5.06666667  4.59733333  5.61066667  5.36533333  6.73066667\n",
      "  5.024       4.96        7.37066667  6.92266667  7.21066667  4.59733333\n",
      "  5.28        4.59733333  5.61066667  6.51733333  5.55733333  5.01333333\n",
      "  5.86666667  5.26933333  6.34666667  6.15466667  6.61333333  6.208\n",
      "  6.12266667  5.71733333  4.992       4.512       4.91733333  5.81333333\n",
      "  5.29066667  6.79466667  5.42933333  5.376       5.16266667  5.48266667\n",
      "  4.66133333  5.984       5.48266667  5.86666667  6.02666667  5.38666667\n",
      "  6.73066667  7.34933333  8.288       5.29066667  4.61866667  5.312\n",
      "  5.29066667  5.12        4.65066667  7.18933333  4.98133333  4.736\n",
      "  4.736       9.32266667  4.704       4.768       4.78933333  4.59733333\n",
      "  5.14133333  5.248       5.92        4.74666667  5.056       5.51466667\n",
      "  4.87466667  5.70666667  5.06666667  4.75733333  4.832       4.736\n",
      "  5.86666667  5.30133333  5.84533333  5.22666667  4.8        10.12266667\n",
      "  5.01333333  5.472       5.024       4.98133333  5.32266667  4.68266667\n",
      "  4.56533333  6.44266667  4.608       4.768       5.25866667  5.504\n",
      "  8.832      12.78866667  6.10133333  7.60533333  4.90666667  5.17333333\n",
      "  5.30133333  8.832       6.54933333  6.53866667  7.712       6.16533333\n",
      "  4.512       4.88533333  5.19466667  4.512       5.952       4.768\n",
      "  5.92        4.97066667  4.96        6.112       5.13066667  4.88533333\n",
      "  5.824       6.25066667  4.84266667  6.752       7.488       5.10933333\n",
      "  5.888       5.83466667  6.22933333  6.89066667  4.96        5.248\n",
      "  5.056       4.69333333  5.29066667  9.20533333  5.408      10.26133333\n",
      "  5.152       5.55733333  5.13066667  5.46133333  5.70666667  5.216\n",
      "  8.064       6.784       4.832       5.6         5.33333333  4.64\n",
      "  4.77866667  5.96266667  6.944       6.06933333  5.09866667  5.536\n",
      "  4.56533333  6.42133333  4.90666667  4.55466667  6.752       4.64\n",
      "  4.82133333 10.826       5.32266667  6.13333333  7.02933333  4.832\n",
      "  5.29066667  5.632       5.73866667  5.65333333  5.65333333  5.04533333\n",
      "  4.704       4.576       5.28        4.58666667  5.48266667  5.74933333\n",
      "  5.04533333  4.94933333  5.64266667  4.736       5.87733333  4.98133333\n",
      "  9.04533333  5.78133333  4.69333333  5.89866667  9.32266667  5.056\n",
      "  4.97066667  6.08        4.56533333  5.26933333  5.48266667  5.41866667\n",
      "  5.472       5.06666667  5.71733333  5.16266667  4.608       5.504\n",
      "  4.96        5.504       4.88533333  5.55733333  4.68266667  5.33333333\n",
      "  5.58933333  5.04533333  7.456       4.864       5.46133333  6.92266667\n",
      "  5.984       5.376       9.97333333  6.89066667  6.13333333  5.29066667\n",
      "  6.272       4.56533333  4.62933333  7.41333333  4.93866667  4.88533333\n",
      "  6.29333333  6.208       4.82133333  6.63466667  4.97066667  5.792\n",
      "  5.04533333  5.22666667  5.94133333  5.00266667 14.506       8.13866667\n",
      "  4.768       5.93066667  9.19466667  5.10933333  6.144       5.68533333\n",
      "  5.17333333  5.07733333  4.736       5.376       4.768       5.20533333\n",
      "  4.864       5.20533333  5.10933333  5.04533333  5.17333333  4.84266667\n",
      "  4.97066667  4.68266667  6.656       8.39466667  4.59733333  5.344\n",
      "  5.54666667  5.20533333  4.85333333  7.25333333  4.704      12.49\n",
      "  5.36533333  5.088       5.376       5.22666667  5.728       5.44\n",
      "  4.84266667  4.64        5.568       4.78933333  4.58666667  5.64266667\n",
      "  6.688       5.89866667  5.14133333  5.984       5.06666667  5.68533333\n",
      "  9.92        5.408       5.65333333  5.17333333  5.856       5.48266667\n",
      "  4.576       4.91733333  5.856       6.63466667  4.91733333  5.14133333\n",
      "  4.93866667  8.928       5.504       4.768       5.99466667  5.36533333\n",
      "  4.768       4.64        5.22666667  9.51466667  5.312       5.10933333\n",
      "  4.62933333  6.19733333  6.624       6.19733333  6.88        5.07733333\n",
      "  6.25066667  4.69333333  4.736      11.31666667  4.736       4.91733333\n",
      "  5.52533333  4.75733333  5.29066667  6.19733333  6.272       5.55733333\n",
      "  4.832       5.62133333  5.216       6.28266667  4.77866667  5.76\n",
      "  4.992       5.504       7.25333333  5.09866667  4.65066667  7.712\n",
      "  4.75733333  6.56        4.52266667  5.64266667 13.642       4.832\n",
      "  5.19466667  5.36533333  5.84533333  6.10133333  4.82133333  8.224\n",
      "  4.864       7.37066667  4.928       5.62133333  4.66133333  4.85333333\n",
      "  4.58666667  5.888       5.568       5.25866667  6.464       5.056\n",
      "  5.024       5.664       4.98133333  4.97066667  5.664       6.93333333\n",
      "  4.736       5.84533333  7.21066667  5.52533333  5.89866667  5.16266667\n",
      "  8.736       4.85333333  5.504       5.97333333  6.03733333 11.562\n",
      "  5.41866667  4.768       4.61866667  4.61866667  6.95466667  4.512\n",
      "  4.85333333  5.54666667  4.736       6.656       4.608       5.984\n",
      "  6.92266667  4.90666667  6.45333333  5.248       6.528       4.61866667\n",
      "  5.792       7.24266667  4.64        5.184       5.19466667  4.65066667\n",
      "  5.55733333  6.45333333  4.64        4.69333333  6.19733333  4.62933333\n",
      "  4.68266667  7.2         5.54666667  5.55733333  5.024       4.56533333\n",
      "  4.88533333  5.35466667  6.57066667  4.78933333  4.576       6.08\n",
      "  5.52533333  5.25866667  4.82133333]\n",
      "1147\n",
      "423\n"
     ]
    }
   ],
   "source": [
    "# Convert the list to a numpy array for statistical calculations\n",
    "synth_lengths_array = np.array([x[0] for x in synth_times])\n",
    "print(synth_lengths_array)\n",
    "lengths_array = np.array(synth_lengths_array)\n",
    "\n",
    "lengths_array_pt = np.array([x[0] for x in pt_times])\n",
    "# Calculate the mean and standard deviation\n",
    "mean_length = np.mean(lengths_array)\n",
    "std_dev_length = np.std(lengths_array)\n",
    "\n",
    "# Calculate the 50th (median) and 75th percentiles\n",
    "median_length_syn = np.percentile(lengths_array, 50)\n",
    "percentile_75_length = np.percentile(lengths_array, 75)\n",
    "percentile_75_length\n",
    "\n",
    "cutoff_time_syn = median_length_syn\n",
    "\n",
    "median_length_pt = np.percentile(lengths_array_pt, 50)\n",
    "percentile_75_length = np.percentile(lengths_array, 75)\n",
    "percentile_75_length\n",
    "\n",
    "cutoff_time_pt = median_length_pt\n",
    "\n",
    "print(len(pt_data))\n",
    "print(len(synth_data))\n",
    "\n",
    "short_pt = {k:v for k,v in pt_data.items() if v[1]<cutoff_time_pt}\n",
    "short_synth = {k:v for k,v in synth_data.items() if v[1]<cutoff_time_syn}\n",
    "long_pt = {k:v for k,v in pt_data.items() if v[1]>=cutoff_time_pt}\n",
    "long_synth = {k:v for k,v in synth_data.items() if v[1]>=cutoff_time_syn}\n",
    "\n",
    "synth_pre_short = {k:v for k,v in synth_pre.items() if k in short_synth}\n",
    "synth_post_short = {k:v for k,v in synth_post.items() if k in short_synth}\n",
    "pt_pre_short = {k:v for k,v in pt_pre.items() if k in short_pt}\n",
    "pt_post_short = {k:v for k,v in pt_post.items() if k in short_pt}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 573)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make distance matrix\n",
    "D = []\n",
    "synth_pre = synth_pre_short\n",
    "synth_post = synth_post_short\n",
    "pt_pre = pt_pre_short\n",
    "pt_post = pt_post_short\n",
    "\n",
    "for syntitem in list(synth_pre.keys())[:]:\n",
    "    row = []\n",
    "    for pointitem in list(pt_pre.keys())[:]:\n",
    "        syntpre = synth_pre[syntitem]\n",
    "        syntpost = synth_post[syntitem]\n",
    "        pointpre = pt_pre[pointitem]\n",
    "        pointpost = pt_post[pointitem]\n",
    "\n",
    "        cost = abs(syntpre-pointpre) + abs(syntpost-pointpost)\n",
    "        if synth_length[syntitem] > point_length[pointitem]:\n",
    "            cost *= 10\n",
    "        # penalize if synt starts before or ends after point\n",
    "        if syntpre > pointpre:\n",
    "            cost *= 2\n",
    "        if syntpost > pointpost:\n",
    "            cost *= 2\n",
    "        row.append(cost)\n",
    "    \n",
    "    D.append(row)\n",
    "dd = np.array(D)\n",
    "dd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting munkres\n",
      "  Using cached munkres-1.1.4-py2.py3-none-any.whl (7.0 kB)\n",
      "Installing collected packages: munkres\n",
      "Successfully installed munkres-1.1.4\n"
     ]
    }
   ],
   "source": [
    "!pip install munkres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "from munkres import Munkres\n",
    "m = Munkres()\n",
    "assignment_re = m.compute(D)\n",
    "f = open('assignment_short.csv','w')\n",
    "f.write('syntitem,pointitem,offset\\n')\n",
    "for pair in assignment_re:\n",
    "    syntidx,pointidx = pair\n",
    "    syntitem = list(synth_pre.keys())[syntidx]\n",
    "    pointitem = list(pt_pre.keys())[pointidx]\n",
    "    f.write('{},{},{}\\n'.format(syntitem, pointitem, pt_pre[pointitem]-synth_pre[syntitem]))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = []\n",
    "with open(\"/tmp/assignment_short.csv\") as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip()\n",
    "        if line.startswith(\"syntitem\"):\n",
    "            continue\n",
    "        parts = line.split(\",\")\n",
    "        selected.append(parts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = []\n",
    "with open(\"/tmp/procced2.1.json\") as inf:\n",
    "    newdata = json.load(inf)\n",
    "for item in newdata:\n",
    "    if item[\"fileid\"] in selected:\n",
    "        filtered.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ffmpeg -i /tmp/output/st2_mirrored.10512_10854_1.23stretch.mp4 -i groundinggpt-generated-speech/hsi_4_0717_211_001_main__ggpt__682.wav -filter_complex \"[1:a]atrim=start=0.8624999999999999[aud]\" -map 0:v -map \"[aud]\" -c:v copy -c:a aac output_minus.mp4\n",
    "\n",
    "with open(\"/tmp/assignment_short.csv\") as f, open(\"/tmp/ffmpeg-runner.sh\", \"w\") as outf:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip()\n",
    "        if line.startswith(\"syntitem\"):\n",
    "            continue\n",
    "        parts = line.split(\",\")\n",
    "        \n",
    "        outf.write(f\"ffmpeg -i /tmp/output/{parts[1]}.mp4 -i /tmp/groundinggpt-generated-speech/{parts[0]}.wav\")\n",
    "        time = float(parts[2])\n",
    "        if time < 0.0:\n",
    "            outf.write(f\" -filter_complex \\\"[1:a]atrim=start={time}[aud]\\\" -map 0:v -map \\\"[aud]\\\"\")\n",
    "        else:\n",
    "            itime = int(time * 1000.0)\n",
    "            outf.write(f\" -filter_complex \\\"[1:a]adelay={itime}|{itime}[aud]\\\" -map 0:v -map \\\"[aud]\\\"\")\n",
    "        outf.write(f\" -c:v copy -c:a aac /tmp/output_minus/{parts[0]}.mp4\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dict = {x[\"fileid\"]: x for x in filtered}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/tmp/assignment_short.csv\") as f, open(\"/tmp/assigned_extended.csv\", \"w\") as outf:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip()\n",
    "        if line.startswith(\"syntitem\"):\n",
    "            outf.write(line + \",room,topic\\n\")\n",
    "            continue\n",
    "        parts = line.split(\",\")\n",
    "        cur = filtered_dict[parts[0]]\n",
    "        outf.write(f\"{line},{cur['room']},{cur['topic']}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nst-tts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
