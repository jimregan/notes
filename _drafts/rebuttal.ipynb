{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdb8dbe0",
   "metadata": {},
   "source": [
    "# Reviewer QkfD\n",
    "\n",
    "First of all, we would like to express our appreciation for your review, in particular, for the wonderful summary of our work.\n",
    "\n",
    "**Q1. About using a simulated environment**\n",
    "\n",
    "This is an excellent point regarding the sim-to-real gap.  All vision components are pre-trained on massive, real-world image datasets, not on AI2-THOR. Therefore, their core visual grounding capabilities are not tied to the simulator.  If anything, we expect the out-of-domain images from the simulator to have worse performance than real-world data. We will add a discussion of this limitation and our reasoning for the approach's likely generalizability to the final manuscript.\n",
    "\n",
    "**Q2. About the grounding component in the two stage method**\n",
    "\n",
    " We thank the reviewer for this insightful question. Our two-stage pipeline employs a deliberate 'divide and conquer' strategy: first, an LLM (GPT-4o) resolves conversational ambiguity using the text-only dialogue history. Second, a specialized VLM (Florence-2) performs the visual grounding by localizing this now-unambiguous phrase in the image.\n",
    "\n",
    " We chose models like Florence-2 because they excel at this open-vocabulary localization. In contrast, many popular VLMs are designed for VQA/captioning and lack this crucial capability, a limitation confirmed in our initial tests where they failed to resolve any pronominal references. For example using GPT-4o failed on grounding tasks (outputting bounding boxes) and only the specialized, fine-tuned GroundingGPT was able to do grounding. We will make these considerations more clear in the paper.\n",
    "\n",
    " **Q3. About the use of active learning in the annotation**\n",
    "\n",
    "The use of crowd-sourcing for verification of annotations is one important step, which we have piloted already with the experiments in this paper. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba826747",
   "metadata": {},
   "source": [
    "# Reviewer wGYR\n",
    "\n",
    "**Q1. About evaluating on more vision-language models**\n",
    "\n",
    "This is an important point, which was also raised by reviewer 2mrB: we agree that expanding VLM evaluation is valuable. While our task requires models that output coordinates—limiting us to options like Florence-2 and GroundingGPT—we recognize that GLIP and Grounded-SAM are strong candidates for this setting. We intend to include evaluations of both in the final version to address this feedback and offer a broader perspective on grounding performance.\n",
    "\n",
    "**Q2. About more details on prompting and utterance history**\n",
    "\n",
    "We have provided prompts for GPT-4o and GroundingGPT in the supplementary material. “information.md” contains a link to an excerpt of the dataset showing dataset format, including how we provide scene context (in the subdirectory `4_scene_data`). We will add examples of intermediate representation of the 2-stage approach. About the utterance history: we sampled from the previous 5 utterances for those that matched the current topic; failing this, we extracted 20 seconds of history from the word-level timestamps. We will add examples of the intermediate representations used in the two-stage pipeline to further support reproducibility.\n",
    "\n",
    "**Q3. About extended diagnostic analysis.**\n",
    "\n",
    "As requested, we will add a deeper failure analysis, including: (1) Per-category performance breakdowns (by expression type, visibility); (2) A qualitative analysis of error propagation in our two-stage pipeline, showing how GPT-4o outputs impact final grounding; (3) Cross-model agreement patterns to identify shared failure modes.\n",
    "\n",
    "We will add these to the supplementary material.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc6168c",
   "metadata": {},
   "source": [
    "# Reviewer 1CkU\n",
    "\n",
    "Our heartfelt thanks for the valuable comments and suggestions.\n",
    "\n",
    "**Q1. About the passive interlocutor**\n",
    "\n",
    "We fully agree that dyadic interactions can present even more challenging patterns, however the passive interlocutor setup was a deliberate design choice to elicit dense, speaker-initiated references in a controlled manner, following the ‘traditional’ referential game study setup of an instruction-follower pair.\n",
    "\n",
    "**Q2. About the the two-stage approach**\n",
    "\n",
    "We thank the reviewer for this insightful observation, which precisely identifies the central motivation for our two-stage approach. Current monolithic VLMs often struggle to simultaneously master long-context dialogue reasoning and precise visual grounding. Our pipeline explicitly addresses this by dividing the labor: GPT-4o acts as a dialogue-aware \"contextualizer\" that translates ambiguous, raw utterances into explicit, groundable phrases. Florence-2 then performs the visual localization, a task it excels at when given a clear input. Therefore, the gain does indeed stem from GPT-4o simplifying the linguistic complexity. We argue this is a strength of the modular design, demonstrating that leveraging the best tool for each sub-problem leads to superior overall performance on this challenging task. We acknowledge the risk of error propagation and will add a discussion of this trade-off to the final manuscript.\n",
    "\n",
    "**Q3. About using GPT-4o for annotation**\n",
    "\n",
    "We will detail our verification pipeline, clarifying that after GPT-4o's initial pass, every expression-object pair was manually verified by human annotators checking against scene graphs and visual information (video stream from egocentric cameras in simulator).\n",
    "\n",
    "Crowd-sourced data can be used to estimate correctness of the model outputs; we could also investigate using multiple annotators and inter-annotator agreement as a future extension to strengthen quality assurance. In the current version, however, we prioritized annotation consistency by relying on trained annotators and structured verification against simulation metadata. We will make this process more transparent in the final version.\n",
    "\n",
    "**Additional comments: regarding the pipeline**\n",
    "\n",
    "The final grounding performance is indeed sensitive to the quality of GPT-4o’s generated expressions. In cases where GPT-4o referred to an incorrect object, the output was treated as a simple mismatch and omitted. Where the output was vague, we found that it was merely a repetition of the existing text. Subject to the agreed terms and conditions, we will include these model outputs with the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f9ed4f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c5c2f55",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
