{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to use pocketsphinx to word align\n",
    "\n",
    "> \"Because timing accuracy in ASR is getting progressively worse, look backwards\"\n",
    "\n",
    "- branch: master\n",
    "- comments: false\n",
    "- categories: [pocketsphinx, hsi, alignment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import pocketsphinx\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPPING = \"\"\"\n",
    "ɑː AA\n",
    "æ AE\n",
    "ə AH\n",
    "ɐ AH\n",
    "ʌ AH\n",
    "ɔː AO\n",
    "aʊ AW\n",
    "aɪ AY\n",
    "b B\n",
    "tʃ CH\n",
    "d D\n",
    "ð DH\n",
    "ɛ EH\n",
    "ɚ ER\n",
    "ɜː ER\n",
    "eɪ EY\n",
    "f F\n",
    "ɡ G\n",
    "h HH\n",
    "ɪ IH\n",
    "i IY\n",
    "iː IY\n",
    "dʒ JH\n",
    "k K\n",
    "l L\n",
    "m M\n",
    "n N\n",
    "ŋ NG\n",
    "oʊ OW\n",
    "ɔɪ OY\n",
    "p P\n",
    "ɹ R\n",
    "s S\n",
    "ʃ SH\n",
    "t T\n",
    "θ TH\n",
    "ʊ UH\n",
    "uː UW\n",
    "v V\n",
    "w W\n",
    "j Y\n",
    "z Z\n",
    "ʒ ZH\n",
    "ɾ D\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "espeak_to_cmudict = {}\n",
    "for line in MAPPING.split(\"\\n\"):\n",
    "    if line == \"\":\n",
    "        continue\n",
    "    line = line.strip()\n",
    "    parts = line.split(\" \")\n",
    "\n",
    "    if len(parts) != 2:\n",
    "        print(line)\n",
    "        continue\n",
    "    k, v = line.split(\" \")\n",
    "    if not k in espeak_to_cmudict:\n",
    "        espeak_to_cmudict[k] = v\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "cmudict_keys = espeak_to_cmudict.keys()\n",
    "cmudict_keys = sorted(cmudict_keys, key=len, reverse=True)\n",
    "espeak_regex = re.compile(rf\"({'|'.join(cmudict_keys)})\")\n",
    "\n",
    "def cmudictify(espeak):\n",
    "    espeak = espeak.replace(\"ˈ\", \"\").replace(\"ˌ\", \"\")\n",
    "    return \" \".join([espeak_to_cmudict[x] for x in re.findall(espeak_regex, espeak)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "EGTEXT = \"Yeah, that's true. I mean, they are the same size and they are a little bit, but I think I I should go more for something that style.\"\n",
    "EGPHON = \"/jˈæ ðˈæs tɹˈuː ə mˈiːn ðˈeɪ ɚ ðə sˈeɪm sˈaɪz ən ðˈeɪ ɚ ə lˈɪɾə bˈɪɾ bˈʌt ˈaɪ θˈɪŋk ˈaɪ ˈaɪ ʃˈʊ ɡˈoʊ mˈɔːɹ fɚ sˈʌmθɪŋ ðˈæt stˈaɪl./\"\n",
    "EGFILE = \"/Users/joregan/Playing/hsi/audio/hsi_7_0719_210_001_main.wav\"\n",
    "EGSTART = 70.028\n",
    "EGEND = 75.441"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "EGTEXT = \"no it's a cheetah, ah, yes it's a cheetah ah and, uh, that one is from, uh, India and, uh, it's really\"\n",
    "EGPHON = \"/nˈoʊ ɪts ɐ tʃˈiːt ˈɑːɛ jˈɑs ɪts ɐ tʃˈiːtə ˈɑː ænd ˈɛ ðˈæt wˌʌn ɪz fɹˈɑːm ˈɛ ˈɪndiæ ænd ˈɛ ɪts ɹˈili/\"\n",
    "EGFILE = \"/Users/joregan/Playing/hsi/audio/hsi_5_0718_211_002_main.wav\"\n",
    "\n",
    "EGTEXT2 = \"So it was standing somewhere in the middle of the room and it was flying around.\"\n",
    "EGSTART2 = 122.709\n",
    "EGEND2 = 126.344"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normword(text):\n",
    "    text = text.strip(\",.;:!?\")\n",
    "    return text.lower()\n",
    "\n",
    "def normphon(phon):\n",
    "    phon = phon.strip(\",.;:!?\")\n",
    "    return phon\n",
    "\n",
    "def make_lexicon(text, phon):\n",
    "    if phon.startswith(\"/\") and phon.endswith(\"/\"):\n",
    "        phon = phon[1:-1]\n",
    "    words = [normword(x) for x in text.split(\" \")]\n",
    "    phonwords = [cmudictify(normphon(x)) for x in phon.split(\" \")]\n",
    "    assert len(words) == len(phonwords)\n",
    "    output = list(set(zip(words, phonwords)))\n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ps_dict(entries):\n",
    "    counts = {}\n",
    "    output = []\n",
    "    lex = sorted(entries)\n",
    "    for entry in lex:\n",
    "        count = 1\n",
    "        if not entry[0] in counts:\n",
    "            counts[entry[0]] = 1\n",
    "        else:\n",
    "            counts[entry[0]] += 1\n",
    "            count = counts[entry[0]]\n",
    "        if count != 1:\n",
    "            subscript = f\"({count})\"\n",
    "        else:\n",
    "            subscript = \"\"\n",
    "        output.append(f\"{entry[0]}{subscript} {entry[1]}\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fsg_transitions_from_text(text):\n",
    "    words = [normword(x) for x in text.split(\" \")]\n",
    "    enum = [x for x in enumerate(words)]\n",
    "    trans = [(x[0], x[0] + 1, 1.0, x[1]) for x in enum]\n",
    "    return trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def espeakify(word):\n",
    "    out=!echo {word}|espeak --ipa -v en-us -q\n",
    "    filt = [x for x in out if x != \"\"]\n",
    "    if len(filt) == 1:\n",
    "        return filt[0].strip()\n",
    "    else:\n",
    "        return \" \".join(filt).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lex_from_espeak(text, overrides=None, concat=False):\n",
    "    words = [normword(x) for x in text.split(\" \")]\n",
    "    default = {x: espeakify(x) for x in words}\n",
    "    res = []\n",
    "    # [ for x in phon.split(\" \")]\n",
    "    for word in words:\n",
    "        if overrides is None or word not in overrides:\n",
    "            cur = (word, cmudictify(normphon(default[word])))\n",
    "            if cur not in res:\n",
    "                res.append(cur)\n",
    "        else:\n",
    "            if concat:\n",
    "                x = (word, cmudictify(normphon(default[word])))\n",
    "                if not x in res:\n",
    "                    res.append(x)\n",
    "            if type(overrides[word]) is list:\n",
    "                for pron in overrides[word]:\n",
    "                    x = (word, cmudictify(normphon(pron)))\n",
    "                    if not x in res:\n",
    "                        res.append(x)\n",
    "            else:\n",
    "                x = (word, cmudictify(normphon(overrides[word])))\n",
    "                if not x in res:\n",
    "                    res.append(x)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = AudioSegment.from_file(EGFILE)\n",
    "audio = audio.set_frame_rate(16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_with_pocketsphinx(text, phones, audio, start, end, overrides=None, concat_dict=False):\n",
    "    if not phones or phones == \"\":\n",
    "        lex = lex_from_espeak(text, overrides, concat_dict)\n",
    "    else:\n",
    "        lex = make_lexicon(text, phones)\n",
    "    entries = make_ps_dict(lex)\n",
    "\n",
    "    segments = []\n",
    "\n",
    "    with (\n",
    "        tempfile.NamedTemporaryFile(suffix=\".dict\", delete=False) as dictf,\n",
    "        tempfile.NamedTemporaryFile(suffix=\".raw\", delete=False) as wavf,\n",
    "    ):\n",
    "\n",
    "        with open(dictf.name, \"w\") as dictout:\n",
    "            for entry in entries:\n",
    "                dictout.write(entry + \"\\n\")\n",
    "\n",
    "        istart = int(start * 1000)\n",
    "        iend = int(end * 1000)\n",
    "        audioseg = audio[istart:iend]\n",
    "        audioseg.export(wavf.name, format=\"s16le\", parameters=[\"-ac\", \"1\", \"-acodec\", \"pcm_s16le\", \"-f\", \"s16le\", \"-ar\", \"16000\"])\n",
    "\n",
    "        fsgt = make_fsg_transitions_from_text(text)\n",
    "        start_state = fsgt[0][0]\n",
    "        end_state = fsgt[-1][1]\n",
    "\n",
    "        decoder = pocketsphinx.Decoder(lm=None, dict=dictf.name)\n",
    "\n",
    "        fsg = decoder.create_fsg(\"dummy\", start_state, end_state, fsgt)\n",
    "        decoder.add_fsg(\"dummy\", fsg)\n",
    "        decoder.activate_search(\"dummy\")\n",
    "\n",
    "        decoder.start_utt()\n",
    "        decoder.process_raw(wavf.read(), full_utt=True)\n",
    "        decoder.end_utt()\n",
    "\n",
    "        for seg in decoder.seg():\n",
    "            segments.append({\n",
    "                \"word\": seg.word,\n",
    "                \"start_ms\": (seg.start_frame * 10) + istart,\n",
    "                \"end_ms\": (seg.end_frame * 10) + istart,\n",
    "                \"phones\": decoder.lookup_word(seg.word)\n",
    "            })\n",
    "\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "segs = align_with_pocketsphinx(EGTEXT2, \"\", audio, EGSTART2, EGEND2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': 'so', 'start_ms': 122709, 'end_ms': 122789, 'phones': 'S OW'},\n",
       " {'word': 'it', 'start_ms': 122799, 'end_ms': 122899, 'phones': 'IH T'},\n",
       " {'word': 'was', 'start_ms': 122909, 'end_ms': 122989, 'phones': 'W AH Z'},\n",
       " {'word': 'standing',\n",
       "  'start_ms': 122999,\n",
       "  'end_ms': 123589,\n",
       "  'phones': 'S T AE N D IH NG'},\n",
       " {'word': '<sil>', 'start_ms': 123599, 'end_ms': 123809, 'phones': 'SIL'},\n",
       " {'word': 'somewhere',\n",
       "  'start_ms': 123819,\n",
       "  'end_ms': 124219,\n",
       "  'phones': 'S AH M W EH R'},\n",
       " {'word': 'in', 'start_ms': 124229, 'end_ms': 124319, 'phones': 'IH N'},\n",
       " {'word': 'the', 'start_ms': 124329, 'end_ms': 124389, 'phones': 'DH AH'},\n",
       " {'word': 'middle',\n",
       "  'start_ms': 124399,\n",
       "  'end_ms': 124599,\n",
       "  'phones': 'M IH D AH L'},\n",
       " {'word': 'of', 'start_ms': 124609, 'end_ms': 124739, 'phones': 'AH V'},\n",
       " {'word': 'the', 'start_ms': 124749, 'end_ms': 124839, 'phones': 'DH AH'},\n",
       " {'word': 'room', 'start_ms': 124849, 'end_ms': 125179, 'phones': 'R UW M'},\n",
       " {'word': 'and', 'start_ms': 125189, 'end_ms': 125289, 'phones': 'AE N D'},\n",
       " {'word': 'it', 'start_ms': 125299, 'end_ms': 125409, 'phones': 'IH T'},\n",
       " {'word': 'was', 'start_ms': 125419, 'end_ms': 125579, 'phones': 'W AH Z'},\n",
       " {'word': 'flying',\n",
       "  'start_ms': 125589,\n",
       "  'end_ms': 125939,\n",
       "  'phones': 'F L AY IH NG'},\n",
       " {'word': 'around',\n",
       "  'start_ms': 125949,\n",
       "  'end_ms': 126319,\n",
       "  'phones': 'AH R AW N D'}]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
