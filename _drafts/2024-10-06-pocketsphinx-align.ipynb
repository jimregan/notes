{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to use pocketsphinx to word align\n",
    "\n",
    "> \"Because timing accuracy in ASR is getting progressively worse, look backwards\"\n",
    "\n",
    "- branch: master\n",
    "- comments: false\n",
    "- categories: [pocketsphinx, hsi, alignment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "import pocketsphinx\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAPPING = \"\"\"\n",
    "ɑː AA\n",
    "æ AE\n",
    "ə AH\n",
    "ɐ AH\n",
    "ʌ AH\n",
    "ɔː AO\n",
    "aʊ AW\n",
    "aɪ AY\n",
    "b B\n",
    "tʃ CH\n",
    "d D\n",
    "ð DH\n",
    "ɛ EH\n",
    "ɚ ER\n",
    "ɜː ER\n",
    "eɪ EY\n",
    "f F\n",
    "ɡ G\n",
    "h HH\n",
    "ɪ IH\n",
    "i IY\n",
    "iː IY\n",
    "dʒ JH\n",
    "k K\n",
    "l L\n",
    "m M\n",
    "n N\n",
    "ŋ NG\n",
    "oʊ OW\n",
    "ɔɪ OY\n",
    "p P\n",
    "ɹ R\n",
    "s S\n",
    "ʃ SH\n",
    "t T\n",
    "θ TH\n",
    "ʊ UH\n",
    "uː UW\n",
    "v V\n",
    "w W\n",
    "j Y\n",
    "z Z\n",
    "ʒ ZH\n",
    "ɾ D\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "espeak_to_cmudict = {}\n",
    "for line in MAPPING.split(\"\\n\"):\n",
    "    if line == \"\":\n",
    "        continue\n",
    "    line = line.strip()\n",
    "    parts = line.split(\" \")\n",
    "\n",
    "    if len(parts) != 2:\n",
    "        print(line)\n",
    "        continue\n",
    "    k, v = line.split(\" \")\n",
    "    if not k in espeak_to_cmudict:\n",
    "        espeak_to_cmudict[k] = v\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "cmudict_keys = espeak_to_cmudict.keys()\n",
    "cmudict_keys = sorted(cmudict_keys, key=len, reverse=True)\n",
    "espeak_regex = re.compile(rf\"({'|'.join(cmudict_keys)})\")\n",
    "\n",
    "def cmudictify(espeak):\n",
    "    espeak = espeak.replace(\"ˈ\", \"\").replace(\"ˌ\", \"\")\n",
    "    return \" \".join([espeak_to_cmudict[x] for x in re.findall(espeak_regex, espeak)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "EGTEXT = \"Yeah, that's true. I mean, they are the same size and they are a little bit, but I think I I should go more for something that style.\"\n",
    "EGPHON = \"/jˈæ ðˈæs tɹˈuː ə mˈiːn ðˈeɪ ɚ ðə sˈeɪm sˈaɪz ən ðˈeɪ ɚ ə lˈɪɾə bˈɪɾ bˈʌt ˈaɪ θˈɪŋk ˈaɪ ˈaɪ ʃˈʊ ɡˈoʊ mˈɔːɹ fɚ sˈʌmθɪŋ ðˈæt stˈaɪl./\"\n",
    "EGFILE = \"/Users/joregan/Playing/hsi/audio/hsi_7_0719_210_001_main.wav\"\n",
    "EGSTART = 70.028\n",
    "EGEND = 75.441"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EGTEXT = \"no it's a cheetah, ah, yes it's a cheetah ah and, uh, that one is from, uh, India and, uh, it's really\"\n",
    "EGPHON = \"/nˈoʊ ɪts ɐ tʃˈiːt ˈɑːɛ jˈɑs ɪts ɐ tʃˈiːtə ˈɑː ænd ˈɛ ðˈæt wˌʌn ɪz fɹˈɑːm ˈɛ ˈɪndiæ ænd ˈɛ ɪts ɹˈili/\"\n",
    "EGFILE = \"/Users/joregan/Playing/hsi/audio/hsi_5_0718_211_002_main.wav\"\n",
    "\n",
    "EGTEXT2 = \"So it was standing somewhere in the middle of the room and it was flying around.\"\n",
    "EGSTART2 = 122.709\n",
    "EGEND2 = 126.344"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normword(text):\n",
    "    text = text.strip(\",.;:!?\")\n",
    "    return text.lower()\n",
    "\n",
    "def normphon(phon):\n",
    "    phon = phon.strip(\",.;:!?\")\n",
    "    return phon\n",
    "\n",
    "def make_lexicon(text, phon):\n",
    "    if phon.startswith(\"/\") and phon.endswith(\"/\"):\n",
    "        phon = phon[1:-1]\n",
    "    words = [normword(x) for x in text.split(\" \")]\n",
    "    phonwords = [cmudictify(normphon(x)) for x in phon.split(\" \")]\n",
    "    assert len(words) == len(phonwords)\n",
    "    output = list(set(zip(words, phonwords)))\n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ps_dict(entries):\n",
    "    counts = {}\n",
    "    output = []\n",
    "    lex = sorted(entries)\n",
    "    for entry in lex:\n",
    "        count = 1\n",
    "        if not entry[0] in counts:\n",
    "            counts[entry[0]] = 1\n",
    "        else:\n",
    "            counts[entry[0]] += 1\n",
    "            count = counts[entry[0]]\n",
    "        if count != 1:\n",
    "            subscript = f\"({count})\"\n",
    "        else:\n",
    "            subscript = \"\"\n",
    "        output.append(f\"{entry[0]}{subscript} {entry[1]}\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fsg_transitions_from_text(text):\n",
    "    words = [normword(x) for x in text.split(\" \")]\n",
    "    enum = [x for x in enumerate(words)]\n",
    "    trans = [(x[0], x[0] + 1, 1.0, x[1]) for x in enum]\n",
    "    return trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = AudioSegment.from_file(EGFILE)\n",
    "audio = audio.set_frame_rate(16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_with_pocketsphinx(text, phones, audio, start, end):\n",
    "    lex = make_lexicon(text, phones)\n",
    "    entries = make_ps_dict(lex)\n",
    "    segments = []\n",
    "\n",
    "    with (\n",
    "        tempfile.NamedTemporaryFile(suffix=\".dict\", delete=False) as dictf,\n",
    "        tempfile.NamedTemporaryFile(suffix=\".raw\", delete=False) as wavf,\n",
    "    ):\n",
    "\n",
    "        with open(dictf.name, \"w\") as dictout:\n",
    "            for entry in entries:\n",
    "                dictout.write(entry + \"\\n\")\n",
    "\n",
    "        istart = int(start * 1000)\n",
    "        iend = int(end * 1000)\n",
    "        audioseg = audio[istart:iend]\n",
    "        audioseg.export(wavf.name, format=\"s16le\", parameters=[\"-ac\", \"1\", \"-acodec\", \"pcm_s16le\", \"-f\", \"s16le\", \"-ar\", \"16000\"])\n",
    "\n",
    "        fsgt = make_fsg_transitions_from_text(text)\n",
    "        start_state = fsgt[0][0]\n",
    "        end_state = fsgt[-1][1]\n",
    "\n",
    "        decoder = pocketsphinx.Decoder(lm=None, dict=dictf.name)\n",
    "        fsg = decoder.create_fsg(\"dummy\", start_state, end_state, fsgt)\n",
    "        decoder.add_fsg(\"dummy\", fsg)\n",
    "        decoder.activate_search(\"dummy\")\n",
    "        decoder.start_utt()\n",
    "        # decoder.process_raw(seg.get_array_of_samples('B'))\n",
    "        decoder.process_raw(wavf.read(), full_utt=True)\n",
    "        decoder.end_utt()\n",
    "        for seg in decoder.seg():\n",
    "            segments.append({\n",
    "                \"word\": seg.word,\n",
    "                \"start_ms\": (seg.start_frame * 10) + istart,\n",
    "                \"end_ms\": (seg.end_frame * 10) + istart\n",
    "            })\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "segs = align_with_pocketsphinx(EGTEXT, EGPHON, audio, EGSTART, EGEND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': 'yeah', 'start_ms': 70028, 'end_ms': 70268},\n",
       " {'word': \"that's\", 'start_ms': 70278, 'end_ms': 70418},\n",
       " {'word': 'true', 'start_ms': 70428, 'end_ms': 70608},\n",
       " {'word': 'i', 'start_ms': 70618, 'end_ms': 70698},\n",
       " {'word': 'mean', 'start_ms': 70708, 'end_ms': 70858},\n",
       " {'word': 'they', 'start_ms': 70868, 'end_ms': 70998},\n",
       " {'word': 'are', 'start_ms': 71008, 'end_ms': 71068},\n",
       " {'word': 'the', 'start_ms': 71078, 'end_ms': 71178},\n",
       " {'word': 'same', 'start_ms': 71188, 'end_ms': 71438},\n",
       " {'word': 'size', 'start_ms': 71448, 'end_ms': 71818},\n",
       " {'word': 'and', 'start_ms': 71828, 'end_ms': 71928},\n",
       " {'word': 'they', 'start_ms': 71938, 'end_ms': 72048},\n",
       " {'word': 'are', 'start_ms': 72058, 'end_ms': 72188},\n",
       " {'word': 'a', 'start_ms': 72198, 'end_ms': 72218},\n",
       " {'word': 'little', 'start_ms': 72228, 'end_ms': 72368},\n",
       " {'word': 'bit', 'start_ms': 72378, 'end_ms': 72528},\n",
       " {'word': 'but', 'start_ms': 72538, 'end_ms': 72758},\n",
       " {'word': 'i(2)', 'start_ms': 72768, 'end_ms': 72878},\n",
       " {'word': 'think', 'start_ms': 72888, 'end_ms': 73128},\n",
       " {'word': 'i(2)', 'start_ms': 73138, 'end_ms': 73388},\n",
       " {'word': 'i', 'start_ms': 73398, 'end_ms': 73418},\n",
       " {'word': 'should', 'start_ms': 73428, 'end_ms': 73578},\n",
       " {'word': 'go', 'start_ms': 73588, 'end_ms': 73758},\n",
       " {'word': 'more', 'start_ms': 73768, 'end_ms': 73978},\n",
       " {'word': 'for', 'start_ms': 73988, 'end_ms': 74178},\n",
       " {'word': 'something', 'start_ms': 74188, 'end_ms': 74498},\n",
       " {'word': 'that', 'start_ms': 74508, 'end_ms': 74798},\n",
       " {'word': 'style', 'start_ms': 74808, 'end_ms': 75428},\n",
       " {'word': '</s>', 'start_ms': 75428, 'end_ms': 75428}]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
