{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b12a1fd8",
   "metadata": {},
   "source": [
    "Got it ‚Äî thanks for the clarification.\n",
    "\n",
    "So you have **two parallel but distinct datasets**:\n",
    "\n",
    "1. **Dataset A**:\n",
    "   ‚Üí Name **text** + **audio** recordings (spoken names)\n",
    "\n",
    "2. **Dataset B**:\n",
    "   ‚Üí Name **text** + **quasi-phonetic** transcriptions (e.g., *‚ÄúSUR-sh…ô ROH-n…ôn‚Äù*)\n",
    "\n",
    "This actually opens up a clear and well-scoped opportunity: the first paper becomes a **mapping task between these two modalities**, anchored by the shared textual name. This simplifies alignment while keeping the technical lift manageable.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úçÔ∏è Updated Paper Focus\n",
    "\n",
    "> **Builds a bridge** between written names, their spoken form (Dataset A), and their readable pronunciation (Dataset B).\n",
    "\n",
    "---\n",
    "\n",
    "## üîÅ Updated Outline: *\"Bridging Written and Spoken Names via Quasi-Phonetic Transcriptions\"*\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Introduction**\n",
    "\n",
    "* Motivation:\n",
    "\n",
    "  * Name pronunciation is often idiosyncratic and weakly correlated with spelling.\n",
    "  * This project connects written names, spoken forms, and quasi-phonetic renderings.\n",
    "* Contribution:\n",
    "\n",
    "  * Release and description of two linked datasets.\n",
    "  * Small-scale modeling experiments to show that quasi-phonetic forms can be predicted from audio (or vice versa).\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Related Work**\n",
    "\n",
    "* Proper name handling in ASR/TTS.\n",
    "* G2P and pseudo-phonetic approaches.\n",
    "* Data resources for pronunciation modeling.\n",
    "* Weak supervision in speech‚Äìtext alignment.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Datasets**\n",
    "\n",
    "**3.1 Dataset A: Spoken Names**\n",
    "\n",
    "* Format: name text + wav\n",
    "* Details: recording conditions, speaker characteristics, size\n",
    "\n",
    "**3.2 Dataset B: Quasi-Phonetic Transcriptions**\n",
    "\n",
    "* Format: name text + \"SUR-sh…ô\"-style transcriptions\n",
    "* Guidelines: stress, syllable boundaries, orthographic approximation\n",
    "* Scope: number of names, annotator instructions\n",
    "\n",
    "**3.3 Cross-Dataset Linkage**\n",
    "\n",
    "* Common field: name text\n",
    "* Mapping limitations: not all names appear in both sets\n",
    "* Use cases enabled by joining: speech-to-pronunciation learning, phoneme prediction, TTS adaptation\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Technical Experiment**\n",
    "\n",
    "Pick **one or two** lightweight technical contributions to validate utility:\n",
    "\n",
    "#### 4.1 Audio ‚Üí Quasi-Phonetic (speech2pron)\n",
    "\n",
    "* Use wav2vec2 or Tacotron encoder to extract name embeddings from audio\n",
    "* Train model to predict quasi-phonetic transcription\n",
    "* Evaluation: Levenshtein distance, syllable-level accuracy\n",
    "\n",
    "#### 4.2 Text ‚Üí Quasi-Phonetic (name2pron)\n",
    "\n",
    "* Train grapheme-to-quasi-phonetic seq2seq model\n",
    "* Useful as a G2P alternative\n",
    "\n",
    "#### 4.3 Visualization or Probing\n",
    "\n",
    "* Visualize latent space of spoken names, cluster by quasi-phonetic form\n",
    "* Train a probing classifier on embeddings to predict stress pattern or syllables\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Applications and Future Work**\n",
    "\n",
    "* Use in:\n",
    "\n",
    "  * Name-aware ASR\n",
    "  * TTS personalization\n",
    "  * Speech-to-IPA alignment with weak supervision\n",
    "* Follow-up: Add phonemic intermediate layer (your injection idea)\n",
    "* Explore crowdsourcing or semi-automatic generation of quasi-phonetic labels\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Conclusion**\n",
    "\n",
    "* Introduced two name pronunciation datasets with shared anchor (name text).\n",
    "* Demonstrated feasibility of modeling quasi-phonetic forms from text or speech.\n",
    "* Set foundation for personalized, fluent name rendering in TTS.\n",
    "\n",
    "---\n",
    "\n",
    "Ready to convert this outline into a filled-in publishing template now?\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
