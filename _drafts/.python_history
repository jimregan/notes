lic = '"Creative Commons Attribution licence (reuse allowed)"'
def inner(cur_id):
    if cur_id in seen:
        return
    req = requests.get(f"https://www.youtube.com/watch?v={cur_id}")
    if req.status_code != 200:
        retry.append(cur_id)
    if lic in req.text:
        cc_by.append(cur_id)
    else:
        other.append(cur_id)
    seen.append(cur_id)
with open("pl_videos.json") as pl_videos:
    for line in pl_videos.readlines():
        line_data = json.loads(line.strip())
        inner(line_data['id'])
with open("uploads.json") as pl_videos:
    for line in pl_videos.readlines():
        line_data = json.loads(line.strip())
with open("pl_videos.json") as pl_videos:
    for line in pl_videos.readlines():
        line_data = json.loads(line.strip())
        inner(line_data['id'])
with open("uploads.json") as pl_videos:
    for line in pl_videos.readlines():
        line_data = json.loads(line.strip())
        inner(line_data['id'])
with open('proc.json', 'w') as outfile:
    json.dump({'cc-by': cc_by, 'other': other, 'retry': retry}, outfile)
lic = 'Creative Commons Attribution licence (reuse allowed)'
line_data = []
with open("pl_videos.json") as pl_videos:
    for line in pl_videos.readlines():
        line_data = json.loads(line.strip())
        inner(line_data['id'])
line_data
from pathlib import Path
for i in Path(".").glob("*.info.json"):
	print(i)
from pathlib import Path
import json
for i in Path(".").glob("*.info.json"):
	data = json.load(i)
for i in Path(".").glob("*.info.json"):
	data = json.load(str(i))
for i in Path(".").glob("*.info.json"):
	with open(i) as f:
		data = json.load(f)
data
data["license"]
CC_BY = 'Creative Commons Attribution license (reuse allowed)'
for i in Path(".").glob("*.info.json"):
	with open(i) as f:
		data = json.load(f)
		if "license" in data and data["license"] == CC_BY:
			print(i)
cc_by_ids = []
for i in Path(".").glob("*.info.json"):
    with open(i) as f:
        data = json.load(f)
        if "license" in data and data["license"] == CC_BY:
            cc_by_ids.append(i.replace(".info.json", ""))
            cc_by_ids.append(str(i).replace(".info.json", ""))
cc_by_ids = []
for i in Path(".").glob("*.info.json"):
    with open(i) as f:
        data = json.load(f)
        if "license" in data and data["license"] == CC_BY:
            cc_by_ids.append(str(i).replace(".info.json", ""))
cc_by_ids
with open("cc-by-ids.txt", "w") as out:
	for vid in cc_by_ids:
		out.write(vid + "\n")
with open("cc-by-ids.txt", "w") as outf:
	for vid in cc_by_ids:
		outf.write(vid + "\n")
print(len(cc_by_ids))
import datasets
datasets.load_dataset('timit_asr', data_dir='/sbtal/TIMIT/')
import datasets
datasets.load_dataset('timit_asr', data_dir='/sbtal/TIMIT/')
timit = datasets.load_dataset('timit_asr', data_dir='/sbtal/TIMIT/')
timit['train'][0]
timit['train'][0]['phonetic_detail'
timit['train'][0]['phonetic_detail']
from transformers import pipeline
_SWE_MODEL = "KBLab/wav2vec2-large-voxrex-swedish"
file = "/tmp/2442101120000160421_759s.wav"
output = pipe(file, chunk_length_s=10, return_timestamps="word")
pipe = pipeline(model=_SWE_MODEL)
output = pipe(file, chunk_length_s=10, return_timestamps="word")
output
output["chunks"]
output["chunks"][1]["text"]
#output["chunks"][1]["text"] = "s책".upper()
"s책".upper()
output["chunks"][1]["text"] = "s책".upper()
output
output["text"].replace("saag", "s책")
for chunk in output["chunks"]:
	print(chunk["timestamp"])
for chunk in output["chunks"]:
	old_ts = chunk["timestamp"]
	chunk["timestamp"] = (old_ts[0] + 759, old_ts[1] + 759)
output
#for chunk in output["chunks
with open("/tmp/2442101120000160421_759s.ctm", "w") as of:
	for chunk in output["chunks"]:
		of.write(f'2442101120000160421 1 {chunk["timestamp"][0]} {chunk["timestamp"][1] - chunk["timestamp"][0]} {chunk["text"].lower()} 1.0\n")
		of.write(f'2442101120000160421 1 {chunk["timestamp"][0]} {chunk["timestamp"][1] - chunk["timestamp"][0]} {chunk["text"].lower()} 1.0\n')
with open("/tmp/2442101120000160421_759s.ctm", "w") as of:
	for chunk in output["chunks"]:
		of.write(f'2442101120000160421 1 {chunk["timestamp"][0]} {chunk["timestamp"][1] - chunk["timestamp"][0]} {chunk["text"].lower()} 1.0\n")
with open("/tmp/2442101120000160421_759s.ctm", "w") as of:
	for chunk in output["chunks"]:
		of.write(f'2442101120000160421 1 {chunk["timestamp"][0]} {chunk["timestamp"][1] - chunk["timestamp"][0]} {chunk["text"].lower()} 1.0\n')
with open("/tmp/2442101120000160421_759s.ctm", "w") as of:
	for chunk in output["chunks"]:
		of.write(f'2442101120000160421 1 {chunk["timestamp"][0] + 0.3} {chunk["timestamp"][1] - chunk["timestamp"][0]} {chunk["text"].lower()} 1.0\n')
input = "En-au-sick_as_a_dog.ogg"
from transformers import pipeline
model = "jonatasgrosman/wav2vec2-large-xlsr-53-english"
pipe = pipeline(model=model)
output = pipe(input, chunk_length_s=10, return_timestamps="word")
