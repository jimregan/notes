{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ALPHABET = {\n",
    "    \"A\": [\"a\"],\n",
    "    \"B\": [\"be\", \"bé\"],\n",
    "    \"C\": [\"ce\", \"se\", \"sé\", \"cé\", \"si\", \"ci\"],\n",
    "    \"D\": [\"de\", \"dé\", \"di\"],\n",
    "    \"E\": [\"e\", \"é\"],\n",
    "    \"F\": [\"eff\", \"ef\"],\n",
    "    \"G\": [\"ge\", \"gé\", \"gi\"],\n",
    "    \"H\": [\"hå\", \"ho\"],\n",
    "    \"I\": [\"i\"],\n",
    "    \"J\": [\"ji\", \"gi\"],\n",
    "    \"K\": [\"kå\", \"ko\"],\n",
    "    \"L\": [\"ell\", \"el\"],\n",
    "    \"M\": [\"emm\", \"em\"],\n",
    "    \"N\": [\"enn\", \"en\"],\n",
    "    \"O\": [\"o\"],\n",
    "    \"P\": [\"pe\", \"pé\", \"pi\"],\n",
    "    \"Q\": [\"qu\"],\n",
    "    \"R\": [\"err\", \"er\", \"är\", \"ärr\"],\n",
    "    \"S\": [\"ess\", \"es\"],\n",
    "    \"T\": [\"te\", \"té\", \"ti\"],\n",
    "    \"U\": [\"u\"],\n",
    "    \"V\": [\"ve\", \"vé\", \"vi\"],\n",
    "    \"W\": [\"dubbelve\"],\n",
    "    \"X\": [\"ex\", \"ecz\", \"ecs\", \"eks\"],\n",
    "    \"Y\": [\"y\"],\n",
    "    \"Z\": [\"zäta\", \"säta\", \"seta\", \"zeta\"],\n",
    "    \"Å\": [\"å\"],\n",
    "    \"Ä\": [\"ä\"],\n",
    "    \"Ö\": [\"ö\"]\n",
    "}\n",
    "\n",
    "DIGITS = {\n",
    "    \"1\": [\"ett\"],\n",
    "    \"2\": [\"två\"],\n",
    "    \"3\": [\"tre\"],\n",
    "    \"4\": [\"fyra\"],\n",
    "    \"5\": [\"fem\"],\n",
    "    \"6\": [\"sex\"],\n",
    "    \"7\": [\"sju\"],\n",
    "    \"8\": [\"åtta\"],\n",
    "    \"9\": [\"nio\", \"ni\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHABET = {k: sorted(v, key=len, reverse=True) for k,v in _ALPHABET.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "2442206120015761721 1 487.78 0.32 essefu 1.0 <eps> ins\n",
    "2442206120015761721 1 488.26 0.16 fem 1.0 SfU5 sub\n",
    "```\n",
    "\n",
    "```\n",
    "2442206120015761721 1 490.6 0.519 tjugohundrafjorton 1.0 <eps> ins\n",
    "2442206120015761721 1 491.2 0.379 femton 1.0 <eps> ins\n",
    "2442206120015761721 1 491.74 0.779 etthundratjugofyra 1.0 2014/15:124 sub\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALNUM = {**ALPHABET, **DIGITS}\n",
    "ALNUM_REGEX = {k: f\"({'|'.join(v)})\" for k,v in ALNUM.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "ACCEPT = [\n",
    "    (\"e\", \"ə\")\n",
    "]\n",
    "\n",
    "a = \"kamaren\"\n",
    "b = \"kamarən\"\n",
    "\n",
    "ok = False\n",
    "\n",
    "s = SequenceMatcher(None, a, b)\n",
    "for tag, i1, i2, j1, j2 in s.get_opcodes():\n",
    "    if tag == \"replace\":\n",
    "        if (a[i1:i2], b[j1:j2]) in ACCEPT:\n",
    "            ok = True\n",
    "        else:\n",
    "            ok = False\n",
    "    elif tag == \"equal\":\n",
    "        ok = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phonemizer import phonemize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'slʉt '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phonemize(\"slut\", language='sv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sync_asr.utils.nst_lexicon import get_nst_lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/joregan/Playing/sync_asr\n",
      "Obtaining file:///Users/joregan/Playing/sync_asr\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pytest in /Users/joregan/opt/anaconda3/envs/phonemizer/lib/python3.11/site-packages (from sync-asr==0.0.1) (8.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/joregan/opt/anaconda3/envs/phonemizer/lib/python3.11/site-packages (from sync-asr==0.0.1) (4.12.3)\n",
      "Requirement already satisfied: requests in /Users/joregan/opt/anaconda3/envs/phonemizer/lib/python3.11/site-packages (from sync-asr==0.0.1) (2.31.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/joregan/opt/anaconda3/envs/phonemizer/lib/python3.11/site-packages (from beautifulsoup4->sync-asr==0.0.1) (2.5)\n",
      "Requirement already satisfied: iniconfig in /Users/joregan/opt/anaconda3/envs/phonemizer/lib/python3.11/site-packages (from pytest->sync-asr==0.0.1) (2.0.0)\n",
      "Requirement already satisfied: packaging in /Users/joregan/opt/anaconda3/envs/phonemizer/lib/python3.11/site-packages (from pytest->sync-asr==0.0.1) (23.2)\n",
      "Requirement already satisfied: pluggy<2.0,>=1.3.0 in /Users/joregan/opt/anaconda3/envs/phonemizer/lib/python3.11/site-packages (from pytest->sync-asr==0.0.1) (1.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/joregan/opt/anaconda3/envs/phonemizer/lib/python3.11/site-packages (from requests->sync-asr==0.0.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/joregan/opt/anaconda3/envs/phonemizer/lib/python3.11/site-packages (from requests->sync-asr==0.0.1) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/joregan/opt/anaconda3/envs/phonemizer/lib/python3.11/site-packages (from requests->sync-asr==0.0.1) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/joregan/opt/anaconda3/envs/phonemizer/lib/python3.11/site-packages (from requests->sync-asr==0.0.1) (2024.2.2)\n",
      "Installing collected packages: sync-asr\n",
      "  Attempting uninstall: sync-asr\n",
      "    Found existing installation: sync-asr 0.0.1\n",
      "    Uninstalling sync-asr-0.0.1:\n",
      "      Successfully uninstalled sync-asr-0.0.1\n",
      "  Running setup.py develop for sync-asr\n",
      "Successfully installed sync-asr-0.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/joregan/Playing/sync_asr\n",
    "%pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = get_nst_lexicon()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = {}\n",
    "for entry in lexicon:\n",
    "    if 'garbage' in entry and entry['garbage'] == 'GARB':\n",
    "        continue\n",
    "    else:\n",
    "        word = entry['orthography']\n",
    "        word = word.replace(\"_\", \" \")\n",
    "        if not word in dictionary:\n",
    "            dictionary[word] = set()\n",
    "        for translit in entry['transliterations']:\n",
    "            dictionary[word].add(translit['ipa'].replace(\".\", \"\").replace(\"¤\", \"\").replace(\"_\", \" \").replace(\"\\u0361\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONSONANTS = \"bdfhjklmnprstvŋɕɖɡɧɭɳʂʈ\"\n",
    "VOWELS = \"aeiouyøɪɑɔɛɵʉʊʏ\"\n",
    "ACCENTS = \"²ˌˈ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'²ɪnte'}\n",
      "ɪntɛ \n"
     ]
    }
   ],
   "source": [
    "print(dictionary[\"inte\"])\n",
    "print(phonemize(\"inte\", language='sv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = set()\n",
    "for entry in dictionary:\n",
    "    for pron in dictionary[entry]:\n",
    "        for char in pron:\n",
    "            characters.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons = set()\n",
    "VS = VOWELS + ACCENTS + \"_\"\n",
    "for entry in dictionary:\n",
    "    for pron in dictionary[entry]:\n",
    "        for char in pron:\n",
    "            if char not in VS:\n",
    "                cons.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_accent(ipa):\n",
    "    accent = \"\"\n",
    "    output = \"\"\n",
    "    for character in ipa:\n",
    "        if character in ACCENTS:\n",
    "            accent = character\n",
    "        elif character in CONSONANTS:\n",
    "            output += character\n",
    "        elif character in VOWELS:\n",
    "            if accent != \"\":\n",
    "                output += accent\n",
    "                accent = \"\"\n",
    "            output += character\n",
    "        else:\n",
    "            output += character\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kr²atʊʂ'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shift_accent(\"²kratʊʂ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import itertools\n",
    "\n",
    "class Rule():\n",
    "    def __init__(self, match, replacement, rulename, example, on_accented = False, before_accented = False):\n",
    "        self.match = match\n",
    "        self.replacement = replacement\n",
    "        self.rulename = rulename\n",
    "        self.example = example\n",
    "        self.on_accented = on_accented\n",
    "        self.before_accented = before_accented\n",
    "\n",
    "    def apply(self, word):\n",
    "        if self.on_accented:\n",
    "            pattern = fr\"((?:[^²ˌˈ]){self.match}|^{self.match})\"\n",
    "        elif self.before_accented:\n",
    "            pattern = fr\"({self.match}(?:[^²ˌˈ]))\"\n",
    "        else:\n",
    "            word = re.sub(\"[²ˌˈ]\", \"\", word)\n",
    "            pattern = self.match\n",
    "        matches = [(m.start(), m.end()) for m in re.finditer(pattern, word)]\n",
    "        if self.on_accented:\n",
    "            tmp = []\n",
    "            for m in matches:\n",
    "                if m[1] - m[0] > len(self.match):\n",
    "                    tmp.append((m[1] - len(self.match), m[1]))\n",
    "                else:\n",
    "                    tmp.append(m)\n",
    "            matches = tmp\n",
    "\n",
    "        pieces = []\n",
    "        prev_end = 0\n",
    "        for piece in matches:\n",
    "            if piece[0] > 0:\n",
    "                pieces.append([word[prev_end:piece[0]]])\n",
    "            pieces.append([word[piece[0]:piece[1]], self.replacement])\n",
    "            prev_end = piece[1]\n",
    "        pieces.append([word[prev_end:]])\n",
    "\n",
    "        output = []\n",
    "        for part in itertools.product(*pieces):\n",
    "            output.append(\"\".join(part))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule = Rule(\"nh\", \"n\", \"n → ∅ / _ h\", \"Stenholm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert rule.apply(\"nhanhanha\") == ['nhanhanha',\n",
    " 'nhanhana',\n",
    " 'nhananha',\n",
    " 'nhanana',\n",
    " 'nanhanha',\n",
    " 'nanhana',\n",
    " 'nananha',\n",
    " 'nanana']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The basic idea with these is that they just apply anyway, because the input\n",
    "# is single words, but at some later processing stage we can validate\n",
    "class AssimilationRule(Rule):\n",
    "    def __init__(self, match, replacement, rulename, example, on_accented = False, before_accented = False, pre_context = \"\", post_context = \"\"):\n",
    "        super.__init__(match, replacement, rulename, example, on_accented, before_accented)\n",
    "        self.pre_context = pre_context\n",
    "        self.post_context = post_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERAL_STRESSED = [\n",
    "    Rule(\"e\", \"ə\", \"e → ə / [-stressed]\", \"\", True),\n",
    "    Rule(\"ɛ\", \"ə\", \"e → ə / [-stressed]\", \"\", True)\n",
    "]\n",
    "\n",
    "AssimilationRule(\"r$\", \"\", \"h → ∅ / r # _\", \"har han\", False, False, \"\", \"h\")\n",
    "AssimilationRule(\"n$\", \"\", \"h → ∅ / n # _\", \"han har\", False, False, \"\", \"h\")\n",
    "AssimilationRule(\"r$\", \"\", \"r → ∅ / _ # [+consonant]\", \"där bilen\", False, False, \"\", f\"[{CONSONANTS}]\")\n",
    "\n",
    "Rule(\"[œɶeə]r\", \"r\", \"e → ∅ / _ r [+stressed]\", \"bero\", False, True)\n",
    "\n",
    "\t# # Same phone twice (within word and across word boundaries (repeated below)\n",
    "\t# $s =~ s/(.) \\1/$1/g;\t\t\t\t\t# RULE:\t@ → ∅ / _ @ \t\t\tetc.\n",
    "\t# $s =~ s/(.) ($wb \\1)/$2/g;\t\t\t\t# RULE:\t@ → ∅ / _ # @ \t\tetc.\n",
    "\t\n",
    "Rule(\"ɪntə\", \"ntə\", \"ɪ → ∅ / [+vowel] # _ n t ə\", \"ska inte\", False, False)\n",
    "Rule(\"ɪnte\", \"nte\", \"ɪ → ∅ / [+vowel] # _ n t e\", \"ska inte\", False, False)\n",
    "\n",
    "Rule(\"nh\", \"h\", \"n → ∅ / _ h\", \"Stenholm\")\n",
    "\t\n",
    "\t# # r\n",
    "\t# $s =~ s/\\@ r m/\\@ m/g;\t\t\t\t\t# RULE:\tr → ∅ / @ _ m \t\tSchleiermacher\n",
    "\t\n",
    "\t# # rd/rl\n",
    "\t# $s =~ s/: rd (rn)/: $1/g;\t\t\t\t# RULE:\trd → ∅ / : _ sn \t\tordning\n",
    "\t# $s =~ s/rl/l/g;\t\t\t\t\t\t# RULE:\trl → l /\t\t\tsvårhanterliga\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "syncasr_stats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
