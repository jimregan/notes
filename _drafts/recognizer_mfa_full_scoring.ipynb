{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e275071d",
   "metadata": {},
   "source": [
    "# üß† Recognizer vs MFA Alignment & Acoustic Scoring\n",
    "\n",
    "This notebook performs detailed comparisons between phonetic recognizer outputs and Montreal Forced Aligner (MFA) results. It includes:\n",
    "\n",
    "- Edit distance between IPA sequences\n",
    "- Soft-DTW alignment cost (mock + optional CUDA support)\n",
    "- Vowel formant validation\n",
    "- Batch processing\n",
    "- Visualization of results\n",
    "- TextGrid generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8c13a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import euclidean\n",
    "import json\n",
    "from textgrid import TextGrid, IntervalTier\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baf7330",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from soft_dtw_cuda import SoftDTW\n",
    "    use_soft_dtw_cuda = True\n",
    "except ImportError:\n",
    "    use_soft_dtw_cuda = False\n",
    "    print(\"‚ö†Ô∏è soft_dtw_cuda not found. Falling back to mock DTW.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61028d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein_distance(s1, s2):\n",
    "    s1 = s1.split()\n",
    "    s2 = s2.split()\n",
    "    m, n = len(s1), len(s2)\n",
    "    dp = np.zeros((m+1, n+1), dtype=int)\n",
    "    for i in range(m+1):\n",
    "        for j in range(n+1):\n",
    "            if i == 0: dp[i][j] = j\n",
    "            elif j == 0: dp[i][j] = i\n",
    "            elif s1[i-1] == s2[j-1]:\n",
    "                dp[i][j] = dp[i-1][j-1]\n",
    "            else:\n",
    "                dp[i][j] = 1 + min(dp[i-1][j], dp[i][j-1], dp[i-1][j-1])\n",
    "    return dp[m][n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8d1d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_dtw_cost(audio_frames, ipa_embeddings, gamma=0.1):\n",
    "    if use_soft_dtw_cuda:\n",
    "        import torch\n",
    "        x = torch.tensor(audio_frames[None, :, :], dtype=torch.float32).cuda()\n",
    "        y = torch.tensor(ipa_embeddings[None, :, :], dtype=torch.float32).cuda()\n",
    "        loss_fn = SoftDTW(use_cuda=True, gamma=gamma)\n",
    "        return float(loss_fn(x, y).item())\n",
    "    else:\n",
    "        T, D = audio_frames.shape\n",
    "        L, _ = ipa_embeddings.shape\n",
    "        cost_matrix = np.zeros((T, L))\n",
    "        for t in range(T):\n",
    "            for l in range(L):\n",
    "                cost_matrix[t, l] = np.linalg.norm(audio_frames[t] - ipa_embeddings[l])\n",
    "        return np.mean(np.min(cost_matrix, axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfab7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_vowel_formants(f1, f2, recognizer_ref, mfa_ref):\n",
    "    return {\n",
    "        \"target_match\": euclidean((f1, f2), recognizer_ref),\n",
    "        \"mfa_match\": euclidean((f1, f2), mfa_ref)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636e8e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_alignment(word, recognizer_ipa, mfa_ipa, f1, f2, \n",
    "                    recognizer_ref_formants, mfa_ref_formants,\n",
    "                    audio_frames, ipa_embeddings):\n",
    "    edit_distance = levenshtein_distance(recognizer_ipa, mfa_ipa)\n",
    "    dtw_cost = soft_dtw_cost(audio_frames, ipa_embeddings)\n",
    "    formant_result = compare_vowel_formants(f1, f2, recognizer_ref_formants, mfa_ref_formants)\n",
    "    flag = \"confident\"\n",
    "    if formant_result[\"mfa_match\"] < formant_result[\"target_match\"]:\n",
    "        flag = \"discrepant_vowel\"\n",
    "    elif edit_distance > 2:\n",
    "        flag = \"high_edit_distance\"\n",
    "    return {\n",
    "        \"word\": word,\n",
    "        \"recognizer_ipa\": recognizer_ipa,\n",
    "        \"mfa_ipa\": mfa_ipa,\n",
    "        \"edit_distance\": int(edit_distance),\n",
    "        \"soft_dtw_cost\": float(dtw_cost),\n",
    "        \"formant_agreement\": formant_result,\n",
    "        \"flag\": flag\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f35ca48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_scoring_dataframe(words, recognizer_ipas, mfa_ipas, formant_pairs,\n",
    "                            recognizer_refs, mfa_refs, audio_frame_list, ipa_embedding_list):\n",
    "    records = []\n",
    "    for i in range(len(words)):\n",
    "        record = score_alignment(\n",
    "            word=words[i],\n",
    "            recognizer_ipa=recognizer_ipas[i],\n",
    "            mfa_ipa=mfa_ipas[i],\n",
    "            f1=formant_pairs[i][0],\n",
    "            f2=formant_pairs[i][1],\n",
    "            recognizer_ref_formants=recognizer_refs[i],\n",
    "            mfa_ref_formants=mfa_refs[i],\n",
    "            audio_frames=audio_frame_list[i],\n",
    "            ipa_embeddings=ipa_embedding_list[i]\n",
    "        )\n",
    "        records.append(record)\n",
    "    return pd.DataFrame.from_records(records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418ed949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_textgrid(word, recognizer_ipa, mfa_ipa, flag, duration, output_dir=\"textgrids\"):\n",
    "    tg = TextGrid(minTime=0, maxTime=duration)\n",
    "    rec_tier = IntervalTier(name=\"Recognizer\", minTime=0, maxTime=duration)\n",
    "    mfa_tier = IntervalTier(name=\"MFA\", minTime=0, maxTime=duration)\n",
    "    flag_tier = IntervalTier(name=\"Flag\", minTime=0, maxTime=duration)\n",
    "    rec_tier.add(0, duration, recognizer_ipa)\n",
    "    mfa_tier.add(0, duration, mfa_ipa)\n",
    "    flag_tier.add(0, duration, flag)\n",
    "    tg.append(rec_tier)\n",
    "    tg.append(mfa_tier)\n",
    "    tg.append(flag_tier)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    path = os.path.join(output_dir, f\"{word}.TextGrid\")\n",
    "    tg.write(path)\n",
    "    return path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670b6f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_formant_scatter(formants, refs, labels):\n",
    "    f1s, f2s = zip(*formants)\n",
    "    ref1s, ref2s = zip(*refs)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.scatter(f2s, f1s, label=\"Measured\", color=\"blue\")\n",
    "    plt.scatter(ref2s, ref1s, label=\"Reference\", color=\"orange\", marker='x')\n",
    "    for i, label in enumerate(labels):\n",
    "        plt.text(f2s[i], f1s[i], label, fontsize=9)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.xlabel(\"F2\")\n",
    "    plt.ylabel(\"F1\")\n",
    "    plt.title(\"Formant Comparison\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
