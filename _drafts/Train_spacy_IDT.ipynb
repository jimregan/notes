{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train spacy IDT.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXyZmjveMocr"
      },
      "source": [
        "# \"Training spaCy 3 on IDT\"\n",
        "> \"Not going well so far\"\n",
        "\n",
        "- toc: false\n",
        "- branch: master\n",
        "- comments: true\n",
        "- categories: [spacy, idt]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9blVYqNcObhq"
      },
      "source": [
        "%%capture\n",
        "!pip install -U pip setuptools wheel\n",
        "!pip install thinc --pre\n",
        "!pip install -U spacy spacy-lookups-data"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tH27c_5MCuri",
        "outputId": "89502e1f-9b9b-45d8-e688-e01e5da0a76a"
      },
      "source": [
        "!python -m spacy project clone pipelines/tagger_parser_ud"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Cloned 'pipelines/tagger_parser_ud' from explosion/projects\u001b[0m\n",
            "/content/tagger_parser_ud\n",
            "\u001b[38;5;2m✔ Your project is now ready!\u001b[0m\n",
            "To fetch the assets, run:\n",
            "python -m spacy project assets /content/tagger_parser_ud\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ryAtsK5DZeP",
        "outputId": "748ba3b8-ceee-4706-b025-a7e8ed4fdb8e"
      },
      "source": [
        "%%writefile tagger_parser_ud/project.yml\n",
        "title: \"Part-of-speech Tagging & Dependency Parsing (Universal Dependencies)\"\n",
        "description: \"This project template lets you train a part-of-speech tagger, morphologizer and dependency parser from a [Universal Dependencies](https://universaldependencies.org/) corpus. It takes care of downloading the treebank, converting it to spaCy's format and training and evaluating the model. The template uses the [`UD_English-EWT`](https://github.com/UniversalDependencies/UD_English-EWT) treebank by default, but you can swap it out for any other available treebank. Just make sure to adjust the `lang` and treebank settings in the variables below. Use `xx` for multi-language if no language-specific tokenizer is available in spaCy. Note that multi-word tokens will be merged together when the corpus is converted since spaCy does not support multi-word token expansion.\"\n",
        "\n",
        "# Variables can be referenced across the project.yml using ${vars.var_name}\n",
        "vars:\n",
        "  config: \"default\"\n",
        "  lang: \"ga\"\n",
        "  treebank: \"UD_Irish-IDT\"\n",
        "  train_name: \"ga_idt-ud-train\"\n",
        "  dev_name: \"ga_idt-ud-dev\"\n",
        "  test_name: \"ga_idt-ud-test\"\n",
        "  package_name: \"ud_ga_idt\"\n",
        "  package_version: \"0.0.0\"\n",
        "  gpu: 0\n",
        "\n",
        "# These are the directories that the project needs. The project CLI will make\n",
        "# sure that they always exist.\n",
        "directories: [\"assets\", \"corpus\", \"training\", \"metrics\", \"configs\", \"packages\"]\n",
        "\n",
        "assets:\n",
        "  - url: \"https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ga.300.vec.gz\"\n",
        "    dest: \"assets/vectors.vec.gz\"\n",
        "    description: \"FastText vectors\"\n",
        "  - dest: \"assets/${vars.treebank}\"\n",
        "    git:\n",
        "      repo: \"https://github.com/UniversalDependencies/${vars.treebank}\"\n",
        "      branch: \"master\"\n",
        "      path: \"\"\n",
        "\n",
        "workflows:\n",
        "  all:\n",
        "    - preprocess\n",
        "    - vectors\n",
        "    - train\n",
        "    - evaluate\n",
        "    - package\n",
        "\n",
        "commands:\n",
        "  - name: preprocess\n",
        "    help: \"Convert the data to spaCy's format\"\n",
        "    script:\n",
        "      - \"mkdir -p corpus/${vars.treebank}\"\n",
        "      - \"python -m spacy convert assets/${vars.treebank}/${vars.train_name}.conllu corpus/${vars.treebank}/ --converter conllu --n-sents 10 --merge-subtokens --morphology\"\n",
        "      - \"python -m spacy convert assets/${vars.treebank}/${vars.dev_name}.conllu corpus/${vars.treebank}/ --converter conllu --n-sents 10 --merge-subtokens --morphology\"\n",
        "      - \"python -m spacy convert assets/${vars.treebank}/${vars.test_name}.conllu corpus/${vars.treebank}/ --converter conllu --n-sents 10 --merge-subtokens --morphology\"\n",
        "      - \"mv corpus/${vars.treebank}/${vars.train_name}.spacy corpus/${vars.treebank}/train.spacy\"\n",
        "      - \"mv corpus/${vars.treebank}/${vars.dev_name}.spacy corpus/${vars.treebank}/dev.spacy\"\n",
        "      - \"mv corpus/${vars.treebank}/${vars.test_name}.spacy corpus/${vars.treebank}/test.spacy\"\n",
        "    deps:\n",
        "      - \"assets/${vars.treebank}/${vars.train_name}.conllu\"\n",
        "      - \"assets/${vars.treebank}/${vars.dev_name}.conllu\"\n",
        "      - \"assets/${vars.treebank}/${vars.test_name}.conllu\"\n",
        "    outputs:\n",
        "      - \"corpus/${vars.treebank}/train.spacy\"\n",
        "      - \"corpus/${vars.treebank}/dev.spacy\"\n",
        "      - \"corpus/${vars.treebank}/test.spacy\"\n",
        "\n",
        "  - name: vectors\n",
        "    help: \"Convert, truncate and prune the vectors.\"\n",
        "    script:\n",
        "      - \"python -m spacy init vectors ga assets/vectors.vec.gz corpus/ga_vectors -n ga_fasttext_cc_vectors_md\"\n",
        "    deps:\n",
        "      - \"assets/vectors.vec.gz\"\n",
        "    outputs:\n",
        "      - \"corpus/ga_vectors\"\n",
        "\n",
        "  - name: train\n",
        "    help: \"Train ${vars.treebank}\"\n",
        "    script:\n",
        "      - \"python -m spacy train configs/${vars.config}.cfg --output training/${vars.treebank} --gpu-id ${vars.gpu} --paths.train corpus/${vars.treebank}/train.spacy --paths.dev corpus/${vars.treebank}/dev.spacy --nlp.lang=${vars.lang}\"\n",
        "    deps:\n",
        "      - \"corpus/${vars.treebank}/train.spacy\"\n",
        "      - \"corpus/${vars.treebank}/dev.spacy\"\n",
        "      - \"configs/${vars.config}.cfg\"\n",
        "      - \"corpus/ga_vectors\"\n",
        "    outputs:\n",
        "      - \"training/${vars.treebank}/model-best\"\n",
        "\n",
        "  - name: evaluate\n",
        "    help: \"Evaluate on the test data and save the metrics\"\n",
        "    script:\n",
        "      - \"python -m spacy evaluate ./training/${vars.treebank}/model-best ./corpus/${vars.treebank}/test.spacy --output ./metrics/${vars.treebank}.json --gpu-id ${vars.gpu}\"\n",
        "    deps:\n",
        "      - \"training/${vars.treebank}/model-best\"\n",
        "      - \"corpus/${vars.treebank}/test.spacy\"\n",
        "    outputs:\n",
        "      - \"metrics/${vars.treebank}.json\"\n",
        "\n",
        "  - name: package\n",
        "    help: \"Package the trained model so it can be installed\"\n",
        "    script:\n",
        "      - \"python -m spacy package training/${vars.treebank}/model-best packages --name ${vars.package_name} --version ${vars.package_version} --force\"\n",
        "    deps:\n",
        "      - \"training/${vars.treebank}/model-best\"\n",
        "    outputs_no_cache:\n",
        "      - \"packages/${vars.lang}_${vars.package_name}-${vars.package_version}/dist/en_${vars.package_name}-${vars.package_version}.tar.gz\"\n",
        "\n",
        "  - name: clean\n",
        "    help: \"Remove intermediate files\"\n",
        "    script:\n",
        "      - \"rm -rf training/*\"\n",
        "      - \"rm -rf metrics/*\"\n",
        "      - \"rm -rf corpus/*\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting tagger_parser_ud/project.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TP3p5fS3D1qF",
        "outputId": "ea4f0eff-bcd0-4cd6-9958-8e1f00d89966"
      },
      "source": [
        "!python -m spacy project assets /content/tagger_parser_ud"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;4mℹ Fetching 2 asset(s)\u001b[0m\n",
            "\u001b[38;5;2m✔ Downloaded asset /content/tagger_parser_ud/assets/vectors.vec.gz\u001b[0m\n",
            "\u001b[38;5;2m✔ Downloaded asset /content/tagger_parser_ud/assets/UD_Irish-IDT\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meFJmpaRU6E8",
        "outputId": "d40152e6-b184-47dc-a452-f5d579a1109a"
      },
      "source": [
        "!python -m spacy project run vectors /content/tagger_parser_ud"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\n",
            "================================== vectors ==================================\u001b[0m\n",
            "Running command: /usr/bin/python3 -m spacy init vectors ga assets/vectors.vec.gz corpus/ga_vectors -n ga_fasttext_cc_vectors_md\n",
            "\u001b[38;5;4mℹ Creating blank nlp object for language 'ga'\u001b[0m\n",
            "[2021-11-30 10:12:19,859] [INFO] Reading vectors from assets/vectors.vec.gz\n",
            "316836it [00:28, 11289.70it/s]\n",
            "[2021-11-30 10:12:48,165] [INFO] Loaded vectors from assets/vectors.vec.gz\n",
            "\u001b[38;5;2m✔ Successfully converted 316836 vectors\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved nlp object with vectors to output directory. You can now use\n",
            "the path to it in your config as the 'vectors' setting in [initialize].\u001b[0m\n",
            "/content/tagger_parser_ud/corpus/ga_vectors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65yySCQfFVsx",
        "outputId": "e2b9509d-ea36-423d-e07f-a9b6215c4fc8"
      },
      "source": [
        "%cd /content\n",
        "!python -m spacy project run preprocess tagger_parser_ud"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "\u001b[1m\n",
            "================================= preprocess =================================\u001b[0m\n",
            "Running command: mkdir -p corpus/UD_Irish-IDT\n",
            "Running command: /usr/bin/python3 -m spacy convert assets/UD_Irish-IDT/ga_idt-ud-train.conllu corpus/UD_Irish-IDT/ --converter conllu --n-sents 10 --merge-subtokens --morphology\n",
            "\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (401 documents):\n",
            "corpus/UD_Irish-IDT/ga_idt-ud-train.spacy\u001b[0m\n",
            "Running command: /usr/bin/python3 -m spacy convert assets/UD_Irish-IDT/ga_idt-ud-dev.conllu corpus/UD_Irish-IDT/ --converter conllu --n-sents 10 --merge-subtokens --morphology\n",
            "\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (46 documents):\n",
            "corpus/UD_Irish-IDT/ga_idt-ud-dev.spacy\u001b[0m\n",
            "Running command: /usr/bin/python3 -m spacy convert assets/UD_Irish-IDT/ga_idt-ud-test.conllu corpus/UD_Irish-IDT/ --converter conllu --n-sents 10 --merge-subtokens --morphology\n",
            "\u001b[38;5;4mℹ Grouping every 10 sentences into a document.\u001b[0m\n",
            "\u001b[38;5;2m✔ Generated output file (46 documents):\n",
            "corpus/UD_Irish-IDT/ga_idt-ud-test.spacy\u001b[0m\n",
            "Running command: mv corpus/UD_Irish-IDT/ga_idt-ud-train.spacy corpus/UD_Irish-IDT/train.spacy\n",
            "Running command: mv corpus/UD_Irish-IDT/ga_idt-ud-dev.spacy corpus/UD_Irish-IDT/dev.spacy\n",
            "Running command: mv corpus/UD_Irish-IDT/ga_idt-ud-test.spacy corpus/UD_Irish-IDT/test.spacy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-q8R-yL3GiO5",
        "outputId": "bb024bbb-8362-47c8-f5ed-7357ffed1536"
      },
      "source": [
        "!python -m spacy project run train tagger_parser_ud"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m\n",
            "=================================== train ===================================\u001b[0m\n",
            "Running command: /usr/bin/python3 -m spacy train configs/default.cfg --output training/UD_Irish-IDT --gpu-id 0 --paths.train corpus/UD_Irish-IDT/train.spacy --paths.dev corpus/UD_Irish-IDT/dev.spacy --nlp.lang=ga\n",
            "\u001b[38;5;2m✔ Created output directory: training/UD_Irish-IDT\u001b[0m\n",
            "\u001b[38;5;4mℹ Saving to output directory: training/UD_Irish-IDT\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/spacy/__main__.py\", line 4, in <module>\n",
            "    setup_cli()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/spacy/cli/_util.py\", line 71, in setup_cli\n",
            "    command(prog_name=COMMAND)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 829, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 782, in main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 1259, in invoke\n",
            "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 1066, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/click/core.py\", line 610, in invoke\n",
            "    return callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/typer/main.py\", line 500, in wrapper\n",
            "    return callback(**use_params)  # type: ignore\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/spacy/cli/train.py\", line 45, in train_cli\n",
            "    train(config_path, output_path, use_gpu=use_gpu, overrides=overrides)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/spacy/cli/train.py\", line 67, in train\n",
            "    setup_gpu(use_gpu)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/spacy/cli/_util.py\", line 554, in setup_gpu\n",
            "    require_gpu(use_gpu)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/thinc/util.py\", line 187, in require_gpu\n",
            "    raise ValueError(\"GPU is not accessible. Was the library installed correctly?\")\n",
            "ValueError: GPU is not accessible. Was the library installed correctly?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wig6uL9M0oov",
        "outputId": "fd3dbf6e-1add-4ea2-fb4b-c395d7edf071"
      },
      "source": [
        "!apt install git-lfs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  git-lfs\n",
            "0 upgraded, 1 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 2,129 kB of archives.\n",
            "After this operation, 7,662 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 git-lfs amd64 2.3.4-1 [2,129 kB]\n",
            "Fetched 2,129 kB in 1s (1,931 kB/s)\n",
            "Selecting previously unselected package git-lfs.\n",
            "(Reading database ... 155219 files and directories currently installed.)\n",
            "Preparing to unpack .../git-lfs_2.3.4-1_amd64.deb ...\n",
            "Unpacking git-lfs (2.3.4-1) ...\n",
            "Setting up git-lfs (2.3.4-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMvOJDOY2CvP"
      },
      "source": [
        "%%capture\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoEbpnA-61DJ"
      },
      "source": [
        "!transformers-cli login\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}