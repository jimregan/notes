Job started on deepspeech at Fri Aug  8 13:40:51 CEST 2025
Using GPU(s): 0
local/chain/run_tdnn.sh --train-set train_vosk --gmm tri4a
local/chain/run_ivector_common.sh: computing a subset of data to train the diagonal UBM.
utils/data/subset_data_dir.sh: reducing #utt from 306257 to 76564
local/chain/run_ivector_common.sh: computing a PCA transform from the data.
steps/online/nnet2/get_pca_transform.sh --cmd run.pl --splice-opts --left-context=3 --right-context=3 --max-utts 10000 --subsample 2 exp/chain/diag_ubm/train_vosk_subset exp/chain/pca_transform
Done estimating PCA transform in exp/chain/pca_transform
local/chain/run_ivector_common.sh: training the diagonal UBM.
steps/online/nnet2/train_diag_ubm.sh --cmd run.pl --nj 10 --num-frames 700000 --num-threads 8 exp/chain/diag_ubm/train_vosk_subset 512 exp/chain/pca_transform exp/chain/diag_ubm
steps/online/nnet2/train_diag_ubm.sh: Directory exp/chain/diag_ubm already exists. Backing up diagonal UBM in exp/chain/diag_ubm/backup.WEi
steps/online/nnet2/train_diag_ubm.sh: initializing model from E-M in memory, 
steps/online/nnet2/train_diag_ubm.sh: starting from 256 Gaussians, reaching 512;
steps/online/nnet2/train_diag_ubm.sh: for 20 iterations, using at most 700000 frames of data
Getting Gaussian-selection info
steps/online/nnet2/train_diag_ubm.sh: will train for 4 iterations, in parallel over
steps/online/nnet2/train_diag_ubm.sh: 10 machines, parallelized with 'run.pl'
steps/online/nnet2/train_diag_ubm.sh: Training pass 0
steps/online/nnet2/train_diag_ubm.sh: Training pass 1
steps/online/nnet2/train_diag_ubm.sh: Training pass 2
steps/online/nnet2/train_diag_ubm.sh: Training pass 3
local/chain/run_ivector_common.sh: training the iVector extractor
steps/online/nnet2/train_ivector_extractor.sh --cmd run.pl --nj 2 --ivector-dim 40 data/train_vosk exp/chain/diag_ubm exp/chain/extractor
steps/online/nnet2/train_ivector_extractor.sh: Directory exp/chain/extractor already exists. Backing up iVector extractor in exp/chain/extractor/backup.CnU
steps/online/nnet2/train_ivector_extractor.sh: doing Gaussian selection and posterior computation
Accumulating stats (pass 0)
Summing accs (pass 0)
Updating model (pass 0)
Accumulating stats (pass 1)
Summing accs (pass 1)
Updating model (pass 1)
Accumulating stats (pass 2)
Summing accs (pass 2)
Updating model (pass 2)
Accumulating stats (pass 3)
Summing accs (pass 3)
Updating model (pass 3)
Accumulating stats (pass 4)
Summing accs (pass 4)
Updating model (pass 4)
Accumulating stats (pass 5)
Summing accs (pass 5)
Updating model (pass 5)
Accumulating stats (pass 6)
Summing accs (pass 6)
Updating model (pass 6)
Accumulating stats (pass 7)
Summing accs (pass 7)
Updating model (pass 7)
Accumulating stats (pass 8)
Summing accs (pass 8)
Updating model (pass 8)
Accumulating stats (pass 9)
Summing accs (pass 9)
Updating model (pass 9)
utils/data/modify_speaker_info.sh: copied data from data/train_vosk to exp/chain/ivectors_train_vosk/train_vosk_max2, number of speakers changed from 945 to 153580
utils/validate_data_dir.sh: text contains 222802 lines with non-printable characters
Job finished at Fri Aug  8 15:21:20 CEST 2025
