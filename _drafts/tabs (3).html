
<html>
<head>
</head>
<body>
<a href="http://localhost:8080/projects/6/data?tab=5">localhost
</a>
<br/>
<a href="https://api.labelstud.io/api-reference/introduction/getting-started">Getting started ‚Äî API Reference | Label Studio
</a>
<br/>
<a href="https://github.com/kyutai-labs/moshi?tab=readme-ov-file">kyutai-labs/moshi
</a>
<br/>
<a href="https://kyutai.org/Moshi.pdf">Moshi.pdf
</a>
<br/>
<a href="http://130.237.3.107:8080/projects/1/data?tab=1&task=22">Label Studio
</a>
<br/>
<a href="http://130.237.3.107:8080/projects/8/data?tab=8&task=110">Label Studio
</a>
<br/>
<a href="http://130.237.3.107:8080/projects/5/data?tab=5&task=71">Label Studio
</a>
<br/>
<a href="http://130.237.3.107:8080/projects/6/data?tab=6&task=87">Label Studio
</a>
<br/>
<a href="http://130.237.3.107:8080/projects/5/data?tab=5">Label Studio
</a>
<br/>
<a href="http://130.237.3.107:8080/projects/6/data?tab=6&task=88">Label Studio
</a>
<br/>
<a href="http://130.237.3.107:8080/projects/3/data?tab=3">Label Studio
</a>
<br/>
<a href="http://130.237.3.107:8080/projects/5/data?tab=5&task=73">Label Studio
</a>
<br/>
<a href="http://130.237.3.107:8080/projects/6/data?tab=6&task=88">Label Studio
</a>
<br/>
<a href="http://130.237.3.107:8080/projects/7/data?tab=7&task=102">Label Studio
</a>
<br/>
<a href="https://sail.usc.edu/publications/files/eyben-preprinttaffc-2015.pdf">TAFFC2457417.pdf
</a>
<br/>
<a href="https://github.com/descriptinc/descript-audio-codec?tab=readme-ov-file">descriptinc/descript-audio-codec: State-of-the-art audio codec with 90x compression factor. Supports 44.1kHz, 24kHz, and 16kHz mono/stereo audio.
</a>
<br/>
<a href="https://github.com/phonlab-tcd/cula4-cruinniu-na-nog-2021?tab=readme-ov-file">phonlab-tcd/cula4-cruinniu-na-nog-2021
</a>
<br/>
<a href="https://github.com/phonlab-tcd/caint-ros-muc-im2-scans/">phonlab-tcd/caint-ros-muc-im2-scans
</a>
<br/>
<a href="https://github.com/phonlab-tcd/sgeilini_na_finne/tree/main/html">sgeilini_na_finne/html at main ¬∑ phonlab-tcd/sgeilini_na_finne
</a>
<br/>
<a href="https://github.com/cjhutto/vaderSentiment">cjhutto/vaderSentiment: VADER Sentiment Analysis. VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media, and works well on texts from other domains.
</a>
<br/>
<a href="https://huggingface.co/models?other=speech-emotion-recognition">Models - Hugging Face
</a>
<br/>
<a href="https://huggingface.co/spaces/3loi/WavLM-SER-Multi-Baseline-Odyssey2024">WavLM SER Multi Baseline Odyssey2024 - a Hugging Face Space by 3loi
</a>
<br/>
<a href="https://huggingface.co/3loi/SER-Odyssey-Baseline-WavLM-Dominance">3loi/SER-Odyssey-Baseline-WavLM-Dominance ¬∑ Hugging Face
</a>
<br/>
<a href="https://huggingface.co/dkounadis/wav2small">dkounadis/wav2small ¬∑ Hugging Face
</a>
<br/>
<a href="https://huggingface.co/3loi/SER-Odyssey-Baseline-WavLM-Valence">3loi/SER-Odyssey-Baseline-WavLM-Valence ¬∑ Hugging Face
</a>
<br/>
<a href="https://huggingface.co/CAiRE/SER-wav2vec2-large-xlsr-53-eng-zho-adults">CAiRE/SER-wav2vec2-large-xlsr-53-eng-zho-adults ¬∑ Hugging Face
</a>
<br/>
<a href="https://huggingface.co/thegenerativegeneration/emotion2vec_base_finetuned">thegenerativegeneration/emotion2vec_base_finetuned ¬∑ Hugging Face
</a>
<br/>
<a href="https://huggingface.co/FarhadMadadzade/wav2vec2-large-xlsr-53-english-ser-cosine">FarhadMadadzade/wav2vec2-large-xlsr-53-english-ser-cosine ¬∑ Hugging Face
</a>
<br/>
<a href="https://huggingface.co/m3hrdadfi/ser">m3hrdadfi/ser ¬∑ Hugging Face
</a>
<br/>
<a href="https://huggingface.co/google-t5/t5-base">google-t5/t5-base ¬∑ Hugging Face
</a>
<br/>
<a href="https://arxiv.org/pdf/1611.04558">1611.04558
</a>
<br/>
<a href="https://github.com/shivammehta25/Match-TTSG">shivammehta25/Match-TTSG
</a>
<br/>
<a href="https://github.com/shivammehta25/Matcha-TTS">shivammehta25/Matcha-TTS: [ICASSP 2024] üçµ Matcha-TTS: A fast TTS architecture with conditional flow matching
</a>
<br/>
<a href="https://shivammehta25.github.io/Matcha-TTS/">Matcha-TTS: A fast TTS architecture with conditional flow matching | Matcha-TTS
</a>
<br/>
<a href="https://github.com/phonlab-tcd/lara/blob/master/Aesop/An_Bhean_agus_An_Madra_Rua/corpus/An_Bhean_agus_An_Madra_Rua.txt">lara/Aesop/An_Bhean_agus_An_Madra_Rua/corpus/An_Bhean_agus_An_Madra_Rua.txt at master ¬∑ phonlab-tcd/lara
</a>
<br/>
<a href="https://github.com/phonlab-tcd/mfa_models">phonlab-tcd/mfa_models
</a>
<br/>
<a href="https://kyutai.org/Moshi.pdf">Moshi.pdf
</a>
<br/>
<a href="https://github.com/xinjli/allosaurus">xinjli/allosaurus: Allosaurus is a pretrained universal phone recognizer for more than 2000 languages
</a>
<br/>
<a href="https://scikit-learn.org/stable/modules/neighbors.html">1.6. Nearest Neighbors ‚Äî scikit-learn 1.5.2 documentation
</a>
<br/>
<a href="https://www.isca-archive.org/interspeech_2024/index.html">ISCA Archive
</a>
<br/>
<a href="https://github.com/StevenVdEeckt/unsupervised-ocl-for-asr">StevenVdEeckt/unsupervised-ocl-for-asr: Supplementary material to the paper "Unsupervised Online Continual Learning for Automatic Speech Recognition", accepted for Interspeech 2024.
</a>
<br/>
<a href="https://www.isca-archive.org/interspeech_2024/prabhu24_interspeech.pdf">prabhu24_interspeech.pdf
</a>
<br/>
<a href="https://www.isca-archive.org/interspeech_2024/tannander24_interspeech.pdf">tannander24_interspeech.pdf
</a>
<br/>
<a href="https://www.isca-archive.org/interspeech_2024/yang24_interspeech.pdf">yang24_interspeech.pdf
</a>
<br/>
<a href="https://github.com/iooops/G2PA">iooops/G2PA
</a>
<br/>
<a href="https://github.com/iooops/G2PA/blob/main/hubert_extractor.py">G2PA/hubert_extractor.py at main ¬∑ iooops/G2PA
</a>
<br/>
<a href="https://github.com/kakaobrain/g2pm">kakaobrain/g2pm: A Neural Grapheme-to-Phoneme Conversion Package for Mandarin Chinese Based on a New Open Benchmark Dataset
</a>
<br/>
<a href="https://github.com/StevenVdEeckt/unsupervised-ocl-for-asr/tree/main/models/conf/training">unsupervised-ocl-for-asr/models/conf/training at main ¬∑ StevenVdEeckt/unsupervised-ocl-for-asr
</a>
<br/>
<a href="https://www.google.com/search?q=fine+tune+t5+multiple+new+tasks&rlz=1C5GCEM_enSE990SE991&oq=fine+tune+t5+multiple+new+tasks&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIKCAEQABiABBiiBDIKCAIQABiABBiiBDIKCAMQABiABBiiBNIBCDYzNzBqMGo3qAIAsAIA&sourceid=chrome&ie=UTF-8">fine tune t5 multiple new tasks - Google Search
</a>
<br/>
<a href="https://medium.com/nlplanet/a-full-guide-to-finetuning-t5-for-text2text-and-building-a-demo-with-streamlit-c72009631887">A Full Guide to Finetuning T5 for Text2Text and Building a Demo with Streamlit | by Fabio Chiusano | NLPlanet | Medium
</a>
<br/>
<a href="https://runeberg.org/">Project Runeberg
</a>
<br/>
<a href="https://www.gutenberg.org/ebooks/author/9475">Books by Hedin, Sven Anders (sorted by popularity) - Project Gutenberg
</a>
<br/>
<a href="https://runeberg.org/admin/">About Project Runeberg
</a>
<br/>
<a href="https://runeberg.org/admin/scannb.html">Scanned by Nasjonalbiblioteket (About Project Runeberg)
</a>
<br/>
<a href="https://www.google.com/search?q=modernisation+of+swedish+texts&rlz=1C5GCEM_enSE990SE991&oq=modernisation+of+swedish+texts&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIKCAEQABiABBiiBDIKCAIQABiABBiiBDIKCAMQABiABBiiBNIBCDYxNDFqMGo3qAIAsAIA&sourceid=chrome&ie=UTF-8">modernisation of swedish texts - Google Search
</a>
<br/>
<a href="https://www.uu.se/en/news/2023/2023-05-10-the-ai-tool-quickly-became-good-at-swedish">The AI tool quickly became good at Swedish - Uppsala University
</a>
<br/>
<a href="https://ep.liu.se/ecp/087/005/ecp1387005.pdf">An SMT Approach to Automatic Annotation of Historical Text
</a>
<br/>
<a href="https://www.academia.edu/57154394/Normalisation_of_historical_text_using_context_sensitive_weighted_Levenshtein_distance_and_compound_splitting">(PDF) Normalisation of historical text using context-sensitive weighted Levenshtein distance and compound splitting | Eva Pettersson - Academia.edu
</a>
<br/>
<a href="https://www.academia.edu/57154394/Normalisation_of_historical_text_using_context_sensitive_weighted_Levenshtein_distance_and_compound_splitting">(PDF) Normalisation of historical text using context-sensitive weighted Levenshtein distance and compound splitting | Eva Pettersson - Academia.edu
</a>
<br/>
<a href="https://spraakbanken.gu.se/resurser/suc3#:~:text=Stockholm%2DUme%C3%A5%2Dkorpus%20(SUC,och%20texter%20med%20olika%20stilniv%C3%A5er.">SUC 3.0 | The Language Bank Text
</a>
<br/>
<a href="https://litteraturbanken.se/f%C3%B6rfattare/DodgsonCL/titlar/Alices%C3%84fventyr/sida/1/faksimil">Alice‚Äôs √§fventyr i sagolandet sida 1 faksimil | Litteraturbanken
</a>
<br/>
<a href="https://runeberg.org/aliceisago/">Alice's √§ventyr i sagolandet
</a>
<br/>
<a href="https://runeberg.org/aliceisago/0016.html">2 (Alice's √§ventyr i sagolandet)
</a>
<br/>
<a href="https://sv.wikisource.org/wiki/Alices_%C3%A4ventyr_i_underlandet/Kapitel_01">Alice's Adventures in Wonderland/Chapter 01 - Wikisource
</a>
<br/>
<a href="https://www.google.com/search?q=the+little+prince&rlz=1C5GCEM_enSE990SE991&oq=the+little+prince&gs_lcrp=EgZjaHJvbWUqBwgAEAAYjwIyBwgAEAAYjwIyEAgBEC4YkQIY1AIYgAQYigUyEAgCEC4YkQIY1AIYgAQYigUyDQgDEAAYkQIYgAQYigUyBwgEEAAYgAQyBwgFEAAYgAQyCggGEC4Y1AIYgAQyCggHEC4Y1AIYgAQyBwgIEAAYgAQyBwgJEAAYgATSAQg0NjE5ajBqN6gCALACAA&sourceid=chrome&ie=UTF-8">the little prince - Google Search
</a>
<br/>
<a href="https://www.fadedpage.com/">fadedpage.com
</a>
<br/>
<a href="https://www.gutenberg.org/browse/languages/sv">Browse By Language: Swedish | Project Gutenberg
</a>
<br/>
<a href="https://www.gutenberg.org/browse/authors/e#a45725">Browse By Author: E | Project Gutenberg
</a>
<br/>
<a href="https://www.gutenberg.org/ebooks/48269">Havsboken by Anna Lenah Elgstr√∂m | Project Gutenberg
</a>
<br/>
<a href="https://www.gutenberg.org/browse/authors/c#a2029">Browse By Author: C | Project Gutenberg
</a>
<br/>
<a href="https://en.wikipedia.org/wiki/Minna_Canth">Minna Canth - Wikipedia
</a>
<br/>
<a href="https://www.gutenberg.org/cache/epub/9951/pg9951-images.html">The Project Gutenberg eBook of Arbetets Herrav√§lde, by Andrew Carnegie
</a>
<br/>
<a href="https://librivox.org/the-empire-of-business-by-andrew-carnegie/">LibriVox
</a>
<br/>
<a href="https://commons.wikimedia.org/wiki/File:The_empire_of_business_(IA_empireofbusiness00carn).pdf">File:The empire of business (IA empireofbusiness00carn).pdf - Wikimedia Commons
</a>
<br/>
<a href="https://github.com/showlab/Show-o?tab=readme-ov-file">showlab/Show-o: Repository for Show-o, One Single Transformer to Unify Multimodal Understanding and Generation.
</a>
<br/>
<a href="https://github.com/roedoejet/g2p/blob/main/g2p/mappings/langs/eng/eng_ipa_to_arpabet.json">g2p/g2p/mappings/langs/eng/eng_ipa_to_arpabet.json at main ¬∑ roedoejet/g2p
</a>
<br/>
<a href="https://readalong-studio.mothertongues.org/#/editor">ReadAlong-Studio for Interactive Storytelling
</a>
<br/>
<a href="https://readalong-studio.mothertongues.org/#/">ReadAlong-Studio for Interactive Storytelling
</a>
<br/>
<a href="https://readalong-studio.mothertongues.org/#/">ReadAlong-Studio for Interactive Storytelling
</a>
<br/>
<a href="https://github.com/drmfinlay/pyjsgf/blob/master/examples/dictation%20grammar%20example.py">pyjsgf/examples/dictation grammar example.py at master ¬∑ drmfinlay/pyjsgf
</a>
<br/>
<a href="https://github.com/kensho-technologies/pyctcdecode/blob/main/pyctcdecode/decoder.py">pyctcdecode/pyctcdecode/decoder.py at main ¬∑ kensho-technologies/pyctcdecode
</a>
<br/>
<a href="https://www.wavlab.org/activities/2024/xeus/">WAVLab | XEUS - Towards Robust Speech Representation Learning for Thousands of Languages
</a>
<br/>
<a href="https://huggingface.co/espnet/owsm_v3.1_ebf">espnet/owsm_v3.1_ebf ¬∑ Hugging Face
</a>
<br/>
<a href="https://www.wavlab.org/activities/2024/owsm/">WAVLab | Open Whisper-style Speech Models (OWSM)
</a>
<br/>
<a href="https://huggingface.co/pyf98/owsm_ctc_v3.1_1B">pyf98/owsm_ctc_v3.1_1B ¬∑ Hugging Face
</a>
<br/>
<a href="https://github.com/speechbrain/speechbrain/pull/2714">Gammatone learnable filterbanks by naspert ¬∑ Pull Request #2714 ¬∑ speechbrain/speechbrain
</a>
<br/>
<a href="https://github.com/speechbrain/speechbrain/pull/2696/files#diff-08c60df427a66b8146ac2fedc01c1970f5bbebc50e0404019315d55f12c51c03">Tokotron: Tokenized TTS by flexthink ¬∑ Pull Request #2696 ¬∑ speechbrain/speechbrain
</a>
<br/>
<a href="https://github.com/speechbrain/speechbrain/pull/2689/commits/ba91d6f72475bba28b4feb072dc67a7acc143ad2">Voice analysis functions by pplantinga ¬∑ Pull Request #2689 ¬∑ speechbrain/speechbrain
</a>
<br/>
<a href="https://github.com/hubertsiuzdak/snac">hubertsiuzdak/snac: Multi-Scale Neural Audio Codec (SNAC) compresses audio into discrete codes at a low bitrate
</a>
<br/>
<a href="https://github.com/speechbrain/speechbrain/pull/2550">Add recipe for audio/speech LLM (ltu-as with llama3) by BenoitWang ¬∑ Pull Request #2550 ¬∑ speechbrain/speechbrain
</a>
<br/>
<a href="https://speechbrain.readthedocs.io/en/latest/API/speechbrain.k2_integration.lattice_decoder.html">speechbrain.k2_integration.lattice_decoder module ‚Äî SpeechBrain 0.5.0 documentation
</a>
<br/>
<a href="https://arxiv.org/pdf/1612.02695">1612.02695
</a>
<br/>
<a href="https://colab.research.google.com/drive/1qbHUhNZUX7AYEpqnZyf29Lrz2IPHBGlX?usp=sharing#scrollTo=r9xffN-eMlUM">k2.ipynb - Colab
</a>
<br/>
<a href="https://colab.research.google.com/github/speechbrain/speechbrain/blob/develop/docs/tutorials/tasks/voice-activity-detection.ipynb#scrollTo=SSOeT58mQM1m">voice-activity-detection.ipynb - Colab
</a>
<br/>
<a href="https://github.com/showlab/Show-o?tab=readme-ov-file">showlab/Show-o: Repository for Show-o, One Single Transformer to Unify Multimodal Understanding and Generation.
</a>
<br/>
<a href="https://huggingface.co/speechbrain/vad-crdnn-libriparty">speechbrain/vad-crdnn-libriparty ¬∑ Hugging Face
</a>
<br/>
<a href="https://github.com/huggingface/parler-tts?tab=readme-ov-file#training">huggingface/parler-tts: Inference and training library for high-quality TTS models.
</a>
<br/>
<a href="https://github.com/ylacombe/scripts_and_notebooks/blob/main/Fine_Tune_W2V2_BERT_on_CV16_Mongolian.ipynb">scripts_and_notebooks/Fine_Tune_W2V2_BERT_on_CV16_Mongolian.ipynb at main ¬∑ ylacombe/scripts_and_notebooks
</a>
<br/>
<a href="https://huggingface.co/posts/reach-vb/328638870427201">@reach-vb on Hugging Face: "What an eventful day in Open Source LLMs today: Mistral released Codestral‚Ä¶"
</a>
<br/>
<a href="https://huggingface.co/mistralai/Mamba-Codestral-7B-v0.1">mistralai/Mamba-Codestral-7B-v0.1 ¬∑ Hugging Face
</a>
<br/>
<a href="https://huggingface.co/HuggingFaceTB/SmolLM-135M">HuggingFaceTB/SmolLM-135M ¬∑ Hugging Face
</a>
<br/>
<a href="https://github.com/rhasspy/piper?tab=readme-ov-file">rhasspy/piper: A fast, local neural text to speech system
</a>
<br/>
<a href="https://github.com/rhasspy/piper/blob/master/notebooks/pretrained_models.json">piper/notebooks/pretrained_models.json at master ¬∑ rhasspy/piper
</a>
<br/>
<a href="https://huggingface.co/datasets/rhasspy/voice-datasets">rhasspy/voice-datasets ¬∑ Datasets at Hugging Face
</a>
<br/>
<a href="https://github.com/rhasspy/piper/blob/master/TRAINING.md">piper/TRAINING.md at master ¬∑ rhasspy/piper
</a>
<br/>
<a href="https://huggingface.co/datasets/rhasspy/piper-checkpoints/tree/main">rhasspy/piper-checkpoints at main
</a>
<br/>
<a href="https://huggingface.co/csukuangfj/vits-piper-pl_PL-gosia-medium/blob/main/MODEL_CARD">MODEL_CARD ¬∑ csukuangfj/vits-piper-pl_PL-gosia-medium at main
</a>
<br/>
<a href="https://www.cstr.ed.ac.uk/downloads/">CSTR Downloads
</a>
<br/>
<a href="https://datashare.ed.ac.uk/handle/10283/561">Repeated Harvard Sentence Prompts corpus version 0.5
</a>
<br/>
<a href="https://www.cstr.ed.ac.uk/projects/eustace/design.html">Design of the sentence materials
</a>
<br/>
<a href="https://www.cstr.ed.ac.uk/projects/blizzard/">Data and tools related to the Blizzard Challenge
</a>
<br/>
<a href="https://zenodo.org/records/7560290">Ressources for End-to-End French Text-to-Speech Blizzard challenge
</a>
<br/>
<a href="https://datashare.ed.ac.uk/handle/10283/347">Hurricane natural speech corpus
</a>
<br/>
<a href="https://groups.inf.ed.ac.uk/ami/download/">AMI Corpus Download
</a>
<br/>
<a href="https://www.openslr.org/resources.php">openslr.org
</a>
<br/>
<a href="https://www.openslr.org/83/">openslr.org
</a>
<br/>
<a href="https://github.com/google/language-resources/issues">Issues ¬∑ google/language-resources
</a>
<br/>
<a href="https://www.linguistics.ucsb.edu/research/santa-barbara-corpus">Santa Barbara Corpus of Spoken American English | Department of Linguistics - UC Santa Barbara
</a>
<br/>
<a href="https://www.openslr.org/152/">openslr.org
</a>
<br/>
<a href="https://www.openslr.org/148/">openslr.org
</a>
<br/>
<a href="https://www.openslr.org/147/">openslr.org
</a>
<br/>
<a href="https://www.openslr.org/142/">openslr.org
</a>
<br/>
<a href="https://huggingface.co/datasets/czyzi0/luna-speech-dataset/viewer/default/train?p=1">czyzi0/luna-speech-dataset ¬∑ Datasets at Hugging Face
</a>
<br/>
<a href="https://zasobynauki.pl/zasoby/korpus-nagran-probek-mowy-do-celow-budowy-modeli-akustycznych-dla-automatycznego-rozpoznawania-mowy,56412/">Korpus nagra≈Ñ pr√≥bek mowy do cel√≥w budowy modeli akustycznych dla automatycznego rozpoznawania mowy w jƒôzyku polskim, cz. 8 - AZON
</a>
<br/>
<a href="https://www.openslr.org/146/">openslr.org
</a>
<br/>
<a href="https://www.openslr.org/139/">openslr.org
</a>
<br/>
<a href="https://www.openslr.org/136/">openslr.org
</a>
<br/>
<a href="https://www.openslr.org/98/">openslr.org
</a>
<br/>
<a href="https://pytorch.org/audio/stable/datasets.html">torchaudio.datasets ‚Äî Torchaudio 2.4.0 documentation
</a>
<br/>
<a href="https://pytorch.org/docs/stable/hub.html">torch.hub ‚Äî PyTorch 2.4 documentation
</a>
<br/>
<a href="https://github.com/jimregan/Matcha-TTS/blob/main/matcha/utils/rich_utils.py">Matcha-TTS/matcha/utils/rich_utils.py at main ¬∑ jimregan/Matcha-TTS
</a>
<br/>
<a href="https://github.com/shivammehta25/Matcha-TTS/blob/77804265f877b0c42f13cfdece6541dde7838090/matcha/utils/get_durations_from_trained_model.py">Matcha-TTS/matcha/utils/get_durations_from_trained_model.py at 77804265f877b0c42f13cfdece6541dde7838090 ¬∑ shivammehta25/Matcha-TTS
</a>
<br/>
<a href="https://github.com/nateraw/hf-hub-lightning/blob/main/examples/hf_hub_lightning_demo.ipynb">hf-hub-lightning/examples/hf_hub_lightning_demo.ipynb at main ¬∑ nateraw/hf-hub-lightning
</a>
<br/>
<a href="https://github.com/pytorch/audio/issues/1723">Working with ".webm" files ¬∑ Issue #1723 ¬∑ pytorch/audio
</a>
<br/>
<a href="https://stackoverflow.com/questions/73029952/error-in-librosa-loadpath-webm-runtimeerror-file-contains-data-in-an-unknow">python - Error in librosa.load('path.webm') RuntimeError: File contains data in an unknown format - Stack Overflow
</a>
<br/>
<a href="https://pytorch.org/audio/main/generated/torchaudio.utils.sox_utils.html#torchaudio.utils.sox_utils.list_read_formats">sox_utils ‚Äî Torchaudio 2.5.0.dev20241001 documentation
</a>
<br/>
<a href="https://pytorch.org/audio/main/generated/torchaudio.utils.ffmpeg_utils.html#torchaudio.utils.ffmpeg_utils.get_audio_decoders">ffmpeg_utils ‚Äî Torchaudio 2.5.0.dev20241001 documentation
</a>
<br/>
<a href="https://pytorch.org/audio/main/generated/torchaudio.utils.sox_utils.html">sox_utils ‚Äî Torchaudio 2.5.0.dev20241001 documentation
</a>
<br/>
<a href="https://peps.python.org/pep-0263/">PEP 263 ‚Äì Defining Python Source Code Encodings | peps.python.org
</a>
<br/>
<a href="https://github.com/shivammehta25/Matcha-TTS/issues/94">the motivation for inserting blank IDs between the input IPA-ids? ¬∑ Issue #94 ¬∑ shivammehta25/Matcha-TTS
</a>
<br/>
<a href="https://github.com/shivammehta25/Matcha-TTS/pull/99">Dataset download/conversion by jimregan ¬∑ Pull Request #99 ¬∑ shivammehta25/Matcha-TTS
</a>
<br/>
<a href="https://github.com/gradio-app/gradio/issues/6815">AttributeError: module 'gradio' has no attribute 'Box' ¬∑ Issue #6815 ¬∑ gradio-app/gradio
</a>
<br/>
<a href="https://github.com/shivammehta25/Matcha-TTS/issues/66">Compare to VoiceFlow TTS ¬∑ Issue #66 ¬∑ shivammehta25/Matcha-TTS
</a>
<br/>
<a href="https://github.com/shivammehta25/Matcha-TTS/issues/89">Matcha-TTS app error: symbol_id = _symbol_to_id[symbol] KeyError: '(' ¬∑ Issue #89 ¬∑ shivammehta25/Matcha-TTS
</a>
<br/>
<a href="https://github.com/shivammehta25/Matcha-TTS/issues/91">Is there any experiment on Chinese data set. ¬∑ Issue #91 ¬∑ shivammehta25/Matcha-TTS
</a>
<br/>
<a href="https://github.com/UlutSoftLLC/MamtilTTS/commit/9c7460b8d98995e3c6544c68d8a512350da15700#diff-7648f5f4cce4bf01d02de43f8c5f6f2130b787baece0cf6338210496d8bdfcdc">save changes ¬∑ UlutSoftLLC/MamtilTTS@9c7460b
</a>
<br/>
<a href="https://huggingface.co/projecte-aina/matxa-tts-cat-multiaccent">projecte-aina/matxa-tts-cat-multiaccent ¬∑ Hugging Face
</a>
<br/>
<a href="https://huggingface.co/spaces/projecte-aina/matxa-alvocat-tts-ca/tree/main">projecte-aina/matxa-alvocat-tts-ca at main
</a>
<br/>
<a href="https://github.com/langtech-bsc/Matcha-TTS/commits/multilang/">Commits ¬∑ langtech-bsc/Matcha-TTS
</a>
<br/>
<a href="https://github.com/langtech-bsc/Matcha-TTS/commit/450b99003619a6bde06b1f54d8a18c4a3d4537e0">add config file for multilanguage experiment ¬∑ langtech-bsc/Matcha-TTS@450b990
</a>
<br/>
<a href="https://github.com/langtech-bsc/Matcha-TTS/commit/450b99003619a6bde06b1f54d8a18c4a3d4537e0#diff-b335630551682c19a781afebcf4d07bf978fb1f8ac04c6bf87428ed5106870f5R27">add config file for multilanguage experiment ¬∑ langtech-bsc/Matcha-TTS@450b990
</a>
<br/>
<a href="https://github.com/langtech-bsc/Matcha-TTS/commit/4d3558d45bfd7e8207b6eca16dc53668e20d0b52">add inference script ¬∑ langtech-bsc/Matcha-TTS@4d3558d
</a>
<br/>
<a href="https://github.com/langtech-bsc/Matcha-TTS/commits/vocos">Commits ¬∑ langtech-bsc/Matcha-TTS
</a>
<br/>
<a href="https://github.com/langtech-bsc/Matcha-TTS/commits/dev-cat-hf/">Commits ¬∑ langtech-bsc/Matcha-TTS
</a>
<br/>
<a href="https://github.com/langtech-bsc/Matcha-TTS/commit/4885b8927a94afd692598dd868619c293b0ca0aa">class method functions added to initialize matcha from HF model and c‚Ä¶ ¬∑ langtech-bsc/Matcha-TTS@4885b89
</a>
<br/>
<a href="https://github.com/langtech-bsc">Language Technologies Unit - BSC
</a>
<br/>
<a href="https://github.com/langtech-bsc/Matcha-TTS/commit/b2e6e1e87e1522753fdb5994671b8d3f25a1f115#diff-6b63d39c98fd1bc31e7d1dddd182dd3e91cd9682fd577f9c97add5ceeb4336aaR109">Update cleaners.py ¬∑ langtech-bsc/Matcha-TTS@b2e6e1e
</a>
<br/>
<a href="https://github.com/langtech-bsc/Matcha-TTS/commit/e4d15b681ea263462617e8c394b4bdb492ca8388">Update process_text on cli.py with catalan cleaners ¬∑ langtech-bsc/Matcha-TTS@e4d15b6
</a>
<br/>
<a href="https://ast-astrec.nict.go.jp/en/release/hi-fi-captain/">Hi-Fi-CAPTAIN | Releases | Advanced Speech Translation Research and Development Promotion Center | ASTREC | UCRI | NICT
</a>
<br/>
<a href="https://github.com/skirdey/voicerestore?tab=readme-ov-file">skirdey/voicerestore: VoiceRestore: Flow-Matching Transformers for Universal Speech Restoration
</a>
<br/>
<a href="https://huggingface.co/jadechoghari/VoiceRestore/tree/main">jadechoghari/VoiceRestore at main
</a>
<br/>
<a href="https://github.com/shivammehta25">shivammehta25 (Shivam Mehta)
</a>
<br/>
<a href="https://github.com/shivammehta25/Matcha-TTS#train-with-your-own-dataset">shivammehta25/Matcha-TTS: [ICASSP 2024] üçµ Matcha-TTS: A fast TTS architecture with conditional flow matching
</a>
<br/>
<a href="https://github.com/shivammehta25/CVPRHumogen">shivammehta25/CVPRHumogen
</a>
<br/>
<a href="https://github.com/shivammehta25/Diff-TTSG">shivammehta25/Diff-TTSG: Diff-TTSG: Denoising probabilistic integrated speech and gesture synthesis
</a>
<br/>
<a href="https://github.com/shivammehta25/Matcha-TTS/blob/main/matcha/utils/get_durations_from_trained_model.py">Matcha-TTS/matcha/utils/get_durations_from_trained_model.py at main ¬∑ shivammehta25/Matcha-TTS
</a>
<br/>
<a href="https://osdn.net/projects/sfnet_tts-indianlang/">Indian Language TTS Japanese Information - OSDN
</a>
<br/>
<a href="https://datashare.ed.ac.uk/handle/10283/2950">VCTK
</a>
<br/>
<a href="https://datashare.ed.ac.uk/bitstream/handle/10283/3443/README.txt?sequence=1&isAllowed=y">datashare.ed.ac.uk/bitstream/handle/10283/3443/README.txt?sequence=1&isAllowed=y
</a>
<br/>
<a href="https://github.com/microsoft/MS-SNSD?tab=readme-ov-file">microsoft/MS-SNSD: The Microsoft Scalable Noisy Speech Dataset (MS-SNSD) is a noisy speech dataset that can scale to arbitrary sizes depending on the number of speakers, noise types, and Speech to Noise Ratio (SNR) levels desired.
</a>
<br/>
<a href="https://datashare.ed.ac.uk/handle/10283/2791">Noisy speech database for training speech enhancement algorithms and TTS models
</a>
<br/>
<a href="https://datashare.ed.ac.uk/bitstream/handle/10283/343/readme_acted_clear_speech.txt?sequence=1&isAllowed=y">datashare.ed.ac.uk/bitstream/handle/10283/343/readme_acted_clear_speech.txt?sequence=1&isAllowed=y
</a>
<br/>
<a href="https://stackoverflow.com/questions/16874598/how-to-calculate-the-md5-checksum-of-a-file-in-python">How to calculate the MD5 checksum of a file in Python? - Stack Overflow
</a>
<br/>
<a href="https://github.com/shivammehta25/Matcha-TTS">shivammehta25/Matcha-TTS: [ICASSP 2024] üçµ Matcha-TTS: A fast TTS architecture with conditional flow matching
</a>
<br/>
<a href="https://github.com/phonlab-tcd/text-normalization/blob/main/txt_files/expand_Connemara.txt">text-normalization/txt_files/expand_Connemara.txt at main ¬∑ phonlab-tcd/text-normalization
</a>
<br/>
<a href="https://github.com/espeak-ng/espeak-ng/blob/master/dictsource/ga_rules">espeak-ng/dictsource/ga_rules at master ¬∑ espeak-ng/espeak-ng
</a>
<br/>
<a href="https://github.com/shivammehta25/Match-TTSG/blob/main/match_ttsg/utils/audio.py">Match-TTSG/match_ttsg/utils/audio.py at main ¬∑ shivammehta25/Match-TTSG
</a>
<br/>
<a href="https://ieeexplore.ieee.org/document/9829287">An E2E-ASR-Based Iteratively-Trained Timestamp Estimator | IEEE Journals & Magazine | IEEE Xplore
</a>
<br/>
<a href="https://arxiv.org/pdf/2306.11473">2306.11473
</a>
<br/>
<a href="https://machinelearning.apple.com/research/asr-contextualization">Contextualization of ASR with LLM Using Phonetic Retrieval-Based Augmentation - Apple Machine Learning Research
</a>
<br/>
<a href="https://arxiv.org/abs/2409.15353">[2409.15353] Contextualization of ASR with LLM using phonetic retrieval-based augmentation
</a>
<br/>
<a href="https://machinelearning.apple.com/research/ctc-based">Personalization of CTC-based End-to-End Speech Recognition Using Pronunciation-Driven Subword Tokenization - Apple Machine Learning Research
</a>
<br/>
<a href="https://github.com/shivammehta25/Matcha-TTS/blob/main/matcha/models/components/text_encoder.py">Matcha-TTS/matcha/models/components/text_encoder.py at main ¬∑ shivammehta25/Matcha-TTS
</a>
<br/>
<a href="https://github.com/shivammehta25/Match-TTSG/blob/main/match_ttsg/models/components/text_encoder.py">Match-TTSG/match_ttsg/models/components/text_encoder.py at main ¬∑ shivammehta25/Match-TTSG
</a>
<br/>
<a href="https://www.google.com/search?q=skeleton+rotation+dual+quaternion&rlz=1C5GCEM_enSE990SE991&oq=skeleton+rotation+dual+quaternion&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIHCAEQIRigATIHCAIQIRigATIHCAMQIRifBTIHCAQQIRifBTIHCAUQIRifBTIHCAYQIRifBTIHCAcQIRifBTIHCAgQIRifBdIBCTEwMzU2ajBqN6gCALACAA&sourceid=chrome&ie=UTF-8">skeleton rotation dual quaternion - Google Search
</a>
<br/>
<a href="https://github.com/ishmeetkohli/dualQuaternionSkinning">ishmeetkohli/dualQuaternionSkinning: Skeletal Animation with Dual Quaternion Skinning and Linear Blend Skinning
</a>
<br/>
<a href="https://github.com/YunjinPark/awesome_talking_face_generation?tab=readme-ov-file">YunjinPark/awesome_talking_face_generation
</a>
<br/>
<a href="https://github.com/yerfor/GeneFacePlusPlus/blob/main/Dockerfile.genface">GeneFacePlusPlus/Dockerfile.genface at main ¬∑ yerfor/GeneFacePlusPlus
</a>
<br/>
<a href="https://github.com/Doubiiu/CodeTalker">github.com
</a>
<br/>
<a href="https://github.com/open-mmlab/mmpose?tab=readme-ov-file">open-mmlab/mmpose: OpenMMLab Pose Estimation Toolbox and Benchmark.
</a>
<br/>
<a href="https://github.com/open-mmlab/mmpose/tree/main/projects/just_dance">mmpose/projects/just_dance at main ¬∑ open-mmlab/mmpose
</a>
<br/>
<a href="https://github.com/open-mmlab/mmpose/tree/main/projects/yolox_pose">mmpose/projects/yolox_pose at main ¬∑ open-mmlab/mmpose
</a>
<br/>
<a href="https://github.com/open-mmlab/mmdetection">open-mmlab/mmdetection: OpenMMLab Detection Toolbox and Benchmark
</a>
<br/>
<a href="https://mmpose.readthedocs.io/en/latest/user_guides/dataset_tools.html">Dataset Annotation and Format Conversion ‚Äî MMPose 1.3.2 documentation
</a>
<br/>
<a href="https://github.com/open-mmlab/mmpose?tab=readme-ov-file">open-mmlab/mmpose: OpenMMLab Pose Estimation Toolbox and Benchmark.
</a>
<br/>
<a href="https://github.com/open-mmlab/mmpose/blob/main/projects/rtmpose3d/rtmpose3d/pose_estimator.py">mmpose/projects/rtmpose3d/rtmpose3d/pose_estimator.py at main ¬∑ open-mmlab/mmpose
</a>
<br/>
<a href="https://www.libhunt.com/r/openpose">Openpose Alternatives and Reviews
</a>
<br/>
<a href="https://www.libhunt.com/r/mediapipe">Mediapipe Alternatives and Reviews
</a>
<br/>
<a href="https://www.libhunt.com/r/freemocap">Freemocap Alternatives and Reviews
</a>
<br/>
<a href="https://github.com/KevinLTT/video2bvh">KevinLTT/video2bvh: Extracts human motion in video and save it as bvh mocap file.
</a>
<br/>
<a href="https://www.google.com/search?q=3d+pose+estimation+from+video&rlz=1C5GCEM_enSE990SE991&oq=3d+pose+estimation+from+video&gs_lcrp=EgZjaHJvbWUyDwgAEEUYORiRAhiABBiKBTIICAEQABgWGB4yCAgCEAAYFhgeMg0IAxAAGIYDGIAEGIoFMg0IBBAAGIYDGIAEGIoFMg0IBRAAGIYDGIAEGIoFMgoIBhAAGIAEGKIEMgoIBxAAGIAEGKIEMgoICBAAGIAEGKIEMgoICRAAGIAEGKIE0gEIODcwMWowajeoAgCwAgA&sourceid=chrome&ie=UTF-8">3d pose estimation from video - Google Search
</a>
<br/>
<a href="https://github.com/open-mmlab">OpenMMLab
</a>
<br/>
<a href="https://github.com/open-mmlab/Amphion">open-mmlab/Amphion: Amphion (/√¶mÀàfa…™…ôn/) is a toolkit for Audio, Music, and Speech Generation. Its purpose is to support reproducible research and help junior researchers and engineers get started in the field of audio, music, and speech generation research and development.
</a>
<br/>
<a href="https://github.com/open-mmlab/mmpose?tab=readme-ov-file">open-mmlab/mmpose: OpenMMLab Pose Estimation Toolbox and Benchmark.
</a>
<br/>
<a href="https://mmpose.readthedocs.io/en/latest/advanced_guides/implement_new_models.html">Implement New Models ‚Äî MMPose 1.3.2 documentation
</a>
<br/>
<a href="https://mmpose.readthedocs.io/en/latest/demos.html">Demos ‚Äî MMPose 1.3.2 documentation
</a>
<br/>
<a href="http://130.237.3.107:8080/projects/5/data?tab=5&task=71">Label Studio
</a>
<br/>
<a href="https://github.com/X-LANCE/VoiceFlow-TTS?tab=readme-ov-file">X-LANCE/VoiceFlow-TTS: [ICASSP 2024] This is the official code for "VoiceFlow: Efficient Text-to-Speech with Rectified Flow Matching"
</a>
<br/>
<a href="https://github.com/X-LANCE/UniCATS-CTX-vec2wav">X-LANCE/UniCATS-CTX-vec2wav: [AAAI 2024] Code for CTX-vec2wav in UniCATS
</a>
<br/>
<a href="https://arxiv.org/pdf/2005.11129">2005.11129
</a>
<br/>
<a href="https://huggingface.co/Revai/reverb-diarization-v2">Revai/reverb-diarization-v2 ¬∑ Hugging Face
</a>
<br/>
<a href="https://github.com/revdotcom/reverb/blob/main/asr/wenet/bin/recognize_wav.py">reverb/asr/wenet/bin/recognize_wav.py at main ¬∑ revdotcom/reverb
</a>
<br/>
<a href="https://github.com/wenet-e2e/wenet/tree/main/examples/openasr2021/s0">wenet/examples/openasr2021/s0 at main ¬∑ wenet-e2e/wenet
</a>
<br/>
<a href="https://huggingface.co/Revai/reverb-asr/tree/main">Revai/reverb-asr at main
</a>
<br/>
<a href="https://github.com/revdotcom/reverb">revdotcom/reverb: Open source inference code for Rev's model
</a>
<br/>
<a href="https://huggingface.co/spaces/Revai/reverb-asr-demo">Reverb ASR Demo - a Hugging Face Space by Revai
</a>
<br/>
<a href="https://github.com/revdotcom/fstalign/blob/develop/docs//NLP-Format.md#wer-tag-sidecar">fstalign/docs/NLP-Format.md at develop ¬∑ revdotcom/fstalign
</a>
<br/>
<a href="https://github.com/revdotcom/speech-datasets/blob/main/earnings22/README.md">speech-datasets/earnings22/README.md at main ¬∑ revdotcom/speech-datasets
</a>
<br/>
<a href="https://github.com/revdotcom/words2num/blob/master/words2num/lang_EN_US.py">words2num/words2num/lang_EN_US.py at master ¬∑ revdotcom/words2num
</a>
<br/>
<a href="https://github.com/wenet-e2e/WenetSpeech">wenet-e2e/WenetSpeech: A 10000+ hours dataset for Chinese speech recognition
</a>
<br/>
<a href="https://github.com/wenet-e2e/wenet/blob/main/wenet/transformer/search.py">wenet/wenet/transformer/search.py at main ¬∑ wenet-e2e/wenet
</a>
<br/>
<a href="https://github.com/hlt-mt/mosel?tab=readme-ov-file">hlt-mt/mosel: Collection of Open Source Speech Data
</a>
<br/>
<a href="https://clarin-pl.eu/dspace/handle/11321/821">EU Parliament Speech corpus
</a>
<br/>
<a href="https://pincproject2020.wordpress.com/blog/">Blog ‚Äì PINC Project
</a>
<br/>
<a href="https://github.com/cmusphinx/sphinx4/tree/master/sphinx4-core/src/main/java/edu/cmu/sphinx/jsgf">sphinx4/sphinx4-core/src/main/java/edu/cmu/sphinx/jsgf at master ¬∑ cmusphinx/sphinx4
</a>
<br/>
<a href="https://github.com/cmusphinx/sphinxbase">cmusphinx/sphinxbase
</a>
<br/>
<a href="https://github.com/abus-aikorea/voice-pro?tab=readme-ov-file">abus-aikorea/voice-pro: The best gradio web-ui for ai transcription, translation and TTS. Automatic subtitle creation using faster whisper. Easy one click installation. Fully portable.
</a>
<br/>
<a href="https://github.com/facebookresearch/demucs?tab=readme-ov-file">facebookresearch/demucs: Code for the paper Hybrid Spectrogram and Waveform Source Separation
</a>
<br/>
<a href="https://github.com/facebookresearch/demucs/issues/334">Demucs v3 Has been fully added to the UVR GUI! ¬∑ Issue #334 ¬∑ facebookresearch/demucs
</a>
<br/>
<a href="https://github.com/Anjok07/ultimatevocalremovergui#installation">Anjok07/ultimatevocalremovergui: GUI for a Vocal Remover that uses Deep Neural Networks.
</a>
<br/>
<a href="https://pypi.org/project/pocketsphinx/">pocketsphinx ¬∑ PyPI
</a>
<br/>
<a href="https://github.com/cmusphinx/pocketsphinx/blob/master/examples/simple.py">pocketsphinx/examples/simple.py at master ¬∑ cmusphinx/pocketsphinx
</a>
<br/>
<a href="https://pocketsphinx.readthedocs.io/en/latest/pocketsphinx.html#pocketsphinx.FsgModel">Main pocketsphinx package ‚Äî PocketSphinx 5.0.3 documentation
</a>
<br/>
<a href="https://cmusphinx.github.io/wiki/pocketsphinx_pronunciation_evaluation/">Pocketsphinx for Pronunication Evaluation ‚Äì CMUSphinx Open Source Speech Recognition
</a>
<br/>
<a href="https://www.w3.org/TR/2000/NOTE-jsgf-20000605/">JSpeech Grammar Format
</a>
<br/>
<a href="https://github.com/synesthesiam/jsgf2fst/blob/master/jsgf2fst/jsgf2fst.py">jsgf2fst/jsgf2fst/jsgf2fst.py at master ¬∑ synesthesiam/jsgf2fst
</a>
<br/>
<a href="https://danesprite/pyjsgf">danesprite
</a>
<br/>
<a href="https://groups.google.com/g/kaldi-help/c/9r6mea7aJVc">Can Kaldi decode in the JSGFGrammar way like sphinx?
</a>
<br/>
<a href="https://vpanayotov.blogspot.com/2012/06/kaldi-decoding-graph-construction.html">Geeky Stuff: Decoding graph construction in Kaldi: A visual walkthrough
</a>
<br/>
<a href="https://github.com/OscarVanL/LibriTTS-British-Accents?tab=readme-ov-file">OscarVanL/LibriTTS-British-Accents: A subset of the popular LibriTTS dataset with subsets for English, Scottish, Welsh, and Irish accents.
</a>
<br/>
<a href="https://github.com/OscarVanL/LibriTTS-British-Accents/blob/master/SPEAKERS_ENGLISH.txt">LibriTTS-British-Accents/SPEAKERS_ENGLISH.txt at master ¬∑ OscarVanL/LibriTTS-British-Accents
</a>
<br/>
<a href="https://wiki.librivox.org/index.php/Accents_Table">Accents Table - Librivox wiki
</a>
<br/>
<a href="https://golding.wordpress.com/home/other-british-readers-on-librivox/">Other British Readers on LibriVox | RuthieG's CataBlog
</a>
<br/>
<a href="https://github.com/OscarVanL/LibriTTS-British-Accents/issues/1">Git LFS data quota exceeded ¬∑ Issue #1 ¬∑ OscarVanL/LibriTTS-British-Accents
</a>
<br/>
<a href="https://github.com/ggerganov/llama.cpp/blob/master/examples/llava/README.md">llama.cpp/examples/llava/README.md at master ¬∑ ggerganov/llama.cpp
</a>
<br/>
<a href="https://github.com/shivammehta25/Matcha-TTS/issues/104">Finetuning and Vocoder Training ¬∑ Issue #104 ¬∑ shivammehta25/Matcha-TTS
</a>
<br/>
<a href="https://www.google.com/search?q=WavLMForAudioFrameClassification&rlz=1C5GCEM_enSE990SE991&oq=WavLMForAudioFrameClassification&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIKCAEQABiABBiiBDIKCAIQABiABBiiBDIKCAMQABiABBiiBDIKCAQQABiABBiiBDIKCAUQABiABBiiBNIBBzQxMmowajeoAgCwAgA&sourceid=chrome&ie=UTF-8">WavLMForAudioFrameClassification - Google Search
</a>
<br/>
<a href="https://github.com/huggingface/transformers/issues/17509">Finetuning AudioFrameClassification model ¬∑ Issue #17509 ¬∑ huggingface/transformers
</a>
<br/>
<a href="https://github.com/huggingface/transformers/blob/main/src/transformers/models/wavlm/modeling_wavlm.py">transformers/src/transformers/models/wavlm/modeling_wavlm.py at main ¬∑ huggingface/transformers
</a>
<br/>
<a href="https://huggingface.co/microsoft/wavlm-base-plus-sd">microsoft/wavlm-base-plus-sd ¬∑ Hugging Face
</a>
<br/>
<a href="https://huggingface.co/models?other=wavlm&p=1&sort=trending">Models - Hugging Face
</a>
<br/>
<a href="https://huggingface.co/lgris/WavLM-large-CORAA-pt">lgris/WavLM-large-CORAA-pt ¬∑ Hugging Face
</a>
<br/>
<a href="https://huggingface.co/wrice/wavlm-large-timit-punctuation">wrice/wavlm-large-timit-punctuation ¬∑ Hugging Face
</a>
<br/>
<a href="https://huggingface.co/jonatasgrosman/exp_w2v2t_sv-se_wavlm_s132">jonatasgrosman/exp_w2v2t_sv-se_wavlm_s132 ¬∑ Hugging Face
</a>
<br/>
<a href="https://arxiv.org/pdf/2405.04485">2405.04485
</a>
<br/>
<a href="https://github.com/sinhat98/adapter-wavlm">sinhat98/adapter-wavlm
</a>
<br/>
<a href="https://github.com/microsoft/unilm/blob/master/wavlm/README.md">unilm/wavlm/README.md at master ¬∑ microsoft/unilm
</a>
<br/>
<a href="https://stackoverflow.com/questions/55461749/extract-email-addresses-from-academic-curly-braces-format">python - Extract email addresses from academic curly braces format - Stack Overflow
</a>
<br/>
<a href="https://github.com/espnet/espnet/pulls">Pull requests ¬∑ espnet/espnet
</a>
<br/>
<a href="https://github.com/espnet/espnet/pull/5912/files">Speechlm by lingranshanye2357 ¬∑ Pull Request #5912 ¬∑ espnet/espnet
</a>
<br/>
<a href="https://github.com/espnet/espnet/pull/5904">[WIP] SpeechLM-based SE for CHiME-4 by YoshikiMas ¬∑ Pull Request #5904 ¬∑ espnet/espnet
</a>
<br/>
<a href="https://github.com/espnet/espnet/pull/5913/files">Add Hugging Face Front End by taiqihe ¬∑ Pull Request #5913 ¬∑ espnet/espnet
</a>
<br/>
<a href="https://github.com/espnet/espnet/pull/5891">Speechtokenizer Implementation by ftshijt ¬∑ Pull Request #5891 ¬∑ espnet/espnet
</a>
<br/>
<a href="https://github.com/espnet/espnet/pull/5876">Init SpeechLM SVS by Tsukasane ¬∑ Pull Request #5876 ¬∑ espnet/espnet
</a>
<br/>
<a href="https://github.com/espnet/espnet/pull/5755">Add tacotron2 to TTS2 by jctian98 ¬∑ Pull Request #5755 ¬∑ espnet/espnet
</a>
<br/>
<a href="https://github.com/amazon-science/stac-speech-translation">amazon-science/stac-speech-translation
</a>
<br/>
<a href="https://github.com/orgs/amazon-science/repositories?type=all&page=5">amazon-science repositories
</a>
<br/>
<a href="https://github.com/amazon-science/supervised-intent-clustering">amazon-science/supervised-intent-clustering: This is a package to fine-tune language models in order to create clustering-friendly embeddings.
</a>
<br/>
<a href="https://github.com/amazon-science/ViLA">amazon-science/ViLA
</a>
<br/>
<a href="https://github.com/amazon-science/refinesumm">amazon-science/refinesumm: REFINESUMM: Self-Refining MLLM for Generating a Multimodal Summarization Dataset. ACL 2024
</a>
<br/>
<a href="https://github.com/amazon-science/tokenalign">amazon-science/tokenalign: Token Alignment via Character Matching for Subword Completion (ACL Findings 2024)
</a>
<br/>
<a href="https://pypi.org/project/pygtrie/">pygtrie ¬∑ PyPI
</a>
<br/>
<a href="https://github.com/amazon-science/long-short-term-transformer">amazon-science/long-short-term-transformer: [NeurIPS 2021 Spotlight] Official implementation of Long Short-Term Transformer for Online Action Detection
</a>
<br/>
<a href="https://github.com/amazon-science/MASSIVE-AMR">amazon-science/MASSIVE-AMR: A dataset with more than 84,000 manually annotated AMR graphs for 1,685 information-seeking utterances mapped to 50+ typologically diverse languages.
</a>
<br/>
<a href="https://github.com/amazon-science/embert">amazon-science/embert: Code for EmBERT, a transformer model for embodied, language-guided visual task completion.
</a>
<br/>
<a href="https://github.com/amazon-science/stac-speech-translation">amazon-science/stac-speech-translation
</a>
<br/>
<a href="https://github.com/amazon-science/iwslt-autodub-task">amazon-science/iwslt-autodub-task
</a>
<br/>
<a href="https://github.com/amazon-science/c2f-seg">amazon-science/c2f-seg: Official Implementation for ICCV'23 paper Coarse-to-Fine Amodal Segmentation with Shape Prior (C2F-Seg).
</a>
<br/>
<a href="https://www.reddit.com/r/opensource/comments/tb40ch/opensource_kahootclone/">Open-Source Kahoot-clone : r/opensource
</a>
<br/>
<a href="https://github.com/mawoka-myblock/ClassQuiz/tree/master?tab=readme-ov-file">mawoka-myblock/ClassQuiz: ClassQuiz is a quiz-application like Kahoot!, but open-source.
</a>
<br/>
<a href="https://www.google.com/search?q=kahoot+clone+github&sca_esv=cc6d6b10f485ae1c&rlz=1C5GCEM_enSE990SE991&sxsrf=ADLYWIKkdQRpOfy7XAWpNWSN-rmi-3wBiw:1728638349714&ei=je0IZ-uhK4mj1fIPuouO4Q0&start=20&sa=N&sstk=Aagrsuj8CrM6EPEk5itue8sQS1DUdnbmD8DDhgnPPKb3YojYrl1x_gCUH2IMWHTUHQWLhhm5d1w64TKLzVxOZgsf4gt_VnZU_ac_00bYEOZPE4msodeRtafMZGgDOelcEavU&ved=2ahUKEwirnJ7W_4WJAxWJUVUIHbqFI9w4ChDw0wN6BAgEEBc&biw=1440&bih=734&dpr=2">kahoot clone github - Google Search
</a>
<br/>
<a href="https://github.com/kwkoo/go-quiz">kwkoo/go-quiz: A Kahoot clone with a UI based on Ethan Brimhall's kahoot-clone-nodejs
</a>
<br/>
<a href="https://github.com/khrj/hackclub-workshops/blob/main/showcase/Kuizzy/app.js">hackclub-workshops/showcase/Kuizzy/app.js at main ¬∑ khrj/hackclub-workshops
</a>
<br/>
<a href="https://github.com/BsmhDevTeam/shablool/tree/password-prod/private">shablool/private at password-prod ¬∑ BsmhDevTeam/shablool
</a>
<br/>
<a href="https://shablool.herokuapp.com/">Heroku | Application Error
</a>
<br/>
<a href="https://chatgpt.com/c/6708ee31-2c18-8011-bff8-995268a1642e">ChatGPT
</a>
<br/>
<a href="https://github.com/Ralex91/Rahoot/blob/main/config.mjs">Rahoot/config.mjs at main ¬∑ Ralex91/Rahoot
</a>
<br/>
<a href="https://github.com/lycaon7/Kahoot-Clone">lycaon7/Kahoot-Clone
</a>
<br/>
<a href="https://supabase.com/blog/meetup-kahoot-alternative">The open source Kahoot alternative
</a>
<br/>
<a href="https://github.com/supabase-community/kahoot-alternative">supabase-community/kahoot-alternative: An open source Kahoot alternative made with Next.js and Supabase
</a>
<br/>
<a href="https://trimesh.org/">trimesh 4.4.9 documentation
</a>
<br/>
<a href="https://github.com/NVIDIAGameWorks/kaolin?tab=readme-ov-file">NVIDIAGameWorks/kaolin: A PyTorch Library for Accelerating 3D Deep Learning Research
</a>
<br/>
<a href="https://scikit-learn.org/dev/modules/generated/sklearn.preprocessing.StandardScaler.html">StandardScaler ‚Äî scikit-learn 1.6.dev0 documentation
</a>
<br/>
<a href="https://docs.scipy.org/doc/scipy/tutorial/interpolate/1D.html#tutorial-interpolate-1dsection">1-D interpolation ‚Äî SciPy v1.14.1 Manual
</a>
<br/>
<a href="https://www.youtube.com/watch?v=QLs4MXfA0ec">COFFEE WITH RICK BEATO - YouTube
</a>
<br/>
<a href="https://www.youtube.com/shorts/H5G0aqiMZjY">This is why men don‚Äôt understand ‚Äúhints‚Äù‚Ä¶#shorts - YouTube
</a>
<br/>
<a href="https://open.spotify.com/episode/02QQcxo9SUkVeVgmaC21Gn?si=fwC7ROAaRH6z_GGBWiWqqw&fbclid=PAZXh0bgNhZW0CMTEAAaaVH5InVXBRlWhpDDdGW9yjGAErn_gUeb2nOaxXZS-qV3jvs2lUFl9tJcg_aem_WJgFR8HIY-znk1AhLXFnVQ&nd=1&dlsi=f93085c908614825#_=_">Taking On The World After A Garlic Cheese Chips with Alan Clarke - Listen, I'm Delicious | Podcast on Spotify
</a>
<br/>
<a href="https://www.youtube.com/watch?v=-drJhZ8FmEE">Eddie Van Halen's Secret Shred Techniques Made Easy - YouTube
</a>
<br/>
<a href="https://code.visualstudio.com/docs/devcontainers/containers">Developing inside a Container using Visual Studio Code Remote Development
</a>
<br/>
<a href="https://code.visualstudio.com/docs/devcontainers/create-dev-container">Create a development container using Visual Studio Code Remote Development
</a>
<br/>
<a href="https://www.youtube.com/watch?v=fFXKNoproGI">The Secret to Develope Praying Mantis Strikes - YouTube
</a>
<br/>
<a href="https://nbviewer.org/gist/r9y9/e7d6604757403ec74557ccd93e1f0c8c">Jupyter Notebook Viewer
</a>
<br/>
<a href="https://www.google.com/search?q=breath+detection+github&rlz=1C5GCEM_enSE990SE991&oq=breath+detection+&gs_lcrp=EgZjaHJvbWUqBggBECMYJzIGCAAQRRg5MgYIARAjGCcyBwgCEAAYgAQyDQgDEAAYhgMYgAQYigUyDQgEEAAYhgMYgAQYigUyBggFEEUYPTIGCAYQRRg8MgYIBxBFGDzSAQg0MjQ5ajBqN6gCALACAA&sourceid=chrome&ie=UTF-8">breath detection github - Google Search
</a>
<br/>
<a href="https://github.com/dioptx/InhaleSense?tab=readme-ov-file">dioptx/InhaleSense: A deep learning approach for respiratory audio discovery and classification.
</a>
<br/>
<a href="https://github.com/snousias/Revisiting-Content-Based-Audio-Classification-for-Asthma-Medication-Adherence/tree/master">snousias/Revisiting-Content-Based-Audio-Classification-for-Asthma-Medication-Adherence: Asthma is a common, usually long-term respiratory disease with negative impact on society and the economy worldwide. Treatment involves using medical devices (inhalers) that distribute medicationto the airways, and its efficiency depends on the precision of the inhalation technique. Health monitoring systems equipped with sensors and embedded with sound signal detection enable the recognition of drug actuation and could be powerful tools for reliable audio content analysis. This repository includes a set of tools for audio processing, feature extraction and classification and is provided along with a dataset consisting of respiratory and drug actuation sounds. The classification models are implemented based on machine learning and deep approaches. This study provides a comparative evaluation of the implemented approaches, examines potential improvements and discusses challenges and future tendencies.
</a>
<br/>
<a href="https://github.com/anhtu1197/Breath-Detection/blob/master/training_main_lstm.py">Breath-Detection/training_main_lstm.py at master ¬∑ anhtu1197/Breath-Detection
</a>
<br/>
<a href="https://github.com/jimregan/sync-asr/pull/58/files#diff-a12ab605015c17649fd175d957dfd2f83135f954fa312c702d8b3ca9e3ef7131">Changes for mm-conv experiments by jimregan ¬∑ Pull Request #58 ¬∑ jimregan/sync-asr
</a>
<br/>
<a href="https://www.reddit.com/r/speechrecognition/comments/nva1hw/kaldivosk_how_to_convert_a_static_graph_hclgfst/">[Kaldi-Vosk] How to convert a static graph (HCLG.fst) into a dynamic graph (HCLr.fst, Gr.fst)? : r/speechrecognition
</a>
<br/>
<a href="https://chrisearch.wordpress.com/2017/03/11/speech-recognition-using-kaldi-extending-and-using-the-aspire-model/">Kaldi ASR: Extending the ASpIRE model ‚Äì Research Stories
</a>
<br/>
<a href="https://stackoverflow.com/questions/4028904/what-is-a-cross-platform-way-to-get-the-home-directory">python - What is a cross-platform way to get the home directory? - Stack Overflow
</a>
<br/>
<a href="https://stackoverflow.com/questions/22366282/python-filenotfound">Python FileNotFound - Stack Overflow
</a>
<br/>
<a href="https://github.com/bootphon/phonemizer/blob/master/test/test_espeak.py">phonemizer/test/test_espeak.py at master ¬∑ bootphon/phonemizer
</a>
<br/>
<a href="http://130.237.3.107:8080/projects/7/data?tab=7&task=102">Label Studio
</a>
<br/>
<a href="https://jimregan.github.io/notes/textgrid/json/hsi/2024/09/20/textgrid-via-labelstudio-api.html">TextGrid to Label Studio | notes
</a>
<br/>
<a href="https://jimregan.github.io/notes/pocketsphinx/hsi/alignment/2024/10/06/pocketsphinx-align.html">Trying to use pocketsphinx to word align | notes
</a>
<br/>
<a href="https://dict-trie.readthedocs.io/en/latest/index.html">Trie implementation using nested dictionaries ‚Äî dict-trie latest documentation
</a>
<br/>
<a href="https://api.labelstud.io/api-reference/api-reference/tasks/get">Get task ‚Äî API Reference | Label Studio
</a>
<br/>
<a href="https://swivid.github.io/F5-TTS/">F5-TTS
</a>
<br/>
<a href="https://github.com/SWivid/F5-TTS/blob/main/model/modules.py">F5-TTS/model/modules.py at main ¬∑ SWivid/F5-TTS
</a>
<br/>
<a href="https://github.com/MahmoudAshraf97/ctc-forced-aligner">MahmoudAshraf97/ctc-forced-aligner: Text to speech alignment using CTC forced alignment
</a>
<br/>
<a href="https://github.com/facebookresearch/ConvNeXt-V2?tab=readme-ov-file">facebookresearch/ConvNeXt-V2: Code release for ConvNeXt V2 model
</a>
<br/>
<a href="https://borisfx.com/blog/what-is-audio-ducking-and-how-is-it-used/">What is Audio Ducking and How is it Used? | Boris FX
</a>
<br/>
<a href="https://medium.com/papercup-ai/tutorial-on-declipping-wav-files-58fa87a27d44">Tutorial on declipping WAV files. I introduce the problem of clipped‚Ä¶ | by Team Papercup | Papercup AI | Medium
</a>
<br/>
<a href="https://www.google.com/search?q=find+clipping+in+a+wave+file+python&rlz=1C5GCEM_enSE990SE991&oq=find&gs_lcrp=EgZjaHJvbWUqCAgAEEUYJxg7MggIABBFGCcYOzIGCAEQRRg5Mg0IAhAAGJECGIAEGIoFMgYIAxBFGD0yBggEEEUYPTIGCAUQRRhBMgYIBhBFGD0yBggHEEUYQdIBBzg2MWowajeoAgCwAgA&sourceid=chrome&ie=UTF-8">find clipping in a wave file python - Google Search
</a>
<br/>
<a href="https://stackoverflow.com/questions/23284531/clipping-tops-of-waveforms-in-python">audio - Clipping Tops of Waveforms in Python - Stack Overflow
</a>
<br/>
<a href="https://pypi.org/project/clipdetect/">clipdetect ¬∑ PyPI
</a>
<br/>
<a href="https://www.google.com/search?q=clipdetect+github&sca_esv=d909a4843931226e&rlz=1C5GCEM_enSE990SE991&sxsrf=ADLYWIIQhUfZM6taau3opV3wUH58GVlvAA%3A1729005095953&ei=J4YOZ4vcOd6bwPAPjtrkiQI&ved=0ahUKEwjLi7z01ZCJAxXeDRAIHQ4tOSEQ4dUDCA8&uact=5&oq=clipdetect+github&gs_lp=Egxnd3Mtd2l6LXNlcnAiEWNsaXBkZXRlY3QgZ2l0aHViMgcQIRigARgKSI4TUIEIWJQRcAJ4AZABAJgBZKABxQSqAQM2LjG4AQPIAQD4AQGYAgmgAuQEwgIKEAAYsAMY1gQYR8ICBxAAGIAEGA3CAggQABgNGB4YD8ICBhAAGA0YHsICCBAAGAUYDRgewgIIEAAYgAQYogTCAgUQIRigAcICBhAAGBYYHpgDAIgGAZAGCJIHAzguMaAHjxg&sclient=gws-wiz-serp">clipdetect github - Google Search
</a>
<br/>
<a href="https://www.reddit.com/r/audioengineering/comments/q240g8/i_wrote_a_clipping_detection_algorithm_in_c/">I wrote a clipping detection algorithm in C : r/audioengineering
</a>
<br/>
<a href="https://github.com/oriBetelgeuse/CLIPDetection">oriBetelgeuse/CLIPDetection
</a>
<br/>
<a href="https://pypi.org/project/clipdetect/#files">clipdetect ¬∑ PyPI
</a>
<br/>
<a href="https://www.sciencedirect.com/science/article/pii/S0167639321000832">Nonlinear waveform distortion: Assessment and detection of clipping on speech data and systems - ScienceDirect
</a>
<br/>
<a href="https://github.com/roedoejet?tab=repositories&q=clip&type=&language=&sort=">roedoejet (roedoejet) / Repositories
</a>
<br/>
<a href="https://github.com/orgs/nrc-cnrc/repositories">nrc-cnrc repositories
</a>
<br/>
<a href="https://github.com/jimregan/mmconv-matcha-prep/compare/clipdetect?expand=1">Comparing main...clipdetect ¬∑ jimregan/mmconv-matcha-prep
</a>
<br/>
<a href="https://en.wikipedia.org/wiki/History_of_the_International_Phonetic_Alphabet">History of the International Phonetic Alphabet - Wikipedia
</a>
<br/>
<a href="https://en.wikipedia.org/wiki/History_of_the_International_Phonetic_Alphabet#CITEREFAssociation_phon%C3%A9tique_internationale1921">History of the International Phonetic Alphabet - Wikipedia
</a>
<br/>
<a href="https://archive.org/details/ecriturephonetiqueinternationale1921">Internet Archive: Service Availability
</a>
<br/>
<a href="https://bsky.app/profile/did:plc:73dpznbu4wqwtcyurwbiulov">Internet Archive (@archive.org) ‚Äî Bluesky
</a>
<br/>
<a href="https://en.wiktionary.org/wiki/%C6%AA">∆™ - Wiktionary, the free dictionary
</a>
<br/>
<a href="https://bsky.app/">Discover ‚Äî Bluesky
</a>
<br/>
<a href="https://bsky.social/about/support/tos">Terms of Service - Bluesky
</a>
<br/>
<a href="https://atproto.com/specs/atp">AT Protocol - AT Protocol
</a>
<br/>
<a href="https://github.com/bluesky-social/atproto">bluesky-social/atproto: Social networking technology created by Bluesky
</a>
<br/>
<a href="https://github.com/bluesky-social">bluesky-social
</a>
<br/>
<a href="https://github.com/bluesky-social/indigo">bluesky-social/indigo: Go source code for Bluesky's atproto services.
</a>
<br/>
<a href="https://github.com/bluesky-social/react-native-paste-input">bluesky-social/react-native-paste-input: React Native TextInput replacement to allow pasting files
</a>
<br/>
<a href="https://bsky.app/">Discover ‚Äî Bluesky
</a>
<br/>
<a href="https://github.com/jbeskow/OverFlow-sardrag">jbeskow/OverFlow-sardrag: Probabilistic speech syntheses by mixing neural HMM TTS with normalising flows
</a>
<br/>
<a href="https://github.com/shivammehta25/OverFlow/compare/main...jimregan:OverFlow:OverFlow-sardrag?expand=1">Comparing shivammehta25:main...jimregan:OverFlow-sardrag ¬∑ shivammehta25/OverFlow
</a>
<br/>
<a href="https://stackoverflow.com/questions/10603671/how-to-add-a-local-repo-and-treat-it-as-a-remote-repo">git - How to add a local repo and treat it as a remote repo - Stack Overflow
</a>
<br/>
<a href="https://serverfault.com/questions/43014/copying-a-large-directory-tree-locally-cp-or-rsync">linux - Copying a large directory tree locally? cp or rsync? - Server Fault
</a>
<br/>
<a href="https://stackoverflow.com/questions/26380455/cannot-get-rsync-to-ignore-my-git-folder-and-my-todo-file">Cannot get rsync to ignore my git folder and my todo file - Stack Overflow
</a>
<br/>
<a href="https://huggingface.co/docs/hub/en/repositories-settings">Repository Settings
</a>
<br/>
<a href="https://github.com/perezpoz?tab=repositories">perezpoz (perezpoz) / Repositories
</a>
<br/>
<a href="https://github.com/perezpoz/KalmANF">perezpoz/KalmANF: A frequency tracker based on a Kalman filter update of a single parameter adaptive notch filter
</a>
<br/>
<a href="https://github.com/perezpoz/wavebender-gan">perezpoz/wavebender-gan
</a>
<br/>
<a href="https://github.com/perezpoz?tab=repositories">perezpoz (perezpoz) / Repositories
</a>
<br/>
<a href="https://github.com/perezpoz/CleanWhisperDetection/tree/main">perezpoz/CleanWhisperDetection
</a>
<br/>
<a href="https://perezpoz.github.io/cwad">A processing framework to access large quantities of whispered speech found in ASMR | Pablo‚Äôs GitHub Pages
</a>
<br/>
<a href="https://github.com/perezpoz/Edyson_whisper/commit/704889b5d6b34742a7d17e1f42fbfd8f570f53f0#diff-cd309897b5ae865b68dd2096074fd3b3c1e044dad9e96e2d4590f6be88570572R17">Provide multitaper and rasta-plp as input features ¬∑ perezpoz/Edyson_whisper@704889b
</a>
<br/>
<a href="https://github.com/wil-j-wil/py_bank">wil-j-wil/py_bank: An audio filter bank implementation in Python, contains ERB and linear filter banks
</a>
<br/>
<a href="https://datashare.ed.ac.uk/bitstream/handle/10283/4836/README.txt?sequence=2&isAllowed=y">datashare.ed.ac.uk/bitstream/handle/10283/4836/README.txt?sequence=2&isAllowed=y
</a>
<br/>
<a href="https://github.com/JeremyCCHsu/Python-Wrapper-for-World-Vocoder?tab=readme-ov-file">JeremyCCHsu/Python-Wrapper-for-World-Vocoder: A Python wrapper for the high-quality vocoder "World"
</a>
<br/>
<a href="https://github.com/mystlee/rasta_py/blob/master/rasta.py">rasta_py/rasta.py at master ¬∑ mystlee/rasta_py
</a>
<br/>
<a href="https://github.com/danijel3/TransformersSpeechAligner/blob/main/src/recognize.py">TransformersSpeechAligner/src/recognize.py at main ¬∑ danijel3/TransformersSpeechAligner
</a>
<br/>
<a href="https://github.com/CoderLine/alphaTab">CoderLine/alphaTab: alphaTab is a cross platform music notation and guitar tablature rendering library.
</a>
<br/>
<a href="https://github.com/Perlence/PyGuitarPro/blob/master/examples/dfh.py">PyGuitarPro/examples/dfh.py at master ¬∑ Perlence/PyGuitarPro
</a>
<br/>
<a href="https://github.com/Perlence/gpdiff">Perlence/gpdiff: Three-way compare and merge tool for GP3, GP4, and GP5 files
</a>
<br/>
<a href="https://github.com/mauricek/kaitai_format_gp5/blob/master/guitar_pro_5.ksy">kaitai_format_gp5/guitar_pro_5.ksy at master ¬∑ mauricek/kaitai_format_gp5
</a>
<br/>
<a href="https://github.com/kaitai-io/awesome-kaitai?tab=readme-ov-file">kaitai-io/awesome-kaitai: A curated list of Kaitai Struct tools and resources
</a>
<br/>
<a href="https://blog.jupyter.org/authoring-custom-jupyter-widgets-2884a462e724">Authoring Custom Jupyter Widgets. A Hands-On Guide | by QuantStack | Jupyter Blog
</a>
<br/>
<a href="https://arxiv.org/pdf/2210.00077">2210.00077
</a>
<br/>
<a href="https://github.com/MahmoudAshraf97/ctc-forced-aligner?tab=readme-ov-file">MahmoudAshraf97/ctc-forced-aligner: Text to speech alignment using CTC forced alignment
</a>
<br/>
<a href="https://github.com/DeepMotionEditing/deep-motion-editing/blob/master/blender_rendering/render.py">deep-motion-editing/blender_rendering/render.py at master ¬∑ DeepMotionEditing/deep-motion-editing
</a>
<br/>
<a href="https://github.com/rpuntaie/syncstart/blob/main/syncstart.py">syncstart/syncstart.py at main ¬∑ rpuntaie/syncstart
</a>
<br/>
<a href="https://github.com/shivammehta25/Matcha-TTS/issues">Issues ¬∑ shivammehta25/Matcha-TTS
</a>
<br/>
<a href="https://github.com/simonalexanderson/ListenDenoiseAction/blob/main/utils/motion_dataset.py">Error
</a>
<br/>
<a href="https://hydra.cc/docs/tutorials/basic/your_first_app/defaults/">Selecting default configs | Hydra
</a>
<br/>
<a href="https://alphacephei.com/vosk/models">VOSK Models
</a>
<br/>
<a href="https://github.com/EnVision-Research/LucidDreamer">EnVision-Research/LucidDreamer: Official implementation of "LucidDreamer: Towards High-Fidelity Text-to-3D Generation via Interval Score Matching"
</a>
<br/>
<a href="https://arxiv.org/pdf/2408.16224">2408.16224
</a>
<br/>
<a href="https://www.instagram.com/direct/t/5060418777378294/">Inbox ‚Ä¢ Direct
</a>
<br/>
<a href="https://www.instagram.com/">Instagram
</a>
<br/>
<a href="http://web.archive.org/web/https://www.ft.com/content/397c50d8-8796-4042-a814-0ac2c068361f">Wayback Machine
</a>
<br/>
<a href="https://www.ft.com/content/7d1a2738-2518-4ddb-811b-8abf9a745590?utm_campaign=feed&utm_medium=referral&utm_source=later-linkinbio">Subscribe to read
</a>
<br/>
<a href="https://github.com/google-research/text-to-text-transfer-transformer">google-research/text-to-text-transfer-transformer: Code for the paper "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer"
</a>
<br/>
<a href="https://github.com/ggerganov/llama.cpp/issues/5763">llama : add T5 (encoder-decoder) support ¬∑ Issue #5763 ¬∑ ggerganov/llama.cpp
</a>
<br/>
<a href="https://github.com/abetlen/llama-cpp-python">abetlen/llama-cpp-python: Python bindings for llama.cpp
</a>
<br/>
<a href="https://github.com/shivammehta25/Matcha-TTS/pulls">Pull requests ¬∑ shivammehta25/Matcha-TTS
</a>
<br/>
<a href="https://www.reddit.com/r/panelshow/">Panelshow
</a>
<br/>
<a href="https://www.reddit.com/r/panelshow/comments/1g75nqq/best_i_test_s09_eps_510_autotranslated_subs/">Best i Test S09 Eps 5-10 Auto-translated Subs : r/panelshow
</a>
<br/>
<a href="https://www.reddit.com/r/panelshow/comments/1g6sn7s/have_i_got_new_for_you_s68e03_hannah_fry_carol/">Have I Got New For You S68E03 - Hannah Fry, Carol Vorderman and Phil Wang : r/panelshow
</a>
<br/>
<a href="https://www.youtube.com/watch?v=xbDlOdzGVl4">Have I Got News for You S68 E3. Hannah Fry. 18 Oct 24 - YouTube
</a>
<br/>
<a href="https://github.com/jimregan/Matcha-TTS/tree/more-data">jimregan/Matcha-TTS at more-data
</a>
<br/>
<a href="https://github.com/shivammehta25/Matcha-TTS/tree/4d2f9c7d9a7497380d571233414c1092539f1490/matcha/utils/data">Matcha-TTS/matcha/utils/data at 4d2f9c7d9a7497380d571233414c1092539f1490 ¬∑ shivammehta25/Matcha-TTS
</a>
<br/>
<a href="https://trinityspeechgesture.scss.tcd.ie/data/Trinity%20Speech-Gesture%20I/GENEA_Challenge_2020_data_release/readme.txt">trinityspeechgesture.scss.tcd.ie/data/Trinity Speech-Gesture I/GENEA_Challenge_2020_data_release/readme.txt
</a>
<br/>
<a href="https://github.com/ultralytics/ultralytics/issues/1238">No space left on device with plenty of space left on GPU ¬∑ Issue #1238 ¬∑ ultralytics/ultralytics
</a>
<br/>
<a href="https://stackoverflow.com/questions/1911109/how-do-i-clone-a-specific-git-branch">How do I clone a specific Git branch? - Stack Overflow
</a>
<br/>
<a href="https://github.com/shivammehta25/Matcha-TTS/pulls">Pull requests ¬∑ shivammehta25/Matcha-TTS
</a>
<br/>
<a href="https://www.instagram.com/direct/t/5060418777378294/">Inbox ‚Ä¢ Direct
</a>
<br/>
<a href="https://github.com/shivammehta25/Matcha-TTS/blob/main/synthesis.ipynb">Matcha-TTS/synthesis.ipynb at main ¬∑ shivammehta25/Matcha-TTS
</a>
<br/>
<a href="https://colab.research.google.com/drive/1T6Gydg7OZ-wsorIBivkH4-GY8YaPZLNa#scrollTo=dekwGvlZeCZb">Untitled44.ipynb - Colab
</a>
<br/>
<a href="https://github.com/shivammehta25/Matcha-TTS?tab=readme-ov-file">shivammehta25/Matcha-TTS: [ICASSP 2024] üçµ Matcha-TTS: A fast TTS architecture with conditional flow matching
</a>
<br/>
<a href="https://arxiv.org/abs/2209.03003">arxiv.org/abs/2209.03003
</a>
<br/>
<a href="https://hydra.cc/">hydra.cc
</a>
<br/>
<a href="https://www.google.com/search?q=omegaconf+load&rlz=1C5GCEM_enSE990SE991&oq=omegaconf+load&gs_lcrp=EgZjaHJvbWUyBggAEEUYOdIBCDM2NDlqMGo3qAIAsAIA&sourceid=chrome&ie=UTF-8">omegaconf load - Google Search
</a>
<br/>
<a href="https://www.google.com/search?q=python+yaml&rlz=1C5GCEM_enSE990SE991&oq=python+yaml&gs_lcrp=EgZjaHJvbWUqBggAEEUYOzIGCAAQRRg7MgYIARBFGDwyBggCEEUYPNIBCDMzOTNqMGo3qAIAsAIA&sourceid=chrome&ie=UTF-8">python yaml - Google Search
</a>
<br/>
<a href="https://docs.docker.com/reference/cli/docker/container/kill/">docker container kill | Docker Docs
</a>
<br/>
<a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/docker-specialized.html">Specialized Configurations with Docker ‚Äî NVIDIA Container Toolkit 1.16.2 documentation
</a>
<br/>
<a href="https://stackoverflow.com/questions/30172605/how-do-i-get-into-a-docker-containers-shell">How do I get into a Docker container's shell? - Stack Overflow
</a>
<br/>
<a href="https://huggingface.co/jimregan/matcha-pl-gosia">jimregan/matcha-pl-gosia ¬∑ Hugging Face
</a>
<br/>
<a href="https://huggingface.co/jimregan/matcha-ljspeech/tensorboard">jimregan/matcha-ljspeech ¬∑ Training metrics
</a>
<br/>
<a href="https://www.youtube.com/watch?v=NWa2LP9jTc4">Truth About Ultimate Self-Defense Championship - YouTube
</a>
<br/>
<a href="https://www.youtube.com/shorts/rb3nQEV61_w">Veronica Zmeykina üá∑üá∫ –í–µ—Ä–æ–Ω–∏–∫–∞ –ó–º–µ–π–∫–∏–Ω–∞ - YouTube
</a>
<br/>
<a href="https://www.youtube.com/watch?v=1DCbvQSHCvw">How did Socrates and Caesar pronounce their names? - a response to Conan O'Brien - YouTube
</a>
<br/>
<a href="https://huggingface.co/jimregan/matcha-pl-gosia">jimregan/matcha-pl-gosia ¬∑ Hugging Face
</a>
<br/>
<a href="https://huggingface.co/docs/huggingface_hub/en/guides/download">Download files from the Hub
</a>
<br/>
<a href="https://github.com/shivammehta25/Matcha-TTS/blob/main/matcha/text/cleaners.py">Matcha-TTS/matcha/text/cleaners.py at main ¬∑ shivammehta25/Matcha-TTS
</a>
<br/>
<a href="https://github.com/bootphon/phonemizer/blob/master/phonemizer/backend/espeak/espeak.py">phonemizer/phonemizer/backend/espeak/espeak.py at master ¬∑ bootphon/phonemizer
</a>
<br/>
<a href="https://docs.google.com/presentation/d/1imrb6eB1gu8ZUGqOBK3G-NMEBS1mZBVi/edit#slide=id.g291f203789e_0_92">Language Variation in Parliamentary Speeches: First Steps Towards Robust Phoneme Recognition.pptx - Google Slides
</a>
<br/>
<a href="https://docs.google.com/presentation/u/1/">Google Slides
</a>
<br/>
<a href="https://www.slideshare.net/jimregan/edit_my_uploads">My uploads
</a>
<br/>
<a href="https://www.slideshare.net/slideshow/towards-quality-transcriptions-of-large-limited-domain-archive-data/269501043">Towards quality transcriptions of large limited domain archive data | PPT
</a>
<br/>
<a href="https://github.com/jiaaro/pydub">jiaaro/pydub: Manipulate audio with a simple and easy high level interface
</a>
<br/>
<a href="https://sprakbanken.se/hostworkshop">Autumn Workshop | The language bank
</a>
<br/>
<a href="https://www.flickr.com/photos/jimregan/54077953649/in/photostream/">Screenshot_20241019-144103 | Jim O'Regan | Flickr
</a>
<br/>
<a href="https://www.instagram.com/">Instagram
</a>
<br/>
<a href="https://de.wiktionary.org/wiki/sportlich">sporty ‚Äì Wiktionary
</a>
<br/>
<a href="https://en.wiktionary.org/wiki/Category:Cockney_rhyming_slang">Category:Cockney rhyming slang - Wiktionary, the free dictionary
</a>
<br/>
<a href="https://en.wiktionary.org/wiki/skint#English">skint - Wiktionary, the free dictionary
</a>
<br/>
<a href="https://commons.wikimedia.org/wiki/File:En-au-skint.ogg">File:En-au-skint.ogg - Wikimedia Commons
</a>
<br/>
<a href="https://commons.wikimedia.org/wiki/Category:English_pronunciation">Category:English pronunciation - Wikimedia Commons
</a>
<br/>
<a href="https://commons.wikimedia.org/wiki/Category:Wikitongues_videos_by_language">Category:Wikitongues videos by language - Wikimedia Commons
</a>
<br/>
<a href="https://commons.wikimedia.org/wiki/File:WIKITONGUES-_M%C3%A1ria_speaking_Swabian_and_Hungarian.webm">File:WIKITONGUES- M√°ria speaking Swabian and Hungarian.webm - Wikimedia Commons
</a>
<br/>
<a href="https://www.youtube.com/watch?v=hd5MB1W5Rg8&t=123s">WIKITONGUES: Lene and B√∏rre speaking Northern Sami - YouTube
</a>
<br/>
<a href="https://www.youtube.com/watch?v=wjwQkOzzSAg&t=13s">WIKITONGUES: Irena speaking Northern Sami - YouTube
</a>
<br/>
<a href="https://www.youtube.com/watch?v=2IzpOFfd4Zs">WIKITONGUES: Anna speaking Kildin Saami - YouTube
</a>
<br/>
<a href="https://www.google.com/search?q=northern+sami+pronunciation+lexicon&rlz=1C5GCEM_enSE990SE991&oq=northern+sami+pronunciation+lexicon&gs_lcrp=EgZjaHJvbWUyBggAEEUYOTIHCAEQIRigAdIBCDc1MThqMGo3qAIAsAIA&sourceid=chrome&ie=UTF-8">northern sami pronunciation lexicon - Google Search
</a>
<br/>
<a href="https://forvo.com/languages-pronunciations/sme/page-8/">Northern Sami: Learn how to pronounce in Northern Sami
</a>
<br/>
<a href="https://forvo.com/about/">About Forvo, the audio pronunciation guide
</a>
<br/>
<a href="https://forvo.com/terms-and-conditions/">Forvo, the pronunciation guide, license of use
</a>
<br/>
<a href="https://huggingface.co/jimregan/matcha-mmconv-test1/blob/main/train.log">train.log ¬∑ jimregan/matcha-mmconv-test1 at main
</a>
<br/>
<a href="https://huggingface.co/jimregan/matcha-mmconv-test1/tensorboard">jimregan/matcha-mmconv-test1 ¬∑ Training metrics
</a>
<br/>
<a href="https://discuss.pytorch.org/t/how-to-fix-cuda-error-device-side-assert-triggered-error/137553">How to fix ‚ÄúCUDA error: device-side assert triggered‚Äù error? - PyTorch Forums
</a>
<br/>
<a href="https://github.com/pytorch/pytorch/issues/121493">Cuda Indexing Error on GPU ¬∑ Issue #121493 ¬∑ pytorch/pytorch
</a>
<br/>
<a href="https://github.com/git-lfs/git-lfs/issues/4376">How do I "fix" a missing lfs pattern, and rewrite history? ¬∑ Issue #4376 ¬∑ git-lfs/git-lfs
</a>
<br/>
<a href="https://dhnb.eu/conferences/dhnb2025/">DHNB 2025 ‚Äì DHNB
</a>
<br/>
<a href="https://www.overleaf.com/project/67182024aaf299f9d0b85621">dhnb - Online LaTeX Editor Overleaf
</a>
<br/>
<a href="https://www.uu.se/kontakt-och-organisation/personal?query=N3-992">Eva Pettersson - Uppsala University
</a>
<br/>
<a href="https://uu.diva-portal.org/smash/record.jsf?pid=diva2%3A1823255&dswid=9266">Low-Resource Techniques for Analysing the Rhetorical Structure of Swedish Historical Petitions
</a>
<br/>
<a href="https://uu.diva-portal.org/smash/record.jsf?pid=diva2%3A885117&dswid=7468">Spelling Normalisation and Linguistic Analysis of Historical Text for Information Extraction
</a>
<br/>
<a href="https://en.wikipedia.org/wiki/Swedish_phonology">Swedish phonology - Wikipedia
</a>
<br/>
<a href="https://support.google.com/chrome/thread/283109775/disable-resume-browsing?hl=en">Disable "resume browsing" - Google Chrome Community
</a>
<br/>
<a href="https://en.wiktionary.org/wiki/sen#Swedish">sen - Wiktionary, the free dictionary
</a>
<br/>
<a href="https://sv.wiktionary.org/wiki/ekologisk">organic - Wiktionary
</a>
<br/>
<a href="https://www.svenskaakademien.se/svenska-spraket/svenska-akademiens-ordlista-saol">Svenska Akademiens ordlista (SAOL)
</a>
<br/>
<a href="https://svenska.se/tre/?sok=ackumulator&pz=8">ackumulator | svenska.se
</a>
<br/>
<a href="https://folkets-lexikon.csc.kth.se/folkets/folkets.en.html#lookup&ekologiskt">The People's Dictionary
</a>
<br/>
<a href="undefined">
</a>
<br/>
</body>
</html>