{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/Users/joregan/Playing/hu-tts/hungarian-single-speaker-tts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(PATH)\n",
    "outdir = path / \"data\"\n",
    "transcript = path / \"transcript.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text, norm = False):\n",
    "    if text.endswith(\" -\"):\n",
    "        text = text[:-2]\n",
    "        text = text.replace(\".S \", \". S \")\n",
    "    if norm:\n",
    "        text = text.replace(\". \", \" \")\n",
    "        if len(text) > 1 and text[-1] in [\".\", \"!\", \"?\", \":\"]:\n",
    "            text = text[:-1]\n",
    "        text = text.replace(\" -, \", \" \")\n",
    "        text = text.replace(\" - \", \" \")\n",
    "        text = text.replace(\". \", \" \")\n",
    "        text = text.replace(\", \", \" \")\n",
    "        text = text.replace(\"? \", \" \")\n",
    "        text = text.replace(\": \", \" \")\n",
    "        text = text.replace(\"! \", \" \")\n",
    "        text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open(str(transcript)) as ts:\n",
    "    for line in ts.readlines():\n",
    "        data.append(line.strip().split(\"|\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen():\n",
    "    for i in data:\n",
    "        filepath = i[0]\n",
    "        fileid = filepath.split(\"/\")[1].replace(\".wav\", \"\")\n",
    "        text = i[1]\n",
    "        lightly_cleaned = clean_text(text)\n",
    "        fully_cleaned = clean_text(text, True)\n",
    "        yield {\n",
    "            \"id\": fileid,\n",
    "            \"audio\": str(path / filepath),\n",
    "            \"original_text\": lightly_cleaned,\n",
    "            \"text\": fully_cleaned,\n",
    "            \"duration\": float(i[3])\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-2ea64471c62bb335\n",
      "/Users/joregan/opt/anaconda3/envs/hf/lib/python3.9/site-packages/datasets/builder.py:712: FutureWarning: 'use_auth_token' was deprecated in version 2.7.1 and will be removed in 3.0.0. Pass `use_auth_token` to the initializer/`load_dataset_builder` instead.\n",
      "  warnings.warn(\n",
      "Found cached dataset generator (/Users/joregan/.cache/huggingface/datasets/generator/default-2ea64471c62bb335/0.0.0)\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, Audio\n",
    "dataset = Dataset.from_generator(data_gen).cast_column(\"audio\", Audio(sampling_rate=22050))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.42s/ba]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.88s/ba]4%|█▍        | 1/7 [00:21<02:08, 21.40s/it]\n",
      "100%|██████████| 1/1 [00:15<00:00, 15.39s/ba]9%|██▊       | 2/7 [00:58<02:33, 30.63s/it]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.11s/ba]3%|████▎     | 3/7 [01:36<02:15, 33.89s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.30s/ba]7%|█████▋    | 4/7 [02:02<01:32, 30.90s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/ba]1%|███████▏  | 5/7 [02:26<00:56, 28.27s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.14s/ba]6%|████████▌ | 6/7 [02:53<00:27, 27.88s/it]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 7/7 [03:06<00:00, 26.57s/it]\n",
      "Deleting unused files from dataset repository: 100%|██████████| 7/7 [02:18<00:00, 19.81s/it]\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [75], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset\u001b[39m.\u001b[39;49mpush_to_hub(\u001b[39m\"\u001b[39;49m\u001b[39mKTH/hungarian-single-speaker-tts\u001b[39;49m\u001b[39m\"\u001b[39;49m, max_shard_size\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m500MB\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/hf/lib/python3.9/site-packages/datasets/arrow_dataset.py:4966\u001b[0m, in \u001b[0;36mDataset.push_to_hub\u001b[0;34m(self, repo_id, split, private, token, branch, max_shard_size, num_shards, shard_size, embed_external_files)\u001b[0m\n\u001b[1;32m   4964\u001b[0m     dataset_metadata \u001b[39m=\u001b[39m DatasetMetadata\u001b[39m.\u001b[39mfrom_readme(Path(dataset_readme_path))\n\u001b[1;32m   4965\u001b[0m     dataset_infos: DatasetInfosDict \u001b[39m=\u001b[39m DatasetInfosDict\u001b[39m.\u001b[39mfrom_metadata(dataset_metadata)\n\u001b[0;32m-> 4966\u001b[0m     repo_info \u001b[39m=\u001b[39m dataset_infos[\u001b[39mnext\u001b[39;49m(\u001b[39miter\u001b[39;49m(dataset_infos))]\n\u001b[1;32m   4967\u001b[0m \u001b[39m# get the deprecated dataset_infos.json to uodate them\u001b[39;00m\n\u001b[1;32m   4968\u001b[0m \u001b[39melif\u001b[39;00m config\u001b[39m.\u001b[39mDATASETDICT_INFOS_FILENAME \u001b[39min\u001b[39;00m repo_files:\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset.push_to_hub(\"KTH/hungarian-single-speaker-tts\", max_shard_size=\"500MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "07bb6a9d2164abcdbb8286fc1e56d7ab9d62a92a750c8fe8e3bd5ac6fe973d15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
