{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14d0d2ba",
   "metadata": {},
   "source": [
    "# Recognizer vs MFA Alignment Scoring\n",
    "This notebook compares phonetic recognizer outputs to MFA-aligned results using edit distance, soft-DTW cost, and formant validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0554de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import euclidean\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d738ceb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein_distance(s1, s2):\n",
    "    s1 = s1.split()\n",
    "    s2 = s2.split()\n",
    "    m, n = len(s1), len(s2)\n",
    "    dp = np.zeros((m+1, n+1), dtype=int)\n",
    "    for i in range(m+1):\n",
    "        for j in range(n+1):\n",
    "            if i == 0: dp[i][j] = j\n",
    "            elif j == 0: dp[i][j] = i\n",
    "            elif s1[i-1] == s2[j-1]:\n",
    "                dp[i][j] = dp[i-1][j-1]\n",
    "            else:\n",
    "                dp[i][j] = 1 + min(dp[i-1][j], dp[i][j-1], dp[i-1][j-1])\n",
    "    return dp[m][n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b8bb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_dtw_cost(audio_frames, ipa_embeddings):\n",
    "    T, D = audio_frames.shape\n",
    "    L, _ = ipa_embeddings.shape\n",
    "    cost_matrix = np.zeros((T, L))\n",
    "    for t in range(T):\n",
    "        for l in range(L):\n",
    "            cost_matrix[t, l] = np.linalg.norm(audio_frames[t] - ipa_embeddings[l])\n",
    "    return np.mean(np.min(cost_matrix, axis=0))  # Crude approximation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db31e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_vowel_formants(f1, f2, recognizer_ref, mfa_ref):\n",
    "    return {\n",
    "        \"target_match\": euclidean((f1, f2), recognizer_ref),\n",
    "        \"mfa_match\": euclidean((f1, f2), mfa_ref)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd8d774",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_alignment(word, recognizer_ipa, mfa_ipa, f1, f2, \n",
    "                    recognizer_ref_formants, mfa_ref_formants,\n",
    "                    audio_frames, ipa_embeddings):\n",
    "    edit_distance = levenshtein_distance(recognizer_ipa, mfa_ipa)\n",
    "    dtw_cost = soft_dtw_cost(audio_frames, ipa_embeddings)\n",
    "    formant_result = compare_vowel_formants(f1, f2, recognizer_ref_formants, mfa_ref_formants)\n",
    "    flag = \"confident\"\n",
    "    if formant_result[\"mfa_match\"] < formant_result[\"target_match\"]:\n",
    "        flag = \"discrepant_vowel\"\n",
    "    elif edit_distance > 2:\n",
    "        flag = \"high_edit_distance\"\n",
    "    return {\n",
    "        \"word\": word,\n",
    "        \"recognizer_ipa\": recognizer_ipa,\n",
    "        \"mfa_ipa\": mfa_ipa,\n",
    "        \"edit_distance\": int(edit_distance),\n",
    "        \"soft_dtw_cost\": float(dtw_cost),\n",
    "        \"formant_agreement\": formant_result,\n",
    "        \"flag\": flag\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9928eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_scoring_dataframe(words, recognizer_ipas, mfa_ipas, formant_pairs,\n",
    "                            recognizer_refs, mfa_refs, audio_frame_list, ipa_embedding_list):\n",
    "    records = []\n",
    "    for i in range(len(words)):\n",
    "        record = score_alignment(\n",
    "            word=words[i],\n",
    "            recognizer_ipa=recognizer_ipas[i],\n",
    "            mfa_ipa=mfa_ipas[i],\n",
    "            f1=formant_pairs[i][0],\n",
    "            f2=formant_pairs[i][1],\n",
    "            recognizer_ref_formants=recognizer_refs[i],\n",
    "            mfa_ref_formants=mfa_refs[i],\n",
    "            audio_frames=audio_frame_list[i],\n",
    "            ipa_embeddings=ipa_embedding_list[i]\n",
    "        )\n",
    "        records.append(record)\n",
    "    return pd.DataFrame.from_records(records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09782310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example mock data for testing\n",
    "words = [\"elephant\", \"banana\", \"zebra\"]\n",
    "recognizer_ipas = [\"ɛ l ə f ə n t\", \"b ə n æ n ə\", \"z i b ɹ ə\"]\n",
    "mfa_ipas = [\"ɛ l ə f n̩ t\", \"b ə n ə n ə\", \"z ɛ b ɹ ə\"]\n",
    "formant_pairs = [(400, 1800), (500, 1600), (450, 1700)]\n",
    "recognizer_refs = [(600, 1900), (550, 1500), (480, 1600)]\n",
    "mfa_refs = [(400, 1800), (500, 1600), (450, 1700)]\n",
    "audio_frame_list = [np.random.rand(60, 16) for _ in range(3)]\n",
    "ipa_embedding_list = [np.random.rand(7, 16) for _ in range(3)]\n",
    "\n",
    "df = build_scoring_dataframe(words, recognizer_ipas, mfa_ipas, formant_pairs,\n",
    "                             recognizer_refs, mfa_refs, audio_frame_list, ipa_embedding_list)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52aa2a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to JSON\n",
    "output_path = \"recognizer_mfa_scoring_output.json\"\n",
    "df.to_json(output_path, orient=\"records\", indent=2)\n",
    "print(f\"Saved to {output_path}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
