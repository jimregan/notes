{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "157976ee",
   "metadata": {},
   "source": [
    "[Chat](https://chatgpt.com/g/g-p-684dc8075e508191ae070a06c599469d-current-things-14-june-2025/c/685942a9-bec0-8011-b909-3d2c8bd9e1d6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c4fdb5",
   "metadata": {},
   "source": [
    "Great, then let‚Äôs **break down the recognizer retraining task into Docker-based action steps**, from environment setup to training. This will help you not just finish the task, but also deliver a reusable container for your supervisor.\n",
    "\n",
    "---\n",
    "\n",
    "## üê≥ ACTION PLAN: Re-training the Phonetic-Word Recognizer in Docker\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ PHASE 1: Prepare Docker Environment\n",
    "\n",
    "#### ‚úÖ 1. Create Dockerfile\n",
    "\n",
    "* [ ] Base image: `pytorch/pytorch:latest` (or a CUDA-compatible variant if GPU support is needed)\n",
    "* [ ] Install dependencies:\n",
    "\n",
    "  * `transformers`\n",
    "  * `datasets`\n",
    "  * `torchaudio`\n",
    "  * `librosa`\n",
    "  * `jiwer` (for error rates)\n",
    "  * `sox`, `ffmpeg` (for audio handling)\n",
    "  * any forced aligner tools, if relevant (e.g., MFA CLI)\n",
    "* [ ] Install your recognizer training code and scripts\n",
    "* [ ] Set up working directory and entrypoint\n",
    "\n",
    "‚úÖ **Goal:** Self-contained environment to fine-tune wav2vec2 on phonetic data.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ PHASE 2: Define Volumes / Inputs\n",
    "\n",
    "#### ‚úÖ 2. Organize Required Inputs\n",
    "\n",
    "* [ ] Waxholm audio files (already converted to WAV, 16kHz)\n",
    "* [ ] Corrected phonetic transcriptions, space-separated per utterance\n",
    "* [ ] CSV/JSONL/TSV format: `utt_id, wav_path, phonetic_label`\n",
    "* [ ] (Optional) Riksdag segments for silver data or later evaluation\n",
    "\n",
    "‚úÖ **Tip:** Keep data and output outside the container and mount with `-v`.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ PHASE 3: Train Inside Docker\n",
    "\n",
    "#### ‚úÖ 3. Launch Training\n",
    "\n",
    "* [ ] Use HuggingFace `Trainer` or PyTorch directly\n",
    "* [ ] Confirm:\n",
    "\n",
    "  * Label set fully matches phoneme inventory\n",
    "  * Output predictions are space-separated phonetic words\n",
    "* [ ] Save:\n",
    "\n",
    "  * Model checkpoint\n",
    "  * Config + tokenizer\n",
    "  * Training log\n",
    "  * Error rates\n",
    "\n",
    "‚úÖ **Goal:** Reproducible, containerized training pipeline with traceable outputs.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ PHASE 4: Package and Share\n",
    "\n",
    "#### ‚úÖ 4. Clean and Share Container\n",
    "\n",
    "* [ ] Create a versioned tag for your container: `swedish-phonrec:v1`\n",
    "* [ ] Write a short `README.md`:\n",
    "\n",
    "  * Usage\n",
    "  * Expected input format\n",
    "  * Entrypoint to train/test\n",
    "* [ ] Push to Docker Hub, GHCR, or send `.tar.gz` if needed\n",
    "\n",
    "‚úÖ **Bonus:** This becomes your base for other tasks your supervisor needs.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Today's Concrete Subtasks\n",
    "\n",
    "If you want *just a day's worth of progress*:\n",
    "\n",
    "| Task                               | Estimated Time | Notes                  |\n",
    "| ---------------------------------- | -------------- | ---------------------- |\n",
    "| Write Dockerfile skeleton          | 30‚Äì60 min      | Use PyTorch base image |\n",
    "| Set up phoneme label list          | 15‚Äì30 min      | Include missing phones |\n",
    "| Format Waxholm into training CSV   | 1 hr           | utt\\_id, wav, label    |\n",
    "| Add phonetic-word decoder to model | 30 min         | If not already set     |\n",
    "\n",
    "---\n",
    "\n",
    "Would you like a working Dockerfile starter and a training data format example for this? I can write that next so you don‚Äôt have to think about it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e55247",
   "metadata": {},
   "source": [
    "```\n",
    "python ../transformers/src/transformers/models/wav2vec2/convert_wav2vec2_original_pytorch_checkpoint_to_pytorch.py --pytorch_dump_folder /home/joregan/wav2vec2-swedish-phonetic-waxholm/ --checkpoint_path $(find $HOME/outputs/ -name '*_best.pt'|tail -n 1) --dict_path /home/joregan/waxholm_fairseq/dict.ltr.txt --config_path /home/joregan/wav2vec2-swedish-phonetic-waxholm/config.json\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd0dba5",
   "metadata": {},
   "source": [
    "Needs:\n",
    "- [X] Data\n",
    "- [ ] Output model path\n",
    "- [ ] KB base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016c3c92",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a018bb1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
