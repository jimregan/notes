{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVXPmmA6f9Y8"
      },
      "source": [
        "# Trying to use pocketsphinx to word align\n",
        "\n",
        "> \"Because timing accuracy in ASR is getting progressively worse, look backwards\"\n",
        "\n",
        "- branch: master\n",
        "- comments: false\n",
        "- categories: [pocketsphinx, polish, alignment]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQCCGpYCf9Y9",
        "outputId": "d556c596-7466-485e-daaf-45344b97e29d"
      },
      "outputs": [],
      "source": [
        "from pydub import AudioSegment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "yuMuYOFof9Y-"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install pocketsphinx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "BIXlkjJOgKuY"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install lupa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3kZ7eEpCuS9H"
      },
      "outputs": [],
      "source": [
        "PL_IPA = r\"\"\"\n",
        "-- Barely modified version of\n",
        "-- https://en.wiktionary.org/wiki/Module:pl-IPA\n",
        "-- (so, CC-BY-SA)\n",
        "-- This was deleted in 2024: https://en.wiktionary.org/w/index.php?title=Special:Log&type=delete&page=Module:pl-IPA\n",
        "local export = {}\n",
        "\n",
        "local letters2phones = {\n",
        "\t[\"a\"] = {\n",
        "\t\t[\"u\"  ] = { \"a\", \"w\" },\n",
        "\t\t[false] = \"a\",\n",
        "\t},\n",
        "\t[\"ą\"] = {\n",
        "\t\t[\"ł\"  ] = { \"ɔ\", \"w\" },\n",
        "\t\t[false] = \"ɔ̃\",\n",
        "\t},\n",
        "\t[\"b\"] = {\n",
        "\t\t[\"i\"  ] = {\n",
        "\t\t\t[\"a\"  ] = { \"bʲ\", \"a\" },\n",
        "\t\t\t[\"ą\"  ] = { \"bʲ\", \"ɔ̃\" },\n",
        "\t\t\t[\"e\"  ] = { \"bʲ\", \"ɛ\" },\n",
        "\t\t\t[\"ę\"  ] = { \"bʲ\", \"ɛ̃\" },\n",
        "\t\t\t[\"i\"  ] = { \"bʲ\", \"j\", \"i\" },\n",
        "\t\t\t[\"o\"  ] = { \"bʲ\", \"ɔ\" },\n",
        "\t\t\t[\"ó\"  ] = { \"bʲ\", \"u\" },\n",
        "\t\t\t[\"u\"  ] = { \"bʲ\", \"u\" },\n",
        "\t\t\t[false] = { \"bʲ\", \"i\" }\n",
        "\t\t\t},\n",
        "\t\t[false] = \"b\"\n",
        "\t},\n",
        "\t[\"c\"] = {\n",
        "\t\t[\"i\"  ] = {\n",
        "\t\t\t[\"ą\"  ] = { \"t͡ɕ\", \"ɔ̃\" },\n",
        "\t\t\t[\"a\"  ] = { \"t͡ɕ\", \"a\" },\n",
        "\t\t\t[\"e\"  ] = { \"t͡ɕ\", \"ɛ\" },\n",
        "\t\t\t[\"ę\"  ] = { \"t͡ɕ\", \"ɛ̃\" },\n",
        "\t\t\t[\"o\"  ] = { \"t͡ɕ\", \"ɔ\" },\n",
        "\t\t\t[\"ó\"  ] = { \"t͡ɕ\", \"u\" },\n",
        "\t\t\t[\"u\"  ] = { \"t͡ɕ\", \"u\" },\n",
        "\t\t\t[\"y\"  ] = { \"t͡ɕ\", \"ɨ\" },\n",
        "\t\t\t[false] = { \"t͡ɕ\", \"i\" }\n",
        "\t\t},\n",
        "\t\t[\"h\"  ] = {\n",
        "\t\t[\"i\" ] = {\n",
        "\t\t\t[\"a\"  ] = { \"xʲ\", \"j\", \"a\" },\n",
        "\t\t\t[\"ą\"  ] = { \"xʲ\", \"j\", \"ɔ̃\" },\n",
        "\t\t\t[\"e\"  ] = { \"xʲ\", \"j\", \"ɛ\" },\n",
        "\t\t\t[\"ę\"  ] = { \"xʲ\", \"j\", \"ɛ̃\" },\n",
        "\t\t\t[\"i\"  ] = { \"xʲ\", \"j\", \"i\" },\n",
        "\t\t\t[\"o\"  ] = { \"xʲ\", \"j\", \"ɔ\" },\n",
        "\t\t\t[\"ó\"  ] = { \"xʲ\", \"j\", \"u\" },\n",
        "\t\t\t[\"u\"  ] = { \"xʲ\", \"j\", \"u\" },\n",
        "\t\t\t[false] = { \"xʲ\", \"i\" }\n",
        "\t\t\t},\n",
        "\t\t[false] = \"x\"\n",
        "                },\n",
        "\t\t[\"z\"  ] = \"t͡ʂ\",\n",
        "\t\t[false] = \"t͡s\"\n",
        "\t},\n",
        "\t[\"ć\"] = \"t͡ɕ\",\n",
        "\t[\"d\"] = {\n",
        "\t\t[\"z\"  ] = {\n",
        "\t\t\t[\"i\"  ] = {\n",
        "\t\t\t\t[\"ą\"  ] = { \"d͡ʑ\", \"ɔ̃\" },\n",
        "\t\t\t\t[\"a\"  ] = { \"d͡ʑ\", \"a\" },\n",
        "\t\t\t\t[\"e\"  ] = { \"d͡ʑ\", \"ɛ\" },\n",
        "\t\t\t\t[\"ę\"  ] = { \"d͡ʑ\", \"ɛ̃\" },\n",
        "\t\t\t\t[\"o\"  ] = { \"d͡ʑ\", \"ɔ\" },\n",
        "\t\t\t\t[\"ó\"  ] = { \"d͡ʑ\", \"u\" },\n",
        "\t\t\t\t[\"u\"  ] = { \"d͡ʑ\", \"u\" },\n",
        "\t\t\t\t[\"y\"  ] = { \"d͡ʑ\", \"ɨ\" },\n",
        "\t\t\t\t[false] = { \"d͡ʑ\", \"i\" }\n",
        "\t\t\t},\n",
        "\t\t\t[false] = \"d͡z\"\n",
        "\t\t},\n",
        "\t\t[\"ż\"  ] = \"d͡ʐ\",\n",
        "\t\t[\"ź\"  ] = \"d͡ʑ\",\n",
        "\t\t[false] = \"d\"\n",
        "\t},\n",
        "\t[\"e\"] = {\n",
        "\t\t[\"u\"  ] = { \"ɛ\", \"w\" },\n",
        "\t\t[\"e\"  ] = { \"ɛ\", \"ʔ\", \"ɛ\" }, -- reedukacja, reewaluacja, etc.\n",
        "\t\t[false] = \"ɛ\",\n",
        "\t},\n",
        "\t[\"ę\"] = {\n",
        "\t\t[\"l\"  ] = { \"ɛ\", \"l\" },\n",
        "\t\t[\"ł\"  ] = { \"ɛ\", \"w\" },\n",
        "\t\t[false] = \"ɛ̃\",\n",
        "\t},\n",
        "\t[\"f\"] = {\n",
        "\t\t[\"i\"  ] = {\n",
        "\t\t\t[\"a\"  ] = { \"fʲ\", \"a\" },\n",
        "\t\t\t[\"ą\"  ] = { \"fʲ\", \"ɔ̃\" },\n",
        "\t\t\t[\"e\"  ] = { \"fʲ\", \"ɛ\" },\n",
        "\t\t\t[\"ę\"  ] = { \"fʲ\", \"ɛ̃\" },\n",
        "\t\t\t[\"i\"  ] = { \"fʲ\", \"j\", \"i\" },\n",
        "\t\t\t[\"o\"  ] = { \"fʲ\", \"ɔ\" },\n",
        "\t\t\t[\"ó\"  ] = { \"fʲ\", \"u\" },\n",
        "\t\t\t[\"u\"  ] = { \"fʲ\", \"u\" },\n",
        "\t\t\t[false] = { \"fʲ\", \"i\" }\n",
        "\t\t\t},\n",
        "\t\t[false] = \"f\"\n",
        "\t},\n",
        "\t[\"g\"] = {\n",
        "\t\t[\"i\" ] = {\n",
        "\t\t\t[\"a\"  ] = { \"ɡʲ\", \"j\", \"a\" },\n",
        "\t\t\t[\"ą\"  ] = { \"ɡʲ\", \"ɔ̃\" }, -- only forms of \"giąć\"\n",
        "\t\t\t[\"e\"  ] = { \"ɡʲ\", \"ɛ\" },\n",
        "\t\t\t[\"ę\"  ] = { \"ɡʲ\", \"ɛ̃\" }, -- only forms of \"giąć\" and \"giętki\"\n",
        "\t\t\t[\"i\"  ] = { \"ɡʲ\", \"j\", \"i\" },\n",
        "\t\t\t[\"o\"  ] = { \"ɡʲ\", \"j\", \"ɔ\" },\n",
        "\t\t\t[\"ó\"  ] = { \"ɡʲ\", \"j\", \"u\" },\n",
        "\t\t\t[\"u\"  ] = { \"ɡʲ\", \"j\", \"u\" },\n",
        "\t\t\t[false] = { \"ɡʲ\", \"i\" }\n",
        "\t\t\t},\n",
        "\t\t[false] = \"ɡ\"\n",
        "\t},\n",
        "\t[\"h\"] = {\n",
        "\t\t[\"i\" ] = {\n",
        "\t\t\t[\"a\"  ] = { \"xʲ\", \"j\", \"a\" },\n",
        "\t\t\t[\"ą\"  ] = { \"xʲ\", \"j\", \"ɔ̃\" },\n",
        "\t\t\t[\"e\"  ] = { \"xʲ\", \"j\", \"ɛ\" },\n",
        "\t\t\t[\"ę\"  ] = { \"xʲ\", \"j\", \"ɛ̃\" },\n",
        "\t\t\t[\"i\"  ] = { \"xʲ\", \"j\", \"i\" },\n",
        "\t\t\t[\"o\"  ] = { \"xʲ\", \"j\", \"ɔ\" },\n",
        "\t\t\t[\"ó\"  ] = { \"xʲ\", \"j\", \"u\" },\n",
        "\t\t\t[\"u\"  ] = { \"xʲ\", \"j\", \"u\" },\n",
        "\t\t\t[false] = { \"xʲ\", \"i\" }\n",
        "\t\t\t},\n",
        "\t\t[false] = \"x\"\n",
        "        },\n",
        "\t[\"i\"] = \"i\",\n",
        "\t[\"j\"] = \"j\",\n",
        "\t[\"k\"] = {\n",
        "\t\t[\"i\" ] = {\n",
        "\t\t\t[\"a\"  ] = { \"kʲ\", \"j\", \"a\" },\n",
        "\t\t\t[\"ą\"  ] = { \"kʲ\", \"j\", \"ɔ̃\" },\n",
        "\t\t\t[\"e\"  ] = { \"kʲ\", \"ɛ\" },\n",
        "\t\t\t[\"ę\"  ] = { \"kʲ\", \"j\", \"ɛ̃\" },\n",
        "\t\t\t[\"i\"  ] = { \"kʲ\", \"j\", \"i\" },\n",
        "\t\t\t[\"o\"  ] = { \"kʲ\", \"j\", \"ɔ\" },\n",
        "\t\t\t[\"ó\"  ] = { \"kʲ\", \"j\", \"u\" },\n",
        "\t\t\t[\"u\"  ] = { \"kʲ\", \"j\", \"u\" },\n",
        "\t\t\t[false] = { \"kʲ\", \"i\" }\n",
        "\t\t\t},\n",
        "\t\t[false] = \"k\"\n",
        "\t},\n",
        "\t[\"l\"] = {\n",
        "\t\t[\"i\" ] = {\n",
        "\t\t\t[\"a\"  ] = { \"lʲ\", \"a\" },\n",
        "\t\t\t[\"ą\"  ] = { \"lʲ\", \"ɔ̃\" },\n",
        "\t\t\t[\"e\"  ] = { \"lʲ\", \"ɛ\" },\n",
        "\t\t\t[\"ę\"  ] = { \"lʲ\", \"ɛ̃\" },\n",
        "\t\t\t[\"i\"  ] = { \"lʲ\", \"j\", \"i\" },\n",
        "\t\t\t[\"o\"  ] = { \"lʲ\", \"ɔ\" },\n",
        "\t\t\t[\"ó\"  ] = { \"lʲ\", \"u\" },\n",
        "\t\t\t[\"u\"  ] = { \"lʲ\", \"u\" },\n",
        "\t\t\t[false] = { \"lʲ\", \"i\" }\n",
        "\t\t\t},\n",
        "\t\t[false] = \"l\"\n",
        "        },\n",
        "\t[\"ł\"] = \"w\",\n",
        "\t[\"m\"] = {\n",
        "\t\t[\"i\"  ] = {\n",
        "\t\t\t[\"a\"  ] = { \"mʲ\", \"a\" },\n",
        "\t\t\t[\"ą\"  ] = { \"mʲ\", \"ɔ̃\" },\n",
        "\t\t\t[\"e\"  ] = { \"mʲ\", \"ɛ\" },\n",
        "\t\t\t[\"ę\"  ] = { \"mʲ\", \"ɛ̃\" },\n",
        "\t\t\t[\"i\"  ] = { \"mʲ\", \"j\", \"i\" },\n",
        "\t\t\t[\"o\"  ] = { \"mʲ\", \"ɔ\" },\n",
        "\t\t\t[\"ó\"  ] = { \"mʲ\", \"u\" },\n",
        "\t\t\t[\"u\"  ] = { \"mʲ\", \"u\" },\n",
        "\t\t\t[false] = { \"mʲ\", \"i\" }\n",
        "\t\t\t},\n",
        "\t\t[false] = \"m\"\n",
        "\t},\n",
        "\t[\"n\"] = {\n",
        "\t\t[\"i\"  ] = {\n",
        "\t\t\t[\"ą\"  ] = { \"ɲ\", \"ɔ̃\" },\n",
        "\t\t\t[\"a\"  ] = { \"ɲ\", \"a\" },\n",
        "\t\t\t[\"e\"  ] = { \"ɲ\", \"ɛ\" },\n",
        "\t\t\t[\"ę\"  ] = { \"ɲ\", \"ɛ̃\" },\n",
        "\t\t\t[\"i\"  ] = { \"ɲ\", \"j\", \"i\" },\n",
        "\t\t\t[\"o\"  ] = { \"ɲ\", \"ɔ\" },\n",
        "\t\t\t[\"ó\"  ] = { \"ɲ\", \"u\" },\n",
        "\t\t\t[\"u\"  ] = { \"ɲ\", \"u\" },\n",
        "\t\t\t[false] = { \"ɲ\", \"i\" }\n",
        "\t\t},\n",
        "\n",
        "\t\t-- \"bank\", \"bankowy\", \"bankowość\" is [baŋk], [baŋˈkɔ.vɨ], [baŋˈko.voɕt͡ɕ]\n",
        "\t\t-- but \"wybranka\", \"łapanka\" and \"zapinka\" would be rather [vɨˈbran.ka], [waˈpan.ka] and [zaˈpin.ka].\n",
        "\t\t-- looks like \"bank\" and related should be manually transcribed.\n",
        "\t\t-- although [bank], etc. is not incorrect, even if somewhat posh. (In the regions where [nk] and [ŋk] can be distinguished, it's actually [baŋk] that is posh).\n",
        "\n",
        "\t\t-- [\"g\"  ] = { \"ŋ\", \"ɡ\" },\n",
        "\t\t-- [\"k\"  ] = { \"ŋ\", \"k\" },\n",
        "\t\t[false] = \"n\"\n",
        "\t},\n",
        "\t[\"ń\"] = \"ɲ\",\n",
        "\t[\"o\"] = {\n",
        "\t\t[\"o\"  ] = { \"ɔ\", \"ʔ\", \"ɔ\" }, -- żaroodporny, ognioodporny, etc.\n",
        "\t\t[false] = \"ɔ\" ,\n",
        "\t},\n",
        "\t[\"ó\"] = \"u\",\n",
        "\t[\"p\"] = {\n",
        "\t\t[\"i\"  ] = {\n",
        "\t\t\t-- piątek, piasek, etc.\n",
        "\t\t\t[\"a\"  ] = { \"pʲ\", \"a\" },\n",
        "\t\t\t[\"ą\"  ] = { \"pʲ\", \"ɔ̃\" },\n",
        "\t\t\t[\"e\"  ] = { \"pʲ\", \"ɛ\" },\n",
        "\t\t\t[\"ę\"  ] = { \"pʲ\", \"ɛ̃\" },\n",
        "\t\t\t[\"i\"  ] = { \"pʲ\", \"j\", \"i\" },\n",
        "\t\t\t[\"o\"  ] = { \"pʲ\", \"ɔ\" },\n",
        "\t\t\t[\"ó\"  ] = { \"pʲ\", \"u\" },\n",
        "\t\t\t[\"u\"  ] = { \"pʲ\", \"u\" },\n",
        "\t\t\t[false] = { \"pʲ\", \"i\" }\n",
        "\t\t\t},\n",
        "\t\t[false] = \"p\"\n",
        "\t},\n",
        "\t[\"r\"] = {\n",
        "\t\t[\"i\" ] = {\n",
        "\t\t\t[\"a\"  ] = { \"rʲ\", \"j\", \"a\" },\n",
        "\t\t\t[\"ą\"  ] = { \"rʲ\", \"j\", \"ɔ̃\" },\n",
        "\t\t\t[\"e\"  ] = { \"rʲ\", \"j\", \"ɛ\" },\n",
        "\t\t\t[\"ę\"  ] = { \"rʲ\", \"j\", \"ɛ̃\" },\n",
        "\t\t\t[\"i\"  ] = { \"rʲ\", \"j\", \"i\" },\n",
        "\t\t\t[\"o\"  ] = { \"rʲ\", \"j\", \"ɔ\" },\n",
        "\t\t\t[\"ó\"  ] = { \"rʲ\", \"j\", \"u\" },\n",
        "\t\t\t[\"u\"  ] = { \"rʲ\", \"j\", \"u\" },\n",
        "\t\t\t[false] = { \"rʲ\", \"i\" }\n",
        "\t\t\t},\n",
        "\t\t[\"z\"  ] = \"ʐ\",\n",
        "\t\t[false] = \"r\"\n",
        "\t},\n",
        "\t[\"q\"] = {\n",
        "\t\t[\"u\"  ] = { \"k\", \"v\" },\n",
        "\t\t[false] = false\n",
        "\t},\n",
        "\t[\"s\"] = {\n",
        "\t\t[\"i\"  ] = {\n",
        "\t\t\t[\"ą\"  ] = { \"ɕ\", \"ɔ̃\" },\n",
        "\t\t\t[\"a\"  ] = { \"ɕ\", \"a\" },\n",
        "\t\t\t[\"e\"  ] = { \"ɕ\", \"ɛ\" },\n",
        "\t\t\t[\"ę\"  ] = { \"ɕ\", \"ɛ̃\" },\n",
        "\t\t\t[\"o\"  ] = { \"ɕ\", \"ɔ\" },\n",
        "\t\t\t[\"ó\"  ] = { \"ɕ\", \"u\" },\n",
        "\t\t\t[\"u\"  ] = { \"ɕ\", \"u\" },\n",
        "\t\t\t[\"y\"  ] = { \"ɕ\", \"ɨ\" },\n",
        "\t\t\t[false] = { \"ɕ\", \"i\" }\n",
        "\t\t},\n",
        "\t\t[\"z\"  ] = \"ʂ\",\n",
        "\t\t[false] = \"s\",\n",
        "\t},\n",
        "\t[\"ś\"] = \"ɕ\",\n",
        "\t[\"t\"] = \"t\",\n",
        "\t[\"u\"] = \"u\",\n",
        "\t[\"v\"] = {\n",
        "\t\t[\"i\"  ] = {\n",
        "\t\t\t[\"a\"  ] = { \"vʲ\", \"a\" },\n",
        "\t\t\t[\"ą\"  ] = { \"vʲ\", \"ɔ̃\" },\n",
        "\t\t\t[\"e\"  ] = { \"vʲ\", \"ɛ\" },\n",
        "\t\t\t[\"ę\"  ] = { \"vʲ\", \"ɛ̃\" },\n",
        "\t\t\t[\"i\"  ] = { \"vʲ\", \"j\", \"i\" },\n",
        "\t\t\t[\"o\"  ] = { \"vʲ\", \"ɔ\" },\n",
        "\t\t\t[\"ó\"  ] = { \"vʲ\", \"u\" },\n",
        "\t\t\t[\"u\"  ] = { \"vʲ\", \"u\" },\n",
        "\t\t\t[false] = { \"vʲ\", \"i\" }\n",
        "\t\t\t},\n",
        "\t\t[false] = \"v\"\n",
        "\t},\n",
        "\t[\"w\"] = {\n",
        "\t\t[\"i\"  ] = {\n",
        "\t\t\t[\"a\"  ] = { \"vʲ\", \"a\" },\n",
        "\t\t\t[\"ą\"  ] = { \"vʲ\", \"ɔ̃\" },\n",
        "\t\t\t[\"e\"  ] = { \"vʲ\", \"ɛ\" },\n",
        "\t\t\t[\"ę\"  ] = { \"vʲ\", \"ɛ̃\" },\n",
        "\t\t\t[\"i\"  ] = { \"vʲ\", \"j\", \"i\" },\n",
        "\t\t\t[\"o\"  ] = { \"vʲ\", \"ɔ\" },\n",
        "\t\t\t[\"ó\"  ] = { \"vʲ\", \"u\" },\n",
        "\t\t\t[\"u\"  ] = { \"vʲ\", \"u\" },\n",
        "\t\t\t[false] = { \"vʲ\", \"i\" }\n",
        "\t\t\t},\n",
        "\t\t[\"j\" ] = { \"vʲ\", \"j\" }, -- e.g. wjazd,\n",
        "\t\t[false] = \"v\"\n",
        "\t},\n",
        "\t[\"x\"] = { \"k\", \"s\" },\n",
        "\t[\"y\"] = \"ɨ\",\n",
        "\t[\"z\"] = {\n",
        "\t\t[\"i\"  ] = {\n",
        "\t\t\t[\"ą\"  ] = { \"ʑ\", \"ɔ̃\" },\n",
        "\t\t\t[\"a\"  ] = { \"ʑ\", \"a\" },\n",
        "\t\t\t[\"e\"  ] = { \"ʑ\", \"ɛ\" },\n",
        "\t\t\t[\"ę\"  ] = { \"ʑ\", \"ɛ̃\" },\n",
        "\t\t\t[\"o\"  ] = { \"ʑ\", \"ɔ\" },\n",
        "\t\t\t[\"ó\"  ] = { \"ʑ\", \"u\" },\n",
        "\t\t\t[\"u\"  ] = { \"ʑ\", \"u\" },\n",
        "\t\t\t[false] = { \"ʑ\", \"i\" }\n",
        "\t\t},\n",
        "\t\t[false] = \"z\"\n",
        "\t},\n",
        "\t[\"ź\"] = \"ʑ\",\n",
        "\t[\"ż\"] = \"ʐ\",\n",
        "\t[\"-\"] = {},\n",
        "}\n",
        "\n",
        "local valid_phone = {\n",
        "\t[\"a\" ] = true, [\"b\" ] = true, [\"bʲ\"] = true, [\"d\" ] = true, [\"d͡z\"] = true, [\"d͡ʑ\"] = true,\n",
        "\t[\"d͡ʐ\"] = true, [\"ɛ\" ] = true, [\"ɛ̃\" ] = true, [\"f\" ] = true, [\"fʲ\"] = true, [\"ɡ\" ] = true,\n",
        "\t[\"ɡʲ\"] = true, [\"i\" ] = true, [\"ɨ\" ] = true, [\"j\" ] = true, [\"k\" ] = true, [\"kʲ\"] = true,\n",
        "\t[\"l\" ] = true, [\"lʲ\"] =true, [\"m\" ] = true, [\"mʲ\"] = true, [\"n\" ] = true, [\"ŋ\" ] = true,\n",
        " [\"ɲ\" ] = true, [\"ɔ\" ] = true, [\"ɔ̃\" ] = true, [\"p\" ] = true, [\"pʲ\"] = true, [\"r\" ] = true, [\"rʲ\"] = true,\n",
        "[\"s\" ] = true, [\"ɕ\" ] = true, [\"ʂ\" ] = true, [\"t\" ] = true, [\"t͡s\"] = true, [\"t͡ɕ\"] = true, [\"t͡ʂ\"] = true,\n",
        "\t[\"u\" ] = true, [\"v\" ] = true, [\"vʲ\"] = true, [\"w\" ] = true, [\"x\" ] = true, [\"xʲ\"] = true, [\"z\" ] = true,\n",
        "\t[\"ʑ\" ] = true, [\"ʐ\" ] = true, [\"ʔ\" ] = true\n",
        "}\n",
        "\n",
        "local sylmarks = {\n",
        "\t[\".\"] = \".\", [\"'\"] = \"ˈ\", [\",\"] = \"ˌ\"\n",
        "}\n",
        "\n",
        "local vowel = {\n",
        "\t[ \"a\"] = true, [ \"ɛ\"] = true, [ \"ɛ̃\"] = true,\n",
        "\t[ \"i\"] = true, [ \"ɨ\"] = true, [ \"ɔ\"] = true,\n",
        "\t[ \"ɔ̃\"] = true, [ \"u\"] = true\n",
        "}\n",
        "\n",
        "local devoice = {\n",
        "\t[\"b\" ] = \"p\" , [\"d\" ] = \"t\" , [\"d͡z\"] = \"t͡s\", [\"d͡ʑ\"] = \"t͡ɕ\",\n",
        "\t[\"d͡ʐ\"] = \"t͡ʂ\", [\"ɡ\" ] = \"k\" , [\"v\" ] = \"f\" , [\"vʲ\"] = \"fʲ\",\n",
        "\t[\"z\" ] = \"s\" , [\"ʑ\" ] = \"ɕ\" , [\"ʐ\" ] = \"ʂ\" ,\n",
        "\n",
        "\t-- non-devoicable\n",
        "\t[\"bʲ\"] = \"bʲ\", [\"ɡʲ\"] = \"ɡʲ\", [\"m\" ] = \"m\" , [\"mʲ\"] = \"mʲ\",\n",
        "\t[\"n\" ] = \"n\" , [\"ɲ\" ] = \"ɲ\" , [\"ŋ\" ] = \"ŋ\" , [\"w\" ] = \"w\" ,\n",
        "\t[\"l\" ] = \"l\" , [\"lʲ\"] = \"lʲ\" , [\"j\" ] = \"j\" , [\"r\" ] = \"r\" , [\"rʲ\"] = \"rʲ\" ,\n",
        "}\n",
        "\n",
        "local denasalized = {\n",
        "\t[ \"ɛ̃\"] =  \"ɛ\",\n",
        "\t[ \"ɔ̃\"] =  \"ɔ\",\n",
        "}\n",
        "\n",
        "local nasal_map = {\n",
        "\t[\"p\" ] = \"m\", [\"pʲ\"] = \"m\", [\"b\" ] = \"m\", [\"bʲ\"] = \"m\", -- zębu, klępa\n",
        "\t[\"k\" ] = \"ŋ\", [\"kʲ\"] = \"ŋ\", [\"ɡ\" ] = \"ŋ\", [\"ɡʲ\"] = \"ŋ\", -- pąk, łęgowy\n",
        "\t[\"t\" ] = \"n\", [\"d\" ] = \"n\", -- wątek, piątek, mądrość\n",
        "\n",
        "\t[\"t͡ɕ\"] = \"ɲ\", [\"d͡ʑ\"] = \"ɲ\", -- pięć, pędziwiatr, łabędź\n",
        "\t-- gęsi, więzi\n",
        "\t[\"t͡ʂ\"] = \"n\", [\"d͡ʐ\"] = \"n\", -- pączek, ?\n",
        "\t-- węszyć, mężny\n",
        "\t[\"t͡s\"] = \"n\", [\"d͡z\"] = \"n\", -- wiedząc, pieniędzy\n",
        "}\n",
        "\n",
        "function export.convert_to_IPA(word)\n",
        "\tif type(word) == \"table\" then\n",
        "\t\tword = word.args[1]\n",
        "\tend\n",
        "\n",
        "\t-- convert letters to phones\n",
        "\tlocal phones = {}\n",
        "\tlocal l2ptab = letters2phones\n",
        "\tfor ch in word:gmatch(\"[%z\\1-\\127\\194-\\244][\\128-\\191]*\") do\n",
        "\t\tlocal value = l2ptab[ch]\n",
        "\n",
        "\t\tif value == nil then\n",
        "\t\t\tvalue = l2ptab[false]\n",
        "\t\t\tif value == false then\n",
        "\t\t\t\treturn nil\n",
        "\t\t\telseif type(value) == \"table\" then\n",
        "\t\t\t\tfor _, phone in ipairs(value) do\n",
        "\t\t\t\t\ttable.insert(phones, phone)\n",
        "\t\t\t\tend\n",
        "\t\t\telse\n",
        "\t\t\t\ttable.insert(phones, value)\n",
        "\t\t\tend\n",
        "\t\t\tl2ptab = letters2phones\n",
        "\t\t\tvalue = l2ptab[ch]\n",
        "\t\tend\n",
        "\n",
        "\t\tif type(value) == \"table\" then\n",
        "\t\t\tif value[false] == nil then\n",
        "\t\t\t\tfor _, phone in ipairs(value) do\n",
        "\t\t\t\t\ttable.insert(phones, phone)\n",
        "\t\t\t\tend\n",
        "\t\t\t\tl2ptab = letters2phones\n",
        "\t\t\telse\n",
        "\t\t\t\tl2ptab = value\n",
        "\t\t\tend\n",
        "\t\telseif type(value) == \"string\" then\n",
        "\t\t\ttable.insert(phones, value)\n",
        "\t\t\tl2ptab = letters2phones\n",
        "\t\telse\n",
        "\t\t\ttable.insert(phones, ch)\n",
        "\t\tend\n",
        "\tend\n",
        "\n",
        "\tif l2ptab ~= letters2phones then\n",
        "\t\ttable.insert(phones, l2ptab[false])\n",
        "\tend\n",
        "\n",
        "\t-- simplify nasals\n",
        "\tlocal new_phones = {}\n",
        "\tfor i, phone in ipairs(phones) do\n",
        "\t\tlocal pnext = phones[i + 1]\n",
        "\t\tif denasalized[phone] then\n",
        "\t\t\tif phone == \"ɛ̃\" and (not pnext or not valid_phone[pnext]) then\n",
        "\t\t\t\t-- denasalize word-final ę\n",
        "\t\t\t\ttable.insert(new_phones, denasalized[phone])\n",
        "\t\t\telseif nasal_map[pnext] then\n",
        "\t\t\t\ttable.insert(new_phones, denasalized[phone])\n",
        "\t\t\t\ttable.insert(new_phones, nasal_map[pnext])\n",
        "\t\t\telse\n",
        "\t\t\t\ttable.insert(new_phones, phone)\n",
        "\t\t\tend\n",
        "\t\telse\n",
        "\t\t\ttable.insert(new_phones, phone)\n",
        "\t\tend\n",
        "\tend\n",
        "\tphones = new_phones\n",
        "\n",
        "\t-- devoice\n",
        "\tfor i = #phones, 1, -1 do\n",
        "\t\tlocal pprev, pcurr, pnext = phones[i - 1], phones[i]\n",
        "\t\tlocal j = i\n",
        "\t\trepeat\n",
        "\t\t\tj = j + 1\n",
        "\t\t\tpnext = phones[j]\n",
        "\t\tuntil not pnext or not sylmarks[pnext]\n",
        "\t\tif devoice[pcurr] and not devoice[pnext] and not vowel[pnext] and not denasalized[pnext] then\n",
        "\t\t\tphones[i] = devoice[pcurr]\n",
        "\t\tend\n",
        "\t\t-- prz, trz, krz, tw, kw(i)\n",
        "\t\tif ((pcurr == \"v\") or (pcurr == \"vʲ\") or (pcurr == \"ʐ\")) and valid_phone[pprev] and not devoice[pprev] and not vowel[pprev] and not denasalized[pprev] then\n",
        "\t\t\tphones[i] = devoice[pcurr]\n",
        "\t\tend\n",
        "\tend\n",
        "\n",
        "\t-- collect syllables\n",
        "\tlocal words, curword, sylmarked, sylbuf = {}, nil, false\n",
        "\tfor i, pcurr in ipairs(phones) do\n",
        "\t\tlocal ppprev, pprev, pnext = phones[i - 2], phones[i - 1], phones[i + 1]\n",
        "\n",
        "\t\tif valid_phone[pcurr] then\n",
        "\t\t\tif not curword then\n",
        "\t\t\t\tcurword, sylbuf, had_vowl, sylmarked = {}, '', false, false\n",
        "\t\t\t\ttable.insert(words, curword)\n",
        "\t\t\tend\n",
        "\n",
        "\t\t\tlocal same_syl = true\n",
        "\n",
        "\t\t\tif vowel[pcurr] then\n",
        "\t\t\t\tif had_vowl then\n",
        "\t\t\t\t\tsame_syl = false\n",
        "\t\t\t\tend\n",
        "\t\t\t\thad_vowl = true\n",
        "\t\t\telseif had_vowl then\n",
        "\t\t\t\tif vowel[pnext] then\n",
        "\t\t\t\t\tsame_syl = false\n",
        "\t\t\t\telseif not vowel[pprev] and not vowel[pnext] then\n",
        "\t\t\t\t\tsame_syl = false\n",
        "\t\t\t\telseif ((pcurr == \"s\") and ((pnext == \"t\") or (pnext == \"p\") or (pnext == \"k\")))\n",
        "\t\t\t\tor (pnext == \"r\") or (pnext == \"f\") or (pnext == \"w\")\n",
        "\t\t\t\tor ((pcurr == \"ɡ\") and (pnext == \"ʐ\"))\n",
        "\t\t\t\tor ((pcurr == \"d\") and ((pnext == \"l\") or (pnext == \"w\") or (pnext == \"ɲ\")))\n",
        "\t\t\t\tthen\n",
        "\t\t\t\t\t-- these should belong to a common syllable\n",
        "\t\t\t\t\tsame_syl = false\n",
        "\t\t\t\tend\n",
        "\t\t\tend\n",
        "\n",
        "\t\t\tif same_syl then\n",
        "\t\t\t\tsylbuf = sylbuf .. pcurr\n",
        "\t\t\telse\n",
        "\t\t\t\ttable.insert(curword, sylbuf)\n",
        "\t\t\t\tsylbuf, had_vowl = pcurr, vowel[pcurr]\n",
        "\t\t\tend\n",
        "\t\telseif (curword or valid_phone[pnext]) and sylmarks[pcurr] then\n",
        "\t\t\tif not curword then\n",
        "\t\t\t\tcurword, sylbuf, had_vowl = {}, '', false\n",
        "\t\t\t\ttable.insert(words, curword)\n",
        "\t\t\tend\n",
        "\t\t\tsylmarked = true\n",
        "\t\t\tif sylbuf then\n",
        "\t\t\t\ttable.insert(curword, sylbuf)\n",
        "\t\t\t\tsylbuf = ''\n",
        "\t\t\tend\n",
        "\t\t\ttable.insert(curword, sylmarks[pcurr])\n",
        "\t\telse\n",
        "\t\t\tif sylbuf then\n",
        "\t\t\t\tif #curword > 0 and not had_vowl then\n",
        "\t\t\t\t\tcurword[#curword] = curword[#curword] .. sylbuf\n",
        "\t\t\t\telse\n",
        "\t\t\t\t\ttable.insert(curword, sylbuf)\n",
        "\t\t\t\tend\n",
        "\t\t\t\tif sylmarked then\n",
        "\t\t\t\t\twords[#words] = table.concat(curword)\n",
        "\t\t\t\tend\n",
        "\t\t\tend\n",
        "\t\t\tcurword, sylbuf = nil, nil\n",
        "\t\t\ttable.insert(words, pcurr)\n",
        "\t\tend\n",
        "\tend\n",
        "\tif sylbuf then\n",
        "\t\tif #curword > 0 and not had_vowl then\n",
        "\t\t\tcurword[#curword] = curword[#curword] .. sylbuf\n",
        "\t\telse\n",
        "\t\t\ttable.insert(curword, sylbuf)\n",
        "\t\tend\n",
        "\t\tif sylmarked then\n",
        "\t\t\twords[#words] = table.concat(curword)\n",
        "\t\tend\n",
        "\tend\n",
        "\n",
        "\t-- mark syllable breaks and stress\n",
        "\tfor i, word in ipairs(words) do\n",
        "\t\tif type(word) == \"table\" then\n",
        "\t\t\t-- unless already marked\n",
        "\t\t\tif not ((word[2] == \".\") or (word[2] == \"ˈ\") or (word[2] == \"ˌ\")) then\n",
        "\t\t\t\tfor j, syl in ipairs(word) do\n",
        "\t\t\t\t\tif j == (#word - 1) then\n",
        "\t\t\t\t\t\tword[j] = \"ˈ\" .. syl\n",
        "\t\t\t\t\telseif j ~= 1 then\n",
        "\t\t\t\t\t\tword[j] = \".\" .. syl\n",
        "\t\t\t\t\tend\n",
        "\t\t\t\tend\n",
        "\t\t\tend\n",
        "\t\t\twords[i] = table.concat(word)\n",
        "\t\tend\n",
        "\tend\n",
        "\n",
        "\treturn table.concat(words)\n",
        "end\n",
        "\n",
        "return export\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IRiFArovu8NU"
      },
      "outputs": [],
      "source": [
        "from lupa import LuaRuntime\n",
        "\n",
        "lua = LuaRuntime(unpack_returned_tuples=True, encoding=\"utf-8\")\n",
        "\n",
        "pl_ipa = lua.execute(PL_IPA)\n",
        "\n",
        "convert_to_ipa = pl_ipa.convert_to_IPA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Pa_sqg6TxBdT",
        "outputId": "c4723508-3126-4e0f-a01b-8cbc58211138"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'ˈzɛm.bɨ'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "convert_to_ipa(\"zęby\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "G9SU0SJTf9Y-"
      },
      "outputs": [],
      "source": [
        "MAPPING = {\n",
        "    \"a\": \"A\",\n",
        "    \"b\": \"B\",\n",
        "    \"t͡ʂ\": \"CZ\",\n",
        "    \"d\": \"D\",\n",
        "    \"d͡ʐ\": \"DRZ\",\n",
        "    \"d͡z\": \"DZ\",\n",
        "    \"d͡ʑ\": \"DZI\",\n",
        "    \"ɛ\": \"E\",\n",
        "    \"ɛ̃\": \"EN\",\n",
        "    \"f\": \"F\",\n",
        "    \"ɡ\": \"G\",\n",
        "    \"i\": \"I\",\n",
        "    \"j\": \"J\",\n",
        "    \"ʲ\": \"J\",\n",
        "    \"k\": \"K\",\n",
        "    \"l\": \"L\",\n",
        "    \"m\": \"M\",\n",
        "    \"n\": \"N\",\n",
        "    \"ɲ\": \"NI\",\n",
        "    \"ɔ\": \"O\",\n",
        "    \"ɔ̃\": \"ON\",\n",
        "    \"p\": \"P\",\n",
        "    \"r\": \"R\",\n",
        "    \"ʐ\": \"RZ\",\n",
        "    \"s\": \"S\",\n",
        "    \"ɕ\": \"SI\",\n",
        "    \"ʂ\": \"SZ\",\n",
        "    \"t\": \"T\",\n",
        "    \"t͡s\": \"TS\",\n",
        "    \"t͡ɕ\": \"TSI\",\n",
        "    \"u\": \"U\",\n",
        "    \"v\": \"V\",\n",
        "    \"w\": \"W\",\n",
        "    \"x\": \"X\",\n",
        "    \"ɨ\": \"Y\",\n",
        "    \"z\": \"Z\",\n",
        "    \"ʑ\": \"ZI\",\n",
        "    \"ˈ\": \"\",\n",
        "    \".\": \"\",\n",
        "    \"ʔ\": \"\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Fv677b_azR3d"
      },
      "outputs": [],
      "source": [
        "ipa_phones = list(MAPPING.keys())\n",
        "ipa_phones.sort(key=len, reverse=True)\n",
        "IPA_KEY_REGEX = fr\"({'|'.join(ipa_phones)})\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1dxT7PqSyIqX"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def convert_to_sphinx(text):\n",
        "    tokens = []\n",
        "    text = text.strip()\n",
        "    while text:\n",
        "        match = re.match(IPA_KEY_REGEX, text)\n",
        "        if not match:\n",
        "            raise ValueError(f\"Could not match token in text: {text}\")\n",
        "        token = match.group(0)\n",
        "        mapped = MAPPING[token]\n",
        "        if mapped != \"\":\n",
        "            tokens.append(mapped)\n",
        "        text = text[len(token):].strip()\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "JS-gA1cCzw2q"
      },
      "outputs": [],
      "source": [
        "def sphinx_pronunciation(text):\n",
        "    ipa = convert_to_ipa(text)\n",
        "    return \" \".join(convert_to_sphinx(ipa))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tDGt0l40Lx7",
        "outputId": "757d4c16-0f48-4524-e2b1-4483e867a282"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('SI I N U S', 'S I N U S')"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sphinx_pronunciation(\"sinus\"), sphinx_pronunciation(\"s-inus\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Osi3kA2fR5Ck"
      },
      "outputs": [],
      "source": [
        "def clean_word(text):\n",
        "    return text.strip(\",;:!?—…„”\\\"“.«»*()[]‘/\\\\\").lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xKFh0MaQSLN1"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class TextWord:\n",
        "    raw: str\n",
        "    word: str\n",
        "    def __init__(self, raw):\n",
        "        self.raw = raw\n",
        "        self.word = clean_word(raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ItAGF0rhSns_"
      },
      "outputs": [],
      "source": [
        "RAW_NORMS = \"https://raw.githubusercontent.com/jimregan/wolnelektury-speech-corpus/refs/heads/main/specific-norms.tsv\"\n",
        "PRON_AS = \"https://raw.githubusercontent.com/jimregan/wolnelektury-speech-corpus/refs/heads/main/pron-data/pronounce-as.tsv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting requests\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests)\n",
            "  Downloading charset_normalizer-3.4.3-cp311-cp311-macosx_10_9_universal2.whl.metadata (36 kB)\n",
            "Collecting idna<4,>=2.5 (from requests)\n",
            "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests)\n",
            "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests)\n",
            "  Downloading certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
            "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "Downloading charset_normalizer-3.4.3-cp311-cp311-macosx_10_9_universal2.whl (204 kB)\n",
            "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
            "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
            "Downloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
            "Installing collected packages: urllib3, idna, charset_normalizer, certifi, requests\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [requests]1/5\u001b[0m [idna]\n",
            "\u001b[1A\u001b[2KSuccessfully installed certifi-2025.8.3 charset_normalizer-3.4.3 idna-3.10 requests-2.32.5 urllib3-2.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "htG_SdScUF1C"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "def download_get_lines(url):\n",
        "    lines = []\n",
        "    req = requests.get(url)\n",
        "    if req.status_code != 200:\n",
        "        return []\n",
        "    for line in req.text.split(\"\\n\"):\n",
        "        if line != \"\":\n",
        "            lines.append(line)\n",
        "    return lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "z34wrwbOtDfe"
      },
      "outputs": [],
      "source": [
        "def pronounce_as_dict(url):\n",
        "    lines = download_get_lines(url)\n",
        "    data = {}\n",
        "    for line in lines:\n",
        "        parts = line.split(\"\\t\")\n",
        "        if not parts[0] in data:\n",
        "            data[parts[0]] = set()\n",
        "        data[parts[0]].add(parts[1])\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "1PwFt6jStjBq"
      },
      "outputs": [],
      "source": [
        "pronounce_as = pronounce_as_dict(PRON_AS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ydg5tySxf9Y-"
      },
      "outputs": [],
      "source": [
        "espeak_to_cmudict = {}\n",
        "for line in MAPPING.split(\"\\n\"):\n",
        "    if line == \"\":\n",
        "        continue\n",
        "    line = line.strip()\n",
        "    parts = line.split(\" \")\n",
        "\n",
        "    if len(parts) != 2:\n",
        "        print(line)\n",
        "        continue\n",
        "    k, v = line.split(\" \")\n",
        "    if not k in espeak_to_cmudict:\n",
        "        espeak_to_cmudict[k] = v\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHDR2Bixf9Y_"
      },
      "outputs": [],
      "source": [
        "def normword(text):\n",
        "    text = text.strip(\",.;:!?\")\n",
        "    return text.lower()\n",
        "\n",
        "def normphon(phon):\n",
        "    phon = phon.strip(\",.;:!?\")\n",
        "    return phon\n",
        "\n",
        "def make_lexicon(text, phon):\n",
        "    if phon.startswith(\"/\") and phon.endswith(\"/\"):\n",
        "        phon = phon[1:-1]\n",
        "    words = [normword(x) for x in text.split(\" \")]\n",
        "    phonwords = [cmudictify(normphon(x)) for x in phon.split(\" \")]\n",
        "    assert len(words) == len(phonwords)\n",
        "    output = list(set(zip(words, phonwords)))\n",
        "    return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4WZWq83f9Y_"
      },
      "outputs": [],
      "source": [
        "lex = make_lexicon(EGTEXT, EGPHON)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdfAdgFnf9Y_"
      },
      "outputs": [],
      "source": [
        "audio = AudioSegment.from_file(EGFILE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qidYZHqrf9Y_"
      },
      "outputs": [],
      "source": [
        "audio = audio.set_frame_rate(16000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XoP6760Sf9ZA"
      },
      "outputs": [],
      "source": [
        "seg = audio[int(EGSTART * 1000):int(EGEND * 1000)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z91HRyMbf9ZA"
      },
      "outputs": [],
      "source": [
        "def make_ps_dict(entries):\n",
        "    counts = {}\n",
        "    output = []\n",
        "    lex = sorted(entries)\n",
        "    for entry in lex:\n",
        "        count = 1\n",
        "        if not entry[0] in counts:\n",
        "            counts[entry[0]] = 1\n",
        "        else:\n",
        "            counts[entry[0]] += 1\n",
        "            count = counts[entry[0]]\n",
        "        if count != 1:\n",
        "            subscript = f\"({count})\"\n",
        "        else:\n",
        "            subscript = \"\"\n",
        "        output.append(f\"{entry[0]}{subscript} {entry[1]}\")\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8F4L_tOf9ZA"
      },
      "outputs": [],
      "source": [
        "def make_fsg_transitions_from_text(text):\n",
        "    words = [normword(x) for x in text.split(\" \")]\n",
        "    enum = [x for x in enumerate(words)]\n",
        "    trans = [(x[0], x[0] + 1, 1.0, x[1]) for x in enum]\n",
        "    return trans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0orFFOtf9ZA"
      },
      "outputs": [],
      "source": [
        "fsgt = make_fsg_transitions_from_text(EGTEXT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "waBzXiHuf9ZA"
      },
      "outputs": [],
      "source": [
        "start_state = fsgt[0][0]\n",
        "end_state = fsgt[-1][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2c1-0mACf9ZA"
      },
      "outputs": [],
      "source": [
        "import pocketsphinx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWafH4dPf9ZA"
      },
      "source": [
        "This was the first attempt. Adding `None` for the dictionary (as the docs suggested) didn't help: can't add words to a dictionary that doesn't exist.\n",
        "\n",
        "This may yet be a thing, because I can't be sure that it really failed to align using the grammar: audio handling sucks, and I should maybe have passed ffmpeg parameters before writing the audio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QhUGuGPAf9ZA"
      },
      "outputs": [],
      "source": [
        "import tempfile\n",
        "entries = make_ps_dict(lex)\n",
        "\n",
        "with (\n",
        "    tempfile.NamedTemporaryFile(suffix=\".dict\") as dictf,\n",
        "    tempfile.NamedTemporaryFile(suffix=\".wav\") as wavf,\n",
        "):\n",
        "    with open(dictf.name, \"w\") as dictout:\n",
        "        for entry in entries:\n",
        "            dictout.write(entry + \"\\n\")\n",
        "\n",
        "    seg.export(wavf.name, format=\"wav\")\n",
        "\n",
        "    decoder = pocketsphinx.Decoder(lm=None, dict=dictf.name)\n",
        "    fsg = decoder.create_fsg(\"dummy\", start_state, end_state, fsgt)\n",
        "    decoder.add_fsg(\"dummy\", fsg)\n",
        "    decoder.activate_search(\"dummy\")\n",
        "    decoder.start_utt()\n",
        "    # decoder.process_raw(seg.get_array_of_samples('B'))\n",
        "    decoder.process_raw(wavf.read(), full_utt=True)\n",
        "    decoder.end_utt()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFxamR0vf9ZA",
        "outputId": "9f6aa6e3-3425-4b64-f24f-15cb25b26ed5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: \"fsg_search.c\", line 944: Final result does not match the grammar in frame 1082\n"
          ]
        }
      ],
      "source": [
        "decoder.seg()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZV8NACCCf9ZA"
      },
      "outputs": [],
      "source": [
        "fsg.writefile(\"/tmp/fsm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_dNBbvYf9ZA",
        "outputId": "4aca0f6f-deb8-4a7e-cf8c-3ef466a39b4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FSG_BEGIN dummy\n",
            "NUM_STATES 29\n",
            "START_STATE 0\n",
            "FINAL_STATE 28\n",
            "TRANSITION 0 0 0.000000 [NOISE]\n",
            "TRANSITION 0 0 0.005001 <sil>\n",
            "TRANSITION 0 1 1.000000 yeah\n",
            "TRANSITION 1 1 0.000000 [NOISE]\n",
            "TRANSITION 1 1 0.005001 <sil>\n",
            "TRANSITION 1 2 1.000000 that's\n",
            "TRANSITION 2 2 0.000000 [NOISE]\n",
            "TRANSITION 2 2 0.005001 <sil>\n",
            "TRANSITION 2 3 1.000000 true\n",
            "TRANSITION 3 3 0.000000 [NOISE]\n",
            "TRANSITION 3 3 0.005001 <sil>\n",
            "TRANSITION 3 4 1.000000 i(2)\n",
            "TRANSITION 3 4 1.000000 i\n",
            "TRANSITION 4 4 0.000000 [NOISE]\n",
            "TRANSITION 4 4 0.005001 <sil>\n",
            "TRANSITION 4 5 1.000000 mean\n",
            "TRANSITION 5 5 0.000000 [NOISE]\n",
            "TRANSITION 5 5 0.005001 <sil>\n",
            "TRANSITION 5 6 1.000000 they\n",
            "TRANSITION 6 6 0.000000 [NOISE]\n",
            "TRANSITION 6 6 0.005001 <sil>\n",
            "TRANSITION 6 7 1.000000 are(2)\n",
            "TRANSITION 6 7 1.000000 are\n",
            "TRANSITION 7 7 0.000000 [NOISE]\n",
            "TRANSITION 7 7 0.005001 <sil>\n",
            "TRANSITION 7 8 1.000000 the\n",
            "TRANSITION 8 8 0.000000 [NOISE]\n",
            "TRANSITION 8 8 0.005001 <sil>\n",
            "TRANSITION 8 9 1.000000 same\n",
            "TRANSITION 9 9 0.000000 [NOISE]\n",
            "TRANSITION 9 9 0.005001 <sil>\n",
            "TRANSITION 9 10 1.000000 size\n",
            "TRANSITION 10 10 0.000000 [NOISE]\n",
            "TRANSITION 10 10 0.005001 <sil>\n",
            "TRANSITION 10 11 1.000000 and\n",
            "TRANSITION 11 11 0.000000 [NOISE]\n",
            "TRANSITION 11 11 0.005001 <sil>\n",
            "TRANSITION 11 12 1.000000 they\n",
            "TRANSITION 12 12 0.000000 [NOISE]\n",
            "TRANSITION 12 12 0.005001 <sil>\n",
            "TRANSITION 12 13 1.000000 are(2)\n",
            "TRANSITION 12 13 1.000000 are\n",
            "TRANSITION 13 13 0.000000 [NOISE]\n",
            "TRANSITION 13 13 0.005001 <sil>\n",
            "TRANSITION 13 14 1.000000 a\n",
            "TRANSITION 14 14 0.000000 [NOISE]\n",
            "TRANSITION 14 14 0.005001 <sil>\n",
            "TRANSITION 14 15 1.000000 little\n",
            "TRANSITION 15 15 0.000000 [NOISE]\n",
            "TRANSITION 15 15 0.005001 <sil>\n",
            "TRANSITION 15 16 1.000000 bit\n",
            "TRANSITION 16 16 0.000000 [NOISE]\n",
            "TRANSITION 16 16 0.005001 <sil>\n",
            "TRANSITION 16 17 1.000000 but\n",
            "TRANSITION 17 17 0.000000 [NOISE]\n",
            "TRANSITION 17 17 0.005001 <sil>\n",
            "TRANSITION 17 18 1.000000 i(2)\n",
            "TRANSITION 17 18 1.000000 i\n",
            "TRANSITION 18 18 0.000000 [NOISE]\n",
            "TRANSITION 18 18 0.005001 <sil>\n",
            "TRANSITION 18 19 1.000000 think\n",
            "TRANSITION 19 20 1.000000 i(2)\n",
            "TRANSITION 19 20 1.000000 i\n",
            "TRANSITION 19 19 0.000000 [NOISE]\n",
            "TRANSITION 19 19 0.005001 <sil>\n",
            "TRANSITION 20 20 0.000000 [NOISE]\n",
            "TRANSITION 20 20 0.005001 <sil>\n",
            "TRANSITION 20 21 1.000000 i(2)\n",
            "TRANSITION 20 21 1.000000 i\n",
            "TRANSITION 21 21 0.000000 [NOISE]\n",
            "TRANSITION 21 21 0.005001 <sil>\n",
            "TRANSITION 21 22 1.000000 should\n",
            "TRANSITION 22 22 0.000000 [NOISE]\n",
            "TRANSITION 22 22 0.005001 <sil>\n",
            "TRANSITION 22 23 1.000000 go\n",
            "TRANSITION 23 23 0.000000 [NOISE]\n",
            "TRANSITION 23 23 0.005001 <sil>\n",
            "TRANSITION 23 24 1.000000 more\n",
            "TRANSITION 24 24 0.000000 [NOISE]\n",
            "TRANSITION 24 24 0.005001 <sil>\n",
            "TRANSITION 24 25 1.000000 for\n",
            "TRANSITION 25 25 0.000000 [NOISE]\n",
            "TRANSITION 25 25 0.005001 <sil>\n",
            "TRANSITION 25 26 1.000000 something\n",
            "TRANSITION 26 26 0.000000 [NOISE]\n",
            "TRANSITION 26 26 0.005001 <sil>\n",
            "TRANSITION 26 27 1.000000 that\n",
            "TRANSITION 27 27 0.000000 [NOISE]\n",
            "TRANSITION 27 27 0.005001 <sil>\n",
            "TRANSITION 27 28 1.000000 style\n",
            "TRANSITION 28 28 0.000000 [NOISE]\n",
            "TRANSITION 28 28 0.005001 <sil>\n",
            "FSG_END\n"
          ]
        }
      ],
      "source": [
        "!cat /tmp/fsm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFjxLuwif9ZA"
      },
      "outputs": [],
      "source": [
        "with open(\"/tmp/mytmp.dict\", \"w\") as dictout:\n",
        "    for entry in entries:\n",
        "        dictout.write(entry + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-Fvt1Oqf9ZB",
        "outputId": "e4862c96-c700-403b-82e9-781b79259463"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_io.BufferedRandom name='/tmp/clip.wav'>"
            ]
          },
          "execution_count": 168,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "seg.export(\"/tmp/clip.wav\", format=\"wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJWExC3-f9ZB"
      },
      "outputs": [],
      "source": [
        "!sox /tmp/clip.wav $(pocketsphinx soxflags) > /tmp/ps.raw\n",
        "psjson=!pocketsphinx align /tmp/ps.raw \"yeah that's true i mean they are the same size and they are a little bit but i think i i should go more for something that style\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WZMVA3cf9ZB",
        "outputId": "73927a0e-f087-4962-c600-d3d0046ac647"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['{\"b\":0.000,\"d\":5.410,\"p\":1.000,\"t\":\"yeah that\\'s true i mean they are the same size and they are a little bit but i think i i should go more for something that style\",\"w\":[{\"b\":0.000,\"d\":0.250,\"p\":0.964,\"t\":\"yeah\"},{\"b\":0.250,\"d\":0.150,\"p\":0.937,\"t\":\"that\\'s\"},{\"b\":0.400,\"d\":0.200,\"p\":0.978,\"t\":\"true\"},{\"b\":0.600,\"d\":0.060,\"p\":0.974,\"t\":\"i\"},{\"b\":0.660,\"d\":0.180,\"p\":0.980,\"t\":\"mean\"},{\"b\":0.840,\"d\":0.140,\"p\":0.979,\"t\":\"they\"},{\"b\":0.980,\"d\":0.070,\"p\":0.983,\"t\":\"are(2)\"},{\"b\":1.050,\"d\":0.110,\"p\":0.987,\"t\":\"the\"},{\"b\":1.160,\"d\":0.260,\"p\":0.974,\"t\":\"same\"},{\"b\":1.420,\"d\":0.380,\"p\":0.956,\"t\":\"size\"},{\"b\":1.800,\"d\":0.120,\"p\":0.975,\"t\":\"and\"},{\"b\":1.920,\"d\":0.110,\"p\":0.986,\"t\":\"they\"},{\"b\":2.030,\"d\":0.140,\"p\":0.983,\"t\":\"are(2)\"},{\"b\":2.170,\"d\":0.030,\"p\":0.990,\"t\":\"a\"},{\"b\":2.200,\"d\":0.180,\"p\":0.914,\"t\":\"little\"},{\"b\":2.380,\"d\":0.140,\"p\":0.980,\"t\":\"bit\"},{\"b\":2.520,\"d\":0.220,\"p\":0.935,\"t\":\"but\"},{\"b\":2.740,\"d\":0.110,\"p\":0.983,\"t\":\"i\"},{\"b\":2.850,\"d\":0.260,\"p\":0.968,\"t\":\"think\"},{\"b\":3.110,\"d\":0.190,\"p\":0.975,\"t\":\"i\"},{\"b\":3.300,\"d\":0.090,\"p\":0.977,\"t\":\"i\"},{\"b\":3.390,\"d\":0.200,\"p\":0.976,\"t\":\"should\"},{\"b\":3.590,\"d\":0.150,\"p\":0.982,\"t\":\"go\"},{\"b\":3.740,\"d\":0.220,\"p\":0.979,\"t\":\"more\"},{\"b\":3.960,\"d\":0.200,\"p\":0.978,\"t\":\"for(2)\"},{\"b\":4.160,\"d\":0.320,\"p\":0.971,\"t\":\"something\"},{\"b\":4.480,\"d\":0.300,\"p\":0.961,\"t\":\"that\"},{\"b\":4.780,\"d\":0.510,\"p\":0.968,\"t\":\"style\"},{\"b\":5.290,\"d\":0.110,\"p\":0.955,\"t\":\"<sil>\"}]}']"
            ]
          },
          "execution_count": 174,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "psjson"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKYxkYTUf9ZB"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "data = json.loads(str(psjson[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9f0GnyEf9ZB",
        "outputId": "fa8cd7d3-2fff-421f-fd7c-dc364506e638"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'b': 0.0,\n",
              " 'd': 5.41,\n",
              " 'p': 1.0,\n",
              " 't': \"yeah that's true i mean they are the same size and they are a little bit but i think i i should go more for something that style\",\n",
              " 'w': [{'b': 0.0, 'd': 0.25, 'p': 0.964, 't': 'yeah'},\n",
              "  {'b': 0.25, 'd': 0.15, 'p': 0.937, 't': \"that's\"},\n",
              "  {'b': 0.4, 'd': 0.2, 'p': 0.978, 't': 'true'},\n",
              "  {'b': 0.6, 'd': 0.06, 'p': 0.974, 't': 'i'},\n",
              "  {'b': 0.66, 'd': 0.18, 'p': 0.98, 't': 'mean'},\n",
              "  {'b': 0.84, 'd': 0.14, 'p': 0.979, 't': 'they'},\n",
              "  {'b': 0.98, 'd': 0.07, 'p': 0.983, 't': 'are(2)'},\n",
              "  {'b': 1.05, 'd': 0.11, 'p': 0.987, 't': 'the'},\n",
              "  {'b': 1.16, 'd': 0.26, 'p': 0.974, 't': 'same'},\n",
              "  {'b': 1.42, 'd': 0.38, 'p': 0.956, 't': 'size'},\n",
              "  {'b': 1.8, 'd': 0.12, 'p': 0.975, 't': 'and'},\n",
              "  {'b': 1.92, 'd': 0.11, 'p': 0.986, 't': 'they'},\n",
              "  {'b': 2.03, 'd': 0.14, 'p': 0.983, 't': 'are(2)'},\n",
              "  {'b': 2.17, 'd': 0.03, 'p': 0.99, 't': 'a'},\n",
              "  {'b': 2.2, 'd': 0.18, 'p': 0.914, 't': 'little'},\n",
              "  {'b': 2.38, 'd': 0.14, 'p': 0.98, 't': 'bit'},\n",
              "  {'b': 2.52, 'd': 0.22, 'p': 0.935, 't': 'but'},\n",
              "  {'b': 2.74, 'd': 0.11, 'p': 0.983, 't': 'i'},\n",
              "  {'b': 2.85, 'd': 0.26, 'p': 0.968, 't': 'think'},\n",
              "  {'b': 3.11, 'd': 0.19, 'p': 0.975, 't': 'i'},\n",
              "  {'b': 3.3, 'd': 0.09, 'p': 0.977, 't': 'i'},\n",
              "  {'b': 3.39, 'd': 0.2, 'p': 0.976, 't': 'should'},\n",
              "  {'b': 3.59, 'd': 0.15, 'p': 0.982, 't': 'go'},\n",
              "  {'b': 3.74, 'd': 0.22, 'p': 0.979, 't': 'more'},\n",
              "  {'b': 3.96, 'd': 0.2, 'p': 0.978, 't': 'for(2)'},\n",
              "  {'b': 4.16, 'd': 0.32, 'p': 0.971, 't': 'something'},\n",
              "  {'b': 4.48, 'd': 0.3, 'p': 0.961, 't': 'that'},\n",
              "  {'b': 4.78, 'd': 0.51, 'p': 0.968, 't': 'style'},\n",
              "  {'b': 5.29, 'd': 0.11, 'p': 0.955, 't': '<sil>'}]}"
            ]
          },
          "execution_count": 176,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fnm29J_4f9ZB"
      },
      "outputs": [],
      "source": [
        "with open(\"/tmp/audacity.tsv\", \"w\") as tsvf:\n",
        "    for word in data[\"w\"]:\n",
        "        tsvf.write(f\"{word['b']}\\t{word['b']+word['d']:.2}\\t{word['t']}\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ps_pl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
