(1) X
https://twitter.com/din0s_/status/1742235150530851120?t=u8auHKcaw80UmIbZ9IfMUA&s=09

Advanced RAG Techniques: an Illustrated Overview | by IVAN ILIN | Dec, 2023 | Towards AI
https://pub.towardsai.net/advanced-rag-techniques-an-illustrated-overview-04d193d8fec6

AK on X: "Nvidia presents Incremental FastPitch Chunk-based High Quality Text to Speech paper page: https://t.co/v1FxDzo7uM Parallel text-to-speech models have been widely applied for real-time speech synthesis, and they offer more controllability and a much faster synthesis processâ€¦ https://t.co/pM4fnSdMAo" / X
https://twitter.com/_akhaliq/status/1742757369895960950?t=D1u9nDfYdG91VqmGcwvFBA&s=09

DJ on X: "I created my YouTube series on Reinforcement Learning because I saw it applied profitably at Lyft. It was a counterexample to the stigma: "RL is only good for scenarios where a perfect simulator can be accessed endlessly. It's general-but-slow trial-and-error." There's truthâ€¦ https://t.co/wowDxJaUWy" / X
https://twitter.com/DuaneJRich/status/1742777245821989224?t=NaPM_jFTb4boJXgU99EknA&s=09

Vaibhav (VB) Srivastav on X: "Parakeet RNNT &amp; CTC models top the Open ASR Leaderboard! ðŸ‘‘ Brought to you by @NVIDIAAI and @suno_ai_, parakeet beats Whisper and regains its first place. The models are released under a commercially permissive license! ðŸ¥³ The models inherit the same FastConformerâ€¦ https://t.co/jF96yecZ1t" / X
https://twitter.com/reach_vb/status/1742261240141918684?t=PM9B52XZuQQKxsN4NEpuBg&s=09

Parakeet Rnnt 1.1b - a Hugging Face Space by nvidia
https://huggingface.co/spaces/nvidia/parakeet-rnnt-1.1b

nvidia/parakeet-rnnt-1.1b Â· Hugging Face
https://huggingface.co/nvidia/parakeet-rnnt-1.1b

Models â€” NVIDIA NeMo
https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/main/asr/models.html#fast-conformer

ASR-with-Transducers.ipynb - Colaboratory
https://colab.research.google.com/github/NVIDIA/NeMo/blob/stable/tutorials/asr/ASR_with_Transducers.ipynb

GitHub - bclavie/RAGatouille
https://github.com/bclavie/RAGatouille

Benjamin ClaviÃ© on X: "The RAG wave is here to stay, but in practice, it's hard to retrieve the right docs w/ embdings, &amp; better IR models are hard to use! Let's fix that: Introducing ðŸª¤RAGatouille, a lib to train&amp;use SotA retrieval model, ColBERT, in just a few lines of code! https://t.co/VRHiGQl0Xv https://t.co/0EpOfV6UWn" / X
https://twitter.com/bclavie/status/1742950315278672040?t=jvJ5amVnF7IObVB2NVFhMA&s=09

GitHub - bclavie/RAGatouille
https://github.com/bclavie/RAGatouille

colbert-ir/colbertv2.0 Â· Hugging Face
https://huggingface.co/colbert-ir/colbertv2.0

twitter.com/lateinteraction/status/1736804963760976092?t=7i9W4jKMslYpN1_GljPjJg&s=09
https://twitter.com/lateinteraction/status/1736804963760976092?t=7i9W4jKMslYpN1_GljPjJg&s=09

[2401.01572] Hallucinations in Neural Automatic Speech Recognition: Identifying Errors and Hallucinatory Models
https://arxiv.org/abs/2401.01572

[2401.02412] LLM Augmented LLMs: Expanding Capabilities through Composition
https://arxiv.org/abs/2401.02412

Jerry Liu on X: "Everyone building RAG uses dense embedding retrieval, but simply doing cosine distance doesnâ€™t always capture fine-grained similarity. Thatâ€™s why SOTA retrieval like ColBERT models are so important; these new architectures are fast but more powerful than pure dense retrieval.â€¦ https://t.co/W2RPBBxml4" / X
https://twitter.com/jerryjliu0/status/1743077679258320925?t=brOCUV_BppsrhGeXsDl7IQ&s=09

[2310.20360] Mathematical Introduction to Deep Learning: Methods, Implementations, and Theory
https://arxiv.org/abs/2310.20360

[2401.02412] LLM Augmented LLMs: Expanding Capabilities through Composition
https://arxiv.org/abs/2401.02412

LLM Augmented LLMs: Expanding Capabilities through Composition
https://browse.arxiv.org/html/2401.02412v1

Philipp Schmid on X: "Is it possible to teach LLMs a different language? ðŸ¤” Can we transfer the capabilities of LLMs, like Llama, from English to non-English language? A group of researchers from Fudan University tried to answer those questions by running vast experiments on extending vocabularyâ€¦ https://t.co/fJLYFyQOqP" / X
https://twitter.com/_philschmid/status/1742888388401811795?t=ytmflM4l3Jrzg3zCWdcZGQ&s=09

Philipp Schmid on X: "Is it possible to teach LLMs a different language? ðŸ¤” Can we transfer the capabilities of LLMs, like Llama, from English to non-English language? A group of researchers from Fudan University tried to answer those questions by running vast experiments on extending vocabularyâ€¦ https://t.co/fJLYFyQOqP" / X
https://twitter.com/_philschmid/status/1742888388401811795?t=7DrcO4SgcHm8nPJMbQF1jQ&s=09

This AI Paper from Meta Introduces Hyper-VolTran: A Novel Neural Network for Transformative 3D Reconstruction and Rendering - MarkTechPost
https://www.marktechpost.com/2024/01/03/this-ai-paper-from-mete-introduces-hyper-voltran-a-novel-neural-network-for-transformative-3d-reconstruction-and-rendering/

Phi-2: The surprising power of small language models - Microsoft Research
https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/

GitHub - ml-explore/mlx-examples: Examples in the MLX framework
https://github.com/ml-explore/mlx-examples

mlx-examples/lora/lora.py at main Â· ml-explore/mlx-examples Â· GitHub
https://github.com/ml-explore/mlx-examples/blob/main/lora/lora.py


