{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e2f9e27",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-30T19:17:59.533681Z",
     "iopub.status.busy": "2026-01-30T19:17:59.533292Z",
     "iopub.status.idle": "2026-01-30T19:18:01.550263Z",
     "shell.execute_reply": "2026-01-30T19:18:01.549024Z"
    },
    "papermill": {
     "duration": 2.024887,
     "end_time": "2026-01-30T19:18:01.553373",
     "exception": false,
     "start_time": "2026-01-30T19:17:59.528486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'SegFeat'...\r\n",
      "remote: Enumerating objects: 55, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (21/21), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (9/9), done.\u001b[K\r\n",
      "remote: Total 55 (delta 14), reused 12 (delta 12), pack-reused 34 (from 1)\u001b[K\r\n",
      "Receiving objects: 100% (55/55), 32.80 MiB | 35.10 MiB/s, done.\r\n",
      "Resolving deltas: 100% (23/23), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/felixkreuk/SegFeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "049f447f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T19:18:01.561210Z",
     "iopub.status.busy": "2026-01-30T19:18:01.560794Z",
     "iopub.status.idle": "2026-01-30T19:18:01.569086Z",
     "shell.execute_reply": "2026-01-30T19:18:01.567609Z"
    },
    "papermill": {
     "duration": 0.015349,
     "end_time": "2026-01-30T19:18:01.571684",
     "exception": false,
     "start_time": "2026-01-30T19:18:01.556335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75cc931c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T19:18:01.579873Z",
     "iopub.status.busy": "2026-01-30T19:18:01.578850Z",
     "iopub.status.idle": "2026-01-30T19:18:01.587893Z",
     "shell.execute_reply": "2026-01-30T19:18:01.586773Z"
    },
    "papermill": {
     "duration": 0.016485,
     "end_time": "2026-01-30T19:18:01.590924",
     "exception": false,
     "start_time": "2026-01-30T19:18:01.574439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing segfeat.patch\n"
     ]
    }
   ],
   "source": [
    "%%writefile segfeat.patch\n",
    "--- dataloader.py.orig\t2026-01-30 19:29:45\n",
    "+++ dataloader.py\t2026-01-30 19:30:20\n",
    "@@ -87,14 +88,14 @@\n",
    " \n",
    "     # extract mel-spectrogram\n",
    "     if hparams.feats == 'mel':\n",
    "-        spect = librosa.feature.melspectrogram(wav,\n",
    "+        spect = librosa.feature.melspectrogram(y=wav,\n",
    "                                                sr=sr,\n",
    "                                                n_fft=hparams.n_fft,\n",
    "                                                hop_length=hparams.hop_length,\n",
    "                                                n_mels=hparams.rnn_input_size)\n",
    "     # extract mfcc\n",
    "     elif hparams.feats == 'mfcc':\n",
    "-        spect = librosa.feature.mfcc(wav,\n",
    "+        spect = librosa.feature.mfcc(y=wav,\n",
    "                                      sr=sr,\n",
    "                                      n_fft=hparams.n_fft,\n",
    "                                      hop_length=hparams.hop_length,\n",
    "@@ -208,7 +209,10 @@\n",
    "         raise NotImplementedError\n",
    " \n",
    "     def process_file(self, wav_path):\n",
    "-        phn_path = wav_path.replace(\"wav\", \"phn\")\n",
    "+        phn_path = wav_path.replace(\"WAV\", \"PHN\")\n",
    " \n",
    "         # load audio\n",
    "         spect = extract_features(wav_path, self.hparams)\n",
    "@@ -235,7 +239,7 @@\n",
    " \n",
    "     def _make_dataset(self):\n",
    "         files = []\n",
    "-        wavs = list(iter_find_files(self.wav_path, \"*.wav\"))\n",
    "+        wavs = list(iter_find_files(self.wav_path, \"*.WAV\"))\n",
    "         if self.hparams.devrun:\n",
    "             wavs = wavs[:self.hparams.devrun_size]\n",
    " \n",
    "@@ -265,10 +269,19 @@\n",
    "         self.data = self._make_dataset()\n",
    " \n",
    "     @staticmethod\n",
    "-    def get_datasets(hparams):\n",
    "-        train_dataset = TimitDataset(join(hparams.wav_path, 'train'),\n",
    "-        test_dataset  = TimitDataset(join(hparams.wav_path, 'test'),\n",
    "+        train_dataset = TimitDataset(join(hparams.wav_path, 'TRAIN'),\n",
    "+        test_dataset  = TimitDataset(join(hparams.wav_path, 'TEST'),\n",
    " \n",
    "         train_len   = len(train_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fac2b535",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T19:18:01.599385Z",
     "iopub.status.busy": "2026-01-30T19:18:01.599043Z",
     "iopub.status.idle": "2026-01-30T19:18:01.609298Z",
     "shell.execute_reply": "2026-01-30T19:18:01.607606Z"
    },
    "papermill": {
     "duration": 0.017754,
     "end_time": "2026-01-30T19:18:01.611576",
     "exception": false,
     "start_time": "2026-01-30T19:18:01.593822",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing lightning.patch\n"
     ]
    }
   ],
   "source": [
    "%%writefile lightning.patch\n",
    "--- main.py.orig\t2026-01-30 19:07:04\n",
    "+++ main.py\t2026-01-30 19:07:16\n",
    "@@ -11,7 +11,7 @@\n",
    " from loguru import logger\n",
    " from pytorch_lightning import Trainer\n",
    " from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "-from pytorch_lightning.logging import TestTubeLogger\n",
    "+from pytorch_lightning.loggers import TensorBoardLogger\n",
    " from torch.backends import cudnn\n",
    " from torch.utils.data import DataLoader, Dataset\n",
    " \n",
    "@@ -44,15 +44,13 @@\n",
    "         mode='min'\n",
    "     )\n",
    " \n",
    "-    tt_logger = TestTubeLogger(\n",
    "+    tb_logger = TensorBoardLogger(\n",
    "         save_dir=hparams.run_dir,\n",
    "         name=\"lightning_logs\",\n",
    "-        debug=False,\n",
    "-        create_git_tag=False\n",
    "     )\n",
    " \n",
    "     checkpoint = ModelCheckpoint(\n",
    "-        filepath=model_save_path,\n",
    "+        dirpath=model_save_path,\n",
    "         save_top_k=1,\n",
    "         verbose=True,\n",
    "         monitor='val_f1_at_2',\n",
    "@@ -60,19 +58,17 @@\n",
    "     )\n",
    " \n",
    "     trainer = Trainer(\n",
    "-            logger=tt_logger,\n",
    "-            overfit_pct=hparams.overfit,\n",
    "+            logger=tb_logger,\n",
    "             check_val_every_n_epoch=1,\n",
    "             min_epochs=1,\n",
    "             max_epochs=hparams.epochs,\n",
    "-            nb_sanity_val_steps=4,\n",
    "-            checkpoint_callback=None,\n",
    "-            val_percent_check=hparams.val_percent_check,\n",
    "+            num_sanity_val_steps=4,\n",
    "+            callbacks=[early_stop, checkpoint],\n",
    "+            limit_val_batches=hparams.val_percent_check,\n",
    "             val_check_interval=hparams.val_check_interval,\n",
    "-            early_stop_callback=None,\n",
    "-            gpus=hparams.gpus,\n",
    "-            show_progress_bar=False,\n",
    "-            distributed_backend=None,\n",
    "+            devices=\"auto\",\n",
    "+            accelerator=\"auto\",\n",
    "+            enable_progress_bar=True,\n",
    "             )\n",
    " \n",
    "     if not hparams.test:\n",
    "--- solver.py.orig\t2026-01-30 19:07:04\n",
    "+++ solver.py\t2026-01-30 19:07:57\n",
    "@@ -19,7 +19,7 @@\n",
    " class Solver(LightningModule):\n",
    "     def __init__(self, config):\n",
    "         super(Solver, self).__init__()\n",
    "-        self.hparams = config\n",
    "+        self.save_hyperparameters(config)\n",
    " \n",
    "         if config.dataset == \"timit\":\n",
    "             self.datasetClass = TimitDataset\n",
    "@@ -46,23 +46,23 @@\n",
    "                         'test':  StatsMeter()}\n",
    "         self._device = 'cuda' if config.cuda else 'cpu'\n",
    " \n",
    "+        self.validation_step_outputs = []\n",
    "+        self.test_step_outputs = []\n",
    "+\n",
    "         self.build_model()\n",
    "         logger.info(f\"running on {self._device}\")\n",
    "         logger.info(f\"rnn input size: {config.rnn_input_size}\")\n",
    "         logger.info(f\"{self.segmentor}\")\n",
    " \n",
    "-    @pl.data_loader\n",
    "     def train_dataloader(self):\n",
    "         self.train_loader = DataLoader(self.train_dataset,\n",
    "                                        batch_size=self.config.batch_size,\n",
    "                                        shuffle=True,\n",
    "                                        collate_fn=collate_fn_padd,\n",
    "                                        num_workers=6)\n",
    "-        logger.info(f\"input shape: {self.train_dataset[0][0].shape}\")\n",
    "         logger.info(f\"training set length {len(self.train_dataset)}\")\n",
    "         return self.train_loader\n",
    " \n",
    "-    @pl.data_loader\n",
    "     def val_dataloader(self):\n",
    "         self.valid_loader = DataLoader(self.valid_dataset,\n",
    "                                        batch_size=self.config.batch_size,\n",
    "@@ -72,7 +72,6 @@\n",
    "         logger.info(f\"validation set length {len(self.valid_dataset)}\")\n",
    "         return self.valid_loader\n",
    " \n",
    "-    @pl.data_loader\n",
    "     def test_dataloader(self):\n",
    "         self.test_loader  = DataLoader(self.test_dataset,\n",
    "                                        batch_size=self.config.batch_size,\n",
    "@@ -200,8 +199,6 @@\n",
    " \n",
    "         for output in outputs:\n",
    "             loss = output[f'{prefix}_loss']\n",
    "-            if self.trainer.use_dp:\n",
    "-                loss = torch.mean(loss)\n",
    "             loss_mean += loss\n",
    " \n",
    "         loss_mean /= len(outputs)\n",
    "@@ -243,19 +240,28 @@\n",
    " \n",
    "         logger.info(f\"\\nEVAL {prefix} STATS:\\n{json.dumps(metrics, sort_keys=True, indent=4)}\\n\")\n",
    " \n",
    "-        return metrics\n",
    "+        for k, v in metrics.items():\n",
    "+            self.log(k, v, prog_bar=(k == f'{prefix}_f1_at_2'))\n",
    " \n",
    "     def validation_step(self, data_batch, batch_i):\n",
    "-        return self.generic_eval_step(data_batch, batch_i, 'val')\n",
    "-\n",
    "-    def validation_epoch_end(self, outputs):\n",
    "-        return self.generic_eval_end(outputs, 'val')\n",
    "+        out = self.generic_eval_step(data_batch, batch_i, 'val')\n",
    "+        self.validation_step_outputs.append(out)\n",
    "+        return out\n",
    " \n",
    "+    def on_validation_epoch_end(self):\n",
    "+        outputs = self.validation_step_outputs\n",
    "+        self.generic_eval_end(outputs, 'val')\n",
    "+        self.validation_step_outputs.clear()\n",
    "+\n",
    "     def test_step(self, data_batch, batch_i):\n",
    "-        return self.generic_eval_step(data_batch, batch_i, 'test')\n",
    "+        out = self.generic_eval_step(data_batch, batch_i, 'test')\n",
    "+        self.test_step_outputs.append(out)\n",
    "+        return out\n",
    " \n",
    "-    def test_epoch_end(self, outputs):\n",
    "-        return self.generic_eval_end(outputs, 'test')\n",
    "+    def on_test_epoch_end(self):\n",
    "+        outputs = self.test_step_outputs\n",
    "+        self.generic_eval_end(outputs, 'test')\n",
    "+        self.test_step_outputs.clear()\n",
    " \n",
    "     def configure_optimizers(self):\n",
    "         optimizer = {'adam':     torch.optim.Adam(self.segmentor.parameters(), lr=self.config.lr),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e188c684",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T19:18:01.620408Z",
     "iopub.status.busy": "2026-01-30T19:18:01.619609Z",
     "iopub.status.idle": "2026-01-30T19:18:01.629875Z",
     "shell.execute_reply": "2026-01-30T19:18:01.627782Z"
    },
    "papermill": {
     "duration": 0.018302,
     "end_time": "2026-01-30T19:18:01.632815",
     "exception": false,
     "start_time": "2026-01-30T19:18:01.614513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/SegFeat\n"
     ]
    }
   ],
   "source": [
    "%cd SegFeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a45f9cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T19:18:01.642600Z",
     "iopub.status.busy": "2026-01-30T19:18:01.642035Z",
     "iopub.status.idle": "2026-01-30T19:18:01.881946Z",
     "shell.execute_reply": "2026-01-30T19:18:01.880621Z"
    },
    "papermill": {
     "duration": 0.246903,
     "end_time": "2026-01-30T19:18:01.884318",
     "exception": false,
     "start_time": "2026-01-30T19:18:01.637415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: corrupt patch at line 29\r\n"
     ]
    }
   ],
   "source": [
    "!git apply ../segfeat.patch\n",
    "!git apply ../lightning.patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f61ca674",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T19:18:01.892542Z",
     "iopub.status.busy": "2026-01-30T19:18:01.892126Z",
     "iopub.status.idle": "2026-01-30T19:18:01.900331Z",
     "shell.execute_reply": "2026-01-30T19:18:01.899302Z"
    },
    "papermill": {
     "duration": 0.015637,
     "end_time": "2026-01-30T19:18:01.902862",
     "exception": false,
     "start_time": "2026-01-30T19:18:01.887225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "torch\n",
    "torchaudio\n",
    "torchvision\n",
    "pytorch-lightning\n",
    "boltons\n",
    "loguru\n",
    "librosa\n",
    "numpy\n",
    "pandas\n",
    "soundfile\n",
    "tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5259325d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T19:18:01.911325Z",
     "iopub.status.busy": "2026-01-30T19:18:01.910977Z",
     "iopub.status.idle": "2026-01-30T19:18:09.302851Z",
     "shell.execute_reply": "2026-01-30T19:18:09.301342Z"
    },
    "papermill": {
     "duration": 7.399404,
     "end_time": "2026-01-30T19:18:09.305327",
     "exception": false,
     "start_time": "2026-01-30T19:18:01.905923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (2.8.0+cu126)\r\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (2.8.0+cu126)\r\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (0.23.0+cu126)\r\n",
      "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (2.6.0)\r\n",
      "Collecting boltons (from -r requirements.txt (line 5))\r\n",
      "  Downloading boltons-25.0.0-py3-none-any.whl.metadata (6.5 kB)\r\n",
      "Collecting loguru (from -r requirements.txt (line 6))\r\n",
      "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\r\n",
      "Requirement already satisfied: librosa in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (0.11.0)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (2.0.2)\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (2.2.2)\r\n",
      "Requirement already satisfied: soundfile in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (0.13.1)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (4.67.1)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (3.20.3)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (4.15.0)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (75.2.0)\r\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (2025.10.0)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (12.6.80)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (9.10.2.21)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (12.6.4.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (11.3.0.4)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (10.3.7.77)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (11.7.1.2)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (12.5.4.2)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (0.7.1)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (2.27.3)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (12.6.85)\r\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (1.11.1.6)\r\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (3.4.0)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->-r requirements.txt (line 3)) (11.3.0)\r\n",
      "Requirement already satisfied: PyYAML>5.4 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning->-r requirements.txt (line 4)) (6.0.3)\r\n",
      "Requirement already satisfied: torchmetrics>0.7.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning->-r requirements.txt (line 4)) (1.8.2)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning->-r requirements.txt (line 4)) (26.0rc2)\r\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning->-r requirements.txt (line 4)) (0.15.2)\r\n",
      "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa->-r requirements.txt (line 7)) (3.0.1)\r\n",
      "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa->-r requirements.txt (line 7)) (0.60.0)\r\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from librosa->-r requirements.txt (line 7)) (1.15.3)\r\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa->-r requirements.txt (line 7)) (1.6.1)\r\n",
      "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa->-r requirements.txt (line 7)) (1.5.3)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa->-r requirements.txt (line 7)) (4.4.2)\r\n",
      "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa->-r requirements.txt (line 7)) (1.8.2)\r\n",
      "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa->-r requirements.txt (line 7)) (1.0.0)\r\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa->-r requirements.txt (line 7)) (0.4)\r\n",
      "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa->-r requirements.txt (line 7)) (1.1.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 9)) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 9)) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 9)) (2025.2)\r\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile->-r requirements.txt (line 10)) (2.0.0)\r\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile->-r requirements.txt (line 10)) (2.23)\r\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning->-r requirements.txt (line 4)) (3.13.3)\r\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa->-r requirements.txt (line 7)) (0.43.0)\r\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa->-r requirements.txt (line 7)) (4.5.1)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa->-r requirements.txt (line 7)) (2.32.5)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 9)) (1.17.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa->-r requirements.txt (line 7)) (3.6.0)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 1)) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->-r requirements.txt (line 1)) (3.0.3)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->-r requirements.txt (line 4)) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->-r requirements.txt (line 4)) (1.4.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->-r requirements.txt (line 4)) (25.4.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->-r requirements.txt (line 4)) (1.8.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->-r requirements.txt (line 4)) (6.7.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->-r requirements.txt (line 4)) (0.4.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->-r requirements.txt (line 4)) (1.22.0)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->-r requirements.txt (line 7)) (3.4.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->-r requirements.txt (line 7)) (3.11)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->-r requirements.txt (line 7)) (2.6.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->-r requirements.txt (line 7)) (2026.1.4)\r\n",
      "Downloading boltons-25.0.0-py3-none-any.whl (194 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.2/194.2 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: loguru, boltons\r\n",
      "Successfully installed boltons-25.0.0 loguru-0.7.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dae132c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T19:18:09.315068Z",
     "iopub.status.busy": "2026-01-30T19:18:09.314726Z",
     "iopub.status.idle": "2026-01-30T19:18:58.986137Z",
     "shell.execute_reply": "2026-01-30T19:18:58.984975Z"
    },
    "papermill": {
     "duration": 49.6797,
     "end_time": "2026-01-30T19:18:58.989089",
     "exception": false,
     "start_time": "2026-01-30T19:18:09.309389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-30 19:18:34.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mrun dir: /tmp/segmentation/segmentation_experiment\u001b[0m\r\n",
      "\u001b[32m2026-01-30 19:18:34.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1msaving log in: /tmp/segmentation/segmentation_experiment/run.log\u001b[0m\r\n",
      "\u001b[32m2026-01-30 19:18:34.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m35\u001b[0m - \u001b[1msaving models in: /tmp/segmentation/segmentation_experiment/ckpt\u001b[0m\r\n",
      "\u001b[32m2026-01-30 19:18:34.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m36\u001b[0m - \u001b[1mearly stopping with patience of 5\u001b[0m\r\n",
      "loading data into memory: 0it [00:00, ?it/s]\r\n",
      "loading data into memory: 0it [00:00, ?it/s]\r\n",
      "\u001b[32m2026-01-30 19:18:34.940\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mdataloader\u001b[0m:\u001b[36mget_datasets\u001b[0m:\u001b[36m278\u001b[0m - \u001b[1msplit timit from 0 to train 0, valid 0\u001b[0m\r\n",
      "\u001b[32m2026-01-30 19:18:34.963\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msolver\u001b[0m:\u001b[36mbuild_model\u001b[0m:\u001b[36m100\u001b[0m - \u001b[1mtraining from scratch\u001b[0m\r\n",
      "\u001b[32m2026-01-30 19:18:34.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msolver\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m53\u001b[0m - \u001b[1mrunning on cpu\u001b[0m\r\n",
      "\u001b[32m2026-01-30 19:18:34.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msolver\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m54\u001b[0m - \u001b[1mrnn input size: 43\u001b[0m\r\n",
      "\u001b[32m2026-01-30 19:18:34.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msolver\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m55\u001b[0m - \u001b[1mSegmentor(\r\n",
      "  (rnn): LSTM(43, 200, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\r\n",
      "  (scorer): Sequential(\r\n",
      "    (0): PReLU(num_parameters=1)\r\n",
      "    (1): Linear(in_features=1200, out_features=100, bias=True)\r\n",
      "    (2): PReLU(num_parameters=1)\r\n",
      "    (3): Linear(in_features=100, out_features=1, bias=True)\r\n",
      "  )\r\n",
      "  (classifier): Sequential(\r\n",
      "    (0): PReLU(num_parameters=1)\r\n",
      "    (1): Linear(in_features=400, out_features=78, bias=True)\r\n",
      "    (2): PReLU(num_parameters=1)\r\n",
      "    (3): Linear(in_features=78, out_features=39, bias=True)\r\n",
      "  )\r\n",
      "  (bin_classifier): Sequential(\r\n",
      "    (0): PReLU(num_parameters=1)\r\n",
      "    (1): Linear(in_features=400, out_features=78, bias=True)\r\n",
      "    (2): PReLU(num_parameters=1)\r\n",
      "    (3): Linear(in_features=78, out_features=2, bias=True)\r\n",
      "  )\r\n",
      ")\u001b[0m\r\n",
      "GPU available: False, used: False\r\n",
      "TPU available: False, using: 0 TPU cores\r\n",
      "`Trainer(limit_val_batches=1.0)` was configured so 100% of the batches will be used..\r\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\r\n",
      "2026-01-30 19:18:37.862747: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
      "E0000 00:00:1769800718.129794      57 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "E0000 00:00:1769800718.202526      57 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "W0000 00:00:1769800718.820643      57 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\r\n",
      "W0000 00:00:1769800718.820708      57 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\r\n",
      "W0000 00:00:1769800718.820713      57 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\r\n",
      "W0000 00:00:1769800718.820717      57 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\r\n",
      "\u001b[32m2026-01-30 19:18:55.225\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msolver\u001b[0m:\u001b[36mconfigure_optimizers\u001b[0m:\u001b[36m269\u001b[0m - \u001b[1moptimizer: Adam (\r\n",
      "Parameter Group 0\r\n",
      "    amsgrad: False\r\n",
      "    betas: (0.9, 0.999)\r\n",
      "    capturable: False\r\n",
      "    decoupled_weight_decay: False\r\n",
      "    differentiable: False\r\n",
      "    eps: 1e-08\r\n",
      "    foreach: None\r\n",
      "    fused: None\r\n",
      "    lr: 0.001\r\n",
      "    maximize: False\r\n",
      "    weight_decay: 0\r\n",
      ")\u001b[0m\r\n",
      "┏━━━┳━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┳━━━━━━━┓\r\n",
      "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mFLOPs\u001b[0m\u001b[1;35m \u001b[0m┃\r\n",
      "┡━━━╇━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━╇━━━━━━━┩\r\n",
      "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ segmentor │ Segmentor │  1.5 M │ train │     0 │\r\n",
      "└───┴───────────┴───────────┴────────┴───────┴───────┘\r\n",
      "\u001b[1mTrainable params\u001b[0m: 1.5 M                                                         \r\n",
      "\u001b[1mNon-trainable params\u001b[0m: 0                                                         \r\n",
      "\u001b[1mTotal params\u001b[0m: 1.5 M                                                             \r\n",
      "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 6                                       \r\n",
      "\u001b[1mModules in train mode\u001b[0m: 17                                                       \r\n",
      "\u001b[1mModules in eval mode\u001b[0m: 0                                                         \r\n",
      "\u001b[1mTotal FLOPs\u001b[0m: 0                                                                  \r\n",
      "\u001b[2K/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: \r\n",
      "UserWarning: This DataLoader will create 6 worker processes in total. Our \r\n",
      "suggested max number of worker in current system is 4, which is smaller than \r\n",
      "what this DataLoader is going to create. Please be aware that excessive worker \r\n",
      "creation might get DataLoader running slow or even freeze, lower the worker \r\n",
      "number to avoid potential slowness/freeze if necessary.\r\n",
      "  warnings.warn(\r\n",
      "\u001b[32m2026-01-30 19:18:55.540\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msolver\u001b[0m:\u001b[36mval_dataloader\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mvalidation set length 0\u001b[0m\r\n",
      "\u001b[2K/usr/local/lib/python3.12/dist-packages/pytorch_lightning/utilities/data.py:106:\r\n",
      "Total length of `DataLoader` across ranks is zero. Please make sure this was \r\n",
      "your intention.\r\n",
      "\u001b[2K\r\n",
      "\u001b[?25hTraceback (most recent call last):\r\n",
      "  File \"/kaggle/working/SegFeat/main.py\", line 131, in <module>\r\n",
      "    main(args)\r\n",
      "  File \"/kaggle/working/SegFeat/main.py\", line 75, in main\r\n",
      "    trainer.fit(solver)\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/trainer.py\", line 584, in fit\r\n",
      "    call._call_and_handle_interrupt(\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/call.py\", line 49, in _call_and_handle_interrupt\r\n",
      "    return trainer_fn(*args, **kwargs)\r\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/trainer.py\", line 630, in _fit_impl\r\n",
      "    self._run(model, ckpt_path=ckpt_path, weights_only=weights_only)\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1079, in _run\r\n",
      "    results = self._run_stage()\r\n",
      "              ^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1123, in _run_stage\r\n",
      "    self.fit_loop.run()\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 209, in run\r\n",
      "    self.setup_data()\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 238, in setup_data\r\n",
      "    train_dataloader = _request_dataloader(source)\r\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py\", line 335, in _request_dataloader\r\n",
      "    return data_source.dataloader()\r\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py\", line 299, in dataloader\r\n",
      "    return call._call_lightning_module_hook(self.instance.trainer, self.name, pl_module=self.instance)\r\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/pytorch_lightning/trainer/call.py\", line 177, in _call_lightning_module_hook\r\n",
      "    output = fn(*args, **kwargs)\r\n",
      "             ^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/kaggle/working/SegFeat/solver.py\", line 58, in train_dataloader\r\n",
      "    self.train_loader = DataLoader(self.train_dataset,\r\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/lightning_fabric/utilities/data.py\", line 325, in wrapper\r\n",
      "    init(obj, *args, **kwargs)\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\", line 388, in __init__\r\n",
      "    sampler = RandomSampler(dataset, generator=generator)  # type: ignore[arg-type]\r\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/usr/local/lib/python3.12/dist-packages/torch/utils/data/sampler.py\", line 156, in __init__\r\n",
      "    raise ValueError(\r\n",
      "ValueError: num_samples should be a positive integer value, but got num_samples=0\r\n"
     ]
    }
   ],
   "source": [
    "!python main.py --wav_path /kaggle/input/darpa-timit-acousticphonetic-continuous-speech/data --dataset timit --delta_feats --dist_feats"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 212391,
     "sourceId": 471627,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31259,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 63.607996,
   "end_time": "2026-01-30T19:18:59.414597",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-30T19:17:55.806601",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
