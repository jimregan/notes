{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "604ba565",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2026-01-30T18:31:58.931745Z",
     "iopub.status.busy": "2026-01-30T18:31:58.931362Z",
     "iopub.status.idle": "2026-01-30T18:32:00.985693Z",
     "shell.execute_reply": "2026-01-30T18:32:00.984503Z"
    },
    "papermill": {
     "duration": 2.060867,
     "end_time": "2026-01-30T18:32:00.988099",
     "exception": false,
     "start_time": "2026-01-30T18:31:58.927232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'SegFeat'...\r\n",
      "remote: Enumerating objects: 55, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (21/21), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (9/9), done.\u001b[K\r\n",
      "remote: Total 55 (delta 14), reused 12 (delta 12), pack-reused 34 (from 1)\u001b[K\r\n",
      "Receiving objects: 100% (55/55), 32.80 MiB | 32.61 MiB/s, done.\r\n",
      "Resolving deltas: 100% (23/23), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/felixkreuk/SegFeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b93dd992",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T18:32:00.995905Z",
     "iopub.status.busy": "2026-01-30T18:32:00.995140Z",
     "iopub.status.idle": "2026-01-30T18:32:01.002045Z",
     "shell.execute_reply": "2026-01-30T18:32:01.001142Z"
    },
    "papermill": {
     "duration": 0.013074,
     "end_time": "2026-01-30T18:32:01.004030",
     "exception": false,
     "start_time": "2026-01-30T18:32:00.990956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working\n"
     ]
    }
   ],
   "source": [
    "%cd /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50f9f2e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T18:32:01.011565Z",
     "iopub.status.busy": "2026-01-30T18:32:01.011066Z",
     "iopub.status.idle": "2026-01-30T18:32:01.018609Z",
     "shell.execute_reply": "2026-01-30T18:32:01.017767Z"
    },
    "papermill": {
     "duration": 0.013797,
     "end_time": "2026-01-30T18:32:01.020615",
     "exception": false,
     "start_time": "2026-01-30T18:32:01.006818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing segfeat.patch\n"
     ]
    }
   ],
   "source": [
    "%%writefile segfeat.patch\n",
    "--- dataloader.py.orig\t2026-01-30 19:29:45\n",
    "+++ dataloader.py\t2026-01-30 19:30:20\n",
    "@@ -3,6 +3,7 @@\n",
    " import random\n",
    " from multiprocessing import Pool\n",
    " from os.path import basename, join\n",
    "+from pathlib import Path\n",
    " \n",
    " import librosa\n",
    " import numpy as np\n",
    "@@ -87,14 +88,14 @@\n",
    " \n",
    "     # extract mel-spectrogram\n",
    "     if hparams.feats == 'mel':\n",
    "-        spect = librosa.feature.melspectrogram(wav,\n",
    "+        spect = librosa.feature.melspectrogram(y=wav,\n",
    "                                                sr=sr,\n",
    "                                                n_fft=hparams.n_fft,\n",
    "                                                hop_length=hparams.hop_length,\n",
    "                                                n_mels=hparams.rnn_input_size)\n",
    "     # extract mfcc\n",
    "     elif hparams.feats == 'mfcc':\n",
    "-        spect = librosa.feature.mfcc(wav,\n",
    "+        spect = librosa.feature.mfcc(y=wav,\n",
    "                                      sr=sr,\n",
    "                                      n_fft=hparams.n_fft,\n",
    "                                      hop_length=hparams.hop_length,\n",
    "@@ -208,7 +209,10 @@\n",
    "         raise NotImplementedError\n",
    " \n",
    "     def process_file(self, wav_path):\n",
    "-        phn_path = wav_path.replace(\"wav\", \"phn\")\n",
    "+        wav_p = Path(wav_path)\n",
    "+        phn_path = str(wav_p.with_suffix(\".phn\"))\n",
    "+        if not os.path.exists(phn_path):\n",
    "+            phn_path = str(wav_p.with_suffix(\".PHN\"))\n",
    " \n",
    "         # load audio\n",
    "         spect = extract_features(wav_path, self.hparams)\n",
    "@@ -235,7 +239,7 @@\n",
    " \n",
    "     def _make_dataset(self):\n",
    "         files = []\n",
    "-        wavs = list(iter_find_files(self.wav_path, \"*.wav\"))\n",
    "+        wavs = list(iter_find_files(self.wav_path, \"*.wav\")) + list(iter_find_files(self.wav_path, \"*.WAV\"))\n",
    "         if self.hparams.devrun:\n",
    "             wavs = wavs[:self.hparams.devrun_size]\n",
    " \n",
    "@@ -265,10 +269,19 @@\n",
    "         self.data = self._make_dataset()\n",
    " \n",
    "     @staticmethod\n",
    "-    def get_datasets(hparams):\n",
    "-        train_dataset = TimitDataset(join(hparams.wav_path, 'train'),\n",
    "+    def _find_subdir(base, name):\n",
    "+        \"\"\"Find a subdirectory case-insensitively.\"\"\"\n",
    "+        target = name.lower()\n",
    "+        for entry in os.listdir(base):\n",
    "+            if entry.lower() == target and os.path.isdir(join(base, entry)):\n",
    "+                return join(base, entry)\n",
    "+        return join(base, name)\n",
    "+\n",
    "+    @staticmethod\n",
    "+    def get_datasets(hparams):\n",
    "+        train_dataset = TimitDataset(TimitDataset._find_subdir(hparams.wav_path, 'train'),\n",
    "                                      hparams)\n",
    "-        test_dataset  = TimitDataset(join(hparams.wav_path, 'test'),\n",
    "+        test_dataset  = TimitDataset(TimitDataset._find_subdir(hparams.wav_path, 'test'),\n",
    "                                      hparams)\n",
    " \n",
    "         train_len   = len(train_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbf032a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T18:32:01.030039Z",
     "iopub.status.busy": "2026-01-30T18:32:01.029337Z",
     "iopub.status.idle": "2026-01-30T18:32:01.037618Z",
     "shell.execute_reply": "2026-01-30T18:32:01.036530Z"
    },
    "papermill": {
     "duration": 0.016294,
     "end_time": "2026-01-30T18:32:01.039641",
     "exception": false,
     "start_time": "2026-01-30T18:32:01.023347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing lightning.patch\n"
     ]
    }
   ],
   "source": [
    "%%writefile lightning.patch\n",
    "--- main.py.orig\t2026-01-30 19:07:04\n",
    "+++ main.py\t2026-01-30 19:07:16\n",
    "@@ -11,7 +11,7 @@\n",
    " from loguru import logger\n",
    " from pytorch_lightning import Trainer\n",
    " from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "-from pytorch_lightning.logging import TestTubeLogger\n",
    "+from pytorch_lightning.loggers import TensorBoardLogger\n",
    " from torch.backends import cudnn\n",
    " from torch.utils.data import DataLoader, Dataset\n",
    " \n",
    "@@ -44,15 +44,13 @@\n",
    "         mode='min'\n",
    "     )\n",
    " \n",
    "-    tt_logger = TestTubeLogger(\n",
    "+    tb_logger = TensorBoardLogger(\n",
    "         save_dir=hparams.run_dir,\n",
    "         name=\"lightning_logs\",\n",
    "-        debug=False,\n",
    "-        create_git_tag=False\n",
    "     )\n",
    " \n",
    "     checkpoint = ModelCheckpoint(\n",
    "-        filepath=model_save_path,\n",
    "+        dirpath=model_save_path,\n",
    "         save_top_k=1,\n",
    "         verbose=True,\n",
    "         monitor='val_f1_at_2',\n",
    "@@ -60,19 +58,17 @@\n",
    "     )\n",
    " \n",
    "     trainer = Trainer(\n",
    "-            logger=tt_logger,\n",
    "-            overfit_pct=hparams.overfit,\n",
    "+            logger=tb_logger,\n",
    "             check_val_every_n_epoch=1,\n",
    "             min_epochs=1,\n",
    "             max_epochs=hparams.epochs,\n",
    "-            nb_sanity_val_steps=4,\n",
    "-            checkpoint_callback=None,\n",
    "-            val_percent_check=hparams.val_percent_check,\n",
    "+            num_sanity_val_steps=4,\n",
    "+            callbacks=[early_stop, checkpoint],\n",
    "+            limit_val_batches=hparams.val_percent_check,\n",
    "             val_check_interval=hparams.val_check_interval,\n",
    "-            early_stop_callback=None,\n",
    "-            gpus=hparams.gpus,\n",
    "-            show_progress_bar=False,\n",
    "-            distributed_backend=None,\n",
    "+            devices=\"auto\",\n",
    "+            accelerator=\"auto\",\n",
    "+            enable_progress_bar=True,\n",
    "             )\n",
    " \n",
    "     if not hparams.test:\n",
    "--- solver.py.orig\t2026-01-30 19:07:04\n",
    "+++ solver.py\t2026-01-30 19:07:57\n",
    "@@ -19,7 +19,7 @@\n",
    " class Solver(LightningModule):\n",
    "     def __init__(self, config):\n",
    "         super(Solver, self).__init__()\n",
    "-        self.hparams = config\n",
    "+        self.save_hyperparameters(config)\n",
    " \n",
    "         if config.dataset == \"timit\":\n",
    "             self.datasetClass = TimitDataset\n",
    "@@ -46,23 +46,23 @@\n",
    "                         'test':  StatsMeter()}\n",
    "         self._device = 'cuda' if config.cuda else 'cpu'\n",
    " \n",
    "+        self.validation_step_outputs = []\n",
    "+        self.test_step_outputs = []\n",
    "+\n",
    "         self.build_model()\n",
    "         logger.info(f\"running on {self._device}\")\n",
    "         logger.info(f\"rnn input size: {config.rnn_input_size}\")\n",
    "         logger.info(f\"{self.segmentor}\")\n",
    " \n",
    "-    @pl.data_loader\n",
    "     def train_dataloader(self):\n",
    "         self.train_loader = DataLoader(self.train_dataset,\n",
    "                                        batch_size=self.config.batch_size,\n",
    "                                        shuffle=True,\n",
    "                                        collate_fn=collate_fn_padd,\n",
    "                                        num_workers=6)\n",
    "-        logger.info(f\"input shape: {self.train_dataset[0][0].shape}\")\n",
    "         logger.info(f\"training set length {len(self.train_dataset)}\")\n",
    "         return self.train_loader\n",
    " \n",
    "-    @pl.data_loader\n",
    "     def val_dataloader(self):\n",
    "         self.valid_loader = DataLoader(self.valid_dataset,\n",
    "                                        batch_size=self.config.batch_size,\n",
    "@@ -72,7 +72,6 @@\n",
    "         logger.info(f\"validation set length {len(self.valid_dataset)}\")\n",
    "         return self.valid_loader\n",
    " \n",
    "-    @pl.data_loader\n",
    "     def test_dataloader(self):\n",
    "         self.test_loader  = DataLoader(self.test_dataset,\n",
    "                                        batch_size=self.config.batch_size,\n",
    "@@ -200,8 +199,6 @@\n",
    " \n",
    "         for output in outputs:\n",
    "             loss = output[f'{prefix}_loss']\n",
    "-            if self.trainer.use_dp:\n",
    "-                loss = torch.mean(loss)\n",
    "             loss_mean += loss\n",
    " \n",
    "         loss_mean /= len(outputs)\n",
    "@@ -243,19 +240,28 @@\n",
    " \n",
    "         logger.info(f\"\\nEVAL {prefix} STATS:\\n{json.dumps(metrics, sort_keys=True, indent=4)}\\n\")\n",
    " \n",
    "-        return metrics\n",
    "+        for k, v in metrics.items():\n",
    "+            self.log(k, v, prog_bar=(k == f'{prefix}_f1_at_2'))\n",
    " \n",
    "     def validation_step(self, data_batch, batch_i):\n",
    "-        return self.generic_eval_step(data_batch, batch_i, 'val')\n",
    "-\n",
    "-    def validation_epoch_end(self, outputs):\n",
    "-        return self.generic_eval_end(outputs, 'val')\n",
    "+        out = self.generic_eval_step(data_batch, batch_i, 'val')\n",
    "+        self.validation_step_outputs.append(out)\n",
    "+        return out\n",
    " \n",
    "+    def on_validation_epoch_end(self):\n",
    "+        outputs = self.validation_step_outputs\n",
    "+        self.generic_eval_end(outputs, 'val')\n",
    "+        self.validation_step_outputs.clear()\n",
    "+\n",
    "     def test_step(self, data_batch, batch_i):\n",
    "-        return self.generic_eval_step(data_batch, batch_i, 'test')\n",
    "+        out = self.generic_eval_step(data_batch, batch_i, 'test')\n",
    "+        self.test_step_outputs.append(out)\n",
    "+        return out\n",
    " \n",
    "-    def test_epoch_end(self, outputs):\n",
    "-        return self.generic_eval_end(outputs, 'test')\n",
    "+    def on_test_epoch_end(self):\n",
    "+        outputs = self.test_step_outputs\n",
    "+        self.generic_eval_end(outputs, 'test')\n",
    "+        self.test_step_outputs.clear()\n",
    " \n",
    "     def configure_optimizers(self):\n",
    "         optimizer = {'adam':     torch.optim.Adam(self.segmentor.parameters(), lr=self.config.lr),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad7b1f83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T18:32:01.047131Z",
     "iopub.status.busy": "2026-01-30T18:32:01.046590Z",
     "iopub.status.idle": "2026-01-30T18:32:01.053309Z",
     "shell.execute_reply": "2026-01-30T18:32:01.052131Z"
    },
    "papermill": {
     "duration": 0.012899,
     "end_time": "2026-01-30T18:32:01.055426",
     "exception": false,
     "start_time": "2026-01-30T18:32:01.042527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/SegFeat\n"
     ]
    }
   ],
   "source": [
    "%cd SegFeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4fda948",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T18:32:01.063303Z",
     "iopub.status.busy": "2026-01-30T18:32:01.062301Z",
     "iopub.status.idle": "2026-01-30T18:32:01.297046Z",
     "shell.execute_reply": "2026-01-30T18:32:01.295937Z"
    },
    "papermill": {
     "duration": 0.24096,
     "end_time": "2026-01-30T18:32:01.299228",
     "exception": false,
     "start_time": "2026-01-30T18:32:01.058268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!git apply ../segfeat.patch\n",
    "!git apply ../lightning.patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ec94552",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T18:32:01.307112Z",
     "iopub.status.busy": "2026-01-30T18:32:01.306272Z",
     "iopub.status.idle": "2026-01-30T18:32:01.312595Z",
     "shell.execute_reply": "2026-01-30T18:32:01.311580Z"
    },
    "papermill": {
     "duration": 0.01234,
     "end_time": "2026-01-30T18:32:01.314373",
     "exception": false,
     "start_time": "2026-01-30T18:32:01.302033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "torch\n",
    "torchaudio\n",
    "torchvision\n",
    "pytorch-lightning\n",
    "boltons\n",
    "loguru\n",
    "librosa\n",
    "numpy\n",
    "pandas\n",
    "soundfile\n",
    "tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4c1dd9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T18:32:01.321553Z",
     "iopub.status.busy": "2026-01-30T18:32:01.321087Z",
     "iopub.status.idle": "2026-01-30T18:32:07.741520Z",
     "shell.execute_reply": "2026-01-30T18:32:07.740508Z"
    },
    "papermill": {
     "duration": 6.426533,
     "end_time": "2026-01-30T18:32:07.743747",
     "exception": false,
     "start_time": "2026-01-30T18:32:01.317214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (2.8.0+cu126)\r\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (2.8.0+cu126)\r\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (0.23.0+cu126)\r\n",
      "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (2.6.0)\r\n",
      "Collecting boltons (from -r requirements.txt (line 5))\r\n",
      "  Downloading boltons-25.0.0-py3-none-any.whl.metadata (6.5 kB)\r\n",
      "Collecting loguru (from -r requirements.txt (line 6))\r\n",
      "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\r\n",
      "Requirement already satisfied: librosa in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (0.11.0)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (2.0.2)\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (2.2.2)\r\n",
      "Requirement already satisfied: soundfile in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (0.13.1)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (4.67.1)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (3.20.3)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (4.15.0)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (75.2.0)\r\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (2025.10.0)\r\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (12.6.80)\r\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (9.10.2.21)\r\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (12.6.4.1)\r\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (11.3.0.4)\r\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (10.3.7.77)\r\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (11.7.1.2)\r\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (12.5.4.2)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (0.7.1)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (2.27.3)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (12.6.77)\r\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (12.6.85)\r\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (1.11.1.6)\r\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 1)) (3.4.0)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->-r requirements.txt (line 3)) (11.3.0)\r\n",
      "Requirement already satisfied: PyYAML>5.4 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning->-r requirements.txt (line 4)) (6.0.3)\r\n",
      "Requirement already satisfied: torchmetrics>0.7.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning->-r requirements.txt (line 4)) (1.8.2)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning->-r requirements.txt (line 4)) (26.0rc2)\r\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from pytorch-lightning->-r requirements.txt (line 4)) (0.15.2)\r\n",
      "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa->-r requirements.txt (line 7)) (3.0.1)\r\n",
      "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa->-r requirements.txt (line 7)) (0.60.0)\r\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from librosa->-r requirements.txt (line 7)) (1.15.3)\r\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa->-r requirements.txt (line 7)) (1.6.1)\r\n",
      "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa->-r requirements.txt (line 7)) (1.5.3)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa->-r requirements.txt (line 7)) (4.4.2)\r\n",
      "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa->-r requirements.txt (line 7)) (1.8.2)\r\n",
      "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa->-r requirements.txt (line 7)) (1.0.0)\r\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa->-r requirements.txt (line 7)) (0.4)\r\n",
      "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa->-r requirements.txt (line 7)) (1.1.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 9)) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 9)) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 9)) (2025.2)\r\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile->-r requirements.txt (line 10)) (2.0.0)\r\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile->-r requirements.txt (line 10)) (2.23)\r\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning->-r requirements.txt (line 4)) (3.13.3)\r\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa->-r requirements.txt (line 7)) (0.43.0)\r\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa->-r requirements.txt (line 7)) (4.5.1)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa->-r requirements.txt (line 7)) (2.32.5)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 9)) (1.17.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa->-r requirements.txt (line 7)) (3.6.0)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 1)) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->-r requirements.txt (line 1)) (3.0.3)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->-r requirements.txt (line 4)) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->-r requirements.txt (line 4)) (1.4.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->-r requirements.txt (line 4)) (25.4.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->-r requirements.txt (line 4)) (1.8.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->-r requirements.txt (line 4)) (6.7.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->-r requirements.txt (line 4)) (0.4.1)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning->-r requirements.txt (line 4)) (1.22.0)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->-r requirements.txt (line 7)) (3.4.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->-r requirements.txt (line 7)) (3.11)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->-r requirements.txt (line 7)) (2.6.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa->-r requirements.txt (line 7)) (2026.1.4)\r\n",
      "Downloading boltons-25.0.0-py3-none-any.whl (194 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.2/194.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: loguru, boltons\r\n",
      "Successfully installed boltons-25.0.0 loguru-0.7.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1df3749",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-30T18:32:07.753904Z",
     "iopub.status.busy": "2026-01-30T18:32:07.752852Z",
     "iopub.status.idle": "2026-01-30T18:34:20.455311Z",
     "shell.execute_reply": "2026-01-30T18:34:20.454247Z"
    },
    "papermill": {
     "duration": 132.71026,
     "end_time": "2026-01-30T18:34:20.457851",
     "exception": false,
     "start_time": "2026-01-30T18:32:07.747591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-30 18:32:30.410\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m28\u001b[0m - \u001b[1mrun dir: /tmp/segmentation/segmentation_experiment\u001b[0m\r\n",
      "\u001b[32m2026-01-30 18:32:30.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1msaving log in: /tmp/segmentation/segmentation_experiment/run.log\u001b[0m\r\n",
      "\u001b[32m2026-01-30 18:32:30.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m35\u001b[0m - \u001b[1msaving models in: /tmp/segmentation/segmentation_experiment/ckpt\u001b[0m\r\n",
      "\u001b[32m2026-01-30 18:32:30.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m36\u001b[0m - \u001b[1mearly stopping with patience of 5\u001b[0m\r\n",
      "loading data into memory:   0%|                        | 0/9240 [00:15<?, ?it/s]\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/kaggle/working/SegFeat/main.py\", line 131, in <module>\r\n",
      "    main(args)\r\n",
      "  File \"/kaggle/working/SegFeat/main.py\", line 38, in main\r\n",
      "    solver = Solver(hparams)\r\n",
      "             ^^^^^^^^^^^^^^^\r\n",
      "  File \"/kaggle/working/SegFeat/solver.py\", line 30, in __init__\r\n",
      "    self.train_dataset, self.valid_dataset, self.test_dataset = self.datasetClass.get_datasets(config)\r\n",
      "                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/kaggle/working/SegFeat/dataloader.py\", line 282, in get_datasets\r\n",
      "    train_dataset = TimitDataset(TimitDataset._find_subdir(hparams.wav_path, 'train'),\r\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/kaggle/working/SegFeat/dataloader.py\", line 269, in __init__\r\n",
      "    self.data = self._make_dataset()\r\n",
      "                ^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/kaggle/working/SegFeat/dataloader.py\", line 247, in _make_dataset\r\n",
      "    res = self.process_file(wav)\r\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/kaggle/working/SegFeat/dataloader.py\", line 221, in process_file\r\n",
      "    with open(phn_path, \"r\") as f:\r\n",
      "         ^^^^^^^^^^^^^^^^^^^\r\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/kaggle/input/darpa-timit-acousticphonetic-continuous-speech/data/TRAIN/DR4/MSRG0/SA1.WAV.PHN'\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python main.py --wav_path /kaggle/input/darpa-timit-acousticphonetic-continuous-speech/data --dataset timit --delta_feats --dist_feats"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 212391,
     "sourceId": 471627,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31259,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 145.046647,
   "end_time": "2026-01-30T18:34:20.882055",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2026-01-30T18:31:55.835408",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
