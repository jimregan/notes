{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joregan/miniconda3/envs/hf/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE=Path(\"/home/chreri/overflow/OverFlow-sardrag/output/nordanvinden\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [str(x) for x in BASE.glob(\"**/*.wav\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Resolving data files: 100%|██████████| 550/550 [00:00<00:00, 541137.04it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"audiofolder\", data_files=filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-large-v2\")\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-large-v2\")\n",
    "forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"swedish\", task=\"transcribe\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "SENTENCES = {\n",
    "    \"sent-1\": \"Nordanvinden och solen tvistade en gång om vem av dem som var starkast.\",\n",
    "    \"sent-2\": \"Just då kom en vandrare vägen fram, insvept i en varm kappa.\",\n",
    "    \"sent-3\": \"De kom då överens om att den som först kunde få vandraren att ta av sig kappan, han skulle anses vara starkare än den andra.\",\n",
    "    \"sent-4\": \"Då blåste nordanvinden så hårt han någonsin kunde, men ju hårdare han blåste, desto tätare svepte vandraren kappan om sig, och till slut gav nordanvinden upp försöket.\",\n",
    "    \"sent-5\": \"Då lät solen sina strålar skina helt varmt och genast tog vandraren av sig kappan, och så var nordanvinden tvungen att erkänna att solen var den starkaste av de två.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Audio\n",
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_pred(batch):\n",
    "    audio = batch[\"audio\"]\n",
    "    path = audio[\"path\"]\n",
    "    start = path.find(\"sent-\")\n",
    "    sentence_id = path[start:start+6]\n",
    "    batch[\"reference\"] = SENTENCES[sentence_id]\n",
    "    input_features = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"], return_tensors=\"pt\").input_features\n",
    "    with torch.no_grad():\n",
    "        predicted_ids = model.generate(input_features)[0]\n",
    "    transcription = processor.decode(predicted_ids)\n",
    "    batch[\"prediction\"] = processor.tokenizer._normalize(transcription)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = dataset.map(map_to_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "BASE=Path(\"/home/chreri/overflow/OverFlow-sardrag/output/nordanvinden\")\n",
    "filenames = [str(x) for x in BASE.glob(\"**/*.wav\")]\n",
    "num_files = len(filenames)\n",
    "model = whisper.load_model(\"large-v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probs(model, filename, v3=True):\n",
    "    num_mels = 128 if v3 else 80\n",
    "    audio = whisper.load_audio(filename)\n",
    "    audio = whisper.pad_or_trim(audio)\n",
    "    mel = whisper.log_mel_spectrogram(audio, n_mels=num_mels).to(model.device)\n",
    "    _, probs = model.detect_language(mel)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for filename in tqdm(filenames):\n",
    "        cur = {}\n",
    "        cur[\"path\"] = filename\n",
    "        cur[\"result\"] = model.transcribe(filename, language=\"sv\", fp16=False, verbose=True)\n",
    "        cur[\"probs\"] = get_probs(model, filename)\n",
    "        results.append(cur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "893157"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getpid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jiwer import wer\n",
    "with open(\"/tmp/results.tsv\", \"w\") as output:\n",
    "    for res in results:\n",
    "        path = res[\"path\"]\n",
    "        start = path.find(\"sent-\")\n",
    "        sentence_id = path[start:start+6]\n",
    "        reference = SENTENCES[sentence_id]\n",
    "        reference_clean = reference.strip().lower().replace(\",\", \"\").replace(\".\", \"\")\n",
    "        pred = res[\"result\"][\"text\"]\n",
    "        pred_clean = pred.strip().lower().replace(\",\", \"\").replace(\".\", \"\")\n",
    "        sv_prob = res[\"probs\"][\"sv\"]\n",
    "        en_prob = res[\"probs\"][\"en\"]\n",
    "        wer_raw = wer(reference, pred)\n",
    "        wer_clean = wer(reference_clean, pred_clean)\n",
    "        output.write(f\"{path}\\t{sentence_id}\\t{reference}\\t{pred}\\t{wer_raw}\\t{wer_clean}\\t{sv_prob}\\t{en_prob}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from pathlib import Path\n",
    "BASE=Path(\"/home/chreri/overflow/OverFlow-sardrag/output/nordanvinden\")\n",
    "filenames = [str(x) for x in BASE.glob(\"**/*.wav\")]\n",
    "dataset = load_dataset(\"audiofolder\", data_files=filenames)\n",
    "from datasets import Audio\n",
    "dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "_SWE_MODEL = \"KBLab/wav2vec2-large-voxrex-swedish\"\n",
    "from transformers import pipeline\n",
    "pipe = pipeline(model=_SWE_MODEL)\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "\n",
    "res = []\n",
    "for it in pipe(KeyDataset(dataset['train'], \"audio\"), return_timestamps=\"word\"):\n",
    "    res.append(it)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attach_path(batch):\n",
    "    batch['path'] = batch['audio']['path']\n",
    "    return batch\n",
    "\n",
    "dataset.map(attach_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fn in filenames:\n",
    "    tmp = pipe(fn, return_timestamps=\"word\")\n",
    "    tmp['path'] = fn\n",
    "    res.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jiwer import wer\n",
    "with open(\"/tmp/results.tsv\", \"w\") as output:\n",
    "    for res in results:\n",
    "        path = res[\"path\"]\n",
    "        start = path.find(\"sent-\")\n",
    "        sentence_id = path[start:start+6]\n",
    "        sv_prob = res[\"probs\"][\"sv\"]\n",
    "        en_prob = res[\"probs\"][\"en\"]\n",
    "        output.write(f\"{path}\\t{sentence_id}\\t{sv_prob}\\t{en_prob}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_v3 = {}\n",
    "with open(\"/Users/joregan/Downloads/results.tsv\") as v3:\n",
    "    for line in v3.readlines():\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        cur = {}\n",
    "        # output.write(f\"{path}\\t{sentence_id}\\t{reference}\\t{pred}\\t{wer_raw}\\t{wer_clean}\\t{sv_prob}\\t{en_prob}\\n\")\n",
    "        cur[\"sv_prob_v3\"] = parts[6]\n",
    "        cur[\"en_prob_v3\"] = parts[7]\n",
    "        res_v3[parts[0]] = cur\n",
    "with open(\"/tmp/results.tsv\") as v2:\n",
    "    for line in v2.readlines():\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        # output.write(f\"{path}\\t{sentence_id}\\t{sv_prob}\\t{en_prob}\\n\")\n",
    "        res_v3[parts[0]][\"sv_prob_v2\"] = parts[2]\n",
    "        res_v3[parts[0]][\"en_prob_v2\"] = parts[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/tmp/both.tsv\", \"w\") as both:\n",
    "    both.write(\"Path\\tID SV (v2)\\tID SV (v3)\\tID EN (v2)\\tID EN (v3)\\n\")\n",
    "    for comp in res_v3:\n",
    "        both.write(f'{comp}\\t{res_v3[comp][\"sv_prob_v2\"]}\\t{res_v3[comp][\"sv_prob_v3\"]}\\t{res_v3[comp][\"en_prob_v2\"]}\\t{res_v3[comp][\"en_prob_v3\"]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/76448210/how-to-feed-a-numpy-array-as-audio-for-whisper-model\n",
    "def get_audioseqment(audio_path):\n",
    "    audio_segment = AudioSegment.from_wav(audio_path)\n",
    "    # convert to expected format\n",
    "    if audio_segment.frame_rate != 16000:\n",
    "        audio_segment = audio_segment.set_frame_rate(16000)\n",
    "    if audio_segment.sample_width != 2:\n",
    "        audio_segment = audio_segment.set_sample_width(2)\n",
    "    if audio_segment.channels != 1:\n",
    "        audio_segment = audio_segment.set_channels(1)\n",
    "    return audio_segment\n",
    "def pydub_to_whisper(audio_segment):\n",
    "    arr = np.array(audio_segment.get_array_of_samples())\n",
    "    arr = arr.astype(np.float32)/32768.0\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"w2v-rec2.json\") as jsonf:\n",
    "    rec_data = json.load(jsonf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for recognition in tqdm(rec_data):\n",
    "    segment = get_audioseqment(recognition['path'])\n",
    "    for chunk in recognition['chunks']:\n",
    "        start = int(chunk['timestamp'][0] * 1000)\n",
    "        end = int(chunk['timestamp'][1] * 1000)\n",
    "        audio_chunk = pydub_to_whisper(segment[start:end])\n",
    "        probs = get_probs_audiosegment(model, audio_chunk)\n",
    "        chunk['prob_sv'] = probs['sv']\n",
    "        chunk['prob_en'] = probs['en']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probs_audiosegment(model, audio, v3=True):\n",
    "    num_mels = 128 if v3 else 80\n",
    "    audio = whisper.pad_or_trim(audio)\n",
    "    mel = whisper.log_mel_spectrogram(audio, n_mels=num_mels).to(model.device)\n",
    "    _, probs = model.detect_language(mel)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTENCES = {\n",
    "    \"sent-1\": \"Sebastian tyckte att maten kunde ha lagats med lite finess.\",\n",
    "    \"sent-2\": \"Våra beroendeterapeuter har aldrig direkt räddat någon.\",\n",
    "    \"sent-3\": \"Forskningen visade tydligt på kopplingen mellan motion och ökad levnadsstandard.\",\n",
    "    \"sent-4\": \"I kemi är molekylärgeometri central för att förklara en förenings egenskaper.\"\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
