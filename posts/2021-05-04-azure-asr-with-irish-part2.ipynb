{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "msspeech.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGqU6jVvQuMI"
      },
      "source": [
        "# \"Azure speech recognition for Irish, part 2\"\n",
        "> \"json output contains nbest, timestamps, and text without replacements\"\n",
        "\n",
        "- toc: false\n",
        "- branch: master\n",
        "- comments: true\n",
        "- categories: [azure, irish, asr]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ecsb9jm6T-Om"
      },
      "source": [
        "%%capture\n",
        "!pip install azure-cognitiveservices-speech\n",
        "!pip install youtube-dl"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6qs816gXoQL"
      },
      "source": [
        "%%capture\n",
        "!youtube-dl https://www.youtube.com/watch?v=cfjdfaqWY3Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcOX1iA5UExx"
      },
      "source": [
        "import azure.cognitiveservices.speech as speechsdk"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yOBo1Y4LmeG"
      },
      "source": [
        "Use either Key1 or Key2 (on [Azure Portal](https://portal.azure.com/), in \"Keys and Endpoints\" from the menu on the left hand side of the screen)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXd-dOicVrR9"
      },
      "source": [
        "_SUBS=input('put your subscription key here: ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsH0IuSdVu0z"
      },
      "source": [
        "_LOC='westeurope'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_bIGnMOVxuK"
      },
      "source": [
        "speech_config = speechsdk.SpeechConfig(region=_LOC, subscription=_SUBS)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hy0YuL_risLk"
      },
      "source": [
        "!wget https://upload.wikimedia.org/wikipedia/commons/6/60/MSF_chapter_3.ogg https://upload.wikimedia.org/wikipedia/commons/e/ee/MSF_chapter_4.ogg https://upload.wikimedia.org/wikipedia/commons/b/b3/MSF_chapter_5.ogg https://upload.wikimedia.org/wikipedia/commons/2/21/MSF_chapter_6.ogg https://upload.wikimedia.org/wikipedia/commons/7/71/MSF_chapter_7.ogg https://upload.wikimedia.org/wikipedia/commons/d/d5/MSF_chapter_8.ogg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABFSgc7PXxqc"
      },
      "source": [
        "!ffmpeg -i MSF_chapter_5.ogg -acodec pcm_s16le -ac 1 -ar 16000 MSF_chapter_5.wav"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBoYXpfwYTwf"
      },
      "source": [
        "speech_config.speech_recognition_language = 'ga-IE'\n",
        "speech_config.request_word_level_timestamps()\n",
        "speech_config.output_format = speechsdk.OutputFormat(1)\n",
        "speech_config.endpoint_id=f'https://{_LOC}.api.cognitive.microsoft.com/sts/v1.0/issuetoken'"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJSt5cgt75-T"
      },
      "source": [
        "# https://github.com/Azure-Samples/cognitive-services-speech-sdk/blob/master/samples/python/console/speech_sample.py\n",
        "# Copyright (c) Microsoft. All rights reserved.\n",
        "# Licensed under the MIT license. See LICENSE.md file in the project root for full license information.\n",
        "import time\n",
        "import json\n",
        "def speech_recognize_continuous_from_file(speech_config, filename):\n",
        "    \"\"\"performs continuous speech recognition with input from an audio file\"\"\"\n",
        "    speech_config = speech_config\n",
        "    audio_config = speechsdk.audio.AudioConfig(filename=filename)\n",
        "    outfilename = filename.replace('.wav', '.json')\n",
        "    outfile = open(outfilename, 'a')\n",
        "\n",
        "\n",
        "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, language='ga-IE', audio_config=audio_config)\n",
        "\n",
        "    done = False\n",
        "\n",
        "    def stop_cb(evt):\n",
        "        \"\"\"callback that signals to stop continuous recognition upon receiving an event `evt`\"\"\"\n",
        "        print('CLOSING on {}'.format(evt))\n",
        "        nonlocal done\n",
        "        done = True\n",
        "\n",
        "    def cancelled(evt):\n",
        "      result = evt.result\n",
        "      cancellation_details = result.cancellation_details\n",
        "      print(\"Speech Recognition canceled: {}\".format(cancellation_details.reason))\n",
        "      if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
        "        print(\"Error details: {}\".format(cancellation_details.error_details))\n",
        "\n",
        "    def recognised(evt):\n",
        "      response = json.loads(evt.result.json)\n",
        "      outfile.write('{}\\n'.format(evt.result.json))\n",
        "\n",
        "    # Connect callbacks to the events fired by the speech recognizer\n",
        "    speech_recognizer.recognizing.connect(lambda evt: print('RECOGNIZING: {}'.format(evt)))\n",
        "    speech_recognizer.recognized.connect(recognised)\n",
        "    speech_recognizer.session_started.connect(lambda evt: print('SESSION STARTED: {}'.format(evt)))\n",
        "    speech_recognizer.session_stopped.connect(lambda evt: print('SESSION STOPPED {}'.format(evt)))\n",
        "    speech_recognizer.canceled.connect(cancelled)\n",
        "    # stop continuous recognition on either session stopped or canceled events\n",
        "    speech_recognizer.session_stopped.connect(stop_cb)\n",
        "    speech_recognizer.canceled.connect(stop_cb)\n",
        "\n",
        "    # Start continuous speech recognition\n",
        "    speech_recognizer.start_continuous_recognition()\n",
        "    while not done:\n",
        "        time.sleep(.5)\n",
        "\n",
        "    speech_recognizer.stop_continuous_recognition()\n",
        "    outfile.close()"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77i7mJbw7_y-"
      },
      "source": [
        "for i in \"345678\":\n",
        "  speech_recognize_continuous_from_file(speech_config, f'MSF_chapter_{i}.wav')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}