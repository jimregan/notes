{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled14.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGqU6jVvQuMI"
      },
      "source": [
        "# \"Azure speech recognition for Irish\"\n",
        "> \"Authentication is a bit of a pain; recognition is fantastic, but let down by number inverse normalisation\"\n",
        "\n",
        "- toc: false\n",
        "- branch: master\n",
        "- comments: true\n",
        "- categories: [azure, irish, asr]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ecsb9jm6T-Om"
      },
      "source": [
        "%%capture\n",
        "!pip install azure-cognitiveservices-speech"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5yQjK_gV5Io"
      },
      "source": [
        "%%capture\n",
        "!pip install youtube-dl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6qs816gXoQL"
      },
      "source": [
        "%%capture\n",
        "!youtube-dl https://www.youtube.com/watch?v=cfjdfaqWY3Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABFSgc7PXxqc"
      },
      "source": [
        "%%capture\n",
        "!ffmpeg -i Cúla4\\ Ar\\ Scoil\\ _\\ Ábhar\\ -\\ Mata\\ _\\ Téama\\ -\\ Bia-cfjdfaqWY3Y.mkv -acodec pcm_s16le -ac 1 -ar 16000 cfjdfaqWY3Y.wav"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbaIiZ3M7gx0"
      },
      "source": [
        "import IPython\n",
        "IPython.display.Audio('/content/cfjdfaqWY3Y.wav')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcOX1iA5UExx"
      },
      "source": [
        "import azure.cognitiveservices.speech as speechsdk"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yOBo1Y4LmeG"
      },
      "source": [
        "Use either Key1 or Key2 (on [Azure Portal](https://portal.azure.com/), in \"Keys and Endpoints\" from the menu on the left hand side of the screen)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXd-dOicVrR9"
      },
      "source": [
        "# put your subscription key here\n",
        "_SUBS=''"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsH0IuSdVu0z"
      },
      "source": [
        "_LOC='westeurope'"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_bIGnMOVxuK"
      },
      "source": [
        "speech_config = speechsdk.SpeechConfig(region=_LOC, subscription=_SUBS)\n"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esIhX4AWYEc_"
      },
      "source": [
        "audio_input=speechsdk.audio.AudioConfig(filename='cfjdfaqWY3Y.wav')"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBoYXpfwYTwf"
      },
      "source": [
        "speech_config.speech_recognition_language = 'ga-IE'\n",
        "speech_config.request_word_level_timestamps()\n",
        "speech_config.output_format = speechsdk.OutputFormat(1)\n",
        "speech_config.endpoint_id='https://westeurope.api.cognitive.microsoft.com/sts/v1.0/issuetoken'"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbg05vvxMn1r"
      },
      "source": [
        "speech_config.set_property(speechsdk.PropertyId.Speech_LogFilename, \"azure.log\")"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJSt5cgt75-T"
      },
      "source": [
        "# https://github.com/Azure-Samples/cognitive-services-speech-sdk/blob/master/samples/python/console/speech_sample.py\n",
        "# Copyright (c) Microsoft. All rights reserved.\n",
        "# Licensed under the MIT license. See LICENSE.md file in the project root for full license information.\n",
        "import time\n",
        "def speech_recognize_continuous_from_file(speech_config, audio_config):\n",
        "    \"\"\"performs continuous speech recognition with input from an audio file\"\"\"\n",
        "    speech_config = speech_config\n",
        "    audio_config = audio_config\n",
        "\n",
        "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, language='ga-IE', audio_config=audio_config)\n",
        "    \n",
        "\n",
        "    done = False\n",
        "\n",
        "    def stop_cb(evt):\n",
        "        \"\"\"callback that signals to stop continuous recognition upon receiving an event `evt`\"\"\"\n",
        "        print('CLOSING on {}'.format(evt))\n",
        "        nonlocal done\n",
        "        done = True\n",
        "\n",
        "    def cancelled(evt):\n",
        "      result = evt.result\n",
        "      cancellation_details = result.cancellation_details\n",
        "      print(\"Speech Recognition canceled: {}\".format(cancellation_details.reason))\n",
        "      if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
        "        print(\"Error details: {}\".format(cancellation_details.error_details))\n",
        "\n",
        "    # Connect callbacks to the events fired by the speech recognizer\n",
        "    speech_recognizer.recognizing.connect(lambda evt: print('RECOGNIZING: {}'.format(evt)))\n",
        "    speech_recognizer.recognized.connect(lambda evt: print('RECOGNIZED: {}'.format(evt)))\n",
        "    speech_recognizer.session_started.connect(lambda evt: print('SESSION STARTED: {}'.format(evt)))\n",
        "    speech_recognizer.session_stopped.connect(lambda evt: print('SESSION STOPPED {}'.format(evt)))\n",
        "    speech_recognizer.canceled.connect(cancelled)\n",
        "    # stop continuous recognition on either session stopped or canceled events\n",
        "    speech_recognizer.session_stopped.connect(stop_cb)\n",
        "    speech_recognizer.canceled.connect(stop_cb)\n",
        "\n",
        "    # Start continuous speech recognition\n",
        "    speech_recognizer.start_continuous_recognition()\n",
        "    while not done:\n",
        "        time.sleep(.5)\n",
        "\n",
        "    speech_recognizer.stop_continuous_recognition()"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77i7mJbw7_y-"
      },
      "source": [
        "speech_recognize_continuous_from_file(speech_config, audio_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ho8IpVbR__-"
      },
      "source": [
        "Debugging with `curl`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfWM-MCmEZil"
      },
      "source": [
        " !curl -v -X POST \"https://{_LOC}.api.cognitive.microsoft.com/sts/v1.0/issueToken\" -H \"Ocp-Apim-Subscription-Key: {_SUBS}\" -H \"Content-type: application/x-www-form-urlencoded\" -H \"Content-Length: 0\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqQ2ThdvFdCP"
      },
      "source": [
        "_TOK=''"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gtBC6gGF4nf"
      },
      "source": [
        "!curl -v -X POST \"https://{_LOC}.stt.speech.microsoft.com/speech/recognition/interactive/cognitiveservices/v1?language=ga-IE\" -H \"Authorization: Bearer {_TOK}\" -H \"Transfer-Encoding: chunked\" -H \"Content-type: audio/wav; codec=audio/pcm; samplerate=16000\" --data-binary @cfjdfaqWY3Y.wav"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odoogRiaR4f5"
      },
      "source": [
        "Next step, get at the innards (TODO)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0iG0hCjaBlR"
      },
      "source": [
        "transcript_display_list = []\n",
        "transcript_ITN_list = []\n",
        "confidence_list = []\n",
        "words = []\n",
        "\n",
        "def parse_azure_result(evt):\n",
        "  import json\n",
        "  response = json.loads(evt.result.json)\n",
        "  transcript_display_list.append(response['DisplayText'])\n",
        "  confidence_list_temp = [item.get('Confidence') for item in response['NBest']]\n",
        "  max_confidence_index = confidence_list_temp.index(max(confidence_list_temp))\n",
        "  confidence_list.append(response['NBest'][max_confidence_index]['Confidence'])\n",
        "  transcript_ITN_list.append(response['NBest'][max_confidence_index]['ITN'])\n",
        "  words.extend(response['NBest'][max_confidence_index]['Words'])\n",
        "  logger.debug(evt)\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}