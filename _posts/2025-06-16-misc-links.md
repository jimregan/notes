---
toc: true
layout: post
hidden: true
description: Misc. interesting things.
title: Interesting links, 16/06/2025
categories: [links]
---

[MASSIVE: A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages](https://arxiv.org/abs/2204.08582),
[code](https://github.com/alexa/massive)

[SLURP: A Spoken Language Understanding Resource Package](https://arxiv.org/abs/2011.13205),
[data](https://github.com/pswietojanski/slurp) --- text is open, audio is not

[ZeroSep: Separate Anything in Audio with Zero Training](https://wikichao.github.io/ZeroSep/),
[arXiv](https://arxiv.org/abs/2505.23625),
[code](https://github.com/WikiChao/ZeroSep)

[There are 6 forms of depression, study shows. Here’s how they’re different.](https://www.nationalgeographic.com/science/article/six-subtypes-depression-brain-imaging)

[Marconi Union - Weightless](https://www.youtube.com/watch?v=UfcAVejslrU) --- supposed to help with anxiety

[Translation-Inspired OCR](https://ieeexplore.ieee.org/document/6065528)

---

[Gramatika kaszëbsczégò jãzëka](http://skarbnicakaszubska.pl/wp-content/uploads/2018/04/GRAMATYKA-hiperlacza.pdf)

[Kashubian through Polish](https://thedomcio.github.io/WonderfulPolishLanguage/#kashubian-kaszubski)

[Najô Ùczba](http://skarbnicakaszubska.pl/najo-uczba/)

[Bajki Kaszubkie](http://www.akademiabajkikaszubskiej.pl/bajki)

[Słownik Polsko-Kaszubski](http://skarbnicakaszubska.pl/wp-content/uploads/2016/11/Slownik_1-1.pdf)

---

[Dependency Parsing Evaluation for Low-resource Spontaneous Speech](https://aclanthology.org/2021.adaptnlp-1.16/)

[The Swedish Parliament Corpus](https://github.com/swerik-project/the-swedish-parliament-corpus)

[Upper Sorbian UD](https://github.com/UniversalDependencies/UD_Upper_Sorbian-UFAL)

[Insert OCRed text and annotations in DjVu](http://www.ub-filosofie.ro/~solcan/wt/gnu/d/hdjv.html)

[TaxoLLaMA: WordNet-based Model for Solving Multiple Lexical Semantic Tasks](https://arxiv.org/abs/2403.09207),
[code](https://github.com/VityaVitalich/TaxoLLaMA)

[Anthropic wins key US ruling on AI training in authors' copyright lawsuit](https://www.reuters.com/legal/litigation/anthropic-wins-key-ruling-ai-authors-copyright-lawsuit-2025-06-24/)

[CILI: the Collaborative Interlingual Index](https://aclanthology.org/2016.gwc-1.9/)

[omwn/omw-data](https://github.com/omwn/omw-data) --- This packages up data for the Open Multilingual Wordnet

[docker image save](https://docs.docker.com/reference/cli/docker/image/save/) --- Save one or more images to a tar archive

[Introducing the V-JEPA 2 world model and new benchmarks for physical reasoning](https://ai.meta.com/blog/v-jepa-2-world-model-benchmarks/)

[facebook/vjepa2-vitl-fpc64-256](https://huggingface.co/facebook/vjepa2-vitl-fpc64-256) --- **actually** open source.

[SPECOM 2025](https://specom.inf.u-szeged.hu/):
- October 13-15, 2025
- deadline: June 30, 2025 (23:59, anywhere on Earth)
- [overleaf](https://www.overleaf.com/latex/templates/springer-lecture-notes-in-computer-science/kzwwpvhwnvfj#.WuA4JS5uZpi)
- [EasyChair](https://easychair.org/conferences/?conf=specom2025)

[Dev Containers tutorial](https://code.visualstudio.com/docs/devcontainers/tutorial)

[Terrible things happen in life – but it is possible to recover from them](https://www.theguardian.com/lifeandstyle/2025/jun/16/better-life-trauma-healing)

[InteractAnything: Zero-shot Human Object-Interaction Synthesis via LLM Feedback and Object Affordance Parsing](https://jinluzhang.site/projects/interactanything/),
[arxiv](https://arxiv.org/abs/2505.24315)

[szgabsz91/jdk-ocamorph-pyphen](https://github.com/szgabsz91/jdk-ocamorph-pyphen)

[Sorbian course](https://sprachkurs.sorbischlernen.de/)

[Sorbian radio](https://www.rbb-online.de/radio/sorbisches_programm/beitragsarchiv-audiothek/sorbische-sendungen-nachhoeren-serbske-wuscelanja-sluchas.html)

[hunpars](http://mokk.bme.hu/resources/hunpars/)

[hunmorph](http://mokk.bme.hu/resources/hunmorph/)

[hunmorph-foma](https://github.com/r0ller/hunmorph-foma)

[Magyar népmesék sorozat](https://www.youtube.com/playlist?list=PLpshJy6oyjM9fD2YtXafkvuSCkkprffuO),
[Hungarian Folk Tales](https://www.youtube.com/@HungarianFolkTales/videos)

[Eupisco 2025](https://eusipco2025.org/)

[JoFrhwld/FAVE](https://github.com/JoFrhwld/FAVE)

[kornai/MoLHandbook](https://github.com/kornai/MoLHandbook)

[Universal Dependencies](https://direct.mit.edu/coli/article/47/2/255/98516/Universal-Dependencies)

[Finnish-NLP/wav2vec2-xlsr-300m-finnish-lm](https://huggingface.co/Finnish-NLP/wav2vec2-xlsr-300m-finnish-lm)

[CREPE](https://github.com/marl/crepe)

[allenai/Molmo-7B-D-0924](https://huggingface.co/allenai/Molmo-7B-D-0924)

[SpeD 2025](https://sped.pub.ro/)
- Conference: October 19-22, 2025
- Paper submission (5 – 6 pages, IEEE format): July 7, 2025
- [OpenReview](https://openreview.net/group?id=IEEE.org/SpeD/2025/Conference)
- [Overleaf](https://www.overleaf.com/gallery/tagged/ieee-official)
- 5-6 pages **including** references

[Audio Flamingo 2: An Audio-Language Model with Long-Audio Understanding and Expert Reasoning Abilities](https://arxiv.org/abs/2503.03983)

[Voicebox: Text-Guided Multilingual Universal Speech Generation at Scale](https://voicebox.metademolab.com/)

[huspacy/huspacy](https://github.com/huspacy/huspacy)

{% twitter https://x.com/DanKornas/status/1940451888165715978 %}

[kyutai/tts-1.6b-en_fr](https://huggingface.co/kyutai/tts-1.6b-en_fr),

{% twitter https://x.com/TivadarDanka/status/1940727246412795939 %}

[timtadh/zhang-shasha](https://github.com/timtadh/zhang-shasha) --- Tree edit distance using the Zhang Shasha algorithm

[The Unbelievable Truth](https://www.bennewsam.co.uk/TUTT.shtml)

[Tool - Back to the beginning](https://www.youtube.com/watch?v=M-NTrVJzQGI)

[The ParlaMint corpora of parliamentary proceedings](https://link.springer.com/article/10.1007/s10579-021-09574-0)

[Spoken Spanish PoS tagging: gold standard dataset](https://link.springer.com/article/10.1007/s10579-024-09751-x)

[ContextASR-Bench: A Massive Contextual Speech Recognition Benchmark](https://arxiv.org/abs/2507.05727),
[code](https://github.com/MrSupW/ContextASR-Bench),
[dataset](https://huggingface.co/datasets/MrSupW/ContextASR-Bench)

[Self-supervised learning of speech representations with Dutch archival data](https://arxiv.org/abs/2507.04554)

[hitachi-speech/EEND](https://github.com/hitachi-speech/EEND) --- EEND (End-to-End Neural Diarization) is a neural-network-based speaker diarization method.

[EEND-SS: Joint End-to-End Neural Speaker Diarization and Speech Separation for Flexible Number of Speakers](https://arxiv.org/abs/2203.17068)

