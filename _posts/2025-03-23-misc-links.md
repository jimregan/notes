---
toc: true
layout: post
hidden: true
description: Misc. interesting things.
title: Interesting links, 23/03/2025
categories: [links]
---

[The big idea: what do we really mean by free speech?](https://www.theguardian.com/world/2025/feb/24/the-big-idea-what-do-we-really-mean-by-free-speech)

[Speaker Change Detection for Transformer Transducer ASR](https://arxiv.org/abs/2302.08549)

Büszkeség és balítélet [Audio](https://mek.oszk.hu/06000/06058/mp3/index.html),
[card](https://mek.oszk.hu/06000/06058/cedula.html),
[Text](https://mek.oszk.hu/00300/00317/)

[Audiobooks in MP3](https://mek.oszk.hu/keresesek/keresesf.phtml?formatum=MP3)

[KnugiHK/WhatsApp-Chat-Exporter](https://github.com/KnugiHK/WhatsApp-Chat-Exporter)

[EliteAndroidApps/WhatsApp-Key-DB-Extractor](https://github.com/EliteAndroidApps/WhatsApp-Key-DB-Extractor)

[BBC Basic](https://www.bbcbasic.co.uk/bbcbasic.html)

[Finetuning for ESPNet OWSM Model](https://github.com/juice500ml/finetune_owsm)

[Liquid AI’s new STAR model architecture outshines Transformer efficiency](https://venturebeat.com/ai/liquid-ais-new-star-model-architecture-outshines-transformer-efficiency/),
[Automated Architecture Synthesis via Targeted Evolution](https://www.liquid.ai/research/automated-architecture-synthesis-via-targeted-evolution),
[arxiv](https://arxiv.org/abs/2411.17800)

ESPnet pull requests:
- [Classification Task and AudioSet-20K #5998](https://github.com/espnet/espnet/pull/5998)
- [add SASV support #5980](https://github.com/espnet/espnet/pull/5980)
- [Add RATS dataset for SV task](https://github.com/espnet/espnet/pull/5840)
- [Add SWBD text processing fix](https://github.com/espnet/espnet/pull/5941)

[The taste of IPA: Towards open-vocabulary keyword spotting and forced alignment in any language](https://aclanthology.org/2024.naacl-long.43/)

[Cold-start Active Learning through Self-supervised Language Modeling](https://aclanthology.org/2020.emnlp-main.637/)

[ModernBERT](https://huggingface.co/blog/modernbert)

[CMU Researchers Introduce TNNGen](https://www.marktechpost.com/2024/12/29/cmu-researchers-introduce-tnngen-an-ai-framework-that-automates-design-of-temporal-neural-networks-tnns-from-pytorch-software-models-to-post-layout-netlists/)

[Open sourcing h3i](https://blog.cloudflare.com/h3i/)

[How Neural Networks Learn: A Probabilistic Viewpoint](https://towardsdatascience.com/how-neural-networks-learn-a-probabilistic-viewpoint-0f6a78dc58e2/)

[FStarLang/karamel](https://github.com/FStarLang/karamel) --- KaRaMeL is a tool for extracting low-level F* programs to readable C code

[Single directional chamfer distance and non-absolute cosine similarity](https://github.com/facebookresearch/pytorch3d/commit/5ffeb4d580f5c7043ed1691e49d2d99f0f655bbc)

[Render DensePose](https://github.com/facebookresearch/pytorch3d/blob/main/docs/tutorials/render_densepose.ipynb) --- Needs SMPL (which is not open source)

[RVC-Boss/GPT-SoVITS](https://github.com/RVC-Boss/GPT-SoVITS) --- 1 min voice data can also be used to train a good TTS model! (few shot voice cloning)

[acids-ircam/ddsp_pytorch](https://github.com/acids-ircam/ddsp_pytorch) --- Implementation of Differentiable Digital Signal Processing (DDSP) in Pytorch

[DDSP-based Neural Waveform Synthesis of Polyphonic Guitar Performance from String-wise MIDI Input](https://arxiv.org/abs/2309.07658),
[code](https://github.com/erl-j/ddsp-guitar)

[jryban/frechet-music-distance](https://github.com/jryban/frechet-music-distance)

[Talking Turns: Benchmarking Audio Foundation Models on Turn-Taking Dynamics](https://arxiv.org/abs/2503.01174)

[huggingface/speech-to-speech](https://github.com/huggingface/speech-to-speech)

[mixup: Data-Dependent Data Augmentation](https://www.inference.vc/mixup-data-dependent-data-augmentation/)

[Gaussian Distributions are Soap Bubbles](https://www.inference.vc/high-dimensional-gaussian-distributions-are-soap-bubble/)

[Musings on Typicality](https://sander.ai/2020/09/01/typicality.html)

[nebius/kvax](https://github.com/nebius/kvax) --- A FlashAttention implementation for JAX with support for efficient document mask computation and context parallelism.

[DiffRhythm: Blazingly Fast and Embarrassingly Simple End-to-End Full-Length Song Generation with Latent Diffusion](https://aslp-lab.github.io/DiffRhythm.github.io/),
[code](https://github.com/ASLP-lab/DiffRhythm),
[arxiv](https://arxiv.org/abs/2503.01183)

[PeterGriffinJin/Search-R1](https://github.com/PeterGriffinJin/Search-R1) --- Search-R1: An Efficient, Scalable RL Training Framework for Reasoning & Search Engine Calling interleaved LLM based on veRL

[MatthewCYM/VoiceBench](https://github.com/MatthewCYM/VoiceBench) --- VoiceBench: Benchmarking LLM-Based Voice Assistants

[IDEA-Research/Grounded-SAM-2](https://github.com/IDEA-Research/Grounded-SAM-2) --- Grounded SAM 2: Ground and Track Anything in Videos with Grounding DINO, Florence-2 and SAM 2

{% twitter https://x.com/karpathy/status/1887211193099825254 %}

[Deep Dive into LLMs like ChatGPT](https://www.youtube.com/watch?v=7xTGNNLPyMI)

[Must-Watch Hungarian TV Series to Improve Your Hungarian](https://www.hungarianpod101.com/blog/2019/04/19/best-hungarian-tv-shows-to-improve-hungarian/)

[r/hungarian resources](https://www.reddit.com/r/hungarian/wiki/resources/)

[Speaking Hungarian S01](https://www.youtube.com/watch?v=IHeEi2Fj5Mw&list=PLU_vdD4vtCbs0587s3KpeJtISBZ-pMza_&index=1)

[ml-explore/mlx-lm](https://github.com/ml-explore/mlx-lm) --- Run LLMs with MLX

[MoshiVis — Teaching Moshi to Converse about Images](https://kyutai.org/moshivis)

[Announcing Pixtral 12B](https://mistral.ai/news/pixtral-12b)

[Moshi: a speech-text foundation model for real-time dialogue](https://arxiv.org/abs/2410.00037),
[code](https://github.com/kyutai-labs/moshi/)

[PyTorch internals](https://blog.ezyang.com/2019/05/pytorch-internals/)

[Inductive Moment Matching](https://arxiv.org/abs/2503.07565)

[mistralai/Mistral-Small-3.1-24B-Instruct-2503](https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503)

[Robust Audio-Visual Segmentation via Audio-Guided Visual Convergent Alignment](https://arxiv.org/abs/2503.12847)

[fasttransform: Reversible Pipelines Made Simple](https://www.fast.ai/posts/2025-02-20-fasttransform)

[nvidia/canary-1b-flash](https://huggingface.co/nvidia/canary-1b-flash) --- CC-BY

[Empowering innovation: The next generation of the Phi family](https://azure.microsoft.com/en-us/blog/empowering-innovation-the-next-generation-of-the-phi-family/),
[microsoft/Phi-4-multimodal-instruct](https://huggingface.co/microsoft/Phi-4-multimodal-instruct)

[Traveling Waves Integrate Spatial Information Through Time](https://kempnerinstitute.harvard.edu/research/deeper-learning/traveling-waves-integrate-spatial-information-through-time/)

[CLIP4Clip: An Empirical Study of CLIP for End to End Video Clip Retrieval](https://arxiv.org/abs/2104.08860),
[code](https://github.com/ArrowLuo/CLIP4Clip)

[yzhuoning/Awesome-CLIP](https://github.com/yzhuoning/Awesome-CLIP)

[UniSep: Universal Target Audio Separation with Language Models at Scale](https://arxiv.org/abs/2503.23762)

[Qieemo: Speech Is All You Need in the Emotion Recognition in Conversations](https://arxiv.org/abs/2503.22687)

[Scaling Rich Style-Prompted Text-to-Speech Datasets](https://arxiv.org/abs/2503.04713),
[code](https://github.com/ajd12342/paraspeechcaps) --- models and data not open.

[Dolphin: A Large-Scale Automatic Speech Recognition Model for Eastern Languages](https://arxiv.org/abs/2503.20212),
[code](https://github.com/DataoceanAI/Dolphin),
[small](https://huggingface.co/DataoceanAI/dolphin-small),
[base](https://huggingface.co/DataoceanAI/dolphin-base)

[NeMo - AED Decoding with N-Gram LM](https://github.com/NVIDIA/NeMo/commit/29be3b88ea708a87440204205dea71095ad68a15)

[Audio Compression using Periodic Gabor with Biorthogonal Exchange: Implementation Using the Zak Transform](https://arxiv.org/abs/2503.22703)

[AudioComposer: Towards Fine-grained Audio Generation with Natural Language Descriptions](https://arxiv.org/abs/2409.12560)

[FireRedTTS-1S: An Upgraded Streamable Foundation Text-to-Speech System](https://arxiv.org/abs/2503.20499),
[code](https://github.com/FireRedTeam/FireRedTTS)

[Enhance Generation Quality of Flow Matching V2A Model via Multi-Step CoT-Like Guidance and Combined Preference Optimization](https://arxiv.org/abs/2503.22200)

[RoboSpatial: Teaching Spatial Understanding to 2D and 3D Vision-Language Models for Robotics](https://arxiv.org/abs/2411.16537),
[dataset](https://huggingface.co/datasets/chanhee-luke/RoboSpatial-Home),
[eval code](https://github.com/chanhee-luke/RoboSpatial-Eval)

[OSWM CTC](https://github.com/espnet/espnet/blob/92f6cbce6167ba8c7591d323834a2342ed2cf2ce/espnet2/s2t/espnet_ctc_model.py#L20),
[OSWM CTC aligner](https://github.com/espnet/espnet/blob/92f6cbce6167ba8c7591d323834a2342ed2cf2ce/espnet2/bin/s2t_ctc_align.py#L4)

[e-branchformer encoder](https://github.com/espnet/espnet/blob/92f6cbce6167ba8c7591d323834a2342ed2cf2ce/espnet2/asr/encoder/e_branchformer_encoder.py)

[CTC-DRO: Robust Optimization for Reducing Language Disparities in Speech Recognition](https://arxiv.org/abs/2502.01777),
[code](https://github.com/Bartelds/ctc-dro),
[espnet code](https://github.com/Bartelds/espnet/tree/master/egs2/asr_dro/asr1)

[llava-hf/llava-v1.6-mistral-7b-hf](https://huggingface.co/llava-hf/llava-v1.6-mistral-7b-hf)

[01-ai/Yi-34B](https://huggingface.co/01-ai/Yi-34B)

[Prompt-based Alignment of Headlines and Images Using OpenCLIP](https://ceur-ws.org/Vol-3658/paper7.pdf),
[workshop](https://ceur-ws.org/Vol-3658/)

[Optimizing Visual Pairings: A CLIP Framework for Precision News Image Rematching](https://ceur-ws.org/Vol-3658/paper20.pdf),
[workshop](https://ceur-ws.org/Vol-3658/)

[rom1504/clip-retrieval](https://github.com/rom1504/clip-retrieval) --- Easily compute clip embeddings and build a clip retrieval system with them

[Wav2CLIP: Learning Robust Audio Representations From CLIP](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9747669),
[arXiv](https://arxiv.org/abs/2110.11499),
[code](https://github.com/descriptinc/lyrebird-Wav2CLIP),
[demo](https://replicate.com/hohsiangwu/wav2clip)

[Fine-tuned CLIP Models are Efficient Video Learners](https://arxiv.org/pdf/2212.03640),
[code](https://github.com/muzairkhattak/ViFi-CLIP)

[dmlc/decord](https://github.com/dmlc/decord) --- An efficient video loader for deep learning with smart shuffling that's super easy to digest

[ibm-granite/granite-speech-3.2-8b](https://huggingface.co/ibm-granite/granite-speech-3.2-8b),
based on [granite-3.1-8b-base](https://huggingface.co/ibm-granite/granite-3.1-8b-base)

[Qwen/Qwen2.5-Omni-7B](https://huggingface.co/Qwen/Qwen2.5-Omni-7B),
[code](https://github.com/QwenLM/Qwen2.5-Omni)

