---
toc: true
layout: post
hidden: true
description: Misc. interesting things.
title: Interesting links, 19/09/2025
categories: [links]
---

[A Visual Guide to Quantization](https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-quantization)

[NetEase-FuXi/EETQ](https://github.com/NetEase-FuXi/EETQ) --- Easy and Efficient Quantization for Transformers

[mmBERT: ModernBERT goes Multilingual](https://huggingface.co/blog/mmbert)

[jhu-clsp/mmBERT](https://github.com/jhu-clsp/mmBERT)
<!-- progressive addition of languages --- how does that work? -->

[Finetuning ByT5 for GED](https://www.kaggle.com/code/asibrahman/finetuning-byt5-for-ged)

[NeMo T5](https://docs.nvidia.com/nemo-framework/user-guide/latest/llms/t5.html#t5)

[spring-media/DeepPhonemizer](https://github.com/spring-media/DeepPhonemizer)

[honzas83/t5s](https://github.com/honzas83/t5s)

[PolyIPA -- Multilingual Phoneme-to-Grapheme Conversion Model](https://arxiv.org/abs/2412.09102)

[Mitigating the Exposure Bias in Sentence-Level Grapheme-to-Phoneme (G2P) Transduction](https://www.isca-archive.org/interspeech_2023/yoon23d_interspeech.html)

```bibtex
@inproceedings{yoon23d_interspeech,
  title     = {Mitigating the Exposure Bias in Sentence-Level {G}rapheme-to-{P}honeme ({G2P}) Transduction},
  author    = {Eunseop Yoon and Hee Suk Yoon and Dhananjaya Gowda and SooHwan Eom and Daehyeok Kim and John Harvill and Heting Gao and Mark Hasegawa-Johnson and Chanwoo Kim and Chang D. Yoo},
  year      = {2023},
  booktitle = {Interspeech 2023},
  pages     = {2028--2032},
  doi       = {10.21437/Interspeech.2023-2336},
  issn      = {2958-1796},
}
```

[T5G2P: Using Text-to-Text Transfer Transformer for Grapheme-to-Phoneme Conversion](https://www.isca-archive.org/interspeech_2021/rezackova21_interspeech.html)

```bibtex
@inproceedings{rezackova21_interspeech,
  title     = {T5G2P: Using Text-to-Text Transfer Transformer for Grapheme-to-Phoneme Conversion},
  author    = {Markéta Řezáčková and Jan Švec and Daniel Tihelka},
  year      = {2021},
  booktitle = {Interspeech 2021},
  pages     = {6--10},
  doi       = {10.21437/Interspeech.2021-546},
  issn      = {2958-1796},
}
```

[T5G2P: Text-to-Text Transfer Transformer Based Grapheme-to-Phoneme Conversion](https://ieeexplore.ieee.org/document/10592637)

```bibtex
@ARTICLE{10592637,
  author={Řezáčková, Markéta and Tihelka, Daniel and Matoušek, Jindřich},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 
  title={T5G2P: Text-to-Text Transfer Transformer Based Grapheme-to-Phoneme Conversion}, 
  year={2024},
  volume={32},
  number={},
  pages={3466-3476},
  doi={10.1109/TASLP.2024.3426332}
}
```

[NeMo Grapheme-to-Phoneme Models](https://docs.nvidia.com/nemo-framework/user-guide/latest/nemotoolkit/tts/g2p.html)

[NeMo G2P YAML](https://github.com/NVIDIA-NeMo/NeMo/blob/main/examples/tts/g2p/conf/g2p_t5.yaml)

[The Oxford-BBC Lip Reading Sentences 2](https://www.robots.ox.ac.uk/~vgg/data/lip_reading/lrs2.html)

[1adrianb/face-alignment](https://github.com/1adrianb/face-alignment) --- 2D and 3D Face alignment library build using pytorch

[MimicTalk: Mimicking a personalized and expressive 3D talking face in few minutes](https://openreview.net/forum?id=gjEzL0bamb),
[code](https://github.com/yerfor/MimicTalk)

[yerfor/Real3DPortrait](https://github.com/yerfor/Real3DPortrait)

[sprakradet/swedia_test_set](https://github.com/sprakradet/swedia_test_set)

[ByteDance-Seed/Seed-OSS-36B-Instruct](https://huggingface.co/ByteDance-Seed/Seed-OSS-36B-Instruct)

[Identity-Preserving Talking Face Generation with Landmark and Appearance Priors](https://www.computer.org/csdl/proceedings-article/cvpr/2023/012900j729/1POPw2eqT7y),
[code](https://github.com/Weizhi-Zhong/IP_LAP)

[OmniGen2: Exploration to Advanced Multimodal Generation](https://arxiv.org/abs/2506.18871),
[code](https://github.com/VectorSpaceLab/OmniGen2),
[model](https://huggingface.co/OmniGen2/OmniGen2)

[GrapheneOS](https://grapheneos.org/)

[Playing with binary formats](https://www.linux.it/~rubini/docs/binfmt/binfmt.html)

[Kyutai STT](https://kyutai.org/next/stt),
[kyutai/stt-1b-en_fr](https://huggingface.co/kyutai/stt-1b-en_fr),
[kyutai/tts-1.6b-en_fr](https://huggingface.co/kyutai/tts-1.6b-en_fr),
[code](https://github.com/kyutai-labs/delayed-streams-modeling/),
[kyutai/mimi](https://huggingface.co/kyutai/mimi)

[The State of Freedom Around the World in 2025](https://www.visualcapitalist.com/the-state-of-freedom-around-the-world-in-2025/)

[baidu/ERNIE-4.5-300B-A47B-Base-PT](https://huggingface.co/baidu/ERNIE-4.5-300B-A47B-Base-PT)

[Add recipe for Qwen2-Audio-7B-Chat on Dynamic-SUPERB ASR task #6194](https://github.com/espnet/espnet/pull/6194)

[Add Harvest algorithm as an option for F0 extraction #6083](https://github.com/espnet/espnet/pull/6083)

[Create a ESPnet bootcamp recipe for proyecto-nahuatl-asr #6066](https://github.com/espnet/espnet/pull/6066)

[Fine-tune an image model](https://replicate.com/docs/get-started/fine-tune-with-flux)

[TalkingGaussian: Structure-Persistent 3D Talking Head Synthesis via Gaussian Splatting](https://arxiv.org/abs/2404.15264)

[GeneFace: Generalized and High-Fidelity Audio-Driven 3D Talking Face Synthesis](https://arxiv.org/abs/2301.13430),
[code](https://github.com/yerfor/GeneFace)

[AD-NeRF: Audio Driven Neural Radiance Fields for Talking Head Synthesis](https://arxiv.org/abs/2103.11078),
[code](https://github.com/YudongGuo/AD-NeRF)

[yenchenlin/nerf-pytorch](https://github.com/yenchenlin/nerf-pytorch)

[XTXMarkets/ternfs](https://github.com/XTXMarkets/ternfs)

[Qwen3-Omni: Natively Omni-Modal Foundation Models!](https://qwen.ai/blog?id=65f766fc2dcba7905c1cb69cc4cab90e94126bf4&from=research.latest-advancements-list),
[code](https://github.com/QwenLM/Qwen3-Omni),
[collection](https://huggingface.co/collections/Qwen/qwen3-omni-68d100a86cd0906843ceccbe),
[Captioner](https://huggingface.co/Qwen/Qwen3-Omni-30B-A3B-Captioner),
[demo](https://huggingface.co/spaces/Qwen/Qwen3-Omni-Captioner-Demo)
