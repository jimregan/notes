---
toc: true
layout: post
hidden: true
description: Misc. interesting things.
title: Interesting links, 20/02/2024
categories: [links]
---

[LAVE: LLM-Powered Agent Assistance and Language Augmentation for Video Editing](https://arxiv.org/abs/2402.10294)

[karpathy/minbpe](https://github.com/karpathy/minbpe) --- Minimal, clean, code for the Byte Pair Encoding (BPE) algorithm commonly used in LLM tokenization.

[MAGVIT: Masked Generative Video Transformer](https://arxiv.org/abs/2212.05199),
[code](https://github.com/google-research/magvit)

[DiffiT: Diffusion Vision Transformers for Image Generation](https://arxiv.org/abs/2312.02139)

[A Novel Sampling Scheme for Text- and Image-Conditional Image Synthesis in Quantized Latent Spaces](https://arxiv.org/abs/2211.07292)

[How to Train Data-Efficient LLMs](https://arxiv.org/abs/2402.09668)

[Fine-tuning Large Language Models for Adaptive Machine Translation](https://arxiv.org/abs/2312.12740)

[Robust agents learn causal world models](https://arxiv.org/abs/2402.10877)

[Mamba: The Hard Way](https://srush.github.io/annotated-mamba/hard.html)

[open-mmlab/Amphion](https://github.com/open-mmlab/Amphion) --- Amphion (/æmˈfaɪən/) is a toolkit for Audio, Music, and Speech Generation. Its purpose is to support reproducible research and help junior researchers and engineers get started in the field of audio, music, and speech generation research and development.

[The effects of automatic speech recognition quality on human transcription latency](https://dl.acm.org/doi/10.1145/2899475.2899478) --- "We present results from 2 studies which indicate that starting with the ASR output is worse unless it is sufficiently accurate (Word Error Rate of under 30%)."

[Lexicographical data/Statistics/Counts of various things by language](https://www.wikidata.org/wiki/Wikidata:Lexicographical_data/Statistics/Counts_of_various_things_by_language)

[OLMo - Open Language Model](https://blog.allenai.org/olmo-open-language-model-87ccfc95f580)

[OpenAccess-AI-Collective/axolotl](https://github.com/OpenAccess-AI-Collective/axolotl) --- Go ahead and axolotl questions

[Listen, Think, and Understand](https://arxiv.org/abs/2305.10790)

[Neural Network Diffusion](https://arxiv.org/abs/2402.13144)

[mistralai/cookbook](https://github.com/mistralai/cookbook)

[OWSM-CTC: An Open Encoder-Only Speech Foundation Model for Speech Recognition, Translation, and Language Identification](https://arxiv.org/abs/2402.12654)

[Encoding of multi-modal emotional information via personalized skin-integrated wireless facial interface](https://www.nature.com/articles/s41467-023-44673-2)

[alterebro/IPA-Keyboard](https://github.com/alterebro/IPA-Keyboard)

[BBA: Bi-Modal Behavioral Alignment for Reasoning with Large Vision-Language Models](https://arxiv.org/abs/2402.13577)

[Exploring Speech Recognition, Translation, and Understanding with Discrete Speech Units: A Comparative Study](https://arxiv.org/abs/2309.15800)

[microsoft/torchscale](https://github.com/microsoft/torchscale) --- Foundation Architecture for (M)LLMs

[A Paradigm Shift in Machine Translation: Boosting Translation Performance of Large Language Models](https://arxiv.org/abs/2309.11674),
[code](https://github.com/fe1ixxu/ALMA)

[lucidrains/flamingo-pytorch](https://github.com/lucidrains/flamingo-pytorch)

