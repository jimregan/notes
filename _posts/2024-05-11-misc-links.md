---
toc: true
layout: post
hidden: true
description: Misc. interesting things.
title: Interesting links, 11/05/2024
categories: [links]
---

[word_prediction_criterion.py](https://github.com/pytorch/translate/blob/master/pytorch_translate/word_prediction/word_prediction_criterion.py)

[xbpeng/DeepMimic](https://github.com/xbpeng/DeepMimic) --- Motion imitation with deep reinforcement learning.

[facebookresearch/fairmotion](https://github.com/facebookresearch/fairmotion)

[facebookresearch/t2motion](https://github.com/facebookresearch/t2motion) --- open source, but needs SMPLH.

[ricsinaruto/gutenberg-dialog](https://github.com/ricsinaruto/gutenberg-dialog) --- Build a dialog dataset from online books in many languages

{% twitter https://twitter.com/electricalWSOP/status/1665265230673321984 %}

[Finetuning Whisper for dynamic audio context robustness](https://github.com/futo-org/whisper-acft)

[andrewgcodes/xlstm](https://github.com/andrewgcodes/xlstm) --- my attempts at implementing various bits of Sepp Hochreiter's new xLSTM architecture

[CMU Graphics Lab Motion Capture Database](http://mocap.cs.cmu.edu/)

[bulletphysics/bullet3](https://github.com/bulletphysics/bullet3) --- Bullet Physics SDK: real-time collision detection and multi-physics simulation for VR, games, visual effects, robotics, machine learning etc.

[ESB: A Benchmark For Multi-Domain End-to-End Speech Recognition](https://arxiv.org/abs/2210.13352)

[WhisperForCTC #26242](https://github.com/huggingface/transformers/issues/26242)

{% twitter https://twitter.com/Anthony_Bonato/status/1787499373712077233 %}

[BlinkDL/rwkv-4-world](https://huggingface.co/BlinkDL/rwkv-4-world)

{% twitter https://twitter.com/mbateman/status/1787160714827997471 %}

[Open Language Model: OLMo](https://allenai.org/olmo)

[haosulab/ManiSkill](https://github.com/haosulab/ManiSkill) --- SAPIEN Manipulation Skill Framework, a GPU parallelized robotics simulator and benchmark
(Code is open, assets are not)

[XFeat: Accelerated Features for Lightweight Image Matching](https://arxiv.org/abs/2404.19174),
[code](https://github.com/verlab/accelerated_features)

[TRAMBA: A Hybrid Transformer and Mamba Architecture for Practical Audio and Bone Conduction Speech Super Resolution and Enhancement on Mobile and Wearable Platforms](https://arxiv.org/abs/2405.01242)

[sato-team/Stable-Text-to-motion-Framework](https://github.com/sato-team/Stable-Text-to-motion-Framework)

[Generating Diverse and Natural 3D Human Motions from Text](https://openaccess.thecvf.com/content/CVPR2022/papers/Guo_Generating_Diverse_and_Natural_3D_Human_Motions_From_Text_CVPR_2022_paper.pdf),
[code](https://github.com/EricGuo5513/text-to-motion)

{% twitter https://twitter.com/borisdayma/status/1786158626496758056 %}

[Kerry King- Trophies of The Tyrant/ Chemical Warfare](https://www.youtube.com/watch?v=16ayjz7NoJQ)

[The evolution of Steve Albini: ‘If the dumbest person is on your side, you’re on the wrong side’](https://www.theguardian.com/music/2023/aug/15/the-evolution-of-steve-albini-if-the-dumbest-person-is-on-your-side-youre-on-the-wrong-side)

[muditbhargava66/PyxLSTM](https://github.com/muditbhargava66/PyxLSTM) --- PyxLSTM is a Python library that provides an efficient and extensible implementation of the Extended Long Short-Term Memory (xLSTM) architecture. xLSTM enhances the traditional LSTM by introducing exponential gating, memory mixing, and a matrix memory structure, enabling improved performance and scalability for sequence modeling tasks.

[cepstrum, quefrency, rahmonic](https://sesquiotic.com/2011/08/16/cepstrum-quefrency-rahmonic/)

[SpeechGuard: Exploring the Adversarial Robustness of Multimodal Large Language Models](https://arxiv.org/abs/2405.08317)

[Simple and Efficient Quantization Techniques for Neural Speech Coding](https://arxiv.org/abs/2405.08417)

[SpeechVerse: A Large-scale Generalizable Audio Language Model](https://arxiv.org/abs/2405.08295)

[A predictive learning model can simulate temporal dynamics and context effects found in neural representations of continuous speech](https://arxiv.org/abs/2405.08237)

[Learning the Meanings of Function Words From Grounded Language Using a Visual Question Answering Model](https://onlinelibrary.wiley.com/doi/10.1111/cogs.13448)

[Coin3D: Controllable and Interactive 3D Assets Generation with Proxy-Guided Conditioning](https://arxiv.org/abs/2405.08054)

[No Time to Waste: Squeeze Time into Channel for Mobile Video Understanding](https://arxiv.org/abs/2405.08344),
[code](https://github.com/mindspore-lab/models/tree/master/research/huawei-noah/SqueezeTime)

{% twitter https://twitter.com/lukas_m_ziegler/status/1790648380080722323 %}

[Naturalistic Music Decoding from EEG Data via Latent Diffusion Models](https://arxiv.org/abs/2405.09062)

[A vector quantized masked autoencoder for audiovisual speech emotion recognition](https://arxiv.org/abs/2305.03568)

{% twitter https://x.com/AkshGarg03/status/1790824537904554351 %}

{% twitter https://x.com/getnormality/status/1790942454688145484 %}

[Jan Kasprowicz - Krzak dzikiej róży w Ciemnych Smreczynach](https://www.youtube.com/watch?v=ozdDv1z1q24)

[polska-poezja.pl](https://polska-poezja.pl/)

[Evolutionary Optimization of Model Merging Recipes](https://arxiv.org/abs/2403.13187),
[code](https://github.com/SakanaAI/evolutionary-model-merge)

[Swedish Kelly list](https://spraakbanken.gu.se/en/resources/kelly)

[A Large-Scale Evaluation of Speech Foundation Models](https://arxiv.org/abs/2404.09385)

[Video ReCap: Recursive Captioning of Hour-Long Videos](https://arxiv.org/abs/2402.13250),
[code](https://github.com/md-mohaiminul/VideoRecap)

[Target Speech Extraction with Pre-trained Self-supervised Learning Models](https://arxiv.org/abs/2402.13199)

[Semi-Autoregressive Streaming ASR With Label Context](https://arxiv.org/abs/2309.10926)

[Towards audio language modeling -- an overview](https://arxiv.org/abs/2402.13236)

[Probing Self-supervised Learning Models with Target Speech Extraction](https://arxiv.org/abs/2402.13200)

[A multimodal dynamical variational autoencoder for audiovisual speech representation learning](https://arxiv.org/abs/2305.03582)

[On the Semantic Latent Space of Diffusion-Based Text-to-Speech Models](https://arxiv.org/abs/2402.12423)

[MINT: Boosting Audio-Language Model via Multi-Target Pre-Training and Instruction Tuning](https://arxiv.org/abs/2402.07485)

[Best Practices for Robot Death](https://www.kth.se/navet/calendar/best-practices-for-robot-death-1.1317985?date=2024-02-23&orgdate=2024-02-19&length=1&orglength=317)

[OWSM-CTC: An Open Encoder-Only Speech Foundation Model for Speech Recognition, Translation, and Language Identification](https://arxiv.org/abs/2402.12654)

[MINT: Boosting Audio-Language Model via Multi-Target Pre-Training and Instruction Tuning](https://arxiv.org/abs/2402.07485)

[Understanding, Using, and Finetuning Gemma](https://lightning.ai/lightning-ai/studios/understanding-using-and-finetuning-gemma)

[Blind estimation of audio effects using an auto-encoder approach and differentiable digital signal processing](https://arxiv.org/abs/2310.11781)

[Sigmoid Loss for Language Image Pre-Training](https://arxiv.org/abs/2303.15343),
[code](https://github.com/google-research/big_vision)

[ChatGPT suspends Scarlett Johansson-like voice as actor speaks out against OpenAI](https://www.theguardian.com/technology/article/2024/may/20/chatgpt-scarlett-johansson-voice)

[CLIP as RNN: Segment Countless Visual Concepts without Training Endeavor](https://arxiv.org/abs/2312.07661),
[code](https://github.com/google-research/google-research/tree/master/clip_as_rnn)

[From Motor Control to Team Play in Simulated Humanoid Football](https://arxiv.org/abs/2105.12196)

[Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing](https://arxiv.org/abs/2309.15826)

[Cross-modal Contrastive Learning for Speech Translation](https://aclanthology.org/2022.naacl-main.376/),
[code](https://github.com/ReneeYe/ConST)

[nateraw/hf-hub-lightning](https://github.com/nateraw/hf-hub-lightning) --- A PyTorch Lightning Callback for pushing models to the Hugging Face Hub

[Learning Transformer Programs](https://arxiv.org/abs/2306.01128)

[Images that Sound: Composing Images and Sounds on a Single Canvas](https://arxiv.org/abs/2405.12221),
[code](https://github.com/IFICL/images-that-sound),
(model is not open).

{% twitter https://x.com/Dexerto/status/1793899911852798319 %)

[ReVideo: Remake a Video with Motion and Content Control](https://arxiv.org/abs/2405.13865)

{% twitter https://x.com/jasonfried/status/1793780149231726670 %}

{% twitter https://x.com/0xgaut/status/1794019623324590475 %}

[2BP: 2-Stage Backpropagation](https://arxiv.org/abs/2405.18047)

[An Introduction to Vision-Language Modeling](https://arxiv.org/abs/2405.17247)

[Your Classifier is Secretly an Energy Based Model and You Should Treat it Like One](https://arxiv.org/abs/1912.03263),
[code](https://github.com/wgrathwohl/JEM)

[MyoHub/myoconverter](https://github.com/MyoHub/myoconverter) --- A tool to convert opensim 4.0+ MSK models into MuJoCo format with optimized muscle kinematics and kinetics

[MoCapAct: A Multi-Task Dataset for Simulated Humanoid Control](https://arxiv.org/abs/2208.07363),
[code](https://github.com/microsoft/MoCapAct)

[From motor control to team play in simulated humanoid football](https://www.science.org/doi/10.1126/scirobotics.abo0235)

[langchain-ai/langchain](https://github.com/langchain-ai/langchain)

[Multi-Modal Data Augmentation for End-to-End ASR](https://arxiv.org/abs/1803.10299)

{% twitter https://x.com/Dorialexander/status/1780959636306481476 %}

[PleIAs/YouTube-Commons](https://huggingface.co/datasets/PleIAs/YouTube-Commons)

(Dataset is noisy, no attempt made to determine if transcript in original
language in any way matches speech --- or if there even is speech --- and
often original transcript is omitted in favour of a translation).

[Self-Rewarding Language Models](https://arxiv.org/abs/2401.10020)

[Learning Disentangled Speech Representations with Contrastive Learning and Time-Invariant Retrieval](https://arxiv.org/abs/2401.08096)

[Revisiting Self-supervised Learning of Speech Representation from a Mutual Information Perspective](https://arxiv.org/abs/2401.08833)

[Phonemes based detection of parkinson’s disease for telehealth applications](https://www.nature.com/articles/s41598-022-13865-z)

[JaColBERT and Hard Negatives, Towards Better Japanese-First Embeddings for Retrieval: Early Technical Report](https://arxiv.org/abs/2312.16144),
[model](https://huggingface.co/bclavie/JaColBERT)

[colbert-ir/colbertv2.0](https://huggingface.co/colbert-ir/colbertv2.0)

> ColBERT relies on fine-grained contextual late interaction: it encodes each passage into a matrix of token-level embeddings (shown above in blue). Then at search time, it embeds every query into another matrix (shown in green) and efficiently finds passages that contextually match the query using scalable vector-similarity (MaxSim) operators.

[From Coarse to Fine: Efficient Training for Audio Spectrogram Transformers](https://arxiv.org/abs/2401.08415)

[The seven sins of memory: Insights from psychology and cognitive neuroscience](https://psycnet.apa.org/record/1999-10334-002)

[mcdermottLab/pycochleagram](https://github.com/mcdermottLab/pycochleagram) --- Generate cochleagrams natively in Python. Ported from Josh McDermott's MATLAB code.

[Codifying the Debates of the Riksdag:
Towards a Framework for Semi-automatic Annotation of
Swedish Parliamentary Discourse](https://ceur-ws.org/Vol-3133/paper12.pdf)

[RefFusion: Reference Adapted Diffusion Models for 3D Scene Inpainting](https://reffusion.github.io/),
[paper](https://arxiv.org/abs/2404.10765)

[jaywalnut310/vits](https://github.com/jaywalnut310/vits)

[Dutch people](https://flickr.com/photos/jimregan/52219137308/)

[SummaryMixing: A Linear-Complexity Alternative to Self-Attention for Speech Recognition and Understanding](https://arxiv.org/abs/2307.07421)

[General-purpose, long-context autoregressive modeling with Perceiver AR](https://arxiv.org/abs/2202.07765),
[code](https://github.com/google-research/perceiver-ar)

[Uneasy on the Ear: An Interview with Lola De La Mata](https://thequietus.com/interviews/lola-de-la-mata-oceans-on-azimuth-tinnitus-interview/),
[Left Ear](https://www.youtube.com/watch?v=4SaHIYxpqc0),
[Right Ear](https://www.youtube.com/watch?v=c59-6B37jho)

{% twitter https://x.com/thomasahle/status/1798408687981297844 %}

[4D ASR: Joint Beam Search Integrating CTC, Attention, Transducer, and Mask Predict Decoders](https://arxiv.org/abs/2406.02950)

[Audio Mamba: Bidirectional State Space Model for Audio Representation Learning](https://arxiv.org/abs/2406.03344)
<!-- [code](https://github.com/mhamzaerol/Audio-Mamba-AuM) -->

[dgreenheck/tree-js](https://github.com/dgreenheck/tree-js) --- Procedural tree generator written with JavaScript and Three.js

[xenova/transformers.js](https://github.com/xenova/transformers.js)

[TextureDreamer: Image-guided Texture Synthesis through Geometry-aware Diffusion](https://arxiv.org/abs/2401.09416)

[Self-Imagine: Effective Unimodal Reasoning with Multimodal Models using Self-Imagination](https://arxiv.org/abs/2401.08025)

[MarcusLoppe/meshgpt-pytorch](https://github.com/MarcusLoppe/meshgpt-pytorch),
[model](https://huggingface.co/MarcusLoren/MeshGPT-preview) --- based on [lucidrains/meshgpt-pytorch](https://github.com/lucidrains/meshgpt-pytorch)

[SemiVL: Semi-Supervised Semantic Segmentation with Vision-Language Guidance](https://arxiv.org/abs/2311.16241),
[code](https://github.com/google-research/semivl)

[Scaling Spherical CNNs](https://arxiv.org/abs/2306.05420),
[code](https://github.com/google-research/spherical-cnn)

[Language Table](https://github.com/google-research/language-table) --- Suite of human-collected datasets and a multi-task continuous control benchmark for open vocabulary visuolinguomotor learning.

[Triplane Meets Gaussian Splatting: Fast and Generalizable Single-View 3D Reconstruction with Transformers](https://arxiv.org/abs/2312.09147),
[code](https://github.com/VAST-AI-Research/TriplaneGaussian)
(depends on `diff-gaussian-rasterization` which is not open source)

[Voice in Parkinson's Disease: A Machine Learning Study](https://www.frontiersin.org/journals/neurology/articles/10.3389/fneur.2022.831428/full)

[Parkinson's Disease Detection Based on Running Speech Data From Phone Calls](https://pubmed.ncbi.nlm.nih.gov/34596531/)

[lucidrains/BS-RoFormer](https://github.com/lucidrains/BS-RoFormer) --- Implementation of Band Split Roformer, SOTA Attention network for music source separation out of ByteDance AI Labs

[Samba: Simple Hybrid State Space Models for Efficient Unlimited Context Language Modeling](https://arxiv.org/abs/2406.07522),
[code](https://github.com/microsoft/Samba)

[LibriTTS-P: A Corpus with Speaking Style and Speaker Identity Prompts for Text-to-Speech and Style Captioning](https://arxiv.org/abs/2406.07969),
[data](https://github.com/line/LibriTTS-P)

[ECAPA2: A Hybrid Neural Network Architecture and Training Strategy for Robust Speaker Embeddings](https://arxiv.org/abs/2401.08342)

[Triplane Meets Gaussian Splatting: Fast and Generalizable Single-View 3D Reconstruction with Transformers](https://arxiv.org/abs/2312.09147),
[code](https://github.com/VAST-AI-Research/TriplaneGaussian)

[Ouroboros3D: Image-to-3D Generation via 3D-aware Recursive Diffusion](https://arxiv.org/abs/2406.03184),
<!-- [code](https://github.com/Costwen/Ouroboros3D) -->

[ReLU-KAN: New Kolmogorov-Arnold Networks that Only Need Matrix Addition, Dot Multiplication, and ReLU](https://arxiv.org/abs/2406.02075)

[Audio Mamba: Bidirectional State Space Model for Audio Representation Learning](https://arxiv.org/abs/2406.03344)

[hokema/Pop2Talk](https://github.com/hokema/Pop2Talk) --- Pop2Talk foreign language prounnciation learning game. Code for the unity client app.

[kyegomez/VisionMamba](https://github.com/kyegomez/VisionMamba) --- Implementation of Vision Mamba from the paper: "Vision Mamba: Efficient Visual Representation Learning with Bidirectional State Space Model" It's 2.8x faster than DeiT and saves 86.8% GPU memory when performing batch inference to extract features on high-res images

{% twitter https://x.com/itsandrewgao/status/1798389860711166130 %}

{% twitter https://x.com/peterjliu/status/1798430625315295290 %}

[The maze is in the mouse](https://pravse.medium.com/the-maze-is-in-the-mouse-980c57cfd61a)

[lucidrains/soundstorm-pytorch](https://github.com/lucidrains/soundstorm-pytorch) --- Implementation of SoundStorm, Efficient Parallel Audio Generation from Google Deepmind, in Pytorch

[lucidrains/mogrifier](https://github.com/lucidrains/mogrifier) --- Usable implementation of Mogrifier, a circuit for enhancing LSTMs and potentially other networks, from Deepmind

[ina-foss/inaSpeechSegmenter](https://github.com/ina-foss/inaSpeechSegmenter) --- CNN-based audio segmentation toolkit. Allows to detect speech, music, noise and speaker gender. Has been designed for large scale gender equality studies based on speech time per gender.

[mHuBERT-147: A Compact Multilingual HuBERT Model](https://arxiv.org/abs/2406.06371),
[fairseq fork](https://github.com/utter-project/fairseq),
[pre-processing scripts](https://github.com/utter-project/mHuBERT-147-scripts/)

