---
toc: true
layout: post
hidden: true
description: Misc. interesting things.
title: Interesting links, 22/01/2025
categories: [links]
---

[UI-TARS: Pioneering Automated GUI Interaction with Native Agents](https://arxiv.org/abs/2501.12326),
[no code yet](https://github.com/bytedance/UI-TARS),
[desktop app](https://github.com/bytedance/UI-TARS-desktop),
[model](https://huggingface.co/bytedance-research/UI-TARS-72B-DPO)

[Swedish terms with IPA pronunciation](https://en.wiktionary.org/wiki/Category:Swedish_terms_with_IPA_pronunciation)

[Combiner: full attention transformer with sparse computation cost](https://dl.acm.org/doi/10.5555/3540261.3541982),
[pdf](https://proceedings.neurips.cc/paper/2021/file/bd4a6d0563e0604510989eb8f9ff71f5-Paper.pdf)

[OuteAI/OuteTTS-0.3-500M](https://huggingface.co/OuteAI/OuteTTS-0.3-500M),
[code](https://github.com/edwko/OuteTTS)
(1B model is not open)

[An Sgéaluidhe Gaedhealach](https://librivox.org/an-sgealuidhe-gaedhealach-by-douglas-hyde/)

[Diffusion Models and Their Applications](https://mhsung.github.io/kaist-cs492d-fall-2024/)

[HidekiKawahara/SparkNG](https://github.com/HidekiKawahara/SparkNG) --- MATLAB real-time/interactive speech tools. This series is obsolete. SP3ARK is the up-to-date series (will be).

[VocalTractLab](https://www.vocaltractlab.de/index.php?page=vocaltractlab-download)

Hakarps kyrka: [audio](https://commons.wikimedia.org/wiki/File:Hakarps_kyrka.ogg),
[revision](https://sv.wikipedia.org/w/index.php?title=Hakarps_kyrka&diff=prev&oldid=14712739) ?

[RandNet-Parareal: a time-parallel PDE solver using Random Neural Networks](https://nips.cc/virtual/2024/poster/96326),
[OpenReview](https://openreview.net/forum?id=974ojuN0jU),
[code](https://github.com/Parallel-in-Time-Differential-Equations/RandNet-Parareal)

[SEL-BALD: Deep Bayesian Active Learning for Selective Labeling with Instance Rejection](https://nips.cc/virtual/2024/poster/93351),
[OpenReview](https://openreview.net/forum?id=tDMTwto6jv)

[Theoretical Foundations of Deep Selective State-Space Models](https://nips.cc/virtual/2024/poster/96743),
[OpenReview](https://openreview.net/forum?id=3SzrqwupUx)

[Task-recency bias strikes back: Adapting covariances in Exemplar-Free Class Incremental Learning](https://nips.cc/virtual/2024/poster/96596),
[OpenReview](https://openreview.net/forum?id=5H4l37IsZ8)
<!-- not open source: https://github.com/grypesc/AdaGauss -->

Related:
[Class-Incremental Learning: Survey and Performance Evaluation on Image Classification](https://ieeexplore.ieee.org/abstract/document/9915459),
[code](https://github.com/mmasana/FACIL)

[What if English actually SOUNDED like this??](https://www.youtube.com/watch?v=4IfbPQgec2M)

[rviz](https://github.com/ros-visualization/rviz) --- ROS 3D Robot Visualizer

[parler-tts](https://huggingface.co/parler-tts),
[code](https://github.com/huggingface/parler-tts),
[parler_tts_mini_v0.1](https://huggingface.co/parler-tts/parler_tts_mini_v0.1),

[HCI-LAB-UGSPEECHDATA/speech_data_ghana_ug](https://github.com/HCI-LAB-UGSPEECHDATA/speech_data_ghana_ug) --- The dataset comprises of 5000 hours speech corpus in Akan, Ewe, Dagbani, Daagare, and Ikposo. Each language includes 1000 hours of audio speech from indigenous speakers of the language and 100 hours of transcription.

[001 - Hungarian short narrative A0](https://www.youtube.com/watch?app=desktop&v=G3jdyzSmNNA&list=PLlUFqz3WqFzr56S7ejSuUNfSyS08d2KSJ&index=1)

[microsoft/GW-BASIC](https://github.com/microsoft/GW-BASIC) --- The original source code of Microsoft GW-BASIC from 1983

[microsoft/MS-DOS](https://github.com/microsoft/MS-DOS) --- The original sources of MS-DOS 1.25, 2.0, and 4.0 for reference purposes

[Standard-Intelligence/hertz-dev](https://github.com/Standard-Intelligence/hertz-dev) --- first base model for full-duplex conversational audio

[wav2gloss/fieldwork](https://huggingface.co/datasets/wav2gloss/fieldwork) --- Mostly open, but includes closed data

[juice500ml/finetune_owsm](https://github.com/juice500ml/finetune_owsm)

[vllm-project/vllm](https://github.com/vllm-project/vllm) --- A high-throughput and memory-efficient inference and serving engine for LLMs

[espnet - Phoneme Recognition with IPAPack](https://github.com/espnet/espnet/pull/5966)

[Active Learning with Task Adaptation Pre-training for Speech Emotion Recognition](https://arxiv.org/abs/2405.00307)

[SemantiCodec: An Ultra Low Bitrate Semantic Audio Codec for General Sound](https://arxiv.org/abs/2405.00233),
[inference code](https://github.com/haoheliu/SemantiCodec-inference)

[How the RWKV language model works](https://johanwind.github.io/2023/03/23/rwkv_details.html),
[RWKV_in_150_lines.py](https://github.com/BlinkDL/ChatRWKV/blob/main/RWKV_in_150_lines.py)

[clee704/audiodiff](https://github.com/clee704/audiodiff) --- A commandline tool that compares two audio files and prints the difference

[PyGyat](https://pygyat.vercel.app/docs),
[code](https://github.com/shamith09/pygyat)

[torch.compile, the missing manual](https://docs.google.com/document/u/0/d/1y5CRfMLdwEoF1nTk9q8qEu1mgMUuUtvhklPKJ2emLU8/mobilebasic)

[Ways to use torch.compile](http://blog.ezyang.com/2024/11/ways-to-use-torch-compile/)

[FaceFormer: Speech-Driven 3D Facial Animation with Transformers](https://arxiv.org/abs/2112.05329),
[code](https://github.com/EvelynFan/FaceFormer) --- Depends on Max Planck stuff, so probably not useable.

[ACE: All-round Creator and Editor Following Instructions via Diffusion Transformer](https://arxiv.org/abs/2410.00086),
[model](https://huggingface.co/scepter-studio/ACE-0.6B-512px),
[code](https://github.com/ali-vilab/ACE)

[modelscope/scepter](https://github.com/modelscope/scepter) --- SCEPTER is an open-source framework used for training, fine-tuning, and inference with generative models.

[TTS-Transducer: End-to-End Speech Synthesis with Neural Transducer](https://arxiv.org/abs/2501.06320)

[rusq/slackdump](https://github.com/rusq/slackdump)

[black-forest-labs/flux](https://github.com/black-forest-labs/flux) --- Official inference repo for FLUX.1 models.
[open model](https://huggingface.co/black-forest-labs/FLUX.1-schnell)

[Investigation of Whisper ASR Hallucinations Induced by Non-Speech Audio](https://arxiv.org/abs/2501.11378),
[data](https://github.com/DSP-AGH/ICASSP2025_Whisper_Hallucination)

[deepseek-r1-webgpu](https://huggingface.co/spaces/webml-community/deepseek-r1-webgpu)

[allenai/OLMo](https://github.com/allenai/OLMo) --- Modeling, training, eval, and inference code for OLMo

[m-a-p/Code-Feedback](https://huggingface.co/datasets/m-a-p/Code-Feedback) --- OpenCodeInterpreter is a family of open-source code generation systems designed to bridge the gap between large language models and advanced proprietary systems like the GPT-4 Code Interpreter. It significantly advances code generation capabilities by integrating execution and iterative refinement functionalities.

[persian-tts-dataset-male](https://www.kaggle.com/datasets/magnoliasis/persian-tts-dataset-male),
[persian-tts-dataset-famale](https://www.kaggle.com/datasets/magnoliasis/persian-tts-dataset-famale)

[DiM-Gesture: Co-Speech Gesture Generation with Adaptive Layer Normalization Mamba-2 framework](https://arxiv.org/abs/2408.00370)

[Dynamic Time Warping Notebook](https://github.com/kamperh/lecture_dtw_notebook)

[kamperh/speech_dtw](https://github.com/kamperh/speech_dtw)

[You Only Cache Once: Decoder-Decoder Architectures for Language Models](https://arxiv.org/abs/2405.05254),
[code](https://github.com/microsoft/unilm/tree/master/YOCO)

[hitz-zentroa/latxa](https://github.com/hitz-zentroa/latxa) --- Latxa: An Open Language Model and Evaluation Suite for Basque

[kamperh/VectorQuantizedCPC](https://github.com/kamperh/VectorQuantizedCPC)

[Looking Backward: Streaming Video-to-Video Translation with Feature Banks](https://arxiv.org/abs/2405.15757)

[A light-weight and efficient punctuation and word casing prediction model for on-device streaming ASR](https://arxiv.org/abs/2407.13142),
[code](https://github.com/frankyoujian/Edge-Punct-Casing)

[Büszkeség és balítélet](https://mek.oszk.hu/06000/06058/)

[EvaByte/EvaByte](https://huggingface.co/EvaByte/EvaByte) --- EvaByte is a 6.5B byte-level language model built upon an improved architecture with multibyte prediction and EVA -- an efficient attention mechanism designed for scalability and performance.

[HKUNLP/efficient-attention](https://github.com/HKUNLP/efficient-attention) --- [EVA ICLR'23; LARA ICML'22] Efficient attention mechanisms via control variates, random features, and importance sampling

[Probing the 3D Awareness of Visual Foundation Models](https://arxiv.org/abs/2404.08636),
[mbanani/probe3d](https://github.com/mbanani/probe3d)

[OpenScene: 3D Scene Understanding with Open Vocabularies](https://arxiv.org/abs/2211.15654),
[code](https://github.com/pengsongyou/openscene)

[Lexicon3D: Probing Visual Foundation Models for Complex 3D Scene Understanding](https://nips.cc/virtual/2024/poster/96742),
[OpenReview](https://openreview.net/forum?id=3TxyhBZHT2),
[code](https://github.com/YunzeMan/Lexicon3D)

[Gaussian Graph Network: Learning Efficient and Generalizable Gaussian Representations from Multi-view Images](https://nips.cc/virtual/2024/poster/96803),
[OpenReview](https://openreview.net/forum?id=2dfBpyqh0A)

[PAConv: Position Adaptive Convolution with Dynamic Kernel Assembling on Point Clouds](https://arxiv.org/abs/2103.14635),
[code](https://github.com/CVMI-Lab/PAConv)

[OFA: Unifying Architectures, Tasks, and Modalities Through a Simple Sequence-to-Sequence Learning Framework](https://arxiv.org/abs/2202.03052),
[code](https://github.com/OFA-Sys/OFA)

[Meta Audiobox Aesthetics: Unified Automatic Quality Assessment for Speech, Music, and Sound](https://ai.meta.com/research/publications/meta-audiobox-aesthetics-unified-automatic-quality-assessment-for-speech-music-and-sound/),
[code](https://github.com/facebookresearch/audiobox-aesthetics) (CC-BY)

[CTC Networks and Language Models: Prefix Beam Search Explained](https://medium.com/corti-ai/ctc-networks-and-language-models-prefix-beam-search-explained-c11d1ee23306)

[A Study on Effects of Implicit and Explicit Language Model Information for DBLSTM-CTC Based Handwriting Recognition](https://arxiv.org/abs/2008.01532)

[Pronunciation modeling for speech technology](https://ieeexplore.ieee.org/abstract/document/1458347)

[A Study on Effects of Implicit and Explicit Language Model Information for DBLSTM-CTC Based Handwriting Recognition](https://arxiv.org/abs/2008.01532)

[D-LUCEA: Curation of the UCU Accent Project Data](https://www.ubiquitypress.com/site/chapters/e/10.5334/bbi.15/)
```bibtex
@inbook{orr2017dlucea,
author = {Orr, Rosemary and Quené, Hugo},
year = {2017},
month = {12},
pages = {181-193},
booktitle = {CLARIN in the Low Countries},
editor    = {Odijk, Jan and van~Hessen, Arjan},
publisher = {Ubiquity Press},
address   = {London},
title = {D-LUCEA: Curation of the UCU Accent Project data},
doi = {10.5334/bbi.15}
}
```

[rhasspy/sv_kaldi-rhasspy](https://github.com/rhasspy/sv_kaldi-rhasspy)

[Recent Advances in Discrete Speech Tokens: A Review](https://arxiv.org/abs/2502.06490)

[AbrahamSanders/codec-bpe](https://github.com/AbrahamSanders/codec-bpe) --- Implementation of Acoustic BPE (Shen et al., 2024), extended for RVQ-based Neural Audio Codecs

[Undergraduate Upends a 40-Year-Old Data Science Conjecture](https://www.quantamagazine.org/undergraduate-upends-a-40-year-old-data-science-conjecture-20250210/)

[https://www.wikidata.org/w/index.php?title=Special:WhatLinksHere/Q56216056&limit=50&offset=120%7C110214728&dir=next](Pages that link to "Q56216056") --- Wikidata property to identify lexicographical entities (Q56216056)

[implemente batch decode for owsm-ctc](https://github.com/espnet/espnet/commit/95dcc722b7c23dad2a7c980b9c3f8e7a453994bf)

[Some of My Best Friends Are Linguists](https://www.jstor.org/stable/30200539?seq=1)

[Generative AI and the Automating of Academia](https://link.springer.com/article/10.1007/s42438-023-00440-6)

[VoxCommunis: A Corpus for Cross-linguistic Phonetic Analysis](https://aclanthology.org/2022.lrec-1.566/)

[Step-Video-T2V Technical Report: The Practice, Challenges, and Future of Video Foundation Model](https://arxiv.org/abs/2502.10248),
[model](https://huggingface.co/stepfun-ai/stepvideo-t2v)

[Turn your Jupyter Notebook into interactive Presentation Slides using Anaconda](https://digitalhumanities.hkust.edu.hk/tutorials/turn-your-jupyter-notebook-into-interactive-presentation-slides-using-anaconda/)

[Introduction to Linear Prediction](https://www.youtube.com/watch?v=InVbYsX7Qjk)

[The taste of IPA: Towards open-vocabulary keyword spotting and forced alignment in any language](https://arxiv.org/abs/2311.08323),
[code](https://github.com/lingjzhu/clap-ipa)

[Digital Archive of Pictures](https://www.keptar.oszk.hu/indexeng.phtml)

[FoQA: A Faroese Question-Answering Dataset](https://arxiv.org/abs/2502.07642),
[code](https://github.com/alexandrainst/foqa)

[Self-Supervised Contrastive Learning for Unsupervised Phoneme Segmentation](https://arxiv.org/abs/2007.13465),
[code](https://github.com/felixkreuk/UnsupSeg)

[LiteASR: Efficient Automatic Speech Recognition with Low-Rank Approximation](https://arxiv.org/abs/2502.20583),
[code](https://github.com/efeslab/LiteASR)

