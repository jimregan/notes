---
toc: true
layout: post
hidden: true
description: Misc. interesting things.
title: Interesting links, 22/01/2025
categories: [links]
---

[UI-TARS: Pioneering Automated GUI Interaction with Native Agents](https://arxiv.org/abs/2501.12326),
[no code yet](https://github.com/bytedance/UI-TARS),
[desktop app](https://github.com/bytedance/UI-TARS-desktop),
[model](https://huggingface.co/bytedance-research/UI-TARS-72B-DPO)

[Swedish terms with IPA pronunciation](https://en.wiktionary.org/wiki/Category:Swedish_terms_with_IPA_pronunciation)

[Combiner: full attention transformer with sparse computation cost](https://dl.acm.org/doi/10.5555/3540261.3541982),
[pdf](https://proceedings.neurips.cc/paper/2021/file/bd4a6d0563e0604510989eb8f9ff71f5-Paper.pdf)

[OuteAI/OuteTTS-0.3-500M](https://huggingface.co/OuteAI/OuteTTS-0.3-500M),
[code](https://github.com/edwko/OuteTTS)
(1B model is not open)

[An Sgéaluidhe Gaedhealach](https://librivox.org/an-sgealuidhe-gaedhealach-by-douglas-hyde/)

[Diffusion Models and Their Applications](https://mhsung.github.io/kaist-cs492d-fall-2024/)

[HidekiKawahara/SparkNG](https://github.com/HidekiKawahara/SparkNG) --- MATLAB real-time/interactive speech tools. This series is obsolete. SP3ARK is the up-to-date series (will be).

[VocalTractLab](https://www.vocaltractlab.de/index.php?page=vocaltractlab-download)

Hakarps kyrka: [audio](https://commons.wikimedia.org/wiki/File:Hakarps_kyrka.ogg),
[revision](https://sv.wikipedia.org/w/index.php?title=Hakarps_kyrka&diff=prev&oldid=14712739) ?

[RandNet-Parareal: a time-parallel PDE solver using Random Neural Networks](https://nips.cc/virtual/2024/poster/96326),
[OpenReview](https://openreview.net/forum?id=974ojuN0jU),
[code](https://github.com/Parallel-in-Time-Differential-Equations/RandNet-Parareal)

[SEL-BALD: Deep Bayesian Active Learning for Selective Labeling with Instance Rejection](https://nips.cc/virtual/2024/poster/93351),
[OpenReview](https://openreview.net/forum?id=tDMTwto6jv)

[Theoretical Foundations of Deep Selective State-Space Models](https://nips.cc/virtual/2024/poster/96743),
[OpenReview](https://openreview.net/forum?id=3SzrqwupUx)

[Task-recency bias strikes back: Adapting covariances in Exemplar-Free Class Incremental Learning](https://nips.cc/virtual/2024/poster/96596),
[OpenReview](https://openreview.net/forum?id=5H4l37IsZ8)
<!-- not open source: https://github.com/grypesc/AdaGauss -->

Related:
[Class-Incremental Learning: Survey and Performance Evaluation on Image Classification](https://ieeexplore.ieee.org/abstract/document/9915459),
[code](https://github.com/mmasana/FACIL)

[What if English actually SOUNDED like this??](https://www.youtube.com/watch?v=4IfbPQgec2M)

[rviz](https://github.com/ros-visualization/rviz) --- ROS 3D Robot Visualizer

[parler-tts](https://huggingface.co/parler-tts),
[code](https://github.com/huggingface/parler-tts),
[parler_tts_mini_v0.1](https://huggingface.co/parler-tts/parler_tts_mini_v0.1),

[HCI-LAB-UGSPEECHDATA/speech_data_ghana_ug](https://github.com/HCI-LAB-UGSPEECHDATA/speech_data_ghana_ug) --- The dataset comprises of 5000 hours speech corpus in Akan, Ewe, Dagbani, Daagare, and Ikposo. Each language includes 1000 hours of audio speech from indigenous speakers of the language and 100 hours of transcription.

[001 - Hungarian short narrative A0](https://www.youtube.com/watch?app=desktop&v=G3jdyzSmNNA&list=PLlUFqz3WqFzr56S7ejSuUNfSyS08d2KSJ&index=1)

[microsoft/GW-BASIC](https://github.com/microsoft/GW-BASIC) --- The original source code of Microsoft GW-BASIC from 1983

[microsoft/MS-DOS](https://github.com/microsoft/MS-DOS) --- The original sources of MS-DOS 1.25, 2.0, and 4.0 for reference purposes

[Standard-Intelligence/hertz-dev](https://github.com/Standard-Intelligence/hertz-dev) --- first base model for full-duplex conversational audio

[wav2gloss/fieldwork](https://huggingface.co/datasets/wav2gloss/fieldwork) --- Mostly open, but includes closed data

[juice500ml/finetune_owsm](https://github.com/juice500ml/finetune_owsm)

[vllm-project/vllm](https://github.com/vllm-project/vllm) --- A high-throughput and memory-efficient inference and serving engine for LLMs

[espnet - Phoneme Recognition with IPAPack](https://github.com/espnet/espnet/pull/5966)

[Active Learning with Task Adaptation Pre-training for Speech Emotion Recognition](https://arxiv.org/abs/2405.00307)

[SemantiCodec: An Ultra Low Bitrate Semantic Audio Codec for General Sound](https://arxiv.org/abs/2405.00233),
[inference code](https://github.com/haoheliu/SemantiCodec-inference)

[How the RWKV language model works](https://johanwind.github.io/2023/03/23/rwkv_details.html),
[RWKV_in_150_lines.py](https://github.com/BlinkDL/ChatRWKV/blob/main/RWKV_in_150_lines.py)

[clee704/audiodiff](https://github.com/clee704/audiodiff) --- A commandline tool that compares two audio files and prints the difference

[PyGyat](https://pygyat.vercel.app/docs),
[code](https://github.com/shamith09/pygyat)

[torch.compile, the missing manual](https://docs.google.com/document/u/0/d/1y5CRfMLdwEoF1nTk9q8qEu1mgMUuUtvhklPKJ2emLU8/mobilebasic)

[Ways to use torch.compile](http://blog.ezyang.com/2024/11/ways-to-use-torch-compile/)

[FaceFormer: Speech-Driven 3D Facial Animation with Transformers](https://arxiv.org/abs/2112.05329),
[code](https://github.com/EvelynFan/FaceFormer) --- Depends on Max Planck stuff, so probably not useable.

[ACE: All-round Creator and Editor Following Instructions via Diffusion Transformer](https://arxiv.org/abs/2410.00086),
[model](https://huggingface.co/scepter-studio/ACE-0.6B-512px),
[code](https://github.com/ali-vilab/ACE)

[modelscope/scepter](https://github.com/modelscope/scepter) --- SCEPTER is an open-source framework used for training, fine-tuning, and inference with generative models.

[TTS-Transducer: End-to-End Speech Synthesis with Neural Transducer](https://arxiv.org/abs/2501.06320)

[rusq/slackdump](https://github.com/rusq/slackdump)

[black-forest-labs/flux](https://github.com/black-forest-labs/flux) --- Official inference repo for FLUX.1 models.
[open model](https://huggingface.co/black-forest-labs/FLUX.1-schnell)

[Investigation of Whisper ASR Hallucinations Induced by Non-Speech Audio](https://arxiv.org/abs/2501.11378),
[data](https://github.com/DSP-AGH/ICASSP2025_Whisper_Hallucination)

[deepseek-r1-webgpu](https://huggingface.co/spaces/webml-community/deepseek-r1-webgpu)

[allenai/OLMo](https://github.com/allenai/OLMo) --- Modeling, training, eval, and inference code for OLMo

[m-a-p/Code-Feedback](https://huggingface.co/datasets/m-a-p/Code-Feedback) --- OpenCodeInterpreter is a family of open-source code generation systems designed to bridge the gap between large language models and advanced proprietary systems like the GPT-4 Code Interpreter. It significantly advances code generation capabilities by integrating execution and iterative refinement functionalities.

[persian-tts-dataset-male](https://www.kaggle.com/datasets/magnoliasis/persian-tts-dataset-male),
[persian-tts-dataset-famale](https://www.kaggle.com/datasets/magnoliasis/persian-tts-dataset-famale)

[DiM-Gesture: Co-Speech Gesture Generation with Adaptive Layer Normalization Mamba-2 framework](https://arxiv.org/abs/2408.00370)

[Dynamic Time Warping Notebook](https://github.com/kamperh/lecture_dtw_notebook)

[kamperh/speech_dtw](https://github.com/kamperh/speech_dtw)

[You Only Cache Once: Decoder-Decoder Architectures for Language Models](https://arxiv.org/abs/2405.05254),
[code](https://github.com/microsoft/unilm/tree/master/YOCO)

[hitz-zentroa/latxa](https://github.com/hitz-zentroa/latxa) --- Latxa: An Open Language Model and Evaluation Suite for Basque

[kamperh/VectorQuantizedCPC](https://github.com/kamperh/VectorQuantizedCPC)

[Looking Backward: Streaming Video-to-Video Translation with Feature Banks](https://arxiv.org/abs/2405.15757)

[A light-weight and efficient punctuation and word casing prediction model for on-device streaming ASR](https://arxiv.org/abs/2407.13142),
[code](https://github.com/frankyoujian/Edge-Punct-Casing)

[Büszkeség és balítélet](https://mek.oszk.hu/06000/06058/)

[EvaByte/EvaByte](https://huggingface.co/EvaByte/EvaByte) --- EvaByte is a 6.5B byte-level language model built upon an improved architecture with multibyte prediction and EVA -- an efficient attention mechanism designed for scalability and performance.

[HKUNLP/efficient-attention](https://github.com/HKUNLP/efficient-attention) --- [EVA ICLR'23; LARA ICML'22] Efficient attention mechanisms via control variates, random features, and importance sampling


