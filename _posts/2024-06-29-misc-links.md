---
toc: true
layout: post
hidden: true
description: Misc. interesting things.
title: Interesting links, 29/06/2024
categories: [links]
---

[Analyzing Open AI's Whisper ASR Accuracy: Word Error Rates Across Languages and Model Sizes](https://www.speechly.com/blog/analyzing-open-ais-whisper-asr-models-word-error-rates-across-languages)

[Lauler/rixvox-alignments](https://huggingface.co/datasets/Lauler/rixvox-alignments)

[swerik-project/riksdagen-records](https://github.com/swerik-project/riksdagen-records)

{% twitter https://x.com/jxmnop/status/1800292343343693934 %}

[sherpa-onnx - audio-tagging-from-a-file](https://github.com/k2-fsa/sherpa-onnx/blob/master/python-api-examples/audio-tagging-from-a-file.py)

[A Closer Look at Wav2Vec2 Embeddings for On-Device Single-Channel Speech Enhancement](https://arxiv.org/abs/2403.01369)

[Evaluating Gammatone Frequency Cepstral Coefficients with Neural Networks for Emotion Recognition from Speech](https://arxiv.org/abs/1806.09010)

[Foundation Transformers](https://arxiv.org/abs/2210.06423)

{% twitter https://x.com/Hamptonism/status/1803344932859502614 %}

{% twitter https://x.com/ProfTomYeh/status/1798042265883156651 %}

{% twitter https://x.com/karpathy/status/1803963383018066272 %}

[Everything You Always Wanted To Know About Mathematics But didn’t even know to ask](https://www.math.cmu.edu/~jmackey/151_128/bws_book.pdf)

{% twitter https://x.com/jdeschena/status/1803096836460155144 %}

{% twitter https://x.com/cgarciae88/status/1803004045084197186 %}

[Conditional flow matching](https://bm371613.github.io/conditional-flow-matching/)

[How Much Context Does My Attention-Based ASR System Need?](https://arxiv.org/abs/2310.15672),
[code](github.com/robflynnyh/long-context-asr)

[SkalskiP/top-cvpr-2024-papers](https://github.com/SkalskiP/top-cvpr-2024-papers)

[Evaluating Gesture Generation in a Large-scale Open Challenge: The GENEA Challenge 2022](https://dl.acm.org/doi/10.1145/3656374)

[Hierarchical Open-Vocabulary 3D Scene Graphs for Language-Grounded Robot Navigation](https://arxiv.org/abs/2403.17846),
[code](https://github.com/hovsg/HOV-SG)

[Understanding FAISS](https://towardsdatascience.com/understanding-faiss-619bb6db2d1a)

[An Empirical Study of Mamba-based Language Models](https://arxiv.org/abs/2406.07887),
[model](https://huggingface.co/nvidia/mamba2-hybrid-8b-3t-4k),
[code](https://github.com/NVIDIA/Megatron-LM/tree/ssm/examples/mamba)

{% twitter https://x.com/HamelHusain/status/1802106197782438019 %}

[pkufool/librilight-text](https://huggingface.co/datasets/pkufool/librilight-text)

[Open CLIP - SigLipLoss](https://github.com/mlfoundations/open_clip/blob/73ad04ae7fb93ede1c02dc9040a828634cb1edf1/src/open_clip/loss.py#L307)

{% twitter https://x.com/rohanpaul_ai/status/1800298331773567412 %}

[Faiss: A library for efficient similarity search](https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/)

[Faiss - Brute force search without an index](https://github.com/facebookresearch/faiss/wiki/Brute-force-search-without-an-index)

[Robust solutions for audio fingerprinting](https://upcommons.upc.edu/bitstream/handle/2117/386744/Master_Thesis_Macia_Amoros_Cortiella.pdf?sequence=5&isAllowed=y)

[Neural Audio Fingerprint for High-Specific Audio Retrieval Based on Contrastive Learning](https://ieeexplore.ieee.org/document/9414337),
[code](https://github.com/mimbres/neural-audio-fp)

[Audio Fingerprinting with Holographic Reduced Representations](https://arxiv.org/abs/2406.13139)

[MahmudulAlam/Holographic-Reduced-Representations](https://github.com/MahmudulAlam/Holographic-Reduced-Representations)

[Learning with Holographic Reduced Representations](https://arxiv.org/abs/2109.02157),
[code](https://github.com/FutureComputing4AI/Learning-with-Holographic-Reduced-Representations)

{% twitter https://x.com/Ethan_smith_20/status/1801493585155526675 %}

[spotify/basic-pitch](https://github.com/spotify/basic-pitch) --- A lightweight yet powerful audio-to-MIDI converter with pitch bend detection

[Step-by-Step Diffusion: An Elementary Tutorial](https://arxiv.org/abs/2406.08929)

[Fourier Diffusion Models: A Method to Control MTF and NPS in Score-Based Stochastic Image Generation](https://arxiv.org/abs/2303.13285)

[Time Series Diffusion in the Frequency Domain](https://arxiv.org/abs/2402.05933),
[code](https://github.com/JonathanCrabbe/FourierDiffusion)

[Data Augmentation in Time and Doppler Frequency Domain for Radar-based Gesture Recognition](https://ieeexplore.ieee.org/document/9784553)

[Frequency Domain Audio Synthesis – With IFFT and Oscillators](https://blog.demofox.org/2015/04/19/frequency-domain-audio-synthesis-with-ifft-and-oscillators/)

[Trajectories and revolutions in popular melody based on U.S. charts from 1950 to 2023](https://www.nature.com/articles/s41598-024-64571-x)

[Speech Recognition and Multi-Speaker Diarization of Long Conversations](https://arxiv.org/abs/2005.08072),
[data](https://www.kaggle.com/datasets/shuyangli94/this-american-life-podcast-transcriptsalignments)

[Vision Language Models Explained](https://huggingface.co/blog/vlms)

| Model                  | **Actually** open |
!------------------------|-------------------|
| LLaVA 1.6 (Hermes 34B) |                   |
| deepseek-vl-7b-base    | ❌                |
| DeepSeek-VL-Chat       | ❌                |
| moondream2             |                   |
| CogVLM-base            | (❌)[https://github.com/THUDM/CogVLM/raw/main/MODEL_LICENSE] |
| CogVLM-Chat            | (❌)[https://github.com/THUDM/CogVLM/raw/main/MODEL_LICENSE] |
| Fuyu-8B                | ❌                |
| KOSMOS-2               | ✅                |
| Qwen-VL                | ❌                |
| Qwen-VL-Chat           | ❌                |
| Yi-VL-34B              | ✅                |


[nmslib/nmslib](https://github.com/nmslib/nmslib) --- Non-Metric Space Library (NMSLIB): An efficient similarity search library and a toolkit for evaluation of k-NN methods for generic non-metric spaces.

[GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers](https://arxiv.org/abs/2210.17323),
[code](https://github.com/IST-DASLab/gptq/)

[Large Language Models are Efficient Learners of Noise-Robust Speech Recognition](https://openreview.net/pdf?id=ceATjGPTUD),
[code](https://github.com/YUCHEN005/RobustGER)

[It's Never Too Late: Fusing Acoustic Information into Large Language Models for Automatic Speech Recognition](https://openreview.net/pdf?id=QqjFHyQwtF),
[code](https://github.com/Hypotheses-Paradise/UADF)

[BAT: Learning to Reason about Spatial Sounds with Large Language Models](https://arxiv.org/abs/2402.01591)

[SpiRit-LM: Interleaved Spoken and Written Language Model](https://arxiv.org/abs/2402.05755)

[WavLLM: Towards Robust and Adaptive Speech Large Language Model](https://arxiv.org/abs/2404.00656),
[code](https://github.com/microsoft/SpeechT5/tree/main/WavLLM)

[An Embarrassingly Simple Approach for LLM with Strong ASR Capacity](https://arxiv.org/abs/2402.08846),
[code](https://github.com/X-LANCE/SLAM-LLM)

[Speech Trident - Awesome Speech LM](https://github.com/ga642381/speech-trident)

[SimpleSpeech: Towards Simple and Efficient Text-to-Speech with Scalar Latent Transformer Diffusion Models](https://arxiv.org/abs/2406.02328)

{% twitter https://x.com/_philschmid/status/1798388387822317933 %}

[Investigating the Effects of Large-Scale Pseudo-Stereo Data and Different Speech Foundation Model on Dialogue Generative Spoken Language Model](https://arxiv.org/abs/2407.01911)

{% twitter https://x.com/tradingMaxiSL/status/1809857803177324992 %}

[Memory3 : Language Modeling with Explicit Memory](https://arxiv.org/abs/2407.01178)

{% twitter https://x.com/cooltechtipz/status/1809758725575737440 %}

[Information Theory: A Tutorial Introduction](https://arxiv.org/abs/1802.05968)

[Data curation via joint example selection further accelerates multimodal learning](https://arxiv.org/abs/2406.17711)

[Depth Anything V2](https://arxiv.org/abs/2406.09414),
[code](https://github.com/DepthAnything/Depth-Anything-V2),
[demo](https://huggingface.co/spaces/depth-anything/Depth-Anything-V2),
[coreml](https://huggingface.co/apple/coreml-depth-anything-v2-small),
[model](https://huggingface.co/depth-anything/Depth-Anything-V2-Small)

[Alice’s Adventures in a differentiable wonderland](https://www.sscardapane.it/alice-book)

[supabase/supabase](https://github.com/supabase/supabase) --- The open source Firebase alternative. Supabase gives you a dedicated Postgres database to build your web, mobile, and AI applications.

{% twitter https://x.com/Rainmaker1973/status/1810531826752168071 %}

[HazyResearch/flash-fft-conv](https://github.com/HazyResearch/flash-fft-conv) --- FlashFFTConv: Efficient Convolutions for Long Sequences with Tensor Cores

[Less is More: Accurate Speech Recognition & Translation without Web-Scale Data](https://arxiv.org/abs/2406.19674),
code in NeMo, model closed but available.

[23606 Workshop on Human Motion Generation](https://www.youtube.com/watch?v=lkQ4sDK4u9U),
key moment [here](https://www.youtube.com/watch?v=lkQ4sDK4u9U&t=12278s)

[microsoft/graphrag](https://github.com/microsoft/graphrag)

[leaningtech/webvm](https://github.com/leaningtech/webvm) --- Virtual Machine for the Web

{% twitter https://x.com/xiaolonw/status/1810387662060269668 %}

[Learning to (Learn at Test Time): RNNs with Expressive Hidden States](https://arxiv.org/abs/2407.04620)

{% twitter https://x.com/omarsar0/status/1812247121560502426 %}

[Audio Spotforming Using Nonnegative Tensor Factorization with Attractor-Based Regularization](https://arxiv.org/abs/2407.08951)

[Beyond Euclid: An Illustrated Guide to Modern Machine Learning with Geometric, Topological, and Algebraic Structures](https://www.arxiv.org/abs/2407.09468)

[Understanding Transformers via N-Gram Statistics](https://www.researchgate.net/publication/382204056_Understanding_Transformers_via_N-Gram_Statistics)

[facebookincubator/submitit](https://github.com/facebookincubator/submitit) --- Python 3.8+ toolbox for submitting jobs to Slurm

[Video Diffusion Alignment via Reward Gradients](https://arxiv.org/abs/2407.08737),
[model](https://huggingface.co/zheyangqin/VADER)
<!-- [code](https://github.com/mihirp1998/VADER) -->

[Deep Dive into LSTMs and xLSTMs by Hand](https://towardsdatascience.com/deep-dive-into-lstms-xlstms-by-hand-%EF%B8%8F-c33e638bebb1)

[Chronos: Learning the Language of Time Series](https://arxiv.org/abs/2403.07815),
[code](https://github.com/amazon-science/chronos-forecasting)

[lm-sys/FastChat](https://github.com/lm-sys/FastChat)

[EnCLAP: Combining Neural Audio Codec and Audio-Text Joint Embedding for Automated Audio Captioning](https://arxiv.org/abs/2401.17690),
[code](https://github.com/jaeyeonkim99/EnCLAP)

[Introducing Triton: Open-source GPU programming for neural networks](https://openai.com/index/triton/)

[CUDA kernels in PyTorch made easy with Numba](https://medium.com/@khalfaoui.ismail/cuda-kernels-in-pytorch-made-easy-with-numba-using-python-only-74012bab23ba),
[notebook](https://colab.research.google.com/drive/1Ix8ENHB31eIsXGwnob9NUJgdHssfIzx7)

[a-brassard/ACORN](https://github.com/a-brassard/ACORN) --- Home repository for the ACORN dataset: 3,500 explanations with aspect-wise human ratings of their quality.

[Let's reproduce GPT-2](https://github.com/karpathy/llm.c/discussions/677)

[facebookresearch/data2vec_vision](https://github.com/facebookresearch/data2vec_vision)

[Fine-tuning Florence-2 - Microsoft's Cutting-edge Vision Language Models](https://huggingface.co/blog/finetune-florence2)

[ManiWAV: Learning Robot Manipulation from In-the-Wild Audio-Visual Data](https://arxiv.org/abs/2406.19464),
[code](https://github.com/real-stanford/maniwav)

[ColPali: Efficient Document Retrieval with Vision Language Models](https://arxiv.org/abs/2407.01449),
[code](https://github.com/illuin-tech/colpali)

[Block Transformer: Global-to-Local Language Modeling for Fast Inference](https://arxiv.org/abs/2406.02657),
[code](https://github.com/itsnamgyu/block-transformer)

[AND: Audio Network Dissection for Interpreting Deep Acoustic Models](https://arxiv.org/abs/2406.16990)
<!-- [code](https://github.com/Trustworthy-ML-Lab/Audio_Network_Dissection) -->

[Sound Field Synthesis with Acoustic Waves](https://arxiv.org/abs/2406.17111)

[SpecMaskGIT: Masked Generative Modeling of Audio Spectrograms for Efficient Audio Synthesis and Beyond](https://arxiv.org/abs/2406.17672)

[Mapping the Past: Geographically Linking an Early 20th Century Swedish Encyclopedia with Wikidata](https://arxiv.org/abs/2406.17903)

[A multi-speaker multi-lingual voice cloning system based on vits2 for limmits 2024 challenge](https://arxiv.org/abs/2406.17801)

[Cambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs](https://arxiv.org/abs/2406.16860),
[code](https://github.com/cambrian-mllm/cambrian),
[model](https://huggingface.co/nyu-visionx/cambrian-34b)

AI by Hand:

{% twitter https://x.com/ProfTomYeh/status/1793623127643037891 %)

{% twitter https://x.com/ProfTomYeh/status/1794070094898704456 %}

{% twitter https://x.com/ProfTomYeh/status/1794451228681712037 %}

{% twitter https://x.com/ProfTomYeh/status/1794848226383655284 %}

{% twitter https://x.com/ProfTomYeh/status/1795221120351715450 %}

{% twitter https://x.com/ProfTomYeh/status/1795076707386360227 %}

{% twitter https://x.com/ProfTomYeh/status/1794144904395837638 %}

{% twitter https://x.com/ProfTomYeh/status/1810849417576186076 %}

[SoundCTM: Uniting Score-based and Consistency Models for Text-to-Sound Generation](https://arxiv.org/abs/2405.18503),
[code](https://github.com/sony/soundctm),
[model](https://huggingface.co/Sony/soundctm)

[Zielon/PBRVulkan](https://github.com/Zielon/PBRVulkan) --- Vulkan Real-time Path Tracer Engine

[UCxn: Typologically Informed Annotation of Constructions Atop Universal Dependencies](https://aclanthology.org/2024.lrec-main.1471/)

[Generative AI Handbook: A Roadmap for Learning Resources](https://genai-handbook.github.io/)

[Crossmodal ASR Error Correction with Discrete Speech Units](https://arxiv.org/abs/2405.16677)
<!-- [code](https://github.com/yc-li20/Crossmodal_AEC) -->

[CMU-MOSI Dataset](http://multicomp.cs.cmu.edu/resources/cmu-mosi-dataset/) --- The Multimodal Corpus of Sentiment Intensity (CMU-MOSI) dataset is a collection of 2199 opinion video clips.

[The essence of calculus](https://www.youtube.com/watch?v=WUvTyaaNkzM&list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr)

[Imitation and Mechanisms of Joint Attention: A Developmental Structure for Building Social Skills on a Humanoid Robot](https://link.springer.com/chapter/10.1007/3-540-48834-0_11)

[Polish Public Domain Works](https://archive.org/details/polishpublicdomain)

[USER-LLM: Efficient LLM contextualization with user embeddings](https://research.google/blog/user-llm-efficient-llm-contextualization-with-user-embeddings/),
[arXiv](https://arxiv.org/abs/2402.13598)

[Perceiver: General Perception with Iterative Attention](https://arxiv.org/abs/2103.03206)

[Reverse the auditory processing pathway: Coarse-to-fine audio reconstruction from fMRI](https://arxiv.org/abs/2405.18726)

[Vocos: Closing the gap between time-domain and Fourier-based neural vocoders for high-quality audio synthesis](https://arxiv.org/abs/2306.00814),
[code](https://github.com/gemelo-ai/vocos),
[vocos-mel-24khz](https://huggingface.co/charactr/vocos-mel-24khz),
[vocos-encodec-24khz](https://huggingface.co/charactr/vocos-encodec-24khz)

[Improving Speech Decoding from ECoG with Self-Supervised Pretraining](https://arxiv.org/abs/2405.18639)

[BLSP-KD: Bootstrapping Language-Speech Pre-training via Knowledge Distillation](https://arxiv.org/abs/2405.19041)

[TF-SepNet: An Efficient 1D Kernel Design in CNNs for Low-Complexity Acoustic Scene Classification](https://arxiv.org/abs/2309.08200)

[Zero-Shot Unsupervised and Text-Based Audio Editing Using DDPM Inversion](https://arxiv.org/abs/2402.10009),
[code](https://github.com/HilaManor/AudioEditingCode/)

[Adapting Frechet Audio Distance for Generative Music Evaluation](https://ieeexplore.ieee.org/document/10446663),
[arXiv](https://arxiv.org/abs/2311.01616),
[code](https://github.com/microsoft/fadtk)

[TRAMBA: A Hybrid Transformer and Mamba Architecture for Practical Audio and Bone Conduction Speech Super Resolution and Enhancement on Mobile and Wearable Platforms](https://arxiv.org/abs/2405.01242)

[CoVoMix: Advancing Zero-Shot Speech Generation for Human-like Multi-talker Conversations](https://arxiv.org/abs/2404.06690)

[Spiketrum: An FPGA-based Implementation of a Neuromorphic Cochlea](https://arxiv.org/abs/2405.15923)

[Contextual Position Encoding: Learning to Count What's Important](https://arxiv.org/abs/2405.18719)

[The Raven: Hungarian](The Raven; with literary and historical commentary/Hungarian)

[IN LOVE WITH THE CZARINA](https://en.wikisource.org/wiki/Stories_by_Foreign_Authors_\(Polish-Greek-Belgian-Hungarian\)/In_Love_with_the_Czarina)

[Simplified Grammar of the Hungarian Language](https://en.wikisource.org/wiki/Simplified_Grammar_of_the_Hungarian_Language)

[In Love With the Czarina, and Other Stories](https://www.gutenberg.org/cache/epub/34574/pg34574-images.html),
[A VAKMERŐ](https://mek.oszk.hu/16400/16475/16475.htm)

[The Hedgehog & the Porcupine: Expressive Linear Attentions with Softmax Mimicry](https://arxiv.org/abs/2402.04347)

[netease-youdao/EmotiVoice](https://github.com/netease-youdao/EmotiVoice) --- a Multi-Voice and Prompt-Controlled TTS Engine

[Voice Cloning with your personal data](https://github.com/netease-youdao/EmotiVoice/wiki/Voice-Cloning-with-your-personal-data)

[ricosjp/truck](https://github.com/ricosjp/truck) --- Truck is a rust CAD kernel

[Hungarian Body Parts Flashcards](https://flashcardo.com/hungarian-flashcards/body/1)

[Hungarian Flashcards](https://flashcardo.com/hungarian-flashcards/)

[OpenVoice: Versatile Instant Voice Cloning](https://arxiv.org/abs/2312.01479),
[code](https://github.com/myshell-ai/OpenVoice)

[LongRoPE: Extending LLM Context Window Beyond 2 Million Tokens](https://arxiv.org/abs/2402.13753)

[A Complete Guide to Write your own Transformers](https://towardsdatascience.com/a-complete-guide-to-write-your-own-transformers-29e23f371ddd)

[NaturalSpeech 3: Zero-Shot Speech Synthesis with Factorized Codec and Diffusion Models](https://arxiv.org/abs/2403.03100),
[FACodec model](https://huggingface.co/amphion/naturalspeech3_facodec),
[code](https://github.com/open-mmlab/Amphion)

[Decades-Old Beer Ads Stitched Straight Into Original Star Wars Movies Go Viral](https://nordic.ign.com/star-wars-episode-iv-a-new-hope-theater/79567/news/decades-old-beer-ads-stitched-straight-into-original-star-wars-movies-go-viral)

[Towards Decoupling Frontend Enhancement and Backend Recognition in Monaural Robust ASR](https://arxiv.org/abs/2403.06387)


