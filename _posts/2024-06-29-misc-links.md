---
toc: true
layout: post
hidden: true
description: Misc. interesting things.
title: Interesting links, 29/06/2024
categories: [links]
---

[Analyzing Open AI's Whisper ASR Accuracy: Word Error Rates Across Languages and Model Sizes](https://www.speechly.com/blog/analyzing-open-ais-whisper-asr-models-word-error-rates-across-languages)

[Lauler/rixvox-alignments](https://huggingface.co/datasets/Lauler/rixvox-alignments)

[swerik-project/riksdagen-records](https://github.com/swerik-project/riksdagen-records)

{% twitter https://x.com/jxmnop/status/1800292343343693934 %}

[sherpa-onnx - audio-tagging-from-a-file](https://github.com/k2-fsa/sherpa-onnx/blob/master/python-api-examples/audio-tagging-from-a-file.py)

[A Closer Look at Wav2Vec2 Embeddings for On-Device Single-Channel Speech Enhancement](https://arxiv.org/abs/2403.01369)

[Evaluating Gammatone Frequency Cepstral Coefficients with Neural Networks for Emotion Recognition from Speech](https://arxiv.org/abs/1806.09010)

[Foundation Transformers](https://arxiv.org/abs/2210.06423)

{% twitter https://x.com/Hamptonism/status/1803344932859502614 %}

{% twitter https://x.com/ProfTomYeh/status/1798042265883156651 %}

{% twitter https://x.com/karpathy/status/1803963383018066272 %}

[Everything You Always Wanted To Know About Mathematics But didn’t even know to ask](https://www.math.cmu.edu/~jmackey/151_128/bws_book.pdf)

{% twitter https://x.com/jdeschena/status/1803096836460155144 %}

{% twitter https://x.com/cgarciae88/status/1803004045084197186 %}

[Conditional flow matching](https://bm371613.github.io/conditional-flow-matching/)

[How Much Context Does My Attention-Based ASR System Need?](https://arxiv.org/abs/2310.15672),
[code](github.com/robflynnyh/long-context-asr)

[SkalskiP/top-cvpr-2024-papers](https://github.com/SkalskiP/top-cvpr-2024-papers)

[Evaluating Gesture Generation in a Large-scale Open Challenge: The GENEA Challenge 2022](https://dl.acm.org/doi/10.1145/3656374)

[Hierarchical Open-Vocabulary 3D Scene Graphs for Language-Grounded Robot Navigation](https://arxiv.org/abs/2403.17846),
[code](https://github.com/hovsg/HOV-SG)

[Understanding FAISS](https://towardsdatascience.com/understanding-faiss-619bb6db2d1a)

[An Empirical Study of Mamba-based Language Models](https://arxiv.org/abs/2406.07887),
[model](https://huggingface.co/nvidia/mamba2-hybrid-8b-3t-4k),
[code](https://github.com/NVIDIA/Megatron-LM/tree/ssm/examples/mamba)

{% twitter https://x.com/HamelHusain/status/1802106197782438019 %}

[pkufool/librilight-text](https://huggingface.co/datasets/pkufool/librilight-text)

[Open CLIP - SigLipLoss](https://github.com/mlfoundations/open_clip/blob/73ad04ae7fb93ede1c02dc9040a828634cb1edf1/src/open_clip/loss.py#L307)

{% twitter https://x.com/rohanpaul_ai/status/1800298331773567412 %}

[Faiss: A library for efficient similarity search](https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/)

[Faiss - Brute force search without an index](https://github.com/facebookresearch/faiss/wiki/Brute-force-search-without-an-index)

[Robust solutions for audio fingerprinting](https://upcommons.upc.edu/bitstream/handle/2117/386744/Master_Thesis_Macia_Amoros_Cortiella.pdf?sequence=5&isAllowed=y)

[Neural Audio Fingerprint for High-Specific Audio Retrieval Based on Contrastive Learning](https://ieeexplore.ieee.org/document/9414337),
[code](https://github.com/mimbres/neural-audio-fp)

[Audio Fingerprinting with Holographic Reduced Representations](https://arxiv.org/abs/2406.13139)

[MahmudulAlam/Holographic-Reduced-Representations](https://github.com/MahmudulAlam/Holographic-Reduced-Representations)

[Learning with Holographic Reduced Representations](https://arxiv.org/abs/2109.02157),
[code](https://github.com/FutureComputing4AI/Learning-with-Holographic-Reduced-Representations)

{% twitter https://x.com/Ethan_smith_20/status/1801493585155526675 %}

[spotify/basic-pitch](https://github.com/spotify/basic-pitch) --- A lightweight yet powerful audio-to-MIDI converter with pitch bend detection

[Step-by-Step Diffusion: An Elementary Tutorial](https://arxiv.org/abs/2406.08929)

[Fourier Diffusion Models: A Method to Control MTF and NPS in Score-Based Stochastic Image Generation](https://arxiv.org/abs/2303.13285)

[Time Series Diffusion in the Frequency Domain](https://arxiv.org/abs/2402.05933),
[code](https://github.com/JonathanCrabbe/FourierDiffusion)

[Data Augmentation in Time and Doppler Frequency Domain for Radar-based Gesture Recognition](https://ieeexplore.ieee.org/document/9784553)

[Frequency Domain Audio Synthesis – With IFFT and Oscillators](https://blog.demofox.org/2015/04/19/frequency-domain-audio-synthesis-with-ifft-and-oscillators/)

[Trajectories and revolutions in popular melody based on U.S. charts from 1950 to 2023](https://www.nature.com/articles/s41598-024-64571-x)

[Speech Recognition and Multi-Speaker Diarization of Long Conversations](https://arxiv.org/abs/2005.08072),
[data](https://www.kaggle.com/datasets/shuyangli94/this-american-life-podcast-transcriptsalignments)

[Vision Language Models Explained](https://huggingface.co/blog/vlms)

| Model                  | **Actually** open |
!------------------------|-------------------|
| LLaVA 1.6 (Hermes 34B) |                   |
| deepseek-vl-7b-base    | ❌                |
| DeepSeek-VL-Chat       | ❌                |
| moondream2             |                   |
| CogVLM-base            | (❌)[https://github.com/THUDM/CogVLM/raw/main/MODEL_LICENSE] |
| CogVLM-Chat            | (❌)[https://github.com/THUDM/CogVLM/raw/main/MODEL_LICENSE] |
| Fuyu-8B                | ❌                |
| KOSMOS-2               | ✅                |
| Qwen-VL                | ❌                |
| Qwen-VL-Chat           | ❌                |
| Yi-VL-34B              | ✅                |


[nmslib/nmslib](https://github.com/nmslib/nmslib) --- Non-Metric Space Library (NMSLIB): An efficient similarity search library and a toolkit for evaluation of k-NN methods for generic non-metric spaces.

[GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers](https://arxiv.org/abs/2210.17323),
[code](https://github.com/IST-DASLab/gptq/)

[Large Language Models are Efficient Learners of Noise-Robust Speech Recognition](https://openreview.net/pdf?id=ceATjGPTUD),
[code](https://github.com/YUCHEN005/RobustGER)

[It's Never Too Late: Fusing Acoustic Information into Large Language Models for Automatic Speech Recognition](https://openreview.net/pdf?id=QqjFHyQwtF),
[code](https://github.com/Hypotheses-Paradise/UADF)

[BAT: Learning to Reason about Spatial Sounds with Large Language Models](https://arxiv.org/abs/2402.01591)

[SpiRit-LM: Interleaved Spoken and Written Language Model](https://arxiv.org/abs/2402.05755)

[WavLLM: Towards Robust and Adaptive Speech Large Language Model](https://arxiv.org/abs/2404.00656),
[code](https://github.com/microsoft/SpeechT5/tree/main/WavLLM)

[An Embarrassingly Simple Approach for LLM with Strong ASR Capacity](https://arxiv.org/abs/2402.08846),
[code](https://github.com/X-LANCE/SLAM-LLM)

[Speech Trident - Awesome Speech LM](https://github.com/ga642381/speech-trident)

[SimpleSpeech: Towards Simple and Efficient Text-to-Speech with Scalar Latent Transformer Diffusion Models](https://arxiv.org/abs/2406.02328)

{% twitter https://x.com/_philschmid/status/1798388387822317933 %}

[Investigating the Effects of Large-Scale Pseudo-Stereo Data and Different Speech Foundation Model on Dialogue Generative Spoken Language Model](https://arxiv.org/abs/2407.01911)

