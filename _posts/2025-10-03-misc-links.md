---
toc: true
layout: post
hidden: true
description: Misc. interesting things.
title: Interesting links, 3/10/2025
categories: [links]
---

# Sámi

[divvun/lang-sme-ml-speech](https://github.com/divvun/lang-sme-ml-speech)

[divvun/lang-sme-ml-swe](https://github.com/divvun/lang-sme-ml-swe)

[NbAiLab/whisper-large-sme](https://huggingface.co/NbAiLab/whisper-large-sme)

[NbAiLab/salmon-whisper-large-smj-lr7e-5](https://huggingface.co/NbAiLab/salmon-whisper-large-smj-lr7e-5)

[NbAiLab/f5-tts-north-sami](https://huggingface.co/spaces/NbAiLab/f5-tts-north-sami)

[divvun-tts/multi-sami](https://huggingface.co/spaces/divvun-tts/multi-sami)

[divvun-tts/6L-TTS](https://huggingface.co/spaces/divvun-tts/6L-TTS)

[Does multilingual and multi-speaker modeling improve low-resource TTS? Experiments on Sámi languages](https://www.isca-archive.org/ssw_2025/hiovainasikainen25_ssw.html)

[aalto-speech/northern-sami-asr](https://github.com/aalto-speech/northern-sami-asr)

[GetmanY1/wav2vec2-xls-r-300m-sami-parl-ext-ft](https://huggingface.co/GetmanY1/wav2vec2-xls-r-300m-sami-parl-ext-ft)

[GetmanY1/wav2vec2-base-sami-22k](https://huggingface.co/GetmanY1/wav2vec2-base-sami-22k)

[giellalt/speech-sme](https://github.com/giellalt/speech-sme)

[Julev Sámi IPA](https://github.com/giellalt/speech-smj/blob/main/docs/Rewrite_to_IPA.md)

# ParlaSpeech

[Spoken corpora of parliamentary debates ParlaSpeech 3.0](https://www.clarin.si/repository/xmlui/handle/11356/1833)

[Welcome to ParlaSpeech](https://clarinsi.github.io/parlaspeech/)

# Misc

[Correct MT output with word alignments](https://www.kaggle.com/code/tajakuz/correct-mt-output-with-word-alignments)

[robertostling/eflomal](https://github.com/robertostling/eflomal)

[Codec-ASR: Training Performant Automatic Speech Recognition Systems with Discrete Speech Representations](https://arxiv.org/abs/2407.03495)

[lucidrains/vector-quantize-pytorch](https://github.com/lucidrains/vector-quantize-pytorch)

[Reproducing Whisper-Style Training Using an Open-Source Toolkit and Publicly Available Data](https://arxiv.org/abs/2309.13876)

[Multiple Consistency-guided Test-Time Adaptation for Contrastive Audio-Language Models with Unlabeled Audio](https://ieeexplore.ieee.org/document/10889886)

[MambaInst: Lightweight State Space Model for Real-Time Instance Segmentation](https://ieeexplore.ieee.org/document/10888610)

[nvidia/canary-1b-flash](https://huggingface.co/spaces/nvidia/canary-1b-flash)

[spaces/nvidia/canary-1b-v2](https://huggingface.co/spaces/nvidia/canary-1b-v2)

[NeMo/blob/main/docker/Dockerfile.speech](https://github.com/NVIDIA-NeMo/NeMo/blob/main/docker/Dockerfile.speech)

[nvidia/nemo-megatron-t5-3B](https://huggingface.co/nvidia/nemo-megatron-t5-3B)

[sparkfish/augraphy](https://github.com/sparkfish/augraphy) --- Augmentation pipeline for rendering synthetic paper printing, faxing, scanning and copy machine processes

[bytedance/MegaTTS3](https://github.com/bytedance/MegaTTS3)

[BiT S09E08](https://drive.google.com/file/d/1P-XBGhu3xUleeSWx0bRQPMPHuOGdEGyh/view)

[Speech-to-Retrieval](https://research.google/blog/speech-to-retrieval-s2r-a-new-approach-to-voice-search/),
[dataset](https://huggingface.co/datasets/google/svq),
[code](https://github.com/google-research/mseb)

[A History of Large Language Models](https://gregorygundersen.com/blog/2025/10/01/large-language-models/)

[neuphonic/neucodec](https://huggingface.co/neuphonic/neucodec),
[code](https://github.com/neuphonic/neucodec),
[space](https://huggingface.co/spaces/neuphonic/neutts-air)

[HiFTNet: A Fast High-Quality Neural Vocoder with Harmonic-plus-Noise Filter and Inverse Short Time Fourier Transform](https://arxiv.org/abs/2309.09493),
[code](https://github.com/yl4579/HiFTNet)

[deepsearch-ai/deepsearch](https://github.com/deepsearch-ai/deepsearch) --- A multimodal RAG application that enables semantic search on multimedia sources like audio, video and images

[Introduction to University Mathematics](https://courses.maths.ox.ac.uk/course/view.php?id=1051)

[Conversational image segmentation with Gemini 2.5](https://developers.googleblog.com/en/conversational-image-segmentation-gemini-2-5/)

[deepreinforce-ai/CRINN](https://github.com/deepreinforce-ai/CRINN)

[Open Whisper-style Speech Models](https://www.wavlab.org/activities/2024/owsm/)

[raminnakhli/GMM-HMM-from-scratch](https://github.com/raminnakhli/GMM-HMM-from-scratch)

[Self-Supervised Contrastive Learning for Unsupervised Phoneme Segmentation](https://arxiv.org/abs/2007.13465),
[code](https://github.com/felixkreuk/UnsupSeg)

[Phi-4-multimodal-korean-finetuning](https://gist.github.com/seastar105/d1d8983b27611370528e3b194dcc5577)

[The best open source OCR models](https://getomni.ai/blog/benchmarking-open-source-models-for-ocr)

[Continuous Speech Tokenizer in Text To Speech](https://aclanthology.org/2025.findings-naacl.184/),
[code](https://github.com/Yixing-Li/Continuous-Speech-Tokenizer)

[Orpheus 3B](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Orpheus_%283B%29-TTS.ipynb)

[DDT: Decoupled Diffusion Transformer](https://github.com/MCG-NJU/DDT)

[SesameAILabs/csm](https://github.com/SesameAILabs/csm) --- A Conversational Speech Generation Model,
[model](https://huggingface.co/sesame/csm-1b)

[langchain-ai/rag-from-scratch](https://github.com/langchain-ai/rag-from-scratch)

[Zettlr/Zettlr](https://github.com/Zettlr/Zettlr)

[Phoneme Segmentation Using Self-Supervised Speech Models](https://arxiv.org/abs/2211.01461),
[code](https://github.com/lstrgar/self-supervised-phone-segmentation)

[Never Mind the Buzzcocks](https://drive.google.com/drive/u/0/folders/1louZ55AJZ47QZ5ta50Oo2jhyZnBAGV34)

[Audio Mamba: Selective State Spaces for Self-Supervised Audio Representations](https://www.isca-archive.org/interspeech_2024/yadav24_interspeech.html),
[code](https://github.com/kaistmm/Audio-Mamba-AuM)

[SoundChoice: Grapheme-to-Phoneme Models with Semantic Disambiguation](https://www.isca-archive.org/interspeech_2022/ploujnikov22_interspeech.html)

[Theomat/sbsur](https://github.com/Theomat/sbsur) --- Stochastic Beam Search + Unique Randomizer

[RF5/transfusion-asr](https://github.com/RF5/transfusion-asr) --- Transcribing Speech with Multinomial Diffusion, training code and models.

[r/AudioBookBay](https://www.reddit.com/r/AudioBookBay/)

> It has also been shown that adding pronunciation variants to the dictionary has a point of diminishing returns, as over-generated pronunciations can lead to ambiguity in the decoder and degrade its performance 

[Adaptation techniques to improve ASR performance on accented speakers](https://www.lti.cs.cmu.edu/people/alumni/alumni-thesis/nallasamy-udhyakumar-thesis.pdf)

[CVSS Corpus and Massively Multilingual Speech-to-Speech Translation](https://arxiv.org/abs/2201.03713)

[google-research-datasets/cvss](https://github.com/google-research-datasets/cvss) --- CVSS: A Massively Multilingual Speech-to-Speech Translation Corpus

[Cymru-Breizh-Agile-Cymru-Project/vosk-cymraeg](https://github.com/Cymru-Breizh-Agile-Cymru-Project/vosk-cymraeg)

[From Weak Labels to Strong Results: Utilizing 5,000 Hours of Noisy Classroom Transcripts with Minimal Accurate Data](https://arxiv.org/abs/2505.17088)

[Flow Matching Guide and Code](https://arxiv.org/abs/2412.06264)

[PnG BERT: Augmented BERT on Phonemes and Graphemes for Neural TTS](https://arxiv.org/abs/2103.15060)

[Distilling an End-to-End Voice Assistant Without Instruction Training Data](https://arxiv.org/abs/2410.02678)

[From the Forests](https://librivox.org/from-the-forests-by-henry-kendall/) --- LibriVox volunteers bring you 18 recordings of From the Forests by Henry Kendall.
This was the Fortnightly Poetry project for March 29, 2020.

[xbpeng/MimicKit](https://github.com/xbpeng/MimicKit) --- Suite of motion imitation methods for training motion controllers.

[VoXtream: Full-Stream Text-to-Speech with Extremely Low Latency](https://arxiv.org/abs/2509.15969),
[code](https://github.com/herimor/voxtream),
[model](https://huggingface.co/herimor/voxtream),
[space](https://huggingface.co/spaces/herimor/voxtream)

[Vyvo/VyvoTTS-v0-Qwen3-0.6B](https://huggingface.co/Vyvo/VyvoTTS-v0-Qwen3-0.6B)

[Special issue on finite-state methods in natural language processing and mathematics of language](https://jlm.ipipan.waw.pl/index.php/JLM/issue/view/21)

[nv-tlabs/vipe](https://github.com/nv-tlabs/vipe) --- ViPE: Video Pose Engine for Geometric 3D Perception

[A First Course on Data Structures in Python](https://donsheehy.github.io/datastructures/fullbook.pdf)

[newton-physics/newton](https://github.com/newton-physics/newton) --- An open-source, GPU-accelerated physics simulation engine built upon NVIDIA Warp, specifically targeting roboticists and simulation researchers.

[Korpus Dawnych Polskich Tekstów Dramatycznych](https://korteda.clarin-pl.eu/)

[H2IOSC](https://www.h2iosc.cnr.it/)

[SLA: Beyond Sparsity in Diffusion Transformers via Fine-Tunable Sparse-Linear Attention](https://arxiv.org/abs/2509.24006),
[code](https://github.com/thu-ml/SLA) (empty)

[Spoken corpora of parliamentary debates ParlaSpeech 3.0](https://www.clarin.si/repository/xmlui/handle/11356/1833)

[vosen/ZLUDA](https://github.com/vosen/ZLUDA) --- CUDA on non-NVIDIA GPUs

[MCG-NJU/MotionRAG](https://github.com/MCG-NJU/MotionRAG) --- [NeurIPS 2025] MotionRAG: Motion Retrieval-Augmented Image-to-Video Generation

[SMM2026](https://smm26.iiit.ac.in/callForPaper.html)

[SvarDOS/edrdos](https://github.com/SvarDOS/edrdos)

[SvarDOS - an open-source DOS distribution](http://svardos.org/)

[Continual-Intelligence/SEAL](https://github.com/Continual-Intelligence/SEAL) --- Self-Adapting Language Models

[Diffusion Transformers with Representation Autoencoders](https://arxiv.org/abs/2510.11690),
[code](https://github.com/bytetriper/RAE)

[yukara-ikemiya/Open-Miipher-2](https://github.com/yukara-ikemiya/Open-Miipher-2) --- PyTorch implementation of Miipher-2 [2025] which is a speech restoration model by Google DeepMind

[DeCodec: Rethinking Audio Codecs as Universal Disentangled Representation Learners](https://arxiv.org/abs/2509.09201)

[MiMo Audio](https://xiaomimimo.github.io/MiMo-Audio-Demo/),
[code](https://github.com/XiaomiMiMo/MiMo-Audio),
[report](https://github.com/XiaomiMiMo/MiMo-Audio/blob/main/MiMo-Audio-Technical-Report.pdf)

[Latent Diffusion Model without Variational Autoencoder](https://arxiv.org/abs/2510.15301)

[Ken Thompson Recalls Unix’s Rowdy, Lock-Picking Origins](https://thenewstack.io/ken-thompson-recalls-unixs-rowdy-lock-picking-origins/)

