{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%cd /tmp","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-25T22:46:58.262063Z","iopub.execute_input":"2021-05-25T22:46:58.262432Z","iopub.status.idle":"2021-05-25T22:46:58.270063Z","shell.execute_reply.started":"2021-05-25T22:46:58.262403Z","shell.execute_reply":"2021-05-25T22:46:58.268990Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"/tmp\n","output_type":"stream"}]},{"cell_type":"code","source":"!git clone https://github.com/pytorch/fairseq/","metadata":{"execution":{"iopub.status.busy":"2021-05-25T22:38:20.218027Z","iopub.execute_input":"2021-05-25T22:38:20.218325Z","iopub.status.idle":"2021-05-25T22:38:23.543393Z","shell.execute_reply.started":"2021-05-25T22:38:20.218298Z","shell.execute_reply":"2021-05-25T22:38:23.542342Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Cloning into 'fairseq'...\nremote: Enumerating objects: 28093, done.\u001b[K\nremote: Counting objects: 100% (514/514), done.\u001b[K\nremote: Compressing objects: 100% (306/306), done.\u001b[K\nremote: Total 28093 (delta 251), reused 393 (delta 197), pack-reused 27579\u001b[K\nReceiving objects: 100% (28093/28093), 11.83 MiB | 17.38 MiB/s, done.\nResolving deltas: 100% (21070/21070), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"%%capture\n!pip install phonemizer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture\n!pip install git+https://github.com/pytorch/fairseq/","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture\n!apt-get -y install espeak","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/kpu/kenlm","metadata":{"execution":{"iopub.status.busy":"2021-05-25T22:47:02.095783Z","iopub.execute_input":"2021-05-25T22:47:02.096273Z","iopub.status.idle":"2021-05-25T22:47:04.527585Z","shell.execute_reply.started":"2021-05-25T22:47:02.096238Z","shell.execute_reply":"2021-05-25T22:47:04.526333Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Cloning into 'kenlm'...\nremote: Enumerating objects: 13824, done.\u001b[K\nremote: Counting objects: 100% (137/137), done.\u001b[K\nremote: Compressing objects: 100% (79/79), done.\u001b[K\nremote: Total 13824 (delta 76), reused 92 (delta 45), pack-reused 13687\u001b[K\nReceiving objects: 100% (13824/13824), 5.49 MiB | 8.25 MiB/s, done.\nResolving deltas: 100% (7956/7956), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"%%capture\n!apt-get -y install libeigen3-dev liblzma-dev zlib1g-dev libbz2-dev","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture\n%cd kenlm\n!mkdir build\n%cd build\n!cmake ..\n!make -j 4\n%cd /tmp","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ['PATH'] = f\"{os.environ['PATH']}:/tmp/kenlm/build/bin/\"\nos.environ['FAIRSEQ_ROOT'] = '/tmp/fairseq'","metadata":{"execution":{"iopub.status.busy":"2021-05-25T22:58:58.397461Z","iopub.execute_input":"2021-05-25T22:58:58.397847Z","iopub.status.idle":"2021-05-25T22:58:58.402393Z","shell.execute_reply.started":"2021-05-25T22:58:58.397816Z","shell.execute_reply":"2021-05-25T22:58:58.401536Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"!cat /kaggle/input/download-common-voice-swedish/cv-corpus-6.1-2020-12-11/sv-SE/test.tsv /kaggle/input/download-common-voice-swedish/cv-corpus-6.1-2020-12-11/sv-SE/dev.tsv /kaggle/input/download-common-voice-swedish/cv-corpus-6.1-2020-12-11/sv-SE/train.tsv | awk -F'\\t' '{print $3}'|grep -v '^sentence$' | sort| uniq > /kaggle/working/sentences.txt\n","metadata":{"execution":{"iopub.status.busy":"2021-05-25T22:55:06.647476Z","iopub.execute_input":"2021-05-25T22:55:06.647866Z","iopub.status.idle":"2021-05-25T22:55:07.423370Z","shell.execute_reply.started":"2021-05-25T22:55:06.647826Z","shell.execute_reply":"2021-05-25T22:55:07.422248Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"%cd fairseq/examples/wav2vec/unsupervised","metadata":{"execution":{"iopub.status.busy":"2021-05-25T22:55:38.373562Z","iopub.execute_input":"2021-05-25T22:55:38.373954Z","iopub.status.idle":"2021-05-25T22:55:38.381414Z","shell.execute_reply.started":"2021-05-25T22:55:38.373919Z","shell.execute_reply":"2021-05-25T22:55:38.380538Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"/tmp/fairseq/examples/wav2vec/unsupervised\n","output_type":"stream"}]},{"cell_type":"code","source":"!apt-get -y install zsh","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir /kaggle/working/preppedtext","metadata":{"execution":{"iopub.status.busy":"2021-05-25T22:58:19.000154Z","iopub.execute_input":"2021-05-25T22:58:19.000630Z","iopub.status.idle":"2021-05-25T22:58:19.721915Z","shell.execute_reply.started":"2021-05-25T22:58:19.000595Z","shell.execute_reply":"2021-05-25T22:58:19.720617Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"%cd scripts","metadata":{"execution":{"iopub.status.busy":"2021-05-25T23:04:33.014283Z","iopub.execute_input":"2021-05-25T23:04:33.014836Z","iopub.status.idle":"2021-05-25T23:04:33.020563Z","shell.execute_reply.started":"2021-05-25T23:04:33.014800Z","shell.execute_reply":"2021-05-25T23:04:33.019689Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"/tmp/fairseq/examples/wav2vec/unsupervised/scripts\n","output_type":"stream"}]},{"cell_type":"code","source":"!zsh prepare_text.sh sv /kaggle/working/sentences.txt /kaggle/working/preppedtext","metadata":{"execution":{"iopub.status.busy":"2021-05-25T23:04:35.656508Z","iopub.execute_input":"2021-05-25T23:04:35.657025Z","iopub.status.idle":"2021-05-25T23:04:56.943588Z","shell.execute_reply.started":"2021-05-25T23:04:35.656994Z","shell.execute_reply":"2021-05-25T23:04:56.942613Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"sv\nsv\n/kaggle/working/sentences.txt\n/kaggle/working/preppedtext\nWarning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\nTraceback (most recent call last):\n  File \"normalize_and_filter_text.py\", line 57, in <module>\n    main()\n  File \"normalize_and_filter_text.py\", line 42, in main\n    model = ft.load_model(args.fasttext_model)\n  File \"/opt/conda/lib/python3.7/site-packages/fasttext/FastText.py\", line 441, in load_model\n    return _FastText(model_path=path)\n  File \"/opt/conda/lib/python3.7/site-packages/fasttext/FastText.py\", line 98, in __init__\n    self.f.loadModel(model_path)\nValueError: lid.187.bin cannot be opened for loading!\none is É› t \nTraceback (most recent call last):\n  File \"/tmp/fairseq/fairseq_cli/preprocess.py\", line 401, in <module>\n    cli_main()\n  File \"/tmp/fairseq/fairseq_cli/preprocess.py\", line 397, in cli_main\n    main(args)\n  File \"/tmp/fairseq/fairseq_cli/preprocess.py\", line 287, in main\n    make_all(args.source_lang, src_dict)\n  File \"/tmp/fairseq/fairseq_cli/preprocess.py\", line 255, in make_all\n    make_dataset(vocab, args.trainpref, \"train\", lang, num_workers=args.workers)\n  File \"/tmp/fairseq/fairseq_cli/preprocess.py\", line 251, in make_dataset\n    make_binary_dataset(vocab, input_prefix, output_prefix, lang, num_workers)\n  File \"/tmp/fairseq/fairseq_cli/preprocess.py\", line 184, in make_binary_dataset\n    100 * sum(replaced.values()) / n_seq_tok[1],\nZeroDivisionError: division by zero\n=== 1/5 Counting and sorting n-grams ===\nReading /kaggle/working/preppedtext/lm.upper.lid.txt\n----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\nUnigram tokens 0 types 3\n=== 2/5 Calculating and sorting adjusted counts ===\nChain sizes: 1:36 2:2571437824 3:4821446144 4:7714313728\nSubstituting fallback discounts for order 0: D1=0.5 D2=1 D3+=1.5\nSubstituting fallback discounts for order 1: D1=0.5 D2=1 D3+=1.5\nSubstituting fallback discounts for order 2: D1=0.5 D2=1 D3+=1.5\nSubstituting fallback discounts for order 3: D1=0.5 D2=1 D3+=1.5\nStatistics:\n1 2 D1=0.5 D2=1 D3+=1.5\n2 0 D1=0.5 D2=1 D3+=1.5\n3 0 D1=0.5 D2=1 D3+=1.5\n4 0 D1=0.5 D2=1 D3+=1.5\nMemory estimate for binary LM:\ntype       B\nprobing  112 assuming -p 1.5\nprobing  132 assuming -r models -p 1.5\ntrie     135 without quantization\ntrie    5248 assuming -q 8 -b 8 quantization \ntrie     181 assuming -a 22 array pointer compression\ntrie    5294 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n=== 3/5 Calculating and sorting initial probabilities ===\nChain sizes: 1:24 2:16 3:20 4:24\n----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n\n=== 4/5 Calculating and writing order-interpolated probabilities ===\nChain sizes: 1:24 2:16 3:20 4:24\n----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n\n=== 5/5 Writing ARPA model ===\n----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n\nName:lmplz\tVmPeak:14916784 kB\tVmRSS:5876 kB\tRSSMax:2957000 kB\tuser:0.414471\tsys:1.40272\tCPU:1.81725\treal:1.82204\nReading /kaggle/working/preppedtext/kenlm.wrd.o40003.arpa\n----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n****************************************************************************************************\n/tmp/kenlm/lm/vocab.cc:305 in void lm::ngram::MissingSentenceMarker(const lm::ngram::Config&, const char*) threw SpecialWordMissingException.\nThe ARPA file is missing </s> and the model is configured to reject these models.  Run build_binary -s to disable this check. Byte: 76\nERROR\npython: can't open file 'examples/speech_recognition/kaldi/kaldi_initializer.py': [Errno 2] No such file or directory\npython: can't open file 'examples/speech_recognition/kaldi/kaldi_initializer.py': [Errno 2] No such file or directory\n=== 1/5 Counting and sorting n-grams ===\nReading /kaggle/working/preppedtext/phones/lm.phones.filtered.txt\n----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\nUnigram tokens 0 types 3\n=== 2/5 Calculating and sorting adjusted counts ===\nChain sizes: 1:36 2:2571437824 3:4821446144 4:7714313728\nSubstituting fallback discounts for order 0: D1=0.5 D2=1 D3+=1.5\nSubstituting fallback discounts for order 1: D1=0.5 D2=1 D3+=1.5\nSubstituting fallback discounts for order 2: D1=0.5 D2=1 D3+=1.5\nSubstituting fallback discounts for order 3: D1=0.5 D2=1 D3+=1.5\nStatistics:\n1 2 D1=0.5 D2=1 D3+=1.5\n2 0 D1=0.5 D2=1 D3+=1.5\n3 0 D1=0.5 D2=1 D3+=1.5\n4 0 D1=0.5 D2=1 D3+=1.5\nMemory estimate for binary LM:\ntype       B\nprobing  112 assuming -p 1.5\nprobing  132 assuming -r models -p 1.5\ntrie     135 without quantization\ntrie    5248 assuming -q 8 -b 8 quantization \ntrie     181 assuming -a 22 array pointer compression\ntrie    5294 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n=== 3/5 Calculating and sorting initial probabilities ===\nChain sizes: 1:24 2:16 3:20 4:24\n----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n\n=== 4/5 Calculating and writing order-interpolated probabilities ===\nChain sizes: 1:24 2:16 3:20 4:24\n----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n\n=== 5/5 Writing ARPA model ===\n----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n\nName:lmplz\tVmPeak:14925980 kB\tVmRSS:5856 kB\tRSSMax:2956940 kB\tuser:0.402609\tsys:1.41751\tCPU:1.82017\treal:1.82736\nReading /kaggle/working/preppedtext/phones/lm.phones.filtered.04.arpa\n----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n****************************************************************************************************\n/tmp/kenlm/lm/vocab.cc:305 in void lm::ngram::MissingSentenceMarker(const lm::ngram::Config&, const char*) threw SpecialWordMissingException.\nThe ARPA file is missing </s> and the model is configured to reject these models.  Run build_binary -s to disable this check. Byte: 76\nERROR\n=== 1/5 Counting and sorting n-grams ===\nReading /kaggle/working/preppedtext/phones/lm.phones.filtered.txt\n----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\nUnigram tokens 0 types 3\n=== 2/5 Calculating and sorting adjusted counts ===\nChain sizes: 1:36 2:929673728 3:1743138176 4:2789021184 5:4067322624 6:5578042368\nSubstituting fallback discounts for order 0: D1=0.5 D2=1 D3+=1.5\nSubstituting fallback discounts for order 1: D1=0.5 D2=1 D3+=1.5\nSubstituting fallback discounts for order 2: D1=0.5 D2=1 D3+=1.5\nSubstituting fallback discounts for order 3: D1=0.5 D2=1 D3+=1.5\nSubstituting fallback discounts for order 4: D1=0.5 D2=1 D3+=1.5\nSubstituting fallback discounts for order 5: D1=0.5 D2=1 D3+=1.5\nStatistics:\n1 2 D1=0.5 D2=1 D3+=1.5\n2 0 D1=0.5 D2=1 D3+=1.5\n3 0 D1=0.5 D2=1 D3+=1.5\n4 0 D1=0.5 D2=1 D3+=1.5\n5 0 D1=0.5 D2=1 D3+=1.5\n6 0 D1=0.5 D2=1 D3+=1.5\nMemory estimate for binary LM:\ntype       B\nprobing  144 assuming -p 1.5\nprobing  172 assuming -r models -p 1.5\ntrie     169 without quantization\ntrie    9366 assuming -q 8 -b 8 quantization \ntrie     261 assuming -a 22 array pointer compression\ntrie    9458 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n=== 3/5 Calculating and sorting initial probabilities ===\nChain sizes: 1:24 2:16 3:20 4:24 5:28 6:32\n----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n\n=== 4/5 Calculating and writing order-interpolated probabilities ===\nChain sizes: 1:24 2:16 3:20 4:24 5:28 6:32\n----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n\n=== 5/5 Writing ARPA model ===\n----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n\nName:lmplz\tVmPeak:14949572 kB\tVmRSS:6080 kB\tRSSMax:2336916 kB\tuser:0.324694\tsys:1.11892\tCPU:1.44367\treal:1.44809\nReading /kaggle/working/preppedtext/phones/lm.phones.filtered.06.arpa\n----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n****************************************************************************************************\n/tmp/kenlm/lm/vocab.cc:305 in void lm::ngram::MissingSentenceMarker(const lm::ngram::Config&, const char*) threw SpecialWordMissingException.\nThe ARPA file is missing </s> and the model is configured to reject these models.  Run build_binary -s to disable this check. Byte: 96\nERROR\nPrimary config directory not found.\nCheck that the config directory '/tmp/fairseq/examples/speech_recognition/kaldi/config' exists and readable\n\nSet the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n","output_type":"stream"}]}]}