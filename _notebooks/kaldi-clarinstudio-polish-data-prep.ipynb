{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imported-ballot",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T19:30:33.220475Z",
     "iopub.status.busy": "2021-05-24T19:30:33.219576Z",
     "iopub.status.idle": "2021-05-24T19:30:33.224753Z",
     "shell.execute_reply": "2021-05-24T19:30:33.224207Z",
     "shell.execute_reply.started": "2021-05-24T18:49:20.935816Z"
    },
    "papermill": {
     "duration": 0.024828,
     "end_time": "2021-05-24T19:30:33.224910",
     "exception": false,
     "start_time": "2021-05-24T19:30:33.200082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt\n"
     ]
    }
   ],
   "source": [
    "%cd /opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "assisted-funeral",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T19:30:33.252714Z",
     "iopub.status.busy": "2021-05-24T19:30:33.252116Z",
     "iopub.status.idle": "2021-05-24T19:30:33.995433Z",
     "shell.execute_reply": "2021-05-24T19:30:33.994956Z",
     "shell.execute_reply.started": "2021-05-24T18:50:27.242561Z"
    },
    "papermill": {
     "duration": 0.757883,
     "end_time": "2021-05-24T19:30:33.995581",
     "exception": false,
     "start_time": "2021-05-24T19:30:33.237698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find: ‘kaldi’: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!find kaldi -name phonetisaurus-apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "multiple-amsterdam",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-05-24T19:30:34.029041Z",
     "iopub.status.busy": "2021-05-24T19:30:34.024542Z",
     "iopub.status.idle": "2021-05-24T19:31:10.372590Z",
     "shell.execute_reply": "2021-05-24T19:31:10.373254Z",
     "shell.execute_reply.started": "2021-05-24T18:49:44.320795Z"
    },
    "papermill": {
     "duration": 36.366612,
     "end_time": "2021-05-24T19:31:10.373439",
     "exception": false,
     "start_time": "2021-05-24T19:30:34.006827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!tar xvf /kaggle/input/extract-prebuilt-kaldi-from-docker/kaldi.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "celtic-belly",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T19:31:10.399634Z",
     "iopub.status.busy": "2021-05-24T19:31:10.399050Z",
     "iopub.status.idle": "2021-05-24T19:31:10.405477Z",
     "shell.execute_reply": "2021-05-24T19:31:10.405052Z",
     "shell.execute_reply.started": "2021-05-24T18:50:35.686028Z"
    },
    "papermill": {
     "duration": 0.020034,
     "end_time": "2021-05-24T19:31:10.405609",
     "exception": false,
     "start_time": "2021-05-24T19:31:10.385575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/kaldi/egs\n"
     ]
    }
   ],
   "source": [
    "%cd kaldi/egs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "insured-agent",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T19:31:10.432429Z",
     "iopub.status.busy": "2021-05-24T19:31:10.431888Z",
     "iopub.status.idle": "2021-05-24T19:31:15.677366Z",
     "shell.execute_reply": "2021-05-24T19:31:15.677864Z",
     "shell.execute_reply.started": "2021-05-24T18:50:39.248768Z"
    },
    "papermill": {
     "duration": 5.261076,
     "end_time": "2021-05-24T19:31:15.678032",
     "exception": false,
     "start_time": "2021-05-24T19:31:10.416956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ClarinStudioKaldi'...\r\n",
      "remote: Enumerating objects: 778, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (3/3), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (3/3), done.\u001b[K\r\n",
      "remote: Total 778 (delta 0), reused 0 (delta 0), pack-reused 775\u001b[K\r\n",
      "Receiving objects: 100% (778/778), 35.26 MiB | 45.94 MiB/s, done.\r\n",
      "Resolving deltas: 100% (262/262), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/danijel3/ClarinStudioKaldi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "persistent-keyboard",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T19:31:15.710216Z",
     "iopub.status.busy": "2021-05-24T19:31:15.709584Z",
     "iopub.status.idle": "2021-05-24T19:31:15.716085Z",
     "shell.execute_reply": "2021-05-24T19:31:15.715569Z",
     "shell.execute_reply.started": "2021-05-24T18:50:45.624159Z"
    },
    "papermill": {
     "duration": 0.023885,
     "end_time": "2021-05-24T19:31:15.716244",
     "exception": false,
     "start_time": "2021-05-24T19:31:15.692359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/kaldi/egs/ClarinStudioKaldi\n"
     ]
    }
   ],
   "source": [
    "%cd ClarinStudioKaldi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ready-sense",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T19:31:15.751372Z",
     "iopub.status.busy": "2021-05-24T19:31:15.748044Z",
     "iopub.status.idle": "2021-05-24T19:33:33.093288Z",
     "shell.execute_reply": "2021-05-24T19:33:33.093692Z",
     "shell.execute_reply.started": "2021-05-24T18:50:45.632869Z"
    },
    "papermill": {
     "duration": 137.363693,
     "end_time": "2021-05-24T19:33:33.093912",
     "exception": false,
     "start_time": "2021-05-24T19:31:15.730219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\r\n",
      "Solving environment: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\r\n",
      "\r\n",
      "## Package Plan ##\r\n",
      "\r\n",
      "  environment location: /opt/conda\r\n",
      "\r\n",
      "  added / updated specs:\r\n",
      "    - perl-perlio-gzip\r\n",
      "\r\n",
      "\r\n",
      "The following packages will be downloaded:\r\n",
      "\r\n",
      "    package                    |            build\r\n",
      "    ---------------------------|-----------------\r\n",
      "    perl-5.26.2                |    h36c2ea0_1008        15.4 MB  conda-forge\r\n",
      "    perl-perlio-gzip-0.20      |  pl526h84994c4_1          17 KB  bioconda\r\n",
      "    ------------------------------------------------------------\r\n",
      "                                           Total:        15.4 MB\r\n",
      "\r\n",
      "The following NEW packages will be INSTALLED:\r\n",
      "\r\n",
      "  perl-perlio-gzip   bioconda/linux-64::perl-perlio-gzip-0.20-pl526h84994c4_1\r\n",
      "\r\n",
      "The following packages will be DOWNGRADED:\r\n",
      "\r\n",
      "  perl                                    5.32.0-h36c2ea0_0 --> 5.26.2-h36c2ea0_1008\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "Downloading and Extracting Packages\r\n",
      "perl-5.26.2          | 15.4 MB   | ##################################### | 100% \r\n",
      "perl-perlio-gzip-0.2 | 17 KB     | ##################################### | 100% \r\n",
      "Preparing transaction: / \b\bdone\r\n",
      "Verifying transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\r\n",
      "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\r\n"
     ]
    }
   ],
   "source": [
    "!conda install -c bioconda perl-perlio-gzip -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "developmental-familiar",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T19:33:33.468562Z",
     "iopub.status.busy": "2021-05-24T19:33:33.467656Z",
     "iopub.status.idle": "2021-05-24T19:33:33.470515Z",
     "shell.execute_reply": "2021-05-24T19:33:33.470039Z",
     "shell.execute_reply.started": "2021-05-24T18:53:22.616551Z"
    },
    "papermill": {
     "duration": 0.191387,
     "end_time": "2021-05-24T19:33:33.470639",
     "exception": false,
     "start_time": "2021-05-24T19:33:33.279252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['LD_LIBRARY_PATH'] = '/opt/conda/lib:/opt/kaldi/tools/openfst-1.6.7/lib:/opt/kaldi/src/lib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "saved-theater",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T19:33:33.849280Z",
     "iopub.status.busy": "2021-05-24T19:33:33.848571Z",
     "iopub.status.idle": "2021-05-24T19:33:35.303708Z",
     "shell.execute_reply": "2021-05-24T19:33:35.304141Z",
     "shell.execute_reply.started": "2021-05-24T18:53:22.626466Z"
    },
    "papermill": {
     "duration": 1.650197,
     "end_time": "2021-05-24T19:33:35.304332",
     "exception": false,
     "start_time": "2021-05-24T19:33:33.654135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cat path.sh|sed -e 's/~\\/apps/\\/opt/' > tmp\n",
    "!mv tmp path.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "creative-rally",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T19:33:35.681112Z",
     "iopub.status.busy": "2021-05-24T19:33:35.680183Z",
     "iopub.status.idle": "2021-05-24T19:33:36.410959Z",
     "shell.execute_reply": "2021-05-24T19:33:36.411416Z",
     "shell.execute_reply.started": "2021-05-24T18:53:24.098924Z"
    },
    "papermill": {
     "duration": 0.91987,
     "end_time": "2021-05-24T19:33:36.411580",
     "exception": false,
     "start_time": "2021-05-24T19:33:35.491710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!echo > local_clarin/clarin_pl_clean.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "completed-apple",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T19:33:36.798574Z",
     "iopub.status.busy": "2021-05-24T19:33:36.794473Z",
     "iopub.status.idle": "2021-05-24T19:33:38.238626Z",
     "shell.execute_reply": "2021-05-24T19:33:38.239065Z",
     "shell.execute_reply.started": "2021-05-24T18:53:24.820866Z"
    },
    "papermill": {
     "duration": 1.639946,
     "end_time": "2021-05-24T19:33:38.239246",
     "exception": false,
     "start_time": "2021-05-24T19:33:36.599300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir /kaggle/working/data\n",
    "!ln -s /kaggle/working/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "electronic-madonna",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T19:33:38.612581Z",
     "iopub.status.busy": "2021-05-24T19:33:38.612036Z",
     "iopub.status.idle": "2021-05-24T19:33:39.399511Z",
     "shell.execute_reply": "2021-05-24T19:33:39.398290Z",
     "shell.execute_reply.started": "2021-05-24T19:06:01.081036Z"
    },
    "papermill": {
     "duration": 0.975037,
     "end_time": "2021-05-24T19:33:39.399692",
     "exception": false,
     "start_time": "2021-05-24T19:33:38.424655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/kaldi/tools/phonetisaurus-g2p/phonetisaurus-g2pfst\r\n"
     ]
    }
   ],
   "source": [
    "!find /opt/kaldi -name phonetisaurus-g2pfst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "serial-orlando",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T19:33:39.811279Z",
     "iopub.status.busy": "2021-05-24T19:33:39.810179Z",
     "iopub.status.idle": "2021-05-24T19:33:39.815490Z",
     "shell.execute_reply": "2021-05-24T19:33:39.814793Z",
     "shell.execute_reply.started": "2021-05-24T19:29:00.984873Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.199839,
     "end_time": "2021-05-24T19:33:39.815684",
     "exception": false,
     "start_time": "2021-05-24T19:33:39.615845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /opt/kaldi/tools/phonetisaurus-g2p/src/scripts/phonetisaurus-apply\n"
     ]
    }
   ],
   "source": [
    "%%writefile /opt/kaldi/tools/phonetisaurus-g2p/src/scripts/phonetisaurus-apply\n",
    "#!/usr/bin/env python\n",
    "# -*- mode: python; coding: utf-8 -*-\n",
    "\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import os, logging, subprocess, time, re\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import tempfile\n",
    "\n",
    "class G2PModelTester () :\n",
    "    \"\"\"G2P Model training wrapper class.\n",
    "\n",
    "    Phonetisaurus G2P modeling training wrapper class.\n",
    "    This wraps the alignment, joint n-gram training, and ARPA to\n",
    "    WFST conversion steps into one command.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__ (self, model, **kwargs) :\n",
    "        self.model = model\n",
    "        self.lexicon_file = kwargs.get (\"lexicon\", None)\n",
    "        self.nbest = kwargs.get (\"nbest\", 1)\n",
    "        self.thresh = kwargs.get (\"thresh\", 99)\n",
    "        self.beam = kwargs.get (\"beam\", 10000)\n",
    "        self.greedy = kwargs.get (\"greedy\", False)\n",
    "        self.accumulate = kwargs.get (\"accumulate\", False)\n",
    "        self.pmass = kwargs.get (\"pmass\", 0.0)\n",
    "        self.probs = kwargs.get (\"probs\", False)\n",
    "        self.verbose = kwargs.get (\"verbose\", False)\n",
    "        self.logger = self.setupLogger ()\n",
    "\n",
    "    def setupLogger (self) :\n",
    "        \"\"\"Setup the logger and logging level.\n",
    "\n",
    "        Setup the logger and logging level.  We only support\n",
    "        verbose and non-verbose mode.\n",
    "\n",
    "        Args:\n",
    "            verbose (bool): Verbose mode, or not.\n",
    "\n",
    "        Returns:\n",
    "            Logger: A configured logger instance.\n",
    "        \"\"\"\n",
    "\n",
    "        level = logging.DEBUG if self.verbose else logging.INFO\n",
    "        logging.basicConfig (\n",
    "            level=level,\n",
    "            format=\"\\033[94m%(levelname)s:%(name)s:\"\\\n",
    "            \"%(asctime)s\\033[0m:  %(message)s\",\n",
    "            datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    "        )\n",
    "\n",
    "        return logging.getLogger (\"phonetisaurus-apply\")\n",
    "\n",
    "    def _loadLexicon (self) :\n",
    "        \"\"\"Load the lexicon from a file.\n",
    "\n",
    "        Load the reference lexicon from a file, and store it\n",
    "        in a defaultdict (list).\n",
    "        \"\"\"\n",
    "\n",
    "        _lexicon = defaultdict (list)\n",
    "        if not self.lexicon_file :\n",
    "            return _lexicon\n",
    "\n",
    "        self.logger.debug (\"Loading lexicon from file...\")\n",
    "        with open (self.lexicon_file, \"r\") as ifp :\n",
    "            for line in ifp :\n",
    "                # py2py3 compatbility,\n",
    "                if sys.version_info[0] < 3:\n",
    "                    line = line.decode(\"utf8\").strip ()\n",
    "                else:\n",
    "                    line = line.strip ()\n",
    "                word, pron = re.split (r\"\\t\", line, 1)\n",
    "                _lexicon [word].append (pron)\n",
    "\n",
    "        return _lexicon\n",
    "\n",
    "    def checkPhonetisaurusConfig (self) :\n",
    "        \"\"\"Run some basic checks before training.\n",
    "\n",
    "        Run some basic checks regarding the $PATH, environment,\n",
    "        and provided data before starting training.\n",
    "\n",
    "        Raises:\n",
    "            EnvironmentError: raised if binaries are not found.\n",
    "        \"\"\"\n",
    "\n",
    "        self.logger.debug (\"Checking command configuration...\")\n",
    "        for program in [\"phonetisaurus-g2pfst\"] :\n",
    "            if not self.which (program) :\n",
    "                raise EnvironmentError(\"Phonetisaurus command, '{0}', \"\\\n",
    "                    \"not found in path.\".format (program))\n",
    "\n",
    "        if self.lexicon_file and not os.path.exists (self.lexicon_file) :\n",
    "            self.logger.error (\"Could not find provided lexicon file.\")\n",
    "            sys.exit (1)\n",
    "\n",
    "        for key,val in sorted (vars (self).items ()) :\n",
    "            self.logger.debug (u\"{0}:  {1}\".format (key, val))\n",
    "\n",
    "        self.lexicon = self._loadLexicon ()\n",
    "\n",
    "        return\n",
    "\n",
    "    def which (self, program) :\n",
    "        \"\"\"Basic 'which' implementation for python.\n",
    "\n",
    "        Basic 'which' implementation for python from stackoverflow:\n",
    "          * https://stackoverflow.com/a/377028/6739158\n",
    "\n",
    "        Args:\n",
    "            program (str): The program name to search the $PATH for.\n",
    "\n",
    "        Returns:\n",
    "            path/None: The path to the executable, or None.\n",
    "        \"\"\"\n",
    "\n",
    "        def is_exe (fpath) :\n",
    "            return os.path.isfile (fpath) and os.access (fpath, os.X_OK)\n",
    "\n",
    "        fpath, fname = os.path.split (program)\n",
    "        if fpath:\n",
    "            if is_exe (program):\n",
    "                return program\n",
    "        else:\n",
    "            for path in os.environ[\"PATH\"].split (os.pathsep) :\n",
    "                path = path.strip ('\"')\n",
    "                exe_file = os.path.join (path, program)\n",
    "                if is_exe (exe_file):\n",
    "                    return exe_file\n",
    "\n",
    "        return None\n",
    "\n",
    "    def makeG2PCommand (self, word_list) :\n",
    "        \"\"\"Build the G2P command.\n",
    "\n",
    "        Build the G2P command from the provided arguments.\n",
    "\n",
    "        Returns:\n",
    "            list: The command in subprocess list format.\n",
    "        \"\"\"\n",
    "\n",
    "        command = [\n",
    "            u\"phonetisaurus-g2pfst\",\n",
    "            u\"--model={0}\".format (self.model),\n",
    "            u\"--nbest={0}\".format (self.nbest),\n",
    "            u\"--beam={0}\".format (self.beam),\n",
    "            u\"--thresh={0}\".format (self.thresh),\n",
    "            u\"--accumulate={0}\".format (str (self.accumulate).lower ()),\n",
    "            u\"--pmass={0}\".format (self.pmass),\n",
    "            u\"--nlog_probs={0}\".format (str(not self.probs).lower ()),\n",
    "            u\"--wordlist={0}\".format (word_list)\n",
    "        ]\n",
    "\n",
    "        self.logger.debug (u\" \".join (command))\n",
    "\n",
    "        return command\n",
    "\n",
    "    def runG2PCommand (self, word_list_file) :\n",
    "        \"\"\"Generate and run the actual G2P command.\n",
    "\n",
    "        Generate and run the actual G2P command.  Each synthesized\n",
    "        entry will be yielded back on-the-fly via the subprocess\n",
    "        stdout readline method.\n",
    "\n",
    "        Args:\n",
    "            word_list_file (str): The input word list.\n",
    "        \"\"\"\n",
    "        g2p_command = self.makeG2PCommand (word_list_file)\n",
    "\n",
    "        self.logger.debug (\"Applying G2P model...\")\n",
    "\n",
    "        with open (os.devnull, \"w\") as devnull :\n",
    "            proc = subprocess.Popen (\n",
    "                g2p_command,\n",
    "                stdout=subprocess.PIPE,\n",
    "                stderr=devnull if not self.verbose else None\n",
    "            )\n",
    "\n",
    "            for line in proc.stdout :\n",
    "                parts = re.split (r\"\\t\", line.decode (\"utf8\").strip ())\n",
    "                if not len (parts) == 3 :\n",
    "                    self.logger.warning (\n",
    "                        u\"No pronunciation for word: '{0}'\".format (parts [0])\n",
    "                    )\n",
    "                    continue\n",
    "\n",
    "                yield parts\n",
    "\n",
    "        return\n",
    "\n",
    "    def applyG2POnly (self, word_list_file) :\n",
    "        \"\"\"Apply the G2P model to a word list.\n",
    "\n",
    "        Apply the G2P model to a word list.  No filtering or application\n",
    "        of a reference lexicon is used here.\n",
    "\n",
    "        Args:\n",
    "            word_list_file (str): The input word list.\n",
    "        \"\"\"\n",
    "        for word, score, pron in self.runG2PCommand (word_list_file) :\n",
    "            line = u\"\"\n",
    "            if self.verbose :\n",
    "                line = u\"{0}\\t{1:.2f}\\t{2}\".format (\n",
    "                    word, float (score), pron\n",
    "                )\n",
    "            else :\n",
    "                line = u\"{0}\\t{1}\".format (word, pron)\n",
    "            # py2py3 compatbility,\n",
    "            if sys.version_info[0] < 3:\n",
    "                print (line.encode (\"utf8\"))\n",
    "            else :\n",
    "                print (line)\n",
    "\n",
    "        return\n",
    "\n",
    "    def applyG2PWithLexicon (self, word_list_file) :\n",
    "        \"\"\"Apply the G2P model to a word list, combined with lexicon.\n",
    "\n",
    "        Apply the G2P model to a word list, but combine this with\n",
    "        a reference lexicon.  Words for which a reference entry exists\n",
    "        will not be sent to the G2P, unless the additional '--greedy'\n",
    "        flag is set to True.\n",
    "\n",
    "        Args:\n",
    "            word_list_file (str): The input word list.\n",
    "        \"\"\"\n",
    "        target_lexicon = defaultdict (list)\n",
    "        tmpwordlist = tempfile.NamedTemporaryFile(mode='w', delete=False)\n",
    "\n",
    "        #First, find any words in the target list for which we already\n",
    "        # have a canonical pronunciation in the reference lexicon.\n",
    "        with open (word_list_file, \"r\") as ifp :\n",
    "            for word in ifp :\n",
    "                # py2py3 compatbility,\n",
    "                if sys.version_info[0] < 3:\n",
    "                    word = word.decode (\"utf8\").strip ()\n",
    "                else:\n",
    "                    word = word.strip () # already in 'utf8'.\n",
    "                if word in self.lexicon :\n",
    "                    target_lexicon [word] = [(0.0,pron)\n",
    "                                             for pron in self.lexicon [word]]\n",
    "                    #In greedy mode we still send words to the G2P, even\n",
    "                    # if we have canonical entries in the reference lexicon.\n",
    "                    if self.greedy :\n",
    "                        print (word.encode (\"utf8\"), file=tmpwordlist)\n",
    "                else :\n",
    "                    # py2py3 compatbility,\n",
    "                    if sys.version_info[0] < 3:\n",
    "                        print (word.encode (\"utf8\"), file=tmpwordlist)\n",
    "                    else:\n",
    "                        print (word, file=tmpwordlist)\n",
    "        tmpwordlist.close ()\n",
    "\n",
    "        #Second, iterate through the G2P output, and filter against\n",
    "        # any possible duplicates previously found in the reference lexicon.\n",
    "        for word, score, pron in self.runG2PCommand (tmpwordlist.name) :\n",
    "            prons = set ([p for s,p in target_lexicon [word]])\n",
    "            if pron in prons :\n",
    "                continue\n",
    "            target_lexicon [word].append ((score, pron))\n",
    "\n",
    "        #Finally, sort everything that is left and print it.\n",
    "        for word in sorted (target_lexicon.keys ()) :\n",
    "            for score, pron in target_lexicon [word] :\n",
    "                line = u\"\"\n",
    "                if self.verbose :\n",
    "                    line = u\"{0}\\t{1:.2f}\\t{2}\".format (\n",
    "                        word, float (score), pron\n",
    "                    )\n",
    "                else :\n",
    "                    line = u\"{0}\\t{1}\".format (word, pron)\n",
    "                # py2py3 compatbility,\n",
    "                if sys.version_info[0] < 3:\n",
    "                    print (line.encode (\"utf8\"))\n",
    "                else :\n",
    "                    print (line)\n",
    "\n",
    "        os.unlink (tmpwordlist.name)\n",
    "        return\n",
    "\n",
    "    def ApplyG2PModel (self, word_list_file) :\n",
    "        \"\"\"Apply the G2P model to a word list.\n",
    "\n",
    "        Apply the G2P model to a word list.\n",
    "\n",
    "        Args:\n",
    "            word_list_file (str): The input word list.\n",
    "        \"\"\"\n",
    "        self.checkPhonetisaurusConfig ()\n",
    "\n",
    "        if not os.path.exists (word_list_file) \\\n",
    "           or not os.path.isfile (word_list_file) :\n",
    "            raise IOError(\"Word list file not found.\")\n",
    "\n",
    "        if len (self.lexicon) == 0 :\n",
    "            self.applyG2POnly (word_list_file)\n",
    "        else :\n",
    "            self.applyG2PWithLexicon (word_list_file)\n",
    "\n",
    "        return\n",
    "\n",
    "if __name__ == \"__main__\" :\n",
    "    import sys, argparse\n",
    "\n",
    "    example = \"{0} --model train/model.fst --word test\".format (sys.argv [0])\n",
    "\n",
    "    parser  = argparse.ArgumentParser (description=example)\n",
    "    parser.add_argument (\"--model\", \"-m\", help=\"Phonetisaurus G2P fst model.\",\n",
    "                         required=True)\n",
    "    parser.add_argument (\"--lexicon\", \"-l\", help=\"Optional reference lexicon.\",\n",
    "                         required=False)\n",
    "    parser.add_argument (\"--nbest\", \"-n\", help=\"Maximum number of hypotheses \"\n",
    "                         \"to produce.  Overridden if --pmass is set.\",\n",
    "                         default=1, type=int)\n",
    "    parser.add_argument (\"--beam\", \"-b\", help=\"Search 'beam'.\",\n",
    "                         default=10000, type=int)\n",
    "    parser.add_argument (\"--thresh\", \"-t\", help=\"Pruning threshold for n-best.\",\n",
    "                         default=99.0, type=float)\n",
    "    parser.add_argument (\"--greedy\", \"-g\", help=\"Use the G2P even if a \"\n",
    "                         \"reference lexicon has been provided.\", default=False,\n",
    "                         action=\"store_true\")\n",
    "    parser.add_argument (\"--accumulate\", \"-a\", help=\"Accumulate probabilities \"\n",
    "                         \"across unique pronunciations.\", default=False,\n",
    "                         action=\"store_true\")\n",
    "    parser.add_argument (\"--pmass\", \"-p\", help=\"Select the maximum number of \"\n",
    "                         \"hypotheses summing to P total mass for a word.\",\n",
    "                         default=0.0, type=float)\n",
    "    parser.add_argument (\"--probs\", \"-pr\", help=\"Print exp(-val) \"\n",
    "                         \"instead of default -log values.\", default=False,\n",
    "                         action=\"store_true\")\n",
    "    parser.add_argument (\"--word_list\", \"-wl\", help=\"Input word or word list to apply \"\n",
    "                        \"G2P model to.\", type=str)\n",
    "\n",
    "    parser.add_argument (\"--verbose\", \"-v\", help=\"Verbose mode.\",\n",
    "                         default=False, action=\"store_true\")\n",
    "    args = parser.parse_args ()\n",
    "\n",
    "    tester = G2PModelTester (\n",
    "        args.model,\n",
    "        **{key:val for key,val in args.__dict__.items ()\n",
    "           if not key in [\"model\",\"word_list\"]}\n",
    "    )\n",
    "\n",
    "    tester.ApplyG2PModel (args.word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "polar-arbitration",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T19:33:40.206296Z",
     "iopub.status.busy": "2021-05-24T19:33:40.202368Z",
     "iopub.status.idle": "2021-05-24T19:33:40.922195Z",
     "shell.execute_reply": "2021-05-24T19:33:40.921692Z",
     "shell.execute_reply.started": "2021-05-24T19:29:14.641765Z"
    },
    "papermill": {
     "duration": 0.909097,
     "end_time": "2021-05-24T19:33:40.922336",
     "exception": false,
     "start_time": "2021-05-24T19:33:40.013239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!chmod a+x /opt/kaldi/tools/phonetisaurus-g2p/src/scripts/phonetisaurus-apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "healthy-efficiency",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T19:33:41.305818Z",
     "iopub.status.busy": "2021-05-24T19:33:41.304860Z",
     "iopub.status.idle": "2021-05-24T19:33:41.309486Z",
     "shell.execute_reply": "2021-05-24T19:33:41.310092Z",
     "shell.execute_reply.started": "2021-05-24T17:53:11.754933Z"
    },
    "papermill": {
     "duration": 0.196787,
     "end_time": "2021-05-24T19:33:41.310315",
     "exception": false,
     "start_time": "2021-05-24T19:33:41.113528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing runmfcc.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile runmfcc.sh\n",
    "#!/bin/bash\n",
    "\n",
    ". ./path.sh ## set the paths in this file correctly!\n",
    "\n",
    "# link to scripts from the standard Kaldi distribution\n",
    "# we try to use these as much as possible\n",
    "if [ ! -f $KALDI_ROOT/egs/wsj/s5/conf ] ; then ln -s $KALDI_ROOT/egs/wsj/s5/conf ; fi\n",
    "if [ ! -f $KALDI_ROOT/egs/wsj/s5/local ] ; then ln -s $KALDI_ROOT/egs/wsj/s5/local ; fi\n",
    "if [ ! -f $KALDI_ROOT/egs/wsj/s5/utils ] ; then ln -s $KALDI_ROOT/egs/wsj/s5/utils ; fi\n",
    "if [ ! -f $KALDI_ROOT/egs/wsj/s5/steps ] ; then ln -s $KALDI_ROOT/egs/wsj/s5/steps ; fi\n",
    "\n",
    "# exits script if error occurs anywhere\n",
    "# you might not want to do this for interactive shells.\n",
    "set -e\n",
    "\n",
    "export nj=40 ##number of concurrent processes\n",
    "export nj_test=30 ## number of concurrent processes for test has to be <=30\n",
    "\n",
    "# This is a shell script, but it's recommended that you run the commands one by\n",
    "# one by copying and pasting into the shell.\n",
    "\n",
    "#run some initial data preparation (look at the file for more details):\n",
    "local_clarin/clarin_pl_data_prep.sh\n",
    "\n",
    "#prepare the lang directory\n",
    "utils/prepare_lang.sh data/local/dict_nosp \"<unk>\" data/local/tmp_nosp data/lang_nosp\n",
    "\n",
    "#make G.fst\n",
    "utils/format_lm.sh data/lang_nosp local_clarin/arpa.lm.gz data/local/dict_nosp/lexicon.txt data/lang_nosp_test\n",
    "\n",
    "# Make normalized MFCC features.\n",
    "steps/make_mfcc.sh --nj $nj data/train\n",
    "steps/compute_cmvn_stats.sh data/train\n",
    "steps/make_mfcc.sh --nj $nj data/test\n",
    "steps/compute_cmvn_stats.sh data/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "marked-wagon",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-24T19:33:41.687330Z",
     "iopub.status.busy": "2021-05-24T19:33:41.686441Z",
     "iopub.status.idle": "2021-05-24T19:42:13.424549Z",
     "shell.execute_reply": "2021-05-24T19:42:13.424004Z"
    },
    "papermill": {
     "duration": 511.927169,
     "end_time": "2021-05-24T19:42:13.424693",
     "exception": false,
     "start_time": "2021-05-24T19:33:41.497524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/kaldi/egs/ClarinStudioKaldi/audio /opt/kaldi/egs/ClarinStudioKaldi\r\n",
      "Downloading audio from the Clarin-pl website (~4.6GB)...\r\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "100 4704M  100 4704M    0     0  23.4M      0  0:03:21  0:03:21 --:--:-- 23.6M\r\n",
      "Extracting files...\r\n",
      "/opt/kaldi/egs/ClarinStudioKaldi\r\n",
      "Generating file lists using proper paths...\r\n",
      "Generating spk2utt...\r\n",
      "Preparing dictionary...\r\n",
      "local_clarin/clarin_prepare_dict.sh data/local/all.wlist data/local/dict_nosp\r\n",
      "local_clarin/clarin_prepare_dict.sh: line 72: phonetisaurus-apply: command not found\r\n",
      "Dictionary preparation succeeded\r\n",
      "utils/prepare_lang.sh data/local/dict_nosp <unk> data/local/tmp_nosp data/lang_nosp\r\n",
      "Checking data/local/dict_nosp/silence_phones.txt ...\r\n",
      "--> reading data/local/dict_nosp/silence_phones.txt\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> data/local/dict_nosp/silence_phones.txt is OK\r\n",
      "\r\n",
      "Checking data/local/dict_nosp/optional_silence.txt ...\r\n",
      "--> reading data/local/dict_nosp/optional_silence.txt\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> data/local/dict_nosp/optional_silence.txt is OK\r\n",
      "\r\n",
      "Checking data/local/dict_nosp/nonsilence_phones.txt ...\r\n",
      "--> reading data/local/dict_nosp/nonsilence_phones.txt\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> data/local/dict_nosp/nonsilence_phones.txt is OK\r\n",
      "\r\n",
      "Checking disjoint: silence_phones.txt, nonsilence_phones.txt\r\n",
      "--> disjoint property is OK.\r\n",
      "\r\n",
      "Checking data/local/dict_nosp/lexicon.txt\r\n",
      "--> reading data/local/dict_nosp/lexicon.txt\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> data/local/dict_nosp/lexicon.txt is OK\r\n",
      "\r\n",
      "Checking data/local/dict_nosp/extra_questions.txt ...\r\n",
      "--> reading data/local/dict_nosp/extra_questions.txt\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> data/local/dict_nosp/extra_questions.txt is OK\r\n",
      "--> SUCCESS [validating dictionary directory data/local/dict_nosp]\r\n",
      "\r\n",
      "**Creating data/local/dict_nosp/lexiconp.txt from data/local/dict_nosp/lexicon.txt\r\n",
      "fstaddselfloops data/lang_nosp/phones/wdisambig_phones.int data/lang_nosp/phones/wdisambig_words.int \r\n",
      "prepare_lang.sh: validating output directory\r\n",
      "utils/validate_lang.pl data/lang_nosp\r\n",
      "Checking existence of separator file\r\n",
      "separator file data/lang_nosp/subword_separator.txt is empty or does not exist, deal in word case.\r\n",
      "Checking data/lang_nosp/phones.txt ...\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> data/lang_nosp/phones.txt is OK\r\n",
      "\r\n",
      "Checking words.txt: #0 ...\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> data/lang_nosp/words.txt is OK\r\n",
      "\r\n",
      "Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...\r\n",
      "--> silence.txt and nonsilence.txt are disjoint\r\n",
      "--> silence.txt and disambig.txt are disjoint\r\n",
      "--> disambig.txt and nonsilence.txt are disjoint\r\n",
      "--> disjoint property is OK\r\n",
      "\r\n",
      "Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...\r\n",
      "--> found no unexplainable phones in phones.txt\r\n",
      "\r\n",
      "Checking data/lang_nosp/phones/context_indep.{txt, int, csl} ...\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> 5 entry/entries in data/lang_nosp/phones/context_indep.txt\r\n",
      "--> data/lang_nosp/phones/context_indep.int corresponds to data/lang_nosp/phones/context_indep.txt\r\n",
      "--> data/lang_nosp/phones/context_indep.csl corresponds to data/lang_nosp/phones/context_indep.txt\r\n",
      "--> data/lang_nosp/phones/context_indep.{txt, int, csl} are OK\r\n",
      "\r\n",
      "Checking data/lang_nosp/phones/nonsilence.{txt, int, csl} ...\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> 144 entry/entries in data/lang_nosp/phones/nonsilence.txt\r\n",
      "--> data/lang_nosp/phones/nonsilence.int corresponds to data/lang_nosp/phones/nonsilence.txt\r\n",
      "--> data/lang_nosp/phones/nonsilence.csl corresponds to data/lang_nosp/phones/nonsilence.txt\r\n",
      "--> data/lang_nosp/phones/nonsilence.{txt, int, csl} are OK\r\n",
      "\r\n",
      "Checking data/lang_nosp/phones/silence.{txt, int, csl} ...\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> 5 entry/entries in data/lang_nosp/phones/silence.txt\r\n",
      "--> data/lang_nosp/phones/silence.int corresponds to data/lang_nosp/phones/silence.txt\r\n",
      "--> data/lang_nosp/phones/silence.csl corresponds to data/lang_nosp/phones/silence.txt\r\n",
      "--> data/lang_nosp/phones/silence.{txt, int, csl} are OK\r\n",
      "\r\n",
      "Checking data/lang_nosp/phones/optional_silence.{txt, int, csl} ...\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> 1 entry/entries in data/lang_nosp/phones/optional_silence.txt\r\n",
      "--> data/lang_nosp/phones/optional_silence.int corresponds to data/lang_nosp/phones/optional_silence.txt\r\n",
      "--> data/lang_nosp/phones/optional_silence.csl corresponds to data/lang_nosp/phones/optional_silence.txt\r\n",
      "--> data/lang_nosp/phones/optional_silence.{txt, int, csl} are OK\r\n",
      "\r\n",
      "Checking data/lang_nosp/phones/disambig.{txt, int, csl} ...\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> 2 entry/entries in data/lang_nosp/phones/disambig.txt\r\n",
      "--> data/lang_nosp/phones/disambig.int corresponds to data/lang_nosp/phones/disambig.txt\r\n",
      "--> data/lang_nosp/phones/disambig.csl corresponds to data/lang_nosp/phones/disambig.txt\r\n",
      "--> data/lang_nosp/phones/disambig.{txt, int, csl} are OK\r\n",
      "\r\n",
      "Checking data/lang_nosp/phones/roots.{txt, int} ...\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> 37 entry/entries in data/lang_nosp/phones/roots.txt\r\n",
      "--> data/lang_nosp/phones/roots.int corresponds to data/lang_nosp/phones/roots.txt\r\n",
      "--> data/lang_nosp/phones/roots.{txt, int} are OK\r\n",
      "\r\n",
      "Checking data/lang_nosp/phones/sets.{txt, int} ...\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> 37 entry/entries in data/lang_nosp/phones/sets.txt\r\n",
      "--> data/lang_nosp/phones/sets.int corresponds to data/lang_nosp/phones/sets.txt\r\n",
      "--> data/lang_nosp/phones/sets.{txt, int} are OK\r\n",
      "\r\n",
      "Checking data/lang_nosp/phones/extra_questions.{txt, int} ...\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> 11 entry/entries in data/lang_nosp/phones/extra_questions.txt\r\n",
      "--> data/lang_nosp/phones/extra_questions.int corresponds to data/lang_nosp/phones/extra_questions.txt\r\n",
      "--> data/lang_nosp/phones/extra_questions.{txt, int} are OK\r\n",
      "\r\n",
      "Checking data/lang_nosp/phones/word_boundary.{txt, int} ...\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> 149 entry/entries in data/lang_nosp/phones/word_boundary.txt\r\n",
      "--> data/lang_nosp/phones/word_boundary.int corresponds to data/lang_nosp/phones/word_boundary.txt\r\n",
      "--> data/lang_nosp/phones/word_boundary.{txt, int} are OK\r\n",
      "\r\n",
      "Checking optional_silence.txt ...\r\n",
      "--> reading data/lang_nosp/phones/optional_silence.txt\r\n",
      "--> data/lang_nosp/phones/optional_silence.txt is OK\r\n",
      "\r\n",
      "Checking disambiguation symbols: #0 and #1\r\n",
      "--> data/lang_nosp/phones/disambig.txt has \"#0\" and \"#1\"\r\n",
      "--> data/lang_nosp/phones/disambig.txt is OK\r\n",
      "\r\n",
      "Checking topo ...\r\n",
      "\r\n",
      "Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...\r\n",
      "--> data/lang_nosp/phones/word_boundary.txt doesn't include disambiguation symbols\r\n",
      "--> data/lang_nosp/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt\r\n",
      "--> data/lang_nosp/phones/word_boundary.txt is OK\r\n",
      "\r\n",
      "Checking word-level disambiguation symbols...\r\n",
      "--> data/lang_nosp/phones/wdisambig.txt exists (newer prepare_lang.sh)\r\n",
      "Checking word_boundary.int and disambig.int\r\n",
      "--> generating a 79 word/subword sequence\r\n",
      "--> resulting phone sequence from L.fst corresponds to the word sequence\r\n",
      "--> L.fst is OK\r\n",
      "--> generating a 13 word/subword sequence\r\n",
      "--> resulting phone sequence from L_disambig.fst corresponds to the word sequence\r\n",
      "--> L_disambig.fst is OK\r\n",
      "\r\n",
      "Checking data/lang_nosp/oov.{txt, int} ...\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> 1 entry/entries in data/lang_nosp/oov.txt\r\n",
      "--> data/lang_nosp/oov.int corresponds to data/lang_nosp/oov.txt\r\n",
      "--> data/lang_nosp/oov.{txt, int} are OK\r\n",
      "\r\n",
      "--> data/lang_nosp/L.fst is olabel sorted\r\n",
      "--> data/lang_nosp/L_disambig.fst is olabel sorted\r\n",
      "--> SUCCESS [validating lang directory data/lang_nosp]\r\n",
      "Converting 'local_clarin/arpa.lm.gz' to FST\r\n",
      "arpa2fst --disambig-symbol=#0 --read-symbol-table=data/lang_nosp_test/words.txt - data/lang_nosp_test/G.fst \r\n",
      "LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:94) Reading \\data\\ section.\r\n",
      "LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading \\1-grams: section.\r\n",
      "WARNING (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:219) line 11 [-2.387844\ta\t-0.2394255] skipped: word 'a' not in symbol table\r\n",
      "WARNING (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:219) line 12 [-5.252399\taare\t-0.05016758] skipped: word 'aare' not in symbol table\r\n",
      "WARNING (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:219) line 13 [-4.800938\tab\t-0.01376556] skipped: word 'ab' not in symbol table\r\n",
      "WARNING (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:219) line 14 [-5.23682\tabażurem\t-0.0302294] skipped: word 'abażurem' not in symbol table\r\n",
      "WARNING (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:219) line 15 [-5.226714\tabchazję\t-0.06154328] skipped: word 'abchazję' not in symbol table\r\n",
      "WARNING (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:219) line 16 [-5.245582\tabchazów\t-0.02685788] skipped: word 'abchazów' not in symbol table\r\n",
      "WARNING (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:219) line 17 [-5.255419\taberon] skipped: word 'aberon' not in symbol table\r\n",
      "WARNING (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:219) line 18 [-5.262231\taberonowi] skipped: word 'aberonowi' not in symbol table\r\n",
      "WARNING (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:219) line 19 [-5.26215\taberracyjna] skipped: word 'aberracyjna' not in symbol table\r\n",
      "WARNING (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:219) line 20 [-5.250469\tabgarowicz] skipped: word 'abgarowicz' not in symbol table\r\n",
      "WARNING (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:219) line 21 [-4.881186\tabonament\t-0.1130914] skipped: word 'abonament' not in symbol table\r\n",
      "WARNING (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:219) line 22 [-4.876382\tabonamentu\t-0.07834942] skipped: word 'abonamentu' not in symbol table\r\n",
      "WARNING (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:219) line 23 [-5.163284\tabonamentów\t-0.06102198] skipped: word 'abonamentów' not in symbol table\r\n",
      "WARNING (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:219) line 24 [-5.184859\tabonentom\t-0.03256992] skipped: word 'abonentom' not in symbol table\r\n",
      "WARNING (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:219) line 25 [-5.010186\taborcja\t-0.1268652] skipped: word 'aborcja' not in symbol table\r\n",
      "WARNING (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:219) line 26 [-4.724734\taborcji\t-0.1546028] skipped: word 'aborcji' not in symbol table\r\n",
      "WARNING (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:219) line 27 [-5.047917\taborcję\t-0.1214982] skipped: word 'aborcję' not in symbol table\r\n",
      "WARNING (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:219) line 28 [-5.229477\tabramsa\t-0.03953429] skipped: word 'abramsa' not in symbol table\r\n",
      "WARNING (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:219) line 29 [-5.259943\tabramsy] skipped: word 'abramsy' not in symbol table\r\n",
      "WARNING (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:219) line 30 [-5.241594\tabruzji\t-0.05095416] skipped: word 'abruzji' not in symbol table\r\n",
      "WARNING (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:219) line 31 [-4.978928\tabsolutna\t-0.03940874] skipped: word 'absolutna' not in symbol table\r\n",
      "WARNING (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:219) line 32 [-5.007071\tabsolutne\t-0.04487412] skipped: word 'absolutne' not in symbol table\r\n",
      "WARNING (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:219) line 33 [-4.915956\tabsolutnej\t-0.08613706] skipped: word 'absolutnej' not in symbol table\r\n",
      "WARNING (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:219) line 34 [-4.264698\tabsolutnie\t-0.1241204] skipped: word 'absolutnie' not in symbol table\r\n",
      "WARNING (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:219) line 35 [-4.894648\tabsolutną\t-0.07766653] skipped: word 'absolutną' not in symbol table\r\n",
      "WARNING (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:219) line 36 [-4.74231\tabsolutorium\t-0.1669805] skipped: word 'absolutorium' not in symbol table\r\n",
      "WARNING (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:219) line 37 [-5.259502\tabsolutów] skipped: word 'absolutów' not in symbol table\r\n",
      "WARNING (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:219) line 38 [-4.900764\tabsolwenci\t-0.06442387] skipped: word 'absolwenci' not in symbol table\r\n",
      "WARNING (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:219) line 39 [-4.807225\tabsolwent\t-0.1084523] skipped: word 'absolwent' not in symbol table\r\n",
      "WARNING (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:219) line 40 [-5.189535\tabsolwentami\t-0.03575665] skipped: word 'absolwentami' not in symbol table\r\n",
      "LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading \\2-grams: section.\r\n",
      "LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading \\3-grams: section.\r\n",
      "WARNING (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:259) Of 1043998 parse warnings, 30 were reported. Run program with --max_warnings=-1 to see all warnings\r\n",
      "LOG (arpa2fst[5.5.0~1-2b62]:RemoveRedundantStates():arpa-lm-compiler.cc:359) Reduced num-states from 3 to 2\r\n",
      "fstisstochastic data/lang_nosp_test/G.fst \r\n",
      "2.50007 0.201763\r\n",
      "Succeeded in formatting LM: 'local_clarin/arpa.lm.gz'\r\n",
      "steps/make_mfcc.sh --nj 40 data/train\r\n",
      "utils/validate_data_dir.sh: Successfully validated data-directory data/train\r\n",
      "steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.\r\n",
      "steps/make_mfcc.sh: Succeeded creating MFCC features for train\r\n",
      "steps/compute_cmvn_stats.sh data/train\r\n",
      "Succeeded creating CMVN stats for train\r\n",
      "steps/make_mfcc.sh --nj 40 data/test\r\n",
      "utils/validate_data_dir.sh: Successfully validated data-directory data/test\r\n",
      "steps/make_mfcc.sh: [info]: no segments file exists: assuming wav.scp indexed by utterance.\r\n",
      "steps/make_mfcc.sh: Succeeded creating MFCC features for test\r\n",
      "steps/compute_cmvn_stats.sh data/test\r\n",
      "Succeeded creating CMVN stats for test\r\n"
     ]
    }
   ],
   "source": [
    "!sh runmfcc.sh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 709.15489,
   "end_time": "2021-05-24T19:42:15.178688",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-24T19:30:26.023798",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
