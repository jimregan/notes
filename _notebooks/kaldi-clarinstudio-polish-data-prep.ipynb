{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%cd /opt","metadata":{"execution":{"iopub.status.busy":"2021-05-24T18:49:20.935481Z","iopub.execute_input":"2021-05-24T18:49:20.935897Z","iopub.status.idle":"2021-05-24T18:49:20.948019Z","shell.execute_reply.started":"2021-05-24T18:49:20.935816Z","shell.execute_reply":"2021-05-24T18:49:20.946733Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/opt\n","output_type":"stream"}]},{"cell_type":"code","source":"!find kaldi -name phonetisaurus-apply","metadata":{"execution":{"iopub.status.busy":"2021-05-24T18:50:27.242215Z","iopub.execute_input":"2021-05-24T18:50:27.242609Z","iopub.status.idle":"2021-05-24T18:50:28.129658Z","shell.execute_reply.started":"2021-05-24T18:50:27.242561Z","shell.execute_reply":"2021-05-24T18:50:28.128286Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"kaldi/tools/phonetisaurus-g2p/src/scripts/phonetisaurus-apply\n","output_type":"stream"}]},{"cell_type":"code","source":"%%capture\n!tar xvf /kaggle/input/extract-prebuilt-kaldi-from-docker/kaldi.tar","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-24T18:49:44.320472Z","iopub.execute_input":"2021-05-24T18:49:44.320826Z","iopub.status.idle":"2021-05-24T18:50:22.999983Z","shell.execute_reply.started":"2021-05-24T18:49:44.320795Z","shell.execute_reply":"2021-05-24T18:50:22.997594Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"%cd kaldi/egs","metadata":{"execution":{"iopub.status.busy":"2021-05-24T18:50:35.685681Z","iopub.execute_input":"2021-05-24T18:50:35.686060Z","iopub.status.idle":"2021-05-24T18:50:35.692545Z","shell.execute_reply.started":"2021-05-24T18:50:35.686028Z","shell.execute_reply":"2021-05-24T18:50:35.691600Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"/opt/kaldi/egs\n","output_type":"stream"}]},{"cell_type":"code","source":"!git clone https://github.com/danijel3/ClarinStudioKaldi","metadata":{"execution":{"iopub.status.busy":"2021-05-24T18:50:39.248421Z","iopub.execute_input":"2021-05-24T18:50:39.248802Z","iopub.status.idle":"2021-05-24T18:50:45.621713Z","shell.execute_reply.started":"2021-05-24T18:50:39.248768Z","shell.execute_reply":"2021-05-24T18:50:45.620785Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Cloning into 'ClarinStudioKaldi'...\nremote: Enumerating objects: 778, done.\u001b[K\nremote: Counting objects: 100% (3/3), done.\u001b[K\nremote: Compressing objects: 100% (3/3), done.\u001b[K\nremote: Total 778 (delta 0), reused 0 (delta 0), pack-reused 775\u001b[K\nReceiving objects: 100% (778/778), 35.26 MiB | 10.31 MiB/s, done.\nResolving deltas: 100% (262/262), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd ClarinStudioKaldi","metadata":{"execution":{"iopub.status.busy":"2021-05-24T18:50:45.623731Z","iopub.execute_input":"2021-05-24T18:50:45.624208Z","iopub.status.idle":"2021-05-24T18:50:45.630835Z","shell.execute_reply.started":"2021-05-24T18:50:45.624159Z","shell.execute_reply":"2021-05-24T18:50:45.629900Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"/opt/kaldi/egs/ClarinStudioKaldi\n","output_type":"stream"}]},{"cell_type":"code","source":"!conda install -c bioconda perl-perlio-gzip -y","metadata":{"execution":{"iopub.status.busy":"2021-05-24T18:50:45.632578Z","iopub.execute_input":"2021-05-24T18:50:45.632899Z","iopub.status.idle":"2021-05-24T18:53:22.614352Z","shell.execute_reply.started":"2021-05-24T18:50:45.632869Z","shell.execute_reply":"2021-05-24T18:53:22.613201Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Collecting package metadata (current_repodata.json): done\nSolving environment: done\n\n## Package Plan ##\n\n  environment location: /opt/conda\n\n  added / updated specs:\n    - perl-perlio-gzip\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    perl-5.26.2                |    h36c2ea0_1008        15.4 MB  conda-forge\n    perl-perlio-gzip-0.20      |  pl526h84994c4_1          17 KB  bioconda\n    ------------------------------------------------------------\n                                           Total:        15.4 MB\n\nThe following NEW packages will be INSTALLED:\n\n  perl-perlio-gzip   bioconda/linux-64::perl-perlio-gzip-0.20-pl526h84994c4_1\n\nThe following packages will be DOWNGRADED:\n\n  perl                                    5.32.0-h36c2ea0_0 --> 5.26.2-h36c2ea0_1008\n\n\n\nDownloading and Extracting Packages\nperl-perlio-gzip-0.2 | 17 KB     | ##################################### | 100% \nperl-5.26.2          | 15.4 MB   | ##################################### | 100% \nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nos.environ['LD_LIBRARY_PATH'] = '/opt/conda/lib:/opt/kaldi/tools/openfst-1.6.7/lib:/opt/kaldi/src/lib'","metadata":{"execution":{"iopub.status.busy":"2021-05-24T18:53:22.616256Z","iopub.execute_input":"2021-05-24T18:53:22.616582Z","iopub.status.idle":"2021-05-24T18:53:22.624434Z","shell.execute_reply.started":"2021-05-24T18:53:22.616551Z","shell.execute_reply":"2021-05-24T18:53:22.620807Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"!cat path.sh|sed -e 's/~\\/apps/\\/opt/' > tmp\n!mv tmp path.sh","metadata":{"execution":{"iopub.status.busy":"2021-05-24T18:53:22.626195Z","iopub.execute_input":"2021-05-24T18:53:22.626495Z","iopub.status.idle":"2021-05-24T18:53:24.096438Z","shell.execute_reply.started":"2021-05-24T18:53:22.626466Z","shell.execute_reply":"2021-05-24T18:53:24.095132Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"!echo > local_clarin/clarin_pl_clean.sh","metadata":{"execution":{"iopub.status.busy":"2021-05-24T18:53:24.098514Z","iopub.execute_input":"2021-05-24T18:53:24.098974Z","iopub.status.idle":"2021-05-24T18:53:24.818613Z","shell.execute_reply.started":"2021-05-24T18:53:24.098924Z","shell.execute_reply":"2021-05-24T18:53:24.817536Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"!mkdir /kaggle/working/data\n!ln -s /kaggle/working/data","metadata":{"execution":{"iopub.status.busy":"2021-05-24T18:53:24.820488Z","iopub.execute_input":"2021-05-24T18:53:24.820913Z","iopub.status.idle":"2021-05-24T18:53:26.255719Z","shell.execute_reply.started":"2021-05-24T18:53:24.820866Z","shell.execute_reply":"2021-05-24T18:53:26.254598Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"!find /opt/kaldi -name phonetisaurus-g2pfst","metadata":{"execution":{"iopub.status.busy":"2021-05-24T19:06:01.080687Z","iopub.execute_input":"2021-05-24T19:06:01.081083Z","iopub.status.idle":"2021-05-24T19:06:01.848216Z","shell.execute_reply.started":"2021-05-24T19:06:01.081036Z","shell.execute_reply":"2021-05-24T19:06:01.847053Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"/opt/kaldi/tools/phonetisaurus-g2p/phonetisaurus-g2pfst\n","output_type":"stream"}]},{"cell_type":"code","source":"os.environ['PATH'] = f'{os.environ[\"PATH\"]}:/opt/kaldi/tools/phonetisaurus-g2p/'\n!echo zajefakenbiÅ›cie > /tmp/wl\n!chmod a+x /opt/kaldi/tools/phonetisaurus-g2p/src/scripts/phonetisaurus-apply\n!/opt/kaldi/tools/phonetisaurus-g2p/src/scripts/phonetisaurus-apply --model local_clarin/model.fst --lexicon local_clarin/lexicon.txt --word_list /tmp/wl -p 0.8 > /tmp/lexicon_raw_nosil.txt || echo fail","metadata":{"execution":{"iopub.status.busy":"2021-05-24T19:09:11.843484Z","iopub.execute_input":"2021-05-24T19:09:11.843852Z","iopub.status.idle":"2021-05-24T19:09:14.411693Z","shell.execute_reply.started":"2021-05-24T19:09:11.843813Z","shell.execute_reply":"2021-05-24T19:09:14.410604Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Traceback (most recent call last):\n  File \"/opt/kaldi/tools/phonetisaurus-g2p/src/scripts/phonetisaurus-apply\", line 324, in <module>\n    tester.ApplyG2PModel (args.word_list)\n  File \"/opt/kaldi/tools/phonetisaurus-g2p/src/scripts/phonetisaurus-apply\", line 278, in ApplyG2PModel\n    self.applyG2PWithLexicon (word_list_file)\n  File \"/opt/kaldi/tools/phonetisaurus-g2p/src/scripts/phonetisaurus-apply\", line 235, in applyG2PWithLexicon\n    print (word.encode (\"utf8\"), file=tmpwordlist)\n  File \"/opt/conda/lib/python3.7/tempfile.py\", line 481, in func_wrapper\n    return func(*args, **kwargs)\nTypeError: a bytes-like object is required, not 'str'\nfail\n","output_type":"stream"}]},{"cell_type":"code","source":"%%writefile /opt/kaldi/tools/phonetisaurus-g2p/src/scripts/phonetisaurus-apply\n#!/usr/bin/env python\n# -*- mode: python; coding: utf-8 -*-\nfrom __future__ import print_function\nimport os, logging, subprocess, time, re\nfrom datetime import datetime\nfrom collections import defaultdict\nimport tempfile\n\nclass G2PModelTester () :\n    \"\"\"G2P Model training wrapper class.\n\n    Phonetisaurus G2P modeling training wrapper class.\n    This wraps the alignment, joint n-gram training, and ARPA to\n    WFST conversion steps into one command.\n    \"\"\"\n    \n    def __init__ (self, model, **kwargs) :\n        self.model = model\n        self.lexicon_file = kwargs.get (\"lexicon\", None)\n        self.nbest = kwargs.get (\"nbest\", 1)\n        self.thresh = kwargs.get (\"thresh\", 99)\n        self.beam = kwargs.get (\"beam\", 10000)\n        self.greedy = kwargs.get (\"greedy\", False)\n        self.accumulate = kwargs.get (\"accumulate\", False)\n        self.pmass = kwargs.get (\"pmass\", 0.0)\n        self.probs = kwargs.get (\"probs\", False)\n        self.verbose = kwargs.get (\"verbose\", False)\n        self.logger = self.setupLogger ()\n\n    def setupLogger (self) :\n        \"\"\"Setup the logger and logging level.\n\n        Setup the logger and logging level.  We only support\n        verbose and non-verbose mode.\n\n        Args:\n            verbose (bool): Verbose mode, or not.\n\n        Returns:\n            Logger: A configured logger instance.\n        \"\"\"\n        \n        level = logging.DEBUG if self.verbose else logging.INFO\n        logging.basicConfig (\n            level=level,\n            format=\"\\033[94m%(levelname)s:%(name)s:\"\\\n            \"%(asctime)s\\033[0m:  %(message)s\",\n            datefmt=\"%Y-%m-%d %H:%M:%S\"\n        )\n\n        return logging.getLogger (\"phonetisaurus-apply\")\n\n    def _loadLexicon (self) :\n        \"\"\"Load the lexicon from a file.\n\n        Load the reference lexicon from a file, and store it\n        in a defaultdict (list).\n        \"\"\"\n        \n        _lexicon = defaultdict (list)\n        if not self.lexicon_file :\n            return _lexicon\n\n        self.logger.debug (\"Loading lexicon from file...\")\n        with open (self.lexicon_file, \"r\") as ifp :\n            for line in ifp :\n                line = line.strip ()\n                word, pron = re.split (r\"\\t\", line)\n                _lexicon [word].append (pron)\n\n        return _lexicon\n    \n    def checkPhonetisaurusConfig (self) :\n        \"\"\"Run some basic checks before training.\n\n        Run some basic checks regarding the $PATH, environment,\n        and provided data before starting training.\n\n        Raises:\n            EnvironmentError: raised if binaries are not found.\n        \"\"\"\n\n        self.logger.debug (\"Checking command configuration...\")\n        for program in [\"phonetisaurus-g2pfst\"] :\n            if not self.which (program) :\n                raise EnvironmentError(\"Phonetisaurus command, '{0}', \"\\\n                    \"not found in path.\".format (program))\n\n        if self.lexicon_file and not os.path.exists (self.lexicon_file) :\n            self.logger.error (\"Could not find provided lexicon file.\")\n            sys.exit (1)\n            \n        for key,val in sorted (vars (self).items ()) :\n            self.logger.debug (u\"{0}:  {1}\".format (key, val))\n            \n        self.lexicon = self._loadLexicon ()\n        \n        return\n    \n    def which (self, program) :\n        \"\"\"Basic 'which' implementation for python.\n\n        Basic 'which' implementation for python from stackoverflow:\n          * https://stackoverflow.com/a/377028/6739158\n\n        Args:\n            program (str): The program name to search the $PATH for.\n\n        Returns:\n            path/None: The path to the executable, or None.\n        \"\"\"\n\n        def is_exe (fpath) :\n            return os.path.isfile (fpath) and os.access (fpath, os.X_OK)\n\n        fpath, fname = os.path.split (program)\n        if fpath:\n            if is_exe (program):\n                return program\n        else:\n            for path in os.environ[\"PATH\"].split (os.pathsep) :\n                path = path.strip ('\"')\n                exe_file = os.path.join (path, program)\n                if is_exe (exe_file):\n                    return exe_file\n\n        return None\n\n    def makeG2PCommand (self, word_list) :\n        \"\"\"Build the G2P command.\n\n        Build the G2P command from the provided arguments.\n\n        Returns:\n            list: The command in subprocess list format.\n        \"\"\"\n\n        command = [\n            u\"phonetisaurus-g2pfst\",\n            u\"--model={0}\".format (self.model),\n            u\"--nbest={0}\".format (self.nbest),\n            u\"--beam={0}\".format (self.beam),\n            u\"--thresh={0}\".format (self.thresh),\n            u\"--accumulate={0}\".format (str (self.accumulate).lower ()),\n            u\"--pmass={0}\".format (self.pmass),\n            u\"--nlog_probs={0}\".format (str(not self.probs).lower ()),\n            u\"--wordlist={0}\".format (word_list)\n        ]\n        \n        self.logger.debug (u\" \".join (command))\n\n        return command\n\n    def runG2PCommand (self, word_list_file) :\n        \"\"\"Generate and run the actual G2P command.\n        \n        Generate and run the actual G2P command.  Each synthesized\n        entry will be yielded back on-the-fly via the subprocess\n        stdout readline method.\n\n        Args:\n            word_list_file (str): The input word list.\n        \"\"\"\n        g2p_command = self.makeG2PCommand (word_list_file)\n        \n        self.logger.debug (\"Applying G2P model...\")\n\n        with open (os.devnull, \"w\") as devnull :\n            proc = subprocess.Popen (\n                g2p_command,\n                stdout=subprocess.PIPE,\n                stderr=devnull if not self.verbose else None\n            )\n            \n            for line in iter (proc.stdout.readline, \"\") :\n                parts = re.split (r\"\\t\", line.strip ())\n                if not len (parts) == 3 :\n                    self.logger.warning (\n                        u\"No pronunciation for word: '{0}'\".format (parts [0])\n                    )\n                    continue\n                \n                yield parts\n\n        return\n\n    def applyG2POnly (self, word_list_file) :\n        \"\"\"Apply the G2P model to a word list.\n\n        Apply the G2P model to a word list.  No filtering or application\n        of a reference lexicon is used here.\n\n        Args:\n            word_list_file (str): The input word list.\n        \"\"\"\n        for word, score, pron in self.runG2PCommand (word_list_file) :\n            line = u\"\"\n            if self.verbose :\n                line = u\"{0}\\t{1:.2f}\\t{2}\".format (\n                    word, float (score), pron\n                )\n            else :\n                line = u\"{0}\\t{1}\".format (word, pron)\n            print (line.encode (\"utf8\"))\n        \n        return\n\n    def applyG2PWithLexicon (self, word_list_file) :\n        \"\"\"Apply the G2P model to a word list, combined with lexicon.\n\n        Apply the G2P model to a word list, but combine this with \n        a reference lexicon.  Words for which a reference entry exists\n        will not be sent to the G2P, unless the additional '--greedy'\n        flag is set to True.\n\n        Args:\n            word_list_file (str): The input word list.\n        \"\"\"\n        target_lexicon = defaultdict (list)\n        tmpwordlist = tempfile.NamedTemporaryFile (delete=False)\n\n        #First, find any words in the target list for which we already\n        # have a canonical pronunciation in the reference lexicon.\n        with open (word_list_file, \"r\") as ifp :\n            for word in ifp :\n                word = word.strip ()\n                if word in self.lexicon :\n                    target_lexicon [word] = [(0.0,pron)\n                                             for pron in self.lexicon [word]]\n                    #In greedy mode we still send words to the G2P, even\n                    # if we have canonical entries in the reference lexicon.\n                    if self.greedy :\n                        print (word.encode (\"utf8\"), file=tmpwordlist)\n                else :\n                    print (word.encode (\"utf8\"), file=tmpwordlist)\n        tmpwordlist.close ()\n\n        #Second, iterate through the G2P output, and filter against\n        # any possible duplicates previously found in the reference lexicon.\n        for word, score, pron in self.runG2PCommand (tmpwordlist.name) :\n            prons = set ([p for s,p in target_lexicon [word]])\n            if pron in prons :\n                continue\n            target_lexicon [word].append ((score, pron))\n\n        #Finally, sort everything that is left and print it.\n        for word in sorted (target_lexicon.keys ()) :\n            for score, pron in target_lexicon [word] :\n                line = u\"\"\n                if self.verbose :\n                    line = u\"{0}\\t{1:.2f}\\t{2}\".format (\n                        word, float (score), pron\n                    )\n                else :\n                    line = u\"{0}\\t{1}\".format (word, pron)\n                print (line.encode (\"utf8\"))\n        \n        os.unlink (tmpwordlist.name)\n        return\n    \n    def ApplyG2PModel (self, word_list_file) :\n        \"\"\"Apply the G2P model to a word list.\n\n        Apply the G2P model to a word list.\n\n        Args:\n            word_list_file (str): The input word list.\n        \"\"\"\n        self.checkPhonetisaurusConfig ()\n        \n        if not os.path.exists (word_list_file) \\\n           or not os.path.isfile (word_list_file) :\n            raise IOError(\"Word list file not found.\")\n\n        if len (self.lexicon) == 0 :\n            self.applyG2POnly (word_list_file)\n        else :\n            self.applyG2PWithLexicon (word_list_file)\n        \n        return\n    \nif __name__ == \"__main__\" :\n    import sys, argparse\n\n    example = \"{0} --model train/model.fst --word test\".format (sys.argv [0])\n    \n    parser  = argparse.ArgumentParser (description=example)\n    parser.add_argument (\"--model\", \"-m\", help=\"Phonetisaurus G2P fst model.\",\n                         required=True)\n    parser.add_argument (\"--lexicon\", \"-l\", help=\"Optional reference lexicon.\",\n                         required=False)\n    parser.add_argument (\"--nbest\", \"-n\", help=\"Maximum number of hypotheses \"\n                         \"to produce.  Overridden if --pmass is set.\",\n                         default=1, type=int)\n    parser.add_argument (\"--beam\", \"-b\", help=\"Search 'beam'.\",\n                         default=10000, type=int)\n    parser.add_argument (\"--thresh\", \"-t\", help=\"Pruning threshold for n-best.\",\n                         default=99.0, type=float)\n    parser.add_argument (\"--greedy\", \"-g\", help=\"Use the G2P even if a \"\n                         \"reference lexicon has been provided.\", default=False,\n                         action=\"store_true\")\n    parser.add_argument (\"--accumulate\", \"-a\", help=\"Accumulate probabilities \"\n                         \"across unique pronunciations.\", default=False,\n                         action=\"store_true\")\n    parser.add_argument (\"--pmass\", \"-p\", help=\"Select the maximum number of \"\n                         \"hypotheses summing to P total mass for a word.\",\n                         default=0.0, type=float)\n    parser.add_argument (\"--probs\", \"-pr\", help=\"Print exp(-val) \"\n                         \"instead of default -log values.\", default=False,\n                         action=\"store_true\")\n    parser.add_argument (\"--word_list\", \"-wl\", help=\"Input word or word list to apply \"\n                        \"G2P model to.\", type=str)\n    \n    parser.add_argument (\"--verbose\", \"-v\", help=\"Verbose mode.\",\n                         default=False, action=\"store_true\")\n    args = parser.parse_args ()\n\n    tester = G2PModelTester (\n        args.model,\n        **{key:val for key,val in args.__dict__.items ()\n           if not key in [\"model\",\"word_list\"]}\n    )\n\n    tester.ApplyG2PModel (args.word_list)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T19:09:05.098928Z","iopub.execute_input":"2021-05-24T19:09:05.099382Z","iopub.status.idle":"2021-05-24T19:09:05.109872Z","shell.execute_reply.started":"2021-05-24T19:09:05.099345Z","shell.execute_reply":"2021-05-24T19:09:05.108434Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Overwriting /opt/kaldi/tools/phonetisaurus-g2p/src/scripts/phonetisaurus-apply\n","output_type":"stream"}]},{"cell_type":"code","source":"%%writefile runmfcc.sh\n#!/bin/bash\n\n. ./path.sh ## set the paths in this file correctly!\n\n#kaldi/tools/phonetisaurus-g2p/src/scripts/phonetisaurus-apply","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%writefile runmfcc.sh\n#!/bin/bash\n\n. ./path.sh ## set the paths in this file correctly!\n\n# link to scripts from the standard Kaldi distribution\n# we try to use these as much as possible\nif [ ! -f $KALDI_ROOT/egs/wsj/s5/conf ] ; then ln -s $KALDI_ROOT/egs/wsj/s5/conf ; fi\nif [ ! -f $KALDI_ROOT/egs/wsj/s5/local ] ; then ln -s $KALDI_ROOT/egs/wsj/s5/local ; fi\nif [ ! -f $KALDI_ROOT/egs/wsj/s5/utils ] ; then ln -s $KALDI_ROOT/egs/wsj/s5/utils ; fi\nif [ ! -f $KALDI_ROOT/egs/wsj/s5/steps ] ; then ln -s $KALDI_ROOT/egs/wsj/s5/steps ; fi\n\n# exits script if error occurs anywhere\n# you might not want to do this for interactive shells.\nset -e\n\nexport nj=40 ##number of concurrent processes\nexport nj_test=30 ## number of concurrent processes for test has to be <=30\n\n# This is a shell script, but it's recommended that you run the commands one by\n# one by copying and pasting into the shell.\n\n#run some initial data preparation (look at the file for more details):\nlocal_clarin/clarin_pl_data_prep.sh\n\n#prepare the lang directory\nutils/prepare_lang.sh data/local/dict_nosp \"<unk>\" data/local/tmp_nosp data/lang_nosp\n\n#make G.fst\nutils/format_lm.sh data/lang_nosp local_clarin/arpa.lm.gz data/local/dict_nosp/lexicon.txt data/lang_nosp_test\n\n# Make normalized MFCC features.\nsteps/make_mfcc.sh --nj $nj data/train\nsteps/compute_cmvn_stats.sh data/train\nsteps/make_mfcc.sh --nj $nj data/test\nsteps/compute_cmvn_stats.sh data/test","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:53:11.754713Z","iopub.execute_input":"2021-05-24T17:53:11.754958Z","iopub.status.idle":"2021-05-24T17:53:11.762425Z","shell.execute_reply.started":"2021-05-24T17:53:11.754933Z","shell.execute_reply":"2021-05-24T17:53:11.76169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!sh runmfcc.sh","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:53:11.763422Z","iopub.execute_input":"2021-05-24T17:53:11.763698Z"},"trusted":true},"execution_count":null,"outputs":[]}]}