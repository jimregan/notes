{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "2021-05-30-wav2vec-u-cv-swedish-gan.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mL3fwRLmbvoD"
      },
      "source": [
        "## Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVVTn1chb1vy",
        "outputId": "053154f0-0860-40ec-fd6c-67dad4712569"
      },
      "source": [
        "!pip install condacolab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting condacolab\n",
            "  Downloading https://files.pythonhosted.org/packages/ee/47/6f9fe13087c31aba889c4b09f9beaa558bf216bf9108c9ccef44e6c9dcfe/condacolab-0.1.2-py3-none-any.whl\n",
            "Installing collected packages: condacolab\n",
            "Successfully installed condacolab-0.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOYIs1bRcBPW",
        "outputId": "750986c9-7aee-41be-a702-5bd547c5fca4"
      },
      "source": [
        "import condacolab\n",
        "condacolab.install()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "⏬ Downloading https://github.com/jaimergp/miniforge/releases/latest/download/Mambaforge-colab-Linux-x86_64.sh...\n",
            "📦 Installing...\n",
            "📌 Adjusting configuration...\n",
            "🩹 Patching environment...\n",
            "⏲ Done in 0:00:34\n",
            "🔁 Restarting kernel...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZCun_MTbvoI",
        "outputId": "7f6f1c57-d06d-4179-e6fa-56eb7f6137e8"
      },
      "source": [
        "!conda install -c pykaldi pykaldi -y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - pykaldi\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    ca-certificates-2021.5.30  |       ha878542_0         136 KB  conda-forge\n",
            "    certifi-2021.5.30          |   py37h89c1867_0         141 KB  conda-forge\n",
            "    conda-4.10.1               |   py37h89c1867_0         3.1 MB  conda-forge\n",
            "    libblas-3.9.0              |       9_openblas          11 KB  conda-forge\n",
            "    libcblas-3.9.0             |       9_openblas          11 KB  conda-forge\n",
            "    libgfortran-ng-9.3.0       |      hff62375_19          22 KB  conda-forge\n",
            "    libgfortran5-9.3.0         |      hff62375_19         2.0 MB  conda-forge\n",
            "    liblapack-3.9.0            |       9_openblas          11 KB  conda-forge\n",
            "    libopenblas-0.3.15         |pthreads_h8fe5266_1         9.2 MB  conda-forge\n",
            "    numpy-1.20.3               |   py37h038b26d_1         5.7 MB  conda-forge\n",
            "    openblas-0.3.15            |pthreads_h4748800_1         9.8 MB  conda-forge\n",
            "    openssl-1.1.1k             |       h7f98852_0         2.1 MB  conda-forge\n",
            "    pykaldi-0.1.3              |   py37h14c3975_1       445.5 MB  pykaldi\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       477.6 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  libblas            conda-forge/linux-64::libblas-3.9.0-9_openblas\n",
            "  libcblas           conda-forge/linux-64::libcblas-3.9.0-9_openblas\n",
            "  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-9.3.0-hff62375_19\n",
            "  libgfortran5       conda-forge/linux-64::libgfortran5-9.3.0-hff62375_19\n",
            "  liblapack          conda-forge/linux-64::liblapack-3.9.0-9_openblas\n",
            "  libopenblas        conda-forge/linux-64::libopenblas-0.3.15-pthreads_h8fe5266_1\n",
            "  numpy              conda-forge/linux-64::numpy-1.20.3-py37h038b26d_1\n",
            "  openblas           conda-forge/linux-64::openblas-0.3.15-pthreads_h4748800_1\n",
            "  pykaldi            pykaldi/linux-64::pykaldi-0.1.3-py37h14c3975_1\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates                      2020.12.5-ha878542_0 --> 2021.5.30-ha878542_0\n",
            "  certifi                          2020.12.5-py37h89c1867_1 --> 2021.5.30-py37h89c1867_0\n",
            "  conda                                4.9.2-py37h89c1867_0 --> 4.10.1-py37h89c1867_0\n",
            "  openssl                                 1.1.1j-h7f98852_0 --> 1.1.1k-h7f98852_0\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "certifi-2021.5.30    | 141 KB    | : 100% 1.0/1 [00:00<00:00,  5.51it/s]                \n",
            "pykaldi-0.1.3        | 445.5 MB  | : 100% 1.0/1 [01:20<00:00, 80.30s/it]\n",
            "ca-certificates-2021 | 136 KB    | : 100% 1.0/1 [00:00<00:00, 12.63it/s]\n",
            "openssl-1.1.1k       | 2.1 MB    | : 100% 1.0/1 [00:00<00:00,  3.11it/s]\n",
            "libcblas-3.9.0       | 11 KB     | : 100% 1.0/1 [00:00<00:00, 22.74it/s]\n",
            "liblapack-3.9.0      | 11 KB     | : 100% 1.0/1 [00:00<00:00, 20.89it/s]\n",
            "libopenblas-0.3.15   | 9.2 MB    | : 100% 1.0/1 [00:01<00:00,  1.45s/it]\n",
            "conda-4.10.1         | 3.1 MB    | : 100% 1.0/1 [00:00<00:00,  1.69it/s]               \n",
            "libgfortran5-9.3.0   | 2.0 MB    | : 100% 1.0/1 [00:00<00:00,  2.44it/s]\n",
            "libgfortran-ng-9.3.0 | 22 KB     | : 100% 1.0/1 [00:00<00:00, 22.54it/s]\n",
            "numpy-1.20.3         | 5.7 MB    | : 100% 1.0/1 [00:01<00:00,  1.03s/it]\n",
            "libblas-3.9.0        | 11 KB     | : 100% 1.0/1 [00:00<00:00, 19.82it/s]\n",
            "openblas-0.3.15      | 9.8 MB    | : 100% 1.0/1 [00:01<00:00,  1.85s/it]\n",
            "Preparing transaction: - \b\bdone\n",
            "Verifying transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Executing transaction: - \b\b\\ \b\b| \b\bdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlKl6b8abvoL",
        "outputId": "a71a59bf-19ad-4e0a-fed2-7e566081f22a"
      },
      "source": [
        "!git clone https://github.com/jimregan/fairseq/ --branch issue3581"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fairseq'...\n",
            "remote: Enumerating objects: 28296, done.\u001b[K\n",
            "remote: Total 28296 (delta 0), reused 0 (delta 0), pack-reused 28296\u001b[K\n",
            "Receiving objects: 100% (28296/28296), 11.77 MiB | 16.71 MiB/s, done.\n",
            "Resolving deltas: 100% (21291/21291), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwUcTOjRbvoM",
        "outputId": "ab6ef8b9-19b8-4d57-8b4e-7fcfe188ef44"
      },
      "source": [
        "!git clone https://github.com/kpu/kenlm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'kenlm'...\n",
            "remote: Enumerating objects: 13824, done.\u001b[K\n",
            "remote: Counting objects: 100% (137/137), done.\u001b[K\n",
            "remote: Compressing objects: 100% (79/79), done.\u001b[K\n",
            "remote: Total 13824 (delta 76), reused 92 (delta 45), pack-reused 13687\u001b[K\n",
            "Receiving objects: 100% (13824/13824), 5.49 MiB | 11.12 MiB/s, done.\n",
            "Resolving deltas: 100% (7956/7956), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfsJ-BmLbvoM"
      },
      "source": [
        "%%capture\n",
        "!apt-get -y install libeigen3-dev liblzma-dev zlib1g-dev libbz2-dev"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MimUvvcPbvoN"
      },
      "source": [
        "%cd kenlm\n",
        "!mkdir build\n",
        "%cd build\n",
        "!cmake ..\n",
        "!make -j 4\n",
        "%cd /tmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9w7eg96HbvoO"
      },
      "source": [
        "%cd /content/kenlm\n",
        "!python setup.py install\n",
        "%cd /tmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m734pIlgbvoO"
      },
      "source": [
        "import os\n",
        "os.environ['PATH'] = f\"{os.environ['PATH']}:/content/kenlm/build/bin/\"\n",
        "os.environ['FAIRSEQ_ROOT'] = '/content/fairseq'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7iGrPGCbvoP",
        "outputId": "b5daaad4-e20e-481a-bc6f-6ea760bed469"
      },
      "source": [
        "%cd /content/fairseq/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/fairseq\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "X1ACsk1ZbvoP"
      },
      "source": [
        "!python setup.py install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QA-J_mFqbvoR"
      },
      "source": [
        "os.environ['HYDRA_FULL_ERROR'] = '1'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8h11qZXbvoS"
      },
      "source": [
        "%%capture\n",
        "!pip install editdistance"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S02ROj2_cl_i"
      },
      "source": [
        "https://colab.research.google.com/github/corrieann/kaggle/blob/master/kaggle_api_in_colab.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvR8jKnzc1E9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "301e2d9a-ebd9-41e8-8e48-77106822b082"
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kaggle\n",
            "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 3.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/site-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/site-packages (from kaggle) (2021.5.30)\n",
            "Collecting python-dateutil\n",
            "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
            "\u001b[K     |████████████████████████████████| 227 kB 17.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/site-packages (from kaggle) (2.25.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/site-packages (from kaggle) (4.59.0)\n",
            "Collecting python-slugify\n",
            "  Downloading python_slugify-5.0.2-py2.py3-none-any.whl (6.7 kB)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/site-packages (from kaggle) (1.26.3)\n",
            "Collecting text-unidecode>=1.3\n",
            "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 8.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/site-packages (from requests->kaggle) (4.0.0)\n",
            "Building wheels for collected packages: kaggle\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73053 sha256=62e57f8f957b249d4e3da48574f61b1c956338e1da0758fcee3c1724ecff0ec2\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/d6/58/5853130f941e75b2177d281eb7e44b4a98ed46dd155f556dc5\n",
            "Successfully built kaggle\n",
            "Installing collected packages: text-unidecode, python-slugify, python-dateutil, kaggle\n",
            "Successfully installed kaggle-1.5.12 python-dateutil-2.8.1 python-slugify-5.0.2 text-unidecode-1.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "dateutil"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8SXwyPDcolN",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "cb547db7-fe13-4b2c-8bcd-8e98a7fbcdee"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "  \n",
        "# Then move kaggle.json into the folder where the API expects to find it.\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-99f401f2-6150-4bbe-869e-1a2c87ed566e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-99f401f2-6150-4bbe-869e-1a2c87ed566e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "User uploaded file \"kaggle.json\" with length 64 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kPXJ6VPeya6",
        "outputId": "2bb50bf7-335f-4ed8-e921-78ada5a77f84"
      },
      "source": [
        "%cd /content"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1KhhOtHfQzW",
        "outputId": "4fb02242-a364-4479-9ff3-234447f8e7e2"
      },
      "source": [
        "!kaggle datasets download \"jimregan/w2vu-cvsv-prepared-text\""
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading w2vu-cvsv-prepared-text.zip to /content\n",
            " 29% 5.00M/17.4M [00:00<00:00, 31.7MB/s]\n",
            "100% 17.4M/17.4M [00:00<00:00, 75.8MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiA4aXvCfW9d",
        "outputId": "238bdc10-f278-4504-81ad-fc7cd31efb19"
      },
      "source": [
        "!unzip /content/w2vu-cvsv-prepared-text.zip"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/w2vu-cvsv-prepared-text.zip\n",
            "  inflating: preppedtext/fst/phn_to_phn_sil/G_lm.phones.filtered.06.fst  \n",
            "  inflating: preppedtext/fst/phn_to_phn_sil/H.phn.fst  \n",
            "  inflating: preppedtext/fst/phn_to_phn_sil/H.phn.fst.isym  \n",
            "  inflating: preppedtext/fst/phn_to_phn_sil/H.phn.fstisym_disambig.int  \n",
            "  inflating: preppedtext/fst/phn_to_phn_sil/HLG.phn.lm.phones.filtered.06.fst  \n",
            "  inflating: preppedtext/fst/phn_to_phn_sil/HLGa.phn.lm.phones.filtered.06.fst  \n",
            "  inflating: preppedtext/fst/phn_to_phn_sil/L.phn.lm.phones.filtered.06.fst  \n",
            "  inflating: preppedtext/fst/phn_to_phn_sil/LG.phn.lm.phones.filtered.06.fst  \n",
            "  inflating: preppedtext/fst/phn_to_phn_sil/kaldi_dict.h_out.phn.txt  \n",
            "  inflating: preppedtext/fst/phn_to_phn_sil/kaldi_dict.lm.phones.filtered.06.txt  \n",
            "  inflating: preppedtext/fst/phn_to_phn_sil/kaldi_dict.lm.phones.filtered.06.txt_disamig  \n",
            "  inflating: preppedtext/fst/phn_to_phn_sil/kaldi_dict.phn.txt  \n",
            "  inflating: preppedtext/fst/phn_to_phn_sil/kaldi_dict.phn_disambig.txt  \n",
            "  inflating: preppedtext/fst/phn_to_phn_sil/kaldi_dict.phn_disambig.txt.int  \n",
            "  inflating: preppedtext/fst/phn_to_phn_sil/kaldi_dict.phn_disambig.txt_disamig  \n",
            "  inflating: preppedtext/fst/phn_to_phn_sil/kaldi_lexicon.phn.lm.phones.filtered.06.txt  \n",
            "  inflating: preppedtext/fst/phn_to_phn_sil/kaldi_lexicon.phn.lm.phones.filtered.06_disambig.txt  \n",
            "  inflating: preppedtext/fst/phn_to_words/G_kenlm.wrd.o40003.fst  \n",
            "  inflating: preppedtext/fst/phn_to_words/H.phn.fst  \n",
            "  inflating: preppedtext/fst/phn_to_words/H.phn.fst.isym  \n",
            "  inflating: preppedtext/fst/phn_to_words/H.phn.fstisym_disambig.int  \n",
            "  inflating: preppedtext/fst/phn_to_words/HLG.phn.kenlm.wrd.o40003.fst  \n",
            "  inflating: preppedtext/fst/phn_to_words/HLGa.phn.kenlm.wrd.o40003.fst  \n",
            "  inflating: preppedtext/fst/phn_to_words/L.phn.kenlm.wrd.o40003.fst  \n",
            "  inflating: preppedtext/fst/phn_to_words/LG.phn.kenlm.wrd.o40003.fst  \n",
            "  inflating: preppedtext/fst/phn_to_words/kaldi_dict.h_out.phn.txt  \n",
            "  inflating: preppedtext/fst/phn_to_words/kaldi_dict.kenlm.wrd.o40003.txt  \n",
            "  inflating: preppedtext/fst/phn_to_words/kaldi_dict.kenlm.wrd.o40003.txt_disamig  \n",
            "  inflating: preppedtext/fst/phn_to_words/kaldi_dict.phn.txt  \n",
            "  inflating: preppedtext/fst/phn_to_words/kaldi_dict.phn_disambig.txt  \n",
            "  inflating: preppedtext/fst/phn_to_words/kaldi_dict.phn_disambig.txt.int  \n",
            "  inflating: preppedtext/fst/phn_to_words/kaldi_dict.phn_disambig.txt_disamig  \n",
            "  inflating: preppedtext/fst/phn_to_words/kaldi_lexicon.phn.kenlm.wrd.o40003.txt  \n",
            "  inflating: preppedtext/fst/phn_to_words/kaldi_lexicon.phn.kenlm.wrd.o40003_disambig.txt  \n",
            "  inflating: preppedtext/fst/phn_to_words_sil/G_kenlm.wrd.o40003.fst  \n",
            "  inflating: preppedtext/fst/phn_to_words_sil/H.phn.fst  \n",
            "  inflating: preppedtext/fst/phn_to_words_sil/H.phn.fst.isym  \n",
            "  inflating: preppedtext/fst/phn_to_words_sil/H.phn.fstisym_disambig.int  \n",
            "  inflating: preppedtext/fst/phn_to_words_sil/HLG.phn.kenlm.wrd.o40003.fst  \n",
            "  inflating: preppedtext/fst/phn_to_words_sil/HLGa.phn.kenlm.wrd.o40003.fst  \n",
            "  inflating: preppedtext/fst/phn_to_words_sil/L.phn.kenlm.wrd.o40003.fst  \n",
            "  inflating: preppedtext/fst/phn_to_words_sil/LG.phn.kenlm.wrd.o40003.fst  \n",
            "  inflating: preppedtext/fst/phn_to_words_sil/kaldi_dict.h_out.phn.txt  \n",
            "  inflating: preppedtext/fst/phn_to_words_sil/kaldi_dict.kenlm.wrd.o40003.txt  \n",
            "  inflating: preppedtext/fst/phn_to_words_sil/kaldi_dict.kenlm.wrd.o40003.txt_disamig  \n",
            "  inflating: preppedtext/fst/phn_to_words_sil/kaldi_dict.phn.txt  \n",
            "  inflating: preppedtext/fst/phn_to_words_sil/kaldi_dict.phn_disambig.txt  \n",
            "  inflating: preppedtext/fst/phn_to_words_sil/kaldi_dict.phn_disambig.txt.int  \n",
            "  inflating: preppedtext/fst/phn_to_words_sil/kaldi_dict.phn_disambig.txt_disamig  \n",
            "  inflating: preppedtext/fst/phn_to_words_sil/kaldi_lexicon.phn.kenlm.wrd.o40003.txt  \n",
            "  inflating: preppedtext/fst/phn_to_words_sil/kaldi_lexicon.phn.kenlm.wrd.o40003_disambig.txt  \n",
            "  inflating: preppedtext/kenlm.wrd.o40003.arpa  \n",
            "  inflating: preppedtext/kenlm.wrd.o40003.bin  \n",
            "  inflating: preppedtext/lexicon.lst  \n",
            "  inflating: preppedtext/lexicon_filtered.lst  \n",
            "  inflating: preppedtext/lm.upper.lid.txt  \n",
            "  inflating: preppedtext/phones.txt  \n",
            "  inflating: preppedtext/phones/dict.phn.txt  \n",
            "  inflating: preppedtext/phones/dict.txt  \n",
            "  inflating: preppedtext/phones/lm.phones.filtered.04.arpa  \n",
            "  inflating: preppedtext/phones/lm.phones.filtered.04.bin  \n",
            "  inflating: preppedtext/phones/lm.phones.filtered.06.arpa  \n",
            "  inflating: preppedtext/phones/lm.phones.filtered.06.bin  \n",
            "  inflating: preppedtext/phones/lm.phones.filtered.txt  \n",
            "  inflating: preppedtext/phones/preprocess.log  \n",
            "  inflating: preppedtext/phones/train.bin  \n",
            "  inflating: preppedtext/phones/train.idx  \n",
            "  inflating: preppedtext/words.txt   \n",
            "  inflating: sentences.txt           \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GyS6aemerz7",
        "outputId": "67cf4144-2f74-4098-a650-63a564e569d3"
      },
      "source": [
        "!kaggle datasets download -d jimregan/w2vu-cvsv-precompute-pca512-cls128-mean-pooled"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading w2vu-cvsv-precompute-pca512-cls128-mean-pooled.zip to /content\n",
            " 94% 369M/394M [00:03<00:00, 122MB/s]\n",
            "100% 394M/394M [00:03<00:00, 120MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RyBEIhahPzB",
        "outputId": "df2647ab-39f3-47d0-cff1-8ca39605bcf1"
      },
      "source": [
        "!unzip w2vu-cvsv-precompute-pca512-cls128-mean-pooled.zip"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  w2vu-cvsv-precompute-pca512-cls128-mean-pooled.zip\n",
            "  inflating: precompute_pca512_cls128_mean_pooled/test.lengths  \n",
            "  inflating: precompute_pca512_cls128_mean_pooled/test.npy  \n",
            "  inflating: precompute_pca512_cls128_mean_pooled/test.phn  \n",
            "  inflating: precompute_pca512_cls128_mean_pooled/test.tsv  \n",
            "  inflating: precompute_pca512_cls128_mean_pooled/test.wrd  \n",
            "  inflating: precompute_pca512_cls128_mean_pooled/train.lengths  \n",
            "  inflating: precompute_pca512_cls128_mean_pooled/train.npy  \n",
            "  inflating: precompute_pca512_cls128_mean_pooled/train.phn  \n",
            "  inflating: precompute_pca512_cls128_mean_pooled/train.tsv  \n",
            "  inflating: precompute_pca512_cls128_mean_pooled/train.wrd  \n",
            "  inflating: precompute_pca512_cls128_mean_pooled/valid.lengths  \n",
            "  inflating: precompute_pca512_cls128_mean_pooled/valid.npy  \n",
            "  inflating: precompute_pca512_cls128_mean_pooled/valid.phn  \n",
            "  inflating: precompute_pca512_cls128_mean_pooled/valid.tsv  \n",
            "  inflating: precompute_pca512_cls128_mean_pooled/valid.wrd  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9ZmDpv5hVyM"
      },
      "source": [
        "!rm *.zip"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g11AbGGWbvoT"
      },
      "source": [
        "## GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISP36CLKbvoU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8bd9aaa0-5704-4997-b48d-719aee5f9383"
      },
      "source": [
        "import torch\n",
        "torch.version.cuda"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'10.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yRc89tWbvoV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ef4c0e1-dd78-4fbb-f7cb-9b1eb34a9a0d"
      },
      "source": [
        "torch.backends.cudnn.version()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7603"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnBUjXAph1lZ",
        "outputId": "69f1f2c8-de50-4be3-99c7-2134618844e3"
      },
      "source": [
        "%cd /content/fairseq"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/fairseq\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMA3E3lVbvoV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a3aff74-d83b-41bf-e333-fa3028313066"
      },
      "source": [
        "%%writefile rungan.sh\n",
        "PREFIX=w2v_unsup_gan_xp\n",
        "#TASK_DATA=/path/to/features/unfiltered/precompute_unfiltered_pca512_cls128_mean_pooled\n",
        "TASK_DATA=/content/precompute_pca512_cls128_mean_pooled\n",
        "#TEXT_DATA=/path/to/data  # path to fairseq-preprocessed GAN data\n",
        "TEXT_DATA=/content/preppedtext/phones/\n",
        "#KENLM_PATH=/path/to/data/kenlm.phn.o4.bin  # KenLM 4-gram phoneme language model (LM data = GAN data here)\n",
        "KENLM_PATH=/content/preppedtext/phones/lm.phones.filtered.04.bin\n",
        "\n",
        "PREFIX=$PREFIX CUDA_LAUNCH_BLOCKING=1 fairseq-hydra-train \\\n",
        "\t-m --config-dir fairseq/config/model/wav2vecu/gan \\\n",
        "\t--config-name w2vu \\\n",
        "\ttask.data=${TASK_DATA} \\\n",
        "\ttask.text_data=${TEXT_DATA} \\\n",
        "\ttask.kenlm_path=${KENLM_PATH} \\\n",
        "\tcheckpoint.no_epoch_checkpoints=false \\\n",
        "\t'common.seed=range(0,5)'"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing rungan.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOAq9uxybvoW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be4db6af-4137-4d28-87f8-7c92afde06c4"
      },
      "source": [
        "!bash rungan.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2021-06-03 20:19:11,645][HYDRA] Launching 5 jobs locally\n",
            "[2021-06-03 20:19:11,645][HYDRA] \t#0 : task.data=/content/precompute_pca512_cls128_mean_pooled task.text_data=/content/preppedtext/phones/ task.kenlm_path=/content/preppedtext/phones/lm.phones.filtered.04.bin checkpoint.no_epoch_checkpoints=False common.seed=0\n",
            "[2021-06-03 20:19:12,958][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': 'json', 'log_file': None, 'tensorboard_logdir': 'tb', 'wandb_project': None, 'azureml_logging': False, 'seed': 0, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': True, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'distributed_num_procs': 1}, 'dataset': {'_name': None, 'num_workers': 6, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': None, 'batch_size': 160, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 160, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 150000, 'stop_time_hours': 0.0, 'clip_norm': 5.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '.', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'weighted_lm_ppl', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec_u', 'discriminator_kernel': 6, 'discriminator_dilation': 1, 'discriminator_dim': 384, 'discriminator_causal': True, 'discriminator_linear_emb': False, 'discriminator_depth': 2, 'discriminator_max_pool': False, 'discriminator_act_after_linear': False, 'discriminator_dropout': 0.0, 'discriminator_spectral_norm': False, 'discriminator_weight_norm': False, 'generator_kernel': 4, 'generator_dilation': 1, 'generator_stride': 1, 'generator_bias': False, 'generator_dropout': 0.1, 'blank_weight': 0.0, 'blank_mode': 'add', 'blank_is_sil': False, 'no_softmax': False, 'smoothness_weight': 0.5, 'smoothing': 0.0, 'smoothing_one_sided': False, 'gradient_penalty': 1.5, 'probabilistic_grad_penalty_slicing': False, 'code_penalty': 4.0, 'gumbel': False, 'hard_gumbel': False, 'temp': [2.0, 0.1, 0.99995], 'input_dim': 512, 'wgan_loss': False, 'segmentation': {'_name': None, 'type': 'JOIN', 'subsample_rate': 0.25, 'mean_pool': True, 'mean_pool_join': False, 'remove_zeros': False}}, 'task': {'_name': 'gan_audio_pretraining_feats', 'data': '/content/precompute_pca512_cls128_mean_pooled', 'text_data': '/content/preppedtext/phones/', 'max_length': None, 'labels': 'phn', 'unfiltered': False, 'ctc_eval': False, 'sort_by_length': False, 'shuffle': True, 'append_eos': False, 'uppercase': False, 'skipwords': '', 'kenlm_path': '/content/preppedtext/phones/lm.phones.filtered.04.bin', 'vocab_usage_power': 2.0, 'word_decoder_config': None, 'word_kenlm_path': None, 'decoding_config': {'_name': None, 'kenlm_path': None, 'lm_weight': 0.0, 'blank_weight': 0.0}}, 'criterion': {'_name': 'model', 'loss_weights': {}, 'log_keys': ['accuracy_dense', 'accuracy_token', 'temp', 'code_ppl']}, 'optimizer': {'_name': 'composite', 'groups': {'generator': {'lr': [0.0004], 'lr_float': None, 'optimizer': {'_name': 'adam', 'adam_betas': [0.5, 0.98], 'adam_eps': 1e-06, 'weight_decay': 0, 'amsgrad': False}, 'lr_scheduler': {'_name': 'fixed', 'warmup_updates': 0}}, 'discriminator': {'lr': [0.0005], 'lr_float': None, 'optimizer': {'_name': 'adam', 'adam_betas': [0.5, 0.98], 'adam_eps': 1e-06, 'weight_decay': 0.0001, 'amsgrad': False}, 'lr_scheduler': {'_name': 'fixed', 'warmup_updates': 0}}}}, 'lr_scheduler': {'_name': 'pass_through'}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}\n",
            "[2021-06-03 20:19:12,986][fairseq_cli.train][INFO] - Wav2vec_U(\n",
            "  (discriminator): Discriminator(\n",
            "    (net): Sequential(\n",
            "      (0): Conv1d(45, 384, kernel_size=(6,), stride=(1,), padding=(5,))\n",
            "      (1): SamePad()\n",
            "      (2): Dropout(p=0.0, inplace=False)\n",
            "      (3): Sequential(\n",
            "        (0): Conv1d(384, 384, kernel_size=(6,), stride=(1,), padding=(5,))\n",
            "        (1): SamePad()\n",
            "        (2): Dropout(p=0.0, inplace=False)\n",
            "        (3): GELU()\n",
            "      )\n",
            "      (4): Conv1d(384, 1, kernel_size=(6,), stride=(1,), padding=(5,))\n",
            "      (5): SamePad()\n",
            "    )\n",
            "  )\n",
            "  (segmenter): JoinSegmenter()\n",
            "  (generator): Generator(\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (proj): Sequential(\n",
            "      (0): TransposeLast()\n",
            "      (1): Conv1d(512, 45, kernel_size=(4,), stride=(1,), padding=(2,), bias=False)\n",
            "      (2): TransposeLast()\n",
            "    )\n",
            "  )\n",
            ")\n",
            "[2021-06-03 20:19:12,987][fairseq_cli.train][INFO] - task: UnpairedAudioText\n",
            "[2021-06-03 20:19:12,987][fairseq_cli.train][INFO] - model: Wav2vec_U\n",
            "[2021-06-03 20:19:12,987][fairseq_cli.train][INFO] - criterion: ModelCriterion\n",
            "[2021-06-03 20:19:12,987][fairseq_cli.train][INFO] - num. shared model params: 1,083,649 (num. trained: 1,083,649)\n",
            "[2021-06-03 20:19:12,987][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)\n",
            "[2021-06-03 20:19:12,997][fairseq.data.extracted_features_dataset][INFO] - loaded 2019, skipped 0 samples\n",
            "[2021-06-03 20:19:12,997][fairseq.tasks.unpaired_audio_text][INFO] - split valid has unpaired text? False\n",
            "[2021-06-03 20:19:16,271][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************\n",
            "[2021-06-03 20:19:16,271][fairseq.utils][INFO] - rank   0: capabilities =  7.5  ; total memory = 14.756 GB ; name = Tesla T4                                \n",
            "[2021-06-03 20:19:16,271][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************\n",
            "[2021-06-03 20:19:16,271][fairseq_cli.train][INFO] - training on 1 devices (GPUs/TPUs)\n",
            "[2021-06-03 20:19:16,271][fairseq_cli.train][INFO] - max tokens per device = None and max sentences per device = 160\n",
            "[2021-06-03 20:19:16,272][fairseq.trainer][INFO] - Preparing to load checkpoint ./checkpoint_last.pt\n",
            "[2021-06-03 20:19:16,273][fairseq.trainer][INFO] - No existing checkpoint found ./checkpoint_last.pt\n",
            "[2021-06-03 20:19:16,273][fairseq.trainer][INFO] - loading train data for epoch 1\n",
            "[2021-06-03 20:19:16,275][fairseq.data.extracted_features_dataset][INFO] - loaded 2331, skipped 0 samples\n",
            "[2021-06-03 20:19:16,276][fairseq.tasks.unpaired_audio_text][INFO] - split train has unpaired text? True\n",
            "[2021-06-03 20:19:16,276][fairseq.data.data_utils][INFO] - loaded 2,328 examples from: /content/preppedtext/phones/train\n",
            "[2021-06-03 20:19:16,320][fairseq.trainer][INFO] - NOTE: your device may support faster training with --fp16 or --amp\n",
            "/usr/local/lib/python3.7/site-packages/torch-1.8.1-py3.7-linux-x86_64.egg/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "[2021-06-03 20:19:16,462][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard\n",
            "[2021-06-03 20:19:16,465][fairseq.trainer][INFO] - begin training epoch 1\n",
            "[2021-06-03 20:19:16,465][fairseq_cli.train][INFO] - Start iterating over samples\n",
            "/usr/local/lib/python3.7/site-packages/fairseq-1.0.0a0+6179d53-py3.7-linux-x86_64.egg/fairseq/utils.py:369: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n",
            "  \"amp_C fused kernels unavailable, disabling multi_tensor_l2norm; \"\n",
            "[2021-06-03 20:19:22,439][fairseq_cli.train][INFO] - begin validation on \"valid\" subset\n",
            "[2021-06-03 20:19:22,479][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard\n",
            "[2021-06-03 20:19:25,186][fairseq.tasks.unpaired_audio_text][INFO] - REF: ɛ n f œ ʂ ə n a d ɵ ʂ ə k t f øː r d eː t s ɔ m h ɛ n d ə p oː ɕ œ r k ɔ n s ɛ t ə n\n",
            "[2021-06-03 20:19:25,191][fairseq.tasks.unpaired_audio_text][INFO] - HYP: ɛː yː a h s ʃ ʉ r s iː m oː uː d ɕ ɕ øː uː ɪ d ɛ ʂ f oː tː m ɪ øː m ʊ yː ŋ ʂ ŋ b j ʂ m h m ŋ sx ʂ m a ŋ kː sx\n",
            "[2021-06-03 20:19:25,200][fairseq.tasks.unpaired_audio_text][INFO] - LM [REF]: -53.44462585449219, 0.05339602260269112\n",
            "[2021-06-03 20:19:25,200][fairseq.tasks.unpaired_audio_text][INFO] - LM [HYP]: -106.40988159179688, 0.006735498805194426\n",
            "[2021-06-03 20:19:25,815][valid][INFO] - {\"epoch\": 1, \"valid_loss\": \"1.119\", \"valid_ntokens\": \"3039.79\", \"valid_nsentences\": \"144.214\", \"valid_lm_score_sum\": \"-116835\", \"valid_num_pred_chars\": \"50154\", \"valid_vocab_seen_pct\": \"0.958188\", \"valid_uer\": \"111.935\", \"valid_weighted_lm_ppl\": \"189.002\", \"valid_lm_ppl\": \"173.527\", \"valid_wps\": \"16854\", \"valid_wpb\": \"3039.8\", \"valid_bsz\": \"144.2\", \"valid_num_updates\": \"16\"}\n",
            "[2021-06-03 20:19:25,817][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 1 @ 16 updates\n",
            "[2021-06-03 20:19:25,817][fairseq.trainer][INFO] - Saving checkpoint to ./checkpoint1.pt\n",
            "[2021-06-03 20:19:25,849][fairseq.trainer][INFO] - Finished saving checkpoint to ./checkpoint1.pt\n",
            "[2021-06-03 20:19:25,873][fairseq.checkpoint_utils][INFO] - Saved checkpoint ./checkpoint1.pt (epoch 1 @ 16 updates, score 189.00200391973922) (writing took 0.05676452500006235 seconds)\n",
            "[2021-06-03 20:19:25,874][fairseq_cli.train][INFO] - end of epoch 1 (average epoch stats below)\n",
            "[2021-06-03 20:19:25,874][train][INFO] - {\"epoch\": 1, \"train_loss\": \"34.484\", \"train_ntokens\": \"145.688\", \"train_nsentences\": \"145.688\", \"train_temp\": \"1.999\", \"train_code_ppl\": \"8.726\", \"train_loss_code_pen\": \"0.015\", \"train_loss_smoothness\": \"2.141\", \"train_loss_dense_g\": \"0.729\", \"train_lm_score_sum\": 0.0, \"train_num_pred_chars\": 0.0, \"train_loss_grad_pen\": \"58.997\", \"train_loss_dense_d\": \"0.668\", \"train_loss_token_d\": \"0.765\", \"train_wps\": \"275\", \"train_ups\": \"1.9\", \"train_wpb\": \"145.7\", \"train_bsz\": \"145.7\", \"train_num_updates\": \"16\", \"train_lr_discriminator\": \"0.0005\", \"train_lr_generator\": \"0.0004\", \"train_gnorm\": \"20.468\", \"train_clip\": \"93.8\", \"train_train_wall\": \"5\", \"train_gb_free\": \"14.2\", \"train_wall\": \"10\"}\n",
            "[2021-06-03 20:19:25,908][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard\n",
            "[2021-06-03 20:19:25,912][fairseq.trainer][INFO] - begin training epoch 2\n",
            "[2021-06-03 20:19:25,912][fairseq_cli.train][INFO] - Start iterating over samples\n",
            "[2021-06-03 20:19:31,488][fairseq_cli.train][INFO] - begin validation on \"valid\" subset\n",
            "[2021-06-03 20:19:31,521][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard\n",
            "[2021-06-03 20:19:34,244][fairseq.tasks.unpaired_audio_text][INFO] - REF: ɛ n f œ ʂ ə n a d ɵ ʂ ə k t f øː r d eː t s ɔ m h ɛ n d ə p oː ɕ œ r k ɔ n s ɛ t ə n\n",
            "[2021-06-03 20:19:34,249][fairseq.tasks.unpaired_audio_text][INFO] - HYP: oː yː a yː h ʃ ə m oː uː d ɕ uː ɪ ə ʂ f oː tː m ɪ m yː ŋ iː uː ŋ iː uː iː uː ə m h ɪ sx m a ŋ sx\n",
            "[2021-06-03 20:19:34,256][fairseq.tasks.unpaired_audio_text][INFO] - LM [REF]: -53.44462585449219, 0.05339602260269112\n",
            "[2021-06-03 20:19:34,256][fairseq.tasks.unpaired_audio_text][INFO] - LM [HYP]: -87.96104431152344, 0.007154984138433159\n",
            "[2021-06-03 20:19:34,874][valid][INFO] - {\"epoch\": 2, \"valid_loss\": \"1.013\", \"valid_ntokens\": \"3039.79\", \"valid_nsentences\": \"144.214\", \"valid_lm_score_sum\": \"-100191\", \"valid_num_pred_chars\": \"41763\", \"valid_vocab_seen_pct\": \"0.947735\", \"valid_uer\": \"101.349\", \"valid_weighted_lm_ppl\": \"216.284\", \"valid_lm_ppl\": \"194.267\", \"valid_wps\": \"16732.7\", \"valid_wpb\": \"3039.8\", \"valid_bsz\": \"144.2\", \"valid_num_updates\": \"32\", \"valid_best_weighted_lm_ppl\": \"189.002\"}\n",
            "[2021-06-03 20:19:34,875][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 2 @ 32 updates\n",
            "[2021-06-03 20:19:34,876][fairseq.trainer][INFO] - Saving checkpoint to ./checkpoint2.pt\n",
            "[2021-06-03 20:19:34,911][fairseq.trainer][INFO] - Finished saving checkpoint to ./checkpoint2.pt\n",
            "[2021-06-03 20:19:34,925][fairseq.checkpoint_utils][INFO] - Saved checkpoint ./checkpoint2.pt (epoch 2 @ 32 updates, score 216.28420573137913) (writing took 0.04985905500006993 seconds)\n",
            "[2021-06-03 20:19:34,926][fairseq_cli.train][INFO] - end of epoch 2 (average epoch stats below)\n",
            "[2021-06-03 20:19:34,926][train][INFO] - {\"epoch\": 2, \"train_loss\": \"10.368\", \"train_ntokens\": \"145.688\", \"train_nsentences\": \"145.688\", \"train_temp\": \"1.998\", \"train_code_ppl\": \"7.924\", \"train_loss_code_pen\": \"0.048\", \"train_loss_smoothness\": \"1.384\", \"train_loss_dense_g\": \"0.371\", \"train_lm_score_sum\": 0.0, \"train_num_pred_chars\": 0.0, \"train_loss_grad_pen\": \"17.887\", \"train_loss_dense_d\": \"1.504\", \"train_loss_token_d\": \"1.409\", \"train_wps\": \"257.5\", \"train_ups\": \"1.77\", \"train_wpb\": \"145.7\", \"train_bsz\": \"145.7\", \"train_num_updates\": \"32\", \"train_lr_discriminator\": \"0.0005\", \"train_lr_generator\": \"0.0004\", \"train_gnorm\": \"40.835\", \"train_clip\": \"100\", \"train_train_wall\": \"5\", \"train_gb_free\": \"14.2\", \"train_wall\": \"19\"}\n",
            "[2021-06-03 20:19:34,958][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard\n",
            "[2021-06-03 20:19:34,961][fairseq.trainer][INFO] - begin training epoch 3\n",
            "[2021-06-03 20:19:34,961][fairseq_cli.train][INFO] - Start iterating over samples\n",
            "[2021-06-03 20:19:40,561][fairseq_cli.train][INFO] - begin validation on \"valid\" subset\n",
            "[2021-06-03 20:19:40,594][fairseq.logging.progress_bar][WARNING] - tensorboard not found, please install with: pip install tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}