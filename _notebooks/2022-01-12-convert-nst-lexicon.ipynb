{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert NST Swedish pronunciation lexicon to JSON\n",
    "\n",
    "> Converting the pronunciation to IPA along the way\n",
    "\n",
    "- toc: false\n",
    "- badges: true\n",
    "- branch: master\n",
    "- categories: [nst, swedish, pronunciation, icu]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Set up field reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyicu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_names = [\n",
    "    \"orthography\",\n",
    "    \"extended_pos\",\n",
    "    \"morphology\",\n",
    "    \"decomp\",\n",
    "    \"decpos\",\n",
    "    \"source\",\n",
    "    \"language_code\",\n",
    "    \"garbage\",\n",
    "    \"domain\",\n",
    "    \"abbr_acr\",\n",
    "    \"expansion\",\n",
    "    \"transliteration1\",\n",
    "    \"certainty_trans_1\",\n",
    "    \"status_trans_1\",\n",
    "    \"language_code_trans_1\",\n",
    "    \"transliteration2\",\n",
    "    \"certainty_trans_2\",\n",
    "    \"status_trans_2\",\n",
    "    \"language_code_trans_2\",\n",
    "    \"transliteration3\",\n",
    "    \"certainty_trans_3\",\n",
    "    \"status_trans_3\",\n",
    "    \"language_code_trans_3\",\n",
    "    \"transliteration4\",\n",
    "    \"certainty_trans_4\",\n",
    "    \"status_trans_4\",\n",
    "    \"language_code_trans_4\",\n",
    "    \"auto_gen_variants\",\n",
    "    \"set_id\",\n",
    "    \"set_name\",\n",
    "    \"style_status\",\n",
    "    \"inflector_role\",\n",
    "    \"lemma\",\n",
    "    \"inflection_rule\",\n",
    "    \"morph_label\",\n",
    "    \"compounder_code\",\n",
    "    \"semantic_info\",\n",
    "    \"available_field1\",\n",
    "    \"available_field2\",\n",
    "    \"available_field3\",\n",
    "    \"available_field4\",\n",
    "    \"available_field5\",\n",
    "    \"available_field6\",\n",
    "    \"available_field7\",\n",
    "    \"available_field8\",\n",
    "    \"available_field9\",\n",
    "    \"frequency\",\n",
    "    \"original_orthography\",\n",
    "    \"comment_field\",\n",
    "    \"update_info\",\n",
    "    \"unique_id\"\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL transformed to HTTPS due to an HSTS policy\n",
      "--2023-01-24 19:57:44--  https://www.nb.no/sbfil/leksikalske_databaser/leksikon/sv.leksikon.tar.gz\n",
      "Resolving www.nb.no (www.nb.no)... 158.39.129.53\n",
      "Connecting to www.nb.no (www.nb.no)|158.39.129.53|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 22041470 (21M) [application/octet-stream]\n",
      "Saving to: ‘/tmp/sv.leksikon.tar.gz’\n",
      "\n",
      "/tmp/sv.leksikon.ta 100%[===================>]  21,02M  3,54MB/s    in 5,4s    \n",
      "\n",
      "2023-01-24 19:57:50 (3,92 MB/s) - ‘/tmp/sv.leksikon.tar.gz’ saved [22041470/22041470]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://www.nb.no/sbfil/leksikalske_databaser/leksikon/sv.leksikon.tar.gz -O /tmp/sv.leksikon.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "with tarfile.open(\"/tmp/sv.leksikon.tar.gz\") as tar:\n",
    "    f = tar.extractfile(\"NST svensk leksikon/swe030224NST.pron/swe030224NST.pron\")\n",
    "    prondata = f.read()\n",
    "    prondata = prondata.decode('latin1')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Set up transliterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSLIT = \"\"\"\n",
    "n\\` → ɳ ;\n",
    "s\\` → ʂ ;\n",
    "l\\` → ɭ ;\n",
    "t\\` → ʈ ;\n",
    "d\\` → ɖ ;\n",
    "A → ɑ ;\n",
    "O → ɔ ;\n",
    "I → ɪ ;\n",
    "E \\* U → e \\u2040 ʊ ;\n",
    "E → ɛ ;\n",
    "U → ʊ ;\n",
    "Y → ʏ ;\n",
    "2 → ø ;\n",
    "9 → ø ;\n",
    "u 0 → ɵ ;\n",
    "N → ŋ ;\n",
    "'\"\"' → ² ;\n",
    "'\"' → ˈ ;\n",
    "\\% → ˌ ;\n",
    "\\: → ː ;\n",
    "\\$ → \\. ;\n",
    "g → ɡ ;\n",
    "s \\\\\\' → ɕ ;\n",
    "x \\\\\\\\ → ɧ ;\n",
    "\\* → \\u2040 ;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import icu\n",
    "def transliterator_from_rules(name, rules):\n",
    "    fromrules = icu.Transliterator.createFromRules(name, rules)\n",
    "    icu.Transliterator.registerInstance(fromrules)\n",
    "    return icu.Transliterator.createInstance(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "swelex_trans = transliterator_from_rules(\"swelex_trans\", TRANSLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert swelex_trans.transliterate('\"\"bA:n`s`$%ma$man') == \"²bɑːɳʂ.ˌma.man\"\n",
    "assert swelex_trans.transliterate('\"b9r$mIN$ham') == \"ˈbør.mɪŋ.ham\"\n",
    "assert swelex_trans.transliterate('\"bI$rU') == \"ˈbɪ.rʊ\"\n",
    "assert swelex_trans.transliterate('\"\"bIsp$%go:$d`en') == \"²bɪsp.ˌɡoː.ɖen\"\n",
    "assert swelex_trans.transliterate('\"x\\A:l') == \"ˈɧɑːl\"\n",
    "assert swelex_trans.transliterate(\"\\\"s'u:$lens\") == \"ˈɕuː.lens\"\n",
    "assert swelex_trans.transliterate('a$\"lE*U$te$n`a') == 'a.ˈle⁀ʊ.te.ɳa'\n",
    "assert swelex_trans.transliterate('\"fu0l') == 'ˈfɵl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collapse_available_fields(data):\n",
    "    output = []\n",
    "    for i in range(1, 10):\n",
    "        if data[f\"available_field{i}\"] != \"\":\n",
    "            output.append(data[f\"available_field{i}\"])\n",
    "        del data[f\"available_field{i}\"]\n",
    "    data[\"available_fields\"] = output\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collapse_transliterations(data):\n",
    "    output = []\n",
    "    for i in range(1, 5):\n",
    "        if data[f\"transliteration{i}\"] != \"\":\n",
    "            tmp = {}\n",
    "            tmp[\"transliteration\"] = data[f\"transliteration{i}\"]\n",
    "            tmp[\"ipa\"] = swelex_trans.transliterate(data[f\"transliteration{i}\"])\n",
    "            tmp[\"certainty\"] = data[f\"certainty_trans_{i}\"]\n",
    "            tmp[\"status\"] = data[f\"status_trans_{i}\"]\n",
    "            tmp[\"language_code\"] = data[f\"language_code_trans_{i}\"]\n",
    "            output.append(tmp)\n",
    "        del data[f\"transliteration{i}\"]\n",
    "        del data[f\"certainty_trans_{i}\"]\n",
    "        del data[f\"status_trans_{i}\"]\n",
    "        del data[f\"language_code_trans_{i}\"]\n",
    "    data[\"transliterations\"] = output\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import io\n",
    "with open(\"svlex.json\", \"w\") as outf:\n",
    "    swelexf = io.StringIO(prondata)\n",
    "    swelex = csv.DictReader(swelexf, delimiter=';', fieldnames=field_names, quoting=csv.QUOTE_NONE)\n",
    "    for row in swelex:\n",
    "        row[\"decomp\"] = [f for f in row[\"decomp\"].split(\"+\") if f != \"\"]\n",
    "        row = collapse_available_fields(row)\n",
    "        row = collapse_transliterations(row)\n",
    "        jsonstr = json.dumps(row)\n",
    "        outf.write(jsonstr + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ctcseg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "04f1aebeda7ca92f6170d2806fa3f3c0cbb14da723fd908a9af630117dfe1004"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
