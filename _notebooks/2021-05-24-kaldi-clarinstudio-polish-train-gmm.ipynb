{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "anonymous-balance",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T08:33:01.399286Z",
     "iopub.status.busy": "2021-05-25T08:33:01.398481Z",
     "iopub.status.idle": "2021-05-25T08:33:01.404398Z",
     "shell.execute_reply": "2021-05-25T08:33:01.403531Z"
    },
    "papermill": {
     "duration": 0.028906,
     "end_time": "2021-05-25T08:33:01.404664",
     "exception": false,
     "start_time": "2021-05-25T08:33:01.375758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt\n"
     ]
    }
   ],
   "source": [
    "%cd /opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "monthly-server",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-05-25T08:33:01.450073Z",
     "iopub.status.busy": "2021-05-25T08:33:01.436240Z",
     "iopub.status.idle": "2021-05-25T08:34:32.675378Z",
     "shell.execute_reply": "2021-05-25T08:34:32.675862Z"
    },
    "papermill": {
     "duration": 91.258149,
     "end_time": "2021-05-25T08:34:32.676084",
     "exception": false,
     "start_time": "2021-05-25T08:33:01.417935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!tar xvf /kaggle/input/extract-prebuilt-kaldi-from-docker/kaldi.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "maritime-catalog",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T08:34:32.706435Z",
     "iopub.status.busy": "2021-05-25T08:34:32.705714Z",
     "iopub.status.idle": "2021-05-25T08:34:32.711827Z",
     "shell.execute_reply": "2021-05-25T08:34:32.712457Z"
    },
    "papermill": {
     "duration": 0.024632,
     "end_time": "2021-05-25T08:34:32.712656",
     "exception": false,
     "start_time": "2021-05-25T08:34:32.688024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/kaldi/egs\n"
     ]
    }
   ],
   "source": [
    "%cd kaldi/egs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "million-antenna",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T08:34:32.745981Z",
     "iopub.status.busy": "2021-05-25T08:34:32.741407Z",
     "iopub.status.idle": "2021-05-25T08:34:37.477514Z",
     "shell.execute_reply": "2021-05-25T08:34:37.476617Z"
    },
    "papermill": {
     "duration": 4.752829,
     "end_time": "2021-05-25T08:34:37.477667",
     "exception": false,
     "start_time": "2021-05-25T08:34:32.724838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ClarinStudioKaldi'...\r\n",
      "remote: Enumerating objects: 778, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (3/3), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (3/3), done.\u001b[K\r\n",
      "remote: Total 778 (delta 0), reused 0 (delta 0), pack-reused 775\u001b[K\r\n",
      "Receiving objects: 100% (778/778), 35.26 MiB | 19.50 MiB/s, done.\r\n",
      "Resolving deltas: 100% (262/262), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/danijel3/ClarinStudioKaldi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "living-swiss",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T08:34:37.515658Z",
     "iopub.status.busy": "2021-05-25T08:34:37.515001Z",
     "iopub.status.idle": "2021-05-25T08:34:37.520358Z",
     "shell.execute_reply": "2021-05-25T08:34:37.519587Z"
    },
    "papermill": {
     "duration": 0.026805,
     "end_time": "2021-05-25T08:34:37.520506",
     "exception": false,
     "start_time": "2021-05-25T08:34:37.493701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/kaldi/egs/ClarinStudioKaldi\n"
     ]
    }
   ],
   "source": [
    "%cd ClarinStudioKaldi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "separate-bulgaria",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T08:34:37.557460Z",
     "iopub.status.busy": "2021-05-25T08:34:37.556824Z",
     "iopub.status.idle": "2021-05-25T08:37:13.087453Z",
     "shell.execute_reply": "2021-05-25T08:37:13.087964Z"
    },
    "papermill": {
     "duration": 155.551135,
     "end_time": "2021-05-25T08:37:13.088179",
     "exception": false,
     "start_time": "2021-05-25T08:34:37.537044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\r\n",
      "Solving environment: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\r\n",
      "\r\n",
      "## Package Plan ##\r\n",
      "\r\n",
      "  environment location: /opt/conda\r\n",
      "\r\n",
      "  added / updated specs:\r\n",
      "    - perl-perlio-gzip\r\n",
      "\r\n",
      "\r\n",
      "The following packages will be downloaded:\r\n",
      "\r\n",
      "    package                    |            build\r\n",
      "    ---------------------------|-----------------\r\n",
      "    perl-5.26.2                |    h36c2ea0_1008        15.4 MB  conda-forge\r\n",
      "    perl-perlio-gzip-0.20      |  pl526h84994c4_1          17 KB  bioconda\r\n",
      "    ------------------------------------------------------------\r\n",
      "                                           Total:        15.4 MB\r\n",
      "\r\n",
      "The following NEW packages will be INSTALLED:\r\n",
      "\r\n",
      "  perl-perlio-gzip   bioconda/linux-64::perl-perlio-gzip-0.20-pl526h84994c4_1\r\n",
      "\r\n",
      "The following packages will be DOWNGRADED:\r\n",
      "\r\n",
      "  perl                                    5.32.0-h36c2ea0_0 --> 5.26.2-h36c2ea0_1008\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "Downloading and Extracting Packages\r\n",
      "perl-5.26.2          | 15.4 MB   | ##################################### | 100% \r\n",
      "perl-perlio-gzip-0.2 | 17 KB     | ##################################### | 100% \r\n",
      "Preparing transaction: \\ \b\b| \b\bdone\r\n",
      "Verifying transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\r\n",
      "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\r\n"
     ]
    }
   ],
   "source": [
    "#apt-get -y install libperlio-gzip-perl\n",
    "!conda install -c bioconda perl-perlio-gzip -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "after-shade",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T08:37:13.678282Z",
     "iopub.status.busy": "2021-05-25T08:37:13.677636Z",
     "iopub.status.idle": "2021-05-25T08:37:13.680512Z",
     "shell.execute_reply": "2021-05-25T08:37:13.681009Z"
    },
    "papermill": {
     "duration": 0.300675,
     "end_time": "2021-05-25T08:37:13.681197",
     "exception": false,
     "start_time": "2021-05-25T08:37:13.380522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ['LD_LIBRARY_PATH'] = f'{os.environ[\"LD_LIBRARY_PATH\"]}:/opt/kaldi/tools/openfst-1.6.7/lib:/opt/kaldi/src/lib'\n",
    "os.environ['LD_LIBRARY_PATH'] = '/opt/conda/lib:/opt/kaldi/tools/openfst-1.6.7/lib:/opt/kaldi/src/lib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "functional-links",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T08:37:14.276668Z",
     "iopub.status.busy": "2021-05-25T08:37:14.273293Z",
     "iopub.status.idle": "2021-05-25T08:37:15.749099Z",
     "shell.execute_reply": "2021-05-25T08:37:15.748527Z"
    },
    "papermill": {
     "duration": 1.774641,
     "end_time": "2021-05-25T08:37:15.749243",
     "exception": false,
     "start_time": "2021-05-25T08:37:13.974602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cat path.sh|sed -e 's/~\\/apps/\\/opt/' > tmp\n",
    "!mv tmp path.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "boring-yacht",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T08:37:16.344270Z",
     "iopub.status.busy": "2021-05-25T08:37:16.340678Z",
     "iopub.status.idle": "2021-05-25T08:37:17.054125Z",
     "shell.execute_reply": "2021-05-25T08:37:17.053529Z"
    },
    "papermill": {
     "duration": 1.010057,
     "end_time": "2021-05-25T08:37:17.054275",
     "exception": false,
     "start_time": "2021-05-25T08:37:16.044218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!echo > local_clarin/clarin_pl_clean.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "classical-product",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T08:37:17.650557Z",
     "iopub.status.busy": "2021-05-25T08:37:17.647385Z",
     "iopub.status.idle": "2021-05-25T08:37:20.540261Z",
     "shell.execute_reply": "2021-05-25T08:37:20.540761Z"
    },
    "papermill": {
     "duration": 3.19256,
     "end_time": "2021-05-25T08:37:20.540972",
     "exception": false,
     "start_time": "2021-05-25T08:37:17.348412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!ln -s ../wsj/s5/steps\n",
    "!ln -s ../wsj/s5/conf\n",
    "!ln -s ../wsj/s5/local\n",
    "!ln -s ../wsj/s5/utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "quiet-field",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T08:37:21.136176Z",
     "iopub.status.busy": "2021-05-25T08:37:21.135526Z",
     "iopub.status.idle": "2021-05-25T08:37:31.146646Z",
     "shell.execute_reply": "2021-05-25T08:37:31.145191Z"
    },
    "papermill": {
     "duration": 10.311463,
     "end_time": "2021-05-25T08:37:31.146825",
     "exception": false,
     "start_time": "2021-05-25T08:37:20.835362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp -r /kaggle/input/kaldi-clarinstudio-polish-data-prep/data /kaggle/working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "little-signal",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T08:37:31.743946Z",
     "iopub.status.busy": "2021-05-25T08:37:31.739821Z",
     "iopub.status.idle": "2021-05-25T08:37:33.883440Z",
     "shell.execute_reply": "2021-05-25T08:37:33.882873Z"
    },
    "papermill": {
     "duration": 2.442242,
     "end_time": "2021-05-25T08:37:33.883590",
     "exception": false,
     "start_time": "2021-05-25T08:37:31.441348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir /kaggle/working/exp\n",
    "!ln -s /kaggle/working/exp\n",
    "!ln -s /kaggle/working/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "computational-relaxation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T08:37:34.479950Z",
     "iopub.status.busy": "2021-05-25T08:37:34.478864Z",
     "iopub.status.idle": "2021-05-25T08:37:34.483794Z",
     "shell.execute_reply": "2021-05-25T08:37:34.483137Z"
    },
    "papermill": {
     "duration": 0.304112,
     "end_time": "2021-05-25T08:37:34.483953",
     "exception": false,
     "start_time": "2021-05-25T08:37:34.179841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting run.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile run.sh\n",
    ". path.sh\n",
    "\n",
    "export nj=40 ##number of concurrent processes\n",
    "export nj_test=30 ## number of concurrent processes for test has to be <=30\n",
    "\n",
    "#train Monophone system\n",
    "steps/train_mono.sh --nj $nj data/train data/lang_nosp exp/mono0\n",
    "\n",
    "#align using the Monophone system\n",
    "steps/align_si.sh --nj $nj data/train data/lang_nosp exp/mono0 exp/mono0_ali\n",
    "\n",
    "#train initial Triphone system\n",
    "steps/train_deltas.sh 2000 10000 data/train data/lang_nosp exp/mono0_ali exp/tri1\n",
    "\n",
    "#re-align using the initial Triphone system\n",
    "steps/align_si.sh --nj $nj data/train data/lang_nosp exp/tri1 exp/tri1_ali\n",
    "\n",
    "#train tri2a, which is deltas + delta-deltas\n",
    "steps/train_deltas.sh 2500 15000 data/train data/lang_nosp exp/tri1_ali exp/tri2a\n",
    "\n",
    "#train tri2b, which is tri2a + LDA\n",
    "steps/train_lda_mllt.sh --splice-opts \"--left-context=3 --right-context=3\" \\\n",
    "   2500 15000 data/train data/lang_nosp exp/tri1_ali exp/tri2b\n",
    "\n",
    "#re-align tri2b system\n",
    "steps/align_si.sh --nj $nj --use-graphs true data/train data/lang_nosp exp/tri2b exp/tri2b_ali \n",
    "\n",
    "\n",
    "#from 2b system, train 3b which is LDA + MLLT + SAT.\n",
    "steps/train_sat.sh 2500 15000 data/train data/lang_nosp exp/tri2b_ali exp/tri3b\n",
    "\n",
    "#get pronounciation probabilities and silence information \n",
    "./steps/get_prons.sh data/train data/lang_nosp exp/tri3b\n",
    "\n",
    "#recreate dict with new pronounciation and silence probabilities\n",
    "./utils/dict_dir_add_pronprobs.sh data/local/dict_nosp \\\n",
    "\texp/tri3b/pron_counts_nowb.txt \\\n",
    "\texp/tri3b/sil_counts_nowb.txt \\\n",
    "\texp/tri3b/pron_bigram_counts_nowb.txt data/local/dict\n",
    "\n",
    "#recreate lang directory\n",
    "utils/prepare_lang.sh data/local/dict \"<unk>\" data/local/tmp data/lang\n",
    "\n",
    "#recreate G.fst\n",
    "utils/format_lm.sh data/lang local_clarin/arpa.lm.gz data/local/dict/lexicon.txt data/lang_test\n",
    "\n",
    "#download a large LM (~843MB)\n",
    "if [ ! -f local_clarin/large.arpa.gz ] ; then\n",
    "(\n",
    "\tcd local_clarin\n",
    "\tcurl -O http://mowa.clarin-pl.eu/korpusy/large.arpa.gz\n",
    ")\n",
    "fi\n",
    "\n",
    "#create the const-arpa lang dir\n",
    "./utils/build_const_arpa_lm.sh local_clarin/large.arpa.gz data/lang data/lang_carpa\n",
    "\n",
    "#from 3b system, align all data\n",
    "steps/align_fmllr.sh --nj $nj data/train data/lang exp/tri3b exp/tri3b_ali\n",
    "\n",
    "#train MMI on tri3b (LDA+MLLT+SAT)\n",
    "steps/make_denlats.sh --nj $nj --transform-dir exp/tri3b_ali data/train data/lang \\\n",
    "\texp/tri3b exp/tri3b_denlats\n",
    "steps/train_mmi.sh data/train data/lang exp/tri3b_ali exp/tri3b_denlats exp/tri3b_mmi\n",
    "\n",
    "#test Monophone system\n",
    "utils/mkgraph.sh data/lang_nosp_test exp/mono0 exp/mono0/graph\n",
    "steps/decode.sh --nj $nj_test exp/mono0/graph data/test exp/mono0/decode\n",
    "\n",
    "#test initial Triphone system\n",
    "utils/mkgraph.sh data/lang_nosp_test exp/tri1 exp/tri1/graph\n",
    "steps/decode.sh --nj $nj_test exp/tri1/graph data/test exp/tri1/decode\n",
    "\n",
    "#test tri2a\n",
    "utils/mkgraph.sh data/lang_nosp_test exp/tri2a exp/tri2a/graph\n",
    "steps/decode.sh --nj $nj_test exp/tri2a/graph data/test exp/tri2a/decode\n",
    "\n",
    "#test tri2b\n",
    "utils/mkgraph.sh data/lang_nosp_test exp/tri2b exp/tri2b/graph\n",
    "steps/decode.sh --nj $nj_test exp/tri2b/graph data/test exp/tri2b/decode\n",
    "\n",
    "#test tri3b\n",
    "utils/mkgraph.sh data/lang_nosp_test exp/tri3b exp/tri3b/graph_nosp\n",
    "steps/decode_fmllr.sh --nj $nj_test exp/tri3b/graph_nosp data/test exp/tri3b/decode_nosp\n",
    "\n",
    "#test tri3b again\n",
    "utils/mkgraph.sh data/lang_test exp/tri3b exp/tri3b/graph\n",
    "steps/decode_fmllr.sh --nj $nj_test exp/tri3b/graph data/test exp/tri3b/decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cardiac-momentum",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T08:37:35.133132Z",
     "iopub.status.busy": "2021-05-25T08:37:35.129388Z",
     "iopub.status.idle": "2021-05-25T16:59:25.452007Z",
     "shell.execute_reply": "2021-05-25T16:59:25.451253Z"
    },
    "papermill": {
     "duration": 30110.623201,
     "end_time": "2021-05-25T16:59:25.452177",
     "exception": false,
     "start_time": "2021-05-25T08:37:34.828976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steps/train_mono.sh --nj 40 data/train data/lang_nosp exp/mono0\r\n",
      "steps/train_mono.sh: Initializing monophone system.\r\n",
      "steps/train_mono.sh: Compiling training graphs\r\n",
      "steps/train_mono.sh: Aligning data equally (pass 0)\r\n",
      "steps/train_mono.sh: Pass 1\r\n",
      "steps/train_mono.sh: Aligning data\r\n",
      "steps/train_mono.sh: Pass 2\r\n",
      "steps/train_mono.sh: Aligning data\r\n",
      "steps/train_mono.sh: Pass 3\r\n",
      "steps/train_mono.sh: Aligning data\r\n",
      "steps/train_mono.sh: Pass 4\r\n",
      "steps/train_mono.sh: Aligning data\r\n",
      "steps/train_mono.sh: Pass 5\r\n",
      "steps/train_mono.sh: Aligning data\r\n",
      "steps/train_mono.sh: Pass 6\r\n",
      "steps/train_mono.sh: Aligning data\r\n",
      "steps/train_mono.sh: Pass 7\r\n",
      "steps/train_mono.sh: Aligning data\r\n",
      "steps/train_mono.sh: Pass 8\r\n",
      "steps/train_mono.sh: Aligning data\r\n",
      "steps/train_mono.sh: Pass 9\r\n",
      "steps/train_mono.sh: Aligning data\r\n",
      "steps/train_mono.sh: Pass 10\r\n",
      "steps/train_mono.sh: Aligning data\r\n",
      "steps/train_mono.sh: Pass 11\r\n",
      "steps/train_mono.sh: Pass 12\r\n",
      "steps/train_mono.sh: Aligning data\r\n",
      "steps/train_mono.sh: Pass 13\r\n",
      "steps/train_mono.sh: Pass 14\r\n",
      "steps/train_mono.sh: Aligning data\r\n",
      "steps/train_mono.sh: Pass 15\r\n",
      "steps/train_mono.sh: Pass 16\r\n",
      "steps/train_mono.sh: Aligning data\r\n",
      "steps/train_mono.sh: Pass 17\r\n",
      "steps/train_mono.sh: Pass 18\r\n",
      "steps/train_mono.sh: Aligning data\r\n",
      "steps/train_mono.sh: Pass 19\r\n",
      "steps/train_mono.sh: Pass 20\r\n",
      "steps/train_mono.sh: Aligning data\r\n",
      "steps/train_mono.sh: Pass 21\r\n",
      "steps/train_mono.sh: Pass 22\r\n",
      "steps/train_mono.sh: Pass 23\r\n",
      "steps/train_mono.sh: Aligning data\r\n",
      "steps/train_mono.sh: Pass 24\r\n",
      "steps/train_mono.sh: Pass 25\r\n",
      "steps/train_mono.sh: Pass 26\r\n",
      "steps/train_mono.sh: Aligning data\r\n",
      "steps/train_mono.sh: Pass 27\r\n",
      "steps/train_mono.sh: Pass 28\r\n",
      "steps/train_mono.sh: Pass 29\r\n",
      "steps/train_mono.sh: Aligning data\r\n",
      "steps/train_mono.sh: Pass 30\r\n",
      "steps/train_mono.sh: Pass 31\r\n",
      "steps/train_mono.sh: Pass 32\r\n",
      "steps/train_mono.sh: Aligning data\r\n",
      "steps/train_mono.sh: Pass 33\r\n",
      "steps/train_mono.sh: Pass 34\r\n",
      "steps/train_mono.sh: Pass 35\r\n",
      "steps/train_mono.sh: Aligning data\r\n",
      "steps/train_mono.sh: Pass 36\r\n",
      "steps/train_mono.sh: Pass 37\r\n",
      "steps/train_mono.sh: Pass 38\r\n",
      "steps/train_mono.sh: Aligning data\r\n",
      "steps/train_mono.sh: Pass 39\r\n",
      "steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang_nosp exp/mono0\r\n",
      "steps/diagnostic/analyze_alignments.sh: see stats in exp/mono0/log/analyze_alignments.log\r\n",
      "6 warnings in exp/mono0/log/init.log\r\n",
      "13685 warnings in exp/mono0/log/align.*.*.log\r\n",
      "570 warnings in exp/mono0/log/acc.*.*.log\r\n",
      "exp/mono0: nj=40 align prob=-94.80 over 43.76h [retry=0.4%, fail=0.0%] states=113 gauss=985\r\n",
      "steps/train_mono.sh: Done training monophone system in exp/mono0\r\n",
      "steps/align_si.sh --nj 40 data/train data/lang_nosp exp/mono0 exp/mono0_ali\r\n",
      "steps/align_si.sh: feature type is delta\r\n",
      "steps/align_si.sh: aligning data in data/train using model from exp/mono0, putting alignments in exp/mono0_ali\r\n",
      "steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang_nosp exp/mono0_ali\r\n",
      "steps/diagnostic/analyze_alignments.sh: see stats in exp/mono0_ali/log/analyze_alignments.log\r\n",
      "steps/align_si.sh: done aligning data.\r\n",
      "steps/train_deltas.sh 2000 10000 data/train data/lang_nosp exp/mono0_ali exp/tri1\r\n",
      "steps/train_deltas.sh: accumulating tree stats\r\n",
      "steps/train_deltas.sh: getting questions for tree-building, via clustering\r\n",
      "steps/train_deltas.sh: building the tree\r\n",
      "steps/train_deltas.sh: converting alignments from exp/mono0_ali to use current tree\r\n",
      "steps/train_deltas.sh: compiling graphs of transcripts\r\n",
      "steps/train_deltas.sh: training pass 1\r\n",
      "steps/train_deltas.sh: training pass 2\r\n",
      "steps/train_deltas.sh: training pass 3\r\n",
      "steps/train_deltas.sh: training pass 4\r\n",
      "steps/train_deltas.sh: training pass 5\r\n",
      "steps/train_deltas.sh: training pass 6\r\n",
      "steps/train_deltas.sh: training pass 7\r\n",
      "steps/train_deltas.sh: training pass 8\r\n",
      "steps/train_deltas.sh: training pass 9\r\n",
      "steps/train_deltas.sh: training pass 10\r\n",
      "steps/train_deltas.sh: aligning data\r\n",
      "steps/train_deltas.sh: training pass 11\r\n",
      "steps/train_deltas.sh: training pass 12\r\n",
      "steps/train_deltas.sh: training pass 13\r\n",
      "steps/train_deltas.sh: training pass 14\r\n",
      "steps/train_deltas.sh: training pass 15\r\n",
      "steps/train_deltas.sh: training pass 16\r\n",
      "steps/train_deltas.sh: training pass 17\r\n",
      "steps/train_deltas.sh: training pass 18\r\n",
      "steps/train_deltas.sh: training pass 19\r\n",
      "steps/train_deltas.sh: training pass 20\r\n",
      "steps/train_deltas.sh: aligning data\r\n",
      "steps/train_deltas.sh: training pass 21\r\n",
      "steps/train_deltas.sh: training pass 22\r\n",
      "steps/train_deltas.sh: training pass 23\r\n",
      "steps/train_deltas.sh: training pass 24\r\n",
      "steps/train_deltas.sh: training pass 25\r\n",
      "steps/train_deltas.sh: training pass 26\r\n",
      "steps/train_deltas.sh: training pass 27\r\n",
      "steps/train_deltas.sh: training pass 28\r\n",
      "steps/train_deltas.sh: training pass 29\r\n",
      "steps/train_deltas.sh: training pass 30\r\n",
      "steps/train_deltas.sh: aligning data\r\n",
      "steps/train_deltas.sh: training pass 31\r\n",
      "steps/train_deltas.sh: training pass 32\r\n",
      "steps/train_deltas.sh: training pass 33\r\n",
      "steps/train_deltas.sh: training pass 34\r\n",
      "steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang_nosp exp/tri1\r\n",
      "steps/diagnostic/analyze_alignments.sh: see stats in exp/tri1/log/analyze_alignments.log\r\n",
      "1 warnings in exp/tri1/log/compile_questions.log\r\n",
      "409 warnings in exp/tri1/log/align.*.*.log\r\n",
      "1 warnings in exp/tri1/log/build_tree.log\r\n",
      "211 warnings in exp/tri1/log/acc.*.*.log\r\n",
      "exp/tri1: nj=40 align prob=-92.83 over 43.74h [retry=0.9%, fail=0.1%] states=1704 gauss=10023 tree-impr=4.66\r\n",
      "steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri1\r\n",
      "steps/align_si.sh --nj 40 data/train data/lang_nosp exp/tri1 exp/tri1_ali\r\n",
      "steps/align_si.sh: feature type is delta\r\n",
      "steps/align_si.sh: aligning data in data/train using model from exp/tri1, putting alignments in exp/tri1_ali\r\n",
      "steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang_nosp exp/tri1_ali\r\n",
      "steps/diagnostic/analyze_alignments.sh: see stats in exp/tri1_ali/log/analyze_alignments.log\r\n",
      "steps/align_si.sh: done aligning data.\r\n",
      "steps/train_deltas.sh 2500 15000 data/train data/lang_nosp exp/tri1_ali exp/tri2a\r\n",
      "steps/train_deltas.sh: accumulating tree stats\r\n",
      "steps/train_deltas.sh: getting questions for tree-building, via clustering\r\n",
      "steps/train_deltas.sh: building the tree\r\n",
      "steps/train_deltas.sh: converting alignments from exp/tri1_ali to use current tree\r\n",
      "steps/train_deltas.sh: compiling graphs of transcripts\r\n",
      "steps/train_deltas.sh: training pass 1\r\n",
      "steps/train_deltas.sh: training pass 2\r\n",
      "steps/train_deltas.sh: training pass 3\r\n",
      "steps/train_deltas.sh: training pass 4\r\n",
      "steps/train_deltas.sh: training pass 5\r\n",
      "steps/train_deltas.sh: training pass 6\r\n",
      "steps/train_deltas.sh: training pass 7\r\n",
      "steps/train_deltas.sh: training pass 8\r\n",
      "steps/train_deltas.sh: training pass 9\r\n",
      "steps/train_deltas.sh: training pass 10\r\n",
      "steps/train_deltas.sh: aligning data\r\n",
      "steps/train_deltas.sh: training pass 11\r\n",
      "steps/train_deltas.sh: training pass 12\r\n",
      "steps/train_deltas.sh: training pass 13\r\n",
      "steps/train_deltas.sh: training pass 14\r\n",
      "steps/train_deltas.sh: training pass 15\r\n",
      "steps/train_deltas.sh: training pass 16\r\n",
      "steps/train_deltas.sh: training pass 17\r\n",
      "steps/train_deltas.sh: training pass 18\r\n",
      "steps/train_deltas.sh: training pass 19\r\n",
      "steps/train_deltas.sh: training pass 20\r\n",
      "steps/train_deltas.sh: aligning data\r\n",
      "steps/train_deltas.sh: training pass 21\r\n",
      "steps/train_deltas.sh: training pass 22\r\n",
      "steps/train_deltas.sh: training pass 23\r\n",
      "steps/train_deltas.sh: training pass 24\r\n",
      "steps/train_deltas.sh: training pass 25\r\n",
      "steps/train_deltas.sh: training pass 26\r\n",
      "steps/train_deltas.sh: training pass 27\r\n",
      "steps/train_deltas.sh: training pass 28\r\n",
      "steps/train_deltas.sh: training pass 29\r\n",
      "steps/train_deltas.sh: training pass 30\r\n",
      "steps/train_deltas.sh: aligning data\r\n",
      "steps/train_deltas.sh: training pass 31\r\n",
      "steps/train_deltas.sh: training pass 32\r\n",
      "steps/train_deltas.sh: training pass 33\r\n",
      "steps/train_deltas.sh: training pass 34\r\n",
      "steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang_nosp exp/tri2a\r\n",
      "steps/diagnostic/analyze_alignments.sh: see stats in exp/tri2a/log/analyze_alignments.log\r\n",
      "341 warnings in exp/tri2a/log/acc.*.*.log\r\n",
      "1 warnings in exp/tri2a/log/compile_questions.log\r\n",
      "1 warnings in exp/tri2a/log/build_tree.log\r\n",
      "458 warnings in exp/tri2a/log/align.*.*.log\r\n",
      "exp/tri2a: nj=40 align prob=-92.40 over 43.73h [retry=0.8%, fail=0.1%] states=2128 gauss=15027 tree-impr=5.40\r\n",
      "steps/train_deltas.sh: Done training system with delta+delta-delta features in exp/tri2a\r\n",
      "steps/train_lda_mllt.sh --splice-opts --left-context=3 --right-context=3 2500 15000 data/train data/lang_nosp exp/tri1_ali exp/tri2b\r\n",
      "steps/train_lda_mllt.sh: Accumulating LDA statistics.\r\n",
      "steps/train_lda_mllt.sh: Accumulating tree stats\r\n",
      "steps/train_lda_mllt.sh: Getting questions for tree clustering.\r\n",
      "steps/train_lda_mllt.sh: Building the tree\r\n",
      "steps/train_lda_mllt.sh: Initializing the model\r\n",
      "steps/train_lda_mllt.sh: Converting alignments from exp/tri1_ali to use current tree\r\n",
      "steps/train_lda_mllt.sh: Compiling graphs of transcripts\r\n",
      "Training pass 1\r\n",
      "Training pass 2\r\n",
      "steps/train_lda_mllt.sh: Estimating MLLT\r\n",
      "Training pass 3\r\n",
      "Training pass 4\r\n",
      "steps/train_lda_mllt.sh: Estimating MLLT\r\n",
      "Training pass 5\r\n",
      "Training pass 6\r\n",
      "steps/train_lda_mllt.sh: Estimating MLLT\r\n",
      "Training pass 7\r\n",
      "Training pass 8\r\n",
      "Training pass 9\r\n",
      "Training pass 10\r\n",
      "Aligning data\r\n",
      "Training pass 11\r\n",
      "Training pass 12\r\n",
      "steps/train_lda_mllt.sh: Estimating MLLT\r\n",
      "Training pass 13\r\n",
      "Training pass 14\r\n",
      "Training pass 15\r\n",
      "Training pass 16\r\n",
      "Training pass 17\r\n",
      "Training pass 18\r\n",
      "Training pass 19\r\n",
      "Training pass 20\r\n",
      "Aligning data\r\n",
      "Training pass 21\r\n",
      "Training pass 22\r\n",
      "Training pass 23\r\n",
      "Training pass 24\r\n",
      "Training pass 25\r\n",
      "Training pass 26\r\n",
      "Training pass 27\r\n",
      "Training pass 28\r\n",
      "Training pass 29\r\n",
      "Training pass 30\r\n",
      "Aligning data\r\n",
      "Training pass 31\r\n",
      "Training pass 32\r\n",
      "Training pass 33\r\n",
      "Training pass 34\r\n",
      "steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang_nosp exp/tri2b\r\n",
      "steps/diagnostic/analyze_alignments.sh: see stats in exp/tri2b/log/analyze_alignments.log\r\n",
      "9 warnings in exp/tri2b/log/lda_acc.*.log\r\n",
      "604 warnings in exp/tri2b/log/align.*.*.log\r\n",
      "1 warnings in exp/tri2b/log/compile_questions.log\r\n",
      "1 warnings in exp/tri2b/log/build_tree.log\r\n",
      "381 warnings in exp/tri2b/log/acc.*.*.log\r\n",
      "exp/tri2b: nj=40 align prob=-44.56 over 43.72h [retry=1.1%, fail=0.1%] states=2096 gauss=15033 tree-impr=4.91 lda-sum=25.48 mllt:impr,logdet=1.29,1.86\r\n",
      "steps/train_lda_mllt.sh: Done training system with LDA+MLLT features in exp/tri2b\r\n",
      "steps/align_si.sh --nj 40 --use-graphs true data/train data/lang_nosp exp/tri2b exp/tri2b_ali\r\n",
      "steps/align_si.sh: feature type is lda\r\n",
      "steps/align_si.sh: aligning data in data/train using model from exp/tri2b, putting alignments in exp/tri2b_ali\r\n",
      "steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang_nosp exp/tri2b_ali\r\n",
      "steps/diagnostic/analyze_alignments.sh: see stats in exp/tri2b_ali/log/analyze_alignments.log\r\n",
      "steps/align_si.sh: done aligning data.\r\n",
      "steps/train_sat.sh 2500 15000 data/train data/lang_nosp exp/tri2b_ali exp/tri3b\r\n",
      "steps/train_sat.sh: feature type is lda\r\n",
      "steps/train_sat.sh: obtaining initial fMLLR transforms since not present in exp/tri2b_ali\r\n",
      "steps/train_sat.sh: Accumulating tree stats\r\n",
      "steps/train_sat.sh: Getting questions for tree clustering.\r\n",
      "steps/train_sat.sh: Building the tree\r\n",
      "steps/train_sat.sh: Initializing the model\r\n",
      "steps/train_sat.sh: Converting alignments from exp/tri2b_ali to use current tree\r\n",
      "steps/train_sat.sh: Compiling graphs of transcripts\r\n",
      "Pass 1\r\n",
      "Pass 2\r\n",
      "Estimating fMLLR transforms\r\n",
      "Pass 3\r\n",
      "Pass 4\r\n",
      "Estimating fMLLR transforms\r\n",
      "Pass 5\r\n",
      "Pass 6\r\n",
      "Estimating fMLLR transforms\r\n",
      "Pass 7\r\n",
      "Pass 8\r\n",
      "Pass 9\r\n",
      "Pass 10\r\n",
      "Aligning data\r\n",
      "Pass 11\r\n",
      "Pass 12\r\n",
      "Estimating fMLLR transforms\r\n",
      "Pass 13\r\n",
      "Pass 14\r\n",
      "Pass 15\r\n",
      "Pass 16\r\n",
      "Pass 17\r\n",
      "Pass 18\r\n",
      "Pass 19\r\n",
      "Pass 20\r\n",
      "Aligning data\r\n",
      "Pass 21\r\n",
      "Pass 22\r\n",
      "Pass 23\r\n",
      "Pass 24\r\n",
      "Pass 25\r\n",
      "Pass 26\r\n",
      "Pass 27\r\n",
      "Pass 28\r\n",
      "Pass 29\r\n",
      "Pass 30\r\n",
      "Aligning data\r\n",
      "Pass 31\r\n",
      "Pass 32\r\n",
      "Pass 33\r\n",
      "Pass 34\r\n",
      "steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang_nosp exp/tri3b\r\n",
      "steps/diagnostic/analyze_alignments.sh: see stats in exp/tri3b/log/analyze_alignments.log\r\n",
      "473 warnings in exp/tri3b/log/acc.*.*.log\r\n",
      "64 warnings in exp/tri3b/log/fmllr.*.*.log\r\n",
      "1 warnings in exp/tri3b/log/compile_questions.log\r\n",
      "1 warnings in exp/tri3b/log/build_tree.log\r\n",
      "583 warnings in exp/tri3b/log/align.*.*.log\r\n",
      "steps/train_sat.sh: Likelihood evolution:\r\n",
      "-45.9508 -45.85 -45.7247 -45.4359 -44.6939 -44.1379 -43.8041 -43.5859 -43.4144 -42.9505 -42.7691 -42.5425 -42.4252 -42.3214 -42.2249 -42.1378 -42.0604 -41.9908 -41.9227 -41.7803 -41.6983 -41.6454 -41.5976 -41.5531 -41.5103 -41.4696 -41.4309 -41.3943 -41.3591 -41.2819 -41.2358 -41.2145 -41.2011 -41.1919 \r\n",
      "exp/tri3b: nj=40 align prob=-44.29 over 43.72h [retry=1.0%, fail=0.1%] states=2112 gauss=15018 fmllr-impr=3.04 over 30.86h tree-impr=7.64\r\n",
      "steps/train_sat.sh: done training SAT system in exp/tri3b\r\n",
      "./steps/get_prons.sh data/train data/lang_nosp exp/tri3b\r\n",
      "./steps/get_prons.sh: exp/tri3b/ali.1.gz exists, so starting from alignments.\r\n",
      "./steps/get_prons.sh: done writing prons to exp/tri3b/prons.*.gz, silence counts in \r\n",
      "./steps/get_prons.sh: exp/tri3b/sil_counts_nowb.txt and pronunciation counts in \r\n",
      "./steps/get_prons.sh: exp/tri3b/pron_counts.{int,txt}\r\n",
      "./steps/get_prons.sh: ... and also in exp/tri3b/pron_counts_nowb.txt\r\n",
      "Checking data/local/dict_nosp/silence_phones.txt ...\r\n",
      "--> reading data/local/dict_nosp/silence_phones.txt\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> data/local/dict_nosp/silence_phones.txt is OK\r\n",
      "\r\n",
      "Checking data/local/dict_nosp/optional_silence.txt ...\r\n",
      "--> reading data/local/dict_nosp/optional_silence.txt\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> data/local/dict_nosp/optional_silence.txt is OK\r\n",
      "\r\n",
      "Checking data/local/dict_nosp/nonsilence_phones.txt ...\r\n",
      "--> reading data/local/dict_nosp/nonsilence_phones.txt\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> data/local/dict_nosp/nonsilence_phones.txt is OK\r\n",
      "\r\n",
      "Checking disjoint: silence_phones.txt, nonsilence_phones.txt\r\n",
      "--> disjoint property is OK.\r\n",
      "\r\n",
      "Checking data/local/dict_nosp/lexicon.txt\r\n",
      "--> reading data/local/dict_nosp/lexicon.txt\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> data/local/dict_nosp/lexicon.txt is OK\r\n",
      "\r\n",
      "Checking data/local/dict_nosp/lexiconp.txt\r\n",
      "--> reading data/local/dict_nosp/lexiconp.txt\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> data/local/dict_nosp/lexiconp.txt is OK\r\n",
      "\r\n",
      "Checking lexicon pair data/local/dict_nosp/lexicon.txt and data/local/dict_nosp/lexiconp.txt\r\n",
      "--> lexicon pair data/local/dict_nosp/lexicon.txt and data/local/dict_nosp/lexiconp.txt match\r\n",
      "\r\n",
      "Checking data/local/dict_nosp/extra_questions.txt ...\r\n",
      "--> reading data/local/dict_nosp/extra_questions.txt\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> data/local/dict_nosp/extra_questions.txt is OK\r\n",
      "--> SUCCESS [validating dictionary directory data/local/dict_nosp]\r\n",
      "\r\n",
      "./utils/dict_dir_add_pronprobs.sh: normalizing pronprobs so maximum is 1 for each word.\r\n",
      "./utils/dict_dir_add_pronprobs.sh: produced dictionary directory with probabilities in data/local/dict/\r\n",
      "./utils/dict_dir_add_pronprobs.sh: validating data/local/dict ..\r\n",
      "Checking data/local/dict/silence_phones.txt ...\r\n",
      "--> reading data/local/dict/silence_phones.txt\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> data/local/dict/silence_phones.txt is OK\r\n",
      "\r\n",
      "Checking data/local/dict/optional_silence.txt ...\r\n",
      "--> reading data/local/dict/optional_silence.txt\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> data/local/dict/optional_silence.txt is OK\r\n",
      "\r\n",
      "Checking data/local/dict/nonsilence_phones.txt ...\r\n",
      "--> reading data/local/dict/nonsilence_phones.txt\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> data/local/dict/nonsilence_phones.txt is OK\r\n",
      "\r\n",
      "Checking disjoint: silence_phones.txt, nonsilence_phones.txt\r\n",
      "--> disjoint property is OK.\r\n",
      "\r\n",
      "Checking data/local/dict/lexicon.txt\r\n",
      "--> reading data/local/dict/lexicon.txt\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> data/local/dict/lexicon.txt is OK\r\n",
      "\r\n",
      "Checking data/local/dict/lexiconp.txt\r\n",
      "--> reading data/local/dict/lexiconp.txt\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> data/local/dict/lexiconp.txt is OK\r\n",
      "\r\n",
      "Checking data/local/dict/lexiconp_silprob.txt\r\n",
      "--> reading data/local/dict/lexiconp_silprob.txt\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> data/local/dict/lexiconp_silprob.txt is OK\r\n",
      "\r\n",
      "Checking lexicon pair data/local/dict/lexicon.txt and data/local/dict/lexiconp.txt\r\n",
      "--> lexicon pair data/local/dict/lexicon.txt and data/local/dict/lexiconp.txt match\r\n",
      "\r\n",
      "Checking lexicon pair data/local/dict/lexiconp.txt and data/local/dict/lexiconp_silprob.txt\r\n",
      "--> lexicon pair data/local/dict/lexiconp.txt and data/local/dict/lexiconp_silprob.txt match\r\n",
      "\r\n",
      "Checking data/local/dict/extra_questions.txt ...\r\n",
      "--> reading data/local/dict/extra_questions.txt\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> data/local/dict/extra_questions.txt is OK\r\n",
      "--> SUCCESS [validating dictionary directory data/local/dict]\r\n",
      "\r\n",
      "Some low-probability prons include: \r\n",
      "# sort -k2,2 -n data/local/dict/lexiconp.txt  | head -n 8\r\n",
      "co 0.00236127 k o\r\n",
      "i 0.00401478 a j\r\n",
      "między 0.00518135 m j en dz I\r\n",
      "szybko 0.012987 S I b k o\r\n",
      "przypadku 0.0136986 p S I p a d k u\r\n",
      "wciąż 0.0169491 f tsi o n Z\r\n",
      "części 0.0169492 tS en si tsi i\r\n",
      "zawsze 0.0171428 z a v S e\r\n",
      "sort: write failed: 'standard output': Broken pipe\r\n",
      "sort: write error\r\n",
      "utils/prepare_lang.sh data/local/dict <unk> data/local/tmp data/lang\r\n",
      "Checking data/local/dict/silence_phones.txt ...\r\n",
      "--> reading data/local/dict/silence_phones.txt\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> data/local/dict/silence_phones.txt is OK\r\n",
      "\r\n",
      "Checking data/local/dict/optional_silence.txt ...\r\n",
      "--> reading data/local/dict/optional_silence.txt\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> data/local/dict/optional_silence.txt is OK\r\n",
      "\r\n",
      "Checking data/local/dict/nonsilence_phones.txt ...\r\n",
      "--> reading data/local/dict/nonsilence_phones.txt\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> data/local/dict/nonsilence_phones.txt is OK\r\n",
      "\r\n",
      "Checking disjoint: silence_phones.txt, nonsilence_phones.txt\r\n",
      "--> disjoint property is OK.\r\n",
      "\r\n",
      "Checking data/local/dict/lexicon.txt\r\n",
      "--> reading data/local/dict/lexicon.txt\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> data/local/dict/lexicon.txt is OK\r\n",
      "\r\n",
      "Checking data/local/dict/lexiconp.txt\r\n",
      "--> reading data/local/dict/lexiconp.txt\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> data/local/dict/lexiconp.txt is OK\r\n",
      "\r\n",
      "Checking data/local/dict/lexiconp_silprob.txt\r\n",
      "--> reading data/local/dict/lexiconp_silprob.txt\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> data/local/dict/lexiconp_silprob.txt is OK\r\n",
      "\r\n",
      "Checking lexicon pair data/local/dict/lexicon.txt and data/local/dict/lexiconp.txt\r\n",
      "--> lexicon pair data/local/dict/lexicon.txt and data/local/dict/lexiconp.txt match\r\n",
      "\r\n",
      "Checking lexicon pair data/local/dict/lexiconp.txt and data/local/dict/lexiconp_silprob.txt\r\n",
      "--> lexicon pair data/local/dict/lexiconp.txt and data/local/dict/lexiconp_silprob.txt match\r\n",
      "\r\n",
      "Checking data/local/dict/extra_questions.txt ...\r\n",
      "--> reading data/local/dict/extra_questions.txt\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> data/local/dict/extra_questions.txt is OK\r\n",
      "--> SUCCESS [validating dictionary directory data/local/dict]\r\n",
      "\r\n",
      "fstaddselfloops data/lang/phones/wdisambig_phones.int data/lang/phones/wdisambig_words.int \r\n",
      "prepare_lang.sh: validating output directory\r\n",
      "utils/validate_lang.pl data/lang\r\n",
      "Checking existence of separator file\r\n",
      "separator file data/lang/subword_separator.txt is empty or does not exist, deal in word case.\r\n",
      "Checking data/lang/phones.txt ...\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> data/lang/phones.txt is OK\r\n",
      "\r\n",
      "Checking words.txt: #0 ...\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> data/lang/words.txt is OK\r\n",
      "\r\n",
      "Checking disjoint: silence.txt, nonsilence.txt, disambig.txt ...\r\n",
      "--> silence.txt and nonsilence.txt are disjoint\r\n",
      "--> silence.txt and disambig.txt are disjoint\r\n",
      "--> disambig.txt and nonsilence.txt are disjoint\r\n",
      "--> disjoint property is OK\r\n",
      "\r\n",
      "Checking sumation: silence.txt, nonsilence.txt, disambig.txt ...\r\n",
      "--> found no unexplainable phones in phones.txt\r\n",
      "\r\n",
      "Checking data/lang/phones/context_indep.{txt, int, csl} ...\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> 5 entry/entries in data/lang/phones/context_indep.txt\r\n",
      "--> data/lang/phones/context_indep.int corresponds to data/lang/phones/context_indep.txt\r\n",
      "--> data/lang/phones/context_indep.csl corresponds to data/lang/phones/context_indep.txt\r\n",
      "--> data/lang/phones/context_indep.{txt, int, csl} are OK\r\n",
      "\r\n",
      "Checking data/lang/phones/nonsilence.{txt, int, csl} ...\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> 144 entry/entries in data/lang/phones/nonsilence.txt\r\n",
      "--> data/lang/phones/nonsilence.int corresponds to data/lang/phones/nonsilence.txt\r\n",
      "--> data/lang/phones/nonsilence.csl corresponds to data/lang/phones/nonsilence.txt\r\n",
      "--> data/lang/phones/nonsilence.{txt, int, csl} are OK\r\n",
      "\r\n",
      "Checking data/lang/phones/silence.{txt, int, csl} ...\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> 5 entry/entries in data/lang/phones/silence.txt\r\n",
      "--> data/lang/phones/silence.int corresponds to data/lang/phones/silence.txt\r\n",
      "--> data/lang/phones/silence.csl corresponds to data/lang/phones/silence.txt\r\n",
      "--> data/lang/phones/silence.{txt, int, csl} are OK\r\n",
      "\r\n",
      "Checking data/lang/phones/optional_silence.{txt, int, csl} ...\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> 1 entry/entries in data/lang/phones/optional_silence.txt\r\n",
      "--> data/lang/phones/optional_silence.int corresponds to data/lang/phones/optional_silence.txt\r\n",
      "--> data/lang/phones/optional_silence.csl corresponds to data/lang/phones/optional_silence.txt\r\n",
      "--> data/lang/phones/optional_silence.{txt, int, csl} are OK\r\n",
      "\r\n",
      "Checking data/lang/phones/disambig.{txt, int, csl} ...\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> 6 entry/entries in data/lang/phones/disambig.txt\r\n",
      "--> data/lang/phones/disambig.int corresponds to data/lang/phones/disambig.txt\r\n",
      "--> data/lang/phones/disambig.csl corresponds to data/lang/phones/disambig.txt\r\n",
      "--> data/lang/phones/disambig.{txt, int, csl} are OK\r\n",
      "\r\n",
      "Checking data/lang/phones/roots.{txt, int} ...\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> 37 entry/entries in data/lang/phones/roots.txt\r\n",
      "--> data/lang/phones/roots.int corresponds to data/lang/phones/roots.txt\r\n",
      "--> data/lang/phones/roots.{txt, int} are OK\r\n",
      "\r\n",
      "Checking data/lang/phones/sets.{txt, int} ...\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> 37 entry/entries in data/lang/phones/sets.txt\r\n",
      "--> data/lang/phones/sets.int corresponds to data/lang/phones/sets.txt\r\n",
      "--> data/lang/phones/sets.{txt, int} are OK\r\n",
      "\r\n",
      "Checking data/lang/phones/extra_questions.{txt, int} ...\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> 11 entry/entries in data/lang/phones/extra_questions.txt\r\n",
      "--> data/lang/phones/extra_questions.int corresponds to data/lang/phones/extra_questions.txt\r\n",
      "--> data/lang/phones/extra_questions.{txt, int} are OK\r\n",
      "\r\n",
      "Checking data/lang/phones/word_boundary.{txt, int} ...\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> 149 entry/entries in data/lang/phones/word_boundary.txt\r\n",
      "--> data/lang/phones/word_boundary.int corresponds to data/lang/phones/word_boundary.txt\r\n",
      "--> data/lang/phones/word_boundary.{txt, int} are OK\r\n",
      "\r\n",
      "Checking optional_silence.txt ...\r\n",
      "--> reading data/lang/phones/optional_silence.txt\r\n",
      "--> data/lang/phones/optional_silence.txt is OK\r\n",
      "\r\n",
      "Checking disambiguation symbols: #0 and #1\r\n",
      "--> data/lang/phones/disambig.txt has \"#0\" and \"#1\"\r\n",
      "--> data/lang/phones/disambig.txt is OK\r\n",
      "\r\n",
      "Checking topo ...\r\n",
      "\r\n",
      "Checking word_boundary.txt: silence.txt, nonsilence.txt, disambig.txt ...\r\n",
      "--> data/lang/phones/word_boundary.txt doesn't include disambiguation symbols\r\n",
      "--> data/lang/phones/word_boundary.txt is the union of nonsilence.txt and silence.txt\r\n",
      "--> data/lang/phones/word_boundary.txt is OK\r\n",
      "\r\n",
      "Checking word-level disambiguation symbols...\r\n",
      "--> data/lang/phones/wdisambig.txt exists (newer prepare_lang.sh)\r\n",
      "Checking word_boundary.int and disambig.int\r\n",
      "--> generating a 3 word/subword sequence\r\n",
      "--> resulting phone sequence from L.fst corresponds to the word sequence\r\n",
      "--> L.fst is OK\r\n",
      "--> generating a 40 word/subword sequence\r\n",
      "--> resulting phone sequence from L_disambig.fst corresponds to the word sequence\r\n",
      "--> L_disambig.fst is OK\r\n",
      "\r\n",
      "Checking data/lang/oov.{txt, int} ...\r\n",
      "--> text seems to be UTF-8 or ASCII, checking whitespaces\r\n",
      "--> text contains only allowed whitespaces\r\n",
      "--> 1 entry/entries in data/lang/oov.txt\r\n",
      "--> data/lang/oov.int corresponds to data/lang/oov.txt\r\n",
      "--> data/lang/oov.{txt, int} are OK\r\n",
      "\r\n",
      "--> data/lang/L.fst is olabel sorted\r\n",
      "--> data/lang/L_disambig.fst is olabel sorted\r\n",
      "--> SUCCESS [validating lang directory data/lang]\r\n",
      "Converting 'local_clarin/arpa.lm.gz' to FST\r\n",
      "arpa2fst --disambig-symbol=#0 --read-symbol-table=data/lang_test/words.txt - data/lang_test/G.fst \r\n",
      "LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:94) Reading \\data\\ section.\r\n",
      "LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading \\1-grams: section.\r\n",
      "LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading \\2-grams: section.\r\n",
      "LOG (arpa2fst[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading \\3-grams: section.\r\n",
      "LOG (arpa2fst[5.5.0~1-2b62]:RemoveRedundantStates():arpa-lm-compiler.cc:359) Reduced num-states from 615820 to 373636\r\n",
      "fstisstochastic data/lang_test/G.fst \r\n",
      "2.3509e-06 -0.441586\r\n",
      "Succeeded in formatting LM: 'local_clarin/arpa.lm.gz'\r\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "100  842M  100  842M    0     0  82.1M      0  0:00:10  0:00:10 --:--:-- 86.3M\r\n",
      "arpa-to-const-arpa --bos-symbol=59176 --eos-symbol=59177 --unk-symbol=1 'gunzip -c local_clarin/large.arpa.gz | utils/map_arpa_lm.pl data/lang_carpa/words.txt|' data/lang_carpa/G.carpa \r\n",
      "LOG (arpa-to-const-arpa[5.5.0~1-2b62]:BuildConstArpaLm():const-arpa-lm.cc:1078) Reading gunzip -c local_clarin/large.arpa.gz | utils/map_arpa_lm.pl data/lang_carpa/words.txt|\r\n",
      "utils/map_arpa_lm.pl: Processing \"\\data\\\"\r\n",
      "utils/map_arpa_lm.pl: Processing \"\\1-grams:\\\"\r\n",
      "LOG (arpa-to-const-arpa[5.5.0~1-2b62]:Read():arpa-file-parser.cc:94) Reading \\data\\ section.\r\n",
      "LOG (arpa-to-const-arpa[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading \\1-grams: section.\r\n",
      "utils/map_arpa_lm.pl: Processing \"\\2-grams:\\\"\r\n",
      "LOG (arpa-to-const-arpa[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading \\2-grams: section.\r\n",
      "utils/map_arpa_lm.pl: Processing \"\\3-grams:\\\"\r\n",
      "LOG (arpa-to-const-arpa[5.5.0~1-2b62]:Read():arpa-file-parser.cc:149) Reading \\3-grams: section.\r\n",
      "steps/align_fmllr.sh --nj 40 data/train data/lang exp/tri3b exp/tri3b_ali\r\n",
      "steps/align_fmllr.sh: feature type is lda\r\n",
      "steps/align_fmllr.sh: compiling training graphs\r\n",
      "steps/align_fmllr.sh: aligning data in data/train using exp/tri3b/final.alimdl and speaker-independent features.\r\n",
      "steps/align_fmllr.sh: computing fMLLR transforms\r\n",
      "steps/align_fmllr.sh: doing final alignment.\r\n",
      "steps/align_fmllr.sh: done aligning data.\r\n",
      "steps/diagnostic/analyze_alignments.sh --cmd run.pl data/lang exp/tri3b_ali\r\n",
      "steps/diagnostic/analyze_alignments.sh: see stats in exp/tri3b_ali/log/analyze_alignments.log\r\n",
      "146 warnings in exp/tri3b_ali/log/align_pass2.*.log\r\n",
      "10 warnings in exp/tri3b_ali/log/fmllr.*.log\r\n",
      "137 warnings in exp/tri3b_ali/log/align_pass1.*.log\r\n",
      "steps/make_denlats.sh --nj 40 --transform-dir exp/tri3b_ali data/train data/lang exp/tri3b exp/tri3b_denlats\r\n",
      "Making unigram grammar FST in exp/tri3b_denlats/lang\r\n",
      "Compiling decoding graph in exp/tri3b_denlats/dengraph\r\n",
      "tree-info exp/tri3b/tree \r\n",
      "tree-info exp/tri3b/tree \r\n",
      "fstpushspecial \r\n",
      "fstdeterminizestar --use-log=true \r\n",
      "fstminimizeencoded \r\n",
      "fsttablecompose exp/tri3b_denlats/lang/L_disambig.fst exp/tri3b_denlats/lang/G.fst \r\n",
      "fstisstochastic exp/tri3b_denlats/lang/tmp/LG.fst \r\n",
      "-0.0200168 -0.0202794\r\n",
      "[info]: LG not stochastic.\r\n",
      "fstcomposecontext --context-size=3 --central-position=1 --read-disambig-syms=exp/tri3b_denlats/lang/phones/disambig.int --write-disambig-syms=exp/tri3b_denlats/lang/tmp/disambig_ilabels_3_1.int exp/tri3b_denlats/lang/tmp/ilabels_3_1.199773 exp/tri3b_denlats/lang/tmp/LG.fst \r\n",
      "fstisstochastic exp/tri3b_denlats/lang/tmp/CLG_3_1.fst \r\n",
      "0 -0.0202794\r\n",
      "[info]: CLG not stochastic.\r\n",
      "make-h-transducer --disambig-syms-out=exp/tri3b_denlats/dengraph/disambig_tid.int --transition-scale=1.0 exp/tri3b_denlats/lang/tmp/ilabels_3_1 exp/tri3b/tree exp/tri3b/final.mdl \r\n",
      "fsttablecompose exp/tri3b_denlats/dengraph/Ha.fst exp/tri3b_denlats/lang/tmp/CLG_3_1.fst \r\n",
      "fstdeterminizestar --use-log=true \r\n",
      "fstminimizeencoded \r\n",
      "fstrmepslocal \r\n",
      "fstrmsymbols exp/tri3b_denlats/dengraph/disambig_tid.int \r\n",
      "fstisstochastic exp/tri3b_denlats/dengraph/HCLGa.fst \r\n",
      "0.000488052 -0.0407675\r\n",
      "HCLGa is not stochastic\r\n",
      "add-self-loops --self-loop-scale=0.1 --reorder=true exp/tri3b/final.mdl exp/tri3b_denlats/dengraph/HCLGa.fst \r\n",
      "steps/make_denlats.sh: feature type is lda\r\n",
      "steps/make_denlats.sh: using fMLLR transforms from exp/tri3b_ali\r\n",
      "steps/make_denlats.sh: done generating denominator lattices.\r\n",
      "steps/train_mmi.sh data/train data/lang exp/tri3b_ali exp/tri3b_denlats exp/tri3b_mmi\r\n",
      "steps/train_mmi.sh: feature type is lda\r\n",
      "Using transforms from exp/tri3b_ali\r\n",
      "Iteration 0 of MMI training\r\n",
      "Iteration 0: objf was 0.186247551210063, MMI auxf change was 0.00409094848223934\r\n",
      "Iteration 1 of MMI training\r\n",
      "Iteration 1: objf was 0.191892349623758, MMI auxf change was 0.0016102985202075\r\n",
      "Iteration 2 of MMI training\r\n",
      "Iteration 2: objf was 0.19502896724715, MMI auxf change was 0.00134787601947304\r\n",
      "Iteration 3 of MMI training\r\n",
      "Iteration 3: objf was 0.197708612320086, MMI auxf change was 0.00126728262847419\r\n",
      "MMI training finished\r\n",
      "tree-info exp/mono0/tree \r\n",
      "tree-info exp/mono0/tree \r\n",
      "fstminimizeencoded \r\n",
      "fsttablecompose data/lang_nosp_test/L_disambig.fst data/lang_nosp_test/G.fst \r\n",
      "fstdeterminizestar --use-log=true \r\n",
      "fstpushspecial \r\n",
      "fstisstochastic data/lang_nosp_test/tmp/LG.fst \r\n",
      "-0.0558215 -0.0565322\r\n",
      "[info]: LG not stochastic.\r\n",
      "fstcomposecontext --context-size=1 --central-position=0 --read-disambig-syms=data/lang_nosp_test/phones/disambig.int --write-disambig-syms=data/lang_nosp_test/tmp/disambig_ilabels_1_0.int data/lang_nosp_test/tmp/ilabels_1_0.205829 data/lang_nosp_test/tmp/LG.fst \r\n",
      "fstisstochastic data/lang_nosp_test/tmp/CLG_1_0.fst \r\n",
      "-0.0558215 -0.0565322\r\n",
      "[info]: CLG not stochastic.\r\n",
      "make-h-transducer --disambig-syms-out=exp/mono0/graph/disambig_tid.int --transition-scale=1.0 data/lang_nosp_test/tmp/ilabels_1_0 exp/mono0/tree exp/mono0/final.mdl \r\n",
      "fstrmepslocal \r\n",
      "fsttablecompose exp/mono0/graph/Ha.fst data/lang_nosp_test/tmp/CLG_1_0.fst \r\n",
      "fstdeterminizestar --use-log=true \r\n",
      "fstrmsymbols exp/mono0/graph/disambig_tid.int \r\n",
      "fstminimizeencoded \r\n",
      "fstisstochastic exp/mono0/graph/HCLGa.fst \r\n",
      "0.000234999 -0.112915\r\n",
      "HCLGa is not stochastic\r\n",
      "add-self-loops --self-loop-scale=0.1 --reorder=true exp/mono0/final.mdl exp/mono0/graph/HCLGa.fst \r\n",
      "steps/decode.sh --nj 30 exp/mono0/graph data/test exp/mono0/decode\r\n",
      "decode.sh: feature type is delta\r\n",
      "steps/diagnostic/analyze_lats.sh --cmd run.pl exp/mono0/graph exp/mono0/decode\r\n",
      "steps/diagnostic/analyze_lats.sh: see stats in exp/mono0/decode/log/analyze_alignments.log\r\n",
      "Overall, lattice depth (10,50,90-percentile)=(1,9,69) and mean=29.0\r\n",
      "steps/diagnostic/analyze_lats.sh: see stats in exp/mono0/decode/log/analyze_lattice_depth_stats.log\r\n",
      "local/score.sh --cmd run.pl data/test exp/mono0/graph exp/mono0/decode\r\n",
      "local/score.sh: scoring with word insertion penalty=0.0,0.5,1.0\r\n",
      "tree-info exp/tri1/tree \r\n",
      "tree-info exp/tri1/tree \r\n",
      "fstcomposecontext --context-size=3 --central-position=1 --read-disambig-syms=data/lang_nosp_test/phones/disambig.int --write-disambig-syms=data/lang_nosp_test/tmp/disambig_ilabels_3_1.int data/lang_nosp_test/tmp/ilabels_3_1.209475 data/lang_nosp_test/tmp/LG.fst \r\n",
      "fstisstochastic data/lang_nosp_test/tmp/CLG_3_1.fst \r\n",
      "0 -0.0565322\r\n",
      "[info]: CLG not stochastic.\r\n",
      "make-h-transducer --disambig-syms-out=exp/tri1/graph/disambig_tid.int --transition-scale=1.0 data/lang_nosp_test/tmp/ilabels_3_1 exp/tri1/tree exp/tri1/final.mdl \r\n",
      "fstminimizeencoded \r\n",
      "fstrmepslocal \r\n",
      "fsttablecompose exp/tri1/graph/Ha.fst data/lang_nosp_test/tmp/CLG_3_1.fst \r\n",
      "fstdeterminizestar --use-log=true \r\n",
      "fstrmsymbols exp/tri1/graph/disambig_tid.int \r\n",
      "fstisstochastic exp/tri1/graph/HCLGa.fst \r\n",
      "0.000487832 -0.176835\r\n",
      "HCLGa is not stochastic\r\n",
      "add-self-loops --self-loop-scale=0.1 --reorder=true exp/tri1/final.mdl exp/tri1/graph/HCLGa.fst \r\n",
      "steps/decode.sh --nj 30 exp/tri1/graph data/test exp/tri1/decode\r\n",
      "decode.sh: feature type is delta\r\n",
      "steps/diagnostic/analyze_lats.sh --cmd run.pl exp/tri1/graph exp/tri1/decode\r\n",
      "steps/diagnostic/analyze_lats.sh: see stats in exp/tri1/decode/log/analyze_alignments.log\r\n",
      "Overall, lattice depth (10,50,90-percentile)=(1,3,13) and mean=6.4\r\n",
      "steps/diagnostic/analyze_lats.sh: see stats in exp/tri1/decode/log/analyze_lattice_depth_stats.log\r\n",
      "local/score.sh --cmd run.pl data/test exp/tri1/graph exp/tri1/decode\r\n",
      "local/score.sh: scoring with word insertion penalty=0.0,0.5,1.0\r\n",
      "tree-info exp/tri2a/tree \r\n",
      "tree-info exp/tri2a/tree \r\n",
      "make-h-transducer --disambig-syms-out=exp/tri2a/graph/disambig_tid.int --transition-scale=1.0 data/lang_nosp_test/tmp/ilabels_3_1 exp/tri2a/tree exp/tri2a/final.mdl \r\n",
      "fstrmsymbols exp/tri2a/graph/disambig_tid.int \r\n",
      "fstdeterminizestar --use-log=true \r\n",
      "fsttablecompose exp/tri2a/graph/Ha.fst data/lang_nosp_test/tmp/CLG_3_1.fst \r\n",
      "fstrmepslocal \r\n",
      "fstminimizeencoded \r\n",
      "fstisstochastic exp/tri2a/graph/HCLGa.fst \r\n",
      "0.000487832 -0.176691\r\n",
      "HCLGa is not stochastic\r\n",
      "add-self-loops --self-loop-scale=0.1 --reorder=true exp/tri2a/final.mdl exp/tri2a/graph/HCLGa.fst \r\n",
      "steps/decode.sh --nj 30 exp/tri2a/graph data/test exp/tri2a/decode\r\n",
      "decode.sh: feature type is delta\r\n",
      "steps/diagnostic/analyze_lats.sh --cmd run.pl exp/tri2a/graph exp/tri2a/decode\r\n",
      "steps/diagnostic/analyze_lats.sh: see stats in exp/tri2a/decode/log/analyze_alignments.log\r\n",
      "Overall, lattice depth (10,50,90-percentile)=(1,3,12) and mean=5.7\r\n",
      "steps/diagnostic/analyze_lats.sh: see stats in exp/tri2a/decode/log/analyze_lattice_depth_stats.log\r\n",
      "local/score.sh --cmd run.pl data/test exp/tri2a/graph exp/tri2a/decode\r\n",
      "local/score.sh: scoring with word insertion penalty=0.0,0.5,1.0\r\n",
      "tree-info exp/tri2b/tree \r\n",
      "tree-info exp/tri2b/tree \r\n",
      "make-h-transducer --disambig-syms-out=exp/tri2b/graph/disambig_tid.int --transition-scale=1.0 data/lang_nosp_test/tmp/ilabels_3_1 exp/tri2b/tree exp/tri2b/final.mdl \r\n",
      "fsttablecompose exp/tri2b/graph/Ha.fst data/lang_nosp_test/tmp/CLG_3_1.fst \r\n",
      "fstminimizeencoded \r\n",
      "fstrmepslocal \r\n",
      "fstdeterminizestar --use-log=true \r\n",
      "fstrmsymbols exp/tri2b/graph/disambig_tid.int \r\n",
      "fstisstochastic exp/tri2b/graph/HCLGa.fst \r\n",
      "0.00048784 -0.176624\r\n",
      "HCLGa is not stochastic\r\n",
      "add-self-loops --self-loop-scale=0.1 --reorder=true exp/tri2b/final.mdl exp/tri2b/graph/HCLGa.fst \r\n",
      "steps/decode.sh --nj 30 exp/tri2b/graph data/test exp/tri2b/decode\r\n",
      "decode.sh: feature type is lda\r\n",
      "steps/diagnostic/analyze_lats.sh --cmd run.pl exp/tri2b/graph exp/tri2b/decode\r\n",
      "steps/diagnostic/analyze_lats.sh: see stats in exp/tri2b/decode/log/analyze_alignments.log\r\n",
      "Overall, lattice depth (10,50,90-percentile)=(1,2,10) and mean=4.5\r\n",
      "steps/diagnostic/analyze_lats.sh: see stats in exp/tri2b/decode/log/analyze_lattice_depth_stats.log\r\n",
      "local/score.sh --cmd run.pl data/test exp/tri2b/graph exp/tri2b/decode\r\n",
      "local/score.sh: scoring with word insertion penalty=0.0,0.5,1.0\r\n",
      "tree-info exp/tri3b/tree \r\n",
      "tree-info exp/tri3b/tree \r\n",
      "make-h-transducer --disambig-syms-out=exp/tri3b/graph_nosp/disambig_tid.int --transition-scale=1.0 data/lang_nosp_test/tmp/ilabels_3_1 exp/tri3b/tree exp/tri3b/final.mdl \r\n",
      "fstrmepslocal \r\n",
      "fstdeterminizestar --use-log=true \r\n",
      "fstrmsymbols exp/tri3b/graph_nosp/disambig_tid.int \r\n",
      "fsttablecompose exp/tri3b/graph_nosp/Ha.fst data/lang_nosp_test/tmp/CLG_3_1.fst \r\n",
      "fstminimizeencoded \r\n",
      "fstisstochastic exp/tri3b/graph_nosp/HCLGa.fst \r\n",
      "0.000487832 -0.176856\r\n",
      "HCLGa is not stochastic\r\n",
      "add-self-loops --self-loop-scale=0.1 --reorder=true exp/tri3b/final.mdl exp/tri3b/graph_nosp/HCLGa.fst \r\n",
      "steps/decode_fmllr.sh --nj 30 exp/tri3b/graph_nosp data/test exp/tri3b/decode_nosp\r\n",
      "steps/decode.sh --scoring-opts  --num-threads 1 --skip-scoring false --acwt 0.083333 --nj 30 --cmd run.pl --beam 10.0 --model exp/tri3b/final.alimdl --max-active 2000 exp/tri3b/graph_nosp data/test exp/tri3b/decode_nosp.si\r\n",
      "decode.sh: feature type is lda\r\n",
      "steps/diagnostic/analyze_lats.sh --cmd run.pl exp/tri3b/graph_nosp exp/tri3b/decode_nosp.si\r\n",
      "steps/diagnostic/analyze_lats.sh: see stats in exp/tri3b/decode_nosp.si/log/analyze_alignments.log\r\n",
      "Overall, lattice depth (10,50,90-percentile)=(1,2,8) and mean=4.0\r\n",
      "steps/diagnostic/analyze_lats.sh: see stats in exp/tri3b/decode_nosp.si/log/analyze_lattice_depth_stats.log\r\n",
      "local/score.sh --cmd run.pl data/test exp/tri3b/graph_nosp exp/tri3b/decode_nosp.si\r\n",
      "local/score.sh: scoring with word insertion penalty=0.0,0.5,1.0\r\n",
      "steps/decode_fmllr.sh: feature type is lda\r\n",
      "steps/decode_fmllr.sh: getting first-pass fMLLR transforms.\r\n",
      "steps/decode_fmllr.sh: doing main lattice generation phase\r\n",
      "steps/decode_fmllr.sh: estimating fMLLR transforms a second time.\r\n",
      "steps/decode_fmllr.sh: doing a final pass of acoustic rescoring.\r\n",
      "steps/diagnostic/analyze_lats.sh --cmd run.pl exp/tri3b/graph_nosp exp/tri3b/decode_nosp\r\n",
      "steps/diagnostic/analyze_lats.sh: see stats in exp/tri3b/decode_nosp/log/analyze_alignments.log\r\n",
      "Overall, lattice depth (10,50,90-percentile)=(1,2,7) and mean=3.3\r\n",
      "steps/diagnostic/analyze_lats.sh: see stats in exp/tri3b/decode_nosp/log/analyze_lattice_depth_stats.log\r\n",
      "local/score.sh --cmd run.pl data/test exp/tri3b/graph_nosp exp/tri3b/decode_nosp\r\n",
      "local/score.sh: scoring with word insertion penalty=0.0,0.5,1.0\r\n",
      "tree-info exp/tri3b/tree \r\n",
      "tree-info exp/tri3b/tree \r\n",
      "fstminimizeencoded \r\n",
      "fsttablecompose data/lang_test/L_disambig.fst data/lang_test/G.fst \r\n",
      "fstdeterminizestar --use-log=true \r\n",
      "fstpushspecial \r\n",
      "fstisstochastic data/lang_test/tmp/LG.fst \r\n",
      "-0.0301516 -0.0307302\r\n",
      "[info]: LG not stochastic.\r\n",
      "fstcomposecontext --context-size=3 --central-position=1 --read-disambig-syms=data/lang_test/phones/disambig.int --write-disambig-syms=data/lang_test/tmp/disambig_ilabels_3_1.int data/lang_test/tmp/ilabels_3_1.229700 data/lang_test/tmp/LG.fst \r\n",
      "fstisstochastic data/lang_test/tmp/CLG_3_1.fst \r\n",
      "0 -0.0307302\r\n",
      "[info]: CLG not stochastic.\r\n",
      "make-h-transducer --disambig-syms-out=exp/tri3b/graph/disambig_tid.int --transition-scale=1.0 data/lang_test/tmp/ilabels_3_1 exp/tri3b/tree exp/tri3b/final.mdl \r\n",
      "fsttablecompose exp/tri3b/graph/Ha.fst data/lang_test/tmp/CLG_3_1.fst \r\n",
      "fstrmepslocal \r\n",
      "fstdeterminizestar --use-log=true \r\n",
      "fstminimizeencoded \r\n",
      "fstrmsymbols exp/tri3b/graph/disambig_tid.int \r\n",
      "fstisstochastic exp/tri3b/graph/HCLGa.fst \r\n",
      "0.000487832 -0.112229\r\n",
      "HCLGa is not stochastic\r\n",
      "add-self-loops --self-loop-scale=0.1 --reorder=true exp/tri3b/final.mdl exp/tri3b/graph/HCLGa.fst \r\n",
      "steps/decode_fmllr.sh --nj 30 exp/tri3b/graph data/test exp/tri3b/decode\r\n",
      "steps/decode.sh --scoring-opts  --num-threads 1 --skip-scoring false --acwt 0.083333 --nj 30 --cmd run.pl --beam 10.0 --model exp/tri3b/final.alimdl --max-active 2000 exp/tri3b/graph data/test exp/tri3b/decode.si\r\n",
      "decode.sh: feature type is lda\r\n",
      "steps/diagnostic/analyze_lats.sh --cmd run.pl exp/tri3b/graph exp/tri3b/decode.si\r\n",
      "steps/diagnostic/analyze_lats.sh: see stats in exp/tri3b/decode.si/log/analyze_alignments.log\r\n",
      "Overall, lattice depth (10,50,90-percentile)=(1,2,7) and mean=3.7\r\n",
      "steps/diagnostic/analyze_lats.sh: see stats in exp/tri3b/decode.si/log/analyze_lattice_depth_stats.log\r\n",
      "local/score.sh --cmd run.pl data/test exp/tri3b/graph exp/tri3b/decode.si\r\n",
      "local/score.sh: scoring with word insertion penalty=0.0,0.5,1.0\r\n",
      "steps/decode_fmllr.sh: feature type is lda\r\n",
      "steps/decode_fmllr.sh: getting first-pass fMLLR transforms.\r\n",
      "steps/decode_fmllr.sh: doing main lattice generation phase\r\n",
      "steps/decode_fmllr.sh: estimating fMLLR transforms a second time.\r\n",
      "steps/decode_fmllr.sh: doing a final pass of acoustic rescoring.\r\n",
      "steps/diagnostic/analyze_lats.sh --cmd run.pl exp/tri3b/graph exp/tri3b/decode\r\n",
      "steps/diagnostic/analyze_lats.sh: see stats in exp/tri3b/decode/log/analyze_alignments.log\r\n",
      "Overall, lattice depth (10,50,90-percentile)=(1,2,6) and mean=3.0\r\n",
      "steps/diagnostic/analyze_lats.sh: see stats in exp/tri3b/decode/log/analyze_lattice_depth_stats.log\r\n",
      "local/score.sh --cmd run.pl data/test exp/tri3b/graph exp/tri3b/decode\r\n",
      "local/score.sh: scoring with word insertion penalty=0.0,0.5,1.0\r\n"
     ]
    }
   ],
   "source": [
    "!bash run.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "directed-courtesy",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-25T16:59:26.307054Z",
     "iopub.status.busy": "2021-05-25T16:59:26.302625Z",
     "iopub.status.idle": "2021-05-25T16:59:27.045992Z",
     "shell.execute_reply": "2021-05-25T16:59:27.046475Z"
    },
    "papermill": {
     "duration": 1.170628,
     "end_time": "2021-05-25T16:59:27.046666",
     "exception": false,
     "start_time": "2021-05-25T16:59:25.876038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: exp/ (stored 0%)\r\n"
     ]
    }
   ],
   "source": [
    "!find exp -type l|zip /kaggle/working/links.zip -@"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 30395.168032,
   "end_time": "2021-05-25T16:59:28.182757",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-25T08:32:53.014725",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
