{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WhisperX to word-level tsv\n",
    "\n",
    "> including basic number denormalisation\n",
    "\n",
    "- comments: false\n",
    "- hidden: true\n",
    "- branch: master\n",
    "- categories: [whisperx, tsv, audacity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "BASE = Path(\"/Users/joregan/Playing/hsi/audio/whisperx-json/\")\n",
    "TSVBASE = Path(\"/Users/joregan/Playing/hsi/audio/whisperx-tsv/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not TSVBASE.is_dir():\n",
    "    TSVBASE.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: num2words in /Users/joregan/opt/anaconda3/envs/hf/lib/python3.9/site-packages (0.5.13)\n",
      "Requirement already satisfied: docopt>=0.6.2 in /Users/joregan/opt/anaconda3/envs/hf/lib/python3.9/site-packages (from num2words) (0.6.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install num2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from num2words import num2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_words(word):\n",
    "    if re.match(\"^[2-9]0s$\", word):\n",
    "        oword = num2words(int(word[0:-1]), lang=\"en\")\n",
    "        return oword[:-1] + \"ies\"\n",
    "    if re.match(\"^[0-9]+(?:th|st|nd|rd)$\", word):\n",
    "        return num2words(int(word[0:-2]), lang=\"en\", to=\"ordinal\")\n",
    "    if re.match(\"^[0-9]+(?:,[0-9][0-9][0-9])+$\", word):\n",
    "        return num2words(int(word.replace(\",\", \"\")), lang=\"en\")\n",
    "    if re.match(\"^\\$[0-9]+(?:,[0-9][0-9][0-9])*$\", word):\n",
    "        return num2words(int(word[1:].replace(\",\", \"\")), lang=\"en\") + \" dollars\"\n",
    "    if re.match(\"^20[1-9][0-9]$\", word):\n",
    "        return \"twenty \" + num2words(int(word[2:]), lang=\"en\")\n",
    "    if re.match(\"^[0-9]+$\", word):\n",
    "        return num2words(int(word), lang=\"en\")\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for jsonfile in BASE.glob(\"*.json\"):\n",
    "    last_end = 0.0\n",
    "    outtsv = TSVBASE / f\"{jsonfile.stem}.tsv\"\n",
    "    with open(str(jsonfile)) as inf, open(str(outtsv), \"w\") as outf:\n",
    "        data = json.load(inf)\n",
    "        for segment in data['segments']:\n",
    "            for word in segment['words']:\n",
    "                if not \"start\" in word:\n",
    "                    start = last_end\n",
    "                    end = last_end + 0.05\n",
    "                    text = get_words(word['word'])\n",
    "                else:\n",
    "                    start = word['start']\n",
    "                    end = word['end']\n",
    "                    text = word['word']\n",
    "                outf.write(str(start) + \"\\t\" + str(end) + \"\\t\" + text + \"\\n\")\n",
    "                last_end = end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSVBASE = Path(\"/Users/joregan/Playing/hsi/audio/whisperx-tsv-sentence/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not TSVBASE.is_dir():\n",
    "    TSVBASE.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_punct(word):\n",
    "    m = re.match(\"^([^A-Za-z0-9]+)(.*[0-9].*)([^A-Za-z0-9]+)$\", word)\n",
    "    if m:\n",
    "        pre = m.group(1)\n",
    "        mid = m.group(2)\n",
    "        post = m.group(3)\n",
    "        return pre + get_words(mid) + post\n",
    "    m = re.match(\"^([^A-Za-z0-9]+)(.*[0-9][A-Za-z0-9]+)$\", word)\n",
    "    if m:\n",
    "        pre = m.group(1)\n",
    "        mid = m.group(2)\n",
    "        return pre + get_words(mid)\n",
    "    m = re.match(\"^([A-Za-z0-9].*[0-9].*)([^A-Za-z0-9]+)$\", word)\n",
    "    if m:\n",
    "        mid = m.group(1)\n",
    "        post = m.group(2)\n",
    "        return get_words(mid) + post\n",
    "    return get_words(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "for jsonfile in BASE.glob(\"*.json\"):\n",
    "    outtsv = TSVBASE / f\"{jsonfile.stem}.tsv\"\n",
    "    with open(str(jsonfile)) as inf, open(str(outtsv), \"w\") as outf:\n",
    "        data = json.load(inf)\n",
    "        for segment in data['segments']:\n",
    "            start = str(segment['start'])\n",
    "            end = str(segment['end'])\n",
    "            text = segment['text'].strip()\n",
    "            normed = [get_words_punct(x) for x in text.split(\" \")]\n",
    "            outf.write(start + \"\\t\" + end + \"\\t\" + \" \".join(normed) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
