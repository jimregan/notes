{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59c6558b",
   "metadata": {},
   "source": [
    "# Process Finck\n",
    "\n",
    "> \"Extract Finck data as JSON; partly generated\"\n",
    "\n",
    "- categories: [finck, irish, json, chatgpt]\n",
    "- branch: master\n",
    "- hidden: true\n",
    "- badges: true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "33de041e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "LANG_MAP = {\n",
    "    \"air.\": \"Old Irish\",\n",
    "    \"mir.\": \"Middle Irish\",\n",
    "    \"nir.\": \"Modern Irish\",\n",
    "    \"engl.\": \"English\",\n",
    "    \"aengl.\": \"Old English\",\n",
    "    \"mengl.\": \"Middle English\",\n",
    "    \"anord.\": \"Old Norse\",\n",
    "    \"aisl.\": \"Old Icelandic\",\n",
    "    \"aschott.\": \"Old Scots\",\n",
    "    \"lat.\": \"Latin\",\n",
    "    \"kymr.\": \"Welsh\",\n",
    "    \"korn.\": \"Cornish\",\n",
    "    \"bret.\": \"Breton\",\n",
    "    \"span.\": \"Spanish\",\n",
    "    \"afranz.\": \"Old French\",\n",
    "}\n",
    "\n",
    "WORK_MAP = {\n",
    "    \"Molloy\": \"Molloy\",\n",
    "    \"Keat.\": \"Keating\",\n",
    "    \"Oâ€™R.\": \"Oâ€™Reilly\",\n",
    "    \"O'R.\": \"Oâ€™Reilly\",\n",
    "    \"Oâ€™Clery\": \"Oâ€™Clery\",\n",
    "    \"O'Clery\": \"Oâ€™Clery\",\n",
    "    \"Atk.\": \"Atkinson\",\n",
    "    \"Bk. of Deer\": \"Book of Deer\",\n",
    "    \"Book of Deer\": \"Book of Deer\",\n",
    "    \"Joyce\": \"Joyce\",\n",
    "}\n",
    "\n",
    "ROMAN_RE = r\"(?:I|II|III|IV|V|VI|VII|VIII|IX|X)\"\n",
    "\n",
    "def split_top_level_semicolons(text: str) -> List[str]:\n",
    "    parts, buf, depth = [], [], 0\n",
    "    for ch in text:\n",
    "        if ch == '(':\n",
    "            depth += 1\n",
    "        elif ch == ')':\n",
    "            depth = max(0, depth - 1)\n",
    "        if ch == ';' and depth == 0:\n",
    "            chunk = ''.join(buf).strip()\n",
    "            if chunk:\n",
    "                parts.append(chunk)\n",
    "            buf = []\n",
    "        else:\n",
    "            buf.append(ch)\n",
    "    last = ''.join(buf).strip()\n",
    "    if last:\n",
    "        parts.append(last)\n",
    "    return parts\n",
    "\n",
    "def parse_neben(chunk: str) -> List[str]:\n",
    "    alts = re.findall(r\"neben\\s+''([^']+)''\", chunk)\n",
    "    return alts\n",
    "\n",
    "def parse_phonetic_head(chunk: str) -> Optional[List[str]]:\n",
    "    m = re.search(r\"^''([^']+)''\", chunk.strip())\n",
    "    if not m:\n",
    "        return None\n",
    "    return [p for p in m.group(1).split() if p]\n",
    "\n",
    "def parse_gloss(chunk: str) -> Optional[str]:\n",
    "    m = re.search(r\"â€([^â€œ]+)â€œ\", chunk)\n",
    "    return m.group(1).strip() if m else None\n",
    "\n",
    "def parse_gender(chunk: str) -> Optional[str]:\n",
    "    m = re.search(r\"\\b([mfn])\\.\\b\", chunk)\n",
    "    if not m: return None\n",
    "    return {\"m\": \"masculine\", \"f\": \"feminine\", \"n\": \"neuter\"}[m.group(1)]\n",
    "\n",
    "def parse_vgl_crossrefs(chunk: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Handles: (vgl. II 251, 15), (vgl. II 251, 15. 266, 5), (vgl. I 263)\n",
    "    Returns list of {volume,page[,line]}\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for par in re.findall(r\"\\(([^)]*vgl\\.[^)]*)\\)\", chunk):\n",
    "        s = par\n",
    "        vgl_m = re.search(r\"vgl\\.\\s*(.*)$\", s)\n",
    "        if not vgl_m: \n",
    "            continue\n",
    "        tail = vgl_m.group(1).strip()\n",
    "\n",
    "        tokens = [t for t in re.split(r\"[,\\.\\s]+\", tail) if t]\n",
    "        cur_vol = None\n",
    "        i = 0\n",
    "        while i < len(tokens):\n",
    "            tok = tokens[i]\n",
    "            if re.fullmatch(ROMAN_RE, tok):\n",
    "                cur_vol = tok\n",
    "                i += 1\n",
    "                continue\n",
    "            if tok.isdigit():\n",
    "                page = tok\n",
    "                line = None\n",
    "\n",
    "                if i + 1 < len(tokens) and tokens[i+1].isdigit():\n",
    "                    line = tokens[i+1]\n",
    "                    i += 1\n",
    "                if cur_vol:\n",
    "                    entry = {\"volume\": cur_vol, \"page\": page}\n",
    "                    if line: entry[\"line\"] = line\n",
    "                    out.append(entry)\n",
    "                i += 1\n",
    "                continue\n",
    "            i += 1\n",
    "    return out\n",
    "\n",
    "def parse_etymology(chunk: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Collects historical stages like: air. bÃ©l; mir. blÃ¡th; aengl. brÃ³c; anord. brÃ³kr\n",
    "    Splits multiple forms after the same label (e.g. 'air. biaid bieid').\n",
    "    \"\"\"\n",
    "    out = []\n",
    "\n",
    "    labels = sorted(LANG_MAP.keys(), key=len, reverse=True)\n",
    "    pattern = r\"\\b(\" + \"|\".join(map(re.escape, labels)) + r\")\\s+([^;,()]+)\"\n",
    "    for abbr, forms_blob in re.findall(pattern, chunk):\n",
    "        forms = [f.strip() for f in forms_blob.split() if f.strip()]\n",
    "        for f in forms:\n",
    "            f = f.rstrip(\".,:;\")\n",
    "            if f:\n",
    "                out.append({\"language\": LANG_MAP[abbr], \"form\": f})\n",
    "    return out\n",
    "\n",
    "def parse_sources(chunk: str) -> List[Dict[str, object]]:\n",
    "    \"\"\"\n",
    "    Captures easy modern source references:\n",
    "      - 'Molloy 49: Ã¡thÃºil' â†’ {work:\"Molloy\", page:\"49\", forms:[\"Ã¡thÃºil\"]}\n",
    "      - 'Keat. breÃ³dhaim, breÃ³ghaim' â†’ {work:\"Keating\", forms:[...]}\n",
    "      - 'Oâ€™R.' â†’ {work:\"Oâ€™Reilly\"} (form optional)\n",
    "      - '(Bk. of Deer)' â†’ {work:\"Book of Deer\"}\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for m in re.finditer(r\"\\b(Molloy)\\s+(\\d+)(?::\\s*([^);]+))?\", chunk):\n",
    "        work = WORK_MAP[m.group(1)]\n",
    "        page = m.group(2)\n",
    "        forms = []\n",
    "        if m.group(3):\n",
    "            forms = [f.strip() for f in re.split(r\",\\s*\", m.group(3).strip()) if f.strip()]\n",
    "        entry = {\"work\": work, \"page\": page}\n",
    "        if forms: entry[\"forms\"] = forms\n",
    "        out.append(entry)\n",
    "\n",
    "    for key, label in WORK_MAP.items():\n",
    "        if key == \"Molloy\":  # already handled\n",
    "            continue\n",
    "\n",
    "        for m in re.finditer(r\"(?:\\(|\\b)\"+re.escape(key)+r\"(?:\\)|\\b)(?::\\s*([^);]+))?\", chunk):\n",
    "            forms_blob = m.group(1)\n",
    "            entry = {\"work\": label}\n",
    "            if forms_blob:\n",
    "                forms = [f.strip() for f in re.split(r\",\\s*\", forms_blob.strip()) if f.strip()]\n",
    "                if forms: entry[\"forms\"] = forms\n",
    "\n",
    "            if entry not in out:\n",
    "                out.append(entry)\n",
    "    return out\n",
    "\n",
    "def extract_easy_entries(volume: str, page: str, section: str, page_text: str) -> List[Dict[str, object]]:\n",
    "    \"\"\"\n",
    "    Minimal-but-useful pass:\n",
    "      - returns a list of dicts with `volume`, `page`, `raw`\n",
    "      - plus: phonetic, alongside (from 'neben'), gloss, gender, see_section, etymology, source_refs\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    page_text = page_text.replace(\"&nbsp;\", \" \")\n",
    "    for raw in split_top_level_semicolons(page_text):\n",
    "        item = {\n",
    "            \"volume\": volume,\n",
    "            \"page\": page,\n",
    "            \"section\": section,\n",
    "            \"raw\": raw.strip()\n",
    "        }\n",
    "        head = parse_phonetic_head(raw)\n",
    "        if head: item[\"phonetic\"] = head\n",
    "        alts = parse_neben(raw)\n",
    "        if alts:\n",
    "            item[\"alongside\"] = alts[0] if len(alts) == 1 else alts\n",
    "        gloss = parse_gloss(raw)\n",
    "        if gloss: item[\"gloss\"] = gloss\n",
    "        gender = parse_gender(raw)\n",
    "        if gender: item[\"gender\"] = gender\n",
    "        refs = parse_vgl_crossrefs(raw)\n",
    "        if refs: item[\"see_section\"] = refs\n",
    "        ety = parse_etymology(raw)\n",
    "        if ety: item[\"etymology\"] = ety\n",
    "        src = parse_sources(raw)\n",
    "        if src: item[\"source_refs\"] = src\n",
    "        results.append(item)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "78043115",
   "metadata": {},
   "outputs": [],
   "source": [
    "P4 = \"\"\"''pus'' â€lippeâ€œ, mir. bus; ''gax'' â€jederâ€œ, gach, air. cach cech; r. prÃ¡is prÃ¡s â€messingâ€œ, mengl. bras; nir. blaosc, mir. blaesc, kymr. blisc â€schaleâ€œ, nir. plaosg, manx. pleaysc, kymr. plisg\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5f04055e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumerate_entries(entries: List[Dict[str, object]], start: int = 78) -> None:\n",
    "    for i, entry in enumerate(entries):\n",
    "        entry[\"id\"] = f\"{entry['volume']}_{entry['section']}_{i + start}\"\n",
    "\n",
    "def write_json(path = \"/private/tmp/irish-attested-pronunciations/finck/raw/\", data = [], section = \"4\"):\n",
    "    with open(f\"{path}/section{section}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        import json\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7bd03b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = \"\"\"''ÇµÄ“'' â€gansâ€œ, mir. gÃ©d; ''ÇµÄ“g'' â€Ã¤stâ€œ, mir. gÃ©c;\n",
    "''Çµ<u>Ç</u>r'' â€scharfâ€œ, air. gÃ©r; ''ÇµlÄ“'' â€eiweissâ€œ, air. glÃ©; ''ÇµlÄ“s'' â€kleid, instrumentâ€œ;\n",
    "''ÇµlÄ“sÄ­m'' â€bekleide, mache fertigâ€œ, mir. glÃ©s (vgl. \n",
    "II 275,25 ï¬€.); ''ÇµÈ´Å'' â€lÃ¤rmâ€œ, mir. gleÃ³; ''ÇµlÅvrÌ¥'' von ''ÇµlÅ''; ''ÇµrÄ“sÄ«''\n",
    "â€schuhmacherâ€œ, zu mir. grÃ©ss; ''hÅ•Ä“Å¡'' â€nachâ€œ, tar Ã©is; ''hÅ«krÌ¥'' \n",
    "(II 139 irrtÃ¼mlich: ''hÅ«á¸±rÌ¥''), engl. hooker; ''Ä«ntÉ™x'' (neben ''iÉ™ntÉ™x'') \n",
    "â€erstauntâ€œ, mir. ingantach; ''Ä«ntÉ™s'' (neben ''iÉ™ntÉ™s'') â€wunderâ€œ, mir. \n",
    "ingantus; ''Ä«'' â€nachtâ€œ (neben ''ihÉ™ iÉ™ Ä«hÉ™''), air. aidche; ''Ä« Ä«hÉ™'' â€essenâ€œ\n",
    "(neben ''Ä«É™ iÉ™'') (Molloy 81: ighthe), mir. ithe; ''Ä«hÅ•Ì¥'' â€ackerfeldâ€œ,\n",
    "mir. ithir; ''Ä«xtrÌ¥'' â€unterer teilâ€œ, air. Ã­chtar; ''Ä«m'' â€esseâ€œ, air. ithim \n",
    "(aber ''Ä«m'' â€butterâ€œ mit eingipfliger exspiration); ''kÄ'' â€spreuâ€œ, air. \n",
    "cÃ¡ith; ''kÈ§ kÇ¡v'', verbalsubst. zu ''kÈ§hÄ­m'' â€verzehreâ€œ etc., mir. \n",
    "caithem; ''klai'' â€steinumzÃ¤unungâ€œ (vgl. II 153), mir. clad; ''kÅtÉ™'' \n",
    "â€rockâ€œ, engl. coat; ''kÅ«'' (neben ''kuÉ™'') â€kummerâ€œ, mir. cuma; ''kÅ«Å‹'' \n",
    "â€engâ€œ, air. cumang; ''kÅ«Å•'' â€gegenwartâ€œ, mir. comair; \n",
    "''kÅ«Å•t'' (neben ''kuÉ™Å•c'') â€besuchâ€œ, air. cuairt (dagegen ''kÅ«Å•c'' â€courtâ€œ in der regel \n",
    "eingipflig); ''á¸±Ç¡Å•'' â€vierâ€œ neben ''á¸±È§hÅ•Ì¥'', air. cethir; ''á¸±Ä“'' â€wer, was, \n",
    "obwohlâ€œ, air. cia; ''á¸±Ä“xtÉ™'' (vgl. II 284, 1) (Molloy 33: cÃ©chta)\n",
    "â€pflugâ€œ, mir. cÃ©cht; ''á¸±Ä“sÄ­m'' â€kreuzigeâ€œ, air. cÃ©ssaim; ''á¸±Ä“Å¡c'' â€frageâ€œ\n",
    "(neben ''á¸±eÅ¡c'' II 284, 2); ''á¸±Ä“Å¡cuÉ™'' â€examenâ€œ, mir. ceist, lat. quaestio;\n",
    "''á¸±Ä“Å¡'' â€sauâ€œ, cÃ©is, Oâ€™R.; ''á¸±Ä“v'' â€schiffslÃ¤ndeâ€œ, engl. quay (vgl. II \n",
    "284, 5); ''á¸±lÄ“v'' gen. sing. und nom./acc. plur. zu ''á¸±liÉ™v'', clÃ©ibh;\n",
    "''á¸±Å, á¸±ÅvrÌ¥, á¸±ÅbrÌ¥nÉ™x'' (vgl. II 284, 32) â€nebel, neblig, nebligkeitâ€œ,\n",
    "mir. ceÃ³ (zu ''á¸±ÅbrÌ¥nÉ™x'' nicht ''á¸±obrÌ¥nÉ™x'' wie irrtÃ¼mlich II 284, 32,\n",
    "folgendes: ceobhraonach (Oâ€™R.) â€mizzling, mistyâ€œ, von ceobhrÃ¡in\n",
    "â€heavy dew falling like rainâ€œ, ceobhrÃ¡on ceobhrÃ¡n â€small rain, \n",
    "mizzling rainâ€œ; braon â€tropfenâ€œ, Keat., air. brÃ³en â€pluviaâ€œ,\n",
    "Z.-E. 31); ''á¸±Å•Ä“'' â€thon, erdeâ€œ, air. crÃ©; ''á¸±Å•Ä«x'' â€endeâ€œ, air. crÃ­ch \n",
    "(Molloy 23: criach); ''á¸±Ä«x'' â€weibliche brustâ€œ, mir. cÃ­ch (Molloy\n",
    "23: ciach); ''á¸±Å•Ä«st'' â€Christusâ€œ, air. CrÃ­st; ''lÌ„aibrÉ™rÄ«'' â€bibliothekâ€œ, \n",
    "engl. library; ''lÌ„ai lÌ„aiÉ™'' â€liegenâ€œ, luighe (Molloy 80: luigheadh),\n",
    "air. lige; ''lÌ„aiÄ­m'' â€liegeâ€œ, mir. laigim; ''lÌ„aiÉ™d'' â€kleinheitâ€œ, mir. \n",
    "laiget; ''lÌ„aiÉ™Å•á¸±Ä«n'' (vgl. II 285, 3), mir. ladar; ''lÌ„auÉ™ lÌ„au'' â€verfaulenâ€œ, \n",
    "''lÌ„auÄ­m'' â€verfauleâ€œ, air. lobad; ''lÌ„Ä'' â€tagâ€œ, air. lÃ¡the etc.; ''lÌ„Äx'' (neben \n",
    "''lÌ„ahÉ™x'') â€schmutzâ€œ, mir. lathach; ''lÌ„uÉ™ lÌ„Å«'' (vgl. 251, 16) â€wenigerâ€œ,\n",
    "air. lugu;\n",
    "\"\"\".replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f2590d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = []\n",
    "for e in extract_easy_entries(\"I\", page=\"6\", section=\"4\", page_text=TEXT):\n",
    "    entries.append(e)\n",
    "\n",
    "enumerate_entries(entries, start=79)\n",
    "\n",
    "write_json(data=entries, section=\"4b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1693d64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "italics = \"ğ˜¢ğ˜£ğ˜¤ğ˜¥ğ˜¦ğ˜§ğ˜¨ğ˜©ğ˜ªğ˜«ğ˜¬ğ˜­ğ˜®ğ˜¯ğ˜°ğ˜±ğ˜²ğ˜³ğ˜´ğ˜µğ˜¶ğ˜·ğ˜¸ğ˜¹ğ˜ºğ˜»\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nst-tts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
