{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "employed-dictionary",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-05-30T14:25:57.056614Z",
     "iopub.status.busy": "2021-05-30T14:25:57.055939Z",
     "iopub.status.idle": "2021-05-30T14:25:57.060195Z",
     "shell.execute_reply": "2021-05-30T14:25:57.060808Z",
     "shell.execute_reply.started": "2021-05-25T22:46:58.262403Z"
    },
    "papermill": {
     "duration": 0.037109,
     "end_time": "2021-05-30T14:25:57.061126",
     "exception": false,
     "start_time": "2021-05-30T14:25:57.024017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt\n"
     ]
    }
   ],
   "source": [
    "%cd /opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "residential-muslim",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T14:25:57.103875Z",
     "iopub.status.busy": "2021-05-30T14:25:57.103209Z",
     "iopub.status.idle": "2021-05-30T14:26:36.932300Z",
     "shell.execute_reply": "2021-05-30T14:26:36.931722Z"
    },
    "papermill": {
     "duration": 39.850944,
     "end_time": "2021-05-30T14:26:36.932476",
     "exception": false,
     "start_time": "2021-05-30T14:25:57.081532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!tar xvf /kaggle/input/extract-prebuilt-kaldi-from-docker/kaldi.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "religious-commissioner",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T14:26:36.976851Z",
     "iopub.status.busy": "2021-05-30T14:26:36.975962Z",
     "iopub.status.idle": "2021-05-30T14:26:36.980577Z",
     "shell.execute_reply": "2021-05-30T14:26:36.980025Z"
    },
    "papermill": {
     "duration": 0.028846,
     "end_time": "2021-05-30T14:26:36.980713",
     "exception": false,
     "start_time": "2021-05-30T14:26:36.951867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp\n"
     ]
    }
   ],
   "source": [
    "%cd /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "attractive-checklist",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T14:26:37.022746Z",
     "iopub.status.busy": "2021-05-30T14:26:37.022103Z",
     "iopub.status.idle": "2021-05-30T14:26:40.018231Z",
     "shell.execute_reply": "2021-05-30T14:26:40.016586Z",
     "shell.execute_reply.started": "2021-05-25T22:38:20.218298Z"
    },
    "papermill": {
     "duration": 3.018202,
     "end_time": "2021-05-30T14:26:40.018458",
     "exception": false,
     "start_time": "2021-05-30T14:26:37.000256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'fairseq'...\r\n",
      "remote: Enumerating objects: 28172, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (586/586), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (340/340), done.\u001b[K\r\n",
      "remote: Total 28172 (delta 308), reused 464 (delta 233), pack-reused 27586\u001b[K\r\n",
      "Receiving objects: 100% (28172/28172), 11.89 MiB | 20.60 MiB/s, done.\r\n",
      "Resolving deltas: 100% (21133/21133), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/pytorch/fairseq/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "contemporary-fields",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T14:26:40.082886Z",
     "iopub.status.busy": "2021-05-30T14:26:40.079190Z",
     "iopub.status.idle": "2021-05-30T14:26:53.409396Z",
     "shell.execute_reply": "2021-05-30T14:26:53.409882Z"
    },
    "papermill": {
     "duration": 13.364863,
     "end_time": "2021-05-30T14:26:53.410114",
     "exception": false,
     "start_time": "2021-05-30T14:26:40.045251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install phonemizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "miniature-crime",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T14:26:53.474200Z",
     "iopub.status.busy": "2021-05-30T14:26:53.469939Z",
     "iopub.status.idle": "2021-05-30T14:27:47.671050Z",
     "shell.execute_reply": "2021-05-30T14:27:47.670212Z"
    },
    "papermill": {
     "duration": 54.234193,
     "end_time": "2021-05-30T14:27:47.671198",
     "exception": false,
     "start_time": "2021-05-30T14:26:53.437005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install git+https://github.com/pytorch/fairseq/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "mobile-disclaimer",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T14:27:47.729317Z",
     "iopub.status.busy": "2021-05-30T14:27:47.728620Z",
     "iopub.status.idle": "2021-05-30T14:27:54.603015Z",
     "shell.execute_reply": "2021-05-30T14:27:54.603514Z"
    },
    "papermill": {
     "duration": 6.904503,
     "end_time": "2021-05-30T14:27:54.603693",
     "exception": false,
     "start_time": "2021-05-30T14:27:47.699190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!apt-get -y install espeak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "running-bunny",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T14:27:54.667382Z",
     "iopub.status.busy": "2021-05-30T14:27:54.666594Z",
     "iopub.status.idle": "2021-05-30T14:27:56.691491Z",
     "shell.execute_reply": "2021-05-30T14:27:56.690851Z",
     "shell.execute_reply.started": "2021-05-25T22:47:02.096238Z"
    },
    "papermill": {
     "duration": 2.060912,
     "end_time": "2021-05-30T14:27:56.691653",
     "exception": false,
     "start_time": "2021-05-30T14:27:54.630741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'kenlm'...\r\n",
      "remote: Enumerating objects: 13824, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (137/137), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (79/79), done.\u001b[K\r\n",
      "remote: Total 13824 (delta 76), reused 92 (delta 45), pack-reused 13687\u001b[K\r\n",
      "Receiving objects: 100% (13824/13824), 5.49 MiB | 11.25 MiB/s, done.\r\n",
      "Resolving deltas: 100% (7956/7956), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/kpu/kenlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "expanded-funeral",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T14:27:56.767580Z",
     "iopub.status.busy": "2021-05-30T14:27:56.766782Z",
     "iopub.status.idle": "2021-05-30T14:28:01.933700Z",
     "shell.execute_reply": "2021-05-30T14:28:01.933126Z"
    },
    "papermill": {
     "duration": 5.209396,
     "end_time": "2021-05-30T14:28:01.933853",
     "exception": false,
     "start_time": "2021-05-30T14:27:56.724457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!apt-get -y install libeigen3-dev liblzma-dev zlib1g-dev libbz2-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fabulous-significance",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T14:28:02.009647Z",
     "iopub.status.busy": "2021-05-30T14:28:02.008691Z",
     "iopub.status.idle": "2021-05-30T14:29:21.350549Z",
     "shell.execute_reply": "2021-05-30T14:29:21.349147Z"
    },
    "papermill": {
     "duration": 79.384822,
     "end_time": "2021-05-30T14:29:21.350936",
     "exception": false,
     "start_time": "2021-05-30T14:28:01.966114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%cd kenlm\n",
    "!mkdir build\n",
    "%cd build\n",
    "!cmake ..\n",
    "!make -j 4\n",
    "%cd /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "unusual-fantasy",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T14:29:21.423966Z",
     "iopub.status.busy": "2021-05-30T14:29:21.423276Z",
     "iopub.status.idle": "2021-05-30T14:29:21.428203Z",
     "shell.execute_reply": "2021-05-30T14:29:21.428777Z",
     "shell.execute_reply.started": "2021-05-25T22:58:58.397816Z"
    },
    "papermill": {
     "duration": 0.042049,
     "end_time": "2021-05-30T14:29:21.428972",
     "exception": false,
     "start_time": "2021-05-30T14:29:21.386923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PATH'] = f\"{os.environ['PATH']}:/tmp/kenlm/build/bin/\"\n",
    "os.environ['FAIRSEQ_ROOT'] = '/tmp/fairseq'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "elect-supplement",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T14:29:21.496395Z",
     "iopub.status.busy": "2021-05-30T14:29:21.495753Z",
     "iopub.status.idle": "2021-05-30T14:29:22.275589Z",
     "shell.execute_reply": "2021-05-30T14:29:22.274923Z",
     "shell.execute_reply.started": "2021-05-25T22:55:06.647826Z"
    },
    "papermill": {
     "duration": 0.814609,
     "end_time": "2021-05-30T14:29:22.275731",
     "exception": false,
     "start_time": "2021-05-30T14:29:21.461122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cat /kaggle/input/wav2vec-u-cv-swedish-audio/*.wrd | grep -v '^$' | sort| uniq > /kaggle/working/sentences.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "incredible-segment",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T14:29:22.343713Z",
     "iopub.status.busy": "2021-05-30T14:29:22.343023Z",
     "iopub.status.idle": "2021-05-30T14:29:22.352160Z",
     "shell.execute_reply": "2021-05-30T14:29:22.351160Z",
     "shell.execute_reply.started": "2021-05-25T22:55:38.373919Z"
    },
    "papermill": {
     "duration": 0.044358,
     "end_time": "2021-05-30T14:29:22.352420",
     "exception": false,
     "start_time": "2021-05-30T14:29:22.308062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/fairseq/examples/wav2vec/unsupervised\n"
     ]
    }
   ],
   "source": [
    "%cd fairseq/examples/wav2vec/unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "awful-detection",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T14:29:22.428372Z",
     "iopub.status.busy": "2021-05-30T14:29:22.424829Z",
     "iopub.status.idle": "2021-05-30T14:29:28.140120Z",
     "shell.execute_reply": "2021-05-30T14:29:28.139380Z"
    },
    "papermill": {
     "duration": 5.754462,
     "end_time": "2021-05-30T14:29:28.140315",
     "exception": false,
     "start_time": "2021-05-30T14:29:22.385853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!apt-get -y install zsh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "hawaiian-tomato",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T14:29:28.215519Z",
     "iopub.status.busy": "2021-05-30T14:29:28.210718Z",
     "iopub.status.idle": "2021-05-30T14:29:28.923409Z",
     "shell.execute_reply": "2021-05-30T14:29:28.922725Z",
     "shell.execute_reply.started": "2021-05-25T22:58:19.000595Z"
    },
    "papermill": {
     "duration": 0.7504,
     "end_time": "2021-05-30T14:29:28.923554",
     "exception": false,
     "start_time": "2021-05-30T14:29:28.173154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir /kaggle/working/preppedtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "controlled-blade",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T14:29:28.995437Z",
     "iopub.status.busy": "2021-05-30T14:29:28.994403Z",
     "iopub.status.idle": "2021-05-30T14:29:28.999863Z",
     "shell.execute_reply": "2021-05-30T14:29:28.999033Z",
     "shell.execute_reply.started": "2021-05-25T23:04:33.0148Z"
    },
    "papermill": {
     "duration": 0.043862,
     "end_time": "2021-05-30T14:29:29.000056",
     "exception": false,
     "start_time": "2021-05-30T14:29:28.956194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/fairseq/examples/wav2vec/unsupervised/scripts\n"
     ]
    }
   ],
   "source": [
    "%cd scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "republican-dispute",
   "metadata": {
    "papermill": {
     "duration": 0.033174,
     "end_time": "2021-05-30T14:29:29.066761",
     "exception": false,
     "start_time": "2021-05-30T14:29:29.033587",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The next part requires a FastText language id model; I don't know where the 187 language model comes from, but there is a model for 176 languages [here](https://fasttext.cc/docs/en/language-identification.html#content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "macro-brain",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T14:29:29.137478Z",
     "iopub.status.busy": "2021-05-30T14:29:29.136813Z",
     "iopub.status.idle": "2021-05-30T14:29:32.689152Z",
     "shell.execute_reply": "2021-05-30T14:29:32.688568Z",
     "shell.execute_reply.started": "2021-05-25T23:26:05.700782Z"
    },
    "papermill": {
     "duration": 3.588603,
     "end_time": "2021-05-30T14:29:32.689307",
     "exception": false,
     "start_time": "2021-05-30T14:29:29.100704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-05-30 14:29:29--  https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin\r\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.74.142, 104.22.75.142, ...\r\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 131266198 (125M) [application/octet-stream]\r\n",
      "Saving to: ‘lid.176.bin’\r\n",
      "\r\n",
      "lid.176.bin         100%[===================>] 125.18M  51.4MB/s    in 2.4s    \r\n",
      "\r\n",
      "2021-05-30 14:29:32 (51.4 MB/s) - ‘lid.176.bin’ saved [131266198/131266198]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "unknown-translator",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T14:29:32.773749Z",
     "iopub.status.busy": "2021-05-30T14:29:32.770457Z",
     "iopub.status.idle": "2021-05-30T14:29:34.220485Z",
     "shell.execute_reply": "2021-05-30T14:29:34.221081Z",
     "shell.execute_reply.started": "2021-05-25T23:28:29.362953Z"
    },
    "papermill": {
     "duration": 1.494317,
     "end_time": "2021-05-30T14:29:34.221288",
     "exception": false,
     "start_time": "2021-05-30T14:29:32.726971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cat normalize_and_filter_text.py|sed -e 's/187/176/' > tmp\n",
    "!mv tmp normalize_and_filter_text.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aboriginal-newcastle",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T14:29:34.299696Z",
     "iopub.status.busy": "2021-05-30T14:29:34.299074Z",
     "iopub.status.idle": "2021-05-30T14:29:34.302997Z",
     "shell.execute_reply": "2021-05-30T14:29:34.303507Z"
    },
    "papermill": {
     "duration": 0.044929,
     "end_time": "2021-05-30T14:29:34.303675",
     "exception": false,
     "start_time": "2021-05-30T14:29:34.258746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Needed to see what's going wrong\n",
    "os.environ['HYDRA_FULL_ERROR'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dental-expert",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T14:29:34.384555Z",
     "iopub.status.busy": "2021-05-30T14:29:34.383883Z",
     "iopub.status.idle": "2021-05-30T14:29:34.387186Z",
     "shell.execute_reply": "2021-05-30T14:29:34.387669Z"
    },
    "papermill": {
     "duration": 0.045433,
     "end_time": "2021-05-30T14:29:34.387847",
     "exception": false,
     "start_time": "2021-05-30T14:29:34.342414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['LD_LIBRARY_PATH'] = '/opt/conda/lib:/opt/kaldi/tools/openfst-1.6.7/lib:/opt/kaldi/src/lib'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-finish",
   "metadata": {
    "papermill": {
     "duration": 0.037435,
     "end_time": "2021-05-30T14:29:34.463075",
     "exception": false,
     "start_time": "2021-05-30T14:29:34.425640",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "There are two lines with missing variables in `prepare_text.sh` - [pull request](https://github.com/pytorch/fairseq/pull/3569) - so replace the file.\n",
    "\n",
    "While I'm replacing the file: most of the first part of the script is unneeded, as I already have a phonetic dictionary, so I'm use that instead.\n",
    "\n",
    "With the calls of the `preprocess.py` script, make sure to check the threshold: there's a divide by zero if the threshold is set too high."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-round",
   "metadata": {
    "papermill": {
     "duration": 0.037243,
     "end_time": "2021-05-30T14:29:34.537783",
     "exception": false,
     "start_time": "2021-05-30T14:29:34.500540",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Config options for `kaldi_initializer.py`\n",
    "\n",
    "- `in_labels`: a naming component, for the Kaldi lexicons/fsts (required)\n",
    "- `wav2letter_lexicon`: path to wav2letter lexicon\n",
    "- `out_labels`: a naming component, for the Kaldi lexicons/fsts: set to `in_label` if missing\n",
    "- `kaldi_root`: path to Kaldi: `/opt/kaldi` for my kaggle image\n",
    "- `fst_dir`: path where generated fsts will be saved\n",
    "- `data_dir`: path to phones data\n",
    "- `lm_arpa`: path to the lm in ARPA format\n",
    "- `blank_symbol`: CTC blank symbol (`<s>` here)\n",
    "- `silence_symbol`: Kaldi symbol for silence (`<SIL>` is set for two of the scripts)\n",
    "\n",
    "A config file needs to exist for this, even though the options set in it seem to be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "flying-bangladesh",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T14:29:34.616376Z",
     "iopub.status.busy": "2021-05-30T14:29:34.615679Z",
     "iopub.status.idle": "2021-05-30T14:29:34.725791Z",
     "shell.execute_reply": "2021-05-30T14:29:34.726520Z"
    },
    "papermill": {
     "duration": 0.15147,
     "end_time": "2021-05-30T14:29:34.726714",
     "exception": false,
     "start_time": "2021-05-30T14:29:34.575244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /tmp/fairseq/examples/speech_recognition/kaldi/config/config.yaml\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/tmp/fairseq/examples/speech_recognition/kaldi/config/config.yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-e447abf2b465>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'writefile'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/tmp/fairseq/examples/speech_recognition/kaldi/config/config.yaml'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'kaldi_root: \"/opt/kaldi\"\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2397\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2398\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2399\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2400\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-98>\u001b[0m in \u001b[0;36mwritefile\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/magics/osm.py\u001b[0m in \u001b[0;36mwritefile\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'a'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    857\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/tmp/fairseq/examples/speech_recognition/kaldi/config/config.yaml'"
     ]
    }
   ],
   "source": [
    "%%writefile /tmp/fairseq/examples/speech_recognition/kaldi/config/config.yaml\n",
    "kaldi_root: \"/opt/kaldi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "other-nerve",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-05-30T14:29:34.810883Z",
     "iopub.status.busy": "2021-05-30T14:29:34.809798Z",
     "iopub.status.idle": "2021-05-30T14:29:34.814185Z",
     "shell.execute_reply": "2021-05-30T14:29:34.814690Z"
    },
    "papermill": {
     "duration": 0.049411,
     "end_time": "2021-05-30T14:29:34.814863",
     "exception": false,
     "start_time": "2021-05-30T14:29:34.765452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting prepare_text.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile prepare_text.sh\n",
    "#!/usr/bin/env zsh\n",
    "# Copyright (c) Facebook, Inc. and its affiliates.\n",
    "#\n",
    "# This source code is licensed under the MIT license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "\n",
    "lg=$1\n",
    "text_path=$2\n",
    "target_dir=$3\n",
    "\n",
    "#ph_lg=${lg:l}\n",
    "#if test \"$lg\" = 'fr'; then\n",
    "#  ph_lg='fr-fr'\n",
    "#elif test \"$lg\" = 'en'; then\n",
    "#  ph_lg='en-us'\n",
    "#elif test \"$lg\" = 'pt'; then\n",
    "#  ph_lg='pt-br'\n",
    "#fi\n",
    "ph_lg=\"sv\"\n",
    "\n",
    "echo $lg\n",
    "echo $ph_lg\n",
    "echo $text_path\n",
    "echo $target_dir\n",
    "\n",
    "mkdir -p $target_dir\n",
    "#python normalize_and_filter_text.py --lang $lg < $text_path | grep -v '\\-\\-\\-' >! $target_dir/lm.upper.lid.txt\n",
    "#python $FAIRSEQ_ROOT/fairseq_cli/preprocess.py --dataset-impl mmap --trainpref $target_dir/lm.upper.lid.txt --only-source --destdir $target_dir --thresholdsrc 2 --padding-factor 1 --dict-only\n",
    "#cut -f1 -d' ' $target_dir/dict.txt | grep -v -x '[[:punct:]]*' | grep -Pv '\\d\\d\\d\\d\\d+' >! $target_dir/words.txt\n",
    "cp /kaggle/input/wav2vec-u-cv-swedish-audio/train.wrd $target_dir/lm.upper.lid.txt\n",
    "cut -f1 -d' ' /kaggle/input/wav2vec-u-cv-swedish-audio/dict.train >! $target_dir/words.txt\n",
    "\n",
    "#one=$(echo \"1\" | PHONEMIZER_ESPEAK_PATH=$(which espeak) phonemize -p ' ' -w '' -l $ph_lg --language-switch remove-flags)\n",
    "#sed 's/$/ 1/' $target_dir/words.txt | PHONEMIZER_ESPEAK_PATH=$(which espeak) phonemize -o $target_dir/phones.txt -p ' ' -w '' -l $ph_lg -j 70 --language-switch remove-flags\n",
    "cut -f2- -d' ' /kaggle/input/wav2vec-u-cv-swedish-audio/dict.train >! $target_dir/phones.txt\n",
    "\n",
    "#echo \"one is ${one}\"\n",
    "\n",
    "#sed -i \"s/${one}$//\" $target_dir/phones.txt\n",
    "#paste $target_dir/words.txt $target_dir/phones.txt >! $target_dir/lexicon.lst\n",
    "cp /kaggle/input/wav2vec-u-cv-swedish-audio/dict.train $target_dir/lexicon.lst\n",
    "\n",
    "#python $FAIRSEQ_ROOT/fairseq_cli/preprocess.py --dataset-impl mmap --trainpref $target_dir/phones.txt --only-source --destdir $target_dir/phones --thresholdsrc 1000 --padding-factor 1 --dict-only\n",
    "python $FAIRSEQ_ROOT/fairseq_cli/preprocess.py --dataset-impl mmap --trainpref $target_dir/phones.txt --only-source --destdir $target_dir/phones --thresholdsrc 2 --padding-factor 1 --dict-only\n",
    "\n",
    "python filter_lexicon.py -d $target_dir/phones/dict.txt < $target_dir/lexicon.lst >! $target_dir/lexicon_filtered.lst\n",
    "python phonemize_with_sil.py -s 0.25 --surround --lexicon $target_dir/lexicon_filtered.lst < $target_dir/lm.upper.lid.txt >! $target_dir/phones/lm.phones.filtered.txt\n",
    "cp $target_dir/phones/dict.txt $target_dir/phones/dict.phn.txt\n",
    "echo \"<SIL> 0\" >> $target_dir/phones/dict.phn.txt\n",
    "python $FAIRSEQ_ROOT/fairseq_cli/preprocess.py --dataset-impl mmap --trainpref $target_dir/phones/lm.phones.filtered.txt --workers 70 --only-source --destdir $target_dir/phones --srcdict $target_dir/phones/dict.phn.txt\n",
    "\n",
    "lmplz -o 4 < $target_dir/lm.upper.lid.txt --discount_fallback --prune 0 0 0 3 >! $target_dir/kenlm.wrd.o40003.arpa\n",
    "build_binary $target_dir/kenlm.wrd.o40003.arpa $target_dir/kenlm.wrd.o40003.bin\n",
    "lg=$lg python $FAIRSEQ_ROOT/examples/speech_recognition/kaldi/kaldi_initializer.py fst_dir=$target_dir/fst/phn_to_words_sil lm_arpa=$target_dir/kenlm.wrd.o40003.arpa wav2letter_lexicon=$target_dir/lexicon_filtered.lst data_dir=$target_dir/phones \"blank_symbol='<SIL>'\" \"in_labels='phn_to_words_sil'\" \"kaldi_root='/opt/kaldi'\"\n",
    "lg=$lg python $FAIRSEQ_ROOT/examples/speech_recognition/kaldi/kaldi_initializer.py fst_dir=$target_dir/fst/phn_to_words lm_arpa=$target_dir/kenlm.wrd.o40003.arpa wav2letter_lexicon=$target_dir/lexicon_filtered.lst data_dir=$target_dir/phones  \"in_labels='phn_to_words'\" \"kaldi_root='/opt/kaldi'\"\n",
    "\n",
    "lmplz -o 4 < $target_dir/phones/lm.phones.filtered.txt --discount_fallback >! $target_dir/phones/lm.phones.filtered.04.arpa\n",
    "build_binary -s $target_dir/phones/lm.phones.filtered.04.arpa $target_dir/phones/lm.phones.filtered.04.bin\n",
    "lmplz -o 6 < $target_dir/phones/lm.phones.filtered.txt --discount_fallback >! $target_dir/phones/lm.phones.filtered.06.arpa\n",
    "build_binary -s $target_dir/phones/lm.phones.filtered.06.arpa $target_dir/phones/lm.phones.filtered.06.bin\n",
    "\n",
    "lg=$lg python $FAIRSEQ_ROOT/examples/speech_recognition/kaldi/kaldi_initializer.py fst_dir=$target_dir/fst/phn_to_phn_sil lm_arpa=$target_dir/phones/lm.phones.filtered.06.arpa data_dir=$target_dir/phones \"blank_symbol='<SIL>'\" \"in_labels='phn_to_phn_sil'\" \"kaldi_root='/opt/kaldi'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "chubby-curtis",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-30T14:29:34.902712Z",
     "iopub.status.busy": "2021-05-30T14:29:34.898651Z",
     "iopub.status.idle": "2021-05-30T14:30:01.219684Z",
     "shell.execute_reply": "2021-05-30T14:30:01.219129Z",
     "shell.execute_reply.started": "2021-05-25T23:28:33.84656Z"
    },
    "papermill": {
     "duration": 26.365651,
     "end_time": "2021-05-30T14:30:01.219855",
     "exception": false,
     "start_time": "2021-05-30T14:29:34.854204",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sv\r\n",
      "sv\r\n",
      "/kaggle/working/sentences.txt\r\n",
      "/kaggle/working/preppedtext\r\n",
      "=== 1/5 Counting and sorting n-grams ===\r\n",
      "Reading /kaggle/working/preppedtext/lm.upper.lid.txt\r\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\r\n",
      "****************************************************************************************************\r\n",
      "Unigram tokens 14359 types 3160\r\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\r\n",
      "Chain sizes: 1:37920 2:2571430400 3:4821431808 4:7714291200\r\n",
      "Statistics:\r\n",
      "1 3160 D1=0.722623 D2=1.14413 D3+=1.45956\r\n",
      "2 10285 D1=0.848104 D2=1.2466 D3+=1.46191\r\n",
      "3 12632 D1=0.943362 D2=1.24166 D3+=1.32723\r\n",
      "4 19/11699 D1=0.970399 D2=1.4843 D3+=2.12351\r\n",
      "Memory estimate for binary LM:\r\n",
      "type     kB\r\n",
      "probing 617 assuming -p 1.5\r\n",
      "probing 764 assuming -r models -p 1.5\r\n",
      "trie    309 without quantization\r\n",
      "trie    182 assuming -q 8 -b 8 quantization \r\n",
      "trie    293 assuming -a 22 array pointer compression\r\n",
      "trie    166 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\r\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\r\n",
      "Chain sizes: 1:37920 2:164560 3:252640 4:456\r\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\r\n",
      "####################################################################################################\r\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\r\n",
      "Chain sizes: 1:37920 2:164560 3:252640 4:456\r\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\r\n",
      "####################################################################################################\r\n",
      "=== 5/5 Writing ARPA model ===\r\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\r\n",
      "****************************************************************************************************\r\n",
      "Name:lmplz\tVmPeak:14925020 kB\tVmRSS:6468 kB\tRSSMax:2975324 kB\tuser:0.442661\tsys:2.84747\tCPU:3.29019\treal:3.28809\r\n",
      "Reading /kaggle/working/preppedtext/kenlm.wrd.o40003.arpa\r\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\r\n",
      "****************************************************************************************************\r\n",
      "SUCCESS\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/tmp/fairseq/examples/speech_recognition/kaldi/kaldi_initializer.py\", line 698, in <module>\r\n",
      "    cli_main()\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/main.py\", line 37, in decorated_main\r\n",
      "    strict=strict,\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/utils.py\", line 347, in _run_hydra\r\n",
      "    lambda: hydra.run(\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/utils.py\", line 201, in run_and_report\r\n",
      "    raise ex\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/utils.py\", line 198, in run_and_report\r\n",
      "    return func()\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/utils.py\", line 350, in <lambda>\r\n",
      "    overrides=args.overrides,\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/hydra.py\", line 104, in run\r\n",
      "    run_mode=RunMode.RUN,\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/hydra.py\", line 505, in compose_config\r\n",
      "    self.config_loader.ensure_main_config_source_available()\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/config_loader_impl.py\", line 139, in ensure_main_config_source_available\r\n",
      "    config_name=None, msg=msg, with_search_path=False\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/config_loader_impl.py\", line 113, in missing_config_error\r\n",
      "    missing_cfg_file=config_name, message=add_search_path()\r\n",
      "hydra.errors.MissingConfigException: Primary config directory not found.\r\n",
      "Check that the config directory '/tmp/fairseq/examples/speech_recognition/kaldi/config' exists and readable\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/tmp/fairseq/examples/speech_recognition/kaldi/kaldi_initializer.py\", line 698, in <module>\r\n",
      "    cli_main()\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/main.py\", line 37, in decorated_main\r\n",
      "    strict=strict,\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/utils.py\", line 347, in _run_hydra\r\n",
      "    lambda: hydra.run(\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/utils.py\", line 201, in run_and_report\r\n",
      "    raise ex\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/utils.py\", line 198, in run_and_report\r\n",
      "    return func()\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/utils.py\", line 350, in <lambda>\r\n",
      "    overrides=args.overrides,\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/hydra.py\", line 104, in run\r\n",
      "    run_mode=RunMode.RUN,\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/hydra.py\", line 505, in compose_config\r\n",
      "    self.config_loader.ensure_main_config_source_available()\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/config_loader_impl.py\", line 139, in ensure_main_config_source_available\r\n",
      "    config_name=None, msg=msg, with_search_path=False\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/config_loader_impl.py\", line 113, in missing_config_error\r\n",
      "    missing_cfg_file=config_name, message=add_search_path()\r\n",
      "hydra.errors.MissingConfigException: Primary config directory not found.\r\n",
      "Check that the config directory '/tmp/fairseq/examples/speech_recognition/kaldi/config' exists and readable\r\n",
      "=== 1/5 Counting and sorting n-grams ===\r\n",
      "Reading /kaggle/working/preppedtext/phones/lm.phones.filtered.txt\r\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\r\n",
      "****************************************************************************************************\r\n",
      "Unigram tokens 63630 types 44\r\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\r\n",
      "Chain sizes: 1:528 2:2571436544 3:4821443584 4:7714310144\r\n",
      "Substituting fallback discounts for order 0: D1=0.5 D2=1 D3+=1.5\r\n",
      "Statistics:\r\n",
      "1 44 D1=0.5 D2=1 D3+=1.5\r\n",
      "2 1060 D1=0.447028 D2=0.897051 D3+=1.55732\r\n",
      "3 8502 D1=0.549292 D2=1.20022 D3+=1.48284\r\n",
      "4 23127 D1=0.645287 D2=1.1465 D3+=1.54319\r\n",
      "Memory estimate for binary LM:\r\n",
      "type     kB\r\n",
      "probing 631 assuming -p 1.5\r\n",
      "probing 687 assuming -r models -p 1.5\r\n",
      "trie    203 without quantization\r\n",
      "trie     88 assuming -q 8 -b 8 quantization \r\n",
      "trie    196 assuming -a 22 array pointer compression\r\n",
      "trie     81 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\r\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\r\n",
      "Chain sizes: 1:528 2:16960 3:170040 4:555048\r\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\r\n",
      "####################################################################################################\r\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\r\n",
      "Chain sizes: 1:528 2:16960 3:170040 4:555048\r\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\r\n",
      "####################################################################################################\r\n",
      "=== 5/5 Writing ARPA model ===\r\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\r\n",
      "****************************************************************************************************\r\n",
      "Name:lmplz\tVmPeak:14916780 kB\tVmRSS:6980 kB\tRSSMax:2973788 kB\tuser:0.447498\tsys:1.43395\tCPU:1.88154\treal:1.88154\r\n",
      "Reading /kaggle/working/preppedtext/phones/lm.phones.filtered.04.arpa\r\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\r\n",
      "****************************************************************************************************\r\n",
      "SUCCESS\r\n",
      "=== 1/5 Counting and sorting n-grams ===\r\n",
      "Reading /kaggle/working/preppedtext/phones/lm.phones.filtered.txt\r\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\r\n",
      "****************************************************************************************************\r\n",
      "Unigram tokens 63630 types 44\r\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\r\n",
      "Chain sizes: 1:528 2:929673280 3:1743137408 4:2789019904 5:4067320832 6:5578039808\r\n",
      "Substituting fallback discounts for order 0: D1=0.5 D2=1 D3+=1.5\r\n",
      "Statistics:\r\n",
      "1 44 D1=0.5 D2=1 D3+=1.5\r\n",
      "2 1060 D1=0.447028 D2=0.897051 D3+=1.55732\r\n",
      "3 8502 D1=0.549292 D2=1.20022 D3+=1.48284\r\n",
      "4 23127 D1=0.704396 D2=1.27443 D3+=1.57841\r\n",
      "5 35921 D1=0.825334 D2=1.32418 D3+=1.54919\r\n",
      "6 43631 D1=0.835995 D2=1.20618 D3+=1.69909\r\n",
      "Memory estimate for binary LM:\r\n",
      "type      kB\r\n",
      "probing 2376 assuming -p 1.5\r\n",
      "probing 2778 assuming -r models -p 1.5\r\n",
      "trie     908 without quantization\r\n",
      "trie     401 assuming -q 8 -b 8 quantization \r\n",
      "trie     839 assuming -a 22 array pointer compression\r\n",
      "trie     331 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\r\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\r\n",
      "Chain sizes: 1:528 2:16960 3:170040 4:555048 5:1005788 6:1396192\r\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\r\n",
      "####################################################################################################\r\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\r\n",
      "Chain sizes: 1:528 2:16960 3:170040 4:555048 5:1005788 6:1396192\r\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\r\n",
      "####################################################################################################\r\n",
      "=== 5/5 Writing ARPA model ===\r\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\r\n",
      "****************************************************************************************************\r\n",
      "Name:lmplz\tVmPeak:14949572 kB\tVmRSS:6652 kB\tRSSMax:2354428 kB\tuser:0.445007\tsys:1.16748\tCPU:1.61253\treal:1.63839\r\n",
      "Reading /kaggle/working/preppedtext/phones/lm.phones.filtered.06.arpa\r\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\r\n",
      "****************************************************************************************************\r\n",
      "SUCCESS\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/tmp/fairseq/examples/speech_recognition/kaldi/kaldi_initializer.py\", line 698, in <module>\r\n",
      "    cli_main()\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/main.py\", line 37, in decorated_main\r\n",
      "    strict=strict,\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/utils.py\", line 347, in _run_hydra\r\n",
      "    lambda: hydra.run(\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/utils.py\", line 201, in run_and_report\r\n",
      "    raise ex\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/utils.py\", line 198, in run_and_report\r\n",
      "    return func()\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/utils.py\", line 350, in <lambda>\r\n",
      "    overrides=args.overrides,\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/hydra.py\", line 104, in run\r\n",
      "    run_mode=RunMode.RUN,\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/hydra.py\", line 505, in compose_config\r\n",
      "    self.config_loader.ensure_main_config_source_available()\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/config_loader_impl.py\", line 139, in ensure_main_config_source_available\r\n",
      "    config_name=None, msg=msg, with_search_path=False\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/config_loader_impl.py\", line 113, in missing_config_error\r\n",
      "    missing_cfg_file=config_name, message=add_search_path()\r\n",
      "hydra.errors.MissingConfigException: Primary config directory not found.\r\n",
      "Check that the config directory '/tmp/fairseq/examples/speech_recognition/kaldi/config' exists and readable\r\n"
     ]
    }
   ],
   "source": [
    "!zsh prepare_text.sh sv /kaggle/working/sentences.txt /kaggle/working/preppedtext"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 253.923608,
   "end_time": "2021-05-30T14:30:02.912545",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-30T14:25:48.988937",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
