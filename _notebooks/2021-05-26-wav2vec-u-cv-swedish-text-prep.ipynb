{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "private-bunch",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-05-29T19:16:48.323062Z",
     "iopub.status.busy": "2021-05-29T19:16:48.322339Z",
     "iopub.status.idle": "2021-05-29T19:16:48.327910Z",
     "shell.execute_reply": "2021-05-29T19:16:48.327234Z",
     "shell.execute_reply.started": "2021-05-25T22:46:58.262403Z"
    },
    "papermill": {
     "duration": 0.032754,
     "end_time": "2021-05-29T19:16:48.328085",
     "exception": false,
     "start_time": "2021-05-29T19:16:48.295331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp\n"
     ]
    }
   ],
   "source": [
    "%cd /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "centered-model",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T19:16:48.377087Z",
     "iopub.status.busy": "2021-05-29T19:16:48.365489Z",
     "iopub.status.idle": "2021-05-29T19:16:53.166576Z",
     "shell.execute_reply": "2021-05-29T19:16:53.165861Z",
     "shell.execute_reply.started": "2021-05-25T22:38:20.218298Z"
    },
    "papermill": {
     "duration": 4.822065,
     "end_time": "2021-05-29T19:16:53.166725",
     "exception": false,
     "start_time": "2021-05-29T19:16:48.344660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'fairseq'...\r\n",
      "remote: Enumerating objects: 28172, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (586/586), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (340/340), done.\u001b[K\r\n",
      "remote: Total 28172 (delta 308), reused 464 (delta 233), pack-reused 27586\u001b[K\r\n",
      "Receiving objects: 100% (28172/28172), 11.89 MiB | 8.49 MiB/s, done.\r\n",
      "Resolving deltas: 100% (21133/21133), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/pytorch/fairseq/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "addressed-kentucky",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T19:16:53.228379Z",
     "iopub.status.busy": "2021-05-29T19:16:53.224210Z",
     "iopub.status.idle": "2021-05-29T19:17:05.593597Z",
     "shell.execute_reply": "2021-05-29T19:17:05.592916Z"
    },
    "papermill": {
     "duration": 12.401279,
     "end_time": "2021-05-29T19:17:05.593741",
     "exception": false,
     "start_time": "2021-05-29T19:16:53.192462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install phonemizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "opponent-balance",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T19:17:05.655204Z",
     "iopub.status.busy": "2021-05-29T19:17:05.650710Z",
     "iopub.status.idle": "2021-05-29T19:18:09.495134Z",
     "shell.execute_reply": "2021-05-29T19:18:09.495680Z"
    },
    "papermill": {
     "duration": 63.876809,
     "end_time": "2021-05-29T19:18:09.495937",
     "exception": false,
     "start_time": "2021-05-29T19:17:05.619128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install git+https://github.com/pytorch/fairseq/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "parental-dollar",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T19:18:09.558321Z",
     "iopub.status.busy": "2021-05-29T19:18:09.553842Z",
     "iopub.status.idle": "2021-05-29T19:18:17.454304Z",
     "shell.execute_reply": "2021-05-29T19:18:17.453718Z"
    },
    "papermill": {
     "duration": 7.932567,
     "end_time": "2021-05-29T19:18:17.454481",
     "exception": false,
     "start_time": "2021-05-29T19:18:09.521914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!apt-get -y install espeak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "floating-october",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T19:18:17.516849Z",
     "iopub.status.busy": "2021-05-29T19:18:17.516150Z",
     "iopub.status.idle": "2021-05-29T19:18:21.152664Z",
     "shell.execute_reply": "2021-05-29T19:18:21.152131Z",
     "shell.execute_reply.started": "2021-05-25T22:47:02.096238Z"
    },
    "papermill": {
     "duration": 3.672719,
     "end_time": "2021-05-29T19:18:21.152809",
     "exception": false,
     "start_time": "2021-05-29T19:18:17.480090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'kenlm'...\r\n",
      "remote: Enumerating objects: 13824, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (137/137), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (79/79), done.\u001b[K\r\n",
      "remote: Total 13824 (delta 76), reused 92 (delta 45), pack-reused 13687\u001b[K\r\n",
      "Receiving objects: 100% (13824/13824), 5.49 MiB | 4.32 MiB/s, done.\r\n",
      "Resolving deltas: 100% (7956/7956), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/kpu/kenlm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "stock-heritage",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T19:18:21.227372Z",
     "iopub.status.busy": "2021-05-29T19:18:21.226700Z",
     "iopub.status.idle": "2021-05-29T19:18:27.371762Z",
     "shell.execute_reply": "2021-05-29T19:18:27.370613Z"
    },
    "papermill": {
     "duration": 6.187097,
     "end_time": "2021-05-29T19:18:27.371918",
     "exception": false,
     "start_time": "2021-05-29T19:18:21.184821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!apt-get -y install libeigen3-dev liblzma-dev zlib1g-dev libbz2-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "other-jordan",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T19:18:27.445253Z",
     "iopub.status.busy": "2021-05-29T19:18:27.444600Z",
     "iopub.status.idle": "2021-05-29T19:19:38.171710Z",
     "shell.execute_reply": "2021-05-29T19:19:38.171151Z"
    },
    "papermill": {
     "duration": 70.768262,
     "end_time": "2021-05-29T19:19:38.171868",
     "exception": false,
     "start_time": "2021-05-29T19:18:27.403606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%cd kenlm\n",
    "!mkdir build\n",
    "%cd build\n",
    "!cmake ..\n",
    "!make -j 4\n",
    "%cd /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "guided-metabolism",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T19:19:38.242865Z",
     "iopub.status.busy": "2021-05-29T19:19:38.241909Z",
     "iopub.status.idle": "2021-05-29T19:19:38.245741Z",
     "shell.execute_reply": "2021-05-29T19:19:38.245213Z",
     "shell.execute_reply.started": "2021-05-25T22:58:58.397816Z"
    },
    "papermill": {
     "duration": 0.041367,
     "end_time": "2021-05-29T19:19:38.245899",
     "exception": false,
     "start_time": "2021-05-29T19:19:38.204532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PATH'] = f\"{os.environ['PATH']}:/tmp/kenlm/build/bin/\"\n",
    "os.environ['FAIRSEQ_ROOT'] = '/tmp/fairseq'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "naked-clothing",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T19:19:38.321585Z",
     "iopub.status.busy": "2021-05-29T19:19:38.316618Z",
     "iopub.status.idle": "2021-05-29T19:19:39.083886Z",
     "shell.execute_reply": "2021-05-29T19:19:39.083187Z",
     "shell.execute_reply.started": "2021-05-25T22:55:06.647826Z"
    },
    "papermill": {
     "duration": 0.805417,
     "end_time": "2021-05-29T19:19:39.084040",
     "exception": false,
     "start_time": "2021-05-29T19:19:38.278623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cat /kaggle/input/wav2vec-u-cv-swedish-audio/*.wrd | grep -v '^$' | sort| uniq > /kaggle/working/sentences.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "impressed-horse",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T19:19:39.154611Z",
     "iopub.status.busy": "2021-05-29T19:19:39.153792Z",
     "iopub.status.idle": "2021-05-29T19:19:39.159734Z",
     "shell.execute_reply": "2021-05-29T19:19:39.158717Z",
     "shell.execute_reply.started": "2021-05-25T22:55:38.373919Z"
    },
    "papermill": {
     "duration": 0.043826,
     "end_time": "2021-05-29T19:19:39.159995",
     "exception": false,
     "start_time": "2021-05-29T19:19:39.116169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/fairseq/examples/wav2vec/unsupervised\n"
     ]
    }
   ],
   "source": [
    "%cd fairseq/examples/wav2vec/unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "decreased-function",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T19:19:39.230384Z",
     "iopub.status.busy": "2021-05-29T19:19:39.229748Z",
     "iopub.status.idle": "2021-05-29T19:19:45.982940Z",
     "shell.execute_reply": "2021-05-29T19:19:45.981976Z"
    },
    "papermill": {
     "duration": 6.788479,
     "end_time": "2021-05-29T19:19:45.983100",
     "exception": false,
     "start_time": "2021-05-29T19:19:39.194621",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "\r\n",
      "The following additional packages will be installed:\r\n",
      "  libcap2 zsh-common\r\n",
      "Suggested packages:\r\n",
      "  zsh-doc\r\n",
      "The following NEW packages will be installed:\r\n",
      "  libcap2 zsh zsh-common\r\n",
      "0 upgraded, 3 newly installed, 0 to remove and 15 not upgraded.\r\n",
      "Need to get 4079 kB of archives.\r\n",
      "After this operation, 15.2 MB of additional disk space will be used.\r\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libcap2 amd64 1:2.25-1.2 [13.0 kB]\r\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 zsh-common all 5.4.2-3ubuntu3.1 [3376 kB]\r\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 zsh amd64 5.4.2-3ubuntu3.1 [690 kB]\r\n",
      "Fetched 4079 kB in 3s (1522 kB/s)\r\n",
      "debconf: delaying package configuration, since apt-utils is not installed\r\n",
      "Selecting previously unselected package libcap2:amd64.\r\n",
      "(Reading database ... 96266 files and directories currently installed.)\r\n",
      "Preparing to unpack .../libcap2_1%3a2.25-1.2_amd64.deb ...\r\n",
      "Unpacking libcap2:amd64 (1:2.25-1.2) ...\r\n",
      "Selecting previously unselected package zsh-common.\r\n",
      "Preparing to unpack .../zsh-common_5.4.2-3ubuntu3.1_all.deb ...\r\n",
      "Unpacking zsh-common (5.4.2-3ubuntu3.1) ...\r\n",
      "Selecting previously unselected package zsh.\r\n",
      "Preparing to unpack .../zsh_5.4.2-3ubuntu3.1_amd64.deb ...\r\n",
      "Unpacking zsh (5.4.2-3ubuntu3.1) ...\r\n",
      "Setting up libcap2:amd64 (1:2.25-1.2) ...\r\n",
      "Setting up zsh-common (5.4.2-3ubuntu3.1) ...\r\n",
      "Setting up zsh (5.4.2-3ubuntu3.1) ...\r\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1.4) ...\r\n"
     ]
    }
   ],
   "source": [
    "!apt-get -y install zsh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "regional-zambia",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T19:19:46.079994Z",
     "iopub.status.busy": "2021-05-29T19:19:46.078848Z",
     "iopub.status.idle": "2021-05-29T19:19:46.807027Z",
     "shell.execute_reply": "2021-05-29T19:19:46.807542Z",
     "shell.execute_reply.started": "2021-05-25T22:58:19.000595Z"
    },
    "papermill": {
     "duration": 0.781675,
     "end_time": "2021-05-29T19:19:46.807731",
     "exception": false,
     "start_time": "2021-05-29T19:19:46.026056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir /kaggle/working/preppedtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "hollywood-shakespeare",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T19:19:46.899045Z",
     "iopub.status.busy": "2021-05-29T19:19:46.898068Z",
     "iopub.status.idle": "2021-05-29T19:19:46.901955Z",
     "shell.execute_reply": "2021-05-29T19:19:46.902472Z",
     "shell.execute_reply.started": "2021-05-25T23:04:33.0148Z"
    },
    "papermill": {
     "duration": 0.052423,
     "end_time": "2021-05-29T19:19:46.902650",
     "exception": false,
     "start_time": "2021-05-29T19:19:46.850227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/fairseq/examples/wav2vec/unsupervised/scripts\n"
     ]
    }
   ],
   "source": [
    "%cd scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-integration",
   "metadata": {
    "papermill": {
     "duration": 0.04385,
     "end_time": "2021-05-29T19:19:46.989458",
     "exception": false,
     "start_time": "2021-05-29T19:19:46.945608",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The next part requires a FastText language id model; I don't know where the 187 language model comes from, but there is a model for 176 languages [here](https://fasttext.cc/docs/en/language-identification.html#content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "official-voluntary",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T19:19:47.086894Z",
     "iopub.status.busy": "2021-05-29T19:19:47.082956Z",
     "iopub.status.idle": "2021-05-29T19:20:01.124149Z",
     "shell.execute_reply": "2021-05-29T19:20:01.123607Z",
     "shell.execute_reply.started": "2021-05-25T23:26:05.700782Z"
    },
    "papermill": {
     "duration": 14.090901,
     "end_time": "2021-05-29T19:20:01.124308",
     "exception": false,
     "start_time": "2021-05-29T19:19:47.033407",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-05-29 19:19:47--  https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin\r\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 104.22.74.142, 172.67.9.4, ...\r\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 131266198 (125M) [application/octet-stream]\r\n",
      "Saving to: ‘lid.176.bin’\r\n",
      "\r\n",
      "lid.176.bin         100%[===================>] 125.18M  11.5MB/s    in 12s     \r\n",
      "\r\n",
      "2021-05-29 19:20:01 (10.4 MB/s) - ‘lid.176.bin’ saved [131266198/131266198]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://dl.fbaipublicfiles.com/fasttext/supervised-models/lid.176.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "objective-fossil",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T19:20:01.252052Z",
     "iopub.status.busy": "2021-05-29T19:20:01.248201Z",
     "iopub.status.idle": "2021-05-29T19:20:02.700405Z",
     "shell.execute_reply": "2021-05-29T19:20:02.699692Z",
     "shell.execute_reply.started": "2021-05-25T23:28:29.362953Z"
    },
    "papermill": {
     "duration": 1.516324,
     "end_time": "2021-05-29T19:20:02.700582",
     "exception": false,
     "start_time": "2021-05-29T19:20:01.184258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cat normalize_and_filter_text.py|sed -e 's/187/176/' > tmp\n",
    "!mv tmp normalize_and_filter_text.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "surface-tobago",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T19:20:02.826445Z",
     "iopub.status.busy": "2021-05-29T19:20:02.825763Z",
     "iopub.status.idle": "2021-05-29T19:20:02.828981Z",
     "shell.execute_reply": "2021-05-29T19:20:02.828372Z"
    },
    "papermill": {
     "duration": 0.066584,
     "end_time": "2021-05-29T19:20:02.829132",
     "exception": false,
     "start_time": "2021-05-29T19:20:02.762548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Needed to see what's going wrong\n",
    "os.environ['HYDRA_FULL_ERROR'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-stack",
   "metadata": {
    "papermill": {
     "duration": 0.057473,
     "end_time": "2021-05-29T19:20:02.944505",
     "exception": false,
     "start_time": "2021-05-29T19:20:02.887032",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "There are two lines with missing variables in `prepare_text.sh` - [pull request](https://github.com/pytorch/fairseq/pull/3569) - so replace the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "broke-instruction",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-05-29T19:20:03.070016Z",
     "iopub.status.busy": "2021-05-29T19:20:03.069285Z",
     "iopub.status.idle": "2021-05-29T19:20:03.073913Z",
     "shell.execute_reply": "2021-05-29T19:20:03.073281Z"
    },
    "papermill": {
     "duration": 0.069996,
     "end_time": "2021-05-29T19:20:03.074067",
     "exception": false,
     "start_time": "2021-05-29T19:20:03.004071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting prepare_text.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile prepare_text.sh\n",
    "#!/usr/bin/env zsh\n",
    "# Copyright (c) Facebook, Inc. and its affiliates.\n",
    "#\n",
    "# This source code is licensed under the MIT license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "\n",
    "lg=$1\n",
    "text_path=$2\n",
    "target_dir=$3\n",
    "\n",
    "ph_lg=${lg:l}\n",
    "if test \"$lg\" = 'fr'; then\n",
    "  ph_lg='fr-fr'\n",
    "elif test \"$lg\" = 'en'; then\n",
    "  ph_lg='en-us'\n",
    "elif test \"$lg\" = 'pt'; then\n",
    "  ph_lg='pt-br'\n",
    "fi\n",
    "\n",
    "echo $lg\n",
    "echo $ph_lg\n",
    "echo $text_path\n",
    "echo $target_dir\n",
    "\n",
    "mkdir -p $target_dir\n",
    "python normalize_and_filter_text.py --lang $lg < $text_path | grep -v '\\-\\-\\-' >! $target_dir/lm.upper.lid.txt\n",
    "python $FAIRSEQ_ROOT/fairseq_cli/preprocess.py --dataset-impl mmap --trainpref $target_dir/lm.upper.lid.txt --only-source --destdir $target_dir --thresholdsrc 2 --padding-factor 1 --dict-only\n",
    "cut -f1 -d' ' $target_dir/dict.txt | grep -v -x '[[:punct:]]*' | grep -Pv '\\d\\d\\d\\d\\d+' >! $target_dir/words.txt\n",
    "\n",
    "one=$(echo \"1\" | PHONEMIZER_ESPEAK_PATH=$(which espeak) phonemize -p ' ' -w '' -l $ph_lg --language-switch remove-flags)\n",
    "sed 's/$/ 1/' $target_dir/words.txt | PHONEMIZER_ESPEAK_PATH=$(which espeak) phonemize -o $target_dir/phones.txt -p ' ' -w '' -l $ph_lg -j 70 --language-switch remove-flags\n",
    "\n",
    "echo \"one is ${one}\"\n",
    "\n",
    "sed -i \"s/${one}$//\" $target_dir/phones.txt\n",
    "paste $target_dir/words.txt $target_dir/phones.txt >! $target_dir/lexicon.lst\n",
    "\n",
    "python $FAIRSEQ_ROOT/fairseq_cli/preprocess.py --dataset-impl mmap --trainpref $target_dir/phones.txt --only-source --destdir $target_dir/phones --thresholdsrc 1000 --padding-factor 1 --dict-only\n",
    "\n",
    "python filter_lexicon.py -d $target_dir/phones/dict.txt < $target_dir/lexicon.lst >! $target_dir/lexicon_filtered.lst\n",
    "python phonemize_with_sil.py -s 0.25 --surround --lexicon $target_dir/lexicon_filtered.lst < $target_dir/lm.upper.lid.txt >! $target_dir/phones/lm.phones.filtered.txt\n",
    "cp $target_dir/phones/dict.txt $target_dir/phones/dict.phn.txt\n",
    "echo \"<SIL> 0\" >> $target_dir/phones/dict.phn.txt\n",
    "python $FAIRSEQ_ROOT/fairseq_cli/preprocess.py --dataset-impl mmap --trainpref $target_dir/phones/lm.phones.filtered.txt --workers 70 --only-source --destdir $target_dir/phones --srcdict $target_dir/phones/dict.phn.txt\n",
    "\n",
    "lmplz -o 4 < $target_dir/lm.upper.lid.txt --discount_fallback --prune 0 0 0 3 >! $target_dir/kenlm.wrd.o40003.arpa\n",
    "build_binary $target_dir/kenlm.wrd.o40003.arpa $target_dir/kenlm.wrd.o40003.bin\n",
    "lg=$lg python $FAIRSEQ_ROOT/examples/speech_recognition/kaldi/kaldi_initializer.py fst_dir=$target_dir/fst/phn_to_words_sil lm_arpa=$target_dir/kenlm.wrd.o40003.arpa wav2letter_lexicon=$target_dir/lexicon_filtered.lst data_dir=$target_dir/phones \"blank_symbol='<SIL>'\"\n",
    "lg=$lg python $FAIRSEQ_ROOT/examples/speech_recognition/kaldi/kaldi_initializer.py fst_dir=$target_dir/fst/phn_to_words lm_arpa=$target_dir/kenlm.wrd.o40003.arpa wav2letter_lexicon=$target_dir/lexicon_filtered.lst data_dir=$target_dir/phones\n",
    "\n",
    "lmplz -o 4 < $target_dir/phones/lm.phones.filtered.txt --discount_fallback >! $target_dir/phones/lm.phones.filtered.04.arpa\n",
    "build_binary $target_dir/phones/lm.phones.filtered.04.arpa $target_dir/phones/lm.phones.filtered.04.bin\n",
    "lmplz -o 6 < $target_dir/phones/lm.phones.filtered.txt --discount_fallback >! $target_dir/phones/lm.phones.filtered.06.arpa\n",
    "build_binary $target_dir/phones/lm.phones.filtered.06.arpa $target_dir/phones/lm.phones.filtered.06.bin\n",
    "\n",
    "lg=$lg python $FAIRSEQ_ROOT/examples/speech_recognition/kaldi/kaldi_initializer.py fst_dir=$target_dir/fst/phn_to_phn_sil lm_arpa=$target_dir/phones/lm.phones.filtered.06.arpa data_dir=$target_dir/phones \"blank_symbol='<SIL>'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "affiliated-earthquake",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-29T19:20:03.195325Z",
     "iopub.status.busy": "2021-05-29T19:20:03.194670Z",
     "iopub.status.idle": "2021-05-29T19:21:05.648621Z",
     "shell.execute_reply": "2021-05-29T19:21:05.647997Z",
     "shell.execute_reply.started": "2021-05-25T23:28:33.84656Z"
    },
    "papermill": {
     "duration": 62.515826,
     "end_time": "2021-05-29T19:21:05.648794",
     "exception": false,
     "start_time": "2021-05-29T19:20:03.132968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sv\r\n",
      "sv\r\n",
      "/kaggle/working/sentences.txt\r\n",
      "/kaggle/working/preppedtext\r\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\r\n",
      "[WARNING] 1 utterances containing language switches on lines 1546\r\n",
      "[WARNING] extra phones may appear in the \"sv\" phoneset\r\n",
      "[WARNING] language switch flags have been removed (applying \"remove-flags\" policy)\r\n",
      "one is ɛ t \r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/tmp/fairseq/fairseq_cli/preprocess.py\", line 401, in <module>\r\n",
      "    cli_main()\r\n",
      "  File \"/tmp/fairseq/fairseq_cli/preprocess.py\", line 397, in cli_main\r\n",
      "    main(args)\r\n",
      "  File \"/tmp/fairseq/fairseq_cli/preprocess.py\", line 287, in main\r\n",
      "    make_all(args.source_lang, src_dict)\r\n",
      "  File \"/tmp/fairseq/fairseq_cli/preprocess.py\", line 255, in make_all\r\n",
      "    make_dataset(vocab, args.trainpref, \"train\", lang, num_workers=args.workers)\r\n",
      "  File \"/tmp/fairseq/fairseq_cli/preprocess.py\", line 251, in make_dataset\r\n",
      "    make_binary_dataset(vocab, input_prefix, output_prefix, lang, num_workers)\r\n",
      "  File \"/tmp/fairseq/fairseq_cli/preprocess.py\", line 184, in make_binary_dataset\r\n",
      "    100 * sum(replaced.values()) / n_seq_tok[1],\r\n",
      "ZeroDivisionError: division by zero\r\n",
      "=== 1/5 Counting and sorting n-grams ===\r\n",
      "Reading /kaggle/working/preppedtext/lm.upper.lid.txt\r\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\r\n",
      "****************************************************************************************************\r\n",
      "Unigram tokens 34312 types 5260\r\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\r\n",
      "Chain sizes: 1:63120 2:2571427328 3:4821426176 4:7714281984\r\n",
      "Statistics:\r\n",
      "1 5260 D1=0.693271 D2=1.11217 D3+=1.57922\r\n",
      "2 20174 D1=0.81526 D2=1.18129 D3+=1.4957\r\n",
      "3 27884 D1=0.914828 D2=1.3954 D3+=1.34166\r\n",
      "4 114/27003 D1=0.954567 D2=1.40148 D3+=1.53144\r\n",
      "Memory estimate for binary LM:\r\n",
      "type      kB\r\n",
      "probing 1261 assuming -p 1.5\r\n",
      "probing 1564 assuming -r models -p 1.5\r\n",
      "trie     630 without quantization\r\n",
      "trie     359 assuming -q 8 -b 8 quantization \r\n",
      "trie     588 assuming -a 22 array pointer compression\r\n",
      "trie     317 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\r\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\r\n",
      "Chain sizes: 1:63120 2:322784 3:557680 4:2736\r\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\r\n",
      "####################################################################################################\r\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\r\n",
      "Chain sizes: 1:63120 2:322784 3:557680 4:2736\r\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\r\n",
      "####################################################################################################\r\n",
      "=== 5/5 Writing ARPA model ===\r\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\r\n",
      "****************************************************************************************************\r\n",
      "Name:lmplz\tVmPeak:14916880 kB\tVmRSS:7132 kB\tRSSMax:2975580 kB\tuser:0.467904\tsys:1.57084\tCPU:2.0388\treal:2.03294\r\n",
      "Reading /kaggle/working/preppedtext/kenlm.wrd.o40003.arpa\r\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\r\n",
      "****************************************************************************************************\r\n",
      "SUCCESS\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/tmp/fairseq/examples/speech_recognition/kaldi/kaldi_initializer.py\", line 698, in <module>\r\n",
      "    cli_main()\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/main.py\", line 37, in decorated_main\r\n",
      "    strict=strict,\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/utils.py\", line 347, in _run_hydra\r\n",
      "    lambda: hydra.run(\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/utils.py\", line 201, in run_and_report\r\n",
      "    raise ex\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/utils.py\", line 198, in run_and_report\r\n",
      "    return func()\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/utils.py\", line 350, in <lambda>\r\n",
      "    overrides=args.overrides,\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/hydra.py\", line 104, in run\r\n",
      "    run_mode=RunMode.RUN,\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/hydra.py\", line 505, in compose_config\r\n",
      "    self.config_loader.ensure_main_config_source_available()\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/config_loader_impl.py\", line 139, in ensure_main_config_source_available\r\n",
      "    config_name=None, msg=msg, with_search_path=False\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/config_loader_impl.py\", line 113, in missing_config_error\r\n",
      "    missing_cfg_file=config_name, message=add_search_path()\r\n",
      "hydra.errors.MissingConfigException: Primary config directory not found.\r\n",
      "Check that the config directory '/tmp/fairseq/examples/speech_recognition/kaldi/config' exists and readable\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/tmp/fairseq/examples/speech_recognition/kaldi/kaldi_initializer.py\", line 698, in <module>\r\n",
      "    cli_main()\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/main.py\", line 37, in decorated_main\r\n",
      "    strict=strict,\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/utils.py\", line 347, in _run_hydra\r\n",
      "    lambda: hydra.run(\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/utils.py\", line 201, in run_and_report\r\n",
      "    raise ex\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/utils.py\", line 198, in run_and_report\r\n",
      "    return func()\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/utils.py\", line 350, in <lambda>\r\n",
      "    overrides=args.overrides,\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/hydra.py\", line 104, in run\r\n",
      "    run_mode=RunMode.RUN,\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/hydra.py\", line 505, in compose_config\r\n",
      "    self.config_loader.ensure_main_config_source_available()\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/config_loader_impl.py\", line 139, in ensure_main_config_source_available\r\n",
      "    config_name=None, msg=msg, with_search_path=False\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/config_loader_impl.py\", line 113, in missing_config_error\r\n",
      "    missing_cfg_file=config_name, message=add_search_path()\r\n",
      "hydra.errors.MissingConfigException: Primary config directory not found.\r\n",
      "Check that the config directory '/tmp/fairseq/examples/speech_recognition/kaldi/config' exists and readable\r\n",
      "=== 1/5 Counting and sorting n-grams ===\r\n",
      "Reading /kaggle/working/preppedtext/phones/lm.phones.filtered.txt\r\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\r\n",
      "Unigram tokens 0 types 3\r\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\r\n",
      "Chain sizes: 1:36 2:2571437824 3:4821446144 4:7714313728\r\n",
      "Substituting fallback discounts for order 0: D1=0.5 D2=1 D3+=1.5\r\n",
      "Substituting fallback discounts for order 1: D1=0.5 D2=1 D3+=1.5\r\n",
      "Substituting fallback discounts for order 2: D1=0.5 D2=1 D3+=1.5\r\n",
      "Substituting fallback discounts for order 3: D1=0.5 D2=1 D3+=1.5\r\n",
      "Statistics:\r\n",
      "1 2 D1=0.5 D2=1 D3+=1.5\r\n",
      "2 0 D1=0.5 D2=1 D3+=1.5\r\n",
      "3 0 D1=0.5 D2=1 D3+=1.5\r\n",
      "4 0 D1=0.5 D2=1 D3+=1.5\r\n",
      "Memory estimate for binary LM:\r\n",
      "type       B\r\n",
      "probing  112 assuming -p 1.5\r\n",
      "probing  132 assuming -r models -p 1.5\r\n",
      "trie     135 without quantization\r\n",
      "trie    5248 assuming -q 8 -b 8 quantization \r\n",
      "trie     181 assuming -a 22 array pointer compression\r\n",
      "trie    5294 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\r\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\r\n",
      "Chain sizes: 1:24 2:16 3:20 4:24\r\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\r\n",
      "\r\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\r\n",
      "Chain sizes: 1:24 2:16 3:20 4:24\r\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\r\n",
      "\r\n",
      "=== 5/5 Writing ARPA model ===\r\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\r\n",
      "\r\n",
      "Name:lmplz\tVmPeak:14916784 kB\tVmRSS:5972 kB\tRSSMax:2956896 kB\tuser:0.398667\tsys:1.40684\tCPU:1.80554\treal:1.81231\r\n",
      "Reading /kaggle/working/preppedtext/phones/lm.phones.filtered.04.arpa\r\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\r\n",
      "****************************************************************************************************\r\n",
      "/tmp/kenlm/lm/vocab.cc:305 in void lm::ngram::MissingSentenceMarker(const lm::ngram::Config&, const char*) threw SpecialWordMissingException.\r\n",
      "The ARPA file is missing </s> and the model is configured to reject these models.  Run build_binary -s to disable this check. Byte: 76\r\n",
      "ERROR\r\n",
      "=== 1/5 Counting and sorting n-grams ===\r\n",
      "Reading /kaggle/working/preppedtext/phones/lm.phones.filtered.txt\r\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\r\n",
      "Unigram tokens 0 types 3\r\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\r\n",
      "Chain sizes: 1:36 2:929673728 3:1743138176 4:2789021184 5:4067322624 6:5578042368\r\n",
      "Substituting fallback discounts for order 0: D1=0.5 D2=1 D3+=1.5\r\n",
      "Substituting fallback discounts for order 1: D1=0.5 D2=1 D3+=1.5\r\n",
      "Substituting fallback discounts for order 2: D1=0.5 D2=1 D3+=1.5\r\n",
      "Substituting fallback discounts for order 3: D1=0.5 D2=1 D3+=1.5\r\n",
      "Substituting fallback discounts for order 4: D1=0.5 D2=1 D3+=1.5\r\n",
      "Substituting fallback discounts for order 5: D1=0.5 D2=1 D3+=1.5\r\n",
      "Statistics:\r\n",
      "1 2 D1=0.5 D2=1 D3+=1.5\r\n",
      "2 0 D1=0.5 D2=1 D3+=1.5\r\n",
      "3 0 D1=0.5 D2=1 D3+=1.5\r\n",
      "4 0 D1=0.5 D2=1 D3+=1.5\r\n",
      "5 0 D1=0.5 D2=1 D3+=1.5\r\n",
      "6 0 D1=0.5 D2=1 D3+=1.5\r\n",
      "Memory estimate for binary LM:\r\n",
      "type       B\r\n",
      "probing  144 assuming -p 1.5\r\n",
      "probing  172 assuming -r models -p 1.5\r\n",
      "trie     169 without quantization\r\n",
      "trie    9366 assuming -q 8 -b 8 quantization \r\n",
      "trie     261 assuming -a 22 array pointer compression\r\n",
      "trie    9458 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\r\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\r\n",
      "Chain sizes: 1:24 2:16 3:20 4:24 5:28 6:32\r\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\r\n",
      "\r\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\r\n",
      "Chain sizes: 1:24 2:16 3:20 4:24 5:28 6:32\r\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\r\n",
      "\r\n",
      "=== 5/5 Writing ARPA model ===\r\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\r\n",
      "\r\n",
      "Name:lmplz\tVmPeak:14949572 kB\tVmRSS:5940 kB\tRSSMax:2336828 kB\tuser:0.309765\tsys:1.12049\tCPU:1.43031\treal:1.44001\r\n",
      "Reading /kaggle/working/preppedtext/phones/lm.phones.filtered.06.arpa\r\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\r\n",
      "****************************************************************************************************\r\n",
      "/tmp/kenlm/lm/vocab.cc:305 in void lm::ngram::MissingSentenceMarker(const lm::ngram::Config&, const char*) threw SpecialWordMissingException.\r\n",
      "The ARPA file is missing </s> and the model is configured to reject these models.  Run build_binary -s to disable this check. Byte: 96\r\n",
      "ERROR\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/tmp/fairseq/examples/speech_recognition/kaldi/kaldi_initializer.py\", line 698, in <module>\r\n",
      "    cli_main()\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/main.py\", line 37, in decorated_main\r\n",
      "    strict=strict,\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/utils.py\", line 347, in _run_hydra\r\n",
      "    lambda: hydra.run(\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/utils.py\", line 201, in run_and_report\r\n",
      "    raise ex\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/utils.py\", line 198, in run_and_report\r\n",
      "    return func()\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/utils.py\", line 350, in <lambda>\r\n",
      "    overrides=args.overrides,\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/hydra.py\", line 104, in run\r\n",
      "    run_mode=RunMode.RUN,\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/hydra.py\", line 505, in compose_config\r\n",
      "    self.config_loader.ensure_main_config_source_available()\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/config_loader_impl.py\", line 139, in ensure_main_config_source_available\r\n",
      "    config_name=None, msg=msg, with_search_path=False\r\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/hydra/_internal/config_loader_impl.py\", line 113, in missing_config_error\r\n",
      "    missing_cfg_file=config_name, message=add_search_path()\r\n",
      "hydra.errors.MissingConfigException: Primary config directory not found.\r\n",
      "Check that the config directory '/tmp/fairseq/examples/speech_recognition/kaldi/config' exists and readable\r\n"
     ]
    }
   ],
   "source": [
    "!zsh prepare_text.sh sv /kaggle/working/sentences.txt /kaggle/working/preppedtext"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 266.982915,
   "end_time": "2021-05-29T19:21:07.233806",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-29T19:16:40.250891",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
