{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Living Audio Irish\"\n",
    "> \"TTS test corpus for Irish from IDLAK\"\n",
    "\n",
    "- toc: false\n",
    "- branch: master\n",
    "- comments: true\n",
    "- categories: [speech, dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!wget https://ia800700.us.archive.org/6/items/ga.ie.cll.48000.tar/ga.ie.cll.48000.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!wget https://raw.githubusercontent.com/Idlak/Living-Audio-Dataset/master/ga/text.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!tar zxvf ga.ie.cll.48000.tar.gz\n",
    "!rm ga.ie.cll.48000.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "soup = BeautifulSoup(open('text.xml').read(), 'lxml')\n",
    "dataset = list()\n",
    "for entry in soup.find_all('fileid'):\n",
    "    current = dict()\n",
    "    current['id'] = entry['id']\n",
    "    current['text'] = unicodedata.normalize('NFC', entry.text.strip())\n",
    "    dataset.append(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm text.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_upper_vowel(letter):\n",
    "  if letter in ['A', 'E', 'I', 'O', 'U', 'Á', 'É', 'Í', 'Ó', 'Ú']:\n",
    "    return True\n",
    "  else:\n",
    "    return False\n",
    "\n",
    "def irish_lower(word):\n",
    "  if len(word) > 1 and word[0] in ['n', 't'] and is_upper_vowel(word[1]):\n",
    "    return word[0] + '-' + word[1:].lower()\n",
    "  else:\n",
    "    return word.lower()\n",
    "\n",
    "def irish_lower_sentence(sentence):\n",
    "  return \" \".join([irish_lower(w) for w in sentence.split(\" \")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "hyphens = 'cll_z0001_713 cll_z0001_804 cll_z0002_069 cll_z0002_296 cll_z0002_448 cll_z0002_481 cll_z0002_484 cll_z0002_495'.split(' ')\n",
    "for entry in dataset:\n",
    "    tmp = entry['text']\n",
    "    tmp = re.sub(' \\- ', ' ', tmp)\n",
    "    tmp = re.sub(' – ', ' ', tmp)\n",
    "    tmp = re.sub('[‘“”\\\"\\.\\?!,–—;:]', '', tmp)\n",
    "    if entry['id'] in hyphens:\n",
    "        tmp = re.sub('\\'', '', tmp)\n",
    "    entry['sentence'] = irish_lower_sentence(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in dataset:\n",
    "    entry['speaker'] = 'cll'\n",
    "    entry['accent'] = 'dublin'\n",
    "    entry['gender'] = 'male'\n",
    "    entry['path'] = '../input/living-audio-irish-speech-corpus/48000_orig/{}.wav'.format(entry['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "datasetjson = json.dumps(dataset)\n",
    "jsonf = open(\"living-audio.json\", \"w\")\n",
    "jsonf.write(datasetjson)\n",
    "jsonf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-04-20 21:54:40--  https://raw.githubusercontent.com/Idlak/idlak/master/idlak-data/ga/ie/lexicon-default.xml\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 405337 (396K) [text/plain]\n",
      "Saving to: ‘lexicon-default.xml’\n",
      "\n",
      "lexicon-default.xml 100%[===================>] 395.84K  --.-KB/s    in 0.03s   \n",
      "\n",
      "2021-04-20 21:54:40 (14.8 MB/s) - ‘lexicon-default.xml’ saved [405337/405337]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/Idlak/idlak/master/idlak-data/ga/ie/lexicon-default.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "soup = BeautifulSoup(open('lexicon-default.xml').read(), 'lxml')\n",
    "lexicon = []\n",
    "for entry in soup.find_all('lex'):\n",
    "    current = {}\n",
    "    current['pron'] = entry['pron']\n",
    "    current['text'] = unicodedata.normalize('NFC', entry.text.strip())\n",
    "    lexicon.append(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexiconjson = json.dumps(lexicon)\n",
    "jsonf = open(\"ga-lexicon.json\", \"w\")\n",
    "jsonf.write(lexiconjson)\n",
    "jsonf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm lexicon-default.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MFA/Kaldi style lexicon\n",
    "with open('lexicon.txt', 'w') as lextxt:\n",
    "    for lex in lexicon:\n",
    "        text = lex['text']\n",
    "        cleaned = lex['pron'].replace('0', '').replace('1', '').replace('2', '')\n",
    "        lextxt.write(f'{text} {cleaned}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
