{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trim LabelStudio annotations\n",
    "\n",
    "> \"to match trimmed audio\"\n",
    "\n",
    "- branch: master\n",
    "- hidden: true\n",
    "- comments: false\n",
    "- categories: [labelstudio, trim, csv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- normalise text for inline marks ([breath], etc.)\n",
    "- get annotation IDs in a better way (currently there's a hardcoded list)\n",
    "- do something better with truncated entries (skip?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slurpfile(filename) -> str:\n",
    "    with open(filename) as inf:\n",
    "        return inf.read().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The API key is just read from `label_studio_mine` in the current directory (relative to the notebook). It's available under \"Accounts & Settings\" in the user menu, top right of the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "timecode_dir = \"/Users/joregan/timecode_cut\"\n",
    "output_dir = \"/tmp/textgrid_cut\"\n",
    "host = \"http://130.237.3.107:8080/api/\"\n",
    "api_token: str = slurpfile(\"../_drafts/label_studio_mine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "timecode_path = Path(timecode_dir)\n",
    "output_path = Path(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timecode_offsets(filename):\n",
    "    if type(filename) == Path:\n",
    "        filename = str(filename)\n",
    "\n",
    "    with open(filename) as inf:\n",
    "        lines = [l.strip() for l in inf.readlines()]\n",
    "        assert lines[0] == \",Frame,Time (Seconds),TimeCode\", f\"CSV file ({filename}) seems to be incorrect\"\n",
    "        p_start = lines[1].split(\",\")\n",
    "        start = float(p_start[2])\n",
    "        p_end = lines[-1].split(\",\")\n",
    "        end = float(p_end[2])\n",
    "        return start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Token {api_token}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIXME: need a better way to get these than hardcoding a list, but that will take a bunch of reading API docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDS = [\n",
    "    89,\n",
    "    163,\n",
    "    164,\n",
    "    165,\n",
    "    166,\n",
    "    167,\n",
    "    168,\n",
    "    169,\n",
    "    170,\n",
    "    171,\n",
    "    172,\n",
    "    173,\n",
    "    174,\n",
    "    175,\n",
    "    176,\n",
    "    177,\n",
    "    178,\n",
    "    223,\n",
    "    224,\n",
    "    225,\n",
    "    226,\n",
    "    227,\n",
    "    228,\n",
    "    230,\n",
    "    231,\n",
    "    232,\n",
    "    233,\n",
    "    234,\n",
    "    235,\n",
    "    236,\n",
    "    237,\n",
    "    238,\n",
    "    239,\n",
    "    240,\n",
    "    241,\n",
    "    264,\n",
    "\n",
    "    286,\n",
    "    297,\n",
    "    295,\n",
    "    298,\n",
    "    290,\n",
    "    287,\n",
    "    285,\n",
    "    282,\n",
    "    281,\n",
    "    280,\n",
    "    279,\n",
    "    278,\n",
    "    277,\n",
    "    276,\n",
    "    275,\n",
    "    273,\n",
    "    271,\n",
    "    272,\n",
    "    289,\n",
    "    291,\n",
    "    292,\n",
    "    265,\n",
    "    288,\n",
    "    293,\n",
    "    299,\n",
    "    303,\n",
    "    304,\n",
    "    302,\n",
    "    267,\n",
    "    270,\n",
    "    266,\n",
    "    284,\n",
    "    162,\n",
    "    161,\n",
    "    229\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task(task_id):\n",
    "    ep = f\"{host}tasks/{task_id}\"\n",
    "    req = requests.get(ep, headers=headers)\n",
    "    if req.status_code != 200:\n",
    "        return {}\n",
    "    data = json.loads(req.text)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotation(annot_it):\n",
    "    ep = f\"{host}annotations/{annot_it}\"\n",
    "    req = requests.get(ep, headers=headers)\n",
    "    assert req.status_code == 200\n",
    "    data = json.loads(req.text)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_annotation(264)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_labels(data):\n",
    "    combined = {}\n",
    "\n",
    "    if \"result\" in data:\n",
    "        for res in data[\"result\"]:\n",
    "            if not res[\"id\"] in combined:\n",
    "                combined[res[\"id\"]] = res\n",
    "            else:\n",
    "                if \"text\" in res[\"value\"]:\n",
    "                    combined[res[\"id\"]][\"value\"][\"text\"] = res[\"value\"][\"text\"]\n",
    "                elif \"labels\" in res[\"value\"]:\n",
    "                    combined[res[\"id\"]][\"value\"][\"labels\"] = res[\"value\"][\"labels\"]\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_times_write_tsv(data):\n",
    "    task = data[\"task\"]\n",
    "    task_data = get_task(task)\n",
    "    if \"data\" in task_data and \"audio\" in task_data[\"data\"]:\n",
    "        orig_file = task_data[\"data\"][\"audio\"]\n",
    "        parts = orig_file.split(\"/\")\n",
    "        orig_file = parts[-1]\n",
    "    if orig_file:\n",
    "        out_part = orig_file.replace(\".wav\", \".csv\")\n",
    "        orig_file = out_part.replace(\"_main\", \"\").replace(\"_inter\", \"\")\n",
    "    else:\n",
    "        return []\n",
    "    tsv_file = timecode_path / orig_file\n",
    "    out_file = output_path / out_part\n",
    "\n",
    "    if not tsv_file.exists():\n",
    "        return []\n",
    "    start, end = get_timecode_offsets(str(tsv_file))\n",
    "\n",
    "    results = []\n",
    "\n",
    "    combined = combine_labels(data)\n",
    "\n",
    "    for item in combined:\n",
    "        val = combined[item][\"value\"]\n",
    "        if not \"labels\" in val:\n",
    "            continue\n",
    "        if not \"Speech\" in val[\"labels\"]:\n",
    "            continue\n",
    "        e_start = val[\"start\"]\n",
    "        e_end = val[\"end\"]\n",
    "        text = val[\"text\"]\n",
    "        if len(text) > 1:\n",
    "            for t in text:\n",
    "                t = t.strip()\n",
    "                if not (t.startswith(\"/\") and t.endswith(\"/\")):\n",
    "                    text = t\n",
    "        else:\n",
    "            if text[0].startswith(\"/\"):\n",
    "                text = None\n",
    "            else:\n",
    "                text = text[0]\n",
    "\n",
    "        new_start = e_start - start\n",
    "        new_end = e_end - start\n",
    "\n",
    "        if text is None:\n",
    "            continue\n",
    "\n",
    "        if new_end < 0.0:\n",
    "            continue\n",
    "        elif e_start >= end and e_end > end:\n",
    "            continue\n",
    "        elif new_start < 0.0 and new_end > 0.0:\n",
    "            if text != \"\":\n",
    "                    print(\"Warning\", out_part, \"truncating entry\", e_start, e_end, text)\n",
    "            if results == []:\n",
    "                results.append((0.0, new_end, text))\n",
    "            else:\n",
    "                print(\"Shouldn't have existing entries!!\", out_part, e_start, e_end, text)\n",
    "                results.append((0.0, new_end, text))\n",
    "        elif e_start >= start and e_end <= end:\n",
    "            results.append((new_start, new_end, text))\n",
    "        elif e_start <= end and e_end > end:\n",
    "            if text != \"\":\n",
    "                print(\"Warning\", out_part, \"truncating entry\", e_start, e_end, text)\n",
    "            results.append((new_start, new_end, text))\n",
    "        else:\n",
    "            print(\"There should be no default case\", out_part, e_start, e_end, text)\n",
    "\n",
    "    sorted_results = sorted(results, key=lambda x: x[0])\n",
    "\n",
    "    with open(out_file, \"w\") as outf:\n",
    "        for res in sorted_results:\n",
    "            outf.write(\"\\t\".join([str(x) for x in list(res)]) + \"\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning hsi_3_0715_227_003_main.csv truncating entry 363.444 365.1383259316222 yeah the dry cloth\n",
      "Warning hsi_6_0718_209_001_inter.csv truncating entry 49.35587531833186 52.93573862019993 So yeah. Hi. It's like it looks like a very nice place you have here.\n",
      "Warning hsi_7_0719_209_001_inter.csv truncating entry 417.936592106509 421.153006513388 Okay, but yeah, yeah good luck with your new apartment.\n",
      "Warning hsi_7_0719_210_003_inter.csv truncating entry 13.8680710731178 14.332960011165142 So.\n",
      "Warning hsi_7_0719_222_002_inter.csv truncating entry 492.1993302338182 492.533 Okay.\n",
      "Warning hsi_7_0719_222_004_inter.csv truncating entry 526.657228680628 526.9760096667176 Mm.\n",
      "Warning hsi_7_0719_227_002_inter.csv truncating entry 23.002000688552826 25.671791447053263 Ok, yeah that's a very nice apartment you have here.\n",
      "Warning hsi_5_0718_209_001_main.csv truncating entry 25.533197231810348 26.154156027630727 Yes.\n",
      "Warning hsi_7_0719_210_001_main.csv truncating entry 338.07886783610707 352.4282676966609 sometimes when I am reading and I feel that I don't have that much light [smack] I just turn that on. But uh otherwise I just keep this setup here with the small lamp and the chair and I just read something have a glass of wine or something that's really nice.\n",
      "Warning hsi_7_0719_210_002_main.csv truncating entry 26.676579746124887 31.425088184751285 Yeah, I mean, I think uh you can give you some, you can give it some personal touches.\n",
      "Warning hsi_7_0719_211_002_main.csv truncating entry 12.215306981869544 15.153977500086084 Yeah, the location is amazing.\n",
      "Warning hsi_7_0719_211_002_main.csv truncating entry 519.8271652038413 520.7117341094214 Thank you for coming\n",
      "Warning hsi_7_0719_211_004_main.csv truncating entry 8.849075943436373 18.624397757882598 Yeah, I mean, you have uh had a short stay here, but uh w- why would you like to leave? I mean, I I don't understand it. Everything is... so nice in this apartment.\n",
      "Warning hsi_7_0719_222_002_main.csv truncating entry 16.703557628345838 19.584572932005063 Oh, yes, you know, it was really expensive property.\n",
      "Warning hsi_7_0719_222_004_main.csv truncating entry 518.185 531.3564080069578 But maybe maybe if you if you put a small table, like two small tables next, I mean, i- on both sides of the fireplace, then maybe you can put them and then they will have this beige... Eh, it went off.\n",
      "Warning hsi_7_0719_227_002_main.csv truncating entry 785.9436 786.5205 Yes.\n",
      "Warning hsi_6_0718_209_001_main.csv truncating entry 603.2377463859283 605.7388453802391 Yeah, I like to think so.\n",
      "Warning hsi_6_0718_209_002_main.csv truncating entry 433.7454776047815 434.08637974797426 Yeah.\n",
      "Warning hsi_6_0718_210_001_main.csv truncating entry 570.7384570526286 570.9335373916265 Yeah.\n",
      "Warning hsi_5_0718_222_003_main.csv truncating entry 437.2425142751991 462.570667 so so and i was thinking of the bins there, uh, do you need one of the bins because you could take one if you want to yes of course take it it's you can have it because i was anyway trying to so so yeah okay now i would love to take this off oh\n",
      "Warning hsi_4_0717_211_001_main.csv truncating entry 11.119310574891584 12.232926943178029 Don't you love it?\n",
      "Warning hsi_3_0715_210_010_main.csv truncating entry 8.226 10.188 Yes, you're so welcome.\n",
      "Warning hsi_3_0715_209_006_main.csv truncating entry 500.29994899419194 502.2566398812048 I hope you'll come back.\n"
     ]
    }
   ],
   "source": [
    "for transcription in IDS:\n",
    "    data = get_annotation(transcription)\n",
    "    if not \"task\" in data:\n",
    "        print(\"Error with task\", transcription)\n",
    "        continue\n",
    "    else:\n",
    "        adjust_times_write_tsv(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
