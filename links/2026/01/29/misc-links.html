<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Interesting links, 19/01/2026 | notes</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Interesting links, 19/01/2026" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Misc. interesting things." />
<meta property="og:description" content="Misc. interesting things." />
<link rel="canonical" href="https://jimregan.github.io/notes/links/2026/01/29/misc-links.html" />
<meta property="og:url" content="https://jimregan.github.io/notes/links/2026/01/29/misc-links.html" />
<meta property="og:site_name" content="notes" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2026-01-29T00:00:00-06:00" />
<script type="application/ld+json">
{"url":"https://jimregan.github.io/notes/links/2026/01/29/misc-links.html","@type":"BlogPosting","headline":"Interesting links, 19/01/2026","dateModified":"2026-01-29T00:00:00-06:00","datePublished":"2026-01-29T00:00:00-06:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://jimregan.github.io/notes/links/2026/01/29/misc-links.html"},"description":"Misc. interesting things.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/notes/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://jimregan.github.io/notes/feed.xml" title="notes" /><link rel="shortcut icon" type="image/x-icon" href="/notes/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper">
    <a class="site-title" rel="author" href="/notes/">notes</a>
      <nav class="site-nav">
        <input type="checkbox" id="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon"></span>
        </label>

        <div class="nav-items">
  <a class="nav-item" href="/notes/about/">About Me</a>
  <a class="nav-item" href="/notes/search/">Search</a>
  <a class="nav-item" href="/notes/categories/">Tags</a>
</div>

      </nav>
  </div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Interesting links, 19/01/2026</h1><p class="page-description">Misc. interesting things.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2026-01-29T00:00:00-06:00" itemprop="datePublished">
        Jan 29, 2026
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      2 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/notes/categories/#links">links</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
</ul><p><a href="https://ieeexplore.ieee.org/document/9855847">Integrating Lattice-Free MMI Into End-to-End Speech Recognition</a></p>

<div class="jekyll-twitter-plugin">
<blockquote class="twitter-tweet">
<p lang="en" dir="ltr">Google discovers emergent temporal abstractions in autoregressive models<br><br>These models learn linearly controllable action representations in their residual streams—activating them executes long-horizon behaviors. This enables Internal RL to solve sparse-reward hierarchical tasks… <a href="https://t.co/GxOObljGcB">pic.twitter.com/GxOObljGcB</a></p>— DailyPapers (@HuggingPapers) <a href="https://twitter.com/HuggingPapers/status/2004645512079659192?ref_src=twsrc%5Etfw">December 26, 2025</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>

<p><a href="https://arxiv.org/abs/2512.20605">Emergent temporal abstractions in autoregressive models enable hierarchical reinforcement learning</a></p>

<p><a href="https://github.com/icicle-emu/icicle-emu">icicle-emu/icicle-emu</a> — Icicle is an experimental fuzzing-specific, multi-architecture emulation framework.</p>

<p><a href="https://github.com/xieh97/language-based-audio-retrieval">language-based-audio-retrieval</a></p>

<p><a href="https://arxiv.org/abs/2505.05335">FLAM: Frame-Wise Language-Audio Modeling</a></p>

<p><a href="https://arxiv.org/abs/2505.07609">TACOS: Temporally-aligned Audio CaptiOnS for Language-Audio Pretraining</a>,
<a href="https://zenodo.org/records/15379789">data</a></p>

<p><a href="https://aclanthology.org/2024.sigul-1.21/">Italian-Ligurian Machine Translation in Its Cultural Context</a>,
<a href="https://github.com/ConseggioLigure/data/">data</a></p>

<p><a href="https://github.com/xieh97/language-based-audio-retrieval">xieh97/language-based-audio-retrieval</a></p>

<p><a href="https://aclanthology.org/2024.sigul-1.40/">Tandem Long-Short Duration-based Modeling for Automatic Speech Recognition</a></p>

<p><a href="https://aclanthology.org/2022.lrec-1.211/">BEA-Base: A Benchmark for ASR of Spontaneous Hungarian</a>,
<a href="https://arxiv.org/abs/2202.00601">arXiv</a></p>

<p><a href="https://aclanthology.org/2024.sigul-1.32/">Philippine Languages Database: A Multilingual Speech Corpora for Developing Systems for Low-Resource Languages</a></p>

<p><a href="https://aclanthology.org/2024.sigul-1.27/">Bi-dialectal ASR of Armenian from Naturalistic and Read Speech</a></p>

<p><a href="https://arxiv.org/abs/2601.15621">Qwen3-TTS Technical Report</a></p>

<p><a href="https://ai.meta.com/research/publications/byte-latent-transformer-patches-scale-better-than-tokens/">Byte Latent Transformer: Patches Scale Better Than Tokens</a></p>

<p>Hilbert - Foundations of Geometry</p>
<ul>
  <li><a href="https://librivox.org/foundations-of-geometry-by-david-hilbert/">librivox</a></li>
  <li>
<a href="https://www.gutenberg.org/ebooks/17384">gutenberg</a> (LaTeX)</li>
</ul>

<p>Calculus Made Easy</p>
<ul>
  <li><a href="https://www.gutenberg.org/ebooks/33283">gutenberg</a></li>
  <li><a href="https://en.wikisource.org/wiki/Calculus_Made_Easy">wikisource</a></li>
  <li><a href="https://librivox.org/calculus-made-easy-by-silvanus-p-thompson/">librivox</a></li>
</ul>

<p><a href="https://www.youtube.com/@zsenileszek">Zseni Leszek</a></p>

<p><a href="https://www.youtube.com/watch?v=E5suxhHY0aY">I was using italki wrong</a></p>

<p><a href="https://www.youtube.com/watch?v=a0INtLdzUiE">How to REALLY Learn a Language in 2026</a></p>

<p><a href="https://duome.eu/vocabulary/en/hu">Duome HU</a></p>

<p><a href="https://github.com/amir-zeldes/DepEdit">DepEdit</a></p>

<p><a href="https://github.com/clarinsi/conllu-diff">clarinsi/conllu-diff</a></p>

<p><a href="https://github.com/jimregan/ClarinStudioKaldi/commit/98624660cf8ce47c8a15d172352ea63fe5f12703#diff-4cc820c4917b5cfc0e6ac5a00a015c46ba578ab8da512539f8428893681ab858">pocketsphinx, clarinstudio</a>,
<a href="https://github.com/jimregan/ClarinStudioKaldi/releases/tag/cmusphinx-0.1">files</a></p>

<p><a href="https://github.com/strob/gentle">strob/gentle</a>,
<a href="https://rmozone.com/gentle/">page</a></p>

<p><a href="https://huggingface.co/jimregan/kaldi-sprakbanken_swe/tree/main/exp/chain/tdnn">tdnn</a></p>

<p><a href="https://mek.oszk.hu/00500/00595/html/">EPICS OF THE HUNGARIAN PLAIN</a></p>

<div class="jekyll-twitter-plugin">
<blockquote class="twitter-tweet">
<p lang="en" dir="ltr">Deep Learning with PyTorch...<br><br>1) Cheat sheet [PDF]: <a href="https://t.co/TcRqfgqFOK">https://t.co/TcRqfgqFOK</a><br><br>2) Learn fundamentals with hands-on coding [PDF]: <a href="https://t.co/IsXFjwVAhk">https://t.co/IsXFjwVAhk</a><br><br>3) <a href="https://twitter.com/hashtag/GenerativeAI?src=hash&amp;ref_src=twsrc%5Etfw">#GenerativeAI</a> with Python and PyTorch: <a href="https://t.co/hfbERRk99u">https://t.co/hfbERRk99u</a> book v/ <a href="https://twitter.com/PacktDataML?ref_src=twsrc%5Etfw">@PacktDataML</a> <a href="https://t.co/o8XVe0A7O1">pic.twitter.com/o8XVe0A7O1</a></p>— Kirk Borne (@KirkDBorne) <a href="https://twitter.com/KirkDBorne/status/2015587872603091378?ref_src=twsrc%5Etfw">January 26, 2026</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>

<p><a href="https://github.com/deepseek-ai/Engram">deepseek-ai/Engram</a></p>

<p><a href="https://github.com/kerrickstaley/genanki">kerrickstaley/genanki</a></p>

<p><a href="https://archive.org/details/folkscanomy_defense">folkscanomy_defense</a></p>

<p><a href="https://arxiv.org/abs/2512.23808">MiMo-Audio: Audio Language Models are Few-Shot Learners</a>,
<a href="https://github.com/XiaomiMiMo/MiMo-Audio">code</a>,
<a href="https://huggingface.co/XiaomiMiMo/MiMo-Audio-Tokenizer">Tokenizer</a>,
<a href="https://huggingface.co/XiaomiMiMo/MiMo-Audio-7B-Base">7B-Base</a>,
<a href="https://huggingface.co/XiaomiMiMo/MiMo-Audio-7B-Instruct">7B-Instruct</a>,
<a href="https://xiaomimimo.github.io/MiMo-Audio-Demo/">demo</a></p>

<p><a href="https://spraakbanken.gu.se/en/resources/kelly">Kelly</a></p>

<p><a href="https://www.sciencedirect.com/special-issue/328510/evaluation-of-speech-and-speech-synthesis">Evaluation of speech and speech synthesis</a></p>
<ul>
  <li>Submission deadline: 30 June 2026</li>
  <li>Submission portal: https://www.editorialmanager.com/ycsla/default.aspx</li>
  <li><a href="https://www.sciencedirect.com/journal/computer-speech-and-language/publish/guide-for-authors">Guide for Authors</a></li>
</ul>

<p><a href="https://github.com/prefix-dev/pixi">prefix-dev/pixi</a></p>

<p><a href="https://github.com/sprakbankental/sardin">sardin</a></p>

<p><a href="https://www.sciencedirect.com/science/article/pii/S0885230825001342">Keyword Mamba: Spoken keyword spotting with state space models</a></p>

<p><a href="https://www.sciencedirect.com/science/article/pii/S0885230825001470">Is self-supervised learning enough to fill in the gap? A study on speech inpainting</a></p>

<p><a href="https://www.sciencedirect.com/science/article/pii/S0885230825001482">Enhanced audio-visual speech enhancement with posterior sampling methods in recurrent variational autoencoders</a></p>

<p><a href="https://www.sciencedirect.com/science/article/pii/S0885230826000069">Mispronunciation detection and diagnosis based on large language models</a></p>

<p><a href="https://arxiv.org/abs/2601.21402">SemanticAudio: Audio Generation and Editing in Semantic Space</a></p>

<p><a href="https://arxiv.org/abs/2601.20896">A Study of Data Selection Strategies for Pre-training Self-Supervised Speech Models</a></p>

<p><a href="https://arxiv.org/abs/2601.21084">Position-invariant Fine-tuning of Speech Enhancement Models with Self-supervised Speech Representations</a></p>

<div class="jekyll-twitter-plugin">
<blockquote class="twitter-tweet">
<p lang="en" dir="ltr">You can now run 70B LLMs on a 4GB GPU.<br><br>AirLLM just killed the "you need expensive hardware" excuse.<br><br>It runs 70B models on 4GB VRAM.<br>It loads models one layer at a time, runs 405B Llama 3.1 on 8GB VRAM.<br><br>→ No quantization needed by default<br>→ Run Llama, Qwen, Mistral, Mixtral… <a href="https://t.co/L697FHoeCi">pic.twitter.com/L697FHoeCi</a></p>— Hasan Toor (@hasantoxr) <a href="https://twitter.com/hasantoxr/status/2017561974398456114?ref_src=twsrc%5Etfw">January 31, 2026</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>

<p><a href="https://arxiv.org/abs/2510.21890">The Principles of Diffusion Models</a></p>

<p><a href="https://ai.meta.com/research/publications/omnilingual-asr-open-source-multilingual-speech-recognition-for-1600-languages/">Omnilingual ASR</a>,
<a href="https://github.com/facebookresearch/omnilingual-asr">code</a>,
<a href="https://huggingface.co/datasets/facebook/omnilingual-asr-corpus">dataset</a>,
<a href="https://arxiv.org/abs/2511.09690">arXiv</a></p>

<p><a href="https://huggingface.co/datasets/espnet/yodas2">yodas2</a></p>

<p><a href="https://huggingface.co/nvidia/parakeet-tdt-0.6b-v2/discussions/47">Poor WER when trying to fine-tune Parakeet v2 TDT to other dataset than English</a>,
<a href="https://github.com/NVIDIA-NeMo/NeMo/issues/13825">bug</a></p>

<p><a href="https://github.com/deepanshu-yadav/Hindi_GramVani_Finetune/blob/main/finetuning-parakeet-on-hindi-dataset.ipynb">finetuning-parakeet-on-hindi-dataset</a></p>

<p><a href="https://ieeexplore.ieee.org/document/4960577">WEB-derived pronunciations</a></p>

<p><a href="https://arxiv.org/abs/2503.00803">HiMo: High-Speed Objects Motion Compensation in Point Clouds</a>,
<a href="https://github.com/KTH-RPL/HiMo">code</a>,
<a href="https://huggingface.co/datasets/KTH/HiMo">dataset</a></p>

<p><a href="https://www.sciencedirect.com/science/article/pii/S0885230825001500">Survey of end-to-end multi-speaker automatic speech recognition for monaural audio</a></p>

<p><a href="https://ieeexplore.ieee.org/document/10768989">Predict-and-Update Network: Audio-Visual Speech Recognition Inspired by Human Speech Perception</a></p>

<p><a href="https://ieeexplore.ieee.org/document/10269014">Disentangling Prosody Representations With Unsupervised Speech Reconstruction</a></p>

<p><a href="https://ieeexplore.ieee.org/document/9829916">Decoupling Speaker-Independent Emotions for Voice Conversion via Source-Filter Networks</a></p>

<p><a href="https://openreview.net/forum?id=TCFtGBTxkq">Efficient Audiovisual Speech Processing via MUTUD: Multimodal Training and Unimodal Deployment</a>,
<a href="https://arxiv.org/abs/2501.18157">arXiv</a></p>

<p><a href="https://ieeexplore.ieee.org/document/9855847">Integrating Lattice-Free MMI Into End-to-End Speech Recognition</a></p>

<hr>

<p><a href="https://en.wiktionary.org/wiki/Template:csb-adecl">csb-adecl</a></p>

<p><a href="https://en.wiktionary.org/wiki/Wiktionary:Frequency_lists/Kashubian/Wikipedia_%282021%29">Kashubian Frequency list</a></p>


  </div><a class="u-url" href="/notes/links/2026/01/29/misc-links.html" hidden></a>
</article>

      </div>
    </main><link id="fa-stylesheet" rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@7.0.0/css/all.min.css">

<footer class="site-footer h-card">
  <data class="u-url" value="/notes/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
      </div>
      <div class="footer-col">
        <p>Things I know I&#39;ll forget</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list">
  <li>
    <a href="https://jimregan.github.io/notes/feed.xml" target="_blank" title="Subscribe to syndication feed">
      <svg class="svg-icon grey" viewbox="0 0 16 16">
        <path d="M12.8 16C12.8 8.978 7.022 3.2 0 3.2V0c8.777 0 16 7.223 16 16h-3.2zM2.194
          11.61c1.21 0 2.195.985 2.195 2.196 0 1.21-.99 2.194-2.2 2.194C.98 16 0 15.017 0
          13.806c0-1.21.983-2.195 2.194-2.195zM10.606
          16h-3.11c0-4.113-3.383-7.497-7.496-7.497v-3.11c5.818 0 10.606 4.79 10.606 10.607z"
        />
      </svg>
    </a>
  </li>
</ul>
</div>

  </div>

</footer>

</body>

</html>
