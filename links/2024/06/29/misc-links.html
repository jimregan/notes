<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Interesting links, 29/06/2024 | notes</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Interesting links, 29/06/2024" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Misc. interesting things." />
<meta property="og:description" content="Misc. interesting things." />
<link rel="canonical" href="https://jimregan.github.io/notes/links/2024/06/29/misc-links.html" />
<meta property="og:url" content="https://jimregan.github.io/notes/links/2024/06/29/misc-links.html" />
<meta property="og:site_name" content="notes" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-06-29T00:00:00-05:00" />
<script type="application/ld+json">
{"url":"https://jimregan.github.io/notes/links/2024/06/29/misc-links.html","@type":"BlogPosting","headline":"Interesting links, 29/06/2024","dateModified":"2024-06-29T00:00:00-05:00","datePublished":"2024-06-29T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://jimregan.github.io/notes/links/2024/06/29/misc-links.html"},"description":"Misc. interesting things.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/notes/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://jimregan.github.io/notes/feed.xml" title="notes" /><link rel="shortcut icon" type="image/x-icon" href="/notes/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper">
    <a class="site-title" rel="author" href="/notes/">notes</a>
      <nav class="site-nav">
        <input type="checkbox" id="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon"></span>
        </label>

        <div class="nav-items">
  <a class="nav-item" href="/notes/about/">About Me</a>
  <a class="nav-item" href="/notes/search/">Search</a>
  <a class="nav-item" href="/notes/categories/">Tags</a>
</div>

      </nav>
  </div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Interesting links, 29/06/2024</h1><p class="page-description">Misc. interesting things.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2024-06-29T00:00:00-05:00" itemprop="datePublished">
        Jun 29, 2024
      </time>
       ‚Ä¢ <span class="read-time" title="Estimated read time">
    
    
      12 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/notes/categories/#links">links</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
</ul><p><a href="https://www.speechly.com/blog/analyzing-open-ais-whisper-asr-models-word-error-rates-across-languages">Analyzing Open AI‚Äôs Whisper ASR Accuracy: Word Error Rates Across Languages and Model Sizes</a></p>

<p><a href="https://huggingface.co/datasets/Lauler/rixvox-alignments">Lauler/rixvox-alignments</a></p>

<p><a href="https://github.com/swerik-project/riksdagen-records">swerik-project/riksdagen-records</a></p>

<div class="jekyll-twitter-plugin">
<blockquote class="twitter-tweet">
<p lang="en" dir="ltr">here is my meticulously curated (and highly biased) summer paper reading list üìö:<br><br>Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks (2020)<br>‚ï∞‚ï¥ <a href="https://t.co/UmRVv3YVua">https://t.co/UmRVv3YVua</a><br><br>LoRA: Low-Rank Adaptation of Large Language Models (2021)<br>‚ï∞‚ï¥ <a href="https://t.co/A7VHVnjMPt">https://t.co/A7VHVnjMPt</a><br><br>Ring‚Ä¶ <a href="https://t.co/WWgcbVK601">https://t.co/WWgcbVK601</a></p>‚Äî jack morris (@jxmnop) <a href="https://twitter.com/jxmnop/status/1800292343343693934?ref_src=twsrc%5Etfw">June 10, 2024</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>

<p><a href="https://github.com/k2-fsa/sherpa-onnx/blob/master/python-api-examples/audio-tagging-from-a-file.py">sherpa-onnx - audio-tagging-from-a-file</a></p>

<p><a href="https://arxiv.org/abs/2403.01369">A Closer Look at Wav2Vec2 Embeddings for On-Device Single-Channel Speech Enhancement</a></p>

<p><a href="https://arxiv.org/abs/1806.09010">Evaluating Gammatone Frequency Cepstral Coefficients with Neural Networks for Emotion Recognition from Speech</a></p>

<p><a href="https://arxiv.org/abs/2210.06423">Foundation Transformers</a></p>

<div class="jekyll-twitter-plugin">
<blockquote class="twitter-tweet">
<p lang="en" dir="ltr">This book is a MUST read if you‚Äôre working in the field of maths.<br>Link belowüëá <a href="https://t.co/H8S4HMvvzB">pic.twitter.com/H8S4HMvvzB</a></p>‚Äî ‚Çï‚Çê‚Çò‚Çö‚Çú‚Çí‚Çô (@hamptonism) <a href="https://twitter.com/hamptonism/status/1803344932859502614?ref_src=twsrc%5Etfw">June 19, 2024</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>

<div class="jekyll-twitter-plugin">
<blockquote class="twitter-tweet">
<p lang="en" dir="ltr">llm.c by Hand‚úçÔ∏è<br><br>C programming +  matrix multiplication by hand<br><br>This combination is perhaps as low as we can get to explain how the Transformer works. <br><br>Special thanks to <a href="https://twitter.com/karpathy?ref_src=twsrc%5Etfw">@karpathy</a> for encouraging early feedback and <a href="https://twitter.com/7etsuo?ref_src=twsrc%5Etfw">@7etsuo</a> for helping me understand the pragma magic.<br><br>I hope‚Ä¶ <a href="https://t.co/jx1Ye0r0ei">pic.twitter.com/jx1Ye0r0ei</a></p>‚Äî Tom Yeh (@ProfTomYeh) <a href="https://twitter.com/ProfTomYeh/status/1798042265883156651?ref_src=twsrc%5Etfw">June 4, 2024</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>

<div class="jekyll-twitter-plugin">
<blockquote class="twitter-tweet">
<p lang="en" dir="ltr">These 94 lines of code are everything that is needed to train a neural network. Everything else is just efficiency.<br><br>This is my earlier project Micrograd. It implements a scalar-valued auto-grad engine. You start with some numbers at the leafs (usually the input data and the‚Ä¶ <a href="https://t.co/2zVJP3cNJ0">pic.twitter.com/2zVJP3cNJ0</a></p>‚Äî Andrej Karpathy (@karpathy) <a href="https://twitter.com/karpathy/status/1803963383018066272?ref_src=twsrc%5Etfw">June 21, 2024</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>

<p><a href="https://www.math.cmu.edu/~jmackey/151_128/bws_book.pdf">Everything You Always Wanted To Know About Mathematics But didn‚Äôt even know to ask</a></p>

<div class="jekyll-twitter-plugin">
<blockquote class="twitter-tweet">
<p lang="en" dir="ltr">In the last weeks, multiple works on diffusion-based language models were released. You might be wondering if you should consider them for your NLP tasks. In our latest preprint, we argue that text-based diffusion models have several properties that deserve your attention. üßµ1/8 <a href="https://t.co/RnrfVyV0Dh">pic.twitter.com/RnrfVyV0Dh</a></p>‚Äî Justin Deschenaux (@jdeschena) <a href="https://twitter.com/jdeschena/status/1803096836460155144?ref_src=twsrc%5Etfw">June 18, 2024</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>

<div class="jekyll-twitter-plugin">
<blockquote class="twitter-tweet">
<p lang="en" dir="ltr">Flow Matching is SOOOO simple<br><br>GG denoising diffusion? <a href="https://t.co/fdArTRk9Z1">pic.twitter.com/fdArTRk9Z1</a></p>‚Äî Cristian Garcia (@cgarciae88) <a href="https://twitter.com/cgarciae88/status/1803004045084197186?ref_src=twsrc%5Etfw">June 18, 2024</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>

<p><a href="https://bm371613.github.io/conditional-flow-matching/">Conditional flow matching</a></p>

<p><a href="https://arxiv.org/abs/2310.15672">How Much Context Does My Attention-Based ASR System Need?</a>,
<a href="github.com/robflynnyh/long-context-asr">code</a></p>

<p><a href="https://github.com/SkalskiP/top-cvpr-2024-papers">SkalskiP/top-cvpr-2024-papers</a></p>

<p><a href="https://dl.acm.org/doi/10.1145/3656374">Evaluating Gesture Generation in a Large-scale Open Challenge: The GENEA Challenge 2022</a></p>

<p><a href="https://arxiv.org/abs/2403.17846">Hierarchical Open-Vocabulary 3D Scene Graphs for Language-Grounded Robot Navigation</a>,
<a href="https://github.com/hovsg/HOV-SG">code</a></p>

<p><a href="https://towardsdatascience.com/understanding-faiss-619bb6db2d1a">Understanding FAISS</a></p>

<p><a href="https://arxiv.org/abs/2406.07887">An Empirical Study of Mamba-based Language Models</a>,
<a href="https://huggingface.co/nvidia/mamba2-hybrid-8b-3t-4k">model</a>,
<a href="https://github.com/NVIDIA/Megatron-LM/tree/ssm/examples/mamba">code</a></p>

<div class="jekyll-twitter-plugin">
<blockquote class="twitter-tweet">
<p lang="en" dir="ltr">This talk by <a href="https://twitter.com/bclavie?ref_src=twsrc%5Etfw">@bclavie</a> is the highest value per second talk I have ever watched on RAG <br><br>Chapter summaries and additional links in next tweet <a href="https://t.co/5uzmSbU6pa">pic.twitter.com/5uzmSbU6pa</a></p>‚Äî Hamel Husain (@HamelHusain) <a href="https://twitter.com/HamelHusain/status/1802106197782438019?ref_src=twsrc%5Etfw">June 15, 2024</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>

<p><a href="https://huggingface.co/datasets/pkufool/librilight-text">pkufool/librilight-text</a></p>

<p><a href="https://github.com/mlfoundations/open_clip/blob/73ad04ae7fb93ede1c02dc9040a828634cb1edf1/src/open_clip/loss.py#L307">Open CLIP - SigLipLoss</a></p>

<div class="jekyll-twitter-plugin">
<blockquote class="twitter-tweet">
<p lang="en" dir="ltr">Very interesting Paper - "Mixture-of-Agents (MoA) Enhances Large Language Model Capabilities": - MoA using only open-source LLMs is the leader of AlpacaEval 2.0 by a substantial gap, achieving a score of 65.1% compared to 57.5% by GPT-4 Omni. üî•<br><br>üìå The paper introduces the‚Ä¶ <a href="https://t.co/P09kddjZMt">pic.twitter.com/P09kddjZMt</a></p>‚Äî Rohan Paul (@rohanpaul_ai) <a href="https://twitter.com/rohanpaul_ai/status/1800298331773567412?ref_src=twsrc%5Etfw">June 10, 2024</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>

<p><a href="https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/">Faiss: A library for efficient similarity search</a></p>

<p><a href="https://github.com/facebookresearch/faiss/wiki/Brute-force-search-without-an-index">Faiss - Brute force search without an index</a></p>

<p><a href="https://upcommons.upc.edu/bitstream/handle/2117/386744/Master_Thesis_Macia_Amoros_Cortiella.pdf?sequence=5&amp;isAllowed=y">Robust solutions for audio fingerprinting</a></p>

<p><a href="https://ieeexplore.ieee.org/document/9414337">Neural Audio Fingerprint for High-Specific Audio Retrieval Based on Contrastive Learning</a>,
<a href="https://github.com/mimbres/neural-audio-fp">code</a></p>

<p><a href="https://arxiv.org/abs/2406.13139">Audio Fingerprinting with Holographic Reduced Representations</a></p>

<p><a href="https://github.com/MahmudulAlam/Holographic-Reduced-Representations">MahmudulAlam/Holographic-Reduced-Representations</a></p>

<p><a href="https://arxiv.org/abs/2109.02157">Learning with Holographic Reduced Representations</a>,
<a href="https://github.com/FutureComputing4AI/Learning-with-Holographic-Reduced-Representations">code</a></p>

<div class="jekyll-twitter-plugin">
<blockquote class="twitter-tweet">
<p lang="en" dir="ltr">so this is nuts, if you're cool with the high frequncy details of an image being reinterpreted/stochastic, you can encode an image quite faithfully into 32 tokens...<br>with a codebook size of 1024 as they use this is just 320bits, new upper bound for the information in an image‚Ä¶ <a href="https://t.co/DSZcmlWQf0">pic.twitter.com/DSZcmlWQf0</a></p>‚Äî Ethan (@torchcompiled) <a href="https://twitter.com/torchcompiled/status/1801493585155526675?ref_src=twsrc%5Etfw">June 14, 2024</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>

<p><a href="https://github.com/spotify/basic-pitch">spotify/basic-pitch</a> ‚Äî A lightweight yet powerful audio-to-MIDI converter with pitch bend detection</p>

<p><a href="https://arxiv.org/abs/2406.08929">Step-by-Step Diffusion: An Elementary Tutorial</a></p>

<p><a href="https://arxiv.org/abs/2303.13285">Fourier Diffusion Models: A Method to Control MTF and NPS in Score-Based Stochastic Image Generation</a></p>

<p><a href="https://arxiv.org/abs/2402.05933">Time Series Diffusion in the Frequency Domain</a>,
<a href="https://github.com/JonathanCrabbe/FourierDiffusion">code</a></p>

<p><a href="https://ieeexplore.ieee.org/document/9784553">Data Augmentation in Time and Doppler Frequency Domain for Radar-based Gesture Recognition</a></p>

<p><a href="https://blog.demofox.org/2015/04/19/frequency-domain-audio-synthesis-with-ifft-and-oscillators/">Frequency Domain Audio Synthesis ‚Äì With IFFT and Oscillators</a></p>

<p><a href="https://www.nature.com/articles/s41598-024-64571-x">Trajectories and revolutions in popular melody based on U.S. charts from 1950 to 2023</a></p>

<p><a href="https://arxiv.org/abs/2005.08072">Speech Recognition and Multi-Speaker Diarization of Long Conversations</a>,
<a href="https://www.kaggle.com/datasets/shuyangli94/this-american-life-podcast-transcriptsalignments">data</a></p>

<p><a href="https://huggingface.co/blog/vlms">Vision Language Models Explained</a></p>

<table>
  <tbody>
    <tr>
      <td>Model</td>
      <td>
<strong>Actually</strong> open</td>
    </tr>
    <tr>
      <td>!‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî</td>
      <td>‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî-</td>
    </tr>
    <tr>
      <td>LLaVA 1.6 (Hermes 34B)</td>
      <td>¬†</td>
    </tr>
    <tr>
      <td>deepseek-vl-7b-base</td>
      <td>‚ùå</td>
    </tr>
    <tr>
      <td>DeepSeek-VL-Chat</td>
      <td>‚ùå</td>
    </tr>
    <tr>
      <td>moondream2</td>
      <td>¬†</td>
    </tr>
    <tr>
      <td>CogVLM-base</td>
      <td>(‚ùå)[https://github.com/THUDM/CogVLM/raw/main/MODEL_LICENSE]</td>
    </tr>
    <tr>
      <td>CogVLM-Chat</td>
      <td>(‚ùå)[https://github.com/THUDM/CogVLM/raw/main/MODEL_LICENSE]</td>
    </tr>
    <tr>
      <td>Fuyu-8B</td>
      <td>‚ùå</td>
    </tr>
    <tr>
      <td>KOSMOS-2</td>
      <td>‚úÖ</td>
    </tr>
    <tr>
      <td>Qwen-VL</td>
      <td>‚ùå</td>
    </tr>
    <tr>
      <td>Qwen-VL-Chat</td>
      <td>‚ùå</td>
    </tr>
    <tr>
      <td>Yi-VL-34B</td>
      <td>‚úÖ</td>
    </tr>
  </tbody>
</table>

<p><a href="https://github.com/nmslib/nmslib">nmslib/nmslib</a> ‚Äî Non-Metric Space Library (NMSLIB): An efficient similarity search library and a toolkit for evaluation of k-NN methods for generic non-metric spaces.</p>

<p><a href="https://arxiv.org/abs/2210.17323">GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers</a>,
<a href="https://github.com/IST-DASLab/gptq/">code</a></p>

<p><a href="https://openreview.net/pdf?id=ceATjGPTUD">Large Language Models are Efficient Learners of Noise-Robust Speech Recognition</a>,
<a href="https://github.com/YUCHEN005/RobustGER">code</a></p>

<p><a href="https://openreview.net/pdf?id=QqjFHyQwtF">It‚Äôs Never Too Late: Fusing Acoustic Information into Large Language Models for Automatic Speech Recognition</a>,
<a href="https://github.com/Hypotheses-Paradise/UADF">code</a></p>

<p><a href="https://arxiv.org/abs/2402.01591">BAT: Learning to Reason about Spatial Sounds with Large Language Models</a></p>

<p><a href="https://arxiv.org/abs/2402.05755">SpiRit-LM: Interleaved Spoken and Written Language Model</a></p>

<p><a href="https://arxiv.org/abs/2404.00656">WavLLM: Towards Robust and Adaptive Speech Large Language Model</a>,
<a href="https://github.com/microsoft/SpeechT5/tree/main/WavLLM">code</a></p>

<p><a href="https://arxiv.org/abs/2402.08846">An Embarrassingly Simple Approach for LLM with Strong ASR Capacity</a>,
<a href="https://github.com/X-LANCE/SLAM-LLM">code</a></p>

<p><a href="https://github.com/ga642381/speech-trident">Speech Trident - Awesome Speech LM</a></p>

<p><a href="https://arxiv.org/abs/2406.02328">SimpleSpeech: Towards Simple and Efficient Text-to-Speech with Scalar Latent Transformer Diffusion Models</a></p>

<div class="jekyll-twitter-plugin">
<blockquote class="twitter-tweet">
<p lang="en" dir="ltr">Creating a Pipeline for Generating Synthetic Data for Fine-Tuning Custom Embedding Models. üëÄ<br><br>Step 1 Create a Knowledge Base: Start with preparing your domain specific knowledge base, such as PDFs or other documents containing information. Convert the content of these documents‚Ä¶ <a href="https://t.co/0mYDJKMylY">pic.twitter.com/0mYDJKMylY</a></p>‚Äî Philipp Schmid (@_philschmid) <a href="https://twitter.com/_philschmid/status/1798388387822317933?ref_src=twsrc%5Etfw">June 5, 2024</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>

<p><a href="https://arxiv.org/abs/2407.01911">Investigating the Effects of Large-Scale Pseudo-Stereo Data and Different Speech Foundation Model on Dialogue Generative Spoken Language Model</a></p>

<div class="jekyll-twitter-plugin"><p>There was a 'Not Found' error fetching URL: 'https://x.com/tradingMaxiSL/status/1809857803177324992'</p></div>

<p><a href="https://arxiv.org/abs/2407.01178">Memory3 : Language Modeling with Explicit Memory</a></p>

<div class="jekyll-twitter-plugin">
<blockquote class="twitter-tweet">
<p lang="en" dir="ltr">These ties should be noted somewhere for everyone's benefit ‚úåÔ∏è <a href="https://t.co/jh5G9QoKoG">pic.twitter.com/jh5G9QoKoG</a></p>‚Äî Learn Something (@cooltechtipz) <a href="https://twitter.com/cooltechtipz/status/1809758725575737440?ref_src=twsrc%5Etfw">July 7, 2024</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>

<p><a href="https://arxiv.org/abs/1802.05968">Information Theory: A Tutorial Introduction</a></p>

<p><a href="https://arxiv.org/abs/2406.17711">Data curation via joint example selection further accelerates multimodal learning</a></p>

<p><a href="https://arxiv.org/abs/2406.09414">Depth Anything V2</a>,
<a href="https://github.com/DepthAnything/Depth-Anything-V2">code</a>,
<a href="https://huggingface.co/spaces/depth-anything/Depth-Anything-V2">demo</a>,
<a href="https://huggingface.co/apple/coreml-depth-anything-v2-small">coreml</a>,
<a href="https://huggingface.co/depth-anything/Depth-Anything-V2-Small">model</a></p>

<p><a href="https://www.sscardapane.it/alice-book">Alice‚Äôs Adventures in a differentiable wonderland</a></p>

<p><a href="https://github.com/supabase/supabase">supabase/supabase</a> ‚Äî The open source Firebase alternative. Supabase gives you a dedicated Postgres database to build your web, mobile, and AI applications.</p>

<div class="jekyll-twitter-plugin">
<blockquote class="twitter-tweet">
<p lang="en" dir="ltr">Richard Feynman's Lectures on Physics are timeless: their main strength is in demonstrating how to reason about physics. You may not know all the lectures are completely online:<br><br>Volume 1: <a href="https://t.co/yDpyRVjdVz">https://t.co/yDpyRVjdVz</a><br>Volume 2: <a href="https://t.co/oEctaDi5Sv">https://t.co/oEctaDi5Sv</a><br>Volume 3: <a href="https://t.co/eXS03nuH5c">https://t.co/eXS03nuH5c</a> <a href="https://t.co/SsNOerIzoq">pic.twitter.com/SsNOerIzoq</a></p>‚Äî Massimo (@Rainmaker1973) <a href="https://twitter.com/Rainmaker1973/status/1810531826752168071?ref_src=twsrc%5Etfw">July 9, 2024</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>

<p><a href="https://github.com/HazyResearch/flash-fft-conv">HazyResearch/flash-fft-conv</a> ‚Äî FlashFFTConv: Efficient Convolutions for Long Sequences with Tensor Cores</p>

<p><a href="https://arxiv.org/abs/2406.19674">Less is More: Accurate Speech Recognition &amp; Translation without Web-Scale Data</a>,
code in NeMo, model closed but available.</p>

<p><a href="https://www.youtube.com/watch?v=lkQ4sDK4u9U">23606 Workshop on Human Motion Generation</a>,
key moment <a href="https://www.youtube.com/watch?v=lkQ4sDK4u9U&amp;t=12278s">here</a></p>

<p><a href="https://github.com/microsoft/graphrag">microsoft/graphrag</a></p>

<p><a href="https://github.com/leaningtech/webvm">leaningtech/webvm</a> ‚Äî Virtual Machine for the Web</p>

<div class="jekyll-twitter-plugin">
<blockquote class="twitter-tweet">
<p lang="en" dir="ltr">Cannot believe this finally happened! Over the last 1.5 years, we have been developing a new LLM architecture, with linear complexity and expressive hidden states, for long-context modeling. The following plots show our model trained from Books scale better (from 125M to 1.3B)‚Ä¶ <a href="https://t.co/Ku0oi8vqvX">pic.twitter.com/Ku0oi8vqvX</a></p>‚Äî Xiaolong Wang (@xiaolonw) <a href="https://twitter.com/xiaolonw/status/1810387662060269668?ref_src=twsrc%5Etfw">July 8, 2024</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>

<p><a href="https://arxiv.org/abs/2407.04620">Learning to (Learn at Test Time): RNNs with Expressive Hidden States</a></p>

<div class="jekyll-twitter-plugin">
<blockquote class="twitter-tweet">
<p lang="en" dir="ltr">After going through 100s of AI papers in the past couple of weeks, I am noticing the deeper integration of ideas (e.g., Mixture of Million Experts and Internet of Agents) and the utility of simple yet very effective methods (e.g., RouteLLM and RankRAG). <br><br>If you are looking for‚Ä¶ <a href="https://t.co/hTVafuLbxQ">pic.twitter.com/hTVafuLbxQ</a></p>‚Äî elvis (@omarsar0) <a href="https://twitter.com/omarsar0/status/1812247121560502426?ref_src=twsrc%5Etfw">July 13, 2024</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>

<p><a href="https://arxiv.org/abs/2407.08951">Audio Spotforming Using Nonnegative Tensor Factorization with Attractor-Based Regularization</a></p>

<p><a href="https://www.arxiv.org/abs/2407.09468">Beyond Euclid: An Illustrated Guide to Modern Machine Learning with Geometric, Topological, and Algebraic Structures</a></p>

<p><a href="https://www.researchgate.net/publication/382204056_Understanding_Transformers_via_N-Gram_Statistics">Understanding Transformers via N-Gram Statistics</a></p>

<p><a href="https://github.com/facebookincubator/submitit">facebookincubator/submitit</a> ‚Äî Python 3.8+ toolbox for submitting jobs to Slurm</p>

<p><a href="https://arxiv.org/abs/2407.08737">Video Diffusion Alignment via Reward Gradients</a>,
<a href="https://huggingface.co/zheyangqin/VADER">model</a>
<!-- [code](https://github.com/mihirp1998/VADER) --></p>

<p><a href="https://towardsdatascience.com/deep-dive-into-lstms-xlstms-by-hand-%EF%B8%8F-c33e638bebb1">Deep Dive into LSTMs and xLSTMs by Hand</a></p>

<p><a href="https://arxiv.org/abs/2403.07815">Chronos: Learning the Language of Time Series</a>,
<a href="https://github.com/amazon-science/chronos-forecasting">code</a></p>

<p><a href="https://github.com/lm-sys/FastChat">lm-sys/FastChat</a></p>

<p><a href="https://arxiv.org/abs/2401.17690">EnCLAP: Combining Neural Audio Codec and Audio-Text Joint Embedding for Automated Audio Captioning</a>,
<a href="https://github.com/jaeyeonkim99/EnCLAP">code</a></p>

<p><a href="https://openai.com/index/triton/">Introducing Triton: Open-source GPU programming for neural networks</a></p>

<p><a href="https://medium.com/@khalfaoui.ismail/cuda-kernels-in-pytorch-made-easy-with-numba-using-python-only-74012bab23ba">CUDA kernels in PyTorch made easy with Numba</a>,
<a href="https://colab.research.google.com/drive/1Ix8ENHB31eIsXGwnob9NUJgdHssfIzx7">notebook</a></p>

<p><a href="https://github.com/a-brassard/ACORN">a-brassard/ACORN</a> ‚Äî Home repository for the ACORN dataset: 3,500 explanations with aspect-wise human ratings of their quality.</p>

<p><a href="https://github.com/karpathy/llm.c/discussions/677">Let‚Äôs reproduce GPT-2</a></p>

<p><a href="https://github.com/facebookresearch/data2vec_vision">facebookresearch/data2vec_vision</a></p>

<p><a href="https://huggingface.co/blog/finetune-florence2">Fine-tuning Florence-2 - Microsoft‚Äôs Cutting-edge Vision Language Models</a></p>

<p><a href="https://arxiv.org/abs/2406.19464">ManiWAV: Learning Robot Manipulation from In-the-Wild Audio-Visual Data</a>,
<a href="https://github.com/real-stanford/maniwav">code</a></p>

<p><a href="https://arxiv.org/abs/2407.01449">ColPali: Efficient Document Retrieval with Vision Language Models</a>,
<a href="https://github.com/illuin-tech/colpali">code</a></p>

<p><a href="https://arxiv.org/abs/2406.02657">Block Transformer: Global-to-Local Language Modeling for Fast Inference</a>,
<a href="https://github.com/itsnamgyu/block-transformer">code</a></p>

<p><a href="https://arxiv.org/abs/2406.16990">AND: Audio Network Dissection for Interpreting Deep Acoustic Models</a>
<!-- [code](https://github.com/Trustworthy-ML-Lab/Audio_Network_Dissection) --></p>

<p><a href="https://arxiv.org/abs/2406.17111">Sound Field Synthesis with Acoustic Waves</a></p>

<p><a href="https://arxiv.org/abs/2406.17672">SpecMaskGIT: Masked Generative Modeling of Audio Spectrograms for Efficient Audio Synthesis and Beyond</a></p>

<p><a href="https://arxiv.org/abs/2406.17903">Mapping the Past: Geographically Linking an Early 20th Century Swedish Encyclopedia with Wikidata</a></p>

<p><a href="https://arxiv.org/abs/2406.17801">A multi-speaker multi-lingual voice cloning system based on vits2 for limmits 2024 challenge</a></p>

<p><a href="https://arxiv.org/abs/2406.16860">Cambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs</a>,
<a href="https://github.com/cambrian-mllm/cambrian">code</a>,
<a href="https://huggingface.co/nyu-visionx/cambrian-34b">model</a></p>

<p>AI by Hand:</p>

<div class="jekyll-twitter-plugin">
<blockquote class="twitter-tweet">
<p lang="en" dir="ltr">1. Dot Product - AI by Hand‚úçÔ∏èWorkbook Series<br><br>I share original hand calculation exercises like this, with 36K followers on LinkedIn. <br><br>I just started to share on X.<br><br>If you find this post helpful, <br>[Follow] me for more! üôå <a href="https://t.co/rbqWVZCmlP">pic.twitter.com/rbqWVZCmlP</a></p>‚Äî Tom Yeh (@ProfTomYeh) <a href="https://twitter.com/ProfTomYeh/status/1793623127643037891?ref_src=twsrc%5Etfw">May 23, 2024</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>

<div class="jekyll-twitter-plugin">
<blockquote class="twitter-tweet">
<p lang="en" dir="ltr">3. Linear Layer - AI by Hand‚úçÔ∏èWorkbook Series   <br><br>I share original hand calculation exercises like this, with 36K followers on LinkedIn. <br><br>I just started sharing on X.  <br><br>If you find this workbook helpful, [Follow] me for more! <a href="https://t.co/X24n6PmydJ">pic.twitter.com/X24n6PmydJ</a></p>‚Äî Tom Yeh (@ProfTomYeh) <a href="https://twitter.com/ProfTomYeh/status/1794451228681712037?ref_src=twsrc%5Etfw">May 25, 2024</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>

<div class="jekyll-twitter-plugin">
<blockquote class="twitter-tweet">
<p lang="en" dir="ltr">4. Activation - AI by Hand‚úçÔ∏èWorkbook Series     <br><br>I share original hand calculation exercises like this, with 36K followers on LinkedIn.  I just started sharing on X.    <br><br>If you find this workbook helpful, <br>[Follow] me for more! <a href="https://t.co/iqzGP1uSUj">pic.twitter.com/iqzGP1uSUj</a></p>‚Äî Tom Yeh (@ProfTomYeh) <a href="https://twitter.com/ProfTomYeh/status/1794848226383655284?ref_src=twsrc%5Etfw">May 26, 2024</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>

<div class="jekyll-twitter-plugin">
<blockquote class="twitter-tweet">
<p lang="en" dir="ltr">5. Artificial Neuron - AI by Hand‚úçÔ∏èWorkbook Series      <br><br>Previous Workbooks:<br>4. Activation: <a href="https://t.co/8btQ2n5AAf">https://t.co/8btQ2n5AAf</a><br>3. Linear Layer: <a href="https://t.co/V571mpwnTq">https://t.co/V571mpwnTq</a><br>2. Matrix Multiplication: <a href="https://t.co/EqfK6AEutb">https://t.co/EqfK6AEutb</a><br>1. Dot Product: <a href="https://t.co/ou9GFdTV1f">https://t.co/ou9GFdTV1f</a><br><br>I share original hand‚Ä¶ <a href="https://t.co/dO0Ff5x4kQ">https://t.co/dO0Ff5x4kQ</a> <a href="https://t.co/3vlR4EUoxZ">pic.twitter.com/3vlR4EUoxZ</a></p>‚Äî Tom Yeh (@ProfTomYeh) <a href="https://twitter.com/ProfTomYeh/status/1795221120351715450?ref_src=twsrc%5Etfw">May 27, 2024</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>

<div class="jekyll-twitter-plugin">
<blockquote class="twitter-tweet">
<p lang="en" dir="ltr">Vector Database by Hand ‚úçÔ∏è<br><br>Vector databases are revolutionizing how we search and analyze complex data. They have become the backbone of Retrieval Augmented Generation (<a href="https://twitter.com/hashtag/RAG?src=hash&amp;ref_src=twsrc%5Etfw">#RAG</a>).<br><br>How do vector databases work?<br><br>[1] Given<br>‚Ü≥ A dataset of three sentences, each has 3 words (or tokens)‚Ä¶ <a href="https://t.co/IIJwqnVjaK">pic.twitter.com/IIJwqnVjaK</a></p>‚Äî Tom Yeh (@ProfTomYeh) <a href="https://twitter.com/ProfTomYeh/status/1795076707386360227?ref_src=twsrc%5Etfw">May 27, 2024</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>

<div class="jekyll-twitter-plugin">
<blockquote class="twitter-tweet">
<p lang="en" dir="ltr">GAN by Hand ‚úçÔ∏è<br><br>Goal: Generate realistic 4-D data from 2-D noise.<br><br>[1] Given<br>‚Ü≥ 4 noise vectors in 2D (N)<br>‚Ü≥ 4 real data vectors in 4D (X)<br><br>[2] üü© Generator: First Layer<br>‚Ü≥ Multiply the noise vectors with weights and biases to obtain new feature vectors<br><br>[3] üü© Generator: ReLU<br>‚Ü≥‚Ä¶ <a href="https://t.co/7ECTTqzOJL">pic.twitter.com/7ECTTqzOJL</a></p>‚Äî Tom Yeh (@ProfTomYeh) <a href="https://twitter.com/ProfTomYeh/status/1794144904395837638?ref_src=twsrc%5Etfw">May 24, 2024</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>

<div class="jekyll-twitter-plugin">
<blockquote class="twitter-tweet">
<p lang="en" dir="ltr">[Transformer] by Hand‚úçÔ∏èüì∫<br>5-minute Video Tutorial<br><br>Anna Rahn made this short video to explain the Transformer exercise for my Computer Vision course last spring. <br><br>In 5 minutes, she demonstrates the key calculations of the Transformer by hand with pen and paper!<br><br>Anna is a‚Ä¶ <a href="https://t.co/NAkESZKaQH">pic.twitter.com/NAkESZKaQH</a></p>‚Äî Tom Yeh (@ProfTomYeh) <a href="https://twitter.com/ProfTomYeh/status/1810849417576186076?ref_src=twsrc%5Etfw">July 10, 2024</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>

<p><a href="https://arxiv.org/abs/2405.18503">SoundCTM: Uniting Score-based and Consistency Models for Text-to-Sound Generation</a>,
<a href="https://github.com/sony/soundctm">code</a>,
<a href="https://huggingface.co/Sony/soundctm">model</a></p>

<p><a href="https://github.com/Zielon/PBRVulkan">Zielon/PBRVulkan</a> ‚Äî Vulkan Real-time Path Tracer Engine</p>

<p><a href="https://aclanthology.org/2024.lrec-main.1471/">UCxn: Typologically Informed Annotation of Constructions Atop Universal Dependencies</a></p>

<p><a href="https://genai-handbook.github.io/">Generative AI Handbook: A Roadmap for Learning Resources</a></p>

<p><a href="https://arxiv.org/abs/2405.16677">Crossmodal ASR Error Correction with Discrete Speech Units</a>
<!-- [code](https://github.com/yc-li20/Crossmodal_AEC) --></p>

<p><a href="http://multicomp.cs.cmu.edu/resources/cmu-mosi-dataset/">CMU-MOSI Dataset</a> ‚Äî The Multimodal Corpus of Sentiment Intensity (CMU-MOSI) dataset is a collection of 2199 opinion video clips.</p>

<p><a href="https://www.youtube.com/watch?v=WUvTyaaNkzM&amp;list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr">The essence of calculus</a></p>

<p><a href="https://link.springer.com/chapter/10.1007/3-540-48834-0_11">Imitation and Mechanisms of Joint Attention: A Developmental Structure for Building Social Skills on a Humanoid Robot</a></p>

<p><a href="https://archive.org/details/polishpublicdomain">Polish Public Domain Works</a></p>

<p><a href="https://research.google/blog/user-llm-efficient-llm-contextualization-with-user-embeddings/">USER-LLM: Efficient LLM contextualization with user embeddings</a>,
<a href="https://arxiv.org/abs/2402.13598">arXiv</a></p>

<p><a href="https://arxiv.org/abs/2103.03206">Perceiver: General Perception with Iterative Attention</a></p>

<p><a href="https://arxiv.org/abs/2405.18726">Reverse the auditory processing pathway: Coarse-to-fine audio reconstruction from fMRI</a></p>

<p><a href="https://arxiv.org/abs/2306.00814">Vocos: Closing the gap between time-domain and Fourier-based neural vocoders for high-quality audio synthesis</a>,
<a href="https://github.com/gemelo-ai/vocos">code</a>,
<a href="https://huggingface.co/charactr/vocos-mel-24khz">vocos-mel-24khz</a>,
<a href="https://huggingface.co/charactr/vocos-encodec-24khz">vocos-encodec-24khz</a></p>

<p><a href="https://arxiv.org/abs/2405.18639">Improving Speech Decoding from ECoG with Self-Supervised Pretraining</a></p>

<p><a href="https://arxiv.org/abs/2405.19041">BLSP-KD: Bootstrapping Language-Speech Pre-training via Knowledge Distillation</a></p>

<p><a href="https://arxiv.org/abs/2309.08200">TF-SepNet: An Efficient 1D Kernel Design in CNNs for Low-Complexity Acoustic Scene Classification</a></p>

<p><a href="https://arxiv.org/abs/2402.10009">Zero-Shot Unsupervised and Text-Based Audio Editing Using DDPM Inversion</a>,
<a href="https://github.com/HilaManor/AudioEditingCode/">code</a></p>

<p><a href="https://ieeexplore.ieee.org/document/10446663">Adapting Frechet Audio Distance for Generative Music Evaluation</a>,
<a href="https://arxiv.org/abs/2311.01616">arXiv</a>,
<a href="https://github.com/microsoft/fadtk">code</a></p>

<p><a href="https://arxiv.org/abs/2405.01242">TRAMBA: A Hybrid Transformer and Mamba Architecture for Practical Audio and Bone Conduction Speech Super Resolution and Enhancement on Mobile and Wearable Platforms</a></p>

<p><a href="https://arxiv.org/abs/2404.06690">CoVoMix: Advancing Zero-Shot Speech Generation for Human-like Multi-talker Conversations</a></p>

<p><a href="https://arxiv.org/abs/2405.15923">Spiketrum: An FPGA-based Implementation of a Neuromorphic Cochlea</a></p>

<p><a href="https://arxiv.org/abs/2405.18719">Contextual Position Encoding: Learning to Count What‚Äôs Important</a></p>

<p><a href="The%20Raven;%20with%20literary%20and%20historical%20commentary/Hungarian">The Raven: Hungarian</a></p>

<p><a href="https://en.wikisource.org/wiki/Stories_by_Foreign_Authors_%5C(Polish-Greek-Belgian-Hungarian%5C)/In_Love_with_the_Czarina">IN LOVE WITH THE CZARINA</a></p>

<p><a href="https://en.wikisource.org/wiki/Simplified_Grammar_of_the_Hungarian_Language">Simplified Grammar of the Hungarian Language</a></p>

<p><a href="https://www.gutenberg.org/cache/epub/34574/pg34574-images.html">In Love With the Czarina, and Other Stories</a>,
<a href="https://mek.oszk.hu/16400/16475/16475.htm">A VAKMER≈ê</a></p>

<p><a href="https://arxiv.org/abs/2402.04347">The Hedgehog &amp; the Porcupine: Expressive Linear Attentions with Softmax Mimicry</a></p>

<p><a href="https://github.com/netease-youdao/EmotiVoice">netease-youdao/EmotiVoice</a> ‚Äî a Multi-Voice and Prompt-Controlled TTS Engine</p>

<p><a href="https://github.com/netease-youdao/EmotiVoice/wiki/Voice-Cloning-with-your-personal-data">Voice Cloning with your personal data</a></p>

<p><a href="https://github.com/ricosjp/truck">ricosjp/truck</a> ‚Äî Truck is a rust CAD kernel</p>

<p><a href="https://flashcardo.com/hungarian-flashcards/body/1">Hungarian Body Parts Flashcards</a></p>

<p><a href="https://flashcardo.com/hungarian-flashcards/">Hungarian Flashcards</a></p>

<p><a href="https://arxiv.org/abs/2312.01479">OpenVoice: Versatile Instant Voice Cloning</a>,
<a href="https://github.com/myshell-ai/OpenVoice">code</a></p>

<p><a href="https://arxiv.org/abs/2402.13753">LongRoPE: Extending LLM Context Window Beyond 2 Million Tokens</a></p>

<p><a href="https://towardsdatascience.com/a-complete-guide-to-write-your-own-transformers-29e23f371ddd">A Complete Guide to Write your own Transformers</a></p>

<p><a href="https://arxiv.org/abs/2403.03100">NaturalSpeech 3: Zero-Shot Speech Synthesis with Factorized Codec and Diffusion Models</a>,
<a href="https://huggingface.co/amphion/naturalspeech3_facodec">FACodec model</a>,
<a href="https://github.com/open-mmlab/Amphion">code</a></p>

<p><a href="https://nordic.ign.com/star-wars-episode-iv-a-new-hope-theater/79567/news/decades-old-beer-ads-stitched-straight-into-original-star-wars-movies-go-viral">Decades-Old Beer Ads Stitched Straight Into Original Star Wars Movies Go Viral</a></p>

<p><a href="https://arxiv.org/abs/2403.06387">Towards Decoupling Frontend Enhancement and Backend Recognition in Monaural Robust ASR</a></p>

<p><a href="https://www.tandfonline.com/doi/full/10.1080/13600826.2022.2052025">I Felt a Little Homosexual Today, So I Called in Sick: The Formation of ‚ÄúReverse Discourse‚Äù by Swedish Gay Activists in the 1970s</a></p>

<p><a href="https://arxiv.org/abs/2405.20410">SeamlessExpressiveLM: Speech Language Model for Expressive Speech-to-Speech Translation with Chain-of-Thought</a></p>

<p><a href="https://arxiv.org/abs/2403.13720">UTDUSS: UTokyo-SaruLab System for Interspeech2024 Speech Processing Using Discrete Speech Unit Challenge</a></p>

<p><a href="https://kth.diva-portal.org/smash/record.jsf?pid=diva2%3A1840732&amp;dswid=1475">Robots Beyond Borders: The Role of Social Robots in Spoken Second Language Practice</a></p>

<p><a href="https://arstechnica.com/information-technology/2024/03/once-too-scary-to-release-gpt-2-gets-squeezed-into-an-excel-spreadsheet/">Once ‚Äútoo scary‚Äù to release, GPT-2 gets squeezed into an Excel spreadsheet</a></p>

<p><a href="https://github.com/ianand/spreadsheets-are-all-you-need">ianand/spreadsheets-are-all-you-need</a></p>

<div class="jekyll-twitter-plugin">
<blockquote class="twitter-tweet">
<p lang="en" dir="ltr">The best CUDA intro course by <a href="https://twitter.com/nvidia?ref_src=twsrc%5Etfw">@nvidia</a> with 460 bite sized videos. It was the course released with Udacity 9 yrs ago.<br><br>It is kinda old, but you can grasp core ideas around it.<a href="https://t.co/OcRqwJ6phf">https://t.co/OcRqwJ6phf</a></p>‚Äî chansung (@algo_diver) <a href="https://twitter.com/algo_diver/status/1784834127839240236?ref_src=twsrc%5Etfw">April 29, 2024</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>

<div class="jekyll-twitter-plugin">
<blockquote class="twitter-tweet">
<p lang="en" dir="ltr">How do you teach a Large Language Model to understand images?<br><br>This paper proposes a technique called Visual Instruction Tuning that is now used by many of the language vision models we see in the field such as GPT4-Vision and Gemini etc.<br><br>In Short:<br>The paper introduces a method‚Ä¶ <a href="https://t.co/HJ6iRtnD3m">pic.twitter.com/HJ6iRtnD3m</a></p>‚Äî Zain (@ZainHasan6) <a href="https://twitter.com/ZainHasan6/status/1784693018554929432?ref_src=twsrc%5Etfw">April 28, 2024</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>

<p><a href="https://opensource.microsoft.com/blog/2024/04/25/open-sourcing-ms-dos-4-0/">Open sourcing MS-DOS 4.0</a></p>

<p><a href="https://github.com/microsoft/MS-DOS">microsoft/MS-DOS</a></p>

<p><a href="https://github.com/sarah-walker-pcem/pcem/">sarah-walker-pcem/pcem/</a> ‚Äî PC emulator</p>

<p><a href="https://infinitemac.org/">Infinite Mac</a> ‚Äî Infinite Mac is a collection of classic Macintosh and NeXT system releases and software, all easily accessible from the comfort of a (modern) web browser.</p>

<p><a href="https://sourceforge.net/projects/previous/">previous - NeXT emulator</a></p>

<p><a href="https://github.com/dingusdev/dingusppc">dingusdev/dingusppc</a> ‚Äî PowerPC Mac emulator</p>

<p><a href="https://basilisk.cebix.net/">Basilisk II</a>,
<a href="https://github.com/cebix/macemu">github</a></p>

<p><a href="https://github.com/autc04/executor">autc04/executor</a> ‚Äî A modern fork of the classic Mac emulator</p>

<p><a href="https://arxiv.org/abs/2407.07082">Can Learned Optimization Make Reinforcement Learning Less Difficult?</a>,
<a href="https://github.com/AlexGoldie/rl-learned-optimization">code</a></p>

<p><a href="https://github.com/google/learned_optimization">google/learned_optimization</a> ‚Äî Meta-learning optimizers and more with JAX</p>

<p><a href="https://arxiv.org/abs/2407.11793">Click-Gaussian: Interactive Segmentation to Any 3D Gaussians</a></p>

<p><a href="https://mistral.ai/news/mistral-nemo/">Mistral NeMo</a></p>

<p><a href="https://arxiv.org/abs/2401.06127">E2GAN: Efficient Training of Efficient GANs for Image-to-Image Translation</a></p>

<p><a href="https://github.com/nerfstudio-project/nerfstudio">nerfstudio-project/nerfstudio</a> ‚Äî A collaboration friendly studio for NeRFs</p>

<p><a href="https://arxiv.org/abs/2407.09252">Context Embeddings for Efficient Answer Generation in RAG</a></p>

<p><a href="https://arxiv.org/abs/2407.09025">SpreadsheetLLM: Encoding Spreadsheets for Large Language Models</a></p>


  </div><a class="u-url" href="/notes/links/2024/06/29/misc-links.html" hidden></a>
</article>

      </div>
    </main><link id="fa-stylesheet" rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css">

<footer class="site-footer h-card">
  <data class="u-url" value="/notes/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
      </div>
      <div class="footer-col">
        <p>Things I know I&#39;ll forget</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list">
  <li>
    <a href="https://jimregan.github.io/notes/feed.xml" target="_blank" title="Subscribe to syndication feed">
      <svg class="svg-icon grey" viewbox="0 0 16 16">
        <path d="M12.8 16C12.8 8.978 7.022 3.2 0 3.2V0c8.777 0 16 7.223 16 16h-3.2zM2.194
          11.61c1.21 0 2.195.985 2.195 2.196 0 1.21-.99 2.194-2.2 2.194C.98 16 0 15.017 0
          13.806c0-1.21.983-2.195 2.194-2.195zM10.606
          16h-3.11c0-4.113-3.383-7.497-7.496-7.497v-3.11c5.818 0 10.606 4.79 10.606 10.607z"
        />
      </svg>
    </a>
  </li>
</ul>
</div>

  </div>

</footer>

</body>

</html>
