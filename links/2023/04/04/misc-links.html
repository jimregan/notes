<article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Interesting links, 04/04/2023</h1><p class="page-description">Misc. interesting things.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2023-04-04T00:00:00-05:00" itemprop="datePublished">
        Apr 4, 2023
      </time>
       ‚Ä¢ <span class="read-time" title="Estimated read time">
    
    
      2 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/notes/categories/#links">links</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
</ul><p><a href="https://arxiv.org/abs/2106.04399">Flow Network based Generative Models for Non-Iterative Diverse Candidate Generation</a></p>

<div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@misc</span><span class="p">{</span><span class="nl">bengio2021flow</span><span class="p">,</span>
      <span class="na">title</span><span class="p">=</span><span class="s">{Flow Network based Generative Models for Non-Iterative Diverse Candidate Generation}</span><span class="p">,</span> 
      <span class="na">author</span><span class="p">=</span><span class="s">{Emmanuel Bengio and Moksh Jain and Maksym Korablyov and Doina Precup and Yoshua Bengio}</span><span class="p">,</span>
      <span class="na">year</span><span class="p">=</span><span class="s">{2021}</span><span class="p">,</span>
      <span class="na">eprint</span><span class="p">=</span><span class="s">{2106.04399}</span><span class="p">,</span>
      <span class="na">archivePrefix</span><span class="p">=</span><span class="s">{arXiv}</span><span class="p">,</span>
      <span class="na">primaryClass</span><span class="p">=</span><span class="s">{cs.LG}</span>
<span class="p">}</span>
</code></pre></div></div>

<p><a href="https://arxiv.org/abs/2209.14792">Make-A-Video: Text-to-Video Generation without Text-Video Data</a></p>

<div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@misc</span><span class="p">{</span><span class="nl">singer2022makeavideo</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.48550/ARXIV.2209.14792}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2209.14792}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Singer, Uriel and Polyak, Adam and Hayes, Thomas and Yin, Xi and An, Jie and Zhang, Songyang and Hu, Qiyuan and Yang, Harry and Ashual, Oron and Gafni, Oran and Parikh, Devi and Gupta, Sonal and Taigman, Yaniv}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Make-A-Video: Text-to-Video Generation without Text-Video Data}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div></div>

<p><a href="https://www.isca-speech.org/archive/eurospeech_1999/goto99_eurospeech.html">A real-time filled pause detection system for spontaneous speech recognition</a></p>

<div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">goto99_eurospeech</span><span class="p">,</span>
  <span class="na">author</span><span class="p">=</span><span class="s">{Masataka Goto and Katunobu Itou and Satoru Hayamizu}</span><span class="p">,</span>
  <span class="na">title</span><span class="p">=</span><span class="s">{A real-time filled pause detection system for spontaneous speech recognition}</span><span class="p">,</span>
  <span class="na">year</span><span class="p">=</span><span class="m">1999</span><span class="p">,</span>
  <span class="na">booktitle</span><span class="p">=</span><span class="s">{Proc. 6th European Conference on Speech Communication and Technology (Eurospeech 1999)}</span><span class="p">,</span>
  <span class="na">pages</span><span class="p">=</span><span class="s">{227--230}</span><span class="p">,</span>
  <span class="na">doi</span><span class="p">=</span><span class="s">{10.21437/Eurospeech.1999-60}</span>
<span class="p">}</span>
</code></pre></div></div>

<p><a href="https://arxiv.org/abs/2210.07677">TransFusion: Transcribing Speech with Multinomial Diffusion</a>, <a href="https://github.com/RF5/transfusion-asr/">code</a> ‚Äì not open source.</p>

<div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@misc</span><span class="p">{</span><span class="nl">baas2022transfusion</span><span class="p">,</span>
      <span class="na">title</span><span class="p">=</span><span class="s">{TransFusion: Transcribing Speech with Multinomial Diffusion}</span><span class="p">,</span> 
      <span class="na">author</span><span class="p">=</span><span class="s">{Matthew Baas and Kevin Eloff and Herman Kamper}</span><span class="p">,</span>
      <span class="na">year</span><span class="p">=</span><span class="s">{2022}</span><span class="p">,</span>
      <span class="na">eprint</span><span class="p">=</span><span class="s">{2210.07677}</span><span class="p">,</span>
      <span class="na">archivePrefix</span><span class="p">=</span><span class="s">{arXiv}</span><span class="p">,</span>
      <span class="na">primaryClass</span><span class="p">=</span><span class="s">{eess.AS}</span>
<span class="p">}</span>
</code></pre></div></div>

<p><a href="https://aclanthology.org/2022.lrec-1.106/">The Norwegian Parliamentary Speech Corpus</a></p>

<div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">solberg-ortiz-2022-norwegian</span><span class="p">,</span>
    <span class="na">title</span> <span class="p">=</span> <span class="s">"The {N}orwegian Parliamentary Speech Corpus"</span><span class="p">,</span>
    <span class="na">author</span> <span class="p">=</span> <span class="s">"Solberg, Per Erik  and
      Ortiz, Pablo"</span><span class="p">,</span>
    <span class="na">booktitle</span> <span class="p">=</span> <span class="s">"Proceedings of the Thirteenth Language Resources and Evaluation Conference"</span><span class="p">,</span>
    <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
    <span class="na">year</span> <span class="p">=</span> <span class="s">"2022"</span><span class="p">,</span>
    <span class="na">address</span> <span class="p">=</span> <span class="s">"Marseille, France"</span><span class="p">,</span>
    <span class="na">publisher</span> <span class="p">=</span> <span class="s">"European Language Resources Association"</span><span class="p">,</span>
    <span class="na">pages</span> <span class="p">=</span> <span class="s">"1003--1008"</span><span class="p">,</span>
<span class="p">}</span>
</code></pre></div></div>

<p><a href="https://hunlang.files.wordpress.com/2009/09/tmthtgfinal.pdf">There is more to Hungarian than goulash! Grammar Course for Beginners</a></p>

<p><a href="https://github.com/sp-nitech/diffsptk">sp-nitech/diffsptk</a> ‚Äî A differential version of SPTK</p>

<p><a href="https://github.com/soobinseo/Transformer-TTS">soobinseo/Transformer-TTS</a> ‚Äî A Pytorch Implementation of ‚ÄúNeural Speech Synthesis with Transformer Network‚Äù</p>

<p><a href="https://github.com/jxzhanggg/nonparaSeq2seqVC_code">jxzhanggg/nonparaSeq2seqVC_code</a> ‚Äî Implementation code of non-parallel sequence-to-sequence VC</p>

<p><a href="https://github.com/snakers4/silero-vad">snakers4/silero-vad</a></p>

<p><a href="http://rtg.isi.edu/many-eng/data-v2.html">Many-to-English: Data v2 and Statistics</a></p>

<div class="jekyll-twitter-plugin">
<blockquote class="twitter-tweet">
<p lang="en" dir="ltr">Probably the best thing you'll see today.<br><br>In 2017, a group of developers hilariously competed for who could create worst volume control interface in the world.<br><br>The results üßµ<br><br>1/22</p>‚Äî 0xDesigner (@0xDesigner) <a href="https://twitter.com/0xDesigner/status/1642554817590566915?ref_src=twsrc%5Etfw">April 2, 2023</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>

<p><a href="https://github.com/neonbjb/tortoise-tts">neonbjb/tortoise-tts</a> ‚Äî A multi-voice TTS system trained with an emphasis on quality</p>

<p><a href="https://github.com/urschrei/pyzotero">urschrei/pyzotero</a> ‚Äî Pyzotero: a Python client for the Zotero API</p>

<p><a href="https://arxiv.org/abs/2205.04421">NaturalSpeech: End-to-End Text to Speech Synthesis with Human-Level Quality</a></p>

<div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@misc</span><span class="p">{</span><span class="nl">tan2022naturalspeech</span><span class="p">,</span>
      <span class="na">title</span><span class="p">=</span><span class="s">{NaturalSpeech: End-to-End Text to Speech Synthesis with Human-Level Quality}</span><span class="p">,</span> 
      <span class="na">author</span><span class="p">=</span><span class="s">{Xu Tan and Jiawei Chen and Haohe Liu and Jian Cong and Chen Zhang and Yanqing Liu and Xi Wang and Yichong Leng and Yuanhao Yi and Lei He and Frank Soong and Tao Qin and Sheng Zhao and Tie-Yan Liu}</span><span class="p">,</span>
      <span class="na">year</span><span class="p">=</span><span class="s">{2022}</span><span class="p">,</span>
      <span class="na">eprint</span><span class="p">=</span><span class="s">{2205.04421}</span><span class="p">,</span>
      <span class="na">archivePrefix</span><span class="p">=</span><span class="s">{arXiv}</span><span class="p">,</span>
      <span class="na">primaryClass</span><span class="p">=</span><span class="s">{eess.AS}</span>
<span class="p">}</span>
</code></pre></div></div>

<p><a href="https://www.lexiconista.com/pdf/Uimhreacha.pdf">Uimhreacha</a></p>

<p><a href="https://arxiv.org/abs/2212.10560">Self-Instruct: Aligning Language Model with Self Generated Instructions</a>, <a href="https://github.com/yizhongw/self-instruct">code</a></p>

<div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@misc</span><span class="p">{</span><span class="nl">wang2022selfinstruct</span><span class="p">,</span>
      <span class="na">title</span><span class="p">=</span><span class="s">{Self-Instruct: Aligning Language Model with Self Generated Instructions}</span><span class="p">,</span> 
      <span class="na">author</span><span class="p">=</span><span class="s">{Yizhong Wang and Yeganeh Kordi and Swaroop Mishra and Alisa Liu and Noah A. Smith and Daniel Khashabi and Hannaneh Hajishirzi}</span><span class="p">,</span>
      <span class="na">year</span><span class="p">=</span><span class="s">{2022}</span><span class="p">,</span>
      <span class="na">eprint</span><span class="p">=</span><span class="s">{2212.10560}</span><span class="p">,</span>
      <span class="na">archivePrefix</span><span class="p">=</span><span class="s">{arXiv}</span><span class="p">,</span>
      <span class="na">primaryClass</span><span class="p">=</span><span class="s">{cs.CL}</span>
<span class="p">}</span>
</code></pre></div></div>

<p><a href="https://www.youtube.com/watch?v=NNnIGh9g6fA">Introduction to Human Behavioral Biology</a></p>

  </div><a class="u-url" href="/notes/links/2023/04/04/misc-links.html" hidden></a>
</article>