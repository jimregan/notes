<article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Interesting links, 24/02/2023</h1><p class="page-description">Misc. interesting things.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2023-02-24T00:00:00-06:00" itemprop="datePublished">
        Feb 24, 2023
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      2 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/notes/categories/#links">links</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
</ul><p><a href="https://www.isca-speech.org/archive/interspeech_2022/deseyssel22_interspeech.html">Probing phoneme, language and speaker information in unsupervised speech representations</a>, <a href="https://www.isca-speech.org/archive/pdfs/interspeech_2022/deseyssel22_interspeech.pdf">pdf</a></p>

<div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">deseyssel22_interspeech</span><span class="p">,</span>
  <span class="na">author</span><span class="p">=</span><span class="s">{Maureen {de Seyssel} and Marvin Lavechin and Yossi Adi and Emmanuel Dupoux and Guillaume Wisniewski}</span><span class="p">,</span>
  <span class="na">title</span><span class="p">=</span><span class="s">{ {Probing phoneme, language and speaker information in unsupervised speech representations}}</span><span class="p">,</span>
  <span class="na">year</span><span class="p">=</span><span class="m">2022</span><span class="p">,</span>
  <span class="na">booktitle</span><span class="p">=</span><span class="s">{Proc. Interspeech 2022}</span><span class="p">,</span>
  <span class="na">pages</span><span class="p">=</span><span class="s">{1402--1406}</span><span class="p">,</span>
  <span class="na">doi</span><span class="p">=</span><span class="s">{10.21437/Interspeech.2022-373}</span>
<span class="p">}</span>
</code></pre></div></div>

<p><a href="https://www.isca-speech.org/archive/interspeech_2022/shi22b_interspeech.html">VQ-T: RNN Transducers using Vector-Quantized Prediction Network States</a>, <a href="https://www.isca-speech.org/archive/pdfs/interspeech_2022/shi22b_interspeech.pdf">pdf</a></p>

<div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">shi22b_interspeech</span><span class="p">,</span>
  <span class="na">author</span><span class="p">=</span><span class="s">{Jiatong Shi and George Saon and David Haws and Shinji Watanabe and Brian Kingsbury}</span><span class="p">,</span>
  <span class="na">title</span><span class="p">=</span><span class="s">{ {VQ-T: RNN Transducers using Vector-Quantized Prediction Network States}}</span><span class="p">,</span>
  <span class="na">year</span><span class="p">=</span><span class="m">2022</span><span class="p">,</span>
  <span class="na">booktitle</span><span class="p">=</span><span class="s">{Proc. Interspeech 2022}</span><span class="p">,</span>
  <span class="na">pages</span><span class="p">=</span><span class="s">{1656--1660}</span><span class="p">,</span>
  <span class="na">doi</span><span class="p">=</span><span class="s">{10.21437/Interspeech.2022-414}</span>
<span class="p">}</span>
</code></pre></div></div>

<p><a href="https://www.isca-speech.org/archive/interspeech_2022/laptev22_interspeech.html">CTC Variations Through New WFST Topologies</a>, <a href="https://www.isca-speech.org/archive/pdfs/interspeech_2022/laptev22_interspeech.pdf">pdf</a></p>

<div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">laptev22_interspeech</span><span class="p">,</span>
  <span class="na">author</span><span class="p">=</span><span class="s">{Aleksandr Laptev and Somshubra Majumdar and Boris Ginsburg}</span><span class="p">,</span>
  <span class="na">title</span><span class="p">=</span><span class="s">{ {CTC Variations Through New WFST Topologies}}</span><span class="p">,</span>
  <span class="na">year</span><span class="p">=</span><span class="m">2022</span><span class="p">,</span>
  <span class="na">booktitle</span><span class="p">=</span><span class="s">{Proc. Interspeech 2022}</span><span class="p">,</span>
  <span class="na">pages</span><span class="p">=</span><span class="s">{1041--1045}</span><span class="p">,</span>
  <span class="na">doi</span><span class="p">=</span><span class="s">{10.21437/Interspeech.2022-10854}</span>
<span class="p">}</span>
</code></pre></div></div>

<p><a href="https://github.com/nvidia-riva/riva-asrlib-decoder">nvidia-riva/riva-asrlib-decoder</a> – Standalone implementation of the CUDA-accelerated WFST Decoder available in Riva</p>

<p><a href="https://www.isca-speech.org/archive/interspeech_2022/sustek22_interspeech.html">Dealing with Unknowns in Continual Learning for End-to-end Automatic Speech Recognition</a>, <a href="https://www.isca-speech.org/archive/pdfs/interspeech_2022/sustek22_interspeech.pdf">pdf</a></p>

<div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">sustek22_interspeech</span><span class="p">,</span>
  <span class="na">author</span><span class="p">=</span><span class="s">{Martin Sustek and Samik Sadhu and Hynek Hermansky}</span><span class="p">,</span>
  <span class="na">title</span><span class="p">=</span><span class="s">{ {Dealing with Unknowns in Continual Learning for End-to-end Automatic Speech Recognition}}</span><span class="p">,</span>
  <span class="na">year</span><span class="p">=</span><span class="m">2022</span><span class="p">,</span>
  <span class="na">booktitle</span><span class="p">=</span><span class="s">{Proc. Interspeech 2022}</span><span class="p">,</span>
  <span class="na">pages</span><span class="p">=</span><span class="s">{1046--1050}</span><span class="p">,</span>
  <span class="na">doi</span><span class="p">=</span><span class="s">{10.21437/Interspeech.2022-11139}</span>
<span class="p">}</span>
</code></pre></div></div>

<p><a href="https://www.isca-speech.org/archive/interspeech_2022/handekabil22_interspeech.html">From Undercomplete to Sparse Overcomplete Autoencoders to Improve LF-MMI based Speech Recognition</a>, <a href="https://www.isca-speech.org/archive/pdfs/interspeech_2022/handekabil22_interspeech.pdf">pdf</a></p>

<div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">handekabil22_interspeech</span><span class="p">,</span>
  <span class="na">author</span><span class="p">=</span><span class="s">{Selen {Hande Kabil} and Herve Bourlard}</span><span class="p">,</span>
  <span class="na">title</span><span class="p">=</span><span class="s">{ {From Undercomplete to Sparse Overcomplete Autoencoders to Improve LF-MMI based Speech Recognition}}</span><span class="p">,</span>
  <span class="na">year</span><span class="p">=</span><span class="m">2022</span><span class="p">,</span>
  <span class="na">booktitle</span><span class="p">=</span><span class="s">{Proc. Interspeech 2022}</span><span class="p">,</span>
  <span class="na">pages</span><span class="p">=</span><span class="s">{1061--1065}</span><span class="p">,</span>
  <span class="na">doi</span><span class="p">=</span><span class="s">{10.21437/Interspeech.2022-11390}</span>
<span class="p">}</span>
</code></pre></div></div>

<p><a href="https://www.isca-speech.org/archive/interspeech_2022/vandermerwe22_interspeech.html">A Temporal Extension of Latent Dirichlet Allocation for Unsupervised Acoustic Unit Discovery</a>, <a href="https://www.isca-speech.org/archive/pdfs/interspeech_2022/vandermerwe22_interspeech.pdf">pdf</a></p>

<div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">vandermerwe22_interspeech</span><span class="p">,</span>
  <span class="na">author</span><span class="p">=</span><span class="s">{Werner {van der Merwe} and Herman Kamper and Johan {Adam du Preez}}</span><span class="p">,</span>
  <span class="na">title</span><span class="p">=</span><span class="s">{ {A Temporal Extension of Latent Dirichlet Allocation for Unsupervised Acoustic Unit Discovery}}</span><span class="p">,</span>
  <span class="na">year</span><span class="p">=</span><span class="m">2022</span><span class="p">,</span>
  <span class="na">booktitle</span><span class="p">=</span><span class="s">{Proc. Interspeech 2022}</span><span class="p">,</span>
  <span class="na">pages</span><span class="p">=</span><span class="s">{1426--1430}</span><span class="p">,</span>
  <span class="na">doi</span><span class="p">=</span><span class="s">{10.21437/Interspeech.2022-11369}</span>
<span class="p">}</span>
</code></pre></div></div>

<p><a href="https://www.isca-speech.org/archive/interspeech_2022/xie22b_interspeech.html">DEFORMER: Coupling Deformed Localized Patterns with Global Context for Robust End-to-end Speech Recognition</a>, <a href="https://www.isca-speech.org/archive/pdfs/interspeech_2022/xie22b_interspeech.pdf">pdf</a></p>

<div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">xie22b_interspeech</span><span class="p">,</span>
  <span class="na">author</span><span class="p">=</span><span class="s">{Jiamin Xie and John H.L. Hansen}</span><span class="p">,</span>
  <span class="na">title</span><span class="p">=</span><span class="s">{ {DEFORMER: Coupling Deformed Localized Patterns with Global Context for Robust End-to-end Speech Recognition}}</span><span class="p">,</span>
  <span class="na">year</span><span class="p">=</span><span class="m">2022</span><span class="p">,</span>
  <span class="na">booktitle</span><span class="p">=</span><span class="s">{Proc. Interspeech 2022}</span><span class="p">,</span>
  <span class="na">pages</span><span class="p">=</span><span class="s">{1392--1396}</span><span class="p">,</span>
  <span class="na">doi</span><span class="p">=</span><span class="s">{10.21437/Interspeech.2022-11172}</span>
<span class="p">}</span>
</code></pre></div></div>

<p><a href="https://www.isca-speech.org/archive/interspeech_2022/kim22k_interspeech.html">Automatic Pronunciation Assessment using Self-Supervised Speech Representation Learning</a>, <a href="https://www.isca-speech.org/archive/pdfs/interspeech_2022/kim22k_interspeech.pdf">pdf</a></p>

<div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">kim22k_interspeech</span><span class="p">,</span>
  <span class="na">author</span><span class="p">=</span><span class="s">{Eesung Kim and Jae-Jin Jeon and Hyeji Seo and Hoon Kim}</span><span class="p">,</span>
  <span class="na">title</span><span class="p">=</span><span class="s">{ {Automatic Pronunciation Assessment using Self-Supervised Speech Representation Learning}}</span><span class="p">,</span>
  <span class="na">year</span><span class="p">=</span><span class="m">2022</span><span class="p">,</span>
  <span class="na">booktitle</span><span class="p">=</span><span class="s">{Proc. Interspeech 2022}</span><span class="p">,</span>
  <span class="na">pages</span><span class="p">=</span><span class="s">{1411--1415}</span><span class="p">,</span>
  <span class="na">doi</span><span class="p">=</span><span class="s">{10.21437/Interspeech.2022-10245}</span>
<span class="p">}</span>
</code></pre></div></div>

<p><a href="https://www.isca-speech.org/archive/interspeech_2022/szalay22_interspeech.html">Knowledge of accent differences can be used to predict speech recognition</a>, <a href="https://www.isca-speech.org/archive/pdfs/interspeech_2022/szalay22_interspeech.pdf">pdf</a></p>

<div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">szalay22_interspeech</span><span class="p">,</span>
  <span class="na">author</span><span class="p">=</span><span class="s">{Tuende Szalay and Mostafa Shahin and Beena Ahmed and Kirrie Ballard}</span><span class="p">,</span>
  <span class="na">title</span><span class="p">=</span><span class="s">{ {Knowledge of accent differences can be used to predict speech recognition}}</span><span class="p">,</span>
  <span class="na">year</span><span class="p">=</span><span class="m">2022</span><span class="p">,</span>
  <span class="na">booktitle</span><span class="p">=</span><span class="s">{Proc. Interspeech 2022}</span><span class="p">,</span>
  <span class="na">pages</span><span class="p">=</span><span class="s">{1372--1376}</span><span class="p">,</span>
  <span class="na">doi</span><span class="p">=</span><span class="s">{10.21437/Interspeech.2022-10162}</span>
<span class="p">}</span>
</code></pre></div></div>

<p><a href="https://www.isca-speech.org/archive/interspeech_2022/rumberg22b_interspeech.html">Improving Phonetic Transcriptions of Children’s Speech by Pronunciation Modelling with Constrained CTC-Decoding</a>, <a href="https://www.isca-speech.org/archive/pdfs/interspeech_2022/rumberg22b_interspeech.pdf">pdf</a></p>

<div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">rumberg22b_interspeech</span><span class="p">,</span>
  <span class="na">author</span><span class="p">=</span><span class="s">{Lars Rumberg and Christopher Gebauer and Hanna Ehlert and Ulrike Lüdtke and Jörn Ostermann}</span><span class="p">,</span>
  <span class="na">title</span><span class="p">=</span><span class="s">{ {Improving Phonetic Transcriptions of Children’s Speech by Pronunciation Modelling with Constrained CTC-Decoding}}</span><span class="p">,</span>
  <span class="na">year</span><span class="p">=</span><span class="m">2022</span><span class="p">,</span>
  <span class="na">booktitle</span><span class="p">=</span><span class="s">{Proc. Interspeech 2022}</span><span class="p">,</span>
  <span class="na">pages</span><span class="p">=</span><span class="s">{1357--1361}</span><span class="p">,</span>
  <span class="na">doi</span><span class="p">=</span><span class="s">{10.21437/Interspeech.2022-332}</span>
<span class="p">}</span>
</code></pre></div></div>


  </div><a class="u-url" href="/notes/links/2023/02/24/misc-links.html" hidden></a>
</article>