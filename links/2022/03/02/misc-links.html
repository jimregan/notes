<article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Interesting links, 02/03/2022</h1><p class="page-description">Misc. interesting things.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-03-02T00:00:00-06:00" itemprop="datePublished">
        Mar 2, 2022
      </time>
       ‚Ä¢ <span class="read-time" title="Estimated read time">
    
    
      1 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/notes/categories/#links">links</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#audio-augmentation">Audio augmentation</a></li>
<li class="toc-entry toc-h2"><a href="#fonetik">Fonetik</a></li>
</ul><p><a href="https://2022.fonetik.se/">Fonetik 2022</a></p>

<p><a href="https://www.bas.uni-muenchen.de/~jmh/lehre/Rdf/EMU-SDMS/lesson6/06-emu-webApp.html">The EMU-webApp</a></p>

<p><a href="https://www.torchstudio.ai/features/">TorchStudio Features</a> ‚Äî Looks interesting, doesn‚Äôt seem to run on ARM Mac though</p>

<p><a href="https://arxiv.org/abs/2103.08993">Fast Development of ASR in African Languages using Self Supervised Speech Representation Learning</a></p>

<p><a href="https://dl.acm.org/doi/10.1145/2700648.2811331">The Effects of Automatic Speech Recognition Quality on Human Transcription Latency</a>
‚ÄúOur studies with 160 participants recruited on Amazon‚Äôs Mechanical Turk indicate that starting with the ASR output is worse unless it is sufficiently accurate (Word Error Rate (WER) is under 30%)‚Äù</p>

<p><a href="https://arxiv.org/abs/2107.11628">Differentiable Allophone Graphs for Language-Universal Speech Recognition</a>,
<a href="https://twitter.com/brianyan918/status/1420860185632022531">tweet</a></p>

<p><a href="https://huggingface.co/birgermoell/lm-swedish">birgermoell/lm-swedish</a></p>

<p><a href="https://huggingface.co/blog/wav2vec2-with-ngram">Boosting Wav2Vec2 with n-grams in ü§ó Transformers</a></p>

<p><a href="https://phoneticsrv3.lcs.tcd.ie/rec/irish_asr">Irish ASR demo</a></p>

<p><a href="https://www.speech.kth.se/qpsr/">QPSR</a></p>

<p><a href="https://www.speech.kth.se/gunnarfant/publications.html">Gunnar Fant publications</a></p>

<p><a href="https://erlj.notion.site/Neural-Instrument-Cloning-from-very-few-samples-2cf41d8b630842ee8c7eb55036a1bfd6">Neural Instrument Cloning from very few samples</a></p>

<p><a href="https://github.com/AI-Nordics/the-nordic-pile">AI-Nordics/the-nordic-pile</a></p>

<p><a href="https://www.nsc.liu.se/systems/berzelius/">Berzelius</a></p>

<p><a href="https://github.com/chinedufn/swift-bridge">chinedufn/swift-bridge</a> ‚Äî swift-bridge facilitates Rust and Swift interop.</p>

<p><a href="https://github.com/qarmin/czkawka">qarmin/czkawka</a> ‚Äî Multi functional app to find duplicates, empty folders, similar images etc.</p>

<p><a href="https://github.com/PyO3/pyo3">PyO3/pyo3</a> ‚Äî Rust bindings for the Python interpreter</p>

<p><a href="https://www.kaggle.com/alvations/n-gram-language-model-with-nltk">N-gram Language Model with NLTK</a></p>

<p><a href="https://speechbrain.readthedocs.io/en/latest/API/speechbrain.lm.counting.html">speechbrain.lm.counting module</a></p>

<p><a href="https://cloud.google.com/speech-to-text/docs/languages">Google cloud ASR languages</a></p>

<p><a href="https://flame.is.tue.mpg.de/index.html">FLAME</a>,
<a href="https://github.com/HavenFeng/photometric_optimization">pytorch</a></p>

<p><a href="https://colab.research.google.com/github/google/flax/blob/main/docs/notebooks/linen_intro.ipynb">Bried intro to Linen</a></p>

<p><a href="https://huggingface.co/datasets/NbAiLab/NPSC">NbAiLab/NPSC</a> ‚Äî Norwegian Parliamentary Speech Corpus</p>

<p><a href="https://github.com/huggingface/transformers/commit/d25e25ee2b63ebfcd099deb689a5a7272574a10f">XGLM: HuggingFace</a></p>

<p><a href="https://filesystem-spec.readthedocs.io/en/latest/intro.html">fsspec</a></p>

<p><a href="https://arxiv.org/abs/2105.03824">FNet: Mixing Tokens with Fourier Transforms</a>,
<a href="https://github.com/google-research/google-research/tree/master/f_net">code</a>,
<a href="https://huggingface.co/docs/transformers/model_doc/fnet">HF</a></p>

<p><a href="https://github.com/huggingface/transformers/commit/125a2882b4997f8ad37beadb8a025114f0f0e1a0">HF: wav2vec update for tiny audio</a></p>

<p><a href="https://www.youtube.com/watch?v=M2ToEXF6Olw">Adding vs. concatenating positional embeddings &amp; Learned positional encodings</a></p>

<p><a href="https://github.com/ageron/handson-ml2/blob/master/math_differential_calculus.ipynb">Math - Differential Calculus</a></p>

<p><a href="https://github.com/BirgerMoell/ToMaHawk">BirgerMoell/ToMaHawk</a></p>

<p><a href="https://huggingface.co/blog/asr-chunking">Making automatic speech recognition work on large files with Wav2Vec2 in ü§ó Transformers</a></p>

<p><a href="https://arxiv.org/abs/2108.12409">Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation</a>,
<a href="https://openreview.net/forum?id=R8sQPpGCv0">OpenReview</a>,
<a href="https://github.com/ofirpress/attention_with_linear_biases">code</a></p>

<p><a href="https://www.youtube.com/watch?v=0TdAmZUMj2k">02 ‚Äì Neural nets: rotation and squashing</a></p>

<h2 id="audio-augmentation">
<a class="anchor" href="#audio-augmentation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Audio augmentation</h2>

<p><a href="https://github.com/facebookresearch/AugLy">facebookresearch/AugLy</a></p>

<p><a href="https://github.com/iver56/audiomentations">iver56/audiomentations</a></p>

<p><a href="https://github.com/asteroid-team/torch-audiomentations">asteroid-team/torch-audiomentations</a></p>

<p><a href="https://github.com/Spijkervet/torchaudio-augmentations">Spijkervet/torchaudio-augmentations</a></p>

<p><a href="https://github.com/spotify/pedalboard">spotify/pedalboard</a></p>

<p><a href="https://github.com/facebookresearch/WavAugment">facebookresearch/WavAugment</a></p>

<p><a href="https://iqtlabs.github.io/voices/">VOiCES Corpus</a></p>

<h2 id="fonetik">
<a class="anchor" href="#fonetik" aria-hidden="true"><span class="octicon octicon-link"></span></a>Fonetik</h2>

<p><a href="https://www.speech.kth.se/prod/publications/files/qpsr/1960/1960_1_2_019-019.pdf">FM-modulation unit for tape-recording</a></p>

<p><a href="https://www.speech.kth.se/prod/publications/files/qpsr/1960/1960_1_1_003-005.pdf">Voice fundamental frequency tracking</a></p>

<p><a href="https://www.speech.kth.se/prod/publications/files/qpsr/1960/1960_1_1_006-009.pdf">Formant frequency tracking</a></p>

<p><a href="https://www.speech.kth.se/prod/publications/files/qpsr/1960/1960_1_1_010-010.pdf">Detection of voicing and Automatic segmentation schemes</a></p>

<p><a href="https://www.speech.kth.se/prod/publications/files/qpsr/1960/1960_1_1_011-013.pdf">Evaluation of spectrographic data sampling techniques</a></p>

<p><a href="https://www.speech.kth.se/prod/publications/files/qpsr/1960/1960_1_2_010-015.pdf">Structural classification of Swedish phonemes</a></p>

<p><a href="https://www.speech.kth.se/prod/publications/files/3547.pdf">In search of the conversational homunculus</a></p>

<p><a href="https://www.speech.kth.se/prod/publications/files/qpsr/2007/2007_50_1_113-116.pdf">Automatic classification of ‚Äòfront‚Äô and ‚Äòback‚Äô pronunciation variants of /r/ in the G√∂taland dialects of Swedish</a></p>


  </div><a class="u-url" href="/notes/links/2022/03/02/misc-links.html" hidden></a>
</article>