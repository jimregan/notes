<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Interesting links, 3/10/2025 | notes</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Interesting links, 3/10/2025" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Misc. interesting things." />
<meta property="og:description" content="Misc. interesting things." />
<link rel="canonical" href="https://jimregan.github.io/notes/links/2025/10/03/misc-links.html" />
<meta property="og:url" content="https://jimregan.github.io/notes/links/2025/10/03/misc-links.html" />
<meta property="og:site_name" content="notes" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-10-03T00:00:00-05:00" />
<script type="application/ld+json">
{"url":"https://jimregan.github.io/notes/links/2025/10/03/misc-links.html","@type":"BlogPosting","headline":"Interesting links, 3/10/2025","dateModified":"2025-10-03T00:00:00-05:00","datePublished":"2025-10-03T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://jimregan.github.io/notes/links/2025/10/03/misc-links.html"},"description":"Misc. interesting things.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/notes/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://jimregan.github.io/notes/feed.xml" title="notes" /><link rel="shortcut icon" type="image/x-icon" href="/notes/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper">
    <a class="site-title" rel="author" href="/notes/">notes</a>
      <nav class="site-nav">
        <input type="checkbox" id="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon"></span>
        </label>

        <div class="nav-items">
  <a class="nav-item" href="/notes/about/">About Me</a>
  <a class="nav-item" href="/notes/search/">Search</a>
  <a class="nav-item" href="/notes/categories/">Tags</a>
</div>

      </nav>
  </div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Interesting links, 3/10/2025</h1><p class="page-description">Misc. interesting things.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2025-10-03T00:00:00-05:00" itemprop="datePublished">
        Oct 3, 2025
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      3 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/notes/categories/#links">links</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#sámi">Sámi</a></li>
<li class="toc-entry toc-h1"><a href="#misc">Misc</a></li>
</ul><h1 id="sámi">
<a class="anchor" href="#s%C3%A1mi" aria-hidden="true"><span class="octicon octicon-link"></span></a>Sámi</h1>

<p><a href="https://github.com/divvun/lang-sme-ml-speech">divvun/lang-sme-ml-speech</a></p>

<p><a href="https://github.com/divvun/lang-sme-ml-swe">divvun/lang-sme-ml-swe</a></p>

<p><a href="https://huggingface.co/NbAiLab/whisper-large-sme">NbAiLab/whisper-large-sme</a></p>

<p><a href="https://huggingface.co/NbAiLab/salmon-whisper-large-smj-lr7e-5">NbAiLab/salmon-whisper-large-smj-lr7e-5</a></p>

<p><a href="https://huggingface.co/spaces/NbAiLab/f5-tts-north-sami">NbAiLab/f5-tts-north-sami</a></p>

<p><a href="https://huggingface.co/spaces/divvun-tts/multi-sami">divvun-tts/multi-sami</a></p>

<p><a href="https://huggingface.co/spaces/divvun-tts/6L-TTS">divvun-tts/6L-TTS</a></p>

<p><a href="https://www.isca-archive.org/ssw_2025/hiovainasikainen25_ssw.html">Does multilingual and multi-speaker modeling improve low-resource TTS? Experiments on Sámi languages</a></p>

<p><a href="https://github.com/aalto-speech/northern-sami-asr">aalto-speech/northern-sami-asr</a></p>

<p><a href="https://huggingface.co/GetmanY1/wav2vec2-xls-r-300m-sami-parl-ext-ft">GetmanY1/wav2vec2-xls-r-300m-sami-parl-ext-ft</a></p>

<p><a href="https://huggingface.co/GetmanY1/wav2vec2-base-sami-22k">GetmanY1/wav2vec2-base-sami-22k</a></p>

<p><a href="https://github.com/giellalt/speech-sme">giellalt/speech-sme</a></p>

<p><a href="https://github.com/giellalt/speech-smj/blob/main/docs/Rewrite_to_IPA.md">Julev Sámi IPA</a></p>

<p># ParlaSpeech</p>

<p><a href="https://www.clarin.si/repository/xmlui/handle/11356/1833">Spoken corpora of parliamentary debates ParlaSpeech 3.0</a></p>

<p><a href="https://clarinsi.github.io/parlaspeech/">Welcome to ParlaSpeech</a></p>

<h1 id="misc">
<a class="anchor" href="#misc" aria-hidden="true"><span class="octicon octicon-link"></span></a>Misc</h1>

<p><a href="https://www.kaggle.com/code/tajakuz/correct-mt-output-with-word-alignments">Correct MT output with word alignments</a></p>

<p><a href="https://github.com/robertostling/eflomal">robertostling/eflomal</a></p>

<p><a href="https://arxiv.org/abs/2407.03495">Codec-ASR: Training Performant Automatic Speech Recognition Systems with Discrete Speech Representations</a></p>

<p><a href="https://github.com/lucidrains/vector-quantize-pytorch">lucidrains/vector-quantize-pytorch</a></p>

<p><a href="https://arxiv.org/abs/2309.13876">Reproducing Whisper-Style Training Using an Open-Source Toolkit and Publicly Available Data</a></p>

<p><a href="https://ieeexplore.ieee.org/document/10889886">Multiple Consistency-guided Test-Time Adaptation for Contrastive Audio-Language Models with Unlabeled Audio</a></p>

<p><a href="https://ieeexplore.ieee.org/document/10888610">MambaInst: Lightweight State Space Model for Real-Time Instance Segmentation</a></p>

<p><a href="https://huggingface.co/spaces/nvidia/canary-1b-flash">nvidia/canary-1b-flash</a></p>

<p><a href="https://huggingface.co/spaces/nvidia/canary-1b-v2">spaces/nvidia/canary-1b-v2</a></p>

<p><a href="https://github.com/NVIDIA-NeMo/NeMo/blob/main/docker/Dockerfile.speech">NeMo/blob/main/docker/Dockerfile.speech</a></p>

<p><a href="https://huggingface.co/nvidia/nemo-megatron-t5-3B">nvidia/nemo-megatron-t5-3B</a></p>

<p><a href="https://github.com/sparkfish/augraphy">sparkfish/augraphy</a> — Augmentation pipeline for rendering synthetic paper printing, faxing, scanning and copy machine processes</p>

<p><a href="https://github.com/bytedance/MegaTTS3">bytedance/MegaTTS3</a></p>

<p><a href="https://drive.google.com/file/d/1P-XBGhu3xUleeSWx0bRQPMPHuOGdEGyh/view">BiT S09E08</a></p>

<p><a href="https://research.google/blog/speech-to-retrieval-s2r-a-new-approach-to-voice-search/">Speech-to-Retrieval</a>,
<a href="https://huggingface.co/datasets/google/svq">dataset</a>,
<a href="https://github.com/google-research/mseb">code</a></p>

<p><a href="https://gregorygundersen.com/blog/2025/10/01/large-language-models/">A History of Large Language Models</a></p>

<p><a href="https://huggingface.co/neuphonic/neucodec">neuphonic/neucodec</a>,
<a href="https://github.com/neuphonic/neucodec">code</a>,
<a href="https://huggingface.co/spaces/neuphonic/neutts-air">space</a></p>

<p><a href="https://arxiv.org/abs/2309.09493">HiFTNet: A Fast High-Quality Neural Vocoder with Harmonic-plus-Noise Filter and Inverse Short Time Fourier Transform</a>,
<a href="https://github.com/yl4579/HiFTNet">code</a></p>

<p><a href="https://github.com/deepsearch-ai/deepsearch">deepsearch-ai/deepsearch</a> — A multimodal RAG application that enables semantic search on multimedia sources like audio, video and images</p>

<p><a href="https://courses.maths.ox.ac.uk/course/view.php?id=1051">Introduction to University Mathematics</a></p>

<p><a href="https://developers.googleblog.com/en/conversational-image-segmentation-gemini-2-5/">Conversational image segmentation with Gemini 2.5</a></p>

<p><a href="https://github.com/deepreinforce-ai/CRINN">deepreinforce-ai/CRINN</a></p>

<p><a href="https://www.wavlab.org/activities/2024/owsm/">Open Whisper-style Speech Models</a></p>

<p><a href="https://github.com/raminnakhli/GMM-HMM-from-scratch">raminnakhli/GMM-HMM-from-scratch</a></p>

<p><a href="https://arxiv.org/abs/2007.13465">Self-Supervised Contrastive Learning for Unsupervised Phoneme Segmentation</a>,
<a href="https://github.com/felixkreuk/UnsupSeg">code</a></p>

<p><a href="https://gist.github.com/seastar105/d1d8983b27611370528e3b194dcc5577">Phi-4-multimodal-korean-finetuning</a></p>

<p><a href="https://getomni.ai/blog/benchmarking-open-source-models-for-ocr">The best open source OCR models</a></p>

<p><a href="https://aclanthology.org/2025.findings-naacl.184/">Continuous Speech Tokenizer in Text To Speech</a>,
<a href="https://github.com/Yixing-Li/Continuous-Speech-Tokenizer">code</a></p>

<p><a href="https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Orpheus_%283B%29-TTS.ipynb">Orpheus 3B</a></p>

<p><a href="https://github.com/MCG-NJU/DDT">DDT: Decoupled Diffusion Transformer</a></p>

<p><a href="https://github.com/SesameAILabs/csm">SesameAILabs/csm</a> — A Conversational Speech Generation Model,
<a href="https://huggingface.co/sesame/csm-1b">model</a></p>

<p><a href="https://github.com/langchain-ai/rag-from-scratch">langchain-ai/rag-from-scratch</a></p>

<p><a href="https://github.com/Zettlr/Zettlr">Zettlr/Zettlr</a></p>

<p><a href="https://arxiv.org/abs/2211.01461">Phoneme Segmentation Using Self-Supervised Speech Models</a>,
<a href="https://github.com/lstrgar/self-supervised-phone-segmentation">code</a></p>

<p><a href="https://drive.google.com/drive/u/0/folders/1louZ55AJZ47QZ5ta50Oo2jhyZnBAGV34">Never Mind the Buzzcocks</a></p>

<p><a href="https://www.isca-archive.org/interspeech_2024/yadav24_interspeech.html">Audio Mamba: Selective State Spaces for Self-Supervised Audio Representations</a>,
<a href="https://github.com/kaistmm/Audio-Mamba-AuM">code</a></p>

<p><a href="https://www.isca-archive.org/interspeech_2022/ploujnikov22_interspeech.html">SoundChoice: Grapheme-to-Phoneme Models with Semantic Disambiguation</a></p>

<p><a href="https://github.com/Theomat/sbsur">Theomat/sbsur</a> — Stochastic Beam Search + Unique Randomizer</p>

<p><a href="https://github.com/RF5/transfusion-asr">RF5/transfusion-asr</a> — Transcribing Speech with Multinomial Diffusion, training code and models.</p>

<p><a href="https://www.reddit.com/r/AudioBookBay/">r/AudioBookBay</a></p>

<blockquote>
  <p>It has also been shown that adding pronunciation variants to the dictionary has a point of diminishing returns, as over-generated pronunciations can lead to ambiguity in the decoder and degrade its performance</p>
</blockquote>

<p><a href="https://www.lti.cs.cmu.edu/people/alumni/alumni-thesis/nallasamy-udhyakumar-thesis.pdf">Adaptation techniques to improve ASR performance on accented speakers</a></p>

<p><a href="https://arxiv.org/abs/2201.03713">CVSS Corpus and Massively Multilingual Speech-to-Speech Translation</a></p>

<p><a href="https://github.com/google-research-datasets/cvss">google-research-datasets/cvss</a> — CVSS: A Massively Multilingual Speech-to-Speech Translation Corpus</p>

<p><a href="https://github.com/Cymru-Breizh-Agile-Cymru-Project/vosk-cymraeg">Cymru-Breizh-Agile-Cymru-Project/vosk-cymraeg</a></p>

<p><a href="https://arxiv.org/abs/2505.17088">From Weak Labels to Strong Results: Utilizing 5,000 Hours of Noisy Classroom Transcripts with Minimal Accurate Data</a></p>

<p><a href="https://arxiv.org/abs/2412.06264">Flow Matching Guide and Code</a></p>

<p><a href="https://arxiv.org/abs/2103.15060">PnG BERT: Augmented BERT on Phonemes and Graphemes for Neural TTS</a></p>

<p><a href="https://arxiv.org/abs/2410.02678">Distilling an End-to-End Voice Assistant Without Instruction Training Data</a></p>

<p><a href="https://librivox.org/from-the-forests-by-henry-kendall/">From the Forests</a> — LibriVox volunteers bring you 18 recordings of From the Forests by Henry Kendall.
This was the Fortnightly Poetry project for March 29, 2020.</p>

<p><a href="https://github.com/xbpeng/MimicKit">xbpeng/MimicKit</a> — Suite of motion imitation methods for training motion controllers.</p>

<p><a href="https://arxiv.org/abs/2509.15969">VoXtream: Full-Stream Text-to-Speech with Extremely Low Latency</a>,
<a href="https://github.com/herimor/voxtream">code</a>,
<a href="https://huggingface.co/herimor/voxtream">model</a>,
<a href="https://huggingface.co/spaces/herimor/voxtream">space</a></p>

<p><a href="https://huggingface.co/Vyvo/VyvoTTS-v0-Qwen3-0.6B">Vyvo/VyvoTTS-v0-Qwen3-0.6B</a></p>

<p><a href="https://jlm.ipipan.waw.pl/index.php/JLM/issue/view/21">Special issue on finite-state methods in natural language processing and mathematics of language</a></p>

<p><a href="https://github.com/nv-tlabs/vipe">nv-tlabs/vipe</a> — ViPE: Video Pose Engine for Geometric 3D Perception</p>

<p><a href="https://donsheehy.github.io/datastructures/fullbook.pdf">A First Course on Data Structures in Python</a></p>

<p><a href="https://github.com/newton-physics/newton">newton-physics/newton</a> — An open-source, GPU-accelerated physics simulation engine built upon NVIDIA Warp, specifically targeting roboticists and simulation researchers.</p>

<p><a href="https://korteda.clarin-pl.eu/">Korpus Dawnych Polskich Tekstów Dramatycznych</a></p>

<p><a href="https://www.h2iosc.cnr.it/">H2IOSC</a></p>

<p><a href="https://arxiv.org/abs/2509.24006">SLA: Beyond Sparsity in Diffusion Transformers via Fine-Tunable Sparse-Linear Attention</a>,
<a href="https://github.com/thu-ml/SLA">code</a> (empty)</p>

<p><a href="https://www.clarin.si/repository/xmlui/handle/11356/1833">Spoken corpora of parliamentary debates ParlaSpeech 3.0</a></p>

<p><a href="https://github.com/vosen/ZLUDA">vosen/ZLUDA</a> — CUDA on non-NVIDIA GPUs</p>

<p><a href="https://github.com/MCG-NJU/MotionRAG">MCG-NJU/MotionRAG</a> — [NeurIPS 2025] MotionRAG: Motion Retrieval-Augmented Image-to-Video Generation</p>

<p><a href="https://smm26.iiit.ac.in/callForPaper.html">SMM2026</a></p>

<p><a href="https://github.com/SvarDOS/edrdos">SvarDOS/edrdos</a></p>

<p><a href="http://svardos.org/">SvarDOS - an open-source DOS distribution</a></p>

<p><a href="https://github.com/Continual-Intelligence/SEAL">Continual-Intelligence/SEAL</a> — Self-Adapting Language Models</p>

<p><a href="https://arxiv.org/abs/2510.11690">Diffusion Transformers with Representation Autoencoders</a>,
<a href="https://github.com/bytetriper/RAE">code</a></p>

<p><a href="https://github.com/yukara-ikemiya/Open-Miipher-2">yukara-ikemiya/Open-Miipher-2</a> — PyTorch implementation of Miipher-2 [2025] which is a speech restoration model by Google DeepMind</p>

<p><a href="https://arxiv.org/abs/2509.09201">DeCodec: Rethinking Audio Codecs as Universal Disentangled Representation Learners</a></p>

<p><a href="https://xiaomimimo.github.io/MiMo-Audio-Demo/">MiMo Audio</a>,
<a href="https://github.com/XiaomiMiMo/MiMo-Audio">code</a>,
<a href="https://github.com/XiaomiMiMo/MiMo-Audio/blob/main/MiMo-Audio-Technical-Report.pdf">report</a></p>

<p><a href="https://arxiv.org/abs/2510.15301">Latent Diffusion Model without Variational Autoencoder</a></p>

<p><a href="https://thenewstack.io/ken-thompson-recalls-unixs-rowdy-lock-picking-origins/">Ken Thompson Recalls Unix’s Rowdy, Lock-Picking Origins</a></p>

<p><a href="https://sprakresurser.isof.se/Svenska_spraknamndens_uttalsordbok/">Svenska språknämndens uttalsordbok</a></p>


  </div><a class="u-url" href="/notes/links/2025/10/03/misc-links.html" hidden></a>
</article>

      </div>
    </main><link id="fa-stylesheet" rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@7.0.0/css/all.min.css">

<footer class="site-footer h-card">
  <data class="u-url" value="/notes/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
      </div>
      <div class="footer-col">
        <p>Things I know I&#39;ll forget</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list">
  <li>
    <a href="https://jimregan.github.io/notes/feed.xml" target="_blank" title="Subscribe to syndication feed">
      <svg class="svg-icon grey" viewbox="0 0 16 16">
        <path d="M12.8 16C12.8 8.978 7.022 3.2 0 3.2V0c8.777 0 16 7.223 16 16h-3.2zM2.194
          11.61c1.21 0 2.195.985 2.195 2.196 0 1.21-.99 2.194-2.2 2.194C.98 16 0 15.017 0
          13.806c0-1.21.983-2.195 2.194-2.195zM10.606
          16h-3.11c0-4.113-3.383-7.497-7.496-7.497v-3.11c5.818 0 10.606 4.79 10.606 10.607z"
        />
      </svg>
    </a>
  </li>
</ul>
</div>

  </div>

</footer>

</body>

</html>
