<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Interesting links, 16/06/2025 | notes</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Interesting links, 16/06/2025" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Misc. interesting things." />
<meta property="og:description" content="Misc. interesting things." />
<link rel="canonical" href="https://jimregan.github.io/notes/links/2025/06/16/misc-links.html" />
<meta property="og:url" content="https://jimregan.github.io/notes/links/2025/06/16/misc-links.html" />
<meta property="og:site_name" content="notes" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-06-16T00:00:00-05:00" />
<script type="application/ld+json">
{"url":"https://jimregan.github.io/notes/links/2025/06/16/misc-links.html","@type":"BlogPosting","headline":"Interesting links, 16/06/2025","dateModified":"2025-06-16T00:00:00-05:00","datePublished":"2025-06-16T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://jimregan.github.io/notes/links/2025/06/16/misc-links.html"},"description":"Misc. interesting things.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/notes/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://jimregan.github.io/notes/feed.xml" title="notes" /><link rel="shortcut icon" type="image/x-icon" href="/notes/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper">
    <a class="site-title" rel="author" href="/notes/">notes</a>
      <nav class="site-nav">
        <input type="checkbox" id="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon"></span>
        </label>

        <div class="nav-items">
  <a class="nav-item" href="/notes/about/">About Me</a>
  <a class="nav-item" href="/notes/search/">Search</a>
  <a class="nav-item" href="/notes/categories/">Tags</a>
</div>

      </nav>
  </div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Interesting links, 16/06/2025</h1><p class="page-description">Misc. interesting things.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2025-06-16T00:00:00-05:00" itemprop="datePublished">
        Jun 16, 2025
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      3 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/notes/categories/#links">links</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
</ul><p><a href="https://arxiv.org/abs/2204.08582">MASSIVE: A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages</a>,
<a href="https://github.com/alexa/massive">code</a></p>

<p><a href="https://arxiv.org/abs/2011.13205">SLURP: A Spoken Language Understanding Resource Package</a>,
<a href="https://github.com/pswietojanski/slurp">data</a> — text is open, audio is not</p>

<p><a href="https://wikichao.github.io/ZeroSep/">ZeroSep: Separate Anything in Audio with Zero Training</a>,
<a href="https://arxiv.org/abs/2505.23625">arXiv</a>,
<a href="https://github.com/WikiChao/ZeroSep">code</a></p>

<p><a href="https://www.nationalgeographic.com/science/article/six-subtypes-depression-brain-imaging">There are 6 forms of depression, study shows. Here’s how they’re different.</a></p>

<p><a href="https://www.youtube.com/watch?v=UfcAVejslrU">Marconi Union - Weightless</a> — supposed to help with anxiety</p>

<p><a href="https://ieeexplore.ieee.org/document/6065528">Translation-Inspired OCR</a></p>

<hr>

<p><a href="http://skarbnicakaszubska.pl/wp-content/uploads/2018/04/GRAMATYKA-hiperlacza.pdf">Gramatika kaszëbsczégò jãzëka</a></p>

<p><a href="https://thedomcio.github.io/WonderfulPolishLanguage/#kashubian-kaszubski">Kashubian through Polish</a></p>

<p><a href="http://skarbnicakaszubska.pl/najo-uczba/">Najô Ùczba</a></p>

<p><a href="http://www.akademiabajkikaszubskiej.pl/bajki">Bajki Kaszubkie</a></p>

<p><a href="http://skarbnicakaszubska.pl/wp-content/uploads/2016/11/Slownik_1-1.pdf">Słownik Polsko-Kaszubski</a></p>

<hr>

<p><a href="https://aclanthology.org/2021.adaptnlp-1.16/">Dependency Parsing Evaluation for Low-resource Spontaneous Speech</a></p>

<p><a href="https://github.com/swerik-project/the-swedish-parliament-corpus">The Swedish Parliament Corpus</a></p>

<p><a href="https://github.com/UniversalDependencies/UD_Upper_Sorbian-UFAL">Upper Sorbian UD</a></p>

<p><a href="http://www.ub-filosofie.ro/~solcan/wt/gnu/d/hdjv.html">Insert OCRed text and annotations in DjVu</a></p>

<p><a href="https://arxiv.org/abs/2403.09207">TaxoLLaMA: WordNet-based Model for Solving Multiple Lexical Semantic Tasks</a>,
<a href="https://github.com/VityaVitalich/TaxoLLaMA">code</a></p>

<p><a href="https://www.reuters.com/legal/litigation/anthropic-wins-key-ruling-ai-authors-copyright-lawsuit-2025-06-24/">Anthropic wins key US ruling on AI training in authors’ copyright lawsuit</a></p>

<p><a href="https://aclanthology.org/2016.gwc-1.9/">CILI: the Collaborative Interlingual Index</a></p>

<p><a href="https://github.com/omwn/omw-data">omwn/omw-data</a> — This packages up data for the Open Multilingual Wordnet</p>

<p><a href="https://docs.docker.com/reference/cli/docker/image/save/">docker image save</a> — Save one or more images to a tar archive</p>

<p><a href="https://ai.meta.com/blog/v-jepa-2-world-model-benchmarks/">Introducing the V-JEPA 2 world model and new benchmarks for physical reasoning</a></p>

<p><a href="https://huggingface.co/facebook/vjepa2-vitl-fpc64-256">facebook/vjepa2-vitl-fpc64-256</a> — <strong>actually</strong> open source.</p>

<p><a href="https://specom.inf.u-szeged.hu/">SPECOM 2025</a>:</p>
<ul>
  <li>October 13-15, 2025</li>
  <li>deadline: June 30, 2025 (23:59, anywhere on Earth)</li>
  <li><a href="https://www.overleaf.com/latex/templates/springer-lecture-notes-in-computer-science/kzwwpvhwnvfj#.WuA4JS5uZpi">overleaf</a></li>
  <li><a href="https://easychair.org/conferences/?conf=specom2025">EasyChair</a></li>
</ul>

<p><a href="https://code.visualstudio.com/docs/devcontainers/tutorial">Dev Containers tutorial</a></p>

<p><a href="https://www.theguardian.com/lifeandstyle/2025/jun/16/better-life-trauma-healing">Terrible things happen in life – but it is possible to recover from them</a></p>

<p><a href="https://jinluzhang.site/projects/interactanything/">InteractAnything: Zero-shot Human Object-Interaction Synthesis via LLM Feedback and Object Affordance Parsing</a>,
<a href="https://arxiv.org/abs/2505.24315">arxiv</a></p>

<p><a href="https://github.com/szgabsz91/jdk-ocamorph-pyphen">szgabsz91/jdk-ocamorph-pyphen</a></p>

<p><a href="https://sprachkurs.sorbischlernen.de/">Sorbian course</a></p>

<p><a href="https://www.rbb-online.de/radio/sorbisches_programm/beitragsarchiv-audiothek/sorbische-sendungen-nachhoeren-serbske-wuscelanja-sluchas.html">Sorbian radio</a></p>

<p><a href="http://mokk.bme.hu/resources/hunpars/">hunpars</a></p>

<p><a href="http://mokk.bme.hu/resources/hunmorph/">hunmorph</a></p>

<p><a href="https://github.com/r0ller/hunmorph-foma">hunmorph-foma</a></p>

<p><a href="https://www.youtube.com/playlist?list=PLpshJy6oyjM9fD2YtXafkvuSCkkprffuO">Magyar népmesék sorozat</a>,
<a href="https://www.youtube.com/@HungarianFolkTales/videos">Hungarian Folk Tales</a></p>

<p><a href="https://eusipco2025.org/">Eupisco 2025</a></p>

<p><a href="https://github.com/JoFrhwld/FAVE">JoFrhwld/FAVE</a></p>

<p><a href="https://github.com/kornai/MoLHandbook">kornai/MoLHandbook</a></p>

<p><a href="https://direct.mit.edu/coli/article/47/2/255/98516/Universal-Dependencies">Universal Dependencies</a></p>

<p><a href="https://huggingface.co/Finnish-NLP/wav2vec2-xlsr-300m-finnish-lm">Finnish-NLP/wav2vec2-xlsr-300m-finnish-lm</a></p>

<p><a href="https://github.com/marl/crepe">CREPE</a></p>

<p><a href="https://huggingface.co/allenai/Molmo-7B-D-0924">allenai/Molmo-7B-D-0924</a></p>

<p><a href="https://sped.pub.ro/">SpeD 2025</a></p>
<ul>
  <li>Conference: October 19-22, 2025</li>
  <li>Paper submission (5 – 6 pages, IEEE format): July 7, 2025</li>
  <li><a href="https://openreview.net/group?id=IEEE.org/SpeD/2025/Conference">OpenReview</a></li>
  <li><a href="https://www.overleaf.com/gallery/tagged/ieee-official">Overleaf</a></li>
  <li>5-6 pages <strong>including</strong> references</li>
</ul>

<p><a href="https://arxiv.org/abs/2503.03983">Audio Flamingo 2: An Audio-Language Model with Long-Audio Understanding and Expert Reasoning Abilities</a></p>

<p><a href="https://voicebox.metademolab.com/">Voicebox: Text-Guided Multilingual Universal Speech Generation at Scale</a></p>

<p><a href="https://github.com/huspacy/huspacy">huspacy/huspacy</a></p>

<div class="jekyll-twitter-plugin">
<blockquote class="twitter-tweet">
<p lang="en" dir="ltr">Neural Network Activation Functions <a href="https://t.co/WYKOER1Ldz">pic.twitter.com/WYKOER1Ldz</a></p>— Dan | Machine Learning Engineer (@DanKornas) <a href="https://twitter.com/DanKornas/status/1940451888165715978?ref_src=twsrc%5Etfw">July 2, 2025</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>

<p><a href="https://huggingface.co/kyutai/tts-1.6b-en_fr">kyutai/tts-1.6b-en_fr</a>,</p>

<div class="jekyll-twitter-plugin">
<blockquote class="twitter-tweet">
<p lang="en" dir="ltr">The single biggest argument about statistics: is probability frequentist or Bayesian?<br><br>It's neither, and I'll explain why.<br><br>Buckle up. Deep-dive explanation incoming. <a href="https://t.co/PYlvOAGyB6">pic.twitter.com/PYlvOAGyB6</a></p>— Tivadar Danka (@TivadarDanka) <a href="https://twitter.com/TivadarDanka/status/1940727246412795939?ref_src=twsrc%5Etfw">July 3, 2025</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>

<p><a href="https://github.com/timtadh/zhang-shasha">timtadh/zhang-shasha</a> — Tree edit distance using the Zhang Shasha algorithm</p>

<p><a href="https://www.bennewsam.co.uk/TUTT.shtml">The Unbelievable Truth</a></p>

<p><a href="https://www.youtube.com/watch?v=M-NTrVJzQGI">Tool - Back to the beginning</a></p>

<p><a href="https://link.springer.com/article/10.1007/s10579-021-09574-0">The ParlaMint corpora of parliamentary proceedings</a></p>

<p><a href="https://link.springer.com/article/10.1007/s10579-024-09751-x">Spoken Spanish PoS tagging: gold standard dataset</a></p>

<p><a href="https://arxiv.org/abs/2507.05727">ContextASR-Bench: A Massive Contextual Speech Recognition Benchmark</a>,
<a href="https://github.com/MrSupW/ContextASR-Bench">code</a>,
<a href="https://huggingface.co/datasets/MrSupW/ContextASR-Bench">dataset</a></p>

<p><a href="https://arxiv.org/abs/2507.04554">Self-supervised learning of speech representations with Dutch archival data</a></p>

<p><a href="https://github.com/hitachi-speech/EEND">hitachi-speech/EEND</a> — EEND (End-to-End Neural Diarization) is a neural-network-based speaker diarization method.</p>

<p><a href="https://arxiv.org/abs/2203.17068">EEND-SS: Joint End-to-End Neural Speaker Diarization and Speech Separation for Flexible Number of Speakers</a></p>

<p><a href="https://github.com/openai/whisper/pull/2343">Add option to carry initial_prompt with the sliding window</a></p>

<p><a href="https://github.com/myshell-ai/MeloTTS">myshell-ai/MeloTTS</a> — High-quality multi-lingual text-to-speech library by MyShell.ai. Support English, Spanish, French, Chinese, Japanese and Korean.</p>

<p><a href="https://arxiv.org/abs/1905.05879">AUTOVC: Zero-Shot Voice Style Transfer with Only Autoencoder Loss</a></p>

<div class="jekyll-twitter-plugin">
<blockquote class="twitter-tweet">
<p lang="en" dir="ltr">Self-supervised Learning (SSL) vs Contrastive Language-Image (CLIP) models is a never-ending battle<br><br>What about using both? This Google paper does exactly that, and results are really good on many different tasks<br><br>TIPS is a model trained with a CLIP loss and 2 SSL losses [1/9] <a href="https://t.co/4tKDfM152W">pic.twitter.com/4tKDfM152W</a></p>— Gabriele Berton (@gabriberton) <a href="https://twitter.com/gabriberton/status/1941010323072602343?ref_src=twsrc%5Etfw">July 4, 2025</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>

<p><a href="https://arxiv.org/abs/2410.16512">TIPS: Text-Image Pretraining with Spatial awareness</a>,
<a href="https://github.com/google-deepmind/tips">code</a></p>

<p><a href="https://arxiv.org/abs/2304.04820">Binary Latent Diffusion</a>,
<a href="https://github.com/ZeWang95/BinaryLatentDiffusion">ZeWang95/BinaryLatentDiffusion</a></p>

<p><a href="https://huggingface.co/espnet/owsm_ctc_v4_1B">espnet/owsm_ctc_v4_1B</a></p>

<p><a href="https://ieeexplore.ieee.org/abstract/document/10023182">Phone-Level Pronunciation Scoring for L1 Using Weighted-Dynamic Time Warping</a></p>

<p><a href="https://arxiv.org/abs/2010.10694">An Investigation of the Relation Between Grapheme Embeddings and Pronunciation for Tacotron-based Systems</a>,
<a href="https://zenodo.org/records/6534268#.Ynn90C8RppQ">models</a></p>

<p><a href="https://datashare.ed.ac.uk/handle/10283/2353">The SIWIS French Speech Synthesis Database</a></p>

<p><a href="https://arxiv.org/abs/2506.22389">Towards Distributed Neural Architectures</a></p>

<p><a href="https://github.com/kb-labb/post-ocr-correction">kb-labb/post-ocr-correction</a></p>

<p><a href="v20250625">https://github.com/openai/whisper/commit/31243bad24cc746f07d4c8bfdd2d974872cb1803</a> — Add option to carry initial_prompt with the sliding window</p>

<p><a href="https://www.isca-archive.org/interspeech_2023/baas23_interspeech.html">Voice Conversion With Just Nearest Neighbors</a>,
<a href="https://github.com/bshall/knn-vc">code</a></p>

<p><a href="https://github.com/atong01/conditional-flow-matching">atong01/conditional-flow-matching</a> — TorchCFM: a Conditional Flow Matching library</p>

<p><a href="https://huggingface.co/THUDM/GLM-4-9B-0414">THUDM/GLM-4-9B-0414</a></p>

<p><a href="https://proceedings.neurips.cc/paper_files/paper/2024/hash/0382cb76309820f71c6eacd47b36ce71-Abstract-Conference.html">einspace: Searching for Neural Architectures from Fundamental Operations</a></p>

<p><a href="https://github.com/cadia-lvl/althingi-asr">cadia-lvl/althingi-asr</a></p>

<p><a href="https://arxiv.org/abs/2505.17088">From Weak Labels to Strong Results: Utilizing 5,000 Hours of Noisy Classroom Transcripts with Minimal Accurate Data</a></p>

<p><a href="https://arxiv.org/abs/2412.06264">Flow Matching Guide and Code</a></p>

<p><a href="https://arxiv.org/abs/2507.13264">Voxtral</a>,
<a href="https://huggingface.co/mistralai/Voxtral-Mini-3B-2507">mistralai/Voxtral-Mini-3B-2507</a></p>

<p><a href="https://arxiv.org/abs/2505.17589">CosyVoice 3: Towards In-the-wild Speech Generation via Scaling-up and Post-training</a>,
<a href="https://github.com/FunAudioLLM/CosyVoice">code</a></p>

<p><a href="https://arxiv.org/abs/2501.04877">Real-Time Textless Dialogue Generation</a></p>

<p><a href="https://www.arxiv.org/abs/2507.03912">Prosody Labeling with Phoneme-BERT and Speech Foundation Models</a></p>


  </div><a class="u-url" href="/notes/links/2025/06/16/misc-links.html" hidden></a>
</article>

      </div>
    </main><link id="fa-stylesheet" rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css">

<footer class="site-footer h-card">
  <data class="u-url" value="/notes/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
      </div>
      <div class="footer-col">
        <p>Things I know I&#39;ll forget</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list">
  <li>
    <a href="https://jimregan.github.io/notes/feed.xml" target="_blank" title="Subscribe to syndication feed">
      <svg class="svg-icon grey" viewbox="0 0 16 16">
        <path d="M12.8 16C12.8 8.978 7.022 3.2 0 3.2V0c8.777 0 16 7.223 16 16h-3.2zM2.194
          11.61c1.21 0 2.195.985 2.195 2.196 0 1.21-.99 2.194-2.2 2.194C.98 16 0 15.017 0
          13.806c0-1.21.983-2.195 2.194-2.195zM10.606
          16h-3.11c0-4.113-3.383-7.497-7.496-7.497v-3.11c5.818 0 10.606 4.79 10.606 10.607z"
        />
      </svg>
    </a>
  </li>
</ul>
</div>

  </div>

</footer>

</body>

</html>
