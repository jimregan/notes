<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Interesting links, 23/03/2025 | notes</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Interesting links, 23/03/2025" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Misc. interesting things." />
<meta property="og:description" content="Misc. interesting things." />
<link rel="canonical" href="https://jimregan.github.io/notes/links/2025/03/23/misc-links.html" />
<meta property="og:url" content="https://jimregan.github.io/notes/links/2025/03/23/misc-links.html" />
<meta property="og:site_name" content="notes" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-03-23T00:00:00-05:00" />
<script type="application/ld+json">
{"url":"https://jimregan.github.io/notes/links/2025/03/23/misc-links.html","@type":"BlogPosting","headline":"Interesting links, 23/03/2025","dateModified":"2025-03-23T00:00:00-05:00","datePublished":"2025-03-23T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://jimregan.github.io/notes/links/2025/03/23/misc-links.html"},"description":"Misc. interesting things.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/notes/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://jimregan.github.io/notes/feed.xml" title="notes" /><link rel="shortcut icon" type="image/x-icon" href="/notes/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper">
    <a class="site-title" rel="author" href="/notes/">notes</a>
      <nav class="site-nav">
        <input type="checkbox" id="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon"></span>
        </label>

        <div class="nav-items">
  <a class="nav-item" href="/notes/about/">About Me</a>
  <a class="nav-item" href="/notes/search/">Search</a>
  <a class="nav-item" href="/notes/categories/">Tags</a>
</div>

      </nav>
  </div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Interesting links, 23/03/2025</h1><p class="page-description">Misc. interesting things.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2025-03-23T00:00:00-05:00" itemprop="datePublished">
        Mar 23, 2025
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      3 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/notes/categories/#links">links</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
</ul><p><a href="https://www.theguardian.com/world/2025/feb/24/the-big-idea-what-do-we-really-mean-by-free-speech">The big idea: what do we really mean by free speech?</a></p>

<p><a href="https://arxiv.org/abs/2302.08549">Speaker Change Detection for Transformer Transducer ASR</a></p>

<p>Büszkeség és balítélet <a href="https://mek.oszk.hu/06000/06058/mp3/index.html">Audio</a>,
<a href="https://mek.oszk.hu/06000/06058/cedula.html">card</a>,
<a href="https://mek.oszk.hu/00300/00317/">Text</a></p>

<p><a href="https://mek.oszk.hu/keresesek/keresesf.phtml?formatum=MP3">Audiobooks in MP3</a></p>

<p><a href="https://github.com/KnugiHK/WhatsApp-Chat-Exporter">KnugiHK/WhatsApp-Chat-Exporter</a></p>

<p><a href="https://github.com/EliteAndroidApps/WhatsApp-Key-DB-Extractor">EliteAndroidApps/WhatsApp-Key-DB-Extractor</a></p>

<p><a href="https://www.bbcbasic.co.uk/bbcbasic.html">BBC Basic</a></p>

<p><a href="https://github.com/juice500ml/finetune_owsm">Finetuning for ESPNet OWSM Model</a></p>

<p><a href="https://venturebeat.com/ai/liquid-ais-new-star-model-architecture-outshines-transformer-efficiency/">Liquid AI’s new STAR model architecture outshines Transformer efficiency</a>,
<a href="https://www.liquid.ai/research/automated-architecture-synthesis-via-targeted-evolution">Automated Architecture Synthesis via Targeted Evolution</a>,
<a href="https://arxiv.org/abs/2411.17800">arxiv</a></p>

<p>ESPnet pull requests:</p>
<ul>
  <li><a href="https://github.com/espnet/espnet/pull/5998">Classification Task and AudioSet-20K #5998</a></li>
  <li><a href="https://github.com/espnet/espnet/pull/5980">add SASV support #5980</a></li>
  <li><a href="https://github.com/espnet/espnet/pull/5840">Add RATS dataset for SV task</a></li>
  <li><a href="https://github.com/espnet/espnet/pull/5941">Add SWBD text processing fix</a></li>
</ul>

<p><a href="https://aclanthology.org/2024.naacl-long.43/">The taste of IPA: Towards open-vocabulary keyword spotting and forced alignment in any language</a></p>

<p><a href="https://aclanthology.org/2020.emnlp-main.637/">Cold-start Active Learning through Self-supervised Language Modeling</a></p>

<p><a href="https://huggingface.co/blog/modernbert">ModernBERT</a></p>

<p><a href="https://www.marktechpost.com/2024/12/29/cmu-researchers-introduce-tnngen-an-ai-framework-that-automates-design-of-temporal-neural-networks-tnns-from-pytorch-software-models-to-post-layout-netlists/">CMU Researchers Introduce TNNGen</a></p>

<p><a href="https://blog.cloudflare.com/h3i/">Open sourcing h3i</a></p>

<p><a href="https://towardsdatascience.com/how-neural-networks-learn-a-probabilistic-viewpoint-0f6a78dc58e2/">How Neural Networks Learn: A Probabilistic Viewpoint</a></p>

<p><a href="https://github.com/FStarLang/karamel">FStarLang/karamel</a> — KaRaMeL is a tool for extracting low-level F* programs to readable C code</p>

<p><a href="https://github.com/facebookresearch/pytorch3d/commit/5ffeb4d580f5c7043ed1691e49d2d99f0f655bbc">Single directional chamfer distance and non-absolute cosine similarity</a></p>

<p><a href="https://github.com/facebookresearch/pytorch3d/blob/main/docs/tutorials/render_densepose.ipynb">Render DensePose</a> — Needs SMPL (which is not open source)</p>

<p><a href="https://github.com/RVC-Boss/GPT-SoVITS">RVC-Boss/GPT-SoVITS</a> — 1 min voice data can also be used to train a good TTS model! (few shot voice cloning)</p>

<p><a href="https://github.com/acids-ircam/ddsp_pytorch">acids-ircam/ddsp_pytorch</a> — Implementation of Differentiable Digital Signal Processing (DDSP) in Pytorch</p>

<p><a href="https://arxiv.org/abs/2309.07658">DDSP-based Neural Waveform Synthesis of Polyphonic Guitar Performance from String-wise MIDI Input</a>,
<a href="https://github.com/erl-j/ddsp-guitar">code</a></p>

<p><a href="https://github.com/jryban/frechet-music-distance">jryban/frechet-music-distance</a></p>

<p><a href="https://arxiv.org/abs/2503.01174">Talking Turns: Benchmarking Audio Foundation Models on Turn-Taking Dynamics</a></p>

<p><a href="https://github.com/huggingface/speech-to-speech">huggingface/speech-to-speech</a></p>

<p><a href="https://www.inference.vc/mixup-data-dependent-data-augmentation/">mixup: Data-Dependent Data Augmentation</a></p>

<p><a href="https://www.inference.vc/high-dimensional-gaussian-distributions-are-soap-bubble/">Gaussian Distributions are Soap Bubbles</a></p>

<p><a href="https://sander.ai/2020/09/01/typicality.html">Musings on Typicality</a></p>

<p><a href="https://github.com/nebius/kvax">nebius/kvax</a> — A FlashAttention implementation for JAX with support for efficient document mask computation and context parallelism.</p>

<p><a href="https://aslp-lab.github.io/DiffRhythm.github.io/">DiffRhythm: Blazingly Fast and Embarrassingly Simple End-to-End Full-Length Song Generation with Latent Diffusion</a>,
<a href="https://github.com/ASLP-lab/DiffRhythm">code</a>,
<a href="https://arxiv.org/abs/2503.01183">arxiv</a></p>

<p><a href="https://github.com/PeterGriffinJin/Search-R1">PeterGriffinJin/Search-R1</a> — Search-R1: An Efficient, Scalable RL Training Framework for Reasoning &amp; Search Engine Calling interleaved LLM based on veRL</p>

<p><a href="https://github.com/MatthewCYM/VoiceBench">MatthewCYM/VoiceBench</a> — VoiceBench: Benchmarking LLM-Based Voice Assistants</p>

<p><a href="https://github.com/IDEA-Research/Grounded-SAM-2">IDEA-Research/Grounded-SAM-2</a> — Grounded SAM 2: Ground and Track Anything in Videos with Grounding DINO, Florence-2 and SAM 2</p>

<div class="jekyll-twitter-plugin">
<blockquote class="twitter-tweet">
<p lang="en" dir="ltr">New 3h31m video on YouTube:<br>"Deep Dive into LLMs like ChatGPT"<br><br>This is a general audience deep dive into the Large Language Model (LLM) AI technology that powers ChatGPT and related products. It is covers the full training stack of how the models are developed, along with mental… <a href="https://t.co/Di0XNgdlwC">pic.twitter.com/Di0XNgdlwC</a></p>— Andrej Karpathy (@karpathy) <a href="https://twitter.com/karpathy/status/1887211193099825254?ref_src=twsrc%5Etfw">February 5, 2025</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

</div>

<p><a href="https://www.youtube.com/watch?v=7xTGNNLPyMI">Deep Dive into LLMs like ChatGPT</a></p>

<p><a href="https://www.hungarianpod101.com/blog/2019/04/19/best-hungarian-tv-shows-to-improve-hungarian/">Must-Watch Hungarian TV Series to Improve Your Hungarian</a></p>

<p><a href="https://www.reddit.com/r/hungarian/wiki/resources/">r/hungarian resources</a></p>

<p><a href="https://www.youtube.com/watch?v=IHeEi2Fj5Mw&amp;list=PLU_vdD4vtCbs0587s3KpeJtISBZ-pMza_&amp;index=1">Speaking Hungarian S01</a></p>

<p><a href="https://github.com/ml-explore/mlx-lm">ml-explore/mlx-lm</a> — Run LLMs with MLX</p>

<p><a href="https://kyutai.org/moshivis">MoshiVis — Teaching Moshi to Converse about Images</a></p>

<p><a href="https://mistral.ai/news/pixtral-12b">Announcing Pixtral 12B</a></p>

<p><a href="https://arxiv.org/abs/2410.00037">Moshi: a speech-text foundation model for real-time dialogue</a>,
<a href="https://github.com/kyutai-labs/moshi/">code</a></p>

<p><a href="https://blog.ezyang.com/2019/05/pytorch-internals/">PyTorch internals</a></p>

<p><a href="https://arxiv.org/abs/2503.07565">Inductive Moment Matching</a></p>

<p><a href="https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503">mistralai/Mistral-Small-3.1-24B-Instruct-2503</a></p>

<p><a href="https://arxiv.org/abs/2503.12847">Robust Audio-Visual Segmentation via Audio-Guided Visual Convergent Alignment</a></p>

<p><a href="https://www.fast.ai/posts/2025-02-20-fasttransform">fasttransform: Reversible Pipelines Made Simple</a></p>

<p><a href="https://huggingface.co/nvidia/canary-1b-flash">nvidia/canary-1b-flash</a> — CC-BY</p>

<p><a href="https://azure.microsoft.com/en-us/blog/empowering-innovation-the-next-generation-of-the-phi-family/">Empowering innovation: The next generation of the Phi family</a>,
<a href="https://huggingface.co/microsoft/Phi-4-multimodal-instruct">microsoft/Phi-4-multimodal-instruct</a></p>

<p><a href="https://kempnerinstitute.harvard.edu/research/deeper-learning/traveling-waves-integrate-spatial-information-through-time/">Traveling Waves Integrate Spatial Information Through Time</a></p>

<p><a href="https://arxiv.org/abs/2104.08860">CLIP4Clip: An Empirical Study of CLIP for End to End Video Clip Retrieval</a>,
<a href="https://github.com/ArrowLuo/CLIP4Clip">code</a></p>

<p><a href="https://github.com/yzhuoning/Awesome-CLIP">yzhuoning/Awesome-CLIP</a></p>

<p><a href="https://arxiv.org/abs/2503.23762">UniSep: Universal Target Audio Separation with Language Models at Scale</a></p>

<p><a href="https://arxiv.org/abs/2503.22687">Qieemo: Speech Is All You Need in the Emotion Recognition in Conversations</a></p>

<p><a href="https://arxiv.org/abs/2503.04713">Scaling Rich Style-Prompted Text-to-Speech Datasets</a>,
<a href="https://github.com/ajd12342/paraspeechcaps">code</a> — models and data not open.</p>

<p><a href="https://arxiv.org/abs/2503.20212">Dolphin: A Large-Scale Automatic Speech Recognition Model for Eastern Languages</a>,
<a href="https://github.com/DataoceanAI/Dolphin">code</a>,
<a href="https://huggingface.co/DataoceanAI/dolphin-small">small</a>,
<a href="https://huggingface.co/DataoceanAI/dolphin-base">base</a></p>

<p><a href="https://github.com/NVIDIA/NeMo/commit/29be3b88ea708a87440204205dea71095ad68a15">NeMo - AED Decoding with N-Gram LM</a></p>

<p><a href="https://arxiv.org/abs/2503.22703">Audio Compression using Periodic Gabor with Biorthogonal Exchange: Implementation Using the Zak Transform</a></p>

<p><a href="https://arxiv.org/abs/2409.12560">AudioComposer: Towards Fine-grained Audio Generation with Natural Language Descriptions</a></p>

<p><a href="https://arxiv.org/abs/2503.20499">FireRedTTS-1S: An Upgraded Streamable Foundation Text-to-Speech System</a>,
<a href="https://github.com/FireRedTeam/FireRedTTS">code</a></p>

<p><a href="https://arxiv.org/abs/2503.22200">Enhance Generation Quality of Flow Matching V2A Model via Multi-Step CoT-Like Guidance and Combined Preference Optimization</a></p>

<p><a href="https://arxiv.org/abs/2411.16537">RoboSpatial: Teaching Spatial Understanding to 2D and 3D Vision-Language Models for Robotics</a>,
<a href="https://huggingface.co/datasets/chanhee-luke/RoboSpatial-Home">dataset</a>,
<a href="https://github.com/chanhee-luke/RoboSpatial-Eval">eval code</a></p>

<p><a href="https://github.com/espnet/espnet/blob/92f6cbce6167ba8c7591d323834a2342ed2cf2ce/espnet2/s2t/espnet_ctc_model.py#L20">OSWM CTC</a>,
<a href="https://github.com/espnet/espnet/blob/92f6cbce6167ba8c7591d323834a2342ed2cf2ce/espnet2/bin/s2t_ctc_align.py#L4">OSWM CTC aligner</a></p>

<p><a href="https://github.com/espnet/espnet/blob/92f6cbce6167ba8c7591d323834a2342ed2cf2ce/espnet2/asr/encoder/e_branchformer_encoder.py">e-branchformer encoder</a></p>

<p><a href="https://arxiv.org/abs/2502.01777">CTC-DRO: Robust Optimization for Reducing Language Disparities in Speech Recognition</a>,
<a href="https://github.com/Bartelds/ctc-dro">code</a>,
<a href="https://github.com/Bartelds/espnet/tree/master/egs2/asr_dro/asr1">espnet code</a></p>

<p><a href="https://huggingface.co/llava-hf/llava-v1.6-mistral-7b-hf">llava-hf/llava-v1.6-mistral-7b-hf</a></p>

<p><a href="https://huggingface.co/01-ai/Yi-34B">01-ai/Yi-34B</a></p>

<p><a href="https://ceur-ws.org/Vol-3658/paper7.pdf">Prompt-based Alignment of Headlines and Images Using OpenCLIP</a>,
<a href="https://ceur-ws.org/Vol-3658/">workshop</a></p>

<p><a href="https://ceur-ws.org/Vol-3658/paper20.pdf">Optimizing Visual Pairings: A CLIP Framework for Precision News Image Rematching</a>,
<a href="https://ceur-ws.org/Vol-3658/">workshop</a></p>

<p><a href="https://github.com/rom1504/clip-retrieval">rom1504/clip-retrieval</a> — Easily compute clip embeddings and build a clip retrieval system with them</p>

<p><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9747669">Wav2CLIP: Learning Robust Audio Representations From CLIP</a>,
<a href="https://arxiv.org/abs/2110.11499">arXiv</a>,
<a href="https://github.com/descriptinc/lyrebird-Wav2CLIP">code</a>,
<a href="https://replicate.com/hohsiangwu/wav2clip">demo</a></p>

<p><a href="https://arxiv.org/pdf/2212.03640">Fine-tuned CLIP Models are Efficient Video Learners</a>,
<a href="https://github.com/muzairkhattak/ViFi-CLIP">code</a></p>

<p><a href="https://github.com/dmlc/decord">dmlc/decord</a> — An efficient video loader for deep learning with smart shuffling that’s super easy to digest</p>

<p><a href="https://huggingface.co/ibm-granite/granite-speech-3.2-8b">ibm-granite/granite-speech-3.2-8b</a>,
based on <a href="https://huggingface.co/ibm-granite/granite-3.1-8b-base">granite-3.1-8b-base</a></p>

<p><a href="https://huggingface.co/Qwen/Qwen2.5-Omni-7B">Qwen/Qwen2.5-Omni-7B</a>,
<a href="https://github.com/QwenLM/Qwen2.5-Omni">code</a></p>

<p><a href="https://huggingface.co/KBLab/kb-whisper-large">KBLab/kb-whisper-large</a></p>

<p><a href="https://huggingface.co/datasets/KBLab/rixvox-v2">KBLab/rixvox-v2</a></p>

<p><a href="https://github.com/ishine/PnG-BERT">ishine/PnG-BERT</a> – unofficial implementation of <a href="https://www.isca-archive.org/interspeech_2021/jia21_interspeech.html">PnG BERT: Augmented BERT on Phonemes and Graphemes for Neural TTS</a></p>

<p><a href="https://www.nature.com/articles/s41598-025-94170-3">People are poorly equipped to detect AI-powered voice clones</a></p>

<p><a href="https://github.com/r9y9/pysptk">r9y9/pysptk</a> — A python wrapper for Speech Signal Processing Toolkit (SPTK).</p>

<p><a href="https://github.com/jameslyons/python_speech_features">jameslyons/python_speech_features</a> — provides common speech features for ASR including MFCCs and filterbank energies</p>


  </div><a class="u-url" href="/notes/links/2025/03/23/misc-links.html" hidden></a>
</article>

      </div>
    </main><link id="fa-stylesheet" rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@latest/css/all.min.css">

<footer class="site-footer h-card">
  <data class="u-url" value="/notes/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
      </div>
      <div class="footer-col">
        <p>Things I know I&#39;ll forget</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list">
  <li>
    <a href="https://jimregan.github.io/notes/feed.xml" target="_blank" title="Subscribe to syndication feed">
      <svg class="svg-icon grey" viewbox="0 0 16 16">
        <path d="M12.8 16C12.8 8.978 7.022 3.2 0 3.2V0c8.777 0 16 7.223 16 16h-3.2zM2.194
          11.61c1.21 0 2.195.985 2.195 2.196 0 1.21-.99 2.194-2.2 2.194C.98 16 0 15.017 0
          13.806c0-1.21.983-2.195 2.194-2.195zM10.606
          16h-3.11c0-4.113-3.383-7.497-7.496-7.497v-3.11c5.818 0 10.606 4.79 10.606 10.607z"
        />
      </svg>
    </a>
  </li>
</ul>
</div>

  </div>

</footer>

</body>

</html>
